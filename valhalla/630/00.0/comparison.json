{"files":[{"patch":"@@ -348,0 +348,1 @@\n+            cat build\/*\/test-results\/*\/text\/other_errors.txt ;\n@@ -814,0 +815,1 @@\n+            cat build\/*\/test-results\/*\/text\/other_errors.txt ;\n@@ -1225,0 +1227,1 @@\n+            Get-Content -Path build\\*\\test-results\\*\\*\\other_errors.txt ;\n@@ -1618,0 +1621,1 @@\n+            cat build\/*\/test-results\/*\/text\/other_errors.txt ;\n","filename":".github\/workflows\/submit.yml","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+version=19\n","filename":".jcheck\/conf","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -453,1 +453,1 @@\n-            dependencies: [\"devkit\", \"gtest\"],\n+            dependencies: [\"devkit\", \"gtest\", \"pandoc\"],\n@@ -1103,0 +1103,11 @@\n+    var pandoc_version;\n+    if (input.build_cpu == \"aarch64\") {\n+        if (input.build_os == \"macosx\") {\n+            pandoc_version = \"2.14.0.2+1.0\";\n+        } else {\n+            pandoc_version = \"2.5+1.0\";\n+        }\n+    } else {\n+        pandoc_version = \"2.3.1+1.0\";\n+    }\n+\n@@ -1157,1 +1168,1 @@\n-            revision: \"1.33+1.0\"\n+            revision: \"1.34+1.0\"\n@@ -1161,8 +1172,1 @@\n-            \/\/ Use custom build of JCov\n-            \/\/ See CODETOOLS-7902734 for more info.\n-            \/\/ server: \"jpg\",\n-            \/\/ product: \"jcov\",\n-            \/\/ version: \"3.0\",\n-            \/\/ build_number: \"b07\",\n-            \/\/ file: \"bundles\/jcov-3_0.zip\",\n-            revision: \"3.0-9-jdk-asm+1.0\",\n+            revision: \"3.0-12-jdk-asm+1.0\",\n@@ -1215,1 +1219,1 @@\n-            revision: (input.build_cpu == 'aarch64' ? \"2.5+1.0\" : \"2.3.1+1.0\"),\n+            revision: pandoc_version,\n","filename":"make\/conf\/jib-profiles.js","additions":15,"deletions":11,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-DEFAULT_VERSION_FEATURE=18\n+DEFAULT_VERSION_FEATURE=19\n@@ -36,2 +36,2 @@\n-DEFAULT_VERSION_DATE=2022-03-15\n-DEFAULT_VERSION_CLASSFILE_MAJOR=62  # \"`$EXPR $DEFAULT_VERSION_FEATURE + 44`\"\n+DEFAULT_VERSION_DATE=2022-09-20\n+DEFAULT_VERSION_CLASSFILE_MAJOR=63  # \"`$EXPR $DEFAULT_VERSION_FEATURE + 44`\"\n@@ -40,2 +40,2 @@\n-DEFAULT_ACCEPTABLE_BOOT_VERSIONS=\"17 18\"\n-DEFAULT_JDK_SOURCE_TARGET_VERSION=18\n+DEFAULT_ACCEPTABLE_BOOT_VERSIONS=\"17 18 19\"\n+DEFAULT_JDK_SOURCE_TARGET_VERSION=19\n","filename":"make\/conf\/version-numbers.conf","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2013, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -133,7 +133,0 @@\n-ifneq ($(call check-jvm-feature, nmt), true)\n-  JVM_CFLAGS_FEATURES += -DINCLUDE_NMT=0\n-  JVM_EXCLUDE_FILES += \\\n-      memBaseline.cpp memReporter.cpp mallocTracker.cpp virtualMemoryTracker.cpp nmtCommon.cpp \\\n-      memTracker.cpp nmtDCmd.cpp mallocSiteTable.cpp threadStackTracker.cpp\n-endif\n-\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -2500,1 +2500,1 @@\n-const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+const TypeVectMask* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n@@ -2751,4 +2751,1 @@\n-  \/\/ StoreVector (VectorStoreMask src)\n-  if (is_vshift_con_pattern(n, m) ||\n-      (UseSVE > 0 && m->Opcode() == Op_VectorStoreMask && n->Opcode() == Op_StoreVector) ||\n-      is_vector_arith_imm_pattern(n, m)) {\n+  if (is_vshift_con_pattern(n, m) || is_vector_arith_imm_pattern(n, m)) {\n@@ -3936,2 +3933,3 @@\n-    \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n-    __ orr(tmp, disp_hdr, markWord::unlocked_value);\n+    if (!UseHeavyMonitors) {\n+      \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n+      __ orr(tmp, disp_hdr, markWord::unlocked_value);\n@@ -3939,32 +3937,4 @@\n-    if (EnableValhalla) {\n-      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n-      __ andr(tmp, tmp, ~((int) markWord::inline_type_bit_in_place));\n-    }\n-\n-    \/\/ Initialize the box. (Must happen before we update the object mark!)\n-    __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Compare object markWord with an unlocked value (tmp) and if\n-    \/\/ equal exchange the stack address of our box with object markWord.\n-    \/\/ On failure disp_hdr contains the possibly locked markWord.\n-    __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n-               \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n-    __ br(Assembler::EQ, cont);\n-\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n-    \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-    \/\/ object, will have now locked it will continue at label cont\n-\n-    __ bind(cas_failed);\n-    \/\/ We did not see an unlocked object so try the fast recursive case.\n-\n-    \/\/ Check if the owner is self by comparing the value in the\n-    \/\/ markWord of object (disp_hdr) with the stack pointer.\n-    __ mov(rscratch1, sp);\n-    __ sub(disp_hdr, disp_hdr, rscratch1);\n-    __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-    \/\/ If condition is true we are cont and hence we can store 0 as the\n-    \/\/ displaced header in the box, which indicates that it is a recursive lock.\n-    __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n-    __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+      if (EnableValhalla) {\n+        \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+        __ andr(tmp, tmp, ~((int) markWord::inline_type_bit_in_place));\n+      }\n@@ -3972,0 +3942,30 @@\n+      \/\/ Initialize the box. (Must happen before we update the object mark!)\n+      __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ Compare object markWord with an unlocked value (tmp) and if\n+      \/\/ equal exchange the stack address of our box with object markWord.\n+      \/\/ On failure disp_hdr contains the possibly locked markWord.\n+      __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n+                 \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n+      __ br(Assembler::EQ, cont);\n+\n+      assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+\n+      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n+      \/\/ object, will have now locked it will continue at label cont\n+\n+      __ bind(cas_failed);\n+      \/\/ We did not see an unlocked object so try the fast recursive case.\n+\n+      \/\/ Check if the owner is self by comparing the value in the\n+      \/\/ markWord of object (disp_hdr) with the stack pointer.\n+      __ mov(rscratch1, sp);\n+      __ sub(disp_hdr, disp_hdr, rscratch1);\n+      __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n+      \/\/ If condition is true we are cont and hence we can store 0 as the\n+      \/\/ displaced header in the box, which indicates that it is a recursive lock.\n+      __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n+      __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    } else {\n+      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n+    }\n@@ -4017,2 +4017,3 @@\n-    \/\/ Find the lock address and load the displaced header from the stack.\n-    __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    if (!UseHeavyMonitors) {\n+      \/\/ Find the lock address and load the displaced header from the stack.\n+      __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n@@ -4020,3 +4021,4 @@\n-    \/\/ If the displaced header is 0, we have a recursive unlock.\n-    __ cmp(disp_hdr, zr);\n-    __ br(Assembler::EQ, cont);\n+      \/\/ If the displaced header is 0, we have a recursive unlock.\n+      __ cmp(disp_hdr, zr);\n+      __ br(Assembler::EQ, cont);\n+    }\n@@ -4028,3 +4030,4 @@\n-    \/\/ Check if it is still a light weight lock, this is is true if we\n-    \/\/ see the stack address of the basicLock in the markWord of the\n-    \/\/ object.\n+    if (!UseHeavyMonitors) {\n+      \/\/ Check if it is still a light weight lock, this is is true if we\n+      \/\/ see the stack address of the basicLock in the markWord of the\n+      \/\/ object.\n@@ -4032,2 +4035,5 @@\n-    __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n-               \/*release*\/ true, \/*weak*\/ false, tmp);\n+      __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n+                 \/*release*\/ true, \/*weak*\/ false, tmp);\n+    } else {\n+      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n+    }\n@@ -4042,1 +4048,0 @@\n-    __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));\n@@ -4046,3 +4051,0 @@\n-    __ cmp(rscratch1, rthread);\n-    __ br(Assembler::NE, cont);\n-\n@@ -4054,1 +4056,1 @@\n-    \/\/ flag == EQ was set in the ownership check above\n+    __ cmp(disp_hdr, disp_hdr); \/\/ Sets flags for result\n@@ -8595,1 +8597,1 @@\n-    __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);\n+    __ mov($tmp$$FloatRegister, __ D, 0, $src$$Register);\n@@ -8598,1 +8600,1 @@\n-    __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);\n+    __ mov($dst$$Register, $tmp$$FloatRegister, __ D, 0);\n@@ -8620,1 +8622,1 @@\n-    __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);\n+    __ mov($dst$$Register, $tmp$$FloatRegister, __ D, 0);\n@@ -8638,1 +8640,1 @@\n-    __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);\n+    __ mov($tmp$$FloatRegister, __ D, 0, $src$$Register);\n@@ -8641,1 +8643,1 @@\n-    __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);\n+    __ mov($dst$$Register, $tmp$$FloatRegister, __ D, 0);\n@@ -8663,1 +8665,1 @@\n-    __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);\n+    __ mov($dst$$Register, $tmp$$FloatRegister, __ D, 0);\n@@ -17100,1 +17102,2 @@\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4,\n+         USE_KILL src, USE_KILL dst, USE len, KILL cr);\n@@ -17102,1 +17105,1 @@\n-  format %{ \"String Compress $src,$dst -> $result    \/\/ KILL R1, R2, R3, R4\" %}\n+  format %{ \"String Compress $src,$dst,$len -> $result  \/\/ KILL $src,$dst\" %}\n@@ -17105,0 +17108,1 @@\n+                           $result$$Register,\n@@ -17106,2 +17110,1 @@\n-                           $tmp3$$FloatRegister, $tmp4$$FloatRegister,\n-                           $result$$Register);\n+                           $tmp3$$FloatRegister, $tmp4$$FloatRegister);\n@@ -17109,1 +17112,1 @@\n-  ins_pipe( pipe_slow );\n+  ins_pipe(pipe_slow);\n@@ -17134,2 +17137,2 @@\n-                          vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,\n-                          vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,\n+                          vRegD_V0 vtmp0, vRegD_V1 vtmp1,\n+                          vRegD_V2 vtmp2, vRegD_V3 vtmp3,\n@@ -17140,2 +17143,2 @@\n-  effect(USE_KILL src, USE_KILL dst, USE_KILL len,\n-         KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);\n+  effect(USE_KILL src, USE_KILL dst, USE len,\n+         KILL vtmp0, KILL vtmp1, KILL vtmp2, KILL vtmp3, KILL cr);\n@@ -17143,1 +17146,1 @@\n-  format %{ \"Encode array $src,$dst,$len -> $result\" %}\n+  format %{ \"Encode ISO array $src,$dst,$len -> $result\" %}\n@@ -17146,2 +17149,3 @@\n-         $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,\n-         $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);\n+                        $result$$Register, false,\n+                        $vtmp0$$FloatRegister, $vtmp1$$FloatRegister,\n+                        $vtmp2$$FloatRegister, $vtmp3$$FloatRegister);\n@@ -17149,1 +17153,21 @@\n-  ins_pipe( pipe_class_memory );\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n+instruct encode_ascii_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,\n+                            vRegD_V0 vtmp0, vRegD_V1 vtmp1,\n+                            vRegD_V2 vtmp2, vRegD_V3 vtmp3,\n+                            iRegI_R0 result, rFlagsReg cr)\n+%{\n+  predicate(((EncodeISOArrayNode*)n)->is_ascii());\n+  match(Set result (EncodeISOArray src (Binary dst len)));\n+  effect(USE_KILL src, USE_KILL dst, USE len,\n+         KILL vtmp0, KILL vtmp1, KILL vtmp2, KILL vtmp3, KILL cr);\n+\n+  format %{ \"Encode ASCII array $src,$dst,$len -> $result\" %}\n+  ins_encode %{\n+    __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,\n+                        $result$$Register, true,\n+                        $vtmp0$$FloatRegister, $vtmp1$$FloatRegister,\n+                        $vtmp2$$FloatRegister, $vtmp3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_class_memory);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":98,"deletions":74,"binary":false,"changes":172,"status":"modified"},{"patch":"@@ -192,8 +192,7 @@\n-  } else  {\n-    intptr_t addr_offset = intptr_t(addr->disp());\n-    if (Address::offset_ok_for_immed(addr_offset, addr->scale()))\n-      return Address(base, addr_offset, Address::lsl(addr->scale()));\n-    else {\n-      __ mov(tmp, addr_offset);\n-      return Address(base, tmp, Address::lsl(addr->scale()));\n-    }\n+  } else {\n+    assert(addr->scale() == 0,\n+           \"expected for immediate operand, was: %d\", addr->scale());\n+    ptrdiff_t offset = ptrdiff_t(addr->disp());\n+    \/\/ NOTE: Does not handle any 16 byte vector access.\n+    const uint type_size = type2aelembytes(addr->type(), true);\n+    return __ legitimize_address(Address(base, offset), type_size, tmp);\n@@ -444,1 +443,5 @@\n-    __ unlock_object(r5, r4, r0, *stub->entry());\n+    if (UseHeavyMonitors) {\n+      __ b(*stub->entry());\n+    } else {\n+      __ unlock_object(r5, r4, r0, *stub->entry());\n+    }\n@@ -1014,8 +1017,1 @@\n-      \/\/ FIXME: OMG this is a horrible kludge.  Any offset from an\n-      \/\/ address that matches klass_offset_in_bytes() will be loaded\n-      \/\/ as a word, not a long.\n-      if (UseCompressedClassPointers && addr->disp() == oopDesc::klass_offset_in_bytes()) {\n-        __ ldrw(dest->as_register(), as_Address(from_addr));\n-      } else {\n-        __ ldr(dest->as_register(), as_Address(from_addr));\n-      }\n+      __ ldr(dest->as_register(), as_Address(from_addr));\n@@ -1060,4 +1056,0 @@\n-  } else if (type == T_ADDRESS && addr->disp() == oopDesc::klass_offset_in_bytes()) {\n-    if (UseCompressedClassPointers) {\n-      __ decode_klass_not_null(dest->as_register());\n-    }\n@@ -2785,1 +2777,1 @@\n-  if (!UseFastLocking) {\n+  if (UseHeavyMonitors) {\n@@ -2804,0 +2796,16 @@\n+void LIR_Assembler::emit_load_klass(LIR_OpLoadKlass* op) {\n+  Register obj = op->obj()->as_pointer_register();\n+  Register result = op->result_opr()->as_pointer_register();\n+\n+  CodeEmitInfo* info = op->info();\n+  if (info != NULL) {\n+    add_debug_info_for_null_check_here(info);\n+  }\n+\n+  if (UseCompressedClassPointers) {\n+    __ ldrw(result, Address (obj, oopDesc::klass_offset_in_bytes()));\n+    __ decode_klass_not_null(result);\n+  } else {\n+    __ ldr(result, Address (obj, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":30,"deletions":22,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -158,1 +158,1 @@\n-      large_disp += index->as_jint() << shift;\n+      large_disp += ((intx)index->as_jint()) << shift;\n@@ -204,1 +204,1 @@\n-    assert(Address::offset_ok_for_immed(large_disp, 0), \"must be\");\n+    assert(Address::offset_ok_for_immed(large_disp, shift), \"failed for large_disp: \" INTPTR_FORMAT \" and shift %d\", large_disp, shift);\n@@ -214,18 +214,1 @@\n-\n-  LIR_Address* addr;\n-  if (index_opr->is_constant()) {\n-    addr = new LIR_Address(array_opr,\n-                           offset_in_bytes + (intx)(index_opr->as_jint()) * elem_size, type);\n-  } else {\n-    if (offset_in_bytes) {\n-      LIR_Opr tmp = new_pointer_register();\n-      __ add(array_opr, LIR_OprFact::intConst(offset_in_bytes), tmp);\n-      array_opr = tmp;\n-      offset_in_bytes = 0;\n-    }\n-    addr =  new LIR_Address(array_opr,\n-                            index_opr,\n-                            LIR_Address::scale(type),\n-                            offset_in_bytes, type);\n-  }\n-  return addr;\n+  return generate_address(array_opr, index_opr, shift, offset_in_bytes, type);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":3,"deletions":20,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -339,1 +339,1 @@\n-void C1_MacroAssembler::verified_entry() {\n+void C1_MacroAssembler::verified_entry(bool breakAtEntry) {\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -364,0 +364,1 @@\n+  fr.set_sp_is_trusted();\n@@ -469,3 +470,11 @@\n-  \/\/ we cannot rely upon the last fp having been saved to the thread\n-  \/\/ in C2 code but it will have been pushed onto the stack. so we\n-  \/\/ have to find it relative to the unextended sp\n+  \/\/ When the sp of a compiled frame is correct, we can get the correct sender sp\n+  \/\/ by unextended sp + frame size.\n+  \/\/ For the following two scenarios, the sp of a compiled frame is correct:\n+  \/\/  a) This compiled frame is built from the anchor.\n+  \/\/  b) This compiled frame is built from a callee frame, and the callee frame can\n+  \/\/    calculate its sp correctly.\n+  \/\/\n+  \/\/ For b), if the callee frame is a native code frame (such as leaf call), the sp of\n+  \/\/ the compiled frame cannot be calculated correctly. There is currently no suitable\n+  \/\/ solution to solve this problem perfectly. But when PreserveFramePointer is enabled,\n+  \/\/ we can get the correct sender sp by fp + 2 (that is sender_sp()).\n@@ -474,1 +483,2 @@\n-  intptr_t* l_sender_sp = unextended_sp() + _cb->frame_size();\n+  intptr_t* l_sender_sp = (!PreserveFramePointer || _sp_is_trusted) ? unextended_sp() + _cb->frame_size()\n+                                                                    : sender_sp();\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":15,"deletions":5,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -127,0 +127,5 @@\n+  \/\/ true means _sp value is correct and we can use it to get the sender's sp\n+  \/\/ of the compiled frame, otherwise, _sp value may be invalid and we can use\n+  \/\/ _fp to get the sender's sp if PreserveFramePointer is enabled.\n+  bool _sp_is_trusted;\n+\n@@ -171,0 +176,2 @@\n+  void set_sp_is_trusted() { _sp_is_trusted = true; }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -241,1 +241,1 @@\n-  __ lsr(card_addr, store_addr, CardTable::card_shift);\n+  __ lsr(card_addr, store_addr, CardTable::card_shift());\n@@ -500,1 +500,1 @@\n-  __ lsr(card_offset, card_offset, CardTable::card_shift);\n+  __ lsr(card_offset, card_offset, CardTable::card_shift());\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1BarrierSetAssembler_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-  __ lsr(obj, obj, CardTable::card_shift);\n+  __ lsr(obj, obj, CardTable::card_shift());\n@@ -67,2 +67,2 @@\n-  __ lsr(start, start, CardTable::card_shift);\n-  __ lsr(end, end, CardTable::card_shift);\n+  __ lsr(start, start, CardTable::card_shift());\n+  __ lsr(end, end, CardTable::card_shift());\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/cardTableBarrierSetAssembler_aarch64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,1 @@\n+#include \"ci\/ciEnv.hpp\"\n@@ -165,2 +166,1 @@\n-  } else if (Instruction_aarch64::extract(insn, 31, 22) == 0b1011100101 &&\n-             Instruction_aarch64::extract(insn, 4, 0) == 0b11111) {\n+  } else if (NativeInstruction::is_ldrw_to_zr(address(&insn))) {\n@@ -289,3 +289,0 @@\n-  } else if (Instruction_aarch64::extract(insn, 31, 22) == 0b1011100101 &&\n-             Instruction_aarch64::extract(insn, 4, 0) == 0b11111) {\n-    return 0;\n@@ -298,0 +295,7 @@\n+address MacroAssembler::target_addr_for_insn_or_null(address insn_addr, unsigned insn) {\n+  if (NativeInstruction::is_ldrw_to_zr(address(&insn))) {\n+    return 0;\n+  }\n+  return MacroAssembler::target_addr_for_insn(insn_addr, insn);\n+}\n+\n@@ -3532,1 +3536,1 @@\n-      mov(v16, T4S, 0, crc);\n+      mov(v16, S, 0, crc);\n@@ -3636,1 +3640,1 @@\n-      mov(tmp, v0, T1D, 0);\n+      mov(tmp, v0, D, 0);\n@@ -3639,1 +3643,1 @@\n-      mov(tmp, v0, T1D, 1);\n+      mov(tmp, v0, D, 1);\n@@ -3642,1 +3646,1 @@\n-      mov(tmp, v1, T1D, 0);\n+      mov(tmp, v1, D, 0);\n@@ -3645,1 +3649,1 @@\n-      mov(tmp, v1, T1D, 1);\n+      mov(tmp, v1, D, 1);\n@@ -5314,2 +5318,18 @@\n-\/\/ Intrinsic for sun\/nio\/cs\/ISO_8859_1$Encoder.implEncodeISOArray and\n-\/\/ java\/lang\/StringUTF16.compress.\n+\/\/ Intrinsic for\n+\/\/\n+\/\/ - sun\/nio\/cs\/ISO_8859_1$Encoder.implEncodeISOArray\n+\/\/     return the number of characters copied.\n+\/\/ - java\/lang\/StringUTF16.compress\n+\/\/     return zero (0) if copy fails, otherwise 'len'.\n+\/\/\n+\/\/ This version always returns the number of characters copied, and does not\n+\/\/ clobber the 'len' register. A successful copy will complete with the post-\n+\/\/ condition: 'res' == 'len', while an unsuccessful copy will exit with the\n+\/\/ post-condition: 0 <= 'res' < 'len'.\n+\/\/\n+\/\/ NOTE: Attempts to use 'ld2' (and 'umaxv' in the ISO part) has proven to\n+\/\/       degrade performance (on Ampere Altra - Neoverse N1), to an extent\n+\/\/       beyond the acceptable, even though the footprint would be smaller.\n+\/\/       Using 'umaxv' in the ASCII-case comes with a small penalty but does\n+\/\/       avoid additional bloat.\n+\/\/\n@@ -5317,3 +5337,3 @@\n-                      Register len, Register result,\n-                      FloatRegister Vtmp1, FloatRegister Vtmp2,\n-                      FloatRegister Vtmp3, FloatRegister Vtmp4)\n+                                      Register len, Register res, bool ascii,\n+                                      FloatRegister vtmp0, FloatRegister vtmp1,\n+                                      FloatRegister vtmp2, FloatRegister vtmp3)\n@@ -5321,97 +5341,3 @@\n-    Label DONE, SET_RESULT, NEXT_32, NEXT_32_PRFM, LOOP_8, NEXT_8, LOOP_1, NEXT_1,\n-        NEXT_32_START, NEXT_32_PRFM_START;\n-    Register tmp1 = rscratch1, tmp2 = rscratch2;\n-\n-      mov(result, len); \/\/ Save initial len\n-\n-      cmp(len, (u1)8); \/\/ handle shortest strings first\n-      br(LT, LOOP_1);\n-      cmp(len, (u1)32);\n-      br(LT, NEXT_8);\n-      \/\/ The following code uses the SIMD 'uzp1' and 'uzp2' instructions\n-      \/\/ to convert chars to bytes\n-      if (SoftwarePrefetchHintDistance >= 0) {\n-        ld1(Vtmp1, Vtmp2, Vtmp3, Vtmp4, T8H, src);\n-        subs(tmp2, len, SoftwarePrefetchHintDistance\/2 + 16);\n-        br(LE, NEXT_32_START);\n-        b(NEXT_32_PRFM_START);\n-        BIND(NEXT_32_PRFM);\n-          ld1(Vtmp1, Vtmp2, Vtmp3, Vtmp4, T8H, src);\n-        BIND(NEXT_32_PRFM_START);\n-          prfm(Address(src, SoftwarePrefetchHintDistance));\n-          orr(v4, T16B, Vtmp1, Vtmp2);\n-          orr(v5, T16B, Vtmp3, Vtmp4);\n-          uzp1(Vtmp1, T16B, Vtmp1, Vtmp2);\n-          uzp1(Vtmp3, T16B, Vtmp3, Vtmp4);\n-          uzp2(v5, T16B, v4, v5); \/\/ high bytes\n-          umov(tmp2, v5, D, 1);\n-          fmovd(tmp1, v5);\n-          orr(tmp1, tmp1, tmp2);\n-          cbnz(tmp1, LOOP_8);\n-          stpq(Vtmp1, Vtmp3, dst);\n-          sub(len, len, 32);\n-          add(dst, dst, 32);\n-          add(src, src, 64);\n-          subs(tmp2, len, SoftwarePrefetchHintDistance\/2 + 16);\n-          br(GE, NEXT_32_PRFM);\n-          cmp(len, (u1)32);\n-          br(LT, LOOP_8);\n-        BIND(NEXT_32);\n-          ld1(Vtmp1, Vtmp2, Vtmp3, Vtmp4, T8H, src);\n-        BIND(NEXT_32_START);\n-      } else {\n-        BIND(NEXT_32);\n-          ld1(Vtmp1, Vtmp2, Vtmp3, Vtmp4, T8H, src);\n-      }\n-      prfm(Address(src, SoftwarePrefetchHintDistance));\n-      uzp1(v4, T16B, Vtmp1, Vtmp2);\n-      uzp1(v5, T16B, Vtmp3, Vtmp4);\n-      orr(Vtmp1, T16B, Vtmp1, Vtmp2);\n-      orr(Vtmp3, T16B, Vtmp3, Vtmp4);\n-      uzp2(Vtmp1, T16B, Vtmp1, Vtmp3); \/\/ high bytes\n-      umov(tmp2, Vtmp1, D, 1);\n-      fmovd(tmp1, Vtmp1);\n-      orr(tmp1, tmp1, tmp2);\n-      cbnz(tmp1, LOOP_8);\n-      stpq(v4, v5, dst);\n-      sub(len, len, 32);\n-      add(dst, dst, 32);\n-      add(src, src, 64);\n-      cmp(len, (u1)32);\n-      br(GE, NEXT_32);\n-      cbz(len, DONE);\n-\n-    BIND(LOOP_8);\n-      cmp(len, (u1)8);\n-      br(LT, LOOP_1);\n-    BIND(NEXT_8);\n-      ld1(Vtmp1, T8H, src);\n-      uzp1(Vtmp2, T16B, Vtmp1, Vtmp1); \/\/ low bytes\n-      uzp2(Vtmp3, T16B, Vtmp1, Vtmp1); \/\/ high bytes\n-      fmovd(tmp1, Vtmp3);\n-      cbnz(tmp1, NEXT_1);\n-      strd(Vtmp2, dst);\n-\n-      sub(len, len, 8);\n-      add(dst, dst, 8);\n-      add(src, src, 16);\n-      cmp(len, (u1)8);\n-      br(GE, NEXT_8);\n-\n-    BIND(LOOP_1);\n-\n-    cbz(len, DONE);\n-    BIND(NEXT_1);\n-      ldrh(tmp1, Address(post(src, 2)));\n-      tst(tmp1, 0xff00);\n-      br(NE, SET_RESULT);\n-      strb(tmp1, Address(post(dst, 1)));\n-      subs(len, len, 1);\n-      br(GT, NEXT_1);\n-\n-    BIND(SET_RESULT);\n-      sub(result, result, len); \/\/ Return index where we stopped\n-                                \/\/ Return len == 0 if we processed all\n-                                \/\/ characters\n-    BIND(DONE);\n-}\n+  Register cnt = res;\n+  Register max = rscratch1;\n+  Register chk = rscratch2;\n@@ -5419,0 +5345,85 @@\n+  prfm(Address(src), PLDL1STRM);\n+  movw(cnt, len);\n+\n+#define ASCII(insn) do { if (ascii) { insn; } } while (0)\n+\n+  Label LOOP_32, DONE_32, FAIL_32;\n+\n+  BIND(LOOP_32);\n+  {\n+    cmpw(cnt, 32);\n+    br(LT, DONE_32);\n+    ld1(vtmp0, vtmp1, vtmp2, vtmp3, T8H, Address(post(src, 64)));\n+    \/\/ Extract lower bytes.\n+    FloatRegister vlo0 = v4;\n+    FloatRegister vlo1 = v5;\n+    uzp1(vlo0, T16B, vtmp0, vtmp1);\n+    uzp1(vlo1, T16B, vtmp2, vtmp3);\n+    \/\/ Merge bits...\n+    orr(vtmp0, T16B, vtmp0, vtmp1);\n+    orr(vtmp2, T16B, vtmp2, vtmp3);\n+    \/\/ Extract merged upper bytes.\n+    FloatRegister vhix = vtmp0;\n+    uzp2(vhix, T16B, vtmp0, vtmp2);\n+    \/\/ ISO-check on hi-parts (all zero).\n+    \/\/                          ASCII-check on lo-parts (no sign).\n+    FloatRegister vlox = vtmp1; \/\/ Merge lower bytes.\n+                                ASCII(orr(vlox, T16B, vlo0, vlo1));\n+    umov(chk, vhix, D, 1);      ASCII(cmlt(vlox, T16B, vlox));\n+    fmovd(max, vhix);           ASCII(umaxv(vlox, T16B, vlox));\n+    orr(chk, chk, max);         ASCII(umov(max, vlox, B, 0));\n+                                ASCII(orr(chk, chk, max));\n+    cbnz(chk, FAIL_32);\n+    subw(cnt, cnt, 32);\n+    st1(vlo0, vlo1, T16B, Address(post(dst, 32)));\n+    b(LOOP_32);\n+  }\n+  BIND(FAIL_32);\n+  sub(src, src, 64);\n+  BIND(DONE_32);\n+\n+  Label LOOP_8, SKIP_8;\n+\n+  BIND(LOOP_8);\n+  {\n+    cmpw(cnt, 8);\n+    br(LT, SKIP_8);\n+    FloatRegister vhi = vtmp0;\n+    FloatRegister vlo = vtmp1;\n+    ld1(vtmp3, T8H, src);\n+    uzp1(vlo, T16B, vtmp3, vtmp3);\n+    uzp2(vhi, T16B, vtmp3, vtmp3);\n+    \/\/ ISO-check on hi-parts (all zero).\n+    \/\/                          ASCII-check on lo-parts (no sign).\n+                                ASCII(cmlt(vtmp2, T16B, vlo));\n+    fmovd(chk, vhi);            ASCII(umaxv(vtmp2, T16B, vtmp2));\n+                                ASCII(umov(max, vtmp2, B, 0));\n+                                ASCII(orr(chk, chk, max));\n+    cbnz(chk, SKIP_8);\n+\n+    strd(vlo, Address(post(dst, 8)));\n+    subw(cnt, cnt, 8);\n+    add(src, src, 16);\n+    b(LOOP_8);\n+  }\n+  BIND(SKIP_8);\n+\n+#undef ASCII\n+\n+  Label LOOP, DONE;\n+\n+  cbz(cnt, DONE);\n+  BIND(LOOP);\n+  {\n+    Register chr = rscratch1;\n+    ldrh(chr, Address(post(src, 2)));\n+    tst(chr, ascii ? 0xff80 : 0xff00);\n+    br(NE, DONE);\n+    strb(chr, Address(post(dst, 1)));\n+    subs(cnt, cnt, 1);\n+    br(GT, LOOP);\n+  }\n+  BIND(DONE);\n+  \/\/ Return index where we stopped.\n+  subw(res, len, cnt);\n+}\n@@ -5527,7 +5538,7 @@\n-                                         FloatRegister tmp1Reg, FloatRegister tmp2Reg,\n-                                         FloatRegister tmp3Reg, FloatRegister tmp4Reg,\n-                                         Register result) {\n-  encode_iso_array(src, dst, len, result,\n-                   tmp1Reg, tmp2Reg, tmp3Reg, tmp4Reg);\n-  cmp(len, zr);\n-  csel(result, result, zr, EQ);\n+                                         Register res,\n+                                         FloatRegister tmp0, FloatRegister tmp1,\n+                                         FloatRegister tmp2, FloatRegister tmp3) {\n+  encode_iso_array(src, dst, len, res, false, tmp0, tmp1, tmp2, tmp3);\n+  \/\/ Adjust result: res == len ? len : 0\n+  cmp(len, res);\n+  csel(res, res, zr, EQ);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":131,"deletions":120,"binary":false,"changes":251,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"metaprogramming\/enableIf.hpp\"\n@@ -501,6 +502,2 @@\n-  inline void mov(Register dst, int imm64)                { mov_immediate64(dst, (uint64_t)imm64); }\n-  inline void mov(Register dst, long imm64)               { mov_immediate64(dst, (uint64_t)imm64); }\n-  inline void mov(Register dst, long long imm64)          { mov_immediate64(dst, (uint64_t)imm64); }\n-  inline void mov(Register dst, unsigned int imm64)       { mov_immediate64(dst, (uint64_t)imm64); }\n-  inline void mov(Register dst, unsigned long imm64)      { mov_immediate64(dst, (uint64_t)imm64); }\n-  inline void mov(Register dst, unsigned long long imm64) { mov_immediate64(dst, (uint64_t)imm64); }\n+  template<typename T, ENABLE_IF(std::is_integral<T>::value)>\n+  inline void mov(Register dst, T o)                      { mov_immediate64(dst, (uint64_t)o); }\n@@ -508,4 +505,1 @@\n-  inline void movw(Register dst, uint32_t imm32)\n-  {\n-    mov_immediate32(dst, imm32);\n-  }\n+  inline void movw(Register dst, uint32_t imm32)          { mov_immediate32(dst, imm32); }\n@@ -645,0 +639,1 @@\n+  static address target_addr_for_insn_or_null(address insn_addr, unsigned insn);\n@@ -649,0 +644,4 @@\n+  static address target_addr_for_insn_or_null(address insn_addr) {\n+    unsigned insn = *(unsigned*)insn_addr;\n+    return target_addr_for_insn_or_null(insn_addr, insn);\n+  }\n@@ -1339,3 +1338,3 @@\n-                           FloatRegister tmp1Reg, FloatRegister tmp2Reg,\n-                           FloatRegister tmp3Reg, FloatRegister tmp4Reg,\n-                           Register result);\n+                           Register res,\n+                           FloatRegister vtmp0, FloatRegister vtmp1,\n+                           FloatRegister vtmp2, FloatRegister vtmp3);\n@@ -1344,3 +1343,4 @@\n-                        Register len, Register result,\n-                        FloatRegister Vtmp1, FloatRegister Vtmp2,\n-                        FloatRegister Vtmp3, FloatRegister Vtmp4);\n+                        Register len, Register res, bool ascii,\n+                        FloatRegister vtmp0, FloatRegister vtmp1,\n+                        FloatRegister vtmp2, FloatRegister vtmp3);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":17,"deletions":17,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -1916,7 +1916,8 @@\n-    \/\/ Load (object->mark() | 1) into swap_reg %r0\n-    __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    __ orr(swap_reg, rscratch1, 1);\n-    if (EnableValhalla) {\n-      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n-      __ andr(swap_reg, swap_reg, ~((int) markWord::inline_type_bit_in_place));\n-    }\n+    if (!UseHeavyMonitors) {\n+      \/\/ Load (object->mark() | 1) into swap_reg %r0\n+      __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ orr(swap_reg, rscratch1, 1);\n+      if (EnableValhalla) {\n+        \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+        __ andr(swap_reg, swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+      }\n@@ -1924,2 +1925,2 @@\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    __ str(swap_reg, Address(lock_reg, mark_word_offset));\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n@@ -1927,4 +1928,4 @@\n-    \/\/ src -> dest iff dest == r0 else r0 <- dest\n-    { Label here;\n-      __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, lock_done, \/*fallthrough*\/NULL);\n-    }\n+      \/\/ src -> dest iff dest == r0 else r0 <- dest\n+      { Label here;\n+        __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, lock_done, \/*fallthrough*\/NULL);\n+      }\n@@ -1932,1 +1933,1 @@\n-    \/\/ Hmm should this move to the slow path code area???\n+      \/\/ Hmm should this move to the slow path code area???\n@@ -1934,8 +1935,8 @@\n-    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-    \/\/  1) (mark & 3) == 0, and\n-    \/\/  2) sp <= mark < mark + os::pagesize()\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 2 bits clear.\n-    \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) sp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n@@ -1943,3 +1944,3 @@\n-    __ sub(swap_reg, sp, swap_reg);\n-    __ neg(swap_reg, swap_reg);\n-    __ ands(swap_reg, swap_reg, 3 - os::vm_page_size());\n+      __ sub(swap_reg, sp, swap_reg);\n+      __ neg(swap_reg, swap_reg);\n+      __ ands(swap_reg, swap_reg, 3 - os::vm_page_size());\n@@ -1947,3 +1948,6 @@\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-    __ br(Assembler::NE, slow_path_lock);\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n+      __ br(Assembler::NE, slow_path_lock);\n+    } else {\n+      __ b(slow_path_lock);\n+    }\n@@ -1952,1 +1956,0 @@\n-\n@@ -2054,3 +2057,5 @@\n-    \/\/ Simple recursive lock?\n-    __ ldr(rscratch1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-    __ cbz(rscratch1, done);\n+    if (!UseHeavyMonitors) {\n+      \/\/ Simple recursive lock?\n+      __ ldr(rscratch1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      __ cbz(rscratch1, done);\n+    }\n@@ -2064,0 +2069,5 @@\n+    if (!UseHeavyMonitors) {\n+      \/\/ get address of the stack lock\n+      __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      \/\/  get old displaced header\n+      __ ldr(old_hdr, Address(r0, 0));\n@@ -2065,9 +2075,7 @@\n-    \/\/ get address of the stack lock\n-    __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-    \/\/  get old displaced header\n-    __ ldr(old_hdr, Address(r0, 0));\n-\n-    \/\/ Atomic swap old header if oop still contains the stack lock\n-    Label succeed;\n-    __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, succeed, &slow_path_unlock);\n-    __ bind(succeed);\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      Label succeed;\n+      __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, succeed, &slow_path_unlock);\n+      __ bind(succeed);\n+    } else {\n+      __ b(slow_path_unlock);\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":49,"deletions":41,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2021, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2022, Red Hat Inc. All rights reserved.\n@@ -3123,2 +3123,1 @@\n-  \/\/ subkeyHtbl_48_entries = c_rarg7 (not used)\n-  \/\/ counter = [sp, #0] pointer to 16 bytes of CTR\n+  \/\/ counter = c_rarg7 - 16 bytes of CTR\n@@ -3150,3 +3149,0 @@\n-    \/\/ Pointer to CTR is passed on the stack before the (fp, lr) pair.\n-    const Address counter_mem(sp, 2 * wordSize);\n-    __ ldr(counter, counter_mem);\n@@ -3239,0 +3235,188 @@\n+  \/\/ Arguments:\n+  \/\/\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - byte[]  source+offset\n+  \/\/   c_rarg1   - int[]   SHA.state\n+  \/\/   c_rarg2   - int     offset\n+  \/\/   c_rarg3   - int     limit\n+  \/\/\n+  address generate_md5_implCompress(bool multi_block, const char *name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", name);\n+    address start = __ pc();\n+\n+    Register buf       = c_rarg0;\n+    Register state     = c_rarg1;\n+    Register ofs       = c_rarg2;\n+    Register limit     = c_rarg3;\n+    Register a         = r4;\n+    Register b         = r5;\n+    Register c         = r6;\n+    Register d         = r7;\n+    Register rscratch3 = r10;\n+    Register rscratch4 = r11;\n+\n+    Label keys;\n+    Label md5_loop;\n+\n+    __ BIND(md5_loop);\n+\n+    \/\/ Save hash values for addition after rounds\n+    __ ldrw(a, Address(state,  0));\n+    __ ldrw(b, Address(state,  4));\n+    __ ldrw(c, Address(state,  8));\n+    __ ldrw(d, Address(state, 12));\n+\n+#define FF(r1, r2, r3, r4, k, s, t)              \\\n+    __ eorw(rscratch3, r3, r4);                  \\\n+    __ movw(rscratch2, t);                       \\\n+    __ andw(rscratch3, rscratch3, r2);           \\\n+    __ addw(rscratch4, r1, rscratch2);           \\\n+    __ ldrw(rscratch1, Address(buf, k*4));       \\\n+    __ eorw(rscratch3, rscratch3, r4);           \\\n+    __ addw(rscratch3, rscratch3, rscratch1);    \\\n+    __ addw(rscratch3, rscratch3, rscratch4);    \\\n+    __ rorw(rscratch2, rscratch3, 32 - s);       \\\n+    __ addw(r1, rscratch2, r2);\n+\n+#define GG(r1, r2, r3, r4, k, s, t)              \\\n+    __ eorw(rscratch2, r2, r3);                  \\\n+    __ ldrw(rscratch1, Address(buf, k*4));       \\\n+    __ andw(rscratch3, rscratch2, r4);           \\\n+    __ movw(rscratch2, t);                       \\\n+    __ eorw(rscratch3, rscratch3, r3);           \\\n+    __ addw(rscratch4, r1, rscratch2);           \\\n+    __ addw(rscratch3, rscratch3, rscratch1);    \\\n+    __ addw(rscratch3, rscratch3, rscratch4);    \\\n+    __ rorw(rscratch2, rscratch3, 32 - s);       \\\n+    __ addw(r1, rscratch2, r2);\n+\n+#define HH(r1, r2, r3, r4, k, s, t)              \\\n+    __ eorw(rscratch3, r3, r4);                  \\\n+    __ movw(rscratch2, t);                       \\\n+    __ addw(rscratch4, r1, rscratch2);           \\\n+    __ ldrw(rscratch1, Address(buf, k*4));       \\\n+    __ eorw(rscratch3, rscratch3, r2);           \\\n+    __ addw(rscratch3, rscratch3, rscratch1);    \\\n+    __ addw(rscratch3, rscratch3, rscratch4);    \\\n+    __ rorw(rscratch2, rscratch3, 32 - s);       \\\n+    __ addw(r1, rscratch2, r2);\n+\n+#define II(r1, r2, r3, r4, k, s, t)              \\\n+    __ movw(rscratch3, t);                       \\\n+    __ ornw(rscratch2, r2, r4);                  \\\n+    __ addw(rscratch4, r1, rscratch3);           \\\n+    __ ldrw(rscratch1, Address(buf, k*4));       \\\n+    __ eorw(rscratch3, rscratch2, r3);           \\\n+    __ addw(rscratch3, rscratch3, rscratch1);    \\\n+    __ addw(rscratch3, rscratch3, rscratch4);    \\\n+    __ rorw(rscratch2, rscratch3, 32 - s);       \\\n+    __ addw(r1, rscratch2, r2);\n+\n+    \/\/ Round 1\n+    FF(a, b, c, d,  0,  7, 0xd76aa478)\n+    FF(d, a, b, c,  1, 12, 0xe8c7b756)\n+    FF(c, d, a, b,  2, 17, 0x242070db)\n+    FF(b, c, d, a,  3, 22, 0xc1bdceee)\n+    FF(a, b, c, d,  4,  7, 0xf57c0faf)\n+    FF(d, a, b, c,  5, 12, 0x4787c62a)\n+    FF(c, d, a, b,  6, 17, 0xa8304613)\n+    FF(b, c, d, a,  7, 22, 0xfd469501)\n+    FF(a, b, c, d,  8,  7, 0x698098d8)\n+    FF(d, a, b, c,  9, 12, 0x8b44f7af)\n+    FF(c, d, a, b, 10, 17, 0xffff5bb1)\n+    FF(b, c, d, a, 11, 22, 0x895cd7be)\n+    FF(a, b, c, d, 12,  7, 0x6b901122)\n+    FF(d, a, b, c, 13, 12, 0xfd987193)\n+    FF(c, d, a, b, 14, 17, 0xa679438e)\n+    FF(b, c, d, a, 15, 22, 0x49b40821)\n+\n+    \/\/ Round 2\n+    GG(a, b, c, d,  1,  5, 0xf61e2562)\n+    GG(d, a, b, c,  6,  9, 0xc040b340)\n+    GG(c, d, a, b, 11, 14, 0x265e5a51)\n+    GG(b, c, d, a,  0, 20, 0xe9b6c7aa)\n+    GG(a, b, c, d,  5,  5, 0xd62f105d)\n+    GG(d, a, b, c, 10,  9, 0x02441453)\n+    GG(c, d, a, b, 15, 14, 0xd8a1e681)\n+    GG(b, c, d, a,  4, 20, 0xe7d3fbc8)\n+    GG(a, b, c, d,  9,  5, 0x21e1cde6)\n+    GG(d, a, b, c, 14,  9, 0xc33707d6)\n+    GG(c, d, a, b,  3, 14, 0xf4d50d87)\n+    GG(b, c, d, a,  8, 20, 0x455a14ed)\n+    GG(a, b, c, d, 13,  5, 0xa9e3e905)\n+    GG(d, a, b, c,  2,  9, 0xfcefa3f8)\n+    GG(c, d, a, b,  7, 14, 0x676f02d9)\n+    GG(b, c, d, a, 12, 20, 0x8d2a4c8a)\n+\n+    \/\/ Round 3\n+    HH(a, b, c, d,  5,  4, 0xfffa3942)\n+    HH(d, a, b, c,  8, 11, 0x8771f681)\n+    HH(c, d, a, b, 11, 16, 0x6d9d6122)\n+    HH(b, c, d, a, 14, 23, 0xfde5380c)\n+    HH(a, b, c, d,  1,  4, 0xa4beea44)\n+    HH(d, a, b, c,  4, 11, 0x4bdecfa9)\n+    HH(c, d, a, b,  7, 16, 0xf6bb4b60)\n+    HH(b, c, d, a, 10, 23, 0xbebfbc70)\n+    HH(a, b, c, d, 13,  4, 0x289b7ec6)\n+    HH(d, a, b, c,  0, 11, 0xeaa127fa)\n+    HH(c, d, a, b,  3, 16, 0xd4ef3085)\n+    HH(b, c, d, a,  6, 23, 0x04881d05)\n+    HH(a, b, c, d,  9,  4, 0xd9d4d039)\n+    HH(d, a, b, c, 12, 11, 0xe6db99e5)\n+    HH(c, d, a, b, 15, 16, 0x1fa27cf8)\n+    HH(b, c, d, a,  2, 23, 0xc4ac5665)\n+\n+    \/\/ Round 4\n+    II(a, b, c, d,  0,  6, 0xf4292244)\n+    II(d, a, b, c,  7, 10, 0x432aff97)\n+    II(c, d, a, b, 14, 15, 0xab9423a7)\n+    II(b, c, d, a,  5, 21, 0xfc93a039)\n+    II(a, b, c, d, 12,  6, 0x655b59c3)\n+    II(d, a, b, c,  3, 10, 0x8f0ccc92)\n+    II(c, d, a, b, 10, 15, 0xffeff47d)\n+    II(b, c, d, a,  1, 21, 0x85845dd1)\n+    II(a, b, c, d,  8,  6, 0x6fa87e4f)\n+    II(d, a, b, c, 15, 10, 0xfe2ce6e0)\n+    II(c, d, a, b,  6, 15, 0xa3014314)\n+    II(b, c, d, a, 13, 21, 0x4e0811a1)\n+    II(a, b, c, d,  4,  6, 0xf7537e82)\n+    II(d, a, b, c, 11, 10, 0xbd3af235)\n+    II(c, d, a, b,  2, 15, 0x2ad7d2bb)\n+    II(b, c, d, a,  9, 21, 0xeb86d391)\n+\n+#undef FF\n+#undef GG\n+#undef HH\n+#undef II\n+\n+    \/\/ write hash values back in the correct order\n+    __ ldrw(rscratch1, Address(state,  0));\n+    __ addw(rscratch1, rscratch1, a);\n+    __ strw(rscratch1, Address(state,  0));\n+\n+    __ ldrw(rscratch2, Address(state,  4));\n+    __ addw(rscratch2, rscratch2, b);\n+    __ strw(rscratch2, Address(state,  4));\n+\n+    __ ldrw(rscratch3, Address(state,  8));\n+    __ addw(rscratch3, rscratch3, c);\n+    __ strw(rscratch3, Address(state,  8));\n+\n+    __ ldrw(rscratch4, Address(state, 12));\n+    __ addw(rscratch4, rscratch4, d);\n+    __ strw(rscratch4, Address(state, 12));\n+\n+    if (multi_block) {\n+      __ add(buf, buf, 64);\n+      __ add(ofs, ofs, 64);\n+      __ cmp(ofs, limit);\n+      __ br(Assembler::LE, md5_loop);\n+      __ mov(c_rarg0, ofs); \/\/ return ofs\n+    }\n+\n+    __ ret(lr);\n+\n+    return start;\n+  }\n+\n@@ -5182,0 +5366,1 @@\n+      __ align(OptoLoopAlignment);\n@@ -5186,1 +5371,0 @@\n-        __ align(OptoLoopAlignment);\n@@ -6238,0 +6422,12 @@\n+  \/\/ Support for spin waits.\n+  address generate_spin_wait() {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"spin_wait\");\n+    address start = __ pc();\n+\n+    __ spin_wait();\n+    __ ret(lr);\n+\n+    return start;\n+  }\n+\n@@ -7665,0 +7861,4 @@\n+    if (UseMD5Intrinsics) {\n+      StubRoutines::_md5_implCompress      = generate_md5_implCompress(false,    \"md5_implCompress\");\n+      StubRoutines::_md5_implCompressMB    = generate_md5_implCompress(true,     \"md5_implCompressMB\");\n+    }\n@@ -7687,0 +7887,2 @@\n+    StubRoutines::aarch64::_spin_wait = generate_spin_wait();\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":210,"deletions":8,"binary":false,"changes":218,"status":"modified"},{"patch":"@@ -723,5 +723,1 @@\n-      if (UseCompressedClassPointers && addr->disp() == oopDesc::klass_offset_in_bytes()) {\n-        __ ldr_u32(dest->as_pointer_register(), as_Address(addr));\n-      } else {\n-        __ ldr(dest->as_pointer_register(), as_Address(addr));\n-      }\n+      __ ldr(dest->as_pointer_register(), as_Address(addr));\n@@ -1687,0 +1683,3 @@\n+      if (!Assembler::is_arith_imm_in_range(c)) {\n+        BAILOUT(\"illegal arithmetic operand\");\n+      }\n@@ -1827,2 +1826,2 @@\n-        __ subs(xlo, xlo, ylo);\n-        __ sbcs(xhi, xhi, yhi);\n+        __ subs(Rtemp, xlo, ylo);\n+        __ sbcs(Rtemp, xhi, yhi);\n@@ -2432,1 +2431,1 @@\n-  if (!UseFastLocking) {\n+  if (UseHeavyMonitors) {\n@@ -2448,0 +2447,15 @@\n+void LIR_Assembler::emit_load_klass(LIR_OpLoadKlass* op) {\n+  Register obj = op->obj()->as_pointer_register();\n+  Register result = op->result_opr()->as_pointer_register();\n+\n+  CodeEmitInfo* info = op->info();\n+  if (info != NULL) {\n+    add_debug_info_for_null_check_here(info);\n+  }\n+\n+  if (UseCompressedClassPointers) { \/\/ On 32 bit arm??\n+    __ ldr_u32(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  } else {\n+    __ ldr(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":22,"deletions":8,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -815,6 +815,1 @@\n-        if (offset == oopDesc::klass_offset_in_bytes() && UseCompressedClassPointers) {\n-          __ lwz(to_reg->as_register(), offset, base);\n-          __ decode_klass_not_null(to_reg->as_register());\n-        } else {\n-          __ ld(to_reg->as_register(), offset, base);\n-        }\n+        __ ld(to_reg->as_register(), offset, base);\n@@ -950,1 +945,2 @@\n-        __ lis(R0, oop_addr.value() >> 16); \/\/ Don't care about sign extend (will use stw).\n+        \/\/ Don't care about sign extend (will use stw).\n+        __ lis(R0, 0); \/\/ Will get patched.\n@@ -952,1 +948,1 @@\n-        __ ori(R0, R0, oop_addr.value() & 0xffff);\n+        __ ori(R0, R0, 0); \/\/ Will get patched.\n@@ -2697,1 +2693,1 @@\n-    if (UseFastLocking) {\n+    if (!UseHeavyMonitors) {\n@@ -2719,1 +2715,1 @@\n-    if (UseFastLocking) {\n+    if (!UseHeavyMonitors) {\n@@ -2735,0 +2731,20 @@\n+void LIR_Assembler::emit_load_klass(LIR_OpLoadKlass* op) {\n+  Register obj = op->obj()->as_pointer_register();\n+  Register result = op->result_opr()->as_pointer_register();\n+\n+  CodeEmitInfo* info = op->info();\n+  if (info != NULL) {\n+    if (!os::zero_page_read_protected() || !ImplicitNullChecks) {\n+      explicit_null_check(obj, info);\n+    } else {\n+      add_debug_info_for_null_check_here(info);\n+    }\n+  }\n+\n+  if (UseCompressedClassPointers) {\n+    __ lwz(result, oopDesc::klass_offset_in_bytes(), obj);\n+    __ decode_klass_not_null(result);\n+  } else {\n+    __ ld(result, oopDesc::klass_offset_in_bytes(), obj);\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":26,"deletions":10,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -953,6 +953,1 @@\n-      if (UseCompressedClassPointers && addr->disp() == oopDesc::klass_offset_in_bytes()) {\n-        __ z_llgf(dest->as_register(), disp_value, disp_reg, src);\n-        __ decode_klass_not_null(dest->as_register());\n-      } else {\n-        __ z_lg(dest->as_register(), disp_value, disp_reg, src);\n-      }\n+      __ z_lg(dest->as_register(), disp_value, disp_reg, src);\n@@ -2738,1 +2733,1 @@\n-  if (!UseFastLocking) {\n+  if (UseHeavyMonitors) {\n@@ -2757,0 +2752,16 @@\n+void LIR_Assembler::emit_load_klass(LIR_OpLoadKlass* op) {\n+  Register obj = op->obj()->as_pointer_register();\n+  Register result = op->result_opr()->as_pointer_register();\n+\n+  CodeEmitInfo* info = op->info();\n+  if (info != NULL) {\n+    add_debug_info_for_null_check_here(info);\n+  }\n+\n+  if (UseCompressedClassPointers) {\n+    __ z_llgf(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n+    __ decode_klass_not_null(result);\n+  } else {\n+    __ z_lg(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRAssembler_s390.cpp","additions":18,"deletions":7,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -466,1 +466,5 @@\n-    __ unlock_object(rdi, rsi, rax, *stub->entry());\n+    if (UseHeavyMonitors) {\n+      __ jmp(*stub->entry());\n+    } else {\n+      __ unlock_object(rdi, rsi, rax, *stub->entry());\n+    }\n@@ -1213,1 +1217,0 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n@@ -1287,5 +1290,1 @@\n-      if (UseCompressedClassPointers && addr->disp() == oopDesc::klass_offset_in_bytes()) {\n-        __ movl(dest->as_register(), from_addr);\n-      } else {\n-        __ movptr(dest->as_register(), from_addr);\n-      }\n+      __ movptr(dest->as_register(), from_addr);\n@@ -1397,6 +1396,0 @@\n-  } else if (type == T_ADDRESS && addr->disp() == oopDesc::klass_offset_in_bytes()) {\n-#ifdef _LP64\n-    if (UseCompressedClassPointers) {\n-      __ decode_klass_not_null(dest->as_register(), tmp_load_klass);\n-    }\n-#endif\n@@ -3720,1 +3713,1 @@\n-  if (!UseFastLocking) {\n+  if (UseHeavyMonitors) {\n@@ -3739,0 +3732,17 @@\n+void LIR_Assembler::emit_load_klass(LIR_OpLoadKlass* op) {\n+  Register obj = op->obj()->as_pointer_register();\n+  Register result = op->result_opr()->as_pointer_register();\n+\n+  CodeEmitInfo* info = op->info();\n+  if (info != NULL) {\n+    add_debug_info_for_null_check_here(info);\n+  }\n+\n+#ifdef _LP64\n+  if (UseCompressedClassPointers) {\n+    __ movl(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n+    __ decode_klass_not_null(result, rscratch1);\n+  } else\n+#endif\n+    __ movptr(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":24,"deletions":14,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -209,2 +209,26 @@\n-    addr = new LIR_Address(array_opr,\n-                           offset_in_bytes + (intx)(index_opr->as_jint()) * elem_size, type);\n+#ifdef _LP64\n+    jint index = index_opr->as_jint();\n+    jlong disp = offset_in_bytes + (jlong)(index) * elem_size;\n+    if (disp > max_jint) {\n+      \/\/ Displacement overflow. Cannot directly use instruction with 32-bit displacement for 64-bit addresses.\n+      \/\/ Convert array index to long to do array offset computation with 64-bit values.\n+      index_opr = new_register(T_LONG);\n+      __ move(LIR_OprFact::longConst(index), index_opr);\n+      addr = new LIR_Address(array_opr, index_opr, LIR_Address::scale(type), offset_in_bytes, type);\n+    } else {\n+      addr = new LIR_Address(array_opr, (intx)disp, type);\n+    }\n+#else\n+    \/\/ A displacement overflow can also occur for x86 but that is not a problem due to the 32-bit address range!\n+    \/\/ Let's assume an array 'a' and an access with displacement 'disp'. When disp overflows, then \"a + disp\" will\n+    \/\/ always be negative (i.e. underflows the 32-bit address range):\n+    \/\/ Let N = 2^32: a + signed_overflow(disp) = a + disp - N.\n+    \/\/ \"a + disp\" is always smaller than N. If an index was chosen which would point to an address beyond N, then\n+    \/\/ range checks would catch that and throw an exception. Thus, a + disp < 0 holds which means that it always\n+    \/\/ underflows the 32-bit address range:\n+    \/\/ unsigned_underflow(a + signed_overflow(disp)) = unsigned_underflow(a + disp - N)\n+    \/\/                                              = (a + disp - N) + N = a + disp\n+    \/\/ This shows that we still end up at the correct address with a displacement overflow due to the 32-bit address\n+    \/\/ range limitation. This overflow only needs to be handled if addresses can be larger as on 64-bit platforms.\n+    addr = new LIR_Address(array_opr, offset_in_bytes + (intx)(index_opr->as_jint()) * elem_size, type);\n+#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":26,"deletions":2,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -362,2 +362,2 @@\n-void C1_MacroAssembler::verified_entry() {\n-  if (C1Breakpoint || VerifyFPU) {\n+void C1_MacroAssembler::verified_entry(bool breakAtEntry) {\n+  if (breakAtEntry || VerifyFPU) {\n@@ -367,1 +367,1 @@\n-    \/\/ C1Breakpoint and VerifyFPU have one byte first instruction.\n+    \/\/ Breakpoint and VerifyFPU have one byte first instruction.\n@@ -373,1 +373,1 @@\n-  if (C1Breakpoint)int3();\n+  if (breakAtEntry) int3();\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -488,0 +488,1 @@\n+    assert(!UseHeavyMonitors, \"+UseHeavyMonitors and +UseRTMForStackLocks are mutually exclusive\");\n@@ -498,5 +499,22 @@\n-  \/\/ Attempt stack-locking ...\n-  orptr (tmpReg, markWord::unlocked_value);\n-  if (EnableValhalla) {\n-    \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n-    andptr(tmpReg, ~((int) markWord::inline_type_bit_in_place));\n+  if (!UseHeavyMonitors) {\n+    \/\/ Attempt stack-locking ...\n+    orptr (tmpReg, markWord::unlocked_value);\n+    if (EnableValhalla) {\n+      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+      andptr(tmpReg, ~((int) markWord::inline_type_bit_in_place));\n+    }\n+    movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n+    lock();\n+    cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n+    jcc(Assembler::equal, DONE_LABEL);           \/\/ Success\n+\n+    \/\/ Recursive locking.\n+    \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n+    \/\/ Locked by current thread if difference with current SP is less than one page.\n+    subptr(tmpReg, rsp);\n+    \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n+    andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - os::vm_page_size())) );\n+    movptr(Address(boxReg, 0), tmpReg);\n+  } else {\n+    \/\/ Clear ZF so that we take the slow path at the DONE label. objReg is known to be not 0.\n+    testptr(objReg, objReg);\n@@ -504,12 +522,0 @@\n-  movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n-  lock();\n-  cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n-  jcc(Assembler::equal, DONE_LABEL);           \/\/ Success\n-\n-  \/\/ Recursive locking.\n-  \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n-  \/\/ Locked by current thread if difference with current SP is less than one page.\n-  subptr(tmpReg, rsp);\n-  \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n-  andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - os::vm_page_size())) );\n-  movptr(Address(boxReg, 0), tmpReg);\n@@ -645,0 +651,1 @@\n+    assert(!UseHeavyMonitors, \"+UseHeavyMonitors and +UseRTMForStackLocks are mutually exclusive\");\n@@ -656,2 +663,4 @@\n-  cmpptr(Address(boxReg, 0), (int32_t)NULL_WORD);                   \/\/ Examine the displaced header\n-  jcc   (Assembler::zero, DONE_LABEL);                              \/\/ 0 indicates recursive stack-lock\n+  if (!UseHeavyMonitors) {\n+    cmpptr(Address(boxReg, 0), (int32_t)NULL_WORD);                   \/\/ Examine the displaced header\n+    jcc   (Assembler::zero, DONE_LABEL);                              \/\/ 0 indicates recursive stack-lock\n+  }\n@@ -659,2 +668,4 @@\n-  testptr(tmpReg, markWord::monitor_value);                         \/\/ Inflated?\n-  jccb  (Assembler::zero, Stacked);\n+  if (!UseHeavyMonitors) {\n+    testptr(tmpReg, markWord::monitor_value);                         \/\/ Inflated?\n+    jccb  (Assembler::zero, Stacked);\n+  }\n@@ -802,5 +813,6 @@\n-  bind  (Stacked);\n-  movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n-  lock();\n-  cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n-\n+  if (!UseHeavyMonitors) {\n+    bind  (Stacked);\n+    movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n+    lock();\n+    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+  }\n@@ -2187,78 +2199,0 @@\n-void C2_MacroAssembler::vpcmpu(BasicType typ, XMMRegister dst, XMMRegister src1, XMMRegister src2, ComparisonPredicate comparison,\n-                            int vlen_in_bytes, XMMRegister vtmp1, XMMRegister vtmp2, Register scratch) {\n-  int vlen_enc = vector_length_encoding(vlen_in_bytes*2);\n-  switch (typ) {\n-  case T_BYTE:\n-    vpmovzxbw(vtmp1, src1, vlen_enc);\n-    vpmovzxbw(vtmp2, src2, vlen_enc);\n-    vpcmpCCW(dst, vtmp1, vtmp2, comparison, Assembler::W, vlen_enc, scratch);\n-    vpacksswb(dst, dst, dst, vlen_enc);\n-    break;\n-  case T_SHORT:\n-    vpmovzxwd(vtmp1, src1, vlen_enc);\n-    vpmovzxwd(vtmp2, src2, vlen_enc);\n-    vpcmpCCW(dst, vtmp1, vtmp2, comparison, Assembler::D, vlen_enc, scratch);\n-    vpackssdw(dst, dst, dst, vlen_enc);\n-    break;\n-  case T_INT:\n-    vpmovzxdq(vtmp1, src1, vlen_enc);\n-    vpmovzxdq(vtmp2, src2, vlen_enc);\n-    vpcmpCCW(dst, vtmp1, vtmp2, comparison, Assembler::Q, vlen_enc, scratch);\n-    vpermilps(dst, dst, 8, vlen_enc);\n-    break;\n-  default:\n-    assert(false, \"Should not reach here\");\n-  }\n-  if (vlen_in_bytes == 16) {\n-    vpermpd(dst, dst, 0x8, vlen_enc);\n-  }\n-}\n-\n-void C2_MacroAssembler::vpcmpu32(BasicType typ, XMMRegister dst, XMMRegister src1, XMMRegister src2, ComparisonPredicate comparison, int vlen_in_bytes,\n-                              XMMRegister vtmp1, XMMRegister vtmp2, XMMRegister vtmp3, Register scratch) {\n-  int vlen_enc = vector_length_encoding(vlen_in_bytes);\n-  switch (typ) {\n-  case T_BYTE:\n-    vpmovzxbw(vtmp1, src1, vlen_enc);\n-    vpmovzxbw(vtmp2, src2, vlen_enc);\n-    vpcmpCCW(dst, vtmp1, vtmp2, comparison, Assembler::W, vlen_enc, scratch);\n-    vextracti128(vtmp1, src1, 1);\n-    vextracti128(vtmp2, src2, 1);\n-    vpmovzxbw(vtmp1, vtmp1, vlen_enc);\n-    vpmovzxbw(vtmp2, vtmp2, vlen_enc);\n-    vpcmpCCW(vtmp3, vtmp1, vtmp2, comparison, Assembler::W, vlen_enc, scratch);\n-    vpacksswb(dst, dst, vtmp3, vlen_enc);\n-    vpermpd(dst, dst, 0xd8, vlen_enc);\n-    break;\n-  case T_SHORT:\n-    vpmovzxwd(vtmp1, src1, vlen_enc);\n-    vpmovzxwd(vtmp2, src2, vlen_enc);\n-    vpcmpCCW(dst, vtmp1, vtmp2, comparison, Assembler::D, vlen_enc, scratch);\n-    vextracti128(vtmp1, src1, 1);\n-    vextracti128(vtmp2, src2, 1);\n-    vpmovzxwd(vtmp1, vtmp1, vlen_enc);\n-    vpmovzxwd(vtmp2, vtmp2, vlen_enc);\n-    vpcmpCCW(vtmp3, vtmp1, vtmp2, comparison, Assembler::D,  vlen_enc, scratch);\n-    vpackssdw(dst, dst, vtmp3, vlen_enc);\n-    vpermpd(dst, dst, 0xd8, vlen_enc);\n-    break;\n-  case T_INT:\n-    vpmovzxdq(vtmp1, src1, vlen_enc);\n-    vpmovzxdq(vtmp2, src2, vlen_enc);\n-    vpcmpCCW(dst, vtmp1, vtmp2, comparison, Assembler::Q, vlen_enc, scratch);\n-    vpshufd(dst, dst, 8, vlen_enc);\n-    vpermq(dst, dst, 8, vlen_enc);\n-    vextracti128(vtmp1, src1, 1);\n-    vextracti128(vtmp2, src2, 1);\n-    vpmovzxdq(vtmp1, vtmp1, vlen_enc);\n-    vpmovzxdq(vtmp2, vtmp2, vlen_enc);\n-    vpcmpCCW(vtmp3, vtmp1, vtmp2, comparison, Assembler::Q,  vlen_enc, scratch);\n-    vpshufd(vtmp3, vtmp3, 8, vlen_enc);\n-    vpermq(vtmp3, vtmp3, 0x80, vlen_enc);\n-    vpblendd(dst, dst, vtmp3, 0xf0, vlen_enc);\n-    break;\n-  default:\n-    assert(false, \"Should not reach here\");\n-  }\n-}\n-\n@@ -4066,6 +4000,85 @@\n-#ifdef _LP64\n-void C2_MacroAssembler::vector_mask_operation(int opc, Register dst, KRegister mask,\n-                                              Register tmp, int masklen, int masksize,\n-                                              int vec_enc) {\n-  if(VM_Version::supports_avx512bw()) {\n-    kmovql(tmp, mask);\n+\/*\n+ * Algorithm for vector D2L and F2I conversions:-\n+ * a) Perform vector D2L\/F2I cast.\n+ * b) Choose fast path if none of the result vector lane contains 0x80000000 value.\n+ *    It signifies that source value could be any of the special floating point\n+ *    values(NaN,-Inf,Inf,Max,-Min).\n+ * c) Set destination to zero if source is NaN value.\n+ * d) Replace 0x80000000 with MaxInt if source lane contains a +ve value.\n+ *\/\n+\n+void C2_MacroAssembler::vector_castD2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                                            Register scratch, int vec_enc) {\n+  Label done;\n+  evcvttpd2qq(dst, src, vec_enc);\n+  evmovdqul(xtmp1, k0, double_sign_flip, false, vec_enc, scratch);\n+  evpcmpeqq(ktmp1, xtmp1, dst, vec_enc);\n+  kortestwl(ktmp1, ktmp1);\n+  jccb(Assembler::equal, done);\n+\n+  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+  evcmppd(ktmp2, k0, src, src, Assembler::UNORD_Q, vec_enc);\n+  evmovdquq(dst, ktmp2, xtmp2, true, vec_enc);\n+\n+  kxorwl(ktmp1, ktmp1, ktmp2);\n+  evcmppd(ktmp1, ktmp1, src, xtmp2, Assembler::NLT_UQ, vec_enc);\n+  vpternlogq(xtmp2, 0x11, xtmp1, xtmp1, vec_enc);\n+  evmovdquq(dst, ktmp1, xtmp2, true, vec_enc);\n+  bind(done);\n+}\n+\n+void C2_MacroAssembler::vector_castF2I_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n+                                           AddressLiteral float_sign_flip, Register scratch, int vec_enc) {\n+  Label done;\n+  vcvttps2dq(dst, src, vec_enc);\n+  vmovdqu(xtmp1, float_sign_flip, scratch, vec_enc);\n+  vpcmpeqd(xtmp2, dst, xtmp1, vec_enc);\n+  vptest(xtmp2, xtmp2, vec_enc);\n+  jccb(Assembler::equal, done);\n+\n+  vpcmpeqd(xtmp4, xtmp4, xtmp4, vec_enc);\n+  vpxor(xtmp1, xtmp1, xtmp4, vec_enc);\n+\n+  vpxor(xtmp4, xtmp4, xtmp4, vec_enc);\n+  vcmpps(xtmp3, src, src, Assembler::UNORD_Q, vec_enc);\n+  vblendvps(dst, dst, xtmp4, xtmp3, vec_enc);\n+\n+  \/\/ Recompute the mask for remaining special value.\n+  vpxor(xtmp2, xtmp2, xtmp3, vec_enc);\n+  \/\/ Extract SRC values corresponding to TRUE mask lanes.\n+  vpand(xtmp4, xtmp2, src, vec_enc);\n+  \/\/ Flip mask bits so that MSB bit of MASK lanes corresponding to +ve special\n+  \/\/ values are set.\n+  vpxor(xtmp3, xtmp2, xtmp4, vec_enc);\n+\n+  vblendvps(dst, dst, xtmp1, xtmp3, vec_enc);\n+  bind(done);\n+}\n+\n+void C2_MacroAssembler::vector_castF2I_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral float_sign_flip,\n+                                            Register scratch, int vec_enc) {\n+  Label done;\n+  vcvttps2dq(dst, src, vec_enc);\n+  evmovdqul(xtmp1, k0, float_sign_flip, false, vec_enc, scratch);\n+  Assembler::evpcmpeqd(ktmp1, k0, xtmp1, dst, vec_enc);\n+  kortestwl(ktmp1, ktmp1);\n+  jccb(Assembler::equal, done);\n+\n+  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+  evcmpps(ktmp2, k0, src, src, Assembler::UNORD_Q, vec_enc);\n+  evmovdqul(dst, ktmp2, xtmp2, true, vec_enc);\n+\n+  kxorwl(ktmp1, ktmp1, ktmp2);\n+  evcmpps(ktmp1, ktmp1, src, xtmp2, Assembler::NLT_UQ, vec_enc);\n+  vpternlogd(xtmp2, 0x11, xtmp1, xtmp1, vec_enc);\n+  evmovdqul(dst, ktmp1, xtmp2, true, vec_enc);\n+  bind(done);\n+}\n+\n+void C2_MacroAssembler::evpternlog(XMMRegister dst, int func, KRegister mask, XMMRegister src2, XMMRegister src3,\n+                                   bool merge, BasicType bt, int vlen_enc) {\n+  if (bt == T_INT) {\n+    evpternlogd(dst, func, mask, src2, src3, merge, vlen_enc);\n@@ -4073,2 +4086,2 @@\n-    assert(masklen <= 16, \"\");\n-    kmovwl(tmp, mask);\n+    assert(bt == T_LONG, \"\");\n+    evpternlogq(dst, func, mask, src2, src3, merge, vlen_enc);\n@@ -4076,2 +4089,49 @@\n-  if (masksize < 16) {\n-    andq(tmp, (((jlong)1 << masklen) - 1));\n+}\n+\n+void C2_MacroAssembler::evpternlog(XMMRegister dst, int func, KRegister mask, XMMRegister src2, Address src3,\n+                                   bool merge, BasicType bt, int vlen_enc) {\n+  if (bt == T_INT) {\n+    evpternlogd(dst, func, mask, src2, src3, merge, vlen_enc);\n+  } else {\n+    assert(bt == T_LONG, \"\");\n+    evpternlogq(dst, func, mask, src2, src3, merge, vlen_enc);\n+  }\n+}\n+\n+#ifdef _LP64\n+void C2_MacroAssembler::vector_long_to_maskvec(XMMRegister dst, Register src, Register rtmp1,\n+                                               Register rtmp2, XMMRegister xtmp, int mask_len,\n+                                               int vec_enc) {\n+  int index = 0;\n+  int vindex = 0;\n+  mov64(rtmp1, 0x0101010101010101L);\n+  pdep(rtmp1, src, rtmp1);\n+  if (mask_len > 8) {\n+    movq(rtmp2, src);\n+    vpxor(xtmp, xtmp, xtmp, vec_enc);\n+    movq(xtmp, rtmp1);\n+  }\n+  movq(dst, rtmp1);\n+\n+  mask_len -= 8;\n+  while (mask_len > 0) {\n+    assert ((mask_len & 0x7) == 0, \"mask must be multiple of 8\");\n+    index++;\n+    if ((index % 2) == 0) {\n+      pxor(xtmp, xtmp);\n+    }\n+    mov64(rtmp1, 0x0101010101010101L);\n+    shrq(rtmp2, 8);\n+    pdep(rtmp1, rtmp2, rtmp1);\n+    pinsrq(xtmp, rtmp1, index % 2);\n+    vindex = index \/ 2;\n+    if (vindex) {\n+      \/\/ Write entire 16 byte vector when both 64 bit\n+      \/\/ lanes are update to save redundant instructions.\n+      if (index % 2) {\n+        vinsertf128(dst, dst, xtmp, vindex);\n+      }\n+    } else {\n+      vmovdqu(dst, xtmp);\n+    }\n+    mask_len -= 8;\n@@ -4079,0 +4139,3 @@\n+}\n+\n+void C2_MacroAssembler::vector_mask_operation_helper(int opc, Register dst, Register tmp, int masklen) {\n@@ -4084,3 +4147,9 @@\n-      mov64(dst, -1);\n-      bsrq(tmp, tmp);\n-      cmov(Assembler::notZero, dst, tmp);\n+      if (VM_Version::supports_lzcnt()) {\n+        lzcntq(tmp, tmp);\n+        movl(dst, 63);\n+        subl(dst, tmp);\n+      } else {\n+        movl(dst, -1);\n+        bsrq(tmp, tmp);\n+        cmov32(Assembler::notZero, dst, tmp);\n+      }\n@@ -4089,3 +4158,28 @@\n-      mov64(dst, masklen);\n-      bsfq(tmp, tmp);\n-      cmov(Assembler::notZero, dst, tmp);\n+      if (VM_Version::supports_bmi1()) {\n+        if (masklen < 32) {\n+          orl(tmp, 1 << masklen);\n+          tzcntl(dst, tmp);\n+        } else if (masklen == 32) {\n+          tzcntl(dst, tmp);\n+        } else {\n+          assert(masklen == 64, \"\");\n+          tzcntq(dst, tmp);\n+        }\n+      } else {\n+        if (masklen < 32) {\n+          orl(tmp, 1 << masklen);\n+          bsfl(dst, tmp);\n+        } else {\n+          assert(masklen == 32 || masklen == 64, \"\");\n+          movl(dst, masklen);\n+          if (masklen == 32)  {\n+            bsfl(tmp, tmp);\n+          } else {\n+            bsfq(tmp, tmp);\n+          }\n+          cmov32(Assembler::notZero, dst, tmp);\n+        }\n+      }\n+      break;\n+    case Op_VectorMaskToLong:\n+      assert(dst == tmp, \"Dst and tmp should be the same for toLong operations\");\n@@ -4097,9 +4191,9 @@\n-void C2_MacroAssembler::vector_mask_operation(int opc, Register dst, XMMRegister mask, XMMRegister xtmp,\n-                                              XMMRegister xtmp1, Register tmp, int masklen, int masksize,\n-                                              int vec_enc) {\n-  assert(VM_Version::supports_avx(), \"\");\n-  vpxor(xtmp, xtmp, xtmp, vec_enc);\n-  vpsubb(xtmp, xtmp, mask, vec_enc);\n-  vpmovmskb(tmp, xtmp, vec_enc);\n-  if (masksize < 16) {\n-    andq(tmp, (((jlong)1 << masklen) - 1));\n+void C2_MacroAssembler::vector_mask_operation(int opc, Register dst, KRegister mask, Register tmp,\n+                                              int masklen, int masksize, int vec_enc) {\n+  assert(VM_Version::supports_popcnt(), \"\");\n+\n+  if(VM_Version::supports_avx512bw()) {\n+    kmovql(tmp, mask);\n+  } else {\n+    assert(masklen <= 16, \"\");\n+    kmovwl(tmp, mask);\n@@ -4107,3 +4201,24 @@\n-  switch(opc) {\n-    case Op_VectorMaskTrueCount:\n-      popcntq(dst, tmp);\n+\n+  \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n+  \/\/ operations needs to be clipped.\n+  if (masksize < 16 && opc != Op_VectorMaskFirstTrue) {\n+    andq(tmp, (1 << masklen) - 1);\n+  }\n+\n+  vector_mask_operation_helper(opc, dst, tmp, masklen);\n+}\n+\n+void C2_MacroAssembler::vector_mask_operation(int opc, Register dst, XMMRegister mask, XMMRegister xtmp,\n+                                              Register tmp, int masklen, BasicType bt, int vec_enc) {\n+  assert(vec_enc == AVX_128bit && VM_Version::supports_avx() ||\n+         vec_enc == AVX_256bit && (VM_Version::supports_avx2() || type2aelembytes(bt) >= 4), \"\");\n+  assert(VM_Version::supports_popcnt(), \"\");\n+\n+  bool need_clip = false;\n+  switch(bt) {\n+    case T_BOOLEAN:\n+      \/\/ While masks of other types contain 0, -1; boolean masks contain lane values of 0, 1\n+      vpxor(xtmp, xtmp, xtmp, vec_enc);\n+      vpsubb(xtmp, xtmp, mask, vec_enc);\n+      vpmovmskb(tmp, xtmp, vec_enc);\n+      need_clip = masklen < 16;\n@@ -4111,4 +4226,3 @@\n-    case Op_VectorMaskLastTrue:\n-      mov64(dst, -1);\n-      bsrq(tmp, tmp);\n-      cmov(Assembler::notZero, dst, tmp);\n+    case T_BYTE:\n+      vpmovmskb(tmp, mask, vec_enc);\n+      need_clip = masklen < 16;\n@@ -4116,4 +4230,7 @@\n-    case Op_VectorMaskFirstTrue:\n-      mov64(dst, masklen);\n-      bsfq(tmp, tmp);\n-      cmov(Assembler::notZero, dst, tmp);\n+    case T_SHORT:\n+      vpacksswb(xtmp, mask, mask, vec_enc);\n+      if (masklen >= 16) {\n+        vpermpd(xtmp, xtmp, 8, vec_enc);\n+      }\n+      vpmovmskb(tmp, xtmp, Assembler::AVX_128bit);\n+      need_clip = masklen < 16;\n@@ -4121,1 +4238,40 @@\n-    default: assert(false, \"Unhandled mask operation\");\n+    case T_INT:\n+    case T_FLOAT:\n+      vmovmskps(tmp, mask, vec_enc);\n+      need_clip = masklen < 4;\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      vmovmskpd(tmp, mask, vec_enc);\n+      need_clip = masklen < 2;\n+      break;\n+    default: assert(false, \"Unhandled type, %s\", type2name(bt));\n+  }\n+\n+  \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n+  \/\/ operations needs to be clipped.\n+  if (need_clip && opc != Op_VectorMaskFirstTrue) {\n+    \/\/ need_clip implies masklen < 32\n+    andq(tmp, (1 << masklen) - 1);\n+  }\n+\n+  vector_mask_operation_helper(opc, dst, tmp, masklen);\n+}\n+#endif\n+\n+void C2_MacroAssembler::vector_maskall_operation(KRegister dst, Register src, int mask_len) {\n+  if (VM_Version::supports_avx512bw()) {\n+    if (mask_len > 32) {\n+      kmovql(dst, src);\n+    } else {\n+      kmovdl(dst, src);\n+      if (mask_len != 32) {\n+        kshiftrdl(dst, dst, 32 - mask_len);\n+      }\n+    }\n+  } else {\n+    assert(mask_len <= 16, \"\");\n+    kmovwl(dst, src);\n+    if (mask_len != 16) {\n+      kshiftrwl(dst, dst, 16 - mask_len);\n+    }\n@@ -4124,0 +4280,7 @@\n+\n+#ifndef _LP64\n+void C2_MacroAssembler::vector_maskall_operation32(KRegister dst, Register src, KRegister tmp, int mask_len) {\n+  assert(VM_Version::supports_avx512bw(), \"\");\n+  kmovdl(tmp, src);\n+  kunpckdql(dst, tmp, tmp);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":305,"deletions":142,"binary":false,"changes":447,"status":"modified"},{"patch":"@@ -303,1 +303,1 @@\n-  __ shrptr(card_addr, CardTable::card_shift);\n+  __ shrptr(card_addr, CardTable::card_shift());\n@@ -569,1 +569,1 @@\n-  __ shrptr(card_addr, CardTable::card_shift);\n+  __ shrptr(card_addr, CardTable::card_shift());\n","filename":"src\/hotspot\/cpu\/x86\/gc\/g1\/g1BarrierSetAssembler_x86.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -63,2 +63,2 @@\n-  __ shrptr(addr, CardTable::card_shift);\n-  __ shrptr(end, CardTable::card_shift);\n+  __ shrptr(addr, CardTable::card_shift());\n+  __ shrptr(end, CardTable::card_shift());\n@@ -75,2 +75,2 @@\n-  __ shrptr(addr, CardTable::card_shift);\n-  __ shrptr(end,   CardTable::card_shift);\n+  __ shrptr(addr, CardTable::card_shift());\n+  __ shrptr(end,   CardTable::card_shift());\n@@ -96,1 +96,1 @@\n-  __ shrptr(obj, CardTable::card_shift);\n+  __ shrptr(obj, CardTable::card_shift());\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/cardTableBarrierSetAssembler_x86.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -423,1 +423,1 @@\n-      __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_strong_narrow), arg0, arg1);\n+      __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_strong_narrow), arg0, arg1);\n@@ -425,1 +425,1 @@\n-      __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_strong), arg0, arg1);\n+      __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_strong), arg0, arg1);\n@@ -436,1 +436,1 @@\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_phantom), arg0, arg1);\n+    __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_phantom), arg0, arg1);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shenandoah\/shenandoahBarrierSetAssembler_x86.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -2559,0 +2559,9 @@\n+void MacroAssembler::vmovdqu(XMMRegister dst, AddressLiteral src, Register scratch_reg, int vector_len) {\n+  assert(vector_len <= AVX_256bit, \"AVX2 vector length\");\n+  if (vector_len == AVX_256bit) {\n+    vmovdqu(dst, src, scratch_reg);\n+  } else {\n+    movdqu(dst, src, scratch_reg);\n+  }\n+}\n+\n@@ -2706,0 +2715,9 @@\n+void MacroAssembler::vmovddup(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch) {\n+  if (reachable(src)) {\n+    Assembler::vmovddup(dst, as_Address(src), vector_len);\n+  } else {\n+    lea(rscratch, src);\n+    Assembler::vmovddup(dst, Address(rscratch, 0), vector_len);\n+  }\n+}\n+\n@@ -3295,0 +3313,9 @@\n+void MacroAssembler::vbroadcastsd(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch) {\n+  if (reachable(src)) {\n+    Assembler::vbroadcastsd(dst, as_Address(src), vector_len);\n+  } else {\n+    lea(rscratch, src);\n+    Assembler::vbroadcastsd(dst, Address(rscratch, 0), vector_len);\n+  }\n+}\n+\n@@ -3363,1 +3390,1 @@\n-void MacroAssembler::vpcmpCCW(XMMRegister dst, XMMRegister nds, XMMRegister src, ComparisonPredicate cond, Width width, int vector_len, Register scratch_reg) {\n+void MacroAssembler::vpcmpCCW(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister xtmp, ComparisonPredicate cond, Width width, int vector_len) {\n@@ -3376,1 +3403,2 @@\n-    vpxor(dst, dst, ExternalAddress(StubRoutines::x86::vector_all_bits_set()), vector_len, scratch_reg);\n+    vallones(xtmp, vector_len);\n+    vpxor(dst, xtmp, dst, vector_len);\n@@ -3380,1 +3408,2 @@\n-    vpxor(dst, dst, ExternalAddress(StubRoutines::x86::vector_all_bits_set()), vector_len, scratch_reg);\n+    vallones(xtmp, vector_len);\n+    vpxor(dst, xtmp, dst, vector_len);\n@@ -3384,1 +3413,2 @@\n-    vpxor(dst, dst, ExternalAddress(StubRoutines::x86::vector_all_bits_set()), vector_len, scratch_reg);\n+    vallones(xtmp, vector_len);\n+    vpxor(dst, xtmp, dst, vector_len);\n@@ -5004,2 +5034,7 @@\n-    push(rscratch1); \/\/ cmpptr trashes rscratch1\n-    cmpptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));\n+    const auto src2 = ExternalAddress((address)CompressedOops::ptrs_base_addr());\n+    assert(!src2.is_lval(), \"should not be lval\");\n+    const bool is_src2_reachable = reachable(src2);\n+    if (!is_src2_reachable) {\n+      push(rscratch1);  \/\/ cmpptr trashes rscratch1\n+    }\n+    cmpptr(r12_heapbase, src2);\n@@ -5009,1 +5044,3 @@\n-    pop(rscratch1);\n+    if (!is_src2_reachable) {\n+      pop(rscratch1);\n+    }\n@@ -5402,1 +5439,1 @@\n-  bool use64byteVector = MaxVectorSize == 64 && AVX3Threshold == 0;\n+  bool use64byteVector = (MaxVectorSize == 64) && (VM_Version::avx3_threshold() == 0);\n@@ -5787,1 +5824,1 @@\n-  bool use64byteVector = MaxVectorSize > 32 && AVX3Threshold == 0;\n+  bool use64byteVector = (MaxVectorSize > 32) && (VM_Version::avx3_threshold() == 0);\n@@ -6027,2 +6064,2 @@\n-          \/\/ If number of bytes to fill < AVX3Threshold, perform fill using AVX2\n-          cmpl(count, AVX3Threshold);\n+          \/\/ If number of bytes to fill < VM_Version::avx3_threshold(), perform fill using AVX2\n+          cmpl(count, VM_Version::avx3_threshold());\n@@ -7738,1 +7775,1 @@\n-void MacroAssembler::kernel_crc32_avx512_256B(Register crc, Register buf, Register len, Register key, Register pos,\n+void MacroAssembler::kernel_crc32_avx512_256B(Register crc, Register buf, Register len, Register table, Register pos,\n@@ -7751,1 +7788,1 @@\n-  movdqu(xmm10, Address(key, 1 * 16));    \/\/rk1 and rk2 in xmm10\n+  movdqu(xmm10, Address(table, 1 * 16));    \/\/rk1 and rk2 in xmm10\n@@ -7778,1 +7815,1 @@\n-  movdqu(xmm10, Address(key, 1 * 16));    \/\/ rk1 and rk2 in xmm10\n+  movdqu(xmm10, Address(table, 1 * 16));    \/\/ rk1 and rk2 in xmm10\n@@ -7898,0 +7935,1 @@\n+* param table address of crc or crc32c table\n@@ -7901,0 +7939,4 @@\n+*\n+* This routine is identical for crc32c with the exception of the precomputed constant\n+* table which will be passed as the table argument.  The calculation steps are\n+* the same for both variants.\n@@ -7902,2 +7944,2 @@\n-void MacroAssembler::kernel_crc32_avx512(Register crc, Register buf, Register len, Register key, Register tmp1, Register tmp2) {\n-  assert_different_registers(crc, buf, len, key, tmp1, tmp2, rax);\n+void MacroAssembler::kernel_crc32_avx512(Register crc, Register buf, Register len, Register table, Register tmp1, Register tmp2) {\n+  assert_different_registers(crc, buf, len, table, tmp1, tmp2, rax, r12);\n@@ -7918,2 +7960,0 @@\n-  lea(key, ExternalAddress(StubRoutines::x86::crc_table_avx512_addr()));\n-  notl(crc);\n@@ -7933,1 +7973,1 @@\n-  evbroadcasti32x4(xmm10, Address(key, 2 * 16), Assembler::AVX_512bit); \/\/zmm10 has rk3 and rk4\n+  evbroadcasti32x4(xmm10, Address(table, 2 * 16), Assembler::AVX_512bit); \/\/zmm10 has rk3 and rk4\n@@ -7941,1 +7981,1 @@\n-  evbroadcasti32x4(xmm16, Address(key, 0 * 16), Assembler::AVX_512bit); \/\/zmm16 has rk-1 and rk-2\n+  evbroadcasti32x4(xmm16, Address(table, 0 * 16), Assembler::AVX_512bit); \/\/zmm16 has rk-1 and rk-2\n@@ -7987,2 +8027,2 @@\n-  evmovdquq(xmm16, Address(key, 5 * 16), Assembler::AVX_512bit); \/\/ multiply by rk9-rk16\n-  evmovdquq(xmm11, Address(key, 9 * 16), Assembler::AVX_512bit); \/\/ multiply by rk17-rk20, rk1,rk2, 0,0\n+  evmovdquq(xmm16, Address(table, 5 * 16), Assembler::AVX_512bit); \/\/ multiply by rk9-rk16\n+  evmovdquq(xmm11, Address(table, 9 * 16), Assembler::AVX_512bit); \/\/ multiply by rk17-rk20, rk1,rk2, 0,0\n@@ -7997,1 +8037,1 @@\n-  movdqu(xmm10, Address(key, 1 * 16));\n+  movdqu(xmm10, Address(table, 1 * 16));\n@@ -8013,1 +8053,1 @@\n-  vpclmulqdq(xmm8, xmm7, xmm10, 0x1);\n+  vpclmulqdq(xmm8, xmm7, xmm10, 0x01);\n@@ -8044,1 +8084,1 @@\n-  vpclmulqdq(xmm8, xmm7, xmm10, 0x1);\n+  vpclmulqdq(xmm8, xmm7, xmm10, 0x01);\n@@ -8051,1 +8091,1 @@\n-  movdqu(xmm10, Address(key, 3 * 16));\n+  movdqu(xmm10, Address(table, 3 * 16));\n@@ -8067,1 +8107,1 @@\n-  kernel_crc32_avx512_256B(crc, buf, len, key, pos, tmp1, tmp2, L_barrett, L_16B_reduction_loop, L_get_last_two_xmms, L_128_done, L_cleanup);\n+  kernel_crc32_avx512_256B(crc, buf, len, table, pos, tmp1, tmp2, L_barrett, L_16B_reduction_loop, L_get_last_two_xmms, L_128_done, L_cleanup);\n@@ -8074,1 +8114,1 @@\n-  movdqu(xmm10, Address(key, 4 * 16));\n+  movdqu(xmm10, Address(table, 4 * 16));\n@@ -8086,1 +8126,0 @@\n-  notl(crc); \/\/ ~c\n@@ -9414,0 +9453,1 @@\n+  int avx3threshold = VM_Version::avx3_threshold();\n@@ -9429,1 +9469,1 @@\n-  if (AVX3Threshold != 0  || MaxVectorSize == 32) {\n+  if ((avx3threshold != 0)  || (MaxVectorSize == 32)) {\n@@ -9432,1 +9472,1 @@\n-      cmpq(count, AVX3Threshold >> shift);\n+      cmpq(count, avx3threshold >> shift);\n@@ -9743,0 +9783,1 @@\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":73,"deletions":32,"binary":false,"changes":105,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1180,0 +1180,2 @@\n+  void vmovdqu(XMMRegister dst, AddressLiteral src, Register scratch_reg, int vector_len);\n+\n@@ -1237,0 +1239,3 @@\n+  using Assembler::vmovddup;\n+  void vmovddup(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch = rscratch1);\n+\n@@ -1345,0 +1350,3 @@\n+  using Assembler::vbroadcastsd;\n+  void vbroadcastsd(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch = rscratch1);\n+\n@@ -1371,1 +1379,1 @@\n-  void vpcmpCCW(XMMRegister dst, XMMRegister nds, XMMRegister src, ComparisonPredicate cond, Width width, int vector_len, Register scratch_reg);\n+  void vpcmpCCW(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister xtmp, ComparisonPredicate cond, Width width, int vector_len);\n@@ -1550,2 +1558,8 @@\n-  void vpxor(XMMRegister dst, XMMRegister src) { Assembler::vpxor(dst, dst, src, true); }\n-  void vpxor(XMMRegister dst, Address src) { Assembler::vpxor(dst, dst, src, true); }\n+  void vpxor(XMMRegister dst, XMMRegister src) {\n+    assert(UseAVX >= 2, \"Should be at least AVX2\");\n+    Assembler::vpxor(dst, dst, src, AVX_256bit);\n+  }\n+  void vpxor(XMMRegister dst, Address src) {\n+    assert(UseAVX >= 2, \"Should be at least AVX2\");\n+    Assembler::vpxor(dst, dst, src, AVX_256bit);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":18,"deletions":4,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -1726,30 +1726,35 @@\n-    \/\/ Load immediate 1 into swap_reg %rax,\n-    __ movptr(swap_reg, 1);\n-\n-    \/\/ Load (object->mark() | 1) into swap_reg %rax,\n-    __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-\n-    \/\/ src -> dest iff dest == rax, else rax, <- dest\n-    \/\/ *obj_reg = lock_reg iff *obj_reg == rax, else rax, = *(obj_reg)\n-    __ lock();\n-    __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    __ jcc(Assembler::equal, lock_done);\n-\n-    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-    \/\/  1) (mark & 3) == 0, and\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 2 bits clear.\n-    \/\/ NOTE: the oopMark is in swap_reg %rax, as the result of cmpxchg\n-\n-    __ subptr(swap_reg, rsp);\n-    __ andptr(swap_reg, 3 - os::vm_page_size());\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-    __ jcc(Assembler::notEqual, slow_path_lock);\n+    if (!UseHeavyMonitors) {\n+      \/\/ Load immediate 1 into swap_reg %rax,\n+      __ movptr(swap_reg, 1);\n+\n+      \/\/ Load (object->mark() | 1) into swap_reg %rax,\n+      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+\n+      \/\/ src -> dest iff dest == rax, else rax, <- dest\n+      \/\/ *obj_reg = lock_reg iff *obj_reg == rax, else rax, = *(obj_reg)\n+      __ lock();\n+      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::equal, lock_done);\n+\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) rsp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg %rax, as the result of cmpxchg\n+\n+      __ subptr(swap_reg, rsp);\n+      __ andptr(swap_reg, 3 - os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+      __ jcc(Assembler::notEqual, slow_path_lock);\n+    } else {\n+      __ jmp(slow_path_lock);\n+    }\n+\n@@ -1874,1 +1879,2 @@\n-    \/\/ Simple recursive lock?\n+    if (!UseHeavyMonitors) {\n+      \/\/ Simple recursive lock?\n@@ -1876,2 +1882,3 @@\n-    __ cmpptr(Address(rbp, lock_slot_rbp_offset), (int32_t)NULL_WORD);\n-    __ jcc(Assembler::equal, done);\n+      __ cmpptr(Address(rbp, lock_slot_rbp_offset), (int32_t)NULL_WORD);\n+      __ jcc(Assembler::equal, done);\n+    }\n@@ -1879,1 +1886,1 @@\n-    \/\/ Must save rax, if if it is live now because cmpxchg must use it\n+    \/\/ Must save rax, if it is live now because cmpxchg must use it\n@@ -1884,2 +1891,3 @@\n-    \/\/  get old displaced header\n-    __ movptr(rbx, Address(rbp, lock_slot_rbp_offset));\n+    if (!UseHeavyMonitors) {\n+      \/\/  get old displaced header\n+      __ movptr(rbx, Address(rbp, lock_slot_rbp_offset));\n@@ -1887,2 +1895,2 @@\n-    \/\/ get address of the stack lock\n-    __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n+      \/\/ get address of the stack lock\n+      __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n@@ -1890,6 +1898,9 @@\n-    \/\/ Atomic swap old header if oop still contains the stack lock\n-    \/\/ src -> dest iff dest == rax, else rax, <- dest\n-    \/\/ *obj_reg = rbx, iff *obj_reg == rax, else rax, = *(obj_reg)\n-    __ lock();\n-    __ cmpxchgptr(rbx, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    __ jcc(Assembler::notEqual, slow_path_unlock);\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      \/\/ src -> dest iff dest == rax, else rax, <- dest\n+      \/\/ *obj_reg = rbx, iff *obj_reg == rax, else rax, = *(obj_reg)\n+      __ lock();\n+      __ cmpxchgptr(rbx, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::notEqual, slow_path_unlock);\n+    } else {\n+      __ jmp(slow_path_unlock);\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":55,"deletions":44,"binary":false,"changes":99,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -2180,9 +2180,3 @@\n-    \/\/ Load immediate 1 into swap_reg %rax\n-    __ movl(swap_reg, 1);\n-\n-    \/\/ Load (object->mark() | 1) into swap_reg %rax\n-    __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    if (EnableValhalla) {\n-      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n-      __ andptr(swap_reg, ~((int) markWord::inline_type_bit_in_place));\n-    }\n+    if (!UseHeavyMonitors) {\n+      \/\/ Load immediate 1 into swap_reg %rax\n+      __ movl(swap_reg, 1);\n@@ -2190,0 +2184,6 @@\n+      \/\/ Load (object->mark() | 1) into swap_reg %rax\n+      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      if (EnableValhalla) {\n+        \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+        __ andptr(swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+      }\n@@ -2191,2 +2191,2 @@\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n@@ -2194,4 +2194,4 @@\n-    \/\/ src -> dest iff dest == rax else rax <- dest\n-    __ lock();\n-    __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    __ jcc(Assembler::equal, lock_done);\n+      \/\/ src -> dest iff dest == rax else rax <- dest\n+      __ lock();\n+      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::equal, lock_done);\n@@ -2199,1 +2199,1 @@\n-    \/\/ Hmm should this move to the slow path code area???\n+      \/\/ Hmm should this move to the slow path code area???\n@@ -2201,8 +2201,8 @@\n-    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-    \/\/  1) (mark & 3) == 0, and\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 2 bits clear.\n-    \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) rsp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n@@ -2210,2 +2210,2 @@\n-    __ subptr(swap_reg, rsp);\n-    __ andptr(swap_reg, 3 - os::vm_page_size());\n+      __ subptr(swap_reg, rsp);\n+      __ andptr(swap_reg, 3 - os::vm_page_size());\n@@ -2213,3 +2213,6 @@\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-    __ jcc(Assembler::notEqual, slow_path_lock);\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+      __ jcc(Assembler::notEqual, slow_path_lock);\n+    } else {\n+      __ jmp(slow_path_lock);\n+    }\n@@ -2323,3 +2326,5 @@\n-    \/\/ Simple recursive lock?\n-    __ cmpptr(Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size), (int32_t)NULL_WORD);\n-    __ jcc(Assembler::equal, done);\n+    if (!UseHeavyMonitors) {\n+      \/\/ Simple recursive lock?\n+      __ cmpptr(Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size), (int32_t)NULL_WORD);\n+      __ jcc(Assembler::equal, done);\n+    }\n@@ -2328,1 +2333,1 @@\n-    \/\/ Must save rax if if it is live now because cmpxchg must use it\n+    \/\/ Must save rax if it is live now because cmpxchg must use it\n@@ -2334,4 +2339,5 @@\n-    \/\/ get address of the stack lock\n-    __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-    \/\/  get old displaced header\n-    __ movptr(old_hdr, Address(rax, 0));\n+    if (!UseHeavyMonitors) {\n+      \/\/ get address of the stack lock\n+      __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      \/\/  get old displaced header\n+      __ movptr(old_hdr, Address(rax, 0));\n@@ -2339,4 +2345,7 @@\n-    \/\/ Atomic swap old header if oop still contains the stack lock\n-    __ lock();\n-    __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    __ jcc(Assembler::notEqual, slow_path_unlock);\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      __ lock();\n+      __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::notEqual, slow_path_unlock);\n+    } else {\n+      __ jmp(slow_path_unlock);\n+    }\n@@ -3800,0 +3809,2 @@\n+  int divisor = sizeof(julong) * 4;\n+  guarantee(longwords <= 8192 \/ divisor, \"must be\");\n@@ -3801,1 +3812,0 @@\n-  guarantee(total_allocation <= 8192, \"must be\");\n@@ -3829,0 +3839,2 @@\n+  int divisor = sizeof(julong) * 3;\n+  guarantee(longwords <= (8192 \/ divisor), \"must be\");\n@@ -3830,1 +3842,0 @@\n-  guarantee(total_allocation <= 8192, \"must be\");\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":55,"deletions":44,"binary":false,"changes":99,"status":"modified"},{"patch":"@@ -1239,5 +1239,0 @@\n-      if (UseAVX >= 2) {\n-        \/\/ clean upper bits of YMM registers\n-        __ vpxor(xmm0, xmm0);\n-        __ vpxor(xmm1, xmm1);\n-      }\n@@ -1317,5 +1312,0 @@\n-      if (UseAVX >= 2) {\n-        \/\/ clean upper bits of YMM registers\n-        __ vpxor(xmm0, xmm0);\n-        __ vpxor(xmm1, xmm1);\n-      }\n@@ -1402,2 +1392,2 @@\n-\n-    bool use64byteVector = MaxVectorSize > 32 && AVX3Threshold == 0;\n+    int avx3threshold = VM_Version::avx3_threshold();\n+    bool use64byteVector = (MaxVectorSize > 32) && (avx3threshold == 0);\n@@ -1466,1 +1456,1 @@\n-      if (AVX3Threshold != 0) {\n+      if (avx3threshold != 0) {\n@@ -1478,1 +1468,1 @@\n-      if (MaxVectorSize < 64  || AVX3Threshold != 0) {\n+      if ((MaxVectorSize < 64)  || (avx3threshold != 0)) {\n@@ -1621,1 +1611,2 @@\n-    bool use64byteVector = MaxVectorSize > 32 && AVX3Threshold == 0;\n+    int avx3threshold = VM_Version::avx3_threshold();\n+    bool use64byteVector = (MaxVectorSize > 32) && (avx3threshold == 0);\n@@ -1686,1 +1677,1 @@\n-      if (MaxVectorSize > 32 && AVX3Threshold != 0) {\n+      if ((MaxVectorSize > 32) && (avx3threshold != 0)) {\n@@ -1691,1 +1682,1 @@\n-      if (MaxVectorSize < 64  || AVX3Threshold != 0) {\n+      if ((MaxVectorSize < 64)  || (avx3threshold != 0)) {\n@@ -4179,0 +4170,1 @@\n+    __ vzeroupper();\n@@ -4194,0 +4186,1 @@\n+    __ vzeroupper();\n@@ -4455,2 +4448,1 @@\n-    const Address avx512_subkeyH_mem(rbp, 3 * wordSize);\n-    const Address counter_mem(rbp, 4 * wordSize);\n+    const Address counter_mem(rbp, 3 * wordSize);\n@@ -4466,2 +4458,1 @@\n-    const Address avx512_subkeyH_mem(rbp, 9 * wordSize);\n-    const Address counter_mem(rbp, 10 * wordSize);\n+    const Address counter_mem(rbp, 9 * wordSize);\n@@ -4485,1 +4476,7 @@\n-    __ movptr(avx512_subkeyHtbl, avx512_subkeyH_mem);\n+\/\/ Save rbp and rsp\n+    __ push(rbp);\n+    __ movq(rbp, rsp);\n+\/\/ Align stack\n+    __ andq(rsp, -64);\n+    __ subptr(rsp, 96 * longSize); \/\/ Create space on the stack for htbl entries\n+    __ movptr(avx512_subkeyHtbl, rsp);\n@@ -4489,0 +4486,4 @@\n+    __ vzeroupper();\n+\n+    __ movq(rsp, rbp);\n+    __ pop(rbp);\n@@ -4605,0 +4606,1 @@\n+    __ vzeroupper();\n@@ -5225,0 +5227,1 @@\n+    __ vzeroupper();\n@@ -6302,0 +6305,3 @@\n+      __ mov64(rax, 0x0000ffffffffffff);\n+      __ kmovql(k2, rax);\n+\n@@ -6323,1 +6329,1 @@\n-      __ evmovdquq(Address(dest, dp), merged0, Assembler::AVX_512bit);\n+      __ evmovdqub(Address(dest, dp), k2, merged0, true, Assembler::AVX_512bit);\n@@ -6570,0 +6576,5 @@\n+        \/\/ The constants used in the CRC32 algorithm requires the 1's compliment of the initial crc value.\n+        \/\/ However, the constant table for CRC32-C assumes the original crc value.  Account for this\n+        \/\/ difference before calling and after returning.\n+      __ lea(table, ExternalAddress(StubRoutines::x86::crc_table_avx512_addr()));\n+      __ notl(crc);\n@@ -6571,0 +6582,1 @@\n+      __ notl(crc);\n@@ -6622,0 +6634,6 @@\n+      if (VM_Version::supports_sse4_1() && VM_Version::supports_avx512_vpclmulqdq() &&\n+          VM_Version::supports_avx512bw() &&\n+          VM_Version::supports_avx512vl()) {\n+        __ lea(j, ExternalAddress(StubRoutines::x86::crc32c_table_avx512_addr()));\n+        __ kernel_crc32_avx512(crc, buf, len, j, l, k);\n+      } else {\n@@ -6623,2 +6641,2 @@\n-      __ push(y);\n-      __ push(z);\n+        __ push(y);\n+        __ push(z);\n@@ -6626,6 +6644,5 @@\n-      __ crc32c_ipl_alg2_alt2(crc, buf, len,\n-                              a, j, k,\n-                              l, y, z,\n-                              c_farg0, c_farg1, c_farg2,\n-                              is_pclmulqdq_supported);\n-      __ movl(rax, crc);\n+        __ crc32c_ipl_alg2_alt2(crc, buf, len,\n+                                a, j, k,\n+                                l, y, z,\n+                                c_farg0, c_farg1, c_farg2,\n+                                is_pclmulqdq_supported);\n@@ -6633,2 +6650,2 @@\n-      __ pop(z);\n-      __ pop(y);\n+        __ pop(z);\n+        __ pop(y);\n@@ -6636,0 +6653,2 @@\n+      }\n+      __ movl(rax, crc);\n@@ -7084,0 +7103,1 @@\n+    __ vzeroupper();\n@@ -7205,0 +7225,1 @@\n+    __ vzeroupper();\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":54,"deletions":33,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -86,0 +86,13 @@\n+#define CPUID_STANDARD_FN   0x0\n+#define CPUID_STANDARD_FN_1 0x1\n+#define CPUID_STANDARD_FN_4 0x4\n+#define CPUID_STANDARD_FN_B 0xb\n+\n+#define CPUID_EXTENDED_FN   0x80000000\n+#define CPUID_EXTENDED_FN_1 0x80000001\n+#define CPUID_EXTENDED_FN_2 0x80000002\n+#define CPUID_EXTENDED_FN_3 0x80000003\n+#define CPUID_EXTENDED_FN_4 0x80000004\n+#define CPUID_EXTENDED_FN_7 0x80000007\n+#define CPUID_EXTENDED_FN_8 0x80000008\n+\n@@ -629,0 +642,143 @@\n+#   undef __\n+\n+    return start;\n+  };\n+\n+\n+  address generate_getCPUIDBrandString(void) {\n+    \/\/ Flags to test CPU type.\n+    const uint32_t HS_EFL_AC           = 0x40000;\n+    const uint32_t HS_EFL_ID           = 0x200000;\n+    \/\/ Values for when we don't have a CPUID instruction.\n+    const int      CPU_FAMILY_SHIFT = 8;\n+    const uint32_t CPU_FAMILY_386   = (3 << CPU_FAMILY_SHIFT);\n+    const uint32_t CPU_FAMILY_486   = (4 << CPU_FAMILY_SHIFT);\n+\n+    Label detect_486, cpu486, detect_586, done, ext_cpuid;\n+\n+    StubCodeMark mark(this, \"VM_Version\", \"getCPUIDNameInfo_stub\");\n+#   define __ _masm->\n+\n+    address start = __ pc();\n+\n+    \/\/\n+    \/\/ void getCPUIDBrandString(VM_Version::CpuidInfo* cpuid_info);\n+    \/\/\n+    \/\/ LP64: rcx and rdx are first and second argument registers on windows\n+\n+    __ push(rbp);\n+#ifdef _LP64\n+    __ mov(rbp, c_rarg0); \/\/ cpuid_info address\n+#else\n+    __ movptr(rbp, Address(rsp, 8)); \/\/ cpuid_info address\n+#endif\n+    __ push(rbx);\n+    __ push(rsi);\n+    __ pushf();          \/\/ preserve rbx, and flags\n+    __ pop(rax);\n+    __ push(rax);\n+    __ mov(rcx, rax);\n+    \/\/\n+    \/\/ if we are unable to change the AC flag, we have a 386\n+    \/\/\n+    __ xorl(rax, HS_EFL_AC);\n+    __ push(rax);\n+    __ popf();\n+    __ pushf();\n+    __ pop(rax);\n+    __ cmpptr(rax, rcx);\n+    __ jccb(Assembler::notEqual, detect_486);\n+\n+    __ movl(rax, CPU_FAMILY_386);\n+    __ jmp(done);\n+\n+    \/\/\n+    \/\/ If we are unable to change the ID flag, we have a 486 which does\n+    \/\/ not support the \"cpuid\" instruction.\n+    \/\/\n+    __ bind(detect_486);\n+    __ mov(rax, rcx);\n+    __ xorl(rax, HS_EFL_ID);\n+    __ push(rax);\n+    __ popf();\n+    __ pushf();\n+    __ pop(rax);\n+    __ cmpptr(rcx, rax);\n+    __ jccb(Assembler::notEqual, detect_586);\n+\n+    __ bind(cpu486);\n+    __ movl(rax, CPU_FAMILY_486);\n+    __ jmp(done);\n+\n+    \/\/\n+    \/\/ At this point, we have a chip which supports the \"cpuid\" instruction\n+    \/\/\n+    __ bind(detect_586);\n+    __ xorl(rax, rax);\n+    __ cpuid();\n+    __ orl(rax, rax);\n+    __ jcc(Assembler::equal, cpu486);   \/\/ if cpuid doesn't support an input\n+                                        \/\/ value of at least 1, we give up and\n+                                        \/\/ assume a 486\n+\n+    \/\/\n+    \/\/ Extended cpuid(0x80000000) for processor brand string detection\n+    \/\/\n+    __ bind(ext_cpuid);\n+    __ movl(rax, CPUID_EXTENDED_FN);\n+    __ cpuid();\n+    __ cmpl(rax, CPUID_EXTENDED_FN_4);\n+    __ jcc(Assembler::below, done);\n+\n+    \/\/\n+    \/\/ Extended cpuid(0x80000002)  \/\/ first 16 bytes in brand string\n+    \/\/\n+    __ movl(rax, CPUID_EXTENDED_FN_2);\n+    __ cpuid();\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_0_offset())));\n+    __ movl(Address(rsi, 0), rax);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_1_offset())));\n+    __ movl(Address(rsi, 0), rbx);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_2_offset())));\n+    __ movl(Address(rsi, 0), rcx);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_3_offset())));\n+    __ movl(Address(rsi,0), rdx);\n+\n+    \/\/\n+    \/\/ Extended cpuid(0x80000003) \/\/ next 16 bytes in brand string\n+    \/\/\n+    __ movl(rax, CPUID_EXTENDED_FN_3);\n+    __ cpuid();\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_4_offset())));\n+    __ movl(Address(rsi, 0), rax);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_5_offset())));\n+    __ movl(Address(rsi, 0), rbx);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_6_offset())));\n+    __ movl(Address(rsi, 0), rcx);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_7_offset())));\n+    __ movl(Address(rsi,0), rdx);\n+\n+    \/\/\n+    \/\/ Extended cpuid(0x80000004) \/\/ last 16 bytes in brand string\n+    \/\/\n+    __ movl(rax, CPUID_EXTENDED_FN_4);\n+    __ cpuid();\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_8_offset())));\n+    __ movl(Address(rsi, 0), rax);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_9_offset())));\n+    __ movl(Address(rsi, 0), rbx);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_10_offset())));\n+    __ movl(Address(rsi, 0), rcx);\n+    __ lea(rsi, Address(rbp, in_bytes(VM_Version::proc_name_11_offset())));\n+    __ movl(Address(rsi,0), rdx);\n+\n+    \/\/\n+    \/\/ return\n+    \/\/\n+    __ bind(done);\n+    __ popf();\n+    __ pop(rsi);\n+    __ pop(rbx);\n+    __ pop(rbp);\n+    __ ret(0);\n+\n@@ -1881,0 +2037,13 @@\n+\/\/ avx3_threshold() sets the threshold at which 64-byte instructions are used\n+\/\/ for implementing the array copy and clear operations.\n+\/\/ The Intel platforms that supports the serialize instruction\n+\/\/ has improved implementation of 64-byte load\/stores and so the default\n+\/\/ threshold is set to 0 for these platforms.\n+int VM_Version::avx3_threshold() {\n+  return (is_intel_family_core() &&\n+          supports_serialize() &&\n+          FLAG_IS_DEFAULT(AVX3Threshold)) ? 0 : AVX3Threshold;\n+}\n+\n+static bool _vm_version_initialized = false;\n+\n@@ -1903,0 +2072,549 @@\n+  _vm_version_initialized = true;\n+}\n+\n+typedef enum {\n+   CPU_FAMILY_8086_8088  = 0,\n+   CPU_FAMILY_INTEL_286  = 2,\n+   CPU_FAMILY_INTEL_386  = 3,\n+   CPU_FAMILY_INTEL_486  = 4,\n+   CPU_FAMILY_PENTIUM    = 5,\n+   CPU_FAMILY_PENTIUMPRO = 6,    \/\/ Same family several models\n+   CPU_FAMILY_PENTIUM_4  = 0xF\n+} FamilyFlag;\n+\n+typedef enum {\n+  RDTSCP_FLAG  = 0x08000000, \/\/ bit 27\n+  INTEL64_FLAG = 0x20000000  \/\/ bit 29\n+} _featureExtendedEdxFlag;\n+\n+typedef enum {\n+   FPU_FLAG     = 0x00000001,\n+   VME_FLAG     = 0x00000002,\n+   DE_FLAG      = 0x00000004,\n+   PSE_FLAG     = 0x00000008,\n+   TSC_FLAG     = 0x00000010,\n+   MSR_FLAG     = 0x00000020,\n+   PAE_FLAG     = 0x00000040,\n+   MCE_FLAG     = 0x00000080,\n+   CX8_FLAG     = 0x00000100,\n+   APIC_FLAG    = 0x00000200,\n+   SEP_FLAG     = 0x00000800,\n+   MTRR_FLAG    = 0x00001000,\n+   PGE_FLAG     = 0x00002000,\n+   MCA_FLAG     = 0x00004000,\n+   CMOV_FLAG    = 0x00008000,\n+   PAT_FLAG     = 0x00010000,\n+   PSE36_FLAG   = 0x00020000,\n+   PSNUM_FLAG   = 0x00040000,\n+   CLFLUSH_FLAG = 0x00080000,\n+   DTS_FLAG     = 0x00200000,\n+   ACPI_FLAG    = 0x00400000,\n+   MMX_FLAG     = 0x00800000,\n+   FXSR_FLAG    = 0x01000000,\n+   SSE_FLAG     = 0x02000000,\n+   SSE2_FLAG    = 0x04000000,\n+   SS_FLAG      = 0x08000000,\n+   HTT_FLAG     = 0x10000000,\n+   TM_FLAG      = 0x20000000\n+} FeatureEdxFlag;\n+\n+static BufferBlob* cpuid_brand_string_stub_blob;\n+static const int   cpuid_brand_string_stub_size = 550;\n+\n+extern \"C\" {\n+  typedef void (*getCPUIDBrandString_stub_t)(void*);\n+}\n+\n+static getCPUIDBrandString_stub_t getCPUIDBrandString_stub = NULL;\n+\n+\/\/ VM_Version statics\n+enum {\n+  ExtendedFamilyIdLength_INTEL = 16,\n+  ExtendedFamilyIdLength_AMD   = 24\n+};\n+\n+const size_t VENDOR_LENGTH = 13;\n+const size_t CPU_EBS_MAX_LENGTH = (3 * 4 * 4 + 1);\n+static char* _cpu_brand_string = NULL;\n+static int64_t _max_qualified_cpu_frequency = 0;\n+\n+static int _no_of_threads = 0;\n+static int _no_of_cores = 0;\n+\n+const char* const _family_id_intel[ExtendedFamilyIdLength_INTEL] = {\n+  \"8086\/8088\",\n+  \"\",\n+  \"286\",\n+  \"386\",\n+  \"486\",\n+  \"Pentium\",\n+  \"Pentium Pro\",   \/\/or Pentium-M\/Woodcrest depeding on model\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Pentium 4\"\n+};\n+\n+const char* const _family_id_amd[ExtendedFamilyIdLength_AMD] = {\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"5x86\",\n+  \"K5\/K6\",\n+  \"Athlon\/AthlonXP\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Opteron\/Athlon64\",\n+  \"Opteron QC\/Phenom\",  \/\/ Barcelona et.al.\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Zen\"\n+};\n+\/\/ Partially from Intel 64 and IA-32 Architecture Software Developer's Manual,\n+\/\/ September 2013, Vol 3C Table 35-1\n+const char* const _model_id_pentium_pro[] = {\n+  \"\",\n+  \"Pentium Pro\",\n+  \"\",\n+  \"Pentium II model 3\",\n+  \"\",\n+  \"Pentium II model 5\/Xeon\/Celeron\",\n+  \"Celeron\",\n+  \"Pentium III\/Pentium III Xeon\",\n+  \"Pentium III\/Pentium III Xeon\",\n+  \"Pentium M model 9\",    \/\/ Yonah\n+  \"Pentium III, model A\",\n+  \"Pentium III, model B\",\n+  \"\",\n+  \"Pentium M model D\",    \/\/ Dothan\n+  \"\",\n+  \"Core 2\",               \/\/ 0xf Woodcrest\/Conroe\/Merom\/Kentsfield\/Clovertown\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Celeron\",              \/\/ 0x16 Celeron 65nm\n+  \"Core 2\",               \/\/ 0x17 Penryn \/ Harpertown\n+  \"\",\n+  \"\",\n+  \"Core i7\",              \/\/ 0x1A CPU_MODEL_NEHALEM_EP\n+  \"Atom\",                 \/\/ 0x1B Z5xx series Silverthorn\n+  \"\",\n+  \"Core 2\",               \/\/ 0x1D Dunnington (6-core)\n+  \"Nehalem\",              \/\/ 0x1E CPU_MODEL_NEHALEM\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Westmere\",             \/\/ 0x25 CPU_MODEL_WESTMERE\n+  \"\",\n+  \"\",\n+  \"\",                     \/\/ 0x28\n+  \"\",\n+  \"Sandy Bridge\",         \/\/ 0x2a \"2nd Generation Intel Core i7, i5, i3\"\n+  \"\",\n+  \"Westmere-EP\",          \/\/ 0x2c CPU_MODEL_WESTMERE_EP\n+  \"Sandy Bridge-EP\",      \/\/ 0x2d CPU_MODEL_SANDYBRIDGE_EP\n+  \"Nehalem-EX\",           \/\/ 0x2e CPU_MODEL_NEHALEM_EX\n+  \"Westmere-EX\",          \/\/ 0x2f CPU_MODEL_WESTMERE_EX\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Ivy Bridge\",           \/\/ 0x3a\n+  \"\",\n+  \"Haswell\",              \/\/ 0x3c \"4th Generation Intel Core Processor\"\n+  \"\",                     \/\/ 0x3d \"Next Generation Intel Core Processor\"\n+  \"Ivy Bridge-EP\",        \/\/ 0x3e \"Next Generation Intel Xeon Processor E7 Family\"\n+  \"\",                     \/\/ 0x3f \"Future Generation Intel Xeon Processor\"\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Haswell\",              \/\/ 0x45 \"4th Generation Intel Core Processor\"\n+  \"Haswell\",              \/\/ 0x46 \"4th Generation Intel Core Processor\"\n+  NULL\n+};\n+\n+\/* Brand ID is for back compability\n+ * Newer CPUs uses the extended brand string *\/\n+const char* const _brand_id[] = {\n+  \"\",\n+  \"Celeron processor\",\n+  \"Pentium III processor\",\n+  \"Intel Pentium III Xeon processor\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Intel Pentium 4 processor\",\n+  NULL\n+};\n+\n+\n+const char* const _feature_edx_id[] = {\n+  \"On-Chip FPU\",\n+  \"Virtual Mode Extensions\",\n+  \"Debugging Extensions\",\n+  \"Page Size Extensions\",\n+  \"Time Stamp Counter\",\n+  \"Model Specific Registers\",\n+  \"Physical Address Extension\",\n+  \"Machine Check Exceptions\",\n+  \"CMPXCHG8B Instruction\",\n+  \"On-Chip APIC\",\n+  \"\",\n+  \"Fast System Call\",\n+  \"Memory Type Range Registers\",\n+  \"Page Global Enable\",\n+  \"Machine Check Architecture\",\n+  \"Conditional Mov Instruction\",\n+  \"Page Attribute Table\",\n+  \"36-bit Page Size Extension\",\n+  \"Processor Serial Number\",\n+  \"CLFLUSH Instruction\",\n+  \"\",\n+  \"Debug Trace Store feature\",\n+  \"ACPI registers in MSR space\",\n+  \"Intel Architecture MMX Technology\",\n+  \"Fast Float Point Save and Restore\",\n+  \"Streaming SIMD extensions\",\n+  \"Streaming SIMD extensions 2\",\n+  \"Self-Snoop\",\n+  \"Hyper Threading\",\n+  \"Thermal Monitor\",\n+  \"\",\n+  \"Pending Break Enable\"\n+};\n+\n+const char* const _feature_extended_edx_id[] = {\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"SYSCALL\/SYSRET\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Execute Disable Bit\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"RDTSCP\",\n+  \"\",\n+  \"Intel 64 Architecture\",\n+  \"\",\n+  \"\"\n+};\n+\n+const char* const _feature_ecx_id[] = {\n+  \"Streaming SIMD Extensions 3\",\n+  \"PCLMULQDQ\",\n+  \"64-bit DS Area\",\n+  \"MONITOR\/MWAIT instructions\",\n+  \"CPL Qualified Debug Store\",\n+  \"Virtual Machine Extensions\",\n+  \"Safer Mode Extensions\",\n+  \"Enhanced Intel SpeedStep technology\",\n+  \"Thermal Monitor 2\",\n+  \"Supplemental Streaming SIMD Extensions 3\",\n+  \"L1 Context ID\",\n+  \"\",\n+  \"Fused Multiply-Add\",\n+  \"CMPXCHG16B\",\n+  \"xTPR Update Control\",\n+  \"Perfmon and Debug Capability\",\n+  \"\",\n+  \"Process-context identifiers\",\n+  \"Direct Cache Access\",\n+  \"Streaming SIMD extensions 4.1\",\n+  \"Streaming SIMD extensions 4.2\",\n+  \"x2APIC\",\n+  \"MOVBE\",\n+  \"Popcount instruction\",\n+  \"TSC-Deadline\",\n+  \"AESNI\",\n+  \"XSAVE\",\n+  \"OSXSAVE\",\n+  \"AVX\",\n+  \"F16C\",\n+  \"RDRAND\",\n+  \"\"\n+};\n+\n+const char* const _feature_extended_ecx_id[] = {\n+  \"LAHF\/SAHF instruction support\",\n+  \"Core multi-processor legacy mode\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"Advanced Bit Manipulations: LZCNT\",\n+  \"SSE4A: MOVNTSS, MOVNTSD, EXTRQ, INSERTQ\",\n+  \"Misaligned SSE mode\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\",\n+  \"\"\n+};\n+\n+void VM_Version::initialize_tsc(void) {\n+  ResourceMark rm;\n+\n+  cpuid_brand_string_stub_blob = BufferBlob::create(\"getCPUIDBrandString_stub\", cpuid_brand_string_stub_size);\n+  if (cpuid_brand_string_stub_blob == NULL) {\n+    vm_exit_during_initialization(\"Unable to allocate getCPUIDBrandString_stub\");\n+  }\n+  CodeBuffer c(cpuid_brand_string_stub_blob);\n+  VM_Version_StubGenerator g(&c);\n+  getCPUIDBrandString_stub = CAST_TO_FN_PTR(getCPUIDBrandString_stub_t,\n+                                   g.generate_getCPUIDBrandString());\n+}\n+\n+const char* VM_Version::cpu_model_description(void) {\n+  uint32_t cpu_family = extended_cpu_family();\n+  uint32_t cpu_model = extended_cpu_model();\n+  const char* model = NULL;\n+\n+  if (cpu_family == CPU_FAMILY_PENTIUMPRO) {\n+    for (uint32_t i = 0; i <= cpu_model; i++) {\n+      model = _model_id_pentium_pro[i];\n+      if (model == NULL) {\n+        break;\n+      }\n+    }\n+  }\n+  return model;\n+}\n+\n+const char* VM_Version::cpu_brand_string(void) {\n+  if (_cpu_brand_string == NULL) {\n+    _cpu_brand_string = NEW_C_HEAP_ARRAY_RETURN_NULL(char, CPU_EBS_MAX_LENGTH, mtInternal);\n+    if (NULL == _cpu_brand_string) {\n+      return NULL;\n+    }\n+    int ret_val = cpu_extended_brand_string(_cpu_brand_string, CPU_EBS_MAX_LENGTH);\n+    if (ret_val != OS_OK) {\n+      FREE_C_HEAP_ARRAY(char, _cpu_brand_string);\n+      _cpu_brand_string = NULL;\n+    }\n+  }\n+  return _cpu_brand_string;\n+}\n+\n+const char* VM_Version::cpu_brand(void) {\n+  const char*  brand  = NULL;\n+\n+  if ((_cpuid_info.std_cpuid1_ebx.value & 0xFF) > 0) {\n+    int brand_num = _cpuid_info.std_cpuid1_ebx.value & 0xFF;\n+    brand = _brand_id[0];\n+    for (int i = 0; brand != NULL && i <= brand_num; i += 1) {\n+      brand = _brand_id[i];\n+    }\n+  }\n+  return brand;\n+}\n+\n+bool VM_Version::cpu_is_em64t(void) {\n+  return ((_cpuid_info.ext_cpuid1_edx.value & INTEL64_FLAG) == INTEL64_FLAG);\n+}\n+\n+bool VM_Version::is_netburst(void) {\n+  return (is_intel() && (extended_cpu_family() == CPU_FAMILY_PENTIUM_4));\n+}\n+\n+bool VM_Version::supports_tscinv_ext(void) {\n+  if (!supports_tscinv_bit()) {\n+    return false;\n+  }\n+\n+  if (is_intel()) {\n+    return true;\n+  }\n+\n+  if (is_amd()) {\n+    return !is_amd_Barcelona();\n+  }\n+\n+  if (is_hygon()) {\n+    return true;\n+  }\n+\n+  return false;\n+}\n+\n+void VM_Version::resolve_cpu_information_details(void) {\n+\n+  \/\/ in future we want to base this information on proper cpu\n+  \/\/ and cache topology enumeration such as:\n+  \/\/ Intel 64 Architecture Processor Topology Enumeration\n+  \/\/ which supports system cpu and cache topology enumeration\n+  \/\/ either using 2xAPICIDs or initial APICIDs\n+\n+  \/\/ currently only rough cpu information estimates\n+  \/\/ which will not necessarily reflect the exact configuration of the system\n+\n+  \/\/ this is the number of logical hardware threads\n+  \/\/ visible to the operating system\n+  _no_of_threads = os::processor_count();\n+\n+  \/\/ find out number of threads per cpu package\n+  int threads_per_package = threads_per_core() * cores_per_cpu();\n+\n+  \/\/ use amount of threads visible to the process in order to guess number of sockets\n+  _no_of_sockets = _no_of_threads \/ threads_per_package;\n+\n+  \/\/ process might only see a subset of the total number of threads\n+  \/\/ from a single processor package. Virtualization\/resource management for example.\n+  \/\/ If so then just write a hard 1 as num of pkgs.\n+  if (0 == _no_of_sockets) {\n+    _no_of_sockets = 1;\n+  }\n+\n+  \/\/ estimate the number of cores\n+  _no_of_cores = cores_per_cpu() * _no_of_sockets;\n+}\n+\n+\n+const char* VM_Version::cpu_family_description(void) {\n+  int cpu_family_id = extended_cpu_family();\n+  if (is_amd()) {\n+    if (cpu_family_id < ExtendedFamilyIdLength_AMD) {\n+      return _family_id_amd[cpu_family_id];\n+    }\n+  }\n+  if (is_intel()) {\n+    if (cpu_family_id == CPU_FAMILY_PENTIUMPRO) {\n+      return cpu_model_description();\n+    }\n+    if (cpu_family_id < ExtendedFamilyIdLength_INTEL) {\n+      return _family_id_intel[cpu_family_id];\n+    }\n+  }\n+  if (is_hygon()) {\n+    return \"Dhyana\";\n+  }\n+  return \"Unknown x86\";\n+}\n+\n+int VM_Version::cpu_type_description(char* const buf, size_t buf_len) {\n+  assert(buf != NULL, \"buffer is NULL!\");\n+  assert(buf_len >= CPU_TYPE_DESC_BUF_SIZE, \"buffer len should at least be == CPU_TYPE_DESC_BUF_SIZE!\");\n+\n+  const char* cpu_type = NULL;\n+  const char* x64 = NULL;\n+\n+  if (is_intel()) {\n+    cpu_type = \"Intel\";\n+    x64 = cpu_is_em64t() ? \" Intel64\" : \"\";\n+  } else if (is_amd()) {\n+    cpu_type = \"AMD\";\n+    x64 = cpu_is_em64t() ? \" AMD64\" : \"\";\n+  } else if (is_hygon()) {\n+    cpu_type = \"Hygon\";\n+    x64 = cpu_is_em64t() ? \" AMD64\" : \"\";\n+  } else {\n+    cpu_type = \"Unknown x86\";\n+    x64 = cpu_is_em64t() ? \" x86_64\" : \"\";\n+  }\n+\n+  jio_snprintf(buf, buf_len, \"%s %s%s SSE SSE2%s%s%s%s%s%s%s%s\",\n+    cpu_type,\n+    cpu_family_description(),\n+    supports_ht() ? \" (HT)\" : \"\",\n+    supports_sse3() ? \" SSE3\" : \"\",\n+    supports_ssse3() ? \" SSSE3\" : \"\",\n+    supports_sse4_1() ? \" SSE4.1\" : \"\",\n+    supports_sse4_2() ? \" SSE4.2\" : \"\",\n+    supports_sse4a() ? \" SSE4A\" : \"\",\n+    is_netburst() ? \" Netburst\" : \"\",\n+    is_intel_family_core() ? \" Core\" : \"\",\n+    x64);\n+\n+  return OS_OK;\n+}\n+\n+int VM_Version::cpu_extended_brand_string(char* const buf, size_t buf_len) {\n+  assert(buf != NULL, \"buffer is NULL!\");\n+  assert(buf_len >= CPU_EBS_MAX_LENGTH, \"buffer len should at least be == CPU_EBS_MAX_LENGTH!\");\n+  assert(getCPUIDBrandString_stub != NULL, \"not initialized\");\n+\n+  \/\/ invoke newly generated asm code to fetch CPU Brand String\n+  getCPUIDBrandString_stub(&_cpuid_info);\n+\n+  \/\/ fetch results into buffer\n+  *((uint32_t*) &buf[0])  = _cpuid_info.proc_name_0;\n+  *((uint32_t*) &buf[4])  = _cpuid_info.proc_name_1;\n+  *((uint32_t*) &buf[8])  = _cpuid_info.proc_name_2;\n+  *((uint32_t*) &buf[12]) = _cpuid_info.proc_name_3;\n+  *((uint32_t*) &buf[16]) = _cpuid_info.proc_name_4;\n+  *((uint32_t*) &buf[20]) = _cpuid_info.proc_name_5;\n+  *((uint32_t*) &buf[24]) = _cpuid_info.proc_name_6;\n+  *((uint32_t*) &buf[28]) = _cpuid_info.proc_name_7;\n+  *((uint32_t*) &buf[32]) = _cpuid_info.proc_name_8;\n+  *((uint32_t*) &buf[36]) = _cpuid_info.proc_name_9;\n+  *((uint32_t*) &buf[40]) = _cpuid_info.proc_name_10;\n+  *((uint32_t*) &buf[44]) = _cpuid_info.proc_name_11;\n+\n+  return OS_OK;\n@@ -1904,0 +2622,204 @@\n+\n+size_t VM_Version::cpu_write_support_string(char* const buf, size_t buf_len) {\n+  guarantee(buf != NULL, \"buffer is NULL!\");\n+  guarantee(buf_len > 0, \"buffer len not enough!\");\n+\n+  unsigned int flag = 0;\n+  unsigned int fi = 0;\n+  size_t       written = 0;\n+  const char*  prefix = \"\";\n+\n+#define WRITE_TO_BUF(string)                                                          \\\n+  {                                                                                   \\\n+    int res = jio_snprintf(&buf[written], buf_len - written, \"%s%s\", prefix, string); \\\n+    if (res < 0) {                                                                    \\\n+      return buf_len - 1;                                                             \\\n+    }                                                                                 \\\n+    written += res;                                                                   \\\n+    if (prefix[0] == '\\0') {                                                          \\\n+      prefix = \", \";                                                                  \\\n+    }                                                                                 \\\n+  }\n+\n+  for (flag = 1, fi = 0; flag <= 0x20000000 ; flag <<= 1, fi++) {\n+    if (flag == HTT_FLAG && (((_cpuid_info.std_cpuid1_ebx.value >> 16) & 0xff) <= 1)) {\n+      continue; \/* no hyperthreading *\/\n+    } else if (flag == SEP_FLAG && (cpu_family() == CPU_FAMILY_PENTIUMPRO && ((_cpuid_info.std_cpuid1_eax.value & 0xff) < 0x33))) {\n+      continue; \/* no fast system call *\/\n+    }\n+    if ((_cpuid_info.std_cpuid1_edx.value & flag) && strlen(_feature_edx_id[fi]) > 0) {\n+      WRITE_TO_BUF(_feature_edx_id[fi]);\n+    }\n+  }\n+\n+  for (flag = 1, fi = 0; flag <= 0x20000000; flag <<= 1, fi++) {\n+    if ((_cpuid_info.std_cpuid1_ecx.value & flag) && strlen(_feature_ecx_id[fi]) > 0) {\n+      WRITE_TO_BUF(_feature_ecx_id[fi]);\n+    }\n+  }\n+\n+  for (flag = 1, fi = 0; flag <= 0x20000000 ; flag <<= 1, fi++) {\n+    if ((_cpuid_info.ext_cpuid1_ecx.value & flag) && strlen(_feature_extended_ecx_id[fi]) > 0) {\n+      WRITE_TO_BUF(_feature_extended_ecx_id[fi]);\n+    }\n+  }\n+\n+  for (flag = 1, fi = 0; flag <= 0x20000000; flag <<= 1, fi++) {\n+    if ((_cpuid_info.ext_cpuid1_edx.value & flag) && strlen(_feature_extended_edx_id[fi]) > 0) {\n+      WRITE_TO_BUF(_feature_extended_edx_id[fi]);\n+    }\n+  }\n+\n+  if (supports_tscinv_bit()) {\n+      WRITE_TO_BUF(\"Invariant TSC\");\n+  }\n+\n+  return written;\n+}\n+\n+\/**\n+ * Write a detailed description of the cpu to a given buffer, including\n+ * feature set.\n+ *\/\n+int VM_Version::cpu_detailed_description(char* const buf, size_t buf_len) {\n+  assert(buf != NULL, \"buffer is NULL!\");\n+  assert(buf_len >= CPU_DETAILED_DESC_BUF_SIZE, \"buffer len should at least be == CPU_DETAILED_DESC_BUF_SIZE!\");\n+\n+  static const char* unknown = \"<unknown>\";\n+  char               vendor_id[VENDOR_LENGTH];\n+  const char*        family = NULL;\n+  const char*        model = NULL;\n+  const char*        brand = NULL;\n+  int                outputLen = 0;\n+\n+  family = cpu_family_description();\n+  if (family == NULL) {\n+    family = unknown;\n+  }\n+\n+  model = cpu_model_description();\n+  if (model == NULL) {\n+    model = unknown;\n+  }\n+\n+  brand = cpu_brand_string();\n+\n+  if (brand == NULL) {\n+    brand = cpu_brand();\n+    if (brand == NULL) {\n+      brand = unknown;\n+    }\n+  }\n+\n+  *((uint32_t*) &vendor_id[0]) = _cpuid_info.std_vendor_name_0;\n+  *((uint32_t*) &vendor_id[4]) = _cpuid_info.std_vendor_name_2;\n+  *((uint32_t*) &vendor_id[8]) = _cpuid_info.std_vendor_name_1;\n+  vendor_id[VENDOR_LENGTH-1] = '\\0';\n+\n+  outputLen = jio_snprintf(buf, buf_len, \"Brand: %s, Vendor: %s\\n\"\n+    \"Family: %s (0x%x), Model: %s (0x%x), Stepping: 0x%x\\n\"\n+    \"Ext. family: 0x%x, Ext. model: 0x%x, Type: 0x%x, Signature: 0x%8.8x\\n\"\n+    \"Features: ebx: 0x%8.8x, ecx: 0x%8.8x, edx: 0x%8.8x\\n\"\n+    \"Ext. features: eax: 0x%8.8x, ebx: 0x%8.8x, ecx: 0x%8.8x, edx: 0x%8.8x\\n\"\n+    \"Supports: \",\n+    brand,\n+    vendor_id,\n+    family,\n+    extended_cpu_family(),\n+    model,\n+    extended_cpu_model(),\n+    cpu_stepping(),\n+    _cpuid_info.std_cpuid1_eax.bits.ext_family,\n+    _cpuid_info.std_cpuid1_eax.bits.ext_model,\n+    _cpuid_info.std_cpuid1_eax.bits.proc_type,\n+    _cpuid_info.std_cpuid1_eax.value,\n+    _cpuid_info.std_cpuid1_ebx.value,\n+    _cpuid_info.std_cpuid1_ecx.value,\n+    _cpuid_info.std_cpuid1_edx.value,\n+    _cpuid_info.ext_cpuid1_eax,\n+    _cpuid_info.ext_cpuid1_ebx,\n+    _cpuid_info.ext_cpuid1_ecx,\n+    _cpuid_info.ext_cpuid1_edx);\n+\n+  if (outputLen < 0 || (size_t) outputLen >= buf_len - 1) {\n+    if (buf_len > 0) { buf[buf_len-1] = '\\0'; }\n+    return OS_ERR;\n+  }\n+\n+  cpu_write_support_string(&buf[outputLen], buf_len - outputLen);\n+\n+  return OS_OK;\n+}\n+\n+\n+\/\/ Fill in Abstract_VM_Version statics\n+void VM_Version::initialize_cpu_information() {\n+  assert(_vm_version_initialized, \"should have initialized VM_Version long ago\");\n+  assert(!_initialized, \"shouldn't be initialized yet\");\n+  resolve_cpu_information_details();\n+\n+  \/\/ initialize cpu_name and cpu_desc\n+  cpu_type_description(_cpu_name, CPU_TYPE_DESC_BUF_SIZE);\n+  cpu_detailed_description(_cpu_desc, CPU_DETAILED_DESC_BUF_SIZE);\n+  _initialized = true;\n+}\n+\n+\/**\n+ *  For information about extracting the frequency from the cpu brand string, please see:\n+ *\n+ *    Intel Processor Identification and the CPUID Instruction\n+ *    Application Note 485\n+ *    May 2012\n+ *\n+ * The return value is the frequency in Hz.\n+ *\/\n+int64_t VM_Version::max_qualified_cpu_freq_from_brand_string(void) {\n+  const char* const brand_string = cpu_brand_string();\n+  if (brand_string == NULL) {\n+    return 0;\n+  }\n+  const int64_t MEGA = 1000000;\n+  int64_t multiplier = 0;\n+  int64_t frequency = 0;\n+  uint8_t idx = 0;\n+  \/\/ The brand string buffer is at most 48 bytes.\n+  \/\/ -2 is to prevent buffer overrun when looking for y in yHz, as z is +2 from y.\n+  for (; idx < 48-2; ++idx) {\n+    \/\/ Format is either \"x.xxyHz\" or \"xxxxyHz\", where y=M, G, T and x are digits.\n+    \/\/ Search brand string for \"yHz\" where y is M, G, or T.\n+    if (brand_string[idx+1] == 'H' && brand_string[idx+2] == 'z') {\n+      if (brand_string[idx] == 'M') {\n+        multiplier = MEGA;\n+      } else if (brand_string[idx] == 'G') {\n+        multiplier = MEGA * 1000;\n+      } else if (brand_string[idx] == 'T') {\n+        multiplier = MEGA * MEGA;\n+      }\n+      break;\n+    }\n+  }\n+  if (multiplier > 0) {\n+    \/\/ Compute freqency (in Hz) from brand string.\n+    if (brand_string[idx-3] == '.') { \/\/ if format is \"x.xx\"\n+      frequency =  (brand_string[idx-4] - '0') * multiplier;\n+      frequency += (brand_string[idx-2] - '0') * multiplier \/ 10;\n+      frequency += (brand_string[idx-1] - '0') * multiplier \/ 100;\n+    } else { \/\/ format is \"xxxx\"\n+      frequency =  (brand_string[idx-4] - '0') * 1000;\n+      frequency += (brand_string[idx-3] - '0') * 100;\n+      frequency += (brand_string[idx-2] - '0') * 10;\n+      frequency += (brand_string[idx-1] - '0');\n+      frequency *= multiplier;\n+    }\n+  }\n+  return frequency;\n+}\n+\n+\n+int64_t VM_Version::maximum_qualified_cpu_frequency(void) {\n+  if (_max_qualified_cpu_frequency == 0) {\n+    _max_qualified_cpu_frequency = max_qualified_cpu_freq_from_brand_string();\n+  }\n+  return _max_qualified_cpu_frequency;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":922,"deletions":0,"binary":false,"changes":922,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2011, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1385,0 +1385,2 @@\n+  static address vector_float_signflip() { return StubRoutines::x86::vector_float_sign_flip();}\n+  static address vector_double_signflip() { return StubRoutines::x86::vector_double_sign_flip();}\n@@ -1406,0 +1408,1 @@\n+    case Op_PopCountVL:\n@@ -1602,0 +1605,15 @@\n+    case Op_SqrtF:\n+      if (UseSSE < 1) {\n+        return false;\n+      }\n+      break;\n+    case Op_SqrtD:\n+#ifdef _LP64\n+      if (UseSSE < 2) {\n+        return false;\n+      }\n+#else\n+      \/\/ x86_32.ad has a special match rule for SqrtD.\n+      \/\/ Together with common x86 rules, this handles all UseSSE cases.\n+#endif\n+      break;\n@@ -1774,9 +1792,1 @@\n-      if (size_in_bits == 256 && UseAVX < 2) {\n-        return false; \/\/ Implementation limitation\n-      }\n-      break;\n-      if (is_integral_type(bt) && size_in_bits == 256 && UseAVX < 2) {\n-        return false;\n-      }\n-      break;\n-      if (is_integral_type(bt) && size_in_bits == 256 && UseAVX < 2) {\n+      if (bt != T_DOUBLE && size_in_bits == 256 && UseAVX < 2) {\n@@ -1795,5 +1805,2 @@\n-    case Op_VectorCastF2X:\n-      if (is_integral_type(bt)) {\n-        \/\/ Casts from FP to integral types require special fixup logic not easily\n-        \/\/ implementable with vectors.\n-        return false; \/\/ Implementation limitation\n+      if (is_subword_type(bt) || bt == T_INT) {\n+        return false;\n@@ -1802,0 +1809,9 @@\n+      if (bt == T_LONG && !VM_Version::supports_avx512dq()) {\n+        return false;\n+      }\n+      break;\n+    case Op_VectorCastF2X:\n+      if (is_subword_type(bt) || bt == T_LONG) {\n+        return false;\n+      }\n+      break;\n@@ -1822,1 +1838,1 @@\n-      if (!is_LP64 || !VM_Version::supports_evex()) {\n+      if (!VM_Version::supports_evex()) {\n@@ -1837,0 +1853,8 @@\n+    case Op_VectorLongToMask:\n+      if (UseAVX < 1 || !is_LP64) {\n+        return false;\n+      }\n+      if (UseAVX < 3 && !VM_Version::supports_bmi2()) {\n+        return false;\n+      }\n+      break;\n@@ -1873,0 +1897,6 @@\n+    case Op_MacroLogicV:\n+      if(bt != T_INT && bt != T_LONG) {\n+        return false;\n+      }\n+      return true;\n+\n@@ -2046,1 +2076,1 @@\n-const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+const TypeVectMask* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n@@ -2538,0 +2568,12 @@\n+static inline jlong high_bit_set(BasicType bt) {\n+  switch (bt) {\n+    case T_BYTE:  return 0x8080808080808080;\n+    case T_SHORT: return 0x8000800080008000;\n+    case T_INT:   return 0x8000000080000000;\n+    case T_LONG:  return 0x8000000000000000;\n+    default:\n+      ShouldNotReachHere();\n+      return 0;\n+  }\n+}\n+\n@@ -4579,1 +4621,2 @@\n-    __ insertps($dst$$XMMRegister, $val$$XMMRegister, $idx$$constant);\n+    uint x_idx = $idx$$constant & right_n_bits(2);\n+    __ insertps($dst$$XMMRegister, $val$$XMMRegister, x_idx << 4);\n@@ -4599,1 +4642,1 @@\n-      __ vinsertps($vtmp$$XMMRegister, $vtmp$$XMMRegister, $val$$XMMRegister, x_idx);\n+      __ vinsertps($vtmp$$XMMRegister, $vtmp$$XMMRegister, $val$$XMMRegister, x_idx << 4);\n@@ -4605,1 +4648,1 @@\n-      __ vinsertps($vtmp$$XMMRegister, $vtmp$$XMMRegister, $val$$XMMRegister, x_idx);\n+      __ vinsertps($vtmp$$XMMRegister, $vtmp$$XMMRegister, $val$$XMMRegister, x_idx << 4);\n@@ -6211,1 +6254,1 @@\n-  predicate(Matcher::vector_length(n) <= 8 && VectorNode::is_vshift_cnt(n->in(2)));\n+  predicate(Matcher::vector_length(n) <= 8 && !n->as_ShiftV()->is_var_shift());\n@@ -6231,1 +6274,1 @@\n-  predicate(Matcher::vector_length(n) == 16 && VectorNode::is_vshift_cnt(n->in(2)) &&\n+  predicate(Matcher::vector_length(n) == 16 && !n->as_ShiftV()->is_var_shift() &&\n@@ -6256,1 +6299,1 @@\n-  predicate(Matcher::vector_length(n) == 16 && VectorNode::is_vshift_cnt(n->in(2)) &&\n+  predicate(Matcher::vector_length(n) == 16 && !n->as_ShiftV()->is_var_shift() &&\n@@ -6277,1 +6320,1 @@\n-  predicate(Matcher::vector_length(n) == 32 && VectorNode::is_vshift_cnt(n->in(2)));\n+  predicate(Matcher::vector_length(n) == 32 && !n->as_ShiftV()->is_var_shift());\n@@ -6302,1 +6345,1 @@\n-  predicate(Matcher::vector_length(n) == 64 && VectorNode::is_vshift_cnt(n->in(2)));\n+  predicate(Matcher::vector_length(n) == 64 && !n->as_ShiftV()->is_var_shift());\n@@ -6335,1 +6378,1 @@\n-  predicate(VectorNode::is_vshift_cnt(n->in(2)));\n+  predicate(!n->as_ShiftV()->is_var_shift());\n@@ -6366,1 +6409,1 @@\n-  predicate(VectorNode::is_vshift_cnt(n->in(2)));\n+  predicate(!n->as_ShiftV()->is_var_shift());\n@@ -6420,1 +6463,1 @@\n-  predicate(VectorNode::is_vshift_cnt(n->in(2)));\n+  predicate(!n->as_ShiftV()->is_var_shift());\n@@ -6461,1 +6504,1 @@\n-  predicate(VectorNode::is_vshift_cnt(n->in(2)) && UseAVX <= 2);\n+  predicate(!n->as_ShiftV()->is_var_shift() && UseAVX <= 2);\n@@ -6490,1 +6533,1 @@\n-  predicate(VectorNode::is_vshift_cnt(n->in(2)) && UseAVX > 2);\n+  predicate(!n->as_ShiftV()->is_var_shift() && UseAVX > 2);\n@@ -6504,1 +6547,1 @@\n-            !VectorNode::is_vshift_cnt(n->in(2)) &&\n+            n->as_ShiftV()->is_var_shift() &&\n@@ -6524,1 +6567,1 @@\n-            !VectorNode::is_vshift_cnt(n->in(2)) &&\n+            n->as_ShiftV()->is_var_shift() &&\n@@ -6552,1 +6595,1 @@\n-            !VectorNode::is_vshift_cnt(n->in(2)) &&\n+            n->as_ShiftV()->is_var_shift() &&\n@@ -6588,1 +6631,1 @@\n-            !VectorNode::is_vshift_cnt(n->in(2)) &&\n+            n->as_ShiftV()->is_var_shift() &&\n@@ -6607,1 +6650,1 @@\n-            !VectorNode::is_vshift_cnt(n->in(2)) &&\n+            n->as_ShiftV()->is_var_shift() &&\n@@ -6631,1 +6674,1 @@\n-            !VectorNode::is_vshift_cnt(n->in(2)) &&\n+            n->as_ShiftV()->is_var_shift() &&\n@@ -6656,1 +6699,1 @@\n-            !VectorNode::is_vshift_cnt(n->in(2)) &&\n+            n->as_ShiftV()->is_var_shift() &&\n@@ -6691,1 +6734,1 @@\n-  predicate(!VectorNode::is_vshift_cnt(n->in(2)) &&\n+  predicate(n->as_ShiftV()->is_var_shift() &&\n@@ -6712,1 +6755,1 @@\n-  predicate(!VectorNode::is_vshift_cnt(n->in(2)));\n+  predicate(n->as_ShiftV()->is_var_shift());\n@@ -6729,1 +6772,1 @@\n-  predicate(!VectorNode::is_vshift_cnt(n->in(2)));\n+  predicate(n->as_ShiftV()->is_var_shift());\n@@ -6746,1 +6789,1 @@\n-            !VectorNode::is_vshift_cnt(n->in(2)) &&\n+            n->as_ShiftV()->is_var_shift() &&\n@@ -6761,1 +6804,1 @@\n-  predicate(!VectorNode::is_vshift_cnt(n->in(2)) &&\n+  predicate(n->as_ShiftV()->is_var_shift() &&\n@@ -6902,2 +6945,3 @@\n-      case T_DOUBLE:\n-        __ vpmovsxbd($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+      case T_DOUBLE: {\n+        int mid_vlen_enc = (vlen_enc == Assembler::AVX_512bit) ? Assembler::AVX_256bit : Assembler::AVX_128bit;\n+        __ vpmovsxbd($dst$$XMMRegister, $src$$XMMRegister, mid_vlen_enc);\n@@ -6906,1 +6950,1 @@\n-\n+      }\n@@ -6973,2 +7017,3 @@\n-      case T_DOUBLE:\n-        __ vpmovsxwd($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+      case T_DOUBLE: {\n+        int mid_vlen_enc = (vlen_enc == Assembler::AVX_512bit) ? Assembler::AVX_256bit : Assembler::AVX_128bit;\n+        __ vpmovsxwd($dst$$XMMRegister, $src$$XMMRegister, mid_vlen_enc);\n@@ -6977,0 +7022,1 @@\n+      }\n@@ -7172,1 +7218,1 @@\n-  format %{ \"vector_cast_f2x  $dst,$src\\t!\" %}\n+  format %{ \"vector_cast_f2d  $dst,$src\\t!\" %}\n@@ -7180,0 +7226,32 @@\n+instruct vcastFtoI_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rRegP scratch, rFlagsReg cr) %{\n+  predicate(!VM_Version::supports_avx512vl() &&\n+            Matcher::vector_length_in_bytes(n) < 64 &&\n+            Matcher::vector_element_basic_type(n) == T_INT);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4, TEMP scratch, KILL cr);\n+  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3 and $xtmp4 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_castF2I_avx($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                          $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $xtmp4$$XMMRegister,\n+                          ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcastFtoI_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n+  predicate((VM_Version::supports_avx512vl() ||\n+             Matcher::vector_length_in_bytes(n) == 64) &&\n+             Matcher::vector_element_basic_type(n) == T_INT);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, TEMP scratch, KILL cr);\n+  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1 and $ktmp2 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_castF2I_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                           $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister,\n+                           ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -7191,0 +7269,14 @@\n+instruct vcastDtoL_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, TEMP scratch, KILL cr);\n+  format %{ \"vector_cast_d2l $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1 and $ktmp2 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_castD2L_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                           $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister,\n+                           ExternalAddress(vector_double_signflip()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -7253,1 +7345,1 @@\n-instruct vcmp(legVec dst, legVec src1, legVec src2, immI8 cond, rRegP scratch) %{\n+instruct vcmp_direct(legVec dst, legVec src1, legVec src2, immI8 cond) %{\n@@ -7258,1 +7350,4 @@\n-            is_integral_type(Matcher::vector_element_basic_type(n->in(1)->in(1)))); \/\/ src1\n+            is_integral_type(Matcher::vector_element_basic_type(n->in(1)->in(1))) &&\n+            (n->in(2)->get_int() == BoolTest::eq ||\n+             n->in(2)->get_int() == BoolTest::lt ||\n+             n->in(2)->get_int() == BoolTest::gt)); \/\/ cond\n@@ -7260,2 +7355,1 @@\n-  effect(TEMP scratch);\n-  format %{ \"vector_compare $dst,$src1,$src2,$cond\\t! using $scratch as TEMP\" %}\n+  format %{ \"vector_compare $dst,$src1,$src2,$cond\\t!\" %}\n@@ -7266,1 +7360,1 @@\n-    __ vpcmpCCW($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, ww, vlen_enc, $scratch$$Register);\n+    __ vpcmpCCW($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, cmp, ww, vlen_enc);\n@@ -7271,1 +7365,1 @@\n-instruct vcmpu(legVec dst, legVec src1, legVec src2, immI8 cond, legVec vtmp1, legVec vtmp2, rRegP scratch) %{\n+instruct vcmp_negate(legVec dst, legVec src1, legVec src2, immI8 cond, legVec xtmp) %{\n@@ -7273,4 +7367,7 @@\n-            is_unsigned_booltest_pred(n->in(2)->get_int()) &&\n-            Matcher::vector_length_in_bytes(n->in(1)->in(1)) >=  8 && \/\/ src1\n-            Matcher::vector_length_in_bytes(n->in(1)->in(1)) <= 16 && \/\/ src1\n-            is_integral_type(Matcher::vector_element_basic_type(n->in(1)->in(1)))); \/\/ src1\n+            !is_unsigned_booltest_pred(n->in(2)->get_int()) &&\n+            Matcher::vector_length_in_bytes(n->in(1)->in(1)) >=  4 && \/\/ src1\n+            Matcher::vector_length_in_bytes(n->in(1)->in(1)) <= 32 && \/\/ src1\n+            is_integral_type(Matcher::vector_element_basic_type(n->in(1)->in(1))) &&\n+            (n->in(2)->get_int() == BoolTest::ne ||\n+             n->in(2)->get_int() == BoolTest::le ||\n+             n->in(2)->get_int() == BoolTest::ge)); \/\/ cond\n@@ -7278,2 +7375,2 @@\n-  effect(TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n-  format %{ \"vector_compareu $dst,$src1,$src2,$cond\\t! using $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp);\n+  format %{ \"vector_compare $dst,$src1,$src2,$cond\\t! using $xtmp as TEMP\" %}\n@@ -7281,1 +7378,1 @@\n-    int vlen = Matcher::vector_length_in_bytes(this, $src1);\n+    int vlen_enc = vector_length_encoding(this, $src1);\n@@ -7283,3 +7380,2 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src1);\n-    __ vpcmpu(bt, $dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen, $vtmp1$$XMMRegister,\n-              $vtmp2$$XMMRegister, $scratch$$Register);\n+    Assembler::Width ww = widthForType(Matcher::vector_element_basic_type(this, $src1));\n+    __ vpcmpCCW($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, $xtmp$$XMMRegister, cmp, ww, vlen_enc);\n@@ -7290,1 +7386,1 @@\n-instruct vcmpu32(legVec dst, legVec src1, legVec src2, immI8 cond, legVec vtmp1, legVec vtmp2, legVec vtmp3, rRegP scratch) %{\n+instruct vcmpu(legVec dst, legVec src1, legVec src2, immI8 cond, legVec xtmp) %{\n@@ -7293,1 +7389,2 @@\n-            Matcher::vector_length_in_bytes(n->in(1)->in(1)) == 32 && \/\/ src1\n+            Matcher::vector_length_in_bytes(n->in(1)->in(1)) >=  4 && \/\/ src1\n+            Matcher::vector_length_in_bytes(n->in(1)->in(1)) <= 32 && \/\/ src1\n@@ -7296,2 +7393,2 @@\n-  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP vtmp3, TEMP scratch);\n-  format %{ \"vector_compareu $dst,$src1,$src2,$cond\\t! using $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp);\n+  format %{ \"vector_compareu $dst,$src1,$src2,$cond\\t! using $xtmp as TEMP\" %}\n@@ -7299,1 +7396,2 @@\n-    int vlen = Matcher::vector_length_in_bytes(this, $src1);\n+    InternalAddress flip_bit = $constantaddress(high_bit_set(Matcher::vector_element_basic_type(this, $src1)));\n+    int vlen_enc = vector_length_encoding(this, $src1);\n@@ -7301,3 +7399,10 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src1);\n-    __ vpcmpu32(bt, $dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen, $vtmp1$$XMMRegister,\n-                $vtmp2$$XMMRegister, $vtmp3$$XMMRegister, $scratch$$Register);\n+    Assembler::Width ww = widthForType(Matcher::vector_element_basic_type(this, $src1));\n+\n+    if (vlen_enc == Assembler::AVX_128bit) {\n+      __ vmovddup($xtmp$$XMMRegister, flip_bit, vlen_enc, noreg);\n+    } else {\n+      __ vbroadcastsd($xtmp$$XMMRegister, flip_bit, vlen_enc, noreg);\n+    }\n+    __ vpxor($dst$$XMMRegister, $xtmp$$XMMRegister, $src1$$XMMRegister, vlen_enc);\n+    __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $src2$$XMMRegister, vlen_enc);\n+    __ vpcmpCCW($dst$$XMMRegister, $dst$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, cmp, ww, vlen_enc);\n@@ -7308,1 +7413,1 @@\n-instruct vcmpu64(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n+instruct vcmp64(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n@@ -8531,0 +8636,14 @@\n+instruct vpopcountL(vec dst, vec src) %{\n+  match(Set dst (PopCountVL src));\n+  format %{ \"vpopcntq  $dst,$src\\t! vector popcount packedL\" %}\n+  ins_encode %{\n+    assert(UsePopCountInstruction, \"not enabled\");\n+\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    __ vpopcntq($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    __ evpmovqd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -8662,1 +8781,1 @@\n-    int mask_len = Matcher::vector_length(this, $mask);\n+    int opcode = this->ideal_Opcode();\n@@ -8664,8 +8783,1 @@\n-    if (VM_Version::supports_avx512vlbw()) {\n-      __ kmovql($dst$$Register, $mask$$KRegister);\n-    } else {\n-      assert(mask_len <= 16, \"\");\n-      __ kmovwl($dst$$Register, $mask$$KRegister);\n-    }\n-    \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n-    \/\/ operations needs to be clipped.\n+    int mask_len = Matcher::vector_length(this, $mask);\n@@ -8673,3 +8785,3 @@\n-    if (mask_size < 16) {\n-      __ andq($dst$$Register, (((jlong)1 << mask_len) - 1));\n-    }\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister,\n+                             $dst$$Register, mask_len, mask_size, vlen_enc);\n@@ -8680,3 +8792,2 @@\n-instruct vmask_tolong_avx(rRegL dst, vec mask, vec xtmp, rFlagsReg cr) %{\n-  predicate(n->in(1)->bottom_type()->isa_vectmask() == NULL &&\n-            n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN);\n+instruct vmask_tolong_bool(rRegL dst, vec mask, vec xtmp, rFlagsReg cr) %{\n+  predicate(n->in(1)->bottom_type()->isa_vectmask() == NULL);\n@@ -8684,1 +8795,1 @@\n-  format %{ \"vector_tolong_avx $dst, $mask \\t! using $xtmp as TEMP\" %}\n+  format %{ \"vector_tolong_bool $dst, $mask \\t! using $xtmp as TEMP\" %}\n@@ -8687,0 +8798,2 @@\n+    int opcode = this->ideal_Opcode();\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8688,0 +8801,14 @@\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$XMMRegister, $xtmp$$XMMRegister,\n+                             $dst$$Register, mask_len, mbt, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmask_tolong_avx(rRegL dst, vec mask, immI size, vec xtmp, rFlagsReg cr) %{\n+  predicate(n->in(1)->in(1)->bottom_type()->isa_vectmask() == NULL);\n+  match(Set dst (VectorMaskToLong (VectorStoreMask mask size)));\n+  format %{ \"vector_tolong_avx $dst, $mask \\t! using $xtmp as TEMP\" %}\n+  effect(TEMP_DEF dst, TEMP xtmp, KILL cr);\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n@@ -8689,0 +8816,1 @@\n+    int mask_len = Matcher::vector_length(this, $mask);\n@@ -8690,9 +8818,2 @@\n-    __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n-    __ vpsubb($xtmp$$XMMRegister, $xtmp$$XMMRegister, $mask$$XMMRegister, vlen_enc);\n-    __ vpmovmskb($dst$$Register, $xtmp$$XMMRegister, vlen_enc);\n-    \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n-    \/\/ operations needs to be clipped.\n-    int mask_size = mask_len * type2aelembytes(mbt);\n-    if (mask_size < 16) {\n-      __ andq($dst$$Register, (((jlong)1 << mask_len) - 1));\n-    }\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$XMMRegister, $xtmp$$XMMRegister,\n+                             $dst$$Register, mask_len, mbt, vlen_enc);\n@@ -8714,2 +8835,2 @@\n-    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register,\n-                             mask_len, mask_size, vlen_enc);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister,\n+                             $tmp$$Register, mask_len, mask_size, vlen_enc);\n@@ -8720,1 +8841,1 @@\n-instruct vmask_truecount_avx(rRegI dst, vec mask, rRegL tmp, vec xtmp, vec xtmp1, rFlagsReg cr) %{\n+instruct vmask_truecount_bool(rRegI dst, vec mask, rRegL tmp, vec xtmp, rFlagsReg cr) %{\n@@ -8723,2 +8844,2 @@\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP xtmp, TEMP xtmp1, KILL cr);\n-  format %{ \"vector_truecount_avx $dst, $mask \\t! using $tmp, $xtmp and $xtmp1 as TEMP\" %}\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP xtmp, KILL cr);\n+  format %{ \"vector_truecount_bool $dst, $mask \\t! using $tmp, $xtmp as TEMP\" %}\n@@ -8729,1 +8850,0 @@\n-    int mask_size = mask_len * type2aelembytes(mbt);\n@@ -8732,1 +8852,17 @@\n-                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, mask_size, vlen_enc);\n+                             $tmp$$Register, mask_len, mbt, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmask_truecount_avx(rRegI dst, vec mask, immI size, rRegL tmp, vec xtmp, rFlagsReg cr) %{\n+  predicate(n->in(1)->in(1)->bottom_type()->isa_vectmask() == NULL);\n+  match(Set dst (VectorMaskTrueCount (VectorStoreMask mask size)));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP xtmp, KILL cr);\n+  format %{ \"vector_truecount_avx $dst, $mask \\t! using $tmp, $xtmp as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n+    int mask_len = Matcher::vector_length(this, $mask);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$XMMRegister, $xtmp$$XMMRegister,\n+                             $tmp$$Register, mask_len, mbt, vlen_enc);\n@@ -8749,2 +8885,2 @@\n-    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register, mask_len,\n-                             mask_size, vlen_enc);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister,\n+                             $tmp$$Register, mask_len, mask_size, vlen_enc);\n@@ -8755,1 +8891,1 @@\n-instruct vmask_first_or_last_true_avx(rRegI dst, vec mask, rRegL tmp, vec xtmp, vec xtmp1, rFlagsReg cr) %{\n+instruct vmask_first_or_last_true_bool(rRegI dst, vec mask, rRegL tmp, vec xtmp, rFlagsReg cr) %{\n@@ -8759,2 +8895,2 @@\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP xtmp, TEMP xtmp1, KILL cr);\n-  format %{ \"vector_mask_first_or_last_true_avx $dst, $mask \\t! using $tmp, $xtmp and $xtmp1 as TEMP\" %}\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP xtmp, KILL cr);\n+  format %{ \"vector_mask_first_or_last_true_bool $dst, $mask \\t! using $tmp, $xtmp as TEMP\" %}\n@@ -8765,1 +8901,0 @@\n-    int mask_size = mask_len * type2aelembytes(mbt);\n@@ -8768,1 +8903,18 @@\n-                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, mask_size, vlen_enc);\n+                             $tmp$$Register, mask_len, mbt, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmask_first_or_last_true_avx(rRegI dst, vec mask, immI size, rRegL tmp, vec xtmp, rFlagsReg cr) %{\n+  predicate(n->in(1)->in(1)->bottom_type()->isa_vectmask() == NULL);\n+  match(Set dst (VectorMaskFirstTrue (VectorStoreMask mask size)));\n+  match(Set dst (VectorMaskLastTrue (VectorStoreMask mask size)));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP xtmp, KILL cr);\n+  format %{ \"vector_mask_first_or_last_true_avx $dst, $mask \\t! using $tmp, $xtmp as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n+    int mask_len = Matcher::vector_length(this, $mask);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$XMMRegister, $xtmp$$XMMRegister,\n+                             $tmp$$Register, mask_len, mbt, vlen_enc);\n@@ -9048,0 +9200,1 @@\n+  predicate(!n->as_ShiftV()->is_var_shift());\n@@ -9056,2 +9209,17 @@\n-    bool is_varshift = !VectorNode::is_vshift_cnt_opcode(in(2)->isa_Mach()->ideal_Opcode());\n-                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, is_varshift);\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, false);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vlshiftv_reg_masked(vec dst, vec src2, kReg mask) %{\n+  predicate(n->as_ShiftV()->is_var_shift());\n+  match(Set dst (LShiftVS (Binary dst src2) mask));\n+  match(Set dst (LShiftVI (Binary dst src2) mask));\n+  match(Set dst (LShiftVL (Binary dst src2) mask));\n+  format %{ \"vplshiftv_masked $dst, $dst, $src2, $mask\\t! lshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, true);\n@@ -9094,0 +9262,1 @@\n+  predicate(!n->as_ShiftV()->is_var_shift());\n@@ -9102,2 +9271,17 @@\n-    bool is_varshift = !VectorNode::is_vshift_cnt_opcode(in(2)->isa_Mach()->ideal_Opcode());\n-                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, is_varshift);\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, false);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vrshiftv_reg_masked(vec dst, vec src2, kReg mask) %{\n+  predicate(n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVS (Binary dst src2) mask));\n+  match(Set dst (RShiftVI (Binary dst src2) mask));\n+  match(Set dst (RShiftVL (Binary dst src2) mask));\n+  format %{ \"vprshiftv_masked $dst, $dst, $src2, $mask\\t! rshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, true);\n@@ -9140,0 +9324,1 @@\n+  predicate(!n->as_ShiftV()->is_var_shift());\n@@ -9148,2 +9333,17 @@\n-    bool is_varshift = !VectorNode::is_vshift_cnt_opcode(in(2)->isa_Mach()->ideal_Opcode());\n-                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, is_varshift);\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, false);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vurshiftv_reg_masked(vec dst, vec src2, kReg mask) %{\n+  predicate(n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS (Binary dst src2) mask));\n+  match(Set dst (URShiftVI (Binary dst src2) mask));\n+  match(Set dst (URShiftVL (Binary dst src2) mask));\n+  format %{ \"vpurshiftv_masked $dst, $dst, $src2, $mask\\t! urshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, true);\n@@ -9331,22 +9531,2 @@\n-#ifdef _LP64\n-instruct mask_all_evexI_imm(kReg dst, immI cnt, rRegL tmp) %{\n-  match(Set dst (MaskAll cnt));\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"mask_all_evexI $dst, $cnt \\t! using $tmp as TEMP\" %}\n-  ins_encode %{\n-    int vec_len = Matcher::vector_length(this);\n-    if (VM_Version::supports_avx512bw()) {\n-      __ movq($tmp$$Register, $cnt$$constant);\n-      __ kmovql($dst$$KRegister, $tmp$$Register);\n-      __ kshiftrql($dst$$KRegister, $dst$$KRegister, 64 - vec_len);\n-    } else {\n-      assert(vec_len <= 16, \"\");\n-      __ movq($tmp$$Register, $cnt$$constant);\n-      __ kmovwl($dst$$KRegister, $tmp$$Register);\n-      __ kshiftrwl($dst$$KRegister, $dst$$KRegister, 16 - vec_len);\n-    }\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct mask_all_evexI(kReg dst, rRegI src, rRegL tmp) %{\n+instruct mask_all_evexI_LE32(kReg dst, rRegI src) %{\n+  predicate(Matcher::vector_length(n) <= 32);\n@@ -9354,2 +9534,1 @@\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"mask_all_evexI $dst, $src \\t! using $tmp as TEMP\" %}\n+  format %{ \"mask_all_evexI_LE32 $dst, $src \\t\" %}\n@@ -9357,28 +9536,2 @@\n-    int vec_len = Matcher::vector_length(this);\n-    if (VM_Version::supports_avx512bw()) {\n-      __ movslq($tmp$$Register, $src$$Register);\n-      __ kmovql($dst$$KRegister, $tmp$$Register);\n-      __ kshiftrql($dst$$KRegister, $dst$$KRegister, 64 - vec_len);\n-    } else {\n-      assert(vec_len <= 16, \"\");\n-      __ kmovwl($dst$$KRegister, $src$$Register);\n-      __ kshiftrwl($dst$$KRegister, $dst$$KRegister, 16 - vec_len);\n-    }\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct mask_all_evexL(kReg dst, rRegL src) %{\n-  match(Set dst (MaskAll src));\n-  effect(TEMP_DEF dst);\n-  format %{ \"mask_all_evexL $dst, $src \\t! mask all operation\" %}\n-  ins_encode %{\n-    int vec_len = Matcher::vector_length(this);\n-    if (VM_Version::supports_avx512bw()) {\n-      __ kmovql($dst$$KRegister, $src$$Register);\n-      __ kshiftrql($dst$$KRegister, $dst$$KRegister, 64 - vec_len);\n-    } else {\n-      assert(vec_len <= 16, \"\");\n-      __ kmovwl($dst$$KRegister, $src$$Register);\n-      __ kshiftrwl($dst$$KRegister, $dst$$KRegister, 16 - vec_len);\n-    }\n+    int mask_len = Matcher::vector_length(this);\n+    __ vector_maskall_operation($dst$$KRegister, $src$$Register, mask_len);\n@@ -9389,0 +9542,1 @@\n+#ifdef _LP64\n@@ -9413,0 +9567,40 @@\n+\n+instruct long_to_maskLE8_avx(vec dst, rRegL src, rRegL rtmp1, rRegL rtmp2, vec xtmp) %{\n+  predicate(n->bottom_type()->isa_vectmask() == NULL && Matcher::vector_length(n) <= 8);\n+  match(Set dst (VectorLongToMask src));\n+  effect(TEMP dst, TEMP rtmp1, TEMP rtmp2, TEMP xtmp);\n+  format %{ \"long_to_mask_avx $dst, $src\\t! using $rtmp1, $rtmp2, $xtmp as TEMP\" %}\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this);\n+    int vec_enc  = vector_length_encoding(mask_len);\n+    __ vector_long_to_maskvec($dst$$XMMRegister, $src$$Register, $rtmp1$$Register,\n+                              $rtmp2$$Register, xnoreg, mask_len, vec_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\n+instruct long_to_maskGT8_avx(vec dst, rRegL src, rRegL rtmp1, rRegL rtmp2, vec xtmp1, rFlagsReg cr) %{\n+  predicate(n->bottom_type()->isa_vectmask() == NULL && Matcher::vector_length(n) > 8);\n+  match(Set dst (VectorLongToMask src));\n+  effect(TEMP dst, TEMP rtmp1, TEMP rtmp2, TEMP xtmp1, KILL cr);\n+  format %{ \"long_to_mask_avx $dst, $src\\t! using $rtmp1, $rtmp2, $xtmp1, as TEMP\" %}\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this);\n+    assert(mask_len <= 32, \"invalid mask length\");\n+    int vec_enc  = vector_length_encoding(mask_len);\n+    __ vector_long_to_maskvec($dst$$XMMRegister, $src$$Register, $rtmp1$$Register,\n+                              $rtmp2$$Register, $xtmp1$$XMMRegister, mask_len, vec_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct long_to_mask_evex(kReg dst, rRegL src) %{\n+  predicate(n->bottom_type()->isa_vectmask());\n+  match(Set dst (VectorLongToMask src));\n+  format %{ \"long_to_mask_evex $dst, $src\\t!\" %}\n+  ins_encode %{\n+    __ kmov($dst$$KRegister, $src$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n@@ -9432,0 +9626,24 @@\n+instruct vternlog_reg_masked(vec dst, vec src2, vec src3, immU8 func, kReg mask) %{\n+  match(Set dst (MacroLogicV dst (Binary src2 (Binary src3 (Binary func mask)))));\n+  format %{ \"vternlog_masked $dst,$src2,$src3,$func,$mask\\t! vternlog masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ evpternlog($dst$$XMMRegister, $func$$constant, $mask$$KRegister,\n+                  $src2$$XMMRegister, $src3$$XMMRegister, true, bt, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vternlogd_mem_masked(vec dst, vec src2, memory src3, immU8 func, kReg mask) %{\n+  match(Set dst (MacroLogicV dst (Binary src2 (Binary src3 (Binary func mask)))));\n+  format %{ \"vternlog_masked $dst,$src2,$src3,$func,$mask\\t! vternlog masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ evpternlog($dst$$XMMRegister, $func$$constant, $mask$$KRegister,\n+                  $src2$$XMMRegister, $src3$$Address, true, bt, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":388,"deletions":170,"binary":false,"changes":558,"status":"modified"},{"patch":"@@ -755,0 +755,1 @@\n+  if (r->is_KRegister()) return rc_kreg;\n@@ -1249,20 +1250,0 @@\n-  assert( size > 0, \"missed a case\" );\n-\n-  \/\/ --------------------------------------------------------------------\n-  \/\/ Check for second bits still needing moving.\n-  if( src_second == dst_second )\n-    return size;               \/\/ Self copy; no move\n-  assert( src_second_rc != rc_bad && dst_second_rc != rc_bad, \"src_second & dst_second cannot be Bad\" );\n-\n-  \/\/ Check for second word int-int move\n-  if( src_second_rc == rc_int && dst_second_rc == rc_int )\n-    return impl_mov_helper(cbuf,do_size,src_second,dst_second,size, st);\n-\n-  \/\/ Check for second word integer store\n-  if( src_second_rc == rc_int && dst_second_rc == rc_stack )\n-    return impl_helper(cbuf,do_size,false,ra_->reg2offset(dst_second),src_second,0x89,\"MOV \",size, st);\n-\n-  \/\/ Check for second word integer load\n-  if( dst_second_rc == rc_int && src_second_rc == rc_stack )\n-    return impl_helper(cbuf,do_size,true ,ra_->reg2offset(src_second),dst_second,0x8B,\"MOV \",size, st);\n-\n@@ -1306,0 +1287,20 @@\n+  assert( size > 0, \"missed a case\" );\n+\n+  \/\/ --------------------------------------------------------------------\n+  \/\/ Check for second bits still needing moving.\n+  if( src_second == dst_second )\n+    return size;               \/\/ Self copy; no move\n+  assert( src_second_rc != rc_bad && dst_second_rc != rc_bad, \"src_second & dst_second cannot be Bad\" );\n+\n+  \/\/ Check for second word int-int move\n+  if( src_second_rc == rc_int && dst_second_rc == rc_int )\n+    return impl_mov_helper(cbuf,do_size,src_second,dst_second,size, st);\n+\n+  \/\/ Check for second word integer store\n+  if( src_second_rc == rc_int && dst_second_rc == rc_stack )\n+    return impl_helper(cbuf,do_size,false,ra_->reg2offset(dst_second),src_second,0x89,\"MOV \",size, st);\n+\n+  \/\/ Check for second word integer load\n+  if( dst_second_rc == rc_int && src_second_rc == rc_stack )\n+    return impl_helper(cbuf,do_size,true ,ra_->reg2offset(src_second),dst_second,0x8B,\"MOV \",size, st);\n+\n@@ -13129,0 +13130,18 @@\n+instruct cmovLL_reg_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, eRegL dst, eRegL src) %{\n+  match(Set dst (CMoveL (Binary cmp flags) (Binary dst src)));\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n+  ins_cost(400);\n+  expand %{\n+    cmovLL_reg_LTGE(cmp, flags, dst, src);\n+  %}\n+%}\n+\n+instruct cmovLL_mem_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, eRegL dst, load_long_memory src) %{\n+  match(Set dst (CMoveL (Binary cmp flags) (Binary dst (LoadL src))));\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n+  ins_cost(500);\n+  expand %{\n+    cmovLL_mem_LTGE(cmp, flags, dst, src);\n+  %}\n+%}\n+\n@@ -13179,0 +13198,10 @@\n+\/\/ Compare 2 unsigned longs and CMOVE ptrs.\n+instruct cmovPP_reg_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, eRegP dst, eRegP src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n+  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n+  ins_cost(200);\n+  expand %{\n+    cmovPP_reg_LTGE(cmp,flags,dst,src);\n+  %}\n+%}\n+\n@@ -13360,0 +13389,10 @@\n+\/\/ Compare 2 unsigned longs and CMOVE ptrs.\n+instruct cmovPP_reg_EQNE_U(cmpOpU cmp, flagsReg_ulong_EQNE flags, eRegP dst, eRegP src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n+  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n+  ins_cost(200);\n+  expand %{\n+    cmovPP_reg_EQNE(cmp,flags,dst,src);\n+  %}\n+%}\n+\n@@ -13569,0 +13608,10 @@\n+\/\/ Compare 2 unsigned longs and CMOVE ptrs.\n+instruct cmovPP_reg_LEGT_U(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, eRegP dst, eRegP src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n+  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n+  ins_cost(200);\n+  expand %{\n+    cmovPP_reg_LEGT(cmp,flags,dst,src);\n+  %}\n+%}\n+\n@@ -13798,0 +13847,22 @@\n+instruct mask_all_evexL_LT32(kReg dst, eRegL src) %{\n+  predicate(Matcher::vector_length(n) <= 32);\n+  match(Set dst (MaskAll src));\n+  format %{ \"mask_all_evexL_LE32 $dst, $src \\t\" %}\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this);\n+    __ vector_maskall_operation($dst$$KRegister, $src$$Register, mask_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct mask_all_evexL_GT32(kReg dst, eRegL src, kReg ktmp) %{\n+  predicate(Matcher::vector_length(n) > 32);\n+  match(Set dst (MaskAll src));\n+  effect(TEMP ktmp);\n+  format %{ \"mask_all_evexL_GT32 $dst, $src \\t! using $ktmp as TEMP \" %}\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this);\n+    __ vector_maskall_operation32($dst$$KRegister, $src$$Register, $ktmp$$KRegister, mask_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n@@ -13799,0 +13870,11 @@\n+instruct mask_all_evexI_GT32(kReg dst, rRegI src, kReg ktmp) %{\n+  predicate(Matcher::vector_length(n) > 32);\n+  match(Set dst (MaskAll src));\n+  effect(TEMP ktmp);\n+  format %{ \"mask_all_evexI_GT32 $dst, $src \\t! using $ktmp as TEMP\" %}\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this);\n+    __ vector_maskall_operation32($dst$$KRegister, $src$$Register, $ktmp$$KRegister, mask_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":102,"deletions":20,"binary":false,"changes":122,"status":"modified"},{"patch":"@@ -13254,0 +13254,23 @@\n+instruct mask_all_evexL(kReg dst, rRegL src) %{\n+  match(Set dst (MaskAll src));\n+  format %{ \"mask_all_evexL $dst, $src \\t! mask all operation\" %}\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this);\n+    __ vector_maskall_operation($dst$$KRegister, $src$$Register, mask_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct mask_all_evexI_GT32(kReg dst, rRegI src, rRegL tmp) %{\n+  predicate(Matcher::vector_length(n) > 32);\n+  match(Set dst (MaskAll src));\n+  effect(TEMP tmp);\n+  format %{ \"mask_all_evexI_GT32 $dst, $src \\t! using $tmp as TEMP\" %}\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this);\n+    __ movslq($tmp$$Register, $src$$Register);\n+    __ vector_maskall_operation($dst$$KRegister, $tmp$$Register, mask_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -4238,2 +4238,2 @@\n-    \"VectorMaskWrapper\", \"VectorMaskCmp\", \"VectorReinterpret\",\"LoadVectorMasked\",\"StoreVectorMasked\",\n-    \"FmaVD\", \"FmaVF\",\"PopCountVI\",\n+    \"VectorMaskWrapper\",\"VectorMaskCmp\",\"VectorReinterpret\",\"LoadVectorMasked\",\"StoreVectorMasked\",\n+    \"FmaVD\",\"FmaVF\",\"PopCountVI\", \"PopCountVL\", \"VectorLongToMask\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -711,1 +711,1 @@\n-  fileStream stream(fopen(\"c1_compile_only\", \"wt\"));\n+  fileStream stream(os::fopen(\"c1_compile_only\", \"wt\"));\n@@ -725,1 +725,1 @@\n-  fileStream stream(fopen(\".hotspot_compiler\", \"at\"));\n+  fileStream stream(os::fopen(\".hotspot_compiler\", \"at\"));\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,1 +46,1 @@\n-\/\/  slots and registers to their frame location\n+\/\/  slots and registers) to their frame location\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+  GrowableArray<BlockList> _bci2block_successors; \/\/ Mapping bcis to their blocks successors while we dont have a blockend\n@@ -94,0 +95,5 @@\n+  int number_of_successors(BlockBegin* block);\n+  BlockBegin* successor_at(BlockBegin* block, int i);\n+  void add_successor(BlockBegin* block, BlockBegin* sux);\n+  bool is_successor(BlockBegin* block, BlockBegin* sux);\n+\n@@ -110,0 +116,1 @@\n+ , _bci2block_successors(scope->method()->code_size())\n@@ -123,0 +130,2 @@\n+  \/\/ _bci2block still contains blocks with _end == null and > 0 sux in _bci2block_successors.\n+\n@@ -165,0 +174,1 @@\n+    _bci2block_successors.at_put_grow(cur_bci, BlockList());\n@@ -175,1 +185,1 @@\n-    predecessor->add_successor(block);\n+    add_successor(predecessor, block);\n@@ -206,2 +216,2 @@\n-      if (!current->is_successor(entry)) {\n-        current->add_successor(entry);\n+      if(!is_successor(current, entry)) {\n+        add_successor(current, entry);\n@@ -423,1 +433,1 @@\n-  for (int i = block->number_of_sux() - 1; i >= 0; i--) {\n+  for (int i = number_of_successors(block) - 1; i >= 0; i--) {\n@@ -425,1 +435,1 @@\n-    loop_state |= mark_loops(block->sux_at(i), in_subroutine);\n+    loop_state |= mark_loops(successor_at(block, i), in_subroutine);\n@@ -457,0 +467,22 @@\n+inline int BlockListBuilder::number_of_successors(BlockBegin* block)\n+{\n+  assert(_bci2block_successors.length() > block->bci(), \"sux must exist\");\n+  return _bci2block_successors.at(block->bci()).length();\n+}\n+\n+inline BlockBegin* BlockListBuilder::successor_at(BlockBegin* block, int i)\n+{\n+  assert(_bci2block_successors.length() > block->bci(), \"sux must exist\");\n+  return _bci2block_successors.at(block->bci()).at(i);\n+}\n+\n+inline void BlockListBuilder::add_successor(BlockBegin* block, BlockBegin* sux)\n+{\n+  assert(_bci2block_successors.length() > block->bci(), \"sux must exist\");\n+  _bci2block_successors.at(block->bci()).append(sux);\n+}\n+\n+inline bool BlockListBuilder::is_successor(BlockBegin* block, BlockBegin* sux) {\n+  assert(_bci2block_successors.length() > block->bci(), \"sux must exist\");\n+  return _bci2block_successors.at(block->bci()).contains(sux);\n+}\n@@ -482,1 +514,1 @@\n-    if (cur->number_of_sux() > 0) {\n+    if (number_of_successors(cur) > 0) {\n@@ -484,2 +516,2 @@\n-      for (int j = 0; j < cur->number_of_sux(); j++) {\n-        BlockBegin* sux = cur->sux_at(j);\n+      for (int j = 0; j < number_of_successors(cur); j++) {\n+        BlockBegin* sux = successor_at(cur, j);\n@@ -2221,12 +2253,0 @@\n-  \/\/ invoke-special-super\n-  if (bc_raw == Bytecodes::_invokespecial && !target->is_object_constructor()) {\n-    ciInstanceKlass* sender_klass = calling_klass;\n-    if (sender_klass->is_interface()) {\n-      int index = state()->stack_size() - (target->arg_size_no_receiver() + 1);\n-      Value receiver = state()->stack_at(index);\n-      CheckCast* c = new CheckCast(sender_klass, receiver, copy_state_before());\n-      c->set_invokespecial_receiver_check();\n-      state()->stack_at_put(index, append_split(c));\n-    }\n-  }\n-\n@@ -2237,0 +2257,7 @@\n+    case Bytecodes::_invokeinterface:\n+      \/\/ convert to invokespecial if the target is the private interface method.\n+      if (target->is_private()) {\n+        assert(holder->is_interface(), \"How did we get a non-interface method here!\");\n+        code = Bytecodes::_invokespecial;\n+      }\n+      break;\n@@ -2253,0 +2280,20 @@\n+  if (code == Bytecodes::_invokespecial) {\n+    \/\/ Additional receiver subtype checks for interface calls via invokespecial or invokeinterface.\n+    ciKlass* receiver_constraint = nullptr;\n+\n+    if (bc_raw == Bytecodes::_invokeinterface) {\n+      receiver_constraint = holder;\n+    } else if (bc_raw == Bytecodes::_invokespecial && !target->is_object_constructor() && calling_klass->is_interface()) {\n+      receiver_constraint = calling_klass;\n+    }\n+\n+    if (receiver_constraint != nullptr) {\n+      int index = state()->stack_size() - (target->arg_size_no_receiver() + 1);\n+      Value receiver = state()->stack_at(index);\n+      CheckCast* c = new CheckCast(receiver_constraint, receiver, copy_state_before());\n+      \/\/ go to uncommon_trap when checkcast fails\n+      c->set_invokespecial_receiver_check();\n+      state()->stack_at_put(index, append_split(c));\n+    }\n+  }\n+\n@@ -2345,4 +2392,2 @@\n-            \/\/ If CHA is able to bind this invoke then update the class\n-            \/\/ to match that class, otherwise klass will refer to the\n-            \/\/ interface.\n-            klass = cha_monomorphic_target->holder();\n+            ciInstanceKlass* holder = cha_monomorphic_target->holder();\n+            ciInstanceKlass* constraint = (holder->is_subtype_of(singleton) ? holder : singleton); \/\/ avoid upcasts\n@@ -2352,1 +2397,1 @@\n-            CheckCast* c = new CheckCast(klass, receiver, copy_state_for_exception());\n+            CheckCast* c = new CheckCast(constraint, receiver, copy_state_for_exception());\n@@ -2354,1 +2399,1 @@\n-            c->set_direct_compare(klass->is_final());\n+            c->set_direct_compare(constraint->is_final());\n@@ -2358,0 +2403,2 @@\n+\n+            dependency_recorder()->assert_unique_implementor(declared_interface, singleton);\n@@ -2381,1 +2428,3 @@\n-  if (!PatchALot && Inline && target->is_loaded() && callee_holder->is_linked() && !patch_for_appendix) {\n+  if (!PatchALot && Inline && target->is_loaded() && !patch_for_appendix &&\n+      callee_holder->is_loaded()) { \/\/ the effect of symbolic reference resolution\n+\n@@ -2383,1 +2432,1 @@\n-    if ((code == Bytecodes::_invokestatic && callee_holder->is_initialized()) || \/\/ invokestatic involves an initialization barrier on resolved klass\n+    if ((code == Bytecodes::_invokestatic && klass->is_initialized()) || \/\/ invokestatic involves an initialization barrier on declaring class\n@@ -3437,1 +3486,1 @@\n-  \/\/ necesary if std_entry is also a backward branch target because\n+  \/\/ necessary if std_entry is also a backward branch target because\n@@ -3611,0 +3660,2 @@\n+  \/\/ End nulls still exist here\n+\n@@ -3714,0 +3765,21 @@\n+# ifdef ASSERT\n+  \/\/All blocks reachable from start_block have _end != NULL\n+  {\n+    BlockList processed;\n+    BlockList to_go;\n+    to_go.append(start_block);\n+    while(to_go.length() > 0) {\n+      BlockBegin* current = to_go.pop();\n+      assert(current != NULL, \"Should not happen.\");\n+      assert(current->end() != NULL, \"All blocks reachable from start_block should have end() != NULL.\");\n+      processed.append(current);\n+      for(int i = 0; i < current->number_of_sux(); i++) {\n+        BlockBegin* s = current->sux_at(i);\n+        if (!processed.contains(s)) {\n+          to_go.append(s);\n+        }\n+      }\n+    }\n+  }\n+#endif \/\/ ASSERT\n+\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":101,"deletions":29,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -196,1 +196,2 @@\n-  , _deoptimize_on_exception(deoptimize_on_exception) {\n+  , _deoptimize_on_exception(deoptimize_on_exception)\n+  , _force_reexecute(false) {\n@@ -208,1 +209,2 @@\n-  , _deoptimize_on_exception(info->_deoptimize_on_exception) {\n+  , _deoptimize_on_exception(info->_deoptimize_on_exception)\n+  , _force_reexecute(info->_force_reexecute) {\n@@ -220,1 +222,2 @@\n-  _scope_debug_info->record_debug_info(recorder, pc_offset, true\/*topmost*\/, _is_method_handle_invoke, maybe_return_as_fields);\n+  bool reexecute = _force_reexecute || _scope_debug_info->should_reexecute();\n+  _scope_debug_info->record_debug_info(recorder, pc_offset, reexecute, _is_method_handle_invoke, maybe_return_as_fields);\n@@ -1265,0 +1268,1 @@\n+#endif \/\/ PRODUCT\n@@ -1266,0 +1270,19 @@\n+#ifdef ASSERT\n+class EndNotNullValidator : public BlockClosure {\n+ public:\n+  virtual void block_do(BlockBegin* block) {\n+    assert(block->end() != NULL, \"Expect block end to exist.\");\n+  }\n+};\n+\n+class XentryFlagValidator : public BlockClosure {\n+ public:\n+  virtual void block_do(BlockBegin* block) {\n+    for (int i = 0; i < block->end()->number_of_sux(); i++) {\n+      assert(!block->end()->sux_at(i)->is_set(BlockBegin::exception_entry_flag), \"must not be xhandler\");\n+    }\n+    for (int i = 0; i < block->number_of_exception_handlers(); i++) {\n+      assert(block->exception_handler_at(i)->is_set(BlockBegin::exception_entry_flag), \"must be xhandler\");\n+    }\n+  }\n+};\n@@ -1269,1 +1292,6 @@\n-class PredecessorValidator : public BlockClosure {\n+\/\/ Validation goals:\n+\/\/ - code() length == blocks length\n+\/\/ - code() contents == blocks content\n+\/\/ - Each block's computed predecessors match sux lists (length)\n+\/\/ - Each block's computed predecessors match sux lists (set content)\n+class PredecessorAndCodeValidator : public BlockClosure {\n@@ -1271,1 +1299,1 @@\n-  BlockListList* _predecessors;\n+  BlockListList* _predecessors; \/\/ Each index i will hold predecessors of block with id i\n@@ -1279,1 +1307,1 @@\n-  PredecessorValidator(IR* hir) {\n+  PredecessorAndCodeValidator(IR* hir) {\n@@ -1282,1 +1310,1 @@\n-    _blocks = new BlockList();\n+    _blocks = new BlockList(BlockBegin::number_of_blocks());\n@@ -1284,1 +1312,0 @@\n-    int i;\n@@ -1288,1 +1315,1 @@\n-      for (i = 0; i < _blocks->length(); i++) {\n+      for (int i = 0; i < _blocks->length(); i++) {\n@@ -1293,1 +1320,1 @@\n-    for (i = 0; i < _blocks->length(); i++) {\n+    for (int i = 0; i < _blocks->length(); i++) {\n@@ -1295,21 +1322,1 @@\n-      BlockList* preds = _predecessors->at(block->block_id());\n-      if (preds == NULL) {\n-        assert(block->number_of_preds() == 0, \"should be the same\");\n-        continue;\n-      }\n-\n-      \/\/ clone the pred list so we can mutate it\n-      BlockList* pred_copy = new BlockList();\n-      int j;\n-      for (j = 0; j < block->number_of_preds(); j++) {\n-        pred_copy->append(block->pred_at(j));\n-      }\n-      \/\/ sort them in the same order\n-      preds->sort(cmp);\n-      pred_copy->sort(cmp);\n-      int length = MIN2(preds->length(), block->number_of_preds());\n-      for (j = 0; j < block->number_of_preds(); j++) {\n-        assert(preds->at(j) == pred_copy->at(j), \"must match\");\n-      }\n-\n-      assert(preds->length() == block->number_of_preds(), \"should be the same\");\n+      verify_block_preds_against_collected_preds(block);\n@@ -1321,13 +1328,18 @@\n-    BlockEnd* be = block->end();\n-    int n = be->number_of_sux();\n-    int i;\n-    for (i = 0; i < n; i++) {\n-      BlockBegin* sux = be->sux_at(i);\n-      assert(!sux->is_set(BlockBegin::exception_entry_flag), \"must not be xhandler\");\n-\n-      BlockList* preds = _predecessors->at_grow(sux->block_id(), NULL);\n-      if (preds == NULL) {\n-        preds = new BlockList();\n-        _predecessors->at_put(sux->block_id(), preds);\n-      }\n-      preds->append(block);\n+    collect_predecessors(block);\n+  }\n+\n+ private:\n+  void collect_predecessors(BlockBegin* block) {\n+    for (int i = 0; i < block->end()->number_of_sux(); i++) {\n+      collect_predecessor(block, block->end()->sux_at(i));\n+    }\n+    for (int i = 0; i < block->number_of_exception_handlers(); i++) {\n+      collect_predecessor(block, block->exception_handler_at(i));\n+    }\n+  }\n+\n+  void collect_predecessor(BlockBegin* const pred, const BlockBegin* sux) {\n+    BlockList* preds = _predecessors->at_grow(sux->block_id(), NULL);\n+    if (preds == NULL) {\n+      preds = new BlockList();\n+      _predecessors->at_put(sux->block_id(), preds);\n@@ -1335,0 +1347,2 @@\n+    preds->append(pred);\n+  }\n@@ -1336,4 +1350,7 @@\n-    n = block->number_of_exception_handlers();\n-    for (i = 0; i < n; i++) {\n-      BlockBegin* sux = block->exception_handler_at(i);\n-      assert(sux->is_set(BlockBegin::exception_entry_flag), \"must be xhandler\");\n+  void verify_block_preds_against_collected_preds(const BlockBegin* block) const {\n+    BlockList* preds = _predecessors->at(block->block_id());\n+    if (preds == NULL) {\n+      assert(block->number_of_preds() == 0, \"should be the same\");\n+      return;\n+    }\n+    assert(preds->length() == block->number_of_preds(), \"should be the same\");\n@@ -1341,6 +1358,10 @@\n-      BlockList* preds = _predecessors->at_grow(sux->block_id(), NULL);\n-      if (preds == NULL) {\n-        preds = new BlockList();\n-        _predecessors->at_put(sux->block_id(), preds);\n-      }\n-      preds->append(block);\n+    \/\/ clone the pred list so we can mutate it\n+    BlockList* pred_copy = new BlockList();\n+    for (int j = 0; j < block->number_of_preds(); j++) {\n+      pred_copy->append(block->pred_at(j));\n+    }\n+    \/\/ sort them in the same order\n+    preds->sort(cmp);\n+    pred_copy->sort(cmp);\n+    for (int j = 0; j < block->number_of_preds(); j++) {\n+      assert(preds->at(j) == pred_copy->at(j), \"must match\");\n@@ -1352,4 +1373,2 @@\n-\n-\n-  virtual void block_do(BlockBegin *block) {\n-    for ( Instruction *cur = block; cur != NULL; cur = cur->next()) {\n+  virtual void block_do(BlockBegin* block) {\n+    for (Instruction* cur = block; cur != NULL; cur = cur->next()) {\n@@ -1362,3 +1381,53 @@\n-void IR::verify() {\n-#ifdef ASSERT\n-  PredecessorValidator pv(this);\n+class ValidateEdgeMutuality : public BlockClosure {\n+ public:\n+  virtual void block_do(BlockBegin* block) {\n+    for (int i = 0; i < block->end()->number_of_sux(); i++) {\n+      assert(block->end()->sux_at(i)->is_predecessor(block), \"Block's successor should have it as predecessor\");\n+    }\n+\n+    for (int i = 0; i < block->number_of_exception_handlers(); i++) {\n+      assert(block->exception_handler_at(i)->is_predecessor(block), \"Block's exception handler should have it as predecessor\");\n+    }\n+\n+    for (int i = 0; i < block->number_of_preds(); i++) {\n+      assert(block->pred_at(i) != NULL, \"Predecessor must exist\");\n+      assert(block->pred_at(i)->end() != NULL, \"Predecessor end must exist\");\n+      bool is_sux      = block->pred_at(i)->end()->is_sux(block);\n+      bool is_xhandler = block->pred_at(i)->is_exception_handler(block);\n+      assert(is_sux || is_xhandler, \"Block's predecessor should have it as successor or xhandler\");\n+    }\n+  }\n+};\n+\n+void IR::expand_with_neighborhood(BlockList& blocks) {\n+  int original_size = blocks.length();\n+  for (int h = 0; h < original_size; h++) {\n+    BlockBegin* block = blocks.at(h);\n+\n+    for (int i = 0; i < block->end()->number_of_sux(); i++) {\n+      if (!blocks.contains(block->end()->sux_at(i))) {\n+        blocks.append(block->end()->sux_at(i));\n+      }\n+    }\n+\n+    for (int i = 0; i < block->number_of_preds(); i++) {\n+      if (!blocks.contains(block->pred_at(i))) {\n+        blocks.append(block->pred_at(i));\n+      }\n+    }\n+\n+    for (int i = 0; i < block->number_of_exception_handlers(); i++) {\n+      if (!blocks.contains(block->exception_handler_at(i))) {\n+        blocks.append(block->exception_handler_at(i));\n+      }\n+    }\n+  }\n+}\n+\n+void IR::verify_local(BlockList& blocks) {\n+  EndNotNullValidator ennv;\n+  blocks.iterate_forward(&ennv);\n+\n+  ValidateEdgeMutuality vem;\n+  blocks.iterate_forward(&vem);\n+\n@@ -1366,2 +1435,1 @@\n-  this->iterate_postorder(&verifier);\n-#endif\n+  blocks.iterate_forward(&verifier);\n@@ -1370,1 +1438,16 @@\n-#endif \/\/ PRODUCT\n+void IR::verify() {\n+  XentryFlagValidator xe;\n+  iterate_postorder(&xe);\n+\n+  PredecessorAndCodeValidator pv(this);\n+\n+  EndNotNullValidator ennv;\n+  iterate_postorder(&ennv);\n+\n+  ValidateEdgeMutuality vem;\n+  iterate_postorder(&vem);\n+\n+  VerifyBlockBeginField verifier;\n+  iterate_postorder(&verifier);\n+}\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/c1\/c1_IR.cpp","additions":148,"deletions":65,"binary":false,"changes":213,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -238,1 +238,1 @@\n-  void record_debug_info(DebugInformationRecorder* recorder, int pc_offset, bool topmost, bool is_method_handle_invoke = false, bool maybe_return_as_fields = false) {\n+  void record_debug_info(DebugInformationRecorder* recorder, int pc_offset, bool reexecute, bool is_method_handle_invoke = false, bool maybe_return_as_fields = false) {\n@@ -241,1 +241,1 @@\n-      caller()->record_debug_info(recorder, pc_offset, false\/*topmost*\/);\n+      caller()->record_debug_info(recorder, pc_offset, false\/*reexecute*\/);\n@@ -247,1 +247,0 @@\n-    bool reexecute = topmost ? should_reexecute() : false;\n@@ -275,0 +274,1 @@\n+  bool              _force_reexecute;            \/\/ force the reexecute flag on, used for patching stub\n@@ -301,0 +301,3 @@\n+  bool     force_reexecute() const         { return _force_reexecute;             }\n+  void     set_force_reexecute()           { _force_reexecute = true;             }\n+\n@@ -302,0 +305,1 @@\n+\n@@ -349,1 +353,4 @@\n-  void verify()                                                               PRODUCT_RETURN;\n+\n+  void expand_with_neighborhood(BlockList& blocks)                          NOT_DEBUG_RETURN;\n+  void verify_local(BlockList&)                                             NOT_DEBUG_RETURN;\n+  void verify()                                                             NOT_DEBUG_RETURN;\n","filename":"src\/hotspot\/share\/c1\/c1_IR.hpp","additions":12,"deletions":5,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -660,9 +660,3 @@\n-void BlockBegin::set_end(BlockEnd* end) {\n-  assert(end != NULL, \"should not reset block end to NULL\");\n-  if (end == _end) {\n-    return;\n-  }\n-  clear_end();\n-\n-  \/\/ Set the new end\n-  _end = end;\n+void BlockBegin::set_end(BlockEnd* new_end) { \/\/ Assumes that no predecessor of new_end still has it as its successor\n+  assert(new_end != NULL, \"Should not reset block new_end to NULL\");\n+  if (new_end == _end) return;\n@@ -670,6 +664,5 @@\n-  _successors.clear();\n-  \/\/ Now reset successors list based on BlockEnd\n-  for (int i = 0; i < end->number_of_sux(); i++) {\n-    BlockBegin* sux = end->sux_at(i);\n-    _successors.append(sux);\n-    sux->_predecessors.append(this);\n+  \/\/ Remove this block as predecessor of its current successors\n+  if (_end != NULL) {\n+    for (int i = 0; i < number_of_sux(); i++) {\n+      sux_at(i)->remove_predecessor(this);\n+    }\n@@ -677,9 +670,1 @@\n-  _end->set_begin(this);\n-}\n-\n-void BlockBegin::clear_end() {\n-  \/\/ Must make the predecessors\/successors match up with the\n-  \/\/ BlockEnd's notion.\n-  if (_end != NULL) {\n-    \/\/ disconnect from the old end\n-    _end->set_begin(NULL);\n+  _end = new_end;\n@@ -688,5 +673,3 @@\n-    \/\/ disconnect this block from it's current successors\n-    for (int i = 0; i < _successors.length(); i++) {\n-      _successors.at(i)->remove_predecessor(this);\n-    }\n-    _end = NULL;\n+  \/\/ Add this block as predecessor of its new successors\n+  for (int i = 0; i < number_of_sux(); i++) {\n+    sux_at(i)->add_predecessor(this);\n@@ -711,1 +694,1 @@\n-      from->_successors.remove_at(s);\n+      from->end()->remove_sux_at(s);\n@@ -719,10 +702,0 @@\n-void BlockBegin::disconnect_from_graph() {\n-  \/\/ disconnect this block from all other blocks\n-  for (int p = 0; p < number_of_preds(); p++) {\n-    pred_at(p)->remove_successor(this);\n-  }\n-  for (int s = 0; s < number_of_sux(); s++) {\n-    sux_at(s)->remove_predecessor(this);\n-  }\n-}\n-\n@@ -805,8 +778,0 @@\n-void BlockBegin::remove_successor(BlockBegin* pred) {\n-  int idx;\n-  while ((idx = _successors.find(pred)) >= 0) {\n-    _successors.remove_at(idx);\n-  }\n-}\n-\n-\n@@ -973,0 +938,5 @@\n+\n+        if (existing_value != new_state->local_at(index) && existing_value->as_Phi() == NULL) {\n+          TRACE_PHI(tty->print_cr(\"required phi for local %d is missing, irreducible loop?\", index));\n+          return false; \/\/ BAILOUT in caller\n+        }\n@@ -1066,5 +1036,0 @@\n-void BlockList::blocks_do(void f(BlockBegin*)) {\n-  for (int i = length() - 1; i >= 0; i--) f(at(i));\n-}\n-\n-\n@@ -1093,15 +1058,0 @@\n-void BlockEnd::set_begin(BlockBegin* begin) {\n-  BlockList* sux = NULL;\n-  if (begin != NULL) {\n-    sux = begin->successors();\n-  } else if (this->begin() != NULL) {\n-    \/\/ copy our sux list\n-    BlockList* sux = new BlockList(this->begin()->number_of_sux());\n-    for (int i = 0; i < this->begin()->number_of_sux(); i++) {\n-      sux->append(this->begin()->sux_at(i));\n-    }\n-  }\n-  _sux = sux;\n-}\n-\n-\n@@ -1112,1 +1062,0 @@\n-\n","filename":"src\/hotspot\/share\/c1\/c1_Instruction.cpp","additions":18,"deletions":69,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -143,1 +143,0 @@\n-  void blocks_do(void f(BlockBegin*));\n@@ -1735,1 +1734,0 @@\n-  BlockList   _successors;                       \/\/ the successors of this block\n@@ -1789,1 +1787,0 @@\n-  , _successors(2)\n@@ -1816,1 +1813,0 @@\n-  BlockList* successors()                        { return &_successors; }\n@@ -1844,3 +1840,1 @@\n-  void set_end(BlockEnd* end);\n-  void clear_end();\n-  void disconnect_from_graph();\n+  void set_end(BlockEnd* new_end);\n@@ -1869,4 +1863,0 @@\n-  void add_successor(BlockBegin* sux);\n-  void remove_successor(BlockBegin* pred);\n-  bool is_successor(BlockBegin* sux) const       { return _successors.contains(sux); }\n-\n@@ -1932,0 +1922,1 @@\n+\n@@ -1965,1 +1956,2 @@\n-  void set_begin(BlockBegin* begin);\n+  inline void remove_sux_at(int i) { _sux->remove_at(i);}\n+  inline int find_sux(BlockBegin* sux) {return _sux->find(sux);}\n@@ -1970,0 +1962,1 @@\n+  bool is_sux(BlockBegin* sux) const             { return _sux == NULL ? false : _sux->contains(sux); }\n@@ -1971,2 +1964,0 @@\n-  BlockBegin** addr_sux_at(int i) const          { return _sux->adr_at(i); }\n-  int sux_index(BlockBegin* sux) const           { return _sux->find(sux); }\n@@ -2144,8 +2135,0 @@\n-  void swap_sux() {\n-    assert(number_of_sux() == 2, \"wrong number of successors\");\n-    BlockList* s = sux();\n-    BlockBegin* t = s->at(0); s->at_put(0, s->at(1)); s->at_put(1, t);\n-    _cond = negate(_cond);\n-    set_flag(UnorderedIsTrueFlag, !check_flag(UnorderedIsTrueFlag));\n-  }\n-\n@@ -2636,3 +2619,2 @@\n-inline int         BlockBegin::number_of_sux() const            { assert(_end == NULL || _end->number_of_sux() == _successors.length(), \"mismatch\"); return _successors.length(); }\n-inline BlockBegin* BlockBegin::sux_at(int i) const              { assert(_end == NULL || _end->sux_at(i) == _successors.at(i), \"mismatch\");          return _successors.at(i); }\n-inline void        BlockBegin::add_successor(BlockBegin* sux)   { assert(_end == NULL, \"Would create mismatch with successors of BlockEnd\");         _successors.append(sux); }\n+inline int         BlockBegin::number_of_sux() const            { assert(_end != NULL, \"need end\"); return _end->number_of_sux(); }\n+inline BlockBegin* BlockBegin::sux_at(int i) const              { assert(_end != NULL , \"need end\"); return _end->sux_at(i); }\n","filename":"src\/hotspot\/share\/c1\/c1_Instruction.hpp","additions":8,"deletions":26,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -630,8 +630,1 @@\n-  \/\/ print predecessors and successors\n-  if (x->successors()->length() > 0) {\n-    output()->print(\" sux:\");\n-    for (int i = 0; i < x->successors()->length(); i ++) {\n-      output()->print(\" B%d\", x->successors()->at(i)->block_id());\n-    }\n-  }\n-\n+  \/\/ print predecessors\n","filename":"src\/hotspot\/share\/c1\/c1_InstructionPrinter.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -137,1 +137,1 @@\n-      \/\/ FP return values can be also in CPU registers on ARM and PPC32 (softfp ABI)\n+      \/\/ FP return values can be also in CPU registers on ARM (softfp ABI)\n@@ -139,2 +139,1 @@\n-             ARM_ONLY(|| kindfield == cpu_register)\n-             PPC32_ONLY(|| kindfield == cpu_register) ) &&\n+             ARM_ONLY(|| kindfield == cpu_register) ) &&\n@@ -144,1 +143,1 @@\n-      \/\/ FP return values can be also in CPU registers on ARM and PPC32 (softfp ABI)\n+      \/\/ FP return values can be also in CPU registers on ARM (softfp ABI)\n@@ -146,2 +145,1 @@\n-             ARM_ONLY(|| kindfield == cpu_register)\n-             PPC32_ONLY(|| kindfield == cpu_register) ) &&\n+             ARM_ONLY(|| kindfield == cpu_register) ) &&\n@@ -537,4 +535,0 @@\n-#ifdef PPC32\n-      if (opConvert->_tmp1->is_valid())      do_temp(opConvert->_tmp1);\n-      if (opConvert->_tmp2->is_valid())      do_temp(opConvert->_tmp2);\n-#endif\n@@ -966,0 +960,13 @@\n+\/\/ LIR_OpLoadKlass\n+    case lir_load_klass:\n+    {\n+      LIR_OpLoadKlass* opLoadKlass = op->as_OpLoadKlass();\n+      assert(opLoadKlass != NULL, \"must be\");\n+\n+      do_input(opLoadKlass->_obj);\n+      do_output(opLoadKlass->_result);\n+      if (opLoadKlass->_info) do_info(opLoadKlass->_info);\n+      break;\n+    }\n+\n+\n@@ -1195,0 +1202,4 @@\n+void LIR_OpLoadKlass::emit_code(LIR_Assembler* masm) {\n+  masm->emit_load_klass(this);\n+}\n+\n@@ -1746,1 +1757,1 @@\n-  if (x->number_of_sux() > 0) {\n+  if (end != NULL && x->number_of_sux() > 0) {\n@@ -2043,6 +2054,0 @@\n-#ifdef PPC32\n-  if(tmp1()->is_valid()) {\n-    tmp1()->print(out); out->print(\" \");\n-    tmp2()->print(out); out->print(\" \");\n-  }\n-#endif\n@@ -2194,0 +2199,5 @@\n+void LIR_OpLoadKlass::print_instr(outputStream* out) const {\n+  obj()->print(out);        out->print(\" \");\n+  result_opr()->print(out); out->print(\" \");\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":27,"deletions":17,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -905,0 +905,1 @@\n+class    LIR_OpLoadKlass;\n@@ -951,0 +952,1 @@\n+      , lir_load_klass\n@@ -1173,0 +1175,1 @@\n+  virtual LIR_OpLoadKlass* as_OpLoadKlass() { return NULL; }\n@@ -1931,0 +1934,17 @@\n+class LIR_OpLoadKlass: public LIR_Op {\n+  friend class LIR_OpVisitState;\n+\n+ private:\n+  LIR_Opr _obj;\n+ public:\n+  LIR_OpLoadKlass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info)\n+    : LIR_Op(lir_load_klass, result, info)\n+    , _obj(obj)\n+    {}\n+\n+  LIR_Opr obj()        const { return _obj;  }\n+\n+  virtual LIR_OpLoadKlass* as_OpLoadKlass() { return this; }\n+  virtual void emit_code(LIR_Assembler* masm);\n+  void print_instr(outputStream* out) const PRODUCT_RETURN;\n+};\n@@ -2414,0 +2434,3 @@\n+\n+  void load_klass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info) { append(new LIR_OpLoadKlass(obj, result, info)); }\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+  info->set_force_reexecute();\n@@ -704,1 +705,1 @@\n-  _masm->verified_entry();\n+  _masm->verified_entry(compilation()->directive()->BreakAtExecuteOption);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -209,0 +209,1 @@\n+  void emit_load_klass(LIR_OpLoadKlass* op);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -628,1 +628,1 @@\n-  CodeStub* slow_path = new MonitorExitStub(lock, UseFastLocking, monitor_no);\n+  CodeStub* slow_path = new MonitorExitStub(lock, !UseHeavyMonitors, monitor_no);\n@@ -986,0 +986,8 @@\n+    if (phi->is_local()) {\n+      for (int i = 0; i < phi->operand_count(); i++) {\n+        Value op = phi->operand_at(i);\n+        if (op != NULL && op->type()->is_illegal()) {\n+          bailout(\"illegal phi operand\");\n+        }\n+      }\n+    }\n@@ -1254,0 +1262,4 @@\n+void LIRGenerator::load_klass(LIR_Opr obj, LIR_Opr klass, CodeEmitInfo* null_check_info) {\n+  __ load_klass(obj, klass, null_check_info);\n+}\n+\n@@ -1260,1 +1272,1 @@\n-  LIR_Opr temp = new_register(T_METADATA);\n+  LIR_Opr temp = new_register(T_ADDRESS);\n@@ -1269,4 +1281,3 @@\n-  \/\/ FIXME T_ADDRESS should actually be T_METADATA but it can't because the\n-  \/\/ meaning of these two is mixed up (see JDK-8026837).\n-  __ move(new LIR_Address(rcvr.result(), oopDesc::klass_offset_in_bytes(), T_ADDRESS), temp, info);\n-  __ move_wide(new LIR_Address(temp, in_bytes(Klass::java_mirror_offset()), T_ADDRESS), temp);\n+  LIR_Opr klass = new_register(T_METADATA);\n+  load_klass(rcvr.result(), klass, info);\n+  __ move_wide(new LIR_Address(klass, in_bytes(Klass::java_mirror_offset()), T_ADDRESS), temp);\n@@ -1345,1 +1356,1 @@\n-  __ move(new LIR_Address(value.result(), oopDesc::klass_offset_in_bytes(), T_ADDRESS), klass, NULL);\n+  load_klass(value.result(), klass, NULL);\n@@ -4134,1 +4145,1 @@\n-  __ move(new LIR_Address(array, oopDesc::klass_offset_in_bytes(), T_ADDRESS), klass, null_check_info);\n+  load_klass(array, klass, null_check_info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":19,"deletions":8,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -245,0 +245,2 @@\n+  void load_klass(LIR_Opr obj, LIR_Opr klass, CodeEmitInfo* null_check_info);\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2144,3 +2144,0 @@\n-#else\n-#if defined(PPC32)\n-        return LIR_OprFact::double_cpu(assigned_regHi, assigned_reg);\n@@ -2149,1 +2146,0 @@\n-#endif \/\/ PPC32\n@@ -2792,3 +2788,0 @@\n-#ifdef PPC32\n-      assert(opr->fpu_regnrLo() == opr->fpu_regnrHi(), \"assumed in calculation (only fpu_regnrHi is used)\");\n-#endif\n","filename":"src\/hotspot\/share\/c1\/c1_LinearScan.cpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -53,1 +53,2 @@\n-  void verified_entry();\n+  void verified_entry(bool breakAtEntry);\n+\n","filename":"src\/hotspot\/share\/c1\/c1_MacroAssembler.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -184,0 +184,19 @@\n+#ifdef ASSERT\n+#define DO_DELAYED_VERIFICATION\n+  \/*\n+   * We need to verify the internal representation after modifying it.\n+   * Verifying only the blocks that have been tampered with is cheaper than verifying the whole graph, but we must\n+   * capture blocks_to_verify_later before making the changes, since they might not be reachable afterwards.\n+   * DO_DELAYED_VERIFICATION ensures that the code for this is either enabled in full, or not at all.\n+   *\/\n+#endif \/\/ ASSERT\n+\n+#ifdef DO_DELAYED_VERIFICATION\n+  BlockList blocks_to_verify_later;\n+  blocks_to_verify_later.append(block);\n+  blocks_to_verify_later.append(t_block);\n+  blocks_to_verify_later.append(f_block);\n+  blocks_to_verify_later.append(sux);\n+  _hir->expand_with_neighborhood(blocks_to_verify_later);\n+#endif \/\/ DO_DELAYED_VERIFICATION\n+\n@@ -253,1 +272,4 @@\n-  _hir->verify();\n+#ifdef DO_DELAYED_VERIFICATION\n+  _hir->verify_local(blocks_to_verify_later);\n+#endif \/\/ DO_DELAYED_VERIFICATION\n+\n@@ -318,0 +340,14 @@\n+\/\/ This removes others' relation to block, but doesnt empty block's lists\n+void disconnect_from_graph(BlockBegin* block) {\n+  for (int p = 0; p < block->number_of_preds(); p++) {\n+    BlockBegin* pred = block->pred_at(p);\n+    int idx;\n+    while ((idx = pred->end()->find_sux(block)) >= 0) {\n+      pred->end()->remove_sux_at(idx);\n+    }\n+  }\n+  for (int s = 0; s < block->number_of_sux(); s++) {\n+    block->sux_at(s)->remove_predecessor(block);\n+  }\n+}\n+\n@@ -342,13 +378,14 @@\n-    if (end->as_Goto() != NULL) {\n-      assert(end->number_of_sux() == 1, \"end must have exactly one successor\");\n-      \/\/ Note: It would be sufficient to check for the number of successors (= 1)\n-      \/\/       in order to decide if this block can be merged potentially. That\n-      \/\/       would then also include switch statements w\/ only a default case.\n-      \/\/       However, in that case we would need to make sure the switch tag\n-      \/\/       expression is executed if it can produce observable side effects.\n-      \/\/       We should probably have the canonicalizer simplifying such switch\n-      \/\/       statements and then we are sure we don't miss these merge opportunities\n-      \/\/       here (was bug - gri 7\/7\/99).\n-      BlockBegin* sux = end->default_sux();\n-      if (sux->number_of_preds() == 1 && !sux->is_entry_block() && !end->is_safepoint()) {\n-        \/\/ merge the two blocks\n+    if (end->as_Goto() == NULL) return false;\n+\n+    assert(end->number_of_sux() == 1, \"end must have exactly one successor\");\n+    \/\/ Note: It would be sufficient to check for the number of successors (= 1)\n+    \/\/       in order to decide if this block can be merged potentially. That\n+    \/\/       would then also include switch statements w\/ only a default case.\n+    \/\/       However, in that case we would need to make sure the switch tag\n+    \/\/       expression is executed if it can produce observable side effects.\n+    \/\/       We should probably have the canonicalizer simplifying such switch\n+    \/\/       statements and then we are sure we don't miss these merge opportunities\n+    \/\/       here (was bug - gri 7\/7\/99).\n+    BlockBegin* sux = end->default_sux();\n+    if (sux->number_of_preds() != 1 || sux->is_entry_block() || end->is_safepoint()) return false;\n+    \/\/ merge the two blocks\n@@ -357,20 +394,20 @@\n-        \/\/ verify that state at the end of block and at the beginning of sux are equal\n-        \/\/ no phi functions must be present at beginning of sux\n-        ValueStack* sux_state = sux->state();\n-        ValueStack* end_state = end->state();\n-\n-        assert(end_state->scope() == sux_state->scope(), \"scopes must match\");\n-        assert(end_state->stack_size() == sux_state->stack_size(), \"stack not equal\");\n-        assert(end_state->locals_size() == sux_state->locals_size(), \"locals not equal\");\n-\n-        int index;\n-        Value sux_value;\n-        for_each_stack_value(sux_state, index, sux_value) {\n-          assert(sux_value == end_state->stack_at(index), \"stack not equal\");\n-        }\n-        for_each_local_value(sux_state, index, sux_value) {\n-          Phi* sux_phi = sux_value->as_Phi();\n-          if (sux_phi != NULL && sux_phi->is_illegal()) continue;\n-          assert(sux_value == end_state->local_at(index), \"locals not equal\");\n-        }\n-        assert(sux_state->caller_state() == end_state->caller_state(), \"caller not equal\");\n+    \/\/ verify that state at the end of block and at the beginning of sux are equal\n+    \/\/ no phi functions must be present at beginning of sux\n+    ValueStack* sux_state = sux->state();\n+    ValueStack* end_state = end->state();\n+\n+    assert(end_state->scope() == sux_state->scope(), \"scopes must match\");\n+    assert(end_state->stack_size() == sux_state->stack_size(), \"stack not equal\");\n+    assert(end_state->locals_size() == sux_state->locals_size(), \"locals not equal\");\n+\n+    int index;\n+    Value sux_value;\n+    for_each_stack_value(sux_state, index, sux_value) {\n+      assert(sux_value == end_state->stack_at(index), \"stack not equal\");\n+    }\n+    for_each_local_value(sux_state, index, sux_value) {\n+      Phi* sux_phi = sux_value->as_Phi();\n+      if (sux_phi != NULL && sux_phi->is_illegal()) continue;\n+        assert(sux_value == end_state->local_at(index), \"locals not equal\");\n+      }\n+    assert(sux_state->caller_state() == end_state->caller_state(), \"caller not equal\");\n@@ -379,20 +416,25 @@\n-        \/\/ find instruction before end & append first instruction of sux block\n-        Instruction* prev = end->prev();\n-        Instruction* next = sux->next();\n-        assert(prev->as_BlockEnd() == NULL, \"must not be a BlockEnd\");\n-        prev->set_next(next);\n-        prev->fixup_block_pointers();\n-        sux->disconnect_from_graph();\n-        block->set_end(sux->end());\n-        \/\/ add exception handlers of deleted block, if any\n-        for (int k = 0; k < sux->number_of_exception_handlers(); k++) {\n-          BlockBegin* xhandler = sux->exception_handler_at(k);\n-          block->add_exception_handler(xhandler);\n-\n-          \/\/ also substitute predecessor of exception handler\n-          assert(xhandler->is_predecessor(sux), \"missing predecessor\");\n-          xhandler->remove_predecessor(sux);\n-          if (!xhandler->is_predecessor(block)) {\n-            xhandler->add_predecessor(block);\n-          }\n-        }\n+#ifdef DO_DELAYED_VERIFICATION\n+    BlockList blocks_to_verify_later;\n+    blocks_to_verify_later.append(block);\n+    _hir->expand_with_neighborhood(blocks_to_verify_later);\n+#endif \/\/ DO_DELAYED_VERIFICATION\n+\n+    \/\/ find instruction before end & append first instruction of sux block\n+    Instruction* prev = end->prev();\n+    Instruction* next = sux->next();\n+    assert(prev->as_BlockEnd() == NULL, \"must not be a BlockEnd\");\n+    prev->set_next(next);\n+    prev->fixup_block_pointers();\n+\n+    \/\/ disconnect this block from all other blocks\n+    disconnect_from_graph(sux);\n+#ifdef DO_DELAYED_VERIFICATION\n+    blocks_to_verify_later.remove(sux); \/\/ Sux is not part of graph anymore\n+#endif \/\/ DO_DELAYED_VERIFICATION\n+    block->set_end(sux->end());\n+\n+    \/\/ TODO Should this be done in set_end universally?\n+    \/\/ add exception handlers of deleted block, if any\n+    for (int k = 0; k < sux->number_of_exception_handlers(); k++) {\n+      BlockBegin* xhandler = sux->exception_handler_at(k);\n+      block->add_exception_handler(xhandler);\n@@ -400,6 +442,15 @@\n-        \/\/ debugging output\n-        _merge_count++;\n-        if (PrintBlockElimination) {\n-          tty->print_cr(\"%d. merged B%d & B%d (stack size = %d)\",\n-                        _merge_count, block->block_id(), sux->block_id(), sux->state()->stack_size());\n-        }\n+      \/\/ TODO This should be in disconnect from graph...\n+      \/\/ also substitute predecessor of exception handler\n+      assert(xhandler->is_predecessor(sux), \"missing predecessor\");\n+      xhandler->remove_predecessor(sux);\n+      if (!xhandler->is_predecessor(block)) {\n+        xhandler->add_predecessor(block);\n+      }\n+    }\n+\n+    \/\/ debugging output\n+    _merge_count++;\n+    if (PrintBlockElimination) {\n+      tty->print_cr(\"%d. merged B%d & B%d (stack size = %d)\",\n+                    _merge_count, block->block_id(), sux->block_id(), sux->state()->stack_size());\n+    }\n@@ -407,11 +458,25 @@\n-        _hir->verify();\n-\n-        If* if_ = block->end()->as_If();\n-        if (if_) {\n-          IfOp* ifop    = if_->x()->as_IfOp();\n-          Constant* con = if_->y()->as_Constant();\n-          bool swapped = false;\n-          if (!con || !ifop) {\n-            ifop = if_->y()->as_IfOp();\n-            con  = if_->x()->as_Constant();\n-            swapped = true;\n+#ifdef DO_DELAYED_VERIFICATION\n+    _hir->verify_local(blocks_to_verify_later);\n+#endif \/\/ DO_DELAYED_VERIFICATION\n+\n+    If* if_ = block->end()->as_If();\n+    if (if_) {\n+      IfOp* ifop    = if_->x()->as_IfOp();\n+      Constant* con = if_->y()->as_Constant();\n+      bool swapped = false;\n+      if (!con || !ifop) {\n+        ifop = if_->y()->as_IfOp();\n+        con  = if_->x()->as_Constant();\n+        swapped = true;\n+      }\n+      if (con && ifop && !ifop->substitutability_check()) {\n+        Constant* tval = ifop->tval()->as_Constant();\n+        Constant* fval = ifop->fval()->as_Constant();\n+        if (tval && fval) {\n+          \/\/ Find the instruction before if_, starting with ifop.\n+          \/\/ When if_ and ifop are not in the same block, prev\n+          \/\/ becomes NULL In such (rare) cases it is not\n+          \/\/ profitable to perform the optimization.\n+          Value prev = ifop;\n+          while (prev != NULL && prev->next() != if_) {\n+            prev = prev->next();\n@@ -419,39 +484,23 @@\n-          if (con && ifop && !ifop->substitutability_check()) {\n-            Constant* tval = ifop->tval()->as_Constant();\n-            Constant* fval = ifop->fval()->as_Constant();\n-            if (tval && fval) {\n-              \/\/ Find the instruction before if_, starting with ifop.\n-              \/\/ When if_ and ifop are not in the same block, prev\n-              \/\/ becomes NULL In such (rare) cases it is not\n-              \/\/ profitable to perform the optimization.\n-              Value prev = ifop;\n-              while (prev != NULL && prev->next() != if_) {\n-                prev = prev->next();\n-              }\n-              if (prev != NULL) {\n-                Instruction::Condition cond = if_->cond();\n-                BlockBegin* tsux = if_->tsux();\n-                BlockBegin* fsux = if_->fsux();\n-                if (swapped) {\n-                  cond = Instruction::mirror(cond);\n-                }\n-\n-                BlockBegin* tblock = tval->compare(cond, con, tsux, fsux);\n-                BlockBegin* fblock = fval->compare(cond, con, tsux, fsux);\n-                if (tblock != fblock && !if_->is_safepoint()) {\n-                  If* newif = new If(ifop->x(), ifop->cond(), false, ifop->y(),\n-                                     tblock, fblock, if_->state_before(), if_->is_safepoint(), ifop->substitutability_check());\n-                  newif->set_state(if_->state()->copy());\n-\n-                  assert(prev->next() == if_, \"must be guaranteed by above search\");\n-                  NOT_PRODUCT(newif->set_printable_bci(if_->printable_bci()));\n-                  prev->set_next(newif);\n-                  block->set_end(newif);\n-\n-                  _merge_count++;\n-                  if (PrintBlockElimination) {\n-                    tty->print_cr(\"%d. replaced If and IfOp at end of B%d with single If\", _merge_count, block->block_id());\n-                  }\n-\n-                  _hir->verify();\n-                }\n+          if (prev != NULL) {\n+            Instruction::Condition cond = if_->cond();\n+            BlockBegin* tsux = if_->tsux();\n+            BlockBegin* fsux = if_->fsux();\n+            if (swapped) {\n+              cond = Instruction::mirror(cond);\n+            }\n+\n+            BlockBegin* tblock = tval->compare(cond, con, tsux, fsux);\n+            BlockBegin* fblock = fval->compare(cond, con, tsux, fsux);\n+            if (tblock != fblock && !if_->is_safepoint()) {\n+              If* newif = new If(ifop->x(), ifop->cond(), false, ifop->y(),\n+                                 tblock, fblock, if_->state_before(), if_->is_safepoint(), ifop->substitutability_check());\n+              newif->set_state(if_->state()->copy());\n+\n+              assert(prev->next() == if_, \"must be guaranteed by above search\");\n+              NOT_PRODUCT(newif->set_printable_bci(if_->printable_bci()));\n+              prev->set_next(newif);\n+              block->set_end(newif);\n+\n+              _merge_count++;\n+              if (PrintBlockElimination) {\n+                tty->print_cr(\"%d. replaced If and IfOp at end of B%d with single If\", _merge_count, block->block_id());\n@@ -460,0 +509,4 @@\n+\n+#ifdef DO_DELAYED_VERIFICATION\n+              _hir->verify_local(blocks_to_verify_later);\n+#endif \/\/ DO_DELAYED_VERIFICATION\n@@ -463,2 +516,0 @@\n-\n-        return true;\n@@ -467,1 +518,2 @@\n-    return false;\n+\n+    return true;\n@@ -471,4 +523,1 @@\n-    _hir->verify();\n-    while (try_merge(block)) {\n-      _hir->verify();\n-    }\n+    while (try_merge(block)) ;\n@@ -479,0 +528,3 @@\n+#ifdef ASSERT\n+#undef DO_DELAYED_VERIFICATION\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/c1\/c1_Optimizer.cpp","additions":170,"deletions":118,"binary":false,"changes":288,"status":"modified"},{"patch":"@@ -255,3 +255,0 @@\n-#if defined(PPC32)\n-  case handle_exception_nofpu_id:\n-#endif\n@@ -871,1 +868,1 @@\n-  if (!UseFastLocking) {\n+  if (UseHeavyMonitors) {\n@@ -1321,34 +1318,0 @@\n-#if defined(PPC32)\n-        if (load_klass_or_mirror_patch_id ||\n-            stub_id == Runtime1::load_appendix_patching_id) {\n-          \/\/ Update the location in the nmethod with the proper\n-          \/\/ metadata.  When the code was generated, a NULL was stuffed\n-          \/\/ in the metadata table and that table needs to be update to\n-          \/\/ have the right value.  On intel the value is kept\n-          \/\/ directly in the instruction instead of in the metadata\n-          \/\/ table, so set_data above effectively updated the value.\n-          nmethod* nm = CodeCache::find_nmethod(instr_pc);\n-          assert(nm != NULL, \"invalid nmethod_pc\");\n-          RelocIterator mds(nm, copy_buff, copy_buff + 1);\n-          bool found = false;\n-          while (mds.next() && !found) {\n-            if (mds.type() == relocInfo::oop_type) {\n-              assert(stub_id == Runtime1::load_mirror_patching_id ||\n-                     stub_id == Runtime1::load_appendix_patching_id, \"wrong stub id\");\n-              oop_Relocation* r = mds.oop_reloc();\n-              oop* oop_adr = r->oop_addr();\n-              *oop_adr = stub_id == Runtime1::load_mirror_patching_id ? mirror() : appendix();\n-              r->fix_oop_relocation();\n-              found = true;\n-            } else if (mds.type() == relocInfo::metadata_type) {\n-              assert(stub_id == Runtime1::load_klass_patching_id, \"wrong stub id\");\n-              metadata_Relocation* r = mds.metadata_reloc();\n-              Metadata** metadata_adr = r->metadata_addr();\n-              *metadata_adr = load_klass;\n-              r->fix_metadata_relocation();\n-              found = true;\n-            }\n-          }\n-          assert(found, \"the metadata must exist!\");\n-        }\n-#endif\n@@ -1412,7 +1375,0 @@\n-#ifdef PPC32\n-          { address instr_pc2 = instr_pc + NativeMovConstReg::lo_offset;\n-            RelocIterator iter2(nm, instr_pc2, instr_pc2 + 1);\n-            relocInfo::change_reloc_info_for_address(&iter2, (address) instr_pc2,\n-                                                     relocInfo::none, rtype);\n-          }\n-#endif\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":1,"deletions":45,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,1 +31,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -508,1 +508,1 @@\n-  \/\/ method parameters are not linked in instructions list, so process them separateley\n+  \/\/ method parameters are not linked in instructions list, so process them separately\n","filename":"src\/hotspot\/share\/c1\/c1_ValueMap.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -119,1 +119,0 @@\n-  void kill_exception();\n","filename":"src\/hotspot\/share\/c1\/c1_ValueMap.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -245,3 +245,0 @@\n-  develop(bool, UseFastLocking, true,                                       \\\n-          \"Use fast inlined locking code\")                                  \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/c1\/c1_globals.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -320,1 +320,1 @@\n-    guarantee(offset <= MAX_SHARED_DELTA, \"must be 32-bit offset\");\n+    guarantee(offset <= MAX_SHARED_DELTA, \"must be 32-bit offset \" INTPTR_FORMAT, offset);\n@@ -327,1 +327,1 @@\n-    guarantee(offset <= MAX_SHARED_DELTA, \"must be 32-bit offset\");\n+    guarantee(offset <= MAX_SHARED_DELTA, \"must be 32-bit offset \" INTPTR_FORMAT, offset);\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -67,1 +67,1 @@\n-    _file = os::open(fd, \"r\");\n+    _file = os::fdopen(fd, \"r\");\n","filename":"src\/hotspot\/share\/cds\/classListParser.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -124,1 +124,0 @@\n-        ResourceMark rm;\n@@ -235,1 +234,1 @@\n-FileMapInfo::FileMapInfo(bool is_static) {\n+FileMapInfo::FileMapInfo(const char* full_path, bool is_static) {\n@@ -237,0 +236,1 @@\n+  _full_path = full_path;\n@@ -257,0 +257,3 @@\n+  if (_file_open) {\n+    ::close(_fd);\n+  }\n@@ -310,2 +313,7 @@\n-    _heap_begin = CompressedOops::begin();\n-    _heap_end = CompressedOops::end();\n+    if (UseCompressedOops) {\n+      _heap_begin = CompressedOops::begin();\n+      _heap_end = CompressedOops::end();\n+    } else {\n+      _heap_begin = (address)G1CollectedHeap::heap()->reserved().start();\n+      _heap_end = (address)G1CollectedHeap::heap()->reserved().end();\n+    }\n@@ -343,1 +351,0 @@\n-    CDS_JAVA_HEAP_ONLY(_heap_obj_roots = CompressedOops::encode(HeapShared::roots());)\n@@ -383,0 +390,1 @@\n+  st->print_cr(\"- heap_begin:                     \" INTPTR_FORMAT, p2i(_heap_begin));\n@@ -835,0 +843,15 @@\n+\/\/ Returns true if a path within the paths exists and has non-zero size.\n+bool FileMapInfo::check_paths_existence(const char* paths) {\n+  ClasspathStream cp_stream(paths);\n+  bool exist = false;\n+  struct stat st;\n+  while (cp_stream.has_next()) {\n+    const char* path = cp_stream.get_next();\n+    if (os::stat(path, &st) == 0 && st.st_size > 0) {\n+      exist = true;\n+      break;\n+    }\n+  }\n+  return exist;\n+}\n+\n@@ -918,1 +941,6 @@\n-      mismatch = true;\n+      ResourceMark rm;\n+      if (check_paths_existence(rp)) {\n+        \/\/ If a path exists in the runtime boot paths, it is considered a mismatch\n+        \/\/ since there's no boot path specified during dump time.\n+        mismatch = true;\n+      }\n@@ -1112,1 +1140,6 @@\n-\/\/ a utility class for checking file header\n+\/\/ A utility class for reading\/validating the GenericCDSFileMapHeader portion of\n+\/\/ a CDS archive's header. The file header of all CDS archives with versions from\n+\/\/ CDS_GENERIC_HEADER_SUPPORTED_MIN_VERSION (12) are guaranteed to always start\n+\/\/ with GenericCDSFileMapHeader. This makes it possible to read important information\n+\/\/ from a CDS archive created by a different version of HotSpot, so that we can\n+\/\/ automatically regenerate the archive as necessary (JDK-8261455).\n@@ -1115,1 +1148,5 @@\n-  GenericCDSFileMapHeader _header;\n+  bool _is_valid;\n+  bool _is_static;\n+  GenericCDSFileMapHeader* _header;\n+  const char* _archive_name;\n+  const char* _base_archive_name;\n@@ -1118,1 +1155,1 @@\n-  FileHeaderHelper() {\n+  FileHeaderHelper(const char* archive_name, bool is_static) {\n@@ -1120,0 +1157,5 @@\n+    _is_valid = false;\n+    _header = nullptr;\n+    _base_archive_name = nullptr;\n+    _archive_name = archive_name;\n+    _is_static = is_static;\n@@ -1124,1 +1166,1 @@\n-      os::close(_fd);\n+      ::close(_fd);\n@@ -1128,2 +1170,3 @@\n-  bool initialize(const char* archive_name) {\n-    _fd = os::open(archive_name, O_RDONLY | O_BINARY, 0);\n+  bool initialize() {\n+    assert(_archive_name != nullptr, \"Archive name is NULL\");\n+    _fd = os::open(_archive_name, O_RDONLY | O_BINARY, 0);\n@@ -1131,0 +1174,1 @@\n+      FileMapInfo::fail_continue(\"Specified shared archive not found (%s)\", _archive_name);\n@@ -1138,1 +1182,4 @@\n-    assert(fd != -1, \"Archive should be opened\");\n+    assert(_archive_name != nullptr, \"Archive name is NULL\");\n+    assert(fd != -1, \"Archive must be opened already\");\n+    \/\/ First read the generic header so we know the exact size of the actual header.\n+    GenericCDSFileMapHeader gen_header;\n@@ -1140,2 +1187,2 @@\n-    lseek(fd, 0, SEEK_SET);\n-    size_t n = os::read(fd, (void*)&_header, (unsigned int)size);\n+    os::lseek(fd, 0, SEEK_SET);\n+    size_t n = ::read(fd, (void*)&gen_header, (unsigned int)size);\n@@ -1143,1 +1190,1 @@\n-      vm_exit_during_initialization(\"Unable to read generic CDS file map header from shared archive\");\n+      FileMapInfo::fail_continue(\"Unable to read generic CDS file map header from shared archive\");\n@@ -1146,22 +1193,4 @@\n-    return true;\n-  }\n-  GenericCDSFileMapHeader* get_generic_file_header() {\n-    return &_header;\n-  }\n-\n-  char* read_base_archive_name() {\n-    assert(_fd != -1, \"Archive should be open\");\n-    size_t name_size = _header._base_archive_name_size;\n-    assert(name_size != 0, \"For non-default base archive, name size should be non-zero!\");\n-    char* base_name = NEW_C_HEAP_ARRAY(char, name_size, mtInternal);\n-    lseek(_fd, _header._base_archive_name_offset, SEEK_SET); \/\/ position to correct offset.\n-    size_t n = os::read(_fd, base_name, (unsigned int)name_size);\n-    if (n != name_size) {\n-      log_info(cds)(\"Unable to read base archive name from archive\");\n-      FREE_C_HEAP_ARRAY(char, base_name);\n-      return nullptr;\n-    }\n-    if (base_name[name_size - 1] != '\\0' || strlen(base_name) != name_size - 1) {\n-      log_info(cds)(\"Base archive name is damaged\");\n-      FREE_C_HEAP_ARRAY(char, base_name);\n-      return nullptr;\n+    if (gen_header._magic != CDS_ARCHIVE_MAGIC &&\n+        gen_header._magic != CDS_DYNAMIC_ARCHIVE_MAGIC) {\n+      FileMapInfo::fail_continue(\"The shared archive file has a bad magic number: %#x\", gen_header._magic);\n+      return false;\n@@ -1170,4 +1199,5 @@\n-    if (!os::file_exists(base_name)) {\n-      log_info(cds)(\"Base archive %s does not exist\", base_name);\n-      FREE_C_HEAP_ARRAY(char, base_name);\n-      return nullptr;\n+\n+    if (gen_header._version < CDS_GENERIC_HEADER_SUPPORTED_MIN_VERSION) {\n+      FileMapInfo::fail_continue(\"Cannot handle shared archive file version %d. Must be at least %d\",\n+                                 gen_header._version, CDS_GENERIC_HEADER_SUPPORTED_MIN_VERSION);\n+      return false;\n@@ -1175,11 +1205,4 @@\n-    return base_name;\n-  }\n-};\n-bool FileMapInfo::check_archive(const char* archive_name, bool is_static) {\n-  FileHeaderHelper file_helper;\n-  if (!file_helper.initialize(archive_name)) {\n-    \/\/ do not vm_exit_during_initialization here because Arguments::init_shared_archive_paths()\n-    \/\/ requires a shared archive name. The open_for_read() function will log a message regarding\n-    \/\/ failure in opening a shared archive.\n-    return false;\n-  }\n+    if (gen_header._version !=  CURRENT_CDS_ARCHIVE_VERSION) {\n+      FileMapInfo::fail_continue(\"The shared archive file version %d does not match the required version %d\",\n+                                    gen_header._version, CURRENT_CDS_ARCHIVE_VERSION);\n+    }\n@@ -1188,4 +1211,3 @@\n-  GenericCDSFileMapHeader* header = file_helper.get_generic_file_header();\n-  if (is_static) {\n-    if (header->_magic != CDS_ARCHIVE_MAGIC) {\n-      vm_exit_during_initialization(\"Not a base shared archive\", archive_name);\n+    size_t filelen = os::lseek(fd, 0, SEEK_END);\n+    if (gen_header._header_size >= filelen) {\n+      FileMapInfo::fail_continue(\"Archive file header larger than archive file\");\n@@ -1194,3 +1216,8 @@\n-    if (header->_base_archive_name_offset != 0) {\n-      log_info(cds)(\"_base_archive_name_offset should be 0\");\n-      log_info(cds)(\"_base_archive_name_offset = \" UINT32_FORMAT, header->_base_archive_name_offset);\n+\n+    \/\/ Read the actual header and perform more checks\n+    size = gen_header._header_size;\n+    _header = (GenericCDSFileMapHeader*)NEW_C_HEAP_ARRAY(char, size, mtInternal);\n+    os::lseek(fd, 0, SEEK_SET);\n+    n = ::read(fd, (void*)_header, (unsigned int)size);\n+    if (n != size) {\n+      FileMapInfo::fail_continue(\"Unable to read actual CDS file map header from shared archive\");\n@@ -1199,3 +1226,2 @@\n-  } else {\n-    if (header->_magic != CDS_DYNAMIC_ARCHIVE_MAGIC) {\n-      vm_exit_during_initialization(\"Not a top shared archive\", archive_name);\n+\n+    if (!check_crc()) {\n@@ -1204,8 +1230,2 @@\n-    unsigned int name_size = header->_base_archive_name_size;\n-    unsigned int name_offset = header->_base_archive_name_offset;\n-    unsigned int header_size = header->_header_size;\n-    if (name_offset + name_size != header_size) {\n-      log_info(cds)(\"_header_size should be equal to _base_archive_name_offset plus _base_archive_name_size\");\n-      log_info(cds)(\"  _base_archive_name_size   = \" UINT32_FORMAT, name_size);\n-      log_info(cds)(\"  _base_archive_name_offset = \" UINT32_FORMAT, name_offset);\n-      log_info(cds)(\"  _header_size              = \" UINT32_FORMAT, header_size);\n+\n+    if (!check_and_init_base_archive_name()) {\n@@ -1214,2 +1234,39 @@\n-    char* base_name = file_helper.read_base_archive_name();\n-    if (base_name == nullptr) {\n+\n+    \/\/ All fields in the GenericCDSFileMapHeader has been validated.\n+    _is_valid = true;\n+    return true;\n+  }\n+\n+  GenericCDSFileMapHeader* get_generic_file_header() {\n+    assert(_header != nullptr && _is_valid, \"must be a valid archive file\");\n+    return _header;\n+  }\n+\n+  const char* base_archive_name() {\n+    assert(_header != nullptr && _is_valid, \"must be a valid archive file\");\n+    return _base_archive_name;\n+  }\n+\n+ private:\n+  bool check_crc() {\n+    if (VerifySharedSpaces) {\n+      FileMapHeader* header = (FileMapHeader*)_header;\n+      int actual_crc = header->compute_crc();\n+      if (actual_crc != header->crc()) {\n+        log_info(cds)(\"_crc expected: %d\", header->crc());\n+        log_info(cds)(\"       actual: %d\", actual_crc);\n+        FileMapInfo::fail_continue(\"Header checksum verification failed.\");\n+        return false;\n+      }\n+    }\n+    return true;\n+  }\n+\n+  bool check_and_init_base_archive_name() {\n+    unsigned int name_offset = _header->_base_archive_name_offset;\n+    unsigned int name_size   = _header->_base_archive_name_size;\n+    unsigned int header_size = _header->_header_size;\n+\n+    if (name_offset + name_size < name_offset) {\n+      FileMapInfo::fail_continue(\"base_archive_name offset\/size overflow: \" UINT32_FORMAT \"\/\" UINT32_FORMAT,\n+                                 name_offset, name_size);\n@@ -1218,1 +1275,38 @@\n-    FREE_C_HEAP_ARRAY(char, base_name);\n+    if (_header->_magic == CDS_ARCHIVE_MAGIC) {\n+      if (name_offset != 0) {\n+        FileMapInfo::fail_continue(\"static shared archive must have zero _base_archive_name_offset\");\n+        return false;\n+      }\n+      if (name_size != 0) {\n+        FileMapInfo::fail_continue(\"static shared archive must have zero _base_archive_name_size\");\n+        return false;\n+      }\n+    } else {\n+      assert(_header->_magic == CDS_DYNAMIC_ARCHIVE_MAGIC, \"must be\");\n+      if ((name_size == 0 && name_offset != 0) ||\n+          (name_size != 0 && name_offset == 0)) {\n+        \/\/ If either is zero, both must be zero. This indicates that we are using the default base archive.\n+        FileMapInfo::fail_continue(\"Invalid base_archive_name offset\/size: \" UINT32_FORMAT \"\/\" UINT32_FORMAT,\n+                                   name_offset, name_size);\n+        return false;\n+      }\n+      if (name_size > 0) {\n+        if (name_offset + name_size > header_size) {\n+          FileMapInfo::fail_continue(\"Invalid base_archive_name offset\/size (out of range): \"\n+                                     UINT32_FORMAT \" + \" UINT32_FORMAT \" > \" UINT32_FORMAT ,\n+                                     name_offset, name_size, header_size);\n+          return false;\n+        }\n+        const char* name = ((const char*)_header) + _header->_base_archive_name_offset;\n+        if (name[name_size - 1] != '\\0' || strlen(name) != name_size - 1) {\n+          FileMapInfo::fail_continue(\"Base archive name is damaged\");\n+          return false;\n+        }\n+        if (!os::file_exists(name)) {\n+          FileMapInfo::fail_continue(\"Base archive %s does not exist\", name);\n+          return false;\n+        }\n+        _base_archive_name = name;\n+      }\n+    }\n+    return true;\n@@ -1220,2 +1314,1 @@\n-  return true;\n-}\n+};\n@@ -1223,0 +1316,7 @@\n+\/\/ Return value:\n+\/\/ false:\n+\/\/      <archive_name> is not a valid archive. *base_archive_name is set to null.\n+\/\/ true && (*base_archive_name) == NULL:\n+\/\/      <archive_name> is a valid static archive.\n+\/\/ true && (*base_archive_name) != NULL:\n+\/\/      <archive_name> is a valid dynamic archive.\n@@ -1225,2 +1325,4 @@\n-  FileHeaderHelper file_helper;\n-  if (!file_helper.initialize(archive_name)) {\n+  FileHeaderHelper file_helper(archive_name, false);\n+  *base_archive_name = NULL;\n+\n+  if (!file_helper.initialize()) {\n@@ -1231,2 +1333,5 @@\n-    \/\/ Not a dynamic header, no need to proceed further.\n-    return false;\n+    assert(header->_magic == CDS_ARCHIVE_MAGIC, \"must be\");\n+    if (AutoCreateSharedArchive) {\n+     log_warning(cds)(\"AutoCreateSharedArchive is ignored because %s is a static archive\", archive_name);\n+    }\n+    return true;\n@@ -1235,7 +1340,2 @@\n-  if ((header->_base_archive_name_size == 0 && header->_base_archive_name_offset != 0) ||\n-      (header->_base_archive_name_size != 0 && header->_base_archive_name_offset == 0)) {\n-    fail_continue(\"Default base archive not set correct\");\n-    return false;\n-  }\n-  if (header->_base_archive_name_size == 0 &&\n-      header->_base_archive_name_offset == 0) {\n+  const char* base = file_helper.base_archive_name();\n+  if (base == nullptr) {\n@@ -1244,5 +1344,1 @@\n-    \/\/ read the base archive name\n-    *base_archive_name = file_helper.read_base_archive_name();\n-    if (*base_archive_name == nullptr) {\n-      return false;\n-    }\n+    *base_archive_name = os::strdup_check_oom(base);\n@@ -1250,0 +1346,1 @@\n+\n@@ -1256,1 +1353,1 @@\n-  FileHeaderHelper file_helper;\n+  FileHeaderHelper file_helper(_full_path, _is_static);\n@@ -1263,6 +1360,10 @@\n-  unsigned int expected_magic = is_static() ? CDS_ARCHIVE_MAGIC : CDS_DYNAMIC_ARCHIVE_MAGIC;\n-  if (gen_header->_magic != expected_magic) {\n-    log_info(cds)(\"_magic expected: 0x%08x\", expected_magic);\n-    log_info(cds)(\"         actual: 0x%08x\", gen_header->_magic);\n-    FileMapInfo::fail_continue(\"The shared archive file has a bad magic number.\");\n-    return false;\n+  if (_is_static) {\n+    if (gen_header->_magic != CDS_ARCHIVE_MAGIC) {\n+      FileMapInfo::fail_continue(\"Not a base shared archive: %s\", _full_path);\n+      return false;\n+    }\n+  } else {\n+    if (gen_header->_magic != CDS_DYNAMIC_ARCHIVE_MAGIC) {\n+      FileMapInfo::fail_continue(\"Not a top shared archive: %s\", _full_path);\n+      return false;\n+    }\n@@ -1272,1 +1373,1 @@\n-  lseek(fd, 0, SEEK_SET); \/\/ reset to begin of the archive\n+  os::lseek(fd, 0, SEEK_SET); \/\/ reset to begin of the archive\n@@ -1274,1 +1375,1 @@\n-  size_t n = os::read(fd, (void*)_header, (unsigned int)size);\n+  size_t n = ::read(fd, (void*)_header, (unsigned int)size);\n@@ -1317,10 +1418,0 @@\n-  if (VerifySharedSpaces) {\n-    int expected_crc = header()->compute_crc();\n-    if (expected_crc != header()->crc()) {\n-      log_info(cds)(\"_crc expected: %d\", expected_crc);\n-      log_info(cds)(\"       actual: %d\", header()->crc());\n-      FileMapInfo::fail_continue(\"Header checksum verification failed.\");\n-      return false;\n-    }\n-  }\n-\n@@ -1332,1 +1423,1 @@\n-    size_t len = lseek(fd, 0, SEEK_END);\n+    size_t len = os::lseek(fd, 0, SEEK_END);\n@@ -1349,1 +1440,1 @@\n-  if (lseek(_fd, (long)pos, SEEK_SET) < 0) {\n+  if (os::lseek(_fd, (long)pos, SEEK_SET) < 0) {\n@@ -1359,5 +1450,0 @@\n-  if (is_static()) {\n-    _full_path = Arguments::GetSharedArchivePath();\n-  } else {\n-    _full_path = Arguments::GetSharedDynamicArchivePath();\n-  }\n@@ -1368,1 +1454,1 @@\n-      fail_continue(\"Specified shared archive not found (%s).\", _full_path);\n+      fail_continue(\"Specified shared archive not found (%s)\", _full_path);\n@@ -1370,1 +1456,1 @@\n-      fail_continue(\"Failed to open shared archive file (%s).\",\n+      fail_continue(\"Failed to open shared archive file (%s)\",\n@@ -1385,6 +1471,1 @@\n-void FileMapInfo::open_for_write(const char* path) {\n-  if (path == NULL) {\n-    _full_path = Arguments::GetSharedArchivePath();\n-  } else {\n-    _full_path = path;\n-  }\n+void FileMapInfo::open_for_write() {\n@@ -1490,1 +1571,5 @@\n-    mapping_offset = (size_t)CompressedOops::encode_not_null(cast_to_oop(base));\n+    if (UseCompressedOops) {\n+      mapping_offset = (size_t)CompressedOops::encode_not_null(cast_to_oop(base));\n+    } else {\n+      mapping_offset = requested_base - (char*)G1CollectedHeap::heap()->reserved().start();\n+    }\n@@ -1624,2 +1709,2 @@\n-  size_t n = os::write(_fd, buffer, (unsigned int)nbytes);\n-  if (n != nbytes) {\n+  ssize_t n = os::write(_fd, buffer, (unsigned int)nbytes);\n+  if (n < 0 || (size_t)n != nbytes) {\n@@ -1760,1 +1845,1 @@\n-  if (lseek(_fd, (long)si->file_offset(), SEEK_SET) != (int)si->file_offset() ||\n+  if (os::lseek(_fd, (long)si->file_offset(), SEEK_SET) != (int)si->file_offset() ||\n@@ -1797,1 +1882,1 @@\n-    \/\/ can't mmap into a ReservedSpace, so we just os::read() the data. We're going to patch all the\n+    \/\/ can't mmap into a ReservedSpace, so we just ::read() the data. We're going to patch all the\n@@ -1903,1 +1988,1 @@\n-  size_t n = os::read(_fd, buffer, (unsigned int)count);\n+  size_t n = ::read(_fd, buffer, (unsigned int)count);\n@@ -2012,1 +2097,4 @@\n-                p2i(CompressedOops::begin()), p2i(CompressedOops::end()));\n+                UseCompressedOops ? p2i(CompressedOops::begin()) :\n+                                    UseG1GC ? p2i((address)G1CollectedHeap::heap()->reserved().start()) : 0L,\n+                UseCompressedOops ? p2i(CompressedOops::end()) :\n+                                    UseG1GC ? p2i((address)G1CollectedHeap::heap()->reserved().end()) : 0L);\n@@ -2022,0 +2110,20 @@\n+\/\/ The address where the bottom of this shared heap region should be mapped\n+\/\/ at runtime\n+address FileMapInfo::heap_region_runtime_start_address(FileMapRegion* spc) {\n+  assert(UseSharedSpaces, \"runtime only\");\n+  spc->assert_is_heap_region();\n+  if (UseCompressedOops) {\n+    return start_address_as_decoded_from_archive(spc);\n+  } else {\n+    assert(is_aligned(spc->mapping_offset(), sizeof(HeapWord)), \"must be\");\n+    return header()->heap_begin() + spc->mapping_offset() + HeapShared::runtime_delta();\n+  }\n+}\n+\n+void FileMapInfo::set_shared_heap_runtime_delta(ptrdiff_t delta) {\n+  if (UseCompressedOops) {\n+    HeapShared::init_narrow_oop_decoding(narrow_oop_base() + delta, narrow_oop_shift());\n+  } else {\n+    HeapShared::set_runtime_delta(delta);\n+  }\n+}\n@@ -2044,9 +2152,23 @@\n-    MemRegion range = get_heap_regions_range_with_current_oop_encoding_mode();\n-    if (!CompressedOops::is_in(range)) {\n-      log_info(cds)(\"CDS heap data needs to be relocated because\");\n-      log_info(cds)(\"the desired range \" PTR_FORMAT \" - \"  PTR_FORMAT, p2i(range.start()), p2i(range.end()));\n-      log_info(cds)(\"is outside of the heap \" PTR_FORMAT \" - \"  PTR_FORMAT, p2i(CompressedOops::begin()), p2i(CompressedOops::end()));\n-      _heap_pointers_need_patching = true;\n-    } else if (header()->heap_end() != CompressedOops::end()) {\n-      log_info(cds)(\"CDS heap data needs to be relocated to the end of the runtime heap to reduce fragmentation\");\n-      _heap_pointers_need_patching = true;\n+    if (UseCompressedOops) {\n+      MemRegion range = get_heap_regions_range_with_current_oop_encoding_mode();\n+      if (!CompressedOops::is_in(range)) {\n+        log_info(cds)(\"CDS heap data needs to be relocated because\");\n+        log_info(cds)(\"the desired range \" PTR_FORMAT \" - \"  PTR_FORMAT, p2i(range.start()), p2i(range.end()));\n+        log_info(cds)(\"is outside of the heap \" PTR_FORMAT \" - \"  PTR_FORMAT, p2i(CompressedOops::begin()), p2i(CompressedOops::end()));\n+        _heap_pointers_need_patching = true;\n+      } else if (header()->heap_end() != CompressedOops::end()) {\n+        log_info(cds)(\"CDS heap data needs to be relocated to the end of the runtime heap to reduce fragmentation\");\n+        _heap_pointers_need_patching = true;\n+      }\n+    } else {\n+      MemRegion range((HeapWord*)header()->heap_begin(), (HeapWord*)header()->heap_end());\n+      if (!G1CollectedHeap::heap()->reserved().contains(range)) {\n+        log_info(cds)(\"CDS heap data needs to be relocated because\");\n+        log_info(cds)(\"the desired range \" PTR_FORMAT \" - \"  PTR_FORMAT, p2i(range.start()), p2i(range.end()));\n+        log_info(cds)(\"is outside of the heap \" PTR_FORMAT \" - \"  PTR_FORMAT,\n+            p2i((address)G1CollectedHeap::heap()->reserved().start()), p2i((address)G1CollectedHeap::heap()->reserved().end()));\n+        _heap_pointers_need_patching = true;\n+      } else if (header()->heap_end() != (address)G1CollectedHeap::heap()->reserved().end()) {\n+        log_info(cds)(\"CDS heap data needs to be relocated to the end of the runtime heap to reduce fragmentation\");\n+        _heap_pointers_need_patching = true;\n+      }\n@@ -2059,1 +2181,1 @@\n-    \/\/   [      |archived heap regions| ]         runtime heap end ------v\n+    \/\/   [      |archived heap regions| ]         run time heap end -----v\n@@ -2061,0 +2183,3 @@\n+    \/\/          ^\n+    \/\/          D                                ^\n+    \/\/                                           R\n@@ -2064,2 +2189,2 @@\n-    \/\/ At run time, they may not be inside the heap, so we move them so\n-    \/\/ that they are now near the top of the runtime time. This can be done by\n+    \/\/ At run time, if the heap ends at a different address, we need to\n+    \/\/ move them near to top of the run time heap. This can be done by\n@@ -2067,0 +2192,7 @@\n+    \/\/\n+    \/\/ Also: D = bottom of a heap region at dump time\n+    \/\/       R = bottom of a heap region at run time\n+    \/\/\n+    \/\/ FileMapRegion* spc = ...;\n+    \/\/   address D = header()->heap_begin() + spc->mapping_offset();\n+    \/\/   address R = D + delta;\n@@ -2068,1 +2200,2 @@\n-    address runtime_heap_end = CompressedOops::end();\n+    address runtime_heap_end = UseCompressedOops ? CompressedOops::end() :\n+                                                   (address)G1CollectedHeap::heap()->reserved().end();\n@@ -2073,1 +2206,2 @@\n-  HeapShared::init_narrow_oop_decoding(narrow_oop_base() + delta, narrow_oop_shift());\n+\n+  set_shared_heap_runtime_delta(delta);\n@@ -2076,1 +2210,2 @@\n-  address relocated_closed_heap_region_bottom = start_address_as_decoded_from_archive(si);\n+  address relocated_closed_heap_region_bottom = heap_region_runtime_start_address(si);\n+\n@@ -2087,1 +2222,2 @@\n-    HeapShared::init_narrow_oop_decoding(narrow_oop_base() + delta, narrow_oop_shift());\n+    set_shared_heap_runtime_delta(delta);\n+    relocated_closed_heap_region_bottom = heap_region_runtime_start_address(si);\n@@ -2089,1 +2225,0 @@\n-    relocated_closed_heap_region_bottom = start_address_as_decoded_from_archive(si);\n@@ -2107,1 +2242,0 @@\n-      HeapShared::set_roots(header()->heap_obj_roots());\n@@ -2148,1 +2282,1 @@\n-      HeapWord* start = (HeapWord*)start_address_as_decoded_from_archive(si);\n+      HeapWord* start = (HeapWord*)heap_region_runtime_start_address(si);\n@@ -2376,8 +2510,12 @@\n-  if (!open_for_read()) {\n-    return false;\n-  }\n-  if (!init_from_file(_fd)) {\n-    return false;\n-  }\n-  if (!validate_header()) {\n-    return false;\n+  if (!open_for_read() || !init_from_file(_fd) || !validate_header()) {\n+    if (_is_static) {\n+      FileMapInfo::fail_continue(\"Initialize static archive failed.\");\n+      return false;\n+    } else {\n+      FileMapInfo::fail_continue(\"Initialize dynamic archive failed.\");\n+      if (AutoCreateSharedArchive) {\n+        DynamicDumpSharedSpaces = true;\n+        ArchiveClassesAtExit = Arguments::GetSharedDynamicArchivePath();\n+      }\n+      return false;\n+    }\n@@ -2385,0 +2523,1 @@\n+\n@@ -2414,2 +2553,2 @@\n-  \/\/ start computing from the field after _crc to end of base archive name.\n-  char* buf = (char*)&(_generic_header._crc) + sizeof(_generic_header._crc);\n+  \/\/ start computing from the field after _header_size to end of base archive name.\n+  char* buf = (char*)&(_generic_header._header_size) + sizeof(_generic_header._header_size);\n@@ -2554,0 +2693,5 @@\n+  if (i == 0) {\n+    \/\/ index 0 corresponds to the ClassPathImageEntry which is a globally shared object\n+    \/\/ and should never be deleted.\n+    return ClassLoader::get_jrt_entry();\n+  }\n@@ -2556,3 +2700,9 @@\n-    if (i == 0) {\n-      ent = ClassLoader::get_jrt_entry();\n-      assert(ent != NULL, \"must be\");\n+    SharedClassPathEntry* scpe = shared_path(i);\n+    assert(scpe->is_jar(), \"must be\"); \/\/ other types of scpe will not produce archived classes\n+\n+    const char* path = scpe->name();\n+    struct stat st;\n+    if (os::stat(path, &st) != 0) {\n+      char *msg = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, char, strlen(path) + 128);\n+      jio_snprintf(msg, strlen(path) + 127, \"error in finding JAR file %s\", path);\n+      THROW_MSG_(vmSymbols::java_io_IOException(), msg, NULL);\n@@ -2560,6 +2710,2 @@\n-      SharedClassPathEntry* scpe = shared_path(i);\n-      assert(scpe->is_jar(), \"must be\"); \/\/ other types of scpe will not produce archived classes\n-\n-      const char* path = scpe->name();\n-      struct stat st;\n-      if (os::stat(path, &st) != 0) {\n+      ent = ClassLoader::create_class_path_entry(THREAD, path, &st, false, false);\n+      if (ent == NULL) {\n@@ -2567,1 +2713,1 @@\n-        jio_snprintf(msg, strlen(path) + 127, \"error in finding JAR file %s\", path);\n+        jio_snprintf(msg, strlen(path) + 127, \"error in opening JAR file %s\", path);\n@@ -2569,7 +2715,0 @@\n-      } else {\n-        ent = ClassLoader::create_class_path_entry(THREAD, path, &st, false, false);\n-        if (ent == NULL) {\n-          char *msg = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, char, strlen(path) + 128);\n-          jio_snprintf(msg, strlen(path) + 127, \"error in opening JAR file %s\", path);\n-          THROW_MSG_(vmSymbols::java_io_IOException(), msg, NULL);\n-        }\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":319,"deletions":180,"binary":false,"changes":499,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -264,1 +264,0 @@\n-  narrowOop _heap_obj_roots;            \/\/ An objArray that stores all the roots of archived heap objects\n@@ -312,1 +311,0 @@\n-  narrowOop heap_obj_roots()               const { return _heap_obj_roots; }\n@@ -319,1 +317,0 @@\n-  void set_heap_obj_roots(narrowOop r)           { _heap_obj_roots = r; }\n@@ -391,2 +388,1 @@\n-  FileMapHeader *header() const       { return _header; }\n-\n+  FileMapHeader *header() const       { return _header; }\n@@ -396,1 +392,0 @@\n-  static bool check_archive(const char* archive_name, bool is_static);\n@@ -410,1 +405,1 @@\n-  FileMapInfo(bool is_static);\n+  FileMapInfo(const char* full_apth, bool is_static);\n@@ -450,2 +445,0 @@\n-  narrowOop heap_obj_roots()               const    { return header()->heap_obj_roots(); }\n-\n@@ -483,1 +476,1 @@\n-  void  open_for_write(const char* path = NULL);\n+  void  open_for_write();\n@@ -597,0 +590,1 @@\n+  bool  check_paths_existence(const char* paths) NOT_CDS_RETURN_(false);\n@@ -610,0 +604,2 @@\n+  address heap_region_runtime_start_address(FileMapRegion* spc) NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n+  void set_shared_heap_runtime_delta(ptrdiff_t delta) NOT_CDS_JAVA_HEAP_RETURN;\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":7,"deletions":11,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -74,0 +74,1 @@\n+bool HeapShared::_disable_writing = false;\n@@ -78,0 +79,1 @@\n+\/\/ Support for loaded heap.\n@@ -90,0 +92,4 @@\n+\n+\/\/ Suport for mapped heap (!UseCompressedOops only)\n+ptrdiff_t HeapShared::_runtime_delta = 0;\n+\n@@ -130,1 +136,0 @@\n-narrowOop HeapShared::_roots_narrow;\n@@ -154,1 +159,0 @@\n-    _roots = OopHandle(Universe::vm_global(), decode_from_archive(_roots_narrow));\n@@ -241,6 +245,0 @@\n-void HeapShared::set_roots(narrowOop roots) {\n-  assert(UseSharedSpaces, \"runtime only\");\n-  assert(is_fully_available(), \"must be\");\n-  _roots_narrow = roots;\n-}\n-\n@@ -377,1 +375,4 @@\n-                  p2i(CompressedOops::begin()), p2i(CompressedOops::end()));\n+                   UseCompressedOops ? p2i(CompressedOops::begin()) :\n+                                       p2i((address)G1CollectedHeap::heap()->reserved().start()),\n+                   UseCompressedOops ? p2i(CompressedOops::end()) :\n+                                       p2i((address)G1CollectedHeap::heap()->reserved().end()));\n@@ -673,1 +674,0 @@\n-\n@@ -677,1 +677,17 @@\n-void HeapShared::serialize_subgraph_info_table_header(SerializeClosure* soc) {\n+void HeapShared::serialize(SerializeClosure* soc) {\n+  oop roots_oop = NULL;\n+\n+  if (soc->reading()) {\n+    soc->do_oop(&roots_oop); \/\/ read from archive\n+    assert(oopDesc::is_oop_or_null(roots_oop), \"is oop\");\n+    \/\/ Create an OopHandle only if we have actually mapped or loaded the roots\n+    if (roots_oop != NULL) {\n+      assert(HeapShared::is_fully_available(), \"must be\");\n+      _roots = OopHandle(Universe::vm_global(), roots_oop);\n+    }\n+  } else {\n+    \/\/ writing\n+    roots_oop = roots();\n+    soc->do_oop(&roots_oop); \/\/ write to archive\n+  }\n+\n@@ -1399,1 +1415,1 @@\n-  narrowOop* _start;\n+  void* _start;\n@@ -1404,1 +1420,1 @@\n-  FindEmbeddedNonNullPointers(narrowOop* start, BitMap* oopmap)\n+  FindEmbeddedNonNullPointers(void* start, BitMap* oopmap)\n@@ -1411,1 +1427,1 @@\n-      size_t idx = p - _start;\n+      size_t idx = p - (narrowOop*)_start;\n@@ -1417,2 +1433,8 @@\n-  virtual void do_oop(oop *p) {\n-    ShouldNotReachHere();\n+  virtual void do_oop(oop* p) {\n+    _num_total_oops ++;\n+    if ((*p) != NULL) {\n+      size_t idx = p - (oop*)_start;\n+      _oopmap->set_bit(idx);\n+    } else {\n+      _num_null_oops ++;\n+    }\n@@ -1425,2 +1447,1 @@\n-  assert(UseCompressedOops, \"must be\");\n-  size_t num_bits = region.byte_size() \/ sizeof(narrowOop);\n+  size_t num_bits = region.byte_size() \/ (UseCompressedOops ? sizeof(narrowOop) : sizeof(oop));\n@@ -1431,1 +1452,1 @@\n-  FindEmbeddedNonNullPointers finder((narrowOop*)p, &oopmap);\n+  FindEmbeddedNonNullPointers finder((void*)p, &oopmap);\n@@ -1452,1 +1473,1 @@\n-class PatchEmbeddedPointers: public BitMapClosure {\n+class PatchCompressedEmbeddedPointers: public BitMapClosure {\n@@ -1456,1 +1477,1 @@\n-  PatchEmbeddedPointers(narrowOop* start) : _start(start) {}\n+  PatchCompressedEmbeddedPointers(narrowOop* start) : _start(start) {}\n@@ -1468,0 +1489,16 @@\n+class PatchUncompressedEmbeddedPointers: public BitMapClosure {\n+  oop* _start;\n+\n+ public:\n+  PatchUncompressedEmbeddedPointers(oop* start) : _start(start) {}\n+\n+  bool do_bit(size_t offset) {\n+    oop* p = _start + offset;\n+    intptr_t dumptime_oop = (intptr_t)((void*)*p);\n+    assert(dumptime_oop != 0, \"null oops should have been filtered out at dump time\");\n+    intptr_t runtime_oop = dumptime_oop + HeapShared::runtime_delta();\n+    RawAccess<IS_NOT_NULL>::oop_store(p, cast_to_oop(runtime_oop));\n+    return true;\n+  }\n+};\n+\n@@ -1480,2 +1517,7 @@\n-  PatchEmbeddedPointers patcher((narrowOop*)region.start());\n-  bm.iterate(&patcher);\n+  if (UseCompressedOops) {\n+    PatchCompressedEmbeddedPointers patcher((narrowOop*)region.start());\n+    bm.iterate(&patcher);\n+  } else {\n+    PatchUncompressedEmbeddedPointers patcher((oop*)region.start());\n+    bm.iterate(&patcher);\n+  }\n@@ -1702,1 +1744,0 @@\n-  set_roots(mapinfo->heap_obj_roots());\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":66,"deletions":25,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -70,0 +70,1 @@\n+#include \"runtime\/globals_extension.hpp\"\n@@ -389,1 +390,1 @@\n-  HeapShared::serialize_subgraph_info_table_header(soc);\n+  HeapShared::serialize(soc);\n@@ -561,1 +562,3 @@\n-  FileMapInfo* mapinfo = new FileMapInfo(true);\n+  const char* static_archive = Arguments::GetSharedArchivePath();\n+  assert(static_archive != nullptr, \"SharedArchiveFile not set?\");\n+  FileMapInfo* mapinfo = new FileMapInfo(static_archive, true);\n@@ -601,1 +604,1 @@\n-    _loaded_cld_handles.append(OopHandle(Universe::vm_global(), cld->holder_phantom()));\n+    _loaded_cld_handles.append(OopHandle(Universe::vm_global(), cld->holder()));\n@@ -645,2 +648,4 @@\n-void MetaspaceShared::link_shared_classes(TRAPS) {\n-  LambdaFormInvokers::regenerate_holder_classes(CHECK);\n+void MetaspaceShared::link_shared_classes(bool jcmd_request, TRAPS) {\n+  if (!jcmd_request) {\n+    LambdaFormInvokers::regenerate_holder_classes(CHECK);\n+  }\n@@ -710,0 +715,24 @@\n+#if INCLUDE_CDS_JAVA_HEAP && defined(_LP64)\n+void MetaspaceShared::adjust_heap_sizes_for_dumping() {\n+  if (!DumpSharedSpaces || UseCompressedOops) {\n+    return;\n+  }\n+  \/\/ CDS heap dumping requires all string oops to have an offset\n+  \/\/ from the heap bottom that can be encoded in 32-bit.\n+  julong max_heap_size = (julong)(4 * G);\n+\n+  if (MinHeapSize > max_heap_size) {\n+    log_debug(cds)(\"Setting MinHeapSize to 4G for CDS dumping, original size = \" SIZE_FORMAT \"M\", MinHeapSize\/M);\n+    FLAG_SET_ERGO(MinHeapSize, max_heap_size);\n+  }\n+  if (InitialHeapSize > max_heap_size) {\n+    log_debug(cds)(\"Setting InitialHeapSize to 4G for CDS dumping, original size = \" SIZE_FORMAT \"M\", InitialHeapSize\/M);\n+    FLAG_SET_ERGO(InitialHeapSize, max_heap_size);\n+  }\n+  if (MaxHeapSize > max_heap_size) {\n+    log_debug(cds)(\"Setting MaxHeapSize to 4G for CDS dumping, original size = \" SIZE_FORMAT \"M\", MaxHeapSize\/M);\n+    FLAG_SET_ERGO(MaxHeapSize, max_heap_size);\n+  }\n+}\n+#endif \/\/ INCLUDE_CDS_JAVA_HEAP && _LP64\n+\n@@ -778,1 +807,1 @@\n-  link_shared_classes(CHECK);\n+  link_shared_classes(false\/*not from jcmd*\/, CHECK);\n@@ -835,5 +864,4 @@\n-      \"Archived java heap is not supported as UseG1GC, \"\n-      \"UseCompressedOops and UseCompressedClassPointers are required.\"\n-      \"Current settings: UseG1GC=%s, UseCompressedOops=%s, UseCompressedClassPointers=%s.\",\n-      BOOL_TO_STR(UseG1GC), BOOL_TO_STR(UseCompressedOops),\n-      BOOL_TO_STR(UseCompressedClassPointers));\n+      \"Archived java heap is not supported as UseG1GC \"\n+      \"and UseCompressedClassPointers are required.\"\n+      \"Current settings: UseG1GC=%s, UseCompressedClassPointers=%s.\",\n+      BOOL_TO_STR(UseG1GC), BOOL_TO_STR(UseCompressedClassPointers));\n@@ -951,0 +979,2 @@\n+      \/\/ turn AutoCreateSharedArchive off if successfully mapped\n+      AutoCreateSharedArchive = false;\n@@ -956,0 +986,3 @@\n+    if (DynamicDumpSharedSpaces) {\n+      warning(\"-XX:ArchiveClassesAtExit is unsupported when base CDS archive is not loaded. Run with -Xlog:cds for more info.\");\n+    }\n@@ -957,0 +990,3 @@\n+    \/\/ The base archive cannot be mapped. We cannot dump the dynamic shared archive.\n+    AutoCreateSharedArchive = false;\n+    DynamicDumpSharedSpaces = false;\n@@ -972,1 +1008,3 @@\n-  FileMapInfo* mapinfo = new FileMapInfo(true);\n+  const char* static_archive = Arguments::GetSharedArchivePath();\n+  assert(static_archive != nullptr, \"SharedArchivePath is NULL\");\n+  FileMapInfo* mapinfo = new FileMapInfo(static_archive, true);\n@@ -984,1 +1022,2 @@\n-  if (Arguments::GetSharedDynamicArchivePath() == NULL) {\n+  const char* dynamic_archive = Arguments::GetSharedDynamicArchivePath();\n+  if (dynamic_archive == nullptr) {\n@@ -988,1 +1027,1 @@\n-  FileMapInfo* mapinfo = new FileMapInfo(false);\n+  FileMapInfo* mapinfo = new FileMapInfo(dynamic_archive, false);\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":54,"deletions":15,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1692,0 +1692,1 @@\n+\n@@ -1694,1 +1695,2 @@\n-  out->print_cr(\"instanceKlass %s\", CURRENT_ENV->replay_name(task()->method()->method_holder()));\n+  ciInstanceKlass::dump_replay_instanceKlass(out, task()->method()->method_holder());\n+\n@@ -1724,1 +1726,1 @@\n-      FILE* replay_data_file = os::open(fd, \"w\");\n+      FILE* replay_data_file = os::fdopen(fd, \"w\");\n@@ -1742,1 +1744,1 @@\n-      FILE* inline_data_file = os::open(fd, \"w\");\n+      FILE* inline_data_file = os::fdopen(fd, \"w\");\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -848,0 +848,13 @@\n+void ciInstanceKlass::dump_replay_instanceKlass(outputStream* out, InstanceKlass* ik) {\n+  if (ik->is_hidden()) {\n+    const char *name = CURRENT_ENV->dyno_name(ik);\n+    if (name != NULL) {\n+      out->print_cr(\"instanceKlass %s # %s\", name, ik->name()->as_quoted_ascii());\n+    } else {\n+      out->print_cr(\"# instanceKlass %s\", ik->name()->as_quoted_ascii());\n+    }\n+  } else {\n+    out->print_cr(\"instanceKlass %s\", ik->name()->as_quoted_ascii());\n+  }\n+}\n+\n@@ -859,10 +872,1 @@\n-      if (isub->is_hidden()) {\n-        const char *name = CURRENT_ENV->dyno_name(isub);\n-        if (name != NULL) {\n-          out->print_cr(\"instanceKlass %s # %s\", name, sub->name()->as_quoted_ascii());\n-        } else {\n-          out->print_cr(\"# instanceKlass %s\", sub->name()->as_quoted_ascii());\n-        }\n-      } else {\n-        out->print_cr(\"instanceKlass %s\", sub->name()->as_quoted_ascii());\n-      }\n+      dump_replay_instanceKlass(out, isub);\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.cpp","additions":14,"deletions":10,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -302,0 +302,3 @@\n+  static void dump_replay_instanceKlass(outputStream* out, InstanceKlass* ik);\n+\n+\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -121,0 +121,1 @@\n+    _can_omit_stack_trace = h_m->can_omit_stack_trace();\n@@ -124,0 +125,1 @@\n+    _can_omit_stack_trace = true;\n@@ -180,0 +182,1 @@\n+  _can_omit_stack_trace(true),\n@@ -803,0 +806,14 @@\n+\/\/ ------------------------------------------------------------------\n+\/\/ ciMethod::can_omit_stack_trace\n+\/\/\n+\/\/ Tries to determine whether a method can omit stack trace in throw in compiled code.\n+bool ciMethod::can_omit_stack_trace() const {\n+  if (!StackTraceInThrowable) {\n+    return true; \/\/ stack trace is switched off.\n+  }\n+  if (!OmitStackTraceInFastThrow) {\n+    return false; \/\/ Have to provide stack trace.\n+  }\n+  return _can_omit_stack_trace;\n+}\n+\n","filename":"src\/hotspot\/share\/ci\/ciMethod.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -96,0 +96,1 @@\n+  bool _can_omit_stack_trace;\n@@ -373,0 +374,2 @@\n+  bool can_omit_stack_trace() const;\n+\n","filename":"src\/hotspot\/share\/ci\/ciMethod.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -107,0 +107,1 @@\n+  bool _inline_late;\n@@ -148,1 +149,1 @@\n-    _stream = fopen(filename, \"rt\");\n+    _stream = os::fopen(filename, \"rt\");\n@@ -724,1 +725,1 @@\n-  \/\/ compile <klass> <name> <signature> <entry_bci> <comp_level> inline <count> (<depth> <bci> <klass> <name> <signature>)*\n+  \/\/ compile <klass> <name> <signature> <entry_bci> <comp_level> inline <count> (<depth> <bci> <inline_late> <klass> <name> <signature>)*\n@@ -766,0 +767,8 @@\n+        int inline_late = 0;\n+        if (_version >= 2) {\n+          inline_late = parse_int(\"inline_late\");\n+          if (had_error()) {\n+              break;\n+          }\n+        }\n+\n@@ -770,1 +779,1 @@\n-        new_ciInlineRecord(inl_method, bci, depth);\n+        new_ciInlineRecord(inl_method, bci, depth, inline_late);\n@@ -1339,1 +1348,1 @@\n-  ciInlineRecord* new_ciInlineRecord(Method* method, int bci, int depth) {\n+  ciInlineRecord* new_ciInlineRecord(Method* method, int bci, int depth, int inline_late) {\n@@ -1346,0 +1355,1 @@\n+    rec->_inline_late = inline_late;\n@@ -1582,1 +1592,1 @@\n-bool ciReplay::should_inline(void* data, ciMethod* method, int bci, int inline_depth) {\n+bool ciReplay::should_inline(void* data, ciMethod* method, int bci, int inline_depth, bool& should_delay) {\n@@ -1584,1 +1594,1 @@\n-    GrowableArray<ciInlineRecord*>*  records = (GrowableArray<ciInlineRecord*>*)data;\n+    GrowableArray<ciInlineRecord*>* records = (GrowableArray<ciInlineRecord*>*)data;\n@@ -1587,1 +1597,6 @@\n-    return CompileReplay::find_ciInlineRecord(records, method->get_Method(), bci, inline_depth) != NULL;\n+    ciInlineRecord* record = CompileReplay::find_ciInlineRecord(records, method->get_Method(), bci, inline_depth);\n+    if (record == NULL) {\n+      return false;\n+    }\n+    should_delay = record->_inline_late;\n+    return true;\n@@ -1591,1 +1606,6 @@\n-    return replay_state->find_ciInlineRecord(method->get_Method(), bci, inline_depth) != NULL;\n+    ciInlineRecord* record = replay_state->find_ciInlineRecord(method->get_Method(), bci, inline_depth);\n+    if (record == NULL) {\n+      return false;\n+    }\n+    should_delay = record->_inline_late;\n+    return true;\n@@ -1598,1 +1618,1 @@\n-    GrowableArray<ciInlineRecord*>*  records = (GrowableArray<ciInlineRecord*>*)data;\n+    GrowableArray<ciInlineRecord*>* records = (GrowableArray<ciInlineRecord*>*)data;\n","filename":"src\/hotspot\/share\/ci\/ciReplay.cpp","additions":30,"deletions":10,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -491,2 +491,3 @@\n-  if (cur_bc() == Bytecodes::_invokedynamic)\n-    return CURRENT_ENV->get_klass_by_name(_holder, ciSymbols::java_lang_invoke_MethodHandle(), false);\n+  if (cur_bc() == Bytecodes::_invokedynamic) {\n+    return CURRENT_ENV->MethodHandle_klass();\n+  }\n","filename":"src\/hotspot\/share\/ci\/ciStreams.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2317,1 +2317,1 @@\n-bool ciTypeFlow::clone_loop_heads(Loop* lp, StateVector* temp_vector, JsrSet* temp_set) {\n+bool ciTypeFlow::clone_loop_heads(StateVector* temp_vector, JsrSet* temp_set) {\n@@ -2320,1 +2320,1 @@\n-    lp = iter.current();\n+    Loop* lp = iter.current();\n@@ -2565,0 +2565,96 @@\n+\/\/ If the tail is a branch to the head, retrieve how many times that path was taken from profiling\n+int ciTypeFlow::profiled_count(ciTypeFlow::Loop* loop) {\n+  ciMethodData* methodData = method()->method_data();\n+  if (!methodData->is_mature()) {\n+    return 0;\n+  }\n+  ciTypeFlow::Block* tail = loop->tail();\n+  if (tail->control() == -1) {\n+    return 0;\n+  }\n+\n+  ciProfileData* data = methodData->bci_to_data(tail->control());\n+\n+  if (data == NULL || !data->is_JumpData()) {\n+    return 0;\n+  }\n+\n+  ciBytecodeStream iter(method());\n+  iter.reset_to_bci(tail->control());\n+\n+  bool is_an_if = false;\n+  bool wide = false;\n+  Bytecodes::Code bc = iter.next();\n+  switch (bc) {\n+    case Bytecodes::_ifeq:\n+    case Bytecodes::_ifne:\n+    case Bytecodes::_iflt:\n+    case Bytecodes::_ifge:\n+    case Bytecodes::_ifgt:\n+    case Bytecodes::_ifle:\n+    case Bytecodes::_if_icmpeq:\n+    case Bytecodes::_if_icmpne:\n+    case Bytecodes::_if_icmplt:\n+    case Bytecodes::_if_icmpge:\n+    case Bytecodes::_if_icmpgt:\n+    case Bytecodes::_if_icmple:\n+    case Bytecodes::_if_acmpeq:\n+    case Bytecodes::_if_acmpne:\n+    case Bytecodes::_ifnull:\n+    case Bytecodes::_ifnonnull:\n+      is_an_if = true;\n+      break;\n+    case Bytecodes::_goto_w:\n+    case Bytecodes::_jsr_w:\n+      wide = true;\n+      break;\n+    case Bytecodes::_goto:\n+    case Bytecodes::_jsr:\n+      break;\n+    default:\n+      fatal(\" invalid bytecode: %s\", Bytecodes::name(iter.cur_bc()));\n+  }\n+\n+  GrowableArray<ciTypeFlow::Block*>* succs = tail->successors();\n+\n+  if (!is_an_if) {\n+    assert(((wide ? iter.get_far_dest() : iter.get_dest()) == loop->head()->start()) == (succs->at(ciTypeFlow::GOTO_TARGET) == loop->head()), \"branch should lead to loop head\");\n+    if (succs->at(ciTypeFlow::GOTO_TARGET) == loop->head()) {\n+      return method()->scale_count(data->as_JumpData()->taken());\n+    }\n+  } else {\n+    assert((iter.get_dest() == loop->head()->start()) == (succs->at(ciTypeFlow::IF_TAKEN) == loop->head()), \"bytecode and CFG not consistent\");\n+    assert((tail->limit() == loop->head()->start()) == (succs->at(ciTypeFlow::IF_NOT_TAKEN) == loop->head()), \"bytecode and CFG not consistent\");\n+    if (succs->at(ciTypeFlow::IF_TAKEN) == loop->head()) {\n+      return method()->scale_count(data->as_JumpData()->taken());\n+    } else if (succs->at(ciTypeFlow::IF_NOT_TAKEN) == loop->head()) {\n+      return method()->scale_count(data->as_BranchData()->not_taken());\n+    }\n+  }\n+\n+  return 0;\n+}\n+\n+bool ciTypeFlow::Loop::at_insertion_point(Loop* lp, Loop* current) {\n+  int lp_pre_order = lp->head()->pre_order();\n+  if (current->head()->pre_order() < lp_pre_order) {\n+    return true;\n+  } else if (current->head()->pre_order() > lp_pre_order) {\n+    return false;\n+  }\n+  \/\/ In the case of a shared head, make the most frequent head\/tail (as reported by profiling) the inner loop\n+  if (current->head() == lp->head()) {\n+    int lp_count = outer()->profiled_count(lp);\n+    int current_count = outer()->profiled_count(current);\n+    if (current_count < lp_count) {\n+      return true;\n+    } else if (current_count > lp_count) {\n+      return false;\n+    }\n+  }\n+  if (current->tail()->pre_order() > lp->tail()->pre_order()) {\n+    return true;\n+  }\n+  return false;\n+}\n+\n@@ -2582,1 +2678,1 @@\n-      if (current == lp)\n+      if (current == lp) {\n@@ -2584,4 +2680,2 @@\n-      if (current->head()->pre_order() < lp_pre_order)\n-        break;\n-      if (current->head()->pre_order() == lp_pre_order &&\n-          current->tail()->pre_order() > lp->tail()->pre_order()) {\n+      }\n+      if (at_insertion_point(lp, current)) {\n@@ -2847,1 +2941,1 @@\n-    bool changed = clone_loop_heads(loop_tree_root(), temp_vector, temp_set);\n+    bool changed = clone_loop_heads(temp_vector, temp_set);\n","filename":"src\/hotspot\/share\/ci\/ciTypeFlow.cpp","additions":102,"deletions":8,"binary":false,"changes":110,"status":"modified"},{"patch":"@@ -723,0 +723,3 @@\n+    ciTypeFlow* outer() const { return head()->outer(); }\n+    bool at_insertion_point(Loop* lp, Loop* current);\n+\n@@ -801,1 +804,1 @@\n-  bool clone_loop_heads(Loop* lp, StateVector* temp_vector, JsrSet* temp_set);\n+  bool clone_loop_heads(StateVector* temp_vector, JsrSet* temp_set);\n@@ -921,0 +924,2 @@\n+  int profiled_count(ciTypeFlow::Loop* loop);\n+\n","filename":"src\/hotspot\/share\/ci\/ciTypeFlow.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -145,1 +145,1 @@\n-#define CONSTANT_CLASS_DESCRIPTORS        62\n+#define JAVA_19_VERSION                   63\n@@ -147,0 +147,1 @@\n+#define CONSTANT_CLASS_DESCRIPTORS        63\n@@ -2991,1 +2992,2 @@\n-  if (name == vmSymbols::finalize_method_name() &&\n+  if (InstanceKlass::is_finalization_enabled() &&\n+      name == vmSymbols::finalize_method_name() &&\n@@ -3208,0 +3210,1 @@\n+\n@@ -3237,8 +3240,9 @@\n-      \/\/ To maintain compatibility, throw an exception if duplicate inner classes\n-      \/\/ entries are found.\n-      guarantee_property((_inner_classes->at(idx) != _inner_classes->at(y) ||\n-                          _inner_classes->at(idx+1) != _inner_classes->at(y+1) ||\n-                          _inner_classes->at(idx+2) != _inner_classes->at(y+2) ||\n-                          _inner_classes->at(idx+3) != _inner_classes->at(y+3)),\n-                         \"Duplicate entry in InnerClasses attribute in class file %s\",\n-                         CHECK_(true));\n+      \/\/ 4347400: make sure there's no duplicate entry in the classes array\n+      if (_major_version >= JAVA_1_5_VERSION) {\n+        guarantee_property((_inner_classes->at(idx) != _inner_classes->at(y) ||\n+                            _inner_classes->at(idx+1) != _inner_classes->at(y+1) ||\n+                            _inner_classes->at(idx+2) != _inner_classes->at(y+2) ||\n+                            _inner_classes->at(idx+3) != _inner_classes->at(y+3)),\n+                           \"Duplicate entry in InnerClasses attribute in class file %s\",\n+                           CHECK_(true));\n+      }\n@@ -3343,2 +3347,1 @@\n-  \/\/ 4347400: make sure there's no duplicate entry in the classes array\n-  \/\/ Also, check for circular entries.\n+  \/\/ Check for circular and duplicate entries.\n@@ -3346,1 +3349,1 @@\n-  if (_need_verify && _major_version >= JAVA_1_5_VERSION) {\n+  if (_need_verify) {\n@@ -4411,1 +4414,2 @@\n-  if (m != NULL && !m->is_empty_method()) {\n+  if (InstanceKlass::is_finalization_enabled() &&\n+      (m != NULL) && !m->is_empty_method()) {\n@@ -4802,1 +4806,0 @@\n-  const bool major_gte_14  = _major_version >= JAVA_14_VERSION;\n@@ -5084,1 +5087,1 @@\n-\/\/ be taken as a fieldname. Allow '\/' if slash_ok is true.\n+\/\/ be taken as a fieldname. Allow non-trailing '\/'s if slash_ok is true.\n@@ -5158,1 +5161,1 @@\n-  return (not_first_ch) ? p : NULL;\n+  return (not_first_ch && !last_is_slash) ? p : NULL;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":20,"deletions":17,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -256,1 +256,1 @@\n-      size_t num_read = os::read(file_handle, (char*) buffer, st.st_size);\n+      size_t num_read = ::read(file_handle, (char*) buffer, st.st_size);\n@@ -258,1 +258,1 @@\n-      os::close(file_handle);\n+      ::close(file_handle);\n@@ -306,1 +306,7 @@\n-  int size = (*filesize) + ((nul_terminate) ? 1 : 0);\n+  size_t size = (uint32_t)(*filesize);\n+  if (nul_terminate) {\n+    if (sizeof(size) == sizeof(uint32_t) && size == UINT_MAX) {\n+      return NULL; \/\/ 32-bit integer overflow will occur.\n+    }\n+    size++;\n+  }\n@@ -312,1 +318,1 @@\n-    buffer[*filesize] = 0;\n+    buffer[size - 1] = 0;\n@@ -1256,1 +1262,2 @@\n-void ClassLoader::record_result(JavaThread* current, InstanceKlass* ik, const ClassFileStream* stream) {\n+void ClassLoader::record_result(JavaThread* current, InstanceKlass* ik,\n+                                const ClassFileStream* stream, bool redefined) {\n@@ -1340,1 +1347,1 @@\n-    \/\/ No path entry found for this class. Must be a shared class loaded by the\n+    \/\/ No path entry found for this class: most likely a shared class loaded by the\n@@ -1342,2 +1349,2 @@\n-    if (classpath_index < 0) {\n-      assert(ik->shared_classpath_index() < 0, \"Sanity\");\n+    if (classpath_index < 0 && !SystemDictionaryShared::is_builtin_loader(ik->class_loader_data())) {\n+      assert(ik->shared_classpath_index() < 0, \"not assigned yet\");\n@@ -1362,1 +1369,1 @@\n-  ClassLoaderExt::record_result(classpath_index, ik);\n+  ClassLoaderExt::record_result(classpath_index, ik, redefined);\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":17,"deletions":10,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -70,0 +70,1 @@\n+#include \"oops\/objArrayKlass.hpp\"\n@@ -362,2 +363,16 @@\n-    \/\/ Do not filter ArrayKlass oops here...\n-    if (k->is_array_klass() || (k->is_instance_klass() && InstanceKlass::cast(k)->is_loaded())) {\n+    \/\/ Filter out InstanceKlasses (or their ObjArrayKlasses) that have not entered the\n+    \/\/ loaded state.\n+    if (k->is_instance_klass()) {\n+      if (!InstanceKlass::cast(k)->is_loaded()) {\n+        continue;\n+      }\n+    } else if (k->is_shared() && k->is_objArray_klass()) {\n+      Klass* bottom = ObjArrayKlass::cast(k)->bottom_klass();\n+      if (bottom->is_instance_klass() && !InstanceKlass::cast(bottom)->is_loaded()) {\n+        \/\/ This could happen if <bottom> is a shared class that has been restored\n+        \/\/ but is not yet marked as loaded. All archived array classes of the\n+        \/\/ bottom class are already restored and placed in the _klasses list.\n+        continue;\n+      }\n+    }\n+\n@@ -365,3 +380,3 @@\n-      oop m = k->java_mirror();\n-      assert(m != NULL, \"NULL mirror\");\n-      assert(m->is_a(vmClasses::Class_klass()), \"invalid mirror\");\n+    oop m = k->java_mirror();\n+    assert(m != NULL, \"NULL mirror\");\n+    assert(m->is_a(vmClasses::Class_klass()), \"invalid mirror\");\n@@ -369,2 +384,1 @@\n-      klass_closure->do_klass(k);\n-    }\n+    klass_closure->do_klass(k);\n@@ -631,2 +645,3 @@\n-\/\/ Tell the GC to keep this klass alive while iterating ClassLoaderDataGraph\n-oop ClassLoaderData::holder_phantom() const {\n+\/\/ Tell the GC to keep this klass alive. Needed while iterating ClassLoaderDataGraph,\n+\/\/ and any runtime code that uses klasses.\n+oop ClassLoaderData::holder() const {\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.cpp","additions":25,"deletions":10,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -177,1 +177,1 @@\n-  oop holder_phantom() const;\n+  oop holder() const;\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -886,2 +886,2 @@\n-  do_intrinsic(_VectorBroadcastCoerced, jdk_internal_vm_vector_VectorSupport, vector_broadcast_coerced_name, vector_broadcast_coerced_sig, F_S)\\\n-   do_signature(vector_broadcast_coerced_sig, \"(Ljava\/lang\/Class;\"                                                                             \\\n+  do_intrinsic(_VectorFromBitsCoerced, jdk_internal_vm_vector_VectorSupport, vector_frombits_coerced_name, vector_frombits_coerced_sig, F_S)   \\\n+   do_signature(vector_frombits_coerced_sig, \"(Ljava\/lang\/Class;\"                                                                              \\\n@@ -891,0 +891,1 @@\n+                                               \"I\"                                                                                             \\\n@@ -892,1 +893,1 @@\n-                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$BroadcastOperation;)\"                                    \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$FromBitsCoercedOperation;)\"                              \\\n@@ -894,1 +895,1 @@\n-   do_name(vector_broadcast_coerced_name, \"broadcastCoerced\")                                                                                  \\\n+   do_name(vector_frombits_coerced_name, \"fromBitsCoerced\")                                                                                    \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -148,0 +148,1 @@\n+  template(sun_invoke_util_ValueConversions,          \"sun\/invoke\/util\/ValueConversions\")         \\\n@@ -358,1 +359,0 @@\n-  template(jdk_incubator_foreign_MemoryAccess,       \"jdk\/incubator\/foreign\/MemoryAccess\")        \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,1 +30,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n","filename":"src\/hotspot\/share\/code\/vtableStubs.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -414,0 +414,1 @@\n+  _last = NULL;\n@@ -1972,0 +1973,2 @@\n+      } else {\n+        task->set_failure_reason(\"breakpoints are present\");\n@@ -2005,1 +2008,1 @@\n-      fp = fopen(file_name, \"wt\");\n+      fp = os::fopen(file_name, \"wt\");\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -100,2 +100,0 @@\n-  bool bailout = false;\n-\n@@ -258,4 +256,0 @@\n-      case Bytecodes::_breakpoint:\n-        \/\/ Bail out of there are breakpoints in here.\n-        bailout = true;\n-        break;\n","filename":"src\/hotspot\/share\/compiler\/methodLiveness.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -445,1 +445,1 @@\n-  Node* card_offset = __ URShiftX( cast, __ ConI(CardTable::card_shift) );\n+  Node* card_offset = __ URShiftX( cast, __ ConI(CardTable::card_shift()) );\n","filename":"src\/hotspot\/share\/gc\/g1\/c2\/g1BarrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -424,2 +424,2 @@\n-bool G1ParScanThreadState::inject_evacuation_failure() {\n-  return _g1h->evac_failure_injector()->evacuation_should_fail(_evac_failure_inject_counter);\n+bool G1ParScanThreadState::inject_evacuation_failure(uint region_idx) {\n+  return _g1h->evac_failure_injector()->evacuation_should_fail(_evac_failure_inject_counter, region_idx);\n@@ -437,0 +437,6 @@\n+void G1ParScanThreadState::update_bot_after_copying(oop obj, size_t word_sz) {\n+  HeapWord* obj_start = cast_from_oop<HeapWord*>(obj);\n+  HeapRegion* region = _g1h->heap_region_containing(obj_start);\n+  region->update_bot_for_obj(obj_start, word_sz);\n+}\n+\n@@ -473,1 +479,1 @@\n-  if (inject_evacuation_failure()) {\n+  if (inject_evacuation_failure(from_region->hrm_index())) {\n@@ -485,0 +491,4 @@\n+  \/\/ Because the forwarding is done with memory_order_relaxed there is no\n+  \/\/ ordering with the above copy.  Clients that get the forwardee must not\n+  \/\/ examine its contents without other synchronization, since the contents\n+  \/\/ may not be up to date for them.\n@@ -502,4 +512,1 @@\n-      \/\/ Currently we only have two destinations and we only need BOT updates for\n-      \/\/ old. If the current allocation was done outside the PLAB this call will\n-      \/\/ have no effect since the _top of the PLAB has not changed.\n-      _plab_allocator->update_bot_for_plab_allocation(dest_attr, word_sz, node_index);\n+      update_bot_after_copying(obj, word_sz);\n@@ -616,3 +623,5 @@\n-    \/\/ Records evac failure objs, this will help speed up iteration\n-    \/\/ of these objs later in *remove self forward* phase of post evacuation.\n-    r->record_evac_failure_obj(old);\n+\n+    \/\/ Objects failing evacuation will turn into old objects since the regions\n+    \/\/ are relabeled as such. We mark the failing objects in the prev bitmap and\n+    \/\/ later use it to handle all failed objects.\n+    _g1h->mark_evac_failure_object(old, _worker_id);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":19,"deletions":10,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -74,1 +74,1 @@\n-  _manager_array = NEW_C_HEAP_ARRAY(ParCompactionManager*, parallel_gc_threads+1, mtGC);\n+  _manager_array = NEW_C_HEAP_ARRAY(ParCompactionManager*, parallel_gc_threads, mtGC);\n@@ -88,3 +88,0 @@\n-  \/\/ The VMThread gets its own ParCompactionManager, which is not available\n-  \/\/ for work stealing.\n-  _manager_array[parallel_gc_threads] = new ParCompactionManager();\n@@ -101,1 +98,1 @@\n-  for (uint i=0; i<=parallel_gc_threads; i++) {\n+  for (uint i=0; i<parallel_gc_threads; i++) {\n@@ -108,1 +105,1 @@\n-  for (uint i=0; i<=parallel_gc_threads; i++) {\n+  for (uint i=0; i<parallel_gc_threads; i++) {\n@@ -120,0 +117,9 @@\n+bool ParCompactionManager::transfer_from_overflow_stack(ObjArrayTask& task) {\n+  while (_objarray_stack.pop_overflow(task)) {\n+    if (!_objarray_stack.try_push_to_taskqueue(task)) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -122,1 +128,2 @@\n-    \/\/ Drain the overflow stack first, to allow stealing from the marking stack.\n+    \/\/ First, try to move tasks from the overflow stack into the shared buffer, so\n+    \/\/ that other threads can steal. Otherwise process the overflow stack first.\n@@ -125,1 +132,3 @@\n-      follow_contents(obj);\n+      if (!marking_stack()->try_push_to_taskqueue(obj)) {\n+        follow_contents(obj);\n+      }\n@@ -133,1 +142,1 @@\n-    if (_objarray_stack.pop_overflow(task) || _objarray_stack.pop_local(task)) {\n+    if (transfer_from_overflow_stack(task) || _objarray_stack.pop_local(task)) {\n@@ -188,1 +197,1 @@\n-  for (uint i = 0; i <= parallel_gc_threads; i++) {\n+  for (uint i = 0; i < parallel_gc_threads; i++) {\n@@ -195,1 +204,1 @@\n-  for (uint i = 0; i <= parallel_gc_threads; i++) {\n+  for (uint i = 0; i < parallel_gc_threads; i++) {\n","filename":"src\/hotspot\/share\/gc\/parallel\/psCompactionManager.cpp","additions":20,"deletions":11,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -1045,1 +1045,1 @@\n-    ct->clear(MemRegion(old_mr.start(), old_mr.end()));\n+    ct->clear(old_mr);\n@@ -1047,1 +1047,1 @@\n-    ct->invalidate(MemRegion(old_mr.start(), old_mr.end()));\n+    ct->invalidate(old_mr);\n@@ -1599,2 +1599,1 @@\n-void PSParallelCompact::summary_phase(ParCompactionManager* cm,\n-                                      bool maximum_compaction)\n+void PSParallelCompact::summary_phase(bool maximum_compaction)\n@@ -1739,4 +1738,0 @@\n-  TimeStamp marking_start;\n-  TimeStamp compaction_start;\n-  TimeStamp collection_exit;\n-\n@@ -1764,3 +1759,0 @@\n-  \/\/ Get the compaction manager reserved for the VM thread.\n-  ParCompactionManager* const vmthread_cm = ParCompactionManager::get_vmthread_cm();\n-\n@@ -1795,2 +1787,1 @@\n-    marking_start.update();\n-    marking_phase(vmthread_cm, &_gc_tracer);\n+    marking_phase(&_gc_tracer);\n@@ -1800,1 +1791,1 @@\n-    summary_phase(vmthread_cm, maximum_heap_compaction || max_on_system_gc);\n+    summary_phase(maximum_heap_compaction || max_on_system_gc);\n@@ -1811,1 +1802,0 @@\n-    compaction_start.update();\n@@ -1926,2 +1916,0 @@\n-  collection_exit.update();\n-\n@@ -1931,4 +1919,0 @@\n-  log_debug(gc, task, time)(\"VM-Thread \" JLONG_FORMAT \" \" JLONG_FORMAT \" \" JLONG_FORMAT,\n-                         marking_start.ticks(), compaction_start.ticks(),\n-                         collection_exit.ticks());\n-\n@@ -1968,30 +1952,0 @@\n-static void mark_from_roots_work(ParallelRootType::Value root_type, uint worker_id) {\n-  assert(ParallelScavengeHeap::heap()->is_gc_active(), \"called outside gc\");\n-\n-  ParCompactionManager* cm =\n-    ParCompactionManager::gc_thread_compaction_manager(worker_id);\n-  PCMarkAndPushClosure mark_and_push_closure(cm);\n-\n-  switch (root_type) {\n-    case ParallelRootType::class_loader_data:\n-      {\n-        CLDToOopClosure cld_closure(&mark_and_push_closure, ClassLoaderData::_claim_strong);\n-        ClassLoaderDataGraph::always_strong_cld_do(&cld_closure);\n-      }\n-      break;\n-\n-    case ParallelRootType::code_cache:\n-      \/\/ Do not treat nmethods as strong roots for mark\/sweep, since we can unload them.\n-      \/\/ScavengableNMethods::scavengable_nmethods_do(CodeBlobToOopClosure(&mark_and_push_closure));\n-      break;\n-\n-    case ParallelRootType::sentinel:\n-    DEBUG_ONLY(default:) \/\/ DEBUG_ONLY hack will create compile error on release builds (-Wswitch) and runtime check on debug builds\n-      fatal(\"Bad enumeration value: %u\", root_type);\n-      break;\n-  }\n-\n-  \/\/ Do the real work\n-  cm->follow_marking_stacks();\n-}\n-\n@@ -2004,3 +1958,3 @@\n-  oop obj = NULL;\n-  ObjArrayTask task;\n-    while (ParCompactionManager::steal_objarray(worker_id,  task)) {\n+    oop obj = NULL;\n+    ObjArrayTask task;\n+    if (ParCompactionManager::steal_objarray(worker_id,  task)) {\n@@ -2009,3 +1963,1 @@\n-      cm->follow_marking_stacks();\n-    }\n-    while (ParCompactionManager::steal(worker_id, obj)) {\n+    } else if (ParCompactionManager::steal(worker_id, obj)) {\n@@ -2013,1 +1965,1 @@\n-      cm->follow_marking_stacks();\n+    cm->follow_marking_stacks();\n@@ -2021,1 +1973,0 @@\n-  SequentialSubTasksDone _subtasks;\n@@ -2029,3 +1980,1 @@\n-      _subtasks(ParallelRootType::sentinel),\n-      _active_workers(active_workers) {\n-  }\n+      _active_workers(active_workers) {}\n@@ -2035,2 +1984,9 @@\n-    for (uint task = 0; _subtasks.try_claim_task(task); \/*empty*\/ ) {\n-      mark_from_roots_work(static_cast<ParallelRootType::Value>(task), worker_id);\n+    ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(worker_id);\n+    PCMarkAndPushClosure mark_and_push_closure(cm);\n+\n+    {\n+      CLDToOopClosure cld_closure(&mark_and_push_closure, ClassLoaderData::_claim_strong);\n+      ClassLoaderDataGraph::always_strong_cld_do(&cld_closure);\n+\n+      \/\/ Do the real work\n+      cm->follow_marking_stacks();\n@@ -2044,3 +2000,1 @@\n-      ParCompactionManager* cm = ParCompactionManager::gc_thread_compaction_manager(worker_id);\n-      PCMarkAndPushClosure closure(cm);\n-      _oop_storage_set_par_state.oops_do(&closure);\n+      _oop_storage_set_par_state.oops_do(&mark_and_push_closure);\n@@ -2079,2 +2033,1 @@\n-void PSParallelCompact::marking_phase(ParCompactionManager* cm,\n-                                      ParallelOldTracer *gc_tracer) {\n+void PSParallelCompact::marking_phase(ParallelOldTracer *gc_tracer) {\n@@ -2139,13 +2092,3 @@\n-}\n-\n-#ifdef ASSERT\n-void PCAdjustPointerClosure::verify_cm(ParCompactionManager* cm) {\n-  assert(cm != NULL, \"associate ParCompactionManage should not be NULL\");\n-  auto vmthread_cm = ParCompactionManager::get_vmthread_cm();\n-  if (Thread::current()->is_VM_thread()) {\n-    assert(cm == vmthread_cm, \"VM threads should use ParCompactionManager from get_vmthread_cm()\");\n-  } else {\n-    assert(Thread::current()->is_Worker_thread(), \"Must be a GC thread\");\n-    assert(cm != vmthread_cm, \"GC threads should use ParCompactionManager from gc_thread_compaction_manager()\");\n-  }\n-}\n+#if TASKQUEUE_STATS\n+  ParCompactionManager::oop_task_queues()->print_and_reset_taskqueue_stats(\"Oop Queue\");\n+  ParCompactionManager::_objarray_task_queues->print_and_reset_taskqueue_stats(\"ObjArrayOop Queue\");\n@@ -2153,0 +2096,1 @@\n+}\n@@ -2544,3 +2488,1 @@\n-    \/\/ Update the deferred objects, if any. In principle, any compaction\n-    \/\/ manager can be used. However, since the current thread is VM thread, we\n-    \/\/ use the rightful one to keep the verification logic happy.\n+    \/\/ Update the deferred objects, if any.\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":27,"deletions":85,"binary":false,"changes":112,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -58,1 +58,1 @@\n-  const uint promotion_manager_num = ParallelGCThreads + 1;\n+  const uint promotion_manager_num = ParallelGCThreads;\n@@ -99,1 +99,1 @@\n-  return &_manager_array[ParallelGCThreads];\n+  return &_manager_array[0];\n@@ -108,1 +108,1 @@\n-  for(uint i=0; i<ParallelGCThreads+1; i++) {\n+  for(uint i=0; i<ParallelGCThreads; i++) {\n@@ -117,1 +117,1 @@\n-  for (uint i = 0; i < ParallelGCThreads + 1; i++) {\n+  for (uint i = 0; i < ParallelGCThreads; i++) {\n@@ -151,2 +151,1 @@\n-void\n-PSPromotionManager::print_taskqueue_stats() {\n+void PSPromotionManager::print_taskqueue_stats() {\n@@ -159,13 +158,2 @@\n-  outputStream* out = &ls;\n-  out->print_cr(\"== GC Tasks Stats, GC %3d\",\n-                ParallelScavengeHeap::heap()->total_collections());\n-\n-  TaskQueueStats totals;\n-  out->print(\"thr \"); TaskQueueStats::print_header(1, out); out->cr();\n-  out->print(\"--- \"); TaskQueueStats::print_header(2, out); out->cr();\n-  for (uint i = 0; i < ParallelGCThreads + 1; ++i) {\n-    TaskQueueStats& next = manager_array(i)->_claimed_stack_depth.stats;\n-    out->print(\"%3d \", i); next.print(out); out->cr();\n-    totals += next;\n-  }\n-  out->print(\"tot \"); totals.print(out); out->cr();\n+\n+  stack_array_depth()->print_taskqueue_stats(&ls, \"Oop Queue\");\n@@ -174,3 +162,3 @@\n-  for (uint i = 0; i < hlines; ++i) out->print_cr(\"%s\", pm_stats_hdr[i]);\n-  for (uint i = 0; i < ParallelGCThreads + 1; ++i) {\n-    manager_array(i)->print_local_stats(out, i);\n+  for (uint i = 0; i < hlines; ++i) ls.print_cr(\"%s\", pm_stats_hdr[i]);\n+  for (uint i = 0; i < ParallelGCThreads; ++i) {\n+    manager_array(i)->print_local_stats(&ls, i);\n@@ -180,2 +168,1 @@\n-void\n-PSPromotionManager::reset_stats() {\n+void PSPromotionManager::reset_stats() {\n@@ -220,2 +207,0 @@\n-  ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();\n-\n@@ -248,6 +233,0 @@\n-#ifdef ASSERT\n-  ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();\n-  MutableSpace* to_space = heap->young_gen()->to_space();\n-  MutableSpace* old_space = heap->old_gen()->object_space();\n-#endif \/* ASSERT *\/\n-\n@@ -364,1 +343,4 @@\n-    _preserved_marks->push_if_necessary(obj, obj_mark);\n+    \/\/ Save the markWord of promotion-failed objs in _preserved_marks for later\n+    \/\/ restoration. This way we don't have to walk the young-gen to locate\n+    \/\/ these promotion-failed objs.\n+    _preserved_marks->push_always(obj, obj_mark);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.cpp","additions":16,"deletions":34,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -103,1 +103,1 @@\n-      Node* new_val = kit->dstore_rounding(val.node());\n+      Node* new_val = kit->dprecision_rounding(val.node());\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -94,1 +94,1 @@\n-  Node* card_offset = __ URShiftX(cast, __ ConI(CardTable::card_shift));\n+  Node* card_offset = __ URShiftX(cast, __ ConI(CardTable::card_shift()));\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/cardTableBarrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -65,1 +65,1 @@\n-class ParallelObjectIterator : public CHeapObj<mtGC> {\n+class ParallelObjectIteratorImpl : public CHeapObj<mtGC> {\n@@ -67,0 +67,1 @@\n+  virtual ~ParallelObjectIteratorImpl() {}\n@@ -68,1 +69,13 @@\n-  virtual ~ParallelObjectIterator() {}\n+};\n+\n+\/\/ User facing parallel object iterator. This is a StackObj, which ensures that\n+\/\/ the _impl is allocated and deleted in the scope of this object. This ensures\n+\/\/ the life cycle of the implementation is as required by ThreadsListHandle,\n+\/\/ which is sometimes used by the root iterators.\n+class ParallelObjectIterator : public StackObj {\n+  ParallelObjectIteratorImpl* _impl;\n+\n+public:\n+  ParallelObjectIterator(uint thread_num);\n+  ~ParallelObjectIterator();\n+  void object_iterate(ObjectClosure* cl, uint worker_id);\n@@ -80,1 +93,1 @@\n-class CollectedHeap : public CHeapObj<mtInternal> {\n+class CollectedHeap : public CHeapObj<mtGC> {\n@@ -85,0 +98,1 @@\n+  friend class ParallelObjectIterator;\n@@ -279,1 +293,4 @@\n-  virtual size_t min_dummy_object_size() const;\n+  static constexpr size_t min_dummy_object_size() {\n+    return oopDesc::header_size();\n+  }\n+\n@@ -388,1 +405,2 @@\n-  virtual ParallelObjectIterator* parallel_object_iterator(uint thread_num) {\n+ protected:\n+  virtual ParallelObjectIteratorImpl* parallel_object_iterator(uint thread_num) {\n@@ -392,0 +410,1 @@\n+ public:\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":25,"deletions":6,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -721,1 +721,1 @@\n-  if (node->Opcode() == Op_ShenandoahLoadReferenceBarrier) return true;\n+  if (node->Opcode() == Op_ShenandoahLoadReferenceBarrier || node->Opcode() == Op_ShenandoahIUBarrier) return true;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahBarrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -57,1 +57,0 @@\n-    DEBUG_ONLY(verify_raw_mem(C->root());)\n@@ -966,1 +965,1 @@\n-void ShenandoahBarrierC2Support::call_lrb_stub(Node*& ctrl, Node*& val, Node* load_addr, Node*& result_mem, Node* raw_mem,\n+void ShenandoahBarrierC2Support::call_lrb_stub(Node*& ctrl, Node*& val, Node* load_addr,\n@@ -971,7 +970,0 @@\n-  \/\/ The slow path stub consumes and produces raw memory in addition\n-  \/\/ to the existing memory edges\n-  Node* base = find_bottom_mem(ctrl, phase);\n-  MergeMemNode* mm = MergeMemNode::make(base);\n-  mm->set_memory_at(Compile::AliasIdxRaw, raw_mem);\n-  phase->register_new_node(mm, ctrl);\n-\n@@ -1015,1 +1007,1 @@\n-  call->init_req(TypeFunc::Memory, mm);\n+  call->init_req(TypeFunc::Memory, phase->C->top());\n@@ -1023,2 +1015,0 @@\n-  result_mem = new ProjNode(call, TypeFunc::Memory);\n-  phase->register_new_node(result_mem, call);\n@@ -1341,1 +1331,0 @@\n-\n@@ -1345,2 +1334,0 @@\n-    Node* init_raw_mem = raw_mem;\n-    Node* raw_mem_for_ctrl = fixer.find_mem(ctrl, NULL);\n@@ -1359,1 +1346,0 @@\n-    Node* raw_mem_phi = PhiNode::make(region, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);\n@@ -1372,1 +1358,0 @@\n-    raw_mem_phi->init_req(_heap_stable, raw_mem);\n@@ -1384,1 +1369,0 @@\n-      raw_mem_phi->init_req(_not_cset, raw_mem);\n@@ -1388,1 +1372,0 @@\n-      raw_mem_phi->del_req(_not_cset);\n@@ -1429,1 +1412,1 @@\n-    call_lrb_stub(ctrl, val, addr, result_mem, raw_mem, lrb->decorators(), phase);\n+    call_lrb_stub(ctrl, val, addr, lrb->decorators(), phase);\n@@ -1432,1 +1415,0 @@\n-    raw_mem_phi->init_req(_evac_path, result_mem);\n@@ -1437,1 +1419,0 @@\n-    phase->register_new_node(raw_mem_phi, region);\n@@ -1450,1 +1431,1 @@\n-      assert(n != init_raw_mem, \"should leave input raw mem above the barrier\");\n+      assert(n != raw_mem, \"should leave input raw mem above the barrier\");\n@@ -1454,8 +1435,0 @@\n-\n-    \/\/ The slow path call produces memory: hook the raw memory phi\n-    \/\/ from the expanded load reference barrier with the rest of the graph\n-    \/\/ which may require adding memory phis at every post dominated\n-    \/\/ region and at enclosing loop heads. Use the memory state\n-    \/\/ collected in memory_nodes to fix the memory graph. Update that\n-    \/\/ memory state as we go.\n-    fixer.fix_mem(ctrl, region, init_raw_mem, raw_mem_for_ctrl, raw_mem_phi, uses);\n@@ -1902,99 +1875,0 @@\n-#ifdef ASSERT\n-void ShenandoahBarrierC2Support::verify_raw_mem(RootNode* root) {\n-  const bool trace = false;\n-  ResourceMark rm;\n-  Unique_Node_List nodes;\n-  Unique_Node_List controls;\n-  Unique_Node_List memories;\n-\n-  nodes.push(root);\n-  for (uint next = 0; next < nodes.size(); next++) {\n-    Node *n  = nodes.at(next);\n-    if (ShenandoahBarrierSetC2::is_shenandoah_lrb_call(n)) {\n-      controls.push(n);\n-      if (trace) { tty->print(\"XXXXXX verifying\"); n->dump(); }\n-      for (uint next2 = 0; next2 < controls.size(); next2++) {\n-        Node *m = controls.at(next2);\n-        for (DUIterator_Fast imax, i = m->fast_outs(imax); i < imax; i++) {\n-          Node* u = m->fast_out(i);\n-          if (u->is_CFG() && !u->is_Root() &&\n-              !(u->Opcode() == Op_CProj && u->in(0)->Opcode() == Op_NeverBranch && u->as_Proj()->_con == 1) &&\n-              !(u->is_Region() && u->unique_ctrl_out()->Opcode() == Op_Halt)) {\n-            if (trace) { tty->print(\"XXXXXX pushing control\"); u->dump(); }\n-            controls.push(u);\n-          }\n-        }\n-      }\n-      memories.push(n->as_Call()->proj_out(TypeFunc::Memory));\n-      for (uint next2 = 0; next2 < memories.size(); next2++) {\n-        Node *m = memories.at(next2);\n-        assert(m->bottom_type() == Type::MEMORY, \"\");\n-        for (DUIterator_Fast imax, i = m->fast_outs(imax); i < imax; i++) {\n-          Node* u = m->fast_out(i);\n-          if (u->bottom_type() == Type::MEMORY && (u->is_Mem() || u->is_ClearArray())) {\n-            if (trace) { tty->print(\"XXXXXX pushing memory\"); u->dump(); }\n-            memories.push(u);\n-          } else if (u->is_LoadStore()) {\n-            if (trace) { tty->print(\"XXXXXX pushing memory\"); u->find_out_with(Op_SCMemProj)->dump(); }\n-            memories.push(u->find_out_with(Op_SCMemProj));\n-          } else if (u->is_MergeMem() && u->as_MergeMem()->memory_at(Compile::AliasIdxRaw) == m) {\n-            if (trace) { tty->print(\"XXXXXX pushing memory\"); u->dump(); }\n-            memories.push(u);\n-          } else if (u->is_Phi()) {\n-            assert(u->bottom_type() == Type::MEMORY, \"\");\n-            if (u->adr_type() == TypeRawPtr::BOTTOM || u->adr_type() == TypePtr::BOTTOM) {\n-              assert(controls.member(u->in(0)), \"\");\n-              if (trace) { tty->print(\"XXXXXX pushing memory\"); u->dump(); }\n-              memories.push(u);\n-            }\n-          } else if (u->is_SafePoint() || u->is_MemBar()) {\n-            for (DUIterator_Fast jmax, j = u->fast_outs(jmax); j < jmax; j++) {\n-              Node* uu = u->fast_out(j);\n-              if (uu->bottom_type() == Type::MEMORY) {\n-                if (trace) { tty->print(\"XXXXXX pushing memory\"); uu->dump(); }\n-                memories.push(uu);\n-              }\n-            }\n-          }\n-        }\n-      }\n-      for (uint next2 = 0; next2 < controls.size(); next2++) {\n-        Node *m = controls.at(next2);\n-        if (m->is_Region()) {\n-          bool all_in = true;\n-          for (uint i = 1; i < m->req(); i++) {\n-            if (!controls.member(m->in(i))) {\n-              all_in = false;\n-              break;\n-            }\n-          }\n-          if (trace) { tty->print(\"XXX verifying %s\", all_in ? \"all in\" : \"\"); m->dump(); }\n-          bool found_phi = false;\n-          for (DUIterator_Fast jmax, j = m->fast_outs(jmax); j < jmax && !found_phi; j++) {\n-            Node* u = m->fast_out(j);\n-            if (u->is_Phi() && memories.member(u)) {\n-              found_phi = true;\n-              for (uint i = 1; i < u->req() && found_phi; i++) {\n-                Node* k = u->in(i);\n-                if (memories.member(k) != controls.member(m->in(i))) {\n-                  found_phi = false;\n-                }\n-              }\n-            }\n-          }\n-          assert(found_phi || all_in, \"\");\n-        }\n-      }\n-      controls.clear();\n-      memories.clear();\n-    }\n-    for( uint i = 0; i < n->len(); ++i ) {\n-      Node *m = n->in(i);\n-      if (m != NULL) {\n-        nodes.push(m);\n-      }\n-    }\n-  }\n-}\n-#endif\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahSupport.cpp","additions":4,"deletions":130,"binary":false,"changes":134,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrier.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -93,0 +93,1 @@\n+    java_lang_Thread_currentThread,                             \/\/ implementation of java.lang.Thread.currentThread()\n","filename":"src\/hotspot\/share\/interpreter\/abstractInterpreter.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1033,1 +1033,0 @@\n-      \/\/ The return type of arraylength is wrong in the bytecodes table (T_VOID).\n","filename":"src\/hotspot\/share\/interpreter\/bytecodeUtils.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -474,1 +474,1 @@\n-  def(_arraylength         , \"arraylength\"         , \"b\"    , NULL    , T_VOID   ,  0, true );\n+  def(_arraylength         , \"arraylength\"         , \"b\"    , NULL    , T_INT    ,  0, true );\n","filename":"src\/hotspot\/share\/interpreter\/bytecodes.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,2 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n","filename":"src\/hotspot\/share\/interpreter\/bytecodes.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -660,1 +660,5 @@\n-    note_trap(current, Deoptimization::Reason_class_check);\n+    if (s == vmSymbols::java_lang_ArrayStoreException()) {\n+      note_trap(current, Deoptimization::Reason_array_check);\n+    } else {\n+      note_trap(current, Deoptimization::Reason_class_check);\n+    }\n@@ -1091,1 +1095,12 @@\n-                                 CHECK);\n+                                 THREAD);\n+\n+    if (HAS_PENDING_EXCEPTION) {\n+      if (ProfileTraps && PENDING_EXCEPTION->klass()->name() == vmSymbols::java_lang_NullPointerException()) {\n+        \/\/ Preserve the original exception across the call to note_trap()\n+        PreserveExceptionMark pm(current);\n+        \/\/ Recording the trap will help the compiler to potentially recognize this exception as \"hot\"\n+        note_trap(current, Deoptimization::Reason_null_check);\n+      }\n+      return;\n+    }\n+\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":17,"deletions":2,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -205,1 +205,3 @@\n-\n+#ifdef AMD64\n+  method_entry(java_lang_Thread_currentThread)\n+#endif\n@@ -435,0 +437,5 @@\n+#ifdef AMD64\n+  case Interpreter::java_lang_Thread_currentThread\n+                                           : entry_point = generate_currentThread(); break;\n+#endif\n+\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreterGenerator.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -2379,1 +2379,1 @@\n-C2V_VMENTRY_0(jlong, translate, (JNIEnv* env, jobject, jobject obj_handle))\n+C2V_VMENTRY_0(jlong, translate, (JNIEnv* env, jobject, jobject obj_handle, jboolean callPostTranslation))\n@@ -2430,1 +2430,3 @@\n-      if (nm == NULL) {\n+      if (result.is_null()) {\n+        \/\/ exception occurred (e.g. OOME) creating a new HotSpotNmethod\n+      } else if (nm == NULL) {\n@@ -2453,0 +2455,7 @@\n+  if (callPostTranslation) {\n+    peerEnv->call_HotSpotJVMCIRuntime_postTranslation(result, JVMCI_CHECK_0);\n+  }\n+  \/\/ Propagate any exception that occurred while creating the translated object\n+  if (peerEnv->transfer_pending_exception(thread, thisEnv)) {\n+    return 0L;\n+  }\n@@ -2793,1 +2802,1 @@\n-  {CC \"translate\",                                    CC \"(\" OBJECT \")J\",                                                                   FN_PTR(translate)},\n+  {CC \"translate\",                                    CC \"(\" OBJECT \"Z)J\",                                                                  FN_PTR(translate)},\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":13,"deletions":4,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -563,2 +563,2 @@\n-  declare_constant(Deoptimization::Reason_LIMIT)                          \\\n-  declare_constant(Deoptimization::_support_large_access_byte_array_virtualization)               \\\n+  declare_constant(Deoptimization::Reason_TRAP_HISTORY_LENGTH)            \\\n+  declare_constant(Deoptimization::_support_large_access_byte_array_virtualization) \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n@@ -30,0 +30,2 @@\n+class outputStream;\n+\n@@ -187,1 +189,0 @@\n-  LOG_TAG(time) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -174,2 +174,0 @@\n-#if INCLUDE_NMT\n-\n@@ -178,6 +176,0 @@\n-#else\n-\n-const bool NMT_track_callsite = false;\n-\n-#endif \/\/ INCLUDE_NMT\n-\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -716,12 +716,6 @@\n-      ParallelObjectIterator* poi = Universe::heap()->parallel_object_iterator(workers->active_workers());\n-      if (poi != NULL) {\n-        \/\/ The GC supports parallel object iteration.\n-\n-        ParHeapInspectTask task(poi, cit, filter);\n-        \/\/ Run task with the active workers.\n-        workers->run_task(&task);\n-\n-        delete poi;\n-        if (task.success()) {\n-          return task.missed_count();\n-        }\n+      ParallelObjectIterator poi(workers->active_workers());\n+      ParHeapInspectTask task(&poi, cit, filter);\n+      \/\/ Run task with the active workers.\n+      workers->run_task(&task);\n+      if (task.success()) {\n+        return task.missed_count();\n","filename":"src\/hotspot\/share\/memory\/heapInspection.cpp","additions":6,"deletions":12,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -113,0 +113,5 @@\n+\/\/ Message details for OOME objects, preallocate these objects since they could be\n+\/\/ used when throwing OOME, we should try to avoid further allocation in such case\n+OopHandle Universe::_msg_metaspace;\n+OopHandle Universe::_msg_class_metaspace;\n+\n@@ -580,1 +585,0 @@\n-\n@@ -680,0 +684,8 @@\n+bool Universe::is_out_of_memory_error_metaspace(oop ex_obj) {\n+  return java_lang_Throwable::message(ex_obj) == _msg_metaspace.resolve();\n+}\n+\n+bool Universe::is_out_of_memory_error_class_metaspace(oop ex_obj) {\n+  return java_lang_Throwable::message(ex_obj) == _msg_class_metaspace.resolve();\n+}\n+\n@@ -699,0 +711,1 @@\n+  _msg_metaspace = OopHandle(vm_global(), msg());\n@@ -702,0 +715,1 @@\n+  _msg_class_metaspace = OopHandle(vm_global(), msg());\n@@ -774,0 +788,4 @@\n+#ifdef _LP64\n+  MetaspaceShared::adjust_heap_sizes_for_dumping();\n+#endif \/\/ _LP64\n+\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":19,"deletions":1,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -139,0 +139,4 @@\n+  \/\/ preallocated message detail strings for error objects\n+  static OopHandle _msg_metaspace;\n+  static OopHandle _msg_class_metaspace;\n+\n@@ -317,0 +321,4 @@\n+  \/\/ If it's a certain type of OOME object\n+  static bool is_out_of_memory_error_metaspace(oop ex_obj);\n+  static bool is_out_of_memory_error_class_metaspace(oop ex_obj);\n+\n","filename":"src\/hotspot\/share\/memory\/universe.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n","filename":"src\/hotspot\/share\/oops\/access.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n","filename":"src\/hotspot\/share\/oops\/accessDecorators.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1224,1 +1224,0 @@\n-  int argc;\n@@ -1227,1 +1226,1 @@\n-  \/\/ tag at index, start..end in range [0..argc],\n+  \/\/ tag at index, start..end in range [0..this_cp->bootstrap_argument_count],\n@@ -1233,1 +1232,1 @@\n-      (end_arg > (argc = this_cp->bootstrap_argument_count_at(index))) ||\n+      (end_arg > this_cp->bootstrap_argument_count_at(index)) ||\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -145,0 +145,1 @@\n+bool InstanceKlass::_finalization_enabled = true;\n@@ -2612,1 +2613,3 @@\n-  it->push(&_fields);\n+\n+  \/\/ _fields might be written into by Rewriter::scan_method() -> fd.set_has_initialized_final_update()\n+  it->push(&_fields, MetaspaceClosure::_writable);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -279,10 +279,9 @@\n-    _misc_has_resolved_methods                = 1 << 13, \/\/ resolved methods table entries added for this class\n-    _misc_has_contended_annotations           = 1 << 14,  \/\/ has @Contended annotation\n-    _misc_has_inline_type_fields              = 1 << 15, \/\/ has inline fields and related embedded section is not empty\n-    _misc_is_empty_inline_type                = 1 << 16, \/\/ empty inline type (*)\n-    _misc_is_naturally_atomic                 = 1 << 17, \/\/ loaded\/stored in one instruction\n-    _misc_is_declared_atomic                  = 1 << 18, \/\/ implements jl.NonTearable\n-    _misc_invalid_inline_super                = 1 << 19, \/\/ invalid super type for an inline type\n-    _misc_invalid_identity_super              = 1 << 20, \/\/ invalid super type for an identity type\n-    _misc_has_injected_identityObject         = 1 << 21, \/\/ IdentityObject has been injected by the JVM\n-    _misc_has_injected_primitiveObject        = 1 << 22  \/\/ PrimitiveObject has been injected by the JVM\n+    _misc_has_contended_annotations           = 1 << 13, \/\/ has @Contended annotation\n+    _misc_has_inline_type_fields              = 1 << 14, \/\/ has inline fields and related embedded section is not empty\n+    _misc_is_empty_inline_type                = 1 << 15, \/\/ empty inline type (*)\n+    _misc_is_naturally_atomic                 = 1 << 16, \/\/ loaded\/stored in one instruction\n+    _misc_is_declared_atomic                  = 1 << 17, \/\/ implements jl.NonTearable\n+    _misc_invalid_inline_super                = 1 << 18, \/\/ invalid super type for an inline type\n+    _misc_invalid_identity_super              = 1 << 19, \/\/ invalid super type for an identity type\n+    _misc_has_injected_identityObject         = 1 << 20, \/\/ IdentityObject has been injected by the JVM\n+    _misc_has_injected_primitiveObject        = 1 << 21  \/\/ PrimitiveObject has been injected by the JVM\n@@ -372,0 +371,3 @@\n+  \/\/ Controls finalizer registration\n+  static bool _finalization_enabled;\n+\n@@ -373,0 +375,7 @@\n+\n+  \/\/ Queries finalization state\n+  static bool is_finalization_enabled() { return _finalization_enabled; }\n+\n+  \/\/ Sets finalization state\n+  static void set_finalization_enabled(bool val) { _finalization_enabled = val; }\n+\n@@ -399,4 +408,0 @@\n-  void clear_shared_loading_failed() {\n-    _misc_flags &= ~_misc_shared_loading_failed;\n-  }\n-\n@@ -411,0 +416,1 @@\n+    assert(!has_nonstatic_fields(), \"set once\");\n@@ -413,2 +419,0 @@\n-    } else {\n-      _misc_flags &= ~_misc_has_nonstatic_fields;\n@@ -678,0 +682,1 @@\n+    assert(!should_verify_class(), \"set once\");\n@@ -680,2 +685,0 @@\n-    } else {\n-      _misc_flags &= ~_misc_should_verify_class;\n@@ -814,0 +817,1 @@\n+    assert(!is_contended(), \"set once\");\n@@ -816,2 +820,0 @@\n-    } else {\n-      _misc_flags &= ~_misc_is_contended;\n@@ -852,0 +854,1 @@\n+    assert(!has_contended_annotations(), \"set once\");\n@@ -854,2 +857,0 @@\n-    } else {\n-      _misc_flags &= ~_misc_has_contended_annotations;\n@@ -908,1 +909,1 @@\n-    return (_misc_flags & _misc_has_resolved_methods) != 0;\n+    return _access_flags.has_resolved_methods();\n@@ -912,1 +913,1 @@\n-    _misc_flags |= _misc_has_resolved_methods;\n+    _access_flags.set_has_resolved_methods();\n@@ -982,0 +983,1 @@\n+    assert(!has_nonstatic_concrete_methods(), \"set once\");\n@@ -984,2 +986,0 @@\n-    } else {\n-      _misc_flags &= ~_misc_has_nonstatic_concrete_methods;\n@@ -993,0 +993,1 @@\n+    assert(!declares_nonstatic_concrete_methods(), \"set once\");\n@@ -995,2 +996,0 @@\n-    } else {\n-      _misc_flags &= ~_misc_declares_nonstatic_concrete_methods;\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":27,"deletions":28,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -121,2 +121,2 @@\n-  \/\/ vtable length\n-  int _vtable_len;\n+  \/\/ Processed access flags, for use by Class.getModifiers.\n+  jint        _modifier_flags;\n@@ -158,1 +158,4 @@\n-  jint        _modifier_flags;  \/\/ Processed access flags, for use by Class.getModifiers.\n+  int _vtable_len;              \/\/ vtable length. This field may be read very often when we\n+                                \/\/ have lots of itable dispatches (e.g., lambdas and streams).\n+                                \/\/ Keep it away from the beginning of a Klass to avoid cacheline\n+                                \/\/ contention that may happen when a nearby object is modified.\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -34,4 +34,1 @@\n-\/\/ This loads the klass's holder as a phantom. This is useful when a weak Klass\n-\/\/ pointer has been \"peeked\" and then must be kept alive before it may\n-\/\/ be used safely.  All uses of klass_holder need to apply the appropriate barriers,\n-\/\/ except during GC.\n+\/\/ This loads and keeps the klass's loader alive.\n@@ -39,1 +36,1 @@\n-  return class_loader_data()->holder_phantom();\n+  return class_loader_data()->holder();\n","filename":"src\/hotspot\/share\/oops\/klass.inline.hpp","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -337,8 +337,5 @@\n-#ifdef ASSERT\n-  {\n-    ResourceMark rm;\n-    assert(is_native() && bcp == code_base() || contains(bcp) || VMError::is_error_reported(),\n-           \"bcp doesn't belong to this method: bcp: \" INTPTR_FORMAT \", method: %s\",\n-           p2i(bcp), name_and_sig_as_C_string());\n-  }\n-#endif\n+  \/\/ Do not have a ResourceMark here because AsyncGetCallTrace stack walking code\n+  \/\/ may call this after interrupting a nested ResourceMark.\n+  assert(is_native() && bcp == code_base() || contains(bcp) || VMError::is_error_reported(),\n+         \"bcp doesn't belong to this method. bcp: \" INTPTR_FORMAT, p2i(bcp));\n+\n@@ -854,0 +851,12 @@\n+\/**\n+ *  Returns false if this is one of specially treated methods for\n+ *  which we have to provide stack trace in throw in compiled code.\n+ *  Returns true otherwise.\n+ *\/\n+bool Method::can_omit_stack_trace() {\n+  if (klass_name() == vmSymbols::sun_invoke_util_ValueConversions()) {\n+    return false; \/\/ All methods in sun.invoke.util.ValueConversions\n+  }\n+  return true;\n+}\n+\n@@ -1242,1 +1251,1 @@\n-  if (_i2i_entry != NULL) {\n+  if (adapter() != NULL) {\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":19,"deletions":10,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -620,0 +620,3 @@\n+  \/\/ true if method can omit stack trace in throw in compiled code.\n+  bool can_omit_stack_trace();\n+\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1633,12 +1633,0 @@\n-bool MethodData::profile_memory_access(const methodHandle& m, int bci) {\n-  Bytecode_invoke inv(m , bci);\n-  if (inv.is_invokestatic()) {\n-    if (inv.klass() == vmSymbols::jdk_incubator_foreign_MemoryAccess()) {\n-      if (inv.name()->starts_with(\"get\") || inv.name()->starts_with(\"set\")) {\n-        return true;\n-      }\n-    }\n-  }\n-  return false;\n-}\n-\n@@ -1674,4 +1662,0 @@\n-  if (profile_memory_access(m, bci)) {\n-    return true;\n-  }\n-\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":0,"deletions":16,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -2129,1 +2130,1 @@\n-    _trap_hist_limit    = 25 JVMCI_ONLY(+5),   \/\/ decoupled from Deoptimization::Reason_LIMIT\n+    _trap_hist_limit    = Deoptimization::Reason_TRAP_HISTORY_LENGTH,\n@@ -2144,0 +2145,1 @@\n+      \/\/ JVMCI separates trap history for OSR compilations from normal compilations\n@@ -2160,1 +2162,1 @@\n-      assert((uint)reason < JVMCI_ONLY(2*) _trap_hist_limit, \"oob\");\n+      assert((uint)reason < ARRAY_SIZE(_trap_hist._array), \"oob\");\n@@ -2167,1 +2169,1 @@\n-      assert((uint)reason < JVMCI_ONLY(2*) _trap_hist_limit, \"oob\");\n+      assert((uint)reason < ARRAY_SIZE(_trap_hist._array), \"oob\");\n","filename":"src\/hotspot\/share\/oops\/methodData.hpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -104,2 +104,0 @@\n-  inline int klass_gap() const;\n-  inline void set_klass_gap(int z);\n@@ -109,1 +107,1 @@\n-  static int header_size() { return sizeof(oopDesc)\/HeapWordSize; }\n+  static constexpr int header_size() { return sizeof(oopDesc)\/HeapWordSize; }\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -128,4 +128,0 @@\n-int oopDesc::klass_gap() const {\n-  return *(int*)(((intptr_t)this) + klass_gap_offset_in_bytes());\n-}\n-\n@@ -138,4 +134,0 @@\n-void oopDesc::set_klass_gap(int v) {\n-  set_klass_gap((HeapWord*)this, v);\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -266,1 +266,1 @@\n-Node *AddINode::Ideal(PhaseGVN *phase, bool can_reshape) {\n+Node* AddNode::IdealIL(PhaseGVN* phase, bool can_reshape, BasicType bt) {\n@@ -272,1 +272,1 @@\n-  if ( op1 == Op_AddI && op2 == Op_SubI ) {\n+  if (op1 == Op_Add(bt) && op2 == Op_Sub(bt)) {\n@@ -279,5 +279,6 @@\n-  if( op1 == Op_SubI ) {\n-    const Type *t_sub1 = phase->type( in1->in(1) );\n-    const Type *t_2    = phase->type( in2        );\n-    if( t_sub1->singleton() && t_2->singleton() && t_sub1 != Type::TOP && t_2 != Type::TOP )\n-      return new SubINode(phase->makecon( add_ring( t_sub1, t_2 ) ), in1->in(2) );\n+  if (op1 == Op_Sub(bt)) {\n+    const Type* t_sub1 = phase->type(in1->in(1));\n+    const Type* t_2    = phase->type(in2       );\n+    if (t_sub1->singleton() && t_2->singleton() && t_sub1 != Type::TOP && t_2 != Type::TOP) {\n+      return SubNode::make(phase->makecon(add_ring(t_sub1, t_2)), in1->in(2), bt);\n+    }\n@@ -285,1 +286,1 @@\n-    if( op2 == Op_SubI ) {\n+    if (op2 == Op_Sub(bt)) {\n@@ -289,3 +290,3 @@\n-      Node *sub  = new SubINode(NULL, NULL);\n-      sub->init_req(1, phase->transform(new AddINode(in1->in(1), in2->in(1) ) ));\n-      sub->init_req(2, phase->transform(new AddINode(in1->in(2), in2->in(2) ) ));\n+      Node* sub = SubNode::make(NULL, NULL, bt);\n+      sub->init_req(1, phase->transform(AddNode::make(in1->in(1), in2->in(1), bt)));\n+      sub->init_req(2, phase->transform(AddNode::make(in1->in(2), in2->in(2), bt)));\n@@ -295,3 +296,3 @@\n-    if( op2 == Op_AddI && in1->in(2) == in2->in(1) ) {\n-      assert(in1->in(1) != this && in2->in(2) != this,\"dead loop in AddINode::Ideal\");\n-      return new AddINode(in1->in(1), in2->in(2));\n+    if (op2 == Op_Add(bt) && in1->in(2) == in2->in(1)) {\n+      assert(in1->in(1) != this && in2->in(2) != this,\"dead loop in AddINode::Ideal\/AddLNode::Ideal\");\n+      return AddNode::make(in1->in(1), in2->in(2), bt);\n@@ -300,13 +301,3 @@\n-    if( op2 == Op_AddI && in1->in(2) == in2->in(2) ) {\n-      assert(in1->in(1) != this && in2->in(1) != this,\"dead loop in AddINode::Ideal\");\n-      return new AddINode(in1->in(1), in2->in(1));\n-    }\n-    \/\/ Convert \"(a-b)+(b-c)\" into \"(a-c)\"\n-    if( op2 == Op_SubI && in1->in(2) == in2->in(1) ) {\n-      assert(in1->in(1) != this && in2->in(2) != this,\"dead loop in AddINode::Ideal\");\n-      return new SubINode(in1->in(1), in2->in(2));\n-    }\n-    \/\/ Convert \"(a-b)+(c-a)\" into \"(c-b)\"\n-    if( op2 == Op_SubI && in1->in(1) == in2->in(2) ) {\n-      assert(in1->in(2) != this && in2->in(1) != this,\"dead loop in AddINode::Ideal\");\n-      return new SubINode(in2->in(1), in1->in(2));\n+    if (op2 == Op_Add(bt) && in1->in(2) == in2->in(2)) {\n+      assert(in1->in(1) != this && in2->in(1) != this,\"dead loop in AddINode::Ideal\/AddLNode::Ideal\");\n+      return AddNode::make(in1->in(1), in2->in(1), bt);\n@@ -317,2 +308,3 @@\n-  if( op2 == Op_SubI && phase->type(in2->in(1)) == TypeInt::ZERO )\n-    return new SubINode(in1, in2->in(2) );\n+  if (op2 == Op_Sub(bt) && phase->type(in2->in(1)) == TypeInteger::zero(bt)) {\n+    return SubNode::make(in1, in2->in(2), bt);\n+  }\n@@ -321,2 +313,3 @@\n-  if( op1 == Op_SubI && phase->type(in1->in(1)) == TypeInt::ZERO )\n-    return new SubINode( in2, in1->in(2) );\n+  if (op1 == Op_Sub(bt) && phase->type(in1->in(1)) == TypeInteger::zero(bt)) {\n+    return SubNode::make(in2, in1->in(2), bt);\n+  }\n@@ -325,1 +318,1 @@\n-  if (op1 == Op_MulI && op2 == Op_MulI) {\n+  if (op1 == Op_Mul(bt) && op2 == Op_Mul(bt)) {\n@@ -353,2 +346,2 @@\n-      Node* add = phase->transform(new AddINode(add_in1, add_in2));\n-      return new MulINode(mul_in, add);\n+      Node* add = phase->transform(AddNode::make(add_in1, add_in2, bt));\n+      return MulNode::make(mul_in, add, bt);\n@@ -358,0 +351,38 @@\n+  \/\/ Convert (x >>> rshift) + (x << lshift) into RotateRight(x, rshift)\n+  if (Matcher::match_rule_supported(Op_RotateRight) &&\n+      ((op1 == Op_URShift(bt) && op2 == Op_LShift(bt)) || (op1 == Op_LShift(bt) && op2 == Op_URShift(bt))) &&\n+      in1->in(1) != NULL && in1->in(1) == in2->in(1)) {\n+    Node* rshift = op1 == Op_URShift(bt) ? in1->in(2) : in2->in(2);\n+    Node* lshift = op1 == Op_URShift(bt) ? in2->in(2) : in1->in(2);\n+    if (rshift != NULL && lshift != NULL) {\n+      const TypeInt* rshift_t = phase->type(rshift)->isa_int();\n+      const TypeInt* lshift_t = phase->type(lshift)->isa_int();\n+      int bits = bt == T_INT ? 32 : 64;\n+      int mask = bt == T_INT ? 0x1F : 0x3F;\n+      if (lshift_t != NULL && lshift_t->is_con() &&\n+          rshift_t != NULL && rshift_t->is_con() &&\n+          ((lshift_t->get_con() & mask) == (bits - (rshift_t->get_con() & mask)))) {\n+        return new RotateRightNode(in1->in(1), phase->intcon(rshift_t->get_con() & mask), TypeInteger::bottom(bt));\n+      }\n+    }\n+  }\n+\n+  \/\/ Convert (~x+c) into (c-1)-x. Note there isn't a bitwise not\n+  \/\/ bytecode, \"~x\" would typically represented as \"x^(-1)\", so (~x+c)\n+  \/\/ will be (x^(-1))+c.\n+  if (op1 == Op_Xor(bt) &&\n+      (in2->Opcode() == Op_ConI || in2->Opcode() == Op_ConL) &&\n+      phase->type(in1->in(2)) == TypeInteger::minus_1(bt)) {\n+    Node* c_minus_one = phase->makecon(add_ring(phase->type(in(2)), TypeInteger::minus_1(bt)));\n+    return SubNode::make(c_minus_one, in1->in(1), bt);\n+  }\n+  return AddNode::Ideal(phase, can_reshape);\n+}\n+\n+\n+Node* AddINode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* in1 = in(1);\n+  Node* in2 = in(2);\n+  int op1 = in1->Opcode();\n+  int op2 = in2->Opcode();\n+\n@@ -369,27 +400,10 @@\n-  if( op1 == Op_URShiftI && op2 == Op_ConI &&\n-      in1->in(2)->Opcode() == Op_ConI ) {\n-    jint z = phase->type( in1->in(2) )->is_int()->get_con() & 0x1f; \/\/ only least significant 5 bits matter\n-    jint y = phase->type( in2 )->is_int()->get_con();\n-\n-    if( z < 5 && -5 < y && y < 0 ) {\n-      const Type *t_in11 = phase->type(in1->in(1));\n-      if( t_in11 != Type::TOP && (t_in11->is_int()->_lo >= -(y << z)) ) {\n-        Node *a = phase->transform( new AddINode( in1->in(1), phase->intcon(y<<z) ) );\n-        return new URShiftINode( a, in1->in(2) );\n-      }\n-    }\n-  }\n-\n-  \/\/ Convert (x >>> rshift) + (x << lshift) into RotateRight(x, rshift)\n-  if (Matcher::match_rule_supported(Op_RotateRight) &&\n-      ((op1 == Op_URShiftI && op2 == Op_LShiftI) || (op1 == Op_LShiftI && op2 == Op_URShiftI)) &&\n-      in1->in(1) != NULL && in1->in(1) == in2->in(1)) {\n-    Node* rshift = op1 == Op_URShiftI ? in1->in(2) : in2->in(2);\n-    Node* lshift = op1 == Op_URShiftI ? in2->in(2) : in1->in(2);\n-    if (rshift != NULL && lshift != NULL) {\n-      const TypeInt* rshift_t = phase->type(rshift)->isa_int();\n-      const TypeInt* lshift_t = phase->type(lshift)->isa_int();\n-      if (lshift_t != NULL && lshift_t->is_con() &&\n-          rshift_t != NULL && rshift_t->is_con() &&\n-          ((lshift_t->get_con() & 0x1F) == (32 - (rshift_t->get_con() & 0x1F)))) {\n-        return new RotateRightNode(in1->in(1), phase->intcon(rshift_t->get_con() & 0x1F), TypeInt::INT);\n+  if (op1 == Op_URShiftI && op2 == Op_ConI &&\n+      in1->in(2)->Opcode() == Op_ConI) {\n+    jint z = phase->type(in1->in(2))->is_int()->get_con() & 0x1f; \/\/ only least significant 5 bits matter\n+    jint y = phase->type(in2)->is_int()->get_con();\n+\n+    if (z < 5 && -5 < y && y < 0) {\n+      const Type* t_in11 = phase->type(in1->in(1));\n+      if( t_in11 != Type::TOP && (t_in11->is_int()->_lo >= -(y << z))) {\n+        Node* a = phase->transform(new AddINode( in1->in(1), phase->intcon(y<<z)));\n+        return new URShiftINode(a, in1->in(2));\n@@ -400,8 +414,1 @@\n-  \/\/ Convert (~x+1) into -x. Note there isn't a bitwise not bytecode,\n-  \/\/ \"~x\" would typically represented as \"x^(-1)\", so (~x+1) will\n-  \/\/ be (x^(-1))+1.\n-  if (op1 == Op_XorI && phase->type(in2) == TypeInt::ONE &&\n-      phase->type(in1->in(2)) == TypeInt::MINUS_1) {\n-    return new SubINode(phase->makecon(TypeInt::ZERO), in1->in(1));\n-  }\n-  return AddNode::Ideal(phase, can_reshape);\n+  return AddNode::IdealIL(phase, can_reshape, T_INT);\n@@ -454,118 +461,2 @@\n-Node *AddLNode::Ideal(PhaseGVN *phase, bool can_reshape) {\n-  Node* in1 = in(1);\n-  Node* in2 = in(2);\n-  int op1 = in1->Opcode();\n-  int op2 = in2->Opcode();\n-  \/\/ Fold (con1-x)+con2 into (con1+con2)-x\n-  if ( op1 == Op_AddL && op2 == Op_SubL ) {\n-    \/\/ Swap edges to try optimizations below\n-    in1 = in2;\n-    in2 = in(1);\n-    op1 = op2;\n-    op2 = in2->Opcode();\n-  }\n-  \/\/ Fold (con1-x)+con2 into (con1+con2)-x\n-  if( op1 == Op_SubL ) {\n-    const Type *t_sub1 = phase->type( in1->in(1) );\n-    const Type *t_2    = phase->type( in2        );\n-    if( t_sub1->singleton() && t_2->singleton() && t_sub1 != Type::TOP && t_2 != Type::TOP )\n-      return new SubLNode(phase->makecon( add_ring( t_sub1, t_2 ) ), in1->in(2) );\n-    \/\/ Convert \"(a-b)+(c-d)\" into \"(a+c)-(b+d)\"\n-    if( op2 == Op_SubL ) {\n-      \/\/ Check for dead cycle: d = (a-b)+(c-d)\n-      assert( in1->in(2) != this && in2->in(2) != this,\n-              \"dead loop in AddLNode::Ideal\" );\n-      Node *sub  = new SubLNode(NULL, NULL);\n-      sub->init_req(1, phase->transform(new AddLNode(in1->in(1), in2->in(1) ) ));\n-      sub->init_req(2, phase->transform(new AddLNode(in1->in(2), in2->in(2) ) ));\n-      return sub;\n-    }\n-    \/\/ Convert \"(a-b)+(b+c)\" into \"(a+c)\"\n-    if( op2 == Op_AddL && in1->in(2) == in2->in(1) ) {\n-      assert(in1->in(1) != this && in2->in(2) != this,\"dead loop in AddLNode::Ideal\");\n-      return new AddLNode(in1->in(1), in2->in(2));\n-    }\n-    \/\/ Convert \"(a-b)+(c+b)\" into \"(a+c)\"\n-    if( op2 == Op_AddL && in1->in(2) == in2->in(2) ) {\n-      assert(in1->in(1) != this && in2->in(1) != this,\"dead loop in AddLNode::Ideal\");\n-      return new AddLNode(in1->in(1), in2->in(1));\n-    }\n-    \/\/ Convert \"(a-b)+(b-c)\" into \"(a-c)\"\n-    if( op2 == Op_SubL && in1->in(2) == in2->in(1) ) {\n-      assert(in1->in(1) != this && in2->in(2) != this,\"dead loop in AddLNode::Ideal\");\n-      return new SubLNode(in1->in(1), in2->in(2));\n-    }\n-    \/\/ Convert \"(a-b)+(c-a)\" into \"(c-b)\"\n-    if( op2 == Op_SubL && in1->in(1) == in2->in(2) ) {\n-      assert(in1->in(2) != this && in2->in(1) != this,\"dead loop in AddLNode::Ideal\");\n-      return new SubLNode(in2->in(1), in1->in(2));\n-    }\n-  }\n-\n-  \/\/ Convert \"x+(0-y)\" into \"(x-y)\"\n-  if( op2 == Op_SubL && phase->type(in2->in(1)) == TypeLong::ZERO )\n-    return new SubLNode( in1, in2->in(2) );\n-\n-  \/\/ Convert \"(0-y)+x\" into \"(x-y)\"\n-  if( op1 == Op_SubL && phase->type(in1->in(1)) == TypeLong::ZERO )\n-    return new SubLNode( in2, in1->in(2) );\n-\n-  \/\/ Associative\n-  if (op1 == Op_MulL && op2 == Op_MulL) {\n-    Node* add_in1 = NULL;\n-    Node* add_in2 = NULL;\n-    Node* mul_in = NULL;\n-\n-    if (in1->in(1) == in2->in(1)) {\n-      \/\/ Convert \"a*b+a*c into a*(b+c)\n-      add_in1 = in1->in(2);\n-      add_in2 = in2->in(2);\n-      mul_in = in1->in(1);\n-    } else if (in1->in(2) == in2->in(1)) {\n-      \/\/ Convert a*b+b*c into b*(a+c)\n-      add_in1 = in1->in(1);\n-      add_in2 = in2->in(2);\n-      mul_in = in1->in(2);\n-    } else if (in1->in(2) == in2->in(2)) {\n-      \/\/ Convert a*c+b*c into (a+b)*c\n-      add_in1 = in1->in(1);\n-      add_in2 = in2->in(1);\n-      mul_in = in1->in(2);\n-    } else if (in1->in(1) == in2->in(2)) {\n-      \/\/ Convert a*b+c*a into a*(b+c)\n-      add_in1 = in1->in(2);\n-      add_in2 = in2->in(1);\n-      mul_in = in1->in(1);\n-    }\n-\n-    if (mul_in != NULL) {\n-      Node* add = phase->transform(new AddLNode(add_in1, add_in2));\n-      return new MulLNode(mul_in, add);\n-    }\n-  }\n-\n-  \/\/ Convert (x >>> rshift) + (x << lshift) into RotateRight(x, rshift)\n-  if (Matcher::match_rule_supported(Op_RotateRight) &&\n-      ((op1 == Op_URShiftL && op2 == Op_LShiftL) || (op1 == Op_LShiftL && op2 == Op_URShiftL)) &&\n-      in1->in(1) != NULL && in1->in(1) == in2->in(1)) {\n-    Node* rshift = op1 == Op_URShiftL ? in1->in(2) : in2->in(2);\n-    Node* lshift = op1 == Op_URShiftL ? in2->in(2) : in1->in(2);\n-    if (rshift != NULL && lshift != NULL) {\n-      const TypeInt* rshift_t = phase->type(rshift)->isa_int();\n-      const TypeInt* lshift_t = phase->type(lshift)->isa_int();\n-      if (lshift_t != NULL && lshift_t->is_con() &&\n-          rshift_t != NULL && rshift_t->is_con() &&\n-          ((lshift_t->get_con() & 0x3F) == (64 - (rshift_t->get_con() & 0x3F)))) {\n-        return new RotateRightNode(in1->in(1), phase->intcon(rshift_t->get_con() & 0x3F), TypeLong::LONG);\n-      }\n-    }\n-  }\n-\n-  \/\/ Convert (~x+1) into -x. Note there isn't a bitwise not bytecode,\n-  \/\/ \"~x\" would typically represented as \"x^(-1)\", so (~x+1) will\n-  \/\/ be (x^(-1))+1\n-  if (op1 == Op_XorL && phase->type(in2) == TypeLong::ONE &&\n-      phase->type(in1->in(2)) == TypeLong::MINUS_1) {\n-    return new SubLNode(phase->makecon(TypeLong::ZERO), in1->in(1));\n-  }\n-  return AddNode::Ideal(phase, can_reshape);\n+Node* AddLNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  return AddNode::IdealIL(phase, can_reshape, T_LONG);\n@@ -1000,4 +891,3 @@\n-  \/\/ Convert ~(x-1) into -x. Note there isn't a bitwise not bytecode,\n-  \/\/ \"~x\" would typically represented as \"x^(-1)\", and \"x-c0\" would\n-  \/\/ convert into \"x+ -c0\" in SubXNode::Ideal. So ~(x-1) will eventually\n-  \/\/ be (x+(-1))^-1.\n+  \/\/ Convert ~(x+c) into (-c-1)-x. Note there isn't a bitwise not\n+  \/\/ bytecode, \"~x\" would typically represented as \"x^(-1)\", so ~(x+c)\n+  \/\/ will eventually be (x+c)^-1.\n@@ -1005,2 +895,4 @@\n-      phase->type(in1->in(2)) == TypeInt::MINUS_1) {\n-    return new SubINode(phase->makecon(TypeInt::ZERO), in1->in(1));\n+      in1->in(2)->Opcode() == Op_ConI) {\n+    jint c = phase->type(in1->in(2))->isa_int()->get_con();\n+    Node* neg_c_minus_one = phase->intcon(java_add(-c, -1));\n+    return new SubINode(neg_c_minus_one, in1->in(1));\n@@ -1079,4 +971,3 @@\n-  \/\/ Convert ~(x-1) into -x. Note there isn't a bitwise not bytecode,\n-  \/\/ \"~x\" would typically represented as \"x^(-1)\", and \"x-c0\" would\n-  \/\/ convert into \"x+ -c0\" in SubXNode::Ideal. So ~(x-1) will eventually\n-  \/\/ be (x+(-1))^-1.\n+  \/\/ Convert ~(x+c) into (-c-1)-x. Note there isn't a bitwise not\n+  \/\/ bytecode, \"~x\" would typically represented as \"x^(-1)\", so ~(x+c)\n+  \/\/ will eventually be (x+c)^-1.\n@@ -1084,2 +975,4 @@\n-      phase->type(in1->in(2)) == TypeLong::MINUS_1) {\n-    return new SubLNode(phase->makecon(TypeLong::ZERO), in1->in(1));\n+      in1->in(2)->Opcode() == Op_ConL) {\n+    jlong c = phase->type(in1->in(2))->isa_long()->get_con();\n+    Node* neg_c_minus_one = phase->longcon(java_add(-c, (jlong)-1));\n+    return new SubLNode(neg_c_minus_one, in1->in(1));\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":93,"deletions":200,"binary":false,"changes":293,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+  _late_inline(false),\n@@ -116,1 +117,1 @@\n-                               int caller_bci, ciCallProfile& profile) {\n+                               int caller_bci, NOT_PRODUCT_ARG(bool& should_delay) ciCallProfile& profile) {\n@@ -131,3 +132,7 @@\n-  int inline_depth = inline_level()+1;\n-  if (ciReplay::should_inline(C->replay_inline_data(), callee_method, caller_bci, inline_depth)) {\n-    set_msg(\"force inline by ciReplay\");\n+  int inline_depth = inline_level() + 1;\n+  if (ciReplay::should_inline(C->replay_inline_data(), callee_method, caller_bci, inline_depth, should_delay)) {\n+    if (should_delay) {\n+      set_msg(\"force (incremental) inline by ciReplay\");\n+    } else {\n+      set_msg(\"force inline by ciReplay\");\n+    }\n@@ -197,1 +202,1 @@\n-                                   int caller_bci, ciCallProfile& profile) {\n+                                   int caller_bci, NOT_PRODUCT_ARG(bool& should_delay) ciCallProfile& profile) {\n@@ -235,3 +240,7 @@\n-  int inline_depth = inline_level()+1;\n-  if (ciReplay::should_inline(C->replay_inline_data(), callee_method, caller_bci, inline_depth)) {\n-    set_msg(\"force inline by ciReplay\");\n+  int inline_depth = inline_level() + 1;\n+  if (ciReplay::should_inline(C->replay_inline_data(), callee_method, caller_bci, inline_depth, should_delay)) {\n+    if (should_delay) {\n+      set_msg(\"force (incremental) inline by ciReplay\");\n+    } else {\n+      set_msg(\"force inline by ciReplay\");\n+    }\n@@ -313,8 +322,0 @@\n-\n-    if (MinInliningThreshold > 0) { \/\/ Deprecated heuristic\n-      intx counter_high_value = TieredCompilation ? InvocationCounter::count_limit \/ 2 : CompileThreshold \/ 2;\n-      if (!callee_method->was_executed_more_than(MIN2(MinInliningThreshold, counter_high_value))) {\n-        set_msg(\"executed < MinInliningThreshold times\");\n-        return true;\n-      }\n-    }\n@@ -372,1 +373,3 @@\n-  if (!should_inline(callee_method, caller_method, caller_bci, profile)) {\n+\n+  \/\/ 'should_delay' can be overridden during replay compilation\n+  if (!should_inline(callee_method, caller_method, caller_bci, NOT_PRODUCT_ARG(should_delay) profile)) {\n@@ -375,1 +378,2 @@\n-  if (should_not_inline(callee_method, caller_method, caller_bci, profile)) {\n+  \/\/ 'should_delay' can be overridden during replay compilation\n+  if (should_not_inline(callee_method, caller_method, caller_bci, NOT_PRODUCT_ARG(should_delay) profile)) {\n@@ -560,2 +564,1 @@\n-  assert(callee_method != NULL, \"caller checks for optimized virtual!\");\n-  assert(!should_delay, \"should be initialized to false\");\n+  assert(callee_method != NULL, \"caller checks for optimized virtual!\");\n@@ -598,1 +601,5 @@\n-    build_inline_tree_for_callee(callee_method, jvms, caller_bci);\n+    InlineTree* callee_tree = build_inline_tree_for_callee(callee_method, jvms, caller_bci);\n+    if (should_delay) {\n+      \/\/ Record late inlining decision in order to dump it for compiler replay\n+      callee_tree->set_late_inline();\n+    }\n@@ -703,1 +710,1 @@\n-  out->print(\" %d %d \", inline_level(), caller_bci());\n+  out->print(\" %d %d %d \", inline_level(), caller_bci(), _late_inline);\n","filename":"src\/hotspot\/share\/opto\/bytecodeInfo.cpp","additions":29,"deletions":22,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -88,1 +88,1 @@\n-          range(0, 64)                                                      \\\n+          range(0, 256)                                                     \\\n@@ -115,0 +115,5 @@\n+  notproduct(uintx, PrintIdealLevel, 0,                                     \\\n+          \"Print ideal IR on stdout. \"                                      \\\n+          \"Same levels as PrintIdealGraphLevel\")                            \\\n+          range(0, 4)                                                       \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -51,0 +51,3 @@\n+const char* C2Compiler::retry_no_iterative_escape_analysis() {\n+  return \"retry without iterative escape analysis\";\n+}\n@@ -102,0 +105,1 @@\n+  bool do_iterative_escape_analysis = DoEscapeAnalysis;\n@@ -107,1 +111,1 @@\n-    Options options(subsume_loads, do_escape_analysis, eliminate_boxing, do_locks_coarsening, install_code);\n+    Options options(subsume_loads, do_escape_analysis, do_iterative_escape_analysis, eliminate_boxing, do_locks_coarsening, install_code);\n@@ -128,0 +132,6 @@\n+      if (C.failure_reason_is(retry_no_iterative_escape_analysis())) {\n+        assert(do_iterative_escape_analysis, \"must make progress\");\n+        do_iterative_escape_analysis = false;\n+        env->report_failure(C.failure_reason());\n+        continue;  \/\/ retry\n+      }\n@@ -699,1 +709,1 @@\n-  case vmIntrinsics::_VectorBroadcastCoerced:\n+  case vmIntrinsics::_VectorFromBitsCoerced:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -439,0 +439,7 @@\n+  \/\/ When inlining a virtual call, the null check at the call and the call itself can throw. These 2 paths have different\n+  \/\/ expression stacks which causes late inlining to break. The MH invoker is not expected to be called from a method wih\n+  \/\/ exception handlers. When there is no exception handler, GraphKit::builtin_throw() pops the stack which solves the issue\n+  \/\/ of late inlining with exceptions.\n+  assert(!jvms->method()->has_exception_handlers() ||\n+         (method()->intrinsic_id() != vmIntrinsics::_linkToVirtual &&\n+          method()->intrinsic_id() != vmIntrinsics::_linkToInterface), \"no exception handler expected\");\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1873,0 +1873,1 @@\n+  init_req( ValidLengthTest    , topnode);\n@@ -1906,52 +1907,0 @@\n-\n-\/\/=============================================================================\n-Node* AllocateArrayNode::Ideal(PhaseGVN *phase, bool can_reshape) {\n-  Node* res = SafePointNode::Ideal(phase, can_reshape);\n-  if (res != NULL) {\n-    return res;\n-  }\n-  \/\/ Don't bother trying to transform a dead node\n-  if (in(0) && in(0)->is_top())  return NULL;\n-\n-  const Type* type = phase->type(Ideal_length());\n-  if (type->isa_int() && type->is_int()->_hi < 0) {\n-    if (can_reshape) {\n-      PhaseIterGVN *igvn = phase->is_IterGVN();\n-      \/\/ Unreachable fall through path (negative array length),\n-      \/\/ the allocation can only throw so disconnect it.\n-      Node* proj = proj_out_or_null(TypeFunc::Control);\n-      Node* catchproj = NULL;\n-      if (proj != NULL) {\n-        for (DUIterator_Fast imax, i = proj->fast_outs(imax); i < imax; i++) {\n-          Node *cn = proj->fast_out(i);\n-          if (cn->is_Catch()) {\n-            catchproj = cn->as_Multi()->proj_out_or_null(CatchProjNode::fall_through_index);\n-            break;\n-          }\n-        }\n-      }\n-      if (catchproj != NULL && catchproj->outcnt() > 0 &&\n-          (catchproj->outcnt() > 1 ||\n-           catchproj->unique_out()->Opcode() != Op_Halt)) {\n-        assert(catchproj->is_CatchProj(), \"must be a CatchProjNode\");\n-        Node* nproj = catchproj->clone();\n-        igvn->register_new_node_with_optimizer(nproj);\n-\n-        Node *frame = new ParmNode( phase->C->start(), TypeFunc::FramePtr );\n-        frame = phase->transform(frame);\n-        \/\/ Halt & Catch Fire\n-        Node* halt = new HaltNode(nproj, frame, \"unexpected negative array length\");\n-        phase->C->root()->add_req(halt);\n-        phase->transform(halt);\n-\n-        igvn->replace_node(catchproj, phase->C->top());\n-        return this;\n-      }\n-    } else {\n-      \/\/ Can't correct it during regular GVN so register for IGVN\n-      phase->C->record_for_igvn(this);\n-    }\n-  }\n-  return NULL;\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":1,"deletions":52,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -953,0 +953,1 @@\n+    ValidLengthTest,\n@@ -965,0 +966,1 @@\n+    fields[ValidLengthTest] = TypeInt::BOOL;\n@@ -1061,3 +1063,3 @@\n-  AllocateArrayNode(Compile* C, const TypeFunc *atype, Node *ctrl, Node *mem, Node *abio,\n-                    Node* size, Node* klass_node, Node* initial_test,\n-                    Node* count_val, Node* default_value, Node* raw_default_value)\n+  AllocateArrayNode(Compile* C, const TypeFunc *atype, Node *ctrl, Node *mem, Node *abio, Node* size, Node* klass_node,\n+                    Node* initial_test, Node* count_val, Node* valid_length_test,\n+                    Node* default_value, Node* raw_default_value)\n@@ -1068,0 +1070,1 @@\n+    set_req(AllocateNode::ValidLengthTest, valid_length_test);\n@@ -1072,1 +1075,0 @@\n-  virtual Node *Ideal(PhaseGVN *phase, bool can_reshape);\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -63,4 +63,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return false;\n-  }\n@@ -107,4 +103,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_INT;\n-  }\n@@ -128,4 +120,1 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_LONG;\n-  }\n+\n","filename":"src\/hotspot\/share\/opto\/castnode.hpp","additions":1,"deletions":12,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2346,0 +2346,1 @@\n+        assert(igvn != NULL, \"sanity check\");\n@@ -2349,4 +2350,3 @@\n-        if (igvn) {\n-          igvn->register_new_node_with_optimizer(new_base);\n-          hook->add_req(new_base);\n-        }\n+        igvn->register_new_node_with_optimizer(new_base);\n+        hook->add_req(new_base);\n+\n@@ -2369,4 +2369,2 @@\n-                if (igvn) {\n-                  igvn->register_new_node_with_optimizer(new_phi);\n-                  hook->add_req(new_phi);\n-                }\n+                igvn->register_new_node_with_optimizer(new_phi);\n+                hook->add_req(new_phi);\n@@ -2390,0 +2388,7 @@\n+        \/\/ Already replace this phi node to cut it off from the graph to not interfere in dead loop checks during the\n+        \/\/ transformations of the new phi nodes below. Otherwise, we could wrongly conclude that there is no dead loop\n+        \/\/ because we are finding this phi node again. Also set the type of the new MergeMem node in case we are also\n+        \/\/ visiting it in the transformations below.\n+        igvn->replace_node(this, result);\n+        igvn->set_type(result, result->bottom_type());\n+\n@@ -2652,1 +2657,1 @@\n-          in(0)->as_BaseCountedLoop()->operates_on(bt, true) &&\n+          in(0)->as_BaseCountedLoop()->bt() == bt &&\n@@ -2818,0 +2823,11 @@\n+      } else if (call->is_AllocateArray()) {\n+        Node* klass_node = call->in(AllocateNode::KlassNode);\n+        Node* length = call->in(AllocateNode::ALength);\n+        const Type* length_type = phase->type(length);\n+        const Type* klass_type = phase->type(klass_node);\n+        Node* valid_length_test = call->in(AllocateNode::ValidLengthTest);\n+        const Type* valid_length_test_t = phase->type(valid_length_test);\n+        if (length_type == Type::TOP || klass_type == Type::TOP || valid_length_test_t == Type::TOP ||\n+            valid_length_test_t->is_int()->is_con(0)) {\n+          f[CatchProjNode::fall_through_index] = Type::TOP;\n+        }\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":25,"deletions":9,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -276,0 +276,1 @@\n+macro(PopCountVL)\n@@ -434,0 +435,1 @@\n+macro(VectorLongToMask)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -515,0 +515,6 @@\n+  if (do_iterative_escape_analysis() != DoEscapeAnalysis && PrintOpto) {\n+    \/\/ Recompiling without iterative escape analysis\n+    tty->print_cr(\"*********************************************************\");\n+    tty->print_cr(\"** Bailout: Recompile without iterative escape analysis**\");\n+    tty->print_cr(\"*********************************************************\");\n+  }\n@@ -545,0 +551,20 @@\n+#ifndef PRODUCT\n+void Compile::print_ideal_ir(const char* phase_name) {\n+  ttyLocker ttyl;\n+  \/\/ keep the following output all in one block\n+  \/\/ This output goes directly to the tty, not the compiler log.\n+  \/\/ To enable tools to match it up with the compilation activity,\n+  \/\/ be sure to tag this tty output with the compile ID.\n+  if (xtty != NULL) {\n+    xtty->head(\"ideal compile_id='%d'%s compile_phase='%s'\",\n+               compile_id(),\n+               is_osr_compilation() ? \" compile_kind='osr'\" : \"\",\n+               phase_name);\n+  }\n+  root()->dump(9999);\n+  if (xtty != NULL) {\n+    xtty->tail(\"ideal\");\n+  }\n+}\n+#endif\n+\n@@ -573,1 +599,0 @@\n-                  _print_ideal(directive->PrintIdealOption),\n@@ -593,1 +618,1 @@\n-                  NOT_PRODUCT(_printer(NULL) COMMA)\n+                  NOT_PRODUCT(_igv_printer(NULL) COMMA)\n@@ -773,2 +798,2 @@\n-  if (should_print(1)) {\n-    _printer->print_inlining();\n+  if (should_print_igv(1)) {\n+    _igv_printer->print_inlining();\n@@ -801,14 +826,2 @@\n-  if (print_ideal()) {\n-    ttyLocker ttyl;  \/\/ keep the following output all in one block\n-    \/\/ This output goes directly to the tty, not the compiler log.\n-    \/\/ To enable tools to match it up with the compilation activity,\n-    \/\/ be sure to tag this tty output with the compile ID.\n-    if (xtty != NULL) {\n-      xtty->head(\"ideal compile_id='%d'%s\", compile_id(),\n-                 is_osr_compilation()    ? \" compile_kind='osr'\" :\n-                 \"\");\n-    }\n-    root()->dump(9999);\n-    if (xtty != NULL) {\n-      xtty->tail(\"ideal\");\n-    }\n+  if (should_print_ideal()) {\n+    print_ideal_ir(\"print_ideal\");\n@@ -874,1 +887,0 @@\n-    _print_ideal(directive->PrintIdealOption),\n@@ -886,1 +898,1 @@\n-    NOT_PRODUCT(_printer(NULL) COMMA)\n+    NOT_PRODUCT(_igv_printer(NULL) COMMA)\n@@ -2352,1 +2364,1 @@\n-        print_method(PHASE_INCREMENTAL_INLINE_STEP, cg->call_node(), 3);\n+        print_method(PHASE_INCREMENTAL_INLINE_STEP, 3, cg->call_node());\n@@ -2550,1 +2562,1 @@\n-  print_method(PHASE_AFTER_PARSING);\n+  print_method(PHASE_AFTER_PARSING, 1);\n@@ -2642,3 +2654,3 @@\n-    ConnectionGraph::do_analysis(this, &igvn);\n-\n-    if (failing())  return;\n+    bool progress;\n+    do {\n+      ConnectionGraph::do_analysis(this, &igvn);\n@@ -2646,5 +2658,1 @@\n-    \/\/ Optimize out fields loads from scalar replaceable allocations.\n-    igvn.optimize();\n-    print_method(PHASE_ITER_GVN_AFTER_EA, 2);\n-\n-    if (failing())  return;\n+      if (failing())  return;\n@@ -2652,5 +2660,1 @@\n-    if (congraph() != NULL && macro_count() > 0) {\n-      TracePhase tp(\"macroEliminate\", &timers[_t_macroEliminate]);\n-      PhaseMacroExpand mexp(igvn);\n-      mexp.eliminate_macro_nodes();\n-      igvn.set_delay_transform(false);\n+      int mcount = macro_count(); \/\/ Record number of allocations and locks before IGVN\n@@ -2658,0 +2662,1 @@\n+      \/\/ Optimize out fields loads from scalar replaceable allocations.\n@@ -2659,1 +2664,1 @@\n-      print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);\n+      print_method(PHASE_ITER_GVN_AFTER_EA, 2);\n@@ -2662,1 +2667,18 @@\n-    }\n+\n+      if (congraph() != NULL && macro_count() > 0) {\n+        TracePhase tp(\"macroEliminate\", &timers[_t_macroEliminate]);\n+        PhaseMacroExpand mexp(igvn);\n+        mexp.eliminate_macro_nodes();\n+        igvn.set_delay_transform(false);\n+\n+        igvn.optimize();\n+        print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);\n+\n+        if (failing())  return;\n+      }\n+      progress = do_iterative_escape_analysis() &&\n+                 (macro_count() < mcount) &&\n+                 ConnectionGraph::has_candidates(this);\n+      \/\/ Try again if candidates exist and made progress\n+      \/\/ by removing some allocations and\/or locks.\n+    } while (progress);\n@@ -2821,1 +2843,1 @@\n-      print_method(PHASE_INLINE_VECTOR_REBOX, cg->call_node());\n+      print_method(PHASE_INLINE_VECTOR_REBOX, 3, cg->call_node());\n@@ -2845,1 +2867,0 @@\n-         n->req() == 2 &&\n@@ -2853,1 +2874,1 @@\n-      return n->req() == 2;\n+      return true;\n@@ -2885,1 +2906,1 @@\n-static uint collect_unique_inputs(Node* n, Unique_Node_List& partition, Unique_Node_List& inputs) {\n+static uint collect_unique_inputs(Node* n, Unique_Node_List& inputs) {\n@@ -2888,0 +2909,1 @@\n+    uint inp_cnt = n->is_predicated_vector() ? n->req()-1 : n->req();\n@@ -2889,1 +2911,1 @@\n-      for (uint i = 1; i < n->req(); i++) {\n+      for (uint i = 1; i < inp_cnt; i++) {\n@@ -2899,1 +2921,1 @@\n-      uint last_req = n->req();\n+      uint last_req = inp_cnt;\n@@ -2901,1 +2923,1 @@\n-        last_req = n->req() - 1; \/\/ skip last input\n+        last_req = inp_cnt - 1; \/\/ skip last input\n@@ -2911,1 +2933,0 @@\n-    partition.push(n);\n@@ -2946,1 +2967,4 @@\n-  return igvn.transform(MacroLogicVNode::make(igvn, in3, in2, in1, func, vt));\n+\n+  Node* pn = partition.at(partition.size() - 1);\n+  Node* mask = pn->is_predicated_vector() ? pn->in(pn->req()-1) : NULL;\n+  return igvn.transform(MacroLogicVNode::make(igvn, in1, in2, in3, mask, func, vt));\n@@ -3026,1 +3050,1 @@\n-  uint input_funcs[] = { 0xAA,   \/\/ (_, _, a) -> a\n+  uint input_funcs[] = { 0xAA,   \/\/ (_, _, c) -> c\n@@ -3028,1 +3052,1 @@\n-                         0xF0 }; \/\/ (c, _, _) -> c\n+                         0xF0 }; \/\/ (a, _, _) -> a\n@@ -3030,1 +3054,1 @@\n-    eval_map.put(inputs.at(i), input_funcs[i]);\n+    eval_map.put(inputs.at(i), input_funcs[2-i]);\n@@ -3073,0 +3097,8 @@\n+\/\/ Criteria under which nodes gets packed into a macro logic node:-\n+\/\/  1) Parent and both child nodes are all unmasked or masked with\n+\/\/     same predicates.\n+\/\/  2) Masked parent can be packed with left child if it is predicated\n+\/\/     and both have same predicates.\n+\/\/  3) Masked parent can be packed with right child if its un-predicated\n+\/\/     or has matching predication condition.\n+\/\/  4) An unmasked parent can be packed with an unmasked child.\n@@ -3082,1 +3114,1 @@\n-    assert(collect_unique_inputs(n, partition, inputs) == 1, \"not unary\");\n+    assert(collect_unique_inputs(n, inputs) == 1, \"not unary\");\n@@ -3086,3 +3118,2 @@\n-  assert(is_vector_binary_bitwise_op(n), \"not binary\");\n-  Node* in1 = n->in(1);\n-  Node* in2 = n->in(2);\n+  bool pack_left_child = true;\n+  bool pack_right_child = true;\n@@ -3090,3 +3121,2 @@\n-  int in1_unique_inputs_cnt = collect_unique_inputs(in1, partition, inputs);\n-  int in2_unique_inputs_cnt = collect_unique_inputs(in2, partition, inputs);\n-  partition.push(n);\n+  bool left_child_LOP = is_vector_bitwise_op(n->in(1));\n+  bool right_child_LOP = is_vector_bitwise_op(n->in(2));\n@@ -3094,7 +3124,21 @@\n-  \/\/ Too many inputs?\n-  if (inputs.size() > 3) {\n-    partition.clear();\n-    inputs.clear();\n-    { \/\/ Recompute in2 inputs\n-      Unique_Node_List not_used;\n-      in2_unique_inputs_cnt = collect_unique_inputs(in2, not_used, not_used);\n+  int left_child_input_cnt = 0;\n+  int right_child_input_cnt = 0;\n+\n+  bool parent_is_predicated = n->is_predicated_vector();\n+  bool left_child_predicated = n->in(1)->is_predicated_vector();\n+  bool right_child_predicated = n->in(2)->is_predicated_vector();\n+\n+  Node* parent_pred = parent_is_predicated ? n->in(n->req()-1) : NULL;\n+  Node* left_child_pred = left_child_predicated ? n->in(1)->in(n->in(1)->req()-1) : NULL;\n+  Node* right_child_pred = right_child_predicated ? n->in(1)->in(n->in(1)->req()-1) : NULL;\n+\n+  do {\n+    if (pack_left_child && left_child_LOP &&\n+        ((!parent_is_predicated && !left_child_predicated) ||\n+        ((parent_is_predicated && left_child_predicated &&\n+          parent_pred == left_child_pred)))) {\n+       partition.push(n->in(1));\n+       left_child_input_cnt = collect_unique_inputs(n->in(1), inputs);\n+    } else {\n+       inputs.push(n->in(1));\n+       left_child_input_cnt = 1;\n@@ -3102,3 +3146,10 @@\n-    \/\/ Pick the node with minimum number of inputs.\n-    if (in1_unique_inputs_cnt >= 3 && in2_unique_inputs_cnt >= 3) {\n-      return false; \/\/ still too many inputs\n+\n+    if (pack_right_child && right_child_LOP &&\n+        (!right_child_predicated ||\n+         (right_child_predicated && parent_is_predicated &&\n+          parent_pred == right_child_pred))) {\n+       partition.push(n->in(2));\n+       right_child_input_cnt = collect_unique_inputs(n->in(2), inputs);\n+    } else {\n+       inputs.push(n->in(2));\n+       right_child_input_cnt = 1;\n@@ -3106,5 +3157,13 @@\n-    \/\/ Recompute partition & inputs.\n-    Node* child       = (in1_unique_inputs_cnt < in2_unique_inputs_cnt ? in1 : in2);\n-    collect_unique_inputs(child, partition, inputs);\n-    Node* other_input = (in1_unique_inputs_cnt < in2_unique_inputs_cnt ? in2 : in1);\n-    inputs.push(other_input);\n+    if (inputs.size() > 3) {\n+      assert(partition.size() > 0, \"\");\n+      inputs.clear();\n+      partition.clear();\n+      if (left_child_input_cnt > right_child_input_cnt) {\n+        pack_left_child = false;\n+      } else {\n+        pack_right_child = false;\n+      }\n+    } else {\n+      break;\n+    }\n+  } while(true);\n@@ -3113,0 +3172,1 @@\n+  if(partition.size()) {\n@@ -3120,1 +3180,0 @@\n-\n@@ -3140,2 +3199,13 @@\n-    Node* macro_logic = xform_to_MacroLogicV(igvn, vt, partition, inputs);\n-    igvn.replace_node(n, macro_logic);\n+    Node* pn = partition.at(partition.size() - 1);\n+    Node* mask = pn->is_predicated_vector() ? pn->in(pn->req()-1) : NULL;\n+    if (mask == NULL ||\n+        Matcher::match_rule_supported_vector_masked(Op_MacroLogicV, vt->length(), vt->element_basic_type())) {\n+      Node* macro_logic = xform_to_MacroLogicV(igvn, vt, partition, inputs);\n+#ifdef ASSERT\n+      if (TraceNewVectors) {\n+        tty->print(\"new Vector node: \");\n+        macro_logic->dump();\n+      }\n+#endif\n+      igvn.replace_node(n, macro_logic);\n+    }\n@@ -3268,1 +3338,1 @@\n-  print_method(PHASE_FINAL_CODE);\n+  print_method(PHASE_FINAL_CODE, 1);\n@@ -3965,1 +4035,1 @@\n-    assert(!n->as_Loop()->is_transformed_long_inner_loop() || _loop_opts_cnt == 0, \"should have been turned into a counted loop\");\n+    assert(!n->as_Loop()->is_loop_nest_inner_loop() || _loop_opts_cnt == 0, \"should have been turned into a counted loop\");\n@@ -4252,1 +4322,1 @@\n-          CallNode *call = n->in(0)->in(0)->as_Call();\n+          CallNode* call = n->in(0)->in(0)->as_Call();\n@@ -4261,1 +4331,1 @@\n-            Node *arg0 = call->in(TypeFunc::Parms);\n+            Node* arg0 = call->in(TypeFunc::Parms);\n@@ -4266,4 +4336,3 @@\n-          } else if (call->entry_point() == OptoRuntime::new_array_Java() &&\n-                     call->req() > TypeFunc::Parms+1 &&\n-                     call->is_CallStaticJava()) {\n-            \/\/ Check for negative array length. In such case, the optimizer has\n+          } else if (call->entry_point() == OptoRuntime::new_array_Java() ||\n+                     call->entry_point() == OptoRuntime::new_array_nozero_Java()) {\n+            \/\/ Check for illegal array length. In such case, the optimizer has\n@@ -4272,3 +4341,5 @@\n-            Node *arg1 = call->in(TypeFunc::Parms+1);\n-            if (arg1->is_Type() &&\n-                arg1->as_Type()->type()->join(TypeInt::POS)->empty()) {\n+            assert(call->is_CallStaticJava(), \"static call expected\");\n+            assert(call->req() == call->jvms()->endoff() + 1, \"missing extra input\");\n+            Node* valid_length_test = call->in(call->req()-1);\n+            call->del_req(call->req()-1);\n+            if (valid_length_test->find_int_con(1) == 0) {\n@@ -4277,0 +4348,2 @@\n+            assert(n->outcnt() == required_outcnt, \"malformed control flow\");\n+            continue;\n@@ -4285,0 +4358,8 @@\n+    } else if (n->is_PCTable() && n->in(0) && n->in(0)->in(0) && n->in(0)->in(0)->is_Call()) {\n+      CallNode* call = n->in(0)->in(0)->as_Call();\n+      if (call->entry_point() == OptoRuntime::new_array_Java() ||\n+          call->entry_point() == OptoRuntime::new_array_nozero_Java()) {\n+        assert(call->is_CallStaticJava(), \"static call expected\");\n+        assert(call->req() == call->jvms()->endoff() + 1, \"missing extra input\");\n+        call->del_req(call->req()-1); \/\/ valid length test useless now\n+      }\n@@ -4524,1 +4605,1 @@\n-    C->print_method(PHASE_FAILURE);\n+    C->print_method(PHASE_FAILURE, 1);\n@@ -5282,1 +5363,1 @@\n-void Compile::print_method(CompilerPhaseType cpt, const char *name, int level) {\n+void Compile::print_method(CompilerPhaseType cpt, int level, Node* n) {\n@@ -5288,2 +5369,13 @@\n-  if (should_print(level)) {\n-    _printer->print_method(name, level);\n+  ResourceMark rm;\n+  stringStream ss;\n+  ss.print_raw(CompilerPhaseTypeHelper::to_string(cpt));\n+  if (n != nullptr) {\n+    ss.print(\": %d %s \", n->_idx, NodeClassNames[n->Opcode()]);\n+  }\n+\n+  const char* name = ss.as_string();\n+  if (should_print_igv(level)) {\n+    _igv_printer->print_method(name, level);\n+  }\n+  if (should_print_ideal(level)) {\n+    print_ideal_ir(name);\n@@ -5295,2 +5387,2 @@\n-void Compile::print_method(CompilerPhaseType cpt, int level, int idx) {\n-  char output[1024];\n+\/\/ Only used from CompileWrapper\n+void Compile::begin_method() {\n@@ -5298,4 +5390,2 @@\n-  if (idx != 0) {\n-    jio_snprintf(output, sizeof(output), \"%s:%d\", CompilerPhaseTypeHelper::to_string(cpt), idx);\n-  } else {\n-    jio_snprintf(output, sizeof(output), \"%s\", CompilerPhaseTypeHelper::to_string(cpt));\n+  if (_method != NULL && should_print_igv(1)) {\n+    _igv_printer->begin_method();\n@@ -5304,13 +5394,1 @@\n-  print_method(cpt, output, level);\n-}\n-\n-void Compile::print_method(CompilerPhaseType cpt, Node* n, int level) {\n-  ResourceMark rm;\n-  stringStream ss;\n-  ss.print_raw(CompilerPhaseTypeHelper::to_string(cpt));\n-  if (n != NULL) {\n-    ss.print(\": %d %s \", n->_idx, NodeClassNames[n->Opcode()]);\n-  } else {\n-    ss.print_raw(\": NULL\");\n-  }\n-  C->print_method(cpt, ss.as_string(), level);\n+  C->_latest_stage_start_counter.stamp();\n@@ -5319,1 +5397,2 @@\n-void Compile::end_method(int level) {\n+\/\/ Only used from CompileWrapper\n+void Compile::end_method() {\n@@ -5322,1 +5401,1 @@\n-    CompilerEvent::PhaseEvent::post(event, C->_latest_stage_start_counter, PHASE_END, C->_compile_id, level);\n+    CompilerEvent::PhaseEvent::post(event, C->_latest_stage_start_counter, PHASE_END, C->_compile_id, 1);\n@@ -5326,2 +5405,2 @@\n-  if (_method != NULL && should_print(level)) {\n-    _printer->end_method();\n+  if (_method != NULL && should_print_igv(1)) {\n+    _igv_printer->end_method();\n@@ -5332,0 +5411,16 @@\n+bool Compile::should_print_igv(int level) {\n+#ifndef PRODUCT\n+  if (PrintIdealGraphLevel < 0) { \/\/ disabled by the user\n+    return false;\n+  }\n+\n+  bool need = directive()->IGVPrintLevelOption >= level;\n+  if (need && !_igv_printer) {\n+    _igv_printer = IdealGraphPrinter::printer();\n+    _igv_printer->set_compile(this);\n+  }\n+  return need;\n+#else\n+  return false;\n+#endif\n+}\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":208,"deletions":113,"binary":false,"changes":321,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -173,0 +173,1 @@\n+  const bool _do_iterative_escape_analysis;  \/\/ Do iterative escape analysis.\n@@ -178,0 +179,1 @@\n+          bool do_iterative_escape_analysis,\n@@ -182,0 +184,1 @@\n+          _do_iterative_escape_analysis(do_iterative_escape_analysis),\n@@ -191,0 +194,1 @@\n+       \/* do_iterative_escape_analysis = *\/ false,\n@@ -328,1 +332,0 @@\n-  bool                  _print_ideal;\n@@ -359,1 +362,1 @@\n-  IdealGraphPrinter*    _printer;\n+  IdealGraphPrinter*    _igv_printer;\n@@ -494,1 +497,1 @@\n-  IdealGraphPrinter* printer() { return _printer; }\n+  IdealGraphPrinter* igv_printer() { return _igv_printer; }\n@@ -543,0 +546,1 @@\n+  bool              do_iterative_escape_analysis() const  { return _options._do_iterative_escape_analysis; }\n@@ -649,1 +653,3 @@\n-  bool          print_ideal() const             { return _print_ideal; }\n+  void          print_ideal_ir(const char* phase_name);\n+  bool          should_print_ideal() const      { return _directive->PrintIdealOption; }\n+  bool          should_print_ideal(uint level) const { return _directive->PrintIdealLevelOption >= level; }\n@@ -663,26 +669,3 @@\n-  void begin_method(int level = 1) {\n-#ifndef PRODUCT\n-    if (_method != NULL && should_print(level)) {\n-      _printer->begin_method();\n-    }\n-#endif\n-    C->_latest_stage_start_counter.stamp();\n-  }\n-\n-  bool should_print(int level = 1) {\n-#ifndef PRODUCT\n-    if (PrintIdealGraphLevel < 0) { \/\/ disabled by the user\n-      return false;\n-    }\n-\n-    bool need = directive()->IGVPrintLevelOption >= level;\n-    if (need && !_printer) {\n-      _printer = IdealGraphPrinter::printer();\n-      assert(_printer != NULL, \"_printer is NULL when we need it!\");\n-      _printer->set_compile(this);\n-    }\n-    return need;\n-#else\n-    return false;\n-#endif\n-  }\n+  void begin_method();\n+  void end_method();\n+  bool should_print_igv(int level);\n@@ -690,3 +673,1 @@\n-  void print_method(CompilerPhaseType cpt, const char *name, int level = 1);\n-  void print_method(CompilerPhaseType cpt, int level = 1, int idx = 0);\n-  void print_method(CompilerPhaseType cpt, Node* n, int level = 3);\n+  void print_method(CompilerPhaseType cpt, int level, Node* n = nullptr);\n@@ -701,2 +682,0 @@\n-  void end_method(int level = 1);\n-\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":15,"deletions":36,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -71,4 +71,6 @@\n-  ciMethod*       caller   = jvms->method();\n-  int             bci      = jvms->bci();\n-  Bytecodes::Code bytecode = caller->java_code_at_bci(bci);\n-  guarantee(callee != NULL, \"failed method resolution\");\n+  assert(callee != NULL, \"failed method resolution\");\n+\n+  ciMethod*       caller      = jvms->method();\n+  int             bci         = jvms->bci();\n+  Bytecodes::Code bytecode    = caller->java_code_at_bci(bci);\n+  ciMethod*       orig_callee = caller->get_method_at_bci(bci);\n@@ -77,1 +79,3 @@\n-                                       (bytecode == Bytecodes::_invokeinterface);\n+                                       (bytecode == Bytecodes::_invokeinterface) ||\n+                                       (orig_callee->intrinsic_id() == vmIntrinsics::_linkToVirtual) ||\n+                                       (orig_callee->intrinsic_id() == vmIntrinsics::_linkToInterface);\n@@ -168,1 +172,1 @@\n-      bool should_delay = false;\n+      bool should_delay = AlwaysIncrementalInline;\n@@ -193,1 +197,1 @@\n-          } else if ((should_delay || AlwaysIncrementalInline)) {\n+          } else if (should_delay) {\n@@ -332,1 +336,2 @@\n-          CallGenerator* cg = CallGenerator::for_guarded_call(holder, miss_cg, hit_cg);\n+          ciKlass* constraint = (holder->is_subclass_of(singleton) ? holder : singleton); \/\/ avoid upcasts\n+          CallGenerator* cg = CallGenerator::for_guarded_call(constraint, miss_cg, hit_cg);\n@@ -334,0 +339,1 @@\n+            dependencies()->assert_unique_implementor(declared_interface, singleton);\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":15,"deletions":9,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-ConnectionGraph::ConnectionGraph(Compile * C, PhaseIterGVN *igvn) :\n+ConnectionGraph::ConnectionGraph(Compile * C, PhaseIterGVN *igvn, int invocation) :\n@@ -53,0 +53,3 @@\n+  _invocation(invocation),\n+  _build_iterations(0),\n+  _build_time(0.),\n@@ -100,1 +103,5 @@\n-  ConnectionGraph* congraph = new(C->comp_arena()) ConnectionGraph(C, igvn);\n+  int invocation = 0;\n+  if (C->congraph() != NULL) {\n+    invocation = C->congraph()->_invocation + 1;\n+  }\n+  ConnectionGraph* congraph = new(C->comp_arena()) ConnectionGraph(C, igvn, invocation);\n@@ -1362,2 +1369,2 @@\n-    assert(ExitEscapeAnalysisOnTimeout, \"infinite EA connection graph build (%f sec, %d iterations) with %d nodes and worklist size %d\",\n-           _build_time, _build_iterations, nodes_size(), ptnodes_worklist.length());\n+    assert(ExitEscapeAnalysisOnTimeout, \"infinite EA connection graph build during invocation %d (%f sec, %d iterations) with %d nodes and worklist size %d\",\n+           _invocation, _build_time, _build_iterations, nodes_size(), ptnodes_worklist.length());\n@@ -1368,6 +1375,0 @@\n-#ifdef ASSERT\n-  if (Verbose && PrintEscapeAnalysis) {\n-    tty->print_cr(\"EA: %d iterations and %f sec to build connection graph with %d nodes and worklist size %d\",\n-                  _build_iterations, _build_time, nodes_size(), ptnodes_worklist.length());\n-  }\n-#endif\n@@ -2721,1 +2722,1 @@\n-      C->record_failure(C2Compiler::retry_no_escape_analysis());\n+      C->record_failure(_invocation > 0 ? C2Compiler::retry_no_iterative_escape_analysis() : C2Compiler::retry_no_escape_analysis());\n@@ -3292,1 +3293,1 @@\n-        _compile->record_failure(C2Compiler::retry_no_escape_analysis());\n+        _compile->record_failure(_invocation > 0 ? C2Compiler::retry_no_iterative_escape_analysis() : C2Compiler::retry_no_escape_analysis());\n@@ -3312,1 +3313,1 @@\n-        _compile->record_failure(C2Compiler::retry_no_escape_analysis());\n+        _compile->record_failure(_invocation > 0 ? C2Compiler::retry_no_iterative_escape_analysis() : C2Compiler::retry_no_escape_analysis());\n@@ -3785,0 +3786,3 @@\n+        tty->print_cr(\"invocation #%d: %d iterations and %f sec to build connection graph with %d nodes and worklist size %d\",\n+                      _invocation, _build_iterations, _build_time, nodes_size(), ptnodes_worklist.length());\n+        tty->cr();\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":17,"deletions":13,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -575,2 +575,1 @@\n-  if (treat_throw_as_hot\n-      && (!StackTraceInThrowable || OmitStackTraceInFastThrow)) {\n+  if (treat_throw_as_hot && method()->can_omit_stack_trace()) {\n@@ -595,5 +594,4 @@\n-      if (java_bc() == Bytecodes::_aastore) {\n-        ex_obj = env()->ArrayStoreException_instance();\n-      } else {\n-        ex_obj = env()->ClassCastException_instance();\n-      }\n+      ex_obj = env()->ClassCastException_instance();\n+      break;\n+    case Deoptimization::Reason_array_check:\n+      ex_obj = env()->ArrayStoreException_instance();\n@@ -630,0 +628,7 @@\n+      if (!method()->has_exception_handlers()) {\n+        \/\/ We don't need to preserve the stack if there's no handler as the entire frame is going to be popped anyway.\n+        \/\/ This prevents issues with exception handling and late inlining.\n+        set_sp(0);\n+        clean_stack(0);\n+      }\n+\n@@ -2473,1 +2478,1 @@\n-        \/\/ the call, dstore_rounding does gvn.transform\n+        \/\/ the call, dprecision_rounding does gvn.transform\n@@ -2475,1 +2480,1 @@\n-        arg = dstore_rounding(arg);\n+        arg = dprecision_rounding(arg);\n@@ -2510,14 +2515,0 @@\n-\/\/ rounding for non-strict double stores\n-Node* GraphKit::dstore_rounding(Node* n) {\n-  if (Matcher::strict_fp_requires_explicit_rounding) {\n-#ifdef IA32\n-    if (UseSSE < 2) {\n-      return _gvn.transform(new RoundDoubleNode(0, n));\n-    }\n-#else\n-    Unimplemented();\n-#endif \/\/ IA32\n-  }\n-  return n;\n-}\n-\n@@ -2617,2 +2608,1 @@\n-                                  Node* parm6, Node* parm7,\n-                                  Node* parm8) {\n+                                  Node* parm6, Node* parm7) {\n@@ -2665,2 +2655,1 @@\n-  if (parm8 != NULL) { call->init_req(TypeFunc::Parms+8, parm8);\n-  \/* close each nested if ===> *\/  } } } } } } } } }\n+  \/* close each nested if ===> *\/  } } } } } } } }\n@@ -2867,1 +2856,3 @@\n-  Node* norm = _gvn.transform( new CatchProjNode(catc, CatchProjNode::fall_through_index, CatchProjNode::no_handler_bci) );\n+  Node* norm = new CatchProjNode(catc, CatchProjNode::fall_through_index, CatchProjNode::no_handler_bci);\n+  _gvn.set_type_bottom(norm);\n+  C->record_for_igvn(norm);\n@@ -3534,1 +3525,4 @@\n-          builtin_throw(Deoptimization::Reason_class_check, makecon(TypeKlassPtr::make(klass)));\n+          bool is_aastore = (java_bc() == Bytecodes::_aastore);\n+          Deoptimization::DeoptReason reason = is_aastore ?\n+            Deoptimization::Reason_array_check : Deoptimization::Reason_class_check;\n+          builtin_throw(reason, makecon(TypeKlassPtr::make(klass)));\n@@ -3540,1 +3534,4 @@\n-            builtin_throw(Deoptimization::Reason_class_check, makecon(TypeKlassPtr::make(objtp->klass())));\n+            bool is_aastore = (java_bc() == Bytecodes::_aastore);\n+            Deoptimization::DeoptReason reason = is_aastore ?\n+              Deoptimization::Reason_array_check : Deoptimization::Reason_class_check;\n+            builtin_throw(reason, makecon(TypeKlassPtr::make(objtp->klass())));\n@@ -3640,1 +3637,4 @@\n-        builtin_throw(Deoptimization::Reason_class_check, obj_klass);\n+        bool is_aastore = (java_bc() == Bytecodes::_aastore);\n+        Deoptimization::DeoptReason reason = is_aastore ?\n+          Deoptimization::Reason_array_check : Deoptimization::Reason_class_check;\n+        builtin_throw(reason, obj_klass);\n@@ -4362,0 +4362,8 @@\n+  Node* valid_length_test = _gvn.intcon(1);\n+  if (ary_type->klass()->is_array_klass()) {\n+    BasicType bt = ary_type->klass()->as_array_klass()->element_type()->basic_type();\n+    jint max = TypeAryPtr::max_array_length(bt);\n+    Node* valid_length_cmp  = _gvn.transform(new CmpUNode(length, intcon(max)));\n+    valid_length_test = _gvn.transform(new BoolNode(valid_length_cmp, BoolTest::le));\n+  }\n+\n@@ -4427,2 +4435,2 @@\n-                                                   length, default_value,\n-                                                   raw_default_value);\n+                                                   length, valid_length_test,\n+                                                   default_value, raw_default_value);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":42,"deletions":34,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -824,3 +824,0 @@\n-  \/\/ rounding for non-strict double stores\n-  Node* dstore_rounding(Node* n);\n-\n@@ -836,2 +833,1 @@\n-                          Node* parm6 = NULL, Node* parm7 = NULL,\n-                          Node* parm8 = NULL);\n+                          Node* parm6 = NULL, Node* parm7 = NULL);\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -663,2 +663,2 @@\n-  case vmIntrinsics::_VectorBroadcastCoerced:\n-    return inline_vector_broadcast_coerced();\n+  case vmIntrinsics::_VectorFromBitsCoerced:\n+    return inline_vector_frombits_coerced();\n@@ -5823,1 +5823,1 @@\n-        Node* vmask      = _gvn.transform(new VectorMaskGenNode(ConvI2X(casted_length), TypeVect::VECTMASK, elem_bt));\n+        Node* vmask      = _gvn.transform(VectorMaskGenNode::make(ConvI2X(casted_length), elem_bt));\n@@ -7191,1 +7191,1 @@\n-      return false;\n+    return false;\n@@ -7207,1 +7207,0 @@\n-\n@@ -7213,16 +7212,0 @@\n-  ciKlass* klass = ciTypeArrayKlass::make(T_LONG);\n-  Node* klass_node = makecon(TypeKlassPtr::make(klass));\n-\n-  \/\/ Does this target support this intrinsic?\n-  if (Matcher::htbl_entries == -1) return false;\n-\n-  Node* subkeyHtbl_48_entries_start;\n-  if (Matcher::htbl_entries != 0) {\n-    \/\/ new array to hold 48 computed htbl entries\n-    Node* subkeyHtbl_48_entries = new_array(klass_node, intcon(Matcher::htbl_entries), 0);\n-    if (subkeyHtbl_48_entries == NULL) return false;\n-    subkeyHtbl_48_entries_start = array_element_address(subkeyHtbl_48_entries, intcon(0), T_LONG);\n-  } else {\n-    \/\/ This target doesn't need the extra-large Htbl.\n-    subkeyHtbl_48_entries_start = ConvL2X(intcon(0));\n-  }\n@@ -7234,1 +7217,1 @@\n-                               in_start, len, ct_start, out_start, k_start, state_start, subkeyHtbl_start, subkeyHtbl_48_entries_start, cnt_start);\n+                               in_start, len, ct_start, out_start, k_start, state_start, subkeyHtbl_start, cnt_start);\n@@ -7239,0 +7222,1 @@\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":6,"deletions":22,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -350,1 +350,1 @@\n-  bool inline_vector_broadcast_coerced();\n+  bool inline_vector_frombits_coerced();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -254,1 +254,1 @@\n-    dominated_by(proj_true, iff);\n+    dominated_by(proj_true->as_IfProj(), iff);\n@@ -260,1 +260,1 @@\n-    dominated_by(proj_false, unswitch_iff_clone);\n+    dominated_by(proj_false->as_IfProj(), unswitch_iff_clone);\n","filename":"src\/hotspot\/share\/opto\/loopUnswitch.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -80,2 +80,2 @@\n-         TransformedLongInnerLoop = 1<<18,\n-         TransformedLongOuterLoop = 1<<19,\n+         LoopNestInnerLoop   = 1<< 18,\n+         LoopNestLongOuterLoop = 1<< 19,\n@@ -83,0 +83,1 @@\n+\n@@ -107,2 +108,2 @@\n-  bool is_transformed_long_inner_loop() const { return _loop_flags & TransformedLongInnerLoop; }\n-  bool is_transformed_long_outer_loop() const { return _loop_flags & TransformedLongOuterLoop; }\n+  bool is_loop_nest_inner_loop() const { return _loop_flags & LoopNestInnerLoop; }\n+  bool is_loop_nest_outer_loop() const { return _loop_flags & LoopNestLongOuterLoop; }\n@@ -119,0 +120,1 @@\n+  void clear_has_range_checks() { _loop_flags &= ~HasRangeChecks; }\n@@ -124,2 +126,2 @@\n-  void mark_transformed_long_inner_loop() { _loop_flags |= TransformedLongInnerLoop; }\n-  void mark_transformed_long_outer_loop() { _loop_flags |= TransformedLongOuterLoop; }\n+  void mark_loop_nest_inner_loop() { _loop_flags |= LoopNestInnerLoop; }\n+  void mark_loop_nest_outer_loop() { _loop_flags |= LoopNestLongOuterLoop; }\n@@ -221,4 +223,2 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return false;\n-  }\n+\n+  jlong stride_con() const;\n@@ -348,4 +348,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_INT;\n-  }\n@@ -372,5 +368,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_LONG;\n-  }\n-\n@@ -383,1 +374,0 @@\n-  jlong   stride_con() const;\n@@ -429,1 +419,1 @@\n-    if (!ln->operates_on(bt(), true)) {\n+    if (ln->as_BaseCountedLoop()->bt() != bt()) {\n@@ -436,4 +426,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return false;\n-  }\n@@ -459,4 +445,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_INT;\n-  }\n@@ -483,4 +465,1 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_LONG;\n-  }\n+\n@@ -504,1 +483,1 @@\n-  if (!result->operates_on(bt(), true)) {\n+  if (result->bt() != bt()) {\n@@ -542,0 +521,6 @@\n+inline jlong BaseCountedLoopNode::stride_con() const {\n+  BaseCountedLoopEndNode* cle = loopexit_or_null();\n+  return cle != NULL ? cle->stride_con() : 0;\n+}\n+\n+\n@@ -740,1 +725,1 @@\n-  bool policy_range_check(PhaseIdealLoop* phase, bool provisional) const;\n+  bool policy_range_check(PhaseIdealLoop* phase, bool provisional, BasicType bt) const;\n@@ -796,0 +781,6 @@\n+\n+  \/\/ Check if the number of residual iterations is large with unroll_cnt.\n+  \/\/ Return true if the residual iterations are more than 10% of the trip count.\n+  bool is_residual_iters_large(int unroll_cnt, CountedLoopNode *cl) const {\n+    return (unroll_cnt - 1) * (100.0 \/ LoopPercentProfileLimit) > cl->profile_trip_cnt();\n+  }\n@@ -923,4 +914,3 @@\n-  Node* clone_skeleton_predicate_for_main_loop(Node* iff, Node* new_init, Node* new_stride, Node* predicate, Node* uncommon_proj, Node* control,\n-                                               IdealLoopTree* outer_loop, Node* input_proj);\n-  Node* clone_skeleton_predicate_bool(Node* iff, Node* new_init, Node* new_stride, Node* predicate, Node* uncommon_proj, Node* control,\n-                                      IdealLoopTree* outer_loop);\n+  Node* clone_skeleton_predicate_for_main_or_post_loop(Node* iff, Node* new_init, Node* new_stride, Node* predicate, Node* uncommon_proj, Node* control,\n+                                                       IdealLoopTree* outer_loop, Node* input_proj);\n+  Node* clone_skeleton_predicate_bool(Node* iff, Node* new_init, Node* new_stride, Node* control);\n@@ -930,0 +920,1 @@\n+  void copy_skeleton_predicates_to_post_loop(LoopNode* main_loop_head, CountedLoopNode* post_loop_head, Node* init, Node* stride);\n@@ -1176,2 +1167,2 @@\n-  Node* long_loop_replace_long_iv(Node* iv_to_replace, Node* inner_iv, Node* outer_phi, Node* inner_head);\n-  bool transform_long_counted_loop(IdealLoopTree* loop, Node_List &old_new);\n+  Node* loop_nest_replace_iv(Node* iv_to_replace, Node* inner_iv, Node* outer_phi, Node* inner_head, BasicType bt);\n+  bool create_loop_nest(IdealLoopTree* loop, Node_List &old_new);\n@@ -1252,3 +1243,3 @@\n-  Node *insert_post_loop(IdealLoopTree *loop, Node_List &old_new,\n-                         CountedLoopNode *main_head, CountedLoopEndNode *main_end,\n-                         Node *incr, Node *limit, CountedLoopNode *&post_head);\n+  Node *insert_post_loop(IdealLoopTree* loop, Node_List& old_new,\n+                         CountedLoopNode* main_head, CountedLoopEndNode* main_end,\n+                         Node*& incr, Node* limit, CountedLoopNode*& post_head);\n@@ -1278,1 +1269,3 @@\n-  bool is_scaled_iv(Node* exp, Node* iv, jlong* p_scale, BasicType bt);\n+  bool is_scaled_iv(Node* exp, Node* iv, jlong* p_scale, BasicType bt, bool* converted);\n+\n+  bool is_iv(Node* exp, Node* iv, BasicType bt);\n@@ -1281,1 +1274,1 @@\n-  bool is_scaled_iv_plus_offset(Node* exp, Node* iv, jlong* p_scale, Node** p_offset, BasicType bt, int depth = 0);\n+  bool is_scaled_iv_plus_offset(Node* exp, Node* iv, jlong* p_scale, Node** p_offset, BasicType bt, bool* converted = NULL, int depth = 0);\n@@ -1463,1 +1456,2 @@\n-  Node *remix_address_expressions( Node *n );\n+  Node* remix_address_expressions(Node* n);\n+  Node* remix_address_expressions_add_left_shift(Node* n, IdealLoopTree* n_loop, Node* n_ctrl, BasicType bt);\n@@ -1485,1 +1479,1 @@\n-  void dominated_by( Node *prevdom, Node *iff, bool flip = false, bool exclude_loop_predicate = false );\n+  void dominated_by(IfProjNode* prevdom, IfNode* iff, bool flip = false, bool exclude_loop_predicate = false);\n@@ -1488,1 +1482,1 @@\n-  Node *split_thru_region( Node *n, Node *region );\n+  RegionNode* split_thru_region(Node* n, RegionNode* region);\n@@ -1493,1 +1487,1 @@\n-  void do_split_if( Node *iff );\n+  void do_split_if(Node *iff, RegionNode** new_false_region = NULL, RegionNode** new_true_region = NULL);\n@@ -1601,2 +1595,3 @@\n-  ProjNode* clone_skeleton_predicate_for_unswitched_loops(Node* iff, ProjNode* predicate, Node* uncommon_proj, Deoptimization::DeoptReason reason,\n-                                                          ProjNode* output_proj, IdealLoopTree* loop);\n+  ProjNode* clone_skeleton_predicate_for_unswitched_loops(Node* iff, ProjNode* predicate,\n+                                                          Deoptimization::DeoptReason reason,\n+                                                          ProjNode* output_proj);\n@@ -1641,1 +1636,1 @@\n-  void check_long_counted_loop(IdealLoopTree* loop, Node* x) NOT_DEBUG_RETURN;\n+  void check_counted_loop_shape(IdealLoopTree* loop, Node* x, BasicType bt) NOT_DEBUG_RETURN;\n@@ -1643,1 +1638,1 @@\n-  LoopNode* create_inner_head(IdealLoopTree* loop, LongCountedLoopNode* head, LongCountedLoopEndNode* exit_test);\n+  LoopNode* create_inner_head(IdealLoopTree* loop, BaseCountedLoopNode* head, IfNode* exit_test);\n@@ -1666,0 +1661,6 @@\n+\n+  void strip_mined_nest_back_to_counted_loop(IdealLoopTree* loop, const BaseCountedLoopNode* head, Node* back_control,\n+                                             IfNode*&exit_test, SafePointNode*&safepoint);\n+  void push_pinned_nodes_thru_region(IfNode* dom_if, Node* region);\n+\n+  bool try_merge_identical_ifs(Node* n);\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":56,"deletions":55,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -239,1 +239,1 @@\n-void PhaseIdealLoop::dominated_by( Node *prevdom, Node *iff, bool flip, bool exclude_loop_predicate ) {\n+void PhaseIdealLoop::dominated_by(IfProjNode* prevdom, IfNode* iff, bool flip, bool exclude_loop_predicate) {\n@@ -243,1 +243,0 @@\n-  assert(iff->is_If(), \"must be\");\n@@ -273,1 +272,1 @@\n-  Node* dp = iff->as_If()->proj_out_or_null(pop == Op_IfTrue);\n+  Node* dp = iff->proj_out_or_null(pop == Op_IfTrue);\n@@ -282,1 +281,1 @@\n-  ProjNode* unc_proj = iff->as_If()->proj_out(1 - dp_proj->_con)->as_Proj();\n+  ProjNode* unc_proj = iff->proj_out(1 - dp_proj->_con)->as_Proj();\n@@ -363,35 +362,3 @@\n-\/\/------------------------------remix_address_expressions----------------------\n-\/\/ Rework addressing expressions to get the most loop-invariant stuff\n-\/\/ moved out.  We'd like to do all associative operators, but it's especially\n-\/\/ important (common) to do address expressions.\n-Node *PhaseIdealLoop::remix_address_expressions( Node *n ) {\n-  if (!has_ctrl(n))  return NULL;\n-  Node *n_ctrl = get_ctrl(n);\n-  IdealLoopTree *n_loop = get_loop(n_ctrl);\n-\n-  \/\/ See if 'n' mixes loop-varying and loop-invariant inputs and\n-  \/\/ itself is loop-varying.\n-\n-  \/\/ Only interested in binary ops (and AddP)\n-  if( n->req() < 3 || n->req() > 4 ) return NULL;\n-\n-  Node *n1_ctrl = get_ctrl(n->in(                    1));\n-  Node *n2_ctrl = get_ctrl(n->in(                    2));\n-  Node *n3_ctrl = get_ctrl(n->in(n->req() == 3 ? 2 : 3));\n-  IdealLoopTree *n1_loop = get_loop( n1_ctrl );\n-  IdealLoopTree *n2_loop = get_loop( n2_ctrl );\n-  IdealLoopTree *n3_loop = get_loop( n3_ctrl );\n-\n-  \/\/ Does one of my inputs spin in a tighter loop than self?\n-  if( (n_loop->is_member( n1_loop ) && n_loop != n1_loop) ||\n-      (n_loop->is_member( n2_loop ) && n_loop != n2_loop) ||\n-      (n_loop->is_member( n3_loop ) && n_loop != n3_loop) )\n-    return NULL;                \/\/ Leave well enough alone\n-\n-  \/\/ Is at least one of my inputs loop-invariant?\n-  if( n1_loop == n_loop &&\n-      n2_loop == n_loop &&\n-      n3_loop == n_loop )\n-    return NULL;                \/\/ No loop-invariant inputs\n-\n-\n+\/\/ Replace expressions like ((V+I) << 2) with (V<<2 + I<<2).\n+Node* PhaseIdealLoop::remix_address_expressions_add_left_shift(Node* n, IdealLoopTree* n_loop, Node* n_ctrl, BasicType bt) {\n+  assert(bt == T_INT || bt == T_LONG, \"only for integers\");\n@@ -400,2 +367,1 @@\n-  \/\/ Replace expressions like ((V+I) << 2) with (V<<2 + I<<2).\n-  if( n_op == Op_LShiftI ) {\n+  if (n_op == Op_LShift(bt)) {\n@@ -403,4 +369,4 @@\n-    Node *scale = n->in(2);\n-    Node *scale_ctrl = get_ctrl(scale);\n-    IdealLoopTree *scale_loop = get_loop(scale_ctrl );\n-    if( n_loop == scale_loop || !scale_loop->is_member( n_loop ) )\n+    Node* scale = n->in(2);\n+    Node* scale_ctrl = get_ctrl(scale);\n+    IdealLoopTree* scale_loop = get_loop(scale_ctrl);\n+    if (n_loop == scale_loop || !scale_loop->is_member(n_loop)) {\n@@ -408,2 +374,3 @@\n-    const TypeInt *scale_t = scale->bottom_type()->isa_int();\n-    if( scale_t && scale_t->is_con() && scale_t->get_con() >= 16 )\n+    }\n+    const TypeInt* scale_t = scale->bottom_type()->isa_int();\n+    if (scale_t != NULL && scale_t->is_con() && scale_t->get_con() >= 16) {\n@@ -411,0 +378,1 @@\n+    }\n@@ -412,5 +380,6 @@\n-    Node *add = n->in(1);\n-    Node *add_ctrl = get_ctrl(add);\n-    IdealLoopTree *add_loop = get_loop(add_ctrl);\n-    \/\/assert( n_loop == add_loop, \"\" );\n-    if( n_loop != add_loop ) return NULL;  \/\/ happens w\/ evil ZKM loops\n+    Node* add = n->in(1);\n+    Node* add_ctrl = get_ctrl(add);\n+    IdealLoopTree* add_loop = get_loop(add_ctrl);\n+    if (n_loop != add_loop) {\n+      return NULL;  \/\/ happens w\/ evil ZKM loops\n+    }\n@@ -419,3 +388,4 @@\n-    if( add->Opcode() == Op_SubI &&\n-        _igvn.type( add->in(1) ) != TypeInt::ZERO ) {\n-      Node *zero = _igvn.intcon(0);\n+    if (add->Opcode() == Op_Sub(bt) &&\n+        _igvn.type(add->in(1)) != TypeInteger::zero(bt)) {\n+      assert(add->Opcode() == Op_SubI || add->Opcode() == Op_SubL, \"\");\n+      Node* zero = _igvn.integercon(0, bt);\n@@ -423,4 +393,4 @@\n-      Node *neg = new SubINode( _igvn.intcon(0), add->in(2) );\n-      register_new_node( neg, get_ctrl(add->in(2) ) );\n-      add = new AddINode( add->in(1), neg );\n-      register_new_node( add, add_ctrl );\n+      Node* neg = SubNode::make(zero, add->in(2), bt);\n+      register_new_node(neg, get_ctrl(add->in(2)));\n+      add = AddNode::make(add->in(1), neg, bt);\n+      register_new_node(add, add_ctrl);\n@@ -428,1 +398,2 @@\n-    if( add->Opcode() != Op_AddI ) return NULL;\n+    if (add->Opcode() != Op_Add(bt)) return NULL;\n+    assert(add->Opcode() == Op_AddI || add->Opcode() == Op_AddL, \"\");\n@@ -430,8 +401,7 @@\n-    Node *add_var = add->in(1);\n-    Node *add_var_ctrl = get_ctrl(add_var);\n-    IdealLoopTree *add_var_loop = get_loop(add_var_ctrl );\n-    Node *add_invar = add->in(2);\n-    Node *add_invar_ctrl = get_ctrl(add_invar);\n-    IdealLoopTree *add_invar_loop = get_loop(add_invar_ctrl );\n-    if( add_var_loop == n_loop ) {\n-    } else if( add_invar_loop == n_loop ) {\n+    Node* add_var = add->in(1);\n+    Node* add_var_ctrl = get_ctrl(add_var);\n+    IdealLoopTree* add_var_loop = get_loop(add_var_ctrl);\n+    Node* add_invar = add->in(2);\n+    Node* add_invar_ctrl = get_ctrl(add_invar);\n+    IdealLoopTree* add_invar_loop = get_loop(add_invar_ctrl);\n+    if (add_invar_loop == n_loop) {\n@@ -443,3 +413,1 @@\n-      Node *add_var_ctrl = get_ctrl(add_var);\n-      IdealLoopTree *add_var_loop = get_loop(add_var_ctrl );\n-    } else                      \/\/ Else neither input is loop invariant\n+    } else if (add_var_loop != n_loop) { \/\/ Else neither input is loop invariant\n@@ -447,1 +415,2 @@\n-    if( n_loop == add_invar_loop || !add_invar_loop->is_member( n_loop ) )\n+    }\n+    if (n_loop == add_invar_loop || !add_invar_loop->is_member(n_loop)) {\n@@ -449,0 +418,1 @@\n+    }\n@@ -451,10 +421,10 @@\n-    Node *inv_scale = new LShiftINode( add_invar, scale );\n-    Node *inv_scale_ctrl =\n-      dom_depth(add_invar_ctrl) > dom_depth(scale_ctrl) ?\n-      add_invar_ctrl : scale_ctrl;\n-    register_new_node( inv_scale, inv_scale_ctrl );\n-    Node *var_scale = new LShiftINode( add_var, scale );\n-    register_new_node( var_scale, n_ctrl );\n-    Node *var_add = new AddINode( var_scale, inv_scale );\n-    register_new_node( var_add, n_ctrl );\n-    _igvn.replace_node( n, var_add );\n+    Node* inv_scale = LShiftNode::make(add_invar, scale, bt);\n+    Node* inv_scale_ctrl =\n+            dom_depth(add_invar_ctrl) > dom_depth(scale_ctrl) ?\n+            add_invar_ctrl : scale_ctrl;\n+    register_new_node(inv_scale, inv_scale_ctrl);\n+    Node* var_scale = LShiftNode::make(add_var, scale, bt);\n+    register_new_node(var_scale, n_ctrl);\n+    Node* var_add = AddNode::make(var_scale, inv_scale, bt);\n+    register_new_node(var_add, n_ctrl);\n+    _igvn.replace_node(n, var_add);\n@@ -463,0 +433,47 @@\n+  return NULL;\n+}\n+\n+\/\/------------------------------remix_address_expressions----------------------\n+\/\/ Rework addressing expressions to get the most loop-invariant stuff\n+\/\/ moved out.  We'd like to do all associative operators, but it's especially\n+\/\/ important (common) to do address expressions.\n+Node* PhaseIdealLoop::remix_address_expressions(Node* n) {\n+  if (!has_ctrl(n))  return NULL;\n+  Node* n_ctrl = get_ctrl(n);\n+  IdealLoopTree* n_loop = get_loop(n_ctrl);\n+\n+  \/\/ See if 'n' mixes loop-varying and loop-invariant inputs and\n+  \/\/ itself is loop-varying.\n+\n+  \/\/ Only interested in binary ops (and AddP)\n+  if (n->req() < 3 || n->req() > 4) return NULL;\n+\n+  Node* n1_ctrl = get_ctrl(n->in(                    1));\n+  Node* n2_ctrl = get_ctrl(n->in(                    2));\n+  Node* n3_ctrl = get_ctrl(n->in(n->req() == 3 ? 2 : 3));\n+  IdealLoopTree* n1_loop = get_loop(n1_ctrl);\n+  IdealLoopTree* n2_loop = get_loop(n2_ctrl);\n+  IdealLoopTree* n3_loop = get_loop(n3_ctrl);\n+\n+  \/\/ Does one of my inputs spin in a tighter loop than self?\n+  if ((n_loop->is_member(n1_loop) && n_loop != n1_loop) ||\n+      (n_loop->is_member(n2_loop) && n_loop != n2_loop) ||\n+      (n_loop->is_member(n3_loop) && n_loop != n3_loop)) {\n+    return NULL;                \/\/ Leave well enough alone\n+  }\n+\n+  \/\/ Is at least one of my inputs loop-invariant?\n+  if (n1_loop == n_loop &&\n+      n2_loop == n_loop &&\n+      n3_loop == n_loop) {\n+    return NULL;                \/\/ No loop-invariant inputs\n+  }\n+\n+  Node* res = remix_address_expressions_add_left_shift(n, n_loop, n_ctrl, T_INT);\n+  if (res != NULL) {\n+    return res;\n+  }\n+  res = remix_address_expressions_add_left_shift(n, n_loop, n_ctrl, T_LONG);\n+  if (res != NULL) {\n+    return res;\n+  }\n@@ -464,0 +481,1 @@\n+  int n_op = n->Opcode();\n@@ -465,1 +483,1 @@\n-  if( n_op == Op_AddI ||\n+  if (n_op == Op_AddI ||\n@@ -472,3 +490,3 @@\n-      n_op == Op_MulD ) {\n-    if( n2_loop == n_loop ) {\n-      assert( n1_loop != n_loop, \"\" );\n+      n_op == Op_MulD) {\n+    if (n2_loop == n_loop) {\n+      assert(n1_loop != n_loop, \"\");\n@@ -481,10 +499,10 @@\n-  if( n_op == Op_AddP ) {\n-    if( n2_loop == n_loop && n3_loop != n_loop ) {\n-      if( n->in(2)->Opcode() == Op_AddP && !n->in(3)->is_Con() ) {\n-        Node *n22_ctrl = get_ctrl(n->in(2)->in(2));\n-        Node *n23_ctrl = get_ctrl(n->in(2)->in(3));\n-        IdealLoopTree *n22loop = get_loop( n22_ctrl );\n-        IdealLoopTree *n23_loop = get_loop( n23_ctrl );\n-        if( n22loop != n_loop && n22loop->is_member(n_loop) &&\n-            n23_loop == n_loop ) {\n-          Node *add1 = new AddPNode( n->in(1), n->in(2)->in(2), n->in(3) );\n+  if (n_op == Op_AddP) {\n+    if (n2_loop == n_loop && n3_loop != n_loop) {\n+      if (n->in(2)->Opcode() == Op_AddP && !n->in(3)->is_Con()) {\n+        Node* n22_ctrl = get_ctrl(n->in(2)->in(2));\n+        Node* n23_ctrl = get_ctrl(n->in(2)->in(3));\n+        IdealLoopTree* n22loop = get_loop(n22_ctrl);\n+        IdealLoopTree* n23_loop = get_loop(n23_ctrl);\n+        if (n22loop != n_loop && n22loop->is_member(n_loop) &&\n+            n23_loop == n_loop) {\n+          Node* add1 = new AddPNode(n->in(1), n->in(2)->in(2), n->in(3));\n@@ -492,4 +510,4 @@\n-          register_new_node( add1, n_loop->_head->in(LoopNode::EntryControl) );\n-          Node *add2 = new AddPNode( n->in(1), add1, n->in(2)->in(3) );\n-          register_new_node( add2, n_ctrl );\n-          _igvn.replace_node( n, add2 );\n+          register_new_node(add1, n_loop->_head->in(LoopNode::EntryControl));\n+          Node* add2 = new AddPNode(n->in(1), add1, n->in(2)->in(3));\n+          register_new_node(add2, n_ctrl);\n+          _igvn.replace_node(n, add2);\n@@ -504,2 +522,2 @@\n-        Node *V = n->in(3)->in(1);\n-        Node *I = n->in(3)->in(2);\n+        Node* V = n->in(3)->in(1);\n+        Node* I = n->in(3)->in(2);\n@@ -511,1 +529,1 @@\n-          Node *add1 = new AddPNode(n->in(1), n->in(2), I);\n+          Node* add1 = new AddPNode(n->in(1), n->in(2), I);\n@@ -514,1 +532,1 @@\n-          Node *add2 = new AddPNode(n->in(1), add1, V);\n+          Node* add2 = new AddPNode(n->in(1), add1, V);\n@@ -1118,1 +1136,1 @@\n-  if (((n_blk->is_CountedLoop() || (n_blk->is_Loop() && n_blk->as_Loop()->is_transformed_long_inner_loop())) && n->Opcode() == Op_AddI) ||\n+  if (((n_blk->is_CountedLoop() || (n_blk->is_Loop() && n_blk->as_Loop()->is_loop_nest_inner_loop())) && n->Opcode() == Op_AddI) ||\n@@ -1239,0 +1257,1 @@\n+\n@@ -1514,22 +1533,1 @@\n-  if (identical_backtoback_ifs(n) && can_split_if(n->in(0))) {\n-    Node *n_ctrl = n->in(0);\n-    PhiNode* bolphi = PhiNode::make_blank(n_ctrl, n->in(1));\n-    IfNode* dom_if = idom(n_ctrl)->as_If();\n-    Node* proj_true = dom_if->proj_out(1);\n-    Node* proj_false = dom_if->proj_out(0);\n-    Node* con_true = _igvn.makecon(TypeInt::ONE);\n-    Node* con_false = _igvn.makecon(TypeInt::ZERO);\n-\n-    for (uint i = 1; i < n_ctrl->req(); i++) {\n-      if (is_dominator(proj_true, n_ctrl->in(i))) {\n-        bolphi->init_req(i, con_true);\n-      } else {\n-        assert(is_dominator(proj_false, n_ctrl->in(i)), \"bad if\");\n-        bolphi->init_req(i, con_false);\n-      }\n-    }\n-    register_new_node(bolphi, n_ctrl);\n-    _igvn.replace_input_of(n, 1, bolphi);\n-\n-    \/\/ Now split the IF\n-    do_split_if(n);\n+  if (try_merge_identical_ifs(n)) {\n@@ -1571,1 +1569,1 @@\n-          dominated_by(prevdom, n, false, true);\n+          dominated_by(prevdom->as_IfProj(), n->as_If(), false, true);\n@@ -1601,0 +1599,112 @@\n+\/\/ Tranform:\n+\/\/\n+\/\/ if (some_condition) {\n+\/\/   \/\/ body 1\n+\/\/ } else {\n+\/\/   \/\/ body 2\n+\/\/ }\n+\/\/ if (some_condition) {\n+\/\/   \/\/ body 3\n+\/\/ } else {\n+\/\/   \/\/ body 4\n+\/\/ }\n+\/\/\n+\/\/ into:\n+\/\/\n+\/\/\n+\/\/ if (some_condition) {\n+\/\/   \/\/ body 1\n+\/\/   \/\/ body 3\n+\/\/ } else {\n+\/\/   \/\/ body 2\n+\/\/   \/\/ body 4\n+\/\/ }\n+bool PhaseIdealLoop::try_merge_identical_ifs(Node* n) {\n+  if (identical_backtoback_ifs(n) && can_split_if(n->in(0))) {\n+    Node *n_ctrl = n->in(0);\n+    IfNode* dom_if = idom(n_ctrl)->as_If();\n+    ProjNode* dom_proj_true = dom_if->proj_out(1);\n+    ProjNode* dom_proj_false = dom_if->proj_out(0);\n+\n+    \/\/ Now split the IF\n+    RegionNode* new_false_region;\n+    RegionNode* new_true_region;\n+    do_split_if(n, &new_false_region, &new_true_region);\n+    assert(new_false_region->req() == new_true_region->req(), \"\");\n+#ifdef ASSERT\n+    for (uint i = 1; i < new_false_region->req(); ++i) {\n+      assert(new_false_region->in(i)->in(0) == new_true_region->in(i)->in(0), \"unexpected shape following split if\");\n+      assert(i == new_false_region->req() - 1 || new_false_region->in(i)->in(0)->in(1) == new_false_region->in(i + 1)->in(0)->in(1), \"unexpected shape following split if\");\n+    }\n+#endif\n+    assert(new_false_region->in(1)->in(0)->in(1) == dom_if->in(1), \"dominating if and dominated if after split must share test\");\n+\n+    \/\/ We now have:\n+    \/\/ if (some_condition) {\n+    \/\/   \/\/ body 1\n+    \/\/   if (some_condition) {\n+    \/\/     body3: \/\/ new_true_region\n+    \/\/     \/\/ body3\n+    \/\/   } else {\n+    \/\/     goto body4;\n+    \/\/   }\n+    \/\/ } else {\n+    \/\/   \/\/ body 2\n+    \/\/  if (some_condition) {\n+    \/\/     goto body3;\n+    \/\/   } else {\n+    \/\/     body4:   \/\/ new_false_region\n+    \/\/     \/\/ body4;\n+    \/\/   }\n+    \/\/ }\n+    \/\/\n+\n+    \/\/ clone pinned nodes thru the resulting regions\n+    push_pinned_nodes_thru_region(dom_if, new_true_region);\n+    push_pinned_nodes_thru_region(dom_if, new_false_region);\n+\n+    \/\/ Optimize out the cloned ifs. Because pinned nodes were cloned, this also allows a CastPP that would be dependent\n+    \/\/ on a projection of n to have the dom_if as a control dependency. We don't want the CastPP to end up with an\n+    \/\/ unrelated control dependency.\n+    for (uint i = 1; i < new_false_region->req(); i++) {\n+      if (is_dominator(dom_proj_true, new_false_region->in(i))) {\n+        dominated_by(dom_proj_true->as_IfProj(), new_false_region->in(i)->in(0)->as_If(), false, false);\n+      } else {\n+        assert(is_dominator(dom_proj_false, new_false_region->in(i)), \"bad if\");\n+        dominated_by(dom_proj_false->as_IfProj(), new_false_region->in(i)->in(0)->as_If(), false, false);\n+      }\n+    }\n+    return true;\n+  }\n+  return false;\n+}\n+\n+void PhaseIdealLoop::push_pinned_nodes_thru_region(IfNode* dom_if, Node* region) {\n+  for (DUIterator i = region->outs(); region->has_out(i); i++) {\n+    Node* u = region->out(i);\n+    if (!has_ctrl(u) || u->is_Phi() || !u->depends_only_on_test() || !_igvn.no_dependent_zero_check(u)) {\n+      continue;\n+    }\n+    assert(u->in(0) == region, \"not a control dependent node?\");\n+    uint j = 1;\n+    for (; j < u->req(); ++j) {\n+      Node* in = u->in(j);\n+      if (!is_dominator(ctrl_or_self(in), dom_if)) {\n+        break;\n+      }\n+    }\n+    if (j == u->req()) {\n+      Node *phi = PhiNode::make_blank(region, u);\n+      for (uint k = 1; k < region->req(); ++k) {\n+        Node* clone = u->clone();\n+        clone->set_req(0, region->in(k));\n+        register_new_node(clone, region->in(k));\n+        phi->init_req(k, clone);\n+      }\n+      register_new_node(phi, region);\n+      _igvn.replace_node(u, phi);\n+      --i;\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":238,"deletions":128,"binary":false,"changes":366,"status":"modified"},{"patch":"@@ -1338,1 +1338,2 @@\n-            address slow_call_address  \/\/ Address of slow call\n+            address slow_call_address,  \/\/ Address of slow call\n+            Node* valid_length_test \/\/ whether length is valid or not\n@@ -1372,2 +1373,1 @@\n-  if (C->env()->dtrace_alloc_probes() ||\n-      (!UseTLAB && !Universe::heap()->supports_inline_contig_alloc())) {\n+  if (!UseTLAB && !Universe::heap()->supports_inline_contig_alloc()) {\n@@ -1528,0 +1528,6 @@\n+  \/\/ For array allocations, copy the valid length check to the call node so Compile::final_graph_reshaping() can verify\n+  \/\/ that the call has the expected number of CatchProj nodes (in case the allocation always fails and the fallthrough\n+  \/\/ path dies).\n+  if (valid_length_test != NULL) {\n+    call->add_req(valid_length_test);\n+  }\n@@ -1765,1 +1771,1 @@\n-  if (C->env()->dtrace_extended_probes()) {\n+  if (C->env()->dtrace_alloc_probes()) {\n@@ -1782,1 +1788,1 @@\n-    call->init_req(TypeFunc::Memory , ctrl);\n+    call->init_req(TypeFunc::Memory , rawmem);\n@@ -2011,1 +2017,1 @@\n-                         OptoRuntime::new_instance_Java());\n+                         OptoRuntime::new_instance_Java(), NULL);\n@@ -2016,0 +2022,1 @@\n+  Node* valid_length_test = alloc->in(AllocateNode::ValidLengthTest);\n@@ -2030,1 +2037,1 @@\n-                         slow_call_address);\n+                         slow_call_address, valid_length_test);\n@@ -2852,0 +2859,1 @@\n+               n->Opcode() == Op_Opaque4   ||\n@@ -2916,0 +2924,13 @@\n+      } else if (n->Opcode() == Op_Opaque4) {\n+        \/\/ With Opaque4 nodes, the expectation is that the test of input 1\n+        \/\/ is always equal to the constant value of input 2. So we can\n+        \/\/ remove the Opaque4 and replace it by input 2. In debug builds,\n+        \/\/ leave the non constant test in instead to sanity check that it\n+        \/\/ never fails (if it does, that subgraph was constructed so, at\n+        \/\/ runtime, a Halt node is executed).\n+#ifdef ASSERT\n+        _igvn.replace_node(n, n->in(1));\n+#else\n+        _igvn.replace_node(n, n->in(2));\n+#endif\n+        success = true;\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":28,"deletions":7,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -95,2 +95,2 @@\n-                              address slow_call_address);\n-  void yank_initalize_node(InitializeNode* node);\n+                              address slow_call_address,\n+                              Node* valid_length_test);\n","filename":"src\/hotspot\/share\/opto\/macro.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -245,1 +245,1 @@\n-  Node* mask_gen =  new VectorMaskGenNode(casted_length, TypeVect::VECTMASK, type);\n+  Node* mask_gen = VectorMaskGenNode::make(casted_length, type);\n","filename":"src\/hotspot\/share\/opto\/macroArrayCopy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -346,1 +346,1 @@\n-  C->print_method(PHASE_BEFORE_MATCHING);\n+  C->print_method(PHASE_BEFORE_MATCHING, 1);\n@@ -659,6 +659,7 @@\n-    \/\/ Exclude last input arg stack slots to avoid spilling vector register there,\n-    \/\/ otherwise RegVectMask spills could stomp over stack slots in caller frame.\n-    for (; (in >= init_in) && (k < scalable_predicate_reg_slots()); k++) {\n-      scalable_stack_mask.Remove(in);\n-      in = OptoReg::add(in, -1);\n-    }\n+    if (Matcher::has_predicated_vectors()) {\n+      \/\/ Exclude last input arg stack slots to avoid spilling vector register there,\n+      \/\/ otherwise RegVectMask spills could stomp over stack slots in caller frame.\n+      for (; (in >= init_in) && (k < scalable_predicate_reg_slots()); k++) {\n+        scalable_stack_mask.Remove(in);\n+        in = OptoReg::add(in, -1);\n+      }\n@@ -666,5 +667,6 @@\n-    \/\/ For RegVectMask\n-    scalable_stack_mask.clear_to_sets(scalable_predicate_reg_slots());\n-    assert(scalable_stack_mask.is_AllStack(), \"should be infinite stack\");\n-    *idealreg2spillmask[Op_RegVectMask] = *idealreg2regmask[Op_RegVectMask];\n-    idealreg2spillmask[Op_RegVectMask]->OR(scalable_stack_mask);\n+      \/\/ For RegVectMask\n+      scalable_stack_mask.clear_to_sets(scalable_predicate_reg_slots());\n+      assert(scalable_stack_mask.is_AllStack(), \"should be infinite stack\");\n+      *idealreg2spillmask[Op_RegVectMask] = *idealreg2regmask[Op_RegVectMask];\n+      idealreg2spillmask[Op_RegVectMask]->OR(scalable_stack_mask);\n+    }\n@@ -2350,0 +2352,8 @@\n+      n->del_req(3);\n+    } else if (n->req() == 6) {\n+      Node* b3 = new BinaryNode(n->in(4), n->in(5));\n+      Node* b2 = new BinaryNode(n->in(3), b3);\n+      Node* b1 = new BinaryNode(n->in(2), b2);\n+      n->set_req(2, b1);\n+      n->del_req(5);\n+      n->del_req(4);\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":23,"deletions":13,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -337,1 +337,1 @@\n-  static const TypeVect* predicate_reg_type(const Type* elemTy, int length);\n+  static const TypeVectMask* predicate_reg_type(const Type* elemTy, int length);\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1671,8 +1671,1 @@\n-        if (mem->is_Phi() && (mem->in(0) == region) && mem->in(i)->in(0) != NULL &&\n-            MemNode::all_controls_dominate(address, region)) {\n-          \/\/ Enable other optimizations such as loop predication which does not work\n-          \/\/ if we directly pin the node to node `in`\n-          x->set_req(0, mem->in(i)->in(0)); \/\/ Use same control as memory\n-        } else {\n-          x->set_req(0, in);\n-        }\n+        x->set_req(0, in);\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -237,0 +237,13 @@\n+MulNode* MulNode::make(Node* in1, Node* in2, BasicType bt) {\n+  switch (bt) {\n+    case T_INT:\n+      return new MulINode(in1, in2);\n+    case T_LONG:\n+      return new MulLNode(in1, in2);\n+    default:\n+      fatal(\"Not implemented for %s\", type2name(bt));\n+  }\n+  return NULL;\n+}\n+\n+\n@@ -507,0 +520,9 @@\n+const Type* AndINode::Value(PhaseGVN* phase) const {\n+  \/\/ patterns similar to (v << 2) & 3\n+  if (AndIL_shift_and_mask_is_always_zero(phase, in(1), in(2), T_INT, true)) {\n+    return TypeInt::ZERO;\n+  }\n+\n+  return MulNode::Value(phase);\n+}\n+\n@@ -546,0 +568,6 @@\n+  \/\/ pattern similar to (v1 + (v2 << 2)) & 3 transformed to v1 & 3\n+  Node* progress = AndIL_add_shift_and_mask(phase, T_INT);\n+  if (progress != NULL) {\n+    return progress;\n+  }\n+\n@@ -631,0 +659,9 @@\n+const Type* AndLNode::Value(PhaseGVN* phase) const {\n+  \/\/ patterns similar to (v << 2) & 3\n+  if (AndIL_shift_and_mask_is_always_zero(phase, in(1), in(2), T_LONG, true)) {\n+    return TypeLong::ZERO;\n+  }\n+\n+  return MulNode::Value(phase);\n+}\n+\n@@ -679,0 +716,6 @@\n+  \/\/ pattern similar to (v1 + (v2 << 2)) & 3 transformed to v1 & 3\n+  Node* progress = AndIL_add_shift_and_mask(phase, T_LONG);\n+  if (progress != NULL) {\n+    return progress;\n+  }\n+\n@@ -685,1 +728,1 @@\n-  uint op = in1->Opcode();\n+  int op = in1->Opcode();\n@@ -718,0 +761,12 @@\n+LShiftNode* LShiftNode::make(Node* in1, Node* in2, BasicType bt) {\n+  switch (bt) {\n+    case T_INT:\n+      return new LShiftINode(in1, in2);\n+    case T_LONG:\n+      return new LShiftLNode(in1, in2);\n+    default:\n+      fatal(\"Not implemented for %s\", type2name(bt));\n+  }\n+  return NULL;\n+}\n+\n@@ -769,1 +824,1 @@\n-  \/\/ Left input is an add of a constant?\n+  \/\/ Left input is an add?\n@@ -774,5 +829,13 @@\n-    const TypeInt *t12 = phase->type(add1->in(2))->isa_int();\n-    if( t12 && t12->is_con() ){ \/\/ Left input is an add of a con?\n-      \/\/ Transform is legal, but check for profit.  Avoid breaking 'i2s'\n-      \/\/ and 'i2b' patterns which typically fold into 'StoreC\/StoreB'.\n-      if( con < 16 ) {\n+\n+    \/\/ Transform is legal, but check for profit.  Avoid breaking 'i2s'\n+    \/\/ and 'i2b' patterns which typically fold into 'StoreC\/StoreB'.\n+    if( con < 16 ) {\n+      \/\/ Left input is an add of the same number?\n+      if (add1->in(1) == add1->in(2)) {\n+        \/\/ Convert \"(x + x) << c0\" into \"x << (c0 + 1)\"\n+        return new LShiftINode(add1->in(1), phase->intcon(con + 1));\n+      }\n+\n+      \/\/ Left input is an add of a constant?\n+      const TypeInt *t12 = phase->type(add1->in(2))->isa_int();\n+      if( t12 && t12->is_con() ){ \/\/ Left input is an add of a con?\n@@ -882,1 +945,1 @@\n-  \/\/ Left input is an add of a constant?\n+  \/\/ Left input is an add?\n@@ -888,0 +951,8 @@\n+\n+    \/\/ Left input is an add of the same number?\n+    if (add1->in(1) == add1->in(2)) {\n+      \/\/ Convert \"(x + x) << c0\" into \"x << (c0 + 1)\"\n+      return new LShiftLNode(add1->in(1), phase->intcon(con + 1));\n+    }\n+\n+    \/\/ Left input is an add of a constant?\n@@ -1693,0 +1764,104 @@\n+\n+\/\/ Given an expression (AndX shift mask) or (AndX mask shift),\n+\/\/ determine if the AndX must always produce zero, because the\n+\/\/ the shift (x<<N) is bitwise disjoint from the mask #M.\n+\/\/ The X in AndX must be I or L, depending on bt.\n+\/\/ Specifically, the following cases fold to zero,\n+\/\/ when the shift value N is large enough to zero out\n+\/\/ all the set positions of the and-mask M.\n+\/\/   (AndI (LShiftI _ #N) #M) => #0\n+\/\/   (AndL (LShiftL _ #N) #M) => #0\n+\/\/   (AndL (ConvI2L (LShiftI _ #N)) #M) => #0\n+\/\/ The M and N values must satisfy ((-1 << N) & M) == 0.\n+\/\/ Because the optimization might work for a non-constant\n+\/\/ mask M, we check the AndX for both operand orders.\n+bool MulNode::AndIL_shift_and_mask_is_always_zero(PhaseGVN* phase, Node* shift, Node* mask, BasicType bt, bool check_reverse) {\n+  if (mask == NULL || shift == NULL) {\n+    return false;\n+  }\n+  const TypeInteger* mask_t = phase->type(mask)->isa_integer(bt);\n+  const TypeInteger* shift_t = phase->type(shift)->isa_integer(bt);\n+  if (mask_t == NULL || shift_t == NULL) {\n+    return false;\n+  }\n+  BasicType shift_bt = bt;\n+  if (bt == T_LONG && shift->Opcode() == Op_ConvI2L) {\n+    bt = T_INT;\n+    Node* val = shift->in(1);\n+    if (val == NULL) {\n+      return false;\n+    }\n+    if (val->Opcode() == Op_LShiftI) {\n+      shift_bt = T_INT;\n+      shift = val;\n+    }\n+  }\n+  if (shift->Opcode() != Op_LShift(shift_bt)) {\n+    if (check_reverse &&\n+        (mask->Opcode() == Op_LShift(bt) ||\n+         (bt == T_LONG && mask->Opcode() == Op_ConvI2L))) {\n+      \/\/ try it the other way around\n+      return AndIL_shift_and_mask_is_always_zero(phase, mask, shift, bt, false);\n+    }\n+    return false;\n+  }\n+  Node* shift2 = shift->in(2);\n+  if (shift2 == NULL) {\n+    return false;\n+  }\n+  const Type* shift2_t = phase->type(shift2);\n+  if (!shift2_t->isa_int() || !shift2_t->is_int()->is_con()) {\n+    return false;\n+  }\n+\n+  jint shift_con = shift2_t->is_int()->get_con() & ((shift_bt == T_INT ? BitsPerJavaInteger : BitsPerJavaLong) - 1);\n+  if ((((jlong)1) << shift_con) > mask_t->hi_as_long() && mask_t->lo_as_long() >= 0) {\n+    return true;\n+  }\n+\n+  return false;\n+}\n+\n+\/\/ Given an expression (AndX (AddX v1 (LShiftX v2 #N)) #M)\n+\/\/ determine if the AndX must always produce (AndX v1 #M),\n+\/\/ because the shift (v2<<N) is bitwise disjoint from the mask #M.\n+\/\/ The X in AndX will be I or L, depending on bt.\n+\/\/ Specifically, the following cases fold,\n+\/\/ when the shift value N is large enough to zero out\n+\/\/ all the set positions of the and-mask M.\n+\/\/   (AndI (AddI v1 (LShiftI _ #N)) #M) => (AndI v1 #M)\n+\/\/   (AndL (AddI v1 (LShiftL _ #N)) #M) => (AndL v1 #M)\n+\/\/   (AndL (AddL v1 (ConvI2L (LShiftI _ #N))) #M) => (AndL v1 #M)\n+\/\/ The M and N values must satisfy ((-1 << N) & M) == 0.\n+\/\/ Because the optimization might work for a non-constant\n+\/\/ mask M, and because the AddX operands can come in either\n+\/\/ order, we check for every operand order.\n+Node* MulNode::AndIL_add_shift_and_mask(PhaseGVN* phase, BasicType bt) {\n+  Node* add = in(1);\n+  Node* mask = in(2);\n+  if (add == NULL || mask == NULL) {\n+    return NULL;\n+  }\n+  int addidx = 0;\n+  if (add->Opcode() == Op_Add(bt)) {\n+    addidx = 1;\n+  } else if (mask->Opcode() == Op_Add(bt)) {\n+    mask = add;\n+    addidx = 2;\n+    add = in(addidx);\n+  }\n+  if (addidx > 0) {\n+    Node* add1 = add->in(1);\n+    Node* add2 = add->in(2);\n+    if (add1 != NULL && add2 != NULL) {\n+      if (AndIL_shift_and_mask_is_always_zero(phase, add1, mask, bt, false)) {\n+        set_req_X(addidx, add2, phase);\n+        return this;\n+      } else if (AndIL_shift_and_mask_is_always_zero(phase, add2, mask, bt, false)) {\n+        set_req_X(addidx, add1, phase);\n+        return this;\n+      }\n+    }\n+  }\n+  return NULL;\n+}\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":184,"deletions":9,"binary":false,"changes":193,"status":"modified"},{"patch":"@@ -184,0 +184,1 @@\n+class ShiftVNode;\n@@ -723,0 +724,1 @@\n+        DEFINE_CLASS_ID(ShiftV, Vector, 3)\n@@ -726,1 +728,0 @@\n-\n@@ -968,0 +969,1 @@\n+  DEFINE_CLASS_QUERY(ShiftV)\n@@ -1285,6 +1287,0 @@\n-public:\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    Unimplemented();\n-    return false;\n-  }\n@@ -1855,0 +1851,35 @@\n+#include \"opto\/opcodes.hpp\"\n+\n+#define Op_IL(op) \\\n+  inline int Op_ ## op(BasicType bt) { \\\n+  assert(bt == T_INT || bt == T_LONG, \"only for int or longs\"); \\\n+  if (bt == T_INT) { \\\n+    return Op_## op ## I; \\\n+  } \\\n+  return Op_## op ## L; \\\n+}\n+\n+Op_IL(Add)\n+Op_IL(Sub)\n+Op_IL(Mul)\n+Op_IL(URShift)\n+Op_IL(LShift)\n+Op_IL(Xor)\n+Op_IL(Cmp)\n+\n+inline int Op_Cmp_unsigned(BasicType bt) {\n+  assert(bt == T_INT || bt == T_LONG, \"only for int or longs\");\n+  if (bt == T_INT) {\n+    return Op_CmpU;\n+  }\n+  return Op_CmpUL;\n+}\n+\n+inline int Op_Cast(BasicType bt) {\n+  assert(bt == T_INT || bt == T_LONG, \"only for int or longs\");\n+  if (bt == T_INT) {\n+    return Op_CastII;\n+  }\n+  return Op_CastLL;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":38,"deletions":7,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -100,4 +100,0 @@\n-  \/\/ Latency from the beginning of the containing basic block (base 1)\n-  \/\/ for each node.\n-  unsigned short *_node_latency;\n-\n@@ -166,4 +162,0 @@\n-  \/\/ Compute the local latencies walking forward over the list of\n-  \/\/ nodes for a basic block\n-  void ComputeLocalLatenciesForward(const Block *bb);\n-\n@@ -2096,1 +2088,0 @@\n-  _node_latency    = NEW_ARENA_ARRAY(arena, unsigned short, node_max);\n@@ -2104,1 +2095,0 @@\n-  memset(_node_latency,       0, node_max * sizeof(unsigned short));\n@@ -2210,48 +2200,0 @@\n-\/\/ Compute the latency of all the instructions.  This is fairly simple,\n-\/\/ because we already have a legal ordering.  Walk over the instructions\n-\/\/ from first to last, and compute the latency of the instruction based\n-\/\/ on the latency of the preceding instruction(s).\n-void Scheduling::ComputeLocalLatenciesForward(const Block *bb) {\n-#ifndef PRODUCT\n-  if (_cfg->C->trace_opto_output())\n-    tty->print(\"# -> ComputeLocalLatenciesForward\\n\");\n-#endif\n-\n-  \/\/ Walk over all the schedulable instructions\n-  for( uint j=_bb_start; j < _bb_end; j++ ) {\n-\n-    \/\/ This is a kludge, forcing all latency calculations to start at 1.\n-    \/\/ Used to allow latency 0 to force an instruction to the beginning\n-    \/\/ of the bb\n-    uint latency = 1;\n-    Node *use = bb->get_node(j);\n-    uint nlen = use->len();\n-\n-    \/\/ Walk over all the inputs\n-    for ( uint k=0; k < nlen; k++ ) {\n-      Node *def = use->in(k);\n-      if (!def)\n-        continue;\n-\n-      uint l = _node_latency[def->_idx] + use->latency(k);\n-      if (latency < l)\n-        latency = l;\n-    }\n-\n-    _node_latency[use->_idx] = latency;\n-\n-#ifndef PRODUCT\n-    if (_cfg->C->trace_opto_output()) {\n-      tty->print(\"# latency %4d: \", latency);\n-      use->dump();\n-    }\n-#endif\n-  }\n-\n-#ifndef PRODUCT\n-  if (_cfg->C->trace_opto_output())\n-    tty->print(\"# <- ComputeLocalLatenciesForward\\n\");\n-#endif\n-\n-} \/\/ end ComputeLocalLatenciesForward\n-\n@@ -2833,3 +2775,0 @@\n-    \/\/ Compute intra-bb latencies for the nodes\n-    ComputeLocalLatenciesForward(bb);\n-\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":1,"deletions":62,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+  bool        _late_inline;       \/\/ method is inlined incrementally\n@@ -78,0 +79,1 @@\n+                            NOT_PRODUCT_ARG(bool& should_delay)\n@@ -82,0 +84,1 @@\n+                                NOT_PRODUCT_ARG(bool& should_delay)\n@@ -115,0 +118,4 @@\n+  void set_late_inline() {\n+    _late_inline = true;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -2750,1 +2750,1 @@\n-    set_pair_local( 0, dstore_rounding(pop_pair()) );\n+    set_pair_local( 0, dprecision_rounding(pop_pair()) );\n@@ -2753,1 +2753,1 @@\n-    set_pair_local( 1, dstore_rounding(pop_pair()) );\n+    set_pair_local( 1, dprecision_rounding(pop_pair()) );\n@@ -2756,1 +2756,1 @@\n-    set_pair_local( 2, dstore_rounding(pop_pair()) );\n+    set_pair_local( 2, dprecision_rounding(pop_pair()) );\n@@ -2759,1 +2759,1 @@\n-    set_pair_local( 3, dstore_rounding(pop_pair()) );\n+    set_pair_local( 3, dprecision_rounding(pop_pair()) );\n@@ -2762,1 +2762,1 @@\n-    set_pair_local( iter().get_index(), dstore_rounding(pop_pair()) );\n+    set_pair_local( iter().get_index(), dprecision_rounding(pop_pair()) );\n@@ -3041,2 +3041,1 @@\n-      c = _gvn.transform(b);\n-      push(c);\n+      push(b);\n@@ -3053,2 +3052,1 @@\n-    c = _gvn.transform(b);\n-    push_pair(c);\n+    push_pair(b);\n@@ -3509,2 +3507,2 @@\n-  if (C->should_print(1)) {\n-    IdealGraphPrinter* printer = C->printer();\n+  if (C->should_print_igv(1)) {\n+    IdealGraphPrinter* printer = C->igv_printer();\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":10,"deletions":12,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -1524,1 +1524,1 @@\n-static PhiNode* countedloop_phi_from_cmp(CmpINode* cmp, Node* n) {\n+static PhiNode* countedloop_phi_from_cmp(CmpNode* cmp, Node* n) {\n@@ -1529,2 +1529,2 @@\n-      if (iff->is_CountedLoopEnd()) {\n-        CountedLoopEndNode* cle = iff->as_CountedLoopEnd();\n+      if (iff->is_BaseCountedLoopEnd()) {\n+        BaseCountedLoopEndNode* cle = iff->as_BaseCountedLoopEnd();\n@@ -1881,2 +1881,2 @@\n-        if (m_op == Op_CmpI) {\n-          PhiNode* phi = countedloop_phi_from_cmp((CmpINode*)m, n);\n+        if (m_op == Op_CmpI || m_op == Op_CmpL) {\n+          PhiNode* phi = countedloop_phi_from_cmp(m->as_Cmp(), n);\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -244,1 +244,1 @@\n-    \/\/ Usually the initialization shoudl be to n->Value(this) instead,\n+    \/\/ Usually the initialization should be to n->Value(this) instead,\n","filename":"src\/hotspot\/share\/opto\/phaseX.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -968,1 +968,1 @@\n-  int num_args = 9;\n+  int num_args = 8;\n@@ -979,1 +979,0 @@\n-  fields[argp++] = TypePtr::NOTNULL; \/\/ long[] avx512_subkeyHtbl newly created\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -35,14 +35,13 @@\n-Node *PhaseIdealLoop::split_thru_region( Node *n, Node *region ) {\n-  uint wins = 0;\n-  assert( n->is_CFG(), \"\" );\n-  assert( region->is_Region(), \"\" );\n-  Node *r = new RegionNode( region->req() );\n-  IdealLoopTree *loop = get_loop( n );\n-  for( uint i = 1; i < region->req(); i++ ) {\n-    Node *x = n->clone();\n-    Node *in0 = n->in(0);\n-    if( in0->in(0) == region ) x->set_req( 0, in0->in(i) );\n-    for( uint j = 1; j < n->req(); j++ ) {\n-      Node *in = n->in(j);\n-      if( get_ctrl(in) == region )\n-        x->set_req( j, in->in(i) );\n+RegionNode* PhaseIdealLoop::split_thru_region(Node* n, RegionNode* region) {\n+  assert(n->is_CFG(), \"\");\n+  RegionNode* r = new RegionNode(region->req());\n+  IdealLoopTree* loop = get_loop(n);\n+  for (uint i = 1; i < region->req(); i++) {\n+    Node* x = n->clone();\n+    Node* in0 = n->in(0);\n+    if (in0->in(0) == region) x->set_req(0, in0->in(i));\n+    for (uint j = 1; j < n->req(); j++) {\n+      Node* in = n->in(j);\n+      if (get_ctrl(in) == region) {\n+        x->set_req(j, in->in(i));\n+      }\n@@ -60,1 +59,1 @@\n-  if( !loop->_child )\n+  if (!loop->_child) {\n@@ -62,0 +61,1 @@\n+  }\n@@ -132,2 +132,2 @@\n-              assert(use->is_If() || use->is_CMove() || use->Opcode() == Op_Opaque1, \"unexpected node type\");\n-              Node *use_c = use->is_If() ? use->in(0) : get_ctrl(use);\n+              assert(use->is_If() || use->is_CMove() || use->Opcode() == Op_Opaque1 || use->is_AllocateArray(), \"unexpected node type\");\n+              Node *use_c = (use->is_If() || use->is_AllocateArray()) ? use->in(0) : get_ctrl(use);\n@@ -170,2 +170,3 @@\n-                assert(u->is_If() || u->is_CMove() || u->Opcode() == Op_Opaque1, \"unexpected node type\");\n-                assert(u->in(1) == bol, \"\");\n+                assert(u->is_If() || u->is_CMove() || u->Opcode() == Op_Opaque1 || u->is_AllocateArray(), \"unexpected node type\");\n+                assert(u->is_AllocateArray() || u->in(1) == bol, \"\");\n+                assert(!u->is_AllocateArray() || u->in(AllocateNode::ValidLengthTest) == bol, \"wrong input to AllocateArray\");\n@@ -173,1 +174,1 @@\n-                Node *u_ctrl = u->is_If() ? u->in(0) : get_ctrl(u);\n+                Node *u_ctrl = (u->is_If() || u->is_AllocateArray()) ? u->in(0) : get_ctrl(u);\n@@ -177,1 +178,1 @@\n-                _igvn.replace_input_of(u, 1, x);\n+                _igvn.replace_input_of(u, u->is_AllocateArray() ? AllocateNode::ValidLengthTest : 1, x);\n@@ -437,1 +438,1 @@\n-void PhaseIdealLoop::do_split_if( Node *iff ) {\n+void PhaseIdealLoop::do_split_if(Node* iff, RegionNode** new_false_region, RegionNode** new_true_region) {\n@@ -446,1 +447,1 @@\n-  Node *region = iff->in(0);\n+  RegionNode *region = iff->in(0)->as_Region();\n@@ -494,1 +495,1 @@\n-  Node *new_iff = split_thru_region( iff, region );\n+  RegionNode *new_iff = split_thru_region(iff, region);\n@@ -499,1 +500,2 @@\n-  Node *new_false = NULL, *new_true = NULL;\n+  RegionNode* new_false = NULL;\n+  RegionNode* new_true = NULL;\n@@ -504,1 +506,1 @@\n-    Node *ifpx = split_thru_region( ifp, region );\n+    RegionNode* ifpx = split_thru_region(ifp, region);\n@@ -580,0 +582,7 @@\n+  if (new_false_region != NULL) {\n+    *new_false_region = new_false;\n+  }\n+  if (new_true_region != NULL) {\n+    *new_true_region = new_true;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/split_if.cpp","additions":35,"deletions":26,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -200,2 +200,2 @@\n-\n-  \/\/ Convert \"x - (y+c0)\" into \"(x-y) - c0\"\n+  \/\/ Convert \"x - (y+c0)\" into \"(x-y) - c0\" AND\n+  \/\/ Convert \"c1 - (y+c0)\" into \"(c1-c0) - y\"\n@@ -203,1 +203,4 @@\n-  if (op2 == Op_AddI && ok_to_convert(in2, in1)) {\n+  if (op2 == Op_AddI\n+      && ok_to_convert(in2, in1)\n+      && in2->in(2)->Opcode() == Op_ConI) {\n+    jint c0 = phase->type(in2->in(2))->isa_int()->get_con();\n@@ -205,5 +208,9 @@\n-    Node* in22 = in2->in(2);\n-    const TypeInt* tcon = phase->type(in22)->isa_int();\n-    if (tcon != NULL && tcon->is_con()) {\n-      Node* sub2 = phase->transform( new SubINode(in1, in21) );\n-      Node* neg_c0 = phase->intcon(- tcon->get_con());\n+    if (in1->Opcode() == Op_ConI) {\n+      \/\/ Match c1\n+      jint c1 = phase->type(in1)->isa_int()->get_con();\n+      Node* sub2 = phase->intcon(java_subtract(c1, c0));\n+      return new SubINode(sub2, in21);\n+    } else {\n+      \/\/ Match x\n+      Node* sub2 = phase->transform(new SubINode(in1, in21));\n+      Node* neg_c0 = phase->intcon(-c0);\n@@ -378,1 +385,2 @@\n-  \/\/ Convert \"x - (y+c0)\" into \"(x-y) - c0\"\n+  \/\/ Convert \"x - (y+c0)\" into \"(x-y) - c0\" AND\n+  \/\/ Convert \"c1 - (y+c0)\" into \"(c1-c0) - y\"\n@@ -380,1 +388,4 @@\n-  if (op2 == Op_AddL && ok_to_convert(in2, in1)) {\n+  if (op2 == Op_AddL\n+      && ok_to_convert(in2, in1)\n+      && in2->in(2)->Opcode() == Op_ConL) {\n+    jlong c0 = phase->type(in2->in(2))->isa_long()->get_con();\n@@ -382,5 +393,8 @@\n-    Node* in22 = in2->in(2);\n-    const TypeLong* tcon = phase->type(in22)->isa_long();\n-    if (tcon != NULL && tcon->is_con()) {\n-      Node* sub2 = phase->transform( new SubLNode(in1, in21) );\n-      Node* neg_c0 = phase->longcon(- tcon->get_con());\n+    if (in1->Opcode() == Op_ConL) {\n+      \/\/ Match c1\n+      jlong c1 = phase->type(in1)->isa_long()->get_con();\n+      Node* sub2 = phase->longcon(java_subtract(c1, c0));\n+      return new SubLNode(sub2, in21);\n+    } else {\n+      Node* sub2 = phase->transform(new SubLNode(in1, in21));\n+      Node* neg_c0 = phase->longcon(-c0);\n@@ -425,0 +439,8 @@\n+  \/\/ Convert \"(A+X) - (X+B)\" into \"A - B\"\n+  if( op1 == Op_AddL && op2 == Op_AddL && in1->in(2) == in2->in(1) )\n+    return new SubLNode( in1->in(1), in2->in(2) );\n+\n+  \/\/ Convert \"(X+A) - (B+X)\" into \"A - B\"\n+  if( op1 == Op_AddL && op2 == Op_AddL && in1->in(1) == in2->in(2) )\n+    return new SubLNode( in1->in(2), in2->in(1) );\n+\n@@ -1930,0 +1952,58 @@\n+\/\/=============================================================================\n+\/\/------------------------------Value------------------------------------------\n+const Type* AbsNode::Value(PhaseGVN* phase) const {\n+  const Type* t1 = phase->type(in(1));\n+  if (t1 == Type::TOP) return Type::TOP;\n+\n+  switch (t1->base()) {\n+  case Type::Int: {\n+    const TypeInt* ti = t1->is_int();\n+    if (ti->is_con()) {\n+      return TypeInt::make(uabs(ti->get_con()));\n+    }\n+    break;\n+  }\n+  case Type::Long: {\n+    const TypeLong* tl = t1->is_long();\n+    if (tl->is_con()) {\n+      return TypeLong::make(uabs(tl->get_con()));\n+    }\n+    break;\n+  }\n+  case Type::FloatCon:\n+    return TypeF::make(abs(t1->getf()));\n+  case Type::DoubleCon:\n+    return TypeD::make(abs(t1->getd()));\n+  default:\n+    break;\n+  }\n+\n+  return bottom_type();\n+}\n+\n+\/\/------------------------------Identity----------------------------------------\n+Node* AbsNode::Identity(PhaseGVN* phase) {\n+  Node* in1 = in(1);\n+  \/\/ No need to do abs for non-negative values\n+  if (phase->type(in1)->higher_equal(TypeInt::POS) ||\n+      phase->type(in1)->higher_equal(TypeLong::POS)) {\n+    return in1;\n+  }\n+  \/\/ Convert \"abs(abs(x))\" into \"abs(x)\"\n+  if (in1->Opcode() == Opcode()) {\n+    return in1;\n+  }\n+  return this;\n+}\n+\n+\/\/------------------------------Ideal------------------------------------------\n+Node* AbsNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* in1 = in(1);\n+  \/\/ Convert \"abs(0-x)\" into \"abs(x)\"\n+  if (in1->is_Sub() && phase->type(in1->in(1))->is_zero_type()) {\n+    set_req_X(1, in1->in(2), phase);\n+    return this;\n+  }\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/subnode.cpp","additions":96,"deletions":16,"binary":false,"changes":112,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -65,4 +65,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return false;\n-  }\n@@ -84,4 +80,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_INT;\n-  }\n@@ -101,4 +93,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_LONG;\n-  }\n@@ -165,4 +153,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return false;\n-  }\n@@ -179,4 +163,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_INT && signed_int;\n-  }\n@@ -194,4 +174,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_INT && !signed_int;\n-  }\n@@ -230,4 +206,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_LONG && signed_int;\n-  }\n@@ -243,4 +215,0 @@\n-  virtual bool operates_on(BasicType bt, bool signed_int) const {\n-    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n-    return bt == T_LONG && !signed_int;\n-  }\n@@ -403,0 +371,3 @@\n+  virtual Node* Identity(PhaseGVN* phase);\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  virtual const Type* Value(PhaseGVN* phase) const;\n","filename":"src\/hotspot\/share\/opto\/subnode.hpp","additions":4,"deletions":33,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -1489,0 +1489,24 @@\n+const TypeInteger* TypeInteger::zero(BasicType bt) {\n+  if (bt == T_INT) {\n+    return TypeInt::ZERO;\n+  }\n+  assert(bt == T_LONG, \"basic type not an int or long\");\n+  return TypeLong::ZERO;\n+}\n+\n+const TypeInteger* TypeInteger::one(BasicType bt) {\n+  if (bt == T_INT) {\n+    return TypeInt::ONE;\n+  }\n+  assert(bt == T_LONG, \"basic type not an int or long\");\n+  return TypeLong::ONE;\n+}\n+\n+const TypeInteger* TypeInteger::minus_1(BasicType bt) {\n+  if (bt == T_INT) {\n+    return TypeInt::MINUS_1;\n+  }\n+  assert(bt == T_LONG, \"basic type not an int or long\");\n+  return TypeLong::MINUS_1;\n+}\n+\n@@ -2655,2 +2679,1 @@\n-    const TypeVect* mtype = Matcher::predicate_reg_type(elem, length);\n-    return (TypeVect*)(const_cast<TypeVect*>(mtype))->hashcons();\n+    return TypeVectMask::make(elem, length);\n@@ -2770,0 +2793,9 @@\n+const TypeVectMask *TypeVectMask::make(const BasicType elem_bt, uint length) {\n+  return make(get_const_basic_type(elem_bt), length);\n+}\n+\n+const TypeVectMask *TypeVectMask::make(const Type* elem, uint length) {\n+  const TypeVectMask* mtype = Matcher::predicate_reg_type(elem, length);\n+  return (TypeVectMask*) const_cast<TypeVectMask*>(mtype)->hashcons();\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":34,"deletions":2,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -591,0 +591,1 @@\n+  bool is_con() const { return lo_as_long() == hi_as_long(); }\n@@ -595,0 +596,3 @@\n+  static const TypeInteger* zero(BasicType type);\n+  static const TypeInteger* one(BasicType type);\n+  static const TypeInteger* minus_1(BasicType type);\n@@ -621,3 +625,3 @@\n-  int is_con() const { return _lo==_hi; }\n-  bool is_con(int i) const { return is_con() && _lo == i; }\n-  jint get_con() const { assert( is_con(), \"\" );  return _lo; }\n+  bool is_con() const { return _lo==_hi; }\n+  bool is_con(jint i) const { return is_con() && _lo == i; }\n+  jint get_con() const { assert(is_con(), \"\" );  return _lo; }\n@@ -689,3 +693,3 @@\n-  int is_con() const { return _lo==_hi; }\n-  bool is_con(int i) const { return is_con() && _lo == i; }\n-  jlong get_con() const { assert( is_con(), \"\" ); return _lo; }\n+  bool is_con() const { return _lo==_hi; }\n+  bool is_con(jlong i) const { return is_con() && _lo == i; }\n+  jlong get_con() const { assert(is_con(), \"\" ); return _lo; }\n@@ -949,0 +953,2 @@\n+  static const TypeVectMask* make(const BasicType elem_bt, uint length);\n+  static const TypeVectMask* make(const Type* elem, uint length);\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":13,"deletions":7,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -99,1 +99,1 @@\n-      C->print_method(PHASE_SCALARIZE_VBOX, vbox, 3);\n+      C->print_method(PHASE_SCALARIZE_VBOX, 3, vbox);\n@@ -134,1 +134,1 @@\n-      C->print_method(PHASE_EXPAND_VUNBOX, vec_unbox, 3);\n+      C->print_method(PHASE_EXPAND_VUNBOX, 3, vec_unbox);\n@@ -152,1 +152,1 @@\n-      C->print_method(PHASE_ELIMINATE_VBOX_ALLOC, vbox_alloc, 3);\n+      C->print_method(PHASE_ELIMINATE_VBOX_ALLOC, 3, vbox_alloc);\n@@ -300,1 +300,1 @@\n-    C->print_method(PHASE_EXPAND_VBOX, vec_box, 3);\n+    C->print_method(PHASE_EXPAND_VBOX, 3, vec_box);\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -716,0 +716,4 @@\n+JVM_ENTRY(jboolean, JVM_IsFinalizationEnabled(JNIEnv * env))\n+  return InstanceKlass::is_finalization_enabled();\n+JVM_END\n+\n@@ -2904,1 +2908,1 @@\n-    size_t count = ::write(defaultStream::output_fd(), s, (int)len);\n+    ssize_t count = os::write(defaultStream::output_fd(), s, (int)len);\n@@ -3716,2 +3720,2 @@\n-    const char* release = Abstract_VM_Version::vm_release();\n-    const char* dbg_level = Abstract_VM_Version::jdk_debug_level();\n+    const char* release = VM_Version::vm_release();\n+    const char* dbg_level = VM_Version::jdk_debug_level();\n@@ -3722,4 +3726,4 @@\n-    seed += (jlong)Abstract_VM_Version::vm_major_version();\n-    seed += (jlong)Abstract_VM_Version::vm_minor_version();\n-    seed += (jlong)Abstract_VM_Version::vm_security_version();\n-    seed += (jlong)Abstract_VM_Version::vm_patch_version();\n+    seed += (jlong)VM_Version::vm_major_version();\n+    seed += (jlong)VM_Version::vm_minor_version();\n+    seed += (jlong)VM_Version::vm_security_version();\n+    seed += (jlong)VM_Version::vm_patch_version();\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":12,"deletions":8,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -361,1 +361,1 @@\n-      if (major < 13 || major > Abstract_VM_Version::vm_major_version()) {\n+      if (major < 13 || major > VM_Version::vm_major_version()) {\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"prims\/jvmtiExport.hpp\"\n@@ -465,0 +466,1 @@\n+  JvmtiVMObjectAllocEventCollector oam;\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+#include \"cds.h\"\n@@ -92,0 +93,1 @@\n+#include \"services\/mallocSiteTable.hpp\"\n@@ -93,0 +95,1 @@\n+#include \"services\/memTracker.hpp\"\n@@ -98,0 +101,1 @@\n+#include \"utilities\/nativeCallStack.hpp\"\n@@ -110,5 +114,0 @@\n-#if INCLUDE_NMT\n-#include \"services\/mallocSiteTable.hpp\"\n-#include \"services\/memTracker.hpp\"\n-#include \"utilities\/nativeCallStack.hpp\"\n-#endif \/\/ INCLUDE_NMT\n@@ -651,1 +650,0 @@\n-#if INCLUDE_NMT\n@@ -709,31 +707,0 @@\n-WB_ENTRY(jboolean, WB_NMTChangeTrackingLevel(JNIEnv* env))\n-  \/\/ Test that we can downgrade NMT levels but not upgrade them.\n-  if (MemTracker::tracking_level() == NMT_off) {\n-    MemTracker::transition_to(NMT_off);\n-    return MemTracker::tracking_level() == NMT_off;\n-  } else {\n-    assert(MemTracker::tracking_level() == NMT_detail, \"Should start out as detail tracking\");\n-    MemTracker::transition_to(NMT_summary);\n-    assert(MemTracker::tracking_level() == NMT_summary, \"Should be summary now\");\n-\n-    \/\/ Can't go to detail once NMT is set to summary.\n-    MemTracker::transition_to(NMT_detail);\n-    assert(MemTracker::tracking_level() == NMT_summary, \"Should still be summary now\");\n-\n-    \/\/ Shutdown sets tracking level to minimal.\n-    MemTracker::shutdown();\n-    assert(MemTracker::tracking_level() == NMT_minimal, \"Should be minimal now\");\n-\n-    \/\/ Once the tracking level is minimal, we cannot increase to summary.\n-    \/\/ The code ignores this request instead of asserting because if the malloc site\n-    \/\/ table overflows in another thread, it tries to change the code to summary.\n-    MemTracker::transition_to(NMT_summary);\n-    assert(MemTracker::tracking_level() == NMT_minimal, \"Should still be minimal now\");\n-\n-    \/\/ Really can never go up to detail, verify that the code would never do this.\n-    MemTracker::transition_to(NMT_detail);\n-    assert(MemTracker::tracking_level() == NMT_minimal, \"Should still be minimal now\");\n-    return MemTracker::tracking_level() == NMT_minimal;\n-  }\n-WB_END\n-\n@@ -760,1 +727,0 @@\n-#endif \/\/ INCLUDE_NMT\n@@ -961,0 +927,66 @@\n+WB_ENTRY(jint, WB_GetMethodDecompileCount(JNIEnv* env, jobject o, jobject method))\n+  jmethodID jmid = reflected_method_to_jmid(thread, env, method);\n+  CHECK_JNI_EXCEPTION_(env, 0);\n+  methodHandle mh(THREAD, Method::checked_resolve_jmethod_id(jmid));\n+  uint cnt = 0;\n+  MethodData* mdo = mh->method_data();\n+  if (mdo != NULL) {\n+    cnt = mdo->decompile_count();\n+  }\n+  return cnt;\n+WB_END\n+\n+\/\/ Get the trap count of a method for a specific reason. If the trap count for\n+\/\/ that reason did overflow, this includes the overflow trap count of the method.\n+\/\/ If 'reason' is NULL, the sum of the traps for all reasons will be returned.\n+\/\/ This number includes the overflow trap count if the trap count for any reason\n+\/\/ did overflow.\n+WB_ENTRY(jint, WB_GetMethodTrapCount(JNIEnv* env, jobject o, jobject method, jstring reason_obj))\n+  jmethodID jmid = reflected_method_to_jmid(thread, env, method);\n+  CHECK_JNI_EXCEPTION_(env, 0);\n+  methodHandle mh(THREAD, Method::checked_resolve_jmethod_id(jmid));\n+  uint cnt = 0;\n+  MethodData* mdo = mh->method_data();\n+  if (mdo != NULL) {\n+    ResourceMark rm(THREAD);\n+    char* reason_str = (reason_obj == NULL) ?\n+      NULL : java_lang_String::as_utf8_string(JNIHandles::resolve_non_null(reason_obj));\n+    bool overflow = false;\n+    for (uint reason = 0; reason < mdo->trap_reason_limit(); reason++) {\n+      if (reason_str != NULL && !strcmp(reason_str, Deoptimization::trap_reason_name(reason))) {\n+        cnt = mdo->trap_count(reason);\n+        \/\/ Count in the overflow trap count on overflow\n+        if (cnt == (uint)-1) {\n+          cnt = mdo->trap_count_limit() + mdo->overflow_trap_count();\n+        }\n+        break;\n+      } else if (reason_str == NULL) {\n+        uint c = mdo->trap_count(reason);\n+        if (c == (uint)-1) {\n+          c = mdo->trap_count_limit();\n+          if (!overflow) {\n+            \/\/ Count overflow trap count just once\n+            overflow = true;\n+            c += mdo->overflow_trap_count();\n+          }\n+        }\n+        cnt += c;\n+      }\n+    }\n+  }\n+  return cnt;\n+WB_END\n+\n+WB_ENTRY(jint, WB_GetDeoptCount(JNIEnv* env, jobject o, jstring reason_obj, jstring action_obj))\n+  if (reason_obj == NULL && action_obj == NULL) {\n+    return Deoptimization::total_deoptimization_count();\n+  }\n+  ResourceMark rm(THREAD);\n+  const char *reason_str = (reason_obj == NULL) ?\n+    NULL : java_lang_String::as_utf8_string(JNIHandles::resolve_non_null(reason_obj));\n+  const char *action_str = (action_obj == NULL) ?\n+    NULL : java_lang_String::as_utf8_string(JNIHandles::resolve_non_null(action_obj));\n+\n+  return Deoptimization::deoptimization_count(reason_str, action_str);\n+WB_END\n+\n@@ -2020,0 +2052,18 @@\n+WB_ENTRY(jint, WB_GetCDSGenericHeaderMinVersion(JNIEnv* env, jobject wb))\n+#if INCLUDE_CDS\n+  return (jint)CDS_GENERIC_HEADER_SUPPORTED_MIN_VERSION;\n+#else\n+  ShouldNotReachHere();\n+  return (jint)-1;\n+#endif\n+WB_END\n+\n+WB_ENTRY(jint, WB_GetCDSCurrentVersion(JNIEnv* env, jobject wb))\n+#if INCLUDE_CDS\n+  return (jint)CURRENT_CDS_ARCHIVE_VERSION;\n+#else\n+  ShouldNotReachHere();\n+  return (jint)-1;\n+#endif\n+WB_END\n+\n@@ -2584,1 +2634,0 @@\n-#if INCLUDE_NMT\n@@ -2594,1 +2643,0 @@\n-  {CC\"NMTChangeTrackingLevel\", CC\"()Z\",               (void*)&WB_NMTChangeTrackingLevel},\n@@ -2599,1 +2647,0 @@\n-#endif \/\/ INCLUDE_NMT\n@@ -2620,0 +2667,7 @@\n+  {CC\"getMethodDecompileCount0\",\n+      CC\"(Ljava\/lang\/reflect\/Executable;)I\",          (void*)&WB_GetMethodDecompileCount},\n+  {CC\"getMethodTrapCount0\",\n+      CC\"(Ljava\/lang\/reflect\/Executable;Ljava\/lang\/String;)I\",\n+                                                      (void*)&WB_GetMethodTrapCount},\n+  {CC\"getDeoptCount0\",\n+      CC\"(Ljava\/lang\/String;Ljava\/lang\/String;)I\",    (void*)&WB_GetDeoptCount},\n@@ -2742,0 +2796,2 @@\n+  {CC\"getCDSGenericHeaderMinVersion\",     CC\"()I\",    (void*)&WB_GetCDSGenericHeaderMinVersion},\n+  {CC\"getCurrentCDSVersion\",              CC\"()I\",    (void*)&WB_GetCDSCurrentVersion},\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":98,"deletions":42,"binary":false,"changes":140,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,1 @@\n+#include \"oops\/instanceKlass.hpp\"\n@@ -121,0 +122,3 @@\n+\/\/ True if -Xshare:auto option was specified.\n+static bool xshare_auto_cmd_line = false;\n+\n@@ -411,1 +415,1 @@\n-  _jdk_boot_class_path_append = new SystemProperty(\"jdk.boot.class.path.append\", \"\", false, true);\n+  _jdk_boot_class_path_append = new SystemProperty(\"jdk.boot.class.path.append\", NULL, false, true);\n@@ -529,2 +533,0 @@\n-  { \"FilterSpuriousWakeups\",        JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::jdk(20) },\n-  { \"MinInliningThreshold\",         JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::jdk(20) },\n@@ -535,0 +537,3 @@\n+#ifdef PRODUCT\n+  { \"UseHeavyMonitors\",             JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::jdk(20) },\n+#endif\n@@ -542,13 +547,3 @@\n-  { \"CriticalJNINatives\",           JDK_Version::jdk(16), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"InlineFrequencyCount\",         JDK_Version::undefined(), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"G1RSetRegionEntries\",          JDK_Version::undefined(), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"G1RSetSparseRegionEntries\",    JDK_Version::undefined(), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"AlwaysLockClassLoader\",        JDK_Version::jdk(17), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"UseBiasedLocking\",             JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"BiasedLockingStartupDelay\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"PrintBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"BiasedLockingBulkRebiasThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"BiasedLockingBulkRevokeThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"BiasedLockingDecayTime\",              JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"UseOptoBiasInlining\",                 JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n-  { \"PrintPreciseBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+\n+  { \"FilterSpuriousWakeups\",        JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::jdk(20) },\n+  { \"MinInliningThreshold\",         JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::jdk(20) },\n@@ -1252,1 +1247,1 @@\n-  FILE* stream = fopen(file_name, \"rb\");\n+  FILE* stream = os::fopen(file_name, \"rb\");\n@@ -1513,1 +1508,1 @@\n-    FLAG_SET_DEFAULT(UseSharedSpaces, false);\n+    UseSharedSpaces = false;\n@@ -2031,0 +2026,21 @@\n+#if !defined(X86) && !defined(AARCH64) && !defined(PPC64)\n+  if (UseHeavyMonitors) {\n+    jio_fprintf(defaultStream::error_stream(),\n+                \"UseHeavyMonitors is not fully implemented on this architecture\");\n+    return false;\n+  }\n+#endif\n+#if (defined(X86) || defined(PPC64)) && !defined(ZERO)\n+  if (UseHeavyMonitors && UseRTMForStackLocks) {\n+    jio_fprintf(defaultStream::error_stream(),\n+                \"-XX:+UseHeavyMonitors and -XX:+UseRTMForStackLocks are mutually exclusive\");\n+\n+    return false;\n+  }\n+#endif\n+  if (VerifyHeavyMonitors && !UseHeavyMonitors) {\n+    jio_fprintf(defaultStream::error_stream(),\n+                \"-XX:+VerifyHeavyMonitors requires -XX:+UseHeavyMonitors\");\n+    return false;\n+  }\n+\n@@ -2698,3 +2714,1 @@\n-      if (FLAG_SET_CMDLINE(DumpSharedSpaces, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n+      DumpSharedSpaces = true;\n@@ -2703,6 +2717,2 @@\n-      if (FLAG_SET_CMDLINE(UseSharedSpaces, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(RequireSharedSpaces, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n+      UseSharedSpaces = true;\n+      RequireSharedSpaces = true;\n@@ -2711,6 +2721,3 @@\n-      if (FLAG_SET_CMDLINE(UseSharedSpaces, true) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(RequireSharedSpaces, false) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n+      UseSharedSpaces = true;\n+      RequireSharedSpaces = false;\n+      xshare_auto_cmd_line = true;\n@@ -2719,6 +2726,2 @@\n-      if (FLAG_SET_CMDLINE(UseSharedSpaces, false) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n-      if (FLAG_SET_CMDLINE(RequireSharedSpaces, false) != JVMFlag::SUCCESS) {\n-        return JNI_EINVAL;\n-      }\n+      UseSharedSpaces = false;\n+      RequireSharedSpaces = false;\n@@ -2883,0 +2886,11 @@\n+    } else if (match_option(option, \"--finalization=\", &tail)) {\n+      if (strcmp(tail, \"enabled\") == 0) {\n+        InstanceKlass::set_finalization_enabled(true);\n+      } else if (strcmp(tail, \"disabled\") == 0) {\n+        InstanceKlass::set_finalization_enabled(false);\n+      } else {\n+        jio_fprintf(defaultStream::error_stream(),\n+                    \"Invalid finalization value '%s', must be 'disabled' or 'enabled'.\\n\",\n+                    tail);\n+        return JNI_EINVAL;\n+      }\n@@ -2985,6 +2999,2 @@\n-    if (FLAG_SET_CMDLINE(UseSharedSpaces, true) != JVMFlag::SUCCESS) {\n-      return JNI_EINVAL;\n-    }\n-    if (FLAG_SET_CMDLINE(RequireSharedSpaces, true) != JVMFlag::SUCCESS) {\n-      return JNI_EINVAL;\n-    }\n+    UseSharedSpaces = true;\n+    RequireSharedSpaces = true;\n@@ -3146,1 +3156,1 @@\n-    \/\/ unsafe with DumpSharedSpaces (which modifies the class metadata in place). Let's disable\n+    \/\/ unsafe with -Xshare:dump (which modifies the class metadata in place). Let's disable\n@@ -3149,2 +3159,2 @@\n-    \/\/ Note: this is not a concern for DynamicDumpSharedSpaces, which makes a copy of the class metadata\n-    \/\/ instead of modifying them in place. The copy is inaccessible to the compiler.\n+    \/\/ Note: this is not a concern for dynamically dumping shared spaces, which makes a copy of the\n+    \/\/ class metadata instead of modifying them in place. The copy is inaccessible to the compiler.\n@@ -3163,1 +3173,1 @@\n-    FLAG_SET_DEFAULT(DynamicDumpSharedSpaces, false);\n+    DynamicDumpSharedSpaces = false;\n@@ -3165,1 +3175,12 @@\n-    FLAG_SET_DEFAULT(DynamicDumpSharedSpaces, true);\n+    DynamicDumpSharedSpaces = true;\n+  }\n+\n+  if (AutoCreateSharedArchive) {\n+    if (SharedArchiveFile == NULL) {\n+      log_warning(cds)(\"-XX:+AutoCreateSharedArchive requires -XX:SharedArchiveFile\");\n+      return JNI_ERR;\n+    }\n+    if (ArchiveClassesAtExit != NULL) {\n+      log_warning(cds)(\"-XX:+AutoCreateSharedArchive does not work with ArchiveClassesAtExit\");\n+      return JNI_ERR;\n+    }\n@@ -3172,1 +3193,1 @@\n-    FLAG_SET_DEFAULT(UseSharedSpaces, false);\n+    UseSharedSpaces = false;\n@@ -3340,1 +3361,1 @@\n-    os::close(fd);\n+    ::close(fd);\n@@ -3346,1 +3367,1 @@\n-    os::close(fd);\n+    ::close(fd);\n@@ -3357,1 +3378,1 @@\n-    os::close(fd);\n+    ::close(fd);\n@@ -3364,2 +3385,2 @@\n-  ssize_t bytes_read = os::read(fd, (void *)buf, (unsigned)bytes_alloc);\n-  os::close(fd);\n+  ssize_t bytes_read = ::read(fd, (void *)buf, (unsigned)bytes_alloc);\n+  ::close(fd);\n@@ -3451,1 +3472,1 @@\n-jint Arguments::set_shared_spaces_flags_and_archive_paths() {\n+void Arguments::set_shared_spaces_flags_and_archive_paths() {\n@@ -3461,1 +3482,5 @@\n-  init_shared_archive_paths();\n+  \/\/\n+  \/\/ UseSharedSpaces may be disabled if -XX:SharedArchiveFile is invalid.\n+  if (DumpSharedSpaces || UseSharedSpaces) {\n+    init_shared_archive_paths();\n+  }\n@@ -3463,1 +3488,0 @@\n-  return JNI_OK;\n@@ -3512,1 +3536,0 @@\n-  FileMapInfo::check_archive((const char*)cur_path, true \/*is_static*\/);\n@@ -3524,1 +3547,0 @@\n-  FileMapInfo::check_archive((const char*)cur_path, false \/*is_static*\/);\n@@ -3535,0 +3557,5 @@\n+\n+    if (os::same_files((const char*)get_default_shared_archive_path(), ArchiveClassesAtExit)) {\n+      vm_exit_during_initialization(\n+        \"Cannot specify the default CDS archive for -XX:ArchiveClassesAtExit\", get_default_shared_archive_path());\n+    }\n@@ -3568,1 +3595,1 @@\n-        char* temp_archive_path = os::strdup_check_oom(SharedArchiveFile, mtArguments);\n+        char* base_archive_path = NULL;\n@@ -3570,1 +3597,1 @@\n-          FileMapInfo::get_base_archive_name_from_header(temp_archive_path, &SharedArchivePath);\n+          FileMapInfo::get_base_archive_name_from_header(SharedArchiveFile, &base_archive_path);\n@@ -3572,1 +3599,13 @@\n-          SharedArchivePath = temp_archive_path;\n+          \/\/ If +AutoCreateSharedArchive and the specified shared archive does not exist,\n+          \/\/ regenerate the dynamic archive base on default archive.\n+          if (AutoCreateSharedArchive && !os::file_exists(SharedArchiveFile)) {\n+            DynamicDumpSharedSpaces = true;\n+            ArchiveClassesAtExit = const_cast<char *>(SharedArchiveFile);\n+            SharedArchivePath = get_default_shared_archive_path();\n+            SharedArchiveFile = nullptr;\n+          } else {\n+            no_shared_spaces(\"invalid archive\");\n+          }\n+        } else if (base_archive_path == NULL) {\n+          \/\/ User has specified a single archive, which is a static archive.\n+          SharedArchivePath = const_cast<char *>(SharedArchiveFile);\n@@ -3574,1 +3613,3 @@\n-          SharedDynamicArchivePath = temp_archive_path;\n+          \/\/ User has specified a single archive, which is a dynamic archive.\n+          SharedDynamicArchivePath = const_cast<char *>(SharedArchiveFile);\n+          SharedArchivePath = base_archive_path; \/\/ has been c-heap allocated.\n@@ -3579,0 +3620,4 @@\n+        if (SharedArchivePath == NULL) {\n+          assert(SharedDynamicArchivePath == NULL, \"must be\");\n+          no_shared_spaces(\"invalid archive\");\n+        }\n@@ -3996,1 +4041,1 @@\n-  if ((UseSharedSpaces && FLAG_IS_CMDLINE(UseSharedSpaces)) ||\n+  if ((UseSharedSpaces && xshare_auto_cmd_line) ||\n@@ -3999,1 +4044,1 @@\n-    FLAG_SET_DEFAULT(UseSharedSpaces, false);\n+    UseSharedSpaces = false;\n@@ -4005,1 +4050,0 @@\n-#if INCLUDE_NMT\n@@ -4017,7 +4061,0 @@\n-#else\n-  if (!FLAG_IS_DEFAULT(NativeMemoryTracking) || PrintNMTStatistics) {\n-    warning(\"Native Memory Tracking is not supported in this VM\");\n-    FLAG_SET_DEFAULT(NativeMemoryTracking, \"off\");\n-    FLAG_SET_DEFAULT(PrintNMTStatistics, false);\n-  }\n-#endif \/\/ INCLUDE_NMT\n@@ -4051,2 +4088,1 @@\n-  result = set_shared_spaces_flags_and_archive_paths();\n-  if (result != JNI_OK) return result;\n+  set_shared_spaces_flags_and_archive_paths();\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":114,"deletions":78,"binary":false,"changes":192,"status":"modified"},{"patch":"@@ -171,3 +171,0 @@\n-  if (TraceDeoptimization) {\n-    tty->print_cr(\"Deoptimizing thread \" INTPTR_FORMAT, p2i(current));\n-  }\n@@ -187,1 +184,0 @@\n-#ifndef PRODUCT\n@@ -221,1 +217,0 @@\n-#endif\n@@ -266,0 +261,1 @@\n+      tty->cr();\n@@ -295,1 +291,0 @@\n-#ifndef PRODUCT\n@@ -299,1 +294,0 @@\n-#endif\n@@ -317,1 +311,1 @@\n-#endif\n+#endif \/\/ !PRODUCT\n@@ -463,0 +457,1 @@\n+#ifndef PRODUCT\n@@ -466,0 +461,2 @@\n+#endif \/\/ !PRODUCT\n+\n@@ -619,1 +616,1 @@\n-  if (deopt_sender.is_compiled_frame() || caller_was_method_handle) {\n+  if (deopt_sender.is_compiled_caller() || caller_was_method_handle) {\n@@ -761,10 +758,0 @@\n-\n-#ifndef PRODUCT\n-  if (TraceDeoptimization) {\n-    tty->print_cr(\"DEOPT UNPACKING thread \" INTPTR_FORMAT \" vframeArray \" INTPTR_FORMAT \" mode %d\",\n-                  p2i(thread), p2i(array), exec_mode);\n-  }\n-#endif\n-  Events::log_deopt_message(thread, \"DEOPT UNPACKING pc=\" INTPTR_FORMAT \" sp=\" INTPTR_FORMAT \" mode %d\",\n-              p2i(stub_frame.pc()), p2i(stub_frame.sp()), exec_mode);\n-\n@@ -832,0 +819,1 @@\n+      Bytecodes::Code next_code = Bytecodes::_shouldnotreachhere;\n@@ -840,1 +828,1 @@\n-        Bytecodes::Code next_code = str.next();\n+        next_code = str.next();\n@@ -888,0 +876,4 @@\n+          tty->print_cr(\"  Current code %s\", Bytecodes::name(cur_code));\n+          if (try_next_mask) {\n+            tty->print_cr(\"  Next code %s\", Bytecodes::name(next_code));\n+          }\n@@ -915,1 +907,1 @@\n-#endif \/* !PRODUCT *\/\n+#endif \/\/ !PRODUCT\n@@ -1505,0 +1497,1 @@\n+#ifndef PRODUCT\n@@ -1508,0 +1501,2 @@\n+#endif \/\/ !PRODUCT\n+\n@@ -1522,0 +1517,1 @@\n+#ifndef PRODUCT\n@@ -1529,0 +1525,1 @@\n+#endif \/\/ !PRODUCT\n@@ -1534,1 +1531,1 @@\n-#endif\n+#endif \/* !COMPILER2 *\/\n@@ -1595,30 +1592,0 @@\n-#ifndef PRODUCT\n-  if (PrintDeoptimizationDetails) {\n-    ResourceMark rm;\n-    stringStream st;\n-    st.print(\"DEOPT PACKING thread \" INTPTR_FORMAT \" \", p2i(thread));\n-    fr.print_on(&st);\n-    st.print_cr(\"     Virtual frames (innermost first):\");\n-    for (int index = 0; index < chunk->length(); index++) {\n-      compiledVFrame* vf = chunk->at(index);\n-      st.print(\"       %2d - \", index);\n-      vf->print_value_on(&st);\n-      int bci = chunk->at(index)->raw_bci();\n-      const char* code_name;\n-      if (bci == SynchronizationEntryBCI) {\n-        code_name = \"sync entry\";\n-      } else {\n-        Bytecodes::Code code = vf->method()->code_at(bci);\n-        code_name = Bytecodes::name(code);\n-      }\n-      st.print(\" - %s\", code_name);\n-      st.print_cr(\" @ bci %d \", bci);\n-      if (Verbose) {\n-        vf->print_on(&st);\n-        st.cr();\n-      }\n-    }\n-    tty->print_raw(st.as_string());\n-  }\n-#endif\n-\n@@ -1642,3 +1609,25 @@\n-#ifndef PRODUCT\n-  if (PrintDeoptimizationDetails) {\n-    tty->print_cr(\"     Created vframeArray \" INTPTR_FORMAT, p2i(array));\n+  if (TraceDeoptimization) {\n+    ResourceMark rm;\n+    stringStream st;\n+    st.print_cr(\"DEOPT PACKING thread=\" INTPTR_FORMAT \" vframeArray=\" INTPTR_FORMAT, p2i(thread), p2i(array));\n+    st.print(\"   \");\n+    fr.print_on(&st);\n+    st.print_cr(\"   Virtual frames (innermost\/newest first):\");\n+    for (int index = 0; index < chunk->length(); index++) {\n+      compiledVFrame* vf = chunk->at(index);\n+      int bci = vf->raw_bci();\n+      const char* code_name;\n+      if (bci == SynchronizationEntryBCI) {\n+        code_name = \"sync entry\";\n+      } else {\n+        Bytecodes::Code code = vf->method()->code_at(bci);\n+        code_name = Bytecodes::name(code);\n+      }\n+\n+      st.print(\"      VFrame %d (\" INTPTR_FORMAT \")\", index, p2i(vf));\n+      st.print(\" - %s\", vf->method()->name_and_sig_as_C_string());\n+      st.print(\" - %s\", code_name);\n+      st.print_cr(\" @ bci=%d \", bci);\n+    }\n+    tty->print_raw(st.as_string());\n+    tty->cr();\n@@ -1646,1 +1635,0 @@\n-#endif \/\/ PRODUCT\n@@ -1913,0 +1901,1 @@\n+\n@@ -1950,6 +1939,4 @@\n-    if (TraceDeoptimization || is_receiver_constraint_failure) {\n-      tty->print_cr(\"  bci=%d pc=\" INTPTR_FORMAT \", relative_pc=\" INTPTR_FORMAT \", method=%s\" JVMCI_ONLY(\", debug_id=%d\"), trap_scope->bci(), p2i(fr.pc()), fr.pc() - nm->code_begin(), trap_scope->method()->name_and_sig_as_C_string()\n-#if INCLUDE_JVMCI\n-          , debug_id\n-#endif\n-          );\n+    if (is_receiver_constraint_failure) {\n+      tty->print_cr(\"  bci=%d pc=\" INTPTR_FORMAT \", relative_pc=\" INTPTR_FORMAT \", method=%s\" JVMCI_ONLY(\", debug_id=%d\"),\n+                    trap_scope->bci(), p2i(fr.pc()), fr.pc() - nm->code_begin(), trap_scope->method()->name_and_sig_as_C_string()\n+                    JVMCI_ONLY(COMMA debug_id));\n@@ -2061,3 +2048,5 @@\n-        tty->print(\"Uncommon trap occurred in\");\n-        nm->method()->print_short_name(tty);\n-        tty->print(\" compiler=%s compile_id=%d\", nm->compiler_name(), nm->compile_id());\n+        stringStream st;\n+        st.print(\"UNCOMMON TRAP method=%s\", trap_scope->method()->name_and_sig_as_C_string());\n+        st.print(\"  bci=%d pc=\" INTPTR_FORMAT \", relative_pc=\" INTPTR_FORMAT JVMCI_ONLY(\", debug_id=%d\"),\n+                 trap_scope->bci(), p2i(fr.pc()), fr.pc() - nm->code_begin() JVMCI_ONLY(COMMA debug_id));\n+        st.print(\" compiler=%s compile_id=%d\", nm->compiler_name(), nm->compile_id());\n@@ -2068,1 +2057,1 @@\n-            tty->print(\" (JVMCI: installed code name=%s) \", installed_code_name);\n+            st.print(\" (JVMCI: installed code name=%s) \", installed_code_name);\n@@ -2072,1 +2061,1 @@\n-        tty->print(\" (@\" INTPTR_FORMAT \") thread=\" UINTX_FORMAT \" reason=%s action=%s unloaded_class_index=%d\" JVMCI_ONLY(\" debug_id=%d\"),\n+        st.print(\" (@\" INTPTR_FORMAT \") thread=\" UINTX_FORMAT \" reason=%s action=%s unloaded_class_index=%d\" JVMCI_ONLY(\" debug_id=%d\"),\n@@ -2083,2 +2072,2 @@\n-          tty->print(unresolved ? \" unresolved class: \" : \" symbol: \");\n-          class_name->print_symbol_on(tty);\n+          st.print(unresolved ? \" unresolved class: \" : \" symbol: \");\n+          class_name->print_symbol_on(&st);\n@@ -2086,1 +2075,2 @@\n-        tty->cr();\n+        st.cr();\n+        tty->print_raw(st.as_string());\n@@ -2374,1 +2364,2 @@\n-      idx += Reason_LIMIT;\n+      \/\/ Upper half of history array used for traps in OSR compilations\n+      idx += Reason_TRAP_HISTORY_LENGTH;\n@@ -2464,3 +2455,0 @@\n-  if (TraceDeoptimization) {\n-    tty->print(\"Uncommon trap \");\n-  }\n@@ -2708,0 +2696,24 @@\n+\/\/ Get the deopt count for a specific reason and a specific action. If either\n+\/\/ one of 'reason' or 'action' is null, the method returns the sum of all\n+\/\/ deoptimizations with the specific 'action' or 'reason' respectively.\n+\/\/ If both arguments are null, the method returns the total deopt count.\n+jint Deoptimization::deoptimization_count(const char *reason_str, const char *action_str) {\n+  if (reason_str == NULL && action_str == NULL) {\n+    return total_deoptimization_count();\n+  }\n+  juint counter = 0;\n+  for (int reason = 0; reason < Reason_LIMIT; reason++) {\n+    if (reason_str == NULL || !strcmp(reason_str, trap_reason_name(reason))) {\n+      for (int action = 0; action < Action_LIMIT; action++) {\n+        if (action_str == NULL || !strcmp(action_str, trap_action_name(action))) {\n+          juint* cases = _deoptimization_hist[reason][1+action];\n+          for (int bc_case = 0; bc_case < BC_CASE_LIMIT; bc_case++) {\n+            counter += cases[bc_case] >> LSB_BITS;\n+          }\n+        }\n+      }\n+    }\n+  }\n+  return counter;\n+}\n+\n@@ -2761,0 +2773,8 @@\n+jint Deoptimization::total_deoptimization_count() {\n+  return 0;\n+}\n+\n+jint Deoptimization::deoptimization_count(const char *reason_str, const char *action_str) {\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":94,"deletions":74,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+  \/\/ Note: Keep this enum in sync. with Deoptimization::_trap_reason_name.\n@@ -101,0 +102,3 @@\n+    \/\/ Used to define MethodData::_trap_hist_limit where Reason_tenured isn't included\n+    Reason_TRAP_HISTORY_LENGTH,\n+\n@@ -102,2 +106,1 @@\n-    \/\/ Related to MethodData::_trap_hist_limit where Reason_tenured isn't included\n-    Reason_tenured,               \/\/ age of the code has reached the limit\n+    Reason_tenured = Reason_TRAP_HISTORY_LENGTH, \/\/ age of the code has reached the limit\n@@ -106,2 +109,0 @@\n-    \/\/ Note:  Keep this enum in sync. with _trap_reason_name.\n-    Reason_RECORDED_LIMIT = Reason_profile_predicate  \/\/ some are not recorded per bc\n@@ -112,0 +113,1 @@\n+    Reason_RECORDED_LIMIT = Reason_profile_predicate,  \/\/ some are not recorded per bc\n@@ -115,0 +117,1 @@\n+  \/\/ Note: Keep this enum in sync. with Deoptimization::_trap_action_name.\n@@ -122,1 +125,0 @@\n-    \/\/ Note:  Keep this enum in sync. with _trap_action_name.\n@@ -438,0 +440,1 @@\n+  static jint deoptimization_count(const char* reason_str, const char* action_str);\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.hpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -468,0 +468,1 @@\n+  st->print_cr(\")\");\n@@ -470,2 +471,0 @@\n-    st->print_cr(\")\");\n-    st->print(\"(\");\n@@ -476,2 +475,0 @@\n-    st->print_cr(\")\");\n-    st->print(\"(\");\n@@ -487,1 +484,1 @@\n-  st->print_cr(\")\");\n+#ifndef PRODUCT\n@@ -492,2 +489,0 @@\n-    st->cr();\n-#ifndef PRODUCT\n@@ -498,2 +493,2 @@\n-#endif\n-  NOT_PRODUCT(if (WizardMode && Verbose) Disassembler::decode(begin, end);)\n+  if (WizardMode && Verbose) Disassembler::decode(begin, end);\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":4,"deletions":9,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -149,0 +149,5 @@\n+  \/\/ is this frame doing a call using the compiled calling convention?\n+  bool is_compiled_caller() const {\n+    return is_compiled_frame() || is_optimized_entry_frame();\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -546,1 +546,1 @@\n-  product(ccstr, NativeMemoryTracking, \"off\",                               \\\n+  product(ccstr, NativeMemoryTracking, DEBUG_ONLY(\"summary\") NOT_DEBUG(\"off\"), \\\n@@ -722,4 +722,0 @@\n-  product(bool, FilterSpuriousWakeups, true,                                \\\n-          \"(Deprecated) When true prevents OS-level spurious, or premature,\"\\\n-          \" wakeups from Object.wait (Ignored for Windows)\")                \\\n-                                                                            \\\n@@ -1087,1 +1083,6 @@\n-          \"use heavyweight instead of lightweight Java monitors\")           \\\n+          \"(Deprecated) Use heavyweight instead of lightweight Java \"       \\\n+          \"monitors\")                                                       \\\n+                                                                            \\\n+  develop(bool, VerifyHeavyMonitors, false,                                 \\\n+          \"Checks that no stack locking happens when using \"                \\\n+          \"+UseHeavyMonitors\")                                              \\\n@@ -1211,4 +1212,0 @@\n-  notproduct(bool, VerifyJNIEnvThread, false,                               \\\n-          \"Verify JNIEnv.thread == Thread::current() when entering VM \"     \\\n-          \"from JNI\")                                                       \\\n-                                                                            \\\n@@ -1301,1 +1298,1 @@\n-  develop(bool, TraceDeoptimization, false,                                 \\\n+  product(bool, TraceDeoptimization, false, DIAGNOSTIC,                     \\\n@@ -1366,5 +1363,0 @@\n-  product(intx, MinInliningThreshold, 0,                                    \\\n-          \"(Deprecated) The minimum invocation count a method needs to\"     \\\n-          \"have to be inlined\")                                             \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n@@ -1821,3 +1813,0 @@\n-  product(bool, UseSharedSpaces, true,                                      \\\n-          \"(Deprecated) Use shared spaces for metadata\")                    \\\n-                                                                            \\\n@@ -1827,11 +1816,0 @@\n-  product(bool, RequireSharedSpaces, false,                                 \\\n-          \"(Deprecated) Require shared spaces for metadata\")                \\\n-                                                                            \\\n-  product(bool, DumpSharedSpaces, false,                                    \\\n-          \"(Deprecated) Special mode: JVM reads a class list, loads \"       \\\n-          \"classes, builds shared spaces, and dumps the shared spaces to \"  \\\n-          \"a file to be used in future JVM runs\")                           \\\n-                                                                            \\\n-  product(bool, DynamicDumpSharedSpaces, false,                             \\\n-          \"(Deprecated) Dynamic archive\")                                   \\\n-                                                                            \\\n@@ -1841,0 +1819,3 @@\n+  product(bool, AutoCreateSharedArchive, false,                             \\\n+          \"Create shared archive at exit if cds mapping failed\")            \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":12,"deletions":31,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -173,5 +173,0 @@\n-void JNIHandles::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* f) {\n-  weak_global_handles()->weak_oops_do(is_alive, f);\n-}\n-\n-\n","filename":"src\/hotspot\/share\/runtime\/jniHandles.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -172,0 +172,8 @@\n+    \/\/ Robustness: asserted in the caller, but handle\/tolerate it for release bits.\n+    LogTarget(Error, safepoint) lt;\n+    if (lt.is_enabled()) {\n+      ResourceMark rm;\n+      LogStream ls(lt);\n+      ls.print(\"Illegal initial state detected: \");\n+      cur_state->print_on(&ls);\n+    }\n@@ -750,0 +758,1 @@\n+  thread->set_thread_state(_thread_in_vm);\n@@ -761,0 +770,2 @@\n+\n+  thread->set_thread_state(_thread_in_Java);\n@@ -986,1 +997,0 @@\n-      ThreadInVMfromJava __tiv(self, false \/* check asyncs *\/);\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,1 +33,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n@@ -409,2 +409,0 @@\n-  static size_t trampoline_size();\n-\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -60,0 +60,34 @@\n+class CleanupObjectMonitorsHashtable: StackObj {\n+ public:\n+  bool do_entry(void*& key, ObjectMonitorsHashtable::PtrList*& list) {\n+    list->clear();  \/\/ clear the LinkListNodes\n+    delete list;    \/\/ then delete the LinkedList\n+    return true;\n+  }\n+};\n+\n+ObjectMonitorsHashtable::~ObjectMonitorsHashtable() {\n+  CleanupObjectMonitorsHashtable cleanup;\n+  _ptrs->unlink(&cleanup);  \/\/ cleanup the LinkedLists\n+  delete _ptrs;             \/\/ then delete the hash table\n+}\n+\n+void ObjectMonitorsHashtable::add_entry(void* key, ObjectMonitor* om) {\n+  ObjectMonitorsHashtable::PtrList* list = get_entry(key);\n+  if (list == nullptr) {\n+    \/\/ Create new list and add it to the hash table:\n+    list = new (ResourceObj::C_HEAP, mtThread) ObjectMonitorsHashtable::PtrList();\n+    add_entry(key, list);\n+  }\n+  list->add(om);  \/\/ Add the ObjectMonitor to the list.\n+  _om_count++;\n+}\n+\n+bool ObjectMonitorsHashtable::has_entry(void* key, ObjectMonitor* om) {\n+  ObjectMonitorsHashtable::PtrList* list = get_entry(key);\n+  if (list == nullptr || list->find(om) == nullptr) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n@@ -436,0 +470,8 @@\n+static bool useHeavyMonitors() {\n+#if defined(X86) || defined(AARCH64) || defined(PPC64)\n+  return UseHeavyMonitors;\n+#else\n+  return false;\n+#endif\n+}\n+\n@@ -448,6 +490,15 @@\n-  markWord mark = obj->mark();\n-  if (mark.is_neutral()) {\n-    \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n-    \/\/ be visible <= the ST performed by the CAS.\n-    lock->set_displaced_header(mark);\n-    if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+  if (!useHeavyMonitors()) {\n+    markWord mark = obj->mark();\n+    if (mark.is_neutral()) {\n+      \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n+      \/\/ be visible <= the ST performed by the CAS.\n+      lock->set_displaced_header(mark);\n+      if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+        return;\n+      }\n+      \/\/ Fall through to inflate() ...\n+    } else if (mark.has_locker() &&\n+               current->is_lock_owned((address)mark.locker())) {\n+      assert(lock != mark.locker(), \"must not re-lock the same lock\");\n+      assert(lock != (BasicLock*)obj->mark().value(), \"don't relock with same BasicLock\");\n+      lock->set_displaced_header(markWord::from_pointer(NULL));\n@@ -456,7 +507,8 @@\n-    \/\/ Fall through to inflate() ...\n-  } else if (mark.has_locker() &&\n-             current->is_lock_owned((address)mark.locker())) {\n-    assert(lock != mark.locker(), \"must not re-lock the same lock\");\n-    assert(lock != (BasicLock*)obj->mark().value(), \"don't relock with same BasicLock\");\n-    lock->set_displaced_header(markWord::from_pointer(NULL));\n-    return;\n+\n+    \/\/ The object header will never be displaced to this lock,\n+    \/\/ so it does not matter what the value is, except that it\n+    \/\/ must be non-zero to avoid looking like a re-entrant lock,\n+    \/\/ and must not look locked either.\n+    lock->set_displaced_header(markWord::unused_mark());\n+  } else if (VerifyHeavyMonitors) {\n+    guarantee(!obj->mark().has_locker(), \"must not be stack-locked\");\n@@ -465,5 +517,0 @@\n-  \/\/ The object header will never be displaced to this lock,\n-  \/\/ so it does not matter what the value is, except that it\n-  \/\/ must be non-zero to avoid looking like a re-entrant lock,\n-  \/\/ and must not look locked either.\n-  lock->set_displaced_header(markWord::unused_mark());\n@@ -482,5 +529,6 @@\n-  markWord mark = object->mark();\n-  if (EnableValhalla && mark.is_inline_type()) {\n-    return;\n-  }\n-  assert(!EnableValhalla || !object->klass()->is_inline_klass(), \"monitor op on inline type\");\n+  if (!useHeavyMonitors()) {\n+    markWord mark = object->mark();\n+    if (EnableValhalla && mark.is_inline_type()) {\n+      return;\n+    }\n+    assert(!EnableValhalla || !object->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -488,4 +536,4 @@\n-  markWord dhw = lock->displaced_header();\n-  if (dhw.value() == 0) {\n-    \/\/ If the displaced header is NULL, then this exit matches up with\n-    \/\/ a recursive enter. No real work to do here except for diagnostics.\n+    markWord dhw = lock->displaced_header();\n+    if (dhw.value() == 0) {\n+      \/\/ If the displaced header is NULL, then this exit matches up with\n+      \/\/ a recursive enter. No real work to do here except for diagnostics.\n@@ -493,19 +541,20 @@\n-    if (mark != markWord::INFLATING()) {\n-      \/\/ Only do diagnostics if we are not racing an inflation. Simply\n-      \/\/ exiting a recursive enter of a Java Monitor that is being\n-      \/\/ inflated is safe; see the has_monitor() comment below.\n-      assert(!mark.is_neutral(), \"invariant\");\n-      assert(!mark.has_locker() ||\n-             current->is_lock_owned((address)mark.locker()), \"invariant\");\n-      if (mark.has_monitor()) {\n-        \/\/ The BasicLock's displaced_header is marked as a recursive\n-        \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n-        \/\/ This is a special case where the Java Monitor was inflated\n-        \/\/ after this thread entered the stack-lock recursively. When a\n-        \/\/ Java Monitor is inflated, we cannot safely walk the Java\n-        \/\/ Monitor owner's stack and update the BasicLocks because a\n-        \/\/ Java Monitor can be asynchronously inflated by a thread that\n-        \/\/ does not own the Java Monitor.\n-        ObjectMonitor* m = mark.monitor();\n-        assert(m->object()->mark() == mark, \"invariant\");\n-        assert(m->is_entered(current), \"invariant\");\n+      if (mark != markWord::INFLATING()) {\n+        \/\/ Only do diagnostics if we are not racing an inflation. Simply\n+        \/\/ exiting a recursive enter of a Java Monitor that is being\n+        \/\/ inflated is safe; see the has_monitor() comment below.\n+        assert(!mark.is_neutral(), \"invariant\");\n+        assert(!mark.has_locker() ||\n+        current->is_lock_owned((address)mark.locker()), \"invariant\");\n+        if (mark.has_monitor()) {\n+          \/\/ The BasicLock's displaced_header is marked as a recursive\n+          \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n+          \/\/ This is a special case where the Java Monitor was inflated\n+          \/\/ after this thread entered the stack-lock recursively. When a\n+          \/\/ Java Monitor is inflated, we cannot safely walk the Java\n+          \/\/ Monitor owner's stack and update the BasicLocks because a\n+          \/\/ Java Monitor can be asynchronously inflated by a thread that\n+          \/\/ does not own the Java Monitor.\n+          ObjectMonitor* m = mark.monitor();\n+          assert(m->object()->mark() == mark, \"invariant\");\n+          assert(m->is_entered(current), \"invariant\");\n+        }\n@@ -513,9 +562,0 @@\n-    }\n-    return;\n-  }\n-\n-  if (mark == markWord::from_pointer(lock)) {\n-    \/\/ If the object is stack-locked by the current thread, try to\n-    \/\/ swing the displaced header from the BasicLock back to the mark.\n-    assert(dhw.is_neutral(), \"invariant\");\n-    if (object->cas_set_mark(dhw, mark) == mark) {\n@@ -525,0 +565,11 @@\n+\n+    if (mark == markWord::from_pointer(lock)) {\n+      \/\/ If the object is stack-locked by the current thread, try to\n+      \/\/ swing the displaced header from the BasicLock back to the mark.\n+      assert(dhw.is_neutral(), \"invariant\");\n+      if (object->cas_set_mark(dhw, mark) == mark) {\n+        return;\n+      }\n+    }\n+  } else if (VerifyHeavyMonitors) {\n+    guarantee(!object->mark().has_locker(), \"must not be stack-locked\");\n@@ -842,1 +893,4 @@\n-\n+    if (VerifyHeavyMonitors) {\n+      assert(UseHeavyMonitors, \"+VerifyHeavyMonitors requires +UseHeavyMonitors\");\n+      guarantee(!mark.has_locker(), \"must not be stack locked\");\n+    }\n@@ -1007,0 +1061,5 @@\n+\/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n+\/\/ ObjectMonitors where owner is set to a stack lock address in thread.\n+\/\/\n+\/\/ This version of monitors_iterate() works with the in-use monitor list.\n+\/\/\n@@ -1012,0 +1071,2 @@\n+      \/\/ Not owned by the target thread and intentionally skips when owner\n+      \/\/ is set to a stack lock address in the target thread.\n@@ -1028,0 +1089,25 @@\n+\/\/ This version of monitors_iterate() works with the specified linked list.\n+\/\/\n+void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure,\n+                                          ObjectMonitorsHashtable::PtrList* list,\n+                                          JavaThread* thread) {\n+  typedef LinkedListIterator<ObjectMonitor*> ObjectMonitorIterator;\n+  ObjectMonitorIterator iter(list->head());\n+  while (!iter.is_empty()) {\n+    ObjectMonitor* mid = *iter.next();\n+    \/\/ Owner set to a stack lock address in thread should never be seen here:\n+    assert(mid->owner() == thread, \"must be\");\n+    if (!mid->is_being_async_deflated() && mid->object_peek() != NULL) {\n+      \/\/ Only process with closure if the object is set.\n+\n+      \/\/ monitors_iterate() is only called at a safepoint or when the\n+      \/\/ target thread is suspended or when the target thread is\n+      \/\/ operating on itself. The current closures in use today are\n+      \/\/ only interested in an owned ObjectMonitor and ownership\n+      \/\/ cannot be dropped under the calling contexts so the\n+      \/\/ ObjectMonitor cannot be async deflated.\n+      closure->do_monitor(mid);\n+    }\n+  }\n+}\n+\n@@ -1357,0 +1443,8 @@\n+\/\/\n+\/\/ If table != nullptr, we gather owned ObjectMonitors indexed by the\n+\/\/ owner in the table. Please note that ObjectMonitors where the owner\n+\/\/ is set to a stack lock address are NOT associated with the JavaThread\n+\/\/ that holds that stack lock. All of the current consumers of\n+\/\/ ObjectMonitorsHashtable info only care about JNI locked monitors and\n+\/\/ those do not have the owner set to a stack lock address.\n+\/\/\n@@ -1358,1 +1452,2 @@\n-                                                elapsedTimer* timer_p) {\n+                                                elapsedTimer* timer_p,\n+                                                ObjectMonitorsHashtable* table) {\n@@ -1369,0 +1464,12 @@\n+    } else if (table != nullptr) {\n+      \/\/ The caller is interested in the owned ObjectMonitors. This does\n+      \/\/ not include when owner is set to a stack lock address in thread.\n+      \/\/ This also does not capture unowned ObjectMonitors that cannot be\n+      \/\/ deflated because of a waiter.\n+      void* key = mid->owner();\n+      \/\/ Since deflate_idle_monitors() and deflate_monitor_list() can be\n+      \/\/ called more than once, we have to make sure the entry has not\n+      \/\/ already been added.\n+      if (key != nullptr && !table->has_entry(key, mid)) {\n+        table->add_entry(key, mid);\n+      }\n@@ -1393,2 +1500,2 @@\n-\/\/ by the VMThread.\n-size_t ObjectSynchronizer::deflate_idle_monitors() {\n+\/\/ and VM_ThreadDump::doit() by the VMThread.\n+size_t ObjectSynchronizer::deflate_idle_monitors(ObjectMonitorsHashtable* table) {\n@@ -1419,1 +1526,1 @@\n-  size_t deflated_count = deflate_monitor_list(current, ls, &timer);\n+  size_t deflated_count = deflate_monitor_list(current, ls, &timer, table);\n@@ -1477,0 +1584,4 @@\n+    if (table != nullptr) {\n+      ls->print_cr(\"ObjectMonitorsHashtable: key_count=\" SIZE_FORMAT \", om_count=\" SIZE_FORMAT,\n+                   table->key_count(), table->om_count());\n+    }\n@@ -1579,1 +1690,1 @@\n-    while (ObjectSynchronizer::deflate_idle_monitors() != 0) {\n+    while (ObjectSynchronizer::deflate_idle_monitors(\/* ObjectMonitorsHashtable is not needed here *\/ nullptr) >= (size_t)MonitorDeflationMax) {\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":172,"deletions":61,"binary":false,"changes":233,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -321,1 +321,0 @@\n-#if INCLUDE_NMT\n@@ -329,1 +328,0 @@\n-#endif \/\/ INCLUDE_NMT\n@@ -1115,1 +1113,1 @@\n-  osthread()->set_interrupted(true);\n+  WINDOWS_ONLY(osthread()->set_interrupted(true);)\n@@ -1160,1 +1158,1 @@\n-    osthread()->set_interrupted(false);\n+    WINDOWS_ONLY(osthread()->set_interrupted(false);)\n@@ -1650,18 +1648,4 @@\n-    switch (thread_state()) {\n-    case _thread_in_vm: {\n-      JavaThread* THREAD = this;\n-      Exceptions::throw_unsafe_access_internal_error(THREAD, __FILE__, __LINE__, \"a fault occurred in an unsafe memory access operation\");\n-      \/\/ We might have blocked in a ThreadBlockInVM wrapper in the call above so make sure we process pending\n-      \/\/ suspend requests and object reallocation operations if any since we might be going to Java after this.\n-      SafepointMechanism::process_if_requested_with_exit_check(this, true \/* check asyncs *\/);\n-      return;\n-    }\n-    case _thread_in_Java: {\n-      ThreadInVMfromJava tiv(this);\n-      JavaThread* THREAD = this;\n-      Exceptions::throw_unsafe_access_internal_error(THREAD, __FILE__, __LINE__, \"a fault occurred in an unsafe memory access operation in compiled Java code\");\n-      return;\n-    }\n-    default:\n-      ShouldNotReachHere();\n-    }\n+    Exceptions::throw_unsafe_access_internal_error(this, __FILE__, __LINE__, \"a fault occurred in an unsafe memory access operation\");\n+    \/\/ We might have blocked in a ThreadBlockInVM wrapper in the call above so make sure we process pending\n+    \/\/ suspend requests and object reallocation operations if any since we might be going to Java after this.\n+    SafepointMechanism::process_if_requested_with_exit_check(this, true \/* check asyncs *\/);\n@@ -1774,12 +1758,5 @@\n-\/\/ this thread.\n-\/\/ Raw thread state transition to _thread_blocked and back again to the original\n-\/\/ state before returning are performed. The current thread is required to\n-\/\/ change to _thread_blocked in order to be seen to be safepoint\/handshake safe\n-\/\/ whilst suspended and only after becoming handshake safe, the other thread can\n-\/\/ complete the handshake used to synchronize with this thread and then perform\n-\/\/ the reallocation and relocking. We cannot use the thread state transition\n-\/\/ helpers because we arrive here in various states and also because the helpers\n-\/\/ indirectly call this method.  After leaving _thread_blocked we have to check\n-\/\/ for safepoint\/handshake, except if _thread_in_native. The thread is safe\n-\/\/ without blocking then. Allowed states are enumerated in\n-\/\/ SafepointSynchronize::block(). See also EscapeBarrier::sync_and_suspend_*()\n+\/\/ this thread. The current thread is required to change to _thread_blocked in order\n+\/\/ to be seen to be safepoint\/handshake safe whilst suspended and only after becoming\n+\/\/ handshake safe, the other thread can complete the handshake used to synchronize\n+\/\/ with this thread and then perform the reallocation and relocking.\n+\/\/ See EscapeBarrier::sync_and_suspend_*()\n@@ -1790,1 +1767,0 @@\n-  JavaThreadState state = thread_state();\n@@ -1794,1 +1770,1 @@\n-    set_thread_state(_thread_blocked);\n+    ThreadBlockInVM tbivm(this, true \/* allow_suspend *\/);\n@@ -1812,8 +1788,0 @@\n-    \/\/ The current thread could have been suspended again. We have to check for\n-    \/\/ suspend after restoring the saved state. Without this the current thread\n-    \/\/ might return to _thread_in_Java and execute bytecode.\n-    set_thread_state_fence(state);\n-\n-    if (state != _thread_in_native) {\n-      SafepointMechanism::process_if_requested(this);\n-    }\n@@ -2738,1 +2706,0 @@\n-#if INCLUDE_NMT\n@@ -2741,1 +2708,0 @@\n-#endif \/\/ INCLUDE_NMT\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":13,"deletions":47,"binary":false,"changes":60,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -553,2 +553,2 @@\n-  void    register_thread_stack_with_NMT() NOT_NMT_RETURN;\n-  void    unregister_thread_stack_with_NMT() NOT_NMT_RETURN;\n+  void    register_thread_stack_with_NMT();\n+  void    unregister_thread_stack_with_NMT();\n@@ -1321,0 +1321,3 @@\n+  \/\/ Returns the current thread as indicated by the given JNIEnv.\n+  \/\/ We don't assert it is Thread::current here as that is done at the\n+  \/\/ external JNI entry points where the JNIEnv is passed into the VM.\n@@ -1322,8 +1325,9 @@\n-    JavaThread *thread_from_jni_env = (JavaThread*)((intptr_t)env - in_bytes(jni_environment_offset()));\n-    \/\/ Only return NULL if thread is off the thread list; starting to\n-    \/\/ exit should not return NULL.\n-    if (thread_from_jni_env->is_terminated()) {\n-      thread_from_jni_env->block_if_vm_exited();\n-      return NULL;\n-    } else {\n-      return thread_from_jni_env;\n+    JavaThread* current = (JavaThread*)((intptr_t)env - in_bytes(jni_environment_offset()));\n+    \/\/ We can't get here in a thread that has completed its execution and so\n+    \/\/ \"is_terminated\", but a thread is also considered terminated if the VM\n+    \/\/ has exited, so we have to check this and block in case this is a daemon\n+    \/\/ thread returning to the VM (the JNI DirectBuffer entry points rely on\n+    \/\/ this).\n+    if (current->is_terminated()) {\n+      current->block_if_vm_exited();\n+      ShouldNotReachHere();\n@@ -1331,0 +1335,1 @@\n+    return current;\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":16,"deletions":11,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -38,1 +38,2 @@\n-  template(None)                                  \\\n+  template(Halt)                                  \\\n+  template(SafepointALot)                         \\\n@@ -45,1 +46,0 @@\n-  template(ForceAsyncSafepoint)                   \\\n@@ -51,1 +51,0 @@\n-  template(DeoptimizeTheWorld)                    \\\n@@ -55,1 +54,0 @@\n-  template(GenCollectFullConcurrent)              \\\n@@ -61,1 +59,2 @@\n-  template(G1Concurrent)                          \\\n+  template(G1PauseRemark)                         \\\n+  template(G1PauseCleanup)                        \\\n@@ -67,2 +66,0 @@\n-  template(HandshakeOneThread)                    \\\n-  template(HandshakeFallback)                     \\\n@@ -92,1 +89,0 @@\n-  template(RotateGCLog)                           \\\n@@ -102,3 +98,0 @@\n-  template(ThreadSuspend)                         \\\n-  template(ThreadsSuspendJVMTI)                   \\\n-  template(ScavengeMonitors)                      \\\n@@ -108,0 +101,1 @@\n+  template(GTestStopSafepoint)                    \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":5,"deletions":11,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -282,0 +282,12 @@\n+  ObjectMonitorsHashtable table;\n+  ObjectMonitorsHashtable* tablep = nullptr;\n+  if (_with_locked_monitors) {\n+    \/\/ The caller wants locked monitor information and that's expensive to gather\n+    \/\/ when there are a lot of inflated monitors. So we deflate idle monitors and\n+    \/\/ gather information about owned monitors at the same time.\n+    tablep = &table;\n+    while (ObjectSynchronizer::deflate_idle_monitors(tablep) >= (size_t)MonitorDeflationMax) {\n+      ; \/* empty *\/\n+    }\n+  }\n+\n@@ -296,1 +308,1 @@\n-      snapshot_thread(jt, tcl);\n+      snapshot_thread(jt, tcl, tablep);\n@@ -331,1 +343,1 @@\n-      snapshot_thread(jt, tcl);\n+      snapshot_thread(jt, tcl, tablep);\n@@ -336,1 +348,2 @@\n-void VM_ThreadDump::snapshot_thread(JavaThread* java_thread, ThreadConcurrentLocks* tcl) {\n+void VM_ThreadDump::snapshot_thread(JavaThread* java_thread, ThreadConcurrentLocks* tcl,\n+                                    ObjectMonitorsHashtable* table) {\n@@ -338,1 +351,1 @@\n-  snapshot->dump_stack_at_safepoint(_max_depth, _with_locked_monitors);\n+  snapshot->dump_stack_at_safepoint(_max_depth, _with_locked_monitors, table);\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -35,7 +35,8 @@\n-class VM_None: public VM_Operation {\n-  const char* _reason;\n- public:\n-  VM_None(const char* reason) : _reason(reason) {}\n-  const char* name() const { return _reason; }\n-  VMOp_Type type() const { return VMOp_None; }\n-  void doit() {};\n+class VM_EmptyOperation : public VM_Operation {\n+public:\n+  virtual void doit() final {}\n+  virtual bool skip_thread_oop_barriers() const final {\n+    \/\/ Neither the doit function nor the the safepoint\n+    \/\/ cleanup tasks read oops in the Java threads.\n+    return true;\n+  }\n@@ -44,1 +45,1 @@\n-class VM_Cleanup: public VM_Operation {\n+class VM_Halt: public VM_EmptyOperation {\n@@ -46,2 +47,1 @@\n-  VMOp_Type type() const { return VMOp_Cleanup; }\n-  void doit() {};\n+  VMOp_Type type() const { return VMOp_Halt; }\n@@ -50,3 +50,1 @@\n-class VM_ClearICs: public VM_Operation {\n- private:\n-  bool _preserve_static_stubs;\n+class VM_SafepointALot: public VM_EmptyOperation {\n@@ -54,3 +52,1 @@\n-  VM_ClearICs(bool preserve_static_stubs) { _preserve_static_stubs = preserve_static_stubs; }\n-  void doit();\n-  VMOp_Type type() const { return VMOp_ClearICs; }\n+  VMOp_Type type() const { return VMOp_SafepointALot; }\n@@ -59,2 +55,1 @@\n-\/\/ empty vm op, evaluated just to force a safepoint\n-class VM_ForceSafepoint: public VM_Operation {\n+class VM_Cleanup: public VM_EmptyOperation {\n@@ -62,2 +57,1 @@\n-  void doit()         {}\n-  VMOp_Type type() const { return VMOp_ForceSafepoint; }\n+  VMOp_Type type() const { return VMOp_Cleanup; }\n@@ -66,2 +60,2 @@\n-\/\/ empty vm op, when forcing a safepoint to suspend a thread\n-class VM_ThreadSuspend: public VM_ForceSafepoint {\n+\/\/ empty vm op, evaluated just to force a safepoint\n+class VM_ForceSafepoint: public VM_EmptyOperation {\n@@ -69,1 +63,1 @@\n-  VMOp_Type type() const { return VMOp_ThreadSuspend; }\n+  VMOp_Type type() const { return VMOp_ForceSafepoint; }\n@@ -72,2 +66,2 @@\n-\/\/ empty vm op, when forcing a safepoint to suspend threads from jvmti\n-class VM_ThreadsSuspendJVMTI: public VM_ForceSafepoint {\n+\/\/ empty vm op, when forcing a safepoint due to inline cache buffers being full\n+class VM_ICBufferFull: public VM_EmptyOperation {\n@@ -75,1 +69,1 @@\n-  VMOp_Type type() const { return VMOp_ThreadsSuspendJVMTI; }\n+  VMOp_Type type() const { return VMOp_ICBufferFull; }\n@@ -78,2 +72,3 @@\n-\/\/ empty vm op, when forcing a safepoint due to inline cache buffers being full\n-class VM_ICBufferFull: public VM_ForceSafepoint {\n+class VM_ClearICs: public VM_Operation {\n+ private:\n+  bool _preserve_static_stubs;\n@@ -81,2 +76,3 @@\n-  VMOp_Type type() const { return VMOp_ICBufferFull; }\n-  virtual bool skip_thread_oop_barriers() const { return true; }\n+  VM_ClearICs(bool preserve_static_stubs) { _preserve_static_stubs = preserve_static_stubs; }\n+  void doit();\n+  VMOp_Type type() const { return VMOp_ClearICs; }\n@@ -210,1 +206,2 @@\n-  void snapshot_thread(JavaThread* java_thread, ThreadConcurrentLocks* tcl);\n+  void snapshot_thread(JavaThread* java_thread, ThreadConcurrentLocks* tcl,\n+                       ObjectMonitorsHashtable* table);\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.hpp","additions":28,"deletions":31,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1775,0 +1775,1 @@\n+  declare_c2_type(PopCountVLNode, VectorNode)                             \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"oops\/instanceKlass.hpp\"\n@@ -422,0 +423,5 @@\n+  if (!InstanceKlass::is_finalization_enabled()) {\n+    output()->print_cr(\"Finalization is disabled\");\n+    return;\n+  }\n+\n@@ -909,2 +915,3 @@\n-  _print_subclasses(\"-s\", \"If a classname is specified, print its subclasses. \"\n-                    \"Otherwise only its superclasses are printed.\", \"BOOLEAN\", false, \"false\"),\n+  _print_subclasses(\"-s\", \"If a classname is specified, print its subclasses \"\n+                    \"in addition to its superclasses. Without this option only the \"\n+                    \"superclasses will be printed.\", \"BOOLEAN\", false, \"false\"),\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2046,1 +2046,0 @@\n-      _poi = Universe::heap()->parallel_object_iterator(_num_dumper_threads);\n@@ -2135,4 +2134,0 @@\n-    if (_poi != NULL) {\n-      delete _poi;\n-      _poi = NULL;\n-    }\n@@ -2388,1 +2383,8 @@\n-    workers->run_task(this);\n+    if (_num_dumper_threads > 1) {\n+      ParallelObjectIterator poi(_num_dumper_threads);\n+      _poi = &poi;\n+      workers->run_task(this);\n+      _poi = NULL;\n+    } else {\n+      workers->run_task(this);\n+    }\n@@ -2522,1 +2524,1 @@\n-      stack_trace->dump_stack_at_safepoint(-1);\n+      stack_trace->dump_stack_at_safepoint(-1, \/* ObjectMonitorsHashtable is not needed here *\/ nullptr);\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":9,"deletions":7,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,4 @@\n+STATIC_ASSERT(NMT_off > NMT_unknown);\n+STATIC_ASSERT(NMT_summary > NMT_off);\n+STATIC_ASSERT(NMT_detail > NMT_summary);\n+\n@@ -36,1 +40,0 @@\n-\n@@ -68,1 +71,0 @@\n-    case NMT_minimal: return \"minimal\"; break;\n","filename":"src\/hotspot\/share\/services\/nmtCommon.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+  JVM_ACC_HAS_RESOLVED_METHODS    = 0x00200000,     \/\/ True if the klass has resolved methods\n@@ -75,1 +76,1 @@\n-  JVM_ACC_HAS_LOCAL_VARIABLE_TABLE= 0x00200000,\n+  JVM_ACC_HAS_LOCAL_VARIABLE_TABLE= 0x00400000,\n@@ -77,1 +78,1 @@\n-  JVM_ACC_PROMOTED_FLAGS          = 0x00200000,     \/\/ flags promoted from methods to the holding klass\n+  JVM_ACC_PROMOTED_FLAGS          = 0x00400000,     \/\/ flags promoted from methods to the holding klass\n@@ -169,0 +170,3 @@\n+  bool has_resolved_methods() const     { return (_flags & JVM_ACC_HAS_RESOLVED_METHODS) != 0; }\n+  void set_has_resolved_methods()       { atomic_set_bits(JVM_ACC_HAS_RESOLVED_METHODS); }\n+\n","filename":"src\/hotspot\/share\/utilities\/accessFlags.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -42,0 +42,8 @@\n+\/\/ Old CDS options\n+bool DumpSharedSpaces;\n+bool DynamicDumpSharedSpaces;\n+bool RequireSharedSpaces;\n+extern \"C\" {\n+JNIEXPORT jboolean UseSharedSpaces = true;\n+}\n+\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -511,0 +511,10 @@\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ old CDS options\n+extern bool DumpSharedSpaces;\n+extern bool DynamicDumpSharedSpaces;\n+extern bool RequireSharedSpaces;\n+extern \"C\" {\n+\/\/ Make sure UseSharedSpaces is accessible to the serviceability agent.\n+extern JNIEXPORT jboolean UseSharedSpaces;\n+}\n+\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,2 @@\n+#include <string.h>\n+\n","filename":"src\/hotspot\/share\/utilities\/stringUtils.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n","filename":"src\/hotspot\/share\/utilities\/stringUtils.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1996, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1996, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,2 +28,0 @@\n-import java.io.ObjectStreamClass.WeakClassKey;\n-import java.lang.ref.ReferenceQueue;\n@@ -35,0 +33,1 @@\n+import java.util.Objects;\n@@ -36,3 +35,0 @@\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n-import static java.io.ObjectStreamClass.processQueue;\n@@ -179,6 +175,7 @@\n-        static final ConcurrentMap<WeakClassKey,Boolean> subclassAudits =\n-            new ConcurrentHashMap<>();\n-\n-        \/** queue for WeakReferences to audited subclasses *\/\n-        static final ReferenceQueue<Class<?>> subclassAuditsQueue =\n-            new ReferenceQueue<>();\n+        static final ClassValue<Boolean> subclassAudits =\n+            new ClassValue<>() {\n+                @Override\n+                protected Boolean computeValue(Class<?> type) {\n+                    return auditSubclass(type);\n+                }\n+            };\n@@ -662,1 +659,1 @@\n-     * {@code readClassDescriptor}, should then be overridden to\n+     * {@link ObjectInputStream#readClassDescriptor readClassDescriptor}, should then be overridden to\n@@ -665,1 +662,2 @@\n-     * defined in the Object Serialization specification.\n+     * defined in the <a href=\"{@docRoot}\/..\/specs\/serialization\/index.html\">\n+     * <cite>Java Object Serialization Specification<\/cite><\/a>.\n@@ -721,4 +719,1 @@\n-        int endoff = off + len;\n-        if (off < 0 || len < 0 || endoff > buf.length || endoff < 0) {\n-            throw new IndexOutOfBoundsException();\n-        }\n+        Objects.checkFromIndexSize(off, len, buf.length);\n@@ -1070,7 +1065,1 @@\n-        processQueue(Caches.subclassAuditsQueue, Caches.subclassAudits);\n-        WeakClassKey key = new WeakClassKey(cl, Caches.subclassAuditsQueue);\n-        Boolean result = Caches.subclassAudits.get(key);\n-        if (result == null) {\n-            result = auditSubclass(cl);\n-            Caches.subclassAudits.putIfAbsent(key, result);\n-        }\n+        boolean result = Caches.subclassAudits.get(cl);\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectOutputStream.java","additions":14,"deletions":25,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -31,4 +31,0 @@\n-import java.lang.ref.Reference;\n-import java.lang.ref.ReferenceQueue;\n-import java.lang.ref.SoftReference;\n-import java.lang.ref.WeakReference;\n@@ -63,1 +59,0 @@\n-import java.util.concurrent.ConcurrentMap;\n@@ -112,2 +107,7 @@\n-        static final ConcurrentMap<WeakClassKey,Reference<?>> localDescs =\n-            new ConcurrentHashMap<>();\n+        static final ClassCache<ObjectStreamClass> localDescs =\n+            new ClassCache<>() {\n+                @Override\n+                protected ObjectStreamClass computeValue(Class<?> type) {\n+                    return new ObjectStreamClass(type);\n+                }\n+            };\n@@ -116,9 +116,7 @@\n-        static final ConcurrentMap<FieldReflectorKey,Reference<?>> reflectors =\n-            new ConcurrentHashMap<>();\n-\n-        \/** queue for WeakReferences to local classes *\/\n-        private static final ReferenceQueue<Class<?>> localDescsQueue =\n-            new ReferenceQueue<>();\n-        \/** queue for WeakReferences to field reflectors keys *\/\n-        private static final ReferenceQueue<Class<?>> reflectorsQueue =\n-            new ReferenceQueue<>();\n+        static final ClassCache<Map<FieldReflectorKey, FieldReflector>> reflectors =\n+            new ClassCache<>() {\n+                @Override\n+                protected Map<FieldReflectorKey, FieldReflector> computeValue(Class<?> type) {\n+                    return new ConcurrentHashMap<>();\n+                }\n+            };\n@@ -366,130 +364,1 @@\n-        processQueue(Caches.localDescsQueue, Caches.localDescs);\n-        WeakClassKey key = new WeakClassKey(cl, Caches.localDescsQueue);\n-        Reference<?> ref = Caches.localDescs.get(key);\n-        Object entry = null;\n-        if (ref != null) {\n-            entry = ref.get();\n-        }\n-        EntryFuture future = null;\n-        if (entry == null) {\n-            EntryFuture newEntry = new EntryFuture();\n-            Reference<?> newRef = new SoftReference<>(newEntry);\n-            do {\n-                if (ref != null) {\n-                    Caches.localDescs.remove(key, ref);\n-                }\n-                ref = Caches.localDescs.putIfAbsent(key, newRef);\n-                if (ref != null) {\n-                    entry = ref.get();\n-                }\n-            } while (ref != null && entry == null);\n-            if (entry == null) {\n-                future = newEntry;\n-            }\n-        }\n-\n-        if (entry instanceof ObjectStreamClass) {  \/\/ check common case first\n-            return (ObjectStreamClass) entry;\n-        }\n-        if (entry instanceof EntryFuture) {\n-            future = (EntryFuture) entry;\n-            if (future.getOwner() == Thread.currentThread()) {\n-                \/*\n-                 * Handle nested call situation described by 4803747: waiting\n-                 * for future value to be set by a lookup() call further up the\n-                 * stack will result in deadlock, so calculate and set the\n-                 * future value here instead.\n-                 *\/\n-                entry = null;\n-            } else {\n-                entry = future.get();\n-            }\n-        }\n-        if (entry == null) {\n-            try {\n-                entry = new ObjectStreamClass(cl);\n-            } catch (Throwable th) {\n-                entry = th;\n-            }\n-            if (future.set(entry)) {\n-                Caches.localDescs.put(key, new SoftReference<>(entry));\n-            } else {\n-                \/\/ nested lookup call already set future\n-                entry = future.get();\n-            }\n-        }\n-\n-        if (entry instanceof ObjectStreamClass) {\n-            return (ObjectStreamClass) entry;\n-        } else if (entry instanceof RuntimeException) {\n-            throw (RuntimeException) entry;\n-        } else if (entry instanceof Error) {\n-            throw (Error) entry;\n-        } else {\n-            throw new InternalError(\"unexpected entry: \" + entry);\n-        }\n-    }\n-\n-    \/**\n-     * Placeholder used in class descriptor and field reflector lookup tables\n-     * for an entry in the process of being initialized.  (Internal) callers\n-     * which receive an EntryFuture belonging to another thread as the result\n-     * of a lookup should call the get() method of the EntryFuture; this will\n-     * return the actual entry once it is ready for use and has been set().  To\n-     * conserve objects, EntryFutures synchronize on themselves.\n-     *\/\n-    private static class EntryFuture {\n-\n-        private static final Object unset = new Object();\n-        private final Thread owner = Thread.currentThread();\n-        private Object entry = unset;\n-\n-        \/**\n-         * Attempts to set the value contained by this EntryFuture.  If the\n-         * EntryFuture's value has not been set already, then the value is\n-         * saved, any callers blocked in the get() method are notified, and\n-         * true is returned.  If the value has already been set, then no saving\n-         * or notification occurs, and false is returned.\n-         *\/\n-        synchronized boolean set(Object entry) {\n-            if (this.entry != unset) {\n-                return false;\n-            }\n-            this.entry = entry;\n-            notifyAll();\n-            return true;\n-        }\n-\n-        \/**\n-         * Returns the value contained by this EntryFuture, blocking if\n-         * necessary until a value is set.\n-         *\/\n-        @SuppressWarnings(\"removal\")\n-        synchronized Object get() {\n-            boolean interrupted = false;\n-            while (entry == unset) {\n-                try {\n-                    wait();\n-                } catch (InterruptedException ex) {\n-                    interrupted = true;\n-                }\n-            }\n-            if (interrupted) {\n-                AccessController.doPrivileged(\n-                    new PrivilegedAction<>() {\n-                        public Void run() {\n-                            Thread.currentThread().interrupt();\n-                            return null;\n-                        }\n-                    }\n-                );\n-            }\n-            return entry;\n-        }\n-\n-        \/**\n-         * Returns the thread that created this EntryFuture.\n-         *\/\n-        Thread getOwner() {\n-            return owner;\n-        }\n+        return Caches.localDescs.get(cl);\n@@ -2256,26 +2125,1 @@\n-            localDesc.cl : null;\n-        processQueue(Caches.reflectorsQueue, Caches.reflectors);\n-        FieldReflectorKey key = new FieldReflectorKey(cl, fields,\n-                                                      Caches.reflectorsQueue);\n-        Reference<?> ref = Caches.reflectors.get(key);\n-        Object entry = null;\n-        if (ref != null) {\n-            entry = ref.get();\n-        }\n-        EntryFuture future = null;\n-        if (entry == null) {\n-            EntryFuture newEntry = new EntryFuture();\n-            Reference<?> newRef = new SoftReference<>(newEntry);\n-            do {\n-                if (ref != null) {\n-                    Caches.reflectors.remove(key, ref);\n-                }\n-                ref = Caches.reflectors.putIfAbsent(key, newRef);\n-                if (ref != null) {\n-                    entry = ref.get();\n-                }\n-            } while (ref != null && entry == null);\n-            if (entry == null) {\n-                future = newEntry;\n-            }\n-        }\n+            localDesc.cl : Void.class;\n@@ -2283,9 +2127,8 @@\n-        if (entry instanceof FieldReflector) {  \/\/ check common case first\n-            return (FieldReflector) entry;\n-        } else if (entry instanceof EntryFuture) {\n-            entry = ((EntryFuture) entry).get();\n-        } else if (entry == null) {\n-            try {\n-                entry = new FieldReflector(matchFields(fields, localDesc));\n-            } catch (Throwable th) {\n-                entry = th;\n+        var clReflectors = Caches.reflectors.get(cl);\n+        var key = new FieldReflectorKey(fields);\n+        var reflector = clReflectors.get(key);\n+        if (reflector == null) {\n+            reflector = new FieldReflector(matchFields(fields, localDesc));\n+            var oldReflector = clReflectors.putIfAbsent(key, reflector);\n+            if (oldReflector != null) {\n+                reflector = oldReflector;\n@@ -2293,14 +2136,1 @@\n-            future.set(entry);\n-            Caches.reflectors.put(key, new SoftReference<>(entry));\n-        }\n-\n-        if (entry instanceof FieldReflector) {\n-            return (FieldReflector) entry;\n-        } else if (entry instanceof InvalidClassException) {\n-            throw (InvalidClassException) entry;\n-        } else if (entry instanceof RuntimeException) {\n-            throw (RuntimeException) entry;\n-        } else if (entry instanceof Error) {\n-            throw (Error) entry;\n-        } else {\n-            throw new InternalError(\"unexpected entry: \" + entry);\n+        return reflector;\n@@ -2312,1 +2142,1 @@\n-     * refer to the same class and equivalent field formats.\n+     * refer to equivalent field formats.\n@@ -2314,1 +2144,1 @@\n-    private static class FieldReflectorKey extends WeakReference<Class<?>> {\n+    private static class FieldReflectorKey {\n@@ -2318,3 +2148,1 @@\n-        private final boolean nullClass;\n-        FieldReflectorKey(Class<?> cl, ObjectStreamField[] fields,\n-                          ReferenceQueue<Class<?>> queue)\n+        FieldReflectorKey(ObjectStreamField[] fields)\n@@ -2323,2 +2151,0 @@\n-            super(cl, queue);\n-            nullClass = (cl == null);\n@@ -2331,1 +2157,1 @@\n-            hash = System.identityHashCode(cl) + Arrays.hashCode(sigs);\n+            hash = Arrays.hashCode(sigs);\n@@ -2339,13 +2165,3 @@\n-            if (obj == this) {\n-                return true;\n-            }\n-\n-            if (obj instanceof FieldReflectorKey other) {\n-                Class<?> referent;\n-                return (nullClass ? other.nullClass\n-                                  : ((referent = get()) != null) &&\n-                                    (other.refersTo(referent))) &&\n-                        Arrays.equals(sigs, other.sigs);\n-            } else {\n-                return false;\n-            }\n+            return obj == this ||\n+                   obj instanceof FieldReflectorKey other &&\n+                   Arrays.equals(sigs, other.sigs);\n@@ -2415,62 +2231,0 @@\n-    \/**\n-     * Removes from the specified map any keys that have been enqueued\n-     * on the specified reference queue.\n-     *\/\n-    static void processQueue(ReferenceQueue<Class<?>> queue,\n-                             ConcurrentMap<? extends\n-                             WeakReference<Class<?>>, ?> map)\n-    {\n-        Reference<? extends Class<?>> ref;\n-        while((ref = queue.poll()) != null) {\n-            map.remove(ref);\n-        }\n-    }\n-\n-    \/**\n-     *  Weak key for Class objects.\n-     *\n-     **\/\n-    static class WeakClassKey extends WeakReference<Class<?>> {\n-        \/**\n-         * saved value of the referent's identity hash code, to maintain\n-         * a consistent hash code after the referent has been cleared\n-         *\/\n-        private final int hash;\n-\n-        \/**\n-         * Create a new WeakClassKey to the given object, registered\n-         * with a queue.\n-         *\/\n-        WeakClassKey(Class<?> cl, ReferenceQueue<Class<?>> refQueue) {\n-            super(cl, refQueue);\n-            hash = System.identityHashCode(cl);\n-        }\n-\n-        \/**\n-         * Returns the identity hash code of the original referent.\n-         *\/\n-        public int hashCode() {\n-            return hash;\n-        }\n-\n-        \/**\n-         * Returns true if the given object is this identical\n-         * WeakClassKey instance, or, if this object's referent has not\n-         * been cleared, if the given object is another WeakClassKey\n-         * instance with the identical non-null referent as this one.\n-         *\/\n-        public boolean equals(Object obj) {\n-            if (obj == this) {\n-                return true;\n-            }\n-\n-            if (obj instanceof WeakClassKey) {\n-                Class<?> referent = get();\n-                return (referent != null) &&\n-                        (((WeakClassKey) obj).refersTo(referent));\n-            } else {\n-                return false;\n-            }\n-        }\n-    }\n-\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectStreamClass.java","additions":32,"deletions":278,"binary":false,"changes":310,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1994, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1994, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1736,1 +1736,1 @@\n-     * type, or void,then this method returns null.\n+     * type, or void, then this method returns null.\n@@ -2239,0 +2239,1 @@\n+     * @see #getDeclaredConstructors()\n@@ -2438,1 +2439,3 @@\n-     * @throws NoSuchMethodException if a matching method is not found.\n+     * @throws NoSuchMethodException if a matching constructor is not found,\n+     *         including when this {@code Class} object represents\n+     *         an interface, a primitive type, an array class, or void.\n@@ -2447,0 +2450,1 @@\n+     * @see #getDeclaredConstructor(Class<?>[])\n@@ -2695,1 +2699,0 @@\n-\n@@ -2698,1 +2701,1 @@\n-     * constructors declared by the class represented by this\n+     * constructors implicitly or explicitly declared by the class represented by this\n@@ -2702,1 +2705,4 @@\n-     * class has a default constructor, it is included in the returned array.\n+     * class has a default constructor (JLS {@jls 8.8.9}), it is included in the returned array.\n+     * If a record class has a canonical constructor (JLS {@jls\n+     * 8.10.4.1}, {@jls 8.10.4.2}), it is included in the returned array.\n+     *\n@@ -2707,3 +2713,0 @@\n-     * <p> See <cite>The Java Language Specification<\/cite>,\n-     * section {@jls 8.2}.\n-     *\n@@ -2734,0 +2737,1 @@\n+     * @see #getConstructors()\n@@ -2895,1 +2899,1 @@\n-     * constructor of the class or interface represented by this\n+     * constructor of the class represented by this\n@@ -2907,1 +2911,3 @@\n-     * @throws  NoSuchMethodException if a matching method is not found.\n+     * @throws  NoSuchMethodException if a matching constructor is not found,\n+     *          including when this {@code Class} object represents\n+     *          an interface, a primitive type, an array class, or void.\n@@ -2929,0 +2935,1 @@\n+     * @see #getConstructor(Class<?>[])\n@@ -3979,4 +3986,3 @@\n-        if (reflectionFactory == null) {\n-            reflectionFactory =\n-                java.security.AccessController.doPrivileged\n-                    (new ReflectionFactory.GetReflectionFactoryAction());\n+        var factory = reflectionFactory;\n+        if (factory != null) {\n+            return factory;\n@@ -3984,1 +3990,3 @@\n-        return reflectionFactory;\n+        return reflectionFactory =\n+                java.security.AccessController.doPrivileged\n+                        (new ReflectionFactory.GetReflectionFactoryAction());\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":24,"deletions":16,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -494,0 +494,6 @@\n+     * <b>When running in a Java virtual machine in which finalization has been\n+     * disabled or removed, the garbage collector will never call\n+     * {@code finalize()}. In a Java virtual machine in which finalization is\n+     * enabled, the garbage collector might call {@code finalize} only after an\n+     * indefinite delay.<\/b>\n+     * <p>\n@@ -559,15 +565,17 @@\n-     * @deprecated The finalization mechanism is inherently problematic.\n-     * Finalization can lead to performance issues, deadlocks, and hangs.\n-     * Errors in finalizers can lead to resource leaks; there is no way to cancel\n-     * finalization if it is no longer necessary; and no ordering is specified\n-     * among calls to {@code finalize} methods of different objects.\n-     * Furthermore, there are no guarantees regarding the timing of finalization.\n-     * The {@code finalize} method might be called on a finalizable object\n-     * only after an indefinite delay, if at all.\n-     *\n-     * Classes whose instances hold non-heap resources should provide a method\n-     * to enable explicit release of those resources, and they should also\n-     * implement {@link AutoCloseable} if appropriate.\n-     * The {@link java.lang.ref.Cleaner} and {@link java.lang.ref.PhantomReference}\n-     * provide more flexible and efficient ways to release resources when an object\n-     * becomes unreachable.\n+     * @deprecated Finalization is deprecated and subject to removal in a future\n+     * release. The use of finalization can lead to problems with security,\n+     * performance, and reliability.\n+     * See <a href=\"https:\/\/openjdk.java.net\/jeps\/421\">JEP 421<\/a> for\n+     * discussion and alternatives.\n+     * <p>\n+     * Subclasses that override {@code finalize} to perform cleanup should use\n+     * alternative cleanup mechanisms and remove the {@code finalize} method.\n+     * Use {@link java.lang.ref.Cleaner} and\n+     * {@link java.lang.ref.PhantomReference} as safer ways to release resources\n+     * when an object becomes unreachable. Alternatively, add a {@code close}\n+     * method to explicitly release resources, and implement\n+     * {@code AutoCloseable} to enable use of the {@code try}-with-resources\n+     * statement.\n+     * <p>\n+     * This method will remain in place until finalizers have been removed from\n+     * most existing code.\n@@ -580,1 +588,1 @@\n-    @Deprecated(since=\"9\")\n+    @Deprecated(since=\"9\", forRemoval=true)\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Object.java","additions":24,"deletions":16,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -686,0 +686,1 @@\n+        assert(!UNSAFE.shouldBeInitialized(holder)) : holder + \"not initialized\";\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/InvokerBytecodeGenerator.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -2005,1 +2005,1 @@\n-         * is not {@linkplain java.lang.instrument.Instrumentation#isModifiableClass(Class)\n+         * is not {@linkplain java.instrument\/java.lang.instrument.Instrumentation#isModifiableClass(Class)\n@@ -2108,0 +2108,1 @@\n+        @SuppressWarnings(\"doclint:reference\") \/\/ cross-module links\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandles.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -45,1 +45,0 @@\n-import static java.util.stream.Collectors.joining;\n@@ -375,1 +374,1 @@\n-    public static VarHandle filterValue(VarHandle target, MethodHandle filterToTarget, MethodHandle filterFromTarget) {\n+    public static VarHandle filterValue(VarHandle target, MethodHandle pFilterToTarget, MethodHandle pFilterFromTarget) {\n@@ -377,2 +376,2 @@\n-        Objects.requireNonNull(filterToTarget);\n-        Objects.requireNonNull(filterFromTarget);\n+        Objects.requireNonNull(pFilterToTarget);\n+        Objects.requireNonNull(pFilterFromTarget);\n@@ -380,2 +379,2 @@\n-        noCheckedExceptions(filterToTarget);\n-        noCheckedExceptions(filterFromTarget);\n+        MethodHandle filterToTarget = adaptForCheckedExceptions(pFilterToTarget);\n+        MethodHandle filterFromTarget = adaptForCheckedExceptions(pFilterFromTarget);\n@@ -489,2 +488,3 @@\n-            noCheckedExceptions(filters[i]);\n-            MethodType filterType = filters[i].type();\n+            MethodHandle filter = Objects.requireNonNull(filters[i]);\n+            filter = adaptForCheckedExceptions(filter);\n+            MethodType filterType = filter.type();\n@@ -580,1 +580,1 @@\n-    public static VarHandle collectCoordinates(VarHandle target, int pos, MethodHandle filter) {\n+    public static VarHandle collectCoordinates(VarHandle target, int pos, MethodHandle pFilter) {\n@@ -582,2 +582,2 @@\n-        Objects.requireNonNull(filter);\n-        noCheckedExceptions(filter);\n+        Objects.requireNonNull(pFilter);\n+        MethodHandle filter = adaptForCheckedExceptions(pFilter);\n@@ -620,1 +620,23 @@\n-    private static void noCheckedExceptions(MethodHandle handle) {\n+    private static MethodHandle adaptForCheckedExceptions(MethodHandle target) {\n+        Class<?>[] exceptionTypes = exceptionTypes(target);\n+        if (exceptionTypes != null) { \/\/ exceptions known\n+            if (Stream.of(exceptionTypes).anyMatch(VarHandles::isCheckedException)) {\n+                throw newIllegalArgumentException(\"Cannot adapt a var handle with a method handle which throws checked exceptions\");\n+            }\n+            return target; \/\/ no adaptation needed\n+        } else {\n+            MethodHandle handler = MethodHandleImpl.getConstantHandle(MethodHandleImpl.MH_VarHandles_handleCheckedExceptions);\n+            MethodHandle zero = MethodHandles.zero(target.type().returnType()); \/\/ dead branch\n+            handler = MethodHandles.collectArguments(zero, 0, handler);\n+            return MethodHandles.catchException(target, Throwable.class, handler);\n+        }\n+    }\n+\n+    static void handleCheckedExceptions(Throwable throwable) throws Throwable {\n+        if (isCheckedException(throwable.getClass())) {\n+            throw new IllegalStateException(\"Adapter handle threw checked exception\", throwable);\n+        }\n+        throw throwable;\n+    }\n+\n+    static Class<?>[] exceptionTypes(MethodHandle handle) {\n@@ -627,2 +649,1 @@\n-            final Class<?>[] exceptionTypes;\n-                exceptionTypes = info.reflectAs(Method.class, MethodHandles.Lookup.IMPL_LOOKUP)\n+                return info.reflectAs(Method.class, MethodHandles.Lookup.IMPL_LOOKUP)\n@@ -632,1 +653,1 @@\n-                exceptionTypes = null;\n+                return new Class<?>[0];\n@@ -634,1 +655,1 @@\n-                exceptionTypes = info.reflectAs(Constructor.class, MethodHandles.Lookup.IMPL_LOOKUP)\n+                return info.reflectAs(Constructor.class, MethodHandles.Lookup.IMPL_LOOKUP)\n@@ -639,15 +660,3 @@\n-            if (exceptionTypes != null) {\n-                if (Stream.of(exceptionTypes).anyMatch(VarHandles::isCheckedException)) {\n-                    throw newIllegalArgumentException(\"Cannot adapt a var handle with a method handle which throws checked exceptions\");\n-                }\n-            }\n-            noCheckedExceptions(((DelegatingMethodHandle)handle).getTarget());\n-        } else {\n-            \/\/bound\n-            BoundMethodHandle boundHandle = (BoundMethodHandle)handle;\n-            for (int i = 0 ; i < boundHandle.fieldCount() ; i++) {\n-                Object arg = boundHandle.arg(i);\n-                if (arg instanceof MethodHandle){\n-                    noCheckedExceptions((MethodHandle) arg);\n-                }\n-            }\n+            return exceptionTypes(((DelegatingMethodHandle)handle).getTarget());\n+        } else if (handle instanceof NativeMethodHandle) {\n+            return new Class<?>[0];\n@@ -656,0 +665,4 @@\n+\n+        assert handle instanceof BoundMethodHandle : \"Unexpected handle type: \" + handle;\n+        \/\/ unknown\n+        return null;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/VarHandles.java","additions":44,"deletions":31,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -171,0 +171,9 @@\n+     * <p> This method may be used by <a href=\"{@docRoot}\/..\/specs\/jni\/index.html\">JNI code<\/a>\n+     * with no caller class on the stack to enable access to a {@link Member member}\n+     * of {@link Member#getDeclaringClass() declaring class} {@code D} if and only if:\n+     * <ul>\n+     *     <li> The member is {@code public} and {@code D} is {@code public} in\n+     *     a package that the module containing {@code D} {@link\n+     *     Module#isExported(String,Module) exports} unconditionally. <\/li>\n+     * <\/ul>\n+     *\n@@ -250,0 +259,5 @@\n+     * <p> If this method is invoked by <a href=\"{@docRoot}\/..\/specs\/jni\/index.html\">JNI code<\/a>\n+     * with no caller class on the stack, the {@code accessible} flag can\n+     * only be set if the member and the declaring class are public, and\n+     * the class is in a package that is exported unconditionally. <\/p>\n+     *\n@@ -308,0 +322,10 @@\n+        if (caller == null) {\n+            \/\/ No caller frame when a native thread attaches to the VM\n+            \/\/ only allow access to a public accessible member\n+            boolean canAccess = Reflection.verifyPublicMemberAccess(declaringClass, declaringClass.getModifiers());\n+            if (!canAccess && throwExceptionIfDenied) {\n+                throwInaccessibleObjectException(caller, declaringClass);\n+            }\n+            return canAccess;\n+        }\n+\n@@ -316,6 +340,1 @@\n-        int modifiers;\n-        if (this instanceof Executable) {\n-            modifiers = ((Executable) this).getModifiers();\n-        } else {\n-            modifiers = ((Field) this).getModifiers();\n-        }\n+        int modifiers = ((Member)this).getModifiers();\n@@ -345,15 +364,1 @@\n-            \/\/ not accessible\n-            String msg = \"Unable to make \";\n-            if (this instanceof Field)\n-                msg += \"field \";\n-            msg += this + \" accessible: \" + declaringModule + \" does not \\\"\";\n-            if (isClassPublic && Modifier.isPublic(modifiers))\n-                msg += \"exports\";\n-            else\n-                msg += \"opens\";\n-            msg += \" \" + pn + \"\\\" to \" + callerModule;\n-            InaccessibleObjectException e = new InaccessibleObjectException(msg);\n-            if (printStackTraceWhenAccessFails()) {\n-                e.printStackTrace(System.err);\n-            }\n-            throw e;\n+            throwInaccessibleObjectException(caller, declaringClass);\n@@ -364,0 +369,26 @@\n+    private void throwInaccessibleObjectException(Class<?> caller, Class<?> declaringClass) {\n+        boolean isClassPublic = Modifier.isPublic(declaringClass.getModifiers());\n+        String pn = declaringClass.getPackageName();\n+        int modifiers = ((Member)this).getModifiers();\n+\n+        \/\/ not accessible\n+        String msg = \"Unable to make \";\n+        if (this instanceof Field)\n+            msg += \"field \";\n+        msg += this + \" accessible\";\n+        msg += caller == null ? \" by JNI attached native thread with no caller frame: \" : \": \";\n+        msg += declaringClass.getModule() + \" does not \\\"\";\n+        if (isClassPublic && Modifier.isPublic(modifiers))\n+            msg += \"exports\";\n+        else\n+            msg += \"opens\";\n+        msg += \" \" + pn + \"\\\"\" ;\n+        if (caller != null)\n+            msg += \" to \" + caller.getModule();\n+        InaccessibleObjectException e = new InaccessibleObjectException(msg);\n+        if (printStackTraceWhenAccessFails()) {\n+            e.printStackTrace(System.err);\n+        }\n+        throw e;\n+    }\n+\n@@ -413,1 +444,5 @@\n-     * with the variation noted in the class description. <\/p>\n+     * with the variation noted in the class description.\n+     * If this method is invoked by <a href=\"{@docRoot}\/..\/specs\/jni\/index.html\">JNI code<\/a>\n+     * with no caller class on the stack, this method returns {@code true}\n+     * if the member and the declaring class are public, and the class is in\n+     * a package that is exported unconditionally. <\/p>\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/AccessibleObject.java","additions":58,"deletions":23,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -375,1 +375,1 @@\n-        for (Class<?> parameterType : getParameterTypes()) {\n+        for (Class<?> parameterType : getSharedParameterTypes()) {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Constructor.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -435,1 +435,1 @@\n-        for (Class<?> parameterType : getParameterTypes()) {\n+        for (Class<?> parameterType : getSharedParameterTypes()) {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Method.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1317,0 +1317,40 @@\n+    \/*\n+     * Invoke the default method of the given proxy with an explicit caller class.\n+     *\n+     * @throws IllegalAccessException if the proxy interface is inaccessible to the caller\n+     *         if caller is non-null\n+     *\/\n+    static Object invokeDefault(Object proxy, Method method, Object[] args, Class<?> caller)\n+            throws Throwable {\n+        \/\/ verify that the object is actually a proxy instance\n+        if (!Proxy.isProxyClass(proxy.getClass())) {\n+            throw new IllegalArgumentException(\"'proxy' is not a proxy instance\");\n+        }\n+        if (!method.isDefault()) {\n+            throw new IllegalArgumentException(\"\\\"\" + method + \"\\\" is not a default method\");\n+        }\n+        @SuppressWarnings(\"unchecked\")\n+        Class<? extends Proxy> proxyClass = (Class<? extends Proxy>)proxy.getClass();\n+\n+        \/\/ skip access check if caller is null\n+        if (caller != null) {\n+            Class<?> intf = method.getDeclaringClass();\n+            \/\/ access check on the default method\n+            method.checkAccess(caller, intf, proxyClass, method.getModifiers());\n+        }\n+\n+        MethodHandle mh = Proxy.defaultMethodHandle(proxyClass, method);\n+        \/\/ invoke the super method\n+        try {\n+            \/\/ the args array can be null if the number of formal parameters required by\n+            \/\/ the method is zero (consistent with Method::invoke)\n+            Object[] params = args != null ? args : Proxy.EMPTY_ARGS;\n+            return mh.invokeExact(proxy, params);\n+        } catch (ClassCastException | NullPointerException e) {\n+            throw new IllegalArgumentException(e.getMessage(), e);\n+        } catch (Proxy.InvocationException e) {\n+            \/\/ unwrap and throw the exception thrown by the default method\n+            throw e.getCause();\n+        }\n+    }\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Proxy.java","additions":40,"deletions":0,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+import java.lang.invoke.StringConcatFactory;\n@@ -35,0 +36,1 @@\n+import java.util.ArrayList;\n@@ -55,0 +57,2 @@\n+    private static final int MAX_STRING_CONCAT_SLOTS = 20;\n+\n@@ -257,24 +261,11 @@\n-    private static MethodHandle makeToString(Class<?> receiverClass,\n-                                             String simpleName,\n-                                             List<MethodHandle> getters,\n-                                             List<String> names) {\n-        \/\/ This is a pretty lousy algorithm; we spread the receiver over N places,\n-        \/\/ apply the N getters, apply N toString operations, and concat the result with String.format\n-        \/\/ Better to use String.format directly, or delegate to StringConcatFactory\n-        \/\/ Also probably want some quoting around String components\n-\n-        assert getters.size() == names.size();\n-\n-        int[] invArgs = new int[getters.size()];\n-        Arrays.fill(invArgs, 0);\n-        MethodHandle[] filters = new MethodHandle[getters.size()];\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(simpleName).append(\"[\");\n-        for (int i=0; i<getters.size(); i++) {\n-            MethodHandle getter = getters.get(i); \/\/ (R)T\n-            MethodHandle stringify = stringifier(getter.type().returnType()); \/\/ (T)String\n-            MethodHandle stringifyThisField = MethodHandles.filterArguments(stringify, 0, getter);    \/\/ (R)String\n-            filters[i] = stringifyThisField;\n-            sb.append(names.get(i)).append(\"=%s\");\n-            if (i != getters.size() - 1)\n-                sb.append(\", \");\n+    private static MethodHandle makeToString(MethodHandles.Lookup lookup,\n+                                            Class<?> receiverClass,\n+                                            String simpleName,\n+                                            MethodHandle[] getters,\n+                                            List<String> names) {\n+        assert getters.length == names.size();\n+        if (getters.length == 0) {\n+            \/\/ special case\n+            MethodHandle emptyRecordCase = MethodHandles.constant(String.class, simpleName + \"[]\");\n+            emptyRecordCase = MethodHandles.dropArguments(emptyRecordCase, 0, receiverClass); \/\/ (R)S\n+            return emptyRecordCase;\n@@ -282,7 +273,85 @@\n-        sb.append(']');\n-        String formatString = sb.toString();\n-        MethodHandle formatter = MethodHandles.insertArguments(STRING_FORMAT, 0, formatString)\n-                                              .asCollector(String[].class, getters.size()); \/\/ (R*)String\n-        if (getters.size() == 0) {\n-            \/\/ Add back extra R\n-            formatter = MethodHandles.dropArguments(formatter, 0, receiverClass);\n+\n+        boolean firstTime = true;\n+        MethodHandle[] mhs;\n+        List<List<MethodHandle>> splits;\n+        MethodHandle[] toSplit = getters;\n+        int namesIndex = 0;\n+        do {\n+            \/* StringConcatFactory::makeConcatWithConstants can only deal with 200 slots, longs and double occupy two\n+             * the rest 1 slot, we need to chop the current `getters` into chunks, it could be that for records with\n+             * a lot of components that we need to do a couple of iterations. The main difference between the first\n+             * iteration and the rest would be on the recipe\n+             *\/\n+            splits = split(toSplit);\n+            mhs = new MethodHandle[splits.size()];\n+            for (int splitIndex = 0; splitIndex < splits.size(); splitIndex++) {\n+                String recipe = \"\";\n+                if (firstTime && splitIndex == 0) {\n+                    recipe = simpleName + \"[\";\n+                }\n+                for (int i = 0; i < splits.get(splitIndex).size(); i++) {\n+                    recipe += firstTime ? names.get(namesIndex) + \"=\" + \"\\1\" : \"\\1\";\n+                    if (firstTime && namesIndex != names.size() - 1) {\n+                        recipe += \", \";\n+                    }\n+                    namesIndex++;\n+                }\n+                if (firstTime && splitIndex == splits.size() - 1) {\n+                    recipe += \"]\";\n+                }\n+                Class<?>[] concatTypeArgs = new Class<?>[splits.get(splitIndex).size()];\n+                \/\/ special case: no need to create another getters if there is only one split\n+                MethodHandle[] currentSplitGetters = new MethodHandle[splits.get(splitIndex).size()];\n+                for (int j = 0; j < splits.get(splitIndex).size(); j++) {\n+                    concatTypeArgs[j] = splits.get(splitIndex).get(j).type().returnType();\n+                    currentSplitGetters[j] = splits.get(splitIndex).get(j);\n+                }\n+                MethodType concatMT = MethodType.methodType(String.class, concatTypeArgs);\n+                try {\n+                    mhs[splitIndex] = StringConcatFactory.makeConcatWithConstants(\n+                            lookup, \"\",\n+                            concatMT,\n+                            recipe,\n+                            new Object[0]\n+                    ).getTarget();\n+                    mhs[splitIndex] = MethodHandles.filterArguments(mhs[splitIndex], 0, currentSplitGetters);\n+                    \/\/ this will spread the receiver class across all the getters\n+                    mhs[splitIndex] = MethodHandles.permuteArguments(\n+                            mhs[splitIndex],\n+                            MethodType.methodType(String.class, receiverClass),\n+                            new int[splits.get(splitIndex).size()]\n+                    );\n+                } catch (Throwable t) {\n+                    throw new RuntimeException(t);\n+                }\n+            }\n+            toSplit = mhs;\n+            firstTime = false;\n+        } while (splits.size() > 1);\n+        return mhs[0];\n+    }\n+\n+    \/**\n+     * Chops the getters into smaller chunks according to the maximum number of slots\n+     * StringConcatFactory::makeConcatWithConstants can chew\n+     * @param getters the current getters\n+     * @return chunks that wont surpass the maximum number of slots StringConcatFactory::makeConcatWithConstants can chew\n+     *\/\n+    private static List<List<MethodHandle>> split(MethodHandle[] getters) {\n+        List<List<MethodHandle>> splits = new ArrayList<>();\n+\n+        int slots = 0;\n+\n+        \/\/ Need to peel, so that neither call has more than acceptable number\n+        \/\/ of slots for the arguments.\n+        List<MethodHandle> cArgs = new ArrayList<>();\n+        for (MethodHandle methodHandle : getters) {\n+            Class<?> returnType = methodHandle.type().returnType();\n+            int needSlots = (returnType == long.class || returnType == double.class) ? 2 : 1;\n+            if (slots + needSlots > MAX_STRING_CONCAT_SLOTS) {\n+                splits.add(cArgs);\n+                cArgs = new ArrayList<>();\n+                slots = 0;\n+            }\n+            cArgs.add(methodHandle);\n+            slots += needSlots;\n@@ -290,3 +359,4 @@\n-        else {\n-            MethodHandle filtered = MethodHandles.filterArguments(formatter, 0, filters);\n-            formatter = MethodHandles.permuteArguments(filtered, MethodType.methodType(String.class, receiverClass), invArgs);\n+\n+        \/\/ Flush the tail slice\n+        if (!cArgs.isEmpty()) {\n+            splits.add(cArgs);\n@@ -295,1 +365,1 @@\n-        return formatter;\n+        return splits;\n@@ -333,3 +403,2 @@\n-     * @throws NullPointerException if any argument but {@code lookup} is {@code null},\n-     *                              in the case of the {@code getters} argument, its\n-     *                              contents cannot be {@code null} either\n+     * @throws NullPointerException if any argument is {@code null} or if any element\n+     *                              in the {@code getters} array is {@code null}\n@@ -342,0 +411,1 @@\n+        requireNonNull(lookup);\n@@ -383,1 +453,1 @@\n-                yield makeToString(receiverType, recordClass.getSimpleName(), getterList, nameList);\n+                yield makeToString(lookup, receiverType, recordClass.getSimpleName(), getters, nameList);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/runtime\/ObjectMethods.java","additions":109,"deletions":39,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2009, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2009, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -168,0 +168,24 @@\n+    \/**\n+     * {@return a string equivalent to the string returned by {@code\n+     * Object.toString} if that method and {@code hashCode} are not\n+     * overridden}\n+     *\n+     * @implNote\n+     * This method constructs a string for an object without calling\n+     * any overridable methods of the object.\n+     *\n+     * @implSpec\n+     * The method returns a string equivalent to:<br>\n+     * {@code o.getClass().getName() + \"@\" + Integer.toHexString(System.identityHashCode(o))}\n+     *\n+     * @param o an object\n+     * @throws NullPointerException if the argument is null\n+     * @see Object#toString\n+     * @see System#identityHashCode(Object)\n+     * @since 19\n+     *\/\n+    public static String toIdentityString(Object o) {\n+        requireNonNull(o);\n+        return o.getClass().getName() + \"@\" + Integer.toHexString(System.identityHashCode(o));\n+    }\n+\n","filename":"src\/java.base\/share\/classes\/java\/util\/Objects.java","additions":25,"deletions":1,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -225,1 +225,1 @@\n-        if (checkClassVersion && readShort(classFileOffset + 6) > Opcodes.V18) {\n+        if (checkClassVersion && readShort(classFileOffset + 6) > Opcodes.V19) {\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/org\/objectweb\/asm\/ClassReader.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -317,0 +317,1 @@\n+    int V19 = 0 << 16 | 63;\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/org\/objectweb\/asm\/Opcodes.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -510,3 +510,9 @@\n-\n-                    ? findConstructor(sym, paramTypes)\n-                    : findMethod(sym, memberName, paramTypes);\n+                    ? findConstructor(sym, paramTypes, true)\n+                    : findMethod(sym, memberName, paramTypes, true);\n+\n+            if (msym == null) {\n+                msym = (memberName == sym.name)\n+                        ? findConstructor(sym, paramTypes, false)\n+                        : findMethod(sym, memberName, paramTypes, false);\n+            }\n+\n@@ -611,1 +617,1 @@\n-    MethodSymbol findConstructor(ClassSymbol tsym, List<Type> paramTypes) {\n+    MethodSymbol findConstructor(ClassSymbol tsym, List<Type> paramTypes, boolean strict) {\n@@ -614,1 +620,1 @@\n-                if (hasParameterTypes((MethodSymbol) sym, paramTypes)) {\n+                if (hasParameterTypes((MethodSymbol) sym, paramTypes, strict)) {\n@@ -622,2 +628,2 @@\n-    private MethodSymbol findMethod(ClassSymbol tsym, Name methodName, List<Type> paramTypes) {\n-        return searchMethod(tsym, methodName, paramTypes, new HashSet<>());\n+    private MethodSymbol findMethod(ClassSymbol tsym, Name methodName, List<Type> paramTypes, boolean strict) {\n+        return searchMethod(tsym, methodName, paramTypes, strict, new HashSet<>());\n@@ -627,1 +633,2 @@\n-                                       List<Type> paramTypes, Set<ClassSymbol> searched) {\n+                                       List<Type> paramTypes, boolean strict,\n+                                       Set<ClassSymbol> searched) {\n@@ -665,1 +672,1 @@\n-                    if (hasParameterTypes((MethodSymbol) sym, paramTypes)) {\n+                    if (hasParameterTypes((MethodSymbol) sym, paramTypes, strict)) {\n@@ -678,1 +685,1 @@\n-            MethodSymbol msym = searchMethod((ClassSymbol) superclass.tsym, methodName, paramTypes, searched);\n+            MethodSymbol msym = searchMethod((ClassSymbol) superclass.tsym, methodName, paramTypes, strict, searched);\n@@ -689,1 +696,1 @@\n-            MethodSymbol msym = searchMethod((ClassSymbol) intf.tsym, methodName, paramTypes, searched);\n+            MethodSymbol msym = searchMethod((ClassSymbol) intf.tsym, methodName, paramTypes, strict, searched);\n@@ -698,1 +705,1 @@\n-            MethodSymbol msym = searchMethod(encl, methodName, paramTypes, searched);\n+            MethodSymbol msym = searchMethod(encl, methodName, paramTypes, strict, searched);\n@@ -707,1 +714,1 @@\n-    private boolean hasParameterTypes(MethodSymbol method, List<Type> paramTypes) {\n+    private boolean hasParameterTypes(MethodSymbol method, List<Type> paramTypes, boolean strict) {\n@@ -715,1 +722,1 @@\n-        if (!Type.isErroneous(paramTypes) && types.isSubtypes(paramTypes, methodParamTypes)) {\n+        if (!strict && !Type.isErroneous(paramTypes) && types.isSubtypes(paramTypes, methodParamTypes)) {\n@@ -983,1 +990,1 @@\n-            toClear.stream().forEach(c -> {\n+            toClear.forEach(c -> {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/api\/JavacTrees.java","additions":22,"deletions":15,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -120,1 +120,6 @@\n-    JDK18(\"18\");\n+    JDK18(\"18\"),\n+\n+    \/**\n+      * 19, tbd\n+      *\/\n+    JDK19(\"19\");\n@@ -172,0 +177,1 @@\n+        case JDK19  -> Target.JDK1_19;\n@@ -318,0 +324,1 @@\n+        case JDK19  -> RELEASE_19;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Source.java","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2307,0 +2307,5 @@\n+        @Override\n+        public Name name() {\n+            return name;\n+        }\n+\n@@ -2345,0 +2350,5 @@\n+        @Override\n+        public Name name() {\n+            return name;\n+        }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Symbol.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -59,1 +59,3 @@\n-import com.sun.tools.javac.tree.TreeInfo;\n+import com.sun.tools.javac.tree.JCTree.JCAnnotatedType;\n+import com.sun.tools.javac.tree.JCTree.JCAnnotation;\n+import com.sun.tools.javac.tree.JCTree.JCArrayTypeTree;\n@@ -63,0 +65,1 @@\n+import com.sun.tools.javac.tree.JCTree.JCFieldAccess;\n@@ -64,0 +67,1 @@\n+import com.sun.tools.javac.tree.JCTree.JCMemberReference;\n@@ -66,0 +70,1 @@\n+import com.sun.tools.javac.tree.JCTree.JCNewArray;\n@@ -68,0 +73,3 @@\n+import com.sun.tools.javac.tree.JCTree.JCTypeIntersection;\n+import com.sun.tools.javac.tree.JCTree.JCTypeParameter;\n+import com.sun.tools.javac.tree.JCTree.JCTypeUnion;\n@@ -69,0 +77,2 @@\n+import com.sun.tools.javac.tree.JCTree.Tag;\n+import com.sun.tools.javac.tree.TreeInfo;\n@@ -70,1 +80,0 @@\n-import com.sun.tools.javac.tree.JCTree.*;\n@@ -1135,1 +1144,1 @@\n-                tree.sym.getRecordComponents().stream().forEach(rc -> scan(rc.accessorMeth));\n+                tree.sym.getRecordComponents().forEach(rc -> scan(rc.accessorMeth));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/TypeAnnotations.java","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+\n@@ -57,0 +58,1 @@\n+\n@@ -1742,1 +1744,2 @@\n-            List<Type> coveredTypes = List.nil();\n+            List<Type> coveredTypesForPatterns = List.nil();\n+            List<Type> coveredTypesForConstants = List.nil();\n@@ -1780,1 +1783,1 @@\n-                                checkCaseLabelDominated(pat.pos(), coveredTypes, sym.type);\n+                                checkCaseLabelDominated(pat.pos(), coveredTypesForConstants, sym.type);\n@@ -1813,1 +1816,1 @@\n-                                    checkCaseLabelDominated(pat.pos(), coveredTypes, types.boxedTypeOrType(pattype));\n+                                    checkCaseLabelDominated(pat.pos(), coveredTypesForConstants, types.boxedTypeOrType(pattype));\n@@ -1846,3 +1849,6 @@\n-                        checkCaseLabelDominated(pat.pos(), coveredTypes, patternType);\n-                        if (primary.unconditional() && !patternType.isErroneous()) {\n-                            coveredTypes = coveredTypes.prepend(patternType);\n+                        checkCaseLabelDominated(pat.pos(), coveredTypesForPatterns, patternType);\n+                        if (!patternType.isErroneous()) {\n+                            coveredTypesForConstants = coveredTypesForConstants.prepend(patternType);\n+                            if (primary.unconditional()) {\n+                                coveredTypesForPatterns = coveredTypesForPatterns.prepend(patternType);\n+                            }\n@@ -3015,0 +3021,6 @@\n+            Type enclType = clazztype.getEnclosingType();\n+            if (enclType != null &&\n+                    enclType.hasTag(CLASS) &&\n+                    !chk.checkDenotable((ClassType)enclType)) {\n+                log.error(tree.encl, Errors.EnclosingClassTypeNonDenotable(enclType));\n+            }\n@@ -3020,0 +3032,1 @@\n+                Env<AttrContext> dupLocalEnv = localEnv.dup(localEnv.tree, localEnv.info.dup(localEnv.info.scope.dupUnshared()));\n@@ -3028,1 +3041,1 @@\n-                                                            localEnv, argtypes, typeargtypes, pkind);\n+                                        dupLocalEnv, argtypes, typeargtypes, pkind);\n@@ -4064,1 +4077,1 @@\n-        Symbol operator = tree.operator = operators.resolveUnary(tree, tree.getTag(), argtype);\n+        OperatorSymbol operator = tree.operator = operators.resolveUnary(tree, tree.getTag(), argtype);\n@@ -4071,1 +4084,1 @@\n-            int opc = ((OperatorSymbol)operator).opcode;\n+            int opc = operator.opcode;\n@@ -4118,1 +4131,1 @@\n-        Symbol operator = tree.operator = operators.resolveBinary(tree, tree.getTag(), left, right);\n+        OperatorSymbol operator = tree.operator = operators.resolveBinary(tree, tree.getTag(), left, right);\n@@ -4124,1 +4137,1 @@\n-            int opc = ((OperatorSymbol)operator).opcode;\n+            int opc = operator.opcode;\n@@ -4470,1 +4483,2 @@\n-                        sym.name == names._super && env.info.constructorArgs)) {\n+                        sym.name == names._super && env.info.constructorArgs &&\n+                        (sitesym.isInterface() || site.tsym == env.enclClass.sym))) {\n@@ -5671,1 +5685,1 @@\n-                Symbol sym = null;\n+                VarSymbol sym = null;\n@@ -5675,1 +5689,1 @@\n-                        ((VarSymbol) sym).getConstValue() == null)\n+                        sym.getConstValue() == null)\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":28,"deletions":14,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -212,1 +212,0 @@\n-    private final DeferredCompletionFailureHandler dcfh;\n@@ -337,1 +336,0 @@\n-        dcfh = DeferredCompletionFailureHandler.instance(context);\n@@ -698,1 +696,1 @@\n-                (constants == null || !isExhaustive(tree.selector.type, constants))) {\n+                (constants == null || !isExhaustive(tree.selector.pos(), tree.selector.type, constants))) {\n@@ -733,1 +731,1 @@\n-                !isExhaustive(tree.selector.type, constants)) {\n+                !isExhaustive(tree.selector.pos(), tree.selector.type, constants)) {\n@@ -756,1 +754,1 @@\n-        private void transitiveCovers(Set<Symbol> covered) {\n+        private void transitiveCovers(DiagnosticPosition pos, Type seltype, Set<Symbol> covered) {\n@@ -778,1 +776,1 @@\n-                                if (isTransitivelyCovered(sup.tsym, covered) &&\n+                                if (isTransitivelyCovered(pos, seltype, sup.tsym, covered) &&\n@@ -789,3 +787,2 @@\n-        private boolean isTransitivelyCovered(Symbol sealed, Set<Symbol> covered) {\n-            DeferredCompletionFailureHandler.Handler prevHandler =\n-                    dcfh.setHandler(dcfh.speculativeCodeHandler);\n+        private boolean isTransitivelyCovered(DiagnosticPosition pos, Type seltype,\n+                                              Symbol sealed, Set<Symbol> covered) {\n@@ -798,1 +795,4 @@\n-                                                 .allMatch(s -> isTransitivelyCovered(s, covered));\n+                                                 .filter(s -> {\n+                                                     return types.isCastable(seltype, s.type\/*, types.noWarnings*\/);\n+                                                 })\n+                                                 .allMatch(s -> isTransitivelyCovered(pos, seltype, s, covered));\n@@ -802,4 +802,2 @@\n-                \/\/safe to ignore, the symbol will be un-completed when the speculative handler is removed.\n-                return false;\n-            } finally {\n-                dcfh.setHandler(prevHandler);\n+                chk.completionError(pos, cf);\n+                return true;\n@@ -809,2 +807,2 @@\n-        private boolean isExhaustive(Type seltype, Set<Symbol> covered) {\n-            transitiveCovers(covered);\n+        private boolean isExhaustive(DiagnosticPosition pos, Type seltype, Set<Symbol> covered) {\n+            transitiveCovers(pos, seltype, covered);\n@@ -815,1 +813,3 @@\n-                            yield ((Type.IntersectionClassType) seltype).getComponents().stream().anyMatch(t -> isExhaustive(t, covered));\n+                            yield ((Type.IntersectionClassType) seltype).getComponents()\n+                                                                        .stream()\n+                                                                        .anyMatch(t -> isExhaustive(pos, t, covered));\n@@ -821,1 +821,1 @@\n-                case TYPEVAR -> isExhaustive(((TypeVar) seltype).getUpperBound(), covered);\n+                case TYPEVAR -> isExhaustive(pos, ((TypeVar) seltype).getUpperBound(), covered);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Flow.java","additions":18,"deletions":18,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -168,3 +168,8 @@\n-        debugLinesOrVars = options.isSet(Option.G)\n-                || options.isSet(Option.G_CUSTOM, \"lines\")\n-                || options.isSet(Option.G_CUSTOM, \"vars\");\n+        boolean lineDebugInfo =\n+            options.isUnset(Option.G_CUSTOM) ||\n+            options.isSet(Option.G_CUSTOM, \"lines\");\n+        boolean varDebugInfo =\n+            options.isUnset(Option.G_CUSTOM)\n+            ? options.isSet(Option.G)\n+            : options.isSet(Option.G_CUSTOM, \"vars\");\n+        debugLinesOrVars = lineDebugInfo || varDebugInfo;\n@@ -427,2 +432,2 @@\n-                JCTree captured_local = make.Ident(fv).setType(fv.type);\n-                syntheticInits.append((JCExpression) captured_local);\n+                JCExpression captured_local = make.Ident(fv).setType(fv.type);\n+                syntheticInits.append(captured_local);\n@@ -433,2 +438,2 @@\n-            JCTree captured_local = make.QualThis(fv.type);\n-            syntheticInits.append((JCExpression) captured_local);\n+            JCExpression captured_local = make.QualThis(fv.type);\n+            syntheticInits.append(captured_local);\n@@ -1192,1 +1197,1 @@\n-            Symbol bsm = rs.resolveInternalMethod(pos, attrEnv, site,\n+            MethodSymbol bsm = rs.resolveInternalMethod(pos, attrEnv, site,\n@@ -1198,1 +1203,1 @@\n-                                            ((MethodSymbol)bsm).asHandle(),\n+                                            bsm.asHandle(),\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/LambdaToMethod.java","additions":14,"deletions":9,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -101,0 +101,1 @@\n+    private final boolean optimizeOuterThis;\n@@ -122,0 +123,3 @@\n+        optimizeOuterThis =\n+            target.optimizeOuterThis() ||\n+            options.getBoolean(\"optimizeOuterThis\", false);\n@@ -1499,0 +1503,4 @@\n+        \/\/ Set NOOUTERTHIS for all synthetic outer instance variables, and unset\n+        \/\/ it when the variable is accessed. If the variable is never accessed,\n+        \/\/ we skip creating an outer instance field and saving the constructor\n+        \/\/ parameter to it.\n@@ -1500,1 +1508,1 @@\n-            new VarSymbol(flags, outerThisName(target, owner), target, owner);\n+            new VarSymbol(flags | NOOUTERTHIS, outerThisName(target, owner), target, owner);\n@@ -1749,0 +1757,1 @@\n+        ot.flags_field &= ~NOOUTERTHIS;\n@@ -1766,0 +1775,1 @@\n+            ot.flags_field &= ~NOOUTERTHIS;\n@@ -1805,0 +1815,1 @@\n+        ot.flags_field &= ~NOOUTERTHIS;\n@@ -1817,0 +1828,1 @@\n+            ot.flags_field &= ~NOOUTERTHIS;\n@@ -1838,2 +1850,1 @@\n-    JCStatement initOuterThis(int pos) {\n-        VarSymbol rhs = outerThisStack.head;\n+    JCStatement initOuterThis(int pos, VarSymbol rhs) {\n@@ -1841,1 +1852,1 @@\n-        VarSymbol lhs = outerThisStack.tail.head;\n+        VarSymbol lhs = outerThisStack.head;\n@@ -2246,1 +2257,1 @@\n-        \/\/ Add this$n and free variables proxy definitions to class.\n+        \/\/ Add free variables proxy definitions to class.\n@@ -2252,1 +2263,3 @@\n-        if (currentClass.hasOuterInstance()) {\n+        \/\/ If this$n was accessed, add the field definition and\n+        \/\/ update initial constructors to initialize it\n+        if (currentClass.hasOuterInstance() && shouldEmitOuterThis(currentClass)) {\n@@ -2255,0 +2268,8 @@\n+\n+           for (JCTree def : tree.defs) {\n+                if (TreeInfo.isInitialConstructor(def)) {\n+                  JCMethodDecl mdef = (JCMethodDecl) def;\n+                  mdef.body.stats = mdef.body.stats.prepend(\n+                      initOuterThis(mdef.body.pos, mdef.params.head.sym));\n+                }\n+            }\n@@ -2271,0 +2292,16 @@\n+    private boolean shouldEmitOuterThis(ClassSymbol sym) {\n+      if (!optimizeOuterThis) {\n+        \/\/ Optimization is disabled\n+        return true;\n+      }\n+      if ((outerThisStack.head.flags_field & NOOUTERTHIS) == 0)  {\n+        \/\/ Enclosing instance field is used\n+        return true;\n+      }\n+      if (rs.isSerializable(sym.type)) {\n+        \/\/ Class is serializable\n+        return true;\n+      }\n+      return false;\n+    }\n+\n@@ -2337,1 +2374,1 @@\n-        Symbol valuesSym = lookupMethod(tree.pos(), names.values,\n+        MethodSymbol valuesSym = lookupMethod(tree.pos(), names.values,\n@@ -2388,1 +2425,1 @@\n-             make.MethodDef((MethodSymbol)valuesSym, make.Block(0, valuesBody));\n+             make.MethodDef(valuesSym, make.Block(0, valuesBody));\n@@ -2603,1 +2640,1 @@\n-        Symbol bsm = rs.resolveInternalMethod(tree.pos(), attrEnv, site,\n+        MethodSymbol bsm = rs.resolveInternalMethod(tree.pos(), attrEnv, site,\n@@ -2615,1 +2652,1 @@\n-                ((MethodSymbol)bsm).asHandle(),\n+                bsm.asHandle(),\n@@ -2725,5 +2762,0 @@\n-            if (currentClass.hasOuterInstance() &&\n-                TreeInfo.isInitialConstructor(tree))\n-            {\n-                added = added.prepend(initOuterThis(tree.body.pos));\n-            }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Lower.java","additions":47,"deletions":15,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -1324,1 +1324,1 @@\n-                    result &= false;\n+                    result = false;\n@@ -1336,1 +1336,1 @@\n-                        result &= true;\n+                        \/\/ do nothing\n@@ -1338,1 +1338,1 @@\n-                        result &= false;\n+                        result = false;\n@@ -1358,1 +1358,1 @@\n-                        result &= true;\n+                        \/\/ do nothing\n@@ -1360,1 +1360,1 @@\n-                        result &= false;\n+                        result = false;\n@@ -2989,3 +2989,0 @@\n-                                final JCDiagnostic details = sym.kind == WRONG_MTH ?\n-                                                ((InapplicableSymbolError)sym.baseSymbol()).errCandidate().snd :\n-                                                null;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Resolve.java","additions":5,"deletions":8,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -113,1 +113,0 @@\n-    private final JCDiagnostic.Factory diags;\n@@ -141,1 +140,0 @@\n-        diags = JCDiagnostic.Factory.instance(context);\n@@ -360,2 +358,4 @@\n-                if (javaLang.members().isEmpty() && !javaLang.exists())\n-                    throw new FatalError(diags.fragment(Fragments.FatalErrNoJavaLang));\n+                if (javaLang.members().isEmpty() && !javaLang.exists()) {\n+                    log.error(Errors.NoJavaLang);\n+                    throw new Abort();\n+                }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -122,1 +122,2 @@\n-        V62(62, 0);   \/\/ JDK 18\n+        V62(62, 0),   \/\/ JDK 18\n+        V63(63, 0);   \/\/ JDK 19\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/ClassFile.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -672,1 +672,1 @@\n-                    if (Code.truncate(typecode) == INTcode)\n+                    if (Code.truncate(typecode) == INTcode && typecode != CHARcode)\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/Items.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2103,1 +2103,1 @@\n-            accept(RPAREN);\n+            accept(RPAREN, tk -> Errors.Expected2(RPAREN, COMMA));\n@@ -2191,1 +2191,1 @@\n-                    args.append(syntaxError(token.pos, Errors.Expected(GT)));\n+                    args.append(syntaxError(token.pos, Errors.Expected2(GT, COMMA)));\n@@ -3488,1 +3488,1 @@\n-            accept(RBRACE);\n+            accept(RBRACE, tk -> Errors.AnnotationMissingElementValue);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -40,1 +40,0 @@\n-import java.util.stream.Collectors;\n@@ -49,1 +48,0 @@\n-import javax.tools.StandardJavaFileManager;\n@@ -1646,1 +1644,1 @@\n-                        originalAnnos.stream().forEach(a -> visitAnnotation(a));\n+                        originalAnnos.forEach(a -> visitAnnotation(a));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/processing\/JavacProcessingEnvironment.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -121,0 +121,3 @@\n+compiler.err.annotation.missing.element.value=\\\n+    annotation is missing element value\n+\n@@ -1535,0 +1538,3 @@\n+compiler.err.no.java.lang=\\\n+    Unable to find package java.lang in platform classes\n+\n@@ -1539,3 +1545,0 @@\n-compiler.misc.fatal.err.no.java.lang=\\\n-    Fatal Error: Unable to find package java.lang in classpath or bootclasspath\n-\n@@ -4008,0 +4011,5 @@\n+\n+# 0: type\n+compiler.err.enclosing.class.type.non.denotable=\\\n+    enclosing class type: {0}\\n\\\n+    is non-denotable, try casting to a denotable type\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -49,0 +49,2 @@\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n@@ -69,0 +71,1 @@\n+import jdk.vm.ci.services.Services;\n@@ -210,0 +213,6 @@\n+    \/**\n+     * Decodes the exception encoded in {@code buffer} and throws it.\n+     *\n+     * @param buffer a native byte buffer containing an exception encoded by\n+     *            {@link #encodeThrowable}\n+     *\/\n@@ -211,2 +220,6 @@\n-    static Throwable decodeThrowable(String encodedThrowable) throws Throwable {\n-        return TranslatedException.decodeThrowable(encodedThrowable);\n+    static void decodeAndThrowThrowable(long buffer) throws Throwable {\n+        Unsafe unsafe = UnsafeAccess.UNSAFE;\n+        int encodingLength = unsafe.getInt(buffer);\n+        byte[] encoding = new byte[encodingLength];\n+        unsafe.copyMemory(null, buffer + 4, encoding, Unsafe.ARRAY_BYTE_BASE_OFFSET, encodingLength);\n+        throw TranslatedException.decodeThrowable(encoding);\n@@ -215,0 +228,12 @@\n+    \/**\n+     * If {@code bufferSize} is large enough, encodes {@code throwable} into a byte array and writes\n+     * it to {@code buffer}. The encoding in {@code buffer} can be decoded by\n+     * {@link #decodeAndThrowThrowable}.\n+     *\n+     * @param throwable the exception to encode\n+     * @param buffer a native byte buffer\n+     * @param bufferSize the size of {@code buffer} in bytes\n+     * @return the number of bytes written into {@code buffer} if {@code bufferSize} is large\n+     *         enough, otherwise {@code -N} where {@code N} is the value {@code bufferSize} needs to\n+     *         be to fit the encoding\n+     *\/\n@@ -216,2 +241,10 @@\n-    static String encodeThrowable(Throwable throwable) throws Throwable {\n-        return TranslatedException.encodeThrowable(throwable);\n+    static int encodeThrowable(Throwable throwable, long buffer, int bufferSize) throws Throwable {\n+        byte[] encoding = TranslatedException.encodeThrowable(throwable);\n+        int requiredSize = 4 + encoding.length;\n+        if (bufferSize < requiredSize) {\n+            return -requiredSize;\n+        }\n+        Unsafe unsafe = UnsafeAccess.UNSAFE;\n+        unsafe.putInt(buffer, encoding.length);\n+        unsafe.copyMemory(encoding, Unsafe.ARRAY_BYTE_BASE_OFFSET, null, buffer + 4, encoding.length);\n+        return requiredSize;\n@@ -246,0 +279,4 @@\n+        ForceTranslateFailure(String.class, null, \"Forces HotSpotJVMCIRuntime.translate to throw an exception in the context \" +\n+                \"of the peer runtime. The value is a filter that can restrict the forced failure to matching translated \" +\n+                \"objects. See HotSpotJVMCIRuntime.postTranslation for more details. This option exists soley to test \" +\n+                \"correct handling of translation failure.\"),\n@@ -1191,1 +1228,82 @@\n-        return compilerToVm.translate(obj);\n+        return compilerToVm.translate(obj, Option.ForceTranslateFailure.getString() != null);\n+    }\n+\n+    private static final Pattern FORCE_TRANSLATE_FAILURE_FILTER_RE = Pattern.compile(\"(?:(method|type|nmethod)\/)?([^:]+)(?::(hotspot|native))?\");\n+\n+    \/**\n+     * Forces translation failure based on {@code translatedObject} and the value of\n+     * {@link Option#ForceTranslateFailure}. The value is zero or more filters separated by a comma.\n+     * The syntax for a filter is:\n+     *\n+     * <pre>\n+     *   Filter = [ TypeSelector \"\/\" ] Substring [ \":\" JVMCIEnvSelector ] .\n+     *   TypeSelector = \"type\" | \"method\" | \"nmethod\"\n+     *   JVMCIEnvSelector = \"native\" | \"hotspot\"\n+     * <\/pre>\n+     *\n+     * For example:\n+     *\n+     * <pre>\n+     *   -Djvmci.ForceTranslateFailure=nmethod\/StackOverflowError:native,method\/computeHash,execute\n+     * <\/pre>\n+     *\n+     * will cause failure of:\n+     * <ul>\n+     * <li>translating a {@link HotSpotNmethod} to the libjvmci heap whose fully qualified name\n+     * contains \"StackOverflowError\"<\/li>\n+     * <li>translating a {@link HotSpotResolvedJavaMethodImpl} to the libjvmci or HotSpot heap whose\n+     * fully qualified name contains \"computeHash\"<\/li>\n+     * <li>translating a {@link HotSpotNmethod}, {@link HotSpotResolvedJavaMethodImpl} or\n+     * {@link HotSpotResolvedObjectTypeImpl} to the libjvmci or HotSpot heap whose fully qualified\n+     * name contains \"execute\"<\/li>\n+     * <\/ul>\n+     *\/\n+    @VMEntryPoint\n+    static void postTranslation(Object translatedObject) {\n+        String value = Option.ForceTranslateFailure.getString();\n+        String toMatch;\n+        String type;\n+        if (translatedObject instanceof HotSpotResolvedJavaMethodImpl) {\n+            toMatch = ((HotSpotResolvedJavaMethodImpl) translatedObject).format(\"%H.%n\");\n+            type = \"method\";\n+        } else if (translatedObject instanceof HotSpotResolvedObjectTypeImpl) {\n+            toMatch = ((HotSpotResolvedObjectTypeImpl) translatedObject).toJavaName();\n+            type = \"type\";\n+        } else if (translatedObject instanceof HotSpotNmethod) {\n+            HotSpotNmethod nmethod = (HotSpotNmethod) translatedObject;\n+            if (nmethod.getMethod() != null) {\n+                toMatch = nmethod.getMethod().format(\"%H.%n\");\n+            } else {\n+                toMatch = String.valueOf(nmethod.getName());\n+            }\n+            type = \"nmethod\";\n+        } else {\n+            return;\n+        }\n+        String[] filters = value.split(\",\");\n+        for (String filter : filters) {\n+            Matcher m = FORCE_TRANSLATE_FAILURE_FILTER_RE.matcher(filter);\n+            if (!m.matches()) {\n+                throw new JVMCIError(Option.ForceTranslateFailure + \" filter does not match \" + FORCE_TRANSLATE_FAILURE_FILTER_RE + \": \" + filter);\n+            }\n+            String typeSelector = m.group(1);\n+            String substring = m.group(2);\n+            String jvmciEnvSelector = m.group(3);\n+            if (jvmciEnvSelector != null) {\n+                if (jvmciEnvSelector.equals(\"native\")) {\n+                    if (!Services.IS_IN_NATIVE_IMAGE) {\n+                        continue;\n+                    }\n+                } else {\n+                    if (Services.IS_IN_NATIVE_IMAGE) {\n+                        continue;\n+                    }\n+                }\n+            }\n+            if (typeSelector != null && !typeSelector.equals(type)) {\n+                continue;\n+            }\n+            if (toMatch.contains(substring)) {\n+                throw new JVMCIError(\"translation of \" + translatedObject + \" failed due to matching \" + Option.ForceTranslateFailure + \" filter \\\"\" + filter + \"\\\"\");\n+            }\n+        }\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk.vm.ci.hotspot\/src\/jdk\/vm\/ci\/hotspot\/HotSpotJVMCIRuntime.java","additions":124,"deletions":6,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -341,1 +341,1 @@\n-    final int deoptReasonOSROffset = getConstant(\"Deoptimization::Reason_LIMIT\", Integer.class);\n+    final int deoptReasonOSROffset = getConstant(\"Deoptimization::Reason_TRAP_HISTORY_LENGTH\", Integer.class);\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk.vm.ci.hotspot\/src\/jdk\/vm\/ci\/hotspot\/HotSpotVMConfig.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -636,0 +636,6 @@\n+     *\n+     * @deprecated The guarantee that a field will always have the same offset\n+     * and base may not be true in a future release. The ability to provide an\n+     * offset and object reference to a heap memory accessor will be removed\n+     * in a future release. Use {@link java.lang.invoke.VarHandle} instead.\n+     *\n@@ -638,0 +644,1 @@\n+    @Deprecated(since=\"18\")\n@@ -671,0 +678,6 @@\n+     *\n+     * @deprecated The guarantee that a field will always have the same offset\n+     * and base may not be true in a future release. The ability to provide an\n+     * offset and object reference to a heap memory accessor will be removed\n+     * in a future release. Use {@link java.lang.invoke.VarHandle} instead.\n+     *\n@@ -673,0 +686,1 @@\n+    @Deprecated(since=\"18\")\n@@ -700,0 +714,5 @@\n+     *\n+     * @deprecated The guarantee that a field will always have the same offset\n+     * and base may not be true in a future release. The ability to provide an\n+     * offset and object reference to a heap memory accessor will be removed\n+     * in a future release. Use {@link java.lang.invoke.VarHandle} instead.\n@@ -701,0 +720,1 @@\n+    @Deprecated(since=\"18\")\n","filename":"src\/jdk.unsupported\/share\/classes\/sun\/misc\/Unsafe.java","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -71,2 +71,2 @@\n-  pm.push(o1.get_oop(), o1.mark());\n-  pm.push(o2.get_oop(), o2.mark());\n+  pm.push_if_necessary(o1.get_oop(), o1.mark());\n+  pm.push_if_necessary(o2.get_oop(), o2.mark());\n","filename":"test\/hotspot\/gtest\/gc\/shared\/test_preservedMarks.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,3 +41,0 @@\n-vmTestbase\/nsk\/jvmti\/AttachOnDemand\/attach002a\/TestDescription.java 8265795 generic-all\n-vmTestbase\/nsk\/jvmti\/AttachOnDemand\/attach022\/TestDescription.java 8265795 generic-all\n-vmTestbase\/nsk\/jdi\/ObjectReference\/referringObjects\/referringObjects002\/referringObjects002.java 8265796  generic-all\n@@ -77,1 +74,1 @@\n-compiler\/codecache\/jmx\/PoolsIndependenceTest.java 8264632 macosx-x64\n+compiler\/codecache\/jmx\/PoolsIndependenceTest.java 8264632 macosx-generic\n@@ -108,1 +105,1 @@\n-runtime\/jni\/checked\/TestPrimitiveArrayCriticalWithBadParam.java 8277350 macosx-x64\n+runtime\/ErrorHandling\/CreateCoredumpOnCrash.java 8267433 macosx-x64\n@@ -112,0 +109,2 @@\n+containers\/docker\/TestJcmd.java 8278102 linux-aarch64\n+\n@@ -129,1 +128,1 @@\n-serviceability\/sa\/ClhsdbPmap.java#core 8267433 macosx-x64\n+serviceability\/sa\/ClhsdbPmap.java#core 8269982,8267433 macosx-aarch64,macosx-x64\n@@ -131,2 +130,2 @@\n-serviceability\/sa\/TestJmapCore.java 8267433 macosx-x64\n-serviceability\/sa\/TestJmapCoreMetaspace.java 8267433 macosx-x64\n+serviceability\/sa\/TestJmapCore.java 8269982,8267433 macosx-aarch64,macosx-x64\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8269982,8267433 macosx-aarch64,macosx-x64\n@@ -194,1 +193,1 @@\n-vmTestbase\/nsk\/jvmti\/SuspendThread\/suspendthrd003\/TestDescription.java 8264605 generic-all\n+vmTestbase\/nsk\/jvmti\/AttachOnDemand\/attach002a\/TestDescription.java 8277812 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":9,"deletions":10,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -49,0 +49,4 @@\n+hotspot_runtime_no_cds = \\\n+  runtime \\\n+  -runtime\/cds\n+\n@@ -82,0 +86,7 @@\n+# Test sets for running inside container environment\n+hotspot_containers_extended = \\\n+  runtime \\\n+  serviceability \\\n+  vmTestbase\/nsk\/jvmti \\\n+  vmTestbase\/nsk\/monitoring\n+\n@@ -105,0 +116,3 @@\n+hotspot_compiler_arraycopy = \\\n+  compiler\/arraycopy\/stress\n+\n@@ -125,1 +139,2 @@\n-  compiler\/gcbarriers\/PreserveFPRegistersTest.java\n+  compiler\/gcbarriers\/PreserveFPRegistersTest.java \\\n+  :hotspot_compiler_arraycopy\n@@ -143,0 +158,1 @@\n+  -:hotspot_slow_compiler\n@@ -185,0 +201,44 @@\n+tier2_compiler = \\\n+  compiler\/allocation\/ \\\n+  compiler\/arguments\/ \\\n+  compiler\/calls\/ \\\n+  compiler\/cha\/ \\\n+  compiler\/controldependency\/ \\\n+  compiler\/conversions\/ \\\n+  compiler\/codegen\/ \\\n+  compiler\/linkage\/ \\\n+  compiler\/loopstripmining\/ \\\n+  compiler\/loopopts\/Test7052494.java \\\n+  compiler\/longcountedloops\/ \\\n+  compiler\/intrinsics\/bmi \\\n+  compiler\/intrinsics\/mathexact \\\n+  compiler\/intrinsics\/sha \\\n+  compiler\/intrinsics\/bigInteger\/TestMultiplyToLen.java \\\n+  compiler\/intrinsics\/zip\/TestAdler32.java \\\n+  compiler\/membars\/ \\\n+  compiler\/onSpinWait\/ \\\n+  compiler\/parsing\/ \\\n+  compiler\/rangechecks\/ \\\n+  compiler\/reflection\/ \\\n+  compiler\/rtm\/ \\\n+  compiler\/runtime\/Test6826736.java \\\n+  compiler\/stable\/ \\\n+  compiler\/stringopts\/ \\\n+  -:tier1_compiler \\\n+  -:hotspot_slow_compiler\n+\n+tier3_compiler = \\\n+  compiler\/c2\/ \\\n+  compiler\/ciReplay\/ \\\n+  compiler\/compilercontrol\/ \\\n+  compiler\/debug\/ \\\n+  compiler\/oracle\/ \\\n+  compiler\/print\/ \\\n+  compiler\/relocations\/ \\\n+  compiler\/tiered\/ \\\n+  compiler\/vectorapi\/ \\\n+  compiler\/whitebox\/ \\\n+  :hotspot_slow_compiler \\\n+  -:tier1_compiler \\\n+  -:tier2_compiler\n+\n@@ -351,0 +411,2 @@\n+hotspot_cds_only = \\\n+  runtime\/cds\/\n@@ -372,0 +434,1 @@\n+ -runtime\/cds\/appcds\/DumpingWithNoCoops.java \\\n@@ -377,0 +440,1 @@\n+ -runtime\/cds\/appcds\/LambdaWithJavaAgent.java \\\n@@ -490,0 +554,1 @@\n+  :tier2_compiler \\\n@@ -495,0 +560,1 @@\n+  :tier3_compiler \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":67,"deletions":1,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -4,1 +4,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -164,1 +164,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -324,1 +324,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -372,1 +372,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -523,1 +523,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -571,1 +571,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -727,1 +727,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -775,1 +775,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/GetfieldChains.jcod","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -44,1 +44,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -78,1 +78,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/HiddenPoint.jcod","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -38,1 +38,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/MultiANewArrayTest\/MultiANewArrayTypeCheck.jcod","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -25,1 +25,1 @@\n-public class runtime\/valhalla\/inlinetypes\/TestFieldTypeMismatchHelper version 62:0 {\n+public class runtime\/valhalla\/inlinetypes\/TestFieldTypeMismatchHelper version 63:0 {\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/TestFieldTypeMismatchHelper.jasm","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -39,1 +39,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/ValuePreloadClient1.jcod","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -96,1 +96,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -356,1 +356,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/WithFieldNoAccessTest.jcod","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -51,1 +51,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -207,1 +207,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -363,1 +363,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -519,1 +519,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -626,1 +626,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -881,1 +881,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1160,1 +1160,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1474,1 +1474,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1752,1 +1752,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -2039,1 +2039,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -2500,1 +2500,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/classfileparser\/cfpTests.jcod","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -4,1 +4,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/identityObject\/IdentityType.jcod","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -94,1 +94,1 @@\n-        return new BasicClassBuilder(\"ANormalClass\", 62, 0)\n+        return new BasicClassBuilder(\"ANormalClass\", 63, 0)\n@@ -100,1 +100,1 @@\n-        return new BasicClassBuilder(\"AbstractWithField\", 62, 0)\n+        return new BasicClassBuilder(\"AbstractWithField\", 63, 0)\n@@ -108,1 +108,1 @@\n-        return new BasicClassBuilder(\"AbstractIdentity\", 62, 0)\n+        return new BasicClassBuilder(\"AbstractIdentity\", 63, 0)\n@@ -116,1 +116,1 @@\n-        return new BasicClassBuilder(\"Identity\", 62, 0)\n+        return new BasicClassBuilder(\"Identity\", 63, 0)\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/primitiveObject\/TestPrimitiveObject.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -302,1 +302,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -562,1 +562,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -821,1 +821,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1082,1 +1082,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1342,1 +1342,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1606,1 +1606,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1866,1 +1866,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/testSupers\/InlineClassWithBadSupers.jcod","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -63,1 +63,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -265,1 +265,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -366,1 +366,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -457,1 +457,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -547,1 +547,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -739,1 +739,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -830,1 +830,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1054,1 +1054,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1236,1 +1236,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/verifier\/verifierTests.jcod","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -187,1 +187,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -344,1 +344,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -485,1 +485,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -613,1 +613,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -718,1 +718,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -807,1 +807,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -896,1 +896,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n@@ -1022,1 +1022,1 @@\n-  62; \/\/ version\n+  63; \/\/ version\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/withfieldTests\/withfieldTests.jcod","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -77,1 +77,3 @@\n-    :jdk_jfr_tier3\n+    :jdk_svc \\\n+   -:jdk_svc_sanity \\\n+   -:svc_tools\n@@ -294,3 +296,0 @@\n-jdk_jfr_tier3 = \\\n-    jdk\/jfr\/event\/metadata\/TestLookForUntestedEvents.java\n-\n@@ -397,3 +396,6 @@\n-    :jdk_awt \\\n-    :jdk_2d \\\n-    :jdk_beans \\\n+    :jdk_desktop_part1 \\\n+    :jdk_desktop_part2 \\\n+    :jdk_desktop_part3\n+\n+jdk_desktop_part1 = \\\n+    :jdk_client_sanity \\\n@@ -401,0 +403,1 @@\n+    :jdk_2d \\\n@@ -403,1 +406,1 @@\n-    :jdk_accessibility \\\n+    :jdk_editpad \\\n@@ -405,2 +408,15 @@\n-    :jdk_client_sanity \\\n-    :jdk_editpad\n+    :jdk_accessibility \\\n+    :jdk_beans\n+\n+jdk_desktop_part2 = \\\n+    :jdk_awt \\\n+    -java\/awt\/Component \\\n+    -java\/awt\/Modal \\\n+    -java\/awt\/datatransfer \\\n+    -java\/awt\/Window\n+\n+jdk_desktop_part3 = \\\n+    java\/awt\/Component \\\n+    java\/awt\/Modal \\\n+    java\/awt\/datatransfer \\\n+    java\/awt\/Window\n@@ -529,1 +545,17 @@\n-  \n+\n+#  This set of tests will be executed in an ipv6 only environment\n+\n+jdk_ipv6_only = \\\n+    :jdk_net \\\n+    :jdk_nio_networkchannel\n+\n+jdk_nio_networkchannel = \\\n+    java\/nio\/channels\/AsyncCloseAndInterrupt.java \\\n+    java\/nio\/channels\/AsynchronousServerSocketChannel \\\n+    java\/nio\/channels\/AsynchronousSocketChannel \\\n+    java\/nio\/channels\/DatagramChannel \\\n+    java\/nio\/channels\/ServerSocketChannel \\\n+    java\/nio\/channels\/SocketChannel \\\n+    java\/nio\/channels\/Selector \\\n+    java\/nio\/channels\/etc\n+\n@@ -578,0 +610,5 @@\n+# Test sets for running inside container environment\n+jdk_containers_extended = \\\n+    :jdk_io \\\n+    :jdk_nio \\\n+    :jdk_svc\n","filename":"test\/jdk\/TEST.groups","additions":48,"deletions":11,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -220,1 +220,1 @@\n-                    .withMajorVersion(62)\n+                    .withMajorVersion(63)\n","filename":"test\/jdk\/java\/lang\/invoke\/common\/test\/java\/lang\/invoke\/lib\/InstructionHelper.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -176,0 +176,1 @@\n+            assertThrows(NPE, () -> ObjectMethods.bootstrap(null, npt.mn(),     npt.mt(), C.class, \"x;y\", C.ACCESSORS));\n","filename":"test\/jdk\/java\/lang\/runtime\/ObjectMethodsTest.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2009, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2009, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,1 @@\n- * @bug 6797535 6889858 6891113 8013712 8011800 8014365\n+ * @bug 6797535 6889858 6891113 8013712 8011800 8014365 8280168\n@@ -28,1 +28,0 @@\n- * @author  Joseph D. Darcy\n@@ -43,0 +42,1 @@\n+        errors += testToIdentityString();\n@@ -138,0 +138,31 @@\n+    private static int testToIdentityString() {\n+        int errors = 0;\n+        \/\/ Test null behavior\n+        try {\n+            Objects.toIdentityString(null);\n+            errors++;\n+        } catch (NullPointerException npe) {\n+            ; \/\/ Expected\n+        }\n+        \/\/ Behavior on typical objects\n+        Object o = new Object(){};\n+        errors += (Objects.toIdentityString(o).equals(o.toString()))? 0 : 1;\n+        \/\/ Verify object's toString *not* called\n+        Object badToString = new Object() {\n+                @Override\n+                public String toString() {\n+                    throw new RuntimeException();\n+                }\n+            };\n+        Objects.toIdentityString(badToString);\n+        \/\/ Verify object's hashCode *not* called\n+        Object badHashCode = new Object() {\n+                @Override\n+                public int hashCode() {\n+                    throw new RuntimeException(\"0xDEADBEFF\");\n+                }\n+            };\n+        Objects.toIdentityString(badHashCode);\n+        return errors;\n+    }\n+\n","filename":"test\/jdk\/java\/util\/Objects\/BasicObjectsTest.java","additions":34,"deletions":3,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -210,0 +210,2 @@\n+compiler.misc.illegal.signature                               # the compiler can now detect more non-denotable types before class writing\n+\n","filename":"test\/langtools\/tools\/javac\/diags\/examples.not-yet.txt","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+CheckFinalize.java:15:12: compiler.warn.has.been.deprecated.for.removal: finalize(), java.lang.Object\n@@ -5,2 +6,0 @@\n-- compiler.note.deprecated.filename: CheckFinalize.java\n-- compiler.note.deprecated.recompile\n@@ -8,0 +7,1 @@\n+1 warning\n","filename":"test\/langtools\/tools\/javac\/valhalla\/lworld-values\/CheckFinalize.out","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,0 +2,1 @@\n+CheckObjectMethodsUsage.java:15:14: compiler.warn.has.been.deprecated.for.removal: finalize(), java.lang.Object\n@@ -13,3 +14,2 @@\n-- compiler.note.deprecated.filename: CheckObjectMethodsUsage.java\n-- compiler.note.deprecated.recompile\n-12 errors\n+12 errors\n+1 warning\n","filename":"test\/langtools\/tools\/javac\/valhalla\/lworld-values\/CheckObjectMethodsUsage.out","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -6,0 +6,1 @@\n+CheckSync.java:23:13: compiler.warn.has.been.deprecated.for.removal: finalize(), java.lang.Object\n@@ -17,2 +18,0 @@\n-- compiler.note.deprecated.filename: CheckSync.java\n-- compiler.note.deprecated.recompile\n@@ -20,1 +19,1 @@\n-2 warnings\n+3 warnings\n","filename":"test\/langtools\/tools\/javac\/valhalla\/lworld-values\/CheckSync.out","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -73,1 +73,1 @@\n-        \" 2: anewarray     #11                 \/\/ class \\\"QUnifiedPrimitiveClassBytecodeTest$X;\\\"\",\n+        \" 2: anewarray     #7                  \/\/ class \\\"QUnifiedPrimitiveClassBytecodeTest$X;\\\"\",\n@@ -90,1 +90,1 @@\n-        \"26: checkcast     #11                 \/\/ class \\\"QUnifiedPrimitiveClassBytecodeTest$X;\\\"\",\n+        \"26: checkcast     #7                  \/\/ class \\\"QUnifiedPrimitiveClassBytecodeTest$X;\\\"\",\n@@ -92,1 +92,1 @@\n-        \"30: ldc           #11                 \/\/ class \\\"QUnifiedPrimitiveClassBytecodeTest$X;\\\"\",\n+        \"30: ldc           #7                  \/\/ class \\\"QUnifiedPrimitiveClassBytecodeTest$X;\\\"\",\n","filename":"test\/langtools\/tools\/javac\/valhalla\/lworld-values\/UnifiedPrimitiveClassBytecodeTest.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-         \"3: withfield     #7                  \/\/ Field i:I\",\n+         \"3: withfield     #3                  \/\/ Field i:I\",\n@@ -70,1 +70,1 @@\n-         \"8: invokevirtual #11                 \/\/ Method java\/lang\/Integer.intValue:()I\",\n+         \"8: invokevirtual #7                  \/\/ Method java\/lang\/Integer.intValue:()I\",\n@@ -73,1 +73,1 @@\n-        \"13: withfield     #7                  \/\/ Field i:I\",\n+        \"13: withfield     #3                  \/\/ Field i:I\",\n","filename":"test\/langtools\/tools\/javac\/valhalla\/lworld-values\/WithFieldOfExplicitSelector.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -69,1 +69,1 @@\n-         \"6: withfield     #7                  \/\/ Field x:I\",\n+         \"6: withfield     #3                  \/\/ Field x:I\",\n@@ -73,2 +73,2 @@\n-        \"12: invokevirtual #11                 \/\/ Method java\/lang\/Integer.intValue:()I\",\n-        \"15: withfield     #7                  \/\/ Field x:I\",\n+        \"12: invokevirtual #7                  \/\/ Method java\/lang\/Integer.intValue:()I\",\n+        \"15: withfield     #3                  \/\/ Field x:I\",\n","filename":"test\/langtools\/tools\/javac\/valhalla\/lworld-values\/WithFieldOfImplicitThis.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-         \"3: withfield     #7                  \/\/ Field i:I\",\n+         \"3: withfield     #3                  \/\/ Field i:I\",\n@@ -70,1 +70,1 @@\n-         \"8: invokevirtual #11                 \/\/ Method java\/lang\/Integer.intValue:()I\",\n+         \"8: invokevirtual #7                  \/\/ Method java\/lang\/Integer.intValue:()I\",\n@@ -73,1 +73,1 @@\n-        \"13: withfield     #7                  \/\/ Field i:I\",\n+        \"13: withfield     #3                  \/\/ Field i:I\",\n","filename":"test\/langtools\/tools\/javac\/valhalla\/value-objects\/WithFieldOfExplicitSelector.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -69,1 +69,1 @@\n-         \"6: withfield     #7                  \/\/ Field x:I\",\n+         \"6: withfield     #3                  \/\/ Field x:I\",\n@@ -73,2 +73,2 @@\n-        \"12: invokevirtual #11                 \/\/ Method java\/lang\/Integer.intValue:()I\",\n-        \"15: withfield     #7                  \/\/ Field x:I\",\n+        \"12: invokevirtual #7                  \/\/ Method java\/lang\/Integer.intValue:()I\",\n+        \"15: withfield     #3                  \/\/ Field x:I\",\n","filename":"test\/langtools\/tools\/javac\/valhalla\/value-objects\/WithFieldOfImplicitThis.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -243,1 +243,0 @@\n-  public native boolean NMTChangeTrackingLevel();\n@@ -335,0 +334,30 @@\n+  public         int     getMethodDecompileCount(Executable method) {\n+    Objects.requireNonNull(method);\n+    return getMethodDecompileCount0(method);\n+  }\n+  private native int     getMethodDecompileCount0(Executable method);\n+  \/\/ Get the total trap count of a method. If the trap count for a specific reason\n+  \/\/ did overflow, this includes the overflow trap count of the method.\n+  public         int     getMethodTrapCount(Executable method) {\n+    Objects.requireNonNull(method);\n+    return getMethodTrapCount0(method, null);\n+  }\n+  \/\/ Get the trap count of a method for a specific reason. If the trap count for\n+  \/\/ that reason did overflow, this includes the overflow trap count of the method.\n+  public         int     getMethodTrapCount(Executable method, String reason) {\n+    Objects.requireNonNull(method);\n+    return getMethodTrapCount0(method, reason);\n+  }\n+  private native int     getMethodTrapCount0(Executable method, String reason);\n+  \/\/ Get the total deopt count.\n+  public         int     getDeoptCount() {\n+    return getDeoptCount0(null, null);\n+  }\n+  \/\/ Get the deopt count for a specific reason and a specific action. If either\n+  \/\/ one of 'reason' or 'action' is null, the method returns the sum of all\n+  \/\/ deoptimizations with the specific 'action' or 'reason' respectively.\n+  \/\/ If both arguments are null, the method returns the total deopt count.\n+  public         int     getDeoptCount(String reason, String action) {\n+    return getDeoptCount0(reason, action);\n+  }\n+  private native int     getDeoptCount0(String reason, String action);\n@@ -612,0 +641,2 @@\n+  public native int     getCDSGenericHeaderMinVersion();\n+  public native int     getCurrentCDSVersion();\n","filename":"test\/lib\/sun\/hotspot\/WhiteBox.java","additions":32,"deletions":1,"binary":false,"changes":33,"status":"modified"}]}