{"files":[{"patch":"@@ -891,1 +891,1 @@\n-          Start-Process -FilePath \"$HOME\\cygwin\\setup-x86_64.exe\" -ArgumentList \"--quiet-mode --packages autoconf,make,zip,unzip --root $HOME\\cygwin\\cygwin64 --local-package-dir $HOME\\cygwin\\packages --site http:\/\/mirrors.kernel.org\/sourceware\/cygwin --no-desktop --no-shortcuts --no-startmenu --no-admin\" -Wait -NoNewWindow\n+          Start-Process -FilePath \"$HOME\\cygwin\\setup-x86_64.exe\" -ArgumentList \"--quiet-mode --packages cygwin=3.2.0-1,autoconf,make,zip,unzip --root $HOME\\cygwin\\cygwin64 --local-package-dir $HOME\\cygwin\\packages --site http:\/\/mirrors.kernel.org\/sourceware\/cygwin --no-desktop --no-shortcuts --no-startmenu --no-admin\" -Wait -NoNewWindow\n@@ -980,1 +980,1 @@\n-          Start-Process -FilePath \"$HOME\\cygwin\\setup-x86_64.exe\" -ArgumentList \"--quiet-mode --packages autoconf,make,zip,unzip --root $HOME\\cygwin\\cygwin64 --local-package-dir $HOME\\cygwin\\packages --site http:\/\/mirrors.kernel.org\/sourceware\/cygwin --no-desktop --no-shortcuts --no-startmenu --no-admin\" -Wait -NoNewWindow\n+          Start-Process -FilePath \"$HOME\\cygwin\\setup-x86_64.exe\" -ArgumentList \"--quiet-mode --packages cygwin=3.2.0-1,autoconf,make,zip,unzip --root $HOME\\cygwin\\cygwin64 --local-package-dir $HOME\\cygwin\\packages --site http:\/\/mirrors.kernel.org\/sourceware\/cygwin --no-desktop --no-shortcuts --no-startmenu --no-admin\" -Wait -NoNewWindow\n@@ -1152,1 +1152,1 @@\n-          Start-Process -FilePath \"$HOME\\cygwin\\setup-x86_64.exe\" -ArgumentList \"--quiet-mode --packages autoconf,make,zip,unzip --root $HOME\\cygwin\\cygwin64 --local-package-dir $HOME\\cygwin\\packages --site http:\/\/mirrors.kernel.org\/sourceware\/cygwin --no-desktop --no-shortcuts --no-startmenu --no-admin\" -Wait -NoNewWindow\n+          Start-Process -FilePath \"$HOME\\cygwin\\setup-x86_64.exe\" -ArgumentList \"--quiet-mode --packages cygwin=3.2.0-1,autoconf,make,zip,unzip --root $HOME\\cygwin\\cygwin64 --local-package-dir $HOME\\cygwin\\packages --site http:\/\/mirrors.kernel.org\/sourceware\/cygwin --no-desktop --no-shortcuts --no-startmenu --no-admin\" -Wait -NoNewWindow\n","filename":".github\/workflows\/submit.yml","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -562,1 +562,1 @@\n-    [ \"linux-x64\", \"macosx-x64\", \"windows-x64\"]\n+    [ \"linux-x64\", \"macosx-x64\", \"windows-x64\", \"linux-aarch64\"]\n@@ -591,0 +591,11 @@\n+        \"linux-aarch64-zero\": {\n+            target_os: \"linux\",\n+            target_cpu: \"aarch64\",\n+            dependencies: [\"devkit\", \"gtest\"],\n+            configure_args: concat(common.configure_args_64bit, [\n+                \"--with-zlib=system\",\n+                \"--with-jvm-variants=zero\",\n+                \"--enable-libffi-bundling\"\n+            ])\n+        },\n+\n@@ -1135,1 +1146,1 @@\n-            version: \"6\",\n+            version: \"6.1\",\n@@ -1137,1 +1148,1 @@\n-            file: \"bundles\/jtreg-6+1.zip\",\n+            file: \"bundles\/jtreg-6.1+1.zip\",\n@@ -1146,1 +1157,1 @@\n-            revision: \"1.28+1.0\"\n+            revision: \"1.33+1.0\"\n","filename":"make\/conf\/jib-profiles.js","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -1202,0 +1202,3 @@\n+reg_class p0_reg(P0);\n+reg_class p1_reg(P1);\n+\n@@ -2048,1 +2051,1 @@\n-  if (src_hi != OptoReg::Bad) {\n+  if (src_hi != OptoReg::Bad && !bottom_type()->isa_vectmask()) {\n@@ -2063,1 +2066,1 @@\n-  if (bottom_type()->isa_vect() != NULL) {\n+  if (bottom_type()->isa_vect() && !bottom_type()->isa_vectmask()) {\n@@ -2169,0 +2172,3 @@\n+      } else if (dst_lo_rc == rc_predicate) {\n+        __ unspill_sve_predicate(as_PRegister(Matcher::_regEncode[dst_lo]), ra_->reg2offset(src_lo),\n+                                 Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n@@ -2171,2 +2177,18 @@\n-        __ unspill(rscratch1, is64, src_offset);\n-        __ spill(rscratch1, is64, dst_offset);\n+        if (ideal_reg() == Op_RegVectMask) {\n+          __ spill_copy_sve_predicate_stack_to_stack(src_offset, dst_offset,\n+                                                     Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n+        } else {\n+          __ unspill(rscratch1, is64, src_offset);\n+          __ spill(rscratch1, is64, dst_offset);\n+        }\n+      }\n+      break;\n+    case rc_predicate:\n+      if (dst_lo_rc == rc_predicate) {\n+        __ sve_mov(as_PRegister(Matcher::_regEncode[dst_lo]), as_PRegister(Matcher::_regEncode[src_lo]));\n+      } else if (dst_lo_rc == rc_stack) {\n+        __ spill_sve_predicate(as_PRegister(Matcher::_regEncode[src_lo]), ra_->reg2offset(dst_lo),\n+                               Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n+      } else {\n+        assert(false, \"bad src and dst rc_class combination.\");\n+        ShouldNotReachHere();\n@@ -2193,1 +2215,1 @@\n-    if (bottom_type()->isa_vect() != NULL) {\n+    if (bottom_type()->isa_vect() && !bottom_type()->isa_vectmask()) {\n@@ -2210,0 +2232,4 @@\n+    } else if (ideal_reg() == Op_RegVectMask) {\n+      assert(Matcher::supports_scalable_vector(), \"bad register type for spill\");\n+      int vsize = Matcher::scalable_predicate_reg_slots() * 32;\n+      st->print(\"\\t# predicate spill size = %d\", vsize);\n@@ -2392,0 +2418,2 @@\n+    case Op_OnSpinWait:\n+      return VM_Version::supports_on_spin_wait();\n@@ -2399,0 +2427,12 @@\n+    case Op_LoadVectorMasked:\n+    case Op_StoreVectorMasked:\n+    case Op_LoadVectorGatherMasked:\n+    case Op_StoreVectorScatterMasked:\n+    case Op_MaskAll:\n+    case Op_AndVMask:\n+    case Op_OrVMask:\n+    case Op_XorVMask:\n+      if (UseSVE == 0) {\n+        ret_value = false;\n+      }\n+      break;\n@@ -2420,3 +2460,0 @@\n-    \/\/ We don't have VectorReinterpret with bit_size less than 64 support for\n-    \/\/ now, even for byte type. To be refined with fully VectorCast support.\n-    case Op_VectorReinterpret:\n@@ -2440,17 +2477,0 @@\n-    \/\/ Some types of VectorCast are not implemented for now.\n-    case Op_VectorCastI2X:\n-      if (bt == T_BYTE) {\n-        return false;\n-      }\n-      break;\n-    case Op_VectorCastS2X:\n-      if (vlen < 4 || bit_size < 64) {\n-        return false;\n-      }\n-      break;\n-    case Op_VectorCastF2X:\n-    case Op_VectorCastD2X:\n-      if (bt == T_INT || bt == T_SHORT || bt == T_BYTE || bt == T_LONG) {\n-        return false;\n-      }\n-      break;\n@@ -2467,0 +2487,9 @@\n+const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+  \/\/ Only SVE supports masked operations.\n+  if (UseSVE == 0) {\n+    return false;\n+  }\n+  return match_rule_supported(opcode) &&\n+         masked_op_sve_supported(opcode, vlen, bt);\n+}\n+\n@@ -2678,0 +2707,41 @@\n+bool can_combine_with_imm(Node* binary_node, Node* replicate_node) {\n+  if (UseSVE == 0 || !VectorNode::is_invariant_vector(replicate_node)){\n+    return false;\n+  }\n+  Node* imm_node = replicate_node->in(1);\n+  if (!imm_node->is_Con()) {\n+    return false;\n+  }\n+\n+  const Type* t = imm_node->bottom_type();\n+  if (!(t->isa_int() || t->isa_long())) {\n+    return false;\n+  }\n+\n+  switch (binary_node->Opcode()) {\n+  case Op_AndV:\n+  case Op_OrV:\n+  case Op_XorV: {\n+    Assembler::SIMD_RegVariant T = Assembler::elemType_to_regVariant(Matcher::vector_element_basic_type(binary_node));\n+    uint64_t value = t->isa_long() ? (uint64_t)imm_node->get_long() : (uint64_t)imm_node->get_int();\n+    return Assembler::operand_valid_for_sve_logical_immediate(Assembler::regVariant_to_elemBits(T), value);\n+  }\n+  case Op_AddVB:\n+    return (imm_node->get_int() <= 255 && imm_node->get_int() >= -255);\n+  case Op_AddVS:\n+  case Op_AddVI:\n+    return Assembler::operand_valid_for_sve_add_sub_immediate((int64_t)imm_node->get_int());\n+  case Op_AddVL:\n+    return Assembler::operand_valid_for_sve_add_sub_immediate(imm_node->get_long());\n+  default:\n+    return false;\n+  }\n+}\n+\n+bool is_vector_arith_imm_pattern(Node* n, Node* m) {\n+  if (n != NULL && m != NULL) {\n+    return can_combine_with_imm(n, m);\n+  }\n+  return false;\n+}\n+\n@@ -2680,2 +2750,7 @@\n-  if (is_vshift_con_pattern(n, m)) { \/\/ ShiftV src (ShiftCntV con)\n-    mstack.push(m, Visit);           \/\/ m = ShiftCntV\n+  \/\/ ShiftV src (ShiftCntV con)\n+  \/\/ StoreVector (VectorStoreMask src)\n+  \/\/ Binary src (Replicate con)\n+  if (is_vshift_con_pattern(n, m) ||\n+      (UseSVE > 0 && m->Opcode() == Op_VectorStoreMask && n->Opcode() == Op_StoreVector) ||\n+      is_vector_arith_imm_pattern(n, m)) {\n+    mstack.push(m, Visit);\n@@ -2684,0 +2759,1 @@\n+\n@@ -3907,1 +3983,1 @@\n-               \/*release*\/ true, \/*weak*\/ false, noreg); \/\/ Sets flags for result\n+               \/*release*\/ true, \/*weak*\/ false, rscratch1); \/\/ Sets flags for result\n@@ -3916,0 +3992,9 @@\n+    __ br(Assembler::EQ, cont); \/\/ CAS success means locking succeeded\n+\n+    __ cmp(rscratch1, rthread);\n+    __ br(Assembler::NE, cont); \/\/ Check for recursive locking\n+\n+    \/\/ Recursive lock case\n+    __ increment(Address(disp_hdr, ObjectMonitor::recursions_offset_in_bytes() - markWord::monitor_value), 1);\n+    \/\/ flag == EQ still from the cmp above, checking if this is a reentrant lock\n+\n@@ -3959,3 +4044,3 @@\n-    __ eor(rscratch1, rscratch1, rthread); \/\/ Will be 0 if we are the owner.\n-    __ orr(rscratch1, rscratch1, disp_hdr); \/\/ Will be 0 if there are 0 recursions\n-    __ cmp(rscratch1, zr); \/\/ Sets flags for result\n+\n+    Label notRecursive;\n+    __ cmp(rscratch1, rthread);\n@@ -3964,0 +4049,9 @@\n+    __ cbz(disp_hdr, notRecursive);\n+\n+    \/\/ Recursive lock\n+    __ sub(disp_hdr, disp_hdr, 1u);\n+    __ str(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));\n+    \/\/ flag == EQ was set in the ownership check above\n+    __ b(cont);\n+\n+    __ bind(notRecursive);\n@@ -4616,0 +4710,11 @@\n+\/\/ 8 bit integer valid for vector add sub immediate\n+operand immBAddSubV()\n+%{\n+  predicate(n->get_int() <= 255 && n->get_int() >= -255);\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -4626,0 +4731,11 @@\n+\/\/ 32 bit integer valid for vector add sub immediate\n+operand immIAddSubV()\n+%{\n+  predicate(Assembler::operand_valid_for_sve_add_sub_immediate((int64_t)n->get_int()));\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -4627,1 +4743,21 @@\n-\/\/ TODO -- check this is right when e.g the mask is 0x80000000\n+\n+operand immBLog()\n+%{\n+  predicate(Assembler::operand_valid_for_sve_logical_immediate(BitsPerByte, (uint64_t)n->get_int()));\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n+operand immSLog()\n+%{\n+  predicate(Assembler::operand_valid_for_sve_logical_immediate(BitsPerShort, (uint64_t)n->get_int()));\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -4705,0 +4841,11 @@\n+\/\/ 64 bit integer valid for addv subv immediate\n+operand immLAddSubV()\n+%{\n+  predicate(Assembler::operand_valid_for_sve_add_sub_immediate(n->get_long()));\n+  match(ConL);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -5558,0 +5705,1 @@\n+  match(pRegGov);\n@@ -5572,0 +5720,18 @@\n+operand pRegGov_P0()\n+%{\n+  constraint(ALLOC_IN_RC(p0_reg));\n+  match(RegVectMask);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n+operand pRegGov_P1()\n+%{\n+  constraint(ALLOC_IN_RC(p1_reg));\n+  match(RegVectMask);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n@@ -8602,0 +8768,1 @@\n+  match(StoreStoreFence);\n@@ -8921,0 +9088,11 @@\n+instruct castVVMask(pRegGov dst)\n+%{\n+  match(Set dst (CastVV dst));\n+\n+  size(0);\n+  format %{ \"# castVV of $dst\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_cost(0);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n@@ -10943,1 +11121,0 @@\n-  match(Set dst (MulI src1 (SubI zero src2)));\n@@ -10995,1 +11172,0 @@\n-  match(Set dst (MulL src1 (SubL zero src2)));\n@@ -11045,1 +11221,0 @@\n-  match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));\n@@ -14405,0 +14580,12 @@\n+instruct onspinwait() %{\n+  match(OnSpinWait);\n+  ins_cost(INSN_COST);\n+\n+  format %{ \"onspinwait\" %}\n+\n+  ins_encode %{\n+    __ spin_wait();\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n@@ -16581,1 +16768,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  predicate((UseSVE == 0) && (((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU));\n@@ -16591,1 +16778,1 @@\n-                      fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);\n+                      fnoreg, fnoreg, fnoreg, pnoreg, pnoreg, StrIntrinsicNode::UU);\n@@ -16599,1 +16786,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  predicate((UseSVE == 0) && (((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL));\n@@ -16608,1 +16795,1 @@\n-                      fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);\n+                      fnoreg, fnoreg, fnoreg, pnoreg, pnoreg, StrIntrinsicNode::LL);\n@@ -16617,1 +16804,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n+  predicate((UseSVE == 0) && (((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL));\n@@ -16628,1 +16815,1 @@\n-                      $vtmp3$$FloatRegister, StrIntrinsicNode::UL);\n+                      $vtmp3$$FloatRegister, pnoreg, pnoreg, StrIntrinsicNode::UL);\n@@ -16637,1 +16824,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n+  predicate((UseSVE == 0) && (((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU));\n@@ -16648,1 +16835,1 @@\n-                      $vtmp3$$FloatRegister,StrIntrinsicNode::LU);\n+                      $vtmp3$$FloatRegister, pnoreg, pnoreg, StrIntrinsicNode::LU);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":230,"deletions":43,"binary":false,"changes":273,"status":"modified"},{"patch":"@@ -73,1 +73,1 @@\n-  : _index(index), _array(NULL), _throw_index_out_of_bounds_exception(true) {\n+  : _index(index), _array(), _throw_index_out_of_bounds_exception(true) {\n@@ -98,1 +98,1 @@\n-    assert(_array != NULL, \"sanity\");\n+    assert(_array != LIR_Opr::nullOpr(), \"sanity\");\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_CodeStubs_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1735,1 +1735,1 @@\n-    assert(addr_ptr->index() == LIR_OprDesc::illegalOpr(), \"need 0 index\");\n+    assert(addr_ptr->index() == LIR_Opr::illegalOpr(), \"need 0 index\");\n@@ -3215,1 +3215,1 @@\n-  Unimplemented();\n+  __ spin_wait();\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -255,1 +255,0 @@\n-    r = NULL;  \/\/ unreachable\n@@ -271,1 +270,1 @@\n-  LIR_Opr imm = NULL;\n+  LIR_Opr imm;\n@@ -790,1 +789,2 @@\n-    case vmIntrinsics::_dsqrt: {\n+    case vmIntrinsics::_dsqrt:\n+    case vmIntrinsics::_dsqrt_strict: {\n@@ -797,1 +797,2 @@\n-        case vmIntrinsics::_dsqrt: {\n+        case vmIntrinsics::_dsqrt:\n+        case vmIntrinsics::_dsqrt_strict: {\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-FloatRegister LIR_OprDesc::as_float_reg() const {\n+FloatRegister LIR_Opr::as_float_reg() const {\n@@ -33,1 +33,1 @@\n-FloatRegister LIR_OprDesc::as_double_reg() const {\n+FloatRegister LIR_Opr::as_double_reg() const {\n@@ -40,5 +40,5 @@\n-  return (LIR_Opr)(intptr_t)((reg1 << LIR_OprDesc::reg1_shift) |\n-                             (reg1 << LIR_OprDesc::reg2_shift) |\n-                             LIR_OprDesc::double_type          |\n-                             LIR_OprDesc::fpu_register         |\n-                             LIR_OprDesc::double_size);\n+  return (LIR_Opr)(intptr_t)((reg1 << LIR_Opr::reg1_shift) |\n+                             (reg1 << LIR_Opr::reg2_shift) |\n+                             LIR_Opr::double_type          |\n+                             LIR_Opr::fpu_register         |\n+                             LIR_Opr::double_size);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIR_aarch64.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1212,1 +1212,1 @@\n-        __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), c_rarg0);\n+        __ call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc)), c_rarg0);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -319,0 +319,1 @@\n+  PRegSet               _p_regs;\n@@ -332,0 +333,2 @@\n+        } else if (vm_reg->is_PRegister()) {\n+          _p_regs += PRegSet::of(vm_reg->as_PRegister());\n@@ -345,1 +348,2 @@\n-      _fp_regs() {\n+      _fp_regs(),\n+      _p_regs() {\n@@ -353,0 +357,1 @@\n+    __ push_p(_p_regs, sp);\n@@ -357,0 +362,1 @@\n+    __ pop_p(_p_regs, sp);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zBarrierSetAssembler_aarch64.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -35,2 +35,1 @@\n-class LIR_OprDesc;\n-typedef LIR_OprDesc* LIR_Opr;\n+class LIR_Opr;\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zBarrierSetAssembler_aarch64.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -116,1 +116,9 @@\n-          range(-1, 4096)\n+          range(-1, 4096)                                               \\\n+  product(ccstr, OnSpinWaitInst, \"none\", DIAGNOSTIC,                    \\\n+          \"The instruction to use to implement \"                        \\\n+          \"java.lang.Thread.onSpinWait().\"                              \\\n+          \"Options: none, nop, isb, yield.\")                            \\\n+  product(uint, OnSpinWaitInstCount, 1, DIAGNOSTIC,                     \\\n+          \"The number of OnSpinWaitInst instructions to generate.\"      \\\n+          \"It cannot be used with OnSpinWaitInst=none.\")                \\\n+          range(1, 99)\n","filename":"src\/hotspot\/cpu\/aarch64\/globals_aarch64.hpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -276,1 +276,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), new_obj);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc)), new_obj);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2020,9 +2020,0 @@\n-\n-void MacroAssembler::pusha() {\n-  push(0x7fffffff, sp);\n-}\n-\n-void MacroAssembler::popa() {\n-  pop(0x7fffffff, sp);\n-}\n-\n@@ -2152,1 +2143,1 @@\n-\/\/ Return the number of dwords poped\n+\/\/ Return the number of dwords popped\n@@ -2211,0 +2202,74 @@\n+\/\/ Return the number of dwords pushed\n+int MacroAssembler::push_p(unsigned int bitset, Register stack) {\n+  bool use_sve = false;\n+  int sve_predicate_size_in_slots = 0;\n+\n+#ifdef COMPILER2\n+  use_sve = Matcher::supports_scalable_vector();\n+  if (use_sve) {\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n+#endif\n+\n+  if (!use_sve) {\n+    return 0;\n+  }\n+\n+  unsigned char regs[PRegisterImpl::number_of_saved_registers];\n+  int count = 0;\n+  for (int reg = 0; reg < PRegisterImpl::number_of_saved_registers; reg++) {\n+    if (1 & bitset)\n+      regs[count++] = reg;\n+    bitset >>= 1;\n+  }\n+\n+  if (count == 0) {\n+    return 0;\n+  }\n+\n+  int total_push_bytes = align_up(sve_predicate_size_in_slots *\n+                                  VMRegImpl::stack_slot_size * count, 16);\n+  sub(stack, stack, total_push_bytes);\n+  for (int i = 0; i < count; i++) {\n+    sve_str(as_PRegister(regs[i]), Address(stack, i));\n+  }\n+  return total_push_bytes \/ 8;\n+}\n+\n+\/\/ Return the number of dwords popped\n+int MacroAssembler::pop_p(unsigned int bitset, Register stack) {\n+  bool use_sve = false;\n+  int sve_predicate_size_in_slots = 0;\n+\n+#ifdef COMPILER2\n+  use_sve = Matcher::supports_scalable_vector();\n+  if (use_sve) {\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n+#endif\n+\n+  if (!use_sve) {\n+    return 0;\n+  }\n+\n+  unsigned char regs[PRegisterImpl::number_of_saved_registers];\n+  int count = 0;\n+  for (int reg = 0; reg < PRegisterImpl::number_of_saved_registers; reg++) {\n+    if (1 & bitset)\n+      regs[count++] = reg;\n+    bitset >>= 1;\n+  }\n+\n+  if (count == 0) {\n+    return 0;\n+  }\n+\n+  int total_pop_bytes = align_up(sve_predicate_size_in_slots *\n+                                 VMRegImpl::stack_slot_size * count, 16);\n+  for (int i = count - 1; i >= 0; i--) {\n+    sve_ldr(as_PRegister(regs[i]), Address(stack, i));\n+  }\n+  add(stack, stack, total_pop_bytes);\n+  return total_pop_bytes \/ 8;\n+}\n+\n@@ -2669,2 +2734,2 @@\n-                                    int sve_vector_size_in_bytes) {\n-  push(0x3fffffff, sp);         \/\/ integer registers except lr & sp\n+                                    int sve_vector_size_in_bytes, int total_predicate_in_bytes) {\n+  push(RegSet::range(r0, r29), sp); \/\/ integer registers except lr & sp\n@@ -2686,0 +2751,6 @@\n+  if (save_vectors && use_sve && total_predicate_in_bytes > 0) {\n+    sub(sp, sp, total_predicate_in_bytes);\n+    for (int i = 0; i < PRegisterImpl::number_of_saved_registers; i++) {\n+      sve_str(as_PRegister(i), Address(sp, i));\n+    }\n+  }\n@@ -2689,1 +2760,7 @@\n-                                   int sve_vector_size_in_bytes) {\n+                                   int sve_vector_size_in_bytes, int total_predicate_in_bytes) {\n+  if (restore_vectors && use_sve && total_predicate_in_bytes > 0) {\n+    for (int i = PRegisterImpl::number_of_saved_registers - 1; i >= 0; i--) {\n+      sve_ldr(as_PRegister(i), Address(sp, i));\n+    }\n+    add(sp, sp, total_predicate_in_bytes);\n+  }\n@@ -2708,1 +2785,8 @@\n-  pop(0x3fffffff, sp);         \/\/ integer registers except lr & sp\n+  \/\/ integer registers except lr & sp\n+  pop(RegSet::range(r0, r17), sp);\n+#ifdef R18_RESERVED\n+  ldp(zr, r19, Address(post(sp, 2 * wordSize)));\n+  pop(RegSet::range(r20, r29), sp);\n+#else\n+  pop(RegSet::range(r18_tls, r29), sp);\n+#endif\n@@ -5899,0 +5983,18 @@\n+\n+void MacroAssembler::spin_wait() {\n+  for (int i = 0; i < VM_Version::spin_wait_desc().inst_count(); ++i) {\n+    switch (VM_Version::spin_wait_desc().inst()) {\n+      case SpinWait::NOP:\n+        nop();\n+        break;\n+      case SpinWait::ISB:\n+        isb();\n+        break;\n+      case SpinWait::YIELD:\n+        yield();\n+        break;\n+      default:\n+        ShouldNotReachHere();\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":116,"deletions":14,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -463,0 +463,3 @@\n+  int push_p(unsigned int bitset, Register stack);\n+  int pop_p(unsigned int bitset, Register stack);\n+\n@@ -474,0 +477,3 @@\n+  void push_p(PRegSet regs, Register stack) { if (regs.bits()) push_p(regs.bits(), stack); }\n+  void pop_p(PRegSet regs, Register stack) { if (regs.bits()) pop_p(regs.bits(), stack); }\n+\n@@ -917,1 +923,1 @@\n-                      int sve_vector_size_in_bytes = 0);\n+                      int sve_vector_size_in_bytes = 0, int total_predicate_in_bytes = 0);\n@@ -919,1 +925,1 @@\n-                      int sve_vector_size_in_bytes = 0);\n+                     int sve_vector_size_in_bytes = 0, int total_predicate_in_bytes = 0);\n@@ -1170,4 +1176,0 @@\n-  \/\/ push all registers onto the stack\n-  void pusha();\n-  void popa();\n-\n@@ -1449,0 +1451,1 @@\n+\n@@ -1452,0 +1455,4 @@\n+  void spill_sve_predicate(PRegister pr, int offset, int predicate_reg_size_in_bytes) {\n+    sve_str(pr, sve_spill_address(predicate_reg_size_in_bytes, offset));\n+  }\n+\n@@ -1462,0 +1469,1 @@\n+\n@@ -1465,0 +1473,4 @@\n+  void unspill_sve_predicate(PRegister pr, int offset, int predicate_reg_size_in_bytes) {\n+    sve_ldr(pr, sve_spill_address(predicate_reg_size_in_bytes, offset));\n+  }\n+\n@@ -1487,0 +1499,6 @@\n+  void spill_copy_sve_predicate_stack_to_stack(int src_offset, int dst_offset,\n+                                               int sve_predicate_reg_size_in_bytes) {\n+    sve_ldr(ptrue, sve_spill_address(sve_predicate_reg_size_in_bytes, src_offset));\n+    sve_str(ptrue, sve_spill_address(sve_predicate_reg_size_in_bytes, dst_offset));\n+    reinitialize_ptrue();\n+  }\n@@ -1490,0 +1508,3 @@\n+  \/\/ Code for java.lang.Thread::onSpinWait() intrinsic.\n+  void spin_wait();\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":27,"deletions":6,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -105,1 +105,4 @@\n-  int v0_offset_in_bytes(void)   { return 0; }\n+  int v0_offset_in_bytes();\n+\n+  \/\/ Total stack size in bytes for saving sve predicate registers.\n+  int total_sve_predicate_in_bytes();\n@@ -143,1 +146,1 @@\n-  int r0_offset = (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n+  int r0_offset = v0_offset_in_bytes() + (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n@@ -147,0 +150,20 @@\n+int RegisterSaver::v0_offset_in_bytes() {\n+  \/\/ The floating point registers are located above the predicate registers if\n+  \/\/ they are present in the stack frame pushed by save_live_registers(). So the\n+  \/\/ offset depends on the saved total predicate vectors in the stack frame.\n+  return (total_sve_predicate_in_bytes() \/ VMRegImpl::stack_slot_size) * BytesPerInt;\n+}\n+\n+int RegisterSaver::total_sve_predicate_in_bytes() {\n+#ifdef COMPILER2\n+  if (_save_vectors && Matcher::supports_scalable_vector()) {\n+    \/\/ The number of total predicate bytes is unlikely to be a multiple\n+    \/\/ of 16 bytes so we manually align it up.\n+    return align_up(Matcher::scalable_predicate_reg_slots() *\n+                    VMRegImpl::stack_slot_size *\n+                    PRegisterImpl::number_of_saved_registers, 16);\n+  }\n+#endif\n+  return 0;\n+}\n+\n@@ -151,0 +174,3 @@\n+  int sve_predicate_size_in_slots = 0;\n+  int total_predicate_in_bytes = total_sve_predicate_in_bytes();\n+  int total_predicate_in_slots = total_predicate_in_bytes \/ VMRegImpl::stack_slot_size;\n@@ -154,2 +180,5 @@\n-  sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n-  sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n+  if (use_sve) {\n+    sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n+    sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n@@ -160,1 +189,0 @@\n-    int vect_words = 0;\n@@ -168,3 +196,4 @@\n-    vect_words = FloatRegisterImpl::number_of_registers * extra_save_slots_per_register \/\n-                 VMRegImpl::slots_per_word;\n-    additional_frame_words += vect_words;\n+    int extra_vector_bytes = extra_save_slots_per_register *\n+                             VMRegImpl::stack_slot_size *\n+                             FloatRegisterImpl::number_of_registers;\n+    additional_frame_words += ((extra_vector_bytes + total_predicate_in_bytes) \/ wordSize);\n@@ -188,1 +217,1 @@\n-  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes);\n+  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes, total_predicate_in_bytes);\n@@ -205,2 +234,1 @@\n-      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots),\n-                                r->as_VMReg());\n+      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots), r->as_VMReg());\n@@ -214,1 +242,1 @@\n-      sp_offset = use_sve ? (sve_vector_size_in_slots * i) :\n+      sp_offset = use_sve ? (total_predicate_in_slots + sve_vector_size_in_slots * i) :\n@@ -219,2 +247,9 @@\n-    oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset),\n-                              r->as_VMReg());\n+    oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset), r->as_VMReg());\n+  }\n+\n+  if (_save_vectors && use_sve) {\n+    for (int i = 0; i < PRegisterImpl::number_of_saved_registers; i++) {\n+      PRegister r = as_PRegister(i);\n+      int sp_offset = sve_predicate_size_in_slots * i;\n+      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset), r->as_VMReg());\n+    }\n@@ -229,1 +264,1 @@\n-                   Matcher::scalable_vector_reg_size(T_BYTE));\n+                   Matcher::scalable_vector_reg_size(T_BYTE), total_sve_predicate_in_bytes());\n@@ -242,0 +277,2 @@\n+\/\/ The SVE supported min vector size is 8 bytes and we need to save\n+\/\/ predicate registers when the vector size is 8 bytes as well.\n@@ -243,1 +280,1 @@\n-  return size > 8;\n+  return size > 8 || (UseSVE > 0 && size >= 8);\n@@ -1385,63 +1422,0 @@\n-\/\/ Unpack an array argument into a pointer to the body and the length\n-\/\/ if the array is non-null, otherwise pass 0 for both.\n-static void unpack_array_argument(MacroAssembler* masm, VMRegPair reg, BasicType in_elem_type, VMRegPair body_arg, VMRegPair length_arg) { Unimplemented(); }\n-\n-\n-class ComputeMoveOrder: public StackObj {\n-  class MoveOperation: public ResourceObj {\n-    friend class ComputeMoveOrder;\n-   private:\n-    VMRegPair        _src;\n-    VMRegPair        _dst;\n-    int              _src_index;\n-    int              _dst_index;\n-    bool             _processed;\n-    MoveOperation*  _next;\n-    MoveOperation*  _prev;\n-\n-    static int get_id(VMRegPair r) { Unimplemented(); return 0; }\n-\n-   public:\n-    MoveOperation(int src_index, VMRegPair src, int dst_index, VMRegPair dst):\n-      _src(src)\n-    , _dst(dst)\n-    , _src_index(src_index)\n-    , _dst_index(dst_index)\n-    , _processed(false)\n-    , _next(NULL)\n-    , _prev(NULL) { Unimplemented(); }\n-\n-    VMRegPair src() const              { Unimplemented(); return _src; }\n-    int src_id() const                 { Unimplemented(); return 0; }\n-    int src_index() const              { Unimplemented(); return 0; }\n-    VMRegPair dst() const              { Unimplemented(); return _src; }\n-    void set_dst(int i, VMRegPair dst) { Unimplemented(); }\n-    int dst_index() const              { Unimplemented(); return 0; }\n-    int dst_id() const                 { Unimplemented(); return 0; }\n-    MoveOperation* next() const        { Unimplemented(); return 0; }\n-    MoveOperation* prev() const        { Unimplemented(); return 0; }\n-    void set_processed()               { Unimplemented(); }\n-    bool is_processed() const          { Unimplemented(); return 0; }\n-\n-    \/\/ insert\n-    void break_cycle(VMRegPair temp_register) { Unimplemented(); }\n-\n-    void link(GrowableArray<MoveOperation*>& killer) { Unimplemented(); }\n-  };\n-\n- private:\n-  GrowableArray<MoveOperation*> edges;\n-\n- public:\n-  ComputeMoveOrder(int total_in_args, VMRegPair* in_regs, int total_c_args, VMRegPair* out_regs,\n-                    BasicType* in_sig_bt, GrowableArray<int>& arg_order, VMRegPair tmp_vmreg) { Unimplemented(); }\n-\n-  \/\/ Collected all the move operations\n-  void add_edge(int src_index, VMRegPair src, int dst_index, VMRegPair dst) { Unimplemented(); }\n-\n-  \/\/ Walk the edges breaking cycles between moves.  The result list\n-  \/\/ can be walked in order to produce the proper set of loads\n-  GrowableArray<MoveOperation*>* get_store_order(VMRegPair temp_register) { Unimplemented(); return 0; }\n-};\n-\n-\n@@ -1560,2 +1534,1 @@\n-                                                BasicType ret_type,\n-                                                address critical_entry) {\n+                                                BasicType ret_type) {\n@@ -1586,6 +1559,1 @@\n-  bool is_critical_native = true;\n-  address native_func = critical_entry;\n-  if (native_func == NULL) {\n-    native_func = method->native_function();\n-    is_critical_native = false;\n-  }\n+  address native_func = method->native_function();\n@@ -1605,13 +1573,1 @@\n-  int total_c_args = total_in_args;\n-  if (!is_critical_native) {\n-    total_c_args += 1;\n-    if (method->is_static()) {\n-      total_c_args++;\n-    }\n-  } else {\n-    for (int i = 0; i < total_in_args; i++) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        total_c_args++;\n-      }\n-    }\n-  }\n+  int total_c_args = total_in_args + (method->is_static() ? 2 : 1);\n@@ -1624,5 +1580,4 @@\n-  if (!is_critical_native) {\n-    out_sig_bt[argc++] = T_ADDRESS;\n-    if (method->is_static()) {\n-      out_sig_bt[argc++] = T_OBJECT;\n-    }\n+  out_sig_bt[argc++] = T_ADDRESS;\n+  if (method->is_static()) {\n+    out_sig_bt[argc++] = T_OBJECT;\n+  }\n@@ -1630,24 +1585,2 @@\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      out_sig_bt[argc++] = in_sig_bt[i];\n-    }\n-  } else {\n-    in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);\n-    SignatureStream ss(method->signature());\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        \/\/ Arrays are passed as int, elem* pair\n-        out_sig_bt[argc++] = T_INT;\n-        out_sig_bt[argc++] = T_ADDRESS;\n-        ss.skip_array_prefix(1);  \/\/ skip one '['\n-        assert(ss.is_primitive(), \"primitive type expected\");\n-        in_elem_bt[i] = ss.type();\n-      } else {\n-        out_sig_bt[argc++] = in_sig_bt[i];\n-        in_elem_bt[i] = T_VOID;\n-      }\n-      if (in_sig_bt[i] != T_VOID) {\n-        assert(in_sig_bt[i] == ss.type() ||\n-               in_sig_bt[i] == T_ARRAY, \"must match\");\n-        ss.next();\n-      }\n-    }\n+  for (int i = 0; i < total_in_args ; i++ ) {\n+    out_sig_bt[argc++] = in_sig_bt[i];\n@@ -1675,28 +1608,0 @@\n-  if (is_critical_native) {\n-    \/\/ Critical natives may have to call out so they need a save area\n-    \/\/ for register arguments.\n-    int double_slots = 0;\n-    int single_slots = 0;\n-    for ( int i = 0; i < total_in_args; i++) {\n-      if (in_regs[i].first()->is_Register()) {\n-        const Register reg = in_regs[i].first()->as_Register();\n-        switch (in_sig_bt[i]) {\n-          case T_BOOLEAN:\n-          case T_BYTE:\n-          case T_SHORT:\n-          case T_CHAR:\n-          case T_INT:  single_slots++; break;\n-          case T_ARRAY:  \/\/ specific to LP64 (7145024)\n-          case T_LONG: double_slots++; break;\n-          default:  ShouldNotReachHere();\n-        }\n-      } else if (in_regs[i].first()->is_FloatRegister()) {\n-        ShouldNotReachHere();\n-      }\n-    }\n-    total_save_slots = double_slots * 2 + single_slots;\n-    \/\/ align the save area\n-    if (double_slots != 0) {\n-      stack_slots = align_up(stack_slots, 2);\n-    }\n-  }\n@@ -1869,4 +1774,1 @@\n-  \/\/ This may iterate in two different directions depending on the\n-  \/\/ kind of native it is.  The reason is that for regular JNI natives\n-  \/\/ the incoming and outgoing registers are offset upwards and for\n-  \/\/ critical natives they are offset down.\n+  \/\/ For JNI natives the incoming and outgoing registers are offset upwards.\n@@ -1877,8 +1779,3 @@\n-  if (!is_critical_native) {\n-    for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n-      arg_order.push(i);\n-      arg_order.push(c_arg);\n-    }\n-  } else {\n-    \/\/ Compute a valid move order, using tmp_vmreg to break any cycles\n-    ComputeMoveOrder cmo(total_in_args, in_regs, total_c_args, out_regs, in_sig_bt, arg_order, tmp_vmreg);\n+  for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n+    arg_order.push(i);\n+    arg_order.push(c_arg);\n@@ -1892,14 +1789,1 @@\n-    if (c_arg == -1) {\n-      assert(is_critical_native, \"should only be required for critical natives\");\n-      \/\/ This arg needs to be moved to a temporary\n-      __ mov(tmp_vmreg.first()->as_Register(), in_regs[i].first()->as_Register());\n-      in_regs[i] = tmp_vmreg;\n-      temploc = i;\n-      continue;\n-    } else if (i == -1) {\n-      assert(is_critical_native, \"should only be required for critical natives\");\n-      \/\/ Read from the temporary location\n-      assert(temploc != -1, \"must be valid\");\n-      i = temploc;\n-      temploc = -1;\n-    }\n+    assert(c_arg != -1 && i != -1, \"wrong order\");\n@@ -1920,13 +1804,0 @@\n-        if (is_critical_native) {\n-          unpack_array_argument(masm, in_regs[i], in_elem_bt[i], out_regs[c_arg + 1], out_regs[c_arg]);\n-          c_arg++;\n-#ifdef ASSERT\n-          if (out_regs[c_arg].first()->is_Register()) {\n-            reg_destroyed[out_regs[c_arg].first()->as_Register()->encoding()] = true;\n-          } else if (out_regs[c_arg].first()->is_FloatRegister()) {\n-            freg_destroyed[out_regs[c_arg].first()->as_FloatRegister()->encoding()] = true;\n-          }\n-#endif\n-          int_args++;\n-          break;\n-        }\n@@ -1935,1 +1806,0 @@\n-        assert(!is_critical_native, \"no oop arguments\");\n@@ -1975,1 +1845,1 @@\n-  if (method->is_static() && !is_critical_native) {\n+  if (method->is_static()) {\n@@ -2033,1 +1903,0 @@\n-    assert(!is_critical_native, \"unhandled\");\n@@ -2091,2 +1960,1 @@\n-  if (!is_critical_native) {\n-    __ lea(c_rarg0, Address(rthread, in_bytes(JavaThread::jni_environment_offset())));\n+  __ lea(c_rarg0, Address(rthread, in_bytes(JavaThread::jni_environment_offset())));\n@@ -2094,5 +1962,4 @@\n-    \/\/ Now set thread in native\n-    __ mov(rscratch1, _thread_in_native);\n-    __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n-    __ stlrw(rscratch1, rscratch2);\n-  }\n+  \/\/ Now set thread in native\n+  __ mov(rscratch1, _thread_in_native);\n+  __ lea(rscratch2, Address(rthread, JavaThread::thread_state_offset()));\n+  __ stlrw(rscratch1, rscratch2);\n@@ -2130,12 +1997,0 @@\n-  \/\/ If this is a critical native, check for a safepoint or suspend request after the call.\n-  \/\/ If a safepoint is needed, transition to native, then to native_trans to handle\n-  \/\/ safepoints like the native methods that are not critical natives.\n-  if (is_critical_native) {\n-    Label needs_safepoint;\n-    __ safepoint_poll(needs_safepoint, false \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n-    __ ldrw(rscratch1, Address(rthread, JavaThread::suspend_flags_offset()));\n-    __ cbnzw(rscratch1, needs_safepoint);\n-    __ b(after_transition);\n-    __ bind(needs_safepoint);\n-  }\n-\n@@ -2250,5 +2105,3 @@\n-  if (!is_critical_native) {\n-    \/\/ reset handle block\n-    __ ldr(r2, Address(rthread, JavaThread::active_handles_offset()));\n-    __ str(zr, Address(r2, JNIHandleBlock::top_offset_in_bytes()));\n-  }\n+  \/\/ reset handle block\n+  __ ldr(r2, Address(rthread, JavaThread::active_handles_offset()));\n+  __ str(zr, Address(r2, JNIHandleBlock::top_offset_in_bytes()));\n@@ -2258,5 +2111,3 @@\n-  if (!is_critical_native) {\n-    \/\/ Any exception pending?\n-    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n-    __ cbnz(rscratch1, exception_pending);\n-  }\n+  \/\/ Any exception pending?\n+  __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+  __ cbnz(rscratch1, exception_pending);\n@@ -2269,3 +2120,2 @@\n-  if (!is_critical_native) {\n-    \/\/ forward the exception\n-    __ bind(exception_pending);\n+  \/\/ forward the exception\n+  __ bind(exception_pending);\n@@ -2273,3 +2123,2 @@\n-    \/\/ and forward the exception\n-    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-  }\n+  \/\/ and forward the exception\n+  __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":83,"deletions":234,"binary":false,"changes":317,"status":"modified"},{"patch":"@@ -4868,12 +4868,0 @@\n-  \/\/ code for comparing 16 bytes of strings with same encoding\n-  void compare_string_16_bytes_same(Label &DIFF1, Label &DIFF2) {\n-    Register result = r0, str1 = r1, cnt1 = r2, str2 = r3, tmp1 = r10, tmp2 = r11;\n-    __ ldr(rscratch1, Address(__ post(str1, 8)));\n-    __ eor(rscratch2, tmp1, tmp2);\n-    __ ldr(cnt1, Address(__ post(str2, 8)));\n-    __ cbnz(rscratch2, DIFF1);\n-    __ ldr(tmp1, Address(__ post(str1, 8)));\n-    __ eor(rscratch2, rscratch1, cnt1);\n-    __ ldr(tmp2, Address(__ post(str2, 8)));\n-    __ cbnz(rscratch2, DIFF2);\n-  }\n@@ -5072,0 +5060,91 @@\n+  enum string_compare_mode {\n+    LL,\n+    LU,\n+    UL,\n+    UU,\n+  };\n+\n+  \/\/ The following registers are declared in aarch64.ad\n+  \/\/ r0  = result\n+  \/\/ r1  = str1\n+  \/\/ r2  = cnt1\n+  \/\/ r3  = str2\n+  \/\/ r4  = cnt2\n+  \/\/ r10 = tmp1\n+  \/\/ r11 = tmp2\n+  \/\/ z0  = ztmp1\n+  \/\/ z1  = ztmp2\n+  \/\/ p0  = pgtmp1\n+  \/\/ p1  = pgtmp2\n+  address generate_compare_long_string_sve(string_compare_mode mode) {\n+    __ align(CodeEntryAlignment);\n+    address entry = __ pc();\n+    Register result = r0, str1 = r1, cnt1 = r2, str2 = r3, cnt2 = r4,\n+             tmp1 = r10, tmp2 = r11;\n+\n+    Label LOOP, MATCH, DONE, NOMATCH;\n+    Register vec_len = tmp1;\n+    Register idx = tmp2;\n+    \/\/ The minimum of the string lengths has been stored in cnt2.\n+    Register cnt = cnt2;\n+    FloatRegister ztmp1 = z0, ztmp2 = z1;\n+    PRegister pgtmp1 = p0, pgtmp2 = p1;\n+\n+    if (mode == LL) {\n+      __ sve_cntb(vec_len);\n+    } else {\n+      __ sve_cnth(vec_len);\n+    }\n+\n+    __ mov(idx, 0);\n+    __ sve_whilelt(pgtmp1, mode == LL ? __ B : __ H, idx, cnt);\n+\n+    __ bind(LOOP);\n+      switch (mode) {\n+        case LL:\n+          __ sve_ld1b(ztmp1, __ B, pgtmp1, Address(str1, idx));\n+          __ sve_ld1b(ztmp2, __ B, pgtmp1, Address(str2, idx));\n+          break;\n+        case LU:\n+          __ sve_ld1b(ztmp1, __ H, pgtmp1, Address(str1, idx));\n+          __ sve_ld1h(ztmp2, __ H, pgtmp1, Address(str2, idx, Address::lsl(1)));\n+          break;\n+        case UL:\n+          __ sve_ld1h(ztmp1, __ H, pgtmp1, Address(str1, idx, Address::lsl(1)));\n+          __ sve_ld1b(ztmp2, __ H, pgtmp1, Address(str2, idx));\n+          break;\n+        case UU:\n+          __ sve_ld1h(ztmp1, __ H, pgtmp1, Address(str1, idx, Address::lsl(1)));\n+          __ sve_ld1h(ztmp2, __ H, pgtmp1, Address(str2, idx, Address::lsl(1)));\n+          break;\n+        default: ShouldNotReachHere();\n+      }\n+      __ add(idx, idx, vec_len);\n+\n+      \/\/ Compare strings.\n+      __ sve_cmp(Assembler::NE, pgtmp2, mode == LL ? __ B : __ H, pgtmp1, ztmp1, ztmp2);\n+      __ br(__ NE, MATCH);\n+      __ sve_whilelt(pgtmp1, mode == LL ? __ B : __ H, idx, cnt);\n+      __ br(__ LT, LOOP);\n+\n+      \/\/ The result has been computed in the caller prior to entering this stub.\n+      __ b(DONE);\n+\n+    __ bind(MATCH);\n+\n+      \/\/ Crop the vector to find its location.\n+      __ sve_brkb(pgtmp2, pgtmp1, pgtmp2, false \/* isMerge *\/);\n+\n+      \/\/ Extract the first different characters of each string.\n+      __ sve_lasta(rscratch1, mode == LL ? __ B : __ H, pgtmp2, ztmp1);\n+      __ sve_lasta(rscratch2, mode == LL ? __ B : __ H, pgtmp2, ztmp2);\n+\n+      \/\/ Compute the difference of the first different characters.\n+      __ sub(result, rscratch1, rscratch2);\n+\n+    __ bind(DONE);\n+      __ ret(lr);\n+\n+    return entry;\n+  }\n+\n@@ -5086,4 +5165,4 @@\n-        tmp1 = r10, tmp2 = r11;\n-    Label SMALL_LOOP, LARGE_LOOP_PREFETCH, CHECK_LAST, DIFF2, TAIL,\n-        LENGTH_DIFF, DIFF, LAST_CHECK_AND_LENGTH_DIFF,\n-        DIFF_LAST_POSITION, DIFF_LAST_POSITION2;\n+        tmp1 = r10, tmp2 = r11, tmp1h = rscratch1, tmp2h = rscratch2;\n+\n+    Label LARGE_LOOP_PREFETCH, LOOP_COMPARE16, DIFF, LESS16, LESS8, CAL_DIFFERENCE, LENGTH_DIFF;\n+\n@@ -5093,2 +5172,5 @@\n-    \/\/ cnt1\/cnt2 contains amount of characters to compare. cnt1 can be re-used\n-    \/\/ update cnt2 counter with already loaded 8 bytes\n+\n+    \/\/ before jumping to stub, pre-load 8 bytes already, so do comparison directly\n+    __ eor(rscratch2, tmp1, tmp2);\n+    __ cbnz(rscratch2, CAL_DIFFERENCE);\n+\n@@ -5103,2 +5185,9 @@\n-        compare_string_16_bytes_same(DIFF, DIFF2);\n-        compare_string_16_bytes_same(DIFF, DIFF2);\n+\n+        __ align(OptoLoopAlignment);\n+        for (int i = 0; i < 4; i++) {\n+          __ ldp(tmp1, tmp1h, Address(str1, i * 16));\n+          __ ldp(tmp2, tmp2h, Address(str2, i * 16));\n+          __ cmp(tmp1, tmp2);\n+          __ ccmp(tmp1h, tmp2h, 0, Assembler::EQ);\n+          __ br(Assembler::NE, DIFF);\n+        }\n@@ -5106,1 +5195,2 @@\n-        compare_string_16_bytes_same(DIFF, DIFF2);\n+        __ add(str1, str1, 64);\n+        __ add(str2, str2, 64);\n@@ -5108,3 +5198,2 @@\n-        compare_string_16_bytes_same(DIFF, DIFF2);\n-        __ br(__ GT, LARGE_LOOP_PREFETCH);\n-        __ cbz(cnt2, LAST_CHECK_AND_LENGTH_DIFF); \/\/ no more chars left?\n+        __ br(Assembler::GE, LARGE_LOOP_PREFETCH);\n+        __ cbz(cnt2, LENGTH_DIFF); \/\/ no more chars left?\n@@ -5112,3 +5201,3 @@\n-    \/\/ less than 16 bytes left?\n-    __ subs(cnt2, cnt2, isLL ? 16 : 8);\n-    __ br(__ LT, TAIL);\n+\n+    __ subs(rscratch1, cnt2, isLL ? 16 : 8);\n+    __ br(Assembler::LE, LESS16);\n@@ -5116,7 +5205,22 @@\n-    __ bind(SMALL_LOOP);\n-      compare_string_16_bytes_same(DIFF, DIFF2);\n-      __ subs(cnt2, cnt2, isLL ? 16 : 8);\n-      __ br(__ GE, SMALL_LOOP);\n-    __ bind(TAIL);\n-      __ adds(cnt2, cnt2, isLL ? 16 : 8);\n-      __ br(__ EQ, LAST_CHECK_AND_LENGTH_DIFF);\n+    __ bind(LOOP_COMPARE16);\n+      __ ldp(tmp1, tmp1h, Address(__ post(str1, 16)));\n+      __ ldp(tmp2, tmp2h, Address(__ post(str2, 16)));\n+      __ cmp(tmp1, tmp2);\n+      __ ccmp(tmp1h, tmp2h, 0, Assembler::EQ);\n+      __ br(Assembler::NE, DIFF);\n+      __ sub(cnt2, cnt2, isLL ? 16 : 8);\n+      __ subs(rscratch2, cnt2, isLL ? 16 : 8);\n+      __ br(Assembler::LT, LESS16);\n+\n+      __ ldp(tmp1, tmp1h, Address(__ post(str1, 16)));\n+      __ ldp(tmp2, tmp2h, Address(__ post(str2, 16)));\n+      __ cmp(tmp1, tmp2);\n+      __ ccmp(tmp1h, tmp2h, 0, Assembler::EQ);\n+      __ br(Assembler::NE, DIFF);\n+      __ sub(cnt2, cnt2, isLL ? 16 : 8);\n+      __ subs(rscratch2, cnt2, isLL ? 16 : 8);\n+      __ br(Assembler::GE, LOOP_COMPARE16);\n+      __ cbz(cnt2, LENGTH_DIFF);\n+\n+    __ bind(LESS16);\n+      \/\/ each 8 compare\n@@ -5124,3 +5228,1 @@\n-      __ br(__ LE, CHECK_LAST);\n-      __ eor(rscratch2, tmp1, tmp2);\n-      __ cbnz(rscratch2, DIFF);\n+      __ br(Assembler::LE, LESS8);\n@@ -5129,0 +5231,2 @@\n+      __ eor(rscratch2, tmp1, tmp2);\n+      __ cbnz(rscratch2, CAL_DIFFERENCE);\n@@ -5130,1 +5234,2 @@\n-    __ bind(CHECK_LAST);\n+\n+    __ bind(LESS8); \/\/ directly load last 8 bytes\n@@ -5132,1 +5237,1 @@\n-        __ add(cnt2, cnt2, cnt2); \/\/ now in bytes\n+        __ add(cnt2, cnt2, cnt2);\n@@ -5134,0 +5239,2 @@\n+      __ ldr(tmp1, Address(str1, cnt2));\n+      __ ldr(tmp2, Address(str2, cnt2));\n@@ -5135,22 +5242,2 @@\n-      __ cbnz(rscratch2, DIFF);\n-      __ ldr(rscratch1, Address(str1, cnt2));\n-      __ ldr(cnt1, Address(str2, cnt2));\n-      __ eor(rscratch2, rscratch1, cnt1);\n-      \/\/ Find the first different characters in the longwords and\n-      \/\/ compute their difference.\n-    __ bind(DIFF2);\n-      __ rev(rscratch2, rscratch2);\n-      __ clz(rscratch2, rscratch2);\n-      __ andr(rscratch2, rscratch2, isLL ? -8 : -16);\n-      __ lsrv(rscratch1, rscratch1, rscratch2);\n-      if (isLL) {\n-        __ lsrv(cnt1, cnt1, rscratch2);\n-        __ uxtbw(rscratch1, rscratch1);\n-        __ uxtbw(cnt1, cnt1);\n-      } else {\n-        __ lsrv(cnt1, cnt1, rscratch2);\n-        __ uxthw(rscratch1, rscratch1);\n-        __ uxthw(cnt1, cnt1);\n-      }\n-      __ subw(result, rscratch1, cnt1);\n-      __ b(LENGTH_DIFF);\n+      __ b(CAL_DIFFERENCE);\n+\n@@ -5159,0 +5246,7 @@\n+      __ cmp(tmp1, tmp2);\n+      __ csel(tmp1, tmp1, tmp1h, Assembler::NE);\n+      __ csel(tmp2, tmp2, tmp2h, Assembler::NE);\n+      \/\/ reuse rscratch2 register for the result of eor instruction\n+      __ eor(rscratch2, tmp1, tmp2);\n+\n+    __ bind(CAL_DIFFERENCE);\n@@ -5163,0 +5257,1 @@\n+      __ lsrv(tmp2, tmp2, rscratch2);\n@@ -5164,1 +5259,0 @@\n-        __ lsrv(tmp2, tmp2, rscratch2);\n@@ -5168,1 +5262,0 @@\n-        __ lsrv(tmp2, tmp2, rscratch2);\n@@ -5173,4 +5266,1 @@\n-      __ b(LENGTH_DIFF);\n-    __ bind(LAST_CHECK_AND_LENGTH_DIFF);\n-      __ eor(rscratch2, tmp1, tmp2);\n-      __ cbnz(rscratch2, DIFF);\n+\n@@ -5183,0 +5273,1 @@\n+    if (UseSVE == 0) {\n@@ -5191,0 +5282,10 @@\n+    } else {\n+      StubRoutines::aarch64::_compare_long_string_LL\n+          = generate_compare_long_string_sve(LL);\n+      StubRoutines::aarch64::_compare_long_string_UU\n+          = generate_compare_long_string_sve(UU);\n+      StubRoutines::aarch64::_compare_long_string_LU\n+          = generate_compare_long_string_sve(LU);\n+      StubRoutines::aarch64::_compare_long_string_UL\n+          = generate_compare_long_string_sve(UL);\n+    }\n@@ -6239,1 +6340,1 @@\n-  void gen_ldaddal_entry(Assembler::operand_size size) {\n+  void gen_ldadd_entry(Assembler::operand_size size, atomic_memory_order order) {\n@@ -6241,2 +6342,8 @@\n-    __ ldaddal(size, incr, prev, addr);\n-    __ membar(Assembler::StoreStore|Assembler::StoreLoad);\n+    \/\/ If not relaxed, then default to conservative.  Relaxed is the only\n+    \/\/ case we use enough to be worth specializing.\n+    if (order == memory_order_relaxed) {\n+      __ ldadd(size, incr, prev, addr);\n+    } else {\n+      __ ldaddal(size, incr, prev, addr);\n+      __ membar(Assembler::StoreStore|Assembler::StoreLoad);\n+    }\n@@ -6272,1 +6379,1 @@\n-    \/\/ All memory_order_conservative\n+    \/\/ ADD, memory_order_conservative\n@@ -6274,1 +6381,1 @@\n-    gen_ldaddal_entry(Assembler::word);\n+    gen_ldadd_entry(Assembler::word, memory_order_conservative);\n@@ -6276,1 +6383,9 @@\n-    gen_ldaddal_entry(Assembler::xword);\n+    gen_ldadd_entry(Assembler::xword, memory_order_conservative);\n+\n+    \/\/ ADD, memory_order_relaxed\n+    AtomicStubMark mark_fetch_add_4_relaxed\n+      (_masm, &aarch64_atomic_fetch_add_4_relaxed_impl);\n+    gen_ldadd_entry(MacroAssembler::word, memory_order_relaxed);\n+    AtomicStubMark mark_fetch_add_8_relaxed\n+      (_masm, &aarch64_atomic_fetch_add_8_relaxed_impl);\n+    gen_ldadd_entry(MacroAssembler::xword, memory_order_relaxed);\n@@ -6278,0 +6393,1 @@\n+    \/\/ XCHG, memory_order_conservative\n@@ -7525,6 +7641,0 @@\n-    \/\/ generate GHASH intrinsics code\n-    if (UseGHASHIntrinsics) {\n-      \/\/ StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks();\n-      StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks_wide();\n-    }\n-\n@@ -7545,1 +7655,0 @@\n-      StubRoutines::_galoisCounterMode_AESCrypt = generate_galoisCounterMode_AESCrypt();\n@@ -7548,0 +7657,7 @@\n+    if (UseGHASHIntrinsics) {\n+      \/\/ StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks();\n+      StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks_wide();\n+    }\n+    if (UseAESIntrinsics && UseGHASHIntrinsics) {\n+      StubRoutines::_galoisCounterMode_AESCrypt = generate_galoisCounterMode_AESCrypt();\n+    }\n@@ -7612,0 +7728,2 @@\n+DEFAULT_ATOMIC_OP(fetch_add, 4, _relaxed)\n+DEFAULT_ATOMIC_OP(fetch_add, 8, _relaxed)\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":198,"deletions":80,"binary":false,"changes":278,"status":"modified"},{"patch":"@@ -1407,1 +1407,1 @@\n-    __ pusha(); \/\/ XXX only save smashed registers\n+    __ push_call_clobbered_registers();\n@@ -1411,1 +1411,2 @@\n-    __ popa(); \/\/ XXX only restore smashed registers\n+    __ pop_call_clobbered_registers();\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1384,1 +1384,1 @@\n-  assert(op->addr()->is_register() || op->addr()->as_address_ptr()->index() == LIR_OprDesc::illegalOpr(), \"unexpected index\");\n+  assert(op->addr()->is_register() || op->addr()->as_address_ptr()->index() == LIR_Opr::illegalOpr(), \"unexpected index\");\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -127,1 +127,1 @@\n-  : _index(index), _array(NULL), _throw_index_out_of_bounds_exception(true) {\n+  : _index(index), _array(), _throw_index_out_of_bounds_exception(true) {\n","filename":"src\/hotspot\/cpu\/x86\/c1_CodeStubs_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -229,1 +229,1 @@\n-  LIR_Opr r = NULL;\n+  LIR_Opr r;\n@@ -841,3 +841,9 @@\n-    case vmIntrinsics::_dabs:   __ abs  (calc_input, calc_result, tmp); break;\n-    case vmIntrinsics::_dsqrt:  __ sqrt (calc_input, calc_result, LIR_OprFact::illegalOpr); break;\n-    default:                    ShouldNotReachHere();\n+    case vmIntrinsics::_dabs:\n+      __ abs(calc_input, calc_result, tmp);\n+      break;\n+    case vmIntrinsics::_dsqrt:\n+    case vmIntrinsics::_dsqrt_strict:\n+      __ sqrt(calc_input, calc_result, LIR_OprFact::illegalOpr);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1614,1 +1614,1 @@\n-        __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc)));\n+        __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc))));\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -581,1 +581,6 @@\n-  \/\/ Intentional fall-through into DONE_LABEL ...\n+  jcc(Assembler::equal, DONE_LABEL);           \/\/ CAS above succeeded; propagate ZF = 1 (success)\n+\n+  cmpptr(r15_thread, rax);                     \/\/ Check if we are already the owner (recursive lock)\n+  jcc(Assembler::notEqual, DONE_LABEL);        \/\/ If not recursive, ZF = 0 at this point (fail)\n+  incq(Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  xorq(rax, rax); \/\/ Set ZF = 1 (success) for recursive lock, denoting locking success\n@@ -677,4 +682,0 @@\n-  \/\/ I'd like to add more cases in fast_lock() and fast_unlock() --\n-  \/\/ such as recursive enter and exit -- but we have to be wary of\n-  \/\/ I$ bloat, T$ effects and BP$ effects.\n-  \/\/\n@@ -728,3 +729,10 @@\n-  xorptr(boxReg, boxReg);\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n-  jccb  (Assembler::notZero, DONE_LABEL);\n+  Label LNotRecursive, LSuccess, LGoSlowPath;\n+\n+  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n+  jccb(Assembler::equal, LNotRecursive);\n+\n+  \/\/ Recursive inflated unlock\n+  decq(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  jmpb(LSuccess);\n+\n+  bind(LNotRecursive);\n@@ -739,1 +747,0 @@\n-  Label LSuccess, LGoSlowPath ;\n@@ -1468,0 +1475,13 @@\n+void C2_MacroAssembler::load_vector_mask(KRegister dst, XMMRegister src, XMMRegister xtmp,\n+                                         Register tmp, bool novlbwdq, int vlen_enc) {\n+  if (novlbwdq) {\n+    vpmovsxbd(xtmp, src, vlen_enc);\n+    evpcmpd(dst, k0, xtmp, ExternalAddress(StubRoutines::x86::vector_int_mask_cmp_bits()),\n+            Assembler::eq, true, vlen_enc, tmp);\n+  } else {\n+    vpxor(xtmp, xtmp, xtmp, vlen_enc);\n+    vpsubb(xtmp, xtmp, src, vlen_enc);\n+    evpmovb2m(dst, xtmp, vlen_enc);\n+  }\n+}\n+\n@@ -3834,0 +3854,212 @@\n+void C2_MacroAssembler::evmasked_op(int ideal_opc, BasicType eType, KRegister mask, XMMRegister dst,\n+                                    XMMRegister src1, int imm8, bool merge, int vlen_enc) {\n+  switch(ideal_opc) {\n+    case Op_LShiftVS:\n+      Assembler::evpsllw(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_LShiftVI:\n+      Assembler::evpslld(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_LShiftVL:\n+      Assembler::evpsllq(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_RShiftVS:\n+      Assembler::evpsraw(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_RShiftVI:\n+      Assembler::evpsrad(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_RShiftVL:\n+      Assembler::evpsraq(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_URShiftVS:\n+      Assembler::evpsrlw(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_URShiftVI:\n+      Assembler::evpsrld(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_URShiftVL:\n+      Assembler::evpsrlq(dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_RotateRightV:\n+      evrord(eType, dst, mask, src1, imm8, merge, vlen_enc); break;\n+    case Op_RotateLeftV:\n+      evrold(eType, dst, mask, src1, imm8, merge, vlen_enc); break;\n+    default:\n+      fatal(\"Unsupported masked operation\"); break;\n+  }\n+}\n+\n+void C2_MacroAssembler::evmasked_op(int ideal_opc, BasicType eType, KRegister mask, XMMRegister dst,\n+                                    XMMRegister src1, XMMRegister src2, bool merge, int vlen_enc,\n+                                    bool is_varshift) {\n+  switch (ideal_opc) {\n+    case Op_AddVB:\n+      evpaddb(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVS:\n+      evpaddw(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVI:\n+      evpaddd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVL:\n+      evpaddq(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVF:\n+      evaddps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVD:\n+      evaddpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVB:\n+      evpsubb(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVS:\n+      evpsubw(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVI:\n+      evpsubd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVL:\n+      evpsubq(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVF:\n+      evsubps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVD:\n+      evsubpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVS:\n+      evpmullw(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVI:\n+      evpmulld(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVL:\n+      evpmullq(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVF:\n+      evmulps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVD:\n+      evmulpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_DivVF:\n+      evdivps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_DivVD:\n+      evdivpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SqrtVF:\n+      evsqrtps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SqrtVD:\n+      evsqrtpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AbsVB:\n+      evpabsb(dst, mask, src2, merge, vlen_enc); break;\n+    case Op_AbsVS:\n+      evpabsw(dst, mask, src2, merge, vlen_enc); break;\n+    case Op_AbsVI:\n+      evpabsd(dst, mask, src2, merge, vlen_enc); break;\n+    case Op_AbsVL:\n+      evpabsq(dst, mask, src2, merge, vlen_enc); break;\n+    case Op_FmaVF:\n+      evpfma213ps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_FmaVD:\n+      evpfma213pd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_VectorRearrange:\n+      evperm(eType, dst, mask, src2, src1, merge, vlen_enc); break;\n+    case Op_LShiftVS:\n+      evpsllw(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_LShiftVI:\n+      evpslld(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_LShiftVL:\n+      evpsllq(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_RShiftVS:\n+      evpsraw(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_RShiftVI:\n+      evpsrad(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_RShiftVL:\n+      evpsraq(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_URShiftVS:\n+      evpsrlw(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_URShiftVI:\n+      evpsrld(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_URShiftVL:\n+      evpsrlq(dst, mask, src1, src2, merge, vlen_enc, is_varshift); break;\n+    case Op_RotateLeftV:\n+      evrold(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_RotateRightV:\n+      evrord(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MaxV:\n+      evpmaxs(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MinV:\n+      evpmins(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_XorV:\n+      evxor(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_OrV:\n+      evor(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AndV:\n+      evand(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    default:\n+      fatal(\"Unsupported masked operation\"); break;\n+  }\n+}\n+\n+void C2_MacroAssembler::evmasked_op(int ideal_opc, BasicType eType, KRegister mask, XMMRegister dst,\n+                                    XMMRegister src1, Address src2, bool merge, int vlen_enc) {\n+  switch (ideal_opc) {\n+    case Op_AddVB:\n+      evpaddb(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVS:\n+      evpaddw(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVI:\n+      evpaddd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVL:\n+      evpaddq(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVF:\n+      evaddps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AddVD:\n+      evaddpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVB:\n+      evpsubb(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVS:\n+      evpsubw(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVI:\n+      evpsubd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVL:\n+      evpsubq(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVF:\n+      evsubps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_SubVD:\n+      evsubpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVS:\n+      evpmullw(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVI:\n+      evpmulld(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVL:\n+      evpmullq(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVF:\n+      evmulps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MulVD:\n+      evmulpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_DivVF:\n+      evdivps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_DivVD:\n+      evdivpd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_FmaVF:\n+      evpfma213ps(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_FmaVD:\n+      evpfma213pd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MaxV:\n+      evpmaxs(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_MinV:\n+      evpmins(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_XorV:\n+      evxor(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_OrV:\n+      evor(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    case Op_AndV:\n+      evand(eType, dst, mask, src1, src2, merge, vlen_enc); break;\n+    default:\n+      fatal(\"Unsupported masked operation\"); break;\n+  }\n+}\n+\n+void C2_MacroAssembler::masked_op(int ideal_opc, int mask_len, KRegister dst,\n+                                  KRegister src1, KRegister src2) {\n+  BasicType etype = T_ILLEGAL;\n+  switch(mask_len) {\n+    case 2:\n+    case 4:\n+    case 8:  etype = T_BYTE; break;\n+    case 16: etype = T_SHORT; break;\n+    case 32: etype = T_INT; break;\n+    case 64: etype = T_LONG; break;\n+    default: fatal(\"Unsupported type\"); break;\n+  }\n+  assert(etype != T_ILLEGAL, \"\");\n+  switch(ideal_opc) {\n+    case Op_AndVMask:\n+      kand(etype, dst, src1, src2); break;\n+    case Op_OrVMask:\n+      kor(etype, dst, src1, src2); break;\n+    case Op_XorVMask:\n+      kxor(etype, dst, src1, src2); break;\n+    default:\n+      fatal(\"Unsupported masked operation\"); break;\n+  }\n+}\n+\n@@ -3835,7 +4067,12 @@\n-void C2_MacroAssembler::vector_mask_operation(int opc, Register dst, XMMRegister mask, XMMRegister xtmp,\n-                                              Register tmp, KRegister ktmp, int masklen, int vec_enc) {\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n-  vpxor(xtmp, xtmp, xtmp, vec_enc);\n-  vpsubb(xtmp, xtmp, mask, vec_enc);\n-  evpmovb2m(ktmp, xtmp, vec_enc);\n-  kmovql(tmp, ktmp);\n+void C2_MacroAssembler::vector_mask_operation(int opc, Register dst, KRegister mask,\n+                                              Register tmp, int masklen, int masksize,\n+                                              int vec_enc) {\n+  if(VM_Version::supports_avx512bw()) {\n+    kmovql(tmp, mask);\n+  } else {\n+    assert(masklen <= 16, \"\");\n+    kmovwl(tmp, mask);\n+  }\n+  if (masksize < 16) {\n+    andq(tmp, (((jlong)1 << masklen) - 1));\n+  }\n@@ -3861,1 +4098,2 @@\n-                                              XMMRegister xtmp1, Register tmp, int masklen, int vec_enc) {\n+                                              XMMRegister xtmp1, Register tmp, int masklen, int masksize,\n+                                              int vec_enc) {\n@@ -3866,1 +4104,1 @@\n-  if (masklen < 64) {\n+  if (masksize < 16) {\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":256,"deletions":18,"binary":false,"changes":274,"status":"modified"},{"patch":"@@ -37,2 +37,1 @@\n-class LIR_OprDesc;\n-typedef LIR_OprDesc* LIR_Opr;\n+class LIR_Opr;\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/zBarrierSetAssembler_x86.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1233,1 +1233,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), new_obj);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast<int (*)(oopDesc*)>(SharedRuntime::dtrace_object_alloc)), new_obj);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5169,2 +5169,0 @@\n-\/\/ !!! If the instructions that get generated here change then function\n-\/\/ instr_size_for_decode_klass_not_null() needs to get updated.\n@@ -5419,1 +5417,1 @@\n-    fill64_avx(base, 0, xtmp, use64byteVector);\n+    fill64(base, 0, xtmp, use64byteVector);\n@@ -5436,1 +5434,1 @@\n-    fill64_masked_avx(3, base, 0, xtmp, mask, cnt, val, true);\n+    fill64_masked(3, base, 0, xtmp, mask, cnt, val, true);\n@@ -5455,1 +5453,1 @@\n-    fill32_masked_avx(3, base, 0, xtmp, mask, cnt, val);\n+    fill32_masked(3, base, 0, xtmp, mask, cnt, val);\n@@ -5797,1 +5795,1 @@\n-    fill64_avx(base, i * 64, xtmp, use64byteVector);\n+    fill64(base, i * 64, xtmp, use64byteVector);\n@@ -5915,0 +5913,9 @@\n+#if defined(COMPILER2) && defined(_LP64)\n+  if(MaxVectorSize >=32 &&\n+     VM_Version::supports_avx512vlbw() &&\n+     VM_Version::supports_bmi2()) {\n+    generate_fill_avx3(t, to, value, count, rtmp, xtmp);\n+    return;\n+  }\n+#endif\n+\n@@ -6135,0 +6142,24 @@\n+void MacroAssembler::evpbroadcast(BasicType type, XMMRegister dst, Register src, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+      evpbroadcastb(dst, src, vector_len);\n+      break;\n+    case T_SHORT:\n+    case T_CHAR:\n+      evpbroadcastw(dst, src, vector_len);\n+      break;\n+    case T_INT:\n+    case T_FLOAT:\n+      evpbroadcastd(dst, src, vector_len);\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      evpbroadcastq(dst, src, vector_len);\n+      break;\n+    default:\n+      fatal(\"Unhandled type : %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n@@ -8942,0 +8973,373 @@\n+void MacroAssembler::knot(uint masklen, KRegister dst, KRegister src, KRegister ktmp, Register rtmp) {\n+  switch(masklen) {\n+    case 2:\n+       knotbl(dst, src);\n+       movl(rtmp, 3);\n+       kmovbl(ktmp, rtmp);\n+       kandbl(dst, ktmp, dst);\n+       break;\n+    case 4:\n+       knotbl(dst, src);\n+       movl(rtmp, 15);\n+       kmovbl(ktmp, rtmp);\n+       kandbl(dst, ktmp, dst);\n+       break;\n+    case 8:\n+       knotbl(dst, src);\n+       break;\n+    case 16:\n+       knotwl(dst, src);\n+       break;\n+    case 32:\n+       knotdl(dst, src);\n+       break;\n+    case 64:\n+       knotql(dst, src);\n+       break;\n+    default:\n+      fatal(\"Unexpected vector length %d\", masklen);\n+      break;\n+  }\n+}\n+\n+void MacroAssembler::kand(BasicType type, KRegister dst, KRegister src1, KRegister src2) {\n+  switch(type) {\n+    case T_BOOLEAN:\n+    case T_BYTE:\n+       kandbl(dst, src1, src2);\n+       break;\n+    case T_CHAR:\n+    case T_SHORT:\n+       kandwl(dst, src1, src2);\n+       break;\n+    case T_INT:\n+    case T_FLOAT:\n+       kanddl(dst, src1, src2);\n+       break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+       kandql(dst, src1, src2);\n+       break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n+void MacroAssembler::kor(BasicType type, KRegister dst, KRegister src1, KRegister src2) {\n+  switch(type) {\n+    case T_BOOLEAN:\n+    case T_BYTE:\n+       korbl(dst, src1, src2);\n+       break;\n+    case T_CHAR:\n+    case T_SHORT:\n+       korwl(dst, src1, src2);\n+       break;\n+    case T_INT:\n+    case T_FLOAT:\n+       kordl(dst, src1, src2);\n+       break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+       korql(dst, src1, src2);\n+       break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n+void MacroAssembler::kxor(BasicType type, KRegister dst, KRegister src1, KRegister src2) {\n+  switch(type) {\n+    case T_BOOLEAN:\n+    case T_BYTE:\n+       kxorbl(dst, src1, src2);\n+       break;\n+    case T_CHAR:\n+    case T_SHORT:\n+       kxorwl(dst, src1, src2);\n+       break;\n+    case T_INT:\n+    case T_FLOAT:\n+       kxordl(dst, src1, src2);\n+       break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+       kxorql(dst, src1, src2);\n+       break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n+void MacroAssembler::evperm(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_BOOLEAN:\n+    case T_BYTE:\n+      evpermb(dst, mask, nds, src, merge, vector_len); break;\n+    case T_CHAR:\n+    case T_SHORT:\n+      evpermw(dst, mask, nds, src, merge, vector_len); break;\n+    case T_INT:\n+    case T_FLOAT:\n+      evpermd(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      evpermq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evperm(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_BOOLEAN:\n+    case T_BYTE:\n+      evpermb(dst, mask, nds, src, merge, vector_len); break;\n+    case T_CHAR:\n+    case T_SHORT:\n+      evpermw(dst, mask, nds, src, merge, vector_len); break;\n+    case T_INT:\n+    case T_FLOAT:\n+      evpermd(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      evpermq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evpmins(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+      evpminsb(dst, mask, nds, src, merge, vector_len); break;\n+    case T_SHORT:\n+      evpminsw(dst, mask, nds, src, merge, vector_len); break;\n+    case T_INT:\n+      evpminsd(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evpminsq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evpmaxs(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+      evpmaxsb(dst, mask, nds, src, merge, vector_len); break;\n+    case T_SHORT:\n+      evpmaxsw(dst, mask, nds, src, merge, vector_len); break;\n+    case T_INT:\n+      evpmaxsd(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evpmaxsq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evpmins(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+      evpminsb(dst, mask, nds, src, merge, vector_len); break;\n+    case T_SHORT:\n+      evpminsw(dst, mask, nds, src, merge, vector_len); break;\n+    case T_INT:\n+      evpminsd(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evpminsq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evpmaxs(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+      evpmaxsb(dst, mask, nds, src, merge, vector_len); break;\n+    case T_SHORT:\n+      evpmaxsw(dst, mask, nds, src, merge, vector_len); break;\n+    case T_INT:\n+      evpmaxsd(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evpmaxsq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evxor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_INT:\n+      evpxord(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evpxorq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evxor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_INT:\n+      evpxord(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evpxorq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_INT:\n+      Assembler::evpord(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evporq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_INT:\n+      Assembler::evpord(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evporq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evand(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_INT:\n+      evpandd(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evpandq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evand(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len) {\n+  switch(type) {\n+    case T_INT:\n+      evpandd(dst, mask, nds, src, merge, vector_len); break;\n+    case T_LONG:\n+      evpandq(dst, mask, nds, src, merge, vector_len); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::anytrue(Register dst, uint masklen, KRegister src1, KRegister src2) {\n+   masklen = masklen < 8 ? 8 : masklen;\n+   ktest(masklen, src1, src2);\n+   setb(Assembler::notZero, dst);\n+   movzbl(dst, dst);\n+}\n+\n+void MacroAssembler::alltrue(Register dst, uint masklen, KRegister src1, KRegister src2, KRegister kscratch) {\n+  if (masklen < 8) {\n+    knotbl(kscratch, src2);\n+    kortestbl(src1, kscratch);\n+    setb(Assembler::carrySet, dst);\n+    movzbl(dst, dst);\n+  } else {\n+    ktest(masklen, src1, src2);\n+    setb(Assembler::carrySet, dst);\n+    movzbl(dst, dst);\n+  }\n+}\n+\n+void MacroAssembler::kortest(uint masklen, KRegister src1, KRegister src2) {\n+  switch(masklen) {\n+    case 8:\n+       kortestbl(src1, src2);\n+       break;\n+    case 16:\n+       kortestwl(src1, src2);\n+       break;\n+    case 32:\n+       kortestdl(src1, src2);\n+       break;\n+    case 64:\n+       kortestql(src1, src2);\n+       break;\n+    default:\n+      fatal(\"Unexpected mask length %d\", masklen);\n+      break;\n+  }\n+}\n+\n+\n+void MacroAssembler::ktest(uint masklen, KRegister src1, KRegister src2) {\n+  switch(masklen)  {\n+    case 8:\n+       ktestbl(src1, src2);\n+       break;\n+    case 16:\n+       ktestwl(src1, src2);\n+       break;\n+    case 32:\n+       ktestdl(src1, src2);\n+       break;\n+    case 64:\n+       ktestql(src1, src2);\n+       break;\n+    default:\n+      fatal(\"Unexpected mask length %d\", masklen);\n+      break;\n+  }\n+}\n+\n+void MacroAssembler::evrold(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src, int shift, bool merge, int vlen_enc) {\n+  switch(type) {\n+    case T_INT:\n+      evprold(dst, mask, src, shift, merge, vlen_enc); break;\n+    case T_LONG:\n+      evprolq(dst, mask, src, shift, merge, vlen_enc); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+      break;\n+  }\n+}\n+\n+void MacroAssembler::evrord(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src, int shift, bool merge, int vlen_enc) {\n+  switch(type) {\n+    case T_INT:\n+      evprord(dst, mask, src, shift, merge, vlen_enc); break;\n+    case T_LONG:\n+      evprorq(dst, mask, src, shift, merge, vlen_enc); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evrold(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vlen_enc) {\n+  switch(type) {\n+    case T_INT:\n+      evprolvd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case T_LONG:\n+      evprolvq(dst, mask, src1, src2, merge, vlen_enc); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n+\n+void MacroAssembler::evrord(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vlen_enc) {\n+  switch(type) {\n+    case T_INT:\n+      evprorvd(dst, mask, src1, src2, merge, vlen_enc); break;\n+    case T_LONG:\n+      evprorvq(dst, mask, src1, src2, merge, vlen_enc); break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type)); break;\n+  }\n+}\n@@ -8944,0 +9348,8 @@\n+void MacroAssembler::fill_masked(BasicType bt, Address dst, XMMRegister xmm, KRegister mask,\n+                                 Register length, Register temp, int vec_enc) {\n+  \/\/ Computing mask for predicated vector store.\n+  movptr(temp, -1);\n+  bzhiq(temp, temp, length);\n+  kmov(mask, temp);\n+  evmovdqu(bt, mask, dst, xmm, vec_enc);\n+}\n@@ -8946,1 +9358,1 @@\n-void MacroAssembler::fill64_masked_avx(uint shift, Register dst, int disp,\n+void MacroAssembler::fill64_masked(uint shift, Register dst, int disp,\n@@ -8950,2 +9362,1 @@\n-  assert(shift != 0, \"shift value should be 1 (short),2(int) or 3(long)\");\n-  BasicType type[] = { T_BYTE, T_SHORT,  T_INT,   T_LONG};\n+  BasicType type[] = { T_BYTE, T_SHORT, T_INT, T_LONG};\n@@ -8953,1 +9364,1 @@\n-    fill32_avx(dst, disp, xmm);\n+    fill32(dst, disp, xmm);\n@@ -8955,1 +9366,1 @@\n-    fill32_masked_avx(shift, dst, disp + 32, xmm, mask, length, temp);\n+    fill32_masked(shift, dst, disp + 32, xmm, mask, length, temp);\n@@ -8958,5 +9369,1 @@\n-    movl(temp, 1);\n-    shlxl(temp, temp, length);\n-    subptr(temp, 1);\n-    kmovwl(mask, temp);\n-    evmovdqu(type[shift], mask, Address(dst, disp), xmm, Assembler::AVX_512bit);\n+    fill_masked(type[shift], Address(dst, disp), xmm, mask, length, temp, Assembler::AVX_512bit);\n@@ -8967,1 +9374,1 @@\n-void MacroAssembler::fill32_masked_avx(uint shift, Register dst, int disp,\n+void MacroAssembler::fill32_masked(uint shift, Register dst, int disp,\n@@ -8971,7 +9378,2 @@\n-  assert(shift != 0, \"shift value should be 1 (short), 2(int) or 3(long)\");\n-  BasicType type[] = { T_BYTE, T_SHORT,  T_INT,   T_LONG};\n-  movl(temp, 1);\n-  shlxl(temp, temp, length);\n-  subptr(temp, 1);\n-  kmovwl(mask, temp);\n-  evmovdqu(type[shift], mask, Address(dst, disp), xmm, Assembler::AVX_256bit);\n+  BasicType type[] = { T_BYTE, T_SHORT, T_INT, T_LONG};\n+  fill_masked(type[shift], Address(dst, disp), xmm, mask, length, temp, Assembler::AVX_256bit);\n@@ -8981,1 +9383,1 @@\n-void MacroAssembler::fill32_avx(Register dst, int disp, XMMRegister xmm) {\n+void MacroAssembler::fill32(Register dst, int disp, XMMRegister xmm) {\n@@ -8986,1 +9388,1 @@\n-void MacroAssembler::fill64_avx(Register dst, int disp, XMMRegister xmm, bool use64byteVector) {\n+void MacroAssembler::fill64(Register dst, int disp, XMMRegister xmm, bool use64byteVector) {\n@@ -8990,2 +9392,2 @@\n-    fill32_avx(dst, disp, xmm);\n-    fill32_avx(dst, disp + 32, xmm);\n+    fill32(dst, disp, xmm);\n+    fill32(dst, disp + 32, xmm);\n@@ -8997,0 +9399,177 @@\n+#ifdef _LP64\n+void MacroAssembler::generate_fill_avx3(BasicType type, Register to, Register value,\n+                                        Register count, Register rtmp, XMMRegister xtmp) {\n+  Label L_exit;\n+  Label L_fill_start;\n+  Label L_fill_64_bytes;\n+  Label L_fill_96_bytes;\n+  Label L_fill_128_bytes;\n+  Label L_fill_128_bytes_loop;\n+  Label L_fill_128_loop_header;\n+  Label L_fill_128_bytes_loop_header;\n+  Label L_fill_128_bytes_loop_pre_header;\n+  Label L_fill_zmm_sequence;\n+\n+  int shift = -1;\n+  switch(type) {\n+    case T_BYTE:  shift = 0;\n+      break;\n+    case T_SHORT: shift = 1;\n+      break;\n+    case T_INT:   shift = 2;\n+      break;\n+    \/* Uncomment when LONG fill stubs are supported.\n+    case T_LONG:  shift = 3;\n+      break;\n+    *\/\n+    default:\n+      fatal(\"Unhandled type: %s\\n\", type2name(type));\n+  }\n+\n+  if (AVX3Threshold != 0  || MaxVectorSize == 32) {\n+\n+    if (MaxVectorSize == 64) {\n+      cmpq(count, AVX3Threshold >> shift);\n+      jcc(Assembler::greater, L_fill_zmm_sequence);\n+    }\n+\n+    evpbroadcast(type, xtmp, value, Assembler::AVX_256bit);\n+\n+    bind(L_fill_start);\n+\n+    cmpq(count, 32 >> shift);\n+    jccb(Assembler::greater, L_fill_64_bytes);\n+    fill32_masked(shift, to, 0, xtmp, k2, count, rtmp);\n+    jmp(L_exit);\n+\n+    bind(L_fill_64_bytes);\n+    cmpq(count, 64 >> shift);\n+    jccb(Assembler::greater, L_fill_96_bytes);\n+    fill64_masked(shift, to, 0, xtmp, k2, count, rtmp);\n+    jmp(L_exit);\n+\n+    bind(L_fill_96_bytes);\n+    cmpq(count, 96 >> shift);\n+    jccb(Assembler::greater, L_fill_128_bytes);\n+    fill64(to, 0, xtmp);\n+    subq(count, 64 >> shift);\n+    fill32_masked(shift, to, 64, xtmp, k2, count, rtmp);\n+    jmp(L_exit);\n+\n+    bind(L_fill_128_bytes);\n+    cmpq(count, 128 >> shift);\n+    jccb(Assembler::greater, L_fill_128_bytes_loop_pre_header);\n+    fill64(to, 0, xtmp);\n+    fill32(to, 64, xtmp);\n+    subq(count, 96 >> shift);\n+    fill32_masked(shift, to, 96, xtmp, k2, count, rtmp);\n+    jmp(L_exit);\n+\n+    bind(L_fill_128_bytes_loop_pre_header);\n+    {\n+      mov(rtmp, to);\n+      andq(rtmp, 31);\n+      jccb(Assembler::zero, L_fill_128_bytes_loop_header);\n+      negq(rtmp);\n+      addq(rtmp, 32);\n+      mov64(r8, -1L);\n+      bzhiq(r8, r8, rtmp);\n+      kmovql(k2, r8);\n+      evmovdqu(T_BYTE, k2, Address(to, 0), xtmp, Assembler::AVX_256bit);\n+      addq(to, rtmp);\n+      shrq(rtmp, shift);\n+      subq(count, rtmp);\n+    }\n+\n+    cmpq(count, 128 >> shift);\n+    jcc(Assembler::less, L_fill_start);\n+\n+    bind(L_fill_128_bytes_loop_header);\n+    subq(count, 128 >> shift);\n+\n+    align32();\n+    bind(L_fill_128_bytes_loop);\n+      fill64(to, 0, xtmp);\n+      fill64(to, 64, xtmp);\n+      addq(to, 128);\n+      subq(count, 128 >> shift);\n+      jccb(Assembler::greaterEqual, L_fill_128_bytes_loop);\n+\n+    addq(count, 128 >> shift);\n+    jcc(Assembler::zero, L_exit);\n+    jmp(L_fill_start);\n+  }\n+\n+  if (MaxVectorSize == 64) {\n+    \/\/ Sequence using 64 byte ZMM register.\n+    Label L_fill_128_bytes_zmm;\n+    Label L_fill_192_bytes_zmm;\n+    Label L_fill_192_bytes_loop_zmm;\n+    Label L_fill_192_bytes_loop_header_zmm;\n+    Label L_fill_192_bytes_loop_pre_header_zmm;\n+    Label L_fill_start_zmm_sequence;\n+\n+    bind(L_fill_zmm_sequence);\n+    evpbroadcast(type, xtmp, value, Assembler::AVX_512bit);\n+\n+    bind(L_fill_start_zmm_sequence);\n+    cmpq(count, 64 >> shift);\n+    jccb(Assembler::greater, L_fill_128_bytes_zmm);\n+    fill64_masked(shift, to, 0, xtmp, k2, count, rtmp, true);\n+    jmp(L_exit);\n+\n+    bind(L_fill_128_bytes_zmm);\n+    cmpq(count, 128 >> shift);\n+    jccb(Assembler::greater, L_fill_192_bytes_zmm);\n+    fill64(to, 0, xtmp, true);\n+    subq(count, 64 >> shift);\n+    fill64_masked(shift, to, 64, xtmp, k2, count, rtmp, true);\n+    jmp(L_exit);\n+\n+    bind(L_fill_192_bytes_zmm);\n+    cmpq(count, 192 >> shift);\n+    jccb(Assembler::greater, L_fill_192_bytes_loop_pre_header_zmm);\n+    fill64(to, 0, xtmp, true);\n+    fill64(to, 64, xtmp, true);\n+    subq(count, 128 >> shift);\n+    fill64_masked(shift, to, 128, xtmp, k2, count, rtmp, true);\n+    jmp(L_exit);\n+\n+    bind(L_fill_192_bytes_loop_pre_header_zmm);\n+    {\n+      movq(rtmp, to);\n+      andq(rtmp, 63);\n+      jccb(Assembler::zero, L_fill_192_bytes_loop_header_zmm);\n+      negq(rtmp);\n+      addq(rtmp, 64);\n+      mov64(r8, -1L);\n+      bzhiq(r8, r8, rtmp);\n+      kmovql(k2, r8);\n+      evmovdqu(T_BYTE, k2, Address(to, 0), xtmp, Assembler::AVX_512bit);\n+      addq(to, rtmp);\n+      shrq(rtmp, shift);\n+      subq(count, rtmp);\n+    }\n+\n+    cmpq(count, 192 >> shift);\n+    jcc(Assembler::less, L_fill_start_zmm_sequence);\n+\n+    bind(L_fill_192_bytes_loop_header_zmm);\n+    subq(count, 192 >> shift);\n+\n+    align32();\n+    bind(L_fill_192_bytes_loop_zmm);\n+      fill64(to, 0, xtmp, true);\n+      fill64(to, 64, xtmp, true);\n+      fill64(to, 128, xtmp, true);\n+      addq(to, 192);\n+      subq(count, 192 >> shift);\n+      jccb(Assembler::greaterEqual, L_fill_192_bytes_loop_zmm);\n+\n+    addq(count, 192 >> shift);\n+    jcc(Assembler::zero, L_exit);\n+    jmp(L_fill_start_zmm_sequence);\n+  }\n+  bind(L_exit);\n+}\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":607,"deletions":28,"binary":false,"changes":635,"status":"modified"},{"patch":"@@ -1368,0 +1368,1 @@\n+  void evpbroadcast(BasicType type, XMMRegister dst, Register src, int vector_len);\n@@ -1400,0 +1401,69 @@\n+  void evpsllw(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsllw(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsllvw(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpslld(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpslld(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsllvd(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsllq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsllq(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsllvq(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsrlw(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsrlw(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsrlvw(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsrld(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsrld(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsrlvd(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsrlq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsrlq(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsrlvq(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsraw(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsraw(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsravw(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsrad(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsrad(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsravd(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsraq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsraq(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsravq(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+\n+  void evpmins(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evpmaxs(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evpmins(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+  void evpmaxs(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n@@ -1689,1 +1759,27 @@\n-  \/\/ Data\n+  \/\/ AVX-512 mask operations.\n+  void kand(BasicType etype, KRegister dst, KRegister src1, KRegister src2);\n+  void kor(BasicType type, KRegister dst, KRegister src1, KRegister src2);\n+  void knot(uint masklen, KRegister dst, KRegister src, KRegister ktmp = knoreg, Register rtmp = noreg);\n+  void kxor(BasicType type, KRegister dst, KRegister src1, KRegister src2);\n+  void kortest(uint masklen, KRegister src1, KRegister src2);\n+  void ktest(uint masklen, KRegister src1, KRegister src2);\n+\n+  void evperm(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evperm(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n+  void evor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n+  void evand(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evand(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n+  void evxor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evxor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n+  void evrold(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src, int shift, bool merge, int vlen_enc);\n+  void evrold(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vlen_enc);\n+  void evrord(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src, int shift, bool merge, int vlen_enc);\n+  void evrord(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vlen_enc);\n+\n+  void alltrue(Register dst, uint masklen, KRegister src1, KRegister src2, KRegister kscratch);\n+  void anytrue(Register dst, uint masklen, KRegister src, KRegister kscratch);\n@@ -1916,1 +2012,4 @@\n-  void fill64_masked_avx(uint shift, Register dst, int disp,\n+  void fill_masked(BasicType bt, Address dst, XMMRegister xmm, KRegister mask,\n+                   Register length, Register temp, int vec_enc);\n+\n+  void fill64_masked(uint shift, Register dst, int disp,\n@@ -1920,1 +2019,1 @@\n-  void fill32_masked_avx(uint shift, Register dst, int disp,\n+  void fill32_masked(uint shift, Register dst, int disp,\n@@ -1924,1 +2023,1 @@\n-  void fill32_avx(Register dst, int disp, XMMRegister xmm);\n+  void fill32(Register dst, int disp, XMMRegister xmm);\n@@ -1926,1 +2025,1 @@\n-  void fill64_avx(Register dst, int dis, XMMRegister xmm, bool use64byteVector = false);\n+  void fill64(Register dst, int dis, XMMRegister xmm, bool use64byteVector = false);\n@@ -1963,0 +2062,4 @@\n+\n+  void generate_fill_avx3(BasicType type, Register to, Register value,\n+                          Register count, Register rtmp, XMMRegister xtmp);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":108,"deletions":5,"binary":false,"changes":113,"status":"modified"},{"patch":"@@ -1256,34 +1256,0 @@\n-\/\/ Unpack an array argument into a pointer to the body and the length\n-\/\/ if the array is non-null, otherwise pass 0 for both.\n-static void unpack_array_argument(MacroAssembler* masm, VMRegPair reg, BasicType in_elem_type, VMRegPair body_arg, VMRegPair length_arg) {\n-  Register tmp_reg = rax;\n-  assert(!body_arg.first()->is_Register() || body_arg.first()->as_Register() != tmp_reg,\n-         \"possible collision\");\n-  assert(!length_arg.first()->is_Register() || length_arg.first()->as_Register() != tmp_reg,\n-         \"possible collision\");\n-\n-  \/\/ Pass the length, ptr pair\n-  Label is_null, done;\n-  VMRegPair tmp(tmp_reg->as_VMReg());\n-  if (reg.first()->is_stack()) {\n-    \/\/ Load the arg up from the stack\n-    simple_move32(masm, reg, tmp);\n-    reg = tmp;\n-  }\n-  __ testptr(reg.first()->as_Register(), reg.first()->as_Register());\n-  __ jccb(Assembler::equal, is_null);\n-  __ lea(tmp_reg, Address(reg.first()->as_Register(), arrayOopDesc::base_offset_in_bytes(in_elem_type)));\n-  simple_move32(masm, tmp, body_arg);\n-  \/\/ load the length relative to the body.\n-  __ movl(tmp_reg, Address(tmp_reg, arrayOopDesc::length_offset_in_bytes() -\n-                           arrayOopDesc::base_offset_in_bytes(in_elem_type)));\n-  simple_move32(masm, tmp, length_arg);\n-  __ jmpb(done);\n-  __ bind(is_null);\n-  \/\/ Pass zeros\n-  __ xorptr(tmp_reg, tmp_reg);\n-  simple_move32(masm, tmp, body_arg);\n-  simple_move32(masm, tmp, length_arg);\n-  __ bind(done);\n-}\n-\n@@ -1392,2 +1358,1 @@\n-                                                BasicType ret_type,\n-                                                address critical_entry) {\n+                                                BasicType ret_type) {\n@@ -1415,6 +1380,1 @@\n-  bool is_critical_native = true;\n-  address native_func = critical_entry;\n-  if (native_func == NULL) {\n-    native_func = method->native_function();\n-    is_critical_native = false;\n-  }\n+  address native_func = method->native_function();\n@@ -1433,13 +1393,1 @@\n-  int total_c_args = total_in_args;\n-  if (!is_critical_native) {\n-    total_c_args += 1;\n-    if (method->is_static()) {\n-      total_c_args++;\n-    }\n-  } else {\n-    for (int i = 0; i < total_in_args; i++) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        total_c_args++;\n-      }\n-    }\n-  }\n+  int  total_c_args       = total_in_args + (method->is_static() ? 2 : 1);\n@@ -1452,5 +1400,4 @@\n-  if (!is_critical_native) {\n-    out_sig_bt[argc++] = T_ADDRESS;\n-    if (method->is_static()) {\n-      out_sig_bt[argc++] = T_OBJECT;\n-    }\n+  out_sig_bt[argc++] = T_ADDRESS;\n+  if (method->is_static()) {\n+    out_sig_bt[argc++] = T_OBJECT;\n+  }\n@@ -1458,24 +1405,2 @@\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      out_sig_bt[argc++] = in_sig_bt[i];\n-    }\n-  } else {\n-    in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);\n-    SignatureStream ss(method->signature());\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        \/\/ Arrays are passed as int, elem* pair\n-        out_sig_bt[argc++] = T_INT;\n-        out_sig_bt[argc++] = T_ADDRESS;\n-        ss.skip_array_prefix(1);  \/\/ skip one '['\n-        assert(ss.is_primitive(), \"primitive type expected\");\n-        in_elem_bt[i] = ss.type();\n-      } else {\n-        out_sig_bt[argc++] = in_sig_bt[i];\n-        in_elem_bt[i] = T_VOID;\n-      }\n-      if (in_sig_bt[i] != T_VOID) {\n-        assert(in_sig_bt[i] == ss.type() ||\n-               in_sig_bt[i] == T_ARRAY, \"must match\");\n-        ss.next();\n-      }\n-    }\n+  for (int i = 0; i < total_in_args ; i++ ) {\n+    out_sig_bt[argc++] = in_sig_bt[i];\n@@ -1499,34 +1424,0 @@\n-  if (is_critical_native) {\n-    \/\/ Critical natives may have to call out so they need a save area\n-    \/\/ for register arguments.\n-    int double_slots = 0;\n-    int single_slots = 0;\n-    for ( int i = 0; i < total_in_args; i++) {\n-      if (in_regs[i].first()->is_Register()) {\n-        const Register reg = in_regs[i].first()->as_Register();\n-        switch (in_sig_bt[i]) {\n-          case T_ARRAY:  \/\/ critical array (uses 2 slots on LP64)\n-          case T_BOOLEAN:\n-          case T_BYTE:\n-          case T_SHORT:\n-          case T_CHAR:\n-          case T_INT:  single_slots++; break;\n-          case T_LONG: double_slots++; break;\n-          default:  ShouldNotReachHere();\n-        }\n-      } else if (in_regs[i].first()->is_XMMRegister()) {\n-        switch (in_sig_bt[i]) {\n-          case T_FLOAT:  single_slots++; break;\n-          case T_DOUBLE: double_slots++; break;\n-          default:  ShouldNotReachHere();\n-        }\n-      } else if (in_regs[i].first()->is_FloatRegister()) {\n-        ShouldNotReachHere();\n-      }\n-    }\n-    total_save_slots = double_slots * 2 + single_slots;\n-    \/\/ align the save area\n-    if (double_slots != 0) {\n-      stack_slots = align_up(stack_slots, 2);\n-    }\n-  }\n@@ -1711,1 +1602,1 @@\n-  int c_arg = is_critical_native ? 0 : (method->is_static() ? 2 : 1 );\n+  int c_arg = method->is_static() ? 2 : 1;\n@@ -1734,6 +1625,0 @@\n-        if (is_critical_native) {\n-          VMRegPair in_arg = in_regs[i];\n-          unpack_array_argument(masm, in_arg, in_elem_bt[i], out_regs[c_arg + 1], out_regs[c_arg]);\n-          c_arg++;\n-          break;\n-        }\n@@ -1742,1 +1627,0 @@\n-        assert(!is_critical_native, \"no oop arguments\");\n@@ -1774,1 +1658,1 @@\n-  if (method->is_static() && !is_critical_native) {\n+  if (method->is_static()) {\n@@ -1829,2 +1713,0 @@\n-    assert(!is_critical_native, \"unhandled\");\n-\n@@ -1882,3 +1764,2 @@\n-  if (!is_critical_native) {\n-    __ lea(rdx, Address(thread, in_bytes(JavaThread::jni_environment_offset())));\n-    __ movptr(Address(rsp, 0), rdx);\n+  __ lea(rdx, Address(thread, in_bytes(JavaThread::jni_environment_offset())));\n+  __ movptr(Address(rsp, 0), rdx);\n@@ -1886,3 +1767,2 @@\n-    \/\/ Now set thread in native\n-    __ movl(Address(thread, JavaThread::thread_state_offset()), _thread_in_native);\n-  }\n+  \/\/ Now set thread in native\n+  __ movl(Address(thread, JavaThread::thread_state_offset()), _thread_in_native);\n@@ -1922,11 +1802,0 @@\n-  \/\/ If this is a critical native, check for a safepoint or suspend request after the call.\n-  \/\/ If a safepoint is needed, transition to native, then to native_trans to handle\n-  \/\/ safepoints like the native methods that are not critical natives.\n-  if (is_critical_native) {\n-    Label needs_safepoint;\n-    __ safepoint_poll(needs_safepoint, thread, false \/* at_return *\/, false \/* in_nmethod *\/);\n-    __ cmpl(Address(thread, JavaThread::suspend_flags_offset()), 0);\n-    __ jcc(Assembler::equal, after_transition);\n-    __ bind(needs_safepoint);\n-  }\n-\n@@ -2065,4 +1934,3 @@\n-  if (!is_critical_native) {\n-    \/\/ reset handle block\n-    __ movptr(rcx, Address(thread, JavaThread::active_handles_offset()));\n-    __ movl(Address(rcx, JNIHandleBlock::top_offset_in_bytes()), NULL_WORD);\n+  \/\/ reset handle block\n+  __ movptr(rcx, Address(thread, JavaThread::active_handles_offset()));\n+  __ movl(Address(rcx, JNIHandleBlock::top_offset_in_bytes()), NULL_WORD);\n@@ -2070,4 +1938,3 @@\n-    \/\/ Any exception pending?\n-    __ cmpptr(Address(thread, in_bytes(Thread::pending_exception_offset())), (int32_t)NULL_WORD);\n-    __ jcc(Assembler::notEqual, exception_pending);\n-  }\n+  \/\/ Any exception pending?\n+  __ cmpptr(Address(thread, in_bytes(Thread::pending_exception_offset())), (int32_t)NULL_WORD);\n+  __ jcc(Assembler::notEqual, exception_pending);\n@@ -2187,3 +2054,2 @@\n-  if (!is_critical_native) {\n-    \/\/ Forward  the exception\n-    __ bind(exception_pending);\n+  \/\/ Forward  the exception\n+  __ bind(exception_pending);\n@@ -2191,2 +2057,2 @@\n-    \/\/ remove possible return value from FPU register stack\n-    __ empty_FPU_stack();\n+  \/\/ remove possible return value from FPU register stack\n+  __ empty_FPU_stack();\n@@ -2194,5 +2060,4 @@\n-    \/\/ pop our frame\n-    __ leave();\n-    \/\/ and forward the exception\n-    __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-  }\n+  \/\/ pop our frame\n+  __ leave();\n+  \/\/ and forward the exception\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":29,"deletions":164,"binary":false,"changes":193,"status":"modified"},{"patch":"@@ -1496,40 +1496,0 @@\n-\/\/ Unpack an array argument into a pointer to the body and the length\n-\/\/ if the array is non-null, otherwise pass 0 for both.\n-static void unpack_array_argument(MacroAssembler* masm, VMRegPair reg, BasicType in_elem_type, VMRegPair body_arg, VMRegPair length_arg) {\n-  Register tmp_reg = rax;\n-  assert(!body_arg.first()->is_Register() || body_arg.first()->as_Register() != tmp_reg,\n-         \"possible collision\");\n-  assert(!length_arg.first()->is_Register() || length_arg.first()->as_Register() != tmp_reg,\n-         \"possible collision\");\n-\n-  __ block_comment(\"unpack_array_argument {\");\n-\n-  \/\/ Pass the length, ptr pair\n-  Label is_null, done;\n-  VMRegPair tmp;\n-  tmp.set_ptr(tmp_reg->as_VMReg());\n-  if (reg.first()->is_stack()) {\n-    \/\/ Load the arg up from the stack\n-    __ move_ptr(reg, tmp);\n-    reg = tmp;\n-  }\n-  __ testptr(reg.first()->as_Register(), reg.first()->as_Register());\n-  __ jccb(Assembler::equal, is_null);\n-  __ lea(tmp_reg, Address(reg.first()->as_Register(), arrayOopDesc::base_offset_in_bytes(in_elem_type)));\n-  __ move_ptr(tmp, body_arg);\n-  \/\/ load the length relative to the body.\n-  __ movl(tmp_reg, Address(tmp_reg, arrayOopDesc::length_offset_in_bytes() -\n-                           arrayOopDesc::base_offset_in_bytes(in_elem_type)));\n-  __ move32_64(tmp, length_arg);\n-  __ jmpb(done);\n-  __ bind(is_null);\n-  \/\/ Pass zeros\n-  __ xorptr(tmp_reg, tmp_reg);\n-  __ move_ptr(tmp, body_arg);\n-  __ move32_64(tmp, length_arg);\n-  __ bind(done);\n-\n-  __ block_comment(\"} unpack_array_argument\");\n-}\n-\n-\n@@ -1811,2 +1771,1 @@\n-                                                BasicType ret_type,\n-                                                address critical_entry) {\n+                                                BasicType ret_type) {\n@@ -1834,6 +1793,1 @@\n-  bool is_critical_native = true;\n-  address native_func = critical_entry;\n-  if (native_func == NULL) {\n-    native_func = method->native_function();\n-    is_critical_native = false;\n-  }\n+  address native_func = method->native_function();\n@@ -1853,13 +1807,1 @@\n-  int total_c_args = total_in_args;\n-  if (!is_critical_native) {\n-    total_c_args += 1;\n-    if (method->is_static()) {\n-      total_c_args++;\n-    }\n-  } else {\n-    for (int i = 0; i < total_in_args; i++) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        total_c_args++;\n-      }\n-    }\n-  }\n+  int total_c_args = total_in_args + (method->is_static() ? 2 : 1);\n@@ -1872,5 +1814,4 @@\n-  if (!is_critical_native) {\n-    out_sig_bt[argc++] = T_ADDRESS;\n-    if (method->is_static()) {\n-      out_sig_bt[argc++] = T_OBJECT;\n-    }\n+  out_sig_bt[argc++] = T_ADDRESS;\n+  if (method->is_static()) {\n+    out_sig_bt[argc++] = T_OBJECT;\n+  }\n@@ -1878,24 +1819,2 @@\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      out_sig_bt[argc++] = in_sig_bt[i];\n-    }\n-  } else {\n-    in_elem_bt = NEW_RESOURCE_ARRAY(BasicType, total_in_args);\n-    SignatureStream ss(method->signature());\n-    for (int i = 0; i < total_in_args ; i++ ) {\n-      if (in_sig_bt[i] == T_ARRAY) {\n-        \/\/ Arrays are passed as int, elem* pair\n-        out_sig_bt[argc++] = T_INT;\n-        out_sig_bt[argc++] = T_ADDRESS;\n-        ss.skip_array_prefix(1);  \/\/ skip one '['\n-        assert(ss.is_primitive(), \"primitive type expected\");\n-        in_elem_bt[i] = ss.type();\n-      } else {\n-        out_sig_bt[argc++] = in_sig_bt[i];\n-        in_elem_bt[i] = T_VOID;\n-      }\n-      if (in_sig_bt[i] != T_VOID) {\n-        assert(in_sig_bt[i] == ss.type() ||\n-               in_sig_bt[i] == T_ARRAY, \"must match\");\n-        ss.next();\n-      }\n-    }\n+  for (int i = 0; i < total_in_args ; i++ ) {\n+    out_sig_bt[argc++] = in_sig_bt[i];\n@@ -1919,34 +1838,0 @@\n-  if (is_critical_native) {\n-    \/\/ Critical natives may have to call out so they need a save area\n-    \/\/ for register arguments.\n-    int double_slots = 0;\n-    int single_slots = 0;\n-    for ( int i = 0; i < total_in_args; i++) {\n-      if (in_regs[i].first()->is_Register()) {\n-        const Register reg = in_regs[i].first()->as_Register();\n-        switch (in_sig_bt[i]) {\n-          case T_BOOLEAN:\n-          case T_BYTE:\n-          case T_SHORT:\n-          case T_CHAR:\n-          case T_INT:  single_slots++; break;\n-          case T_ARRAY:  \/\/ specific to LP64 (7145024)\n-          case T_LONG: double_slots++; break;\n-          default:  ShouldNotReachHere();\n-        }\n-      } else if (in_regs[i].first()->is_XMMRegister()) {\n-        switch (in_sig_bt[i]) {\n-          case T_FLOAT:  single_slots++; break;\n-          case T_DOUBLE: double_slots++; break;\n-          default:  ShouldNotReachHere();\n-        }\n-      } else if (in_regs[i].first()->is_FloatRegister()) {\n-        ShouldNotReachHere();\n-      }\n-    }\n-    total_save_slots = double_slots * 2 + single_slots;\n-    \/\/ align the save area\n-    if (double_slots != 0) {\n-      stack_slots = align_up(stack_slots, 2);\n-    }\n-  }\n@@ -2147,4 +2032,1 @@\n-  \/\/ This may iterate in two different directions depending on the\n-  \/\/ kind of native it is.  The reason is that for regular JNI natives\n-  \/\/ the incoming and outgoing registers are offset upwards and for\n-  \/\/ critical natives they are offset down.\n+  \/\/ For JNI natives the incoming and outgoing registers are offset upwards.\n@@ -2156,8 +2038,3 @@\n-  if (!is_critical_native) {\n-    for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n-      arg_order.push(i);\n-      arg_order.push(c_arg);\n-    }\n-  } else {\n-    \/\/ Compute a valid move order, using tmp_vmreg to break any cycles\n-    ComputeMoveOrder cmo(total_in_args, in_regs, total_c_args, out_regs, in_sig_bt, arg_order, tmp_vmreg);\n+  for (int i = total_in_args - 1, c_arg = total_c_args - 1; i >= 0; i--, c_arg--) {\n+    arg_order.push(i);\n+    arg_order.push(c_arg);\n@@ -2171,14 +2048,0 @@\n-    if (c_arg == -1) {\n-      assert(is_critical_native, \"should only be required for critical natives\");\n-      \/\/ This arg needs to be moved to a temporary\n-      __ mov(tmp_vmreg.first()->as_Register(), in_regs[i].first()->as_Register());\n-      in_regs[i] = tmp_vmreg;\n-      temploc = i;\n-      continue;\n-    } else if (i == -1) {\n-      assert(is_critical_native, \"should only be required for critical natives\");\n-      \/\/ Read from the temporary location\n-      assert(temploc != -1, \"must be valid\");\n-      i = temploc;\n-      temploc = -1;\n-    }\n@@ -2199,12 +2062,0 @@\n-        if (is_critical_native) {\n-          unpack_array_argument(masm, in_regs[i], in_elem_bt[i], out_regs[c_arg + 1], out_regs[c_arg]);\n-          c_arg++;\n-#ifdef ASSERT\n-          if (out_regs[c_arg].first()->is_Register()) {\n-            reg_destroyed[out_regs[c_arg].first()->as_Register()->encoding()] = true;\n-          } else if (out_regs[c_arg].first()->is_XMMRegister()) {\n-            freg_destroyed[out_regs[c_arg].first()->as_XMMRegister()->encoding()] = true;\n-          }\n-#endif\n-          break;\n-        }\n@@ -2213,1 +2064,0 @@\n-        assert(!is_critical_native, \"no oop arguments\");\n@@ -2247,24 +2097,19 @@\n-  if (!is_critical_native) {\n-    \/\/ point c_arg at the first arg that is already loaded in case we\n-    \/\/ need to spill before we call out\n-    c_arg = total_c_args - total_in_args;\n-\n-    if (method->is_static()) {\n-\n-      \/\/  load oop into a register\n-      __ movoop(oop_handle_reg, JNIHandles::make_local(method->method_holder()->java_mirror()));\n-\n-      \/\/ Now handlize the static class mirror it's known not-null.\n-      __ movptr(Address(rsp, klass_offset), oop_handle_reg);\n-      map->set_oop(VMRegImpl::stack2reg(klass_slot_offset));\n-\n-      \/\/ Now get the handle\n-      __ lea(oop_handle_reg, Address(rsp, klass_offset));\n-      \/\/ store the klass handle as second argument\n-      __ movptr(c_rarg1, oop_handle_reg);\n-      \/\/ and protect the arg if we must spill\n-      c_arg--;\n-    }\n-  } else {\n-    \/\/ For JNI critical methods we need to save all registers in save_args.\n-    c_arg = 0;\n+  \/\/ point c_arg at the first arg that is already loaded in case we\n+  \/\/ need to spill before we call out\n+  c_arg = total_c_args - total_in_args;\n+\n+  if (method->is_static()) {\n+\n+    \/\/  load oop into a register\n+    __ movoop(oop_handle_reg, JNIHandles::make_local(method->method_holder()->java_mirror()));\n+\n+    \/\/ Now handlize the static class mirror it's known not-null.\n+    __ movptr(Address(rsp, klass_offset), oop_handle_reg);\n+    map->set_oop(VMRegImpl::stack2reg(klass_slot_offset));\n+\n+    \/\/ Now get the handle\n+    __ lea(oop_handle_reg, Address(rsp, klass_offset));\n+    \/\/ store the klass handle as second argument\n+    __ movptr(c_rarg1, oop_handle_reg);\n+    \/\/ and protect the arg if we must spill\n+    c_arg--;\n@@ -2322,2 +2167,0 @@\n-    assert(!is_critical_native, \"unhandled\");\n-\n@@ -2382,2 +2225,1 @@\n-  if (!is_critical_native) {\n-    __ lea(c_rarg0, Address(r15_thread, in_bytes(JavaThread::jni_environment_offset())));\n+  __ lea(c_rarg0, Address(r15_thread, in_bytes(JavaThread::jni_environment_offset())));\n@@ -2385,3 +2227,2 @@\n-    \/\/ Now set thread in native\n-    __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n-  }\n+  \/\/ Now set thread in native\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n@@ -2416,11 +2257,0 @@\n-  \/\/ If this is a critical native, check for a safepoint or suspend request after the call.\n-  \/\/ If a safepoint is needed, transition to native, then to native_trans to handle\n-  \/\/ safepoints like the native methods that are not critical natives.\n-  if (is_critical_native) {\n-    Label needs_safepoint;\n-    __ safepoint_poll(needs_safepoint, r15_thread, false \/* at_return *\/, false \/* in_nmethod *\/);\n-    __ cmpl(Address(r15_thread, JavaThread::suspend_flags_offset()), 0);\n-    __ jcc(Assembler::equal, after_transition);\n-    __ bind(needs_safepoint);\n-  }\n-\n@@ -2547,5 +2377,3 @@\n-  if (!is_critical_native) {\n-    \/\/ reset handle block\n-    __ movptr(rcx, Address(r15_thread, JavaThread::active_handles_offset()));\n-    __ movl(Address(rcx, JNIHandleBlock::top_offset_in_bytes()), (int32_t)NULL_WORD);\n-  }\n+  \/\/ reset handle block\n+  __ movptr(rcx, Address(r15_thread, JavaThread::active_handles_offset()));\n+  __ movl(Address(rcx, JNIHandleBlock::top_offset_in_bytes()), (int32_t)NULL_WORD);\n@@ -2557,5 +2385,3 @@\n-  if (!is_critical_native) {\n-    \/\/ Any exception pending?\n-    __ cmpptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), (int32_t)NULL_WORD);\n-    __ jcc(Assembler::notEqual, exception_pending);\n-  }\n+  \/\/ Any exception pending?\n+  __ cmpptr(Address(r15_thread, in_bytes(Thread::pending_exception_offset())), (int32_t)NULL_WORD);\n+  __ jcc(Assembler::notEqual, exception_pending);\n@@ -2569,3 +2395,2 @@\n-  if (!is_critical_native) {\n-    \/\/ forward the exception\n-    __ bind(exception_pending);\n+  \/\/ forward the exception\n+  __ bind(exception_pending);\n@@ -2573,3 +2398,2 @@\n-    \/\/ and forward the exception\n-    __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-  }\n+  \/\/ and forward the exception\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":45,"deletions":221,"binary":false,"changes":266,"status":"modified"},{"patch":"@@ -2131,1 +2131,1 @@\n-    const Register to       = c_rarg0;  \/\/ source array address\n+    const Register to       = c_rarg0;  \/\/ destination array address\n@@ -2134,0 +2134,1 @@\n+    __ mov(r11, count);\n@@ -2137,1 +2138,1 @@\n-    __ generate_fill(t, aligned, to, value, count, rax, xmm0);\n+    __ generate_fill(t, aligned, to, value, r11, rax, xmm0);\n@@ -7863,0 +7864,1 @@\n+    StubRoutines::x86::_vector_int_mask_cmp_bits = generate_vector_mask(\"vector_int_mask_cmp_bits\", 0x0000000100000001);\n@@ -8020,1 +8022,1 @@\n-    void *libsvml = NULL;\n+    void *libjsvml = NULL;\n@@ -8023,2 +8025,2 @@\n-    if (os::dll_locate_lib(dll_name, sizeof(dll_name), Arguments::get_dll_dir(), \"svml\")) {\n-      libsvml = os::dll_load(dll_name, ebuf, sizeof ebuf);\n+    if (os::dll_locate_lib(dll_name, sizeof(dll_name), Arguments::get_dll_dir(), \"jsvml\")) {\n+      libjsvml = os::dll_load(dll_name, ebuf, sizeof ebuf);\n@@ -8026,1 +8028,1 @@\n-    if (libsvml != NULL) {\n+    if (libjsvml != NULL) {\n@@ -8028,1 +8030,1 @@\n-      \/\/   All the methods are named as __svml_op<T><N>_ha_<VV>\n+      \/\/   All the methods are named as __jsvml_op<T><N>_ha_<VV>\n@@ -8039,2 +8041,2 @@\n-      \/\/      e.g. __svml_expf16_ha_z0 is the method for computing 16 element vector float exp using AVX 512 insns\n-      \/\/           __svml_exp8_ha_z0 is the method for computing 8 element vector double exp using AVX 512 insns\n+      \/\/      e.g. __jsvml_expf16_ha_z0 is the method for computing 16 element vector float exp using AVX 512 insns\n+      \/\/           __jsvml_exp8_ha_z0 is the method for computing 8 element vector double exp using AVX 512 insns\n@@ -8042,1 +8044,1 @@\n-      log_info(library)(\"Loaded library %s, handle \" INTPTR_FORMAT, JNI_LIB_PREFIX \"svml\" JNI_LIB_SUFFIX, p2i(libsvml));\n+      log_info(library)(\"Loaded library %s, handle \" INTPTR_FORMAT, JNI_LIB_PREFIX \"jsvml\" JNI_LIB_SUFFIX, p2i(libjsvml));\n@@ -8050,2 +8052,2 @@\n-          snprintf(ebuf, sizeof(ebuf), \"__svml_%sf16_ha_z0\", VectorSupport::svmlname[op]);\n-          StubRoutines::_vector_f_math[VectorSupport::VEC_SIZE_512][op] = (address)os::dll_lookup(libsvml, ebuf);\n+          snprintf(ebuf, sizeof(ebuf), \"__jsvml_%sf16_ha_z0\", VectorSupport::svmlname[op]);\n+          StubRoutines::_vector_f_math[VectorSupport::VEC_SIZE_512][op] = (address)os::dll_lookup(libjsvml, ebuf);\n@@ -8053,2 +8055,2 @@\n-          snprintf(ebuf, sizeof(ebuf), \"__svml_%s8_ha_z0\", VectorSupport::svmlname[op]);\n-          StubRoutines::_vector_d_math[VectorSupport::VEC_SIZE_512][op] = (address)os::dll_lookup(libsvml, ebuf);\n+          snprintf(ebuf, sizeof(ebuf), \"__jsvml_%s8_ha_z0\", VectorSupport::svmlname[op]);\n+          StubRoutines::_vector_d_math[VectorSupport::VEC_SIZE_512][op] = (address)os::dll_lookup(libjsvml, ebuf);\n@@ -8063,2 +8065,2 @@\n-        snprintf(ebuf, sizeof(ebuf), \"__svml_%sf4_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n-        StubRoutines::_vector_f_math[VectorSupport::VEC_SIZE_64][op] = (address)os::dll_lookup(libsvml, ebuf);\n+        snprintf(ebuf, sizeof(ebuf), \"__jsvml_%sf4_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n+        StubRoutines::_vector_f_math[VectorSupport::VEC_SIZE_64][op] = (address)os::dll_lookup(libjsvml, ebuf);\n@@ -8066,2 +8068,2 @@\n-        snprintf(ebuf, sizeof(ebuf), \"__svml_%sf4_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n-        StubRoutines::_vector_f_math[VectorSupport::VEC_SIZE_128][op] = (address)os::dll_lookup(libsvml, ebuf);\n+        snprintf(ebuf, sizeof(ebuf), \"__jsvml_%sf4_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n+        StubRoutines::_vector_f_math[VectorSupport::VEC_SIZE_128][op] = (address)os::dll_lookup(libjsvml, ebuf);\n@@ -8069,2 +8071,2 @@\n-        snprintf(ebuf, sizeof(ebuf), \"__svml_%sf8_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n-        StubRoutines::_vector_f_math[VectorSupport::VEC_SIZE_256][op] = (address)os::dll_lookup(libsvml, ebuf);\n+        snprintf(ebuf, sizeof(ebuf), \"__jsvml_%sf8_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n+        StubRoutines::_vector_f_math[VectorSupport::VEC_SIZE_256][op] = (address)os::dll_lookup(libjsvml, ebuf);\n@@ -8072,2 +8074,2 @@\n-        snprintf(ebuf, sizeof(ebuf), \"__svml_%s1_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n-        StubRoutines::_vector_d_math[VectorSupport::VEC_SIZE_64][op] = (address)os::dll_lookup(libsvml, ebuf);\n+        snprintf(ebuf, sizeof(ebuf), \"__jsvml_%s1_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n+        StubRoutines::_vector_d_math[VectorSupport::VEC_SIZE_64][op] = (address)os::dll_lookup(libjsvml, ebuf);\n@@ -8075,2 +8077,2 @@\n-        snprintf(ebuf, sizeof(ebuf), \"__svml_%s2_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n-        StubRoutines::_vector_d_math[VectorSupport::VEC_SIZE_128][op] = (address)os::dll_lookup(libsvml, ebuf);\n+        snprintf(ebuf, sizeof(ebuf), \"__jsvml_%s2_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n+        StubRoutines::_vector_d_math[VectorSupport::VEC_SIZE_128][op] = (address)os::dll_lookup(libjsvml, ebuf);\n@@ -8078,2 +8080,2 @@\n-        snprintf(ebuf, sizeof(ebuf), \"__svml_%s4_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n-        StubRoutines::_vector_d_math[VectorSupport::VEC_SIZE_256][op] = (address)os::dll_lookup(libsvml, ebuf);\n+        snprintf(ebuf, sizeof(ebuf), \"__jsvml_%s4_ha_%s\", VectorSupport::svmlname[op], avx_sse_str);\n+        StubRoutines::_vector_d_math[VectorSupport::VEC_SIZE_256][op] = (address)os::dll_lookup(libjsvml, ebuf);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":28,"deletions":26,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -1472,0 +1472,8 @@\n+#ifdef COMPILER2\n+  if (FLAG_IS_DEFAULT(OptimizeFill)) {\n+    if (MaxVectorSize < 32 || !VM_Version::supports_avx512vlbw()) {\n+      OptimizeFill = false;\n+    }\n+  }\n+#endif\n+\n@@ -1588,6 +1596,0 @@\n-  if (FLAG_IS_DEFAULT(OptimizeFill)) {\n-    \/\/ 8247307: On x86, the auto-vectorized loop array fill code shows\n-    \/\/ better performance than the array fill stubs. We should reenable\n-    \/\/ this after the x86 stubs get improved.\n-    OptimizeFill = false;\n-  }\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":8,"deletions":6,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1377,0 +1377,1 @@\n+  static address vector_int_mask_cmp_bits() { return StubRoutines::x86::vector_int_mask_cmp_bits(); }\n@@ -1559,0 +1560,1 @@\n+    case Op_VectorMaskToLong:\n@@ -1805,0 +1807,2 @@\n+    case Op_LoadVectorGatherMasked:\n+    case Op_StoreVectorScatterMasked:\n@@ -1806,1 +1810,1 @@\n-      if(bt == T_BYTE || bt == T_SHORT) {\n+      if(is_subword_type(bt)) {\n@@ -1817,0 +1821,11 @@\n+    case Op_MaskAll:\n+      if (!is_LP64 || !VM_Version::supports_evex()) {\n+        return false;\n+      }\n+      if ((vlen > 16 || is_subword_type(bt)) && !VM_Version::supports_avx512bw()) {\n+        return false;\n+      }\n+      if (size_in_bits < 512 && !VM_Version::supports_avx512vl()) {\n+        return false;\n+      }\n+      break;\n@@ -1826,0 +1841,142 @@\n+const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+  \/\/ ADLC based match_rule_supported routine checks for the existence of pattern based\n+  \/\/ on IR opcode. Most of the unary\/binary\/ternary masked operation share the IR nodes\n+  \/\/ of their non-masked counterpart with mask edge being the differentiator.\n+  \/\/ This routine does a strict check on the existence of masked operation patterns\n+  \/\/ by returning a default false value for all the other opcodes apart from the\n+  \/\/ ones whose masked instruction patterns are defined in this file.\n+  if (!match_rule_supported_vector(opcode, vlen, bt)) {\n+    return false;\n+  }\n+\n+  const bool is_LP64 = LP64_ONLY(true) NOT_LP64(false);\n+  int size_in_bits = vlen * type2aelembytes(bt) * BitsPerByte;\n+  if (size_in_bits != 512 && !VM_Version::supports_avx512vl()) {\n+    return false;\n+  }\n+  switch(opcode) {\n+    \/\/ Unary masked operations\n+    case Op_AbsVB:\n+    case Op_AbsVS:\n+      if(!VM_Version::supports_avx512bw()) {\n+        return false;  \/\/ Implementation limitation\n+      }\n+    case Op_AbsVI:\n+    case Op_AbsVL:\n+      return true;\n+\n+    \/\/ Ternary masked operations\n+    case Op_FmaVF:\n+    case Op_FmaVD:\n+      return true;\n+\n+    \/\/ Binary masked operations\n+    case Op_AddVB:\n+    case Op_AddVS:\n+    case Op_SubVB:\n+    case Op_SubVS:\n+    case Op_MulVS:\n+    case Op_LShiftVS:\n+    case Op_RShiftVS:\n+    case Op_URShiftVS:\n+      assert(size_in_bits == 512 || VM_Version::supports_avx512vl(), \"\");\n+      if (!VM_Version::supports_avx512bw()) {\n+        return false;  \/\/ Implementation limitation\n+      }\n+      return true;\n+\n+    case Op_MulVL:\n+      assert(size_in_bits == 512 || VM_Version::supports_avx512vl(), \"\");\n+      if (!VM_Version::supports_avx512dq()) {\n+        return false;  \/\/ Implementation limitation\n+      }\n+      return true;\n+\n+    case Op_AndV:\n+    case Op_OrV:\n+    case Op_XorV:\n+    case Op_RotateRightV:\n+    case Op_RotateLeftV:\n+      if (bt != T_INT && bt != T_LONG) {\n+        return false; \/\/ Implementation limitation\n+      }\n+      return true;\n+\n+    case Op_VectorLoadMask:\n+      assert(size_in_bits == 512 || VM_Version::supports_avx512vl(), \"\");\n+      if (is_subword_type(bt) && !VM_Version::supports_avx512bw()) {\n+        return false;\n+      }\n+      return true;\n+\n+    case Op_AddVI:\n+    case Op_AddVL:\n+    case Op_AddVF:\n+    case Op_AddVD:\n+    case Op_SubVI:\n+    case Op_SubVL:\n+    case Op_SubVF:\n+    case Op_SubVD:\n+    case Op_MulVI:\n+    case Op_MulVF:\n+    case Op_MulVD:\n+    case Op_DivVF:\n+    case Op_DivVD:\n+    case Op_SqrtVF:\n+    case Op_SqrtVD:\n+    case Op_LShiftVI:\n+    case Op_LShiftVL:\n+    case Op_RShiftVI:\n+    case Op_RShiftVL:\n+    case Op_URShiftVI:\n+    case Op_URShiftVL:\n+    case Op_LoadVectorMasked:\n+    case Op_StoreVectorMasked:\n+    case Op_LoadVectorGatherMasked:\n+    case Op_StoreVectorScatterMasked:\n+      return true;\n+\n+    case Op_MaxV:\n+    case Op_MinV:\n+      if (is_subword_type(bt) && !VM_Version::supports_avx512bw()) {\n+        return false; \/\/ Implementation limitation\n+      }\n+      if (is_floating_point_type(bt)) {\n+        return false; \/\/ Implementation limitation\n+      }\n+      return true;\n+\n+    case Op_VectorMaskCmp:\n+      if (is_subword_type(bt) && !VM_Version::supports_avx512bw()) {\n+        return false; \/\/ Implementation limitation\n+      }\n+      return true;\n+\n+    case Op_VectorRearrange:\n+      if (bt == T_SHORT && !VM_Version::supports_avx512bw()) {\n+        return false; \/\/ Implementation limitation\n+      }\n+      if (bt == T_BYTE && !VM_Version::supports_avx512_vbmi()) {\n+        return false; \/\/ Implementation limitation\n+      } else if ((bt == T_INT || bt == T_FLOAT) && size_in_bits < 256) {\n+        return false; \/\/ Implementation limitation\n+      }\n+      return true;\n+\n+    \/\/ Binary Logical operations\n+    case Op_AndVMask:\n+    case Op_OrVMask:\n+    case Op_XorVMask:\n+      if (vlen > 16 && !VM_Version::supports_avx512bw()) {\n+        return false; \/\/ Implementation limitation\n+      }\n+      return true;\n+\n+    case Op_MaskAll:\n+      return true;\n+\n+    default:\n+      return false;\n+  }\n+}\n+\n@@ -1890,1 +2047,1 @@\n-  return new TypeVectMask(TypeInt::BOOL, length);\n+  return new TypeVectMask(elemTy, length);\n@@ -3325,0 +3482,1 @@\n+\n@@ -3326,0 +3484,73 @@\n+instruct reinterpret_mask(kReg dst) %{\n+  predicate(n->bottom_type()->isa_vectmask() &&\n+            Matcher::vector_length(n) == Matcher::vector_length(n->in(1))); \/\/ dst == src\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(125);\n+  format %{ \"vector_reinterpret $dst\\t!\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct reinterpret_mask_W2B(kReg dst, kReg src, vec xtmp) %{\n+  predicate(UseAVX > 2 && Matcher::vector_length(n) != Matcher::vector_length(n->in(1)) &&\n+            n->bottom_type()->isa_vectmask() &&\n+            n->in(1)->bottom_type()->isa_vectmask() &&\n+            n->in(1)->bottom_type()->is_vectmask()->element_basic_type() == T_SHORT &&\n+            n->bottom_type()->is_vectmask()->element_basic_type() == T_BYTE); \/\/ dst == src\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP xtmp);\n+  format %{ \"vector_mask_reinterpret_W2B $dst $src\\t!\" %}\n+  ins_encode %{\n+     int src_sz = Matcher::vector_length(this, $src)*type2aelembytes(T_SHORT);\n+     int dst_sz = Matcher::vector_length(this)*type2aelembytes(T_BYTE);\n+     assert(src_sz == dst_sz , \"src and dst size mismatch\");\n+     int vlen_enc = vector_length_encoding(src_sz);\n+     __  evpmovm2w($xtmp$$XMMRegister, $src$$KRegister, vlen_enc);\n+     __  evpmovb2m($dst$$KRegister, $xtmp$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct reinterpret_mask_D2B(kReg dst, kReg src, vec xtmp) %{\n+  predicate(UseAVX > 2 && Matcher::vector_length(n) != Matcher::vector_length(n->in(1)) &&\n+            n->bottom_type()->isa_vectmask() &&\n+            n->in(1)->bottom_type()->isa_vectmask() &&\n+            (n->in(1)->bottom_type()->is_vectmask()->element_basic_type() == T_INT ||\n+             n->in(1)->bottom_type()->is_vectmask()->element_basic_type() == T_FLOAT) &&\n+            n->bottom_type()->is_vectmask()->element_basic_type() == T_BYTE); \/\/ dst == src\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP xtmp);\n+  format %{ \"vector_mask_reinterpret_D2B $dst $src\\t!\" %}\n+  ins_encode %{\n+     int src_sz = Matcher::vector_length(this, $src)*type2aelembytes(T_INT);\n+     int dst_sz = Matcher::vector_length(this)*type2aelembytes(T_BYTE);\n+     assert(src_sz == dst_sz , \"src and dst size mismatch\");\n+     int vlen_enc = vector_length_encoding(src_sz);\n+     __  evpmovm2d($xtmp$$XMMRegister, $src$$KRegister, vlen_enc);\n+     __  evpmovb2m($dst$$KRegister, $xtmp$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct reinterpret_mask_Q2B(kReg dst, kReg src, vec xtmp) %{\n+  predicate(UseAVX > 2 && Matcher::vector_length(n) != Matcher::vector_length(n->in(1)) &&\n+            n->bottom_type()->isa_vectmask() &&\n+            n->in(1)->bottom_type()->isa_vectmask() &&\n+            (n->in(1)->bottom_type()->is_vectmask()->element_basic_type() == T_LONG ||\n+             n->in(1)->bottom_type()->is_vectmask()->element_basic_type() == T_DOUBLE) &&\n+            n->bottom_type()->is_vectmask()->element_basic_type() == T_BYTE); \/\/ dst == src\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP xtmp);\n+  format %{ \"vector_mask_reinterpret_Q2B $dst $src\\t!\" %}\n+  ins_encode %{\n+     int src_sz = Matcher::vector_length(this, $src)*type2aelembytes(T_LONG);\n+     int dst_sz = Matcher::vector_length(this)*type2aelembytes(T_BYTE);\n+     assert(src_sz == dst_sz , \"src and dst size mismatch\");\n+     int vlen_enc = vector_length_encoding(src_sz);\n+     __  evpmovm2q($xtmp$$XMMRegister, $src$$KRegister, vlen_enc);\n+     __  evpmovb2m($dst$$KRegister, $xtmp$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n@@ -3328,1 +3559,2 @@\n-  predicate(Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1))); \/\/ dst == src\n+  predicate(!n->bottom_type()->isa_vectmask() &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1))); \/\/ dst == src\n@@ -3363,0 +3595,1 @@\n+            !n->bottom_type()->isa_vectmask() &&\n@@ -3378,0 +3611,1 @@\n+            !n->bottom_type()->isa_vectmask() &&\n@@ -3395,1 +3629,2 @@\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)) > Matcher::vector_length_in_bytes(n)); \/\/ src > dst\n+  predicate(!n->bottom_type()->isa_vectmask() &&\n+            Matcher::vector_length_in_bytes(n->in(1)) > Matcher::vector_length_in_bytes(n)); \/\/ src > dst\n@@ -3597,1 +3832,1 @@\n-  predicate(Matcher::vector_length_in_bytes(n) <= 32);\n+  predicate(!VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n) <= 32);\n@@ -3622,1 +3857,1 @@\n-  predicate(Matcher::vector_length_in_bytes(n) == 64);\n+  predicate(VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64);\n@@ -3625,1 +3860,1 @@\n-  format %{ \"load_vector_gather $dst, $mem, $idx\\t! using $tmp and k2 as TEMP\" %}\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t! using $tmp and ktmp as TEMP\" %}\n@@ -3641,0 +3876,18 @@\n+instruct evgather_masked(vec dst, memory mem, vec idx, kReg mask, kReg ktmp, rRegP tmp) %{\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx mask)));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP ktmp);\n+  format %{ \"load_vector_gather_masked $dst, $mem, $idx, $mask\\t! using $tmp and ktmp as TEMP\" %}\n+  ins_encode %{\n+    assert(UseAVX > 2, \"sanity\");\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType elem_bt = Matcher::vector_element_basic_type(this);\n+    assert(!is_subword_type(elem_bt), \"sanity\"); \/\/ T_INT, T_LONG, T_FLOAT, T_DOUBLE\n+    \/\/ Note: Since gather instruction partially updates the opmask register used\n+    \/\/ for predication hense moving mask operand to a temporary.\n+    __ kmovwl($ktmp$$KRegister, $mask$$KRegister);\n+    __ vpxor($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    __ lea($tmp$$Register, $mem$$Address);\n+    __ evgather(elem_bt, $dst$$XMMRegister, $ktmp$$KRegister, $tmp$$Register, $idx$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n@@ -3664,0 +3917,18 @@\n+instruct scatter_masked(memory mem, vec src, vec idx, kReg mask, kReg ktmp, rRegP tmp) %{\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx mask))));\n+  effect(TEMP tmp, TEMP ktmp);\n+  format %{ \"store_vector_scatter_masked $mem, $idx, $src, $mask\\t!\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType elem_bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(Matcher::vector_length_in_bytes(this, $src) >= 16, \"sanity\");\n+    assert(!is_subword_type(elem_bt), \"sanity\"); \/\/ T_INT, T_LONG, T_FLOAT, T_DOUBLE\n+    \/\/ Note: Since scatter instruction partially updates the opmask register used\n+    \/\/ for predication hense moving mask operand to a temporary.\n+    __ kmovwl($ktmp$$KRegister, $mask$$KRegister);\n+    __ lea($tmp$$Register, $mem$$Address);\n+    __ evscatter(elem_bt, $tmp$$Register, $idx$$XMMRegister, $ktmp$$KRegister, $src$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -3909,1 +4180,1 @@\n-  predicate(UseAVX > 0);\n+  predicate(UseAVX > 0 && Matcher::vector_length_in_bytes(n) >= 16);\n@@ -5875,0 +6146,1 @@\n+  ins_cost(400);\n@@ -5887,0 +6159,1 @@\n+  ins_cost(400);\n@@ -5899,0 +6172,1 @@\n+  ins_cost(400);\n@@ -5911,0 +6185,1 @@\n+  ins_cost(400);\n@@ -6919,1 +7194,2 @@\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)->in(1)) >=  8 && \/\/ src1\n+  predicate(n->bottom_type()->isa_vectmask() == NULL &&\n+            Matcher::vector_length_in_bytes(n->in(1)->in(1)) >=  8 && \/\/ src1\n@@ -6936,1 +7212,1 @@\n-instruct evcmpFD(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n+instruct evcmpFD64(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n@@ -6938,0 +7214,1 @@\n+            n->bottom_type()->isa_vectmask() == NULL &&\n@@ -6957,0 +7234,19 @@\n+instruct evcmpFD(kReg dst, vec src1, vec src2, immI8 cond) %{\n+  predicate(n->bottom_type()->isa_vectmask() &&\n+            is_floating_point_type(Matcher::vector_element_basic_type(n->in(1)->in(1)))); \/\/ src1 T_FLOAT, T_DOUBLE\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  format %{ \"vector_compare_evex $dst,$src1,$src2,$cond\\t!\" %}\n+  ins_encode %{\n+    assert(bottom_type()->isa_vectmask(), \"TypeVectMask expected\");\n+    int vlen_enc = vector_length_encoding(this, $src1);\n+    Assembler::ComparisonPredicateFP cmp = booltest_pred_to_comparison_pred_fp($cond$$constant);\n+    KRegister mask = k0; \/\/ The comparison itself is not being masked.\n+    if (Matcher::vector_element_basic_type(this, $src1) == T_FLOAT) {\n+      __ evcmpps($dst$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+    } else {\n+      __ evcmppd($dst$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -6958,1 +7254,1 @@\n-  predicate((UseAVX <= 2 || !VM_Version::supports_avx512vl()) &&\n+  predicate(n->bottom_type()->isa_vectmask() == NULL &&\n@@ -6976,1 +7272,1 @@\n-  predicate((UseAVX == 2 || !VM_Version::supports_avx512vl()) &&\n+  predicate(n->bottom_type()->isa_vectmask() == NULL &&\n@@ -6995,1 +7291,1 @@\n-  predicate((UseAVX == 2 || !VM_Version::supports_avx512vl()) &&\n+  predicate(n->bottom_type()->isa_vectmask() == NULL &&\n@@ -7012,3 +7308,2 @@\n-instruct evcmp(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n-  predicate(UseAVX > 2 &&\n-            (VM_Version::supports_avx512vl() ||\n+instruct vcmpu64(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n+  predicate((n->bottom_type()->isa_vectmask() == NULL &&\n@@ -7030,0 +7325,33 @@\n+    switch (src1_elem_bt) {\n+      case T_INT: {\n+        __ evpcmpd($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n+        __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        break;\n+      }\n+      case T_LONG: {\n+        __ evpcmpq($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n+        __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        break;\n+      }\n+      default: assert(false, \"%s\", type2name(src1_elem_bt));\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\n+instruct evcmp(kReg dst, vec src1, vec src2, immI8 cond) %{\n+  predicate(n->bottom_type()->isa_vectmask() &&\n+            is_integral_type(Matcher::vector_element_basic_type(n->in(1)->in(1)))); \/\/ src1\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  format %{ \"vector_compared_evex $dst,$src1,$src2,$cond\\t!\" %}\n+  ins_encode %{\n+    assert(UseAVX > 2, \"required\");\n+    assert(bottom_type()->isa_vectmask(), \"TypeVectMask expected\");\n+\n+    int vlen_enc = vector_length_encoding(this, $src1);\n+    Assembler::ComparisonPredicate cmp = booltest_pred_to_comparison_pred($cond$$constant);\n+    bool is_unsigned = is_unsigned_booltest_pred($cond$$constant);\n+    BasicType src1_elem_bt = Matcher::vector_element_basic_type(this, $src1);\n+\n+    \/\/ Comparison i\n@@ -7032,2 +7360,1 @@\n-        __ evpcmpb($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n-        __ evmovdqub($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpb($dst$$KRegister, k0, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n@@ -7037,2 +7364,1 @@\n-        __ evpcmpw($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n-        __ evmovdquw($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpw($dst$$KRegister, k0, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n@@ -7042,2 +7368,1 @@\n-        __ evpcmpd($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n-        __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpd($dst$$KRegister, k0, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n@@ -7047,2 +7372,1 @@\n-        __ evpcmpq($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n-        __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpq($dst$$KRegister, k0, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n@@ -7201,0 +7525,1 @@\n+            n->in(2)->bottom_type()->isa_vectmask() == NULL &&\n@@ -7214,0 +7539,1 @@\n+            n->in(2)->bottom_type()->isa_vectmask() == NULL &&\n@@ -7226,1 +7552,2 @@\n-  predicate(Matcher::vector_length_in_bytes(n) == 64);\n+  predicate(Matcher::vector_length_in_bytes(n) == 64 &&\n+            n->in(2)->bottom_type()->isa_vectmask() == NULL);\n@@ -7239,0 +7566,16 @@\n+\n+instruct evblendvp64_masked(vec dst, vec src1, vec src2, kReg mask, rRegP scratch) %{\n+  predicate(n->in(2)->bottom_type()->isa_vectmask() &&\n+            (!is_subword_type(Matcher::vector_element_basic_type(n)) ||\n+             VM_Version::supports_avx512bw()));\n+  match(Set dst (VectorBlend (Binary src1 src2) mask));\n+  format %{ \"vector_blend  $dst,$src1,$src2,$mask\\t! using $scratch and k2 as TEMP\" %}\n+  effect(TEMP scratch);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType elem_bt = Matcher::vector_element_basic_type(this);\n+    __ evpblend(elem_bt, $dst$$XMMRegister, $mask$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -7243,0 +7586,1 @@\n+  ins_cost(450);\n@@ -7258,0 +7602,1 @@\n+  ins_cost(450);\n@@ -7274,0 +7619,1 @@\n+  ins_cost(250);\n@@ -7288,0 +7634,1 @@\n+  ins_cost(450);\n@@ -7360,1 +7707,2 @@\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)) >= 4 &&\n+  predicate(!VM_Version::supports_avx512bwdq() &&\n+            Matcher::vector_length_in_bytes(n->in(1)) >= 4 &&\n@@ -7365,1 +7713,1 @@\n-  format %{ \"vector_test $dst,$src1, $src2\\t! using $vtmp1, $vtmp2 and $cr as TEMP\" %}\n+  format %{ \"vptest_alltrue_lt16 $dst,$src1, $src2\\t! using $vtmp1, $vtmp2 and $cr as TEMP\" %}\n@@ -7375,2 +7723,3 @@\n-instruct vptest_alltrue(rRegI dst, legVec src1, legVec src2, rFlagsReg cr) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)) >= 16 &&\n+instruct vptest_alltrue_ge16(rRegI dst, legVec src1, legVec src2, rFlagsReg cr) %{\n+  predicate(!VM_Version::supports_avx512bwdq() &&\n+            Matcher::vector_length_in_bytes(n->in(1)) >= 16 &&\n@@ -7381,1 +7730,1 @@\n-  format %{ \"vector_test $dst,$src1, $src2\\t! using $cr as TEMP\" %}\n+  format %{ \"vptest_alltrue_ge16  $dst,$src1, $src2\\t! using $cr as TEMP\" %}\n@@ -7391,6 +7740,8 @@\n-instruct vptest_alltrue_evex(rRegI dst, legVec src1, legVec src2, kReg ktmp, rFlagsReg cr) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)) == 64 &&\n-            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n-  match(Set dst (VectorTest src1 src2 ));\n-  effect(KILL cr, TEMP ktmp);\n-  format %{ \"vector_test $dst,$src1, $src2\\t! using $cr as TEMP\" %}\n+instruct vptest_alltrue_lt8_evex(rRegI dst, kReg src1, kReg src2, kReg kscratch, rFlagsReg cr) %{\n+  predicate(VM_Version::supports_avx512bwdq() &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow &&\n+            n->in(1)->bottom_type()->isa_vectmask() &&\n+            Matcher::vector_length(n->in(1)) < 8);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(KILL cr, TEMP kscratch);\n+  format %{ \"vptest_alltrue_lt8_evex $dst,$src1,$src2\\t! using $cr as TEMP\" %}\n@@ -7398,4 +7749,24 @@\n-    int vlen = Matcher::vector_length_in_bytes(this, $src1);\n-    __ vectortest(BoolTest::overflow, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n-    __ setb(Assembler::carrySet, $dst$$Register);\n-    __ movzbl($dst$$Register, $dst$$Register);\n+    const MachNode* mask1 = static_cast<const MachNode*>(this->in(this->operand_index($src1)));\n+    const MachNode* mask2 = static_cast<const MachNode*>(this->in(this->operand_index($src2)));\n+    assert(0 == Type::cmp(mask1->bottom_type(), mask2->bottom_type()), \"\");\n+    uint masklen = Matcher::vector_length(this, $src1);\n+    __ alltrue($dst$$Register, masklen, $src1$$KRegister, $src2$$KRegister, $kscratch$$KRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\n+instruct vptest_alltrue_ge8_evex(rRegI dst, kReg src1, kReg src2, rFlagsReg cr) %{\n+  predicate(VM_Version::supports_avx512bwdq() &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow &&\n+            n->in(1)->bottom_type()->isa_vectmask() &&\n+            Matcher::vector_length(n->in(1)) >= 8);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(KILL cr);\n+  format %{ \"vptest_alltrue_ge8_evex $dst,$src1,$src2\\t! using $cr as TEMP\" %}\n+  ins_encode %{\n+    const MachNode* mask1 = static_cast<const MachNode*>(this->in(this->operand_index($src1)));\n+    const MachNode* mask2 = static_cast<const MachNode*>(this->in(this->operand_index($src2)));\n+    assert(0 == Type::cmp(mask1->bottom_type(), mask2->bottom_type()), \"\");\n+    uint masklen = Matcher::vector_length(this, $src1);\n+    __ alltrue($dst$$Register, masklen, $src1$$KRegister, $src2$$KRegister, knoreg);\n@@ -7406,0 +7777,1 @@\n+\n@@ -7407,1 +7779,2 @@\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)) >= 4 &&\n+  predicate(!VM_Version::supports_avx512bwdq() &&\n+            Matcher::vector_length_in_bytes(n->in(1)) >= 4 &&\n@@ -7412,1 +7785,1 @@\n-  format %{ \"vector_test_any_true $dst,$src1,$src2\\t! using $vtmp, $cr as TEMP\" %}\n+  format %{ \"vptest_anytrue_lt16 $dst,$src1,$src2\\t! using $vtmp, $cr as TEMP\" %}\n@@ -7422,2 +7795,3 @@\n-instruct vptest_anytrue(rRegI dst, legVec src1, legVec src2, rFlagsReg cr) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)) >= 16 &&\n+instruct vptest_anytrue_ge16(rRegI dst, legVec src1, legVec src2, rFlagsReg cr) %{\n+  predicate(!VM_Version::supports_avx512bwdq() &&\n+            Matcher::vector_length_in_bytes(n->in(1)) >= 16 &&\n@@ -7428,1 +7802,1 @@\n-  format %{ \"vector_test_any_true $dst,$src1,$src2\\t! using $cr as TEMP\" %}\n+  format %{ \"vptest_anytrue_ge16 $dst,$src1,$src2\\t! using $cr as TEMP\" %}\n@@ -7438,2 +7812,2 @@\n-instruct vptest_anytrue_evex(rRegI dst, legVec src1, legVec src2, kReg ktmp, rFlagsReg cr) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)) == 64 &&\n+instruct vptest_anytrue_evex(rRegI dst, kReg src1, kReg src2, rFlagsReg cr) %{\n+  predicate(VM_Version::supports_avx512bwdq() &&\n@@ -7441,3 +7815,3 @@\n-  match(Set dst (VectorTest src1 src2 ));\n-  effect(KILL cr, TEMP ktmp);\n-  format %{ \"vector_test_any_true $dst,$src1,$src2\\t! using $cr as TEMP\" %}\n+  match(Set dst (VectorTest src1 src2));\n+  effect(KILL cr);\n+  format %{ \"vptest_anytrue_lt8_evex $dst,$src1,$src2\\t! using $cr as TEMP\" %}\n@@ -7445,4 +7819,5 @@\n-    int vlen = Matcher::vector_length_in_bytes(this, $src1);\n-    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n-    __ setb(Assembler::notZero, $dst$$Register);\n-    __ movzbl($dst$$Register, $dst$$Register);\n+    const MachNode* mask1 = static_cast<const MachNode*>(this->in(this->operand_index($src1)));\n+    const MachNode* mask2 = static_cast<const MachNode*>(this->in(this->operand_index($src2)));\n+    assert(0 == Type::cmp(mask1->bottom_type(), mask2->bottom_type()), \"\");\n+    uint  masklen = Matcher::vector_length(this, $src1);\n+    __ anytrue($dst$$Register, masklen, $src1$$KRegister, $src2$$KRegister);\n@@ -7454,1 +7829,2 @@\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)->in(1)) >= 4 &&\n+  predicate(!VM_Version::supports_avx512bwdq() &&\n+            Matcher::vector_length_in_bytes(n->in(1)->in(1)) >= 4 &&\n@@ -7459,1 +7835,1 @@\n-  format %{ \"cmp_vector_test_any_true $src1,$src2\\t! using $vtmp as TEMP\" %}\n+  format %{ \"cmpvptest_anytrue_lt16 $src1,$src2\\t! using $vtmp as TEMP\" %}\n@@ -7467,2 +7843,3 @@\n-instruct cmpvptest_anytrue(rFlagsReg cr, legVec src1, legVec src2, immI_0 zero) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)->in(1)) >= 16 &&\n+instruct cmpvptest_anytrue_ge16(rFlagsReg cr, legVec src1, legVec src2, immI_0 zero) %{\n+  predicate(!VM_Version::supports_avx512bwdq() &&\n+            Matcher::vector_length_in_bytes(n->in(1)->in(1)) >= 16 &&\n@@ -7472,1 +7849,1 @@\n-  format %{ \"cmp_vector_test_any_true $src1,$src2\\t!\" %}\n+  format %{ \"cmpvptest_anytrue_ge16 $src1,$src2\\t!\" %}\n@@ -7480,2 +7857,2 @@\n-instruct cmpvptest_anytrue_evex(rFlagsReg cr, legVec src1, legVec src2, immI_0 zero, kReg ktmp) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(1)->in(1)) == 64 &&\n+instruct cmpvptest_anytrue_evex(rFlagsReg cr, kReg src1, kReg src2, immI_0 zero) %{\n+  predicate(VM_Version::supports_avx512bwdq() &&\n@@ -7484,2 +7861,1 @@\n-  effect(TEMP ktmp);\n-  format %{ \"cmp_vector_test_any_true $src1,$src2\\t!\" %}\n+  format %{ \"cmpvptest_anytrue_evex $src1,$src2\\t!\" %}\n@@ -7487,2 +7863,6 @@\n-    int vlen = Matcher::vector_length_in_bytes(this, $src1);\n-    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n+    uint masklen = Matcher::vector_length(this, $src1);\n+    const MachNode* mask1 = static_cast<const MachNode*>(this->in(this->operand_index($src1)));\n+    const MachNode* mask2 = static_cast<const MachNode*>(this->in(this->operand_index($src2)));\n+    assert(0 == Type::cmp(mask1->bottom_type(), mask2->bottom_type()), \"\");\n+    masklen = masklen < 8 ? 8 : masklen;\n+    __ ktest(masklen, $src1$$KRegister, $src2$$KRegister);\n@@ -7497,1 +7877,1 @@\n-  predicate(!VM_Version::supports_avx512vlbw());\n+  predicate(n->bottom_type()->isa_vectmask() == NULL && !VM_Version::supports_avx512vlbw());\n@@ -7500,1 +7880,1 @@\n-  format %{ \"vector_loadmask_byte $dst,$src\\n\\t\" %}\n+  format %{ \"vector_loadmask_byte $dst, $src\\n\\t\" %}\n@@ -7504,1 +7884,0 @@\n-\n@@ -7510,2 +7889,2 @@\n-instruct loadMask_evex(vec dst, vec src) %{\n-  predicate(VM_Version::supports_avx512vlbw());\n+instruct loadMask64(kReg dst, vec src, vec xtmp, rRegI tmp) %{\n+  predicate(n->bottom_type()->isa_vectmask() && !VM_Version::supports_avx512vlbw());\n@@ -7513,2 +7892,2 @@\n-  effect(TEMP dst);\n-  format %{ \"vector_loadmask_byte $dst,$src\\n\\t\" %}\n+  effect(TEMP xtmp, TEMP tmp);\n+  format %{ \"vector_loadmask_64byte $dst, $src\\t! using $xtmp and $tmp as TEMP\" %}\n@@ -7516,2 +7895,5 @@\n-    int vlen_in_bytes = Matcher::vector_length_in_bytes(this);\n-    BasicType elem_bt = Matcher::vector_element_basic_type(this);\n+    __ load_vector_mask($dst$$KRegister, $src$$XMMRegister, $xtmp$$XMMRegister,\n+                        $tmp$$Register, true, Assembler::AVX_512bit);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n@@ -7519,1 +7901,9 @@\n-    __ load_vector_mask($dst$$XMMRegister, $src$$XMMRegister, vlen_in_bytes, elem_bt, false);\n+instruct loadMask_evex(kReg dst, vec src,  vec xtmp) %{\n+  predicate(n->bottom_type()->isa_vectmask() && VM_Version::supports_avx512vlbw());\n+  match(Set dst (VectorLoadMask src));\n+  effect(TEMP xtmp);\n+  format %{ \"vector_loadmask_byte $dst, $src\\t! using $xtmp as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(in(1));\n+    __ load_vector_mask($dst$$KRegister, $src$$XMMRegister, $xtmp$$XMMRegister,\n+                        noreg, false, vlen_enc);\n@@ -7526,2 +7916,2 @@\n-instruct storeMask1B(vec dst, vec src, immI_1 size) %{\n-  predicate(Matcher::vector_length(n) < 64 || VM_Version::supports_avx512vlbw());\n+instruct vstoreMask1B(vec dst, vec src, immI_1 size) %{\n+  predicate(Matcher::vector_length(n) < 64 && n->in(1)->bottom_type()->isa_vectmask() == NULL);\n@@ -7529,1 +7919,1 @@\n-  format %{ \"vector_store_mask $dst,$src\\t!\" %}\n+  format %{ \"vector_store_mask $dst, $src \\t! elem size is $size byte[s]\" %}\n@@ -7531,2 +7921,3 @@\n-    assert(UseSSE >= 3, \"required\");\n-    if (Matcher::vector_length_in_bytes(this) <= 16) {\n+    int vlen = Matcher::vector_length(this);\n+    if (vlen <= 16 && UseAVX <= 2) {\n+      assert(UseSSE >= 3, \"required\");\n@@ -7535,1 +7926,1 @@\n-      assert(UseAVX >= 2, \"required\");\n+      assert(UseAVX > 0, \"required\");\n@@ -7543,2 +7934,2 @@\n-instruct storeMask2B(vec dst, vec src, immI_2 size) %{\n-  predicate(Matcher::vector_length(n) <= 8);\n+instruct vstoreMask2B(vec dst, vec src, vec xtmp, immI_2 size) %{\n+  predicate(Matcher::vector_length(n) <= 16 && n->in(1)->bottom_type()->isa_vectmask() == NULL);\n@@ -7546,14 +7937,2 @@\n-  format %{ \"vector_store_mask $dst,$src\\n\\t\" %}\n-  ins_encode %{\n-    assert(UseSSE >= 3, \"required\");\n-    __ pabsw($dst$$XMMRegister, $src$$XMMRegister);\n-    __ packsswb($dst$$XMMRegister, $dst$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct vstoreMask2B(vec dst, vec src, immI_2 size) %{\n-  predicate(Matcher::vector_length(n) == 16 && !VM_Version::supports_avx512bw());\n-  match(Set dst (VectorStoreMask src size));\n-  effect(TEMP dst);\n-  format %{ \"vector_store_mask $dst,$src\\t!\" %}\n+  effect(TEMP_DEF dst, TEMP xtmp);\n+  format %{ \"vector_store_mask $dst, $src \\t! elem size is $size byte[s]\" %}\n@@ -7562,3 +7941,12 @@\n-    __ vextracti128($dst$$XMMRegister, $src$$XMMRegister, 0x1);\n-    __ vpacksswb($dst$$XMMRegister, $src$$XMMRegister, $dst$$XMMRegister,vlen_enc);\n-    __ vpabsb($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    int vlen = Matcher::vector_length(this);\n+    if (vlen <= 8) {\n+      assert(UseSSE >= 3, \"required\");\n+      __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n+      __ pabsw($dst$$XMMRegister, $src$$XMMRegister);\n+      __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n+    } else {\n+      assert(UseAVX > 0, \"required\");\n+      __ vextracti128($dst$$XMMRegister, $src$$XMMRegister, 0x1);\n+      __ vpacksswb($dst$$XMMRegister, $src$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+      __ vpabsb($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    }\n@@ -7569,2 +7957,2 @@\n-instruct vstoreMask2B_evex(vec dst, vec src, immI_2 size) %{\n-  predicate(VM_Version::supports_avx512bw());\n+instruct vstoreMask4B(vec dst, vec src, vec xtmp, immI_4 size) %{\n+  predicate(UseAVX <= 2 && Matcher::vector_length(n) <= 8 && n->in(1)->bottom_type()->isa_vectmask() == NULL);\n@@ -7572,1 +7960,2 @@\n-  format %{ \"vector_store_mask $dst,$src\\t!\" %}\n+  format %{ \"vector_store_mask $dst, $src \\t! elem size is $size byte[s]\" %}\n+  effect(TEMP_DEF dst, TEMP xtmp);\n@@ -7574,4 +7963,16 @@\n-    int src_vlen_enc = vector_length_encoding(this, $src);\n-    int dst_vlen_enc = vector_length_encoding(this);\n-    __ evpmovwb($dst$$XMMRegister, $src$$XMMRegister, src_vlen_enc);\n-    __ vpabsb($dst$$XMMRegister, $dst$$XMMRegister, dst_vlen_enc);\n+    int vlen_enc = Assembler::AVX_128bit;\n+    int vlen = Matcher::vector_length(this);\n+    if (vlen <= 4) {\n+      assert(UseSSE >= 3, \"required\");\n+      __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n+      __ pabsd($dst$$XMMRegister, $src$$XMMRegister);\n+      __ packusdw($dst$$XMMRegister, $xtmp$$XMMRegister);\n+      __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n+    } else {\n+      assert(UseAVX > 0, \"required\");\n+      __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n+      __ vextracti128($dst$$XMMRegister, $src$$XMMRegister, 0x1);\n+      __ vpackssdw($dst$$XMMRegister, $src$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+      __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n+      __ vpabsb($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    }\n@@ -7582,2 +7983,2 @@\n-instruct storeMask4B(vec dst, vec src, immI_4 size) %{\n-  predicate(Matcher::vector_length(n) <= 4 && UseAVX <= 2);\n+instruct storeMask8B(vec dst, vec src, vec xtmp, immI_8 size) %{\n+  predicate(UseAVX <= 2 && Matcher::vector_length(n) == 2);\n@@ -7585,1 +7986,2 @@\n-  format %{ \"vector_store_mask $dst,$src\\t!\" %}\n+  effect(TEMP_DEF dst, TEMP xtmp);\n+  format %{ \"vector_store_mask $dst, $src \\t! elem size is $size byte[s]\" %}\n@@ -7588,3 +7990,5 @@\n-    __ pabsd($dst$$XMMRegister, $src$$XMMRegister);\n-    __ packssdw($dst$$XMMRegister, $dst$$XMMRegister);\n-    __ packsswb($dst$$XMMRegister, $dst$$XMMRegister);\n+    __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n+    __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x8);\n+    __ pabsd($dst$$XMMRegister, $dst$$XMMRegister);\n+    __ packusdw($dst$$XMMRegister, $xtmp$$XMMRegister);\n+    __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7595,2 +7999,2 @@\n-instruct vstoreMask4B(vec dst, vec src, immI_4 size) %{\n-  predicate(Matcher::vector_length(n) == 8 && UseAVX <= 2);\n+instruct storeMask8B_avx(vec dst, vec src, immI_8 size, vec vtmp) %{\n+  predicate(UseAVX <= 2 && Matcher::vector_length(n) == 4);\n@@ -7598,2 +8002,2 @@\n-  format %{ \"vector_store_mask $dst,$src\\t!\" %}\n-  effect(TEMP dst);\n+  format %{ \"vector_store_mask $dst, $src \\t! elem size is $size byte[s], using $vtmp as TEMP\" %}\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -7602,3 +8006,6 @@\n-    __ vextracti128($dst$$XMMRegister, $src$$XMMRegister, 0x1);\n-    __ vpackssdw($dst$$XMMRegister, $src$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n-    __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    __ vpshufps($dst$$XMMRegister, $src$$XMMRegister, $src$$XMMRegister, 0x88, Assembler::AVX_256bit);\n+    __ vextracti128($vtmp$$XMMRegister, $dst$$XMMRegister, 0x1);\n+    __ vblendps($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, 0xC, vlen_enc);\n+    __ vpxor($vtmp$$XMMRegister, $vtmp$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n+    __ vpackssdw($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n+    __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n@@ -7610,2 +8017,2 @@\n-instruct vstoreMask4B_evex(vec dst, vec src, immI_4 size) %{\n-  predicate(UseAVX > 2);\n+instruct vstoreMask4B_evex_novectmask(vec dst, vec src, immI_4 size) %{\n+  predicate(UseAVX > 2 && n->in(1)->bottom_type()->isa_vectmask() == NULL);\n@@ -7613,1 +8020,1 @@\n-  format %{ \"vector_store_mask $dst,$src\\t!\" %}\n+  format %{ \"vector_store_mask $dst, $src \\t! elem size is $size byte[s]\" %}\n@@ -7626,2 +8033,2 @@\n-instruct storeMask8B(vec dst, vec src, immI_8 size) %{\n-  predicate(Matcher::vector_length(n) == 2 && UseAVX <= 2);\n+instruct vstoreMask8B_evex_novectmask(vec dst, vec src, immI_8 size) %{\n+  predicate(UseAVX > 2 && n->in(1)->bottom_type()->isa_vectmask() == NULL);\n@@ -7629,1 +8036,1 @@\n-  format %{ \"vector_store_mask $dst,$src\\t!\" %}\n+  format %{ \"vector_store_mask $dst, $src \\t! elem size is $size byte[s]\" %}\n@@ -7631,6 +8038,8 @@\n-    assert(UseSSE >= 3, \"required\");\n-    __ pshufd($dst$$XMMRegister, $src$$XMMRegister, 0x8);\n-    __ packssdw($dst$$XMMRegister, $dst$$XMMRegister);\n-    __ packsswb($dst$$XMMRegister, $dst$$XMMRegister);\n-    __ pabsb($dst$$XMMRegister, $dst$$XMMRegister);\n-  %}\n+    int src_vlen_enc = vector_length_encoding(this, $src);\n+    int dst_vlen_enc = vector_length_encoding(this);\n+    if (!VM_Version::supports_avx512vl()) {\n+      src_vlen_enc = Assembler::AVX_512bit;\n+    }\n+    __ evpmovqb($dst$$XMMRegister, $src$$XMMRegister, src_vlen_enc);\n+    __ vpabsb($dst$$XMMRegister, $dst$$XMMRegister, dst_vlen_enc);\n+  %}\n@@ -7640,5 +8049,5 @@\n-instruct storeMask8B_avx(vec dst, vec src, immI_8 size, legVec vtmp) %{\n-  predicate(Matcher::vector_length(n) == 4 && UseAVX <= 2);\n-  match(Set dst (VectorStoreMask src size));\n-  format %{ \"vector_store_mask $dst,$src\\t! using $vtmp as TEMP\" %}\n-  effect(TEMP dst, TEMP vtmp);\n+instruct vstoreMask_evex_vectmask(vec dst, kReg mask, immI size, rRegI tmp) %{\n+  predicate(n->in(1)->bottom_type()->isa_vectmask() && !VM_Version::supports_avx512vlbw());\n+  match(Set dst (VectorStoreMask mask size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vector_store_mask $dst, $mask \\t! elem size is $size byte[s]\" %}\n@@ -7646,7 +8055,4 @@\n-    int vlen_enc = Assembler::AVX_128bit;\n-    __ vpshufps($dst$$XMMRegister, $src$$XMMRegister, $src$$XMMRegister, 0x88, Assembler::AVX_256bit);\n-    __ vextracti128($vtmp$$XMMRegister, $dst$$XMMRegister, 0x1);\n-    __ vblendps($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, 0xC, vlen_enc);\n-    __ vpackssdw($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n-    __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n-    __ vpabsb($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    assert(Matcher::vector_length_in_bytes(this, $mask) == 64, \"\");\n+    __ evmovdqul($dst$$XMMRegister, $mask$$KRegister, ExternalAddress(vector_int_mask_cmp_bits()),\n+                 false, Assembler::AVX_512bit, $tmp$$Register);\n+    __ evpmovdb($dst$$XMMRegister, $dst$$XMMRegister, Assembler::AVX_512bit);\n@@ -7657,4 +8063,5 @@\n-instruct vstoreMask8B_evex(vec dst, vec src, immI_8 size) %{\n-  predicate(UseAVX > 2);\n-  match(Set dst (VectorStoreMask src size));\n-  format %{ \"vector_store_mask $dst,$src\\t!\" %}\n+instruct vstoreMask_evex(vec dst, kReg mask, immI size) %{\n+  predicate(n->in(1)->bottom_type()->isa_vectmask() && VM_Version::supports_avx512vlbw());\n+  match(Set dst (VectorStoreMask mask size));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vector_store_mask $dst, $mask \\t! elem size is $size byte[s]\" %}\n@@ -7662,5 +8069,1 @@\n-    int src_vlen_enc = vector_length_encoding(this, $src);\n-    if (!VM_Version::supports_avx512vl()) {\n-      src_vlen_enc = Assembler::AVX_512bit;\n-    }\n-    __ evpmovqb($dst$$XMMRegister, $src$$XMMRegister, src_vlen_enc);\n+    __ evpmovm2b($dst$$XMMRegister, $mask$$KRegister, dst_vlen_enc);\n@@ -7673,0 +8076,11 @@\n+instruct vmaskcast_evex(kReg dst) %{\n+  predicate(Matcher::vector_length(n) == Matcher::vector_length(n->in(1)));\n+  match(Set dst (VectorMaskCast dst));\n+  ins_cost(0);\n+  format %{ \"vector_mask_cast $dst\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(empty);\n+%}\n+\n@@ -8242,2 +8656,49 @@\n-instruct vmask_truecount_evex(rRegI dst, vec mask, rRegL tmp, kReg ktmp, vec xtmp) %{\n-  predicate(VM_Version::supports_avx512vlbw());\n+instruct vmask_tolong_evex(rRegL dst, kReg mask, rFlagsReg cr) %{\n+  predicate(n->in(1)->bottom_type()->isa_vectmask());\n+  match(Set dst (VectorMaskToLong mask));\n+  effect(TEMP dst, KILL cr);\n+  format %{ \"vector_tolong_evex $dst, $mask \\t! vector mask tolong\" %}\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n+    if (VM_Version::supports_avx512vlbw()) {\n+      __ kmovql($dst$$Register, $mask$$KRegister);\n+    } else {\n+      assert(mask_len <= 16, \"\");\n+      __ kmovwl($dst$$Register, $mask$$KRegister);\n+    }\n+    \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n+    \/\/ operations needs to be clipped.\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    if (mask_size < 16) {\n+      __ andq($dst$$Register, (((jlong)1 << mask_len) - 1));\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmask_tolong_avx(rRegL dst, vec mask, vec xtmp, rFlagsReg cr) %{\n+  predicate(n->in(1)->bottom_type()->isa_vectmask() == NULL &&\n+            n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN);\n+  match(Set dst (VectorMaskToLong mask));\n+  format %{ \"vector_tolong_avx $dst, $mask \\t! using $xtmp as TEMP\" %}\n+  effect(TEMP_DEF dst, TEMP xtmp, KILL cr);\n+  ins_encode %{\n+    int mask_len = Matcher::vector_length(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n+    __ vpsubb($xtmp$$XMMRegister, $xtmp$$XMMRegister, $mask$$XMMRegister, vlen_enc);\n+    __ vpmovmskb($dst$$Register, $xtmp$$XMMRegister, vlen_enc);\n+    \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n+    \/\/ operations needs to be clipped.\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    if (mask_size < 16) {\n+      __ andq($dst$$Register, (((jlong)1 << mask_len) - 1));\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmask_truecount_evex(rRegI dst, kReg mask, rRegL tmp, rFlagsReg cr) %{\n+  predicate(n->in(1)->bottom_type()->isa_vectmask());\n@@ -8245,2 +8706,2 @@\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP ktmp, TEMP xtmp);\n-  format %{ \"vector_truecount_evex $mask \\t! vector mask true count\" %}\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"vector_truecount_evex $dst, $mask \\t! using $tmp as TEMP\" %}\n@@ -8249,1 +8710,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8251,2 +8712,4 @@\n-    __ vector_mask_operation(opcode, $dst$$Register, $mask$$XMMRegister, $xtmp$$XMMRegister,\n-                             $tmp$$Register, $ktmp$$KRegister, mask_len, vlen_enc);\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register,\n+                             mask_len, mask_size, vlen_enc);\n@@ -8257,6 +8720,5 @@\n-instruct vmask_first_or_last_true_evex(rRegI dst, vec mask, rRegL tmp, kReg ktmp, vec xtmp, rFlagsReg cr) %{\n-  predicate(VM_Version::supports_avx512vlbw());\n-  match(Set dst (VectorMaskFirstTrue mask));\n-  match(Set dst (VectorMaskLastTrue mask));\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP ktmp, TEMP xtmp, KILL cr);\n-  format %{ \"vector_mask_first_or_last_true_evex $mask \\t! vector first\/last true location\" %}\n+instruct vmask_truecount_avx(rRegI dst, vec mask, rRegL tmp, vec xtmp, vec xtmp1, rFlagsReg cr) %{\n+  predicate(n->in(1)->bottom_type()->isa_vectmask() == NULL);\n+  match(Set dst (VectorMaskTrueCount mask));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP xtmp, TEMP xtmp1, KILL cr);\n+  format %{ \"vector_truecount_avx $dst, $mask \\t! using $tmp, $xtmp and $xtmp1 as TEMP\" %}\n@@ -8265,1 +8727,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8267,0 +8729,2 @@\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n@@ -8268,1 +8732,1 @@\n-                             $tmp$$Register, $ktmp$$KRegister, mask_len, vlen_enc);\n+                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, mask_size, vlen_enc);\n@@ -8273,5 +8737,6 @@\n-instruct vmask_truecount_avx(rRegI dst, vec mask, rRegL tmp, vec xtmp, vec xtmp1) %{\n-  predicate(!VM_Version::supports_avx512vlbw());\n-  match(Set dst (VectorMaskTrueCount mask));\n-  effect(TEMP_DEF dst, TEMP tmp, TEMP xtmp, TEMP xtmp1);\n-  format %{ \"vector_truecount_avx $mask \\t! vector mask true count\" %}\n+instruct vmask_first_or_last_true_evex(rRegI dst, kReg mask, rRegL tmp, rFlagsReg cr) %{\n+  predicate(n->in(1)->bottom_type()->isa_vectmask());\n+  match(Set dst (VectorMaskFirstTrue mask));\n+  match(Set dst (VectorMaskLastTrue mask));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"vector_mask_first_or_last_true_evex $dst, $mask \\t! using $tmp as TEMP\" %}\n@@ -8280,1 +8745,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8282,2 +8747,4 @@\n-    __ vector_mask_operation(opcode, $dst$$Register, $mask$$XMMRegister, $xtmp$$XMMRegister,\n-                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, vlen_enc);\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register, mask_len,\n+                             mask_size, vlen_enc);\n@@ -8289,1 +8756,1 @@\n-  predicate(!VM_Version::supports_avx512vlbw());\n+  predicate(n->in(1)->bottom_type()->isa_vectmask() == NULL);\n@@ -8293,1 +8760,1 @@\n-  format %{ \"vector_mask_first_or_last_true_avx $mask \\t! vector first\/last true location\" %}\n+  format %{ \"vector_mask_first_or_last_true_avx $dst, $mask \\t! using $tmp, $xtmp and $xtmp1 as TEMP\" %}\n@@ -8296,1 +8763,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8298,0 +8765,2 @@\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n@@ -8299,1 +8768,1 @@\n-                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, vlen_enc);\n+                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, mask_size, vlen_enc);\n@@ -8305,0 +8774,669 @@\n+\/\/ ---------------------------------- Vector Masked Operations ------------------------------------\n+\n+instruct vadd_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (AddVB (Binary dst src2) mask));\n+  match(Set dst (AddVS (Binary dst src2) mask));\n+  match(Set dst (AddVI (Binary dst src2) mask));\n+  match(Set dst (AddVL (Binary dst src2) mask));\n+  match(Set dst (AddVF (Binary dst src2) mask));\n+  match(Set dst (AddVD (Binary dst src2) mask));\n+  format %{ \"vpadd_masked $dst, $dst, $src2, $mask\\t! add masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vadd_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (AddVB (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (AddVS (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (AddVI (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (AddVL (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (AddVF (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (AddVD (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vpadd_masked $dst, $dst, $src2, $mask\\t! add masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vxor_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (XorV (Binary dst src2) mask));\n+  format %{ \"vxor_masked $dst, $dst, $src2, $mask\\t! xor masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vxor_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (XorV (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vxor_masked $dst, $dst, $src2, $mask\\t! xor masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vor_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (OrV (Binary dst src2) mask));\n+  format %{ \"vor_masked $dst, $dst, $src2, $mask\\t! or masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vor_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (OrV (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vor_masked $dst, $dst, $src2, $mask\\t! or masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vand_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (AndV (Binary dst src2) mask));\n+  format %{ \"vand_masked $dst, $dst, $src2, $mask\\t! and masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vand_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (AndV (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vand_masked $dst, $dst, $src2, $mask\\t! and masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vsub_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (SubVB (Binary dst src2) mask));\n+  match(Set dst (SubVS (Binary dst src2) mask));\n+  match(Set dst (SubVI (Binary dst src2) mask));\n+  match(Set dst (SubVL (Binary dst src2) mask));\n+  match(Set dst (SubVF (Binary dst src2) mask));\n+  match(Set dst (SubVD (Binary dst src2) mask));\n+  format %{ \"vpsub_masked $dst, $dst, $src2, $mask\\t! sub masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vsub_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (SubVB (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (SubVS (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (SubVI (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (SubVL (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (SubVF (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (SubVD (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vpsub_masked $dst, $dst, $src2, $mask\\t! sub masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmul_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (MulVS (Binary dst src2) mask));\n+  match(Set dst (MulVI (Binary dst src2) mask));\n+  match(Set dst (MulVL (Binary dst src2) mask));\n+  match(Set dst (MulVF (Binary dst src2) mask));\n+  match(Set dst (MulVD (Binary dst src2) mask));\n+  format %{ \"vpmul_masked $dst, $dst, $src2, $mask\\t! mul masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmul_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (MulVS (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (MulVI (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (MulVL (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (MulVF (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (MulVD (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vpmul_masked $dst, $dst, $src2, $mask\\t! mul masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vsqrt_reg_masked(vec dst, kReg mask) %{\n+  match(Set dst (SqrtVF dst mask));\n+  match(Set dst (SqrtVD dst mask));\n+  ins_cost(100);\n+  format %{ \"vpsqrt_masked $dst, $mask\\t! sqrt masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $dst$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vdiv_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (DivVF (Binary dst src2) mask));\n+  match(Set dst (DivVD (Binary dst src2) mask));\n+  format %{ \"vpdiv_masked $dst, $dst, $src2, $mask\\t! div masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vdiv_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (DivVF (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (DivVD (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vpdiv_masked $dst, $dst, $src2, $mask\\t! div masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\n+instruct vrol_imm_masked(vec dst, immI8 shift, kReg mask) %{\n+  match(Set dst (RotateLeftV (Binary dst shift) mask));\n+  match(Set dst (RotateRightV (Binary dst shift) mask));\n+  format %{ \"vprotate_imm_masked $dst, $dst, $shift, $mask\\t! rotate masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $shift$$constant, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vrol_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (RotateLeftV (Binary dst src2) mask));\n+  match(Set dst (RotateRightV (Binary dst src2) mask));\n+  format %{ \"vrotate_masked $dst, $dst, $src2, $mask\\t! rotate masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vlshift_imm_masked(vec dst, immI8 shift, kReg mask) %{\n+  match(Set dst (LShiftVS (Binary dst (LShiftCntV shift)) mask));\n+  match(Set dst (LShiftVI (Binary dst (LShiftCntV shift)) mask));\n+  match(Set dst (LShiftVL (Binary dst (LShiftCntV shift)) mask));\n+  format %{ \"vplshift_imm_masked $dst, $dst, $shift, $mask\\t! lshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $shift$$constant, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vlshift_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (LShiftVS (Binary dst src2) mask));\n+  match(Set dst (LShiftVI (Binary dst src2) mask));\n+  match(Set dst (LShiftVL (Binary dst src2) mask));\n+  format %{ \"vplshift_masked $dst, $dst, $src2, $mask\\t! lshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    bool is_varshift = !VectorNode::is_vshift_cnt_opcode(in(2)->isa_Mach()->ideal_Opcode());\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, is_varshift);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vlshift_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (LShiftVS (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (LShiftVI (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (LShiftVL (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vplshift_masked $dst, $dst, $src2, $mask\\t! lshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vrshift_imm_masked(vec dst, immI8 shift, kReg mask) %{\n+  match(Set dst (RShiftVS (Binary dst (RShiftCntV shift)) mask));\n+  match(Set dst (RShiftVI (Binary dst (RShiftCntV shift)) mask));\n+  match(Set dst (RShiftVL (Binary dst (RShiftCntV shift)) mask));\n+  format %{ \"vprshift_imm_masked $dst, $dst, $shift, $mask\\t! rshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $shift$$constant, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vrshift_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (RShiftVS (Binary dst src2) mask));\n+  match(Set dst (RShiftVI (Binary dst src2) mask));\n+  match(Set dst (RShiftVL (Binary dst src2) mask));\n+  format %{ \"vprshift_masked $dst, $dst, $src2, $mask\\t! rshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    bool is_varshift = !VectorNode::is_vshift_cnt_opcode(in(2)->isa_Mach()->ideal_Opcode());\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, is_varshift);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vrshift_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (RShiftVS (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (RShiftVI (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (RShiftVL (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vprshift_masked $dst, $dst, $src2, $mask\\t! rshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vurshift_imm_masked(vec dst, immI8 shift, kReg mask) %{\n+  match(Set dst (URShiftVS (Binary dst (RShiftCntV shift)) mask));\n+  match(Set dst (URShiftVI (Binary dst (RShiftCntV shift)) mask));\n+  match(Set dst (URShiftVL (Binary dst (RShiftCntV shift)) mask));\n+  format %{ \"vpurshift_imm_masked $dst, $dst, $shift, $mask\\t! urshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $shift$$constant, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vurshift_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (URShiftVS (Binary dst src2) mask));\n+  match(Set dst (URShiftVI (Binary dst src2) mask));\n+  match(Set dst (URShiftVL (Binary dst src2) mask));\n+  format %{ \"vpurshift_masked $dst, $dst, $src2, $mask\\t! urshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    bool is_varshift = !VectorNode::is_vshift_cnt_opcode(in(2)->isa_Mach()->ideal_Opcode());\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc, is_varshift);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vurshift_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (URShiftVS (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (URShiftVI (Binary dst (LoadVector src2)) mask));\n+  match(Set dst (URShiftVL (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vpurshift_masked $dst, $dst, $src2, $mask\\t! urshift masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmaxv_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (MaxV (Binary dst src2) mask));\n+  format %{ \"vpmax_masked $dst, $dst, $src2, $mask\\t! max masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmaxv_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (MaxV (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vpmax_masked $dst, $dst, $src2, $mask\\t! max masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vminv_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (MinV (Binary dst src2) mask));\n+  format %{ \"vpmin_masked $dst, $dst, $src2, $mask\\t! min masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vminv_mem_masked(vec dst, memory src2, kReg mask) %{\n+  match(Set dst (MinV (Binary dst (LoadVector src2)) mask));\n+  format %{ \"vpmin_masked $dst, $dst, $src2, $mask\\t! min masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vrearrangev_reg_masked(vec dst, vec src2, kReg mask) %{\n+  match(Set dst (VectorRearrange (Binary dst src2) mask));\n+  format %{ \"vprearrange_masked $dst, $dst, $src2, $mask\\t! rearrange masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $src2$$XMMRegister, false, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vabs_masked(vec dst, kReg mask) %{\n+  match(Set dst (AbsVB dst mask));\n+  match(Set dst (AbsVS dst mask));\n+  match(Set dst (AbsVI dst mask));\n+  match(Set dst (AbsVL dst mask));\n+  format %{ \"vabs_masked $dst, $mask \\t! vabs masked operation\" %}\n+  ins_cost(100);\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $dst$$XMMRegister, $dst$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vfma_reg_masked(vec dst, vec src2, vec src3, kReg mask) %{\n+  match(Set dst (FmaVF (Binary dst src2) (Binary src3 mask)));\n+  match(Set dst (FmaVD (Binary dst src2) (Binary src3 mask)));\n+  format %{ \"vfma_masked $dst, $src2, $src3, $mask \\t! vfma masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $src2$$XMMRegister, $src3$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vfma_mem_masked(vec dst, vec src2, memory src3, kReg mask) %{\n+  match(Set dst (FmaVF (Binary dst src2) (Binary (LoadVector src3) mask)));\n+  match(Set dst (FmaVD (Binary dst src2) (Binary (LoadVector src3) mask)));\n+  format %{ \"vfma_masked $dst, $src2, $src3, $mask \\t! vfma masked operation\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int opc = this->ideal_Opcode();\n+    __ evmasked_op(opc, bt, $mask$$KRegister, $dst$$XMMRegister,\n+                   $src2$$XMMRegister, $src3$$Address, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct evcmp_masked(kReg dst, vec src1, vec src2, immI8 cond, kReg mask, rRegP scratch) %{\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond mask)));\n+  effect(TEMP scratch);\n+  format %{ \"vcmp_masked $dst, $src1, $src2, $cond, $mask\\t! using $scratch as TEMP\" %}\n+  ins_encode %{\n+    assert(bottom_type()->isa_vectmask(), \"TypeVectMask expected\");\n+    int vlen_enc = vector_length_encoding(this, $src1);\n+    BasicType src1_elem_bt = Matcher::vector_element_basic_type(this, $src1);\n+\n+    \/\/ Comparison i\n+    switch (src1_elem_bt) {\n+      case T_BYTE: {\n+        bool is_unsigned = is_unsigned_booltest_pred($cond$$constant);\n+        Assembler::ComparisonPredicate cmp = booltest_pred_to_comparison_pred($cond$$constant);\n+        __ evpcmpb($dst$$KRegister, $mask$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n+        break;\n+      }\n+      case T_SHORT: {\n+        bool is_unsigned = is_unsigned_booltest_pred($cond$$constant);\n+        Assembler::ComparisonPredicate cmp = booltest_pred_to_comparison_pred($cond$$constant);\n+        __ evpcmpw($dst$$KRegister, $mask$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n+        break;\n+      }\n+      case T_INT: {\n+        bool is_unsigned = is_unsigned_booltest_pred($cond$$constant);\n+        Assembler::ComparisonPredicate cmp = booltest_pred_to_comparison_pred($cond$$constant);\n+        __ evpcmpd($dst$$KRegister, $mask$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n+        break;\n+      }\n+      case T_LONG: {\n+        bool is_unsigned = is_unsigned_booltest_pred($cond$$constant);\n+        Assembler::ComparisonPredicate cmp = booltest_pred_to_comparison_pred($cond$$constant);\n+        __ evpcmpq($dst$$KRegister, $mask$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n+        break;\n+      }\n+      case T_FLOAT: {\n+        Assembler::ComparisonPredicateFP cmp = booltest_pred_to_comparison_pred_fp($cond$$constant);\n+        __ evcmpps($dst$$KRegister, $mask$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        break;\n+      }\n+      case T_DOUBLE: {\n+        Assembler::ComparisonPredicateFP cmp = booltest_pred_to_comparison_pred_fp($cond$$constant);\n+        __ evcmppd($dst$$KRegister, $mask$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        break;\n+      }\n+      default: assert(false, \"%s\", type2name(src1_elem_bt)); break;\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+#ifdef _LP64\n+instruct mask_all_evexI_imm(kReg dst, immI cnt, rRegL tmp) %{\n+  match(Set dst (MaskAll cnt));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"mask_all_evexI $dst, $cnt \\t! using $tmp as TEMP\" %}\n+  ins_encode %{\n+    int vec_len = Matcher::vector_length(this);\n+    if (VM_Version::supports_avx512bw()) {\n+      __ movq($tmp$$Register, $cnt$$constant);\n+      __ kmovql($dst$$KRegister, $tmp$$Register);\n+      __ kshiftrql($dst$$KRegister, $dst$$KRegister, 64 - vec_len);\n+    } else {\n+      assert(vec_len <= 16, \"\");\n+      __ movq($tmp$$Register, $cnt$$constant);\n+      __ kmovwl($dst$$KRegister, $tmp$$Register);\n+      __ kshiftrwl($dst$$KRegister, $dst$$KRegister, 16 - vec_len);\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct mask_all_evexI(kReg dst, rRegI src, rRegL tmp) %{\n+  match(Set dst (MaskAll src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"mask_all_evexI $dst, $src \\t! using $tmp as TEMP\" %}\n+  ins_encode %{\n+    int vec_len = Matcher::vector_length(this);\n+    if (VM_Version::supports_avx512bw()) {\n+      __ movslq($tmp$$Register, $src$$Register);\n+      __ kmovql($dst$$KRegister, $tmp$$Register);\n+      __ kshiftrql($dst$$KRegister, $dst$$KRegister, 64 - vec_len);\n+    } else {\n+      assert(vec_len <= 16, \"\");\n+      __ kmovwl($dst$$KRegister, $src$$Register);\n+      __ kshiftrwl($dst$$KRegister, $dst$$KRegister, 16 - vec_len);\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct mask_all_evexL(kReg dst, rRegL src) %{\n+  match(Set dst (MaskAll src));\n+  effect(TEMP_DEF dst);\n+  format %{ \"mask_all_evexL $dst, $src \\t! mask all operation\" %}\n+  ins_encode %{\n+    int vec_len = Matcher::vector_length(this);\n+    if (VM_Version::supports_avx512bw()) {\n+      __ kmovql($dst$$KRegister, $src$$Register);\n+      __ kshiftrql($dst$$KRegister, $dst$$KRegister, 64 - vec_len);\n+    } else {\n+      assert(vec_len <= 16, \"\");\n+      __ kmovwl($dst$$KRegister, $src$$Register);\n+      __ kshiftrwl($dst$$KRegister, $dst$$KRegister, 16 - vec_len);\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct mask_not_immLT8(kReg dst, kReg src, rRegI rtmp, kReg ktmp, immI_M1 cnt) %{\n+  predicate(Matcher::vector_length(n) < 8 && VM_Version::supports_avx512dq());\n+  match(Set dst (XorVMask src (MaskAll cnt)));\n+  effect(TEMP_DEF dst, TEMP rtmp, TEMP ktmp);\n+  format %{ \"mask_not_LT8 $dst, $src, $cnt \\t!using $ktmp and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    uint masklen = Matcher::vector_length(this);\n+    __ knot(masklen, $dst$$KRegister, $src$$KRegister, $ktmp$$KRegister, $rtmp$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct mask_not_imm(kReg dst, kReg src, immI_M1 cnt) %{\n+  predicate((Matcher::vector_length(n) == 8 && VM_Version::supports_avx512dq()) ||\n+            (Matcher::vector_length(n) == 16) ||\n+            (Matcher::vector_length(n) > 16 && VM_Version::supports_avx512bw()));\n+  match(Set dst (XorVMask src (MaskAll cnt)));\n+  format %{ \"mask_not $dst, $src, $cnt \\t! mask not operation\" %}\n+  ins_encode %{\n+    uint masklen = Matcher::vector_length(this);\n+    __ knot(masklen, $dst$$KRegister, $src$$KRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+#endif\n+\n+instruct mask_opers_evex(kReg dst, kReg src1, kReg src2, kReg kscratch) %{\n+  match(Set dst (AndVMask src1 src2));\n+  match(Set dst (OrVMask src1 src2));\n+  match(Set dst (XorVMask src1 src2));\n+  effect(TEMP kscratch);\n+  format %{ \"mask_opers_evex $dst, $src1, $src2\\t! using $kscratch as TEMP\" %}\n+  ins_encode %{\n+    const MachNode* mask1 = static_cast<const MachNode*>(this->in(this->operand_index($src1)));\n+    const MachNode* mask2 = static_cast<const MachNode*>(this->in(this->operand_index($src2)));\n+    assert(0 == Type::cmp(mask1->bottom_type(), mask2->bottom_type()), \"\");\n+    uint masklen = Matcher::vector_length(this);\n+    masklen = (masklen < 16 && !VM_Version::supports_avx512dq()) ? 16 : masklen;\n+    __ masked_op(this->ideal_Opcode(), masklen, $dst$$KRegister, $src1$$KRegister, $src2$$KRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct castMM(kReg dst)\n+%{\n+  match(Set dst (CastVV dst));\n+\n+  size(0);\n+  format %{ \"# castVV of $dst\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_cost(0);\n+  ins_pipe(empty);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":1318,"deletions":180,"binary":false,"changes":1498,"status":"modified"},{"patch":"@@ -6659,0 +6659,1 @@\n+  match(StoreStoreFence);\n@@ -7203,0 +7204,1 @@\n+  predicate(UseSSE >= 1);\n@@ -7211,0 +7213,19 @@\n+  predicate(UseSSE >= 2);\n+  match(Set dst (CastDD dst));\n+  format %{ \"#castDD of $dst\" %}\n+  ins_encode( \/*empty encoding*\/ );\n+  ins_cost(0);\n+  ins_pipe( empty );\n+%}\n+\n+instruct castFF_PR( regFPR dst ) %{\n+  predicate(UseSSE < 1);\n+  match(Set dst (CastFF dst));\n+  format %{ \"#castFF of $dst\" %}\n+  ins_encode( \/*empty encoding*\/ );\n+  ins_cost(0);\n+  ins_pipe( empty );\n+%}\n+\n+instruct castDD_PR( regDPR dst ) %{\n+  predicate(UseSSE < 2);\n@@ -13129,1 +13150,19 @@\n-\/\/ Compare 2 longs and CMOVE ints.\n+instruct cmovII_reg_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, rRegI dst, rRegI src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n+  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n+  ins_cost(200);\n+  expand %{\n+    cmovII_reg_LTGE(cmp, flags, dst, src);\n+  %}\n+%}\n+\n+instruct cmovII_mem_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, rRegI dst, memory src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n+  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n+  ins_cost(250);\n+  expand %{\n+    cmovII_mem_LTGE(cmp, flags, dst, src);\n+  %}\n+%}\n+\n+\/\/ Compare 2 longs and CMOVE ptrs.\n@@ -13292,1 +13331,19 @@\n-\/\/ Compare 2 longs and CMOVE ints.\n+instruct cmovII_reg_EQNE_U(cmpOpU cmp, flagsReg_ulong_EQNE flags, rRegI dst, rRegI src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n+  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n+  ins_cost(200);\n+  expand %{\n+    cmovII_reg_EQNE(cmp, flags, dst, src);\n+  %}\n+%}\n+\n+instruct cmovII_mem_EQNE_U(cmpOpU cmp, flagsReg_ulong_EQNE flags, rRegI dst, memory src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n+  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n+  ins_cost(250);\n+  expand %{\n+    cmovII_mem_EQNE(cmp, flags, dst, src);\n+  %}\n+%}\n+\n+\/\/ Compare 2 longs and CMOVE ptrs.\n@@ -13448,5 +13505,3 @@\n-  format %{ \"CMOV$cmp $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cmp $dst.hi,$src.hi\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg_Lo2( dst, src ), enc_cmov(cmp), RegReg_Hi2( dst, src ) );\n-  ins_pipe( pipe_cmov_reg_long );\n+  expand %{\n+    cmovLL_reg_LEGT(cmp, flags, dst, src);\n+  %}\n@@ -13459,5 +13514,3 @@\n-  format %{ \"CMOV$cmp $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cmp $dst.hi,$src.hi+4\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegMem(dst, src), enc_cmov(cmp), RegMem_Hi(dst, src) );\n-  ins_pipe( pipe_cmov_reg_long );\n+  expand %{\n+    cmovLL_mem_LEGT(cmp, flags, dst, src);\n+  %}\n@@ -13487,0 +13540,18 @@\n+instruct cmovII_reg_LEGT_U(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, rRegI dst, rRegI src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n+  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n+  ins_cost(200);\n+  expand %{\n+    cmovII_reg_LEGT(cmp, flags, dst, src);\n+  %}\n+%}\n+\n+instruct cmovII_mem_LEGT_U(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, rRegI dst, memory src) %{\n+  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n+  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n+  ins_cost(250);\n+  expand %{\n+    cmovII_mem_LEGT(cmp, flags, dst, src);\n+  %}\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":83,"deletions":12,"binary":false,"changes":95,"status":"modified"},{"patch":"@@ -6805,0 +6805,1 @@\n+  match(StoreStoreFence);\n@@ -8558,0 +8559,13 @@\n+instruct umulHiL_rReg(rdx_RegL dst, no_rax_RegL src, rax_RegL rax, rFlagsReg cr)\n+%{\n+  match(Set dst (UMulHiL src rax));\n+  effect(USE_KILL rax, KILL cr);\n+\n+  ins_cost(300);\n+  format %{ \"mulq   RDX:RAX, RAX, $src\\t# umulhi\" %}\n+  ins_encode %{\n+    __ mulq($src$$Register);\n+  %}\n+  ins_pipe(ialu_reg_reg_alu0);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -75,2 +75,1 @@\n-\/\/ No performance work done here yet.\n-define_pd_global(bool, CompactStrings, false);\n+define_pd_global(bool, CompactStrings, true);\n","filename":"src\/hotspot\/cpu\/zero\/globals_zero.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -99,2 +99,1 @@\n-                                                BasicType ret_type,\n-                                                address critical_entry) {\n+                                                BasicType ret_type) {\n","filename":"src\/hotspot\/cpu\/zero\/sharedRuntime_zero.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2285,0 +2285,1 @@\n+  if (strcmp(name, \"RegVectMask\") == 0) size = globalAD->get_preproc_def(\"AARCH64\") ? 1 : 2;\n@@ -3518,1 +3519,2 @@\n-    \"StoreVector\", \"LoadVector\", \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorMasked\", \"StoreVectorMasked\",\n+    \"StoreVector\", \"LoadVector\", \"LoadVectorMasked\", \"StoreVectorMasked\",\n+    \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorGatherMasked\", \"StoreVectorScatterMasked\",\n@@ -3822,1 +3824,1 @@\n-\/\/-------------------------- has_commutative_op -------------------------------\n+\/\/-------------------------- count_commutative_op -------------------------------\n@@ -3828,7 +3830,1 @@\n-    \"AddVB\",\"AddVS\",\"AddVI\",\"AddVL\",\"AddVF\",\"AddVD\",\n-    \"AndV\",\n-    \"MaxV\", \"MinV\",\n-    \"MulVB\",\"MulVS\",\"MulVI\",\"MulVL\",\"MulVF\",\"MulVD\",\n-    \"OrV\",\n-    \"XorI\",\"XorL\",\n-    \"XorV\"\n+    \"XorI\",\"XorL\"\n@@ -3840,2 +3836,8 @@\n-  int cnt = sizeof(commut_op_list)\/sizeof(char*);\n-  if( _lChild && _rChild && (_lChild->_lChild || _rChild->_lChild) ) {\n+  static const char *commut_vector_op_list[] = {\n+    \"AddVB\", \"AddVS\", \"AddVI\", \"AddVL\", \"AddVF\", \"AddVD\",\n+    \"MulVB\", \"MulVS\", \"MulVI\", \"MulVL\", \"MulVF\", \"MulVD\",\n+    \"AndV\", \"OrV\", \"XorV\",\n+    \"MaxV\", \"MinV\"\n+  };\n+\n+  if (_lChild && _rChild && (_lChild->_lChild || _rChild->_lChild)) {\n@@ -3845,1 +3847,1 @@\n-    if( _rChild->_lChild == NULL && _rChild->_rChild == NULL ) {\n+    if (_rChild->_lChild == NULL && _rChild->_rChild == NULL) {\n@@ -3848,3 +3850,3 @@\n-      if ( form ) {\n-        OperandForm  *oper = form->is_operand();\n-        if( oper && oper->interface_type(globals) == Form::constant_interface )\n+      if (form) {\n+        OperandForm *oper = form->is_operand();\n+        if (oper && oper->interface_type(globals) == Form::constant_interface)\n@@ -3854,5 +3856,19 @@\n-    if( !is_const ) {\n-      for( int i=0; i<cnt; i++ ) {\n-        if( strcmp(_opType, commut_op_list[i]) == 0 ) {\n-          count++;\n-          _commutative_id = count; \/\/ id should be > 0\n+\n+    if (!is_const) {\n+      int scalar_cnt = sizeof(commut_op_list)\/sizeof(char*);\n+      int vector_cnt = sizeof(commut_vector_op_list)\/sizeof(char*);\n+      bool matched = false;\n+\n+      \/\/ Check the commutative vector op first. It's noncommutative if\n+      \/\/ the current node is a masked vector op, since a mask value\n+      \/\/ is added to the original vector node's input list and the original\n+      \/\/ first two inputs are packed into one BinaryNode. So don't swap\n+      \/\/ if one of the operands is a BinaryNode.\n+      for (int i = 0; i < vector_cnt; i++) {\n+        if (strcmp(_opType, commut_vector_op_list[i]) == 0) {\n+          if (strcmp(_lChild->_opType, \"Binary\") != 0 &&\n+              strcmp(_rChild->_opType, \"Binary\") != 0) {\n+            count++;\n+            _commutative_id = count; \/\/ id should be > 0\n+          }\n+          matched = true;\n@@ -3862,0 +3878,12 @@\n+\n+      \/\/ Then check the scalar op if the current op is not in\n+      \/\/ the commut_vector_op_list.\n+      if (!matched) {\n+        for (int i = 0; i < scalar_cnt; i++) {\n+          if (strcmp(_opType, commut_op_list[i]) == 0) {\n+            count++;\n+            _commutative_id = count; \/\/ id should be > 0\n+            break;\n+          }\n+        }\n+      }\n@@ -3864,1 +3892,1 @@\n-  if( _lChild )\n+  if (_lChild)\n@@ -3866,1 +3894,1 @@\n-  if( _rChild )\n+  if (_rChild)\n@@ -4092,0 +4120,1 @@\n+        strcmp(opType,\"MaskAll\")==0 ||\n@@ -4121,0 +4150,1 @@\n+    !strcmp(_opType,\"StoreStoreFence\") ||\n@@ -4203,1 +4233,1 @@\n-    \"LoadVectorGather\", \"StoreVectorScatter\",\n+    \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorGatherMasked\", \"StoreVectorScatterMasked\",\n@@ -4210,0 +4240,2 @@\n+    \/\/ Next are vector mask ops.\n+    \"MaskAll\", \"AndVMask\", \"OrVMask\", \"XorVMask\", \"VectorMaskCast\",\n@@ -4212,2 +4244,1 @@\n-    \"ExtractB\",\"ExtractUB\",\"ExtractC\",\"ExtractS\",\"ExtractI\",\"ExtractL\",\"ExtractF\",\"ExtractD\",\n-    \"VectorMaskCast\"\n+    \"ExtractB\",\"ExtractUB\",\"ExtractC\",\"ExtractS\",\"ExtractI\",\"ExtractL\",\"ExtractF\",\"ExtractD\"\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":56,"deletions":25,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -402,0 +402,5 @@\n+  \/\/ Dump compilation data to replay it.\n+  if (_directive->DumpReplayOption) {\n+    env()->dump_replay_data(env()->compile_id());\n+  }\n+\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -53,1 +53,0 @@\n-class LIR_OprDesc;\n@@ -57,1 +56,0 @@\n-typedef LIR_OprDesc* LIR_Opr;\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -65,4 +65,0 @@\n-class LIR_OprDesc;\n-typedef LIR_OprDesc* LIR_Opr;\n-\n-\n@@ -86,1 +82,1 @@\n-  friend class LIR_OprDesc;\n+  friend class LIR_Opr;\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -3616,0 +3616,1 @@\n+  case vmIntrinsics::_dsqrt_strict  : \/\/ fall through\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -38,2 +38,0 @@\n-class LIR_OprDesc;\n-typedef LIR_OprDesc* LIR_Opr;\n","filename":"src\/hotspot\/share\/c1\/c1_Instruction.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-Register LIR_OprDesc::as_register() const {\n+Register LIR_Opr::as_register() const {\n@@ -41,1 +41,1 @@\n-Register LIR_OprDesc::as_register_lo() const {\n+Register LIR_Opr::as_register_lo() const {\n@@ -45,1 +45,1 @@\n-Register LIR_OprDesc::as_register_hi() const {\n+Register LIR_Opr::as_register_hi() const {\n@@ -50,0 +50,1 @@\n+LIR_Opr LIR_OprFact::nullOpr = LIR_Opr();\n@@ -96,1 +97,1 @@\n-char LIR_OprDesc::type_char(BasicType t) {\n+char LIR_Opr::type_char(BasicType t) {\n@@ -125,1 +126,1 @@\n-void LIR_OprDesc::validate_type() const {\n+void LIR_Opr::validate_type() const {\n@@ -178,1 +179,1 @@\n-bool LIR_OprDesc::is_oop() const {\n+bool LIR_Opr::is_oop() const {\n@@ -1523,1 +1524,1 @@\n-  \/\/ guarantee(sizeof(LIR_OprDesc) == wordSize, \"may not have a v-table\");\n+  \/\/ guarantee(sizeof(LIR_Opr) == wordSize, \"may not have a v-table\");\n@@ -1624,2 +1625,2 @@\n-\/\/ LIR_OprDesc\n-void LIR_OprDesc::print() const {\n+\/\/ LIR_Opr\n+void LIR_Opr::print() const {\n@@ -1629,1 +1630,1 @@\n-void LIR_OprDesc::print(outputStream* out) const {\n+void LIR_Opr::print(outputStream* out) const {\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":11,"deletions":10,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -49,1 +49,0 @@\n-\/\/  LIR_OprDesc\n@@ -54,1 +53,0 @@\n-class LIR_OprDesc;\n@@ -59,0 +57,1 @@\n+class LIR_Opr;\n@@ -60,2 +59,0 @@\n-\n-typedef LIR_OprDesc* LIR_Opr;\n@@ -68,1 +65,1 @@\n-\/\/ define LIR_OprPtr early so LIR_OprDesc can refer to it\n+\/\/ define LIR_OprPtr early so LIR_Opr can refer to it\n@@ -187,1 +184,1 @@\n-\/\/ The class LIR_OprDesc represents a LIR instruction operand;\n+\/\/ The class LIR_Opr represents a LIR instruction operand;\n@@ -190,2 +187,3 @@\n-\/\/ structures (see above).\n-\/\/ Registers and stack locations are inlined into the this pointer\n+\/\/ structures (see above), and pointers are stored in the _value field (cast to\n+\/\/ an intptr_t).\n+\/\/ Registers and stack locations are represented inline as integers.\n@@ -194,1 +192,7 @@\n-class LIR_OprDesc: public CompilationResourceObj {\n+\/\/ Previously, this class was derived from CompilationResourceObj.\n+\/\/ However, deriving from any of the \"Obj\" types in allocation.hpp seems\n+\/\/ detrimental, since in some build modes it would add a vtable to this class,\n+\/\/ which make it no longer be a 1-word trivially-copyable wrapper object,\n+\/\/ which is the entire point of it.\n+\n+class LIR_Opr {\n@@ -209,0 +213,1 @@\n+  intptr_t _value;\n@@ -210,1 +215,1 @@\n-  intptr_t value() const                         { return (intptr_t) this; }\n+  intptr_t value() const                         { return _value; }\n@@ -282,0 +287,13 @@\n+  LIR_Opr() : _value(0) {}\n+  LIR_Opr(intptr_t val) : _value(val) {}\n+  LIR_Opr(LIR_OprPtr *val) : _value(reinterpret_cast<intptr_t>(val)) {}\n+  bool operator==(const LIR_Opr &other) const { return _value == other._value; }\n+  bool operator!=(const LIR_Opr &other) const { return _value != other._value; }\n+  explicit operator bool() const { return _value != 0; }\n+\n+  \/\/ UGLY HACK: make this value object look like a pointer (to itself). This\n+  \/\/ operator overload should be removed, and all callers updated from\n+  \/\/ `opr->fn()` to `opr.fn()`.\n+  const LIR_Opr* operator->() const { return this; }\n+  LIR_Opr* operator->() { return this; }\n+\n@@ -288,0 +306,1 @@\n+  static inline LIR_Opr nullOpr();\n@@ -347,1 +366,1 @@\n-  bool is_equal(LIR_Opr opr) const         { return this == opr; }\n+  bool is_equal(LIR_Opr opr) const         { return *this == opr; }\n@@ -426,1 +445,1 @@\n-  LIR_OprPtr* pointer()  const                   { assert(is_pointer(), \"type check\");      return (LIR_OprPtr*)this; }\n+  LIR_OprPtr* pointer() const { assert(_value != 0 && is_pointer(), \"nullness and type check\"); return (LIR_OprPtr*)_value; }\n@@ -463,2 +482,1 @@\n-\n-inline LIR_OprDesc::OprType as_OprType(BasicType type) {\n+inline LIR_Opr::OprType as_OprType(BasicType type) {\n@@ -466,4 +484,4 @@\n-  case T_INT:      return LIR_OprDesc::int_type;\n-  case T_LONG:     return LIR_OprDesc::long_type;\n-  case T_FLOAT:    return LIR_OprDesc::float_type;\n-  case T_DOUBLE:   return LIR_OprDesc::double_type;\n+  case T_INT:      return LIR_Opr::int_type;\n+  case T_LONG:     return LIR_Opr::long_type;\n+  case T_FLOAT:    return LIR_Opr::float_type;\n+  case T_DOUBLE:   return LIR_Opr::double_type;\n@@ -472,3 +490,3 @@\n-  case T_ARRAY:    return LIR_OprDesc::object_type;\n-  case T_ADDRESS:  return LIR_OprDesc::address_type;\n-  case T_METADATA: return LIR_OprDesc::metadata_type;\n+  case T_ARRAY:    return LIR_Opr::object_type;\n+  case T_ADDRESS:  return LIR_Opr::address_type;\n+  case T_METADATA: return LIR_Opr::metadata_type;\n@@ -476,1 +494,1 @@\n-  default: ShouldNotReachHere(); return LIR_OprDesc::unknown_type;\n+  default: ShouldNotReachHere(); return LIR_Opr::unknown_type;\n@@ -480,1 +498,1 @@\n-inline BasicType as_BasicType(LIR_OprDesc::OprType t) {\n+inline BasicType as_BasicType(LIR_Opr::OprType t) {\n@@ -482,8 +500,8 @@\n-  case LIR_OprDesc::int_type:     return T_INT;\n-  case LIR_OprDesc::long_type:    return T_LONG;\n-  case LIR_OprDesc::float_type:   return T_FLOAT;\n-  case LIR_OprDesc::double_type:  return T_DOUBLE;\n-  case LIR_OprDesc::object_type:  return T_OBJECT;\n-  case LIR_OprDesc::address_type: return T_ADDRESS;\n-  case LIR_OprDesc::metadata_type:return T_METADATA;\n-  case LIR_OprDesc::unknown_type: \/\/ fall through\n+  case LIR_Opr::int_type:     return T_INT;\n+  case LIR_Opr::long_type:    return T_LONG;\n+  case LIR_Opr::float_type:   return T_FLOAT;\n+  case LIR_Opr::double_type:  return T_DOUBLE;\n+  case LIR_Opr::object_type:  return T_OBJECT;\n+  case LIR_Opr::address_type: return T_ADDRESS;\n+  case LIR_Opr::metadata_type:return T_METADATA;\n+  case LIR_Opr::unknown_type: \/\/ fall through\n@@ -527,1 +545,1 @@\n-     , _index(LIR_OprDesc::illegalOpr())\n+     , _index(LIR_Opr::illegalOpr())\n@@ -534,1 +552,1 @@\n-     , _index(LIR_OprDesc::illegalOpr())\n+     , _index(LIR_Opr::illegalOpr())\n@@ -575,0 +593,1 @@\n+  static LIR_Opr nullOpr;\n@@ -577,4 +596,4 @@\n-    return (LIR_Opr)(intptr_t)((reg  << LIR_OprDesc::reg1_shift) |\n-                               LIR_OprDesc::int_type             |\n-                               LIR_OprDesc::cpu_register         |\n-                               LIR_OprDesc::single_size);\n+    return (LIR_Opr)(intptr_t)((reg  << LIR_Opr::reg1_shift) |\n+                               LIR_Opr::int_type             |\n+                               LIR_Opr::cpu_register         |\n+                               LIR_Opr::single_size);\n@@ -583,4 +602,4 @@\n-    return (LIR_Opr)(intptr_t)((reg  << LIR_OprDesc::reg1_shift) |\n-                               LIR_OprDesc::object_type          |\n-                               LIR_OprDesc::cpu_register         |\n-                               LIR_OprDesc::single_size);\n+    return (LIR_Opr)(intptr_t)((reg  << LIR_Opr::reg1_shift) |\n+                               LIR_Opr::object_type          |\n+                               LIR_Opr::cpu_register         |\n+                               LIR_Opr::single_size);\n@@ -589,4 +608,4 @@\n-    return (LIR_Opr)(intptr_t)((reg  << LIR_OprDesc::reg1_shift) |\n-                               LIR_OprDesc::address_type         |\n-                               LIR_OprDesc::cpu_register         |\n-                               LIR_OprDesc::single_size);\n+    return (LIR_Opr)(intptr_t)((reg  << LIR_Opr::reg1_shift) |\n+                               LIR_Opr::address_type         |\n+                               LIR_Opr::cpu_register         |\n+                               LIR_Opr::single_size);\n@@ -595,4 +614,4 @@\n-    return (LIR_Opr)(intptr_t)((reg  << LIR_OprDesc::reg1_shift) |\n-                               LIR_OprDesc::metadata_type        |\n-                               LIR_OprDesc::cpu_register         |\n-                               LIR_OprDesc::single_size);\n+    return (LIR_Opr)(intptr_t)((reg  << LIR_Opr::reg1_shift) |\n+                               LIR_Opr::metadata_type        |\n+                               LIR_Opr::cpu_register         |\n+                               LIR_Opr::single_size);\n@@ -602,5 +621,5 @@\n-    return (LIR_Opr)(intptr_t)((reg1 << LIR_OprDesc::reg1_shift) |\n-                               (reg2 << LIR_OprDesc::reg2_shift) |\n-                               LIR_OprDesc::long_type            |\n-                               LIR_OprDesc::cpu_register         |\n-                               LIR_OprDesc::double_size);\n+    return (LIR_Opr)(intptr_t)((reg1 << LIR_Opr::reg1_shift) |\n+                               (reg2 << LIR_Opr::reg2_shift) |\n+                               LIR_Opr::long_type            |\n+                               LIR_Opr::cpu_register         |\n+                               LIR_Opr::double_size);\n@@ -610,4 +629,4 @@\n-    return (LIR_Opr)(intptr_t)((reg  << LIR_OprDesc::reg1_shift) |\n-                               LIR_OprDesc::float_type           |\n-                               LIR_OprDesc::fpu_register         |\n-                               LIR_OprDesc::single_size);\n+    return (LIR_Opr)(intptr_t)((reg  << LIR_Opr::reg1_shift) |\n+                               LIR_Opr::float_type           |\n+                               LIR_Opr::fpu_register         |\n+                               LIR_Opr::single_size);\n@@ -621,4 +640,4 @@\n-    return (LIR_Opr)(intptr_t)((reg  << LIR_OprDesc::reg1_shift) |\n-                               LIR_OprDesc::float_type           |\n-                               LIR_OprDesc::cpu_register         |\n-                               LIR_OprDesc::single_size);\n+    return (LIR_Opr)(intptr_t)((reg  << LIR_Opr::reg1_shift) |\n+                               LIR_Opr::float_type           |\n+                               LIR_Opr::cpu_register         |\n+                               LIR_Opr::single_size);\n@@ -627,5 +646,5 @@\n-    return (LIR_Opr)(intptr_t)((reg1 << LIR_OprDesc::reg1_shift) |\n-                               (reg2 << LIR_OprDesc::reg2_shift) |\n-                               LIR_OprDesc::double_type          |\n-                               LIR_OprDesc::cpu_register         |\n-                               LIR_OprDesc::double_size);\n+    return (LIR_Opr)(intptr_t)((reg1 << LIR_Opr::reg1_shift) |\n+                               (reg2 << LIR_Opr::reg2_shift) |\n+                               LIR_Opr::double_type          |\n+                               LIR_Opr::cpu_register         |\n+                               LIR_Opr::double_size);\n@@ -637,5 +656,5 @@\n-    return (LIR_Opr)(intptr_t)((reg << LIR_OprDesc::reg1_shift) |\n-                               LIR_OprDesc::float_type          |\n-                               LIR_OprDesc::fpu_register        |\n-                               LIR_OprDesc::single_size         |\n-                               LIR_OprDesc::is_xmm_mask);\n+    return (LIR_Opr)(intptr_t)((reg << LIR_Opr::reg1_shift) |\n+                               LIR_Opr::float_type          |\n+                               LIR_Opr::fpu_register        |\n+                               LIR_Opr::single_size         |\n+                               LIR_Opr::is_xmm_mask);\n@@ -644,6 +663,6 @@\n-    return (LIR_Opr)(intptr_t)((reg << LIR_OprDesc::reg1_shift) |\n-                               (reg << LIR_OprDesc::reg2_shift) |\n-                               LIR_OprDesc::double_type         |\n-                               LIR_OprDesc::fpu_register        |\n-                               LIR_OprDesc::double_size         |\n-                               LIR_OprDesc::is_xmm_mask);\n+    return (LIR_Opr)(intptr_t)((reg << LIR_Opr::reg1_shift) |\n+                               (reg << LIR_Opr::reg2_shift) |\n+                               LIR_Opr::double_type         |\n+                               LIR_Opr::fpu_register        |\n+                               LIR_Opr::double_size         |\n+                               LIR_Opr::is_xmm_mask);\n@@ -654,1 +673,1 @@\n-    if (index > LIR_OprDesc::vreg_max) {\n+    if (index > LIR_Opr::vreg_max) {\n@@ -664,5 +683,5 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift)  |\n-                                            LIR_OprDesc::object_type  |\n-                                            LIR_OprDesc::cpu_register |\n-                                            LIR_OprDesc::single_size  |\n-                                            LIR_OprDesc::virtual_mask);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift)  |\n+                                            LIR_Opr::object_type  |\n+                                            LIR_Opr::cpu_register |\n+                                            LIR_Opr::single_size  |\n+                                            LIR_Opr::virtual_mask);\n@@ -672,5 +691,5 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift)  |\n-                                            LIR_OprDesc::metadata_type|\n-                                            LIR_OprDesc::cpu_register |\n-                                            LIR_OprDesc::single_size  |\n-                                            LIR_OprDesc::virtual_mask);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift)  |\n+                                            LIR_Opr::metadata_type|\n+                                            LIR_Opr::cpu_register |\n+                                            LIR_Opr::single_size  |\n+                                            LIR_Opr::virtual_mask);\n@@ -680,5 +699,5 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::int_type              |\n-                                  LIR_OprDesc::cpu_register          |\n-                                  LIR_OprDesc::single_size           |\n-                                  LIR_OprDesc::virtual_mask);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::int_type              |\n+                                  LIR_Opr::cpu_register          |\n+                                  LIR_Opr::single_size           |\n+                                  LIR_Opr::virtual_mask);\n@@ -688,5 +707,5 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::address_type          |\n-                                  LIR_OprDesc::cpu_register          |\n-                                  LIR_OprDesc::single_size           |\n-                                  LIR_OprDesc::virtual_mask);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::address_type          |\n+                                  LIR_Opr::cpu_register          |\n+                                  LIR_Opr::single_size           |\n+                                  LIR_Opr::virtual_mask);\n@@ -696,5 +715,5 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::long_type             |\n-                                  LIR_OprDesc::cpu_register          |\n-                                  LIR_OprDesc::double_size           |\n-                                  LIR_OprDesc::virtual_mask);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::long_type             |\n+                                  LIR_Opr::cpu_register          |\n+                                  LIR_Opr::double_size           |\n+                                  LIR_Opr::virtual_mask);\n@@ -705,5 +724,5 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::float_type  |\n-                                  LIR_OprDesc::cpu_register |\n-                                  LIR_OprDesc::single_size |\n-                                  LIR_OprDesc::virtual_mask);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::float_type  |\n+                                  LIR_Opr::cpu_register |\n+                                  LIR_Opr::single_size |\n+                                  LIR_Opr::virtual_mask);\n@@ -712,5 +731,5 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::double_type |\n-                                  LIR_OprDesc::cpu_register |\n-                                  LIR_OprDesc::double_size |\n-                                  LIR_OprDesc::virtual_mask);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::double_type |\n+                                  LIR_Opr::cpu_register |\n+                                  LIR_Opr::double_size |\n+                                  LIR_Opr::virtual_mask);\n@@ -720,5 +739,5 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::float_type           |\n-                                  LIR_OprDesc::fpu_register         |\n-                                  LIR_OprDesc::single_size          |\n-                                  LIR_OprDesc::virtual_mask);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::float_type           |\n+                                  LIR_Opr::fpu_register         |\n+                                  LIR_Opr::single_size          |\n+                                  LIR_Opr::virtual_mask);\n@@ -728,5 +747,5 @@\n-        T_DOUBLE: res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                            LIR_OprDesc::double_type           |\n-                                            LIR_OprDesc::fpu_register          |\n-                                            LIR_OprDesc::double_size           |\n-                                            LIR_OprDesc::virtual_mask);\n+        T_DOUBLE: res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                            LIR_Opr::double_type           |\n+                                            LIR_Opr::fpu_register          |\n+                                            LIR_Opr::double_size           |\n+                                            LIR_Opr::virtual_mask);\n@@ -741,2 +760,2 @@\n-    assert(index >= LIR_OprDesc::vreg_base, \"must start at vreg_base\");\n-    assert(index <= (max_jint >> LIR_OprDesc::data_shift), \"index is too big\");\n+    assert(index >= LIR_Opr::vreg_base, \"must start at vreg_base\");\n+    assert(index <= (max_jint >> LIR_Opr::data_shift), \"index is too big\");\n@@ -745,1 +764,1 @@\n-    LIR_OprDesc::OprType t = as_OprType(type);\n+    LIR_Opr::OprType t = as_OprType(type);\n@@ -747,1 +766,1 @@\n-    LIR_Opr old_res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n+    LIR_Opr old_res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n@@ -749,2 +768,2 @@\n-                               LIR_OprDesc::cpu_register |\n-                               LIR_OprDesc::size_for(type) | LIR_OprDesc::virtual_mask);\n+                               LIR_Opr::cpu_register |\n+                               LIR_Opr::size_for(type) | LIR_Opr::virtual_mask);\n@@ -752,3 +771,3 @@\n-    LIR_Opr old_res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) | t |\n-                                          ((type == T_FLOAT || type == T_DOUBLE) ?  LIR_OprDesc::fpu_register : LIR_OprDesc::cpu_register) |\n-                               LIR_OprDesc::size_for(type) | LIR_OprDesc::virtual_mask);\n+    LIR_Opr old_res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) | t |\n+                                          ((type == T_FLOAT || type == T_DOUBLE) ?  LIR_Opr::fpu_register : LIR_Opr::cpu_register) |\n+                               LIR_Opr::size_for(type) | LIR_Opr::virtual_mask);\n@@ -771,4 +790,4 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::object_type           |\n-                                  LIR_OprDesc::stack_value           |\n-                                  LIR_OprDesc::single_size);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::object_type           |\n+                                  LIR_Opr::stack_value           |\n+                                  LIR_Opr::single_size);\n@@ -778,4 +797,4 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::metadata_type         |\n-                                  LIR_OprDesc::stack_value           |\n-                                  LIR_OprDesc::single_size);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::metadata_type         |\n+                                  LIR_Opr::stack_value           |\n+                                  LIR_Opr::single_size);\n@@ -784,4 +803,4 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::int_type              |\n-                                  LIR_OprDesc::stack_value           |\n-                                  LIR_OprDesc::single_size);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::int_type              |\n+                                  LIR_Opr::stack_value           |\n+                                  LIR_Opr::single_size);\n@@ -791,4 +810,4 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::address_type          |\n-                                  LIR_OprDesc::stack_value           |\n-                                  LIR_OprDesc::single_size);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::address_type          |\n+                                  LIR_Opr::stack_value           |\n+                                  LIR_Opr::single_size);\n@@ -798,4 +817,4 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::long_type             |\n-                                  LIR_OprDesc::stack_value           |\n-                                  LIR_OprDesc::double_size);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::long_type             |\n+                                  LIR_Opr::stack_value           |\n+                                  LIR_Opr::double_size);\n@@ -805,4 +824,4 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::float_type            |\n-                                  LIR_OprDesc::stack_value           |\n-                                  LIR_OprDesc::single_size);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::float_type            |\n+                                  LIR_Opr::stack_value           |\n+                                  LIR_Opr::single_size);\n@@ -811,4 +830,4 @@\n-        res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                  LIR_OprDesc::double_type           |\n-                                  LIR_OprDesc::stack_value           |\n-                                  LIR_OprDesc::double_size);\n+        res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                  LIR_Opr::double_type           |\n+                                  LIR_Opr::stack_value           |\n+                                  LIR_Opr::double_size);\n@@ -822,1 +841,1 @@\n-    assert(index <= (max_jint >> LIR_OprDesc::data_shift), \"index is too big\");\n+    assert(index <= (max_jint >> LIR_Opr::data_shift), \"index is too big\");\n@@ -824,2 +843,2 @@\n-    LIR_Opr old_res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |\n-                                          LIR_OprDesc::stack_value           |\n+    LIR_Opr old_res = (LIR_Opr)(intptr_t)((index << LIR_Opr::data_shift) |\n+                                          LIR_Opr::stack_value           |\n@@ -827,1 +846,1 @@\n-                                          LIR_OprDesc::size_for(type));\n+                                          LIR_Opr::size_for(type));\n@@ -2598,1 +2617,3 @@\n-inline LIR_Opr LIR_OprDesc::illegalOpr()   { return LIR_OprFact::illegalOpr; };\n+inline LIR_Opr LIR_Opr::illegalOpr()   { return LIR_OprFact::illegalOpr; };\n+\n+inline LIR_Opr LIR_Opr::nullOpr()   { return LIR_OprFact::nullOpr; };\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":187,"deletions":166,"binary":false,"changes":353,"status":"modified"},{"patch":"@@ -1042,1 +1042,1 @@\n-  if (vreg_num + 20 >= LIR_OprDesc::vreg_max) {\n+  if (vreg_num + 20 >= LIR_Opr::vreg_max) {\n@@ -1044,1 +1044,1 @@\n-    if (vreg_num + 2 >= LIR_OprDesc::vreg_max) {\n+    if (vreg_num + 2 >= LIR_Opr::vreg_max) {\n@@ -1046,2 +1046,2 @@\n-      _virtual_register_number = LIR_OprDesc::vreg_base;\n-      vreg_num = LIR_OprDesc::vreg_base;\n+      _virtual_register_number = LIR_Opr::vreg_base;\n+      vreg_num = LIR_Opr::vreg_base;\n@@ -2179,1 +2179,1 @@\n-  LIR_Opr zero = NULL;\n+  LIR_Opr zero;\n@@ -3460,0 +3460,1 @@\n+  case vmIntrinsics::_dsqrt_strict:   \/\/ fall through\n@@ -3493,0 +3494,3 @@\n+  case vmIntrinsics::_storeStoreFence:\n+    __ membar_storestore();\n+    break;\n@@ -3823,1 +3827,1 @@\n-  LIR_Opr counter_holder = NULL;\n+  LIR_Opr counter_holder;\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":10,"deletions":6,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -329,1 +329,1 @@\n-  virtual void CardTableBarrierSet_post_barrier_helper(LIR_OprDesc* addr, LIR_Const* card_table_base);\n+  virtual void CardTableBarrierSet_post_barrier_helper(LIR_Opr addr, LIR_Const* card_table_base);\n@@ -527,1 +527,1 @@\n-    , _virtual_register_number(LIR_OprDesc::vreg_base)\n+    , _virtual_register_number(LIR_Opr::vreg_base)\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -176,1 +176,1 @@\n-  return i->reg_num() >= LIR_OprDesc::vreg_base;\n+  return i->reg_num() >= LIR_Opr::vreg_base;\n@@ -185,1 +185,1 @@\n-  return i->reg_num() >= LIR_OprDesc::vreg_base;\n+  return i->reg_num() >= LIR_Opr::vreg_base;\n@@ -187,1 +187,1 @@\n-  return i->reg_num() >= LIR_OprDesc::vreg_base && (i->type() != T_FLOAT && i->type() != T_DOUBLE);\n+  return i->reg_num() >= LIR_Opr::vreg_base && (i->type() != T_FLOAT && i->type() != T_DOUBLE);\n@@ -199,1 +199,1 @@\n-  return i->reg_num() >= LIR_OprDesc::vreg_base && (i->type() == T_FLOAT || i->type() == T_DOUBLE);\n+  return i->reg_num() >= LIR_Opr::vreg_base && (i->type() == T_FLOAT || i->type() == T_DOUBLE);\n@@ -277,1 +277,1 @@\n-  if (reg_num < LIR_OprDesc::vreg_base) {\n+  if (reg_num < LIR_Opr::vreg_base) {\n@@ -822,1 +822,1 @@\n-    for (int j = 0; j < LIR_OprDesc::vreg_base; j++) {\n+    for (int j = 0; j < LIR_Opr::vreg_base; j++) {\n@@ -1336,1 +1336,1 @@\n-      assert(number >= LIR_OprDesc::vreg_base, \"fixed intervals must not be live on block bounds\");\n+      assert(number >= LIR_Opr::vreg_base, \"fixed intervals must not be live on block bounds\");\n@@ -1709,1 +1709,1 @@\n-  result = new Interval(LIR_OprDesc::vreg_base);\n+  result = new Interval(LIR_Opr::vreg_base);\n@@ -2438,1 +2438,1 @@\n-    assert(interval->reg_num() >= LIR_OprDesc::vreg_base, \"fixed interval found\");\n+    assert(interval->reg_num() >= LIR_Opr::vreg_base, \"fixed interval found\");\n@@ -3221,1 +3221,1 @@\n-  } else if (reg_num >= LIR_OprDesc::vreg_base) {\n+  } else if (reg_num >= LIR_Opr::vreg_base) {\n@@ -3301,1 +3301,1 @@\n-    if (i1->reg_num() >= LIR_OprDesc::vreg_base && i1->type() == T_ILLEGAL) {\n+    if (i1->reg_num() >= LIR_Opr::vreg_base && i1->type() == T_ILLEGAL) {\n@@ -3972,1 +3972,1 @@\n-  if (reg_num + 20 >= LIR_OprDesc::vreg_max) {\n+  if (reg_num + 20 >= LIR_Opr::vreg_max) {\n@@ -3974,1 +3974,1 @@\n-    if (reg_num + 2 >= LIR_OprDesc::vreg_max) {\n+    if (reg_num + 2 >= LIR_Opr::vreg_max) {\n@@ -3976,1 +3976,1 @@\n-      reg_num = LIR_OprDesc::vreg_base;\n+      reg_num = LIR_Opr::vreg_base;\n@@ -4408,1 +4408,1 @@\n-  if (use_kind != noUse && reg_num() >= LIR_OprDesc::vreg_base) {\n+  if (use_kind != noUse && reg_num() >= LIR_Opr::vreg_base) {\n@@ -4638,1 +4638,1 @@\n-  if (reg_num() < LIR_OprDesc::vreg_base) {\n+  if (reg_num() < LIR_Opr::vreg_base) {\n@@ -4655,1 +4655,1 @@\n-    if (reg_num() < LIR_OprDesc::vreg_base) {\n+    if (reg_num() < LIR_Opr::vreg_base) {\n","filename":"src\/hotspot\/share\/c1\/c1_LinearScan.cpp","additions":17,"deletions":17,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -1142,4 +1142,0 @@\n-  if (mapinfo->header()->magic() == CDS_DYNAMIC_ARCHIVE_MAGIC) {\n-    mapinfo->set_header_base_archive_name_size(strlen(Arguments::GetSharedArchivePath()) + 1);\n-    mapinfo->set_header_base_archive_is_default(FLAG_IS_DEFAULT(SharedArchiveFile));\n-  }\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -449,1 +449,1 @@\n-#if !(defined(_LP64) && (defined(LINUX) || defined(__APPLE__)))\n+#if !(defined(_LP64) && (defined(LINUX) || defined(__APPLE__) || defined(_WINDOWS)))\n@@ -451,1 +451,1 @@\n-  \/\/ (3) MacOSX\/64-bit\n+  \/\/ (3) MacOSX\/64-bit and (4) Windowss\/64-bit\n","filename":"src\/hotspot\/share\/cds\/classListParser.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+#include \"runtime\/globals_extension.hpp\"\n@@ -237,2 +238,1 @@\n-  size_t header_size;\n-  if (is_static) {\n+  if (_is_static) {\n@@ -241,1 +241,0 @@\n-    header_size = sizeof(FileMapHeader);\n@@ -245,6 +244,0 @@\n-    header_size = sizeof(DynamicArchiveHeader);\n-  _header = (FileMapHeader*)os::malloc(header_size, mtInternal);\n-  memset((void*)_header, 0, header_size);\n-  _header->set_header_size(header_size);\n-  _header->set_version(INVALID_CDS_ARCHIVE_VERSION);\n-  _header->set_has_platform_or_app_classes(true);\n@@ -267,6 +260,8 @@\n-  header()->populate(this, core_region_alignment);\n-}\n-\n-void FileMapHeader::populate(FileMapInfo* mapinfo, size_t core_region_alignment) {\n-  if (DynamicDumpSharedSpaces) {\n-    _magic = CDS_DYNAMIC_ARCHIVE_MAGIC;\n+  assert(_header == NULL, \"Sanity check\");\n+  size_t c_header_size;\n+  size_t header_size;\n+  size_t base_archive_name_size = 0;\n+  size_t base_archive_name_offset = 0;\n+  if (is_static()) {\n+    c_header_size = sizeof(FileMapHeader);\n+    header_size = c_header_size;\n@@ -274,1 +269,33 @@\n-    _magic = CDS_ARCHIVE_MAGIC;\n+    \/\/ dynamic header including base archive name for non-default base archive\n+    c_header_size = sizeof(DynamicArchiveHeader);\n+    header_size = c_header_size;\n+    if (!FLAG_IS_DEFAULT(SharedArchiveFile)) {\n+      base_archive_name_size = strlen(Arguments::GetSharedArchivePath()) + 1;\n+      header_size += base_archive_name_size;\n+      base_archive_name_offset = c_header_size;\n+    }\n+  }\n+  _header = (FileMapHeader*)os::malloc(header_size, mtInternal);\n+  memset((void*)_header, 0, header_size);\n+  _header->populate(this,\n+                    core_region_alignment,\n+                    header_size,\n+                    base_archive_name_size,\n+                    base_archive_name_offset);\n+}\n+\n+void FileMapHeader::populate(FileMapInfo *info, size_t core_region_alignment,\n+                             size_t header_size, size_t base_archive_name_size,\n+                             size_t base_archive_name_offset) {\n+  \/\/ 1. We require _generic_header._magic to be at the beginning of the file\n+  \/\/ 2. FileMapHeader also assumes that _generic_header is at the beginning of the file\n+  assert(offset_of(FileMapHeader, _generic_header) == 0, \"must be\");\n+  set_header_size((unsigned int)header_size);\n+  set_base_archive_name_offset((unsigned int)base_archive_name_offset);\n+  set_base_archive_name_size((unsigned int)base_archive_name_size);\n+  set_magic(DynamicDumpSharedSpaces ? CDS_DYNAMIC_ARCHIVE_MAGIC : CDS_ARCHIVE_MAGIC);\n+  set_version(CURRENT_CDS_ARCHIVE_VERSION);\n+\n+  if (!info->is_static() && base_archive_name_size != 0) {\n+    \/\/ copy base archive name\n+    copy_base_archive_name(Arguments::GetSharedArchivePath());\n@@ -276,1 +303,0 @@\n-  _version = CURRENT_CDS_ARCHIVE_VERSION;\n@@ -313,3 +339,0 @@\n-  \/\/ the following 2 fields will be set in write_header for dynamic archive header\n-  _base_archive_name_size = 0;\n-  _base_archive_is_default = false;\n@@ -319,1 +342,1 @@\n-    set_shared_path_table(mapinfo->_shared_path_table);\n+    set_shared_path_table(info->_shared_path_table);\n@@ -324,0 +347,7 @@\n+void FileMapHeader::copy_base_archive_name(const char* archive) {\n+  assert(base_archive_name_size() != 0, \"_base_archive_name_size not set\");\n+  assert(base_archive_name_offset() != 0, \"_base_archive_name_offset not set\");\n+  assert(header_size() > sizeof(*this), \"_base_archive_name_size not included in header size?\");\n+  memcpy((char*)this + base_archive_name_offset(), archive, base_archive_name_size());\n+}\n+\n@@ -327,3 +357,6 @@\n-  st->print_cr(\"- magic:                          0x%08x\", _magic);\n-  st->print_cr(\"- crc:                            0x%08x\", _crc);\n-  st->print_cr(\"- version:                        %d\", _version);\n+  st->print_cr(\"- magic:                          0x%08x\", magic());\n+  st->print_cr(\"- crc:                            0x%08x\", crc());\n+  st->print_cr(\"- version:                        %d\", version());\n+  st->print_cr(\"- header_size:                    \" UINT32_FORMAT, header_size());\n+  st->print_cr(\"- base_archive_name_offset:       \" UINT32_FORMAT, base_archive_name_offset());\n+  st->print_cr(\"- base_archive_name_size:         \" UINT32_FORMAT, base_archive_name_size());\n@@ -337,1 +370,0 @@\n-  st->print_cr(\"- header_size:                    \" SIZE_FORMAT, _header_size);\n@@ -352,2 +384,0 @@\n-  st->print_cr(\"- base_archive_is_default:        %d\", _base_archive_is_default);\n-  st->print_cr(\"- base_archive_name_size:         \" SIZE_FORMAT, _base_archive_name_size);\n@@ -1082,0 +1112,67 @@\n+\/\/ a utility class for checking file header\n+class FileHeaderHelper {\n+  int _fd;\n+  GenericCDSFileMapHeader _header;\n+\n+public:\n+  FileHeaderHelper() {\n+    _fd = -1;\n+  }\n+\n+  ~FileHeaderHelper() {\n+    if (_fd != -1) {\n+      os::close(_fd);\n+    }\n+  }\n+\n+  bool initialize(const char* archive_name) {\n+    _fd = os::open(archive_name, O_RDONLY | O_BINARY, 0);\n+    if (_fd < 0) {\n+      return false;\n+    }\n+    return initialize(_fd);\n+  }\n+\n+  \/\/ for an already opened file, do not set _fd\n+  bool initialize(int fd) {\n+    assert(fd != -1, \"Archive should be opened\");\n+    size_t size = sizeof(GenericCDSFileMapHeader);\n+    lseek(fd, 0, SEEK_SET);\n+    size_t n = os::read(fd, (void*)&_header, (unsigned int)size);\n+    if (n != size) {\n+      vm_exit_during_initialization(\"Unable to read generic CDS file map header from shared archive\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  GenericCDSFileMapHeader* get_generic_file_header() {\n+    return &_header;\n+  }\n+\n+  char* read_base_archive_name() {\n+    assert(_fd != -1, \"Archive should be open\");\n+    size_t name_size = _header._base_archive_name_size;\n+    assert(name_size != 0, \"For non-default base archive, name size should be non-zero!\");\n+    char* base_name = NEW_C_HEAP_ARRAY(char, name_size, mtInternal);\n+    lseek(_fd, _header._base_archive_name_offset, SEEK_SET); \/\/ position to correct offset.\n+    size_t n = os::read(_fd, base_name, (unsigned int)name_size);\n+    if (n != name_size) {\n+      log_info(cds)(\"Unable to read base archive name from archive\");\n+      FREE_C_HEAP_ARRAY(char, base_name);\n+      return nullptr;\n+    }\n+    if (base_name[name_size - 1] != '\\0' || strlen(base_name) != name_size - 1) {\n+      log_info(cds)(\"Base archive name is damaged\");\n+      FREE_C_HEAP_ARRAY(char, base_name);\n+      return nullptr;\n+    }\n+    if (!os::file_exists(base_name)) {\n+      log_info(cds)(\"Base archive %s does not exist\", base_name);\n+      FREE_C_HEAP_ARRAY(char, base_name);\n+      return nullptr;\n+    }\n+    return base_name;\n+  }\n+};\n+\n@@ -1083,2 +1180,2 @@\n-  int fd = os::open(archive_name, O_RDONLY | O_BINARY, 0);\n-  if (fd < 0) {\n+  FileHeaderHelper file_helper;\n+  if (!file_helper.initialize(archive_name)) {\n@@ -1091,10 +1188,1 @@\n-  size_t sz = is_static ? sizeof(FileMapHeader) : sizeof(DynamicArchiveHeader);\n-  void* header = os::malloc(sz, mtInternal);\n-  memset(header, 0, sz);\n-  size_t n = os::read(fd, header, (unsigned int)sz);\n-  if (n != sz) {\n-    os::free(header);\n-    os::close(fd);\n-    vm_exit_during_initialization(\"Unable to read header from shared archive\", archive_name);\n-    return false;\n-  }\n+  GenericCDSFileMapHeader* header = file_helper.get_generic_file_header();\n@@ -1102,4 +1190,1 @@\n-    FileMapHeader* static_header = (FileMapHeader*)header;\n-    if (static_header->magic() != CDS_ARCHIVE_MAGIC) {\n-      os::free(header);\n-      os::close(fd);\n+    if (header->_magic != CDS_ARCHIVE_MAGIC) {\n@@ -1109,0 +1194,5 @@\n+    if (header->_base_archive_name_offset != 0) {\n+      log_info(cds)(\"_base_archive_name_offset should be 0\");\n+      log_info(cds)(\"_base_archive_name_offset = \" UINT32_FORMAT, header->_base_archive_name_offset);\n+      return false;\n+    }\n@@ -1110,4 +1200,1 @@\n-    DynamicArchiveHeader* dynamic_header = (DynamicArchiveHeader*)header;\n-    if (dynamic_header->magic() != CDS_DYNAMIC_ARCHIVE_MAGIC) {\n-      os::free(header);\n-      os::close(fd);\n+    if (header->_magic != CDS_DYNAMIC_ARCHIVE_MAGIC) {\n@@ -1117,0 +1204,15 @@\n+    unsigned int name_size = header->_base_archive_name_size;\n+    unsigned int name_offset = header->_base_archive_name_offset;\n+    unsigned int header_size = header->_header_size;\n+    if (name_offset + name_size != header_size) {\n+      log_info(cds)(\"_header_size should be equal to _base_archive_name_offset plus _base_archive_name_size\");\n+      log_info(cds)(\"  _base_archive_name_size   = \" UINT32_FORMAT, name_size);\n+      log_info(cds)(\"  _base_archive_name_offset = \" UINT32_FORMAT, name_offset);\n+      log_info(cds)(\"  _header_size              = \" UINT32_FORMAT, header_size);\n+      return false;\n+    }\n+    char* base_name = file_helper.read_base_archive_name();\n+    if (base_name == nullptr) {\n+      return false;\n+    }\n+    FREE_C_HEAP_ARRAY(char, base_name);\n@@ -1118,2 +1220,0 @@\n-  os::free(header);\n-  os::close(fd);\n@@ -1124,4 +1224,3 @@\n-                                                    int* size, char** base_archive_name) {\n-  int fd = os::open(archive_name, O_RDONLY | O_BINARY, 0);\n-  if (fd < 0) {\n-    *size = 0;\n+                                                    char** base_archive_name) {\n+  FileHeaderHelper file_helper;\n+  if (!file_helper.initialize(archive_name)) {\n@@ -1130,9 +1229,3 @@\n-\n-  \/\/ read the header as a dynamic archive header\n-  size_t sz = sizeof(DynamicArchiveHeader);\n-  DynamicArchiveHeader* dynamic_header = (DynamicArchiveHeader*)os::malloc(sz, mtInternal);\n-  size_t n = os::read(fd, dynamic_header, (unsigned int)sz);\n-  if (n != sz) {\n-    fail_continue(\"Unable to read the file header.\");\n-    os::free(dynamic_header);\n-    os::close(fd);\n+  GenericCDSFileMapHeader* header = file_helper.get_generic_file_header();\n+  if (header->_magic != CDS_DYNAMIC_ARCHIVE_MAGIC) {\n+    \/\/ Not a dynamic header, no need to proceed further.\n@@ -1141,5 +1234,4 @@\n-  if (dynamic_header->magic() != CDS_DYNAMIC_ARCHIVE_MAGIC) {\n-    \/\/ Not a dynamic header, no need to proceed further.\n-    *size = 0;\n-    os::free(dynamic_header);\n-    os::close(fd);\n+\n+  if ((header->_base_archive_name_size == 0 && header->_base_archive_name_offset != 0) ||\n+      (header->_base_archive_name_size != 0 && header->_base_archive_name_offset == 0)) {\n+    fail_continue(\"Default base archive not set correct\");\n@@ -1148,1 +1240,2 @@\n-  if (dynamic_header->base_archive_is_default()) {\n+  if (header->_base_archive_name_size == 0 &&\n+      header->_base_archive_name_offset == 0) {\n@@ -1152,14 +1245,2 @@\n-    size_t name_size = dynamic_header->base_archive_name_size();\n-    if (name_size == 0) {\n-      os::free(dynamic_header);\n-      os::close(fd);\n-      return false;\n-    }\n-    *base_archive_name = NEW_C_HEAP_ARRAY(char, name_size, mtInternal);\n-    n = os::read(fd, *base_archive_name, (unsigned int)name_size);\n-    if (n != name_size) {\n-      fail_continue(\"Unable to read the base archive name from the header.\");\n-      FREE_C_HEAP_ARRAY(char, *base_archive_name);\n-      *base_archive_name = NULL;\n-      os::free(dynamic_header);\n-      os::close(fd);\n+    *base_archive_name = file_helper.read_base_archive_name();\n+    if (*base_archive_name == nullptr) {\n@@ -1169,3 +1250,0 @@\n-\n-  os::free(dynamic_header);\n-  os::close(fd);\n@@ -1178,3 +1256,2 @@\n-  size_t sz = is_static() ? sizeof(FileMapHeader) : sizeof(DynamicArchiveHeader);\n-  size_t n = os::read(fd, header(), (unsigned int)sz);\n-  if (n != sz) {\n+  FileHeaderHelper file_helper;\n+  if (!file_helper.initialize(fd)) {\n@@ -1184,5 +1261,1 @@\n-\n-  if (!Arguments::has_jimage()) {\n-    FileMapInfo::fail_continue(\"The shared archive file cannot be used with an exploded module build.\");\n-    return false;\n-  }\n+  GenericCDSFileMapHeader* gen_header = file_helper.get_generic_file_header();\n@@ -1191,1 +1264,1 @@\n-  if (header()->magic() != expected_magic) {\n+  if (gen_header->_magic != expected_magic) {\n@@ -1193,1 +1266,1 @@\n-    log_info(cds)(\"         actual: 0x%08x\", header()->magic());\n+    log_info(cds)(\"         actual: 0x%08x\", gen_header->_magic);\n@@ -1198,0 +1271,9 @@\n+  _header = (FileMapHeader*)os::malloc(gen_header->_header_size, mtInternal);\n+  lseek(fd, 0, SEEK_SET); \/\/ reset to begin of the archive\n+  size_t size = gen_header->_header_size;\n+  size_t n = os::read(fd, (void*)_header, (unsigned int)size);\n+  if (n != size) {\n+    fail_continue(\"Failed to read file header from the top archive file\\n\");\n+    return false;\n+  }\n+\n@@ -1205,5 +1287,11 @@\n-  if (header()->header_size() != sz) {\n-    log_info(cds)(\"_header_size expected: \" SIZE_FORMAT, sz);\n-    log_info(cds)(\"               actual: \" SIZE_FORMAT, header()->header_size());\n-    FileMapInfo::fail_continue(\"The shared archive file has an incorrect header size.\");\n-    return false;\n+  unsigned int base_offset = header()->base_archive_name_offset();\n+  unsigned int name_size = header()->base_archive_name_size();\n+  unsigned int header_size = header()->header_size();\n+  if (base_offset != 0 && name_size != 0) {\n+    if (header_size != base_offset + name_size) {\n+      log_info(cds)(\"_header_size: \" UINT32_FORMAT, header_size);\n+      log_info(cds)(\"base_archive_name_size: \" UINT32_FORMAT, name_size);\n+      log_info(cds)(\"base_archive_name_offset: \" UINT32_FORMAT, base_offset);\n+      FileMapInfo::fail_continue(\"The shared archive file has an incorrect header size.\");\n+      return false;\n+    }\n@@ -1239,1 +1327,1 @@\n-  _file_offset = n + header()->base_archive_name_size(); \/\/ accounts for the size of _base_archive_name\n+  _file_offset = header()->header_size(); \/\/ accounts for the size of _base_archive_name\n@@ -1327,3 +1415,0 @@\n-  if (header()->magic() == CDS_DYNAMIC_ARCHIVE_MAGIC) {\n-    header_bytes += strlen(Arguments::GetSharedArchivePath()) + 1;\n-  }\n@@ -1336,1 +1421,0 @@\n-\n@@ -1344,7 +1428,0 @@\n-\n-  if (header()->magic() == CDS_DYNAMIC_ARCHIVE_MAGIC) {\n-    char* base_archive_name = (char*)Arguments::GetSharedArchivePath();\n-    if (base_archive_name != NULL) {\n-      write_bytes(base_archive_name, header()->base_archive_name_size());\n-    }\n-  }\n@@ -2294,0 +2371,5 @@\n+  if (!Arguments::has_jimage()) {\n+    FileMapInfo::fail_continue(\"The shared archive file cannot be used with an exploded module build.\");\n+    return false;\n+  }\n+\n@@ -2332,3 +2414,3 @@\n-  \/\/ start computing from the field after _crc\n-  char* buf = (char*)&_crc + sizeof(_crc);\n-  size_t sz = _header_size - (buf - start);\n+  \/\/ start computing from the field after _crc to end of base archive name.\n+  char* buf = (char*)&(_generic_header._crc) + sizeof(_generic_header._crc);\n+  size_t sz = header_size() - (buf - start);\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":197,"deletions":115,"binary":false,"changes":312,"status":"modified"},{"patch":"@@ -216,2 +216,0 @@\n-  size_t _header_size;\n-\n@@ -235,1 +233,0 @@\n-  bool _base_archive_is_default;    \/\/ indicates if the base archive is the system default one\n@@ -242,2 +239,0 @@\n-  \/\/ size of the base archive name including NULL terminator\n-  size_t _base_archive_name_size;\n@@ -276,9 +271,14 @@\n-  \/\/ Accessors -- fields declared in CDSFileMapHeaderBase\n-  unsigned int magic()                    const { return _magic; }\n-  int crc()                               const { return _crc; }\n-  int version()                           const { return _version; }\n-\n-  void set_crc(int crc_value)                   { _crc = crc_value; }\n-  void set_version(int v)                       { _version = v; }\n-\n-  \/\/ Accessors -- fields declared in FileMapHeader\n+  \/\/ Accessors -- fields declared in GenericCDSFileMapHeader\n+  unsigned int magic()                    const { return _generic_header._magic;    }\n+  int crc()                               const { return _generic_header._crc;      }\n+  int version()                           const { return _generic_header._version;  }\n+  unsigned int header_size()              const { return _generic_header._header_size;              }\n+  unsigned int base_archive_name_offset() const { return _generic_header._base_archive_name_offset; }\n+  unsigned int base_archive_name_size()   const { return _generic_header._base_archive_name_size;   }\n+\n+  void set_magic(unsigned int m)                    { _generic_header._magic = m;       }\n+  void set_crc(int crc_value)                       { _generic_header._crc = crc_value; }\n+  void set_version(int v)                           { _generic_header._version = v;     }\n+  void set_header_size(unsigned int s)              { _generic_header._header_size = s;              }\n+  void set_base_archive_name_offset(unsigned int s) { _generic_header._base_archive_name_offset = s; }\n+  void set_base_archive_name_size(unsigned int s)   { _generic_header._base_archive_name_size = s;   }\n@@ -286,1 +286,0 @@\n-  size_t header_size()                     const { return _header_size; }\n@@ -300,2 +299,0 @@\n-  bool base_archive_is_default()           const { return _base_archive_is_default; }\n-  size_t base_archive_name_size()          const { return _base_archive_name_size; }\n@@ -320,3 +317,0 @@\n-  void set_base_archive_name_size(size_t s)      { _base_archive_name_size = s; }\n-  void set_base_archive_is_default(bool b)       { _base_archive_is_default = b; }\n-  void set_header_size(size_t s)                 { _header_size = s; }\n@@ -326,0 +320,1 @@\n+  void copy_base_archive_name(const char* name);\n@@ -350,2 +345,2 @@\n-  void populate(FileMapInfo* info, size_t core_region_alignment);\n-\n+  void populate(FileMapInfo *info, size_t core_region_alignment, size_t header_size,\n+                size_t base_archive_name_size, size_t base_archive_name_offset);\n@@ -400,1 +395,1 @@\n-                                                int* size, char** base_archive_name);\n+                                                char** base_archive_name);\n@@ -435,3 +430,0 @@\n-  void   set_header_base_archive_name_size(size_t size)      { header()->set_base_archive_name_size(size); }\n-  void   set_header_base_archive_is_default(bool is_default) { header()->set_base_archive_is_default(is_default); }\n-\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":18,"deletions":26,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -437,1 +437,1 @@\n-  int size = objArrayOopDesc::object_size(length);\n+  size_t size = objArrayOopDesc::object_size(length);\n@@ -456,1 +456,1 @@\n-  log_info(cds)(\"archived obj roots[%d] = %d words, klass = %p, obj = %p\", length, size, k, mem);\n+  log_info(cds)(\"archived obj roots[%d] = \" SIZE_FORMAT \" words, klass = %p, obj = %p\", length, size, k, mem);\n@@ -920,1 +920,1 @@\n-        log_debug(cds, heap)(\"(%d) %s[\" SIZE_FORMAT \"] ==> \" PTR_FORMAT \" size %d %s\", _level,\n+        log_debug(cds, heap)(\"(%d) %s[\" SIZE_FORMAT \"] ==> \" PTR_FORMAT \" size \" SIZE_FORMAT \" %s\", _level,\n@@ -1031,1 +1031,1 @@\n-        PTR_FORMAT \") size %d, skipped.\",\n+        PTR_FORMAT \") size \" SIZE_FORMAT \", skipped.\",\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -589,1 +589,1 @@\n-  GrowableArray<Handle> _loaded_cld_handles; \/\/ keep the CLDs alive\n+  GrowableArray<OopHandle> _loaded_cld_handles; \/\/ keep the CLDs alive\n@@ -594,2 +594,2 @@\n-    for (int i = 0; i < _loaded_cld.length(); i++) {\n-      ClassLoaderData* cld = _loaded_cld.at(i);\n+    for (int i = 0; i < _loaded_cld_handles.length(); i++) {\n+      _loaded_cld_handles.at(i).release(Universe::vm_global());\n@@ -599,4 +599,3 @@\n-    if (!cld->is_unloading()) {\n-      _loaded_cld.append(cld);\n-      _loaded_cld_handles.append(Handle(_current_thread, cld->holder_phantom()));\n-    }\n+    assert(cld->is_alive(), \"must be\");\n+    _loaded_cld.append(cld);\n+    _loaded_cld_handles.append(OopHandle(Universe::vm_global(), cld->holder_phantom()));\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":6,"deletions":7,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -57,1 +57,0 @@\n-  bool is_java_klass() const  { return true; }\n","filename":"src\/hotspot\/share\/ci\/ciArrayKlass.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -658,0 +658,1 @@\n+  ciKlass* ciKlass = get_klass(klass);\n@@ -659,1 +660,7 @@\n-  return get_klass(klass);\n+#ifndef PRODUCT\n+  if (ReplayCompiles && ciKlass == _unloaded_ciinstance_klass) {\n+    \/\/ Klass was unresolved at replay dump time and therefore not accessible.\n+    is_accessible = false;\n+  }\n+#endif\n+  return ciKlass;\n@@ -1474,8 +1481,16 @@\n-    \/\/ Check <MethodHandle subclass>.argL0 field\n-    \/\/ Probably BoundMethodHandle.Species_L, but we only care if the field exists\n-    oop arg = obj_field(mh, \"argL0\");\n-    if (arg != NULL) {\n-      RecordLocation fp(this, \"argL0\");\n-      if (arg->klass()->is_instance_klass()) {\n-        InstanceKlass* ik2 = InstanceKlass::cast(arg->klass());\n-        record_best_dyno_loc(ik2);\n+    \/\/ Check <MethodHandle subclass>.argL<n> fields\n+    \/\/ Probably BoundMethodHandle.Species_L*, but we only care if the field exists\n+    char arg_name[] = \"argLXX\";\n+    int max_arg = 99;\n+    for (int index = 0; index <= max_arg; ++index) {\n+      jio_snprintf(arg_name, sizeof (arg_name), \"argL%d\", index);\n+      oop arg = obj_field(mh, arg_name);\n+      if (arg != NULL) {\n+        RecordLocation fp(this, \"%s\", arg_name);\n+        if (arg->klass()->is_instance_klass()) {\n+          InstanceKlass* ik2 = InstanceKlass::cast(arg->klass());\n+          record_best_dyno_loc(ik2);\n+          record_call_site_obj(thread, arg);\n+        }\n+      } else {\n+        break;\n@@ -1490,1 +1505,1 @@\n-void ciEnv::record_call_site_obj(Thread* thread, const constantPoolHandle& pool, const Handle obj)\n+void ciEnv::record_call_site_obj(Thread* thread, oop obj)\n@@ -1492,5 +1507,5 @@\n-  if (obj.not_null()) {\n-    if (java_lang_invoke_MethodHandle::is_instance(obj())) {\n-        record_mh(thread, obj());\n-    } else if (java_lang_invoke_ConstantCallSite::is_instance(obj())) {\n-      oop target = java_lang_invoke_CallSite::target(obj());\n+  if (obj != NULL) {\n+    if (java_lang_invoke_MethodHandle::is_instance(obj)) {\n+        record_mh(thread, obj);\n+    } else if (java_lang_invoke_ConstantCallSite::is_instance(obj)) {\n+      oop target = java_lang_invoke_CallSite::target(obj);\n@@ -1507,1 +1522,1 @@\n-void ciEnv::record_call_site_method(Thread* thread, const constantPoolHandle& pool, Method* adapter) {\n+void ciEnv::record_call_site_method(Thread* thread, Method* adapter) {\n@@ -1522,1 +1537,1 @@\n-    record_call_site_method(thread, cp, adapter);\n+    record_call_site_method(thread, adapter);\n@@ -1524,1 +1539,1 @@\n-    Handle appendix(thread, cp_cache_entry->appendix_if_resolved(cp));\n+    oop appendix = cp_cache_entry->appendix_if_resolved(cp);\n@@ -1527,1 +1542,1 @@\n-      record_call_site_obj(thread, cp, appendix);\n+      record_call_site_obj(thread, appendix);\n@@ -1532,2 +1547,1 @@\n-    oop bsm_oop = cp->resolve_possibly_cached_constant_at(bootstrap_specifier.bsm_index(), thread);\n-    Handle bsm(thread, bsm_oop);\n+    oop bsm = cp->resolve_possibly_cached_constant_at(bootstrap_specifier.bsm_index(), thread);\n@@ -1536,1 +1550,1 @@\n-      record_call_site_obj(thread, cp, bsm);\n+      record_call_site_obj(thread, bsm);\n@@ -1554,2 +1568,2 @@\n-      Handle appendix(thread, cp_cache_entry->appendix_if_resolved(cp));\n-      record_call_site_method(thread, cp, adapter);\n+      oop appendix = cp_cache_entry->appendix_if_resolved(cp);\n+      record_call_site_method(thread, adapter);\n@@ -1559,1 +1573,1 @@\n-        record_call_site_obj(thread, cp, appendix);\n+        record_call_site_obj(thread, appendix);\n@@ -1667,0 +1681,1 @@\n+  out->print_cr(\"version %d\", REPLAY_VERSION);\n@@ -1677,0 +1692,3 @@\n+  \/\/ The very first entry is the InstanceKlass of the root method of the current compilation in order to get the right\n+  \/\/ protection domain to load subsequent classes during replay compilation.\n+  out->print_cr(\"instanceKlass %s\", CURRENT_ENV->replay_name(task()->method()->method_holder()));\n@@ -1701,2 +1719,2 @@\n-  static char buffer[O_BUFLEN];\n-  int ret = jio_snprintf(buffer, O_BUFLEN, \"replay_pid%p_compid%d.log\", os::current_process_id(), compile_id);\n+  char buffer[64];\n+  int ret = jio_snprintf(buffer, sizeof(buffer), \"replay_pid%d_compid%d.log\", os::current_process_id(), compile_id);\n@@ -1719,2 +1737,2 @@\n-  static char buffer[O_BUFLEN];\n-  int ret = jio_snprintf(buffer, O_BUFLEN, \"inline_pid%p_compid%d.log\", os::current_process_id(), compile_id);\n+  char buffer[64];\n+  int ret = jio_snprintf(buffer, sizeof(buffer), \"inline_pid%d_compid%d.log\", os::current_process_id(), compile_id);\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":47,"deletions":29,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"ci\/ciReplay.hpp\"\n@@ -192,0 +193,9 @@\n+#ifndef PRODUCT\n+      if (ReplayCompiles && o->is_klass()) {\n+        Klass* k = (Klass*)o;\n+        if (k->is_instance_klass() && ciReplay::is_klass_unresolved((InstanceKlass*)k)) {\n+          \/\/ Klass was unresolved at replay dump time. Simulate this case.\n+          return ciEnv::_unloaded_ciinstance_klass;\n+        }\n+      }\n+#endif\n@@ -511,2 +521,2 @@\n-  void record_call_site_obj(Thread* thread, const constantPoolHandle& pool, const Handle appendix);\n-  void record_call_site_method(Thread* thread, const constantPoolHandle& pool, Method* adapter);\n+  void record_call_site_obj(Thread* thread, oop obj);\n+  void record_call_site_method(Thread* thread, Method* adapter);\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -68,1 +68,0 @@\n-  _nonstatic_field_size = ik->nonstatic_field_size();\n@@ -93,1 +92,1 @@\n-  Thread *thread = Thread::current();\n+  JavaThread *thread = JavaThread::current();\n@@ -129,1 +128,0 @@\n-  _nonstatic_field_size = -1;\n@@ -525,3 +523,0 @@\n-  \/\/ Size in bytes of my fields, including inherited fields.\n-  int fsize = nonstatic_field_size() * heapOopSize;\n-\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.cpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+  friend class ciReplay;\n@@ -63,2 +64,0 @@\n-  jint                   _nonstatic_field_size;\n-  jint                   _nonstatic_oop_map_size;\n@@ -176,3 +175,0 @@\n-  jint                   nonstatic_field_size()  {\n-    assert(is_loaded(), \"must be loaded\");\n-    return _nonstatic_field_size; }\n@@ -182,3 +178,0 @@\n-  jint                   nonstatic_oop_map_size()  {\n-    assert(is_loaded(), \"must be loaded\");\n-    return _nonstatic_oop_map_size; }\n@@ -291,1 +284,0 @@\n-  bool is_java_klass() const     { return true; }\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.hpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -52,3 +52,0 @@\n-  _creation_mileage(0),\n-  _current_mileage(0),\n-  _backedge_counter(0),\n@@ -253,3 +250,0 @@\n-  _creation_mileage = mdo->creation_mileage();\n-  _current_mileage = MethodData::mileage_of(mdo->method());\n-  _backedge_counter = mdo->backedge_count();\n@@ -713,1 +707,1 @@\n-  out->print(\" %d %d\", _state, current_mileage());\n+  out->print(\" %d %d\", _state, _invocation_counter);\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.cpp","additions":1,"deletions":7,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -432,5 +432,0 @@\n-  int _creation_mileage; \/\/ method mileage at MDO creation\n-\n-  \/\/ Maturity of the oop when the snapshot is taken.\n-  int _current_mileage;\n-\n@@ -441,1 +436,0 @@\n-  int _backedge_counter;\n@@ -514,4 +508,0 @@\n-  int creation_mileage() { return _creation_mileage; }\n-  int current_mileage()  { return _current_mileage; }\n-\n-  int backedge_count()   { return _backedge_counter;   }\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.hpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -389,0 +389,1 @@\n+      assert(!ReplayCompiles || ciReplay::no_replay_state() || !ciReplay::is_klass_unresolved((InstanceKlass*)k), \"must be whitelisted for replay compilation\");\n","filename":"src\/hotspot\/share\/ci\/ciObjectFactory.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -53,0 +53,1 @@\n+#include \"runtime\/jniHandles.inline.hpp\"\n@@ -68,1 +69,1 @@\n-  int _current_mileage;\n+  int _invocation_counter;\n@@ -94,0 +95,5 @@\n+typedef struct _ciInstanceKlassRecord {\n+  const InstanceKlass* _klass;\n+  jobject _java_mirror; \/\/ Global handle to java mirror to prevent unloading\n+} ciInstanceKlassRecord;\n+\n@@ -111,0 +117,1 @@\n+  bool    _protection_domain_initialized;\n@@ -112,0 +119,1 @@\n+  int     _version;\n@@ -115,0 +123,1 @@\n+  GrowableArray<ciInstanceKlassRecord*> _ci_instance_klass_records;\n@@ -125,1 +134,0 @@\n-  int   _buffer_pos;\n@@ -138,0 +146,1 @@\n+    _protection_domain_initialized = false;\n@@ -150,1 +159,0 @@\n-    _buffer_pos = 0;\n@@ -156,0 +164,1 @@\n+    _version = 0;\n@@ -186,4 +195,0 @@\n-    \/\/ Restore the _buffer contents for error reporting\n-    for (int i = 0; i < _buffer_pos; i++) {\n-      if (_buffer[i] == '\\0') _buffer[i] = ' ';\n-    }\n@@ -229,0 +234,4 @@\n+  \/\/ Ignore the rest of the line\n+  void skip_remaining() {\n+    _bufptr = &_bufptr[strlen(_bufptr)]; \/\/ skip ahead to terminator\n+  }\n@@ -431,1 +440,1 @@\n-        obj = cp->resolve_possibly_cached_constant_at(bootstrap_specifier.bsm_index(), thread);\n+        obj = cp->resolve_possibly_cached_constant_at(bootstrap_specifier.bsm_index(), CHECK_NULL);\n@@ -460,4 +469,6 @@\n-      {\n-        bool found_it;\n-        obj = cp->find_cached_constant_at(cpi, found_it, thread);\n-      }\n+      ik->link_class(CHECK_NULL);\n+      obj = cp->resolve_possibly_cached_constant_at(cpi, CHECK_NULL);\n+    }\n+    if (obj == NULL) {\n+      report_error(\"null cp object found\");\n+      return NULL;\n@@ -466,8 +477,18 @@\n-    if (obj != NULL) {\n-      skip_ws();\n-      \/\/ loop: read fields\n-      char* field = NULL;\n-      do {\n-        field = parse_string();\n-        if (field == NULL) {\n-          report_error(\"no field found\");\n+    skip_ws();\n+    \/\/ loop: read fields\n+    char* field = NULL;\n+    do {\n+      field = parse_string();\n+      if (field == NULL) {\n+        report_error(\"no field found\");\n+        return NULL;\n+      }\n+      if (strcmp(field, \";\") == 0) {\n+        break;\n+      }\n+      \/\/ raw Method*\n+      if (strcmp(field, \"<vmtarget>\") == 0) {\n+        Method* vmtarget = java_lang_invoke_MemberName::vmtarget(obj);\n+        k = (vmtarget == NULL) ? NULL : vmtarget->method_holder();\n+        if (k == NULL) {\n+          report_error(\"null vmtarget found\");\n@@ -476,16 +497,3 @@\n-        if (strcmp(field, \";\") == 0) {\n-          break;\n-        }\n-        \/\/ raw Method*\n-        if (strcmp(field, \"<vmtarget>\") == 0) {\n-          Method* vmtarget = java_lang_invoke_MemberName::vmtarget(obj);\n-          k = (vmtarget == NULL) ? NULL : vmtarget->method_holder();\n-          if (k == NULL) {\n-            report_error(\"null vmtarget found\");\n-            return NULL;\n-          }\n-          if (!parse_terminator()) {\n-            report_error(\"missing terminator\");\n-            return NULL;\n-          }\n-          return k;\n+        if (!parse_terminator()) {\n+          report_error(\"missing terminator\");\n+          return NULL;\n@@ -493,10 +501,10 @@\n-        obj = ciReplay::obj_field(obj, field);\n-        \/\/ array\n-        if (obj != NULL && obj->is_objArray()) {\n-          objArrayOop arr = (objArrayOop)obj;\n-          int index = parse_int(\"index\");\n-          if (index >= arr->length()) {\n-            report_error(\"bad array index\");\n-            return NULL;\n-          }\n-          obj = arr->obj_at(index);\n+        return k;\n+      }\n+      obj = ciReplay::obj_field(obj, field);\n+      \/\/ array\n+      if (obj != NULL && obj->is_objArray()) {\n+        objArrayOop arr = (objArrayOop)obj;\n+        int index = parse_int(\"index\");\n+        if (index >= arr->length()) {\n+          report_error(\"bad array index\");\n+          return NULL;\n@@ -504,4 +512,1 @@\n-      } while (obj != NULL);\n-      if (obj == NULL) {\n-        report_error(\"null field found\");\n-        return NULL;\n+        obj = arr->obj_at(index);\n@@ -509,1 +514,4 @@\n-      k = obj->klass();\n+    } while (obj != NULL);\n+    if (obj == NULL) {\n+      report_error(\"null field found\");\n+      return NULL;\n@@ -511,0 +519,1 @@\n+    k = obj->klass();\n@@ -578,0 +587,1 @@\n+    int buffer_pos = 0;\n@@ -579,1 +589,1 @@\n-      if (_buffer_pos + 1 >= _buffer_length) {\n+      if (buffer_pos + 1 >= _buffer_length) {\n@@ -591,1 +601,1 @@\n-        _buffer[_buffer_pos++] = c;\n+        _buffer[buffer_pos++] = c;\n@@ -596,2 +606,1 @@\n-    _buffer[_buffer_pos] = '\\0'; \/\/ NL or EOF\n-    _buffer_pos = 0;\n+    _buffer[buffer_pos] = '\\0'; \/\/ NL or EOF\n@@ -611,1 +620,2 @@\n-        tty->print_cr(\"Error while parsing line %d: %s\\n\", line_no, _error_message);\n+        int pos = _bufptr - _buffer + 1;\n+        tty->print_cr(\"Error while parsing line %d at position %d: %s\\n\", line_no, pos, _error_message);\n@@ -629,1 +639,10 @@\n-      \/\/ ignore\n+      \/\/ comment line, print or ignore\n+      if (Verbose) {\n+        tty->print_cr(\"# %s\", _bufptr);\n+      }\n+      skip_remaining();\n+    } else if (strcmp(\"version\", cmd) == 0) {\n+      _version = parse_int(\"version\");\n+      if (_version < 0 || _version > REPLAY_VERSION) {\n+        tty->print_cr(\"# unrecognized version %d, expected 0 <= version <= %d\", _version, REPLAY_VERSION);\n+      }\n@@ -649,0 +668,3 @@\n+    if (!had_error() && *_bufptr != '\\0') {\n+      report_error(\"line not properly terminated\");\n+    }\n@@ -791,1 +813,1 @@\n-  \/\/ ciMethodData <klass> <name> <signature> <state> <current_mileage> orig <length> <byte>* data <length> <ptr>* oops <length> (<offset> <klass>)* methods <length> (<offset> <klass> <name> <signature>)*\n+  \/\/ ciMethodData <klass> <name> <signature> <state> <invocation_counter> orig <length> <byte>* data <length> <ptr>* oops <length> (<offset> <klass>)* methods <length> (<offset> <klass> <name> <signature>)*\n@@ -816,1 +838,5 @@\n-    rec->_current_mileage = parse_int(\"current_mileage\");\n+    if (_version < 1) {\n+      parse_int(\"current_mileage\");\n+    } else {\n+      rec->_invocation_counter = parse_int(\"invocation_counter\");\n+    }\n@@ -865,0 +891,13 @@\n+\n+    if (_version >= 1) {\n+      if (!_protection_domain_initialized && k != NULL) {\n+        assert(_protection_domain() == NULL, \"must be uninitialized\");\n+        \/\/ The first entry is the holder class of the method for which a replay compilation is requested.\n+        \/\/ Use the same protection domain to load all subsequent classes in order to resolve all classes\n+        \/\/ in signatures of inlinees. This ensures that inlining can be done as stated in the replay file.\n+        _protection_domain = Handle(_thread, k->protection_domain());\n+      }\n+\n+      _protection_domain_initialized = true;\n+    }\n+\n@@ -874,3 +913,7 @@\n-    if (is_comment && Verbose) {\n-      const char* hidden = parse_string();\n-      tty->print_cr(\"Found %s for %s\", k->name()->as_quoted_ascii(), hidden);\n+    \/\/ comment, print or ignore\n+    if (is_comment) {\n+      if (Verbose) {\n+        const char* hidden = parse_string();\n+        tty->print_cr(\"Found %s for %s\", k->name()->as_quoted_ascii(), hidden);\n+      }\n+      skip_remaining();\n@@ -886,1 +929,1 @@\n-    InstanceKlass* k = (InstanceKlass *)parse_klass(CHECK);\n+    InstanceKlass* k = (InstanceKlass*)parse_klass(CHECK);\n@@ -888,0 +931,1 @@\n+      skip_remaining();\n@@ -909,0 +953,1 @@\n+    new_ciInstanceKlass(k);\n@@ -956,4 +1001,4 @@\n-          if (tag == JVM_CONSTANT_Class) {\n-          } else if (tag == JVM_CONSTANT_UnresolvedClass) {\n-            tty->print_cr(\"Warning: entry was unresolved in the replay data\");\n-          } else {\n+          if (tag == JVM_CONSTANT_UnresolvedClass) {\n+            Klass* k = cp->klass_at(i, CHECK);\n+            tty->print_cr(\"Warning: entry was unresolved in the replay data: %s\", k->name()->as_utf8());\n+          } else if (tag != JVM_CONSTANT_Class) {\n@@ -1132,0 +1177,1 @@\n+        skip_remaining();\n@@ -1244,0 +1290,22 @@\n+  \/\/ Create and initialize a record for a ciInstanceKlass which was present at replay dump time.\n+  void new_ciInstanceKlass(const InstanceKlass* klass) {\n+    ciInstanceKlassRecord* rec = NEW_RESOURCE_OBJ(ciInstanceKlassRecord);\n+    rec->_klass = klass;\n+    oop java_mirror = klass->java_mirror();\n+    Handle h_java_mirror(_thread, java_mirror);\n+    rec->_java_mirror = JNIHandles::make_global(h_java_mirror);\n+    _ci_instance_klass_records.append(rec);\n+  }\n+\n+  \/\/ Check if a ciInstanceKlass was present at replay dump time for a klass.\n+  ciInstanceKlassRecord* find_ciInstanceKlass(const InstanceKlass* klass) {\n+    for (int i = 0; i < _ci_instance_klass_records.length(); i++) {\n+      ciInstanceKlassRecord* rec = _ci_instance_klass_records.at(i);\n+      if (klass == rec->_klass) {\n+        \/\/ ciInstanceKlass for this klass was resolved.\n+        return rec;\n+      }\n+    }\n+    return NULL;\n+  }\n+\n@@ -1377,0 +1445,4 @@\n+bool ciReplay::no_replay_state() {\n+  return replay_state == NULL;\n+}\n+\n@@ -1448,1 +1520,1 @@\n-  if (replay_state == NULL) {\n+  if (no_replay_state()) {\n@@ -1466,1 +1538,1 @@\n-    m->_current_mileage = rec->_current_mileage;\n+    m->_invocation_counter = rec->_invocation_counter;\n@@ -1502,1 +1574,1 @@\n-  if (replay_state == NULL) {\n+  if (no_replay_state()) {\n@@ -1539,1 +1611,1 @@\n-  if (replay_state == NULL) {\n+  if (no_replay_state()) {\n@@ -1568,0 +1640,9 @@\n+void ciReplay::initialize(ciInstanceKlass* ci_ik, InstanceKlass* ik) {\n+  assert(!no_replay_state(), \"must have replay state\");\n+\n+  ASSERT_IN_VM;\n+  ciInstanceKlassRecord* rec = replay_state->find_ciInstanceKlass(ik);\n+  assert(rec != NULL, \"ciInstanceKlass must be whitelisted\");\n+  ci_ik->_java_mirror = CURRENT_ENV->get_instance(JNIHandles::resolve(rec->_java_mirror));\n+}\n+\n@@ -1569,1 +1650,1 @@\n-  if (replay_state == NULL) {\n+  if (no_replay_state()) {\n@@ -1579,0 +1660,10 @@\n+\n+bool ciReplay::is_klass_unresolved(const InstanceKlass* klass) {\n+  if (no_replay_state()) {\n+    return false;\n+  }\n+\n+  \/\/ Check if klass is found on whitelist.\n+  ciInstanceKlassRecord* rec = replay_state->find_ciInstanceKlass(klass);\n+  return rec == NULL;\n+}\n","filename":"src\/hotspot\/share\/ci\/ciReplay.cpp","additions":163,"deletions":72,"binary":false,"changes":235,"status":"modified"},{"patch":"@@ -206,2 +206,3 @@\n-  int get_int_table( int index ) const {\n-    return Bytes::get_Java_u4((address)&_table_base[index]); }\n+  jint get_int_table( int index ) const {\n+    return (jint)Bytes::get_Java_u4((address)&_table_base[index]);\n+  }\n@@ -210,1 +211,2 @@\n-    return cur_bci() + get_int_table(index); }\n+    return cur_bci() + get_int_table(index);\n+  }\n","filename":"src\/hotspot\/share\/ci\/ciStreams.hpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -170,1 +170,1 @@\n-  assert(cfs->allocated_on_stack(), \"should be local\");\n+  assert(cfs->allocated_on_stack_or_embedded(), \"should be local\");\n@@ -3299,0 +3299,7 @@\n+\n+    if (outer_class_info_index != 0) {\n+      const Symbol* const outer_class_name = cp->klass_name_at(outer_class_info_index);\n+      char* bytes = (char*)outer_class_name->bytes();\n+      guarantee_property(bytes[0] != JVM_SIGNATURE_ARRAY,\n+                         \"Outer class is an array class in class file %s\", CHECK_0);\n+    }\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1141,1 +1141,1 @@\n-  EventMark m(\"loading class %s\", class_name);\n+  EventMarkClassLoading m(\"Loading class %s\", class_name);\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+#include \"classfile\/systemDictionaryShared.hpp\"\n@@ -137,2 +138,1 @@\n-  _metaspace_lock(new Mutex(Mutex::nosafepoint-2, \"MetaspaceAllocation_lock\",\n-                            Mutex::_safepoint_check_never)),\n+  _metaspace_lock(new Mutex(Mutex::nosafepoint-2, \"MetaspaceAllocation_lock\")),\n@@ -357,0 +357,3 @@\n+  \/\/ To call this, one must have the MultiArray_lock held, but the _klasses list still has lock free reads.\n+  assert_locked_or_safepoint(MultiArray_lock);\n+\n@@ -905,0 +908,2 @@\n+      \/\/ But still have to remove it from the dumptime_table.\n+      SystemDictionaryShared::handle_class_unloading(ik);\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1011,1 +1011,1 @@\n-    java_lang_Class::set_klass(mirror(), k);\n+    set_klass(mirror(), k);\n@@ -1016,1 +1016,1 @@\n-    java_lang_Class::set_static_oop_field_count(mirror(), mk->compute_static_oop_field_count(mirror()));\n+    set_static_oop_field_count(mirror(), mk->compute_static_oop_field_count(mirror()));\n@@ -1055,1 +1055,1 @@\n-        java_lang_Class::set_klass(mirror(), NULL);\n+        set_klass(mirror(), NULL);\n@@ -1293,1 +1293,1 @@\n-      oop comp_mirror = java_lang_Class::component_mirror(mirror);\n+      oop comp_mirror = component_mirror(mirror);\n@@ -1305,1 +1305,1 @@\n-    java_lang_Class::set_component_mirror(archived_mirror, archived_comp_mirror);\n+    set_component_mirror(archived_mirror, archived_comp_mirror);\n@@ -1312,1 +1312,1 @@\n-    java_lang_Class:set_init_lock(archived_mirror, NULL);\n+    set_init_lock(archived_mirror, NULL);\n@@ -1425,1 +1425,1 @@\n-  java_lang_Class::set_module(k->java_mirror(), module());\n+  set_module(k->java_mirror(), module());\n@@ -1428,1 +1428,1 @@\n-void java_lang_Class::set_oop_size(HeapWord* java_class, int size) {\n+void java_lang_Class::set_oop_size(HeapWord* java_class, size_t size) {\n@@ -1430,2 +1430,3 @@\n-  assert(size > 0, \"Oop size must be greater than zero, not %d\", size);\n-  *(int*)(((char*)java_class) + _oop_size_offset) = size;\n+  assert(size > 0, \"Oop size must be greater than zero, not \" SIZE_FORMAT, size);\n+  assert(size <= INT_MAX, \"Lossy conversion: \" SIZE_FORMAT, size);\n+  *(int*)(((char*)java_class) + _oop_size_offset) = (int)size;\n@@ -1533,1 +1534,1 @@\n-    o = StringTable::intern(java_lang_Class::as_external_name(java_class()), THREAD);\n+    o = StringTable::intern(as_external_name(java_class()), THREAD);\n@@ -1560,1 +1561,1 @@\n-  assert(java_lang_Class::static_oop_field_count(java_class) == 0, \"should have been zeroed by allocation\");\n+  assert(static_oop_field_count(java_class) == 0, \"should have been zeroed by allocation\");\n@@ -1566,1 +1567,1 @@\n-  assert(java_lang_Class::is_instance(java_class), \"must be a Class object\");\n+  assert(is_instance(java_class), \"must be a Class object\");\n@@ -1572,1 +1573,1 @@\n-  assert(java_lang_Class::is_instance(java_class), \"must be a Class object\");\n+  assert(is_instance(java_class), \"must be a Class object\");\n@@ -1596,1 +1597,1 @@\n-  assert(java_lang_Class::is_instance(java_class), \"must be a Class object\");\n+  assert(is_instance(java_class), \"must be a Class object\");\n@@ -1632,1 +1633,1 @@\n-  assert(java_lang_Class::is_instance(java_class), \"must be a Class object\");\n+  assert(is_instance(java_class), \"must be a Class object\");\n@@ -1659,1 +1660,1 @@\n-  assert(java_lang_Class::is_primitive(java_class), \"just checking\");\n+  assert(is_primitive(java_class), \"just checking\");\n@@ -1673,1 +1674,1 @@\n-  assert(java_lang_Class::is_instance(java_class), \"must be a Class object\");\n+  assert(is_instance(java_class), \"must be a Class object\");\n@@ -1689,1 +1690,1 @@\n-  assert(java_lang_Class::is_primitive(mirror), \"must be primitive\");\n+  assert(is_primitive(mirror), \"must be primitive\");\n@@ -4302,2 +4303,2 @@\n-  nmethodBucket* volatile* vmdeps_addr = (nmethodBucket* volatile*)call_site->field_addr(_vmdependencies_offset);\n-  volatile uint64_t* last_cleanup_addr = (volatile uint64_t*)call_site->field_addr(_last_cleanup_offset);\n+  nmethodBucket* volatile* vmdeps_addr = call_site->field_addr<nmethodBucket* volatile>(_vmdependencies_offset);\n+  volatile uint64_t* last_cleanup_addr = call_site->field_addr<volatile uint64_t>(_last_cleanup_offset);\n@@ -4361,1 +4362,1 @@\n-  return HeapAccess<MO_ACQUIRE>::load_at(loader, _loader_data_offset);\n+  return Atomic::load_acquire(loader->field_addr<ClassLoaderData*>(_loader_data_offset));\n@@ -4367,1 +4368,1 @@\n-  return HeapAccess<>::load_at(loader, _loader_data_offset);\n+  return *loader->field_addr<ClassLoaderData*>(_loader_data_offset);\n@@ -4373,1 +4374,1 @@\n-  HeapAccess<MO_RELEASE>::store_at(loader, _loader_data_offset, new_data);\n+  Atomic::release_store(loader->field_addr<ClassLoaderData*>(_loader_data_offset), new_data);\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":25,"deletions":24,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -381,2 +381,2 @@\n-  static int oop_size(oop java_class);\n-  static void set_oop_size(HeapWord* java_class, int size);\n+  static size_t oop_size(oop java_class);\n+  static void set_oop_size(HeapWord* java_class, size_t size);\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -80,1 +80,1 @@\n-  return java_string->obj_field_addr<uint8_t>(_flags_offset);\n+  return java_string->field_addr<uint8_t>(_flags_offset);\n@@ -149,1 +149,1 @@\n-  return ref->obj_field_addr<HeapWord>(_referent_offset);\n+  return ref->field_addr<HeapWord>(_referent_offset);\n@@ -165,1 +165,1 @@\n-  return ref->obj_field_addr<HeapWord>(_next_offset);\n+  return ref->field_addr<HeapWord>(_next_offset);\n@@ -181,1 +181,1 @@\n-  return ref->obj_field_addr<HeapWord>(_discovered_offset);\n+  return ref->field_addr<HeapWord>(_discovered_offset);\n@@ -282,1 +282,1 @@\n-inline int java_lang_Class::oop_size(oop java_class) {\n+inline size_t java_lang_Class::oop_size(oop java_class) {\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.inline.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -82,0 +82,1 @@\n+#include \"services\/finalizerService.hpp\"\n@@ -1680,1 +1681,1 @@\n-\n+      MANAGEMENT_ONLY(FinalizerService::purge_unloaded();)\n@@ -1704,0 +1705,1 @@\n+    MutexLocker ml(is_concurrent ? ClassInitError_lock : NULL);\n@@ -2435,2 +2437,2 @@\n-  \/\/ call condy: java.lang.invoke.MethodHandleNatives::linkDynamicConstant(caller, condy_index, bsm, type, info)\n-  \/\/       indy: java.lang.invoke.MethodHandleNatives::linkCallSite(caller, indy_index, bsm, name, mtype, info, &appendix)\n+  \/\/ call condy: java.lang.invoke.MethodHandleNatives::linkDynamicConstant(caller, bsm, type, info)\n+  \/\/       indy: java.lang.invoke.MethodHandleNatives::linkCallSite(caller, bsm, name, mtype, info, &appendix)\n@@ -2439,1 +2441,0 @@\n-  args.push_int(bootstrap_specifier.bss_index());\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1854,1 +1854,1 @@\n-          \/\/ And jsr and ret are not in the new class file format in JDK1.5.\n+          \/\/ And jsr and ret are not in the new class file format in JDK1.6.\n@@ -2366,0 +2366,1 @@\n+  bool is_getfield = false;\n@@ -2424,0 +2425,1 @@\n+      is_getfield = true;\n@@ -2426,3 +2428,0 @@\n-      for (int i = 0; i < n; i++) {\n-        current_frame->push_stack(field_type[i], CHECK_VERIFY(this));\n-      }\n@@ -2458,1 +2457,9 @@\n-      if (was_recursively_verified()) return;\n+      if (was_recursively_verified()) {\n+        if (is_getfield) {\n+          \/\/ Push field type for getfield.\n+          for (int i = 0; i < n; i++) {\n+            current_frame->push_stack(field_type[i], CHECK_VERIFY(this));\n+          }\n+        }\n+        return;\n+      }\n@@ -2479,1 +2486,2 @@\n-              \"Bad access to protected data in getfield\");\n+              \"Bad access to protected data in %s\",\n+              is_getfield ? \"getfield\" : \"putfield\");\n@@ -2487,0 +2495,6 @@\n+  if (is_getfield) {\n+    \/\/ Push field type for getfield after doing protection check.\n+    for (int i = 0; i < n; i++) {\n+      current_frame->push_stack(field_type[i], CHECK_VERIFY(this));\n+    }\n+  }\n","filename":"src\/hotspot\/share\/classfile\/verifier.cpp","additions":20,"deletions":6,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  const int neg = JVM_ACC_STATIC | JVM_ACC_SYNCHRONIZED;\n+  const int neg = JVM_ACC_STATIC | JVM_ACC_SYNCHRONIZED | JVM_ACC_NATIVE;\n@@ -42,1 +42,1 @@\n-  const int neg = JVM_ACC_STATIC;\n+  const int neg = JVM_ACC_STATIC | JVM_ACC_NATIVE;\n@@ -54,1 +54,1 @@\n-  const int neg = JVM_ACC_SYNCHRONIZED;\n+  const int neg = JVM_ACC_SYNCHRONIZED | JVM_ACC_NATIVE;\n@@ -84,0 +84,1 @@\n+  case vmIntrinsics::_dsqrt_strict:\n@@ -130,0 +131,1 @@\n+  case vmIntrinsics::_dsqrt_strict:\n@@ -270,0 +272,1 @@\n+  case vmIntrinsics::_dsqrt_strict:\n@@ -278,2 +281,0 @@\n-  case vmIntrinsics::_min:\n-  case vmIntrinsics::_max:\n@@ -282,0 +283,2 @@\n+  case vmIntrinsics::_min:\n+  case vmIntrinsics::_max:\n@@ -286,0 +289,6 @@\n+  case vmIntrinsics::_min_strict:\n+  case vmIntrinsics::_max_strict:\n+  case vmIntrinsics::_maxF_strict:\n+  case vmIntrinsics::_minF_strict:\n+  case vmIntrinsics::_maxD_strict:\n+  case vmIntrinsics::_minD_strict:\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":14,"deletions":5,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -110,1 +110,1 @@\n-  do_intrinsic(_hashCode,                 java_lang_Object,       hashCode_name, void_int_signature,             F_R)   \\\n+  do_intrinsic(_hashCode,                 java_lang_Object,       hashCode_name, void_int_signature,             F_RN)  \\\n@@ -112,1 +112,1 @@\n-  do_intrinsic(_getClass,                 java_lang_Object,       getClass_name, void_class_signature,           F_R)   \\\n+  do_intrinsic(_getClass,                 java_lang_Object,       getClass_name, void_class_signature,           F_RN)  \\\n@@ -114,1 +114,1 @@\n-  do_intrinsic(_clone,                    java_lang_Object,       clone_name, void_object_signature,             F_R)   \\\n+  do_intrinsic(_clone,                    java_lang_Object,       clone_name, void_object_signature,             F_RN)  \\\n@@ -116,1 +116,1 @@\n-  do_intrinsic(_notify,                   java_lang_Object,       notify_name, void_method_signature,            F_R)   \\\n+  do_intrinsic(_notify,                   java_lang_Object,       notify_name, void_method_signature,            F_RN)  \\\n@@ -118,1 +118,1 @@\n-  do_intrinsic(_notifyAll,                java_lang_Object,       notifyAll_name, void_method_signature,         F_R)   \\\n+  do_intrinsic(_notifyAll,                java_lang_Object,       notifyAll_name, void_method_signature,         F_RN)  \\\n@@ -143,0 +143,1 @@\n+  do_name(unsignedMultiplyHigh_name,\"unsignedMultiplyHigh\")                                                             \\\n@@ -176,0 +177,1 @@\n+  do_intrinsic(_unsignedMultiplyHigh,     java_lang_Math,         unsignedMultiplyHigh_name, long2_long_signature, F_S) \\\n@@ -191,1 +193,11 @@\n-  do_intrinsic(_floatToRawIntBits,        java_lang_Float,        floatToRawIntBits_name,   float_int_signature, F_S)   \\\n+  \/* StrictMath intrinsics, similar to what we have in Math. *\/                                                         \\\n+  do_intrinsic(_min_strict,               java_lang_StrictMath,   min_name,           int2_int_signature,        F_S)   \\\n+  do_intrinsic(_max_strict,               java_lang_StrictMath,   max_name,           int2_int_signature,        F_S)   \\\n+  do_intrinsic(_minF_strict,              java_lang_StrictMath,   min_name,           float2_float_signature,    F_S)   \\\n+  do_intrinsic(_maxF_strict,              java_lang_StrictMath,   max_name,           float2_float_signature,    F_S)   \\\n+  do_intrinsic(_minD_strict,              java_lang_StrictMath,   min_name,           double2_double_signature,  F_S)   \\\n+  do_intrinsic(_maxD_strict,              java_lang_StrictMath,   max_name,           double2_double_signature,  F_S)   \\\n+  \/* Special flavor of dsqrt intrinsic to handle the \"native\" method in StrictMath. Otherwise the same as in Math. *\/   \\\n+  do_intrinsic(_dsqrt_strict,             java_lang_StrictMath,   sqrt_name,          double_double_signature,   F_SN)  \\\n+                                                                                                                        \\\n+  do_intrinsic(_floatToRawIntBits,        java_lang_Float,        floatToRawIntBits_name,   float_int_signature, F_SN)  \\\n@@ -195,1 +207,1 @@\n-  do_intrinsic(_intBitsToFloat,           java_lang_Float,        intBitsToFloat_name,      int_float_signature, F_S)   \\\n+  do_intrinsic(_intBitsToFloat,           java_lang_Float,        intBitsToFloat_name,      int_float_signature, F_SN)  \\\n@@ -197,1 +209,1 @@\n-  do_intrinsic(_doubleToRawLongBits,      java_lang_Double,       doubleToRawLongBits_name, double_long_signature, F_S) \\\n+  do_intrinsic(_doubleToRawLongBits,      java_lang_Double,       doubleToRawLongBits_name, double_long_signature, F_SN)\\\n@@ -201,1 +213,1 @@\n-  do_intrinsic(_longBitsToDouble,         java_lang_Double,       longBitsToDouble_name,    long_double_signature, F_S) \\\n+  do_intrinsic(_longBitsToDouble,         java_lang_Double,       longBitsToDouble_name,    long_double_signature, F_SN)\\\n@@ -222,1 +234,1 @@\n-  do_intrinsic(_identityHashCode,         java_lang_System,       identityHashCode_name, object_int_signature,   F_S)   \\\n+  do_intrinsic(_identityHashCode,         java_lang_System,       identityHashCode_name, object_int_signature,   F_SN)  \\\n@@ -224,1 +236,1 @@\n-  do_intrinsic(_currentTimeMillis,        java_lang_System,       currentTimeMillis_name, void_long_signature,   F_S)   \\\n+  do_intrinsic(_currentTimeMillis,        java_lang_System,       currentTimeMillis_name, void_long_signature,   F_SN)  \\\n@@ -227,1 +239,1 @@\n-  do_intrinsic(_nanoTime,                 java_lang_System,       nanoTime_name,          void_long_signature,   F_S)   \\\n+  do_intrinsic(_nanoTime,                 java_lang_System,       nanoTime_name,          void_long_signature,   F_SN)  \\\n@@ -232,1 +244,1 @@\n-  do_intrinsic(_arraycopy,                java_lang_System,       arraycopy_name, arraycopy_signature,           F_S)   \\\n+  do_intrinsic(_arraycopy,                java_lang_System,       arraycopy_name, arraycopy_signature,           F_SN)  \\\n@@ -235,1 +247,1 @@\n-  do_intrinsic(_currentThread,            java_lang_Thread,       currentThread_name, currentThread_signature,   F_S)   \\\n+  do_intrinsic(_currentThread,            java_lang_Thread,       currentThread_name, currentThread_signature,   F_SN)  \\\n@@ -396,3 +408,3 @@\n-  do_intrinsic(_Reference_get,            java_lang_ref_Reference, get_name,    void_object_signature, F_R)             \\\n-  do_intrinsic(_Reference_refersTo0,     java_lang_ref_Reference, refersTo0_name, object_boolean_signature, F_R)        \\\n-  do_intrinsic(_PhantomReference_refersTo0, java_lang_ref_PhantomReference, refersTo0_name, object_boolean_signature, F_R) \\\n+  do_intrinsic(_Reference_get,              java_lang_ref_Reference, get_name,       void_object_signature,    F_R)     \\\n+  do_intrinsic(_Reference_refersTo0,        java_lang_ref_Reference, refersTo0_name, object_boolean_signature, F_RN)    \\\n+  do_intrinsic(_PhantomReference_refersTo0, java_lang_ref_PhantomReference, refersTo0_name, object_boolean_signature, F_RN) \\\n@@ -522,1 +534,1 @@\n-  do_intrinsic(_loadFence,                jdk_internal_misc_Unsafe,     loadFence_name, loadFence_signature,           F_RN)     \\\n+  do_intrinsic(_loadFence,                jdk_internal_misc_Unsafe,     loadFence_name, loadFence_signature,           F_R)      \\\n@@ -525,1 +537,1 @@\n-  do_intrinsic(_storeFence,               jdk_internal_misc_Unsafe,     storeFence_name, storeFence_signature,         F_RN)     \\\n+  do_intrinsic(_storeFence,               jdk_internal_misc_Unsafe,     storeFence_name, storeFence_signature,         F_R)      \\\n@@ -528,0 +540,3 @@\n+  do_intrinsic(_storeStoreFence,          jdk_internal_misc_Unsafe,     storeStoreFence_name, storeStoreFence_signature, F_R)    \\\n+   do_name(     storeStoreFence_name,                                   \"storeStoreFence\")                                       \\\n+   do_alias(    storeStoreFence_signature,                              void_method_signature)                                   \\\n@@ -834,1 +849,8 @@\n-   do_signature(vector_unary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/util\/function\/Function;)Ljava\/lang\/Object;\") \\\n+   do_signature(vector_unary_op_sig, \"(I\"                                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Class;Ljava\/lang\/Class;\"                                                                     \\\n+                                      \"I\"                                                                                                      \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                          \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                      \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$UnaryOperation;)\"                                                 \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                         \\\n@@ -838,2 +860,10 @@\n-   do_signature(vector_binary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"                              \\\n-                                       \"Ljava\/util\/function\/BiFunction;)Ljava\/lang\/Object;\")                                                   \\\n+   do_signature(vector_binary_op_sig, \"(I\"                                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"I\"                                                                                                     \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\"                                                  \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\"                                                  \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                     \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$BinaryOperation;)\"                                               \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                                 \\\n@@ -843,2 +873,11 @@\n-   do_signature(vector_ternary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"                             \\\n-                                        \"Ljava\/lang\/Object;Ljdk\/internal\/vm\/vector\/VectorSupport$TernaryOperation;)Ljava\/lang\/Object;\")        \\\n+   do_signature(vector_ternary_op_sig, \"(I\"                                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"I\"                                                                                                    \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                        \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                        \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                        \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                    \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$TernaryOperation;)\"                                             \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                       \\\n@@ -848,2 +887,7 @@\n-   do_signature(vector_broadcast_coerced_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;IJLjdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"      \\\n-                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$BroadcastOperation;)Ljava\/lang\/Object;\")                 \\\n+   do_signature(vector_broadcast_coerced_sig, \"(Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"I\"                                                                                             \\\n+                                               \"J\"                                                                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                                          \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$BroadcastOperation;)\"                                    \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                         \\\n@@ -853,2 +897,6 @@\n-   do_signature(vector_shuffle_step_iota_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"        \\\n-                                               \"IIIILjdk\/internal\/vm\/vector\/VectorSupport$ShuffleIotaOperation;)Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\") \\\n+   do_signature(vector_shuffle_step_iota_sig, \"(Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                                          \\\n+                                               \"IIII\"                                                                                          \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$ShuffleIotaOperation;)\"                                  \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\")                                         \\\n@@ -858,2 +906,6 @@\n-   do_signature(vector_shuffle_to_vector_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\" \\\n-                                               \"ILjdk\/internal\/vm\/vector\/VectorSupport$ShuffleToVectorOperation;)Ljava\/lang\/Object;\")          \\\n+   do_signature(vector_shuffle_to_vector_sig, \"(Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\"                                          \\\n+                                               \"ILjdk\/internal\/vm\/vector\/VectorSupport$ShuffleToVectorOperation;)\"                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                \\\n@@ -863,2 +915,10 @@\n-   do_signature(vector_load_op_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;JLjava\/lang\/Object;\"                                \\\n-                                     \"ILjdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;Ljdk\/internal\/vm\/vector\/VectorSupport$LoadOperation;)Ljava\/lang\/Object;\") \\\n+   do_signature(vector_load_op_sig, \"(Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Object;\"                                                                                      \\\n+                                     \"J\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Object;\"                                                                                      \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                                                    \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$LoadOperation;)\"                                                   \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                                   \\\n@@ -867,0 +927,15 @@\n+  do_intrinsic(_VectorLoadMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_load_masked_op_name, vector_load_masked_op_sig, F_S)          \\\n+   do_signature(vector_load_masked_op_sig, \"(Ljava\/lang\/Class;\"                                                                                \\\n+                                            \"Ljava\/lang\/Class;\"                                                                                \\\n+                                            \"Ljava\/lang\/Class;\"                                                                                \\\n+                                            \"I\"                                                                                                \\\n+                                            \"Ljava\/lang\/Object;\"                                                                               \\\n+                                            \"J\"                                                                                                \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                \\\n+                                            \"Ljava\/lang\/Object;\"                                                                               \\\n+                                            \"I\"                                                                                                \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                                             \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$LoadVectorMaskedOperation;)\"                                \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                   \\\n+   do_name(vector_load_masked_op_name,     \"loadMasked\")                                                                                       \\\n+                                                                                                                                               \\\n@@ -868,2 +943,8 @@\n-   do_signature(vector_store_op_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;JLjdk\/internal\/vm\/vector\/VectorSupport$Vector;\"    \\\n-                                      \"Ljava\/lang\/Object;ILjdk\/internal\/vm\/vector\/VectorSupport$StoreVectorOperation;)V\")                      \\\n+   do_signature(vector_store_op_sig, \"(Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"I\"                                                                                                      \\\n+                                      \"Ljava\/lang\/Object;\"                                                                                     \\\n+                                      \"J\"                                                                                                      \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                          \\\n+                                      \"Ljava\/lang\/Object;ILjdk\/internal\/vm\/vector\/VectorSupport$StoreVectorOperation;)\"                        \\\n+                                      \"V\")                                                                                                     \\\n@@ -872,2 +953,25 @@\n-  do_intrinsic(_VectorReductionCoerced, jdk_internal_vm_vector_VectorSupport, vector_reduction_coerced_name, vector_reduction_coerced_sig, F_S) \\\n-   do_signature(vector_reduction_coerced_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljava\/util\/function\/Function;)J\") \\\n+  do_intrinsic(_VectorStoreMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_store_masked_op_name, vector_store_masked_op_sig, F_S)       \\\n+   do_signature(vector_store_masked_op_sig, \"(Ljava\/lang\/Class;\"                                                                               \\\n+                                             \"Ljava\/lang\/Class;\"                                                                               \\\n+                                             \"Ljava\/lang\/Class;\"                                                                               \\\n+                                             \"I\"                                                                                               \\\n+                                             \"Ljava\/lang\/Object;\"                                                                              \\\n+                                             \"J\"                                                                                               \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                   \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                               \\\n+                                             \"Ljava\/lang\/Object;\"                                                                              \\\n+                                             \"I\"                                                                                               \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$StoreVectorMaskedOperation;)\"                              \\\n+                                             \"V\")                                                                                              \\\n+   do_name(vector_store_masked_op_name,     \"storeMasked\")                                                                                     \\\n+                                                                                                                                               \\\n+  do_intrinsic(_VectorReductionCoerced, jdk_internal_vm_vector_VectorSupport, vector_reduction_coerced_name, vector_reduction_coerced_sig, F_S)\\\n+   do_signature(vector_reduction_coerced_sig, \"(I\"                                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"I\"                                                                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                 \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$ReductionOperation;)\"                                    \\\n+                                               \"J\")                                                                                            \\\n@@ -877,1 +981,8 @@\n-   do_signature(vector_test_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/util\/function\/BiFunction;)Z\") \\\n+   do_signature(vector_test_sig, \"(I\"                                                                                                          \\\n+                                  \"Ljava\/lang\/Class;\"                                                                                          \\\n+                                  \"Ljava\/lang\/Class;\"                                                                                          \\\n+                                  \"I\"                                                                                                          \\\n+                                  \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                          \\\n+                                  \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                          \\\n+                                  \"Ljava\/util\/function\/BiFunction;)\"                                                                           \\\n+                                  \"Z\")                                                                                                         \\\n@@ -881,3 +992,9 @@\n-   do_signature(vector_blend_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                      \\\n-                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\" \\\n-                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorBlendOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")       \\\n+   do_signature(vector_blend_sig, \"(Ljava\/lang\/Class;\"                                                                                         \\\n+                                   \"Ljava\/lang\/Class;\"                                                                                         \\\n+                                   \"Ljava\/lang\/Class;\"                                                                                         \\\n+                                   \"I\"                                                                                                         \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                             \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                             \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                         \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorBlendOp;)\"                                                     \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                            \\\n@@ -887,3 +1004,9 @@\n-   do_signature(vector_compare_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                   \\\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\" \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"           \\\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorCompareOp;\" \")\" \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\") \\\n+   do_signature(vector_compare_sig, \"(I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;Ljava\/lang\/Class;\"                                                                      \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                           \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                           \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorCompareOp;)\"                                                 \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\")                                                      \\\n@@ -893,3 +1016,10 @@\n-   do_signature(vector_rearrange_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                  \\\n-                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\"     \\\n-                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorRearrangeOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\") \\\n+   do_signature(vector_rearrange_sig, \"(Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"I\"                                                                                                     \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                         \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\"                                                  \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                     \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorRearrangeOp;)\"                                             \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                        \\\n@@ -899,3 +1029,7 @@\n-   do_signature(vector_extract_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                                     \\\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;I\"                                                          \\\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VecExtractOp;)J\")                                                  \\\n+   do_signature(vector_extract_sig, \"(Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                           \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VecExtractOp;)\"                                                    \\\n+                                     \"J\")                                                                                                      \\\n@@ -905,3 +1039,7 @@\n-   do_signature(vector_insert_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                                      \\\n-                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;IJ\"                                                          \\\n-                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$VecInsertOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")        \\\n+   do_signature(vector_insert_sig, \"(Ljava\/lang\/Class;\"                                                                                        \\\n+                                    \"Ljava\/lang\/Class;\"                                                                                        \\\n+                                    \"I\"                                                                                                        \\\n+                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                            \\\n+                                    \"IJ\"                                                                                                       \\\n+                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$VecInsertOp;)\"                                                      \\\n+                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                           \\\n@@ -911,3 +1049,10 @@\n-   do_signature(vector_broadcast_int_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;I\"                                                              \\\n-                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;I\"                                                    \\\n-                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorBroadcastIntOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\") \\\n+   do_signature(vector_broadcast_int_sig, \"(I\"                                                                                                 \\\n+                                           \"Ljava\/lang\/Class;\"                                                                                 \\\n+                                           \"Ljava\/lang\/Class;\"                                                                                 \\\n+                                           \"Ljava\/lang\/Class;\"                                                                                 \\\n+                                           \"I\"                                                                                                 \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                     \\\n+                                           \"I\"                                                                                                 \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                 \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorBroadcastIntOp;)\"                                      \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                    \\\n@@ -917,2 +1062,7 @@\n-   do_signature(vector_convert_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;I\"                                                                    \\\n-                                     \"Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                                     \\\n+   do_signature(vector_convert_sig, \"(I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n@@ -921,1 +1071,2 @@\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorConvertOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\") \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorConvertOp;)\"                                                 \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                                   \\\n@@ -925,2 +1076,7 @@\n-    do_signature(vector_gather_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Class;\"                                                    \\\n-                                     \"Ljava\/lang\/Object;J\"                                                                                     \\\n+    do_signature(vector_gather_sig, \"(Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Object;\"                                                                                      \\\n+                                     \"J\"                                                                                                       \\\n@@ -928,1 +1084,3 @@\n-                                     \"Ljava\/lang\/Object;I[II\"                                                                                  \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                       \\\n+                                     \"Ljava\/lang\/Object;\"                                                                                      \\\n+                                     \"I[II\"                                                                                                    \\\n@@ -935,5 +1093,13 @@\n-    do_signature(vector_scatter_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Class;\"                                                   \\\n-                                      \"Ljava\/lang\/Object;J\"                                                                                    \\\n-                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"             \\\n-                                      \"Ljava\/lang\/Object;I[II\"                                                                                 \\\n-                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$StoreVectorOperationWithMap;)V\")                                  \\\n+    do_signature(vector_scatter_sig, \"(Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"I\"                                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Object;\"                                                                                     \\\n+                                      \"J\"                                                                                                      \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                          \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                          \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;Ljava\/lang\/Object;\"                                    \\\n+                                      \"I[II\"                                                                                                   \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$StoreVectorOperationWithMap;)\"                                    \\\n+                                      \"V\")                                                                                                     \\\n@@ -943,1 +1109,2 @@\n-   do_alias(vector_rebox_sig, object_object_signature)                                                                                         \\\n+    do_signature(vector_rebox_sig, \"(Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;)\"                                                    \\\n+                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                                    \\\n@@ -947,2 +1114,7 @@\n-    do_signature(vector_mask_oper_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;\"                                               \\\n-                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMaskOp;)I\")                                               \\\n+    do_signature(vector_mask_oper_sig, \"(I\"                                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"I\"                                                                                                    \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                    \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMaskOp;)\"                                                 \\\n+                                        \"J\")                                                                                                   \\\n@@ -953,1 +1125,1 @@\n-  do_intrinsic(_park,                     jdk_internal_misc_Unsafe,     park_name, park_signature,                     F_R)    \\\n+  do_intrinsic(_park,                     jdk_internal_misc_Unsafe,     park_name, park_signature,                     F_RN)   \\\n@@ -956,1 +1128,1 @@\n-  do_intrinsic(_unpark,                   jdk_internal_misc_Unsafe,     unpark_name, unpark_signature,                 F_R)    \\\n+  do_intrinsic(_unpark,                   jdk_internal_misc_Unsafe,     unpark_name, unpark_signature,                 F_RN)   \\\n@@ -1092,3 +1264,3 @@\n-    F_R,                        \/\/ !static ?native !synchronized (R=\"regular\")\n-    F_S,                        \/\/  static ?native !synchronized\n-    F_Y,                        \/\/ !static ?native  synchronized\n+    F_R,                        \/\/ !static !native !synchronized (R=\"regular\")\n+    F_S,                        \/\/  static !native !synchronized\n+    F_Y,                        \/\/ !static !native  synchronized\n@@ -1104,0 +1276,44 @@\n+  static constexpr bool is_flag_static(Flags flags) {\n+    switch (flags) {\n+      case F_S:\n+      case F_SN:\n+        return true;\n+      case F_R:\n+      case F_Y:\n+      case F_RN:\n+        return false;\n+      default:\n+        ShouldNotReachHere();\n+        return false;\n+    }\n+  }\n+\n+  static constexpr bool is_flag_synchronized(Flags flags) {\n+    switch (flags) {\n+      case F_Y:\n+        return true;\n+      case F_RN:\n+      case F_SN:\n+      case F_S:\n+      case F_R:\n+        return false;\n+      default:\n+        ShouldNotReachHere();\n+        return false;\n+    }\n+  }\n+\n+  static constexpr bool is_flag_native(Flags flags) {\n+    switch (flags) {\n+      case F_RN:\n+      case F_SN:\n+        return true;\n+      case F_S:\n+      case F_R:\n+      case F_Y:\n+        return false;\n+      default:\n+        ShouldNotReachHere();\n+        return false;\n+    }\n+  }\n@@ -1155,3 +1371,9 @@\n-    assert(    class_for(id) == holder, \"correct id\");\n-    assert(     name_for(id) == name,   \"correct id\");\n-    assert(signature_for(id) == sig,    \"correct id\");\n+    assert(    class_for(id) == holder, \"correct class: %s\",     name_at(id));\n+    assert(     name_for(id) == name,   \"correct name: %s\",      name_at(id));\n+    assert(signature_for(id) == sig,    \"correct signature: %s\", name_at(id));\n+    assert(      is_flag_static(flags_for(id)) == ((flags & JVM_ACC_STATIC)       != 0),\n+                 \"correct static flag: %s\", name_at(id));\n+    assert(is_flag_synchronized(flags_for(id)) == ((flags & JVM_ACC_SYNCHRONIZED) != 0),\n+           \"correct synchronized flag: %s\", name_at(id));\n+    assert(      is_flag_native(flags_for(id)) == ((flags & JVM_ACC_NATIVE)       != 0),\n+                 \"correct native flag: %s\", name_at(id));\n@@ -1166,1 +1388,1 @@\n-  static Flags              flags_for(ID id);\n+  static Flags          flags_for(ID id);\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":300,"deletions":78,"binary":false,"changes":378,"status":"modified"},{"patch":"@@ -345,1 +345,1 @@\n-  template(linkDynamicConstant_signature, \"(Ljava\/lang\/Object;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;)Ljava\/lang\/Object;\") \\\n+  template(linkDynamicConstant_signature, \"(Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;)Ljava\/lang\/Object;\") \\\n@@ -347,1 +347,1 @@\n-  template(linkCallSite_signature, \"(Ljava\/lang\/Object;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;[Ljava\/lang\/Object;)Ljava\/lang\/invoke\/MemberName;\") \\\n+  template(linkCallSite_signature, \"(Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;[Ljava\/lang\/Object;)Ljava\/lang\/invoke\/MemberName;\") \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -685,1 +685,6 @@\n-    nm->print_nmethod(verbose);\n+    if (verbose && st == tty) {\n+      \/\/ verbose is only ever true when called from findpc in debug.cpp\n+      nm->print_nmethod(true);\n+    } else {\n+      nm->print(st);\n+    }\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -495,0 +495,4 @@\n+    } else {\n+      \/\/ This inline cache is a megamorphic vtable call. Those ICs never hold\n+      \/\/ any Metadata and should therefore never be cleaned by this function.\n+      return true;\n","filename":"src\/hotspot\/share\/code\/compiledMethod.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -70,0 +70,1 @@\n+#include \"runtime\/threadWXSetters.inline.hpp\"\n@@ -2555,1 +2556,1 @@\n-  print_on(tty, NULL);\n+  print_on(st, NULL);\n@@ -2906,0 +2907,3 @@\n+  \/\/ Decoding an nmethod can write to a PcDescCache (see PcDescCache::add_pc_desc)\n+  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, Thread::current());)\n+\n@@ -2915,0 +2919,1 @@\n+    st->print_cr(\"[Disassembly]\");\n@@ -2916,0 +2921,2 @@\n+    st->bol();\n+    st->print_cr(\"[\/Disassembly]\");\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2203,1 +2203,1 @@\n-  push_jni_handle_block();\n+  JNIHandleMark jhm(thread);\n@@ -2322,3 +2322,0 @@\n-  \/\/ Remove the JNI handle block after the ciEnv destructor has run in\n-  \/\/ the previous block.\n-  pop_jni_handle_block();\n@@ -2485,32 +2482,0 @@\n-\/\/ ------------------------------------------------------------------\n-\/\/ CompileBroker::push_jni_handle_block\n-\/\/\n-\/\/ Push on a new block of JNI handles.\n-void CompileBroker::push_jni_handle_block() {\n-  JavaThread* thread = JavaThread::current();\n-\n-  \/\/ Allocate a new block for JNI handles.\n-  \/\/ Inlined code from jni_PushLocalFrame()\n-  JNIHandleBlock* java_handles = thread->active_handles();\n-  JNIHandleBlock* compile_handles = JNIHandleBlock::allocate_block(thread);\n-  assert(compile_handles != NULL && java_handles != NULL, \"should not be NULL\");\n-  compile_handles->set_pop_frame_link(java_handles);  \/\/ make sure java handles get gc'd.\n-  thread->set_active_handles(compile_handles);\n-}\n-\n-\n-\/\/ ------------------------------------------------------------------\n-\/\/ CompileBroker::pop_jni_handle_block\n-\/\/\n-\/\/ Pop off the current block of JNI handles.\n-void CompileBroker::pop_jni_handle_block() {\n-  JavaThread* thread = JavaThread::current();\n-\n-  \/\/ Release our JNI handle block\n-  JNIHandleBlock* compile_handles = thread->active_handles();\n-  JNIHandleBlock* java_handles = compile_handles->pop_frame_link();\n-  thread->set_active_handles(java_handles);\n-  compile_handles->set_pop_frame_link(NULL);\n-  JNIHandleBlock::release_block(compile_handles, thread); \/\/ may block\n-}\n-\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":1,"deletions":36,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -88,1 +88,1 @@\n-    NOT_PRODUCT(_evac_failure_inject_counter(0) COMMA)\n+    EVAC_FAILURE_INJECTOR_ONLY(_evac_failure_inject_counter(0) COMMA)\n@@ -238,2 +238,2 @@\n-  HeapRegion* hr = _g1h->heap_region_containing(to_array);\n-  G1SkipCardEnqueueSetter x(&_scanner, hr->is_young());\n+  G1HeapRegionAttr dest_attr = _g1h->region_attr(to_array);\n+  G1SkipCardEnqueueSetter x(&_scanner, dest_attr.is_new_survivor());\n@@ -271,0 +271,5 @@\n+  \/\/ Skip the card enqueue iff the object (to_array) is in survivor region.\n+  \/\/ However, HeapRegion::is_survivor() is too expensive here.\n+  \/\/ Instead, we use dest_attr.is_young() because the two values are always\n+  \/\/ equal: successfully allocated young regions must be survivor regions.\n+  assert(dest_attr.is_young() == _g1h->heap_region_containing(to_array)->is_survivor(), \"must be\");\n@@ -418,1 +423,1 @@\n-#ifndef PRODUCT\n+#if EVAC_FAILURE_INJECTOR\n@@ -496,0 +501,5 @@\n+    } else {\n+      \/\/ Currently we only have two destinations and we only need BOT updates for\n+      \/\/ old. If the current allocation was done outside the PLAB this call will\n+      \/\/ have no effect since the _top of the PLAB has not changed.\n+      _plab_allocator->update_bot_for_plab_allocation(dest_attr, word_sz, node_index);\n@@ -523,0 +533,5 @@\n+    \/\/ Skip the card enqueue iff the object (obj) is in survivor region.\n+    \/\/ However, HeapRegion::is_survivor() is too expensive here.\n+    \/\/ Instead, we use dest_attr.is_young() because the two values are always\n+    \/\/ equal: successfully allocated young regions must be survivor regions.\n+    assert(dest_attr.is_young() == _g1h->heap_region_containing(obj)->is_survivor(), \"must be\");\n@@ -601,0 +616,3 @@\n+    \/\/ Records evac failure objs, this will help speed up iteration\n+    \/\/ of these objs later in *remove self forward* phase of post evacuation.\n+    r->record_evac_failure_obj(old);\n@@ -609,1 +627,8 @@\n-    G1SkipCardEnqueueSetter x(&_scanner, r->is_young());\n+    \/\/ For iterating objects that failed evacuation currently we can reuse the\n+    \/\/ existing closure to scan evacuated objects because:\n+    \/\/ - for objects referring into the collection set we do not need to gather\n+    \/\/ cards at this time. The regions they are in will be unconditionally turned\n+    \/\/ to old regions without remembered sets.\n+    \/\/ - since we are iterating from a collection set region (i.e. never a Survivor\n+    \/\/ region), we always need to gather cards for this case.\n+    G1SkipCardEnqueueSetter x(&_scanner, false \/* skip_card_enqueue *\/);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":30,"deletions":5,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -71,1 +71,1 @@\n-  uint parallel_gc_threads = ParallelScavengeHeap::heap()->workers().total_workers();\n+  uint parallel_gc_threads = ParallelScavengeHeap::heap()->workers().max_workers();\n@@ -91,1 +91,1 @@\n-  assert(ParallelScavengeHeap::heap()->workers().total_workers() != 0,\n+  assert(ParallelScavengeHeap::heap()->workers().max_workers() != 0,\n@@ -96,2 +96,1 @@\n-  _shadow_region_monitor = new Monitor(Mutex::nosafepoint, \"CompactionManager_lock\",\n-                                       Monitor::_safepoint_check_never);\n+  _shadow_region_monitor = new Monitor(Mutex::nosafepoint, \"CompactionManager_lock\");\n@@ -101,1 +100,1 @@\n-  uint parallel_gc_threads = ParallelScavengeHeap::heap()->workers().total_workers();\n+  uint parallel_gc_threads = ParallelScavengeHeap::heap()->workers().max_workers();\n@@ -108,1 +107,1 @@\n-  uint parallel_gc_threads = ParallelScavengeHeap::heap()->workers().total_workers();\n+  uint parallel_gc_threads = ParallelScavengeHeap::heap()->workers().max_workers();\n","filename":"src\/hotspot\/share\/gc\/parallel\/psCompactionManager.cpp","additions":5,"deletions":6,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -63,1 +63,2 @@\n-#include \"gc\/shared\/workgroup.hpp\"\n+#include \"gc\/shared\/workerThread.hpp\"\n+#include \"gc\/shared\/workerUtils.hpp\"\n@@ -855,1 +856,0 @@\n-      true,                \/\/ mt discovery\n@@ -1769,1 +1769,1 @@\n-      WorkerPolicy::calc_active_workers(ParallelScavengeHeap::heap()->workers().total_workers(),\n+      WorkerPolicy::calc_active_workers(ParallelScavengeHeap::heap()->workers().max_workers(),\n@@ -1772,1 +1772,1 @@\n-    ParallelScavengeHeap::heap()->workers().update_active_workers(active_workers);\n+    ParallelScavengeHeap::heap()->workers().set_active_workers(active_workers);\n@@ -1926,2 +1926,0 @@\n-  NOT_PRODUCT(ref_processor()->verify_no_references_recorded());\n-\n@@ -2020,1 +2018,1 @@\n-class MarkFromRootsTask : public AbstractGangTask {\n+class MarkFromRootsTask : public WorkerTask {\n@@ -2029,1 +2027,1 @@\n-      AbstractGangTask(\"MarkFromRootsTask\"),\n+      WorkerTask(\"MarkFromRootsTask\"),\n@@ -2156,1 +2154,1 @@\n-class PSAdjustTask final : public AbstractGangTask {\n+class PSAdjustTask final : public WorkerTask {\n@@ -2164,2 +2162,0 @@\n-    PSAdjustSubTask_old_ref_process,\n-    PSAdjustSubTask_young_ref_process,\n@@ -2172,1 +2168,1 @@\n-    AbstractGangTask(\"PSAdjust task\"),\n+    WorkerTask(\"PSAdjust task\"),\n@@ -2207,10 +2203,0 @@\n-    if (_sub_tasks.try_claim_task(PSAdjustSubTask_old_ref_process)) {\n-      PSParallelCompact::ref_processor()->weak_oops_do(&adjust);\n-    }\n-    if (_sub_tasks.try_claim_task(PSAdjustSubTask_young_ref_process)) {\n-      \/\/ Roots were visited so references into the young gen in roots\n-      \/\/ may have been scanned.  Process them also.\n-      \/\/ Should the reference processor have a span that excludes\n-      \/\/ young gen objects?\n-      PSScavenge::reference_processor()->weak_oops_do(&adjust);\n-    }\n@@ -2495,1 +2481,1 @@\n-class UpdateDensePrefixAndCompactionTask: public AbstractGangTask {\n+class UpdateDensePrefixAndCompactionTask: public WorkerTask {\n@@ -2502,1 +2488,1 @@\n-      AbstractGangTask(\"UpdateDensePrefixAndCompactionTask\"),\n+      WorkerTask(\"UpdateDensePrefixAndCompactionTask\"),\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":10,"deletions":24,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -47,1 +47,1 @@\n-class AbstractGangTask;\n+class WorkerTask;\n@@ -62,1 +62,1 @@\n-class WorkGang;\n+class WorkerThreads;\n@@ -252,4 +252,4 @@\n-  oop obj_allocate(Klass* klass, int size, TRAPS);\n-  oop obj_buffer_allocate(Klass* klass, int size, TRAPS); \/\/ doesn't clear memory\n-  virtual oop array_allocate(Klass* klass, int size, int length, bool do_zero, TRAPS);\n-  oop class_allocate(Klass* klass, int size, TRAPS);\n+  oop obj_allocate(Klass* klass, size_t size, TRAPS);\n+  oop obj_buffer_allocate(Klass* klass, size_t size, TRAPS); \/\/ doesn't clear memory\n+  virtual oop array_allocate(Klass* klass, size_t size, int length, bool do_zero, TRAPS);\n+  oop class_allocate(Klass* klass, size_t size, TRAPS);\n@@ -465,9 +465,10 @@\n-  \/\/ Provides a thread pool to SafepointSynchronize to use\n-  \/\/ for parallel safepoint cleanup.\n-  \/\/ GCs that use a GC worker thread pool may want to share\n-  \/\/ it for use during safepoint cleanup. This is only possible\n-  \/\/ if the GC can pause and resume concurrent work (e.g. G1\n-  \/\/ concurrent marking) for an intermittent non-GC safepoint.\n-  \/\/ If this method returns NULL, SafepointSynchronize will\n-  \/\/ perform cleanup tasks serially in the VMThread.\n-  virtual WorkGang* safepoint_workers() { return NULL; }\n+  \/\/ Workers used in non-GC safepoints for parallel safepoint cleanup. If this\n+  \/\/ method returns NULL, cleanup tasks are done serially in the VMThread. See\n+  \/\/ `SafepointSynchronize::do_cleanup_tasks` for details.\n+  \/\/ GCs using a GC worker thread pool inside GC safepoints may opt to share\n+  \/\/ that pool with non-GC safepoints, avoiding creating extraneous threads.\n+  \/\/ Such sharing is safe, because GC safepoints and non-GC safepoints never\n+  \/\/ overlap. For example, `G1CollectedHeap::workers()` (for GC safepoints) and\n+  \/\/ `G1CollectedHeap::safepoint_workers()` (for non-GC safepoints) return the\n+  \/\/ same thread-pool.\n+  virtual WorkerThreads* safepoint_workers() { return NULL; }\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":16,"deletions":15,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-inline oop CollectedHeap::obj_allocate(Klass* klass, int size, TRAPS) {\n+inline oop CollectedHeap::obj_allocate(Klass* klass, size_t size, TRAPS) {\n@@ -39,1 +39,1 @@\n-inline oop CollectedHeap::obj_buffer_allocate(Klass* klass, int size, TRAPS) {\n+inline oop CollectedHeap::obj_buffer_allocate(Klass* klass, size_t size, TRAPS) {\n@@ -44,1 +44,1 @@\n-inline oop CollectedHeap::array_allocate(Klass* klass, int size, int length, bool do_zero, TRAPS) {\n+inline oop CollectedHeap::array_allocate(Klass* klass, size_t size, int length, bool do_zero, TRAPS) {\n@@ -49,1 +49,1 @@\n-inline oop CollectedHeap::class_allocate(Klass* klass, int size, TRAPS) {\n+inline oop CollectedHeap::class_allocate(Klass* klass, size_t size, TRAPS) {\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.inline.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -242,1 +242,1 @@\n-      SharedRuntime::dtrace_object_alloc(obj(), (int)word_size);\n+      SharedRuntime::dtrace_object_alloc(Thread::current(), obj(), word_size);\n@@ -431,1 +431,1 @@\n-  java_lang_Class::set_oop_size(mem, (int)_word_size);\n+  java_lang_Class::set_oop_size(mem, _word_size);\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -152,0 +152,1 @@\n+      case vmIntrinsics::_dsqrt_strict : \/\/ fall thru\n","filename":"src\/hotspot\/share\/interpreter\/abstractInterpreter.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -902,1 +902,1 @@\n-    ScopeValue *klass_sv = new ConstantOopWriteValue(JNIHandles::make_local(Thread::current(), javaMirror));\n+    ScopeValue *klass_sv = new ConstantOopWriteValue(JNIHandles::make_local(javaMirror));\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCodeInstaller.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -89,23 +89,0 @@\n-void JNIHandleMark::push_jni_handle_block(JavaThread* thread) {\n-  if (thread != NULL) {\n-    \/\/ Allocate a new block for JNI handles.\n-    \/\/ Inlined code from jni_PushLocalFrame()\n-    JNIHandleBlock* java_handles = thread->active_handles();\n-    JNIHandleBlock* compile_handles = JNIHandleBlock::allocate_block(thread);\n-    assert(compile_handles != NULL && java_handles != NULL, \"should not be NULL\");\n-    compile_handles->set_pop_frame_link(java_handles);\n-    thread->set_active_handles(compile_handles);\n-  }\n-}\n-\n-void JNIHandleMark::pop_jni_handle_block(JavaThread* thread) {\n-  if (thread != NULL) {\n-    \/\/ Release our JNI handle block\n-    JNIHandleBlock* compile_handles = thread->active_handles();\n-    JNIHandleBlock* java_handles = compile_handles->pop_frame_link();\n-    thread->set_active_handles(java_handles);\n-    compile_handles->set_pop_frame_link(NULL);\n-    JNIHandleBlock::release_block(compile_handles, thread); \/\/ may block\n-  }\n-}\n-\n@@ -1048,1 +1025,2 @@\n-    value = ((long) stream.bci());\n+    \/\/ FIXME: Why was this long before?\n+    value = ((jlong) stream.bci());\n@@ -1050,1 +1028,1 @@\n-    value = ((long) stream.line());\n+    value = ((jlong) stream.line());\n@@ -1894,1 +1872,1 @@\n-C2V_VMENTRY_NULL(jobject, readFieldValue, (JNIEnv* env, jobject, jobject object, jobject expected_type, long displacement, jboolean is_volatile, jobject kind_object))\n+C2V_VMENTRY_NULL(jobject, readFieldValue, (JNIEnv* env, jobject, jobject object, jobject expected_type, jlong displacement, jobject kind_object))\n@@ -1934,1 +1912,2 @@\n-  if (displacement < 0 || ((long) displacement + type2aelembytes(basic_type) > HeapWordSize * obj->size())) {\n+  int basic_type_elemsize = type2aelembytes(basic_type);\n+  if (displacement < 0 || ((size_t) displacement + basic_type_elemsize > HeapWordSize * obj->size())) {\n@@ -1941,0 +1920,4 @@\n+  bool aligned = (displacement % basic_type_elemsize) == 0;\n+  if (!aligned) {\n+    JVMCI_THROW_MSG_NULL(IllegalArgumentException, \"read is unaligned\");\n+  }\n@@ -1978,0 +1961,5 @@\n+\n+  \/\/ Treat all reads as volatile for simplicity as this function can be used\n+  \/\/ both for reading Java fields declared as volatile as well as for constant\n+  \/\/ folding Unsafe.get* methods with volatile semantics.\n+\n@@ -1979,4 +1967,4 @@\n-    case T_BOOLEAN: value = is_volatile ? obj->bool_field_acquire(displacement)   : obj->bool_field(displacement);  break;\n-    case T_BYTE:    value = is_volatile ? obj->byte_field_acquire(displacement)   : obj->byte_field(displacement);  break;\n-    case T_SHORT:   value = is_volatile ? obj->short_field_acquire(displacement)  : obj->short_field(displacement); break;\n-    case T_CHAR:    value = is_volatile ? obj->char_field_acquire(displacement)   : obj->char_field(displacement);  break;\n+    case T_BOOLEAN: value = obj->bool_field_acquire(displacement);  break;\n+    case T_BYTE:    value = obj->byte_field_acquire(displacement);  break;\n+    case T_SHORT:   value = obj->short_field_acquire(displacement); break;\n+    case T_CHAR:    value = obj->char_field_acquire(displacement);  break;\n@@ -1984,1 +1972,1 @@\n-    case T_INT:     value = is_volatile ? obj->int_field_acquire(displacement)    : obj->int_field(displacement);   break;\n+    case T_INT:     value = obj->int_field_acquire(displacement);   break;\n@@ -1986,1 +1974,1 @@\n-    case T_LONG:    value = is_volatile ? obj->long_field_acquire(displacement)   : obj->long_field(displacement);  break;\n+    case T_LONG:    value = obj->long_field_acquire(displacement);  break;\n@@ -1996,1 +1984,2 @@\n-      oop value = is_volatile ? obj->obj_field_acquire(displacement) : obj->obj_field(displacement);\n+      oop value = obj->obj_field_acquire(displacement);\n+\n@@ -2785,2 +2774,2 @@\n-  {CC \"readFieldValue\",                               CC \"(\" HS_RESOLVED_KLASS HS_RESOLVED_KLASS \"JZLjdk\/vm\/ci\/meta\/JavaKind;)\" JAVACONSTANT, FN_PTR(readFieldValue)},\n-  {CC \"readFieldValue\",                               CC \"(\" OBJECTCONSTANT HS_RESOLVED_KLASS \"JZLjdk\/vm\/ci\/meta\/JavaKind;)\" JAVACONSTANT,  FN_PTR(readFieldValue)},\n+  {CC \"readFieldValue\",                               CC \"(\" HS_RESOLVED_KLASS HS_RESOLVED_KLASS \"JLjdk\/vm\/ci\/meta\/JavaKind;)\" JAVACONSTANT, FN_PTR(readFieldValue)},\n+  {CC \"readFieldValue\",                               CC \"(\" OBJECTCONSTANT HS_RESOLVED_KLASS \"JLjdk\/vm\/ci\/meta\/JavaKind;)\" JAVACONSTANT,   FN_PTR(readFieldValue)},\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":25,"deletions":36,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -176,11 +176,0 @@\n-class JNIHandleMark : public StackObj {\n-  JavaThread* _thread;\n-  public:\n-    JNIHandleMark(JavaThread* thread) : _thread(thread) { push_jni_handle_block(thread); }\n-    ~JNIHandleMark() { pop_jni_handle_block(_thread); }\n-\n-  private:\n-    static void push_jni_handle_block(JavaThread* thread);\n-    static void pop_jni_handle_block(JavaThread* thread);\n-};\n-\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.hpp","additions":1,"deletions":12,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -74,0 +74,1 @@\n+  LOG_TAG(finalizer) \\\n@@ -200,2 +201,1 @@\n-  LOG_TAG(vtablestubs) \\\n-  LOG_TAG(workgang)\n+  LOG_TAG(vtablestubs)\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -412,1 +412,1 @@\n-  bool allocated_on_stack()    const { return get_allocation_type() == STACK_OR_EMBEDDED; }\n+  bool allocated_on_stack_or_embedded() const { return get_allocation_type() == STACK_OR_EMBEDDED; }\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,1 +37,0 @@\n-#include \"oops\/reflectionAccessorImplKlassHelper.hpp\"\n@@ -480,6 +479,0 @@\n-  \/\/ Special treatment for generated core reflection accessor classes: print invocation target.\n-  if (ReflectionAccessorImplKlassHelper::is_generated_accessor(klass)) {\n-    st->print(\" (invokes: \");\n-    ReflectionAccessorImplKlassHelper::print_invocation_target(st, klass);\n-    st->print(\")\");\n-  }\n@@ -715,3 +708,3 @@\n-    WorkGang* gang = Universe::heap()->safepoint_workers();\n-    if (gang != NULL) {\n-      \/\/ The GC provided a WorkGang to be used during a safepoint.\n+    WorkerThreads* workers = Universe::heap()->safepoint_workers();\n+    if (workers != NULL) {\n+      \/\/ The GC provided a WorkerThreads to be used during a safepoint.\n@@ -719,2 +712,3 @@\n-      \/\/ Can't run with more threads than provided by the WorkGang.\n-      WithUpdatedActiveWorkers update_and_restore(gang, parallel_thread_num);\n+      \/\/ Can't run with more threads than provided by the WorkerThreads.\n+      const uint capped_parallel_thread_num = MIN2(parallel_thread_num, workers->max_workers());\n+      WithActiveWorkers with_active_workers(workers, capped_parallel_thread_num);\n@@ -722,1 +716,1 @@\n-      ParallelObjectIterator* poi = Universe::heap()->parallel_object_iterator(gang->active_workers());\n+      ParallelObjectIterator* poi = Universe::heap()->parallel_object_iterator(workers->active_workers());\n@@ -728,1 +722,1 @@\n-        gang->run_task(&task);\n+        workers->run_task(&task);\n","filename":"src\/hotspot\/share\/memory\/heapInspection.cpp","additions":8,"deletions":14,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/shared\/workerThread.hpp\"\n@@ -33,1 +34,0 @@\n-#include \"gc\/shared\/workgroup.hpp\"\n@@ -156,16 +156,0 @@\n-  template <class T> static int count_bytes(T* x) {\n-    return (HeapWordSize * ((x) ? (x)->size() : 0));\n-  }\n-\n-  template <class T> static int count_bytes_array(T* x) {\n-    if (x == NULL) {\n-      return 0;\n-    }\n-    if (x->length() == 0) {\n-      \/\/ This is a shared array, e.g., Universe::the_empty_int_array(). Don't\n-      \/\/ count it to avoid double-counting.\n-      return 0;\n-    }\n-    return HeapWordSize * x->size();\n-  }\n-\n@@ -234,1 +218,1 @@\n-class ParHeapInspectTask : public AbstractGangTask {\n+class ParHeapInspectTask : public WorkerTask {\n@@ -247,1 +231,1 @@\n-      AbstractGangTask(\"Iterating heap\"),\n+      WorkerTask(\"Iterating heap\"),\n@@ -253,1 +237,1 @@\n-      _mutex(Mutex::nosafepoint, \"ParHeapInspectTask_lock\", Mutex::_safepoint_check_never) {}\n+      _mutex(Mutex::nosafepoint, \"ParHeapInspectTask_lock\") {}\n","filename":"src\/hotspot\/share\/memory\/heapInspection.hpp","additions":4,"deletions":20,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/dynamicArchive.hpp\"\n@@ -563,0 +564,1 @@\n+static void reinitialize_itables() {\n@@ -564,4 +566,8 @@\n-static void initialize_itable_for_klass(InstanceKlass* k) {\n-  k->itable().initialize_itable();\n-}\n-\n+  class ReinitTableClosure : public KlassClosure {\n+   public:\n+    void do_klass(Klass* k) {\n+      if (k->is_instance_klass()) {\n+         InstanceKlass::cast(k)->itable().initialize_itable();\n+      }\n+    }\n+  };\n@@ -569,2 +575,2 @@\n-static void reinitialize_itables() {\n-  ClassLoaderDataGraph::dictionary_classes_do(initialize_itable_for_klass);\n+  ReinitTableClosure cl;\n+  ClassLoaderDataGraph::classes_do(&cl);\n@@ -801,0 +807,1 @@\n+  DynamicArchive::check_for_dynamic_dump();\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":13,"deletions":6,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -154,1 +154,1 @@\n-  int size = objArrayOopDesc::object_size(length);\n+  size_t size = objArrayOopDesc::object_size(length);\n@@ -163,18 +163,0 @@\n-void ArrayKlass::array_klasses_do(void f(Klass* k, TRAPS), TRAPS) {\n-  Klass* k = this;\n-  \/\/ Iterate over this array klass and all higher dimensions\n-  while (k != NULL) {\n-    f(k, CHECK);\n-    k = ArrayKlass::cast(k)->higher_dimension();\n-  }\n-}\n-\n-void ArrayKlass::array_klasses_do(void f(Klass* k)) {\n-  Klass* k = this;\n-  \/\/ Iterate over this array klass and all higher dimensions\n-  while (k != NULL) {\n-    f(k);\n-    k = ArrayKlass::cast(k)->higher_dimension();\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":1,"deletions":19,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -130,4 +130,0 @@\n-  \/\/ Iterators\n-  void array_klasses_do(void f(Klass* k));\n-  void array_klasses_do(void f(Klass* k, TRAPS), TRAPS);\n-\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -197,1 +197,1 @@\n-int FlatArrayKlass::oop_size(oop obj) const {\n+size_t FlatArrayKlass::oop_size(oop obj) const {\n","filename":"src\/hotspot\/share\/oops\/flatArrayKlass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -104,1 +104,1 @@\n-  int oop_size(oop obj) const;\n+  size_t oop_size(oop obj) const;\n","filename":"src\/hotspot\/share\/oops\/flatArrayKlass.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -215,14 +215,0 @@\n-void InlineKlass::array_klasses_do(void f(Klass* k)) {\n-  InstanceKlass::array_klasses_do(f);\n-  if (value_array_klasses() != NULL) {\n-    value_array_klasses()->array_klasses_do(f);\n-  }\n-}\n-\n-void InlineKlass::array_klasses_do(void f(Klass* k, TRAPS), TRAPS) {\n-  InstanceKlass::array_klasses_do(f, THREAD);\n-  if (value_array_klasses() != NULL) {\n-    value_array_klasses()->array_klasses_do(f, THREAD);\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":0,"deletions":14,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -157,4 +157,0 @@\n-  \/\/ Iterators\n-  virtual void array_klasses_do(void f(Klass* k));\n-  virtual void array_klasses_do(void f(Klass* k, TRAPS), TRAPS);\n-\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -87,0 +87,1 @@\n+#include \"services\/finalizerService.hpp\"\n@@ -100,1 +101,0 @@\n-\n@@ -637,1 +637,4 @@\n-  release_C_heap_structures_internal();\n+  \/\/ Can't release the constant pool here because the constant pool can be\n+  \/\/ deallocated separately from the InstanceKlass for default methods and\n+  \/\/ redefine classes.\n+  release_C_heap_structures(\/* release_constant_pool *\/ false);\n@@ -779,1 +782,0 @@\n-\/\/ To remove these from requires an incompatible change and CCC request.\n@@ -1168,1 +1170,1 @@\n-  MutexLocker ml(ClassInitError_lock);\n+  assert_locked_or_safepoint(ClassInitError_lock);\n@@ -1557,1 +1559,1 @@\n-  int size = objArrayOopDesc::object_size(length);\n+  size_t size = objArrayOopDesc::object_size(length);\n@@ -1574,1 +1576,1 @@\n-  methodHandle mh (THREAD, Universe::finalizer_register_method());\n+  methodHandle mh(THREAD, Universe::finalizer_register_method());\n@@ -1576,0 +1578,1 @@\n+  MANAGEMENT_ONLY(FinalizerService::on_register(h_i(), THREAD);)\n@@ -1581,1 +1584,1 @@\n-  int size = size_helper();  \/\/ Query before forming handle.\n+  size_t size = size_helper();  \/\/ Query before forming handle.\n@@ -1811,1 +1814,2 @@\n-  if (!is_loaded()) {\n+  \/\/ Redefined scratch classes are on the list and need to be cleaned\n+  if (!is_loaded() && !is_scratch_class()) {\n@@ -1894,10 +1898,0 @@\n-void InstanceKlass::array_klasses_do(void f(Klass* k, TRAPS), TRAPS) {\n-  if (array_klasses() != NULL)\n-    array_klasses()->array_klasses_do(f, THREAD);\n-}\n-\n-void InstanceKlass::array_klasses_do(void f(Klass* k)) {\n-  if (array_klasses() != NULL)\n-    array_klasses()->array_klasses_do(f);\n-}\n-\n@@ -2244,2 +2238,2 @@\n-\/* jni_id_for_impl for jfieldIds only *\/\n-JNIid* InstanceKlass::jni_id_for_impl(int offset) {\n+\/* jni_id_for for jfieldIds only *\/\n+JNIid* InstanceKlass::jni_id_for(int offset) {\n@@ -2247,1 +2241,0 @@\n-  \/\/ Retry lookup after we got the lock\n@@ -2250,1 +2243,1 @@\n-    \/\/ Slow case, allocate new static field identifier\n+    \/\/ Allocate new static field identifier\n@@ -2257,10 +2250,0 @@\n-\n-\/* jni_id_for for jfieldIds only *\/\n-JNIid* InstanceKlass::jni_id_for(int offset) {\n-  JNIid* probe = jni_ids() == NULL ? NULL : jni_ids()->find(offset);\n-  if (probe == NULL) {\n-    probe = jni_id_for_impl(offset);\n-  }\n-  return probe;\n-}\n-\n@@ -2779,0 +2762,3 @@\n+    \/\/ To get a consistent list of classes we need MultiArray_lock to ensure\n+    \/\/ array classes aren't observed while they are being restored.\n+     MutexLocker ml(MultiArray_lock);\n@@ -2796,0 +2782,5 @@\n+  if (MetaspaceShared::is_in_shared_metaspace(this)) {\n+    \/\/ This is a class that was dumped into the base archive, so we know\n+    \/\/ it was verified at dump time.\n+    return true;\n+  }\n@@ -2882,2 +2873,2 @@\n-void InstanceKlass::release_C_heap_structures() {\n-\n+\/\/ Called also by InstanceKlass::deallocate_contents, with false for release_constant_pool.\n+void InstanceKlass::release_C_heap_structures(bool release_constant_pool) {\n@@ -2885,2 +2876,1 @@\n-  release_C_heap_structures_internal();\n-  constants()->release_C_heap_structures();\n+  Klass::release_C_heap_structures();\n@@ -2890,8 +2880,0 @@\n-}\n-\n-void InstanceKlass::release_C_heap_structures_internal() {\n-  Klass::release_C_heap_structures();\n-\n-  \/\/ Can't release the constant pool here because the constant pool can be\n-  \/\/ deallocated separately from the InstanceKlass for default methods and\n-  \/\/ redefine classes.\n@@ -2933,0 +2915,4 @@\n+\n+  if (release_constant_pool) {\n+    constants()->release_C_heap_structures();\n+  }\n@@ -3261,0 +3247,12 @@\n+      if (!ok->is_instance_klass()) {\n+        \/\/ If the outer class is not an instance klass then it cannot have\n+        \/\/ declared any inner classes.\n+        ResourceMark rm(THREAD);\n+        Exceptions::fthrow(\n+          THREAD_AND_LOCATION,\n+          vmSymbols::java_lang_IncompatibleClassChangeError(),\n+          \"%s and %s disagree on InnerClasses attribute\",\n+          ok->external_name(),\n+          external_name());\n+        return NULL;\n+      }\n@@ -3763,1 +3761,1 @@\n-  st->print_cr(BULLET\"---- fields (total size %d words):\", oop_size(obj));\n+  st->print_cr(BULLET\"---- fields (total size \" SIZE_FORMAT \" words):\", oop_size(obj));\n@@ -3773,1 +3771,1 @@\n-      st->print_cr(BULLET\"---- static fields (%d words):\", java_lang_Class::static_oop_field_count(obj));\n+      st->print_cr(BULLET\"---- static fields (%d):\", java_lang_Class::static_oop_field_count(obj));\n@@ -4205,2 +4203,0 @@\n-      \/\/ For debugging purposes.\n-      pv_node->set_is_scratch_class();\n@@ -4321,2 +4317,0 @@\n-    \/\/ For debugging purposes.\n-    scratch_class->set_is_scratch_class();\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":44,"deletions":50,"binary":false,"changes":94,"status":"modified"},{"patch":"@@ -280,10 +280,9 @@\n-    _misc_is_being_redefined                  = 1 << 14, \/\/ used for locking redefinition\n-    _misc_has_contended_annotations           = 1 << 15,  \/\/ has @Contended annotation\n-    _misc_has_inline_type_fields              = 1 << 16, \/\/ has inline fields and related embedded section is not empty\n-    _misc_is_empty_inline_type                = 1 << 17, \/\/ empty inline type (*)\n-    _misc_is_naturally_atomic                 = 1 << 18, \/\/ loaded\/stored in one instruction\n-    _misc_is_declared_atomic                  = 1 << 19, \/\/ implements jl.NonTearable\n-    _misc_invalid_inline_super                = 1 << 20, \/\/ invalid super type for an inline type\n-    _misc_invalid_identity_super              = 1 << 21, \/\/ invalid super type for an identity type\n-    _misc_has_injected_identityObject         = 1 << 22, \/\/ IdentityObject has been injected by the JVM\n-    _misc_has_injected_primitiveObject        = 1 << 23  \/\/ PrimitiveObject has been injected by the JVM\n+    _misc_has_contended_annotations           = 1 << 14,  \/\/ has @Contended annotation\n+    _misc_has_inline_type_fields              = 1 << 15, \/\/ has inline fields and related embedded section is not empty\n+    _misc_is_empty_inline_type                = 1 << 16, \/\/ empty inline type (*)\n+    _misc_is_naturally_atomic                 = 1 << 17, \/\/ loaded\/stored in one instruction\n+    _misc_is_declared_atomic                  = 1 << 18, \/\/ implements jl.NonTearable\n+    _misc_invalid_inline_super                = 1 << 19, \/\/ invalid super type for an inline type\n+    _misc_invalid_identity_super              = 1 << 20, \/\/ invalid super type for an identity type\n+    _misc_has_injected_identityObject         = 1 << 21, \/\/ IdentityObject has been injected by the JVM\n+    _misc_has_injected_primitiveObject        = 1 << 22  \/\/ PrimitiveObject has been injected by the JVM\n@@ -509,1 +508,0 @@\n-  void set_array_klasses(ArrayKlass* k) { _array_klasses = k; }\n@@ -856,1 +854,2 @@\n-\n+  \/\/ The flag is in access_flags so that it can be set and reset using atomic\n+  \/\/ operations, and not be reset by other misc_flag settings.\n@@ -858,1 +857,1 @@\n-    return (_misc_flags & _misc_is_being_redefined);\n+    return _access_flags.is_being_redefined();\n@@ -862,1 +861,1 @@\n-      _misc_flags |= _misc_is_being_redefined;\n+      _access_flags.set_is_being_redefined();\n@@ -864,1 +863,1 @@\n-      _misc_flags &= ~_misc_is_being_redefined;\n+      _access_flags.clear_is_being_redefined();\n@@ -1121,1 +1120,1 @@\n-  int oop_size(oop obj)  const             { return size_helper(); }\n+  size_t oop_size(oop obj)  const             { return size_helper(); }\n@@ -1133,2 +1132,0 @@\n-  virtual void array_klasses_do(void f(Klass* k));\n-  virtual void array_klasses_do(void f(Klass* k, TRAPS), TRAPS);\n@@ -1243,1 +1240,1 @@\n-  virtual void release_C_heap_structures();\n+  virtual void release_C_heap_structures(bool release_constant_pool = true);\n@@ -1341,2 +1338,0 @@\n-  \/* jni_id_for_impl for jfieldID only *\/\n-  JNIid* jni_id_for_impl                         (int offset);\n@@ -1361,3 +1356,0 @@\n-  \/\/ Free CHeap allocated fields.\n-  void release_C_heap_structures_internal();\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":16,"deletions":24,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -132,1 +132,1 @@\n-  T* p         = (T*)obj->obj_field_addr<T>(map->offset());\n+  T* p         = obj->field_addr<T>(map->offset());\n@@ -142,1 +142,1 @@\n-  T* const start = (T*)obj->obj_field_addr<T>(map->offset());\n+  T* const start = obj->field_addr<T>(map->offset());\n@@ -153,1 +153,1 @@\n-  T* p   = (T*)obj->obj_field_addr<T>(map->offset());\n+  T* p   = obj->field_addr<T>(map->offset());\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -108,1 +108,1 @@\n-void Klass::release_C_heap_structures() {\n+void Klass::release_C_heap_structures(bool release_constant_pool) {\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -573,2 +573,2 @@\n-  \/\/ actual oop size of obj in memory\n-  virtual int oop_size(oop obj) const = 0;\n+  \/\/ actual oop size of obj in memory in word size.\n+  virtual size_t oop_size(oop obj) const = 0;\n@@ -698,2 +698,0 @@\n-  virtual void array_klasses_do(void f(Klass* k)) {}\n-\n@@ -708,1 +706,1 @@\n-  virtual void release_C_heap_structures();\n+  virtual void release_C_heap_structures(bool release_constant_pool = true);\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1527,3 +1527,0 @@\n-  \/\/ Statistics\n-  update_stats(itable_size * wordSize);\n-\n@@ -1644,71 +1641,0 @@\n-\n-class VtableStats : AllStatic {\n- public:\n-  static int no_klasses;                \/\/ # classes with vtables\n-  static int no_array_klasses;          \/\/ # array classes\n-  static int no_instance_klasses;       \/\/ # instanceKlasses\n-  static int sum_of_vtable_len;         \/\/ total # of vtable entries\n-  static int sum_of_array_vtable_len;   \/\/ total # of vtable entries in array klasses only\n-  static int fixed;                     \/\/ total fixed overhead in bytes\n-  static int filler;                    \/\/ overhead caused by filler bytes\n-  static int entries;                   \/\/ total bytes consumed by vtable entries\n-  static int array_entries;             \/\/ total bytes consumed by array vtable entries\n-\n-  static void do_class(Klass* k) {\n-    Klass* kl = k;\n-    klassVtable vt = kl->vtable();\n-    no_klasses++;\n-    if (kl->is_instance_klass()) {\n-      no_instance_klasses++;\n-      kl->array_klasses_do(do_class);\n-    }\n-    if (kl->is_array_klass()) {\n-      no_array_klasses++;\n-      sum_of_array_vtable_len += vt.length();\n-    }\n-    sum_of_vtable_len += vt.length();\n-  }\n-\n-  static void compute() {\n-    LockedClassesDo locked_do_class(&do_class);\n-    ClassLoaderDataGraph::classes_do(&locked_do_class);\n-    fixed  = no_klasses * oopSize;      \/\/ vtable length\n-    \/\/ filler size is a conservative approximation\n-    filler = oopSize * (no_klasses - no_instance_klasses) * (sizeof(InstanceKlass) - sizeof(ArrayKlass) - 1);\n-    entries = sizeof(vtableEntry) * sum_of_vtable_len;\n-    array_entries = sizeof(vtableEntry) * sum_of_array_vtable_len;\n-  }\n-};\n-\n-int VtableStats::no_klasses = 0;\n-int VtableStats::no_array_klasses = 0;\n-int VtableStats::no_instance_klasses = 0;\n-int VtableStats::sum_of_vtable_len = 0;\n-int VtableStats::sum_of_array_vtable_len = 0;\n-int VtableStats::fixed = 0;\n-int VtableStats::filler = 0;\n-int VtableStats::entries = 0;\n-int VtableStats::array_entries = 0;\n-\n-void klassVtable::print_statistics() {\n-  ResourceMark rm;\n-  VtableStats::compute();\n-  tty->print_cr(\"vtable statistics:\");\n-  tty->print_cr(\"%6d classes (%d instance, %d array)\", VtableStats::no_klasses, VtableStats::no_instance_klasses, VtableStats::no_array_klasses);\n-  int total = VtableStats::fixed + VtableStats::filler + VtableStats::entries;\n-  tty->print_cr(\"%6d bytes fixed overhead (refs + vtable object header)\", VtableStats::fixed);\n-  tty->print_cr(\"%6d bytes filler overhead\", VtableStats::filler);\n-  tty->print_cr(\"%6d bytes for vtable entries (%d for arrays)\", VtableStats::entries, VtableStats::array_entries);\n-  tty->print_cr(\"%6d bytes total\", total);\n-}\n-\n-int    klassItable::_total_classes;   \/\/ Total no. of classes with itables\n-size_t klassItable::_total_size;      \/\/ Total no. of bytes used for itables\n-\n-void klassItable::print_statistics() {\n- tty->print_cr(\"itable statistics:\");\n- tty->print_cr(\"%6d classes with itables\", _total_classes);\n- tty->print_cr(SIZE_FORMAT_W(6) \" K uses for itables (average by class: \" SIZE_FORMAT \" bytes)\",\n-               _total_size \/ K, _total_size \/ _total_classes);\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/klassVtable.cpp","additions":0,"deletions":74,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -100,1 +100,0 @@\n-  static void print_statistics()                            PRODUCT_RETURN;\n@@ -325,2 +324,0 @@\n-  \/\/ Debugging\/Statistics\n-  static void print_statistics() PRODUCT_RETURN;\n@@ -334,5 +331,0 @@\n-  \/\/ Statistics\n-  NOT_PRODUCT(static int  _total_classes;)   \/\/ Total no. of classes with itables\n-  NOT_PRODUCT(static size_t _total_size;)    \/\/ Total no. of bytes used for itables\n-\n-  static void update_stats(int size) PRODUCT_RETURN NOT_PRODUCT({ _total_classes++; _total_size += size; })\n","filename":"src\/hotspot\/share\/oops\/klassVtable.hpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1724,15 +1724,0 @@\n-  case VM_SYMBOL_ENUM_NAME(java_lang_StrictMath):\n-    \/\/ Second chance: check in regular Math.\n-    switch (name_id) {\n-    case VM_SYMBOL_ENUM_NAME(min_name):\n-    case VM_SYMBOL_ENUM_NAME(max_name):\n-    case VM_SYMBOL_ENUM_NAME(sqrt_name):\n-      \/\/ pretend it is the corresponding method in the non-strict class:\n-      klass_id = VM_SYMBOL_ENUM_NAME(java_lang_Math);\n-      id = vmIntrinsics::find_id(klass_id, name_id, sig_id, flags);\n-      break;\n-    default:\n-      break;\n-    }\n-    break;\n-\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":0,"deletions":15,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -644,1 +644,2 @@\n-  st->print(\"parameter types\"); \/\/ FIXME extra ignored?\n+  print_shared(st, \"ParametersTypeData\", extra);\n+  tab(st);\n@@ -646,0 +647,1 @@\n+  st->cr();\n@@ -1254,1 +1256,1 @@\n-    _extra_data_lock(Mutex::nonleaf-2, \"MDOExtraData_lock\", Mutex::_safepoint_check_always),\n+    _extra_data_lock(Mutex::safepoint-2, \"MDOExtraData_lock\"),\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -177,1 +177,1 @@\n-int ObjArrayKlass::oop_size(oop obj) const {\n+size_t ObjArrayKlass::oop_size(oop obj) const {\n@@ -184,1 +184,1 @@\n-  int size = objArrayOopDesc::object_size(length);\n+  size_t size = objArrayOopDesc::object_size(length);\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-  int oop_size(oop obj) const;\n+  size_t oop_size(oop obj) const;\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -184,2 +184,2 @@\n-address oopDesc::address_field(int offset) const                      { return HeapAccess<>::load_at(as_oop(), offset); }\n-address oopDesc::address_field_acquire(int offset) const              { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n+address oopDesc::address_field(int offset) const                      { return *field_addr<address>(offset); }\n+address oopDesc::address_field_acquire(int offset) const              { return Atomic::load_acquire(field_addr<address>(offset)); }\n@@ -187,2 +187,2 @@\n-void oopDesc::address_field_put(int offset, address value)            { HeapAccess<>::store_at(as_oop(), offset, value); }\n-void oopDesc::release_address_field_put(int offset, address value)    { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+void oopDesc::address_field_put(int offset, address value)            { *field_addr<address>(offset) = value; }\n+void oopDesc::release_address_field_put(int offset, address value)    { Atomic::release_store(field_addr<address>(offset), value); }\n@@ -190,2 +190,2 @@\n-Metadata* oopDesc::metadata_field(int offset) const                   { return HeapAccess<>::load_at(as_oop(), offset); }\n-void oopDesc::metadata_field_put(int offset, Metadata* value)         { HeapAccess<>::store_at(as_oop(), offset, value); }\n+Metadata* oopDesc::metadata_field(int offset) const                   { return *field_addr<Metadata*>(offset); }\n+void oopDesc::metadata_field_put(int offset, Metadata* value)         { *field_addr<Metadata*>(offset) = value; }\n@@ -193,2 +193,2 @@\n-Metadata* oopDesc::metadata_field_acquire(int offset) const           { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_metadata_field_put(int offset, Metadata* value) { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+Metadata* oopDesc::metadata_field_acquire(int offset) const           { return Atomic::load_acquire(field_addr<Metadata*>(offset)); }\n+void oopDesc::release_metadata_field_put(int offset, Metadata* value) { Atomic::release_store(field_addr<Metadata*>(offset), value); }\n@@ -196,2 +196,2 @@\n-jbyte oopDesc::byte_field_acquire(int offset) const                   { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_byte_field_put(int offset, jbyte value)         { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+jbyte oopDesc::byte_field_acquire(int offset) const                   { return Atomic::load_acquire(field_addr<jbyte>(offset)); }\n+void oopDesc::release_byte_field_put(int offset, jbyte value)         { Atomic::release_store(field_addr<jbyte>(offset), value); }\n@@ -199,2 +199,2 @@\n-jchar oopDesc::char_field_acquire(int offset) const                   { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_char_field_put(int offset, jchar value)         { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+jchar oopDesc::char_field_acquire(int offset) const                   { return Atomic::load_acquire(field_addr<jchar>(offset)); }\n+void oopDesc::release_char_field_put(int offset, jchar value)         { Atomic::release_store(field_addr<jchar>(offset), value); }\n@@ -202,2 +202,2 @@\n-jboolean oopDesc::bool_field_acquire(int offset) const                { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_bool_field_put(int offset, jboolean value)      { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, jboolean(value & 1)); }\n+jboolean oopDesc::bool_field_acquire(int offset) const                { return Atomic::load_acquire(field_addr<jboolean>(offset)); }\n+void oopDesc::release_bool_field_put(int offset, jboolean value)      { Atomic::release_store(field_addr<jboolean>(offset), jboolean(value & 1)); }\n@@ -205,2 +205,2 @@\n-jint oopDesc::int_field_acquire(int offset) const                     { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_int_field_put(int offset, jint value)           { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+jint oopDesc::int_field_acquire(int offset) const                     { return Atomic::load_acquire(field_addr<jint>(offset)); }\n+void oopDesc::release_int_field_put(int offset, jint value)           { Atomic::release_store(field_addr<jint>(offset), value); }\n@@ -208,2 +208,2 @@\n-jshort oopDesc::short_field_acquire(int offset) const                 { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_short_field_put(int offset, jshort value)       { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+jshort oopDesc::short_field_acquire(int offset) const                 { return Atomic::load_acquire(field_addr<jshort>(offset)); }\n+void oopDesc::release_short_field_put(int offset, jshort value)       { Atomic::release_store(field_addr<jshort>(offset), value); }\n@@ -211,2 +211,2 @@\n-jlong oopDesc::long_field_acquire(int offset) const                   { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_long_field_put(int offset, jlong value)         { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+jlong oopDesc::long_field_acquire(int offset) const                   { return Atomic::load_acquire(field_addr<jlong>(offset)); }\n+void oopDesc::release_long_field_put(int offset, jlong value)         { Atomic::release_store(field_addr<jlong>(offset), value); }\n@@ -214,2 +214,2 @@\n-jfloat oopDesc::float_field_acquire(int offset) const                 { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_float_field_put(int offset, jfloat value)       { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+jfloat oopDesc::float_field_acquire(int offset) const                 { return Atomic::load_acquire(field_addr<jfloat>(offset)); }\n+void oopDesc::release_float_field_put(int offset, jfloat value)       { Atomic::release_store(field_addr<jfloat>(offset), value); }\n@@ -217,2 +217,2 @@\n-jdouble oopDesc::double_field_acquire(int offset) const               { return HeapAccess<MO_ACQUIRE>::load_at(as_oop(), offset); }\n-void oopDesc::release_double_field_put(int offset, jdouble value)     { HeapAccess<MO_RELEASE>::store_at(as_oop(), offset, value); }\n+jdouble oopDesc::double_field_acquire(int offset) const               { return Atomic::load_acquire(field_addr<jdouble>(offset)); }\n+void oopDesc::release_double_field_put(int offset, jdouble value)     { Atomic::release_store(field_addr<jdouble>(offset), value); }\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":24,"deletions":24,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -115,1 +115,1 @@\n-  inline int size();\n+  inline size_t size();\n@@ -119,1 +119,1 @@\n-  inline int size_given_klass(Klass* klass);\n+  inline size_t size_given_klass(Klass* klass);\n@@ -142,5 +142,2 @@\n-  \/\/ field addresses in oop\n-  inline void* field_addr(int offset) const;\n-\n-  \/\/ Need this as public for garbage collection.\n-  template <class T> inline T* obj_field_addr(int offset) const;\n+  template<typename T>\n+  inline T* field_addr(int offset) const;\n@@ -293,1 +290,1 @@\n-  inline int oop_iterate_size(OopClosureType* cl);\n+  inline size_t oop_iterate_size(OopClosureType* cl);\n@@ -296,1 +293,1 @@\n-  inline int oop_iterate_size(OopClosureType* cl, MemRegion mr);\n+  inline size_t oop_iterate_size(OopClosureType* cl, MemRegion mr);\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":6,"deletions":9,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -146,1 +146,1 @@\n-int oopDesc::size()  {\n+size_t oopDesc::size()  {\n@@ -150,1 +150,1 @@\n-int oopDesc::size_given_klass(Klass* klass)  {\n+size_t oopDesc::size_given_klass(Klass* klass)  {\n@@ -152,1 +152,1 @@\n-  int s;\n+  size_t s;\n@@ -185,1 +185,1 @@\n-      s = (int)(align_up(size_in_bytes, MinObjAlignmentInBytes) \/ HeapWordSize);\n+      s = align_up(size_in_bytes, MinObjAlignmentInBytes) \/ HeapWordSize;\n@@ -201,2 +201,2 @@\n-  assert(s > 0, \"Oop size must be greater than zero, not %d\", s);\n-  assert(is_object_aligned(s), \"Oop size is not properly aligned: %d\", s);\n+  assert(s > 0, \"Oop size must be greater than zero, not \" SIZE_FORMAT, s);\n+  assert(is_object_aligned(s), \"Oop size is not properly aligned: \" SIZE_FORMAT, s);\n@@ -226,4 +226,2 @@\n-void*    oopDesc::field_addr(int offset)     const { return reinterpret_cast<void*>(cast_from_oop<intptr_t>(as_oop()) + offset); }\n-\n-template <class T>\n-T*       oopDesc::obj_field_addr(int offset) const { return (T*) field_addr(offset); }\n+template<typename T>\n+T*       oopDesc::field_addr(int offset)     const { return reinterpret_cast<T*>(cast_from_oop<intptr_t>(as_oop()) + offset); }\n@@ -240,2 +238,2 @@\n-inline jbyte oopDesc::byte_field(int offset) const                  { return HeapAccess<>::load_at(as_oop(), offset);  }\n-inline void  oopDesc::byte_field_put(int offset, jbyte value)       { HeapAccess<>::store_at(as_oop(), offset, value); }\n+inline jbyte oopDesc::byte_field(int offset) const                  { return *field_addr<jbyte>(offset);  }\n+inline void  oopDesc::byte_field_put(int offset, jbyte value)       { *field_addr<jbyte>(offset) = value; }\n@@ -243,2 +241,2 @@\n-inline jchar oopDesc::char_field(int offset) const                  { return HeapAccess<>::load_at(as_oop(), offset);  }\n-inline void  oopDesc::char_field_put(int offset, jchar value)       { HeapAccess<>::store_at(as_oop(), offset, value); }\n+inline jchar oopDesc::char_field(int offset) const                  { return *field_addr<jchar>(offset);  }\n+inline void  oopDesc::char_field_put(int offset, jchar value)       { *field_addr<jchar>(offset) = value; }\n@@ -246,6 +244,6 @@\n-inline jboolean oopDesc::bool_field(int offset) const               { return HeapAccess<>::load_at(as_oop(), offset); }\n-inline void     oopDesc::bool_field_put(int offset, jboolean value) { HeapAccess<>::store_at(as_oop(), offset, jboolean(value & 1)); }\n-inline jboolean oopDesc::bool_field_volatile(int offset) const      { return HeapAccess<MO_SEQ_CST>::load_at(as_oop(), offset); }\n-inline void     oopDesc::bool_field_put_volatile(int offset, jboolean value) { HeapAccess<MO_SEQ_CST>::store_at(as_oop(), offset, jboolean(value & 1)); }\n-inline jshort oopDesc::short_field(int offset) const                { return HeapAccess<>::load_at(as_oop(), offset);  }\n-inline void   oopDesc::short_field_put(int offset, jshort value)    { HeapAccess<>::store_at(as_oop(), offset, value); }\n+inline jboolean oopDesc::bool_field(int offset) const               { return *field_addr<jboolean>(offset); }\n+inline void     oopDesc::bool_field_put(int offset, jboolean value) { *field_addr<jboolean>(offset) = jboolean(value & 1); }\n+inline jboolean oopDesc::bool_field_volatile(int offset) const      { return RawAccess<MO_SEQ_CST>::load(field_addr<jboolean>(offset)); }\n+inline void     oopDesc::bool_field_put_volatile(int offset, jboolean value) { RawAccess<MO_SEQ_CST>::store(field_addr<jboolean>(offset), jboolean(value & 1)); }\n+inline jshort oopDesc::short_field(int offset) const                { return *field_addr<jshort>(offset);   }\n+inline void   oopDesc::short_field_put(int offset, jshort value)    { *field_addr<jshort>(offset) = value;  }\n@@ -253,2 +251,2 @@\n-inline jint oopDesc::int_field(int offset) const                    { return HeapAccess<>::load_at(as_oop(), offset);  }\n-inline void oopDesc::int_field_put(int offset, jint value)          { HeapAccess<>::store_at(as_oop(), offset, value); }\n+inline jint oopDesc::int_field(int offset) const                    { return *field_addr<jint>(offset);     }\n+inline void oopDesc::int_field_put(int offset, jint value)          { *field_addr<jint>(offset) = value;    }\n@@ -256,2 +254,2 @@\n-inline jlong oopDesc::long_field(int offset) const                  { return HeapAccess<>::load_at(as_oop(), offset);  }\n-inline void  oopDesc::long_field_put(int offset, jlong value)       { HeapAccess<>::store_at(as_oop(), offset, value); }\n+inline jlong oopDesc::long_field(int offset) const                  { return *field_addr<jlong>(offset);    }\n+inline void  oopDesc::long_field_put(int offset, jlong value)       { *field_addr<jlong>(offset) = value;   }\n@@ -259,2 +257,2 @@\n-inline jfloat oopDesc::float_field(int offset) const                { return HeapAccess<>::load_at(as_oop(), offset);  }\n-inline void   oopDesc::float_field_put(int offset, jfloat value)    { HeapAccess<>::store_at(as_oop(), offset, value); }\n+inline jfloat oopDesc::float_field(int offset) const                { return *field_addr<jfloat>(offset);   }\n+inline void   oopDesc::float_field_put(int offset, jfloat value)    { *field_addr<jfloat>(offset) = value;  }\n@@ -262,2 +260,2 @@\n-inline jdouble oopDesc::double_field(int offset) const              { return HeapAccess<>::load_at(as_oop(), offset);  }\n-inline void    oopDesc::double_field_put(int offset, jdouble value) { HeapAccess<>::store_at(as_oop(), offset, value); }\n+inline jdouble oopDesc::double_field(int offset) const              { return *field_addr<jdouble>(offset);  }\n+inline void    oopDesc::double_field_put(int offset, jdouble value) { *field_addr<jdouble>(offset) = value; }\n@@ -309,0 +307,1 @@\n+  assert(is_forwarded(), \"only decode when actually forwarded\");\n@@ -314,1 +313,1 @@\n-  assert(!is_forwarded(), \"Attempt to read age from forwarded mark\");\n+  assert(!mark().is_marked(), \"Attempt to read age from forwarded mark\");\n@@ -323,1 +322,1 @@\n-  assert(!is_forwarded(), \"Attempt to increment age of forwarded mark\");\n+  assert(!mark().is_marked(), \"Attempt to increment age of forwarded mark\");\n@@ -342,1 +341,1 @@\n-int oopDesc::oop_iterate_size(OopClosureType* cl) {\n+size_t oopDesc::oop_iterate_size(OopClosureType* cl) {\n@@ -344,1 +343,1 @@\n-  int size = size_given_klass(k);\n+  size_t size = size_given_klass(k);\n@@ -350,1 +349,1 @@\n-int oopDesc::oop_iterate_size(OopClosureType* cl, MemRegion mr) {\n+size_t oopDesc::oop_iterate_size(OopClosureType* cl, MemRegion mr) {\n@@ -352,1 +351,1 @@\n-  int size = size_given_klass(k);\n+  size_t size = size_given_klass(k);\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":33,"deletions":34,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -158,1 +158,1 @@\n-    unsigned addr_bits = (unsigned)((uintptr_t)this >> (LogBytesPerWord + 3));\n+    unsigned addr_bits = (unsigned)((uintptr_t)this >> LogBytesPerWord);\n","filename":"src\/hotspot\/share\/oops\/symbol.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -93,1 +93,1 @@\n-  return (typeArrayOop)Universe::heap()->array_allocate(this, (int)size, length,\n+  return (typeArrayOop)Universe::heap()->array_allocate(this, size, length,\n@@ -229,1 +229,1 @@\n-int TypeArrayKlass::oop_size(oop obj) const {\n+size_t TypeArrayKlass::oop_size(oop obj) const {\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -118,2 +118,1 @@\n-\n-  static int object_size(int lh, int length) {\n+  static size_t object_size(int lh, int length) {\n@@ -131,1 +130,1 @@\n-    return align_object_size((intptr_t)size_in_words);\n+    return align_object_size((size_t)size_in_words);\n@@ -135,1 +134,1 @@\n-  inline int object_size(const TypeArrayKlass* tk) const;\n+  inline size_t object_size(const TypeArrayKlass* tk) const;\n","filename":"src\/hotspot\/share\/oops\/typeArrayOop.hpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1122,0 +1122,1 @@\n+  BasicType bt = is_int ? T_INT: T_LONG;\n@@ -1130,1 +1131,1 @@\n-  if (!is_unsigned) {\n+  if (is_int && !is_unsigned) {\n@@ -1132,8 +1133,2 @@\n-      if (is_int) {\n-        res =  gvn.transform(new MaxINode(a, b));\n-        assert(gvn.type(res)->is_int()->_lo >= t->is_int()->_lo && gvn.type(res)->is_int()->_hi <= t->is_int()->_hi, \"type doesn't match\");\n-      } else {\n-        Node* cmp = gvn.transform(new CmpLNode(a, b));\n-        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-        res = gvn.transform(new CMoveLNode(bol, a, b, t->is_long()));\n-      }\n+      res =  gvn.transform(new MaxINode(a, b));\n+      assert(gvn.type(res)->is_int()->_lo >= t->is_int()->_lo && gvn.type(res)->is_int()->_hi <= t->is_int()->_hi, \"type doesn't match\");\n@@ -1141,8 +1136,2 @@\n-      if (is_int) {\n-        Node* res =  gvn.transform(new MinINode(a, b));\n-        assert(gvn.type(res)->is_int()->_lo >= t->is_int()->_lo && gvn.type(res)->is_int()->_hi <= t->is_int()->_hi, \"type doesn't match\");\n-      } else {\n-        Node* cmp = gvn.transform(new CmpLNode(b, a));\n-        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-        res = gvn.transform(new CMoveLNode(bol, a, b, t->is_long()));\n-      }\n+      Node* res =  gvn.transform(new MinINode(a, b));\n+      assert(gvn.type(res)->is_int()->_lo >= t->is_int()->_lo && gvn.type(res)->is_int()->_hi <= t->is_int()->_hi, \"type doesn't match\");\n@@ -1151,0 +1140,1 @@\n+    Node* cmp = NULL;\n@@ -1152,9 +1142,1 @@\n-      if (is_int) {\n-        Node* cmp = gvn.transform(new CmpUNode(a, b));\n-        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-        res = gvn.transform(new CMoveINode(bol, a, b, t->is_int()));\n-      } else {\n-        Node* cmp = gvn.transform(new CmpULNode(a, b));\n-        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-        res = gvn.transform(new CMoveLNode(bol, a, b, t->is_long()));\n-      }\n+      cmp = gvn.transform(CmpNode::make(a, b, bt, is_unsigned));\n@@ -1162,9 +1144,1 @@\n-      if (is_int) {\n-        Node* cmp = gvn.transform(new CmpUNode(b, a));\n-        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-        res = gvn.transform(new CMoveINode(bol, a, b, t->is_int()));\n-      } else {\n-        Node* cmp = gvn.transform(new CmpULNode(b, a));\n-        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-        res = gvn.transform(new CMoveLNode(bol, a, b, t->is_long()));\n-      }\n+      cmp = gvn.transform(CmpNode::make(b, a, bt, is_unsigned));\n@@ -1172,0 +1146,2 @@\n+    Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n+    res = gvn.transform(CMoveNode::make(NULL, bol, a, b, t));\n@@ -1183,6 +1159,2 @@\n-  Node* zero = NULL;\n-  if (is_int) {\n-    zero = gvn.intcon(0);\n-  } else {\n-    zero = gvn.longcon(0);\n-  }\n+  BasicType bt = is_int ? T_INT: T_LONG;\n+  Node* zero = gvn.integercon(0, bt);\n@@ -1196,1 +1168,1 @@\n-  Node* res = NULL;\n+  Node* cmp = NULL;\n@@ -1198,11 +1170,1 @@\n-    if (is_int) {\n-      Node* cmp = gvn.transform(new CmpINode(a, b));\n-      Node* sub = gvn.transform(new SubINode(a, b));\n-      Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-      res = gvn.transform(new CMoveINode(bol, sub, zero, t->is_int()));\n-    } else {\n-      Node* cmp = gvn.transform(new CmpLNode(a, b));\n-      Node* sub = gvn.transform(new SubLNode(a, b));\n-      Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-      res = gvn.transform(new CMoveLNode(bol, sub, zero, t->is_long()));\n-    }\n+    cmp = gvn.transform(CmpNode::make(a, b, bt, false));\n@@ -1210,11 +1172,1 @@\n-    if (is_int) {\n-      Node* cmp = gvn.transform(new CmpINode(b, a));\n-      Node* sub = gvn.transform(new SubINode(a, b));\n-      Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-      res = gvn.transform(new CMoveINode(bol, sub, zero, t->is_int()));\n-    } else {\n-      Node* cmp = gvn.transform(new CmpLNode(b, a));\n-      Node* sub = gvn.transform(new SubLNode(a, b));\n-      Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n-      res = gvn.transform(new CMoveLNode(bol, sub, zero, t->is_long()));\n-    }\n+    cmp = gvn.transform(CmpNode::make(b, a, bt, false));\n@@ -1222,0 +1174,3 @@\n+  Node* sub = gvn.transform(SubNode::make(a, b, bt));\n+  Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));\n+  Node* res = gvn.transform(CMoveNode::make(NULL, bol, sub, zero, t));\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":19,"deletions":64,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -234,4 +234,0 @@\n-    if (false && r->is_reg() && !r->is_concrete()) {\n-      continue;\n-    }\n-\n@@ -315,3 +311,1 @@\n-            if (b->is_stack() || b->is_concrete() || true ) {\n-              omap->set_oop( b);\n-            }\n+            omap->set_oop(b);\n@@ -320,3 +314,1 @@\n-        if (b->is_stack() || b->is_concrete() || true ) {\n-          omap->set_derived_oop( r, b);\n-        }\n+        omap->set_derived_oop(r, b);\n@@ -350,3 +342,1 @@\n-      if ( callee->is_concrete() || true ) {\n-        omap->set_callee_saved( r, callee);\n-      }\n+      omap->set_callee_saved(r, callee);\n","filename":"src\/hotspot\/share\/opto\/buildOopMap.cpp","additions":4,"deletions":14,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"compiler\/compilationPolicy.hpp\"\n@@ -155,2 +156,2 @@\n-  int call_site_count  = method()->scale_count(profile.count());\n-  int invoke_count     = method()->interpreter_invocation_count();\n+  int call_site_count  = caller_method->scale_count(profile.count());\n+  int invoke_count     = caller_method->interpreter_invocation_count();\n@@ -195,4 +196,2 @@\n-bool InlineTree::should_not_inline(ciMethod *callee_method,\n-                                   ciMethod* caller_method,\n-                                   JVMState* jvms) {\n-\n+bool InlineTree::should_not_inline(ciMethod* callee_method, ciMethod* caller_method,\n+                                   int caller_bci, ciCallProfile& profile) {\n@@ -236,1 +235,0 @@\n-  int caller_bci = jvms->bci();\n@@ -292,1 +290,0 @@\n-\n@@ -302,8 +299,12 @@\n-    } else {\n-      intx counter_high_value;\n-      \/\/ Tiered compilation uses a different \"high value\" than non-tiered compilation.\n-      \/\/ Determine the right value to use.\n-      if (TieredCompilation) {\n-        counter_high_value = InvocationCounter::count_limit \/ 2;\n-      } else {\n-        counter_high_value = CompileThreshold \/ 2;\n+    }\n+\n+    if (MinInlineFrequencyRatio > 0) {\n+      int call_site_count  = caller_method->scale_count(profile.count());\n+      int invoke_count     = caller_method->interpreter_invocation_count();\n+      assert(invoke_count != 0, \"require invocation count greater than zero\");\n+      double freq = (double)call_site_count \/ (double)invoke_count;\n+      double min_freq = MAX2(MinInlineFrequencyRatio, 1.0 \/ CompilationPolicy::min_invocations());\n+\n+      if (freq < min_freq) {\n+        set_msg(\"low call site frequency\");\n+        return true;\n@@ -311,0 +312,4 @@\n+    }\n+\n+    if (MinInliningThreshold > 0) { \/\/ Deprecated heuristic\n+      intx counter_high_value = TieredCompilation ? InvocationCounter::count_limit \/ 2 : CompileThreshold \/ 2;\n@@ -370,1 +375,1 @@\n-  if (should_not_inline(callee_method, caller_method, jvms)) {\n+  if (should_not_inline(callee_method, caller_method, caller_bci, profile)) {\n","filename":"src\/hotspot\/share\/opto\/bytecodeInfo.cpp","additions":22,"deletions":17,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -107,1 +107,2 @@\n-    Compile C(env, target, entry_bci, subsume_loads, do_escape_analysis, eliminate_boxing, do_locks_coarsening, install_code, directive);\n+    Options options(subsume_loads, do_escape_analysis, eliminate_boxing, do_locks_coarsening, install_code);\n+    Compile C(env, target, entry_bci, options, directive);\n@@ -429,0 +430,3 @@\n+  case vmIntrinsics::_unsignedMultiplyHigh:\n+    if (!Matcher::match_rule_supported(Op_UMulHiL)) return false;\n+    break;\n@@ -454,0 +458,1 @@\n+  case vmIntrinsics::_maxF_strict:\n@@ -457,0 +462,1 @@\n+  case vmIntrinsics::_minF_strict:\n@@ -460,0 +466,1 @@\n+  case vmIntrinsics::_maxD_strict:\n@@ -463,0 +470,1 @@\n+  case vmIntrinsics::_minD_strict:\n@@ -503,0 +511,1 @@\n+  case vmIntrinsics::_dsqrt_strict:\n@@ -509,0 +518,2 @@\n+  case vmIntrinsics::_min_strict:\n+  case vmIntrinsics::_max_strict:\n@@ -608,0 +619,1 @@\n+  case vmIntrinsics::_storeStoreFence:\n@@ -691,0 +703,1 @@\n+  case vmIntrinsics::_VectorLoadMaskedOp:\n@@ -692,0 +705,1 @@\n+  case vmIntrinsics::_VectorStoreMaskedOp:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -703,1 +703,2 @@\n-    if (is_boxing_late_inline() && callprojs->resproj[0] != nullptr) {\n+    \/\/ Disabled due to JDK-8276112\n+    if (false && is_boxing_late_inline() && callprojs->resproj[0] != nullptr) {\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -143,1 +143,1 @@\n-  virtual uint ideal_reg() const { return Op_RegF; }\n+  virtual uint ideal_reg() const { return in(1)->ideal_reg(); }\n@@ -153,1 +153,1 @@\n-  virtual uint ideal_reg() const { return Op_RegD; }\n+  virtual uint ideal_reg() const { return in(1)->ideal_reg(); }\n","filename":"src\/hotspot\/share\/opto\/castnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1380,1 +1380,2 @@\n-  if (true_path != 0) {\n+  \/\/ Delay CMove'ing identity if Ideal has not had the chance to handle unsafe cases, yet.\n+  if (true_path != 0 && !(phase->is_IterGVN() && wait_for_region_igvn(phase))) {\n@@ -1382,1 +1383,3 @@\n-    if (id != NULL)  return id;\n+    if (id != NULL) {\n+      return id;\n+    }\n@@ -2473,41 +2476,0 @@\n-  \/\/ Phi (VB ... VB) => VB (Phi ...) (Phi ...)\n-  if (EnableVectorReboxing && can_reshape && progress == NULL) {\n-    PhaseIterGVN* igvn = phase->is_IterGVN();\n-\n-    bool all_inputs_are_equiv_vboxes = true;\n-    for (uint i = 1; i < req(); ++i) {\n-      Node* n = in(i);\n-      if (in(i)->Opcode() != Op_VectorBox) {\n-        all_inputs_are_equiv_vboxes = false;\n-        break;\n-      }\n-      \/\/ Check that vector type of vboxes is equivalent\n-      if (i != 1) {\n-        if (Type::cmp(in(i-0)->in(VectorBoxNode::Value)->bottom_type(),\n-                      in(i-1)->in(VectorBoxNode::Value)->bottom_type()) != 0) {\n-          all_inputs_are_equiv_vboxes = false;\n-          break;\n-        }\n-        if (Type::cmp(in(i-0)->in(VectorBoxNode::Box)->bottom_type(),\n-                      in(i-1)->in(VectorBoxNode::Box)->bottom_type()) != 0) {\n-          all_inputs_are_equiv_vboxes = false;\n-          break;\n-        }\n-      }\n-    }\n-\n-    if (all_inputs_are_equiv_vboxes) {\n-      VectorBoxNode* vbox = static_cast<VectorBoxNode*>(in(1));\n-      PhiNode* new_vbox_phi = new PhiNode(r, vbox->box_type());\n-      PhiNode* new_vect_phi = new PhiNode(r, vbox->vec_type());\n-      for (uint i = 1; i < req(); ++i) {\n-        VectorBoxNode* old_vbox = static_cast<VectorBoxNode*>(in(i));\n-        new_vbox_phi->set_req(i, old_vbox->in(VectorBoxNode::Box));\n-        new_vect_phi->set_req(i, old_vbox->in(VectorBoxNode::Value));\n-      }\n-      igvn->register_new_node_with_optimizer(new_vbox_phi, this);\n-      igvn->register_new_node_with_optimizer(new_vect_phi, this);\n-      progress = new VectorBoxNode(igvn->C, new_vbox_phi, new_vect_phi, vbox->box_type(), vbox->vec_type());\n-    }\n-  }\n-\n@@ -2517,1 +2479,1 @@\n-  if (EnableValhalla && (_type->isa_ptr() || _type->isa_inlinetype()) && req() > 2 && progress == NULL) {\n+  if (EnableValhalla && (_type->isa_ptr() || _type->isa_inlinetype()) && req() > 2) {\n@@ -2566,1 +2528,1 @@\n-      progress = push_inline_types_through(phase, can_reshape, vk, is_init);\n+      return push_inline_types_through(phase, can_reshape, vk, is_init);\n@@ -2570,0 +2532,5 @@\n+  \/\/ Phi (VB ... VB) => VB (Phi ...) (Phi ...)\n+  if (EnableVectorReboxing && can_reshape && progress == NULL && type()->isa_oopptr()) {\n+    progress = merge_through_phi(this, phase->is_IterGVN());\n+  }\n+\n@@ -2573,0 +2540,93 @@\n+Node* PhiNode::clone_through_phi(Node* root_phi, const Type* t, uint c, PhaseIterGVN* igvn) {\n+  Node_Stack stack(1);\n+  VectorSet  visited;\n+  Node_List  node_map;\n+\n+  stack.push(root_phi, 1); \/\/ ignore control\n+  visited.set(root_phi->_idx);\n+\n+  Node* new_phi = new PhiNode(root_phi->in(0), t);\n+  node_map.map(root_phi->_idx, new_phi);\n+\n+  while (stack.is_nonempty()) {\n+    Node* n   = stack.node();\n+    uint  idx = stack.index();\n+    assert(n->is_Phi(), \"not a phi\");\n+    if (idx < n->req()) {\n+      stack.set_index(idx + 1);\n+      Node* def = n->in(idx);\n+      if (def == NULL) {\n+        continue; \/\/ ignore dead path\n+      } else if (def->is_Phi()) { \/\/ inner node\n+        Node* new_phi = node_map[n->_idx];\n+        if (!visited.test_set(def->_idx)) { \/\/ not visited yet\n+          node_map.map(def->_idx, new PhiNode(def->in(0), t));\n+          stack.push(def, 1); \/\/ ignore control\n+        }\n+        Node* new_in = node_map[def->_idx];\n+        new_phi->set_req(idx, new_in);\n+      } else if (def->Opcode() == Op_VectorBox) { \/\/ leaf\n+        assert(n->is_Phi(), \"not a phi\");\n+        Node* new_phi = node_map[n->_idx];\n+        new_phi->set_req(idx, def->in(c));\n+      } else {\n+        assert(false, \"not optimizeable\");\n+        return NULL;\n+      }\n+    } else {\n+      Node* new_phi = node_map[n->_idx];\n+      igvn->register_new_node_with_optimizer(new_phi, n);\n+      stack.pop();\n+    }\n+  }\n+  return new_phi;\n+}\n+\n+Node* PhiNode::merge_through_phi(Node* root_phi, PhaseIterGVN* igvn) {\n+  Node_Stack stack(1);\n+  VectorSet  visited;\n+\n+  stack.push(root_phi, 1); \/\/ ignore control\n+  visited.set(root_phi->_idx);\n+\n+  VectorBoxNode* cached_vbox = NULL;\n+  while (stack.is_nonempty()) {\n+    Node* n   = stack.node();\n+    uint  idx = stack.index();\n+    if (idx < n->req()) {\n+      stack.set_index(idx + 1);\n+      Node* in = n->in(idx);\n+      if (in == NULL) {\n+        continue; \/\/ ignore dead path\n+      } else if (in->isa_Phi()) {\n+        if (!visited.test_set(in->_idx)) {\n+          stack.push(in, 1); \/\/ ignore control\n+        }\n+      } else if (in->Opcode() == Op_VectorBox) {\n+        VectorBoxNode* vbox = static_cast<VectorBoxNode*>(in);\n+        if (cached_vbox == NULL) {\n+          cached_vbox = vbox;\n+        } else if (vbox->vec_type() != cached_vbox->vec_type()) {\n+          \/\/ TODO: vector type mismatch can be handled with additional reinterpret casts\n+          assert(Type::cmp(vbox->vec_type(), cached_vbox->vec_type()) != 0, \"inconsistent\");\n+          return NULL; \/\/ not optimizable: vector type mismatch\n+        } else if (vbox->box_type() != cached_vbox->box_type()) {\n+          assert(Type::cmp(vbox->box_type(), cached_vbox->box_type()) != 0, \"inconsistent\");\n+          return NULL; \/\/ not optimizable: box type mismatch\n+        }\n+      } else {\n+        return NULL; \/\/ not optimizable: neither Phi nor VectorBox\n+      }\n+    } else {\n+      stack.pop();\n+    }\n+  }\n+\n+  assert(cached_vbox != NULL, \"sanity\");\n+  const TypeInstPtr* btype = cached_vbox->box_type();\n+  const TypeVect*    vtype = cached_vbox->vec_type();\n+  Node* new_vbox_phi = clone_through_phi(root_phi, btype, VectorBoxNode::Box,   igvn);\n+  Node* new_vect_phi = clone_through_phi(root_phi, vtype, VectorBoxNode::Value, igvn);\n+  return new VectorBoxNode(igvn->C, new_vbox_phi, new_vect_phi, btype, vtype);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":105,"deletions":45,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -145,0 +145,3 @@\n+  static Node* clone_through_phi(Node* root_phi, const Type* t, uint c, PhaseIterGVN* igvn);\n+  static Node* merge_through_phi(Node* root_phi, PhaseIterGVN* igvn);\n+\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -80,0 +80,1 @@\n+  if( _is_predicate ) tty->print(\"Predicate \");\n@@ -641,1 +642,2 @@\n-      } else if (lrg.num_regs() == 1) {\n+      } else if ((lrg.num_regs() == 1 && !lrg.is_scalable()) ||\n+                 (lrg.is_scalable() && lrg.scalable_reg_slots() == 1)) {\n@@ -656,9 +658,13 @@\n-          OptoReg::Name lo = OptoReg::add(hi, (1-num_regs)); \/\/ Find lo\n-          \/\/ We have to use pair [lo,lo+1] even for wide vectors because\n-          \/\/ the rest of code generation works only with pairs. It is safe\n-          \/\/ since for registers encoding only 'lo' is used.\n-          \/\/ Second reg from pair is used in ScheduleAndBundle on SPARC where\n-          \/\/ vector max size is 8 which corresponds to registers pair.\n-          \/\/ It is also used in BuildOopMaps but oop operations are not\n-          \/\/ vectorized.\n-          set2(i, lo);\n+          if (num_regs == 1) {\n+            set1(i, hi);\n+          } else {\n+            OptoReg::Name lo = OptoReg::add(hi, (1 - num_regs)); \/\/ Find lo\n+            \/\/ We have to use pair [lo,lo+1] even for wide vectors\/vmasks because\n+            \/\/ the rest of code generation works only with pairs. It is safe\n+            \/\/ since for registers encoding only 'lo' is used.\n+            \/\/ Second reg from pair is used in ScheduleAndBundle with vector max\n+            \/\/ size 8 which corresponds to registers pair.\n+            \/\/ It is also used in BuildOopMaps but oop operations are not\n+            \/\/ vectorized.\n+            set2(i, lo);\n+          }\n@@ -827,0 +833,14 @@\n+\n+        if (ireg == Op_RegVectMask) {\n+          assert(Matcher::has_predicated_vectors(), \"predicated vector should be supported\");\n+          lrg._is_predicate = 1;\n+          if (Matcher::supports_scalable_vector()) {\n+            lrg._is_scalable = 1;\n+            \/\/ For scalable predicate, when it is allocated in physical register,\n+            \/\/ num_regs is RegMask::SlotsPerRegVectMask for reg mask,\n+            \/\/ which may not be the actual physical register size.\n+            \/\/ If it is allocated in stack, we need to get the actual\n+            \/\/ physical length of scalable predicate register.\n+            lrg.set_scalable_reg_slots(Matcher::scalable_predicate_reg_slots());\n+          }\n+        }\n@@ -828,1 +848,1 @@\n-               ireg == Op_RegD || ireg == Op_RegL  || ireg == Op_RegVectMask,\n+               ireg == Op_RegD || ireg == Op_RegL || ireg == Op_RegVectMask,\n@@ -922,0 +942,2 @@\n+          assert(Matcher::has_predicated_vectors(), \"sanity\");\n+          assert(RegMask::num_registers(Op_RegVectMask) == RegMask::SlotsPerRegVectMask, \"sanity\");\n@@ -1374,0 +1396,5 @@\n+    } else if (lrg._is_predicate) {\n+      assert(num_regs == RegMask::SlotsPerRegVectMask, \"scalable predicate register\");\n+      num_regs = lrg.scalable_reg_slots();\n+      mask.clear_to_sets(num_regs);\n+      return mask.find_first_set(lrg, num_regs);\n@@ -1420,1 +1447,1 @@\n-  if (lrg._is_vector || lrg.num_regs() == 2) {\n+  if (lrg._is_vector || lrg.num_regs() == 2 || lrg.is_scalable()) {\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":39,"deletions":12,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -223,0 +223,1 @@\n+macro(StoreStoreFence)\n@@ -242,0 +243,1 @@\n+macro(UMulHiL)\n@@ -419,0 +421,1 @@\n+macro(LoadVectorGatherMasked)\n@@ -421,0 +424,1 @@\n+macro(StoreVectorScatterMasked)\n@@ -429,0 +433,1 @@\n+macro(VectorMaskToLong)\n@@ -479,0 +484,4 @@\n+macro(MaskAll)\n+macro(AndVMask)\n+macro(OrVMask)\n+macro(XorVMask)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -503,1 +503,1 @@\n-  if (_subsume_loads == false && PrintOpto) {\n+  if (!subsume_loads() && PrintOpto) {\n@@ -509,1 +509,1 @@\n-  if (_do_escape_analysis != DoEscapeAnalysis && PrintOpto) {\n+  if ((do_escape_analysis() != DoEscapeAnalysis) && PrintOpto) {\n@@ -515,1 +515,1 @@\n-  if (_eliminate_boxing != EliminateAutoBox && PrintOpto) {\n+  if ((eliminate_boxing() != EliminateAutoBox) && PrintOpto) {\n@@ -521,1 +521,1 @@\n-  if ((_do_locks_coarsening != EliminateLocks) && PrintOpto) {\n+  if ((do_locks_coarsening() != EliminateLocks) && PrintOpto) {\n@@ -554,2 +554,1 @@\n-                  bool subsume_loads, bool do_escape_analysis, bool eliminate_boxing,\n-                  bool do_locks_coarsening, bool install_code, DirectiveSet* directive)\n+                  Options options, DirectiveSet* directive)\n@@ -558,5 +557,1 @@\n-                  _subsume_loads(subsume_loads),\n-                  _do_escape_analysis(do_escape_analysis),\n-                  _install_code(install_code),\n-                  _eliminate_boxing(eliminate_boxing),\n-                  _do_locks_coarsening(do_locks_coarsening),\n+                  _options(options),\n@@ -565,0 +560,1 @@\n+                  _ilt(NULL),\n@@ -864,5 +860,1 @@\n-    _subsume_loads(true),\n-    _do_escape_analysis(false),\n-    _install_code(true),\n-    _eliminate_boxing(false),\n-    _do_locks_coarsening(false),\n+    _options(Options::for_runtime_stub()),\n@@ -1056,1 +1048,1 @@\n-  if (!_do_escape_analysis && aliaslevel == 3)\n+  if (!do_escape_analysis() && aliaslevel == 3) {\n@@ -1058,0 +1050,1 @@\n+  }\n@@ -2617,1 +2610,2 @@\n-    for_igvn()->clear();\n+    Unique_Node_List* old_worklist = for_igvn();\n+    old_worklist->clear();\n@@ -2627,1 +2621,1 @@\n-    set_for_igvn(save_for_igvn);\n+    set_for_igvn(old_worklist); \/\/ new_worklist is dead beyond this point\n@@ -2640,1 +2634,1 @@\n-  if (_do_escape_analysis && ConnectionGraph::has_candidates(this)) {\n+  if (do_escape_analysis() && ConnectionGraph::has_candidates(this)) {\n@@ -2851,0 +2845,1 @@\n+         n->req() == 2 &&\n@@ -2858,1 +2853,1 @@\n-      return true;\n+      return n->req() == 2;\n@@ -3933,0 +3928,2 @@\n+  case Op_LoadVectorGatherMasked:\n+  case Op_StoreVectorScatterMasked:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":18,"deletions":21,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -167,0 +167,31 @@\n+class Options {\n+  friend class Compile;\n+  friend class VMStructs;\n+ private:\n+  const bool _subsume_loads;         \/\/ Load can be matched as part of a larger op.\n+  const bool _do_escape_analysis;    \/\/ Do escape analysis.\n+  const bool _eliminate_boxing;      \/\/ Do boxing elimination.\n+  const bool _do_locks_coarsening;   \/\/ Do locks coarsening\n+  const bool _install_code;          \/\/ Install the code that was compiled\n+ public:\n+  Options(bool subsume_loads, bool do_escape_analysis,\n+          bool eliminate_boxing, bool do_locks_coarsening,\n+          bool install_code) :\n+          _subsume_loads(subsume_loads),\n+          _do_escape_analysis(do_escape_analysis),\n+          _eliminate_boxing(eliminate_boxing),\n+          _do_locks_coarsening(do_locks_coarsening),\n+          _install_code(install_code) {\n+  }\n+\n+  static Options for_runtime_stub() {\n+    return Options(\n+       \/* subsume_loads = *\/ true,\n+       \/* do_escape_analysis = *\/ false,\n+       \/* eliminate_boxing = *\/ false,\n+       \/* do_lock_coarsening = *\/ false,\n+       \/* install_code = *\/ true\n+    );\n+  }\n+};\n+\n@@ -251,5 +282,1 @@\n-  const bool            _subsume_loads;         \/\/ Load can be matched as part of a larger op.\n-  const bool            _do_escape_analysis;    \/\/ Do escape analysis.\n-  const bool            _install_code;          \/\/ Install the code that was compiled\n-  const bool            _eliminate_boxing;      \/\/ Do boxing elimination.\n-  const bool            _do_locks_coarsening;   \/\/ Do locks coarsening\n+  const Options         _options;               \/\/ Compilation options\n@@ -513,1 +540,1 @@\n-  bool              subsume_loads() const       { return _subsume_loads; }\n+  bool              subsume_loads() const       { return _options._subsume_loads; }\n@@ -515,1 +542,1 @@\n-  bool              do_escape_analysis() const  { return _do_escape_analysis; }\n+  bool              do_escape_analysis() const  { return _options._do_escape_analysis; }\n@@ -517,1 +544,1 @@\n-  bool              eliminate_boxing() const    { return _eliminate_boxing; }\n+  bool              eliminate_boxing() const    { return _options._eliminate_boxing; }\n@@ -519,2 +546,2 @@\n-  bool              aggressive_unboxing() const { return _eliminate_boxing && AggressiveUnboxing; }\n-  bool              should_install_code() const { return _install_code; }\n+  bool              aggressive_unboxing() const { return _options._eliminate_boxing && AggressiveUnboxing; }\n+  bool              should_install_code() const { return _options._install_code; }\n@@ -522,1 +549,1 @@\n-  bool              do_locks_coarsening() const { return _do_locks_coarsening; }\n+  bool              do_locks_coarsening() const { return _options._do_locks_coarsening; }\n@@ -1059,3 +1086,1 @@\n-          int entry_bci, bool subsume_loads, bool do_escape_analysis,\n-          bool eliminate_boxing, bool do_locks_coarsening,\n-          bool install_code, DirectiveSet* directive);\n+          int entry_bci, Options options, DirectiveSet* directive);\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":39,"deletions":14,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -122,2 +122,4 @@\n-  if( in(1)->Opcode() == Op_RoundDouble )\n-  set_req(1,in(1)->in(1));\n+  if (in(1)->Opcode() == Op_RoundDouble) {\n+    set_req(1, in(1)->in(1));\n+    return this;\n+  }\n@@ -156,2 +158,4 @@\n-  if( in(1)->Opcode() == Op_RoundDouble )\n-  set_req(1,in(1)->in(1));\n+  if (in(1)->Opcode() == Op_RoundDouble) {\n+    set_req(1, in(1)->in(1));\n+    return this;\n+  }\n@@ -193,2 +197,4 @@\n-  if( in(1)->Opcode() == Op_RoundFloat )\n-  set_req(1,in(1)->in(1));\n+  if (in(1)->Opcode() == Op_RoundFloat) {\n+    set_req(1, in(1)->in(1));\n+    return this;\n+  }\n@@ -220,2 +226,4 @@\n-  if( in(1)->Opcode() == Op_RoundFloat )\n-  set_req(1,in(1)->in(1));\n+  if (in(1)->Opcode() == Op_RoundFloat) {\n+    set_req(1, in(1)->in(1));\n+    return this;\n+  }\n","filename":"src\/hotspot\/share\/opto\/convertnode.cpp","additions":16,"deletions":8,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -1741,0 +1741,10 @@\n+    if (in(0)->is_BaseCountedLoopEnd()) {\n+      \/\/ CountedLoopEndNode may be eliminated by if subsuming, replace CountedLoopNode with LoopNode to\n+      \/\/ avoid mismatching between CountedLoopNode and CountedLoopEndNode in the following optimization.\n+      Node* head = unique_ctrl_out();\n+      if (head != NULL && head->is_BaseCountedLoop() && head->in(LoopNode::LoopBackControl) == this) {\n+        Node* new_head = new LoopNode(head->in(LoopNode::EntryControl), this);\n+        phase->is_IterGVN()->register_new_node_with_optimizer(new_head);\n+        phase->is_IterGVN()->replace_node(head, new_head);\n+      }\n+    }\n","filename":"src\/hotspot\/share\/opto\/ifnode.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -730,1 +730,2 @@\n-        case Op_StoreVectorScatter:\n+        case Op_StoreVectorScatter:\n+        case Op_StoreVectorScatterMasked:\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -265,0 +265,1 @@\n+  case vmIntrinsics::_dsqrt_strict:\n@@ -274,3 +275,0 @@\n-  case vmIntrinsics::_min:\n-  case vmIntrinsics::_max:                      return inline_min_max(intrinsic_id());\n-\n@@ -290,0 +288,1 @@\n+  case vmIntrinsics::_unsignedMultiplyHigh:     return inline_math_unsignedMultiplyHigh();\n@@ -474,0 +473,1 @@\n+  case vmIntrinsics::_storeStoreFence:\n@@ -641,0 +641,6 @@\n+  case vmIntrinsics::_min:\n+  case vmIntrinsics::_max:\n+  case vmIntrinsics::_min_strict:\n+  case vmIntrinsics::_max_strict:\n+    return inline_min_max(intrinsic_id());\n+\n@@ -645,1 +651,5 @@\n-    return inline_fp_min_max(intrinsic_id());\n+  case vmIntrinsics::_maxF_strict:\n+  case vmIntrinsics::_minF_strict:\n+  case vmIntrinsics::_maxD_strict:\n+  case vmIntrinsics::_minD_strict:\n+      return inline_fp_min_max(intrinsic_id());\n@@ -663,0 +673,2 @@\n+  case vmIntrinsics::_VectorLoadMaskedOp:\n+    return inline_vector_mem_masked_operation(\/*is_store*\/false);\n@@ -665,0 +677,2 @@\n+  case vmIntrinsics::_VectorStoreMaskedOp:\n+    return inline_vector_mem_masked_operation(\/*is_store=*\/true);\n@@ -1608,1 +1622,3 @@\n-  case vmIntrinsics::_dsqrt:  n = new SqrtDNode(C, control(),  arg);  break;\n+  case vmIntrinsics::_dsqrt:\n+  case vmIntrinsics::_dsqrt_strict:\n+                              n = new SqrtDNode(C, control(),  arg);  break;\n@@ -1751,1 +1767,3 @@\n-  case vmIntrinsics::_dsqrt:  return Matcher::match_rule_supported(Op_SqrtD) ? inline_double_math(id) : false;\n+  case vmIntrinsics::_dsqrt:\n+  case vmIntrinsics::_dsqrt_strict:\n+                              return Matcher::match_rule_supported(Op_SqrtD) ? inline_double_math(id) : false;\n@@ -1878,0 +1896,5 @@\n+bool LibraryCallKit::inline_math_unsignedMultiplyHigh() {\n+  set_result(_gvn.transform(new UMulHiLNode(argument(0), argument(2))));\n+  return true;\n+}\n+\n@@ -1888,1 +1911,1 @@\n-  bool want_max = (id == vmIntrinsics::_max);\n+  bool want_max = (id == vmIntrinsics::_max || id == vmIntrinsics::_max_strict);\n@@ -2890,0 +2913,3 @@\n+    case vmIntrinsics::_storeStoreFence:\n+      insert_mem_bar(Op_StoreStoreFence);\n+      return true;\n@@ -7447,0 +7473,2 @@\n+  case vmIntrinsics::_maxF_strict:\n+  case vmIntrinsics::_minF_strict:\n@@ -7453,0 +7481,2 @@\n+  case vmIntrinsics::_maxD_strict:\n+  case vmIntrinsics::_minD_strict:\n@@ -7462,5 +7492,19 @@\n-  case vmIntrinsics::_maxF:  n = new MaxFNode(a, b);  break;\n-  case vmIntrinsics::_minF:  n = new MinFNode(a, b);  break;\n-  case vmIntrinsics::_maxD:  n = new MaxDNode(a, b);  break;\n-  case vmIntrinsics::_minD:  n = new MinDNode(a, b);  break;\n-  default:  fatal_unexpected_iid(id);  break;\n+  case vmIntrinsics::_maxF:\n+  case vmIntrinsics::_maxF_strict:\n+    n = new MaxFNode(a, b);\n+    break;\n+  case vmIntrinsics::_minF:\n+  case vmIntrinsics::_minF_strict:\n+    n = new MinFNode(a, b);\n+    break;\n+  case vmIntrinsics::_maxD:\n+  case vmIntrinsics::_maxD_strict:\n+    n = new MaxDNode(a, b);\n+    break;\n+  case vmIntrinsics::_minD:\n+  case vmIntrinsics::_minD_strict:\n+    n = new MinDNode(a, b);\n+    break;\n+  default:\n+    fatal_unexpected_iid(id);\n+    break;\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":56,"deletions":12,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -243,0 +243,1 @@\n+  bool inline_math_unsignedMultiplyHigh();\n@@ -354,0 +355,1 @@\n+  bool inline_vector_mem_masked_operation(bool is_store);\n@@ -367,4 +369,5 @@\n-    VecMaskUseLoad,\n-    VecMaskUseStore,\n-    VecMaskUseAll,\n-    VecMaskNotUsed\n+    VecMaskUseLoad  = 1 << 0,\n+    VecMaskUseStore = 1 << 1,\n+    VecMaskUseAll   = VecMaskUseLoad | VecMaskUseStore,\n+    VecMaskUsePred  = 1 << 2,\n+    VecMaskNotUsed  = 1 << 3\n@@ -374,1 +377,1 @@\n-  bool arch_supports_vector_rotate(int opc, int num_elem, BasicType elem_bt, bool has_scalar_args = false);\n+  bool arch_supports_vector_rotate(int opc, int num_elem, BasicType elem_bt, VectorMaskUseType mask_use_type, bool has_scalar_args = false);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -740,1 +740,1 @@\n-  bool policy_range_check( PhaseIdealLoop *phase ) const;\n+  bool policy_range_check(PhaseIdealLoop* phase, bool provisional) const;\n@@ -744,0 +744,2 @@\n+  bool is_range_check_if(IfNode* iff, PhaseIdealLoop* phase, BasicType bt, Node* iv, Node*& range, Node*& offset,\n+                         jlong& scale) const;\n@@ -1174,1 +1176,1 @@\n-  void long_loop_replace_long_iv(Node* iv_to_replace, Node* inner_iv, Node* outer_phi, Node* inner_head);\n+  Node* long_loop_replace_long_iv(Node* iv_to_replace, Node* inner_iv, Node* outer_phi, Node* inner_head);\n@@ -1276,1 +1278,1 @@\n-  bool is_scaled_iv(Node* exp, Node* iv, int* p_scale);\n+  bool is_scaled_iv(Node* exp, Node* iv, jlong* p_scale, BasicType bt);\n@@ -1279,1 +1281,12 @@\n-  bool is_scaled_iv_plus_offset(Node* exp, Node* iv, int* p_scale, Node** p_offset, int depth = 0);\n+  bool is_scaled_iv_plus_offset(Node* exp, Node* iv, jlong* p_scale, Node** p_offset, BasicType bt, int depth = 0);\n+  bool is_scaled_iv_plus_offset(Node* exp, Node* iv, int* p_scale, Node** p_offset) {\n+    jlong long_scale;\n+    if (is_scaled_iv_plus_offset(exp, iv, &long_scale, p_offset, T_INT)) {\n+      int int_scale = checked_cast<int>(long_scale);\n+      if (p_scale != NULL) {\n+        *p_scale = int_scale;\n+      }\n+      return true;\n+    }\n+    return false;\n+  }\n@@ -1309,1 +1322,2 @@\n-                         Node* range, bool upper, bool &overflow);\n+                         Node* range, bool upper, bool &overflow,\n+                         bool negate);\n@@ -1631,0 +1645,8 @@\n+\n+  int extract_long_range_checks(const IdealLoopTree* loop, jlong stride_con, int iters_limit, PhiNode* phi,\n+                                      Node_List &range_checks);\n+\n+  void transform_long_range_checks(int stride_con, const Node_List &range_checks, Node* outer_phi,\n+                                   Node* inner_iters_actual_int, Node* inner_phi,\n+                                   Node* iv_add, LoopNode* inner_head);\n+\n@@ -1640,0 +1662,4 @@\n+\n+  Node* clamp(Node* R, Node* L, Node* H);\n+\n+  bool safe_for_if_replacement(const Node* dom) const;\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":31,"deletions":5,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -1139,1 +1139,1 @@\n-  if (n_blk->is_CountedLoop()) {\n+  if (n_blk->is_BaseCountedLoop()) {\n@@ -1557,1 +1557,2 @@\n-        if (dom->req() > 1 && dom->in(1) == bol && prevdom->in(0) == dom) {\n+        if (dom->req() > 1 && dom->in(1) == bol && prevdom->in(0) == dom &&\n+            safe_for_if_replacement(dom)) {\n@@ -1600,0 +1601,19 @@\n+bool PhaseIdealLoop::safe_for_if_replacement(const Node* dom) const {\n+  if (!dom->is_CountedLoopEnd()) {\n+    return true;\n+  }\n+  CountedLoopEndNode* le = dom->as_CountedLoopEnd();\n+  CountedLoopNode* cl = le->loopnode();\n+  if (cl == NULL) {\n+    return true;\n+  }\n+  if (!cl->is_main_loop()) {\n+    return true;\n+  }\n+  if (cl->is_canonical_loop_entry() == NULL) {\n+    return true;\n+  }\n+  \/\/ Further unrolling is possible so loop exit condition might change\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":22,"deletions":2,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -1769,1 +1769,2 @@\n-                                          CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc_base),\n+                                          CAST_FROM_FN_PTR(address,\n+                                          static_cast<int (*)(Thread*, oopDesc*)>(SharedRuntime::dtrace_object_alloc)),\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -203,0 +203,1 @@\n+  void migrate_outs(Node *old, Node *target);\n","filename":"src\/hotspot\/share\/opto\/macro.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -458,0 +458,18 @@\n+const int Matcher::scalable_predicate_reg_slots() {\n+  assert(Matcher::has_predicated_vectors() && Matcher::supports_scalable_vector(),\n+        \"scalable predicate vector should be supported\");\n+  int vector_reg_bit_size = Matcher::scalable_vector_reg_size(T_BYTE) << LogBitsPerByte;\n+  \/\/ We assume each predicate register is one-eighth of the size of\n+  \/\/ scalable vector register, one mask bit per vector byte.\n+  int predicate_reg_bit_size = vector_reg_bit_size >> 3;\n+  \/\/ Compute number of slots which is required when scalable predicate\n+  \/\/ register is spilled. E.g. if scalable vector register is 640 bits,\n+  \/\/ predicate register is 80 bits, which is 2.5 * slots.\n+  \/\/ We will round up the slot number to power of 2, which is required\n+  \/\/ by find_first_set().\n+  int slots = predicate_reg_bit_size & (BitsPerInt - 1)\n+              ? (predicate_reg_bit_size >> LogBitsPerInt) + 1\n+              : predicate_reg_bit_size >> LogBitsPerInt;\n+  return round_up_power_of_2(slots);\n+}\n+\n@@ -567,0 +585,2 @@\n+  } else {\n+    *idealreg2spillmask[Op_RegVectMask] = RegMask::Empty;\n@@ -639,0 +659,13 @@\n+    \/\/ Exclude last input arg stack slots to avoid spilling vector register there,\n+    \/\/ otherwise RegVectMask spills could stomp over stack slots in caller frame.\n+    for (; (in >= init_in) && (k < scalable_predicate_reg_slots()); k++) {\n+      scalable_stack_mask.Remove(in);\n+      in = OptoReg::add(in, -1);\n+    }\n+\n+    \/\/ For RegVectMask\n+    scalable_stack_mask.clear_to_sets(scalable_predicate_reg_slots());\n+    assert(scalable_stack_mask.is_AllStack(), \"should be infinite stack\");\n+    *idealreg2spillmask[Op_RegVectMask] = *idealreg2regmask[Op_RegVectMask];\n+    idealreg2spillmask[Op_RegVectMask]->OR(scalable_stack_mask);\n+\n@@ -2261,0 +2294,1 @@\n+    case Op_VectorLoadMask:\n@@ -2306,0 +2340,15 @@\n+  if (n->is_predicated_vector()) {\n+    \/\/ Restructure into binary trees for Matching.\n+    if (n->req() == 4) {\n+      n->set_req(1, new BinaryNode(n->in(1), n->in(2)));\n+      n->set_req(2, n->in(3));\n+      n->del_req(3);\n+    } else if (n->req() == 5) {\n+      n->set_req(1, new BinaryNode(n->in(1), n->in(2)));\n+      n->set_req(2, new BinaryNode(n->in(3), n->in(4)));\n+      n->del_req(4);\n+      n->del_req(3);\n+    }\n+    return;\n+  }\n+\n@@ -2452,0 +2501,1 @@\n+    case Op_LoadVectorGatherMasked:\n@@ -2458,0 +2508,9 @@\n+    case Op_StoreVectorScatterMasked: {\n+      Node* pair = new BinaryNode(n->in(MemNode::ValueIn+1), n->in(MemNode::ValueIn+2));\n+      n->set_req(MemNode::ValueIn+1, pair);\n+      n->del_req(MemNode::ValueIn+2);\n+      pair = new BinaryNode(n->in(MemNode::ValueIn), n->in(MemNode::ValueIn+1));\n+      n->set_req(MemNode::ValueIn, pair);\n+      n->del_req(MemNode::ValueIn+1);\n+      break;\n+    }\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":59,"deletions":0,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -334,0 +334,2 @@\n+  static const bool match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt);\n+\n@@ -350,0 +352,2 @@\n+  \/\/ Actual max scalable predicate register length.\n+  static const int scalable_predicate_reg_slots();\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1091,1 +1091,2 @@\n-          opc == Op_MemBarStoreStore) {\n+          opc == Op_MemBarStoreStore ||\n+          opc == Op_StoreStoreFence) {\n@@ -1146,1 +1147,1 @@\n-      if (store_Opcode() == Op_StoreVector) {\n+      if (st->is_StoreVector()) {\n@@ -3427,0 +3428,2 @@\n+  case Op_MemBarStoreStore:  return new MemBarStoreStoreNode(C, atp, pn);\n+  case Op_StoreStoreFence:   return new StoreStoreFenceNode(C, atp, pn);\n@@ -3433,1 +3436,0 @@\n-  case Op_MemBarStoreStore:  return new MemBarStoreStoreNode(C, atp, pn);\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1323,0 +1323,7 @@\n+class StoreStoreFenceNode: public MemBarNode {\n+public:\n+  StoreStoreFenceNode(Compile* C, int alias_idx, Node* precedent)\n+    : MemBarNode(C, alias_idx, precedent) {}\n+  virtual int Opcode() const;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -447,1 +447,0 @@\n-  \/\/ Either input is TOP ==> the result is TOP\n@@ -450,0 +449,14 @@\n+  const Type *bot = bottom_type();\n+  return MulHiValue(t1, t2, bot);\n+}\n+\n+const Type* UMulHiLNode::Value(PhaseGVN* phase) const {\n+  const Type *t1 = phase->type( in(1) );\n+  const Type *t2 = phase->type( in(2) );\n+  const Type *bot = bottom_type();\n+  return MulHiValue(t1, t2, bot);\n+}\n+\n+\/\/ A common routine used by UMulHiLNode and MulHiLNode\n+const Type* MulHiValue(const Type *t1, const Type *t2, const Type *bot) {\n+  \/\/ Either input is TOP ==> the result is TOP\n@@ -454,1 +467,0 @@\n-  const Type *bot = bottom_type();\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -102,0 +102,1 @@\n+class LShiftNode;\n@@ -180,0 +181,1 @@\n+class VectorUnboxNode;\n@@ -181,0 +183,1 @@\n+class VectorReinterpretNode;\n@@ -718,0 +721,2 @@\n+        DEFINE_CLASS_ID(VectorUnbox, Vector, 1)\n+        DEFINE_CLASS_ID(VectorReinterpret, Vector, 2)\n@@ -770,0 +775,1 @@\n+    DEFINE_CLASS_ID(LShift,   Node, 18)\n@@ -792,1 +798,2 @@\n-    Flag_for_post_loop_opts_igvn     = 1 << 15,\n+    Flag_is_predicated_vector        = 1 << 15,\n+    Flag_for_post_loop_opts_igvn     = 1 << 16,\n@@ -901,0 +908,1 @@\n+  DEFINE_CLASS_QUERY(LShift)\n@@ -953,0 +961,3 @@\n+  DEFINE_CLASS_QUERY(VectorMaskCmp)\n+  DEFINE_CLASS_QUERY(VectorUnbox)\n+  DEFINE_CLASS_QUERY(VectorReinterpret);\n@@ -957,1 +968,0 @@\n-  DEFINE_CLASS_QUERY(VectorMaskCmp)\n@@ -1008,0 +1018,2 @@\n+  bool is_predicated_vector() const { return (_flags & Flag_is_predicated_vector) != 0; }\n+\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2984,0 +2984,10 @@\n+  if (OptoReg::is_reg(def_reg)) {\n+    VMReg vmreg = OptoReg::as_VMReg(def_reg);\n+    if (vmreg->is_reg() && !vmreg->is_concrete() && !vmreg->prev()->is_concrete()) {\n+      \/\/ This is one of the high slots of a vector register.\n+      \/\/ ScheduleAndBundle already checked there are no live wide\n+      \/\/ vectors in this method so it can be safely ignored.\n+      return;\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -81,1 +81,2 @@\n-                                JVMState* jvms);\n+                                int caller_bci,\n+                                ciCallProfile& profile);\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -761,2 +761,2 @@\n-  int lo_index     = iter().get_int_table(1);\n-  int hi_index     = iter().get_int_table(2);\n+  jint lo_index    = iter().get_int_table(1);\n+  jint hi_index    = iter().get_int_table(2);\n@@ -789,1 +789,1 @@\n-    uint cnt = 1;\n+    float cnt = 1.0F;\n@@ -791,1 +791,1 @@\n-      cnt = profile->default_count() \/ (hi_index != max_jint ? 2 : 1);\n+      cnt = (float)profile->default_count() \/ (hi_index != max_jint ? 2.0F : 1.0F);\n@@ -799,1 +799,1 @@\n-    uint cnt = 1;\n+    float cnt = 1.0F;\n@@ -801,1 +801,1 @@\n-      cnt = profile->count_at(j);\n+      cnt = (float)profile->count_at(j);\n@@ -810,1 +810,1 @@\n-    uint cnt = 1;\n+    float cnt = 1.0F;\n@@ -812,1 +812,1 @@\n-      cnt = profile->default_count() \/ (lo_index != min_jint ? 2 : 1);\n+      cnt = (float)profile->default_count() \/ (lo_index != min_jint ? 2.0F : 1.0F);\n@@ -838,1 +838,1 @@\n-  int len          = iter().get_int_table(1);\n+  jint len          = iter().get_int_table(1);\n@@ -864,1 +864,1 @@\n-      table[3*j+2] = (profile == NULL) ? 1 : MIN2<uint>(max_jint, profile->count_at(j));\n+      table[3*j+2] = (profile == NULL) ? 1 : (jint)MIN2<uint>((uint)max_jint, profile->count_at(j));\n@@ -869,13 +869,1 @@\n-  float defaults = 0;\n-  jint prev = min_jint;\n-  for (int j = 0; j < len; j++) {\n-    jint match_int = table[3*j+0];\n-    if (match_int != prev) {\n-      defaults += (float)match_int - prev;\n-    }\n-    prev = match_int+1;\n-  }\n-  if (prev != min_jint) {\n-    defaults += (float)max_jint - prev + 1;\n-  }\n-  float default_cnt = 1;\n+  float default_cnt = 1.0F;\n@@ -883,1 +871,2 @@\n-    default_cnt = profile->default_count()\/defaults;\n+    juint defaults = max_juint - len;\n+    default_cnt = (float)profile->default_count()\/(float)defaults;\n@@ -892,3 +881,3 @@\n-    int  dest        = table[3*j+1];\n-    int  cnt         = table[3*j+2];\n-    int  next_lo     = rp < 0 ? min_jint : ranges[rp].hi()+1;\n+    jint  dest        = table[3*j+1];\n+    jint  cnt         = table[3*j+2];\n+    jint  next_lo     = rp < 0 ? min_jint : ranges[rp].hi()+1;\n@@ -896,1 +885,1 @@\n-    float c = default_cnt * ((float)match_int - next_lo);\n+    float c = default_cnt * ((float)match_int - (float)next_lo);\n@@ -901,1 +890,1 @@\n-    if (rp < 0 || !ranges[rp].adjoin(match_int, dest, cnt, trim_ranges)) {\n+    if (rp < 0 || !ranges[rp].adjoin(match_int, dest, (float)cnt, trim_ranges)) {\n@@ -903,1 +892,1 @@\n-      ranges[++rp].set(match_int, dest, cnt);\n+      ranges[++rp].set(match_int, dest,  (float)cnt);\n@@ -909,2 +898,2 @@\n-      !ranges[rp].adjoinRange(highest+1, max_jint, default_dest, default_cnt * ((float)max_jint - highest), trim_ranges)) {\n-    ranges[++rp].setRange(highest+1, max_jint, default_dest, default_cnt * ((float)max_jint - highest));\n+      !ranges[rp].adjoinRange(highest+1, max_jint, default_dest, default_cnt * ((float)max_jint - (float)highest), trim_ranges)) {\n+    ranges[++rp].setRange(highest+1, max_jint, default_dest, default_cnt * ((float)max_jint - (float)highest));\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":21,"deletions":32,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -795,3 +795,1 @@\n-    jint int_con = (jint)l;\n-    assert(((long)int_con) == l, \"not an int\");\n-    return intcon(int_con);\n+    return intcon(checked_cast<jint>(l));\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -311,1 +311,1 @@\n-    int size = TypeArrayKlass::cast(array_type)->oop_size(result);\n+    const size_t size = TypeArrayKlass::cast(array_type)->oop_size(result);\n@@ -1290,0 +1290,5 @@\n+  \/\/ The frame we rethrow the exception to might not have been processed by the GC yet.\n+  \/\/ The stack watermark barrier takes care of detecting that and ensuring the frame\n+  \/\/ has updated oops.\n+  StackWatermarkSet::after_unwind(current);\n+\n@@ -1432,1 +1437,1 @@\n-    RegisterMap map(current, false);\n+    RegisterMap map(current, false \/* update_map *\/, false \/* process_frames *\/);\n@@ -1471,5 +1476,0 @@\n-  \/\/ The frame we rethrow the exception to might not have been processed by the GC yet.\n-  \/\/ The stack watermark barrier takes care of detecting that and ensuring the frame\n-  \/\/ has updated oops.\n-  StackWatermarkSet::after_unwind(thread);\n-\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1585,0 +1585,3 @@\n+  const int cmp1_op = cmp1->Opcode();\n+  const int cmp2_op = cmp2->Opcode();\n+\n@@ -1587,1 +1590,0 @@\n-  uint op2 = cmp2->Opcode();\n@@ -1591,1 +1593,1 @@\n-  if( con->is_Con() && !cmp2->is_Con() && op2 != Op_Opaque1 &&\n+  if( con->is_Con() && !cmp2->is_Con() && cmp2_op != Op_Opaque1 &&\n@@ -1609,1 +1611,1 @@\n-      cmp1->Opcode() == Op_AndI && cmp2->Opcode() == Op_ConI &&\n+      cmp1_op == Op_AndI && cmp2_op == Op_ConI &&\n@@ -1623,1 +1625,1 @@\n-      cmp1->Opcode() == Op_AndL && cmp2->Opcode() == Op_ConL &&\n+      cmp1_op == Op_AndL && cmp2_op == Op_ConL &&\n@@ -1634,0 +1636,32 @@\n+  \/\/ Change \"cmp (add X min_jint) (add Y min_jint)\" into \"cmpu X Y\"\n+  \/\/ and    \"cmp (add X min_jint) c\" into \"cmpu X (c + min_jint)\"\n+  if (cop == Op_CmpI &&\n+      cmp1_op == Op_AddI &&\n+      phase->type(cmp1->in(2)) == TypeInt::MIN) {\n+    if (cmp2_op == Op_ConI) {\n+      Node* ncmp2 = phase->intcon(java_add(cmp2->get_int(), min_jint));\n+      Node* ncmp = phase->transform(new CmpUNode(cmp1->in(1), ncmp2));\n+      return new BoolNode(ncmp, _test._test);\n+    } else if (cmp2_op == Op_AddI &&\n+               phase->type(cmp2->in(2)) == TypeInt::MIN) {\n+      Node* ncmp = phase->transform(new CmpUNode(cmp1->in(1), cmp2->in(1)));\n+      return new BoolNode(ncmp, _test._test);\n+    }\n+  }\n+\n+  \/\/ Change \"cmp (add X min_jlong) (add Y min_jlong)\" into \"cmpu X Y\"\n+  \/\/ and    \"cmp (add X min_jlong) c\" into \"cmpu X (c + min_jlong)\"\n+  if (cop == Op_CmpL &&\n+      cmp1_op == Op_AddL &&\n+      phase->type(cmp1->in(2)) == TypeLong::MIN) {\n+    if (cmp2_op == Op_ConL) {\n+      Node* ncmp2 = phase->longcon(java_add(cmp2->get_long(), min_jlong));\n+      Node* ncmp = phase->transform(new CmpULNode(cmp1->in(1), ncmp2));\n+      return new BoolNode(ncmp, _test._test);\n+    } else if (cmp2_op == Op_AddL &&\n+               phase->type(cmp2->in(2)) == TypeLong::MIN) {\n+      Node* ncmp = phase->transform(new CmpULNode(cmp1->in(1), cmp2->in(1)));\n+      return new BoolNode(ncmp, _test._test);\n+    }\n+  }\n+\n@@ -1637,1 +1671,0 @@\n-  int cmp1_op = cmp1->Opcode();\n","filename":"src\/hotspot\/share\/opto\/subnode.cpp","additions":38,"deletions":5,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -65,0 +65,4 @@\n+  virtual bool operates_on(BasicType bt, bool signed_int) const {\n+    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n+    return false;\n+  }\n@@ -80,0 +84,4 @@\n+  virtual bool operates_on(BasicType bt, bool signed_int) const {\n+    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n+    return bt == T_INT;\n+  }\n@@ -93,0 +101,4 @@\n+  virtual bool operates_on(BasicType bt, bool signed_int) const {\n+    assert(bt == T_INT || bt == T_LONG, \"unsupported\");\n+    return bt == T_LONG;\n+  }\n","filename":"src\/hotspot\/share\/opto\/subnode.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1072,1 +1072,0 @@\n-\n@@ -2624,1 +2623,4 @@\n-const TypeVect* TypeVect::make(const Type *elem, uint length) {\n+const TypeVect* TypeVect::make(const Type *elem, uint length, bool is_mask) {\n+  if (is_mask) {\n+    return makemask(elem, length);\n+  }\n@@ -2650,1 +2652,3 @@\n-  if (Matcher::has_predicated_vectors()) {\n+  BasicType elem_bt = elem->array_element_basic_type();\n+  if (Matcher::has_predicated_vectors() &&\n+      Matcher::match_rule_supported_vector_masked(Op_VectorLoadMask, length, elem_bt)) {\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -883,1 +883,1 @@\n-  static const TypeVect *make(const BasicType elem_bt, uint length) {\n+  static const TypeVect *make(const BasicType elem_bt, uint length, bool is_mask = false) {\n@@ -885,1 +885,1 @@\n-    return make(get_const_basic_type(elem_bt), length);\n+    return make(get_const_basic_type(elem_bt), length, is_mask);\n@@ -888,1 +888,1 @@\n-  static const TypeVect *make(const Type* elem, uint length);\n+  static const TypeVect *make(const Type* elem, uint length, bool is_mask = false);\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -318,0 +318,15 @@\n+  } else if (vbox->is_Phi() && (vect->is_Vector() || vect->is_LoadVector())) {\n+    \/\/ Handle the case when the allocation input to VectorBoxNode is a phi\n+    \/\/ but the vector input is not, which can definitely be the case if the\n+    \/\/ vector input has been value-numbered. It seems to be safe to do by\n+    \/\/ construction because VectorBoxNode and VectorBoxAllocate come in a\n+    \/\/ specific order as a result of expanding an intrinsic call. After that, if\n+    \/\/ any of the inputs to VectorBoxNode are value-numbered they can only\n+    \/\/ move up and are guaranteed to dominate.\n+    Node* new_phi = new PhiNode(vbox->as_Phi()->region(), box_type);\n+    for (uint i = 1; i < vbox->req(); i++) {\n+      Node* new_box = expand_vbox_node_helper(vbox->in(i), vect, box_type, vect_type);\n+      new_phi->set_req(i, new_box);\n+    }\n+    new_phi = C->initial_gvn()->transform(new_phi);\n+    return new_phi;\n@@ -341,1 +356,4 @@\n-  if (is_mask && bt != T_BOOLEAN) {\n+  \/\/ If boxed mask value is present in a predicate register, it must be\n+  \/\/ spilled to a vector though a VectorStoreMaskOperation before actual StoreVector\n+  \/\/ operation to vector payload field.\n+  if (is_mask && (value->bottom_type()->isa_vectmask() || bt != T_BOOLEAN)) {\n@@ -457,1 +475,1 @@\n-      vec_val_load = gvn.transform(new VectorLoadMaskNode(vec_val_load, TypeVect::make(masktype, num_elem)));\n+      vec_val_load = gvn.transform(new VectorLoadMaskNode(vec_val_load, TypeVect::makemask(masktype, num_elem)));\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":21,"deletions":3,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -655,5 +655,2 @@\n-  JNIHandleBlock* old_handles = thread->active_handles();\n-  JNIHandleBlock* new_handles = JNIHandleBlock::allocate_block(thread);\n-  assert(new_handles != NULL, \"should not be NULL\");\n-  new_handles->set_pop_frame_link(old_handles);\n-  thread->set_active_handles(new_handles);\n+\n+  thread->push_jni_handle_block();\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -108,0 +108,3 @@\n+#if INCLUDE_MANAGEMENT\n+#include \"services\/finalizerService.hpp\"\n+#endif\n@@ -427,2 +430,2 @@\n-  if (DynamicDumpSharedSpaces) {\n-    DynamicArchive::prepare_for_dynamic_dumping();\n+  if (DynamicArchive::should_dump_at_vm_exit()) {\n+    DynamicArchive::prepare_for_dump_at_exit();\n@@ -683,1 +686,1 @@\n-  const int size = obj->size();\n+  const size_t size = obj->size();\n@@ -707,0 +710,6 @@\n+\/\/ java.lang.ref.Finalizer \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(void, JVM_ReportFinalizationComplete(JNIEnv * env, jobject finalizee))\n+  MANAGEMENT_ONLY(FinalizerService::on_complete(JNIHandles::resolve_non_null(finalizee), THREAD);)\n+JVM_END\n+\n@@ -3033,1 +3042,1 @@\n-      JavaThread::send_async_exception(java_thread, java_throwable);\n+      JavaThread::send_async_exception(receiver, java_throwable);\n@@ -3432,1 +3441,1 @@\n-JVM_ENTRY_NO_ENV(void*, JVM_LoadLibrary(const char* name))\n+JVM_ENTRY_NO_ENV(void*, JVM_LoadLibrary(const char* name, jboolean throwException))\n@@ -3441,12 +3450,17 @@\n-    char msg[1024];\n-    jio_snprintf(msg, sizeof msg, \"%s: %s\", name, ebuf);\n-    \/\/ Since 'ebuf' may contain a string encoded using\n-    \/\/ platform encoding scheme, we need to pass\n-    \/\/ Exceptions::unsafe_to_utf8 to the new_exception method\n-    \/\/ as the last argument. See bug 6367357.\n-    Handle h_exception =\n-      Exceptions::new_exception(thread,\n-                                vmSymbols::java_lang_UnsatisfiedLinkError(),\n-                                msg, Exceptions::unsafe_to_utf8);\n-\n-    THROW_HANDLE_0(h_exception);\n+    if (throwException) {\n+      char msg[1024];\n+      jio_snprintf(msg, sizeof msg, \"%s: %s\", name, ebuf);\n+      \/\/ Since 'ebuf' may contain a string encoded using\n+      \/\/ platform encoding scheme, we need to pass\n+      \/\/ Exceptions::unsafe_to_utf8 to the new_exception method\n+      \/\/ as the last argument. See bug 6367357.\n+      Handle h_exception =\n+        Exceptions::new_exception(thread,\n+                                  vmSymbols::java_lang_UnsatisfiedLinkError(),\n+                                  msg, Exceptions::unsafe_to_utf8);\n+\n+      THROW_HANDLE_0(h_exception);\n+    } else {\n+      log_info(library)(\"Failed to load library %s\", name);\n+      return load_result;\n+    }\n@@ -3764,1 +3778,1 @@\n-  DynamicArchive::dump(archive_name, CHECK);\n+  DynamicArchive::dump_for_jcmd(archive_name, CHECK);\n@@ -3923,0 +3937,1 @@\n+\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":33,"deletions":18,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -1075,1 +1075,1 @@\n-  JavaThread::send_async_exception(java_thread->threadObj(), e);\n+  JavaThread::send_async_exception(java_thread, e);\n@@ -1563,1 +1563,1 @@\n-    Handshake::execute(&op, java_thread);\n+    Handshake::execute(&op, &tlh, java_thread);\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -144,3 +144,0 @@\n-#if 0\n-  JNIHandleBlock* _hblock;\n-#endif\n@@ -152,6 +149,0 @@\n-#if 0\n-    _hblock = thread->active_handles();\n-    _hblock->clear_thoroughly(); \/\/ so we can be safe\n-#else\n-    \/\/ we want to use the code above - but that needs the JNIHandle changes - later...\n-    \/\/ for now, steal JNI push local frame code\n@@ -165,6 +156,1 @@\n-    JNIHandleBlock* old_handles = thread->active_handles();\n-    JNIHandleBlock* new_handles = JNIHandleBlock::allocate_block(thread);\n-    assert(new_handles != NULL, \"should not be NULL\");\n-    new_handles->set_pop_frame_link(old_handles);\n-    thread->set_active_handles(new_handles);\n-#endif\n+    thread->push_jni_handle_block();\n@@ -176,14 +162,1 @@\n-#if 0\n-    _hblock->clear(); \/\/ for consistency with future correct behavior\n-#else\n-    \/\/ we want to use the code above - but that needs the JNIHandle changes - later...\n-    \/\/ for now, steal JNI pop local frame code\n-    JNIHandleBlock* old_handles = _thread->active_handles();\n-    JNIHandleBlock* new_handles = old_handles->pop_frame_link();\n-    assert(new_handles != NULL, \"should not be NULL\");\n-    _thread->set_active_handles(new_handles);\n-    \/\/ Note that we set the pop_frame_link to NULL explicitly, otherwise\n-    \/\/ the release_block call will release the blocks.\n-    old_handles->set_pop_frame_link(NULL);\n-    JNIHandleBlock::release_block(old_handles, _thread); \/\/ may block\n-#endif\n+    _thread->pop_jni_handle_block();\n@@ -199,6 +172,0 @@\n-#if 0\n-  jobject to_jobject(oop obj) { return obj == NULL? NULL : _hblock->allocate_handle_fast(obj); }\n-#else\n-  \/\/ we want to use the code above - but that needs the JNIHandle changes - later...\n-  \/\/ for now, use regular make_local\n-#endif\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.cpp","additions":2,"deletions":35,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -4415,0 +4415,3 @@\n+  \/\/ Scratch class is unloaded but still needs cleaning, and skipping for CDS.\n+  scratch_class->set_is_scratch_class();\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -128,1 +128,1 @@\n-      assert(p->field_addr((jint)byte_offset) == ptr_plus_disp,\n+      assert(p->field_addr<void>((jint)byte_offset) == ptr_plus_disp,\n@@ -226,8 +226,2 @@\n-    if (_obj == NULL) {\n-      GuardUnsafeAccess guard(_thread);\n-      T ret = RawAccess<>::load(addr());\n-      return normalize_for_read(ret);\n-    } else {\n-      T ret = HeapAccess<>::load_at(_obj, _offset);\n-      return normalize_for_read(ret);\n-    }\n+    GuardUnsafeAccess guard(_thread);\n+    return normalize_for_read(*addr());\n@@ -237,7 +231,3 @@\n-    if (_obj == NULL) {\n-      GuardUnsafeAccess guard(_thread);\n-      RawAccess<>::store(addr(), normalize_for_write(x));\n-    } else {\n-      assert(!_obj->is_inline_type() || _obj->mark().is_larval_state(), \"must be an object instance or a larval inline type\");\n-      HeapAccess<>::store_at(_obj, _offset, normalize_for_write(x));\n-    }\n+    GuardUnsafeAccess guard(_thread);\n+    assert(_obj == NULL || !_obj->is_inline_type() || _obj->mark().is_larval_state(), \"must be an object instance or a larval inline type\");\n+    *addr() = normalize_for_write(x);\n@@ -246,8 +236,3 @@\n-    if (_obj == NULL) {\n-      GuardUnsafeAccess guard(_thread);\n-      volatile T ret = RawAccess<MO_SEQ_CST>::load(addr());\n-      return normalize_for_read(ret);\n-    } else {\n-      T ret = HeapAccess<MO_SEQ_CST>::load_at(_obj, _offset);\n-      return normalize_for_read(ret);\n-    }\n+    GuardUnsafeAccess guard(_thread);\n+    volatile T ret = RawAccess<MO_SEQ_CST>::load(addr());\n+    return normalize_for_read(ret);\n@@ -258,6 +243,2 @@\n-    if (_obj == NULL) {\n-      GuardUnsafeAccess guard(_thread);\n-      RawAccess<MO_SEQ_CST>::store(addr(), normalize_for_write(x));\n-    } else {\n-      HeapAccess<MO_SEQ_CST>::store_at(_obj, _offset, normalize_for_write(x));\n-    }\n+    GuardUnsafeAccess guard(_thread);\n+    RawAccess<MO_SEQ_CST>::store(addr(), normalize_for_write(x));\n@@ -477,8 +458,0 @@\n-UNSAFE_LEAF(void, Unsafe_LoadFence(JNIEnv *env, jobject unsafe)) {\n-  OrderAccess::acquire();\n-} UNSAFE_END\n-\n-UNSAFE_LEAF(void, Unsafe_StoreFence(JNIEnv *env, jobject unsafe)) {\n-  OrderAccess::release();\n-} UNSAFE_END\n-\n@@ -892,7 +865,2 @@\n-  if (p == NULL) {\n-    volatile jint* addr = (volatile jint*)index_oop_from_field_offset_long(p, offset);\n-    return RawAccess<>::atomic_cmpxchg(addr, e, x);\n-  } else {\n-    assert_field_offset_sane(p, offset);\n-    return HeapAccess<>::atomic_cmpxchg_at(p, (ptrdiff_t)offset, e, x);\n-  }\n+  volatile jint* addr = (volatile jint*)index_oop_from_field_offset_long(p, offset);\n+  return Atomic::cmpxchg(addr, e, x);\n@@ -903,7 +871,2 @@\n-  if (p == NULL) {\n-    volatile jlong* addr = (volatile jlong*)index_oop_from_field_offset_long(p, offset);\n-    return RawAccess<>::atomic_cmpxchg(addr, e, x);\n-  } else {\n-    assert_field_offset_sane(p, offset);\n-    return HeapAccess<>::atomic_cmpxchg_at(p, (ptrdiff_t)offset, e, x);\n-  }\n+  volatile jlong* addr = (volatile jlong*)index_oop_from_field_offset_long(p, offset);\n+  return Atomic::cmpxchg(addr, e, x);\n@@ -923,7 +886,2 @@\n-  if (p == NULL) {\n-    volatile jint* addr = (volatile jint*)index_oop_from_field_offset_long(p, offset);\n-    return RawAccess<>::atomic_cmpxchg(addr, e, x) == e;\n-  } else {\n-    assert_field_offset_sane(p, offset);\n-    return HeapAccess<>::atomic_cmpxchg_at(p, (ptrdiff_t)offset, e, x) == e;\n-  }\n+  volatile jint* addr = (volatile jint*)index_oop_from_field_offset_long(p, offset);\n+  return Atomic::cmpxchg(addr, e, x) == e;\n@@ -934,7 +892,2 @@\n-  if (p == NULL) {\n-    volatile jlong* addr = (volatile jlong*)index_oop_from_field_offset_long(p, offset);\n-    return RawAccess<>::atomic_cmpxchg(addr, e, x) == e;\n-  } else {\n-    assert_field_offset_sane(p, offset);\n-    return HeapAccess<>::atomic_cmpxchg_at(p, (ptrdiff_t)offset, e, x) == e;\n-  }\n+  volatile jlong* addr = (volatile jlong*)index_oop_from_field_offset_long(p, offset);\n+  return Atomic::cmpxchg(addr, e, x) == e;\n@@ -1105,2 +1058,0 @@\n-    {CC \"loadFence\",          CC \"()V\",                  FN_PTR(Unsafe_LoadFence)},\n-    {CC \"storeFence\",         CC \"()V\",                  FN_PTR(Unsafe_StoreFence)},\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":19,"deletions":68,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -2163,4 +2163,7 @@\n-  oop thread_oop = JNIHandles::resolve(thread_handle);\n-  if (thread_oop != NULL) {\n-    JavaThread* target = java_lang_Thread::thread(thread_oop);\n-    Handshake::execute(&rmc, target);\n+  if (thread_handle != NULL) {\n+    ThreadsListHandle tlh;\n+    JavaThread* target = nullptr;\n+    bool is_alive = tlh.cv_internal_thread_to_JavaThread(thread_handle, &target, NULL);\n+    if (is_alive) {\n+      Handshake::execute(&rmc, &tlh, target);\n+    }\n@@ -2194,5 +2197,6 @@\n-  } else {\n-    oop thread_oop = JNIHandles::resolve(thread_handle);\n-    if (thread_oop != NULL) {\n-      JavaThread* target = java_lang_Thread::thread(thread_oop);\n-      Handshake::execute(&tsc, target);\n+  } else if (thread_handle != NULL) {\n+    ThreadsListHandle tlh;\n+    JavaThread* target = nullptr;\n+    bool is_alive = tlh.cv_internal_thread_to_JavaThread(thread_handle, &target, NULL);\n+    if (is_alive) {\n+      Handshake::execute(&tsc, &tlh, target);\n@@ -2222,5 +2226,8 @@\n-  oop thread_oop = JNIHandles::resolve(thread_handle);\n-  if (thread_oop != NULL) {\n-    JavaThread* target = java_lang_Thread::thread(thread_oop);\n-    TraceSelfClosure* tsc = new TraceSelfClosure(target);\n-    Handshake::execute(tsc, target);\n+  if (thread_handle != NULL) {\n+    ThreadsListHandle tlh;\n+    JavaThread* target = nullptr;\n+    bool is_alive = tlh.cv_internal_thread_to_JavaThread(thread_handle, &target, NULL);\n+    if (is_alive) {\n+      TraceSelfClosure* tsc = new TraceSelfClosure(target);\n+      Handshake::execute(tsc, target);\n+    }\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":21,"deletions":14,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -530,0 +530,5 @@\n+  { \"MinInliningThreshold\",         JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::jdk(20) },\n+  { \"DumpSharedSpaces\",             JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::undefined() },\n+  { \"DynamicDumpSharedSpaces\",      JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::undefined() },\n+  { \"RequireSharedSpaces\",          JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::undefined() },\n+  { \"UseSharedSpaces\",              JDK_Version::jdk(18), JDK_Version::jdk(19), JDK_Version::undefined() },\n@@ -1441,0 +1446,2 @@\n+      } else {\n+        log_info(cds)(\"CDS is disabled when the %s option is specified.\", unsupported_options[i]);\n@@ -3147,7 +3154,0 @@\n-  if (DumpSharedSpaces || ArchiveClassesAtExit != NULL) {\n-    \/\/ Always verify non-system classes during CDS dump\n-    if (!BytecodeVerificationRemote) {\n-      BytecodeVerificationRemote = true;\n-      log_info(cds)(\"All non-system classes will be verified (-Xverify:remote) during CDS dump time.\");\n-    }\n-  }\n@@ -3157,1 +3157,2 @@\n-    log_info(cds)(\"RecordDynamicDumpInfo is for jcmd only, could not set with -XX:ArchiveClassesAtExit.\");\n+    jio_fprintf(defaultStream::output_stream(),\n+                \"-XX:+RecordDynamicDumpInfo cannot be used with -XX:ArchiveClassesAtExit.\\n\");\n@@ -3173,0 +3174,8 @@\n+\n+  if (DumpSharedSpaces || DynamicDumpSharedSpaces) {\n+    \/\/ Always verify non-system classes during CDS dump\n+    if (!BytecodeVerificationRemote) {\n+      BytecodeVerificationRemote = true;\n+      log_info(cds)(\"All non-system classes will be verified (-Xverify:remote) during CDS dump time.\");\n+    }\n+  }\n@@ -3452,3 +3461,1 @@\n-  if (!init_shared_archive_paths()) {\n-    return JNI_ENOMEM;\n-  }\n+  init_shared_archive_paths();\n@@ -3517,1 +3524,0 @@\n-  \/\/cur_path[len] = '\\0';\n@@ -3522,2 +3528,3 @@\n-bool Arguments::init_shared_archive_paths() {\n-  if (ArchiveClassesAtExit != NULL) {\n+void Arguments::init_shared_archive_paths() {\n+  if (ArchiveClassesAtExit != nullptr) {\n+    assert(!RecordDynamicDumpInfo, \"already checked\");\n@@ -3527,10 +3534,2 @@\n-    if (FLAG_SET_CMDLINE(DynamicDumpSharedSpaces, true) != JVMFlag::SUCCESS) {\n-      return false;\n-    }\n-    SharedDynamicArchivePath = os::strdup_check_oom(ArchiveClassesAtExit, mtArguments);\n-  } else {\n-    if (SharedDynamicArchivePath != nullptr) {\n-      os::free(SharedDynamicArchivePath);\n-      SharedDynamicArchivePath = nullptr;\n-    }\n-  if (SharedArchiveFile == NULL) {\n+\n+  if (SharedArchiveFile == nullptr) {\n@@ -3542,12 +3541,5 @@\n-    if (is_dumping_archive()) {\n-      if (archives > 1) {\n-        vm_exit_during_initialization(\n-          \"Cannot have more than 1 archive file specified in -XX:SharedArchiveFile during CDS dumping\");\n-      }\n-      if (DynamicDumpSharedSpaces) {\n-        if (os::same_files(SharedArchiveFile, ArchiveClassesAtExit)) {\n-          vm_exit_during_initialization(\n-            \"Cannot have the same archive file specified for -XX:SharedArchiveFile and -XX:ArchiveClassesAtExit\",\n-            SharedArchiveFile);\n-        }\n-      }\n+    assert(archives > 0, \"must be\");\n+\n+    if (is_dumping_archive() && archives > 1) {\n+      vm_exit_during_initialization(\n+        \"Cannot have more than 1 archive file specified in -XX:SharedArchiveFile during CDS dumping\");\n@@ -3555,1 +3547,16 @@\n-    if (!is_dumping_archive()){\n+\n+    if (DumpSharedSpaces) {\n+      assert(archives == 1, \"must be\");\n+      \/\/ Static dump is simple: only one archive is allowed in SharedArchiveFile. This file\n+      \/\/ will be overwritten no matter regardless of its contents\n+      SharedArchivePath = os::strdup_check_oom(SharedArchiveFile, mtArguments);\n+    } else {\n+      \/\/ SharedArchiveFile may specify one or two files. In case (c), the path for base.jsa\n+      \/\/ is read from top.jsa\n+      \/\/    (a) 1 file:  -XX:SharedArchiveFile=base.jsa\n+      \/\/    (b) 2 files: -XX:SharedArchiveFile=base.jsa:top.jsa\n+      \/\/    (c) 2 files: -XX:SharedArchiveFile=top.jsa\n+      \/\/\n+      \/\/ However, if either RecordDynamicDumpInfo or ArchiveClassesAtExit is used, we do not\n+      \/\/ allow cases (b) and (c). Case (b) is already checked above.\n+\n@@ -3562,2 +3569,1 @@\n-        int name_size;\n-          FileMapInfo::get_base_archive_name_from_header(temp_archive_path, &name_size, &SharedArchivePath);\n+          FileMapInfo::get_base_archive_name_from_header(temp_archive_path, &SharedArchivePath);\n@@ -3574,2 +3580,18 @@\n-    } else { \/\/ CDS dumping\n-      SharedArchivePath = os::strdup_check_oom(SharedArchiveFile, mtArguments);\n+\n+      if (SharedDynamicArchivePath != nullptr) {\n+        \/\/ Check for case (c)\n+        if (RecordDynamicDumpInfo) {\n+          vm_exit_during_initialization(\"-XX:+RecordDynamicDumpInfo is unsupported when a dynamic CDS archive is specified in -XX:SharedArchiveFile\",\n+                                        SharedArchiveFile);\n+        }\n+        if (ArchiveClassesAtExit != nullptr) {\n+          vm_exit_during_initialization(\"-XX:ArchiveClassesAtExit is unsupported when a dynamic CDS archive is specified in -XX:SharedArchiveFile\",\n+                                        SharedArchiveFile);\n+        }\n+      }\n+\n+      if (ArchiveClassesAtExit != nullptr && os::same_files(SharedArchiveFile, ArchiveClassesAtExit)) {\n+          vm_exit_during_initialization(\n+            \"Cannot have the same archive file specified for -XX:SharedArchiveFile and -XX:ArchiveClassesAtExit\",\n+            SharedArchiveFile);\n+      }\n@@ -3578,1 +3600,0 @@\n-  return (SharedArchivePath != NULL);\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":63,"deletions":42,"binary":false,"changes":105,"status":"modified"},{"patch":"@@ -211,1 +211,1 @@\n-      st.print(\" allocated (%d bytes)\", obj->size() * HeapWordSize);\n+      st.print(\" allocated (\" SIZE_FORMAT \" bytes)\", obj->size() * HeapWordSize);\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -89,1 +89,1 @@\n-\/\/    These flags are external exported interface (see CCC).  The list of\n+\/\/    These flags are external exported interface (see CSR).  The list of\n@@ -94,1 +94,1 @@\n-\/\/    - the flag is defined in a CCC as an external exported interface.\n+\/\/    - the flag is defined in a CSR request as an external exported interface.\n@@ -317,3 +317,0 @@\n-  product(bool, CriticalJNINatives, false,                                  \\\n-          \"(Deprecated) Check for critical JNI entry points\")               \\\n-                                                                            \\\n@@ -1112,3 +1109,0 @@\n-  notproduct(bool, PrintVtableStats, false,                                 \\\n-          \"print vtables stats at end of run\")                              \\\n-                                                                            \\\n@@ -1357,0 +1351,4 @@\n+  product(int, ErrorLogPrintCodeLimit, 3, DIAGNOSTIC,                       \\\n+          \"max number of compiled code units to print in error log\")        \\\n+          range(0, VMError::max_error_log_print_code)                       \\\n+                                                                            \\\n@@ -1368,3 +1366,3 @@\n-  product(intx, MinInliningThreshold, 250,                                  \\\n-          \"The minimum invocation count a method needs to have to be \"      \\\n-          \"inlined\")                                                        \\\n+  product(intx, MinInliningThreshold, 0,                                    \\\n+          \"(Deprecated) The minimum invocation count a method needs to\"     \\\n+          \"have to be inlined\")                                             \\\n@@ -1424,0 +1422,4 @@\n+  product(double, MinInlineFrequencyRatio, 0.0085, DIAGNOSTIC,               \\\n+          \"Minimum ratio of call site execution to caller method\"           \\\n+          \"invocation to be considered for inlining\")                       \\\n+                                                                            \\\n@@ -1459,3 +1461,0 @@\n-  develop(bool, MetaspaceHandleDeallocations, true,                         \\\n-          \"Switch off Metapace deallocation handling.\")                     \\\n-                                                                            \\\n@@ -1823,1 +1822,1 @@\n-          \"Use shared spaces for metadata\")                                 \\\n+          \"(Deprecated) Use shared spaces for metadata\")                    \\\n@@ -1829,1 +1828,1 @@\n-          \"Require shared spaces for metadata\")                             \\\n+          \"(Deprecated) Require shared spaces for metadata\")                \\\n@@ -1832,3 +1831,3 @@\n-          \"Special mode: JVM reads a class list, loads classes, builds \"    \\\n-          \"shared spaces, and dumps the shared spaces to a file to be \"     \\\n-          \"used in future JVM runs\")                                        \\\n+          \"(Deprecated) Special mode: JVM reads a class list, loads \"       \\\n+          \"classes, builds shared spaces, and dumps the shared spaces to \"  \\\n+          \"a file to be used in future JVM runs\")                           \\\n@@ -1837,1 +1836,1 @@\n-          \"Dynamic archive\")                                                \\\n+          \"(Deprecated) Dynamic archive\")                                   \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":19,"deletions":20,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -61,1 +61,1 @@\n-  return make_local(Thread::current(), obj);\n+  return make_local(JavaThread::current(), obj);\n@@ -65,1 +65,1 @@\n-jobject JNIHandles::make_local(Thread* thread, oop obj, AllocFailType alloc_failmode) {\n+jobject JNIHandles::make_local(JavaThread* thread, oop obj, AllocFailType alloc_failmode) {\n@@ -70,2 +70,1 @@\n-    assert(thread->is_Java_thread(), \"not a Java thread\");\n-    return thread->active_handles()->allocate_handle(obj, alloc_failmode);\n+    return thread->active_handles()->allocate_handle(thread, obj, alloc_failmode);\n@@ -192,1 +191,1 @@\n-jobjectRefType JNIHandles::handle_type(Thread* thread, jobject handle) {\n+jobjectRefType JNIHandles::handle_type(JavaThread* thread, jobject handle) {\n@@ -210,3 +209,1 @@\n-      if (is_local_handle(thread, handle) ||\n-          (thread->is_Java_thread() &&\n-           is_frame_handle(JavaThread::cast(thread), handle))) {\n+      if (is_local_handle(thread, handle) || is_frame_handle(thread, handle)) {\n@@ -225,1 +222,1 @@\n-bool JNIHandles::is_local_handle(Thread* thread, jobject handle) {\n+bool JNIHandles::is_local_handle(JavaThread* thread, jobject handle) {\n@@ -348,5 +345,1 @@\n-int             JNIHandleBlock::_blocks_allocated     = 0;\n-JNIHandleBlock* JNIHandleBlock::_block_free_list      = NULL;\n-#ifndef PRODUCT\n-JNIHandleBlock* JNIHandleBlock::_block_list           = NULL;\n-#endif\n+int JNIHandleBlock::_blocks_allocated = 0;\n@@ -385,2 +378,4 @@\n-JNIHandleBlock* JNIHandleBlock::allocate_block(Thread* thread, AllocFailType alloc_failmode)  {\n-  assert(thread == NULL || thread == Thread::current(), \"sanity check\");\n+JNIHandleBlock* JNIHandleBlock::allocate_block(JavaThread* thread, AllocFailType alloc_failmode)  {\n+  \/\/ The VM thread can allocate a handle block in behalf of another thread during a safepoint.\n+  assert(thread == NULL || thread == Thread::current() || SafepointSynchronize::is_at_safepoint(),\n+         \"sanity check\");\n@@ -393,17 +388,6 @@\n-  }\n-  else {\n-    \/\/ locking with safepoint checking introduces a potential deadlock:\n-    \/\/ - we would hold JNIHandleBlockFreeList_lock and then Threads_lock\n-    \/\/ - another would hold Threads_lock (jni_AttachCurrentThread) and then\n-    \/\/   JNIHandleBlockFreeList_lock (JNIHandleBlock::allocate_block)\n-    MutexLocker ml(JNIHandleBlockFreeList_lock,\n-                   Mutex::_no_safepoint_check_flag);\n-    if (_block_free_list == NULL) {\n-      \/\/ Allocate new block\n-      if (alloc_failmode == AllocFailStrategy::RETURN_NULL) {\n-        block = new (std::nothrow) JNIHandleBlock();\n-        if (block == NULL) {\n-          return NULL;\n-        }\n-      } else {\n-        block = new JNIHandleBlock();\n+  } else {\n+    \/\/ Allocate new block\n+    if (alloc_failmode == AllocFailStrategy::RETURN_NULL) {\n+      block = new (std::nothrow) JNIHandleBlock();\n+      if (block == NULL) {\n+        return NULL;\n@@ -411,10 +395,1 @@\n-      _blocks_allocated++;\n-      block->zap();\n-      #ifndef PRODUCT\n-      \/\/ Link new block to list of all allocated blocks\n-      block->_block_list_link = _block_list;\n-      _block_list = block;\n-      #endif\n-      \/\/ Get block from free list\n-      block = _block_free_list;\n-      _block_free_list = _block_free_list->_next;\n+      block = new JNIHandleBlock();\n@@ -423,0 +398,2 @@\n+    Atomic::inc(&_blocks_allocated);\n+    block->zap();\n@@ -436,1 +413,1 @@\n-void JNIHandleBlock::release_block(JNIHandleBlock* block, Thread* thread) {\n+void JNIHandleBlock::release_block(JNIHandleBlock* block, JavaThread* thread) {\n@@ -457,14 +434,2 @@\n-    \/\/ Return blocks to free list\n-    \/\/ locking with safepoint checking introduces a potential deadlock:\n-    \/\/ - we would hold JNIHandleBlockFreeList_lock and then Threads_lock\n-    \/\/ - another would hold Threads_lock (jni_AttachCurrentThread) and then\n-    \/\/   JNIHandleBlockFreeList_lock (JNIHandleBlock::allocate_block)\n-    MutexLocker ml(JNIHandleBlockFreeList_lock,\n-                   Mutex::_no_safepoint_check_flag);\n-    while (block != NULL) {\n-      block->zap();\n-      JNIHandleBlock* next = block->_next;\n-      block->_next = _block_free_list;\n-      _block_free_list = block;\n-      block = next;\n-    }\n+    Atomic::dec(&_blocks_allocated);\n+    delete block;\n@@ -510,1 +475,1 @@\n-jobject JNIHandleBlock::allocate_handle(oop obj, AllocFailType alloc_failmode) {\n+jobject JNIHandleBlock::allocate_handle(JavaThread* caller, oop obj, AllocFailType alloc_failmode) {\n@@ -558,1 +523,1 @@\n-    return allocate_handle(obj, alloc_failmode);\n+    return allocate_handle(caller, obj, alloc_failmode);\n@@ -565,5 +530,1 @@\n-    \/\/ Append new block\n-    Thread* thread = Thread::current();\n-    Handle obj_handle(thread, obj);\n-    \/\/ This can block, so we need to preserve obj across call.\n-    _last->_next = JNIHandleBlock::allocate_block(thread, alloc_failmode);\n+    _last->_next = JNIHandleBlock::allocate_block(caller, alloc_failmode);\n@@ -575,2 +536,1 @@\n-    obj = obj_handle();\n-  return allocate_handle(obj, alloc_failmode);  \/\/ retry\n+  return allocate_handle(caller, obj, alloc_failmode);  \/\/ retry\n@@ -654,43 +614,0 @@\n-\n-\n-#ifndef PRODUCT\n-\n-bool JNIHandles::is_local_handle(jobject handle) {\n-  return JNIHandleBlock::any_contains(handle);\n-}\n-\n-bool JNIHandleBlock::any_contains(jobject handle) {\n-  assert(handle != NULL, \"precondition\");\n-  for (JNIHandleBlock* current = _block_list; current != NULL; current = current->_block_list_link) {\n-    if (current->contains(handle)) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-\n-void JNIHandleBlock::print_statistics() {\n-  int used_blocks = 0;\n-  int free_blocks = 0;\n-  int used_handles = 0;\n-  int free_handles = 0;\n-  JNIHandleBlock* block = _block_list;\n-  while (block != NULL) {\n-    if (block->_top > 0) {\n-      used_blocks++;\n-    } else {\n-      free_blocks++;\n-    }\n-    used_handles += block->_top;\n-    free_handles += (block_size_in_oops - block->_top);\n-    block = block->_block_list_link;\n-  }\n-  tty->print_cr(\"JNIHandleBlocks statistics\");\n-  tty->print_cr(\"- blocks allocated: %d\", used_blocks + free_blocks);\n-  tty->print_cr(\"- blocks in use:    %d\", used_blocks);\n-  tty->print_cr(\"- blocks free:      %d\", free_blocks);\n-  tty->print_cr(\"- handles in use:   %d\", used_handles);\n-  tty->print_cr(\"- handles free:     %d\", free_handles);\n-}\n-\n-#endif\n","filename":"src\/hotspot\/share\/runtime\/jniHandles.cpp","additions":27,"deletions":110,"binary":false,"changes":137,"status":"modified"},{"patch":"@@ -40,1 +40,2 @@\n-#include \"gc\/shared\/workgroup.hpp\"\n+#include \"gc\/shared\/workerThread.hpp\"\n+#include \"gc\/shared\/workerUtils.hpp\"\n@@ -519,1 +520,1 @@\n-class ParallelSPCleanupTask : public AbstractGangTask {\n+class ParallelSPCleanupTask : public WorkerTask {\n@@ -543,1 +544,1 @@\n-    AbstractGangTask(\"Parallel Safepoint Cleanup\"),\n+    WorkerTask(\"Parallel Safepoint Cleanup\"),\n@@ -606,1 +607,1 @@\n-  WorkGang* cleanup_workers = heap->safepoint_workers();\n+  WorkerThreads* cleanup_workers = heap->safepoint_workers();\n@@ -709,1 +710,0 @@\n-  assert(is_a_block_safe_state(state), \"Illegal threadstate encountered: %d\", state);\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -503,1 +503,1 @@\n-      \/\/ * OptoRuntime::rethrow_C for C2 code\n+      \/\/ * OptoRuntime::handle_exception_C_helper for C2 code\n@@ -1008,2 +1008,2 @@\n-int SharedRuntime::dtrace_object_alloc(oopDesc* o, int size) {\n-  return dtrace_object_alloc_base(Thread::current(), o, size);\n+int SharedRuntime::dtrace_object_alloc(oopDesc* o) {\n+  return dtrace_object_alloc(Thread::current(), o, o->size());\n@@ -1012,1 +1012,5 @@\n-int SharedRuntime::dtrace_object_alloc_base(Thread* thread, oopDesc* o, int size) {\n+int SharedRuntime::dtrace_object_alloc(Thread* thread, oopDesc* o) {\n+  return dtrace_object_alloc(thread, o, o->size());\n+}\n+\n+int SharedRuntime::dtrace_object_alloc(Thread* thread, oopDesc* o, size_t size) {\n@@ -3249,1 +3253,0 @@\n-  address critical_entry = NULL;\n@@ -3255,5 +3258,0 @@\n-  if (CriticalJNINatives && !method->is_method_handle_intrinsic()) {\n-    \/\/ We perform the I\/O with transition to native before acquiring AdapterHandlerLibrary_lock.\n-    critical_entry = NativeLookup::lookup_critical_entry(method);\n-  }\n-\n@@ -3312,1 +3310,1 @@\n-      nm = SharedRuntime::generate_native_wrapper(&_masm, method, compile_id, sig_bt, regs, ret_type, critical_entry);\n+      nm = SharedRuntime::generate_native_wrapper(&_masm, method, compile_id, sig_bt, regs, ret_type);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":9,"deletions":11,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -275,2 +275,3 @@\n-  static int dtrace_object_alloc(oopDesc* o, int size);\n-  static int dtrace_object_alloc_base(Thread* thread, oopDesc* o, int size);\n+  static int dtrace_object_alloc(oopDesc* o);\n+  static int dtrace_object_alloc(Thread* thread, oopDesc* o);\n+  static int dtrace_object_alloc(Thread* thread, oopDesc* o, size_t size);\n@@ -502,2 +503,1 @@\n-  \/\/ is a JNI critical method, or a compiled method handle adapter,\n-  \/\/ such as _invokeBasic, _linkToVirtual, etc.\n+  \/\/ is a compiled method handle adapter, such as _invokeBasic, _linkToVirtual, etc.\n@@ -509,2 +509,1 @@\n-                                          BasicType ret_type,\n-                                          address critical_entry);\n+                                          BasicType ret_type);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":5,"deletions":6,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -224,2 +224,0 @@\n-  set_active_handles(NULL);\n-  set_free_handle_block(NULL);\n@@ -439,3 +437,6 @@\n-\/\/ Is the target JavaThread protected by the calling Thread\n-\/\/ or by some other mechanism:\n-bool Thread::is_JavaThread_protected(const JavaThread* p) {\n+\/\/ Is the target JavaThread protected by the calling Thread or by some other\n+\/\/ mechanism?\n+\/\/\n+bool Thread::is_JavaThread_protected(const JavaThread* target) {\n+  Thread* current_thread = Thread::current();\n+\n@@ -452,1 +453,1 @@\n-  if (p->osthread() == NULL || p->osthread()->get_state() <= INITIALIZED) {\n+  if (target->osthread() == NULL || target->osthread()->get_state() <= INITIALIZED) {\n@@ -457,2 +458,1 @@\n-  Thread* current_thread = Thread::current();\n-  if (current_thread == p || Threads_lock->owner() == current_thread) {\n+  if (current_thread == target || Threads_lock->owner() == current_thread) {\n@@ -467,6 +467,2 @@\n-  for (SafeThreadsListPtr* stlp = current_thread->_threads_list_ptr;\n-       stlp != NULL; stlp = stlp->previous()) {\n-    if (stlp->list()->includes(p)) {\n-      \/\/ The target JavaThread is protected by this ThreadsList:\n-      return true;\n-    }\n+  if (is_JavaThread_protected_by_TLH(target)) {\n+    return true;\n@@ -477,2 +473,2 @@\n-  \/\/ guarantee(!UseNewCode, \"current_thread=\" INTPTR_FORMAT \" is not protecting p=\"\n-  \/\/           INTPTR_FORMAT, p2i(current_thread), p2i(p));\n+  \/\/ guarantee(!UseNewCode, \"current_thread=\" INTPTR_FORMAT \" is not protecting target=\"\n+  \/\/           INTPTR_FORMAT, p2i(current_thread), p2i(target));\n@@ -480,2 +476,2 @@\n-  \/\/ Note: Since 'p' isn't protected by a TLH, the call to\n-  \/\/ p->is_handshake_safe_for() may crash, but we have debug bits so\n+  \/\/ Note: Since 'target' isn't protected by a TLH, the call to\n+  \/\/ target->is_handshake_safe_for() may crash, but we have debug bits so\n@@ -483,2 +479,2 @@\n-  assert(p->is_handshake_safe_for(current_thread), \"JavaThread=\" INTPTR_FORMAT\n-         \" is not protected and not handshake safe.\", p2i(p));\n+  assert(target->is_handshake_safe_for(current_thread), \"JavaThread=\" INTPTR_FORMAT\n+         \" is not protected and not handshake safe.\", p2i(target));\n@@ -490,0 +486,20 @@\n+\/\/ Is the target JavaThread protected by a ThreadsListHandle (TLH) associated\n+\/\/ with the calling Thread?\n+\/\/\n+bool Thread::is_JavaThread_protected_by_TLH(const JavaThread* target) {\n+  Thread* current_thread = Thread::current();\n+\n+  \/\/ Check the ThreadsLists associated with the calling thread (if any)\n+  \/\/ to see if one of them protects the target JavaThread:\n+  for (SafeThreadsListPtr* stlp = current_thread->_threads_list_ptr;\n+       stlp != NULL; stlp = stlp->previous()) {\n+    if (stlp->list()->includes(target)) {\n+      \/\/ The target JavaThread is protected by this ThreadsList:\n+      return true;\n+    }\n+  }\n+\n+  \/\/ The target JavaThread is not protected by a TLH so it is not safe to query:\n+  return false;\n+}\n+\n@@ -533,3 +549,0 @@\n-  if (active_handles() != NULL) {\n-    active_handles()->oops_do(f);\n-  }\n@@ -1001,0 +1014,2 @@\n+  _active_handles(NULL),\n+  _free_handle_block(NULL),\n@@ -1006,1 +1021,3 @@\n-  _async_exception_condition(_no_async_condition),\n+#ifdef ASSERT\n+  _is_unsafe_access_error(false),\n+#endif\n@@ -1576,3 +1593,0 @@\n-\/\/ Note: this function shouldn't block if it's called in\n-\/\/ _thread_in_native_trans state (such as from\n-\/\/ check_special_condition_for_native_trans()).\n@@ -1604,9 +1618,1 @@\n-  AsyncExceptionCondition condition = clear_async_exception_condition();\n-  if (condition == _no_async_condition) {\n-    \/\/ Conditions have changed since has_special_runtime_exit_condition()\n-    \/\/ was called:\n-    \/\/ - if we were here only because of an external suspend request,\n-    \/\/   then that was taken care of above (or cancelled) so we are done\n-    \/\/ - if we were here because of another async request, then it has\n-    \/\/   been cleared between the has_special_runtime_exit_condition()\n-    \/\/   and now so again we are done\n+  if (!clear_async_exception_condition()) {\n@@ -1616,2 +1622,1 @@\n-  \/\/ Check for pending async. exception\n-    \/\/ Only overwrite an already pending exception, if it is not a threadDeath.\n+    \/\/ Only overwrite an already pending exception if it is not a threadDeath.\n@@ -1635,4 +1640,6 @@\n-      _pending_async_exception = NULL;\n-      \/\/ Clear condition from _suspend_flags since we have finished processing it.\n-      clear_suspend_flag(_has_async_exception);\n-  }\n+    \/\/ Always null out the _pending_async_exception oop here since the async condition was\n+    \/\/ already cleared above and thus considered handled.\n+    _pending_async_exception = NULL;\n+  } else {\n+    assert(_is_unsafe_access_error, \"must be\");\n+    DEBUG_ONLY(_is_unsafe_access_error = false);\n@@ -1641,1 +1648,0 @@\n-  if (condition == _async_unsafe_access_error && !has_pending_exception()) {\n@@ -1648,6 +1654,3 @@\n-      return;\n-    }\n-    case _thread_in_native: {\n-      ThreadInVMfromNative tiv(this);\n-      JavaThread* THREAD = this;\n-      Exceptions::throw_unsafe_access_internal_error(THREAD, __FILE__, __LINE__, \"a fault occurred in an unsafe memory access operation\");\n+      \/\/ We might have blocked in a ThreadBlockInVM wrapper in the call above so make sure we process pending\n+      \/\/ suspend requests and object reallocation operations if any since we might be going to Java after this.\n+      SafepointMechanism::process_if_requested_with_exit_check(this, true \/* check asyncs *\/);\n@@ -1666,2 +1669,0 @@\n-\n-  assert(has_pending_exception(), \"must have handled the async condition if no exception\");\n@@ -1700,1 +1701,1 @@\n-void JavaThread::send_async_exception(oop java_thread, oop java_throwable) {\n+void JavaThread::send_async_exception(JavaThread* target, oop java_throwable) {\n@@ -1702,1 +1703,0 @@\n-  JavaThread* target = java_lang_Thread::thread(java_thread);\n@@ -1762,5 +1762,2 @@\n-  ThreadsListHandle tlh;\n-  if (!tlh.includes(this)) {\n-    log_trace(thread, suspend)(\"JavaThread:\" INTPTR_FORMAT \" not on ThreadsList, no suspension\", p2i(this));\n-    return false;\n-  }\n+  guarantee(Thread::is_JavaThread_protected_by_TLH(\/* target *\/ this),\n+            \"missing ThreadsListHandle in calling context.\");\n@@ -1771,5 +1768,2 @@\n-  ThreadsListHandle tlh;\n-  if (!tlh.includes(this)) {\n-    log_trace(thread, suspend)(\"JavaThread:\" INTPTR_FORMAT \" not on ThreadsList, nothing to resume\", p2i(this));\n-    return false;\n-  }\n+  guarantee(Thread::is_JavaThread_protected_by_TLH(\/* target *\/ this),\n+            \"missing ThreadsListHandle in calling context.\");\n@@ -1851,0 +1845,2 @@\n+  thread->set_thread_state(_thread_in_vm);\n+\n@@ -1854,1 +1850,1 @@\n-  SafepointMechanism::process_if_requested_with_exit_check(thread, false \/* check asyncs *\/);\n+  SafepointMechanism::process_if_requested_with_exit_check(thread, true \/* check asyncs *\/);\n@@ -1860,6 +1856,0 @@\n-\n-  if (thread->has_async_exception_condition(false \/* check unsafe access error *\/)) {\n-    \/\/ We are in _thread_in_native_trans state, don't handle unsafe\n-    \/\/ access error since that may block.\n-    thread->check_and_handle_async_exceptions();\n-  }\n@@ -1952,0 +1942,22 @@\n+\/\/ Push on a new block of JNI handles.\n+void JavaThread::push_jni_handle_block() {\n+  \/\/ Allocate a new block for JNI handles.\n+  \/\/ Inlined code from jni_PushLocalFrame()\n+  JNIHandleBlock* old_handles = active_handles();\n+  JNIHandleBlock* new_handles = JNIHandleBlock::allocate_block(this);\n+  assert(old_handles != NULL && new_handles != NULL, \"should not be NULL\");\n+  new_handles->set_pop_frame_link(old_handles);  \/\/ make sure java handles get gc'd.\n+  set_active_handles(new_handles);\n+}\n+\n+\/\/ Pop off the current block of JNI handles.\n+void JavaThread::pop_jni_handle_block() {\n+  \/\/ Release our JNI handle block\n+  JNIHandleBlock* old_handles = active_handles();\n+  JNIHandleBlock* new_handles = old_handles->pop_frame_link();\n+  assert(new_handles != nullptr, \"should never set active handles to null\");\n+  set_active_handles(new_handles);\n+  old_handles->set_pop_frame_link(NULL);\n+  JNIHandleBlock::release_block(old_handles, this);\n+}\n+\n@@ -1959,0 +1971,4 @@\n+  if (active_handles() != NULL) {\n+    active_handles()->oops_do(f);\n+  }\n+\n@@ -2159,1 +2175,1 @@\n-  if (Thread::is_JavaThread_protected(this)) {\n+  if (Thread::is_JavaThread_protected(\/* target *\/ this)) {\n@@ -2852,1 +2868,1 @@\n-    Thread* vmthread = VMThread::vm_thread();\n+    VMThread* vmthread = VMThread::vm_thread();\n@@ -2864,1 +2880,1 @@\n-      while (vmthread->active_handles() == NULL) {\n+      while (!vmthread->is_running()) {\n@@ -3291,2 +3307,2 @@\n-  if (DynamicDumpSharedSpaces) {\n-    DynamicArchive::prepare_for_dynamic_dumping();\n+  if (DynamicArchive::should_dump_at_vm_exit()) {\n+    DynamicArchive::prepare_for_dump_at_exit();\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":91,"deletions":75,"binary":false,"changes":166,"status":"modified"},{"patch":"@@ -102,1 +102,0 @@\n-\/\/         - GangWorker\n@@ -203,3 +202,6 @@\n-  \/\/ Is the target JavaThread protected by the calling Thread\n-  \/\/ or by some other mechanism:\n-  static bool is_JavaThread_protected(const JavaThread* p);\n+  \/\/ Is the target JavaThread protected by the calling Thread or by some other\n+  \/\/ mechanism?\n+  static bool is_JavaThread_protected(const JavaThread* target);\n+  \/\/ Is the target JavaThread protected by a ThreadsListHandle (TLH) associated\n+  \/\/ with the calling Thread?\n+  static bool is_JavaThread_protected_by_TLH(const JavaThread* target);\n@@ -240,6 +242,0 @@\n-  \/\/ Active_handles points to a block of handles\n-  JNIHandleBlock* _active_handles;\n-\n-  \/\/ One-element thread local free list\n-  JNIHandleBlock* _free_handle_block;\n-\n@@ -418,6 +414,0 @@\n-  \/\/ JNI handle support\n-  JNIHandleBlock* active_handles() const         { return _active_handles; }\n-  void set_active_handles(JNIHandleBlock* block) { _active_handles = block; }\n-  JNIHandleBlock* free_handle_block() const      { return _free_handle_block; }\n-  void set_free_handle_block(JNIHandleBlock* block) { _free_handle_block = block; }\n-\n@@ -609,1 +599,0 @@\n-  static ByteSize active_handles_offset()        { return byte_offset_of(Thread, _active_handles); }\n@@ -750,0 +739,7 @@\n+\n+  \/\/ Active_handles points to a block of handles\n+  JNIHandleBlock* _active_handles;\n+\n+  \/\/ One-element thread local free list\n+  JNIHandleBlock* _free_handle_block;\n+\n@@ -777,0 +773,9 @@\n+  \/\/ JNI handle support\n+  JNIHandleBlock* active_handles() const         { return _active_handles; }\n+  void set_active_handles(JNIHandleBlock* block) { _active_handles = block; }\n+  JNIHandleBlock* free_handle_block() const      { return _free_handle_block; }\n+  void set_free_handle_block(JNIHandleBlock* block) { _free_handle_block = block; }\n+\n+  void push_jni_handle_block();\n+  void pop_jni_handle_block();\n+\n@@ -807,14 +812,4 @@\n-  enum AsyncExceptionCondition {\n-    _no_async_condition = 0,\n-    _async_exception,\n-    _async_unsafe_access_error\n-  };\n-  AsyncExceptionCondition _async_exception_condition;\n-  oop                     _pending_async_exception;\n-\n-  void set_async_exception_condition(AsyncExceptionCondition aec) { _async_exception_condition = aec; }\n-  AsyncExceptionCondition clear_async_exception_condition() {\n-    AsyncExceptionCondition x = _async_exception_condition;\n-    _async_exception_condition = _no_async_condition;\n-    return x;\n-  }\n+  oop     _pending_async_exception;\n+#ifdef ASSERT\n+  bool    _is_unsafe_access_error;\n+#endif\n@@ -822,0 +817,1 @@\n+  inline bool clear_async_exception_condition();\n@@ -823,3 +819,2 @@\n-  bool has_async_exception_condition(bool check_unsafe_access_error = true) {\n-    return check_unsafe_access_error ? _async_exception_condition != _no_async_condition\n-                                     : _async_exception_condition == _async_exception;\n+  bool has_async_exception_condition() {\n+    return (_suspend_flags & _has_async_exception) != 0;\n@@ -828,9 +823,2 @@\n-  void set_pending_unsafe_access_error()  {\n-    \/\/ Don't overwrite an asynchronous exception sent by another thread\n-    if (_async_exception_condition == _no_async_condition) {\n-      set_async_exception_condition(_async_unsafe_access_error);\n-    }\n-  }\n-  void check_and_handle_async_exceptions();\n-  \/\/ Installs a pending exception to be inserted later\n-  static void send_async_exception(oop thread_oop, oop java_throwable);\n+  inline void set_pending_unsafe_access_error();\n+  static void send_async_exception(JavaThread* jt, oop java_throwable);\n@@ -838,0 +826,1 @@\n+  void check_and_handle_async_exceptions();\n@@ -1182,2 +1171,1 @@\n-    return (_async_exception_condition != _no_async_condition) ||\n-           (_suspend_flags & (_obj_deopt JFR_ONLY(| _trace_flag))) != 0;\n+    return (_suspend_flags & (_has_async_exception | _obj_deopt JFR_ONLY(| _trace_flag))) != 0;\n@@ -1308,0 +1296,2 @@\n+  static ByteSize active_handles_offset()        { return byte_offset_of(JavaThread, _active_handles); }\n+\n@@ -1770,0 +1760,9 @@\n+class JNIHandleMark : public StackObj {\n+  JavaThread* _thread;\n+ public:\n+  JNIHandleMark(JavaThread* thread) : _thread(thread) {\n+    thread->push_jni_handle_block();\n+  }\n+  ~JNIHandleMark() { _thread->pop_jni_handle_block(); }\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":44,"deletions":45,"binary":false,"changes":89,"status":"modified"},{"patch":"@@ -371,1 +371,1 @@\n-  Monitor timer(Mutex::nosafepoint, \"VM_ExitTimer_lock\", Monitor::_safepoint_check_never);\n+  Monitor timer(Mutex::nosafepoint, \"VM_ExitTimer_lock\");\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -709,1 +709,0 @@\n-  nonstatic_field(Thread,                      _active_handles,                               JNIHandleBlock*)                       \\\n@@ -722,1 +721,0 @@\n-  nonstatic_field(JavaThread,                  _async_exception_condition,                    JavaThread::AsyncExceptionCondition)   \\\n@@ -734,0 +732,1 @@\n+  nonstatic_field(JavaThread,                  _active_handles,                               JNIHandleBlock*)                       \\\n@@ -830,1 +829,0 @@\n-  nonstatic_field(ciMethodData,                _current_mileage,                              int)                                   \\\n@@ -891,3 +889,1 @@\n-  c2_nonstatic_field(Compile,                  _subsume_loads,                                const bool)                            \\\n-  c2_nonstatic_field(Compile,                  _do_escape_analysis,                           const bool)                            \\\n-  c2_nonstatic_field(Compile,                  _eliminate_boxing,                             const bool)                            \\\n+  c2_nonstatic_field(Compile,                  _options,                                      const Options)                         \\\n@@ -896,0 +892,6 @@\n+  c2_nonstatic_field(Options,                  _subsume_loads,                                const bool)                            \\\n+  c2_nonstatic_field(Options,                  _do_escape_analysis,                           const bool)                            \\\n+  c2_nonstatic_field(Options,                  _eliminate_boxing,                             const bool)                            \\\n+  c2_nonstatic_field(Options,                  _do_locks_coarsening,                          const bool)                            \\\n+  c2_nonstatic_field(Options,                  _install_code,                                 const bool)                            \\\n+                                                                                                                                     \\\n@@ -1449,0 +1451,1 @@\n+  declare_c2_toplevel_type(Options)                                       \\\n@@ -1679,0 +1682,1 @@\n+  declare_c2_type(UMulHiLNode, Node)                                      \\\n@@ -1853,0 +1857,4 @@\n+  declare_c2_type(MaskAllNode, VectorNode)                                \\\n+  declare_c2_type(AndVMaskNode, VectorNode)                               \\\n+  declare_c2_type(OrVMaskNode, VectorNode)                                \\\n+  declare_c2_type(XorVMaskNode, VectorNode)                               \\\n@@ -1959,1 +1967,0 @@\n-  declare_integer_type(JavaThread::AsyncExceptionCondition)               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":14,"deletions":7,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n-#include \"gc\/shared\/workgroup.hpp\"\n+#include \"gc\/shared\/workerThread.hpp\"\n@@ -57,1 +57,1 @@\n-#include \"runtime\/vmThread.hpp\"\n+#include \"runtime\/vmThread.hpp\"\n@@ -74,2 +74,1 @@\n- *            have the same size as host pointers. For example, on\n- *            Solaris and Win32, the size is 4.\n+ *            have the same size as host pointers.\n@@ -333,1 +332,1 @@\n-typedef enum {\n+enum hprofTag : u1 {\n@@ -378,1 +377,1 @@\n-} hprofTag;\n+};\n@@ -428,1 +427,1 @@\n-  void write_fast(void* s, size_t len);\n+  void write_fast(const void* s, size_t len);\n@@ -450,1 +449,1 @@\n-  virtual void write_raw(void* s, size_t len);\n+  virtual void write_raw(const void* s, size_t len);\n@@ -480,1 +479,1 @@\n-void AbstractDumpWriter::write_fast(void* s, size_t len) {\n+void AbstractDumpWriter::write_fast(const void* s, size_t len) {\n@@ -493,1 +492,1 @@\n-void AbstractDumpWriter::write_raw(void* s, size_t len) {\n+void AbstractDumpWriter::write_raw(const void* s, size_t len) {\n@@ -518,1 +517,1 @@\n-  WRITE_KNOWN_TYPE((void*) &x, 1);\n+  WRITE_KNOWN_TYPE(&x, 1);\n@@ -524,1 +523,1 @@\n-  WRITE_KNOWN_TYPE((void*)&v, 2);\n+  WRITE_KNOWN_TYPE(&v, 2);\n@@ -530,1 +529,1 @@\n-  WRITE_KNOWN_TYPE((void*)&v, 4);\n+  WRITE_KNOWN_TYPE(&v, 4);\n@@ -536,1 +535,1 @@\n-  WRITE_KNOWN_TYPE((void*)&v, 8);\n+  WRITE_KNOWN_TYPE(&v, 8);\n@@ -644,1 +643,1 @@\n-  virtual void flush(bool force = false);\n+  void flush(bool force = false) override;\n@@ -651,1 +650,1 @@\n-  virtual julong bytes_written() const          { return (julong) _backend.get_written(); }\n+  julong bytes_written() const override { return (julong) _backend.get_written(); }\n@@ -653,1 +652,1 @@\n-  virtual char const* error() const             { return _backend.error(); }\n+  char const* error() const override    { return _backend.error(); }\n@@ -658,1 +657,1 @@\n-  virtual void deactivate()             { flush(); _backend.deactivate(); }\n+  void deactivate() override            { flush(); _backend.deactivate(); }\n@@ -660,1 +659,1 @@\n-  CompressionBackend* backend_ptr() { return &_backend; }\n+  CompressionBackend* backend_ptr()     { return &_backend; }\n@@ -738,1 +737,1 @@\n-  virtual void flush(bool force = false) {\n+  void flush(bool force = false) override {\n@@ -779,2 +778,2 @@\n-  virtual julong bytes_written() const          { return (julong) _backend_ptr->get_written(); }\n-  virtual char const* error() const { return _err == NULL ? _backend_ptr->error() : _err; }\n+  julong bytes_written() const override { return (julong) _backend_ptr->get_written(); }\n+  char const* error() const override    { return _err == NULL ? _backend_ptr->error() : _err; }\n@@ -784,1 +783,1 @@\n-    _lock = new (std::nothrow) PaddedMonitor(Mutex::nonleaf, \"ParallelHProfWriter_lock\", Mutex::_safepoint_check_always);\n+    _lock = new (std::nothrow) PaddedMonitor(Mutex::safepoint, \"ParallelHProfWriter_lock\");\n@@ -794,1 +793,1 @@\n-  virtual void write_raw(void* s, size_t len) {\n+  void write_raw(const void* s, size_t len) override {\n@@ -815,1 +814,1 @@\n-  virtual void deactivate()             { flush(true); _backend_ptr->deactivate(); }\n+  void deactivate() override { flush(true); _backend_ptr->deactivate(); }\n@@ -992,1 +991,1 @@\n-  writer->write_u1((u1)tag);\n+  writer->write_u1(tag);\n@@ -1046,0 +1045,7 @@\n+template<typename T, typename F> T bit_cast(F from) { \/\/ replace with the real thing when we can use c++20\n+  T to;\n+  static_assert(sizeof(to) == sizeof(from), \"must be of the same size\");\n+  memcpy(&to, &from, sizeof(to));\n+  return to;\n+}\n+\n@@ -1049,1 +1055,1 @@\n-    writer->write_u4(0x7fc00000);    \/\/ collapsing NaNs\n+    writer->write_u4(0x7fc00000); \/\/ collapsing NaNs\n@@ -1051,6 +1057,1 @@\n-    union {\n-      int i;\n-      float f;\n-    } u;\n-    u.f = (float)f;\n-    writer->write_u4((u4)u.i);\n+    writer->write_u4(bit_cast<u4>(f));\n@@ -1062,7 +1063,2 @@\n-  union {\n-    jlong l;\n-    double d;\n-  } u;\n-  if (g_isnan(d)) {                 \/\/ collapsing NaNs\n-    u.l = (jlong)(0x7ff80000);\n-    u.l = (u.l << 32);\n+  if (g_isnan(d)) {\n+    writer->write_u8(0x7ff80000ull << 32); \/\/ collapsing NaNs\n@@ -1070,1 +1066,1 @@\n-    u.d = (double)d;\n+    writer->write_u8(bit_cast<u8>(d));\n@@ -1072,1 +1068,0 @@\n-  writer->write_u8((u8)u.l);\n@@ -1104,1 +1099,1 @@\n-      writer->write_u1((u1)b);\n+      writer->write_u1(b);\n@@ -1109,1 +1104,1 @@\n-      writer->write_u2((u2)c);\n+      writer->write_u2(c);\n@@ -1114,1 +1109,1 @@\n-      writer->write_u2((u2)s);\n+      writer->write_u2(s);\n@@ -1129,1 +1124,1 @@\n-      writer->write_u4((u4)i);\n+      writer->write_u4(i);\n@@ -1134,1 +1129,1 @@\n-      writer->write_u8((u8)l);\n+      writer->write_u8(l);\n@@ -1139,1 +1134,1 @@\n-      writer->write_u1((u1)b);\n+      writer->write_u1(b);\n@@ -1600,1 +1595,1 @@\n-        writer->write_raw((void*)(array->int_at_addr(0)), length_in_bytes);\n+        writer->write_raw(array->int_at_addr(0), length_in_bytes);\n@@ -1605,1 +1600,1 @@\n-      writer->write_raw((void*)(array->byte_at_addr(0)), length_in_bytes);\n+      writer->write_raw(array->byte_at_addr(0), length_in_bytes);\n@@ -1612,1 +1607,1 @@\n-        writer->write_raw((void*)(array->char_at_addr(0)), length_in_bytes);\n+        writer->write_raw(array->char_at_addr(0), length_in_bytes);\n@@ -1620,1 +1615,1 @@\n-        writer->write_raw((void*)(array->short_at_addr(0)), length_in_bytes);\n+        writer->write_raw(array->short_at_addr(0), length_in_bytes);\n@@ -1628,1 +1623,1 @@\n-        writer->write_raw((void*)(array->bool_at_addr(0)), length_in_bytes);\n+        writer->write_raw(array->bool_at_addr(0), length_in_bytes);\n@@ -1636,1 +1631,1 @@\n-        writer->write_raw((void*)(array->long_at_addr(0)), length_in_bytes);\n+        writer->write_raw(array->long_at_addr(0), length_in_bytes);\n@@ -1950,2 +1945,1 @@\n-     _lock(new (std::nothrow) PaddedMonitor(Mutex::nonleaf, \"DumperController_lock\",\n-    Mutex::_safepoint_check_always)),\n+     _lock(new (std::nothrow) PaddedMonitor(Mutex::safepoint, \"DumperController_lock\")),\n@@ -1990,1 +1984,1 @@\n-class VM_HeapDumper : public VM_GC_Operation, public AbstractGangTask {\n+class VM_HeapDumper : public VM_GC_Operation, public WorkerTask {\n@@ -2110,1 +2104,1 @@\n-    AbstractGangTask(\"dump heap\") {\n+    WorkerTask(\"dump heap\") {\n@@ -2385,1 +2379,1 @@\n-  WorkGang* gang = ch->safepoint_workers();\n+  WorkerThreads* workers = ch->safepoint_workers();\n@@ -2387,1 +2381,1 @@\n-  if (gang == NULL) {\n+  if (workers == NULL) {\n@@ -2393,2 +2387,2 @@\n-    prepare_parallel_dump(gang->active_workers());\n-    gang->run_task(this);\n+    prepare_parallel_dump(workers->active_workers());\n+    workers->run_task(this);\n@@ -2418,2 +2412,1 @@\n-    writer()->write_raw((void*)header, (int)strlen(header));\n-    writer()->write_u1(0); \/\/ terminator\n+    writer()->write_raw(header, strlen(header) + 1); \/\/ NUL terminated\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":57,"deletions":64,"binary":false,"changes":121,"status":"modified"},{"patch":"@@ -72,0 +72,1 @@\n+  JVM_ACC_IS_BEING_REDEFINED      = 0x00100000,     \/\/ True if the klass is being redefined.\n@@ -163,0 +164,4 @@\n+  bool is_being_redefined() const       { return (_flags & JVM_ACC_IS_BEING_REDEFINED) != 0; }\n+  void set_is_being_redefined()         { atomic_set_bits(JVM_ACC_IS_BEING_REDEFINED); }\n+  void clear_is_being_redefined()       { atomic_clear_bits(JVM_ACC_IS_BEING_REDEFINED); }\n+\n","filename":"src\/hotspot\/share\/utilities\/accessFlags.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -325,0 +325,11 @@\n+  void truncate_to(int idx) {\n+    for (int i = 0, j = idx; j < length(); i++, j++) {\n+      at_put(i, at(j));\n+    }\n+    trunc_to(length() - idx);\n+  }\n+\n+  void truncate_from(int idx) {\n+    trunc_to(idx);\n+  }\n+\n","filename":"src\/hotspot\/share\/utilities\/growableArray.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -86,3 +86,4 @@\n- * <p>Classes that require special handling during the serialization and\n- * deserialization process must implement special methods with these exact\n- * signatures:\n+ * <p>Serializable classes that require special handling during the\n+ * serialization and deserialization process should implement methods\n+ * with the following signatures:\n+ *\n@@ -99,0 +100,6 @@\n+ * <p>The method name, modifiers, return type, and number and type of\n+ * parameters must match exactly for the method to be used by\n+ * serialization or deserialization. The methods should only be\n+ * declared to throw checked exceptions consistent with these\n+ * signatures.\n+ *\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectOutputStream.java","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2524,1 +2524,1 @@\n-        static abstract class Key {\n+        abstract static class Key {\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectStreamClass.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -294,1 +294,1 @@\n-     *     synchronized static method of that class.\n+     *     static synchronized method of that class.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Object.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+import java.lang.reflect.Modifier;\n+\n@@ -160,1 +162,1 @@\n-                if (targetClass == implClass) {\n+                if (targetClass == implClass && Modifier.isPrivate(implInfo.getModifiers())) {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/AbstractValidatingLambdaMetafactory.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -261,1 +261,0 @@\n-                                   int indexInCP,\n@@ -320,1 +319,0 @@\n-                                      int indexInCP,\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandleNatives.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -878,34 +878,14 @@\n-     * <table class=\"striped\">\n-     * <caption style=\"display:none\">\n-     * Public types in the following packages are accessible to the\n-     * lookup class and the previous lookup class.\n-     * <\/caption>\n-     * <thead>\n-     * <tr>\n-     * <th scope=\"col\">Equally accessible types to {@code M0} and {@code M1}<\/th>\n-     * <\/tr>\n-     * <\/thead>\n-     * <tbody>\n-     * <tr>\n-     * <th scope=\"row\" style=\"text-align:left\">unconditional-exported packages from {@code M1}<\/th>\n-     * <\/tr>\n-     * <tr>\n-     * <th scope=\"row\" style=\"text-align:left\">unconditional-exported packages from {@code M0} if {@code M1} reads {@code M0}<\/th>\n-     * <\/tr>\n-     * <tr>\n-     * <th scope=\"row\" style=\"text-align:left\">unconditional-exported packages from a third module {@code M2}\n-     * if both {@code M0} and {@code M1} read {@code M2}<\/th>\n-     * <\/tr>\n-     * <tr>\n-     * <th scope=\"row\" style=\"text-align:left\">qualified-exported packages from {@code M1} to {@code M0}<\/th>\n-     * <\/tr>\n-     * <tr>\n-     * <th scope=\"row\" style=\"text-align:left\">qualified-exported packages from {@code M0} to {@code M1}\n-     * if {@code M1} reads {@code M0}<\/th>\n-     * <\/tr>\n-     * <tr>\n-     * <th scope=\"row\" style=\"text-align:left\">qualified-exported packages from a third module {@code M2} to\n-     * both {@code M0} and {@code M1} if both {@code M0} and {@code M1} read {@code M2}<\/th>\n-     * <\/tr>\n-     * <\/tbody>\n-     * <\/table>\n+     * <ul>\n+     * <li>unconditional-exported packages from {@code M1}<\/li>\n+     * <li>unconditional-exported packages from {@code M0} if {@code M1} reads {@code M0}<\/li>\n+     * <li>\n+     *     unconditional-exported packages from a third module {@code M2}if both {@code M0}\n+     *     and {@code M1} read {@code M2}\n+     * <\/li>\n+     * <li>qualified-exported packages from {@code M1} to {@code M0}<\/li>\n+     * <li>qualified-exported packages from {@code M0} to {@code M1} if {@code M1} reads {@code M0}<\/li>\n+     * <li>\n+     *     qualified-exported packages from a third module {@code M2} to both {@code M0} and\n+     *     {@code M1} if both {@code M0} and {@code M1} read {@code M2}\n+     * <\/li>\n+     * <\/ul>\n@@ -978,1 +958,1 @@\n-     * <td>{@code CL.in(D).in(C)} hop back to module<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code CL.in(D).in(C)} hop back to module<\/th>\n@@ -987,1 +967,1 @@\n-     * <td>{@code PRI1 = privateLookupIn(C1,CL)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1 = privateLookupIn(C1,CL)}<\/th>\n@@ -996,1 +976,1 @@\n-     * <td>{@code PRI1a = privateLookupIn(C,PRI1)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1a = privateLookupIn(C,PRI1)}<\/th>\n@@ -1005,1 +985,1 @@\n-     * <td>{@code PRI1.in(C1)} same package<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1.in(C1)} same package<\/th>\n@@ -1014,1 +994,1 @@\n-     * <td>{@code PRI1.in(C1)} different package<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1.in(C1)} different package<\/th>\n@@ -1023,1 +1003,1 @@\n-     * <td>{@code PRI1.in(D)} different module<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1.in(D)} different module<\/th>\n@@ -1032,1 +1012,1 @@\n-     * <td>{@code PRI1.dropLookupMode(PROTECTED)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1.dropLookupMode(PROTECTED)}<\/th>\n@@ -1041,1 +1021,1 @@\n-     * <td>{@code PRI1.dropLookupMode(PRIVATE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1.dropLookupMode(PRIVATE)}<\/th>\n@@ -1050,1 +1030,1 @@\n-     * <td>{@code PRI1.dropLookupMode(PACKAGE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1.dropLookupMode(PACKAGE)}<\/th>\n@@ -1059,1 +1039,1 @@\n-     * <td>{@code PRI1.dropLookupMode(MODULE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1.dropLookupMode(MODULE)}<\/th>\n@@ -1068,1 +1048,1 @@\n-     * <td>{@code PRI1.dropLookupMode(PUBLIC)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI1.dropLookupMode(PUBLIC)}<\/th>\n@@ -1076,1 +1056,1 @@\n-     * <td>{@code PRI2 = privateLookupIn(D,CL)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2 = privateLookupIn(D,CL)}<\/th>\n@@ -1085,1 +1065,1 @@\n-     * <td>{@code privateLookupIn(D,PRI1)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code privateLookupIn(D,PRI1)}<\/th>\n@@ -1094,1 +1074,1 @@\n-     * <td>{@code privateLookupIn(C,PRI2)} fails<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code privateLookupIn(C,PRI2)} fails<\/th>\n@@ -1103,1 +1083,1 @@\n-     * <td>{@code PRI2.in(D2)} same package<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.in(D2)} same package<\/th>\n@@ -1112,1 +1092,1 @@\n-     * <td>{@code PRI2.in(D2)} different package<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.in(D2)} different package<\/th>\n@@ -1121,1 +1101,1 @@\n-     * <td>{@code PRI2.in(C1)} hop back to module<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.in(C1)} hop back to module<\/th>\n@@ -1130,1 +1110,1 @@\n-     * <td>{@code PRI2.in(E)} hop to third module<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.in(E)} hop to third module<\/th>\n@@ -1139,1 +1119,1 @@\n-     * <td>{@code PRI2.dropLookupMode(PROTECTED)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.dropLookupMode(PROTECTED)}<\/th>\n@@ -1148,1 +1128,1 @@\n-     * <td>{@code PRI2.dropLookupMode(PRIVATE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.dropLookupMode(PRIVATE)}<\/th>\n@@ -1157,1 +1137,1 @@\n-     * <td>{@code PRI2.dropLookupMode(PACKAGE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.dropLookupMode(PACKAGE)}<\/th>\n@@ -1166,1 +1146,1 @@\n-     * <td>{@code PRI2.dropLookupMode(MODULE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.dropLookupMode(MODULE)}<\/th>\n@@ -1175,1 +1155,1 @@\n-     * <td>{@code PRI2.dropLookupMode(PUBLIC)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PRI2.dropLookupMode(PUBLIC)}<\/th>\n@@ -1184,1 +1164,1 @@\n-     * <td>{@code CL.dropLookupMode(PROTECTED)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code CL.dropLookupMode(PROTECTED)}<\/th>\n@@ -1193,1 +1173,1 @@\n-     * <td>{@code CL.dropLookupMode(PRIVATE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code CL.dropLookupMode(PRIVATE)}<\/th>\n@@ -1202,1 +1182,1 @@\n-     * <td>{@code CL.dropLookupMode(PACKAGE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code CL.dropLookupMode(PACKAGE)}<\/th>\n@@ -1211,1 +1191,1 @@\n-     * <td>{@code CL.dropLookupMode(MODULE)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code CL.dropLookupMode(MODULE)}<\/th>\n@@ -1220,1 +1200,1 @@\n-     * <td>{@code CL.dropLookupMode(PUBLIC)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code CL.dropLookupMode(PUBLIC)}<\/th>\n@@ -1229,1 +1209,1 @@\n-     * <td>{@code PUB = publicLookup()}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PUB = publicLookup()}<\/th>\n@@ -1238,1 +1218,1 @@\n-     * <td>{@code PUB.in(D)} different module<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PUB.in(D)} different module<\/th>\n@@ -1247,1 +1227,1 @@\n-     * <td>{@code PUB.in(D).in(E)} third module<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PUB.in(D).in(E)} third module<\/th>\n@@ -1256,1 +1236,1 @@\n-     * <td>{@code PUB.dropLookupMode(UNCONDITIONAL)}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code PUB.dropLookupMode(UNCONDITIONAL)}<\/th>\n@@ -1265,1 +1245,1 @@\n-     * <td>{@code privateLookupIn(C1,PUB)} fails<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code privateLookupIn(C1,PUB)} fails<\/th>\n@@ -1274,1 +1254,1 @@\n-     * <td>{@code ANY.in(X)}, for inaccessible {@code X}<\/td>\n+     * <th scope=\"row\" style=\"text-align:left\">{@code ANY.in(X)}, for inaccessible {@code X}<\/th>\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandles.java","additions":48,"deletions":68,"binary":false,"changes":116,"status":"modified"},{"patch":"@@ -3771,1 +3771,4 @@\n-    public native void loadFence();\n+    public final void loadFence() {\n+        \/\/ If loadFence intrinsic is not available, fall back to full fence.\n+        fullFence();\n+    }\n@@ -3782,1 +3785,0 @@\n-     *\n@@ -3786,1 +3788,4 @@\n-    public native void storeFence();\n+    public final void storeFence() {\n+        \/\/ If storeFence intrinsic is not available, fall back to full fence.\n+        fullFence();\n+    }\n@@ -3817,3 +3822,0 @@\n-     * @implNote\n-     * This method is operationally equivalent to {@link #storeFence()}.\n-     *\n@@ -3822,0 +3824,1 @@\n+    @IntrinsicCandidate\n@@ -3823,0 +3826,1 @@\n+        \/\/ If storeStoreFence intrinsic is not available, fall back to storeFence.\n@@ -3826,1 +3830,0 @@\n-\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/misc\/Unsafe.java","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -153,0 +153,1 @@\n+        jdk.charsets,\n@@ -370,0 +371,1 @@\n+    uses java.net.spi.InetAddressResolverProvider;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -816,1 +816,1 @@\n-    public static abstract class TypeSymbol extends Symbol {\n+    public abstract static class TypeSymbol extends Symbol {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Symbol.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -231,0 +231,8 @@\n+    \/\/ For serialization lint checking\n+    public final Type objectStreamFieldType;\n+    public final Type objectInputStreamType;\n+    public final Type objectOutputStreamType;\n+    public final Type ioExceptionType;\n+    public final Type objectStreamExceptionType;\n+    public final Type externalizableType;\n+\n@@ -608,0 +616,7 @@\n+        \/\/ For serialization lint checking\n+        objectStreamFieldType = enterClass(\"java.io.ObjectStreamField\");\n+        objectInputStreamType = enterClass(\"java.io.ObjectInputStream\");\n+        objectOutputStreamType = enterClass(\"java.io.ObjectOutputStream\");\n+        ioExceptionType = enterClass(\"java.io.IOException\");\n+        objectStreamExceptionType = enterClass(\"java.io.ObjectStreamException\");\n+        externalizableType = enterClass(\"java.io.Externalizable\");\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Symtab.java","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -305,1 +305,1 @@\n-    public static abstract class StructuralTypeMapping<S> extends Types.TypeMapping<S> {\n+    public abstract static class StructuralTypeMapping<S> extends Types.TypeMapping<S> {\n@@ -2094,1 +2094,1 @@\n-    public static abstract class DelegatedType extends Type {\n+    public abstract static class DelegatedType extends Type {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Type.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1724,1 +1724,1 @@\n-                    false :\n+                    true :\n@@ -5117,1 +5117,1 @@\n-    public static abstract class DefaultTypeVisitor<R,S> implements Type.Visitor<R,S> {\n+    public abstract static class DefaultTypeVisitor<R,S> implements Type.Visitor<R,S> {\n@@ -5144,1 +5144,1 @@\n-    public static abstract class DefaultSymbolVisitor<R,S> implements Symbol.Visitor<R,S> {\n+    public abstract static class DefaultSymbolVisitor<R,S> implements Symbol.Visitor<R,S> {\n@@ -5167,1 +5167,1 @@\n-    public static abstract class SimpleVisitor<R,S> extends DefaultTypeVisitor<R,S> {\n+    public abstract static class SimpleVisitor<R,S> extends DefaultTypeVisitor<R,S> {\n@@ -5187,1 +5187,1 @@\n-    public static abstract class TypeRelation extends SimpleVisitor<Boolean,Type> {}\n+    public abstract static class TypeRelation extends SimpleVisitor<Boolean,Type> {}\n@@ -5197,1 +5197,1 @@\n-    public static abstract class UnaryVisitor<R> extends SimpleVisitor<R,Void> {\n+    public abstract static class UnaryVisitor<R> extends SimpleVisitor<R,Void> {\n@@ -5262,1 +5262,1 @@\n-    public static abstract class SignatureGenerator {\n+    public abstract static class SignatureGenerator {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Types.java","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1873,0 +1873,1 @@\n+                preFlow(c);\n@@ -3084,1 +3085,1 @@\n-                    isSerializable(clazztype)) {\n+                    rs.isSerializable(clazztype)) {\n@@ -3212,1 +3213,1 @@\n-            if (needsRecovery && isSerializable(pt())) {\n+            if (needsRecovery && rs.isSerializable(pt())) {\n@@ -3713,1 +3714,1 @@\n-                    isSerializable(pt());\n+                    rs.isSerializable(pt());\n@@ -5300,0 +5301,8 @@\n+    @Override\n+    public void visitModifiers(JCModifiers tree) {\n+        \/\/error recovery only:\n+        Assert.check(resultInfo.pkind == KindSelector.ERR);\n+\n+        attribAnnotationTypes(tree.annotations, env);\n+    }\n+\n@@ -5573,1 +5582,1 @@\n-                if (isSerializable(c.type)) {\n+                if (rs.isSerializable(c.type)) {\n@@ -5716,1 +5725,2 @@\n-        \/\/ Check for proper use of serialVersionUID\n+        \/\/ Check for proper use of serialVersionUID and other\n+        \/\/ serialization-related fields and methods\n@@ -5718,2 +5728,1 @@\n-                && isSerializable(c.type)\n-                && (c.flags() & (Flags.ENUM | Flags.INTERFACE)) == 0\n+                && rs.isSerializable(c.type)\n@@ -5721,1 +5730,1 @@\n-            checkSerialVersionUID(tree, c, env);\n+            chk.checkSerialStructure(tree, c);\n@@ -5742,53 +5751,0 @@\n-        \/** check if a type is a subtype of Serializable, if that is available. *\/\n-        boolean isSerializable(Type t) {\n-            try {\n-                syms.serializableType.complete();\n-            }\n-            catch (CompletionFailure e) {\n-                return false;\n-            }\n-            return types.isSubtype(t, syms.serializableType);\n-        }\n-\n-        \/** Check that an appropriate serialVersionUID member is defined. *\/\n-        private void checkSerialVersionUID(JCClassDecl tree, ClassSymbol c, Env<AttrContext> env) {\n-\n-            \/\/ check for presence of serialVersionUID\n-            VarSymbol svuid = null;\n-            for (Symbol sym : c.members().getSymbolsByName(names.serialVersionUID)) {\n-                if (sym.kind == VAR) {\n-                    svuid = (VarSymbol)sym;\n-                    break;\n-                }\n-            }\n-\n-            if (svuid == null) {\n-                if (!c.isRecord())\n-                    log.warning(LintCategory.SERIAL, tree.pos(), Warnings.MissingSVUID(c));\n-                return;\n-            }\n-\n-            \/\/ Check if @SuppressWarnings(\"serial\") is an annotation of serialVersionUID.\n-            \/\/ See JDK-8231622 for more information.\n-            Lint lint = env.info.lint.augment(svuid);\n-            if (lint.isSuppressed(LintCategory.SERIAL)) {\n-                return;\n-            }\n-\n-            \/\/ check that it is static final\n-            if ((svuid.flags() & (STATIC | FINAL)) !=\n-                (STATIC | FINAL))\n-                log.warning(LintCategory.SERIAL,\n-                        TreeInfo.diagnosticPositionFor(svuid, tree), Warnings.ImproperSVUID(c));\n-\n-            \/\/ check that it is long\n-            else if (!svuid.type.hasTag(LONG))\n-                log.warning(LintCategory.SERIAL,\n-                        TreeInfo.diagnosticPositionFor(svuid, tree), Warnings.LongSVUID(c));\n-\n-            \/\/ check constant\n-            else if (svuid.getConstValue() == null)\n-                log.warning(LintCategory.SERIAL,\n-                        TreeInfo.diagnosticPositionFor(svuid, tree), Warnings.ConstantSVUID(c));\n-        }\n-\n@@ -6134,0 +6090,2 @@\n+            initTypeIfNeeded(that);\n+            initTypeIfNeeded(that.var);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":19,"deletions":61,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+import java.util.function.BiConsumer;\n@@ -74,0 +75,7 @@\n+import javax.lang.model.element.Element;\n+import javax.lang.model.element.ExecutableElement;\n+import javax.lang.model.element.TypeElement;\n+import javax.lang.model.type.DeclaredType;\n+import javax.lang.model.type.TypeMirror;\n+import javax.lang.model.util.ElementFilter;\n+import javax.lang.model.util.ElementKindVisitor14;\n@@ -4594,0 +4602,689 @@\n+\n+    \/** check if a type is a subtype of Externalizable, if that is available. *\/\n+    boolean isExternalizable(Type t) {\n+        try {\n+            syms.externalizableType.complete();\n+        }\n+        catch (CompletionFailure e) {\n+            return false;\n+        }\n+        return types.isSubtype(t, syms.externalizableType);\n+    }\n+\n+    \/**\n+     * Check structure of serialization declarations.\n+     *\/\n+    public void checkSerialStructure(JCClassDecl tree, ClassSymbol c) {\n+        (new SerialTypeVisitor()).visit(c, tree);\n+    }\n+\n+    \/**\n+     * This visitor will warn if a serialization-related field or\n+     * method is declared in a suspicious or incorrect way. In\n+     * particular, it will warn for cases where the runtime\n+     * serialization mechanism will silently ignore a mis-declared\n+     * entity.\n+     *\n+     * Distinguished serialization-related fields and methods:\n+     *\n+     * Methods:\n+     *\n+     * private void writeObject(ObjectOutputStream stream) throws IOException\n+     * ANY-ACCESS-MODIFIER Object writeReplace() throws ObjectStreamException\n+     *\n+     * private void readObject(ObjectInputStream stream) throws IOException, ClassNotFoundException\n+     * private void readObjectNoData() throws ObjectStreamException\n+     * ANY-ACCESS-MODIFIER Object readResolve() throws ObjectStreamException\n+     *\n+     * Fields:\n+     *\n+     * private static final long serialVersionUID\n+     * private static final ObjectStreamField[] serialPersistentFields\n+     *\n+     * Externalizable: methods defined on the interface\n+     * public void writeExternal(ObjectOutput) throws IOException\n+     * public void readExternal(ObjectInput) throws IOException\n+     *\/\n+    private class SerialTypeVisitor extends ElementKindVisitor14<Void, JCClassDecl> {\n+        SerialTypeVisitor() {\n+            this.lint = Check.this.lint;\n+        }\n+\n+        private static final Set<String> serialMethodNames =\n+            Set.of(\"writeObject\", \"writeReplace\",\n+                   \"readObject\",  \"readObjectNoData\",\n+                   \"readResolve\");\n+\n+        private static final Set<String> serialFieldNames =\n+            Set.of(\"serialVersionUID\", \"serialPersistentFields\");\n+\n+        \/\/ Type of serialPersistentFields\n+        private final Type OSF_TYPE = new Type.ArrayType(syms.objectStreamFieldType, syms.arrayClass);\n+\n+        Lint lint;\n+\n+        @Override\n+        public Void defaultAction(Element e, JCClassDecl p) {\n+            throw new IllegalArgumentException(Objects.requireNonNullElse(e.toString(), \"\"));\n+        }\n+\n+        @Override\n+        public Void visitType(TypeElement e, JCClassDecl p) {\n+            runUnderLint(e, p, (symbol, param) -> super.visitType(symbol, param));\n+            return null;\n+        }\n+\n+        @Override\n+        public Void visitTypeAsClass(TypeElement e,\n+                                     JCClassDecl p) {\n+            \/\/ Anonymous classes filtered out by caller.\n+\n+            ClassSymbol c = (ClassSymbol)e;\n+\n+            checkCtorAccess(p, c);\n+\n+            \/\/ Check for missing serialVersionUID; check *not* done\n+            \/\/ for enums or records.\n+            VarSymbol svuidSym = null;\n+            for (Symbol sym : c.members().getSymbolsByName(names.serialVersionUID)) {\n+                if (sym.kind == VAR) {\n+                    svuidSym = (VarSymbol)sym;\n+                    break;\n+                }\n+            }\n+\n+            if (svuidSym == null) {\n+                log.warning(LintCategory.SERIAL, p.pos(), Warnings.MissingSVUID(c));\n+            }\n+\n+            \/\/ Check for serialPersistentFields to gate checks for\n+            \/\/ non-serializable non-transient instance fields\n+            boolean serialPersistentFieldsPresent =\n+                    c.members()\n+                     .getSymbolsByName(names.serialPersistentFields, sym -> sym.kind == VAR)\n+                     .iterator()\n+                     .hasNext();\n+\n+            \/\/ Check declarations of serialization-related methods and\n+            \/\/ fields\n+            for(Symbol el : c.getEnclosedElements()) {\n+                runUnderLint(el, p, (enclosed, tree) -> {\n+                    String name = null;\n+                    switch(enclosed.getKind()) {\n+                    case FIELD -> {\n+                        if (!serialPersistentFieldsPresent) {\n+                            var flags = enclosed.flags();\n+                            if ( ((flags & TRANSIENT) == 0) &&\n+                                 ((flags & STATIC) == 0)) {\n+                                Type varType = enclosed.asType();\n+                                if (!canBeSerialized(varType)) {\n+                                    \/\/ Note per JLS arrays are\n+                                    \/\/ serializable even if the\n+                                    \/\/ component type is not.\n+                                    log.warning(LintCategory.SERIAL,\n+                                                TreeInfo.diagnosticPositionFor(enclosed, tree),\n+                                                Warnings.NonSerializableInstanceField);\n+                                } else if (varType.hasTag(ARRAY)) {\n+                                    ArrayType arrayType = (ArrayType)varType;\n+                                    Type elementType = arrayType.elemtype;\n+                                    while (elementType.hasTag(ARRAY)) {\n+                                        arrayType = (ArrayType)elementType;\n+                                        elementType = arrayType.elemtype;\n+                                    }\n+                                    if (!canBeSerialized(elementType)) {\n+                                        log.warning(LintCategory.SERIAL,\n+                                                    TreeInfo.diagnosticPositionFor(enclosed, tree),\n+                                                    Warnings.NonSerializableInstanceFieldArray(elementType));\n+                                    }\n+                                }\n+                            }\n+                        }\n+\n+                        name = enclosed.getSimpleName().toString();\n+                        if (serialFieldNames.contains(name)) {\n+                            VarSymbol field = (VarSymbol)enclosed;\n+                            switch (name) {\n+                            case \"serialVersionUID\"       ->  checkSerialVersionUID(tree, e, field);\n+                            case \"serialPersistentFields\" ->  checkSerialPersistentFields(tree, e, field);\n+                            default -> throw new AssertionError();\n+                            }\n+                        }\n+                    }\n+\n+                    \/\/ Correctly checking the serialization-related\n+                    \/\/ methods is subtle. For the methods declared to be\n+                    \/\/ private or directly declared in the class, the\n+                    \/\/ enclosed elements of the class can be checked in\n+                    \/\/ turn. However, writeReplace and readResolve can be\n+                    \/\/ declared in a superclass and inherited. Note that\n+                    \/\/ the runtime lookup walks the superclass chain\n+                    \/\/ looking for writeReplace\/readResolve via\n+                    \/\/ Class.getDeclaredMethod. This differs from calling\n+                    \/\/ Elements.getAllMembers(TypeElement) as the latter\n+                    \/\/ will also pull in default methods from\n+                    \/\/ superinterfaces. In other words, the runtime checks\n+                    \/\/ (which long predate default methods on interfaces)\n+                    \/\/ do not admit the possibility of inheriting methods\n+                    \/\/ this way, a difference from general inheritance.\n+\n+                    \/\/ The current implementation just checks the enclosed\n+                    \/\/ elements and does not directly check the inherited\n+                    \/\/ methods. If all the types are being checked this is\n+                    \/\/ less of a concern; however, there are cases that\n+                    \/\/ could be missed. In particular, readResolve and\n+                    \/\/ writeReplace could, in principle, by inherited from\n+                    \/\/ a non-serializable superclass and thus not checked\n+                    \/\/ even if compiled with a serializable child class.\n+                    case METHOD -> {\n+                        var method = (MethodSymbol)enclosed;\n+                        name = method.getSimpleName().toString();\n+                        if (serialMethodNames.contains(name)) {\n+                            switch (name) {\n+                            case \"writeObject\"      -> checkWriteObject(tree, e, method);\n+                            case \"writeReplace\"     -> checkWriteReplace(tree,e, method);\n+                            case \"readObject\"       -> checkReadObject(tree,e, method);\n+                            case \"readObjectNoData\" -> checkReadObjectNoData(tree, e, method);\n+                            case \"readResolve\"      -> checkReadResolve(tree, e, method);\n+                            default ->  throw new AssertionError();\n+                            }\n+                        }\n+                    }\n+                    }\n+                });\n+            }\n+\n+            return null;\n+        }\n+\n+        boolean canBeSerialized(Type type) {\n+            return type.isPrimitive() || rs.isSerializable(type);\n+        }\n+\n+        \/**\n+         * Check that Externalizable class needs a public no-arg\n+         * constructor.\n+         *\n+         * Check that a Serializable class has access to the no-arg\n+         * constructor of its first nonserializable superclass.\n+         *\/\n+        private void checkCtorAccess(JCClassDecl tree, ClassSymbol c) {\n+            if (isExternalizable(c.type)) {\n+                for(var sym : c.getEnclosedElements()) {\n+                    if (sym.isConstructor() &&\n+                        ((sym.flags() & PUBLIC) == PUBLIC)) {\n+                        if (((MethodSymbol)sym).getParameters().isEmpty()) {\n+                            return;\n+                        }\n+                    }\n+                }\n+                log.warning(LintCategory.SERIAL, tree.pos(),\n+                            Warnings.ExternalizableMissingPublicNoArgCtor);\n+            } else {\n+                \/\/ Approximate access to the no-arg constructor up in\n+                \/\/ the superclass chain by checking that the\n+                \/\/ constructor is not private. This may not handle\n+                \/\/ some cross-package situations correctly.\n+                Type superClass = c.getSuperclass();\n+                \/\/ java.lang.Object is *not* Serializable so this loop\n+                \/\/ should terminate.\n+                while (rs.isSerializable(superClass) ) {\n+                    try {\n+                        superClass = (Type)((TypeElement)(((DeclaredType)superClass)).asElement()).getSuperclass();\n+                    } catch(ClassCastException cce) {\n+                        return ; \/\/ Don't try to recover\n+                    }\n+                }\n+                \/\/ Non-Serializable super class\n+                try {\n+                    ClassSymbol supertype = ((ClassSymbol)(((DeclaredType)superClass).asElement()));\n+                    for(var sym : supertype.getEnclosedElements()) {\n+                        if (sym.isConstructor()) {\n+                            MethodSymbol ctor = (MethodSymbol)sym;\n+                            if (ctor.getParameters().isEmpty()) {\n+                                if (((ctor.flags() & PRIVATE) == PRIVATE) ||\n+                                    \/\/ Handle nested classes and implicit this$0\n+                                    (supertype.getNestingKind() == NestingKind.MEMBER &&\n+                                     ((supertype.flags() & STATIC) == 0)))\n+                                    log.warning(LintCategory.SERIAL, tree.pos(),\n+                                                Warnings.SerializableMissingAccessNoArgCtor(supertype.getQualifiedName()));\n+                            }\n+                        }\n+                    }\n+                } catch (ClassCastException cce) {\n+                    return ; \/\/ Don't try to recover\n+                }\n+                return;\n+            }\n+        }\n+\n+        private void checkSerialVersionUID(JCClassDecl tree, Element e, VarSymbol svuid) {\n+            \/\/ To be effective, serialVersionUID must be marked static\n+            \/\/ and final, but private is recommended. But alas, in\n+            \/\/ practice there are many non-private serialVersionUID\n+            \/\/ fields.\n+             if ((svuid.flags() & (STATIC | FINAL)) !=\n+                 (STATIC | FINAL)) {\n+                 log.warning(LintCategory.SERIAL,\n+                             TreeInfo.diagnosticPositionFor(svuid, tree),\n+                             Warnings.ImproperSVUID((Symbol)e));\n+             }\n+\n+             \/\/ check svuid has type long\n+             if (!svuid.type.hasTag(LONG)) {\n+                 log.warning(LintCategory.SERIAL,\n+                             TreeInfo.diagnosticPositionFor(svuid, tree),\n+                             Warnings.LongSVUID((Symbol)e));\n+             }\n+\n+             if (svuid.getConstValue() == null)\n+                 log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(svuid, tree),\n+                             Warnings.ConstantSVUID((Symbol)e));\n+        }\n+\n+        private void checkSerialPersistentFields(JCClassDecl tree, Element e, VarSymbol spf) {\n+            \/\/ To be effective, serialPersisentFields must be private, static, and final.\n+             if ((spf.flags() & (PRIVATE | STATIC | FINAL)) !=\n+                 (PRIVATE | STATIC | FINAL)) {\n+                 log.warning(LintCategory.SERIAL,\n+                             TreeInfo.diagnosticPositionFor(spf, tree), Warnings.ImproperSPF);\n+             }\n+\n+             if (!types.isSameType(spf.type, OSF_TYPE)) {\n+                 log.warning(LintCategory.SERIAL,\n+                             TreeInfo.diagnosticPositionFor(spf, tree), Warnings.OSFArraySPF);\n+             }\n+\n+            if (isExternalizable((Type)(e.asType()))) {\n+                log.warning(LintCategory.SERIAL, tree.pos(),\n+                            Warnings.IneffectualSerialFieldExternalizable);\n+            }\n+\n+            \/\/ Warn if serialPersistentFields is initialized to a\n+            \/\/ literal null.\n+            JCTree spfDecl = TreeInfo.declarationFor(spf, tree);\n+            if (spfDecl != null && spfDecl.getTag() == VARDEF) {\n+                JCVariableDecl variableDef = (JCVariableDecl) spfDecl;\n+                JCExpression initExpr = variableDef.init;\n+                 if (initExpr != null && TreeInfo.isNull(initExpr)) {\n+                     log.warning(LintCategory.SERIAL, initExpr.pos(),\n+                                 Warnings.SPFNullInit);\n+                 }\n+            }\n+        }\n+\n+        private void checkWriteObject(JCClassDecl tree, Element e, MethodSymbol method) {\n+            \/\/ The \"synchronized\" modifier is seen in the wild on\n+            \/\/ readObject and writeObject methods and is generally\n+            \/\/ innocuous.\n+\n+            \/\/ private void writeObject(ObjectOutputStream stream) throws IOException\n+            checkPrivateNonStaticMethod(tree, method);\n+            checkReturnType(tree, e, method, syms.voidType);\n+            checkOneArg(tree, e, method, syms.objectOutputStreamType);\n+            checkExceptions(tree, e, method, syms.ioExceptionType);\n+            checkExternalizable(tree, e, method);\n+        }\n+\n+        private void checkWriteReplace(JCClassDecl tree, Element e, MethodSymbol method) {\n+            \/\/ ANY-ACCESS-MODIFIER Object writeReplace() throws\n+            \/\/ ObjectStreamException\n+\n+            \/\/ Excluding abstract, could have a more complicated\n+            \/\/ rule based on abstract-ness of the class\n+            checkConcreteInstanceMethod(tree, e, method);\n+            checkReturnType(tree, e, method, syms.objectType);\n+            checkNoArgs(tree, e, method);\n+            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+        }\n+\n+        private void checkReadObject(JCClassDecl tree, Element e, MethodSymbol method) {\n+            \/\/ The \"synchronized\" modifier is seen in the wild on\n+            \/\/ readObject and writeObject methods and is generally\n+            \/\/ innocuous.\n+\n+            \/\/ private void readObject(ObjectInputStream stream)\n+            \/\/   throws IOException, ClassNotFoundException\n+            checkPrivateNonStaticMethod(tree, method);\n+            checkReturnType(tree, e, method, syms.voidType);\n+            checkOneArg(tree, e, method, syms.objectInputStreamType);\n+            checkExceptions(tree, e, method, syms.ioExceptionType, syms.classNotFoundExceptionType);\n+            checkExternalizable(tree, e, method);\n+        }\n+\n+        private void checkReadObjectNoData(JCClassDecl tree, Element e, MethodSymbol method) {\n+            \/\/ private void readObjectNoData() throws ObjectStreamException\n+            checkPrivateNonStaticMethod(tree, method);\n+            checkReturnType(tree, e, method, syms.voidType);\n+            checkNoArgs(tree, e, method);\n+            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+            checkExternalizable(tree, e, method);\n+        }\n+\n+        private void checkReadResolve(JCClassDecl tree, Element e, MethodSymbol method) {\n+            \/\/ ANY-ACCESS-MODIFIER Object readResolve()\n+            \/\/ throws ObjectStreamException\n+\n+            \/\/ Excluding abstract, could have a more complicated\n+            \/\/ rule based on abstract-ness of the class\n+            checkConcreteInstanceMethod(tree, e, method);\n+            checkReturnType(tree,e, method, syms.objectType);\n+            checkNoArgs(tree, e, method);\n+            checkExceptions(tree, e, method, syms.objectStreamExceptionType);\n+        }\n+\n+        void checkPrivateNonStaticMethod(JCClassDecl tree, MethodSymbol method) {\n+            var flags = method.flags();\n+            if ((flags & PRIVATE) == 0) {\n+                log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n+                            Warnings.SerialMethodNotPrivate(method.getSimpleName()));\n+            }\n+\n+            if ((flags & STATIC) != 0) {\n+                log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n+                            Warnings.SerialMethodStatic(method.getSimpleName()));\n+            }\n+        }\n+\n+        \/**\n+         * Per section 1.12 \"Serialization of Enum Constants\" of\n+         * the serialization specification, due to the special\n+         * serialization handling of enums, any writeObject,\n+         * readObject, writeReplace, and readResolve methods are\n+         * ignored as are serialPersistentFields and\n+         * serialVersionUID fields.\n+         *\/\n+        @Override\n+        public Void visitTypeAsEnum(TypeElement e,\n+                                    JCClassDecl p) {\n+            for(Element el : e.getEnclosedElements()) {\n+                runUnderLint(el, p, (enclosed, tree) -> {\n+                    String name = enclosed.getSimpleName().toString();\n+                    switch(enclosed.getKind()) {\n+                    case FIELD -> {\n+                        if (serialFieldNames.contains(name)) {\n+                            log.warning(LintCategory.SERIAL, tree.pos(),\n+                                        Warnings.IneffectualSerialFieldEnum(name));\n+                        }\n+                    }\n+\n+                    case METHOD -> {\n+                        if (serialMethodNames.contains(name)) {\n+                            log.warning(LintCategory.SERIAL, tree.pos(),\n+                                        Warnings.IneffectualSerialMethodEnum(name));\n+                        }\n+                    }\n+                    }\n+                });\n+            }\n+            return null;\n+        }\n+\n+        \/**\n+         * Most serialization-related fields and methods on interfaces\n+         * are ineffectual or problematic.\n+         *\/\n+        @Override\n+        public Void visitTypeAsInterface(TypeElement e,\n+                                         JCClassDecl p) {\n+            for(Element el : e.getEnclosedElements()) {\n+                runUnderLint(el, p, (enclosed, tree) -> {\n+                    String name = null;\n+                    switch(enclosed.getKind()) {\n+                    case FIELD -> {\n+                        var field = (VarSymbol)enclosed;\n+                        name = field.getSimpleName().toString();\n+                        switch(name) {\n+                        case \"serialPersistentFields\" -> {\n+                            log.warning(LintCategory.SERIAL,\n+                                        TreeInfo.diagnosticPositionFor(field, tree),\n+                                        Warnings.IneffectualSerialFieldInterface);\n+                        }\n+\n+                        case \"serialVersionUID\" -> {\n+                            checkSerialVersionUID(tree, e, field);\n+                        }\n+                        }\n+                    }\n+\n+                    case METHOD -> {\n+                        var method = (MethodSymbol)enclosed;\n+                        name = enclosed.getSimpleName().toString();\n+                        if (serialMethodNames.contains(name)) {\n+                            switch (name) {\n+                            case\n+                                \"readObject\",\n+                                \"readObjectNoData\",\n+                                \"writeObject\"      -> checkPrivateMethod(tree, e, method);\n+\n+                            case\n+                                \"writeReplace\",\n+                                \"readResolve\"      -> checkDefaultIneffective(tree, e, method);\n+\n+                            default ->  throw new AssertionError();\n+                            }\n+\n+                        }\n+                    }\n+                    }\n+                });\n+            }\n+\n+            return null;\n+        }\n+\n+        private void checkPrivateMethod(JCClassDecl tree,\n+                                        Element e,\n+                                        MethodSymbol method) {\n+            if ((method.flags() & PRIVATE) == 0) {\n+                log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n+                            Warnings.NonPrivateMethodWeakerAccess);\n+            }\n+        }\n+\n+        private void checkDefaultIneffective(JCClassDecl tree,\n+                                             Element e,\n+                                             MethodSymbol method) {\n+            if ((method.flags() & DEFAULT) == DEFAULT) {\n+                log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n+                            Warnings.DefaultIneffective);\n+\n+            }\n+        }\n+\n+        @Override\n+        public Void visitTypeAsAnnotationType(TypeElement e,\n+                                              JCClassDecl p) {\n+            \/\/ Per the JLS, annotation types are not serializeable\n+            return null;\n+        }\n+\n+        \/**\n+         * From the Java Object Serialization Specification, 1.13\n+         * Serialization of Records:\n+         *\n+         * \"The process by which record objects are serialized or\n+         * externalized cannot be customized; any class-specific\n+         * writeObject, readObject, readObjectNoData, writeExternal,\n+         * and readExternal methods defined by record classes are\n+         * ignored during serialization and deserialization. However,\n+         * a substitute object to be serialized or a designate\n+         * replacement may be specified, by the writeReplace and\n+         * readResolve methods, respectively. Any\n+         * serialPersistentFields field declaration is\n+         * ignored. Documenting serializable fields and data for\n+         * record classes is unnecessary, since there is no variation\n+         * in the serial form, other than whether a substitute or\n+         * replacement object is used. The serialVersionUID of a\n+         * record class is 0L unless explicitly declared. The\n+         * requirement for matching serialVersionUID values is waived\n+         * for record classes.\"\n+         *\/\n+        @Override\n+        public Void visitTypeAsRecord(TypeElement e,\n+                                      JCClassDecl p) {\n+            for(Element el : e.getEnclosedElements()) {\n+                runUnderLint(el, p, (enclosed, tree) -> {\n+                    String name = enclosed.getSimpleName().toString();\n+                    switch(enclosed.getKind()) {\n+                    case FIELD -> {\n+                        switch(name) {\n+                        case \"serialPersistentFields\" -> {\n+                            log.warning(LintCategory.SERIAL, tree.pos(),\n+                                        Warnings.IneffectualSerialFieldRecord);\n+                        }\n+\n+                        case \"serialVersionUID\" -> {\n+                            \/\/ Could generate additional warning that\n+                            \/\/ svuid value is not checked to match for\n+                            \/\/ records.\n+                            checkSerialVersionUID(tree, e, (VarSymbol)enclosed);\n+                        }\n+\n+                        }\n+                    }\n+\n+                    case METHOD -> {\n+                        var method = (MethodSymbol)enclosed;\n+                        switch(name) {\n+                        case \"writeReplace\" -> checkWriteReplace(tree, e, method);\n+                        case \"readResolve\"  -> checkReadResolve(tree, e, method);\n+                        default -> {\n+                            if (serialMethodNames.contains(name)) {\n+                                log.warning(LintCategory.SERIAL, tree.pos(),\n+                                            Warnings.IneffectualSerialMethodRecord(name));\n+                            }\n+                        }\n+                        }\n+\n+                    }\n+                    }\n+                });\n+            }\n+            return null;\n+        }\n+\n+        void checkConcreteInstanceMethod(JCClassDecl tree,\n+                                         Element enclosing,\n+                                         MethodSymbol method) {\n+            if ((method.flags() & (STATIC | ABSTRACT)) != 0) {\n+                    log.warning(LintCategory.SERIAL,\n+                                TreeInfo.diagnosticPositionFor(method, tree),\n+                                Warnings.SerialConcreteInstanceMethod(method.getSimpleName()));\n+            }\n+        }\n+\n+        private void checkReturnType(JCClassDecl tree,\n+                                     Element enclosing,\n+                                     MethodSymbol method,\n+                                     Type expectedReturnType) {\n+            \/\/ Note: there may be complications checking writeReplace\n+            \/\/ and readResolve since they return Object and could, in\n+            \/\/ principle, have covariant overrides and any synthetic\n+            \/\/ bridge method would not be represented here for\n+            \/\/ checking.\n+            Type rtype = method.getReturnType();\n+            if (!types.isSameType(expectedReturnType, rtype)) {\n+                log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n+                            Warnings.SerialMethodUnexpectedReturnType(method.getSimpleName(),\n+                                                                      rtype, expectedReturnType));\n+            }\n+        }\n+\n+        private void checkOneArg(JCClassDecl tree,\n+                                 Element enclosing,\n+                                 MethodSymbol method,\n+                                 Type expectedType) {\n+            String name = method.getSimpleName().toString();\n+\n+            var parameters= method.getParameters();\n+\n+            if (parameters.size() != 1) {\n+                log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n+                            Warnings.SerialMethodOneArg(method.getSimpleName(), parameters.size()));\n+                return;\n+            }\n+\n+            Type parameterType = parameters.get(0).asType();\n+            if (!types.isSameType(parameterType, expectedType)) {\n+                log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(method, tree),\n+                            Warnings.SerialMethodParameterType(method.getSimpleName(),\n+                                                               expectedType,\n+                                                               parameterType));\n+            }\n+        }\n+\n+        private void checkNoArgs(JCClassDecl tree, Element enclosing, MethodSymbol method) {\n+            var parameters = method.getParameters();\n+            if (!parameters.isEmpty()) {\n+                log.warning(LintCategory.SERIAL,\n+                            TreeInfo.diagnosticPositionFor(parameters.get(0), tree),\n+                            Warnings.SerialMethodNoArgs(method.getSimpleName()));\n+            }\n+        }\n+\n+        private void checkExternalizable(JCClassDecl tree, Element enclosing, MethodSymbol method) {\n+            \/\/ If the enclosing class is externalizable, warn for the method\n+            if (isExternalizable((Type)enclosing.asType())) {\n+                log.warning(LintCategory.SERIAL, tree.pos(),\n+                            Warnings.IneffectualSerialMethodExternalizable(method.getSimpleName()));\n+            }\n+            return;\n+        }\n+\n+        private void checkExceptions(JCClassDecl tree,\n+                                     Element enclosing,\n+                                     MethodSymbol method,\n+                                     Type... declaredExceptions) {\n+            for (Type thrownType: method.getThrownTypes()) {\n+                \/\/ For each exception in the throws clause of the\n+                \/\/ method, if not an Error and not a RuntimeException,\n+                \/\/ check if the exception is a subtype of a declared\n+                \/\/ exception from the throws clause of the\n+                \/\/ serialization method in question.\n+                if (types.isSubtype(thrownType, syms.runtimeExceptionType) ||\n+                    types.isSubtype(thrownType, syms.errorType) ) {\n+                    continue;\n+                } else {\n+                    boolean declared = false;\n+                    for (Type declaredException : declaredExceptions) {\n+                        if (types.isSubtype(thrownType, declaredException)) {\n+                            declared = true;\n+                            continue;\n+                        }\n+                    }\n+                    if (!declared) {\n+                        log.warning(LintCategory.SERIAL,\n+                                    TreeInfo.diagnosticPositionFor(method, tree),\n+                                    Warnings.SerialMethodUnexpectedException(method.getSimpleName(),\n+                                                                             thrownType));\n+                    }\n+                }\n+            }\n+            return;\n+        }\n+\n+        private <E extends Element> Void runUnderLint(E symbol, JCClassDecl p, BiConsumer<E, JCClassDecl> task) {\n+            Lint prevLint = lint;\n+            try {\n+                lint = lint.augment((Symbol) symbol);\n+\n+                if (lint.isEnabled(LintCategory.SERIAL)) {\n+                    task.accept(symbol, p);\n+                }\n+\n+                return null;\n+            } finally {\n+                lint = prevLint;\n+            }\n+        }\n+\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":697,"deletions":0,"binary":false,"changes":697,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -380,1 +380,1 @@\n-                c.sourcefile = tree.sourcefile;\n+                c.classfile = c.sourcefile = tree.sourcefile;\n@@ -499,1 +499,1 @@\n-        c.sourcefile = env.toplevel.sourcefile;\n+        c.classfile = c.sourcefile = env.toplevel.sourcefile;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Enter.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -346,1 +346,1 @@\n-    static abstract class BaseAnalyzer extends TreeScanner {\n+    abstract static class BaseAnalyzer extends TreeScanner {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Flow.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3955,0 +3955,11 @@\n+    \/** check if a type is a subtype of Serializable, if that is available.*\/\n+    boolean isSerializable(Type t) {\n+        try {\n+            syms.serializableType.complete();\n+        }\n+        catch (CompletionFailure e) {\n+            return false;\n+        }\n+        return types.isSubtype(t, syms.serializableType);\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Resolve.java","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -3127,0 +3127,1 @@\n+            JCCaseLabel defaultPattern = toP(F.at(pos).DefaultCaseLabel());\n@@ -3129,1 +3130,0 @@\n-            int patternPos = token.pos;\n@@ -3145,1 +3145,0 @@\n-            JCCaseLabel defaultPattern = toP(F.at(patternPos).DefaultCaseLabel());\n@@ -5144,1 +5143,1 @@\n-    protected static abstract class AbstractEndPosTable implements EndPosTable {\n+    protected abstract static class AbstractEndPosTable implements EndPosTable {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1849,0 +1849,8 @@\n+compiler.warn.improper.SPF=\\\n+    serialPersistentFields must be declared private static final to be effective\n+\n+compiler.warn.SPF.null.init=\\\n+    serialPersistentFields ineffective if initialized to null.\\n\\\n+    Initialize to an empty array to indicate no fields\n+\n+\n@@ -1869,0 +1877,3 @@\n+compiler.warn.OSF.array.SPF=\\\n+    serialPersistentFields must be of type java.io.ObjectStreamField[] to be effective\n+\n@@ -1873,0 +1884,79 @@\n+# 0: name\n+compiler.warn.serializable.missing.access.no.arg.ctor=\\\n+    cannot access a no-arg constructor in first non-serializable superclass {0}\n+\n+# 0: name\n+compiler.warn.serial.method.not.private=\\\n+    serialization-related method {0} not declared private\n+\n+# 0: name\n+compiler.warn.serial.concrete.instance.method=\\\n+    serialization-related method {0} must be a concrete instance method to be effective, neither abstract nor static\n+\n+# 0: name\n+compiler.warn.serial.method.static=\\\n+    serialization-related method {0} declared static; must instead be an instance method to be effective\n+\n+# 0: name\n+compiler.warn.serial.method.no.args=\\\n+    to be effective serialization-related method {0} must have no parameters\n+\n+# 0: name, 1: number\n+compiler.warn.serial.method.one.arg=\\\n+    to be effective serialization-related method {0} must have exactly one parameter rather than {1} parameters\n+\n+# 0: name, 1: type, 2: type\n+compiler.warn.serial.method.parameter.type=\\\n+    sole parameter of serialization-related method {0} must have type {1} to be effective rather than type {2}\n+\n+# 0: name, 1: type, 2: type\n+compiler.warn.serial.method.unexpected.return.type=\\\n+    serialization-related method {0} declared with a return type of {1} rather than expected type {2}.\\n\\\n+    As declared, the method will be ineffective for serialization\n+\n+# 0: name, 1: type\n+compiler.warn.serial.method.unexpected.exception=\\\n+    serialization-related method {0} declared to throw an unexpected type {1}\n+\n+compiler.warn.ineffectual.serial.field.interface=\\\n+    serialPersistentFields is not effective in an interface\n+\n+# 0: string\n+compiler.warn.ineffectual.serial.field.enum=\\\n+     serialization-related field {0} is not effective in an enum class\n+\n+# 0: string\n+compiler.warn.ineffectual.serial.method.enum=\\\n+    serialization-related method {0} is not effective in an enum class\n+\n+compiler.warn.ineffectual.serial.field.record=\\\n+    serialPersistentFields is not effective in a record class\n+\n+# 0: string\n+compiler.warn.ineffectual.serial.method.record=\\\n+    serialization-related method {0} is not effective in a record class\n+\n+# 0: name\n+compiler.warn.ineffectual.serial.method.externalizable=\\\n+    serialization-related method {0} is not effective in an Externalizable class\n+\n+compiler.warn.ineffectual.serial.field.externalizable=\\\n+    serialPersistentFields is not effective in an Externalizable class\n+\n+compiler.warn.externalizable.missing.public.no.arg.ctor=\\\n+    an Externalizable class needs a public no-arg constructor\n+\n+compiler.warn.non.serializable.instance.field=\\\n+    non-transient instance field of a serializable class declared with a non-serializable type\n+\n+# 0: type\n+compiler.warn.non.serializable.instance.field.array=\\\n+    non-transient instance field of a serializable class declared with an array having a non-serializable base component type {0}\n+\n+compiler.warn.non.private.method.weaker.access=\\\n+    serialization-related method declared non-private in an interface will prevent\\n\\\n+    classes implementing the interface from declaring the method as private\n+\n+compiler.warn.default.ineffective=\\\n+    serialization-related default method from an interface will not be run by serialization for an implementing class\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":90,"deletions":0,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -246,2 +246,2 @@\n-    Warn about Serializable classes that do not provide a serial version ID. \\n\\\n-\\                         Also warn about access to non-public members from a serializable element.\n+    Warn about Serializable classes that do not have a serialVersionUID field. \\n\\\n+\\                         Also warn about other suspect declarations in Serializable and Externalizable classes and interfaces.\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/javac.properties","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -700,1 +700,1 @@\n-    public static abstract class JCStatement extends JCTree implements StatementTree {\n+    public abstract static class JCStatement extends JCTree implements StatementTree {\n@@ -713,1 +713,1 @@\n-    public static abstract class JCCaseLabel extends JCTree implements CaseLabelTree {\n+    public abstract static class JCCaseLabel extends JCTree implements CaseLabelTree {\n@@ -721,1 +721,1 @@\n-    public static abstract class JCExpression extends JCCaseLabel implements ExpressionTree {\n+    public abstract static class JCExpression extends JCCaseLabel implements ExpressionTree {\n@@ -750,1 +750,1 @@\n-    public static abstract class JCPolyExpression extends JCExpression {\n+    public abstract static class JCPolyExpression extends JCExpression {\n@@ -772,1 +772,1 @@\n-    public static abstract class JCFunctionalExpression extends JCPolyExpression {\n+    public abstract static class JCFunctionalExpression extends JCPolyExpression {\n@@ -2125,1 +2125,1 @@\n-    public static abstract class JCOperatorExpression extends JCExpression {\n+    public abstract static class JCOperatorExpression extends JCExpression {\n@@ -2307,1 +2307,1 @@\n-    public static abstract class JCPattern extends JCCaseLabel\n+    public abstract static class JCPattern extends JCCaseLabel\n@@ -3058,1 +3058,1 @@\n-    public static abstract class JCDirective extends JCTree\n+    public abstract static class JCDirective extends JCTree\n@@ -3471,1 +3471,1 @@\n-    public static abstract class Visitor {\n+    public abstract static class Visitor {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/JCTree.java","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-abstract public class Metadata extends VMObject {\n+public abstract class Metadata extends VMObject {\n@@ -91,1 +91,1 @@\n-  abstract public void printValueOn(PrintStream tty);\n+  public abstract void printValueOn(PrintStream tty);\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Metadata.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -149,2 +149,1 @@\n-        if ((obj != null) && (obj instanceof ObjectReferenceImpl)) {\n-            ObjectReferenceImpl other = (ObjectReferenceImpl) obj;\n+        if (obj instanceof ObjectReferenceImpl other) {\n@@ -158,0 +157,1 @@\n+    @Override\n@@ -159,1 +159,1 @@\n-        return(int)ref();\n+        return Long.hashCode(ref());\n","filename":"src\/jdk.jdi\/share\/classes\/com\/sun\/tools\/jdi\/ObjectReferenceImpl.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -561,3 +561,5 @@\n-                \/\/ token wasn't a terminating one.  Special case: within braces,\n-                \/\/ comma can proceed semicolon, e.g. the values list in enum\n-                if (ct.kind.isStart() && !prevTK.isOkToTerminate() && prevTK != COMMA) {\n+                \/\/ token wasn't a terminating one.  Special cases:\n+                \/\/ -within braces, comma can procede semicolon, e.g. the values list in enum\n+                \/\/ -arrow can be followed by a throw, e.g. in a switch\/switch expression\n+                if (ct.kind.isStart() && !prevTK.isOkToTerminate() && prevTK != COMMA &&\n+                    !(prevTK == ARROW && ct.kind == THROW)) {\n","filename":"src\/jdk.jshell\/share\/classes\/jdk\/jshell\/CompletenessAnalyzer.java","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -101,3 +101,0 @@\n-runtime\/InvocationTests\/invokevirtualTests.java#current-int 8271125 generic-all\n-runtime\/InvocationTests\/invokevirtualTests.java#current-comp 8271125 generic-all\n-runtime\/InvocationTests\/invokevirtualTests.java#old-int 8271125 generic-all\n@@ -111,0 +108,1 @@\n+runtime\/jni\/checked\/TestPrimitiveArrayCriticalWithBadParam.java 8277350 macosx-x64\n@@ -112,1 +110,1 @@\n-applications\/jcstress\/copy.java 8229852 linux-x64\n+applications\/jcstress\/copy.java 8229852 linux-all\n@@ -128,6 +126,7 @@\n-serviceability\/sa\/ClhsdbCDSCore.java 8269982 macosx-aarch64\n-serviceability\/sa\/ClhsdbFindPC.java#xcomp-core 8269982 macosx-aarch64\n-serviceability\/sa\/ClhsdbFindPC.java#no-xcomp-core 8269982 macosx-aarch64\n-serviceability\/sa\/ClhsdbPstack.java#core 8269982 macosx-aarch64\n-\n-resourcehogs\/serviceability\/sa\/TestHeapDumpForLargeArray.java 8274620 macosx-x64\n+serviceability\/sa\/ClhsdbCDSCore.java 8269982,8267433 macosx-aarch64,macosx-x64\n+serviceability\/sa\/ClhsdbFindPC.java#xcomp-core 8269982,8267433 macosx-aarch64,macosx-x64\n+serviceability\/sa\/ClhsdbFindPC.java#no-xcomp-core 8269982,8267433 macosx-aarch64,macosx-x64\n+serviceability\/sa\/ClhsdbPmap.java#core 8267433 macosx-x64\n+serviceability\/sa\/ClhsdbPstack.java#core 8269982,8267433 macosx-aarch64,macosx-x64\n+serviceability\/sa\/TestJmapCore.java 8267433 macosx-x64\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8267433 macosx-x64\n@@ -196,1 +195,0 @@\n-vmTestbase\/nsk\/jvmti\/PopFrame\/popframe011\/TestDescription.java 8266593 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":9,"deletions":11,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -229,1 +229,0 @@\n-  -gc\/CriticalNativeArgs.java \\\n@@ -244,3 +243,1 @@\n-tier2_gc_epsilon = \\\n-  gc\/CriticalNativeArgs.java \\\n-  gc\/stress\/CriticalNativeStress.java\n+tier2_gc_epsilon =\n@@ -285,2 +282,0 @@\n-  gc\/CriticalNativeArgs.java \\\n-  gc\/stress\/CriticalNativeStress.java \\\n@@ -377,0 +372,1 @@\n+ -runtime\/cds\/appcds\/LambdaContainsOldInf.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -77,2 +77,12 @@\n-    private static final CompLevel TIERED_COMPILATION_STOP_AT_LEVEL = CompLevel.forValue(((Long)WHITE_BOX.getVMFlag(\"TieredStopAtLevel\")).intValue());\n-    public static final boolean TEST_C1 = TIERED_COMPILATION && TIERED_COMPILATION_STOP_AT_LEVEL.getValue() < CompLevel.C2.getValue();\n+    private static final CompLevel TIERED_COMPILATION_STOP_AT_LEVEL;\n+    private static final boolean CLIENT_VM = Platform.isClient();\n+\n+    static {\n+        CompLevel level = CompLevel.forValue(((Long)WHITE_BOX.getVMFlag(\"TieredStopAtLevel\")).intValue());\n+        if (CLIENT_VM && level == CompLevel.C2) {\n+            \/\/ No C2 available, use C1 level without profiling.\n+            level = CompLevel.C1_SIMPLE;\n+        }\n+        TIERED_COMPILATION_STOP_AT_LEVEL = level;\n+    }\n+    public static final boolean TEST_C1 = (TIERED_COMPILATION && TIERED_COMPILATION_STOP_AT_LEVEL.getValue() < CompLevel.C2.getValue()) || CLIENT_VM;\n@@ -568,1 +578,4 @@\n-        if (!TIERED_COMPILATION && compLevel.getValue() < CompLevel.C2.getValue()) {\n+        if (TEST_C1 && compLevel == CompLevel.C2) {\n+            return CompLevel.SKIP;\n+        }\n+        if ((!TIERED_COMPILATION && !CLIENT_VM) && compLevel.getValue() < CompLevel.C2.getValue()) {\n@@ -571,1 +584,1 @@\n-        if (TIERED_COMPILATION && compLevel.getValue() > TIERED_COMPILATION_STOP_AT_LEVEL.getValue()) {\n+        if ((TIERED_COMPILATION || CLIENT_VM) && compLevel.getValue() > TIERED_COMPILATION_STOP_AT_LEVEL.getValue()) {\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/test\/TestVM.java","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -54,1 +54,0 @@\n-import jdk.test.lib.Platform;\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/loaderConstraints\/LoaderConstraintsTest.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -392,0 +392,3 @@\n+jdk_editpad = \\\n+     jdk\/editpad\n+\n@@ -401,1 +404,2 @@\n-    :jdk_client_sanity\n+    :jdk_client_sanity \\\n+    :jdk_editpad\n","filename":"test\/jdk\/TEST.groups","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"}]}