{"files":[{"patch":"@@ -1,1 +1,1 @@\n-# Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -114,1 +114,3 @@\n-    --override-methods=summary\n+    --enable-preview -source $(JDK_SOURCE_TARGET_VERSION) \\\n+    --override-methods=summary \\\n+    --no-external-specs-page\n@@ -120,1 +122,2 @@\n-    -html5 -javafx --expand-requires transitive\n+    -html5 -javafx --expand-requires transitive \\\n+    --no-external-specs-page\n@@ -623,1 +626,1 @@\n-SPECS_TOP := $(if $(filter true, $(IS_DRAFT)), <header class=\"draft-header\">$(DRAFT_TEXT)<\/header>)\n+SPECS_TOP := $(if $(filter true, $(IS_DRAFT)), <header class=\"draft-header\" role=\"banner\">$(DRAFT_TEXT)<\/header>)\n","filename":"make\/Docs.gmk","additions":7,"deletions":4,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,1 @@\n+#include \"oops\/constMethodFlags.hpp\"\n@@ -193,1 +194,1 @@\n-      cmpw(Address(tmp, Method::intrinsic_id_offset_in_bytes()), static_cast<int>(vmIntrinsics::_compiledLambdaForm));\n+      cmpw(Address(tmp, Method::intrinsic_id_offset()), static_cast<int>(vmIntrinsics::_compiledLambdaForm));\n@@ -272,1 +273,1 @@\n-         \" last_sp != NULL\");\n+         \" last_sp != null\");\n@@ -304,1 +305,1 @@\n-         \" last_sp != NULL\");\n+         \" last_sp != nullptr\");\n@@ -403,1 +404,1 @@\n-    jcc(Assembler::zero, L); \/\/ if (thread->jvmti_thread_state() == NULL) exit;\n+    jcc(Assembler::zero, L); \/\/ if (thread->jvmti_thread_state() == nullptr) exit;\n@@ -514,2 +515,2 @@\n-  movptr(result, Address(result, ConstantPool::cache_offset_in_bytes()));\n-  movptr(result, Address(result, ConstantPoolCache::resolved_references_offset_in_bytes()));\n+  movptr(result, Address(result, ConstantPool::cache_offset()));\n+  movptr(result, Address(result, ConstantPoolCache::resolved_references_offset()));\n@@ -530,1 +531,1 @@\n-  movptr(resolved_klasses, Address(cpool, ConstantPool::resolved_klasses_offset_in_bytes()));\n+  movptr(resolved_klasses, Address(cpool, ConstantPool::resolved_klasses_offset()));\n@@ -1047,1 +1048,1 @@\n-  movptr(rax, Address(robj, BasicObjectLock::obj_offset_in_bytes()));\n+  movptr(rax, Address(robj, BasicObjectLock::obj_offset()));\n@@ -1130,1 +1131,1 @@\n-    cmpptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), NULL_WORD);\n+    cmpptr(Address(rmon, BasicObjectLock::obj_offset()), NULL_WORD);\n@@ -1203,2 +1204,2 @@\n-    if (StressInlineTypeReturnedAsFields) {\n-      \/\/ TODO 8284443 Enable this for value class returns (L-type descriptor)\n+    \/\/ TODO 8284443 Enable\n+    if (StressCallingConvention && false) {\n@@ -1207,4 +1208,3 @@\n-      movptr(rscratch1, Address(rscratch1, Method::const_offset()));\n-      load_unsigned_byte(rscratch1, Address(rscratch1, ConstMethod::result_type_offset()));\n-      cmpl(rscratch1, T_PRIMITIVE_OBJECT);\n-      jcc(Assembler::notEqual, skip_stress);\n+      movl(rscratch1, Address(rscratch1, Method::flags_offset()));\n+      testl(rcx, ConstMethodFlags::has_scalarized_return_flag());\n+      jcc(Assembler::zero, skip_stress);\n@@ -1358,1 +1358,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -1370,2 +1370,2 @@\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n+    const int obj_offset = in_bytes(BasicObjectLock::obj_offset());\n+    const int lock_offset = in_bytes(BasicObjectLock::lock_offset());\n@@ -1385,2 +1385,20 @@\n-    \/\/ Load immediate 1 into swap_reg %rax\n-    movl(swap_reg, 1);\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+#ifdef _LP64\n+      const Register thread = r15_thread;\n+#else\n+      const Register thread = lock_reg;\n+      get_thread(thread);\n+#endif\n+      \/\/ Load object header, prepare for CAS from unlocked to locked.\n+      movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      fast_lock_impl(obj_reg, swap_reg, thread, tmp_reg, slow_case);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ Load immediate 1 into swap_reg %rax\n+      movl(swap_reg, 1);\n+\n+      \/\/ Load (object->mark() | 1) into swap_reg %rax\n+      orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      if (EnableValhalla) {\n+        \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+        andptr(swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+      }\n@@ -1388,6 +1406,45 @@\n-    \/\/ Load (object->mark() | 1) into swap_reg %rax\n-    orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    if (EnableValhalla) {\n-      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n-      andptr(swap_reg, ~((int) markWord::inline_type_bit_in_place));\n-    }\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      movptr(Address(lock_reg, mark_offset), swap_reg);\n+\n+      assert(lock_offset == 0,\n+             \"displaced header must be first word in BasicObjectLock\");\n+\n+      lock();\n+      cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      jcc(Assembler::zero, count_locking);\n+\n+      const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n+\n+      \/\/ Fast check for recursive lock.\n+      \/\/\n+      \/\/ Can apply the optimization only if this is a stack lock\n+      \/\/ allocated in this thread. For efficiency, we can focus on\n+      \/\/ recently allocated stack locks (instead of reading the stack\n+      \/\/ base and checking whether 'mark' points inside the current\n+      \/\/ thread stack):\n+      \/\/  1) (mark & zero_bits) == 0, and\n+      \/\/  2) rsp <= mark < mark + os::pagesize()\n+      \/\/\n+      \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n+      \/\/ neither apply the optimization for an inflated lock allocated\n+      \/\/ just above the thread stack (this is why condition 1 matters)\n+      \/\/ nor apply the optimization if the stack lock is inside the stack\n+      \/\/ of another thread. The latter is avoided even in case of overflow\n+      \/\/ because we have guard pages at the end of all stacks. Hence, if\n+      \/\/ we go over the stack base and hit the stack of another thread,\n+      \/\/ this should not be in a writeable area that could contain a\n+      \/\/ stack lock allocated by that thread. As a consequence, a stack\n+      \/\/ lock less than page size away from rsp is guaranteed to be\n+      \/\/ owned by the current thread.\n+      \/\/\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant bits clear.\n+      \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n+      subptr(swap_reg, rsp);\n+      andptr(swap_reg, zero_bits - (int)os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      movptr(Address(lock_reg, mark_offset), swap_reg);\n+      jcc(Assembler::notZero, slow_case);\n@@ -1395,47 +1452,2 @@\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-\n-    assert(lock_offset == 0,\n-           \"displaced header must be first word in BasicObjectLock\");\n-\n-    lock();\n-    cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    jcc(Assembler::zero, count_locking);\n-\n-    const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & zero_bits) == 0, and\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from rsp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n-    subptr(swap_reg, rsp);\n-    andptr(swap_reg, zero_bits - os::vm_page_size());\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-    jcc(Assembler::notZero, slow_case);\n-\n-    bind(count_locking);\n+      bind(count_locking);\n+    }\n@@ -1448,4 +1460,9 @@\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            lock_reg);\n-\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n+              obj_reg);\n+    } else {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+              lock_reg);\n+    }\n@@ -1473,1 +1490,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -1484,3 +1501,5 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %rax\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+      \/\/ structure Store the BasicLock address into %rax\n+      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset()));\n+    }\n@@ -1489,1 +1508,1 @@\n-    movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+    movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset()));\n@@ -1492,1 +1511,1 @@\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), NULL_WORD);\n+    movptr(Address(lock_reg, BasicObjectLock::obj_offset()), NULL_WORD);\n@@ -1494,16 +1513,33 @@\n-    \/\/ Load the old header from BasicLock structure\n-    movptr(header_reg, Address(swap_reg,\n-                               BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Test for recursion\n-    testptr(header_reg, header_reg);\n-\n-    \/\/ zero for recursive case\n-    jcc(Assembler::zero, count_locking);\n-\n-    \/\/ Atomic swap back the old header\n-    lock();\n-    cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ zero for simple unlock of a stack-lock case\n-    jcc(Assembler::notZero, slow_case);\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+#ifdef _LP64\n+      const Register thread = r15_thread;\n+#else\n+      const Register thread = header_reg;\n+      get_thread(thread);\n+#endif\n+      \/\/ Handle unstructured locking.\n+      Register tmp = swap_reg;\n+      movl(tmp, Address(thread, JavaThread::lock_stack_top_offset()));\n+      cmpptr(obj_reg, Address(thread, tmp, Address::times_1,  -oopSize));\n+      jcc(Assembler::notEqual, slow_case);\n+      \/\/ Try to swing header from locked to unlocked.\n+      movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      fast_unlock_impl(obj_reg, swap_reg, header_reg, slow_case);\n+    } else if (LockingMode == LM_LEGACY) {\n+      \/\/ Load the old header from BasicLock structure\n+      movptr(header_reg, Address(swap_reg,\n+                                 BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ Test for recursion\n+      testptr(header_reg, header_reg);\n+\n+      \/\/ zero for recursive case\n+      jcc(Assembler::zero, count_locking);\n+\n+      \/\/ Atomic swap back the old header\n+      lock();\n+      cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+      \/\/ zero for simple unlock of a stack-lock case\n+      jcc(Assembler::notZero, slow_case);\n@@ -1511,1 +1547,2 @@\n-    bind(count_locking);\n+      bind(count_locking);\n+    }\n@@ -1517,1 +1554,1 @@\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), obj_reg); \/\/ restore obj\n+    movptr(Address(lock_reg, BasicObjectLock::obj_offset()), obj_reg); \/\/ restore obj\n@@ -1543,1 +1580,1 @@\n-  \/\/ Test MDO to avoid the call if it is NULL.\n+  \/\/ Test MDO to avoid the call if it is null.\n@@ -1926,1 +1963,1 @@\n-  \/\/ observed the item[start_row] is NULL.\n+  \/\/ observed the item[start_row] is null.\n@@ -1942,1 +1979,1 @@\n-\/\/   if (row[0].rec != NULL) {\n+\/\/   if (row[0].rec != nullptr) {\n@@ -1945,1 +1982,1 @@\n-\/\/     if (row[1].rec != NULL) {\n+\/\/     if (row[1].rec != nullptr) {\n@@ -1948,1 +1985,1 @@\n-\/\/       if (row[2].rec != NULL) { count.incr(); goto done; } \/\/ overflow\n+\/\/       if (row[2].rec != nullptr) { count.incr(); goto done; } \/\/ overflow\n@@ -2232,1 +2269,1 @@\n-  if (where != NULL) {\n+  if (where != nullptr) {\n@@ -2309,0 +2346,14 @@\n+\n+void InterpreterMacroAssembler::load_resolved_indy_entry(Register cache, Register index) {\n+  \/\/ Get index out of bytecode pointer, get_cache_entry_pointer_at_bcp\n+  get_cache_index_at_bcp(index, 1, sizeof(u4));\n+  \/\/ Get address of invokedynamic array\n+  movptr(cache, Address(rbp, frame::interpreter_frame_cache_offset * wordSize));\n+  movptr(cache, Address(cache, in_bytes(ConstantPoolCache::invokedynamic_entries_offset())));\n+  if (is_power_of_2(sizeof(ResolvedIndyEntry))) {\n+    shll(index, log2i_exact(sizeof(ResolvedIndyEntry))); \/\/ Scale index by power of 2\n+  } else {\n+    imull(index, index, sizeof(ResolvedIndyEntry)); \/\/ Scale the index to be the entry index * sizeof(ResolvedInvokeDynamicInfo)\n+  }\n+  lea(cache, Address(cache, index, Address::times_1, Array<ResolvedIndyEntry>::base_offset_in_bytes()));\n+}\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":159,"deletions":108,"binary":false,"changes":267,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -122,1 +122,1 @@\n- , _bci2block(new BlockList(scope->method()->code_size(), NULL))\n+ , _bci2block(new BlockList(scope->method()->code_size(), nullptr))\n@@ -153,2 +153,2 @@\n-  BlockBegin* std_entry = make_block_at(0, NULL);\n-  if (scope()->caller() == NULL) {\n+  BlockBegin* std_entry = make_block_at(0, nullptr);\n+  if (scope()->caller() == nullptr) {\n@@ -158,1 +158,1 @@\n-    BlockBegin* osr_entry = make_block_at(osr_bci, NULL);\n+    BlockBegin* osr_entry = make_block_at(osr_bci, nullptr);\n@@ -167,1 +167,1 @@\n-    BlockBegin* entry = make_block_at(h->handler_bci(), NULL);\n+    BlockBegin* entry = make_block_at(h->handler_bci(), nullptr);\n@@ -178,1 +178,1 @@\n-  if (block == NULL) {\n+  if (block == nullptr) {\n@@ -185,1 +185,1 @@\n-    assert(predecessor == NULL || predecessor->bci() < cur_bci, \"targets for backward branches must already exist\");\n+    assert(predecessor == nullptr || predecessor->bci() < cur_bci, \"targets for backward branches must already exist\");\n@@ -188,1 +188,1 @@\n-  if (predecessor != NULL) {\n+  if (predecessor != nullptr) {\n@@ -220,1 +220,1 @@\n-      assert(entry != NULL && entry == _bci2block->at(h->handler_bci()), \"entry must be set\");\n+      assert(entry != nullptr && entry == _bci2block->at(h->handler_bci()), \"entry must be set\");\n@@ -251,1 +251,1 @@\n-  BlockBegin* current = NULL;\n+  BlockBegin* current = nullptr;\n@@ -268,1 +268,1 @@\n-    assert(current != NULL, \"must have current block\");\n+    assert(current != nullptr, \"must have current block\");\n@@ -312,1 +312,1 @@\n-        current = NULL;\n+        current = nullptr;\n@@ -335,1 +335,1 @@\n-        current = NULL;\n+        current = nullptr;\n@@ -340,1 +340,1 @@\n-        current = NULL;\n+        current = nullptr;\n@@ -345,1 +345,1 @@\n-        current = NULL;\n+        current = nullptr;\n@@ -350,1 +350,1 @@\n-        current = NULL;\n+        current = nullptr;\n@@ -355,1 +355,1 @@\n-        current = NULL;\n+        current = nullptr;\n@@ -366,1 +366,1 @@\n-        current = NULL;\n+        current = nullptr;\n@@ -378,1 +378,1 @@\n-        current = NULL;\n+        current = nullptr;\n@@ -577,1 +577,1 @@\n-    int offset = field->offset();\n+    int offset = field->offset_in_bytes();\n@@ -581,1 +581,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -587,2 +587,2 @@\n-    int offset = field->offset();\n-    _values.at_put_grow(offset, value, NULL);\n+    int offset = field->offset_in_bytes();\n+    _values.at_put_grow(offset, value, nullptr);\n@@ -628,1 +628,1 @@\n-      int offset = field->offset();\n+      int offset = field->offset_in_bytes();\n@@ -633,1 +633,1 @@\n-        if (buf->at(field) == NULL && is_default_value(value)) {\n+        if (buf->at(field) == nullptr && is_default_value(value)) {\n@@ -640,1 +640,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -645,1 +645,1 @@\n-        _objects.at_put_grow(offset, object, NULL);\n+        _objects.at_put_grow(offset, object, nullptr);\n@@ -696,2 +696,2 @@\n-      int offset = field->offset();\n-      Value result = NULL;\n+      int offset = field->offset_in_bytes();\n+      Value result = nullptr;\n@@ -701,1 +701,1 @@\n-      } else if (_objects.at_grow(offset, NULL) == object) {\n+      } else if (_objects.at_grow(offset, nullptr) == object) {\n@@ -704,1 +704,1 @@\n-      if (result != NULL) {\n+      if (result != nullptr) {\n@@ -722,1 +722,1 @@\n-    if (_fields.at_grow(index, NULL) == NULL) {\n+    if (_fields.at_grow(index, nullptr) == nullptr) {\n@@ -733,1 +733,1 @@\n-    if (_fields.at_grow(index, NULL) == NULL) {\n+    if (_fields.at_grow(index, nullptr) == nullptr) {\n@@ -767,2 +767,2 @@\n-  , _bci2block(NULL)\n-  , _scope(NULL)\n+  , _bci2block(nullptr)\n+  , _scope(nullptr)\n@@ -770,2 +770,2 @@\n-  , _stream(NULL)\n-  , _work_list(NULL)\n+  , _stream(nullptr)\n+  , _work_list(nullptr)\n@@ -773,1 +773,1 @@\n-  , _continuation(NULL)\n+  , _continuation(nullptr)\n@@ -775,1 +775,1 @@\n-  , _jsr_xhandlers(NULL)\n+  , _jsr_xhandlers(nullptr)\n@@ -777,3 +777,3 @@\n-  , _cleanup_block(NULL)\n-  , _cleanup_return_prev(NULL)\n-  , _cleanup_state(NULL)\n+  , _cleanup_block(nullptr)\n+  , _cleanup_return_prev(nullptr)\n+  , _cleanup_state(nullptr)\n@@ -782,1 +782,1 @@\n-  if (parent != NULL) {\n+  if (parent != nullptr) {\n@@ -808,1 +808,1 @@\n-    if (block != NULL && block == parent()->bci2block()->at(bci)) {\n+    if (block != nullptr && block == parent()->bci2block()->at(bci)) {\n@@ -839,1 +839,1 @@\n-  if (_jsr_xhandlers == NULL) {\n+  if (_jsr_xhandlers == nullptr) {\n@@ -851,1 +851,1 @@\n-  if (parent() != NULL) {\n+  if (parent() != nullptr) {\n@@ -868,1 +868,1 @@\n-  if (_work_list == NULL) {\n+  if (_work_list == nullptr) {\n@@ -913,1 +913,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -920,1 +920,1 @@\n-  return (_work_list == NULL || _work_list->length() == 0);\n+  return (_work_list == nullptr || _work_list->length() == 0);\n@@ -969,1 +969,1 @@\n-    ValueStack* patch_state = NULL;\n+    ValueStack* patch_state = nullptr;\n@@ -1002,1 +1002,1 @@\n-    if (patch_state != NULL) {\n+    if (patch_state != nullptr) {\n@@ -1013,1 +1013,1 @@\n-    if (patch_state != NULL) {\n+    if (patch_state != nullptr) {\n@@ -1037,1 +1037,1 @@\n-  assert(x != NULL && !x->type()->is_illegal(), \"access of illegal local variable\");\n+  assert(x != nullptr && !x->type()->is_illegal(), \"access of illegal local variable\");\n@@ -1039,1 +1039,1 @@\n-  if (x->as_NewInlineTypeInstance() != NULL && x->as_NewInlineTypeInstance()->in_larval_state()) {\n+  if (x->as_NewInlineTypeInstance() != nullptr && x->as_NewInlineTypeInstance()->in_larval_state()) {\n@@ -1052,1 +1052,1 @@\n-  if (x->as_NewInlineTypeInstance() != NULL) {\n+  if (x->as_NewInlineTypeInstance() != nullptr) {\n@@ -1071,1 +1071,1 @@\n-           cur_scope_data != NULL && cur_scope_data->parsing_jsr() && cur_scope_data->scope() == scope();\n+           cur_scope_data != nullptr && cur_scope_data->parsing_jsr() && cur_scope_data->scope() == scope();\n@@ -1083,1 +1083,1 @@\n-  if (x->as_NewInlineTypeInstance() != NULL) {\n+  if (x->as_NewInlineTypeInstance() != nullptr) {\n@@ -1091,1 +1091,1 @@\n-  ValueStack* state_before = NULL;\n+  ValueStack* state_before = nullptr;\n@@ -1103,1 +1103,1 @@\n-  Value length = NULL;\n+  Value length = nullptr;\n@@ -1105,1 +1105,1 @@\n-      (array->as_Constant() != NULL) ||\n+      (array->as_Constant() != nullptr) ||\n@@ -1113,2 +1113,2 @@\n-  LoadIndexed* load_indexed = NULL;\n-  Instruction* result = NULL;\n+  LoadIndexed* load_indexed = nullptr;\n+  Instruction* result = nullptr;\n@@ -1177,1 +1177,1 @@\n-  ValueStack* state_before = NULL;\n+  ValueStack* state_before = nullptr;\n@@ -1190,1 +1190,1 @@\n-  Value length = NULL;\n+  Value length = nullptr;\n@@ -1192,1 +1192,1 @@\n-      (array->as_Constant() != NULL) ||\n+      (array->as_Constant() != nullptr) ||\n@@ -1200,1 +1200,1 @@\n-  if (array_type != NULL) {\n+  if (array_type != nullptr) {\n@@ -1258,1 +1258,1 @@\n-        if (w1 != NULL && w1->as_NewInlineTypeInstance() != NULL) {\n+        if (w1 != nullptr && w1->as_NewInlineTypeInstance() != nullptr) {\n@@ -1352,1 +1352,1 @@\n-    if (s1 != NULL) {\n+    if (s1 != nullptr) {\n@@ -1355,1 +1355,1 @@\n-      if (l != NULL && l->op() == Bytecodes::_ishl) {\n+      if (l != nullptr && l->op() == Bytecodes::_ishl) {\n@@ -1358,1 +1358,1 @@\n-        if (s0 != NULL) {\n+        if (s0 != nullptr) {\n@@ -1442,1 +1442,1 @@\n-      if (left_klass == NULL || right_klass == NULL) {\n+      if (left_klass == nullptr || right_klass == nullptr) {\n@@ -1461,1 +1461,1 @@\n-  Instruction *i = append(new If(x, cond, false, y, tsux, fsux, (is_bb || compilation()->is_optimistic() || subst_check) ? state_before : NULL, is_bb, subst_check));\n+  Instruction *i = append(new If(x, cond, false, y, tsux, fsux, (is_bb || compilation()->is_optimistic() || subst_check) ? state_before : nullptr, is_bb, subst_check));\n@@ -1463,1 +1463,1 @@\n-  assert(i->as_Goto() == NULL ||\n+  assert(i->as_Goto() == nullptr ||\n@@ -1470,1 +1470,1 @@\n-    if (if_node != NULL) {\n+    if (if_node != nullptr) {\n@@ -1488,1 +1488,1 @@\n-    if (goto_node != NULL) {\n+    if (goto_node != nullptr) {\n@@ -1539,1 +1539,1 @@\n-       cur_scope_data != NULL && cur_scope_data->parsing_jsr() && cur_scope_data->scope() == scope();\n+       cur_scope_data != nullptr && cur_scope_data->parsing_jsr() && cur_scope_data->scope() == scope();\n@@ -1582,1 +1582,1 @@\n-    BlockList* sux = new BlockList(l + 1, NULL);\n+    BlockList* sux = new BlockList(l + 1, nullptr);\n@@ -1628,1 +1628,1 @@\n-    BlockList* sux = new BlockList(l + 1, NULL);\n+    BlockList* sux = new BlockList(l + 1, nullptr);\n@@ -1663,1 +1663,1 @@\n-  assert(receiver != NULL, \"must have a receiver\");\n+  assert(receiver != nullptr, \"must have a receiver\");\n@@ -1666,1 +1666,1 @@\n-  if (exact_type == NULL &&\n+  if (exact_type == nullptr &&\n@@ -1683,1 +1683,1 @@\n-  if (exact_type != NULL) {\n+  if (exact_type != nullptr) {\n@@ -1685,1 +1685,1 @@\n-  } else if (declared_type != NULL) {\n+  } else if (declared_type != nullptr) {\n@@ -1753,1 +1753,1 @@\n-  if (continuation() != NULL) {\n+  if (continuation() != nullptr) {\n@@ -1757,1 +1757,1 @@\n-    if (x != NULL  && !ignore_return) {\n+    if (x != nullptr  && !ignore_return) {\n@@ -1762,1 +1762,1 @@\n-        if (declared_ret_type->is_klass() && x->exact_type() == NULL &&\n+        if (declared_ret_type->is_klass() && x->exact_type() == nullptr &&\n@@ -1793,1 +1793,1 @@\n-    if (x != NULL) {\n+    if (x != nullptr) {\n@@ -1838,1 +1838,1 @@\n-  if (!field_value.is_valid())  return NULL;\n+  if (!field_value.is_valid())  return nullptr;\n@@ -1857,1 +1857,1 @@\n-      return NULL; \/\/ Not a constant.\n+      return nullptr; \/\/ Not a constant.\n@@ -1868,1 +1868,1 @@\n-      int off = inner_field->offset() + sec_offset - vk->first_field_offset();\n+      int off = inner_field->offset_in_bytes() + sec_offset - vk->first_field_offset();\n@@ -1891,1 +1891,1 @@\n-  ValueStack* state_before = NULL;\n+  ValueStack* state_before = nullptr;\n@@ -1898,1 +1898,1 @@\n-  Value obj = NULL;\n+  Value obj = nullptr;\n@@ -1900,1 +1900,1 @@\n-    if (state_before != NULL) {\n+    if (state_before != nullptr) {\n@@ -1919,1 +1919,1 @@\n-  int offset = !needs_patching ? field->offset() : -1;\n+  int offset = !needs_patching ? field->offset_in_bytes() : -1;\n@@ -1923,1 +1923,1 @@\n-      Value constant = NULL;\n+      Value constant = nullptr;\n@@ -1934,1 +1934,1 @@\n-      if (constant != NULL) {\n+      if (constant != nullptr) {\n@@ -1937,1 +1937,1 @@\n-        if (state_before == NULL) {\n+        if (state_before == nullptr) {\n@@ -1948,1 +1948,1 @@\n-      if (state_before == NULL) {\n+      if (state_before == nullptr) {\n@@ -1964,2 +1964,2 @@\n-      Value constant = NULL;\n-      if (state_before == NULL && field->is_flattened()) {\n+      Value constant = nullptr;\n+      if (state_before == nullptr && field->is_flattened()) {\n@@ -2001,1 +2001,1 @@\n-      if (constant != NULL) {\n+      if (constant != nullptr) {\n@@ -2004,1 +2004,1 @@\n-        if (state_before == NULL) {\n+        if (state_before == nullptr) {\n@@ -2013,2 +2013,2 @@\n-            assert(field != NULL, \"field not found\");\n-            set_pending_field_access(NULL);\n+            assert(field != nullptr, \"field not found\");\n+            set_pending_field_access(nullptr);\n@@ -2021,1 +2021,1 @@\n-            set_pending_load_indexed(NULL);\n+            set_pending_load_indexed(nullptr);\n@@ -2068,1 +2068,1 @@\n-              DelayedFieldAccess* dfa = new DelayedFieldAccess(obj, field->holder(), field->offset());\n+              DelayedFieldAccess* dfa = new DelayedFieldAccess(obj, field->holder(), field->offset_in_bytes());\n@@ -2079,1 +2079,1 @@\n-                set_pending_field_access(NULL);\n+                set_pending_field_access(nullptr);\n@@ -2081,1 +2081,1 @@\n-                set_pending_load_indexed(NULL);\n+                set_pending_load_indexed(nullptr);\n@@ -2091,1 +2091,1 @@\n-              set_pending_load_indexed(NULL);\n+              set_pending_load_indexed(nullptr);\n@@ -2100,1 +2100,1 @@\n-                                    pending_field_access()->offset() + field->offset() - field->holder()->as_inline_klass()->first_field_offset(),\n+                                    pending_field_access()->offset() + field->offset_in_bytes() - field->holder()->as_inline_klass()->first_field_offset(),\n@@ -2102,1 +2102,1 @@\n-                set_pending_field_access(NULL);\n+                set_pending_field_access(nullptr);\n@@ -2104,1 +2104,1 @@\n-                copy_inline_content(inline_klass, obj, field->offset(), new_instance, inline_klass->first_field_offset(), state_before);\n+                copy_inline_content(inline_klass, obj, field->offset_in_bytes(), new_instance, inline_klass->first_field_offset(), state_before);\n@@ -2122,1 +2122,1 @@\n-      if (state_before == NULL) {\n+      if (state_before == nullptr) {\n@@ -2135,1 +2135,1 @@\n-        if (store != NULL) {\n+        if (store != nullptr) {\n@@ -2174,1 +2174,1 @@\n-  const int offset_modify = !needs_patching ? field_modify->offset() : -1;\n+  const int offset_modify = !needs_patching ? field_modify->offset_in_bytes() : -1;\n@@ -2180,1 +2180,1 @@\n-  if (obj->as_NewInlineTypeInstance() != NULL && obj->as_NewInlineTypeInstance()->in_larval_state()) {\n+  if (obj->as_NewInlineTypeInstance() != nullptr && obj->as_NewInlineTypeInstance()->in_larval_state()) {\n@@ -2191,1 +2191,1 @@\n-      int offset = field->offset();\n+      int offset = field->offset_in_bytes();\n@@ -2193,1 +2193,1 @@\n-      if (offset != field_modify->offset()) {\n+      if (offset != field_modify->offset_in_bytes()) {\n@@ -2238,1 +2238,1 @@\n-    if (data != NULL && (data->is_CallTypeData() || data->is_VirtualCallTypeData())) {\n+    if (data != nullptr && (data->is_CallTypeData() || data->is_VirtualCallTypeData())) {\n@@ -2243,2 +2243,2 @@\n-  if (profile_parameters() && target != NULL) {\n-    if (target->method_data() != NULL && target->method_data()->parameters_type_data() != NULL) {\n+  if (profile_parameters() && target != nullptr) {\n+    if (target->method_data() != nullptr && target->method_data()->parameters_type_data() != nullptr) {\n@@ -2254,1 +2254,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2260,1 +2260,1 @@\n-  ciSignature* declared_signature = NULL;\n+  ciSignature* declared_signature = nullptr;\n@@ -2270,2 +2270,2 @@\n-  if (obj_args == NULL) {\n-    return NULL;\n+  if (obj_args == nullptr) {\n+    return nullptr;\n@@ -2287,1 +2287,1 @@\n-  ciSignature* declared_signature = NULL;\n+  ciSignature* declared_signature = nullptr;\n@@ -2291,1 +2291,1 @@\n-  assert(declared_signature != NULL, \"cannot be null\");\n+  assert(declared_signature != nullptr, \"cannot be null\");\n@@ -2304,1 +2304,1 @@\n-  if (log != NULL)\n+  if (log != nullptr)\n@@ -2370,3 +2370,3 @@\n-  ciMethod* cha_monomorphic_target = NULL;\n-  ciMethod* exact_target = NULL;\n-  Value better_receiver = NULL;\n+  ciMethod* cha_monomorphic_target = nullptr;\n+  ciMethod* exact_target = nullptr;\n+  Value better_receiver = nullptr;\n@@ -2378,2 +2378,2 @@\n-    Value receiver = NULL;\n-    ciInstanceKlass* receiver_klass = NULL;\n+    Value receiver = nullptr;\n+    ciInstanceKlass* receiver_klass = nullptr;\n@@ -2386,1 +2386,1 @@\n-      if (type != NULL && type->is_loaded() &&\n+      if (type != nullptr && type->is_loaded() &&\n@@ -2391,1 +2391,1 @@\n-      if (type == NULL) {\n+      if (type == nullptr) {\n@@ -2393,1 +2393,1 @@\n-        if (type != NULL && type->is_loaded() &&\n+        if (type != nullptr && type->is_loaded() &&\n@@ -2405,1 +2405,1 @@\n-    if (receiver_klass != NULL && type_is_exact &&\n+    if (receiver_klass != nullptr && type_is_exact &&\n@@ -2410,1 +2410,1 @@\n-      if (exact_target != NULL) {\n+      if (exact_target != nullptr) {\n@@ -2415,1 +2415,1 @@\n-    if (receiver_klass != NULL &&\n+    if (receiver_klass != nullptr &&\n@@ -2425,1 +2425,1 @@\n-    } else if (code == Bytecodes::_invokeinterface && callee_holder->is_loaded() && receiver != NULL) {\n+    } else if (code == Bytecodes::_invokeinterface && callee_holder->is_loaded() && receiver != nullptr) {\n@@ -2443,1 +2443,1 @@\n-      if (singleton != NULL) {\n+      if (singleton != nullptr) {\n@@ -2446,1 +2446,1 @@\n-        if (cha_monomorphic_target != NULL) {\n+        if (cha_monomorphic_target != nullptr) {\n@@ -2462,1 +2462,1 @@\n-            cha_monomorphic_target = NULL; \/\/ subtype check against Object is useless\n+            cha_monomorphic_target = nullptr; \/\/ subtype check against Object is useless\n@@ -2469,1 +2469,1 @@\n-  if (cha_monomorphic_target != NULL) {\n+  if (cha_monomorphic_target != nullptr) {\n@@ -2493,2 +2493,2 @@\n-      ciMethod* inline_target = (cha_monomorphic_target != NULL) ? cha_monomorphic_target : target;\n-      bool holder_known = (cha_monomorphic_target != NULL) || (exact_target != NULL);\n+      ciMethod* inline_target = (cha_monomorphic_target != nullptr) ? cha_monomorphic_target : target;\n+      bool holder_known = (cha_monomorphic_target != nullptr) || (exact_target != nullptr);\n@@ -2537,1 +2537,1 @@\n-  Value recv = has_receiver ? apop() : NULL;\n+  Value recv = has_receiver ? apop() : nullptr;\n@@ -2556,1 +2556,1 @@\n-    if (recv != NULL) {\n+    if (recv != nullptr) {\n@@ -2565,3 +2565,3 @@\n-        assert(cha_monomorphic_target == NULL || exact_target == NULL, \"both can not be set\");\n-        ciKlass* target_klass = NULL;\n-        if (cha_monomorphic_target != NULL) {\n+        assert(cha_monomorphic_target == nullptr || exact_target == nullptr, \"both can not be set\");\n+        ciKlass* target_klass = nullptr;\n+        if (cha_monomorphic_target != nullptr) {\n@@ -2569,1 +2569,1 @@\n-        } else if (exact_target != NULL) {\n+        } else if (exact_target != nullptr) {\n@@ -2572,1 +2572,1 @@\n-        profile_call(target, recv, target_klass, collect_args_for_profiling(args, NULL, false), false);\n+        profile_call(target, recv, target_klass, collect_args_for_profiling(args, nullptr, false), false);\n@@ -2691,1 +2691,1 @@\n-    assert(obj_type == NULL || !obj_type->is_inlinetype(), \"inline types cannot have synchronized methods\");\n+    assert(obj_type == nullptr || !obj_type->is_inlinetype(), \"inline types cannot have synchronized methods\");\n@@ -2697,1 +2697,1 @@\n-      if (obj_type == NULL || obj_type->as_klass()->can_be_inline_klass()) {\n+      if (obj_type == nullptr || obj_type->as_klass()->can_be_inline_klass()) {\n@@ -2723,1 +2723,1 @@\n-  Values* dims = new Values(dimensions, dimensions, NULL);\n+  Values* dims = new Values(dimensions, dimensions, nullptr);\n@@ -2753,3 +2753,3 @@\n-          fp_value->as_Constant() == NULL &&\n-          fp_value->as_Local() == NULL &&       \/\/ method parameters need no rounding\n-          fp_value->as_RoundFP() == NULL) {\n+          fp_value->as_Constant() == nullptr &&\n+          fp_value->as_Local() == nullptr &&       \/\/ method parameters need no rounding\n+          fp_value->as_RoundFP() == nullptr) {\n@@ -2790,1 +2790,1 @@\n-  assert(i1->next() == NULL, \"shouldn't already be linked\");\n+  assert(i1->next() == nullptr, \"shouldn't already be linked\");\n@@ -2812,1 +2812,1 @@\n-  if (s != NULL) {\n+  if (s != nullptr) {\n@@ -2815,1 +2815,1 @@\n-      if (s->as_Invoke() != NULL || (intrinsic && !intrinsic->preserves_state())) {\n+      if (s->as_Invoke() != nullptr || (intrinsic && !intrinsic->preserves_state())) {\n@@ -2825,1 +2825,1 @@\n-    assert(i1->exception_state() != NULL || !i1->needs_exception_state() || bailed_out(), \"handle_exception must set exception state\");\n+    assert(i1->exception_state() != nullptr || !i1->needs_exception_state() || bailed_out(), \"handle_exception must set exception state\");\n@@ -2832,1 +2832,1 @@\n-  assert(instr->as_StateSplit() == NULL || instr->as_BlockEnd() != NULL, \"wrong append used\");\n+  assert(instr->as_StateSplit() == nullptr || instr->as_BlockEnd() != nullptr, \"wrong append used\");\n@@ -2843,1 +2843,1 @@\n-  if (value->as_NewArray() != NULL || value->as_NewInstance() != NULL || value->as_NewInlineTypeInstance() != NULL) {\n+  if (value->as_NewArray() != nullptr || value->as_NewInstance() != nullptr || value->as_NewInlineTypeInstance() != nullptr) {\n@@ -2864,2 +2864,2 @@\n-  if (!has_handler() && (!instruction->needs_exception_state() || instruction->exception_state() != NULL)) {\n-    assert(instruction->exception_state() == NULL\n+  if (!has_handler() && (!instruction->needs_exception_state() || instruction->exception_state() != nullptr)) {\n+    assert(instruction->exception_state() == nullptr\n@@ -2875,1 +2875,1 @@\n-  ValueStack* prev_state = NULL;\n+  ValueStack* prev_state = nullptr;\n@@ -2878,1 +2878,1 @@\n-  assert(cur_state != NULL, \"state_before must be set\");\n+  assert(cur_state != nullptr, \"state_before must be set\");\n@@ -2907,1 +2907,1 @@\n-        assert(entry->state() == NULL || cur_state->total_locks_size() == entry->state()->total_locks_size(), \"locks do not match\");\n+        assert(entry->state() == nullptr || cur_state->total_locks_size() == entry->state()->total_locks_size(), \"locks do not match\");\n@@ -2913,1 +2913,1 @@\n-        if (instruction->exception_state() == NULL) {\n+        if (instruction->exception_state() == nullptr) {\n@@ -2965,1 +2965,1 @@\n-      if (prev_state != NULL) {\n+      if (prev_state != nullptr) {\n@@ -2968,1 +2968,1 @@\n-      if (instruction->exception_state() == NULL) {\n+      if (instruction->exception_state() == nullptr) {\n@@ -2989,1 +2989,1 @@\n-  } while (cur_scope_data != NULL);\n+  } while (cur_scope_data != nullptr);\n@@ -3016,1 +3016,1 @@\n-  if (phi == NULL) {\n+  if (phi == nullptr) {\n@@ -3037,1 +3037,1 @@\n-    Value subst = NULL;\n+    Value subst = nullptr;\n@@ -3041,1 +3041,1 @@\n-      assert(opd != NULL, \"Operand must exist!\");\n+      assert(opd != nullptr, \"Operand must exist!\");\n@@ -3051,1 +3051,1 @@\n-      assert(new_opd != NULL, \"Simplified operand must exist!\");\n+      assert(new_opd != nullptr, \"Simplified operand must exist!\");\n@@ -3054,1 +3054,1 @@\n-        if (subst == NULL) {\n+        if (subst == nullptr) {\n@@ -3066,1 +3066,1 @@\n-    assert(subst != NULL, \"illegal phi function\");\n+    assert(subst != nullptr, \"illegal phi function\");\n@@ -3095,1 +3095,1 @@\n-    assert(phi == NULL || phi->block() != b, \"must not have phi function to simplify in caller state\");\n+    assert(phi == nullptr || phi->block() != b, \"must not have phi function to simplify in caller state\");\n@@ -3130,1 +3130,1 @@\n-  assert(state() != NULL, \"ValueStack missing!\");\n+  assert(state() != nullptr, \"ValueStack missing!\");\n@@ -3140,1 +3140,1 @@\n-  if (block()->is_set(BlockBegin::exception_entry_flag) && block()->next() == NULL) {\n+  if (block()->is_set(BlockBegin::exception_entry_flag) && block()->next() == nullptr) {\n@@ -3147,1 +3147,1 @@\n-  while (!bailed_out() && last()->as_BlockEnd() == NULL &&\n+  while (!bailed_out() && last()->as_BlockEnd() == nullptr &&\n@@ -3149,1 +3149,1 @@\n-         (block_at(s.cur_bci()) == NULL || block_at(s.cur_bci()) == block())) {\n+         (block_at(s.cur_bci()) == nullptr || block_at(s.cur_bci()) == block())) {\n@@ -3152,1 +3152,1 @@\n-    if (log != NULL)\n+    if (log != nullptr)\n@@ -3347,1 +3347,1 @@\n-      case Bytecodes::_return         : method_return(NULL  , ignore_return); break;\n+      case Bytecodes::_return         : method_return(nullptr, ignore_return); break;\n@@ -3374,1 +3374,1 @@\n-      case Bytecodes::_breakpoint     : BAILOUT_(\"concurrent setting of breakpoint\", NULL);\n+      case Bytecodes::_breakpoint     : BAILOUT_(\"concurrent setting of breakpoint\", nullptr);\n@@ -3378,1 +3378,1 @@\n-    if (log != NULL)\n+    if (log != nullptr)\n@@ -3385,1 +3385,1 @@\n-  CHECK_BAILOUT_(NULL);\n+  CHECK_BAILOUT_(nullptr);\n@@ -3394,1 +3394,1 @@\n-  if (end == NULL) {\n+  if (end == nullptr) {\n@@ -3401,2 +3401,2 @@\n-  assert(end->state() != NULL, \"state must already be present\");\n-  assert(end->as_Return() == NULL || end->as_Throw() == NULL || end->state()->stack_size() == 0, \"stack not needed for return and throw\");\n+  assert(end->state() != nullptr, \"state must already be present\");\n+  assert(end->as_Return() == nullptr || end->as_Throw() == nullptr || end->state()->stack_size() == 0, \"stack not needed for return and throw\");\n@@ -3412,1 +3412,1 @@\n-    if (!sux->try_merge(end->state(), compilation()->has_irreducible_loops())) BAILOUT_(\"block join failed\", NULL);\n+    if (!sux->try_merge(end->state(), compilation()->has_irreducible_loops())) BAILOUT_(\"block join failed\", nullptr);\n@@ -3416,1 +3416,1 @@\n-  scope_data()->set_stream(NULL);\n+  scope_data()->set_stream(nullptr);\n@@ -3430,1 +3430,1 @@\n-      while ((b = scope_data()->remove_from_work_list()) != NULL) {\n+      while ((b = scope_data()->remove_from_work_list()) != nullptr) {\n@@ -3564,1 +3564,1 @@\n-  if (base->std_entry()->state() == NULL) {\n+  if (base->std_entry()->state() == nullptr) {\n@@ -3569,1 +3569,1 @@\n-  assert(base->std_entry()->state() != NULL, \"\");\n+  assert(base->std_entry()->state() != nullptr, \"\");\n@@ -3588,1 +3588,1 @@\n-  assert(target != NULL && target->is_set(BlockBegin::osr_entry_flag), \"must be there\");\n+  assert(target != nullptr && target->is_set(BlockBegin::osr_entry_flag), \"must be there\");\n@@ -3644,1 +3644,1 @@\n-  assert(state->caller_state() == NULL, \"should be top scope\");\n+  assert(state->caller_state() == nullptr, \"should be top scope\");\n@@ -3651,1 +3651,1 @@\n-  scope_data()->set_stream(NULL);\n+  scope_data()->set_stream(nullptr);\n@@ -3656,1 +3656,1 @@\n-  ValueStack* state = new ValueStack(scope(), NULL);\n+  ValueStack* state = new ValueStack(scope(), nullptr);\n@@ -3681,1 +3681,1 @@\n-    state->lock(NULL);\n+    state->lock(nullptr);\n@@ -3689,1 +3689,1 @@\n-  : _scope_data(NULL)\n+  : _scope_data(nullptr)\n@@ -3692,1 +3692,1 @@\n-  , _inline_bailout_msg(NULL)\n+  , _inline_bailout_msg(nullptr)\n@@ -3694,3 +3694,3 @@\n-  , _osr_entry(NULL)\n-  , _pending_field_access(NULL)\n-  , _pending_load_indexed(NULL)\n+  , _osr_entry(nullptr)\n+  , _pending_field_access(nullptr)\n+  , _pending_load_indexed(nullptr)\n@@ -3819,1 +3819,1 @@\n-  \/\/All blocks reachable from start_block have _end != NULL\n+  \/\/ For all blocks reachable from start_block: _end must be non-null\n@@ -3826,2 +3826,2 @@\n-      assert(current != NULL, \"Should not happen.\");\n-      assert(current->end() != NULL, \"All blocks reachable from start_block should have end() != NULL.\");\n+      assert(current != nullptr, \"Should not happen.\");\n+      assert(current->end() != nullptr, \"All blocks reachable from start_block should have end() != nullptr.\");\n@@ -3879,1 +3879,1 @@\n-  if (!has_handler()) return NULL;\n+  if (!has_handler()) return nullptr;\n@@ -3885,1 +3885,1 @@\n-  if (s == NULL) {\n+  if (s == nullptr) {\n@@ -3897,1 +3897,1 @@\n-  for (IRScope* s = scope(); s != NULL; s = s->caller()) {\n+  for (IRScope* s = scope(); s != nullptr; s = s->caller()) {\n@@ -3907,1 +3907,1 @@\n-  const char* msg = NULL;\n+  const char* msg = nullptr;\n@@ -3914,1 +3914,1 @@\n-  if (msg != NULL) {\n+  if (msg != nullptr) {\n@@ -3945,1 +3945,1 @@\n-  if (msg != NULL) {\n+  if (msg != nullptr) {\n@@ -3975,1 +3975,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -3978,1 +3978,1 @@\n-\/\/ negative filter: should callee NOT be inlined?  returns NULL, ok to inline, or rejection msg\n+\/\/ negative filter: should callee NOT be inlined?  returns null, ok to inline, or rejection msg\n@@ -3982,1 +3982,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4063,1 +4063,1 @@\n-        Value recv = NULL;\n+        Value recv = nullptr;\n@@ -4068,1 +4068,1 @@\n-        profile_call(callee, recv, NULL, collect_args_for_profiling(args, callee, true), true);\n+        profile_call(callee, recv, nullptr, collect_args_for_profiling(args, callee, true), true);\n@@ -4117,1 +4117,1 @@\n-  assert(cont != NULL, \"continuation must exist (BlockListBuilder starts a new block after a jsr\");\n+  assert(cont != nullptr, \"continuation must exist (BlockListBuilder starts a new block after a jsr\");\n@@ -4130,1 +4130,1 @@\n-  assert(jsr_start_block != NULL, \"jsr start block must exist\");\n+  assert(jsr_start_block != nullptr, \"jsr start block must exist\");\n@@ -4134,1 +4134,1 @@\n-  assert(jsr_start_block->state() == NULL, \"should have fresh jsr starting block\");\n+  assert(jsr_start_block->state() == nullptr, \"should have fresh jsr starting block\");\n@@ -4141,1 +4141,1 @@\n-  scope_data()->set_stream(NULL);\n+  scope_data()->set_stream(nullptr);\n@@ -4156,1 +4156,1 @@\n-  if (cont->state() != NULL) {\n+  if (cont->state() != nullptr) {\n@@ -4184,1 +4184,1 @@\n-  assert(lock != NULL && sync_handler != NULL, \"lock or handler missing\");\n+  assert(lock != nullptr && sync_handler != nullptr, \"lock or handler missing\");\n@@ -4187,1 +4187,1 @@\n-  assert(_last->as_MonitorEnter() != NULL, \"monitor enter expected\");\n+  assert(_last->as_MonitorEnter() != nullptr, \"monitor enter expected\");\n@@ -4212,1 +4212,1 @@\n-  assert(sync_handler != NULL, \"handler missing\");\n+  assert(sync_handler != nullptr, \"handler missing\");\n@@ -4215,1 +4215,1 @@\n-  assert(lock != NULL || default_handler, \"lock or handler missing\");\n+  assert(lock != nullptr || default_handler, \"lock or handler missing\");\n@@ -4291,1 +4291,1 @@\n-  Value recv = NULL;\n+  Value recv = nullptr;\n@@ -4329,1 +4329,1 @@\n-      while (top->caller() != NULL) {\n+      while (top->caller() != nullptr) {\n@@ -4368,1 +4368,1 @@\n-      if (obj_args != NULL) {\n+      if (obj_args != nullptr) {\n@@ -4380,1 +4380,1 @@\n-      profile_call(callee, recv, holder_known ? callee->holder() : NULL, obj_args, true);\n+      profile_call(callee, recv, holder_known ? callee->holder() : nullptr, obj_args, true);\n@@ -4391,1 +4391,1 @@\n-  if (cont == NULL) {\n+  if (cont == nullptr) {\n@@ -4433,2 +4433,2 @@\n-  Value lock = NULL;\n-  BlockBegin* sync_handler = NULL;\n+  Value lock = nullptr;\n+  BlockBegin* sync_handler = nullptr;\n@@ -4455,1 +4455,1 @@\n-  if (callee_start_block != NULL) {\n+  if (callee_start_block != nullptr) {\n@@ -4470,1 +4470,1 @@\n-  scope_data()->set_stream(NULL);\n+  scope_data()->set_stream(nullptr);\n@@ -4474,1 +4474,1 @@\n-  if (log != NULL) log->head(\"parse method='%d'\", log->identify(callee));\n+  if (log != nullptr) log->head(\"parse method='%d'\", log->identify(callee));\n@@ -4478,1 +4478,1 @@\n-  iterate_all_blocks(callee_start_block == NULL);\n+  iterate_all_blocks(callee_start_block == nullptr);\n@@ -4480,1 +4480,1 @@\n-  if (log != NULL) log->done(\"parse\");\n+  if (log != nullptr) log->done(\"parse\");\n@@ -4529,1 +4529,1 @@\n-  if (callee->is_synchronized() && sync_handler->state() != NULL) {\n+  if (callee->is_synchronized() && sync_handler->state() != nullptr) {\n@@ -4606,1 +4606,1 @@\n-            if (obj->exact_type() == NULL &&\n+            if (obj->exact_type() == nullptr &&\n@@ -4619,1 +4619,1 @@\n-              if (obj->exact_type() == NULL &&\n+              if (obj->exact_type() == nullptr &&\n@@ -4658,1 +4658,1 @@\n-  assert(msg != NULL, \"inline bailout msg must exist\");\n+  assert(msg != nullptr, \"inline bailout msg must exist\");\n@@ -4664,1 +4664,1 @@\n-  _inline_bailout_msg = NULL;\n+  _inline_bailout_msg = nullptr;\n@@ -4669,1 +4669,1 @@\n-  ScopeData* data = new ScopeData(NULL);\n+  ScopeData* data = new ScopeData(nullptr);\n@@ -4687,1 +4687,1 @@\n-    blb.bci2block()->at_put(0, NULL);\n+    blb.bci2block()->at_put(0, nullptr);\n@@ -4812,1 +4812,1 @@\n-    Instruction* store = append(new StoreIndexed(array, index, NULL, T_CHAR, value, state_before, false, true));\n+    Instruction* store = append(new StoreIndexed(array, index, nullptr, T_CHAR, value, state_before, false, true));\n@@ -4816,1 +4816,1 @@\n-    Instruction* load = append(new LoadIndexed(array, index, NULL, T_CHAR, state_before, true));\n+    Instruction* load = append(new LoadIndexed(array, index, nullptr, T_CHAR, state_before, true));\n@@ -4824,2 +4824,2 @@\n-  if (log != NULL) {\n-    assert(msg != NULL, \"inlining msg should not be null!\");\n+  if (log != nullptr) {\n+    assert(msg != nullptr, \"inlining msg should not be null!\");\n@@ -4869,1 +4869,1 @@\n-  assert(known_holder == NULL || (known_holder->is_instance_klass() &&\n+  assert(known_holder == nullptr || (known_holder->is_instance_klass() &&\n@@ -4872,2 +4872,2 @@\n-  if (known_holder != NULL) {\n-    if (known_holder->exact_klass() == NULL) {\n+  if (known_holder != nullptr) {\n+    if (known_holder->exact_klass() == nullptr) {\n@@ -4882,2 +4882,2 @@\n-  assert((m == NULL) == (invoke_bci < 0), \"invalid method and invalid bci together\");\n-  if (m == NULL) {\n+  assert((m == nullptr) == (invoke_bci < 0), \"invalid method and invalid bci together\");\n+  if (m == nullptr) {\n@@ -4891,1 +4891,1 @@\n-  if (data != NULL && (data->is_CallTypeData() || data->is_VirtualCallTypeData())) {\n+  if (data != nullptr && (data->is_CallTypeData() || data->is_VirtualCallTypeData())) {\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":260,"deletions":260,"binary":false,"changes":520,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -47,1 +47,1 @@\n-\/\/ To avoid vicious circularities, we initialize ciField::_type to NULL\n+\/\/ To avoid vicious circularities, we initialize ciField::_type to null\n@@ -73,2 +73,2 @@\n-ciField::ciField(ciInstanceKlass* klass, int index) :\n-  _original_holder(NULL), _is_flattened(false), _known_to_link_with_put(NULL), _known_to_link_with_get(NULL) {\n+ciField::ciField(ciInstanceKlass* klass, int index, Bytecodes::Code bc) :\n+  _original_holder(nullptr), _is_flattened(false), _known_to_link_with_put(nullptr), _known_to_link_with_get(nullptr) {\n@@ -85,1 +85,1 @@\n-  Symbol* name  = cpool->name_ref_at(index);\n+  Symbol* name  = cpool->name_ref_at(index, bc);\n@@ -88,1 +88,1 @@\n-  int nt_index = cpool->name_and_type_ref_index_at(index);\n+  int nt_index = cpool->name_and_type_ref_index_at(index, bc);\n@@ -115,1 +115,1 @@\n-  int holder_index = cpool->klass_ref_index_at(index);\n+  int holder_index = cpool->klass_ref_index_at(index, bc);\n@@ -161,1 +161,1 @@\n-  if (canonical_holder == NULL) {\n+  if (canonical_holder == nullptr) {\n@@ -202,1 +202,1 @@\n-    _known_to_link_with_put(NULL), _known_to_link_with_get(NULL) {\n+    _known_to_link_with_put(nullptr), _known_to_link_with_get(nullptr) {\n@@ -217,1 +217,1 @@\n-    _type = NULL;  \/\/ must call compute_type on first access\n+    _type = nullptr;  \/\/ must call compute_type on first access\n@@ -249,1 +249,1 @@\n-  _original_holder = (field->_original_holder != NULL) ? field->_original_holder : field->_holder;\n+  _original_holder = (field->_original_holder != nullptr) ? field->_original_holder : field->_holder;\n@@ -255,1 +255,1 @@\n-  if (holder == NULL)\n+  if (holder == nullptr)\n@@ -296,1 +296,1 @@\n-  _flags = ciFlags(fd->access_flags());\n+  _flags = ciFlags(fd->access_flags(), fd->field_flags().is_stable(), fd->field_status().is_initialized_final_update());\n@@ -299,1 +299,1 @@\n-  assert(field_holder != NULL, \"null field_holder\");\n+  assert(field_holder != nullptr, \"null field_holder\");\n@@ -303,1 +303,1 @@\n-  _original_holder = NULL;\n+  _original_holder = nullptr;\n@@ -317,1 +317,1 @@\n-      assert(vmClasses::System_klass() != NULL, \"Check once per vm\");\n+      assert(vmClasses::System_klass() != nullptr, \"Check once per vm\");\n@@ -336,1 +336,1 @@\n-    assert(vmClasses::CallSite_klass() != NULL, \"should be already initialized\");\n+    assert(vmClasses::CallSite_klass() != nullptr, \"should be already initialized\");\n@@ -358,3 +358,2 @@\n-    VM_ENTRY_MARK;\n-    ciInstance* mirror = CURRENT_ENV->get_instance(_holder->get_Klass()->java_mirror());\n-    _constant_value = mirror->field_value_impl(type()->basic_type(), offset());\n+    ciInstance* mirror = _holder->java_mirror();\n+    _constant_value = mirror->field_value_impl(type()->basic_type(), offset_in_bytes());\n@@ -391,1 +390,1 @@\n-  ciKlass* accessing_klass = (_original_holder != NULL) ? _original_holder : _holder;\n+  ciKlass* accessing_klass = (_original_holder != nullptr) ? _original_holder : _holder;\n@@ -469,1 +468,1 @@\n-  if (callsite_klass == NULL)\n+  if (callsite_klass == nullptr)\n@@ -495,1 +494,1 @@\n-  if (_type != NULL)\n+  if (_type != nullptr)\n","filename":"src\/hotspot\/share\/ci\/ciField.cpp","additions":22,"deletions":23,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -66,1 +66,1 @@\n-  ciField(ciInstanceKlass* klass, int index);\n+  ciField(ciInstanceKlass* klass, int index, Bytecodes::Code bc);\n@@ -110,1 +110,1 @@\n-  ciType* type() { return (_type == NULL) ? compute_type() : _type; }\n+  ciType* type() { return (_type == nullptr) ? compute_type() : _type; }\n@@ -117,1 +117,1 @@\n-  BasicType layout_type() { return type2field[type()->basic_type()]; }\n+  BasicType layout_type() { return type2field[(_type == nullptr) ? T_OBJECT : _type->basic_type()]; }\n@@ -122,2 +122,2 @@\n-  \/\/ What is the offset of this field?\n-  int offset() const {\n+  \/\/ What is the offset of this field? (Fields are aligned to the byte level.)\n+  int offset_in_bytes() const {\n@@ -128,5 +128,0 @@\n-  \/\/ Same question, explicit units.  (Fields are aligned to the byte level.)\n-  int offset_in_bytes() const {\n-    return offset();\n-  }\n-\n@@ -212,1 +207,1 @@\n-  ciMultiField(ciInstanceKlass* klass, int index) : ciField(klass, index) {}\n+  ciMultiField(ciInstanceKlass* klass, int index, Bytecodes::Code bc) : ciField(klass, index, bc) {}\n","filename":"src\/hotspot\/share\/ci\/ciField.hpp","additions":7,"deletions":12,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-    int field_offset = field->offset();\n+    int field_offset = field->offset_in_bytes();\n@@ -67,1 +67,1 @@\n-        int sec_field_offset = sec_field->offset();\n+        int sec_field_offset = sec_field->offset_in_bytes();\n","filename":"src\/hotspot\/share\/ci\/ciInlineKlass.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -72,1 +72,1 @@\n-  _nonstatic_fields = NULL; \/\/ initialized lazily by compute_nonstatic_fields:\n+  _nonstatic_fields = nullptr; \/\/ initialized lazily by compute_nonstatic_fields:\n@@ -74,1 +74,2 @@\n-  _implementor = NULL; \/\/ we will fill these lazily\n+  _implementor = nullptr; \/\/ we will fill these lazily\n+  _transitive_interfaces = nullptr;\n@@ -84,1 +85,1 @@\n-    \/\/ non-strong hidden classes alive (loader == NULL). Klass holder should\n+    \/\/ non-strong hidden classes alive (loader == nullptr). Klass holder should\n@@ -88,1 +89,1 @@\n-    assert(holder != NULL, \"holder of hidden class is the mirror which is never null\");\n+    assert(holder != nullptr, \"holder of hidden class is the mirror which is never null\");\n@@ -109,2 +110,2 @@\n-  _super  = NULL;\n-  _java_mirror = NULL;\n+  _super  = nullptr;\n+  _java_mirror = nullptr;\n@@ -119,1 +120,1 @@\n-  _field_cache = NULL;\n+  _field_cache = nullptr;\n@@ -131,1 +132,1 @@\n-  _nonstatic_fields = NULL;            \/\/ initialized lazily by compute_nonstatic_fields\n+  _nonstatic_fields = nullptr;         \/\/ initialized lazily by compute_nonstatic_fields\n@@ -138,3 +139,3 @@\n-  _super = NULL;\n-  _java_mirror = NULL;\n-  _field_cache = NULL;\n+  _super = nullptr;\n+  _java_mirror = nullptr;\n+  _field_cache = nullptr;\n@@ -160,1 +161,1 @@\n-    _has_subklass = ik->subklass() != NULL ? subklass_true : subklass_false;\n+    _has_subklass = ik->subklass() != nullptr ? subklass_true : subklass_false;\n@@ -197,1 +198,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -199,1 +200,1 @@\n-  if (_field_cache == NULL) {\n+  if (_field_cache == nullptr) {\n@@ -228,1 +229,1 @@\n-  if (field != NULL) {\n+  if (field != nullptr) {\n@@ -234,1 +235,1 @@\n-      if (super == NULL ||\n+      if (super == nullptr ||\n@@ -258,1 +259,1 @@\n-  return _loader == NULL;\n+  return _loader == nullptr;\n@@ -361,1 +362,1 @@\n-  if (_super == NULL && !is_java_lang_Object()) {\n+  if (_super == nullptr && !is_java_lang_Object()) {\n@@ -379,1 +380,1 @@\n-  if (_java_mirror == NULL) {\n+  if (_java_mirror == nullptr) {\n@@ -388,3 +389,3 @@\n-  if (!is_loaded())     return NULL; \/\/ No change if class is not loaded\n-  if (!is_abstract())   return NULL; \/\/ Only applies to abstract classes.\n-  if (!has_subklass())  return NULL; \/\/ Must have at least one subklass.\n+  if (!is_loaded())     return nullptr; \/\/ No change if class is not loaded\n+  if (!is_abstract())   return nullptr; \/\/ Only applies to abstract classes.\n+  if (!has_subklass())  return nullptr; \/\/ Must have at least one subklass.\n@@ -396,1 +397,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -406,1 +407,1 @@\n-  return Dependencies::find_finalizable_subclass(get_instanceKlass()) != NULL;\n+  return Dependencies::find_finalizable_subclass(get_instanceKlass()) != nullptr;\n@@ -439,1 +440,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -445,1 +446,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -452,1 +453,1 @@\n-  if (super() != NULL && super()->has_nonstatic_fields()) {\n+  if (super() != nullptr && super()->has_nonstatic_fields()) {\n@@ -454,1 +455,1 @@\n-    if (f != NULL) {\n+    if (f != nullptr) {\n@@ -471,1 +472,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -481,2 +482,2 @@\n-  if (def == NULL) {\n-    return NULL;\n+  if (def == nullptr) {\n+    return nullptr;\n@@ -499,1 +500,1 @@\n-  if (_nonstatic_fields != NULL)\n+  if (_nonstatic_fields != nullptr)\n@@ -504,1 +505,1 @@\n-    _nonstatic_fields = new (arena) GrowableArray<ciField*>(arena, 0, 0, NULL);\n+    _nonstatic_fields = new (arena) GrowableArray<ciField*>(arena, 0, 0, nullptr);\n@@ -510,2 +511,2 @@\n-  GrowableArray<ciField*>* super_fields = NULL;\n-  if (super != NULL && super->has_nonstatic_fields()) {\n+  GrowableArray<ciField*>* super_fields = nullptr;\n+  if (super != nullptr && super->has_nonstatic_fields()) {\n@@ -514,1 +515,1 @@\n-    assert(super_flen == 0 || super_fields != NULL, \"first get nof_fields\");\n+    assert(super_flen == 0 || super_fields != nullptr, \"first get nof_fields\");\n@@ -517,1 +518,1 @@\n-  GrowableArray<ciField*>* fields = NULL;\n+  GrowableArray<ciField*>* fields = nullptr;\n@@ -522,1 +523,1 @@\n-  if (fields == NULL) {\n+  if (fields == nullptr) {\n@@ -524,1 +525,1 @@\n-    if (super_fields != NULL) {\n+    if (super_fields != nullptr) {\n@@ -540,1 +541,1 @@\n-  GrowableArray<ciField*>* fields = NULL;\n+  GrowableArray<ciField*>* fields = nullptr;\n@@ -550,1 +551,1 @@\n-    return NULL;  \/\/ return nothing if none are locally declared\n+    return nullptr;  \/\/ return nothing if none are locally declared\n@@ -552,1 +553,1 @@\n-  if (super_fields != NULL) {\n+  if (super_fields != nullptr) {\n@@ -555,3 +556,2 @@\n-\n-  fields = new (arena) GrowableArray<ciField*>(arena, flen, 0, NULL);\n-  if (super_fields != NULL) {\n+  fields = new (arena) GrowableArray<ciField*>(arena, flen, 0, nullptr);\n+  if (super_fields != nullptr) {\n@@ -582,1 +582,1 @@\n-        int offset = field_offset + (flattened_field->offset() - vk->first_field_offset());\n+        int offset = field_offset + (flattened_field->offset_in_bytes() - vk->first_field_offset());\n@@ -629,1 +629,1 @@\n-  if (super() != NULL && super()->has_injected_fields()) {\n+  if (super() != nullptr && super()->has_injected_fields()) {\n@@ -650,1 +650,1 @@\n-  if (loader_oop == NULL) {\n+  if (loader_oop == nullptr) {\n@@ -667,1 +667,1 @@\n-  if (m == NULL)  return NULL;\n+  if (m == nullptr)  return nullptr;\n@@ -694,1 +694,1 @@\n-  if (impl == NULL) {\n+  if (impl == nullptr) {\n@@ -700,4 +700,4 @@\n-      MutexLocker ml(Compile_lock);\n-      Klass* k = get_instanceKlass()->implementor();\n-      if (k != NULL) {\n-        if (k == get_instanceKlass()) {\n+      InstanceKlass* ik = get_instanceKlass();\n+      Klass* implk = ik->implementor();\n+      if (implk != nullptr) {\n+        if (implk == ik) {\n@@ -707,1 +707,1 @@\n-          impl = CURRENT_THREAD_ENV->get_instance_klass(k);\n+          impl = CURRENT_THREAD_ENV->get_instance_klass(implk);\n@@ -808,1 +808,1 @@\n-      if (value == NULL) {\n+      if (value == nullptr) {\n@@ -814,1 +814,1 @@\n-          _out->print(\"\\\"%s\\\"\", (ascii_value != NULL) ? ascii_value : \"\");\n+          _out->print(\"\\\"%s\\\"\", (ascii_value != nullptr) ? ascii_value : \"\");\n@@ -842,1 +842,1 @@\n-      assert(k != NULL && !HAS_PENDING_EXCEPTION, \"can resolve klass?\");\n+      assert(k != nullptr && !HAS_PENDING_EXCEPTION, \"can resolve klass?\");\n@@ -867,1 +867,1 @@\n-    if (name != NULL) {\n+    if (name != nullptr) {\n@@ -877,0 +877,26 @@\n+GrowableArray<ciInstanceKlass*>* ciInstanceKlass::transitive_interfaces() const{\n+  if (_transitive_interfaces == nullptr) {\n+    const_cast<ciInstanceKlass*>(this)->compute_transitive_interfaces();\n+  }\n+  return _transitive_interfaces;\n+}\n+\n+void ciInstanceKlass::compute_transitive_interfaces() {\n+  GUARDED_VM_ENTRY(\n+          InstanceKlass* ik = get_instanceKlass();\n+          Array<InstanceKlass*>* interfaces = ik->transitive_interfaces();\n+          int orig_length = interfaces->length();\n+          Arena* arena = CURRENT_ENV->arena();\n+          int transitive_interfaces_len = orig_length + (is_interface() ? 1 : 0);\n+          GrowableArray<ciInstanceKlass*>* transitive_interfaces = new(arena)GrowableArray<ciInstanceKlass*>(arena, transitive_interfaces_len,\n+                                                                                                             0, nullptr);\n+          for (int i = 0; i < orig_length; i++) {\n+            transitive_interfaces->append(CURRENT_ENV->get_instance_klass(interfaces->at(i)));\n+          }\n+          if (is_interface()) {\n+            transitive_interfaces->append(this);\n+          }\n+          _transitive_interfaces = transitive_interfaces;\n+  );\n+}\n+\n@@ -885,1 +911,1 @@\n-  while (sub != NULL) {\n+  while (sub != nullptr) {\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.cpp","additions":87,"deletions":61,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -77,1 +77,1 @@\n-  \/\/   NULL: no implementor.\n+  \/\/   null: no implementor.\n@@ -81,0 +81,1 @@\n+  GrowableArray<ciInstanceKlass*>* _transitive_interfaces;\n@@ -84,0 +85,1 @@\n+  void compute_transitive_interfaces();\n@@ -186,1 +188,1 @@\n-    if (impl == NULL) {\n+    if (impl == nullptr) {\n@@ -215,1 +217,1 @@\n-    if (_nonstatic_fields == NULL) {\n+    if (_nonstatic_fields == nullptr) {\n@@ -233,1 +235,1 @@\n-    assert(_nonstatic_fields != NULL, \"\");\n+    assert(_nonstatic_fields != nullptr, \"\");\n@@ -263,1 +265,1 @@\n-    return (impl != this ? impl : NULL);\n+    return (impl != this ? impl : nullptr);\n@@ -290,1 +292,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -301,0 +303,1 @@\n+  GrowableArray<ciInstanceKlass*>* transitive_interfaces() const;\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.hpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/share\/ci\/ciType.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -52,0 +53,1 @@\n+#include \"oops\/fieldInfo.hpp\"\n@@ -163,2 +165,2 @@\n-  assert(stream != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n@@ -326,1 +328,1 @@\n-        assert(utf8_buffer != NULL, \"null utf8 buffer\");\n+        assert(utf8_buffer != nullptr, \"null utf8 buffer\");\n@@ -340,1 +342,1 @@\n-        if (result == NULL) {\n+        if (result == nullptr) {\n@@ -403,1 +405,1 @@\n-  assert(cp != NULL, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n@@ -407,1 +409,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -431,2 +433,2 @@\n-  assert(cp != NULL, \"invariant\");\n-  assert(stream != NULL, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n@@ -459,2 +461,2 @@\n-        const int klass_ref_index = cp->klass_ref_index_at(index);\n-        const int name_and_type_ref_index = cp->name_and_type_ref_index_at(index);\n+        const int klass_ref_index = cp->uncached_klass_ref_index_at(index);\n+        const int name_and_type_ref_index = cp->uncached_name_and_type_ref_index_at(index);\n@@ -669,1 +671,1 @@\n-          cp->name_and_type_ref_index_at(index);\n+          cp->uncached_name_and_type_ref_index_at(index);\n@@ -692,1 +694,1 @@\n-          cp->name_and_type_ref_index_at(index);\n+          cp->uncached_name_and_type_ref_index_at(index);\n@@ -750,1 +752,1 @@\n-              cp->name_and_type_ref_index_at(ref_index);\n+              cp->uncached_name_and_type_ref_index_at(ref_index);\n@@ -811,12 +813,1 @@\n-  NameSigHash*  _next;             \/\/ Next entry in hash table\n-};\n-\n-static const int HASH_ROW_SIZE = 256;\n-\n-static unsigned int hash(const Symbol* name, const Symbol* sig) {\n-  unsigned int raw_hash = 0;\n-  raw_hash += ((unsigned int)(uintptr_t)name) >> (LogHeapWordSize + 2);\n-  raw_hash += ((unsigned int)(uintptr_t)sig) >> LogHeapWordSize;\n-\n-  return (raw_hash + (unsigned int)(uintptr_t)name) % HASH_ROW_SIZE;\n-}\n+  static const int HASH_ROW_SIZE = 256;\n@@ -825,10 +816,3 @@\n-static void initialize_hashtable(NameSigHash** table) {\n-  memset((void*)table, 0, sizeof(NameSigHash*) * HASH_ROW_SIZE);\n-}\n-\/\/ Return false if the name\/sig combination is found in table.\n-\/\/ Return true if no duplicate is found. And name\/sig is added as a new entry in table.\n-\/\/ The old format checker uses heap sort to find duplicates.\n-\/\/ NOTE: caller should guarantee that GC doesn't happen during the life cycle\n-\/\/ of table since we don't expect Symbol*'s to move.\n-static bool put_after_lookup(const Symbol* name, const Symbol* sig, NameSigHash** table) {\n-  assert(name != NULL, \"name in constant pool is NULL\");\n+  NameSigHash(Symbol* name, Symbol* sig) :\n+    _name(name),\n+    _sig(sig) {}\n@@ -836,8 +820,2 @@\n-  \/\/ First lookup for duplicates\n-  int index = hash(name, sig);\n-  NameSigHash* entry = table[index];\n-  while (entry != NULL) {\n-    if (entry->_name == name && entry->_sig == sig) {\n-      return false;\n-    }\n-    entry = entry->_next;\n+  static unsigned int hash(NameSigHash const& namesig) {\n+    return namesig._name->identity_hash() ^ namesig._sig->identity_hash();\n@@ -846,8 +824,5 @@\n-  \/\/ No duplicate is found, allocate a new entry and fill it.\n-  entry = new NameSigHash();\n-  entry->_name = name;\n-  entry->_sig = sig;\n-\n-  \/\/ Insert into hash table\n-  entry->_next = table[index];\n-  table[index] = entry;\n+  static bool equals(NameSigHash const& e0, NameSigHash const& e1) {\n+    return (e0._name == e1._name) &&\n+          (e0._sig  == e1._sig);\n+  }\n+};\n@@ -855,2 +830,4 @@\n-  return true;\n-}\n+using NameSigHashtable = ResourceHashtable<NameSigHash, int,\n+                                           NameSigHash::HASH_ROW_SIZE,\n+                                           AnyObj::RESOURCE_AREA, mtInternal,\n+                                           &NameSigHash::hash, &NameSigHash::equals>;\n@@ -859,1 +836,1 @@\n-  assert(super_type != NULL,\"Method doesn't support null super type\");\n+  assert(super_type != nullptr,\"Method doesn't support null super type\");\n@@ -898,3 +875,3 @@\n-  assert(stream != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n-  assert(has_nonstatic_concrete_methods != NULL, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(has_nonstatic_concrete_methods != nullptr, \"invariant\");\n@@ -924,15 +901,9 @@\n-    NameSigHash** interface_names = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD,\n-                                                                 NameSigHash*,\n-                                                                 HASH_ROW_SIZE);\n-    initialize_hashtable(interface_names);\n-    bool dup = false;\n-    const Symbol* name = NULL;\n-    {\n-      debug_only(NoSafepointVerifier nsv;)\n-      for (index = 0; index < itfs_len; index++) {\n-        name = cp->klass_name_at(_local_interface_indexes->at(index));\n-        \/\/ If no duplicates, add (name, NULL) in hashtable interface_names.\n-        if (!put_after_lookup(name, NULL, interface_names)) {\n-          dup = true;\n-          break;\n-        }\n+    \/\/ Set containing interface names\n+    ResourceHashtable<Symbol*, int>* interface_names = new ResourceHashtable<Symbol*, int>();\n+    for (index = 0; index < itfs_len; index++) {\n+      Symbol* interface_name = cp->klass_name_at(_local_interface_indexes->at(index));\n+      \/\/ If no duplicates, add (name, nullptr) in hashtable interface_names.\n+      if (!interface_names->put(interface_name, 0)) {\n+        classfile_parse_error(\"Duplicate interface name \\\"%s\\\" in class file %s\",\n+                               interface_name->as_C_string(), THREAD);\n+        return;\n@@ -941,4 +912,0 @@\n-    if (dup) {\n-      classfile_parse_error(\"Duplicate interface name \\\"%s\\\" in class file %s\",\n-                             name->as_C_string(), THREAD);\n-    }\n@@ -1076,2 +1043,2 @@\n-    _field_annotations(NULL),\n-    _field_type_annotations(NULL) {}\n+    _field_annotations(nullptr),\n+    _field_type_annotations(nullptr) {}\n@@ -1109,1 +1076,1 @@\n-  assert(buffer != NULL, \"invariant\");\n+  assert(buffer != nullptr, \"invariant\");\n@@ -1123,1 +1090,1 @@\n-  assert(buffer != NULL, \"invariant\");\n+  assert(buffer != nullptr, \"invariant\");\n@@ -1176,4 +1143,4 @@\n-  assert(cp != NULL, \"invariant\");\n-  assert(buffer != NULL, \"invariant\");\n-  assert(coll != NULL, \"invariant\");\n-  assert(loader_data != NULL, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(buffer != nullptr, \"invariant\");\n+  assert(coll != nullptr, \"invariant\");\n+  assert(loader_data != nullptr, \"invariant\");\n@@ -1213,2 +1180,2 @@\n-    if (aname == NULL)  break;  \/\/ invalid annotation name\n-    const Symbol* member = NULL;\n+    if (aname == nullptr)  break;  \/\/ invalid annotation name\n+    const Symbol* member = nullptr;\n@@ -1218,1 +1185,1 @@\n-      if (member == NULL)  break;  \/\/ invalid member name\n+      if (member == nullptr)  break;  \/\/ invalid member name\n@@ -1272,5 +1239,5 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(constantvalue_index_addr != NULL, \"invariant\");\n-  assert(is_synthetic_addr != NULL, \"invariant\");\n-  assert(generic_signature_index_addr != NULL, \"invariant\");\n-  assert(parsed_annotations != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(constantvalue_index_addr != nullptr, \"invariant\");\n+  assert(is_synthetic_addr != nullptr, \"invariant\");\n+  assert(generic_signature_index_addr != nullptr, \"invariant\");\n+  assert(parsed_annotations != nullptr, \"invariant\");\n@@ -1282,1 +1249,1 @@\n-  const u1* runtime_visible_annotations = NULL;\n+  const u1* runtime_visible_annotations = nullptr;\n@@ -1284,1 +1251,1 @@\n-  const u1* runtime_invisible_annotations = NULL;\n+  const u1* runtime_invisible_annotations = nullptr;\n@@ -1286,1 +1253,1 @@\n-  const u1* runtime_visible_type_annotations = NULL;\n+  const u1* runtime_visible_type_annotations = nullptr;\n@@ -1288,1 +1255,1 @@\n-  const u1* runtime_invisible_type_annotations = NULL;\n+  const u1* runtime_invisible_type_annotations = nullptr;\n@@ -1349,1 +1316,1 @@\n-        if (runtime_visible_annotations != NULL) {\n+        if (runtime_visible_annotations != nullptr) {\n@@ -1356,1 +1323,1 @@\n-        assert(runtime_visible_annotations != NULL, \"null visible annotations\");\n+        assert(runtime_visible_annotations != nullptr, \"null visible annotations\");\n@@ -1375,1 +1342,1 @@\n-          assert(runtime_invisible_annotations != NULL, \"null invisible annotations\");\n+          assert(runtime_invisible_annotations != nullptr, \"null invisible annotations\");\n@@ -1379,1 +1346,1 @@\n-        if (runtime_visible_type_annotations != NULL) {\n+        if (runtime_visible_type_annotations != nullptr) {\n@@ -1386,1 +1353,1 @@\n-        assert(runtime_visible_type_annotations != NULL, \"null visible type annotations\");\n+        assert(runtime_visible_type_annotations != nullptr, \"null visible type annotations\");\n@@ -1399,1 +1366,1 @@\n-          assert(runtime_invisible_type_annotations != NULL, \"null invisible type annotations\");\n+          assert(runtime_invisible_type_annotations != nullptr, \"null invisible type annotations\");\n@@ -1533,4 +1500,4 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(fac != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n-  assert(java_fields_count_ptr != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(fac != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(java_fields_count_ptr != nullptr, \"invariant\");\n@@ -1538,3 +1505,2 @@\n-  assert(NULL == _fields, \"invariant\");\n-  assert(NULL == _fields_annotations, \"invariant\");\n-  assert(NULL == _fields_type_annotations, \"invariant\");\n+  assert(nullptr == _fields_annotations, \"invariant\");\n+  assert(nullptr == _fields_type_annotations, \"invariant\");\n@@ -1556,21 +1522,3 @@\n-  \/\/ The field array starts with tuples of shorts\n-  \/\/ [access, name index, sig index, initial value index, byte offset].\n-  \/\/ A generic signature slot only exists for field with generic\n-  \/\/ signature attribute. And the access flag is set with\n-  \/\/ JVM_ACC_FIELD_HAS_GENERIC_SIGNATURE for that field. The generic\n-  \/\/ signature slots are at the end of the field array and after all\n-  \/\/ other fields data.\n-  \/\/\n-  \/\/   f1: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/   f2: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/       ...\n-  \/\/   fn: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/       [generic signature index]\n-  \/\/       [generic signature index]\n-  \/\/       ...\n-  \/\/\n-  \/\/ Allocate a temporary resource array for field data. For each field,\n-  \/\/ a slot is reserved in the temporary array for the generic signature\n-  \/\/ index. After parsing all fields, the data are copied to a permanent\n-  \/\/ array and any unused slots will be discarded.\n-  ResourceMark rm(THREAD);\n+  \/\/ Allocate a temporary resource array to collect field data.\n+  \/\/ After parsing all fields, data are stored in a UNSIGNED5 compressed stream.\n+  _temp_field_info = new GrowableArray<FieldInfo>(total_fields);\n@@ -1578,2 +1526,2 @@\n-  GrowableArray<FieldInfo>* temp_fieldinfo = new GrowableArray<FieldInfo>(total_fields);\n-  GrowableArray<u2>* temp_generic_signature = new GrowableArray<u2>(total_fields);\n+  int instance_fields_count = 0;\n+  \/\/ ResourceMark rm(THREAD);\n@@ -1581,4 +1529,2 @@\n-  FieldInfo fi;\n-  FieldInfo* f = &fi;\n-  GrowableArray<AnnotationArray*>* fields_annotations = NULL;\n-  GrowableArray<AnnotationArray*>* fields_type_annotations = NULL;\n+  GrowableArray<AnnotationArray*>* fields_annotations = nullptr;\n+  GrowableArray<AnnotationArray*>* fields_type_annotations = nullptr;\n@@ -1586,5 +1532,0 @@\n-\n-  \/\/ The generic signature slots start after all other fields' data.\n-  int generic_signature_slot = total_fields * FieldInfo::field_slots;\n-  int instance_fields_count = 0;\n-  int inj_multifields = 0;\n@@ -1592,0 +1533,1 @@\n+  int inj_multifields = 0;\n@@ -1603,0 +1545,1 @@\n+    FieldInfo::FieldFlags fieldFlags(0);\n@@ -1637,2 +1580,2 @@\n-      if (parsed_annotations.field_annotations() != NULL) {\n-        if (fields_annotations == NULL) {\n+      if (parsed_annotations.field_annotations() != nullptr) {\n+        if (fields_annotations == nullptr) {\n@@ -1642,2 +1585,2 @@\n-        fields_annotations->at_put_grow(field_index, parsed_annotations.field_annotations(), NULL);\n-        parsed_annotations.set_field_annotations(NULL);\n+        fields_annotations->at_put_grow(field_index, parsed_annotations.field_annotations(), nullptr);\n+        parsed_annotations.set_field_annotations(nullptr);\n@@ -1645,2 +1588,2 @@\n-      if (parsed_annotations.field_type_annotations() != NULL) {\n-        if (fields_type_annotations == NULL) {\n+      if (parsed_annotations.field_type_annotations() != nullptr) {\n+        if (fields_type_annotations == nullptr) {\n@@ -1649,2 +1592,2 @@\n-        fields_type_annotations->at_put_grow(field_index, parsed_annotations.field_type_annotations(), NULL);\n-        parsed_annotations.set_field_type_annotations(NULL);\n+        fields_type_annotations->at_put_grow(field_index, parsed_annotations.field_type_annotations(), nullptr);\n+        parsed_annotations.set_field_type_annotations(nullptr);\n@@ -1657,3 +1600,1 @@\n-        access_flags.set_field_has_generic_signature();\n-        temp_generic_signature->append(generic_signature_index);\n-        generic_signature_slot ++;\n+        fieldFlags.update_generic(true);\n@@ -1663,7 +1604,0 @@\n-    f->initialize(access_flags.as_short(),\n-                      name_index,\n-                      signature_index,\n-                      constantvalue_index);\n-    int base_idx = temp_fieldinfo->append(fi);\n-    assert(base_idx == field_index, \"Must be\");\n-    FieldInfo* const field = temp_fieldinfo->adr_at(field_index);\n@@ -1675,6 +1609,8 @@\n-    \/\/ After field is initialized with type, we can augment it with aux info\n-    if (parsed_annotations.has_any_annotations()) {\n-      parsed_annotations.apply_to(field);\n-      if (field->is_contended()) {\n-        _has_contended_fields = true;\n-      }\n+    FieldInfo fi(access_flags, name_index, signature_index, constantvalue_index, fieldFlags);\n+    fi.set_index(field_index);\n+    if (fieldFlags.is_generic()) {\n+      fi.set_generic_signature_index(generic_signature_index);\n+    }\n+    parsed_annotations.apply_to(&fi);\n+    if (fi.field_flags().is_contended()) {\n+      _has_contended_fields = true;\n@@ -1683,0 +1619,4 @@\n+    int base_idx = _temp_field_info->append(fi);\n+    assert(base_idx == field_index, \"Must be\");\n+    FieldInfo* const field = _temp_field_info->adr_at(field_index);\n+\n@@ -1684,1 +1624,1 @@\n-      field->set_multifield_base(true);\n+      field->field_flags_addr()->update_multifield_base(true);\n@@ -1695,7 +1635,1 @@\n-        f->initialize(access_flags.as_short(),\n-                      mfi_idx,\n-                      signature_index,\n-                      constantvalue_index);\n-        int inj_idx = temp_fieldinfo->append(fi);\n-        assert(inj_idx == field_index, \"Must be\");\n-        FieldInfo* const field = temp_fieldinfo->adr_at(inj_idx);\n+\n@@ -1705,2 +1639,13 @@\n-        field->set_multifield(true);\n-        if (fields_annotations != NULL && fields_annotations->at(base_idx) != NULL) {\n+\n+        FieldInfo::FieldFlags fflags(0);\n+        \/\/ fflags.update_injected(true);\n+        AccessFlags aflags;\n+        FieldInfo fi(aflags, (u2)(mfi_idx), (u2)signature_index, 0, fflags);\n+        fi.set_index(field_index);\n+\n+        int inj_idx = _temp_field_info->append(fi);\n+        assert(inj_idx == field_index, \"Must be\");\n+        FieldInfo* const field = _temp_field_info->adr_at(inj_idx);\n+\n+        field->field_flags_addr()->update_multifield(true);\n+        if (fields_annotations != nullptr && fields_annotations->at(base_idx) != nullptr) {\n@@ -1709,1 +1654,1 @@\n-        if (fields_type_annotations != NULL && fields_type_annotations->at(base_idx) != NULL) {\n+        if (fields_type_annotations != nullptr && fields_type_annotations->at(base_idx) != nullptr) {\n@@ -1716,0 +1661,1 @@\n+  assert(_temp_field_info->length() == (length + inj_multifields), \"Must be\");\n@@ -1727,1 +1673,1 @@\n-          const FieldInfo* const f = temp_fieldinfo->adr_at(i);\n+          const FieldInfo* const f = _temp_field_info->adr_at(i);\n@@ -1736,0 +1682,1 @@\n+          \/\/ These will be removed from the field array at the end\n@@ -1741,4 +1688,6 @@\n-      f->initialize((u2)JVM_ACC_FIELD_INTERNAL,\n-                        (u2)(injected[n].name_index),\n-                        (u2)(injected[n].signature_index),\n-                        0);\n+      FieldInfo::FieldFlags fflags(0);\n+      fflags.update_injected(true);\n+      AccessFlags aflags;\n+      FieldInfo fi(aflags, (u2)(injected[n].name_index), (u2)(injected[n].signature_index), 0, fflags);\n+      fi.set_index(field_index);\n+\n@@ -1746,1 +1695,1 @@\n-      int inj_idx = temp_fieldinfo->append(fi);\n+      int inj_idx = _temp_field_info->append(fi);\n@@ -1749,2 +1698,1 @@\n-      const BasicType type = Signature::basic_type(injected[n].signature());\n-\n+      const BasicType type = Signature::basic_type(injected[n].signature());\n@@ -1758,4 +1706,11 @@\n-    f->initialize(JVM_ACC_FIELD_INTERNAL | JVM_ACC_STATIC,\n-                      (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(default_value_name)),\n-                      (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(object_signature)),\n-                      0);\n+    \/\/ Inject static \".default\" field\n+    FieldInfo::FieldFlags fflags(0);\n+    fflags.update_injected(true);\n+    AccessFlags aflags(JVM_ACC_STATIC);\n+    FieldInfo fi(aflags,\n+                 (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(default_value_name)),\n+                 (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(object_signature)),\n+                 0,\n+                 fflags);\n+    fi.set_index(index);\n+\n@@ -1763,1 +1718,1 @@\n-    int inj_idx = temp_fieldinfo->append(fi);\n+    int inj_idx = _temp_field_info->append(fi);\n@@ -1765,0 +1720,1 @@\n+\n@@ -1771,0 +1727,1 @@\n+    \/\/ Inject \".empty\" dummy field\n@@ -1772,4 +1729,11 @@\n-    f->initialize(JVM_ACC_FIELD_INTERNAL,\n-        (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(empty_marker_name)),\n-        (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(byte_signature)),\n-        0);\n+\n+    FieldInfo::FieldFlags fflags(0);\n+    fflags.update_injected(true);\n+    AccessFlags aflags;\n+    FieldInfo fi(aflags,\n+                 (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(empty_marker_name)),\n+                 (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(byte_signature)),\n+                 0,\n+                 fflags);\n+    fi.set_index(index);\n+\n@@ -1777,1 +1741,1 @@\n-    int inj_idx = temp_fieldinfo->append(fi);\n+    int inj_idx = _temp_field_info->append(fi);\n@@ -1779,0 +1743,1 @@\n+\n@@ -1788,27 +1753,1 @@\n-  assert(NULL == _fields, \"invariant\");\n-  assert(index == field_index + 1, \"Must be\");\n-  assert(temp_fieldinfo->length() == field_index + 1, \"Must be\");\n-\n-  _fields =\n-    MetadataFactory::new_array<u2>(_loader_data,\n-                                   temp_fieldinfo->length() * FieldInfo::field_slots + temp_generic_signature->length(),\n-                                   CHECK);\n-  \/\/ Sometimes injected fields already exist in the Java source so\n-  \/\/ the fields array could be too long.  In that case the\n-  \/\/ fields array is trimmed. Also unused slots that were reserved\n-  \/\/ for generic signature indexes are discarded.\n-  {\n-    int i = 0;\n-    for (i = 0; i < index; i++) {\n-      u2* adr = (u2*)temp_fieldinfo->adr_at(i);\n-      for (int j = 0; j < FieldInfo::field_slots; j++) {\n-        _fields->at_put(i * FieldInfo::field_slots + j, adr[j]);\n-      }\n-    }\n-    i = index * FieldInfo::field_slots;\n-    for (int j = 0; j < temp_generic_signature->length(); j++) {\n-      _fields->at_put(i++, temp_generic_signature->at(j));\n-    }\n-\n-    assert(_fields->length() == i, \"\");\n-  }\n+  assert(_temp_field_info->length() == index, \"Must be\");\n@@ -1817,1 +1756,3 @@\n-    _multifield_info = MetadataFactory::new_array<MultiFieldInfo>(_loader_data, temp_multifield_info->length(), CHECK);\n+    _multifield_info = MetadataFactory::new_array<MultiFieldInfo>(_loader_data,\n+                                                                  temp_multifield_info->length(),\n+                                                                  CHECK);\n@@ -1823,4 +1764,5 @@\n-  if (fields_annotations != NULL) {\n-    _fields_annotations = MetadataFactory::new_array<AnnotationArray*>(\n-                                             _loader_data, temp_fieldinfo->length(), NULL,\n-                                             CHECK);\n+  if (fields_annotations != nullptr) {\n+    _fields_annotations = MetadataFactory::new_array<AnnotationArray*>(_loader_data,\n+                                                                       _temp_field_info->length(),\n+                                                                       nullptr,\n+                                                                       CHECK);\n@@ -1832,4 +1774,5 @@\n-  if (fields_type_annotations != NULL) {\n-     _fields_type_annotations = MetadataFactory::new_array<AnnotationArray*>(\n-                                             _loader_data, temp_fieldinfo->length(), NULL,\n-                                             CHECK);\n+  if (fields_type_annotations != nullptr) {\n+     _fields_type_annotations = MetadataFactory::new_array<AnnotationArray*>(_loader_data,\n+                                                                             _temp_field_info->length(),\n+                                                                             nullptr,\n+                                                                             CHECK);\n@@ -1844,16 +1787,10 @@\n-    NameSigHash** names_and_sigs = NEW_RESOURCE_ARRAY_IN_THREAD(\n-      THREAD, NameSigHash*, HASH_ROW_SIZE);\n-    initialize_hashtable(names_and_sigs);\n-    bool dup = false;\n-    const Symbol* name = NULL;\n-    const Symbol* sig = NULL;\n-    {\n-      debug_only(NoSafepointVerifier nsv;)\n-      for (AllFieldStream fs(_fields, cp, _multifield_info); !fs.done(); fs.next()) {\n-        name = fs.name();\n-        sig = fs.signature();\n-        \/\/ If no duplicates, add name\/signature in hashtable names_and_sigs.\n-        if (!put_after_lookup(name, sig, names_and_sigs)) {\n-          dup = true;\n-          break;\n-        }\n+    \/\/ Set containing name-signature pairs\n+    NameSigHashtable* names_and_sigs = new NameSigHashtable();\n+    for (int i = 0; i < _temp_field_info->length(); i++) {\n+      NameSigHash name_and_sig(_temp_field_info->adr_at(i)->name(_multifield_info, _cp),\n+                               _temp_field_info->adr_at(i)->signature(_cp));\n+      \/\/ If no duplicates, add name\/signature in hashtable names_and_sigs.\n+      if(!names_and_sigs->put(name_and_sig, 0)) {\n+        classfile_parse_error(\"Duplicate field name \\\"%s\\\" with signature \\\"%s\\\" in class file %s\",\n+                               name_and_sig._name->as_C_string(), name_and_sig._sig->as_klass_external_name(), THREAD);\n+        return;\n@@ -1862,4 +1799,0 @@\n-    if (dup) {\n-      classfile_parse_error(\"Duplicate field name \\\"%s\\\" with signature \\\"%s\\\" in class file %s\",\n-                             name->as_C_string(), sig->as_klass_external_name(), THREAD);\n-    }\n@@ -1874,1 +1807,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -1877,1 +1810,1 @@\n-  assert(exception_table_start != NULL, \"null exception table\");\n+  assert(exception_table_start != nullptr, \"null exception table\");\n@@ -1926,1 +1859,1 @@\n-  if ((*write_stream) == NULL) {\n+  if ((*write_stream) == nullptr) {\n@@ -2015,1 +1948,1 @@\n-  assert(localvariable_table_start != NULL, \"null local variable table\");\n+  assert(localvariable_table_start != nullptr, \"null local variable table\");\n@@ -2033,1 +1966,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2039,1 +1972,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2072,2 +2005,1 @@\n-                                      bool need_verify,\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -2077,1 +2009,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -2081,1 +2013,1 @@\n-  assert(stackmap_table_start != NULL, \"null stackmap table\");\n+  assert(stackmap_table_start != nullptr, \"null stackmap table\");\n@@ -2083,1 +2015,1 @@\n-  \/\/ check code_attribute_length first\n+  \/\/ check code_attribute_length\n@@ -2086,3 +2018,0 @@\n-  if (!need_verify && !DumpSharedSpaces) {\n-    return NULL;\n-  }\n@@ -2096,2 +2025,2 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(checked_exceptions_length != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(checked_exceptions_length != nullptr, \"invariant\");\n@@ -2104,1 +2033,1 @@\n-  assert(checked_exceptions_start != NULL, \"null checked exceptions\");\n+  assert(checked_exceptions_start != nullptr, \"null checked exceptions\");\n@@ -2133,2 +2062,2 @@\n-  assert(name != NULL, \"invariant\");\n-  assert(sig != NULL, \"invariant\");\n+  assert(name != nullptr, \"invariant\");\n+  assert(sig != nullptr, \"invariant\");\n@@ -2246,0 +2175,1 @@\n+    \/\/ Setting the contended group also sets the contended bit in field flags\n@@ -2248,1 +2178,1 @@\n-    f->set_stable(true);\n+    (f->field_flags_addr())->update_stable(true);\n@@ -2259,1 +2189,1 @@\n-    m->set_caller_sensitive(true);\n+    m->set_caller_sensitive();\n@@ -2261,1 +2191,1 @@\n-    m->set_force_inline(true);\n+    m->set_force_inline();\n@@ -2263,1 +2193,1 @@\n-    m->set_dont_inline(true);\n+    m->set_dont_inline();\n@@ -2265,1 +2195,1 @@\n-    m->set_changes_current_thread(true);\n+    m->set_changes_current_thread();\n@@ -2267,1 +2197,1 @@\n-    m->set_jvmti_mount_transition(true);\n+    m->set_jvmti_mount_transition();\n@@ -2269,1 +2199,1 @@\n-    m->set_has_injected_profile(true);\n+    m->set_has_injected_profile();\n@@ -2273,1 +2203,1 @@\n-    m->set_hidden(true);\n+    m->set_is_hidden();\n@@ -2275,1 +2205,1 @@\n-    m->set_scoped(true);\n+    m->set_scoped();\n@@ -2277,1 +2207,1 @@\n-    m->set_intrinsic_candidate(true);\n+    m->set_intrinsic_candidate();\n@@ -2279,1 +2209,1 @@\n-    m->set_has_reserved_stack_access(true);\n+    m->set_has_reserved_stack_access();\n@@ -2283,1 +2213,1 @@\n-  assert(ik != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n@@ -2359,1 +2289,1 @@\n-      if (entry == NULL) {\n+      if (entry == nullptr) {\n@@ -2424,1 +2354,1 @@\n-                             NULL,\n+                             nullptr,\n@@ -2447,3 +2377,1 @@\n-\/\/ The promoted_flags parameter is used to pass relevant access_flags\n-\/\/ from the method back up to the containing klass. These flag values\n-\/\/ are added to klass's access_flags.\n+\/\/ The has_localvariable_table parameter is used to pass up the value to InstanceKlass.\n@@ -2456,1 +2384,1 @@\n-                                      AccessFlags* const promoted_flags,\n+                                      bool* const has_localvariable_table,\n@@ -2458,3 +2386,3 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n-  assert(promoted_flags != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(has_localvariable_table != nullptr, \"invariant\");\n@@ -2493,1 +2421,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -2554,1 +2482,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2565,1 +2493,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -2577,1 +2505,1 @@\n-  const unsafe_u2* exception_table_start = NULL; \/\/ (potentially unaligned) pointer to array of u2 elements\n+  const unsafe_u2* exception_table_start = nullptr; \/\/ (potentially unaligned) pointer to array of u2 elements\n@@ -2580,2 +2508,2 @@\n-  const unsafe_u2* checked_exceptions_start = NULL; \/\/ (potentially unaligned) pointer to array of u2 elements\n-  CompressedLineNumberWriteStream* linenumber_table = NULL;\n+  const unsafe_u2* checked_exceptions_start = nullptr; \/\/ (potentially unaligned) pointer to array of u2 elements\n+  CompressedLineNumberWriteStream* linenumber_table = nullptr;\n@@ -2589,4 +2517,4 @@\n-  u2* localvariable_table_length = NULL;\n-  const unsafe_u2** localvariable_table_start = NULL; \/\/ (potentially unaligned) pointer to array of LVT attributes\n-  u2* localvariable_type_table_length = NULL;\n-  const unsafe_u2** localvariable_type_table_start = NULL; \/\/ (potentially unaligned) pointer to LVTT attributes\n+  u2* localvariable_table_length = nullptr;\n+  const unsafe_u2** localvariable_table_start = nullptr; \/\/ (potentially unaligned) pointer to array of LVT attributes\n+  u2* localvariable_type_table_length = nullptr;\n+  const unsafe_u2** localvariable_type_table_start = nullptr; \/\/ (potentially unaligned) pointer to LVTT attributes\n@@ -2594,1 +2522,1 @@\n-  const u1* method_parameters_data = NULL;\n+  const u1* method_parameters_data = nullptr;\n@@ -2600,1 +2528,1 @@\n-  const u1* stackmap_data = NULL;\n+  const u1* stackmap_data = nullptr;\n@@ -2604,1 +2532,1 @@\n-  const u1* runtime_visible_annotations = NULL;\n+  const u1* runtime_visible_annotations = nullptr;\n@@ -2606,1 +2534,1 @@\n-  const u1* runtime_invisible_annotations = NULL;\n+  const u1* runtime_invisible_annotations = nullptr;\n@@ -2608,1 +2536,1 @@\n-  const u1* runtime_visible_parameter_annotations = NULL;\n+  const u1* runtime_visible_parameter_annotations = nullptr;\n@@ -2610,1 +2538,1 @@\n-  const u1* runtime_invisible_parameter_annotations = NULL;\n+  const u1* runtime_invisible_parameter_annotations = nullptr;\n@@ -2612,1 +2540,1 @@\n-  const u1* runtime_visible_type_annotations = NULL;\n+  const u1* runtime_visible_type_annotations = nullptr;\n@@ -2614,1 +2542,1 @@\n-  const u1* runtime_invisible_type_annotations = NULL;\n+  const u1* runtime_invisible_type_annotations = nullptr;\n@@ -2619,1 +2547,1 @@\n-  const u1* annotation_default = NULL;\n+  const u1* annotation_default = nullptr;\n@@ -2645,1 +2573,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2664,1 +2592,1 @@\n-      assert(code_start != NULL, \"null code start\");\n+      assert(code_start != nullptr, \"null code start\");\n@@ -2778,1 +2706,1 @@\n-            return NULL;\n+            return nullptr;\n@@ -2780,1 +2708,1 @@\n-          stackmap_data = parse_stackmap_table(cfs, code_attribute_length, _need_verify, CHECK_NULL);\n+          stackmap_data = parse_stackmap_table(cfs, code_attribute_length, CHECK_NULL);\n@@ -2799,1 +2727,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2812,1 +2740,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2821,1 +2749,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2834,1 +2762,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2843,1 +2771,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2851,1 +2779,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2857,1 +2785,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2861,1 +2789,1 @@\n-        if (runtime_visible_annotations != NULL) {\n+        if (runtime_visible_annotations != nullptr) {\n@@ -2865,1 +2793,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2869,1 +2797,1 @@\n-        assert(runtime_visible_annotations != NULL, \"null visible annotations\");\n+        assert(runtime_visible_annotations != nullptr, \"null visible annotations\");\n@@ -2883,1 +2811,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2889,1 +2817,1 @@\n-          assert(runtime_invisible_annotations != NULL, \"null invisible annotations\");\n+          assert(runtime_invisible_annotations != nullptr, \"null invisible annotations\");\n@@ -2893,1 +2821,1 @@\n-        if (runtime_visible_parameter_annotations != NULL) {\n+        if (runtime_visible_parameter_annotations != nullptr) {\n@@ -2897,1 +2825,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2901,1 +2829,1 @@\n-        assert(runtime_visible_parameter_annotations != NULL, \"null visible parameter annotations\");\n+        assert(runtime_visible_parameter_annotations != nullptr, \"null visible parameter annotations\");\n@@ -2908,1 +2836,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2914,1 +2842,1 @@\n-          assert(runtime_invisible_parameter_annotations != NULL,\n+          assert(runtime_invisible_parameter_annotations != nullptr,\n@@ -2919,1 +2847,1 @@\n-        if (annotation_default != NULL) {\n+        if (annotation_default != nullptr) {\n@@ -2923,1 +2851,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2927,1 +2855,1 @@\n-        assert(annotation_default != NULL, \"null annotation default\");\n+        assert(annotation_default != nullptr, \"null annotation default\");\n@@ -2930,1 +2858,1 @@\n-        if (runtime_visible_type_annotations != NULL) {\n+        if (runtime_visible_type_annotations != nullptr) {\n@@ -2934,1 +2862,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2938,1 +2866,1 @@\n-        assert(runtime_visible_type_annotations != NULL, \"null visible type annotations\");\n+        assert(runtime_visible_type_annotations != nullptr, \"null visible type annotations\");\n@@ -2946,1 +2874,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2953,1 +2881,1 @@\n-          assert(runtime_invisible_type_annotations != NULL, \"null invisible type annotations\");\n+          assert(runtime_invisible_type_annotations != nullptr, \"null invisible type annotations\");\n@@ -2966,1 +2894,1 @@\n-  if (linenumber_table != NULL) {\n+  if (linenumber_table != nullptr) {\n@@ -3017,1 +2945,1 @@\n-  if (stackmap_data != NULL) {\n+  if (stackmap_data != nullptr) {\n@@ -3028,1 +2956,1 @@\n-  if (linenumber_table != NULL) {\n+  if (linenumber_table != nullptr) {\n@@ -3063,1 +2991,1 @@\n-    promoted_flags->set_has_localvariable_table();\n+    *has_localvariable_table = true;\n@@ -3078,1 +3006,1 @@\n-    m->set_hidden(true);\n+    m->set_is_hidden();\n@@ -3119,3 +3047,0 @@\n-\/\/ The promoted_flags parameter is used to pass relevant access_flags\n-\/\/ from the methods back up to the containing klass. These flag values\n-\/\/ are added to klass's access_flags.\n@@ -3127,1 +3052,1 @@\n-                                    AccessFlags* promoted_flags,\n+                                    bool* const has_localvariable_table,\n@@ -3131,4 +3056,4 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(promoted_flags != NULL, \"invariant\");\n-  assert(has_final_method != NULL, \"invariant\");\n-  assert(declares_nonstatic_concrete_methods != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(has_localvariable_table != nullptr, \"invariant\");\n+  assert(has_final_method != nullptr, \"invariant\");\n+  assert(declares_nonstatic_concrete_methods != nullptr, \"invariant\");\n@@ -3136,1 +3061,1 @@\n-  assert(NULL == _methods, \"invariant\");\n+  assert(nullptr == _methods, \"invariant\");\n@@ -3145,1 +3070,1 @@\n-                                                   NULL,\n+                                                   nullptr,\n@@ -3154,1 +3079,1 @@\n-                                    promoted_flags,\n+                                    has_localvariable_table,\n@@ -3172,17 +3097,10 @@\n-      NameSigHash** names_and_sigs = NEW_RESOURCE_ARRAY_IN_THREAD(\n-        THREAD, NameSigHash*, HASH_ROW_SIZE);\n-      initialize_hashtable(names_and_sigs);\n-      bool dup = false;\n-      const Symbol* name = NULL;\n-      const Symbol* sig = NULL;\n-      {\n-        debug_only(NoSafepointVerifier nsv;)\n-        for (int i = 0; i < length; i++) {\n-          const Method* const m = _methods->at(i);\n-          name = m->name();\n-          sig = m->signature();\n-          \/\/ If no duplicates, add name\/signature in hashtable names_and_sigs.\n-          if (!put_after_lookup(name, sig, names_and_sigs)) {\n-            dup = true;\n-            break;\n-          }\n+      \/\/ Set containing name-signature pairs\n+      NameSigHashtable* names_and_sigs = new NameSigHashtable();\n+      for (int i = 0; i < length; i++) {\n+        const Method* const m = _methods->at(i);\n+        NameSigHash name_and_sig(m->name(), m->signature());\n+        \/\/ If no duplicates, add name\/signature in hashtable names_and_sigs.\n+        if(!names_and_sigs->put(name_and_sig, 0)) {\n+          classfile_parse_error(\"Duplicate method name \\\"%s\\\" with signature \\\"%s\\\" in class file %s\",\n+                                 name_and_sig._name->as_C_string(), name_and_sig._sig->as_klass_external_name(), THREAD);\n+          return;\n@@ -3191,4 +3109,0 @@\n-      if (dup) {\n-        classfile_parse_error(\"Duplicate method name \\\"%s\\\" with signature \\\"%s\\\" in class file %s\",\n-                               name->as_C_string(), sig->as_klass_external_name(), THREAD);\n-      }\n@@ -3217,1 +3131,1 @@\n-  intArray* method_ordering = NULL;\n+  intArray* method_ordering = nullptr;\n@@ -3236,1 +3150,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -3250,1 +3164,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -3264,1 +3178,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -3267,1 +3181,1 @@\n-  assert(sde_buffer != NULL, \"null sde buffer\");\n+  assert(sde_buffer != nullptr, \"null sde buffer\");\n@@ -3377,1 +3291,1 @@\n-  if (inner_classes_attribute_start != NULL) {\n+  if (inner_classes_attribute_start != nullptr) {\n@@ -3413,1 +3327,1 @@\n-    const Symbol* outer_class_name = NULL;\n+    const Symbol* outer_class_name = nullptr;\n@@ -3502,1 +3416,1 @@\n-  if (nest_members_attribute_start != NULL) {\n+  if (nest_members_attribute_start != nullptr) {\n@@ -3534,1 +3448,1 @@\n-  if (permitted_subclasses_attribute_start != NULL) {\n+  if (permitted_subclasses_attribute_start != nullptr) {\n@@ -3568,1 +3482,1 @@\n-  if (preload_attribute_start != NULL) {\n+  if (preload_attribute_start != nullptr) {\n@@ -3615,1 +3529,1 @@\n-  if (record_attribute_start != NULL) {\n+  if (record_attribute_start != nullptr) {\n@@ -3623,1 +3537,1 @@\n-    MetadataFactory::new_array<RecordComponent*>(_loader_data, components_count, NULL, CHECK_0);\n+    MetadataFactory::new_array<RecordComponent*>(_loader_data, components_count, nullptr, CHECK_0);\n@@ -3646,1 +3560,1 @@\n-    const u1* runtime_visible_annotations = NULL;\n+    const u1* runtime_visible_annotations = nullptr;\n@@ -3648,1 +3562,1 @@\n-    const u1* runtime_invisible_annotations = NULL;\n+    const u1* runtime_invisible_annotations = nullptr;\n@@ -3651,1 +3565,1 @@\n-    const u1* runtime_visible_type_annotations = NULL;\n+    const u1* runtime_visible_type_annotations = nullptr;\n@@ -3653,1 +3567,1 @@\n-    const u1* runtime_invisible_type_annotations = NULL;\n+    const u1* runtime_invisible_type_annotations = nullptr;\n@@ -3686,1 +3600,1 @@\n-        if (runtime_visible_annotations != NULL) {\n+        if (runtime_visible_annotations != nullptr) {\n@@ -3694,1 +3608,1 @@\n-        assert(runtime_visible_annotations != NULL, \"null record component visible annotation\");\n+        assert(runtime_visible_annotations != nullptr, \"null record component visible annotation\");\n@@ -3708,1 +3622,1 @@\n-          assert(runtime_invisible_annotations != NULL, \"null record component invisible annotation\");\n+          assert(runtime_invisible_annotations != nullptr, \"null record component invisible annotation\");\n@@ -3713,1 +3627,1 @@\n-        if (runtime_visible_type_annotations != NULL) {\n+        if (runtime_visible_type_annotations != nullptr) {\n@@ -3721,1 +3635,1 @@\n-        assert(runtime_visible_type_annotations != NULL, \"null record component visible type annotation\");\n+        assert(runtime_visible_type_annotations != nullptr, \"null record component visible type annotation\");\n@@ -3735,1 +3649,1 @@\n-          assert(runtime_invisible_type_annotations != NULL, \"null record component invisible type annotation\");\n+          assert(runtime_invisible_type_annotations != nullptr, \"null record component invisible type annotation\");\n@@ -3774,1 +3688,1 @@\n-  assert(cfs != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n@@ -3788,2 +3702,2 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n@@ -3870,3 +3784,3 @@\n-  assert(cfs != NULL, \"invariant\");\n-  assert(cp != NULL, \"invariant\");\n-  assert(parsed_annotations != NULL, \"invariant\");\n+  assert(cfs != nullptr, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(parsed_annotations != nullptr, \"invariant\");\n@@ -3893,1 +3807,1 @@\n-  const u1* runtime_visible_annotations = NULL;\n+  const u1* runtime_visible_annotations = nullptr;\n@@ -3895,1 +3809,1 @@\n-  const u1* runtime_invisible_annotations = NULL;\n+  const u1* runtime_invisible_annotations = nullptr;\n@@ -3897,1 +3811,1 @@\n-  const u1* runtime_visible_type_annotations = NULL;\n+  const u1* runtime_visible_type_annotations = nullptr;\n@@ -3899,1 +3813,1 @@\n-  const u1* runtime_invisible_type_annotations = NULL;\n+  const u1* runtime_invisible_type_annotations = nullptr;\n@@ -3904,1 +3818,1 @@\n-  const u1* inner_classes_attribute_start = NULL;\n+  const u1* inner_classes_attribute_start = nullptr;\n@@ -3908,1 +3822,1 @@\n-  const u1* nest_members_attribute_start = NULL;\n+  const u1* nest_members_attribute_start = nullptr;\n@@ -3910,1 +3824,1 @@\n-  const u1* record_attribute_start = NULL;\n+  const u1* record_attribute_start = nullptr;\n@@ -3912,1 +3826,1 @@\n-  const u1* permitted_subclasses_attribute_start = NULL;\n+  const u1* permitted_subclasses_attribute_start = nullptr;\n@@ -3914,1 +3828,1 @@\n-  const u1* preload_attribute_start = NULL;\n+  const u1* preload_attribute_start = nullptr;\n@@ -3992,1 +3906,1 @@\n-        if (runtime_visible_annotations != NULL) {\n+        if (runtime_visible_annotations != nullptr) {\n@@ -3999,1 +3913,1 @@\n-        assert(runtime_visible_annotations != NULL, \"null visible annotations\");\n+        assert(runtime_visible_annotations != nullptr, \"null visible annotations\");\n@@ -4018,1 +3932,1 @@\n-          assert(runtime_invisible_annotations != NULL, \"null invisible annotations\");\n+          assert(runtime_invisible_annotations != nullptr, \"null invisible annotations\");\n@@ -4056,1 +3970,1 @@\n-        if (runtime_visible_type_annotations != NULL) {\n+        if (runtime_visible_type_annotations != nullptr) {\n@@ -4063,1 +3977,1 @@\n-        assert(runtime_visible_type_annotations != NULL, \"null visible type annotations\");\n+        assert(runtime_visible_type_annotations != nullptr, \"null visible type annotations\");\n@@ -4077,1 +3991,1 @@\n-          assert(runtime_invisible_type_annotations != NULL, \"null invisible type annotations\");\n+          assert(runtime_invisible_type_annotations != nullptr, \"null invisible type annotations\");\n@@ -4250,1 +4164,1 @@\n-  assert(k != NULL, \"invariant\");\n+  assert(k != nullptr, \"invariant\");\n@@ -4260,1 +4174,1 @@\n-  if (_sde_buffer != NULL) {\n+  if (_sde_buffer != nullptr) {\n@@ -4268,4 +4182,4 @@\n-    if (_class_annotations == NULL &&\n-        _class_type_annotations == NULL &&\n-        _fields_annotations == NULL &&\n-        _fields_type_annotations == NULL) {\n+    if (_class_annotations == nullptr &&\n+        _class_type_annotations == nullptr &&\n+        _fields_annotations == nullptr &&\n+        _fields_type_annotations == nullptr) {\n@@ -4288,4 +4202,4 @@\n-    _class_annotations       = NULL;\n-    _class_type_annotations  = NULL;\n-    _fields_annotations      = NULL;\n-    _fields_type_annotations = NULL;\n+    _class_annotations       = nullptr;\n+    _class_type_annotations  = nullptr;\n+    _fields_annotations      = nullptr;\n+    _fields_type_annotations = nullptr;\n@@ -4298,1 +4212,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4302,1 +4216,0 @@\n-  this_klass->set_fields(_fields, java_fields_count);\n@@ -4304,0 +4217,2 @@\n+  this_klass->set_fieldinfo_stream(_fieldinfo_stream);\n+  this_klass->set_fields_status(_fields_status);\n@@ -4329,3 +4244,3 @@\n-  AnnotationArray* annotations = NULL;\n-  if (runtime_visible_annotations != NULL ||\n-      runtime_invisible_annotations != NULL) {\n+  AnnotationArray* annotations = nullptr;\n+  if (runtime_visible_annotations != nullptr ||\n+      runtime_invisible_annotations != nullptr) {\n@@ -4336,1 +4251,1 @@\n-    if (runtime_visible_annotations != NULL) {\n+    if (runtime_visible_annotations != nullptr) {\n@@ -4341,1 +4256,1 @@\n-    if (runtime_invisible_annotations != NULL) {\n+    if (runtime_invisible_annotations != nullptr) {\n@@ -4355,2 +4270,2 @@\n-  assert(cp != NULL, \"invariant\");\n-  const InstanceKlass* super_klass = NULL;\n+  assert(cp != nullptr, \"invariant\");\n+  const InstanceKlass* super_klass = nullptr;\n@@ -4385,1 +4300,1 @@\n-    _nonstatic_oop_maps = NULL;\n+    _nonstatic_oop_maps = nullptr;\n@@ -4503,1 +4418,1 @@\n-  if (name == NULL || sig == NULL) {\n+  if (name == nullptr || sig == nullptr) {\n@@ -4517,1 +4432,1 @@\n-  assert(ik != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n@@ -4519,1 +4434,1 @@\n-  const Klass* const super = ik->super();\n+  const InstanceKlass* const super = ik->java_super();\n@@ -4525,1 +4440,1 @@\n-        (super != NULL && super->has_finalizer())) {\n+        (super != nullptr && super->has_finalizer())) {\n@@ -4535,1 +4450,1 @@\n-      (m != NULL) && !m->is_empty_method()) {\n+      (m != nullptr) && !m->is_empty_method()) {\n@@ -4560,1 +4475,1 @@\n-  if (super == NULL) {\n+  if (super == nullptr) {\n@@ -4574,1 +4489,1 @@\n-      if (constructor != NULL && constructor->is_vanilla_constructor()) {\n+      if (constructor != nullptr && constructor->is_vanilla_constructor()) {\n@@ -4587,1 +4502,1 @@\n-      || (ik->name() == vmSymbols::java_lang_Class() && ik->class_loader() == NULL)\n+      || (ik->name() == vmSymbols::java_lang_Class() && ik->class_loader() == nullptr)\n@@ -4618,2 +4533,2 @@\n-  assert(local_ifs != NULL, \"invariant\");\n-  assert(loader_data != NULL, \"invariant\");\n+  assert(local_ifs != nullptr, \"invariant\");\n+  assert(loader_data != nullptr, \"invariant\");\n@@ -4625,1 +4540,1 @@\n-  if (super != NULL) {\n+  if (super != nullptr) {\n@@ -4653,1 +4568,1 @@\n-    if (super != NULL) {\n+    if (super != nullptr) {\n@@ -4673,1 +4588,1 @@\n-      assert(e != NULL, \"just checking\");\n+      assert(e != nullptr, \"just checking\");\n@@ -4681,1 +4596,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4684,1 +4599,1 @@\n-  if (super != NULL) {\n+  if (super != nullptr) {\n@@ -4712,1 +4627,1 @@\n-      if (super_package != NULL &&\n+      if (super_package != nullptr &&\n@@ -4734,1 +4649,1 @@\n-      if (msg == NULL) {\n+      if (msg == nullptr) {\n@@ -4760,1 +4675,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4765,1 +4680,1 @@\n-    assert (k != NULL && k->is_interface(), \"invalid interface\");\n+    assert (k != nullptr && k->is_interface(), \"invalid interface\");\n@@ -4782,1 +4697,1 @@\n-      if (msg == NULL) {\n+      if (msg == nullptr) {\n@@ -4807,1 +4722,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4821,3 +4736,3 @@\n-      const Klass* k = this_klass->super();\n-      const Method* super_m = NULL;\n-      while (k != NULL) {\n+      const InstanceKlass* k = this_klass->java_super();\n+      const Method* super_m = nullptr;\n+      while (k != nullptr) {\n@@ -4828,1 +4743,1 @@\n-          if (super_m == NULL) {\n+          if (super_m == nullptr) {\n@@ -4853,1 +4768,1 @@\n-          k = super_m->method_holder()->super();\n+          k = super_m->method_holder()->java_super();\n@@ -4857,1 +4772,1 @@\n-        k = k->super();\n+        k = k->java_super();\n@@ -4866,1 +4781,1 @@\n-  assert(this_klass != NULL, \"invariant\");\n+  assert(this_klass != nullptr, \"invariant\");\n@@ -4909,1 +4824,1 @@\n-  const bool is_inner_class = name != NULL;\n+  const bool is_inner_class = name != nullptr;\n@@ -4966,1 +4881,1 @@\n-    if (name == NULL) { \/\/ Not an inner class\n+    if (name == nullptr) { \/\/ Not an inner class\n@@ -5264,1 +5179,1 @@\n-\/\/ Return NULL if no fieldname at all was found, or in the case of slash_ok\n+\/\/ Return null if no fieldname at all was found, or in the case of slash_ok\n@@ -5289,1 +5204,1 @@\n-          return NULL;  \/\/ Don't permit consecutive slashes\n+          return nullptr;  \/\/ Don't permit consecutive slashes\n@@ -5328,1 +5243,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -5334,1 +5249,1 @@\n-    return (not_first_ch) ? old_p : NULL;\n+    return (not_first_ch) ? old_p : nullptr;\n@@ -5336,1 +5251,1 @@\n-  return (not_first_ch && !last_is_slash) ? p : NULL;\n+  return (not_first_ch && !last_is_slash) ? p : nullptr;\n@@ -5343,1 +5258,1 @@\n-\/\/ Return NULL if no legal signature is found.\n+\/\/ Return null if no legal signature is found.\n@@ -5351,1 +5266,1 @@\n-    case JVM_SIGNATURE_VOID: if (!void_ok) { return NULL; }\n+    case JVM_SIGNATURE_VOID: if (!void_ok) { return nullptr; }\n@@ -5368,1 +5283,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -5387,1 +5302,1 @@\n-        if (c != NULL) {\n+        if (c != nullptr) {\n@@ -5394,1 +5309,1 @@\n-            return NULL;\n+            return nullptr;\n@@ -5399,1 +5314,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -5406,1 +5321,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -5414,1 +5329,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -5417,1 +5332,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -5433,1 +5348,1 @@\n-      legal = (p != NULL) && ((p - bytes) == (int)length);\n+      legal = (p != nullptr) && ((p - bytes) == (int)length);\n@@ -5437,1 +5352,1 @@\n-        legal = (p != NULL) && ((p - bytes) == (int)length);\n+        legal = (p != nullptr) && ((p - bytes) == (int)length);\n@@ -5453,1 +5368,1 @@\n-    assert(_class_name != NULL, \"invariant\");\n+    assert(_class_name != nullptr, \"invariant\");\n@@ -5476,1 +5391,1 @@\n-        legal = (p != NULL) && ((p - bytes) == (int)length);\n+        legal = (p != nullptr) && ((p - bytes) == (int)length);\n@@ -5486,1 +5401,1 @@\n-    assert(_class_name != NULL, \"invariant\");\n+    assert(_class_name != nullptr, \"invariant\");\n@@ -5501,1 +5416,1 @@\n-  assert(name != NULL, \"method name is null\");\n+  assert(name != nullptr, \"method name is null\");\n@@ -5517,1 +5432,1 @@\n-      legal = (p != NULL) && ((p - bytes) == (int)length);\n+      legal = (p != nullptr) && ((p - bytes) == (int)length);\n@@ -5526,1 +5441,1 @@\n-    assert(_class_name != NULL, \"invariant\");\n+    assert(_class_name != nullptr, \"invariant\");\n@@ -5551,1 +5466,1 @@\n-  if (p == NULL || (p - bytes) != (int)length) {\n+  if (p == nullptr || (p - bytes) != (int)length) {\n@@ -5605,1 +5520,1 @@\n-    while ((length > 0) && (nextp != NULL)) {\n+    while ((length > 0) && (nextp != nullptr)) {\n@@ -5630,1 +5545,1 @@\n-  assert(_field_info != NULL, \"invariant\");\n+  assert(_field_info != nullptr, \"invariant\");\n@@ -5635,1 +5550,1 @@\n-  assert(_field_info != NULL, \"invariant\");\n+  assert(_field_info != nullptr, \"invariant\");\n@@ -5640,1 +5555,1 @@\n-  assert(_field_info != NULL, \"invariant\");\n+  assert(_field_info != nullptr, \"invariant\");\n@@ -5646,2 +5561,2 @@\n-  assert(ik != NULL, \"invariant\");\n-  assert(methods != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n+  assert(methods != nullptr, \"invariant\");\n@@ -5742,1 +5657,1 @@\n-  if (_klass != NULL) {\n+  if (_klass != nullptr) {\n@@ -5763,1 +5678,1 @@\n-  assert(ik != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n@@ -5770,1 +5685,1 @@\n-  \/\/ including classes in the bootstrap (NULL) class loader.\n+  \/\/ including classes in the bootstrap (null) class loader.\n@@ -5777,1 +5692,1 @@\n-  assert(_field_info != NULL, \"invariant\");\n+  assert(_field_info != nullptr, \"invariant\");\n@@ -5801,1 +5716,1 @@\n-  assert(_fac != NULL, \"invariant\");\n+  assert(_fac != nullptr, \"invariant\");\n@@ -5807,0 +5722,3 @@\n+  if (ik->is_inline_klass()) {\n+    InlineKlass::cast(ik)->init_fixed_block();\n+  }\n@@ -5809,1 +5727,1 @@\n-  if (cl_inst_info.dynamic_nest_host() != NULL) {\n+  if (cl_inst_info.dynamic_nest_host() != nullptr) {\n@@ -5814,10 +5732,15 @@\n-  assert(NULL == _cp, \"invariant\");\n-  assert(NULL == _fields, \"invariant\");\n-  assert(NULL == _methods, \"invariant\");\n-  assert(NULL == _inner_classes, \"invariant\");\n-  assert(NULL == _nest_members, \"invariant\");\n-  assert(NULL == _preload_classes, \"invariant\");\n-  assert(NULL == _combined_annotations, \"invariant\");\n-  assert(NULL == _record_components, \"invariant\");\n-  assert(NULL == _permitted_subclasses, \"invariant\");\n-  assert(NULL == _multifield_info, \"invariant\");\n+  assert(nullptr == _cp, \"invariant\");\n+  assert(nullptr == _fieldinfo_stream, \"invariant\");\n+  assert(nullptr == _fields_status, \"invariant\");\n+  assert(nullptr == _methods, \"invariant\");\n+  assert(nullptr == _inner_classes, \"invariant\");\n+  assert(nullptr == _nest_members, \"invariant\");\n+  assert(nullptr == _preload_classes, \"invariant\");\n+  assert(nullptr == _combined_annotations, \"invariant\");\n+  assert(nullptr == _record_components, \"invariant\");\n+  assert(nullptr == _permitted_subclasses, \"invariant\");\n+  assert(nullptr == _multifield_info, \"invariant\");\n+\n+  if (_has_localvariable_table) {\n+    ik->set_has_localvariable_table(true);\n+  }\n@@ -5866,1 +5789,1 @@\n-  ik->set_package(cld, NULL, CHECK);\n+  ik->set_package(cld, nullptr, CHECK);\n@@ -5869,1 +5792,1 @@\n-  assert(methods != NULL, \"invariant\");\n+  assert(methods != nullptr, \"invariant\");\n@@ -5884,1 +5807,1 @@\n-      (_super_klass != NULL && _super_klass->has_miranda_methods())\n+      (_super_klass != nullptr && _super_klass->has_miranda_methods())\n@@ -5894,2 +5817,2 @@\n-  _transitive_interfaces = NULL;\n-  _local_interfaces = NULL;\n+  _transitive_interfaces = nullptr;\n+  _local_interfaces = nullptr;\n@@ -5908,1 +5831,1 @@\n-      ( _super_klass != NULL && _super_klass->has_contended_annotations())) {\n+      ( _super_klass != nullptr && _super_klass->has_contended_annotations())) {\n@@ -5931,1 +5854,1 @@\n-  assert(module_entry != NULL, \"module_entry should always be set\");\n+  assert(module_entry != nullptr, \"module_entry should always be set\");\n@@ -5945,1 +5868,1 @@\n-  assert(_all_mirandas != NULL, \"invariant\");\n+  assert(_all_mirandas != nullptr, \"invariant\");\n@@ -6008,1 +5931,1 @@\n-      if (ik->java_super() != NULL) {\n+      if (ik->java_super() != nullptr) {\n@@ -6015,1 +5938,1 @@\n-      if (local_interfaces != NULL) {\n+      if (local_interfaces != nullptr) {\n@@ -6031,1 +5954,1 @@\n-  set_klass_to_deallocate(NULL);\n+  set_klass_to_deallocate(nullptr);\n@@ -6068,1 +5991,1 @@\n-  _class_name(NULL),\n+  _class_name(nullptr),\n@@ -6074,5 +5997,6 @@\n-  _cp(NULL),\n-  _fields(NULL),\n-  _methods(NULL),\n-  _inner_classes(NULL),\n-  _nest_members(NULL),\n+  _cp(nullptr),\n+  _fieldinfo_stream(nullptr),\n+  _fields_status(nullptr),\n+  _methods(nullptr),\n+  _inner_classes(nullptr),\n+  _nest_members(nullptr),\n@@ -6080,20 +6004,21 @@\n-  _permitted_subclasses(NULL),\n-  _preload_classes(NULL),\n-  _record_components(NULL),\n-  _local_interfaces(NULL),\n-  _local_interface_indexes(NULL),\n-  _transitive_interfaces(NULL),\n-  _combined_annotations(NULL),\n-  _class_annotations(NULL),\n-  _class_type_annotations(NULL),\n-  _fields_annotations(NULL),\n-  _fields_type_annotations(NULL),\n-  _klass(NULL),\n-  _klass_to_deallocate(NULL),\n-  _parsed_annotations(NULL),\n-  _fac(NULL),\n-  _field_info(NULL),\n-  _inline_type_field_klasses(NULL),\n-  _method_ordering(NULL),\n-  _all_mirandas(NULL),\n-  _multifield_info(NULL),\n+  _permitted_subclasses(nullptr),\n+  _preload_classes(nullptr),\n+  _record_components(nullptr),\n+  _local_interfaces(nullptr),\n+  _local_interface_indexes(nullptr),\n+  _transitive_interfaces(nullptr),\n+  _combined_annotations(nullptr),\n+  _class_annotations(nullptr),\n+  _class_type_annotations(nullptr),\n+  _fields_annotations(nullptr),\n+  _fields_type_annotations(nullptr),\n+  _klass(nullptr),\n+  _klass_to_deallocate(nullptr),\n+  _parsed_annotations(nullptr),\n+  _fac(nullptr),\n+  _field_info(nullptr),\n+  _inline_type_field_klasses(nullptr),\n+  _temp_field_info(nullptr),\n+  _method_ordering(nullptr),\n+  _all_mirandas(nullptr),\n+  _multifield_info(nullptr),\n@@ -6109,1 +6034,1 @@\n-  _sde_buffer(NULL),\n+  _sde_buffer(nullptr),\n@@ -6122,0 +6047,1 @@\n+  _has_localvariable_table(false),\n@@ -6136,1 +6062,1 @@\n-  _class_name = name != NULL ? name : vmSymbols::unknown_class_name();\n+  _class_name = name != nullptr ? name : vmSymbols::unknown_class_name();\n@@ -6139,3 +6065,3 @@\n-  assert(_loader_data != NULL, \"invariant\");\n-  assert(stream != NULL, \"invariant\");\n-  assert(_stream != NULL, \"invariant\");\n+  assert(_loader_data != nullptr, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n+  assert(_stream != nullptr, \"invariant\");\n@@ -6143,1 +6069,1 @@\n-  assert(_class_name != NULL, \"invariant\");\n+  assert(_class_name != nullptr, \"invariant\");\n@@ -6174,12 +6100,13 @@\n-  _cp = NULL;\n-  _fields = NULL;\n-  _methods = NULL;\n-  _inner_classes = NULL;\n-  _nest_members = NULL;\n-  _permitted_subclasses = NULL;\n-  _preload_classes = NULL;\n-  _combined_annotations = NULL;\n-  _class_annotations = _class_type_annotations = NULL;\n-  _fields_annotations = _fields_type_annotations = NULL;\n-  _record_components = NULL;\n-  _multifield_info = NULL;\n+  _cp = nullptr;\n+  _fieldinfo_stream = nullptr;\n+  _fields_status = nullptr;\n+  _methods = nullptr;\n+  _inner_classes = nullptr;\n+  _nest_members = nullptr;\n+  _permitted_subclasses = nullptr;\n+  _preload_classes = nullptr;\n+  _combined_annotations = nullptr;\n+  _class_annotations = _class_type_annotations = nullptr;\n+  _fields_annotations = _fields_type_annotations = nullptr;\n+  _record_components = nullptr;\n+  _multifield_info = nullptr;\n@@ -6192,1 +6119,1 @@\n-  if (_cp != NULL) {\n+  if (_cp != nullptr) {\n@@ -6195,2 +6122,7 @@\n-  if (_fields != NULL) {\n-    MetadataFactory::free_array<u2>(_loader_data, _fields);\n+\n+  if (_fieldinfo_stream != nullptr) {\n+    MetadataFactory::free_array<u1>(_loader_data, _fieldinfo_stream);\n+  }\n+\n+  if (_fields_status != nullptr) {\n+    MetadataFactory::free_array<FieldStatus>(_loader_data, _fields_status);\n@@ -6199,1 +6131,1 @@\n-  if (_multifield_info != NULL) {\n+  if (_multifield_info != nullptr) {\n@@ -6203,1 +6135,1 @@\n-  if (_inline_type_field_klasses != NULL) {\n+  if (_inline_type_field_klasses != nullptr) {\n@@ -6207,1 +6139,1 @@\n-  if (_methods != NULL) {\n+  if (_methods != nullptr) {\n@@ -6213,1 +6145,1 @@\n-  if (_inner_classes != NULL && _inner_classes != Universe::the_empty_short_array()) {\n+  if (_inner_classes != nullptr && _inner_classes != Universe::the_empty_short_array()) {\n@@ -6217,1 +6149,1 @@\n-  if (_nest_members != NULL && _nest_members != Universe::the_empty_short_array()) {\n+  if (_nest_members != nullptr && _nest_members != Universe::the_empty_short_array()) {\n@@ -6221,1 +6153,1 @@\n-  if (_record_components != NULL) {\n+  if (_record_components != nullptr) {\n@@ -6225,1 +6157,1 @@\n-  if (_permitted_subclasses != NULL && _permitted_subclasses != Universe::the_empty_short_array()) {\n+  if (_permitted_subclasses != nullptr && _permitted_subclasses != Universe::the_empty_short_array()) {\n@@ -6229,1 +6161,1 @@\n-  if (_preload_classes != NULL && _preload_classes != Universe::the_empty_short_array()) {\n+  if (_preload_classes != nullptr && _preload_classes != Universe::the_empty_short_array()) {\n@@ -6237,1 +6169,1 @@\n-  if (_combined_annotations != NULL) {\n+  if (_combined_annotations != nullptr) {\n@@ -6244,1 +6176,1 @@\n-    \/\/ If the _combined_annotations pointer is non-NULL,\n+    \/\/ If the _combined_annotations pointer is non-null,\n@@ -6246,4 +6178,4 @@\n-    assert(_class_annotations       == NULL, \"Should have been cleared\");\n-    assert(_class_type_annotations  == NULL, \"Should have been cleared\");\n-    assert(_fields_annotations      == NULL, \"Should have been cleared\");\n-    assert(_fields_type_annotations == NULL, \"Should have been cleared\");\n+    assert(_class_annotations       == nullptr, \"Should have been cleared\");\n+    assert(_class_type_annotations  == nullptr, \"Should have been cleared\");\n+    assert(_fields_annotations      == nullptr, \"Should have been cleared\");\n+    assert(_fields_type_annotations == nullptr, \"Should have been cleared\");\n@@ -6260,2 +6192,2 @@\n-  _transitive_interfaces = NULL;\n-  _local_interfaces = NULL;\n+  _transitive_interfaces = nullptr;\n+  _local_interfaces = nullptr;\n@@ -6266,1 +6198,1 @@\n-  if (_klass_to_deallocate != NULL) {\n+  if (_klass_to_deallocate != nullptr) {\n@@ -6274,2 +6206,2 @@\n-  assert(stream != NULL, \"invariant\");\n-  assert(_class_name != NULL, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n+  assert(_class_name != nullptr, \"invariant\");\n@@ -6344,1 +6276,1 @@\n-  assert(class_name_in_cp != NULL, \"class_name can't be null\");\n+  assert(class_name_in_cp != nullptr, \"class_name can't be null\");\n@@ -6348,1 +6280,0 @@\n-\n@@ -6396,1 +6327,1 @@\n-    assert(_class_name != NULL, \"Unexpected null _class_name\");\n+    assert(_class_name != nullptr, \"Unexpected null _class_name\");\n@@ -6434,1 +6365,1 @@\n-      if (stream->source() != NULL) {\n+      if (stream->source() != nullptr) {\n@@ -6448,1 +6379,1 @@\n-  const Symbol* super_klass_name = _super_class_index ? cp->klass_name_at(_super_class_index) : NULL;\n+  const Symbol* super_klass_name = _super_class_index ? cp->klass_name_at(_super_class_index) : nullptr;\n@@ -6470,1 +6401,1 @@\n-  assert(_fields != NULL, \"invariant\");\n+  assert(_temp_field_info != nullptr, \"invariant\");\n@@ -6473,1 +6404,0 @@\n-  AccessFlags promoted_flags;\n@@ -6478,1 +6408,1 @@\n-                &promoted_flags,\n+                &_has_localvariable_table,\n@@ -6483,4 +6413,1 @@\n-  assert(_methods != NULL, \"invariant\");\n-\n-  \/\/ promote flags from parse_methods() to the klass' flags\n-  _access_flags.add_promoted_flags(promoted_flags.as_int());\n+  assert(_methods != nullptr, \"invariant\");\n@@ -6496,1 +6423,1 @@\n-  assert(_inner_classes != NULL, \"invariant\");\n+  assert(_inner_classes != nullptr, \"invariant\");\n@@ -6536,1 +6463,1 @@\n-  assert(_class_name != NULL, \"Unexpected null _class_name\");\n+  assert(_class_name != nullptr, \"Unexpected null _class_name\");\n@@ -6565,1 +6492,1 @@\n-  assert(stream != NULL, \"invariant\");\n+  assert(stream != nullptr, \"invariant\");\n@@ -6567,2 +6494,2 @@\n-  assert(cp != NULL, \"invariant\");\n-  assert(_loader_data != NULL, \"invariant\");\n+  assert(cp != nullptr, \"invariant\");\n+  assert(_loader_data != nullptr, \"invariant\");\n@@ -6576,1 +6503,1 @@\n-  if (_super_class_index > 0 && NULL == _super_klass) {\n+  if (_super_class_index > 0 && nullptr == _super_klass) {\n@@ -6586,1 +6513,4 @@\n-    _super_klass = (const InstanceKlass*)\n+    if (loader.is_null() && super_class_name == vmSymbols::java_lang_Object()) {\n+      _super_klass = vmClasses::Object_klass();\n+    } else {\n+      _super_klass = (const InstanceKlass*)\n@@ -6593,0 +6523,1 @@\n+    }\n@@ -6595,1 +6526,1 @@\n-  if (_super_klass != NULL) {\n+  if (_super_klass != nullptr) {\n@@ -6621,3 +6552,3 @@\n-  int itfs_len = _local_interface_indexes == NULL ? 0 : _local_interface_indexes->length();\n-  _local_interfaces = MetadataFactory::new_array<InstanceKlass*>(_loader_data, itfs_len, NULL, CHECK);\n-  if (_local_interface_indexes != NULL) {\n+  int itfs_len = _local_interface_indexes == nullptr ? 0 : _local_interface_indexes->length();\n+  _local_interfaces = MetadataFactory::new_array<InstanceKlass*>(_loader_data, itfs_len, nullptr, CHECK);\n+  if (_local_interface_indexes != nullptr) {\n@@ -6669,1 +6600,1 @@\n-  assert(_local_interfaces != NULL, \"invariant\");\n+  assert(_local_interfaces != nullptr, \"invariant\");\n@@ -6678,1 +6609,1 @@\n-  assert(_transitive_interfaces != NULL, \"invariant\");\n+  assert(_transitive_interfaces != nullptr, \"invariant\");\n@@ -6701,2 +6632,2 @@\n-  assert(_fac != NULL, \"invariant\");\n-  assert(_parsed_annotations != NULL, \"invariant\");\n+  assert(_fac != nullptr, \"invariant\");\n+  assert(_parsed_annotations != nullptr, \"invariant\");\n@@ -6708,1 +6639,1 @@\n-                                                   NULL,\n+                                                   nullptr,\n@@ -6710,2 +6641,5 @@\n-    for (AllFieldStream fs(_fields, cp, _multifield_info); !fs.done(); fs.next()) {\n-      if (Signature::basic_type(fs.signature()) == T_PRIMITIVE_OBJECT && !fs.access_flags().is_static()) {\n+    for (GrowableArrayIterator<FieldInfo> it = _temp_field_info->begin(); it != _temp_field_info->end(); ++it) {\n+      FieldInfo fieldinfo = *it;\n+      Symbol* sig = fieldinfo.signature(cp);\n+\n+      if (Signature::basic_type(sig) == T_PRIMITIVE_OBJECT && !fieldinfo.access_flags().is_static()) {\n@@ -6713,1 +6647,1 @@\n-        Klass* klass = SystemDictionary::resolve_inline_type_field_or_fail(&fs,\n+        Klass* klass = SystemDictionary::resolve_inline_type_field_or_fail(sig,\n@@ -6716,1 +6650,1 @@\n-        assert(klass != NULL, \"Sanity check\");\n+        assert(klass != nullptr, \"Sanity check\");\n@@ -6725,1 +6659,1 @@\n-        _inline_type_field_klasses->at_put(fs.index(), InlineKlass::cast(klass));\n+        _inline_type_field_klasses->at_put(fieldinfo.index(), InlineKlass::cast(klass));\n@@ -6731,1 +6665,1 @@\n-  FieldLayoutBuilder lb(class_name(), super_klass(), _cp, _fields,\n+  FieldLayoutBuilder lb(class_name(), super_klass(), _cp, \/*_fields*\/ _temp_field_info,\n@@ -6741,0 +6675,8 @@\n+\n+  int injected_fields_count = _temp_field_info->length() - _java_fields_count;\n+  _fieldinfo_stream =\n+    FieldInfoStream::create_FieldInfoStream(_temp_field_info, _java_fields_count,\n+                                            injected_fields_count, loader_data(), CHECK);\n+  _fields_status =\n+    MetadataFactory::new_array<FieldStatus>(_loader_data, _temp_field_info->length(),\n+                                            FieldStatus(0), CHECK);\n@@ -6746,2 +6688,2 @@\n-  if (klass != NULL) {\n-    assert(NULL == _klass, \"leaking?\");\n+  if (klass != nullptr) {\n+    assert(nullptr == _klass, \"leaking?\");\n@@ -6757,2 +6699,2 @@\n-  if (klass != NULL) {\n-    assert(NULL == _klass_to_deallocate, \"leaking?\");\n+  if (klass != nullptr) {\n+    assert(nullptr == _klass_to_deallocate, \"leaking?\");\n@@ -6768,1 +6710,1 @@\n-  assert(_stream != NULL, \"invariant\");\n+  assert(_stream != nullptr, \"invariant\");\n@@ -6774,1 +6716,1 @@\n-  return _super_klass == NULL ? REF_NONE : _super_klass->reference_type();\n+  return _super_klass == nullptr ? REF_NONE : _super_klass->reference_type();\n@@ -6787,1 +6729,1 @@\n-  if (_super_klass == NULL) {\n+  if (_super_klass == nullptr) {\n@@ -6806,1 +6748,1 @@\n-  if (class_name != NULL) {\n+  if (class_name != nullptr) {\n@@ -6809,1 +6751,1 @@\n-    return strchr(name, JVM_SIGNATURE_DOT) == NULL;\n+    return strchr(name, JVM_SIGNATURE_DOT) == nullptr;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":575,"deletions":633,"binary":false,"changes":1208,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"oops\/fieldInfo.hpp\"\n@@ -123,1 +124,1 @@\n-  \/\/ in which case these pointers have been set to NULL.\n+  \/\/ in which case these pointers have been set to null.\n@@ -126,1 +127,2 @@\n-  Array<u2>* _fields;\n+  Array<u1>* _fieldinfo_stream;\n+  Array<FieldStatus>* _fields_status;\n@@ -149,0 +151,1 @@\n+  GrowableArray<FieldInfo>* _temp_field_info;\n@@ -200,0 +203,1 @@\n+  bool _has_localvariable_table;\n@@ -291,1 +295,1 @@\n-                       AccessFlags* const promoted_flags,\n+                       bool* const has_localvariable_table,\n@@ -298,1 +302,1 @@\n-                     AccessFlags* const promoted_flags,\n+                     bool* const has_localvariable_table,\n@@ -476,2 +480,2 @@\n-                                 const Symbol* name = NULL,\n-                                 const Symbol* sig  = NULL) const;\n+                                 const Symbol* name = nullptr,\n+                                 const Symbol* sig  = nullptr) const;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":11,"deletions":7,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,3 +41,3 @@\n-  _next_block(NULL),\n-  _prev_block(NULL),\n-  _inline_klass(NULL),\n+  _next_block(nullptr),\n+  _prev_block(nullptr),\n+  _inline_klass(nullptr),\n@@ -58,3 +58,3 @@\n- _next_block(NULL),\n- _prev_block(NULL),\n- _inline_klass(NULL),\n+ _next_block(nullptr),\n+ _prev_block(nullptr),\n+ _inline_klass(nullptr),\n@@ -83,5 +83,5 @@\n-  _next(NULL),\n-  _small_primitive_fields(NULL),\n-  _big_primitive_fields(NULL),\n-  _oop_fields(NULL),\n-  _multifields(NULL),\n+  _next(nullptr),\n+  _small_primitive_fields(nullptr),\n+  _big_primitive_fields(nullptr),\n+  _oop_fields(nullptr),\n+  _multifields(nullptr),\n@@ -91,1 +91,1 @@\n-void FieldGroup::add_primitive_field(AllFieldStream fs, BasicType type) {\n+void FieldGroup::add_primitive_field(int idx, BasicType type) {\n@@ -93,1 +93,1 @@\n-  LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size \/* alignment == size for primitive types *\/, false, -1);\n+  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::REGULAR, size, size \/* alignment == size for primitive types *\/, false, -1);\n@@ -101,1 +101,1 @@\n-void FieldGroup::add_oop_field(AllFieldStream fs) {\n+void FieldGroup::add_oop_field(int idx) {\n@@ -103,2 +103,2 @@\n-  LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size \/* alignment == size for oops *\/, true, -1);\n-  if (_oop_fields == NULL) {\n+  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::REGULAR, size, size \/* alignment == size for oops *\/, true, -1);\n+  if (_oop_fields == nullptr) {\n@@ -111,2 +111,2 @@\n-void FieldGroup::add_inlined_field(AllFieldStream fs, InlineKlass* vk) {\n-  LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INLINED, vk->get_exact_size_in_bytes(), vk->get_alignment(), false, -1);\n+void FieldGroup::add_inlined_field(int idx, InlineKlass* vk) {\n+  LayoutRawBlock* block = new LayoutRawBlock(idx, LayoutRawBlock::INLINED, vk->get_exact_size_in_bytes(), vk->get_alignment(), false, -1);\n@@ -121,4 +121,4 @@\n-void FieldGroup::add_multifield(AllFieldStream fs, Array<MultiFieldInfo>* multifield_info, InlineKlass* vk) {\n-  assert(fs.is_multifield() || fs.is_multifield_base(), \"Must be\");\n-  u2 base = fs.multifield_base();\n-  BasicType type = Signature::basic_type(fs.signature());\n+void FieldGroup::add_multifield(ConstantPool* cp, FieldInfo* field, Array<MultiFieldInfo>* multifield_info, InlineKlass* vk) {\n+  assert(field->is_multifield() || field->is_multifield_base(), \"Must be\");\n+  u2 base = field->multifield_base(multifield_info);\n+  BasicType type = Signature::basic_type(field->signature(cp));\n@@ -137,2 +137,2 @@\n-    mfg = new MultiFieldGroup(base, fs.signature());\n-    mfg->add_field(fs, vk);\n+    mfg = new MultiFieldGroup(base, field->signature(cp));\n+    mfg->add_field(cp, field, vk, multifield_info);\n@@ -141,1 +141,1 @@\n-    mfg->add_field(fs, vk);\n+    mfg->add_field(cp, field, vk, multifield_info);\n@@ -146,1 +146,1 @@\n-  if (_small_primitive_fields != NULL) {\n+  if (_small_primitive_fields != nullptr) {\n@@ -149,1 +149,1 @@\n-  if (_big_primitive_fields != NULL) {\n+  if (_big_primitive_fields != nullptr) {\n@@ -171,1 +171,1 @@\n-  if (_small_primitive_fields == NULL) {\n+  if (_small_primitive_fields == nullptr) {\n@@ -178,1 +178,1 @@\n-  if (_big_primitive_fields == NULL) {\n+  if (_big_primitive_fields == nullptr) {\n@@ -186,4 +186,3 @@\n-void MultiFieldGroup::add_field(AllFieldStream fs, InlineKlass* vk) {\n-  assert(fs.is_multifield() || fs.is_multifield_base(), \"Must be\");\n-  assert(fs.multifield_base() == multifield_base(), \"multifield base mismatch\");\n-  jbyte idx = fs.multifield_index();\n+void MultiFieldGroup::add_field(ConstantPool* cp, FieldInfo* field, InlineKlass* vk, Array<MultiFieldInfo>* multifield_info) {\n+  assert(field->is_multifield() || field->is_multifield_base(), \"Must be\");\n+  assert(field->multifield_base(multifield_info) == multifield_base(), \"multifield base mismatch\");\n@@ -193,1 +192,1 @@\n-    guarantee(fs.signature() == signature(), \"multifield signature mismatch\");\n+    guarantee(field->signature(cp) == signature(), \"multifield signature mismatch\");\n@@ -195,1 +194,1 @@\n-  BasicType type = Signature::basic_type(fs.signature());\n+  BasicType type = Signature::basic_type(field->signature(cp));\n@@ -198,2 +197,2 @@\n-    block = new LayoutRawBlock(fs.index(), LayoutRawBlock::MULTIFIELD, vk->get_exact_size_in_bytes(),\n-                               vk->get_alignment(), false, fs.multifield_index());\n+    block = new LayoutRawBlock(field->index(), LayoutRawBlock::MULTIFIELD, vk->get_exact_size_in_bytes(),\n+                               vk->get_alignment(), false, field->multifield_index(multifield_info));\n@@ -202,1 +201,1 @@\n-    block = new LayoutRawBlock(fs.index(), LayoutRawBlock::MULTIFIELD, size, size, false, fs.multifield_index());\n+    block = new LayoutRawBlock(field->index(), LayoutRawBlock::MULTIFIELD, size, size, false, field->multifield_index(multifield_info));\n@@ -206,2 +205,2 @@\n-    assert(_fields->at(cursor)->multifield_index() != fs.multifield_index(), \"multifield index duplicate found\");\n-    if (_fields->at(cursor)->multifield_index() > fs.multifield_index()) break;\n+    assert(_fields->at(cursor)->multifield_index() != field->multifield_index(multifield_info), \"multifield index duplicate found\");\n+    if (_fields->at(cursor)->multifield_index() > field->multifield_index(multifield_info)) break;\n@@ -212,2 +211,2 @@\n-FieldLayout::FieldLayout(Array<u2>* fields, ConstantPool* cp, Array<MultiFieldInfo>* multifields) :\n-  _fields(fields),\n+FieldLayout::FieldLayout(GrowableArray<FieldInfo>* field_info, ConstantPool* cp, Array<MultiFieldInfo>* multifields) :\n+  _field_info(field_info),\n@@ -216,1 +215,1 @@\n-  _blocks(NULL),\n+  _blocks(nullptr),\n@@ -236,1 +235,1 @@\n-  if (super_klass == NULL) {\n+  if (super_klass == nullptr) {\n@@ -256,1 +255,1 @@\n-  while (block != NULL\n+  while (block != nullptr\n@@ -272,2 +271,2 @@\n-  if (list == NULL) return;\n-  if (start == NULL) start = this->_start;\n+  if (list == nullptr) return;\n+  if (start == nullptr) start = this->_start;\n@@ -279,2 +278,2 @@\n-    LayoutRawBlock* cursor = NULL;\n-    LayoutRawBlock* candidate = NULL;\n+    LayoutRawBlock* cursor = nullptr;\n+    LayoutRawBlock* candidate = nullptr;\n@@ -296,1 +295,1 @@\n-      assert(cursor != NULL, \"Sanity check\");\n+      assert(cursor != nullptr, \"Sanity check\");\n@@ -301,1 +300,1 @@\n-          if (candidate == NULL || cursor->size() < candidate->size()) {\n+          if (candidate == nullptr || cursor->size() < candidate->size()) {\n@@ -307,1 +306,1 @@\n-      if (candidate == NULL) {\n+      if (candidate == nullptr) {\n@@ -311,1 +310,1 @@\n-      assert(candidate != NULL, \"Candidate must not be null\");\n+      assert(candidate != nullptr, \"Candidate must not be null\");\n@@ -321,1 +320,1 @@\n-  assert(block != NULL, \"Sanity check\");\n+  assert(block != nullptr, \"Sanity check\");\n@@ -323,1 +322,1 @@\n-  if (start == NULL) {\n+  if (start == nullptr) {\n@@ -327,1 +326,1 @@\n-  while (slot != NULL) {\n+  while (slot != nullptr) {\n@@ -341,1 +340,1 @@\n-      FieldInfo::from_field_array(_fields, block->field_index())->set_offset(block->offset());\n+      _field_info->adr_at(block->field_index())->set_offset(block->offset());\n@@ -353,2 +352,2 @@\n-  if (list == NULL) return;\n-  if (start == NULL) {\n+  if (list == nullptr) return;\n+  if (start == nullptr) {\n@@ -364,1 +363,1 @@\n-  LayoutRawBlock* candidate = NULL;\n+  LayoutRawBlock* candidate = nullptr;\n@@ -377,1 +376,1 @@\n-    assert(candidate != NULL, \"Candidate must not be null\");\n+    assert(candidate != nullptr, \"Candidate must not be null\");\n@@ -431,1 +430,1 @@\n-  FieldInfo::from_field_array(_fields, block->field_index())->set_offset(block->offset());\n+  _field_info->adr_at(block->field_index())->set_offset(block->offset());\n@@ -438,2 +437,2 @@\n-  while (ik != NULL) {\n-    for (AllFieldStream fs(ik->fields(), ik->constants(), ik->multifield_info()); !fs.done(); fs.next()) {\n+  while (ik != nullptr) {\n+    for (AllFieldStream fs(ik->fieldinfo_stream(), ik->constants(), ik->multifield_info()); !fs.done(); fs.next()) {\n@@ -458,1 +457,1 @@\n-    ik = ik->super() == NULL ? NULL : InstanceKlass::cast(ik->super());\n+    ik = ik->super() == nullptr ? nullptr : InstanceKlass::cast(ik->super());\n@@ -481,1 +480,1 @@\n-  assert(_blocks != NULL, \"Sanity check\");\n+  assert(_blocks != nullptr, \"Sanity check\");\n@@ -485,1 +484,1 @@\n-  while (b->next_block() != NULL) {\n+  while (b->next_block() != nullptr) {\n@@ -497,1 +496,1 @@\n-  assert(b->next_block() == NULL, \"Invariant at this point\");\n+  assert(b->next_block() == nullptr, \"Invariant at this point\");\n@@ -541,1 +540,1 @@\n-  if (block->prev_block() != NULL) {\n+  if (block->prev_block() != nullptr) {\n@@ -551,1 +550,1 @@\n-  assert(block != NULL, \"Sanity check\");\n+  assert(block != nullptr, \"Sanity check\");\n@@ -555,2 +554,2 @@\n-    if (_blocks != NULL) {\n-      _blocks->set_prev_block(NULL);\n+    if (_blocks != nullptr) {\n+      _blocks->set_prev_block(nullptr);\n@@ -559,1 +558,1 @@\n-    assert(block->prev_block() != NULL, \"_prev should be set for non-head blocks\");\n+    assert(block->prev_block() != nullptr, \"_prev should be set for non-head blocks\");\n@@ -573,46 +572,47 @@\n-    case LayoutRawBlock::REGULAR: {\n-      FieldInfo* fi = FieldInfo::from_field_array(_fields, b->field_index());\n-      output->print_cr(\" @%d \\\"%s\\\" %s %d\/%d %s\",\n-                       b->offset(),\n-                       fi->name(_multifield_info, _cp)->as_C_string(),\n-                       fi->signature(_cp)->as_C_string(),\n-                       b->size(),\n-                       b->alignment(),\n-                       \"REGULAR\");\n-      break;\n-    }\n-    case LayoutRawBlock::INLINED: {\n-      FieldInfo* fi = FieldInfo::from_field_array(_fields, b->field_index());\n-      output->print_cr(\" @%d \\\"%s\\\" %s %d\/%d %s\",\n-                       b->offset(),\n-                       fi->name(_multifield_info, _cp)->as_C_string(),\n-                       fi->signature(_cp)->as_C_string(),\n-                       b->size(),\n-                       b->alignment(),\n-                       \"INLINED\");\n-      break;\n-    }\n-    case LayoutRawBlock::RESERVED: {\n-      output->print_cr(\" @%d %d\/- %s\",\n-                       b->offset(),\n-                       b->size(),\n-                       \"RESERVED\");\n-      break;\n-    }\n-    case LayoutRawBlock::INHERITED: {\n-      assert(!is_static, \"Static fields are not inherited in layouts\");\n-      assert(super != NULL, \"super klass must be provided to retrieve inherited fields info\");\n-      bool found = false;\n-      const InstanceKlass* ik = super;\n-      while (!found && ik != NULL) {\n-        for (AllFieldStream fs(ik->fields(), ik->constants(), ik->multifield_info()); !fs.done(); fs.next()) {\n-          if (fs.offset() == b->offset()) {\n-            output->print_cr(\" @%d \\\"%s\\\" %s %d\/%d %s\",\n-                b->offset(),\n-                fs.name()->as_C_string(),\n-                fs.signature()->as_C_string(),\n-                b->size(),\n-                b->size(), \/\/ so far, alignment constraint == size, will change with Valhalla\n-                \"INHERITED\");\n-            found = true;\n-            break;\n+      case LayoutRawBlock::REGULAR: {\n+        FieldInfo* fi = _field_info->adr_at(b->field_index());\n+        output->print_cr(\" @%d \\\"%s\\\" %s %d\/%d %s\",\n+                         b->offset(),\n+                         fi->name(_multifield_info, _cp)->as_C_string(),\n+                         fi->signature(_cp)->as_C_string(),\n+                         b->size(),\n+                         b->alignment(),\n+                         \"REGULAR\");\n+        break;\n+      }\n+      case LayoutRawBlock::INLINED: {\n+        FieldInfo* fi = _field_info->adr_at(b->field_index());\n+        output->print_cr(\" @%d \\\"%s\\\" %s %d\/%d %s\",\n+                         b->offset(),\n+                         fi->name(_multifield_info, _cp)->as_C_string(),\n+                         fi->signature(_cp)->as_C_string(),\n+                         b->size(),\n+                         b->alignment(),\n+                         \"INLINED\");\n+        break;\n+      }\n+      case LayoutRawBlock::RESERVED: {\n+        output->print_cr(\" @%d %d\/- %s\",\n+                         b->offset(),\n+                         b->size(),\n+                         \"RESERVED\");\n+        break;\n+      }\n+      case LayoutRawBlock::INHERITED: {\n+        assert(!is_static, \"Static fields are not inherited in layouts\");\n+        assert(super != nullptr, \"super klass must be provided to retrieve inherited fields info\");\n+        bool found = false;\n+        const InstanceKlass* ik = super;\n+        while (!found && ik != nullptr) {\n+          for (AllFieldStream fs(ik->fieldinfo_stream(), ik->constants(), ik->multifield_info()); !fs.done(); fs.next()) {\n+            if (fs.offset() == b->offset()) {\n+              output->print_cr(\" @%d \\\"%s\\\" %s %d\/%d %s\",\n+                  b->offset(),\n+                  fs.name()->as_C_string(),\n+                  fs.signature()->as_C_string(),\n+                  b->size(),\n+                  b->size(), \/\/ so far, alignment constraint == size, will change with Valhalla\n+                  \"INHERITED\");\n+              found = true;\n+              break;\n+            }\n@@ -622,0 +622,1 @@\n+        break;\n@@ -623,24 +624,22 @@\n-      break;\n-    }\n-    case LayoutRawBlock::EMPTY:\n-      output->print_cr(\" @%d %d\/1 %s\",\n-                       b->offset(),\n-                       b->size(),\n-                       \"EMPTY\");\n-      break;\n-    case LayoutRawBlock::PADDING:\n-      output->print_cr(\" @%d %d\/1 %s\",\n-                       b->offset(),\n-                       b->size(),\n-                       \"PADDING\");\n-      break;\n-    case LayoutRawBlock::MULTIFIELD:\n-      FieldInfo* fi = FieldInfo::from_field_array(_fields, b->field_index());\n-      output->print_cr(\" @%d \\\"%s\\\" %s %d\/%d %s\",\n-                       b->offset(),\n-                       fi->name(_multifield_info, _cp)->as_C_string(),\n-                       fi->signature(_cp)->as_C_string(),\n-                       b->size(),\n-                       b->alignment(),\n-                       \"MULTIFIELD\");\n-      break;\n+      case LayoutRawBlock::EMPTY:\n+        output->print_cr(\" @%d %d\/1 %s\",\n+                         b->offset(),\n+                         b->size(),\n+                         \"EMPTY\");\n+        break;\n+      case LayoutRawBlock::PADDING:\n+        output->print_cr(\" @%d %d\/1 %s\",\n+                         b->offset(),\n+                         b->size(),\n+                         \"PADDING\");\n+        break;\n+      case LayoutRawBlock::MULTIFIELD:\n+        FieldInfo* fi = _field_info->adr_at(b->field_index());\n+        output->print_cr(\" @%d \\\"%s\\\" %s %d\/%d %s\",\n+                         b->offset(),\n+                         fi->name(_multifield_info, _cp)->as_C_string(),\n+                         fi->signature(_cp)->as_C_string(),\n+                         b->size(),\n+                         b->alignment(),\n+                         \"MULTIFIELD\");\n+        break;\n@@ -653,1 +652,1 @@\n-                                       Array<u2>* fields, bool is_contended, bool is_inline_type,\n+                                       GrowableArray<FieldInfo>* field_info, bool is_contended, bool is_inline_type,\n@@ -659,1 +658,1 @@\n-  _fields(fields),\n+  _field_info(field_info),\n@@ -663,5 +662,5 @@\n-  _root_group(NULL),\n-  _contended_groups(GrowableArray<FieldGroup*>(0)),\n-  _static_fields(NULL),\n-  _layout(NULL),\n-  _static_layout(NULL),\n+  _root_group(nullptr),\n+  _contended_groups(GrowableArray<FieldGroup*>(8)),\n+  _static_fields(nullptr),\n+  _layout(nullptr),\n+  _static_layout(nullptr),\n@@ -683,1 +682,1 @@\n-  FieldGroup* fg = NULL;\n+  FieldGroup* fg = nullptr;\n@@ -694,1 +693,1 @@\n-  _layout = new FieldLayout(_fields, _constant_pool, _multifield_info);\n+  _layout = new FieldLayout(_field_info, _constant_pool, _multifield_info);\n@@ -697,1 +696,1 @@\n-  if (super_klass != NULL) {\n+  if (super_klass != nullptr) {\n@@ -700,1 +699,1 @@\n-  _static_layout = new FieldLayout(_fields, _constant_pool, _multifield_info);\n+  _static_layout = new FieldLayout(_field_info, _constant_pool, _multifield_info);\n@@ -713,3 +712,6 @@\n-  for (AllFieldStream fs(_fields, _constant_pool, _multifield_info); !fs.done(); fs.next()) {\n-    FieldGroup* group = NULL;\n-    if (fs.access_flags().is_static()) {\n+  int idx = 0;\n+  for (GrowableArrayIterator<FieldInfo> it = _field_info->begin(); it != _field_info->end(); ++it, ++idx) {\n+    FieldInfo ctrl = _field_info->at(0);\n+    FieldGroup* group = nullptr;\n+    FieldInfo fieldinfo = *it;\n+    if (fieldinfo.access_flags().is_static()) {\n@@ -720,2 +722,2 @@\n-      if (fs.is_contended()) {\n-        int g = fs.contended_group();\n+      if (fieldinfo.field_flags().is_contended()) {\n+        int g = fieldinfo.contended_group();\n@@ -732,2 +734,2 @@\n-    assert(group != NULL, \"invariant\");\n-    BasicType type = Signature::basic_type(fs.signature());\n+    assert(group != nullptr, \"invariant\");\n+    BasicType type = Signature::basic_type(fieldinfo.signature(_constant_pool));\n@@ -735,2 +737,2 @@\n-    if (fs.is_multifield() || fs.is_multifield_base()) {\n-      group->add_multifield(fs, _multifield_info);\n+    if (fieldinfo.is_multifield() || fieldinfo.is_multifield_base()) {\n+      group->add_multifield(_constant_pool, &fieldinfo, _multifield_info);\n@@ -739,49 +741,45 @@\n-        case T_BYTE:\n-        case T_CHAR:\n-        case T_DOUBLE:\n-        case T_FLOAT:\n-        case T_INT:\n-        case T_LONG:\n-        case T_SHORT:\n-        case T_BOOLEAN:\n-          group->add_primitive_field(fs, type);\n-          break;\n-        case T_OBJECT:\n-        case T_ARRAY:\n-          if (group != _static_fields) _nonstatic_oopmap_count++;\n-          group->add_oop_field(fs);\n-          break;\n-        case T_PRIMITIVE_OBJECT:\n-          _has_inline_type_fields = true;\n-          if (group == _static_fields) {\n-            \/\/ static fields are never inlined\n-            group->add_oop_field(fs);\n-          } else {\n-            _has_flattening_information = true;\n-            \/\/ Flattening decision to be taken here\n-            \/\/ This code assumes all verification already have been performed\n-            \/\/ (field's type has been loaded and it is an inline klass)\n-            JavaThread* THREAD = JavaThread::current();\n-            Klass* klass =  _inline_type_field_klasses->at(fs.index());\n-            assert(klass != NULL, \"Sanity check\");\n-            InlineKlass* vk = InlineKlass::cast(klass);\n-            bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&\n-                                      (vk->size_helper() * HeapWordSize) > InlineFieldMaxFlatSize);\n-            bool too_atomic_to_flatten = vk->is_declared_atomic() || AlwaysAtomicAccesses;\n-            bool too_volatile_to_flatten = fs.access_flags().is_volatile();\n-            if (vk->is_naturally_atomic()) {\n-              too_atomic_to_flatten = false;\n-              \/\/too_volatile_to_flatten = false; \/\/FIXME\n-              \/\/ volatile fields are currently never inlined, this could change in the future\n-            }\n-            if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten) || fs.access_flags().is_final()) {\n-              group->add_inlined_field(fs, vk);\n-              _nonstatic_oopmap_count += vk->nonstatic_oop_map_count();\n-              fs.set_inlined(true);\n-              if (!vk->is_atomic()) {  \/\/ flat and non-atomic: take note\n-                _has_nonatomic_values = true;\n-                _atomic_field_count--;  \/\/ every other field is atomic but this one\n-              }\n-            } else {\n-              _nonstatic_oopmap_count++;\n-              group->add_oop_field(fs);\n+      case T_BYTE:\n+      case T_CHAR:\n+      case T_DOUBLE:\n+      case T_FLOAT:\n+      case T_INT:\n+      case T_LONG:\n+      case T_SHORT:\n+      case T_BOOLEAN:\n+        group->add_primitive_field(idx, type);\n+        break;\n+      case T_OBJECT:\n+      case T_ARRAY:\n+        if (group != _static_fields) _nonstatic_oopmap_count++;\n+        group->add_oop_field(idx);\n+        break;\n+      case T_PRIMITIVE_OBJECT:\n+        _has_inline_type_fields = true;\n+        if (group == _static_fields) {\n+          \/\/ static fields are never inlined\n+          group->add_oop_field(idx);\n+        } else {\n+          _has_flattening_information = true;\n+          \/\/ Flattening decision to be taken here\n+          \/\/ This code assumes all verification already have been performed\n+          \/\/ (field's type has been loaded and it is an inline klass)\n+          JavaThread* THREAD = JavaThread::current();\n+          Klass* klass =  _inline_type_field_klasses->at(idx);\n+          assert(klass != nullptr, \"Sanity check\");\n+          InlineKlass* vk = InlineKlass::cast(klass);\n+          bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&\n+                                     (vk->size_helper() * HeapWordSize) > InlineFieldMaxFlatSize);\n+          bool too_atomic_to_flatten = vk->is_declared_atomic() || AlwaysAtomicAccesses;\n+          bool too_volatile_to_flatten = fieldinfo.access_flags().is_volatile();\n+          if (vk->is_naturally_atomic()) {\n+            too_atomic_to_flatten = false;\n+            \/\/too_volatile_to_flatten = false; \/\/FIXME\n+            \/\/ volatile fields are currently never inlined, this could change in the future\n+          }\n+          if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten) || fieldinfo.access_flags().is_final()) {\n+            group->add_inlined_field(idx, vk);\n+            _nonstatic_oopmap_count += vk->nonstatic_oop_map_count();\n+            _field_info->adr_at(idx)->field_flags_addr()->update_inlined(true);\n+            if (!vk->is_atomic()) {  \/\/ flat and non-atomic: take note\n+              _has_nonatomic_values = true;\n+              _atomic_field_count--;  \/\/ every other field is atomic but this one\n@@ -789,0 +787,3 @@\n+          } else {\n+            _nonstatic_oopmap_count++;\n+            group->add_oop_field(idx);\n@@ -790,3 +791,4 @@\n-          break;\n-        default:\n-          fatal(\"Something wrong?\");\n+        }\n+        break;\n+      default:\n+        fatal(\"Something wrong?\");\n@@ -819,2 +821,3 @@\n-  for (AllFieldStream fs(_fields, _constant_pool, _multifield_info); !fs.done(); fs.next()) {\n-    FieldGroup* group = NULL;\n+  for (GrowableArrayIterator<FieldInfo> it = _field_info->begin(); it != _field_info->end(); ++it) {\n+    FieldGroup* group = nullptr;\n+    FieldInfo fieldinfo = *it;\n@@ -822,1 +825,1 @@\n-    if (fs.access_flags().is_static()) {\n+    if (fieldinfo.access_flags().is_static()) {\n@@ -829,2 +832,0 @@\n-    assert(group != NULL, \"invariant\");\n-    BasicType type = Signature::basic_type(fs.signature());\n@@ -832,2 +833,2 @@\n-    if (fs.is_multifield() || fs.is_multifield_base()) {\n-      group->add_multifield(fs, _multifield_info);\n+    if (fieldinfo.is_multifield() || fieldinfo.is_multifield_base()) {\n+      group->add_multifield(_constant_pool, &fieldinfo, _multifield_info);\n@@ -835,0 +836,2 @@\n+      assert(group != nullptr, \"invariant\");\n+      BasicType type = Signature::basic_type(fieldinfo.signature(_constant_pool));\n@@ -836,18 +839,43 @@\n-        case T_BYTE:\n-        case T_CHAR:\n-        case T_DOUBLE:\n-        case T_FLOAT:\n-        case T_INT:\n-        case T_LONG:\n-        case T_SHORT:\n-        case T_BOOLEAN:\n-          if (group != _static_fields) {\n-            field_alignment = type2aelembytes(type); \/\/ alignment == size for primitive types\n-          }\n-          group->add_primitive_field(fs, type);\n-          break;\n-        case T_OBJECT:\n-        case T_ARRAY:\n-          if (group != _static_fields) {\n-            _nonstatic_oopmap_count++;\n-            field_alignment = type2aelembytes(type); \/\/ alignment == size for oops\n+      case T_BYTE:\n+      case T_CHAR:\n+      case T_DOUBLE:\n+      case T_FLOAT:\n+      case T_INT:\n+      case T_LONG:\n+      case T_SHORT:\n+      case T_BOOLEAN:\n+        if (group != _static_fields) {\n+          field_alignment = type2aelembytes(type); \/\/ alignment == size for primitive types\n+        }\n+        group->add_primitive_field(fieldinfo.index(), type);\n+        break;\n+      case T_OBJECT:\n+      case T_ARRAY:\n+        if (group != _static_fields) {\n+          _nonstatic_oopmap_count++;\n+          field_alignment = type2aelembytes(type); \/\/ alignment == size for oops\n+        }\n+        group->add_oop_field(fieldinfo.index());\n+        break;\n+      case T_PRIMITIVE_OBJECT: {\n+  \/\/      fs.set_inline(true);\n+        _has_inline_type_fields = true;\n+        if (group == _static_fields) {\n+          \/\/ static fields are never inlined\n+          group->add_oop_field(fieldinfo.index());\n+        } else {\n+          \/\/ Flattening decision to be taken here\n+          \/\/ This code assumes all verifications have already been performed\n+          \/\/ (field's type has been loaded and it is an inline klass)\n+          JavaThread* THREAD = JavaThread::current();\n+          Klass* klass =  _inline_type_field_klasses->at(fieldinfo.index());\n+          assert(klass != nullptr, \"Sanity check\");\n+          InlineKlass* vk = InlineKlass::cast(klass);\n+          bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&\n+                                     (vk->size_helper() * HeapWordSize) > InlineFieldMaxFlatSize);\n+          bool too_atomic_to_flatten = vk->is_declared_atomic() || AlwaysAtomicAccesses;\n+          bool too_volatile_to_flatten = fieldinfo.access_flags().is_volatile();\n+          if (vk->is_naturally_atomic()) {\n+            too_atomic_to_flatten = false;\n+            \/\/too_volatile_to_flatten = false; \/\/FIXME\n+            \/\/ volatile fields are currently never inlined, this could change in the future\n@@ -855,38 +883,8 @@\n-          group->add_oop_field(fs);\n-          break;\n-        case T_PRIMITIVE_OBJECT: {\n-          \/\/      fs.set_inline(true);\n-          _has_inline_type_fields = true;\n-          if (group == _static_fields) {\n-            \/\/ static fields are never inlined\n-            group->add_oop_field(fs);\n-          } else {\n-            \/\/ Flattening decision to be taken here\n-            \/\/ This code assumes all verifications have already been performed\n-            \/\/ (field's type has been loaded and it is an inline klass)\n-            JavaThread* THREAD = JavaThread::current();\n-            Klass* klass =  _inline_type_field_klasses->at(fs.index());\n-            assert(klass != NULL, \"Sanity check\");\n-            InlineKlass* vk = InlineKlass::cast(klass);\n-            bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&\n-                                      (vk->size_helper() * HeapWordSize) > InlineFieldMaxFlatSize);\n-            bool too_atomic_to_flatten = vk->is_declared_atomic() || AlwaysAtomicAccesses;\n-            bool too_volatile_to_flatten = fs.access_flags().is_volatile();\n-            if (vk->is_naturally_atomic()) {\n-              too_atomic_to_flatten = false;\n-              \/\/too_volatile_to_flatten = false; \/\/FIXME\n-              \/\/ volatile fields are currently never inlined, this could change in the future\n-            }\n-            if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten) || fs.access_flags().is_final()) {\n-              group->add_inlined_field(fs, vk);\n-              _nonstatic_oopmap_count += vk->nonstatic_oop_map_count();\n-              field_alignment = vk->get_alignment();\n-              fs.set_inlined(true);\n-              if (!vk->is_atomic()) {  \/\/ flat and non-atomic: take note\n-                _has_nonatomic_values = true;\n-                _atomic_field_count--;  \/\/ every other field is atomic but this one\n-              }\n-            } else {\n-              _nonstatic_oopmap_count++;\n-              field_alignment = type2aelembytes(T_OBJECT);\n-              group->add_oop_field(fs);\n+          if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten) || fieldinfo.access_flags().is_final()) {\n+            group->add_inlined_field(fieldinfo.index(), vk);\n+            _nonstatic_oopmap_count += vk->nonstatic_oop_map_count();\n+            field_alignment = vk->get_alignment();\n+            _field_info->adr_at(fieldinfo.index())->field_flags_addr()->update_inlined(true);\n+            if (!vk->is_atomic()) {  \/\/ flat and non-atomic: take note\n+              _has_nonatomic_values = true;\n+              _atomic_field_count--;  \/\/ every other field is atomic but this one\n@@ -894,0 +892,4 @@\n+          } else {\n+            _nonstatic_oopmap_count++;\n+            field_alignment = type2aelembytes(T_OBJECT);\n+            group->add_oop_field(fieldinfo.index());\n@@ -895,3 +897,4 @@\n-          break;\n-        default:\n-          fatal(\"Unexpected BasicType\");\n+        break;\n+      }\n+      default:\n+        fatal(\"Unexpected BasicType\");\n@@ -899,0 +902,1 @@\n+      if (!fieldinfo.access_flags().is_static() && field_alignment > alignment) alignment = field_alignment;\n@@ -901,1 +905,0 @@\n-    if (!fs.access_flags().is_static() && field_alignment > alignment) alignment = field_alignment;\n@@ -1025,1 +1028,1 @@\n-   if (first_field != NULL) {\n+   if (first_field != nullptr) {\n@@ -1054,1 +1057,1 @@\n-  if (list != NULL) {\n+  if (list != nullptr) {\n@@ -1059,1 +1062,1 @@\n-        assert(vk != NULL, \"Should have been initialized\");\n+        assert(vk != nullptr, \"Should have been initialized\");\n@@ -1069,1 +1072,1 @@\n-  if (group->oop_fields() != NULL) {\n+  if (group->oop_fields() != nullptr) {\n@@ -1081,1 +1084,1 @@\n-  int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass->nonstatic_oop_map_count();\n+  int super_oop_map_count = (_super_klass == nullptr) ? 0 :_super_klass->nonstatic_oop_map_count();\n@@ -1094,1 +1097,1 @@\n-        assert(cg->oop_fields() != NULL && cg->oop_fields()->at(0) != NULL, \"oop_count > 0 but no oop fields found\");\n+        assert(cg->oop_fields() != nullptr && cg->oop_fields()->at(0) != nullptr, \"oop_count > 0 but no oop fields found\");\n@@ -1135,1 +1138,1 @@\n-    _static_layout->print(tty, true, NULL);\n+    _static_layout->print(tty, true, nullptr);\n","filename":"src\/hotspot\/share\/classfile\/fieldLayoutBuilder.cpp","additions":293,"deletions":290,"binary":false,"changes":583,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -100,1 +100,1 @@\n-    assert(_inline_klass != NULL, \"Must be initialized\");\n+    assert(_inline_klass != nullptr, \"Must be initialized\");\n@@ -146,3 +146,3 @@\n-  void add_field(AllFieldStream fs, InlineKlass* vk);\n-    static int compare_multifield_index(LayoutRawBlock** x, LayoutRawBlock** y) {\n-     return (*x)->multifield_index() - (*y)->multifield_index();\n+  void add_field(ConstantPool* cp, FieldInfo* field, InlineKlass* vk, Array<MultiFieldInfo>* multifield_info);\n+  static int compare_multifield_index(LayoutRawBlock** x, LayoutRawBlock** y) {\n+    return (*x)->multifield_index() - (*y)->multifield_index();\n@@ -189,4 +189,4 @@\n-  void add_primitive_field(AllFieldStream fs, BasicType type);\n-  void add_oop_field(AllFieldStream fs);\n-  void add_inlined_field(AllFieldStream fs, InlineKlass* vk);\n-  void add_multifield(AllFieldStream fs, Array<MultiFieldInfo>* multifield_info, InlineKlass* vk = NULL);\n+  void add_primitive_field(int idx, BasicType type);\n+  void add_oop_field(int idx);\n+  void add_inlined_field(int idx, InlineKlass* vk);\n+  void add_multifield(ConstantPool* cp, FieldInfo* field, Array<MultiFieldInfo>* multifield_info, InlineKlass* vk = NULL);\n@@ -218,1 +218,1 @@\n-  Array<u2>* _fields;\n+  GrowableArray<FieldInfo>* _field_info;\n@@ -226,1 +226,1 @@\n-  FieldLayout(Array<u2>* fields, ConstantPool* cp, Array<MultiFieldInfo>* multifields);\n+  FieldLayout(GrowableArray<FieldInfo>* field_info, ConstantPool* cp, Array<MultiFieldInfo>* multifields);\n@@ -245,4 +245,4 @@\n-  void add(GrowableArray<LayoutRawBlock*>* list, LayoutRawBlock* start = NULL);\n-  void add_field_at_offset(LayoutRawBlock* blocks, int offset, LayoutRawBlock* start = NULL);\n-  void add_contiguously(GrowableArray<LayoutRawBlock*>* list, LayoutRawBlock* start = NULL);\n-  void add_multifield(MultiFieldGroup* multifield, LayoutRawBlock* start = NULL);\n+  void add(GrowableArray<LayoutRawBlock*>* list, LayoutRawBlock* start = nullptr);\n+  void add_field_at_offset(LayoutRawBlock* blocks, int offset, LayoutRawBlock* start = nullptr);\n+  void add_contiguously(GrowableArray<LayoutRawBlock*>* list, LayoutRawBlock* start = nullptr);\n+  void add_multifield(MultiFieldGroup* multifield, LayoutRawBlock* start = nullptr);\n@@ -286,1 +286,1 @@\n-  Array<u2>* _fields;\n+  GrowableArray<FieldInfo>* _field_info;\n@@ -312,2 +312,2 @@\n-      Array<u2>* fields, bool is_contended, bool is_inline_type, FieldLayoutInfo* info,\n-      Array<InlineKlass*>* inline_type_field_klasses, Array<MultiFieldInfo>* multifields);\n+                     GrowableArray<FieldInfo>* field_info, bool is_contended, bool is_inline_type, FieldLayoutInfo* info,\n+                     Array<InlineKlass*>* inline_type_field_klasses, Array<MultiFieldInfo>* multifields);\n","filename":"src\/hotspot\/share\/classfile\/fieldLayoutBuilder.hpp","additions":18,"deletions":18,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -53,0 +53,1 @@\n+#include \"oops\/fieldInfo.hpp\"\n@@ -129,1 +130,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -149,1 +150,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -160,1 +161,1 @@\n-  if (ik == NULL) {\n+  if (ik == nullptr) {\n@@ -186,1 +187,1 @@\n-  if (name == NULL) {\n+  if (name == nullptr) {\n@@ -254,1 +255,1 @@\n-      assert(mirror != NULL, \"String must have mirror already\");\n+      assert(mirror != nullptr, \"String must have mirror already\");\n@@ -323,1 +324,1 @@\n-  if (utf8_str == NULL) {\n+  if (utf8_str == nullptr) {\n@@ -405,1 +406,1 @@\n-  assert(str != NULL, \"bad arguments\");\n+  assert(str != nullptr, \"bad arguments\");\n@@ -408,1 +409,1 @@\n-  static to_java_string_fn_t _to_java_string_fn = NULL;\n+  static to_java_string_fn_t _to_java_string_fn = nullptr;\n@@ -410,1 +411,1 @@\n-  if (_to_java_string_fn == NULL) {\n+  if (_to_java_string_fn == nullptr) {\n@@ -414,1 +415,1 @@\n-    if (_to_java_string_fn == NULL) {\n+    if (_to_java_string_fn == nullptr) {\n@@ -419,1 +420,1 @@\n-    if (_to_java_string_fn == NULL) {\n+    if (_to_java_string_fn == nullptr) {\n@@ -424,1 +425,1 @@\n-  jstring js = NULL;\n+  jstring js = nullptr;\n@@ -441,1 +442,1 @@\n-  static to_platform_string_fn_t _to_platform_string_fn = NULL;\n+  static to_platform_string_fn_t _to_platform_string_fn = nullptr;\n@@ -443,1 +444,1 @@\n-  if (_to_platform_string_fn == NULL) {\n+  if (_to_platform_string_fn == nullptr) {\n@@ -446,1 +447,1 @@\n-    if (_to_platform_string_fn == NULL) {\n+    if (_to_platform_string_fn == nullptr) {\n@@ -476,1 +477,1 @@\n-  if (result == NULL) {\n+  if (result == nullptr) {\n@@ -488,1 +489,1 @@\n-  if (result != NULL) {\n+  if (result != nullptr) {\n@@ -553,1 +554,1 @@\n-  if (length == 0) return NULL;\n+  if (length == 0) return nullptr;\n@@ -578,1 +579,1 @@\n-    jchar* base = (length == 0) ? NULL : value->char_at_addr(0);\n+    jchar* base = (length == 0) ? nullptr : value->char_at_addr(0);\n@@ -583,1 +584,1 @@\n-    jbyte* position = (length == 0) ? NULL : value->byte_at_addr(0);\n+    jbyte* position = (length == 0) ? nullptr : value->byte_at_addr(0);\n@@ -595,1 +596,1 @@\n-    jchar* base = (length == 0) ? NULL : value->char_at_addr(0);\n+    jchar* base = (length == 0) ? nullptr : value->char_at_addr(0);\n@@ -599,1 +600,1 @@\n-    jbyte* position = (length == 0) ? NULL : value->byte_at_addr(0);\n+    jbyte* position = (length == 0) ? nullptr : value->byte_at_addr(0);\n@@ -634,1 +635,1 @@\n-    jchar* position = (length == 0) ? NULL : value->char_at_addr(0);\n+    jchar* position = (length == 0) ? nullptr : value->char_at_addr(0);\n@@ -637,1 +638,1 @@\n-    jbyte* position = (length == 0) ? NULL : value->byte_at_addr(0);\n+    jbyte* position = (length == 0) ? nullptr : value->byte_at_addr(0);\n@@ -649,1 +650,1 @@\n-    jchar *position = (len == 0) ? NULL : value->char_at_addr(0);\n+    jchar *position = (len == 0) ? nullptr : value->char_at_addr(0);\n@@ -656,1 +657,1 @@\n-    jbyte *position = (len == 0) ? NULL : value->byte_at_addr(0);\n+    jbyte *position = (len == 0) ? nullptr : value->byte_at_addr(0);\n@@ -671,1 +672,1 @@\n-    jchar* position = (length == 0) ? NULL : value->char_at_addr(0);\n+    jchar* position = (length == 0) ? nullptr : value->char_at_addr(0);\n@@ -674,1 +675,1 @@\n-    jbyte* position = (length == 0) ? NULL : value->byte_at_addr(0);\n+    jbyte* position = (length == 0) ? nullptr : value->byte_at_addr(0);\n@@ -757,1 +758,1 @@\n-  if (value == NULL) {\n+  if (value == nullptr) {\n@@ -760,1 +761,1 @@\n-    st->print(\"NULL\");\n+    st->print(\"nullptr\");\n@@ -769,2 +770,7 @@\n-    st->print(\"%c\", (!is_latin1) ?  value->char_at(index) :\n-                           ((jchar) value->byte_at(index)) & 0xff );\n+    jchar c = (!is_latin1) ?  value->char_at(index) :\n+                             ((jchar) value->byte_at(index)) & 0xff;\n+    if (c < ' ') {\n+      st->print(\"\\\\x%02X\", c); \/\/ print control characters e.g. \\x0A\n+    } else {\n+      st->print(\"%c\", c);\n+    }\n@@ -794,2 +800,2 @@\n-GrowableArray<Klass*>* java_lang_Class::_fixup_mirror_list = NULL;\n-GrowableArray<Klass*>* java_lang_Class::_fixup_module_field_list = NULL;\n+GrowableArray<Klass*>* java_lang_Class::_fixup_mirror_list = nullptr;\n+GrowableArray<Klass*>* java_lang_Class::_fixup_module_field_list = nullptr;\n@@ -813,12 +819,0 @@\n-#if INCLUDE_CDS_JAVA_HEAP\n-static void initialize_static_string_field_for_dump(fieldDescriptor* fd, Handle mirror) {\n-  DEBUG_ONLY(assert_valid_static_string_field(fd);)\n-  assert(DumpSharedSpaces, \"must be\");\n-  assert(HeapShared::is_archived_object_during_dumptime(mirror()), \"must be\");\n-  \/\/ Archive the String field and update the pointer.\n-  oop s = mirror()->obj_field(fd->offset());\n-  oop archived_s = StringTable::create_archived_string(s);\n-  mirror()->obj_field_put(fd->offset(), archived_s);\n-}\n-#endif\n-\n@@ -871,13 +865,0 @@\n-#if INCLUDE_CDS_JAVA_HEAP\n-static void initialize_static_field_for_dump(fieldDescriptor* fd, Handle mirror) {\n-  assert(mirror.not_null() && fd->is_static(), \"just checking\");\n-  if (fd->has_initial_value()) {\n-    if (fd->field_type() != T_OBJECT) {\n-      initialize_static_primitive_field(fd, mirror);\n-    } else {\n-      initialize_static_string_field_for_dump(fd, mirror);\n-    }\n-  }\n-}\n-#endif\n-\n@@ -893,4 +874,16 @@\n-      for (JavaFieldStream fs(InstanceKlass::cast(k)); !fs.done(); fs.next()) {\n-        if (fs.access_flags().is_static()) {\n-          int real_offset = fs.offset() + InstanceMirrorKlass::offset_of_static_fields();\n-          fs.set_offset(real_offset);\n+\n+      \/\/ Unfortunately, the FieldInfo stream is encoded with UNSIGNED5 which doesn't allow\n+      \/\/ content updates. So the FieldInfo stream has to be decompressed into a temporary array,\n+      \/\/ static fields offsets are updated in this array before reencoding everything into\n+      \/\/ a new UNSIGNED5 stream, and substitute it to the old FieldInfo stream.\n+\n+      int java_fields;\n+      int injected_fields;\n+      InstanceKlass* ik = InstanceKlass::cast(k);\n+      GrowableArray<FieldInfo>* fields =\n+        FieldInfoStream::create_FieldInfoArray(ik->fieldinfo_stream(),\n+                                               &java_fields, &injected_fields);\n+      for (int i = 0; i < fields->length(); i++) {\n+        FieldInfo* fi = fields->adr_at(i);\n+        if (fi->access_flags().is_static()) {\n+          fi->set_offset(fi->offset() + InstanceMirrorKlass::offset_of_static_fields());\n@@ -899,0 +892,5 @@\n+      Array<u1>* old_stream = ik->fieldinfo_stream();\n+      assert(fields->length() == (java_fields + injected_fields), \"Must be\");\n+      Array<u1>* new_fis = FieldInfoStream::create_FieldInfoStream(fields, java_fields, injected_fields, k->class_loader_data(), CHECK);\n+      ik->set_fieldinfo_stream(new_fis);\n+      MetadataFactory::free_array<u1>(k->class_loader_data(), old_stream);\n@@ -903,1 +901,1 @@\n-    if (ArchiveHeapLoader::are_archived_mirrors_available()) {\n+    if (ArchiveHeapLoader::is_in_use()) {\n@@ -933,1 +931,1 @@\n-    \/\/ During startup, the module may be NULL only if java.base has not been defined yet.\n+    \/\/ During startup, the module may be null only if java.base has not been defined yet.\n@@ -935,1 +933,1 @@\n-    \/\/ for java.base is known. But note that since we captured the NULL module another\n+    \/\/ for java.base is known. But note that since we captured the null module another\n@@ -943,1 +941,1 @@\n-        assert(k->java_mirror() != NULL, \"Class's mirror is null\");\n+        assert(k->java_mirror() != nullptr, \"Class's mirror is null\");\n@@ -945,1 +943,1 @@\n-        assert(fixup_module_field_list() != NULL, \"fixup_module_field_list not initialized\");\n+        assert(fixup_module_field_list() != nullptr, \"fixup_module_field_list not initialized\");\n@@ -955,1 +953,1 @@\n-      assert(javabase_entry != NULL && javabase_entry->module() != NULL,\n+      assert(javabase_entry != nullptr && javabase_entry->module() != nullptr,\n@@ -980,0 +978,69 @@\n+void java_lang_Class::allocate_mirror(Klass* k, bool is_scratch, Handle protection_domain, Handle classData,\n+                                      Handle& mirror, Handle& comp_mirror, TRAPS) {\n+  \/\/ Allocate mirror (java.lang.Class instance)\n+  oop mirror_oop = InstanceMirrorKlass::cast(vmClasses::Class_klass())->allocate_instance(k, CHECK);\n+  mirror = Handle(THREAD, mirror_oop);\n+\n+  \/\/ Setup indirection from mirror->klass\n+  set_klass(mirror(), k);\n+\n+  InstanceMirrorKlass* mk = InstanceMirrorKlass::cast(mirror->klass());\n+  assert(oop_size(mirror()) == mk->instance_size(k), \"should have been set\");\n+\n+  set_static_oop_field_count(mirror(), mk->compute_static_oop_field_count(mirror()));\n+\n+  \/\/ It might also have a component mirror.  This mirror must already exist.\n+  if (k->is_array_klass()) {\n+    if (k->is_flatArray_klass()) {\n+      Klass* element_klass = (Klass*) FlatArrayKlass::cast(k)->element_klass();\n+      assert(element_klass->is_inline_klass(), \"Must be inline type component\");\n+      if (is_scratch) {\n+        comp_mirror = Handle(THREAD, HeapShared::scratch_java_mirror(element_klass));\n+      } else {\n+        InlineKlass* vk = InlineKlass::cast(element_klass);\n+        comp_mirror = Handle(THREAD, vk->val_mirror());\n+      }\n+    } else if (k->is_typeArray_klass()) {\n+      BasicType type = TypeArrayKlass::cast(k)->element_type();\n+      if (is_scratch) {\n+        comp_mirror = Handle(THREAD, HeapShared::scratch_java_mirror(type));\n+      } else {\n+        comp_mirror = Handle(THREAD, Universe::java_mirror(type));\n+      }\n+    } else {\n+      assert(k->is_objArray_klass(), \"Must be\");\n+      Klass* element_klass = ObjArrayKlass::cast(k)->element_klass();\n+      assert(element_klass != nullptr, \"Must have an element klass\");\n+      oop comp_oop = element_klass->java_mirror();\n+      if (element_klass->is_inline_klass()) {\n+        InlineKlass* ik = InlineKlass::cast(element_klass);\n+        comp_oop = k->name()->is_Q_array_signature() ? ik->val_mirror() : ik->ref_mirror();\n+      }\n+      if (is_scratch) {\n+        comp_mirror = Handle(THREAD, HeapShared::scratch_java_mirror(element_klass));\n+      } else {\n+        comp_mirror = Handle(THREAD, comp_oop);\n+      }\n+    }\n+    assert(comp_mirror() != nullptr, \"must have a mirror\");\n+\n+    \/\/ Two-way link between the array klass and its component mirror:\n+    \/\/ (array_klass) k -> mirror -> component_mirror -> array_klass -> k\n+    set_component_mirror(mirror(), comp_mirror());\n+    \/\/ See below for ordering dependencies between field array_klass in component mirror\n+    \/\/ and java_mirror in this klass.\n+  } else {\n+    assert(k->is_instance_klass(), \"Must be\");\n+\n+    initialize_mirror_fields(k, mirror, protection_domain, classData, THREAD);\n+    if (HAS_PENDING_EXCEPTION) {\n+      \/\/ If any of the fields throws an exception like OOM remove the klass field\n+      \/\/ from the mirror so GC doesn't follow it after the klass has been deallocated.\n+      \/\/ This mirror looks like a primitive type, which logically it is because it\n+      \/\/ it represents no class.\n+      set_klass(mirror(), nullptr);\n+      return;\n+    }\n+  }\n+}\n+\n@@ -983,2 +1050,2 @@\n-  assert(k != NULL, \"Use create_basic_type_mirror for primitive types\");\n-  assert(k->java_mirror() == NULL, \"should only assign mirror once\");\n+  assert(k != nullptr, \"Use create_basic_type_mirror for primitive types\");\n+  assert(k->java_mirror() == nullptr, \"should only assign mirror once\");\n@@ -995,3 +1062,1 @@\n-    \/\/ Allocate mirror (java.lang.Class instance)\n-    oop mirror_oop = InstanceMirrorKlass::cast(vmClasses::Class_klass())->allocate_instance(k, CHECK);\n-    Handle mirror(THREAD, mirror_oop);\n+    Handle mirror;\n@@ -1000,49 +1065,1 @@\n-    \/\/ Setup indirection from mirror->klass\n-    set_klass(mirror(), k);\n-\n-    InstanceMirrorKlass* mk = InstanceMirrorKlass::cast(mirror->klass());\n-    assert(oop_size(mirror()) == mk->instance_size(k), \"should have been set\");\n-\n-    set_static_oop_field_count(mirror(), mk->compute_static_oop_field_count(mirror()));\n-\n-    \/\/ It might also have a component mirror.  This mirror must already exist.\n-    if (k->is_array_klass()) {\n-      if (k->is_flatArray_klass()) {\n-        Klass* element_klass = (Klass*) FlatArrayKlass::cast(k)->element_klass();\n-        assert(element_klass->is_inline_klass(), \"Must be inline type component\");\n-        InlineKlass* vk = InlineKlass::cast(element_klass);\n-        comp_mirror = Handle(THREAD, vk->val_mirror());\n-      } else if (k->is_typeArray_klass()) {\n-        BasicType type = TypeArrayKlass::cast(k)->element_type();\n-        comp_mirror = Handle(THREAD, Universe::java_mirror(type));\n-      } else {\n-        assert(k->is_objArray_klass(), \"Must be\");\n-        Klass* element_klass = ObjArrayKlass::cast(k)->element_klass();\n-        assert(element_klass != NULL, \"Must have an element klass\");\n-        oop comp_oop = element_klass->java_mirror();\n-        if (element_klass->is_inline_klass()) {\n-          InlineKlass* ik = InlineKlass::cast(element_klass);\n-          comp_oop = k->name()->is_Q_array_signature() ? ik->val_mirror() : ik->ref_mirror();\n-        }\n-        comp_mirror = Handle(THREAD, comp_oop);\n-      }\n-      assert(comp_mirror() != NULL, \"must have a mirror\");\n-\n-      \/\/ Two-way link between the array klass and its component mirror:\n-      \/\/ (array_klass) k -> mirror -> component_mirror -> array_klass -> k\n-      set_component_mirror(mirror(), comp_mirror());\n-      \/\/ See below for ordering dependencies between field array_klass in component mirror\n-      \/\/ and java_mirror in this klass.\n-    } else {\n-      assert(k->is_instance_klass(), \"Must be\");\n-\n-      initialize_mirror_fields(k, mirror, protection_domain, classData, THREAD);\n-      if (HAS_PENDING_EXCEPTION) {\n-        \/\/ If any of the fields throws an exception like OOM remove the klass field\n-        \/\/ from the mirror so GC doesn't follow it after the klass has been deallocated.\n-        \/\/ This mirror looks like a primitive type, which logically it is because it\n-        \/\/ it represents no class.\n-        set_klass(mirror(), NULL);\n-        return;\n-      }\n-    }\n+    allocate_mirror(k, \/*is_scratch=*\/false, protection_domain, classData, mirror, comp_mirror, CHECK);\n@@ -1062,1 +1079,1 @@\n-    if (comp_mirror() != NULL) {\n+    if (comp_mirror() != nullptr) {\n@@ -1073,0 +1090,3 @@\n+    if (DumpSharedSpaces) {\n+      create_scratch_mirror(k, CHECK);\n+    }\n@@ -1074,1 +1094,1 @@\n-    assert(fixup_mirror_list() != NULL, \"fixup_mirror_list not initialized\");\n+    assert(fixup_mirror_list() != nullptr, \"fixup_mirror_list not initialized\");\n@@ -1099,87 +1119,4 @@\n-\/\/ Clears mirror fields. Static final fields with initial values are reloaded\n-\/\/ from constant pool. The object identity hash is in the object header and is\n-\/\/ not affected.\n-class ResetMirrorField: public FieldClosure {\n- private:\n-  Handle _m;\n-\n- public:\n-  ResetMirrorField(Handle mirror) : _m(mirror) {}\n-\n-  void do_field(fieldDescriptor* fd) {\n-    assert(DumpSharedSpaces, \"dump time only\");\n-    assert(_m.not_null(), \"Mirror cannot be NULL\");\n-\n-    if (fd->is_static() && fd->has_initial_value()) {\n-      initialize_static_field_for_dump(fd, _m);\n-      return;\n-    }\n-\n-    BasicType ft = fd->field_type();\n-    switch (ft) {\n-      case T_BYTE:\n-        _m()->byte_field_put(fd->offset(), 0);\n-        break;\n-      case T_CHAR:\n-        _m()->char_field_put(fd->offset(), 0);\n-        break;\n-      case T_DOUBLE:\n-        _m()->double_field_put(fd->offset(), 0);\n-        break;\n-      case T_FLOAT:\n-        _m()->float_field_put(fd->offset(), 0);\n-        break;\n-      case T_INT:\n-        _m()->int_field_put(fd->offset(), 0);\n-        break;\n-      case T_LONG:\n-        _m()->long_field_put(fd->offset(), 0);\n-        break;\n-      case T_SHORT:\n-        _m()->short_field_put(fd->offset(), 0);\n-        break;\n-      case T_BOOLEAN:\n-        _m()->bool_field_put(fd->offset(), false);\n-        break;\n-      case T_PRIMITIVE_OBJECT:\n-      case T_ARRAY:\n-      case T_OBJECT: {\n-        \/\/ It might be useful to cache the String field, but\n-        \/\/ for now just clear out any reference field\n-        oop o = _m()->obj_field(fd->offset());\n-        _m()->obj_field_put(fd->offset(), NULL);\n-        break;\n-      }\n-      default:\n-        ShouldNotReachHere();\n-        break;\n-     }\n-  }\n-};\n-\n-void java_lang_Class::archive_basic_type_mirrors() {\n-  assert(HeapShared::can_write(), \"must be\");\n-\n-  for (int t = T_BOOLEAN; t < T_VOID+1; t++) {\n-    BasicType bt = (BasicType)t;\n-    if (!is_reference_type(bt)) {\n-      oop m = Universe::java_mirror(bt);\n-      assert(m != NULL, \"sanity\");\n-      \/\/ Update the field at _array_klass_offset to point to the relocated array klass.\n-      oop archived_m = HeapShared::archive_object(m);\n-      assert(archived_m != NULL, \"sanity\");\n-\n-      \/\/ Clear the fields. Just to be safe\n-      Klass *k = m->klass();\n-      Handle archived_mirror_h(Thread::current(), archived_m);\n-      ResetMirrorField reset(archived_mirror_h);\n-      InstanceKlass::cast(k)->do_nonstatic_fields(&reset);\n-\n-      log_trace(cds, heap, mirror)(\n-        \"Archived %s mirror object from \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n-        type2name(bt), p2i(m), p2i(archived_m));\n-\n-      Universe::set_archived_basic_type_mirror_index(bt, HeapShared::append_root(archived_m));\n-    }\n-  }\n-}\n+\/\/ The \"scratch mirror\" stores the states of the mirror object that can be\n+\/\/ decided at dump time (such as the initial values of the static fields, the\n+\/\/ component mirror, etc). At runtime, more information is added to it by\n+\/\/ java_lang_Class::restore_archived_mirror().\n@@ -1187,2 +1124,2 @@\n-\/\/ After the mirror object is successfully archived, the archived\n-\/\/ klass is set with _has_archived_raw_mirror flag.\n+\/\/ Essentially, \/*dumptime*\/create_scratch_mirror() + \/*runtime*\/restore_archived_mirror()\n+\/\/ produces the same result as \/*runtime*\/create_mirror().\n@@ -1190,46 +1127,9 @@\n-\/\/ The _has_archived_raw_mirror flag is cleared at runtime when the\n-\/\/ archived mirror is restored. If archived java heap data cannot\n-\/\/ be used at runtime, new mirror object is created for the shared\n-\/\/ class. The _has_archived_raw_mirror is cleared also during the process.\n-oop java_lang_Class::archive_mirror(Klass* k) {\n-  assert(HeapShared::can_write(), \"must be\");\n-\n-  \/\/ Mirror is already archived\n-  if (k->has_archived_mirror_index()) {\n-    assert(k->archived_java_mirror() != NULL, \"no archived mirror\");\n-    return k->archived_java_mirror();\n-  }\n-\n-  \/\/ No mirror\n-  oop mirror = k->java_mirror();\n-  if (mirror == NULL) {\n-    return NULL;\n-  }\n-\n-  if (k->is_instance_klass()) {\n-    InstanceKlass *ik = InstanceKlass::cast(k);\n-    assert(ik->signers() == NULL, \"class with signer should have been excluded\");\n-\n-    if (!(ik->is_shared_boot_class() || ik->is_shared_platform_class() ||\n-          ik->is_shared_app_class())) {\n-      \/\/ Archiving mirror for classes from non-builtin loaders is not\n-      \/\/ supported.\n-      return NULL;\n-    }\n-  }\n-\n-  if (k->is_inline_klass()) {\n-    \/\/ Inline types have a primary mirror and a secondary mirror. Don't handle this for now. TODO:CDS\n-    k->clear_java_mirror_handle();\n-    return NULL;\n-  }\n-\n-  \/\/ Now start archiving the mirror object\n-  oop archived_mirror = HeapShared::archive_object(mirror);\n-  if (archived_mirror == NULL) {\n-    return NULL;\n-  }\n-\n-  archived_mirror = process_archived_mirror(k, mirror, archived_mirror);\n-  if (archived_mirror == NULL) {\n-    return NULL;\n+\/\/ Note: we archive the \"scratch mirror\" instead of k->java_mirror(), because the\n+\/\/ latter may contain dumptime-specific information that cannot be archived\n+\/\/ (e.g., ClassLoaderData*, or static fields that are modified by Java code execution).\n+void java_lang_Class::create_scratch_mirror(Klass* k, TRAPS) {\n+  if (k->class_loader() != nullptr &&\n+      k->class_loader() != SystemDictionary::java_platform_loader() &&\n+      k->class_loader() != SystemDictionary::java_system_loader()) {\n+    \/\/ We only archive the mirrors of classes loaded by the built-in loaders\n+    return;\n@@ -1238,42 +1138,4 @@\n-  k->set_archived_java_mirror(archived_mirror);\n-\n-  ResourceMark rm;\n-  log_trace(cds, heap, mirror)(\n-    \"Archived %s mirror object from \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n-    k->external_name(), p2i(mirror), p2i(archived_mirror));\n-\n-  return archived_mirror;\n-}\n-\n-\/\/ The process is based on create_mirror().\n-oop java_lang_Class::process_archived_mirror(Klass* k, oop mirror,\n-                                             oop archived_mirror) {\n-  \/\/ Clear nonstatic fields in archived mirror. Some of the fields will be set\n-  \/\/ to archived metadata and objects below.\n-  Klass *c = archived_mirror->klass();\n-  Handle archived_mirror_h(Thread::current(), archived_mirror);\n-  ResetMirrorField reset(archived_mirror_h);\n-  InstanceKlass::cast(c)->do_nonstatic_fields(&reset);\n-\n-  if (k->is_array_klass()) {\n-    oop archived_comp_mirror;\n-    if (k->is_typeArray_klass()) {\n-      \/\/ The primitive type mirrors are already archived. Get the archived mirror.\n-      oop comp_mirror = component_mirror(mirror);\n-      archived_comp_mirror = HeapShared::find_archived_heap_object(comp_mirror);\n-      assert(archived_comp_mirror != NULL, \"Must be\");\n-    } else {\n-      assert(k->is_objArray_klass(), \"Must be\");\n-      Klass* element_klass = ObjArrayKlass::cast(k)->element_klass();\n-      assert(element_klass != NULL, \"Must have an element klass\");\n-      archived_comp_mirror = archive_mirror(element_klass);\n-      if (archived_comp_mirror == NULL) {\n-        return NULL;\n-      }\n-    }\n-    set_component_mirror(archived_mirror, archived_comp_mirror);\n-  } else {\n-    assert(k->is_instance_klass(), \"Must be\");\n-\n-    \/\/ Reset local static fields in the mirror\n-    InstanceKlass::cast(k)->do_local_static_fields(&reset);\n+  Handle protection_domain, classData; \/\/ set to null. Will be reinitialized at runtime\n+  Handle mirror;\n+  Handle comp_mirror;\n+  allocate_mirror(k, \/*is_scratch=*\/true, protection_domain, classData, mirror, comp_mirror, CHECK);\n@@ -1281,3 +1143,2 @@\n-    set_protection_domain(archived_mirror, NULL);\n-    set_signers(archived_mirror, NULL);\n-    set_source_file(archived_mirror, NULL);\n+  if (comp_mirror() != nullptr) {\n+    release_set_array_klass(comp_mirror(), k);\n@@ -1286,5 +1147,1 @@\n-  \/\/ clear class loader and mirror_module_field\n-  set_class_loader(archived_mirror, NULL);\n-  set_module(archived_mirror, NULL);\n-\n-  return archived_mirror;\n+  HeapShared::set_scratch_java_mirror(k, mirror());\n@@ -1302,1 +1159,1 @@\n-    assert(fixup_mirror_list() != NULL, \"fixup_mirror_list not initialized\");\n+    assert(fixup_mirror_list() != nullptr, \"fixup_mirror_list not initialized\");\n@@ -1308,1 +1165,1 @@\n-  assert(m != NULL, \"must have stored non-null archived mirror\");\n+  assert(m != nullptr, \"must have stored non-null archived mirror\");\n@@ -1315,3 +1172,0 @@\n-  if (ArchiveHeapLoader::is_mapped()) {\n-    assert(Universe::heap()->is_archived_object(m), \"must be archived mirror object\");\n-  }\n@@ -1449,1 +1303,1 @@\n-  if (o == NULL) {\n+  if (o == nullptr) {\n@@ -1469,1 +1323,1 @@\n-  oop java_class = InstanceMirrorKlass::cast(vmClasses::Class_klass())->allocate_instance(NULL, CHECK_NULL);\n+  oop java_class = InstanceMirrorKlass::cast(vmClasses::Class_klass())->allocate_instance(nullptr, CHECK_NULL);\n@@ -1472,1 +1326,1 @@\n-    assert(aklass != NULL, \"correct bootstrap\");\n+    assert(aklass != nullptr, \"correct bootstrap\");\n@@ -1490,1 +1344,1 @@\n-  Symbol* name = NULL;\n+  Symbol* name = nullptr;\n@@ -1501,1 +1355,1 @@\n-  if (name == NULL) {\n+  if (name == nullptr) {\n@@ -1550,1 +1404,1 @@\n-  const char* name = NULL;\n+  const char* name = nullptr;\n@@ -1556,1 +1410,1 @@\n-  if (name == NULL) {\n+  if (name == nullptr) {\n@@ -1564,1 +1418,1 @@\n-  assert(k == NULL || k->is_klass() && k->is_array_klass(), \"should be array klass\");\n+  assert(k == nullptr || k->is_klass() && k->is_array_klass(), \"should be array klass\");\n@@ -1579,1 +1433,1 @@\n-  if (ak != NULL) {\n+  if (ak != nullptr) {\n@@ -1585,1 +1439,9 @@\n-  assert(Universe::java_mirror(type) == java_class, \"must be consistent\");\n+#ifdef ASSERT\n+  if (DumpSharedSpaces) {\n+    oop mirror = Universe::java_mirror(type);\n+    oop scratch_mirror = HeapShared::scratch_java_mirror(type);\n+    assert(java_class == mirror || java_class == scratch_mirror, \"must be consistent\");\n+  } else {\n+    assert(Universe::java_mirror(type) == java_class, \"must be consistent\");\n+  }\n+#endif\n@@ -1592,2 +1454,2 @@\n-    if (reference_klass != NULL)\n-      (*reference_klass) = NULL;\n+    if (reference_klass != nullptr)\n+      (*reference_klass) = nullptr;\n@@ -1596,1 +1458,1 @@\n-    if (reference_klass != NULL)\n+    if (reference_klass != nullptr)\n@@ -1605,1 +1467,1 @@\n-  assert(mirror != NULL && mirror->is_a(vmClasses::Class_klass()), \"must be a Class\");\n+  assert(mirror != nullptr && mirror->is_a(vmClasses::Class_klass()), \"must be a Class\");\n@@ -1708,2 +1570,3 @@\n-void java_lang_Thread_FieldHolder::set_daemon(oop holder) {\n-  holder->bool_field_put(_daemon_offset, true);\n+void java_lang_Thread_FieldHolder::set_daemon(oop holder, bool val) {\n+  assert(val, \"daemon status is never turned off\");\n+  holder->bool_field_put(_daemon_offset, val);\n@@ -1722,1 +1585,0 @@\n-int java_lang_Thread_Constants::_static_NOT_SUPPORTED_CLASSLOADER_offset = 0;\n@@ -1725,2 +1587,1 @@\n-  macro(_static_VTHREAD_GROUP_offset,             k, \"VTHREAD_GROUP\",             threadgroup_signature, true); \\\n-  macro(_static_NOT_SUPPORTED_CLASSLOADER_offset, k, \"NOT_SUPPORTED_CLASSLOADER\", classloader_signature, true);\n+  macro(_static_VTHREAD_GROUP_offset,             k, \"VTHREAD_GROUP\",             threadgroup_signature, true);\n@@ -1747,5 +1608,0 @@\n-oop java_lang_Thread_Constants::get_NOT_SUPPORTED_CLASSLOADER() {\n-  InstanceKlass* k = vmClasses::Thread_Constants_klass();\n-  oop base = k->static_field_base_raw();\n-  return base->obj_field(_static_NOT_SUPPORTED_CLASSLOADER_offset);\n-}\n@@ -1759,0 +1615,2 @@\n+int java_lang_Thread::_jvmti_VTMS_transition_disable_count_offset;\n+int java_lang_Thread::_jvmti_is_in_VTMS_transition_offset;\n@@ -1794,1 +1652,5 @@\n-  return (JavaThread*)java_thread->address_field(_eetop_offset);\n+  return reinterpret_cast<JavaThread*>(java_thread->address_field(_eetop_offset));\n+}\n+\n+JavaThread* java_lang_Thread::thread_acquire(oop java_thread) {\n+  return reinterpret_cast<JavaThread*>(java_thread->address_field_acquire(_eetop_offset));\n@@ -1801,0 +1663,4 @@\n+void java_lang_Thread::release_set_thread(oop java_thread, JavaThread* thread) {\n+  java_thread->release_address_field_put(_eetop_offset, (address)thread);\n+}\n+\n@@ -1809,0 +1675,29 @@\n+int java_lang_Thread::VTMS_transition_disable_count(oop java_thread) {\n+  return java_thread->int_field(_jvmti_VTMS_transition_disable_count_offset);\n+}\n+\n+void java_lang_Thread::inc_VTMS_transition_disable_count(oop java_thread) {\n+  assert(JvmtiVTMSTransition_lock->owned_by_self(), \"Must be locked\");\n+  int val = VTMS_transition_disable_count(java_thread);\n+  java_thread->int_field_put(_jvmti_VTMS_transition_disable_count_offset, val + 1);\n+}\n+\n+void java_lang_Thread::dec_VTMS_transition_disable_count(oop java_thread) {\n+  assert(JvmtiVTMSTransition_lock->owned_by_self(), \"Must be locked\");\n+  int val = VTMS_transition_disable_count(java_thread);\n+  assert(val > 0, \"VTMS_transition_disable_count should never be negative\");\n+  java_thread->int_field_put(_jvmti_VTMS_transition_disable_count_offset, val - 1);\n+}\n+\n+bool java_lang_Thread::is_in_VTMS_transition(oop java_thread) {\n+  return java_thread->bool_field_volatile(_jvmti_is_in_VTMS_transition_offset);\n+}\n+\n+void java_lang_Thread::set_is_in_VTMS_transition(oop java_thread, bool val) {\n+  java_thread->bool_field_put_volatile(_jvmti_is_in_VTMS_transition_offset, val);\n+}\n+\n+int java_lang_Thread::is_in_VTMS_transition_offset() {\n+  return _jvmti_is_in_VTMS_transition_offset;\n+}\n+\n@@ -1810,2 +1705,2 @@\n-  assert(java_thread != NULL, \"need a java_lang_Thread pointer here\");\n-  java_thread->obj_field_put(_scopedValueBindings_offset, NULL);\n+  assert(java_thread != nullptr, \"need a java_lang_Thread pointer here\");\n+  java_thread->obj_field_put(_scopedValueBindings_offset, nullptr);\n@@ -1815,1 +1710,2 @@\n-    return java_thread->obj_field(_holder_offset);\n+  \/\/ Note: may return null if the thread is still attaching\n+  return java_thread->obj_field(_holder_offset);\n@@ -1846,0 +1742,24 @@\n+\/\/ Convenience macros for setting and getting Thread fields that\n+\/\/ are actually stored in the FieldHolder object of the thread.\n+\/\/ The FieldHolder can be null whilst a thread is attaching via\n+\/\/ JNI, and when the main thread is attaching.\n+\n+\/\/ The default value should be the default\/zero initialized value\n+\/\/ of the field as it would be in java.lang.Thread.FieldHolder.\n+#define GET_FIELDHOLDER_FIELD(java_thread, field, default_val)  \\\n+  {                                                             \\\n+    oop holder = java_lang_Thread::holder(java_thread);         \\\n+    if (holder != nullptr)                                      \\\n+      return java_lang_Thread_FieldHolder::field(holder);       \\\n+    else                                                        \\\n+      return default_val;                                       \\\n+  }\n+\n+\/\/ We should never be trying to set a field of an attaching thread.\n+#define SET_FIELDHOLDER_FIELD(java_thread, field, value)        \\\n+  {                                                             \\\n+    oop holder = java_lang_Thread::holder(java_thread);         \\\n+    assert(holder != nullptr, \"Thread not fully initialized\");  \\\n+    java_lang_Thread_FieldHolder::set_##field(holder, value);   \\\n+  }\n+\n@@ -1848,3 +1768,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  assert(holder != NULL, \"Java Thread not initialized\");\n-  return java_lang_Thread_FieldHolder::priority(holder);\n+  GET_FIELDHOLDER_FIELD(java_thread, priority, (ThreadPriority)0);\n@@ -1855,3 +1773,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  assert(holder != NULL, \"Java Thread not initialized\");\n-  java_lang_Thread_FieldHolder::set_priority(holder, priority);\n+  SET_FIELDHOLDER_FIELD(java_thread, priority, priority)\n@@ -1862,3 +1778,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  assert(holder != NULL, \"Java Thread not initialized\");\n-  return java_lang_Thread_FieldHolder::threadGroup(holder);\n+  GET_FIELDHOLDER_FIELD(java_thread, threadGroup, nullptr);\n@@ -1870,1 +1784,1 @@\n-  return (thr != NULL);\n+  return (thr != nullptr);\n@@ -1875,3 +1789,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  assert(holder != NULL, \"Java Thread not initialized\");\n-  return java_lang_Thread_FieldHolder::is_daemon(holder);\n+  GET_FIELDHOLDER_FIELD(java_thread, is_daemon, false);\n@@ -1882,3 +1794,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  assert(holder != NULL, \"Java Thread not initialized\");\n-  java_lang_Thread_FieldHolder::set_daemon(holder);\n+  SET_FIELDHOLDER_FIELD(java_thread, daemon, true);\n@@ -1897,3 +1807,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  assert(holder != NULL, \"Java Thread not initialized\");\n-  return java_lang_Thread_FieldHolder::stackSize(holder);\n+  GET_FIELDHOLDER_FIELD(java_thread, stackSize, 0);\n@@ -1904,3 +1812,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  assert(holder != NULL, \"Java Thread not initialized\");\n-  java_lang_Thread_FieldHolder::set_thread_status(holder, status);\n+  SET_FIELDHOLDER_FIELD(java_thread, thread_status, status);\n@@ -1916,6 +1822,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  if (holder == NULL) {\n-    return JavaThreadStatus::NEW;  \/\/ Java Thread not initialized\n-  } else {\n-    return java_lang_Thread_FieldHolder::get_thread_status(holder);\n-  }\n+  GET_FIELDHOLDER_FIELD(java_thread, get_thread_status, JavaThreadStatus::NEW \/* not initialized *\/);\n@@ -1938,2 +1839,2 @@\n-    if (carrier_thread == NULL) {\n-      return NULL;\n+    if (carrier_thread == nullptr) {\n+      return nullptr;\n@@ -1945,2 +1846,2 @@\n-  if (thread == NULL) {\n-    return NULL;\n+  if (thread == nullptr) {\n+    return nullptr;\n@@ -1994,1 +1895,1 @@\n-        carrier = (thread->vthread_continuation() != NULL);\n+        carrier = (thread->vthread_continuation() != nullptr);\n@@ -2034,1 +1935,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -2039,1 +1940,1 @@\n-  assert(k != NULL, \"must be loaded in 1.4+\");\n+  assert(k != nullptr, \"must be loaded in 1.4+\");\n@@ -2057,3 +1958,1 @@\n-  oop holder = java_lang_Thread::holder(java_thread);\n-  assert(holder != NULL, \"Java Thread not initialized\");\n-  JavaThreadStatus status = java_lang_Thread_FieldHolder::get_thread_status(holder);\n+  JavaThreadStatus status = get_thread_status(java_thread);\n@@ -2088,1 +1987,1 @@\n-  if (name != NULL) {\n+  if (name != nullptr) {\n@@ -2091,1 +1990,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2126,1 +2025,0 @@\n-int java_lang_VirtualThread::static_notify_jvmti_events_offset;\n@@ -2133,1 +2031,0 @@\n-  macro(static_notify_jvmti_events_offset, k, \"notifyJvmtiEvents\",  bool_signature,              true);  \\\n@@ -2139,1 +2036,0 @@\n-static bool vthread_notify_jvmti_events = JNI_FALSE;\n@@ -2146,9 +2042,1 @@\n-void java_lang_VirtualThread::init_static_notify_jvmti_events() {\n-  if (vthread_notify_jvmti_events) {\n-    InstanceKlass* ik = vmClasses::VirtualThread_klass();\n-    oop base = ik->static_field_base_raw();\n-    base->release_bool_field_put(static_notify_jvmti_events_offset, vthread_notify_jvmti_events);\n-  }\n-}\n-\n-  return obj != NULL && is_subclass(obj->klass());\n+  return obj != nullptr && is_subclass(obj->klass());\n@@ -2206,9 +2094,0 @@\n-bool java_lang_VirtualThread::notify_jvmti_events() {\n-  return vthread_notify_jvmti_events == JNI_TRUE;\n-}\n-\n-void java_lang_VirtualThread::set_notify_jvmti_events(bool enable) {\n-  vthread_notify_jvmti_events = enable;\n-}\n-\n-\n@@ -2274,1 +2153,1 @@\n-\/\/ Return Symbol for detailed_message or NULL\n+\/\/ Return Symbol for detailed_message or null\n@@ -2278,1 +2157,1 @@\n-  if (detailed_message != NULL) {\n+  if (detailed_message != nullptr) {\n@@ -2281,1 +2160,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2294,1 +2173,1 @@\n-  set_stacktrace(throwable, NULL);\n+  set_stacktrace(throwable, nullptr);\n@@ -2301,1 +2180,1 @@\n-  assert(k != NULL, \"just checking\");\n+  assert(k != nullptr, \"just checking\");\n@@ -2304,1 +2183,1 @@\n-  if (msg != NULL) {\n+  if (msg != nullptr) {\n@@ -2314,1 +2193,1 @@\n-  return method != NULL && (method->constants()->version() == version);\n+  return method != nullptr && (method->constants()->version() == version);\n@@ -2351,1 +2230,1 @@\n-    assert(methods != NULL, \"method array should be initialized in backtrace\");\n+    assert(methods != nullptr, \"method array should be initialized in backtrace\");\n@@ -2356,1 +2235,1 @@\n-    assert(bcis != NULL, \"bci array should be initialized in backtrace\");\n+    assert(bcis != nullptr, \"bci array should be initialized in backtrace\");\n@@ -2361,1 +2240,1 @@\n-    assert(mirrors != NULL, \"mirror array should be initialized in backtrace\");\n+    assert(mirrors != nullptr, \"mirror array should be initialized in backtrace\");\n@@ -2366,1 +2245,1 @@\n-    assert(names != NULL, \"names array should be initialized in backtrace\");\n+    assert(names != nullptr, \"names array should be initialized in backtrace\");\n@@ -2371,1 +2250,1 @@\n-    return hidden != NULL;\n+    return hidden != nullptr;\n@@ -2377,1 +2256,1 @@\n-  BacktraceBuilder(TRAPS): _head(NULL), _methods(NULL), _bcis(NULL), _mirrors(NULL), _names(NULL), _has_hidden_top_frame(false) {\n+  BacktraceBuilder(TRAPS): _head(nullptr), _methods(nullptr), _bcis(nullptr), _mirrors(nullptr), _names(nullptr), _has_hidden_top_frame(false) {\n@@ -2426,1 +2305,1 @@\n-    new_head->obj_at_put(trace_hidden_offset, NULL);\n+    new_head->obj_at_put(trace_hidden_offset, nullptr);\n@@ -2462,1 +2341,1 @@\n-    assert(method->method_holder()->java_mirror() != NULL, \"never push null for mirror\");\n+    assert(method->method_holder()->java_mirror() != nullptr, \"never push null for mirror\");\n@@ -2475,1 +2354,1 @@\n-      assert(_methods != NULL, \"we need a legal oop\");\n+      assert(_methods != nullptr, \"we need a legal oop\");\n@@ -2535,1 +2414,1 @@\n-    return _result.not_null() && _mirrors->obj_at(_index) != NULL;\n+    return _result.not_null() && _mirrors->obj_at(_index) != nullptr;\n@@ -2553,1 +2432,1 @@\n-  char* source_file_name = NULL;\n+  char* source_file_name = nullptr;\n@@ -2555,1 +2434,1 @@\n-  if (source != NULL) {\n+  if (source != nullptr) {\n@@ -2560,1 +2439,1 @@\n-  char *module_name = NULL, *module_version = NULL;\n+  char *module_name = nullptr, *module_version = nullptr;\n@@ -2565,1 +2444,1 @@\n-    if (module->version() != NULL) {\n+    if (module->version() != nullptr) {\n@@ -2572,1 +2451,2 @@\n-  char* buf = NEW_RESOURCE_ARRAY(char, buf_len + 64);\n+  const size_t buf_size = buf_len + 64;\n+  char* buf = NEW_RESOURCE_ARRAY(char, buf_size);\n@@ -2575,1 +2455,1 @@\n-  sprintf(buf, \"\\tat %s.%s(\", klass_name, method_name);\n+  size_t buf_off = os::snprintf_checked(buf, buf_size, \"\\tat %s.%s(\", klass_name, method_name);\n@@ -2578,3 +2458,3 @@\n-  if (module_name != NULL) {\n-    if (module_version != NULL) {\n-      sprintf(buf + (int)strlen(buf), \"%s@%s\/\", module_name, module_version);\n+  if (module_name != nullptr) {\n+    if (module_version != nullptr) {\n+      buf_off += os::snprintf_checked(buf + buf_off, buf_size - buf_off, \"%s@%s\/\", module_name, module_version);\n@@ -2582,1 +2462,1 @@\n-      sprintf(buf + (int)strlen(buf), \"%s\/\", module_name);\n+      buf_off += os::snprintf_checked(buf + buf_off, buf_size - buf_off, \"%s\/\", module_name);\n@@ -2586,1 +2466,1 @@\n-  \/\/ The method can be NULL if the requested class version is gone\n+  \/\/ The method can be null if the requested class version is gone\n@@ -2595,1 +2475,1 @@\n-      if (source_file_name != NULL && (line_number != -1)) {\n+      if (source_file_name != nullptr && (line_number != -1)) {\n@@ -2597,2 +2477,2 @@\n-        sprintf(buf + (int)strlen(buf), \"%s:%d)\", source_file_name, line_number);\n-      } else if (source_file_name != NULL) {\n+        buf_off += os::snprintf_checked(buf + buf_off, buf_size - buf_off, \"%s:%d)\", source_file_name, line_number);\n+      } else if (source_file_name != nullptr) {\n@@ -2600,1 +2480,1 @@\n-        sprintf(buf + (int)strlen(buf), \"%s)\", source_file_name);\n+        buf_off += os::snprintf_checked(buf + buf_off, buf_size - buf_off, \"%s)\", source_file_name);\n@@ -2603,1 +2483,1 @@\n-        sprintf(buf + (int)strlen(buf), \"Unknown Source)\");\n+        buf_off += os::snprintf_checked(buf + buf_off, buf_size - buf_off, \"Unknown Source)\");\n@@ -2606,2 +2486,2 @@\n-      if (WizardMode && nm != NULL) {\n-        sprintf(buf + (int)strlen(buf), \"(nmethod \" INTPTR_FORMAT \")\", (intptr_t)nm);\n+      if (WizardMode && nm != nullptr) {\n+        os::snprintf_checked(buf + buf_off, buf_size - buf_off, \"(nmethod \" INTPTR_FORMAT \")\", (intptr_t)nm);\n@@ -2691,1 +2571,1 @@\n-  set_backtrace(throwable(), NULL);\n+  set_backtrace(throwable(), nullptr);\n@@ -2704,1 +2584,1 @@\n-    if (max_depth >= 1 && method() != NULL) {\n+    if (max_depth >= 1 && method() != nullptr) {\n@@ -2728,1 +2608,1 @@\n-  CompiledMethod* nm = NULL;\n+  CompiledMethod* nm = nullptr;\n@@ -2735,1 +2615,1 @@\n-    Method* method = NULL;\n+    Method* method = nullptr;\n@@ -2769,1 +2649,1 @@\n-        \/\/ HMMM QQQ might be nice to have frame return nm as NULL if cb is non-NULL\n+        \/\/ HMMM QQQ might be nice to have frame return nm as null if cb is non-null\n@@ -2772,1 +2652,1 @@\n-        if (cb == NULL || !cb->is_compiled()) {\n+        if (cb == nullptr || !cb->is_compiled()) {\n@@ -2776,1 +2656,1 @@\n-        assert(nm->method() != NULL, \"must be\");\n+        assert(nm->method() != nullptr, \"must be\");\n@@ -2909,1 +2789,1 @@\n-  assert(java_lang_Throwable::unassigned_stacktrace() != NULL, \"not initialized\");\n+  assert(java_lang_Throwable::unassigned_stacktrace() != nullptr, \"not initialized\");\n@@ -2950,4 +2830,5 @@\n-Handle java_lang_Throwable::get_cause_with_stack_trace(Handle throwable, TRAPS) {\n-  \/\/ Call to JVM to fill in the stack trace and clear declaringClassObject to\n-  \/\/ not keep classes alive in the stack trace.\n-  \/\/ call this:  public StackTraceElement[] getStackTrace()\n+Handle java_lang_Throwable::create_initialization_error(JavaThread* current, Handle throwable) {\n+  \/\/ Creates an ExceptionInInitializerError to be recorded as the initialization error when class initialization\n+  \/\/ failed due to the passed in 'throwable'. We cannot save 'throwable' directly due to issues with keeping alive\n+  \/\/ all objects referenced via its stacktrace. So instead we save a new EIIE instance, with the same message and\n+  \/\/ symbolic stacktrace of 'throwable'.\n@@ -2956,13 +2837,1 @@\n-  JavaValue result(T_ARRAY);\n-  JavaCalls::call_virtual(&result, throwable,\n-                          vmClasses::Throwable_klass(),\n-                          vmSymbols::getStackTrace_name(),\n-                          vmSymbols::getStackTrace_signature(),\n-                          CHECK_NH);\n-  Handle stack_trace(THREAD, result.get_oop());\n-  assert(stack_trace->is_objArray(), \"Should be an array\");\n-\n-  \/\/ Throw ExceptionInInitializerError as the cause with this exception in\n-  \/\/ the message and stack trace.\n-\n-  \/\/ Now create the message with the original exception and thread name.\n+  \/\/ Now create the message from the original exception and thread name.\n@@ -2970,1 +2839,1 @@\n-  ResourceMark rm(THREAD);\n+  ResourceMark rm(current);\n@@ -2974,2 +2843,2 @@\n-  if (message == NULL) {\n-    st.print(\"[in thread \\\"%s\\\"]\", THREAD->name());\n+  if (message == nullptr) {\n+    st.print(\"[in thread \\\"%s\\\"]\", current->name());\n@@ -2977,1 +2846,1 @@\n-    st.print(\"%s [in thread \\\"%s\\\"]\", message->as_C_string(), THREAD->name());\n+    st.print(\"%s [in thread \\\"%s\\\"]\", message->as_C_string(), current->name());\n@@ -2981,4 +2850,4 @@\n-  Handle h_cause = Exceptions::new_exception(THREAD, exception_name, st.as_string());\n-\n-  \/\/ If new_exception returns a different exception while creating the exception, return null.\n-  if (h_cause->klass()->name() != exception_name) {\n+  Handle init_error = Exceptions::new_exception(current, exception_name, st.as_string());\n+  \/\/ If new_exception returns a different exception while creating the exception,\n+  \/\/ abandon the attempt to save the initialization error and return null.\n+  if (init_error->klass()->name() != exception_name) {\n@@ -2986,1 +2855,1 @@\n-                          h_cause->klass()->external_name());\n+                        init_error->klass()->external_name());\n@@ -2989,4 +2858,23 @@\n-  java_lang_Throwable::set_stacktrace(h_cause(), stack_trace());\n-  \/\/ Clear backtrace because the stacktrace should be used instead.\n-  set_backtrace(h_cause(), NULL);\n-  return h_cause;\n+\n+  \/\/ Call to java to fill in the stack trace and clear declaringClassObject to\n+  \/\/ not keep classes alive in the stack trace.\n+  \/\/ call this:  public StackTraceElement[] getStackTrace()\n+  JavaValue result(T_ARRAY);\n+  JavaCalls::call_virtual(&result, throwable,\n+                          vmClasses::Throwable_klass(),\n+                          vmSymbols::getStackTrace_name(),\n+                          vmSymbols::getStackTrace_signature(),\n+                          current);\n+  if (!current->has_pending_exception()){\n+    Handle stack_trace(current, result.get_oop());\n+    assert(stack_trace->is_objArray(), \"Should be an array\");\n+    java_lang_Throwable::set_stacktrace(init_error(), stack_trace());\n+    \/\/ Clear backtrace because the stacktrace should be used instead.\n+    set_backtrace(init_error(), nullptr);\n+  } else {\n+    log_info(class, init)(\"Exception thrown while getting stack trace for initialization exception %s\",\n+                        init_error->klass()->external_name());\n+    current->clear_pending_exception();\n+  }\n+\n+  return init_error;\n@@ -3005,1 +2893,1 @@\n-  if (hidden != NULL) {\n+  if (hidden != nullptr) {\n@@ -3013,1 +2901,1 @@\n-  assert(holder != NULL, \"first element should be non-null\");\n+  assert(holder != nullptr, \"first element should be non-null\");\n@@ -3017,1 +2905,1 @@\n-  if (m == NULL || !version_matches(m, bte._version)) {\n+  if (m == nullptr || !version_matches(m, bte._version)) {\n@@ -3029,1 +2917,1 @@\n-  assert(k != NULL, \"must be loaded in 1.4+\");\n+  assert(k != nullptr, \"must be loaded in 1.4+\");\n@@ -3056,1 +2944,1 @@\n-  if (loader != NULL) {\n+  if (loader != nullptr) {\n@@ -3058,1 +2946,1 @@\n-    if (loader_name != NULL)\n+    if (loader_name != nullptr)\n@@ -3072,1 +2960,1 @@\n-    if (module->version() != NULL) {\n+    if (module->version() != nullptr) {\n@@ -3075,1 +2963,1 @@\n-      module_version = NULL;\n+      module_version = nullptr;\n@@ -3080,1 +2968,1 @@\n-  if (method() == NULL || !version_matches(method(), version)) {\n+  if (method() == nullptr || !version_matches(method(), version)) {\n@@ -3082,1 +2970,1 @@\n-    java_lang_StackTraceElement::set_fileName(element(), NULL);\n+    java_lang_StackTraceElement::set_fileName(element(), nullptr);\n@@ -3106,1 +2994,1 @@\n-  if (source != NULL) {\n+  if (source != nullptr) {\n@@ -3109,1 +2997,1 @@\n-    if (source_file == NULL) {\n+    if (source_file == nullptr) {\n@@ -3115,2 +3003,2 @@\n-    if (source_file != NULL) {\n-      source_file = NULL;\n+    if (source_file != nullptr) {\n+      source_file = nullptr;\n@@ -3129,1 +3017,1 @@\n-  filename = NULL;\n+  filename = nullptr;\n@@ -3189,1 +3077,1 @@\n-  oop contScope = cont_h() != NULL ? jdk_internal_vm_Continuation::scope(cont_h()) : (oop)NULL;\n+  oop contScope = cont_h() != nullptr ? jdk_internal_vm_Continuation::scope(cont_h()) : (oop)nullptr;\n@@ -3572,1 +3460,1 @@\n-  assert(ik != NULL, \"must be loaded\");\n+  assert(ik != nullptr, \"must be loaded\");\n@@ -3589,1 +3477,1 @@\n-  Method* accessor_method = NULL;\n+  Method* accessor_method = nullptr;\n@@ -3600,1 +3488,1 @@\n-  if (accessor_method != NULL) {\n+  if (accessor_method != nullptr) {\n@@ -3605,1 +3493,1 @@\n-    java_lang_reflect_RecordComponent::set_accessor(element(), NULL);\n+    java_lang_reflect_RecordComponent::set_accessor(element(), nullptr);\n@@ -3614,1 +3502,1 @@\n-    java_lang_reflect_RecordComponent::set_signature(element(), NULL);\n+    java_lang_reflect_RecordComponent::set_signature(element(), nullptr);\n@@ -3755,1 +3643,1 @@\n-  assert(module != NULL, \"module can't be null\");\n+  assert(module != nullptr, \"module can't be null\");\n@@ -3764,1 +3652,1 @@\n-  if (module_entry == NULL) {\n+  if (module_entry == nullptr) {\n@@ -3777,1 +3665,1 @@\n-  assert(module != NULL, \"module can't be null\");\n+  assert(module != nullptr, \"module can't be null\");\n@@ -3859,1 +3747,1 @@\n-  assert(obj != NULL, \"sanity\");\n+  assert(obj != nullptr, \"sanity\");\n@@ -3896,1 +3784,1 @@\n-  if (k == NULL)  return NULL;\n+  if (k == nullptr)  return nullptr;\n@@ -3907,1 +3795,1 @@\n-  if (box == NULL)  return NULL;\n+  if (box == nullptr)  return nullptr;\n@@ -3934,1 +3822,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -3941,1 +3829,1 @@\n-  if (box == NULL)  return T_ILLEGAL;\n+  if (box == nullptr)  return T_ILLEGAL;\n@@ -4074,1 +3962,1 @@\n-  oop member_name = NULL;\n+  oop member_name = nullptr;\n@@ -4148,1 +4036,1 @@\n-  assert(k != NULL, \"jdk mismatch\");\n+  assert(k != nullptr, \"jdk mismatch\");\n@@ -4163,1 +4051,1 @@\n-  assert (k != NULL, \"jdk mismatch\");\n+  assert (k != nullptr, \"jdk mismatch\");\n@@ -4174,1 +4062,1 @@\n-  return obj != NULL && is_subclass(obj->klass());\n+  return obj != nullptr && is_subclass(obj->klass());\n@@ -4185,1 +4073,1 @@\n-  return obj != NULL && is_subclass(obj->klass());\n+  return obj != nullptr && is_subclass(obj->klass());\n@@ -4225,1 +4113,1 @@\n-  return obj != NULL && is_subclass(obj->klass());\n+  return obj != nullptr && is_subclass(obj->klass());\n@@ -4279,1 +4167,1 @@\n-  return obj != NULL && is_subclass(obj->klass());\n+  return obj != nullptr && is_subclass(obj->klass());\n@@ -4317,1 +4205,1 @@\n-  return obj != NULL && is_subclass(obj->klass());\n+  return obj != nullptr && is_subclass(obj->klass());\n@@ -4404,1 +4292,1 @@\n-  return method == NULL ? NULL : java_lang_invoke_ResolvedMethodName::vmtarget(method);\n+  return method == nullptr ? nullptr : java_lang_invoke_ResolvedMethodName::vmtarget(method);\n@@ -4451,1 +4339,1 @@\n-  if (resolved_method != NULL) {\n+  if (resolved_method != nullptr) {\n@@ -4514,1 +4402,1 @@\n-  if (pts != NULL) {\n+  if (pts != nullptr) {\n@@ -4519,1 +4407,1 @@\n-    st->print(\"NULL\");\n+    st->print(\"null\");\n@@ -4523,1 +4411,1 @@\n-  if (rt != NULL) {\n+  if (rt != nullptr) {\n@@ -4526,1 +4414,1 @@\n-    st->print(\"NULL\");\n+    st->print(\"null\");\n@@ -4714,1 +4602,1 @@\n-  assert(loader != NULL, \"loader must not be NULL\");\n+  assert(loader != nullptr, \"loader must not be null\");\n@@ -4720,1 +4608,1 @@\n-  assert(loader != NULL, \"loader must not be NULL\");\n+  assert(loader != nullptr, \"loader must not be null\");\n@@ -4726,1 +4614,1 @@\n-  assert(loader != NULL, \"loader must not be NULL\");\n+  assert(loader != nullptr, \"loader must not be null\");\n@@ -4782,1 +4670,1 @@\n-  assert(cl == NULL || is_instance(cl), \"cl argument must be oop\");\n+  assert(cl == nullptr || is_instance(cl), \"cl argument must be oop\");\n@@ -4792,1 +4680,1 @@\n-  } while (acl != NULL);\n+  } while (acl != nullptr);\n@@ -4797,1 +4685,1 @@\n-  return obj != NULL && is_subclass(obj->klass());\n+  return obj != nullptr && is_subclass(obj->klass());\n@@ -4806,1 +4694,1 @@\n-  return (class_loader->obj_field(_parallelCapable_offset) != NULL);\n+  return (class_loader->obj_field(_parallelCapable_offset) != nullptr);\n@@ -4814,1 +4702,1 @@\n-  while(cl != NULL) {\n+  while(cl != nullptr) {\n@@ -4824,1 +4712,1 @@\n-  if (loader != NULL) {\n+  if (loader != nullptr) {\n@@ -4827,1 +4715,1 @@\n-    return (delegating_cl_class != NULL && loader->is_a(delegating_cl_class));\n+    return (delegating_cl_class != nullptr && loader->is_a(delegating_cl_class));\n@@ -4888,1 +4776,1 @@\n-  return base->obj_field(_static_security_offset) != NULL;\n+  return base->obj_field(_static_security_offset) != nullptr;\n@@ -4910,1 +4798,1 @@\n-    _page_size = os::vm_page_size();\n+    _page_size = (int)os::vm_page_size();\n@@ -4918,1 +4806,1 @@\n-    assert(mirror != NULL, \"UnsafeConstants must have mirror already\");\n+    assert(mirror != nullptr, \"UnsafeConstants must have mirror already\");\n@@ -5103,1 +4991,1 @@\n-  return obj != NULL && is_subclass(obj->klass());\n+  return obj != nullptr && is_subclass(obj->klass());\n@@ -5116,1 +5004,1 @@\n-  guarantee(k != NULL && k->is_initialized(), \"must be loaded and initialized\");\n+  guarantee(k != nullptr && k->is_initialized(), \"must be loaded and initialized\");\n@@ -5146,1 +5034,1 @@\n-  guarantee(k != NULL && k->is_initialized(), \"must be loaded and initialized\");\n+  guarantee(k != nullptr && k->is_initialized(), \"must be loaded and initialized\");\n@@ -5176,1 +5064,1 @@\n-  guarantee(k != NULL && k->is_initialized(), \"must be loaded and initialized\");\n+  guarantee(k != nullptr && k->is_initialized(), \"must be loaded and initialized\");\n@@ -5206,1 +5094,1 @@\n-  guarantee(k != NULL && k->is_initialized(), \"must be loaded and initialized\");\n+  guarantee(k != nullptr && k->is_initialized(), \"must be loaded and initialized\");\n@@ -5236,1 +5124,1 @@\n-  guarantee(k != NULL && k->is_initialized(), \"must be loaded and initialized\");\n+  guarantee(k != nullptr && k->is_initialized(), \"must be loaded and initialized\");\n@@ -5271,1 +5159,1 @@\n-  guarantee(k != NULL && k->is_initialized(), \"must be loaded and initialized\");\n+  guarantee(k != nullptr && k->is_initialized(), \"must be loaded and initialized\");\n@@ -5551,1 +5439,1 @@\n-    if (!may_be_java && !fs.access_flags().is_internal()) {\n+    if (!may_be_java && !fs.field_flags().is_injected()) {\n@@ -5575,1 +5463,0 @@\n-  java_lang_VirtualThread::init_static_notify_jvmti_events();\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":430,"deletions":543,"binary":false,"changes":973,"status":"modified"},{"patch":"@@ -92,1 +92,1 @@\n-  do_klass(BasicVirtualThread_klass,                    java_lang_BaseVirtualThread                           ) \\\n+  do_klass(BaseVirtualThread_klass,                     java_lang_BaseVirtualThread                           ) \\\n@@ -94,0 +94,1 @@\n+  do_klass(BoundVirtualThread_klass,                    java_lang_BoundVirtualThread                          ) \\\n","filename":"src\/hotspot\/share\/classfile\/vmClassMacros.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -70,0 +70,1 @@\n+  template(java_lang_BoundVirtualThread,              \"java\/lang\/ThreadBuilders$BoundVirtualThread\") \\\n@@ -489,0 +490,5 @@\n+  template(notifyJvmtiStart_name,                     \"notifyJvmtiStart\")                         \\\n+  template(notifyJvmtiEnd_name,                       \"notifyJvmtiEnd\")                           \\\n+  template(notifyJvmtiMount_name,                     \"notifyJvmtiMount\")                         \\\n+  template(notifyJvmtiUnmount_name,                   \"notifyJvmtiUnmount\")                       \\\n+  template(notifyJvmtiHideFrames_name,                \"notifyJvmtiHideFrames\")                    \\\n@@ -598,0 +604,2 @@\n+  template(jvmti_VTMS_transition_disable_count_name,  \"jvmti_VTMS_transition_disable_count\")      \\\n+  template(jvmti_is_in_VTMS_transition_name,          \"jvmti_is_in_VTMS_transition\")              \\\n@@ -627,0 +635,1 @@\n+  template(bool_bool_void_signature,                  \"(ZZ)V\")                                    \\\n@@ -831,0 +840,3 @@\n+  template(encodeAnnotations_name,                     \"encodeAnnotations\")                                       \\\n+  template(encodeAnnotations_signature,                \"([BLjava\/lang\/Class;Ljdk\/internal\/reflect\/ConstantPool;Z[Ljava\/lang\/Class;)[B\")\\\n+  template(decodeAndThrowThrowable_signature,          \"(JZ)V\")                                                   \\\n@@ -958,1 +970,1 @@\n-    assert(_type_signatures[t] != NULL, \"domain check\");\n+    assert(_type_signatures[t] != nullptr, \"domain check\");\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":13,"deletions":1,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -57,1 +57,1 @@\n-  if (nm != NULL) {\n+  if (nm != nullptr) {\n@@ -71,1 +71,1 @@\n-  assert(_obj_pool != NULL, \"object pool does not exist\");\n+  assert(_obj_pool != nullptr, \"object pool does not exist\");\n@@ -85,1 +85,1 @@\n-  assert(_obj_pool != NULL, \"object pool does not exist\");\n+  assert(_obj_pool != nullptr, \"object pool does not exist\");\n@@ -93,1 +93,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -104,1 +104,1 @@\n-  ScopeValue* result = NULL;\n+  ScopeValue* result = nullptr;\n@@ -258,1 +258,1 @@\n-    assert(JNIHandles::resolve(value()) == NULL ||\n+    assert(JNIHandles::resolve(value()) == nullptr ||\n@@ -279,1 +279,1 @@\n-  assert(_value() == NULL ||\n+  assert(_value() == nullptr ||\n@@ -288,1 +288,1 @@\n-  if (value()() != NULL) {\n+  if (value()() != nullptr) {\n@@ -291,1 +291,1 @@\n-    st->print(\"NULL\");\n+    st->print(\"nullptr\");\n","filename":"src\/hotspot\/share\/code\/debugInfo.cpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -132,1 +132,1 @@\n-  ObjectValue(int id, ScopeValue* klass, ScopeValue* is_init = NULL, ScopeValue* is_larval = NULL)\n+  ObjectValue(int id, ScopeValue* klass, ScopeValue* is_init = nullptr, ScopeValue* is_larval = nullptr)\n@@ -145,3 +145,3 @@\n-     , _is_larval(NULL)\n-     , _klass(NULL)\n-     , _is_init(NULL)\n+     , _is_larval(nullptr)\n+     , _klass(nullptr)\n+     , _is_init(nullptr)\n@@ -313,1 +313,1 @@\n-  DebugInfoReadStream(const CompiledMethod* code, int offset, GrowableArray<ScopeValue*>* obj_pool = NULL) :\n+  DebugInfoReadStream(const CompiledMethod* code, int offset, GrowableArray<ScopeValue*>* obj_pool = nullptr) :\n@@ -324,1 +324,1 @@\n-    assert(o == NULL || o->is_metadata(), \"meta data only\");\n+    assert(o == nullptr || o->is_metadata(), \"meta data only\");\n","filename":"src\/hotspot\/share\/code\/debugInfo.hpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -177,1 +177,1 @@\n-\/\/ handles NULL pointers\n+\/\/ handles null pointers\n@@ -182,1 +182,1 @@\n-  ALWAYSINLINE void* operator new(size_t size, MEMFLAGS f) throw() {\n+  ALWAYSINLINE void* operator new(size_t size, MEMFLAGS f) {\n@@ -188,1 +188,1 @@\n-                                  const NativeCallStack& stack) throw() {\n+                                  const NativeCallStack& stack) {\n@@ -205,1 +205,1 @@\n-  ALWAYSINLINE void* operator new[](size_t size, MEMFLAGS f) throw() {\n+  ALWAYSINLINE void* operator new[](size_t size, MEMFLAGS f) {\n@@ -211,1 +211,1 @@\n-                                    const NativeCallStack& stack) throw() {\n+                                    const NativeCallStack& stack) {\n@@ -236,1 +236,1 @@\n-  ALWAYSINLINE void* operator new(size_t size) throw() {\n+  ALWAYSINLINE void* operator new(size_t size) {\n@@ -241,1 +241,1 @@\n-                                  const NativeCallStack& stack) throw() {\n+                                  const NativeCallStack& stack) {\n@@ -254,1 +254,1 @@\n-  ALWAYSINLINE void* operator new[](size_t size) throw() {\n+  ALWAYSINLINE void* operator new[](size_t size) {\n@@ -259,1 +259,1 @@\n-                                    const NativeCallStack& stack) throw() {\n+                                    const NativeCallStack& stack) {\n@@ -285,5 +285,5 @@\n- private:\n-  void* operator new(size_t size) throw();\n-  void* operator new [](size_t size) throw();\n-  void  operator delete(void* p);\n-  void  operator delete [](void* p);\n+ public:\n+  void* operator new(size_t size) = delete;\n+  void* operator new [](size_t size) = delete;\n+  void  operator delete(void* p) = delete;\n+  void  operator delete [](void* p) = delete;\n@@ -324,1 +324,1 @@\n-  \/\/ When CDS is not enabled, both pointers are set to NULL.\n+  \/\/ When CDS is not enabled, both pointers are set to null.\n@@ -338,1 +338,1 @@\n-    \/\/ both be NULL and all values of p will be rejected quickly.\n+    \/\/ both be null and all values of p will be rejected quickly.\n@@ -373,0 +373,1 @@\n+  f(SharedClassPathEntry) \\\n@@ -374,1 +375,2 @@\n-  f(MultiFieldInfo)\n+  f(MultiFieldInfo) \\\n+  f(InlineKlassFixedBlock)\n@@ -390,1 +392,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -436,1 +438,1 @@\n-  void* operator new(size_t size) throw() {\n+  void* operator new(size_t size) {\n@@ -504,2 +506,2 @@\n-  void* operator new(size_t size, Arena *arena) throw();\n-  void* operator new [](size_t size, Arena *arena) throw() = delete;\n+  void* operator new(size_t size, Arena *arena);\n+  void* operator new [](size_t size, Arena *arena) = delete;\n@@ -508,1 +510,1 @@\n-  void* operator new(size_t size) throw() {\n+  void* operator new(size_t size) {\n@@ -515,1 +517,1 @@\n-    DEBUG_ONLY(if (res != NULL) set_allocation_type(res, RESOURCE_AREA);)\n+    DEBUG_ONLY(if (res != nullptr) set_allocation_type(res, RESOURCE_AREA);)\n@@ -519,2 +521,2 @@\n-  void* operator new [](size_t size) throw() = delete;\n-  void* operator new [](size_t size, const std::nothrow_t& nothrow_constant) throw() = delete;\n+  void* operator new [](size_t size) = delete;\n+  void* operator new [](size_t size, const std::nothrow_t& nothrow_constant) = delete;\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":28,"deletions":26,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -47,0 +47,1 @@\n+  class   InlineKlassFixedBlock; \/\/ no C++ vtable\n@@ -82,8 +83,0 @@\n-  enum SpecialRef {\n-    \/\/ A field that points to a method entry. E.g., Method::_i2i_entry\n-    _method_entry_ref,\n-\n-    \/\/ A field that points to a location inside the current object.\n-    _internal_pointer_ref,\n-  };\n-\n@@ -118,1 +111,0 @@\n-    bool _keep_after_pushing;\n@@ -125,1 +117,1 @@\n-    Ref(Writability w) : _writability(w), _keep_after_pushing(false), _next(NULL), _user_data(NULL) {}\n+    Ref(Writability w) : _writability(w), _next(nullptr), _user_data(nullptr) {}\n@@ -146,2 +138,0 @@\n-    void set_keep_after_pushing()   { _keep_after_pushing = true; }\n-    bool keep_after_pushing()       { return _keep_after_pushing; }\n@@ -170,1 +160,1 @@\n-    virtual bool not_null()                const { return dereference() != NULL; }\n+    virtual bool not_null()                const { return dereference() != nullptr; }\n@@ -197,1 +187,1 @@\n-    virtual bool not_null()                const { return dereference() != NULL;  }\n+    virtual bool not_null()                const { return dereference() != nullptr;  }\n@@ -275,1 +265,1 @@\n-  MetaspaceClosure(): _pending_refs(NULL), _nest_level(0), _enclosing_ref(NULL) {}\n+  MetaspaceClosure(): _pending_refs(nullptr), _nest_level(0), _enclosing_ref(nullptr) {}\n@@ -291,1 +281,1 @@\n-  \/\/ when do_pending_ref(r) is called, and will return NULL when do_ref(r) is called.\n+  \/\/ when do_pending_ref(r) is called, and will return null when do_ref(r) is called.\n@@ -353,1 +343,1 @@\n-    Hashtable<bool, mtInternal>* h  = NULL;\n+    Hashtable<bool, mtInternal>* h  = nullptr;\n@@ -356,1 +346,1 @@\n-    Array<Hashtable<bool, mtInternal>*>* a6 = NULL;\n+    Array<Hashtable<bool, mtInternal>*>* a6 = nullptr;\n@@ -359,1 +349,1 @@\n-    Array<int*>* a7 = NULL;\n+    Array<int*>* a7 = nullptr;\n@@ -364,25 +354,0 @@\n-  template <class T> void push_method_entry(T** mpp, intptr_t* p) {\n-    Ref* ref = new MSORef<T>(mpp, _default);\n-    push_special(_method_entry_ref, ref, p);\n-    if (!ref->keep_after_pushing()) {\n-      delete ref;\n-    }\n-  }\n-\n-  template <class T> void push_internal_pointer(T** mpp, intptr_t* p) {\n-    Ref* ref = new MSORef<T>(mpp, _default);\n-    push_special(_internal_pointer_ref, ref, p);\n-    if (!ref->keep_after_pushing()) {\n-      delete ref;\n-    }\n-  }\n-\n-  \/\/ This is for tagging special pointers that are not a reference to MetaspaceObj. It's currently\n-  \/\/ used to mark the method entry points in Method\/ConstMethod.\n-  virtual void push_special(SpecialRef type, Ref* obj, intptr_t* p) {\n-    assert_valid(type);\n-  }\n-\n-  static void assert_valid(SpecialRef type) {\n-    assert(type == _method_entry_ref || type == _internal_pointer_ref, \"only special types allowed for now\");\n-  }\n","filename":"src\/hotspot\/share\/memory\/metaspaceClosure.hpp","additions":10,"deletions":45,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -189,1 +189,1 @@\n-      (Symbol*)NULL : symbol_at(_generic_signature_index);\n+      nullptr : symbol_at(_generic_signature_index);\n@@ -197,1 +197,1 @@\n-      (Symbol*)NULL : symbol_at(_source_file_name_index);\n+      nullptr : symbol_at(_source_file_name_index);\n@@ -239,0 +239,3 @@\n+  oop resolved_reference_at(int obj_index) const;\n+  oop set_resolved_reference_at(int index, oop new_value);\n+\n@@ -256,14 +259,0 @@\n-\n-  \/\/ The invokedynamic points at a CP cache entry.  This entry points back\n-  \/\/ at the original CP entry (CONSTANT_InvokeDynamic) and also (via f2) at an entry\n-  \/\/ in the resolved_references array (which provides the appendix argument).\n-  int invokedynamic_cp_cache_index(int indy_index) const {\n-    assert(is_invokedynamic_index(indy_index), \"should be a invokedynamic index\");\n-    int cache_index = decode_invokedynamic_index(indy_index);\n-    return cache_index;\n-  }\n-  ConstantPoolCacheEntry* invokedynamic_cp_cache_entry_at(int indy_index) const {\n-    \/\/ decode index that invokedynamic points to.\n-    int cp_cache_index = invokedynamic_cp_cache_index(indy_index);\n-    return cache()->entry_at(cp_cache_index);\n-  }\n@@ -274,1 +263,1 @@\n-    return invokedynamic_cp_cache_entry_at(indy_index)->constant_pool_index();\n+    return cache()->resolved_indy_entry_at(decode_invokedynamic_index(indy_index))->constant_pool_index();\n@@ -278,4 +267,4 @@\n-  static int tags_offset_in_bytes()         { return offset_of(ConstantPool, _tags); }\n-  static int cache_offset_in_bytes()        { return offset_of(ConstantPool, _cache); }\n-  static int pool_holder_offset_in_bytes()  { return offset_of(ConstantPool, _pool_holder); }\n-  static int resolved_klasses_offset_in_bytes()    { return offset_of(ConstantPool, _resolved_klasses); }\n+  static ByteSize tags_offset()         { return byte_offset_of(ConstantPool, _tags); }\n+  static ByteSize cache_offset()        { return byte_offset_of(ConstantPool, _cache); }\n+  static ByteSize pool_holder_offset()  { return byte_offset_of(ConstantPool, _pool_holder); }\n+  static ByteSize resolved_klasses_offset()    { return byte_offset_of(ConstantPool, _resolved_klasses); }\n@@ -486,1 +475,1 @@\n-    return resolved_references()->obj_at(obj_index);\n+    return resolved_reference_at(obj_index);\n@@ -524,1 +513,1 @@\n-    return impl_name_ref_at(member, true);\n+    return uncached_name_ref_at(member);\n@@ -528,1 +517,1 @@\n-    return impl_signature_ref_at(member, true);\n+    return uncached_signature_ref_at(member);\n@@ -532,1 +521,1 @@\n-    return impl_klass_ref_index_at(member, true);\n+    return uncached_klass_ref_index_at(member);\n@@ -574,1 +563,1 @@\n-    if (operands == NULL || operands->length() == 0)  return 0;\n+    if (operands == nullptr || operands->length() == 0)  return 0;\n@@ -680,4 +669,10 @@\n-  Klass* klass_ref_at(int which, TRAPS);\n-  Symbol* klass_ref_at_noresolve(int which);\n-  Symbol* name_ref_at(int which)                { return impl_name_ref_at(which, false); }\n-  Symbol* signature_ref_at(int which)           { return impl_signature_ref_at(which, false); }\n+  Klass* klass_ref_at(int which, Bytecodes::Code code, TRAPS);\n+  Symbol* klass_ref_at_noresolve(int which, Bytecodes::Code code);\n+  Symbol* name_ref_at(int which, Bytecodes::Code code) {\n+    int name_index = name_ref_index_at(name_and_type_ref_index_at(which, code));\n+    return symbol_at(name_index);\n+  }\n+  Symbol* signature_ref_at(int which, Bytecodes::Code code) {\n+    int signature_index = signature_ref_index_at(name_and_type_ref_index_at(which, code));\n+    return symbol_at(signature_index);\n+  }\n@@ -685,2 +680,2 @@\n-  int klass_ref_index_at(int which)               { return impl_klass_ref_index_at(which, false); }\n-  int name_and_type_ref_index_at(int which)       { return impl_name_and_type_ref_index_at(which, false); }\n+  int klass_ref_index_at(int which, Bytecodes::Code code);\n+  int name_and_type_ref_index_at(int which, Bytecodes::Code code);\n@@ -690,1 +685,3 @@\n-  constantTag tag_ref_at(int cp_cache_index)      { return impl_tag_ref_at(cp_cache_index, false); }\n+  constantTag tag_ref_at(int cp_cache_index, Bytecodes::Code code);\n+\n+  int to_cp_index(int which, Bytecodes::Code code);\n@@ -706,1 +703,1 @@\n-  void archive_resolved_references() NOT_CDS_JAVA_HEAP_RETURN;\n+  objArrayOop prepare_resolved_references_for_archiving() NOT_CDS_JAVA_HEAP_RETURN_(nullptr);\n@@ -725,1 +722,1 @@\n-    return resolve_constant_at_impl(h_this, index, _no_index_sentinel, NULL, THREAD);\n+    return resolve_constant_at_impl(h_this, index, _no_index_sentinel, nullptr, THREAD);\n@@ -730,1 +727,1 @@\n-    return resolve_constant_at_impl(h_this, _no_index_sentinel, cache_index, NULL, THREAD);\n+    return resolve_constant_at_impl(h_this, _no_index_sentinel, cache_index, nullptr, THREAD);\n@@ -735,1 +732,1 @@\n-    return resolve_constant_at_impl(h_this, pool_index, _possible_index_sentinel, NULL, THREAD);\n+    return resolve_constant_at_impl(h_this, pool_index, _possible_index_sentinel, nullptr, THREAD);\n@@ -792,5 +789,11 @@\n-  Symbol* uncached_klass_ref_at_noresolve(int which);\n-  Symbol* uncached_name_ref_at(int which)                 { return impl_name_ref_at(which, true); }\n-  Symbol* uncached_signature_ref_at(int which)            { return impl_signature_ref_at(which, true); }\n-  int       uncached_klass_ref_index_at(int which)          { return impl_klass_ref_index_at(which, true); }\n-  int       uncached_name_and_type_ref_index_at(int which)  { return impl_name_and_type_ref_index_at(which, true); }\n+  Symbol* uncached_klass_ref_at_noresolve(int cp_index);\n+  Symbol* uncached_name_ref_at(int cp_index) {\n+    int name_index = name_ref_index_at(uncached_name_and_type_ref_index_at(cp_index));\n+    return symbol_at(name_index);\n+  }\n+  Symbol* uncached_signature_ref_at(int cp_index) {\n+    int signature_index = signature_ref_index_at(uncached_name_and_type_ref_index_at(cp_index));\n+    return symbol_at(signature_index);\n+  }\n+  int       uncached_klass_ref_index_at(int cp_index);\n+  int       uncached_name_and_type_ref_index_at(int cp_index);\n@@ -820,1 +823,1 @@\n-  Array<u2>* reference_map() const        {  return (_cache == NULL) ? NULL :  _cache->reference_map(); }\n+  Array<u2>* reference_map() const        {  return (_cache == nullptr) ? nullptr :  _cache->reference_map(); }\n@@ -823,7 +826,0 @@\n-  Symbol* impl_name_ref_at(int which, bool uncached);\n-  Symbol* impl_signature_ref_at(int which, bool uncached);\n-\n-  int       impl_klass_ref_index_at(int which, bool uncached);\n-  int       impl_name_and_type_ref_index_at(int which, bool uncached);\n-  constantTag impl_tag_ref_at(int which, bool uncached);\n-\n@@ -936,0 +932,11 @@\n+\n+  \/\/ ResolvedIndyEntry getters\n+  ResolvedIndyEntry* resolved_indy_entry_at(int index) {\n+    return cache()->resolved_indy_entry_at(index);\n+  }\n+  int resolved_indy_entries_length() {\n+    return cache()->resolved_indy_entries_length();\n+  }\n+  oop resolved_reference_from_indy(int index) {\n+    return resolved_references()->obj_at(cache()->resolved_indy_entry_at(index)->resolved_references_index());\n+  }\n","filename":"src\/hotspot\/share\/oops\/constantPool.hpp","additions":58,"deletions":51,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,2 +26,2 @@\n-#include \"oops\/fieldInfo.hpp\"\n-#include \"oops\/instanceKlass.hpp\"\n+#include \"oops\/fieldInfo.inline.hpp\"\n+#include \"runtime\/atomic.hpp\"\n@@ -29,3 +29,14 @@\n-Symbol* FieldInfo::get_multifield_name(Array<MultiFieldInfo>* multifield_info) const {\n-  assert(is_multifield(), \"Sanity check\");\n-  return multifield_info->at(secondary_index()).name();\n+void FieldInfo::print(outputStream* os, ConstantPool* cp) {\n+  os->print_cr(\"index=%d name_index=%d name=%s signature_index=%d signature=%s offset=%d \"\n+               \"AccessFlags=%d FieldFlags=%d \"\n+               \"initval_index=%d gen_signature_index=%d, gen_signature=%s contended_group=%d\",\n+                index(),\n+                name_index(), name(nullptr, cp)->as_utf8(),\n+                signature_index(), signature(cp)->as_utf8(),\n+                offset(),\n+                access_flags().as_int(),\n+                field_flags().as_uint(),\n+                initializer_index(),\n+                generic_signature_index(),\n+                _field_flags.is_injected() ? lookup_symbol(generic_signature_index())->as_utf8() : cp->symbol_at(generic_signature_index())->as_utf8(),\n+                contended_group());\n@@ -34,3 +45,4 @@\n-u2 FieldInfo::multifield_base(Array<MultiFieldInfo>* multifield_info) const {\n-  assert(is_multifield(), \"Sanity check\");\n-  return multifield_info->at(secondary_index()).base_index();\n+void FieldInfo::print_from_growable_array(outputStream* os, GrowableArray<FieldInfo>* array, ConstantPool* cp) {\n+  for (int i = 0; i < array->length(); i++) {\n+    array->adr_at(i)->print(os, cp);\n+  }\n@@ -39,4 +51,97 @@\n-jbyte FieldInfo::multifield_index(Array<MultiFieldInfo>* multifield_info) const {\n-  assert(is_multifield(), \"Sanity check\");\n-  return multifield_info->at(secondary_index()).multifield_index();\n-}\n+Array<u1>* FieldInfoStream::create_FieldInfoStream(GrowableArray<FieldInfo>* fields, int java_fields, int injected_fields,\n+                                                          ClassLoaderData* loader_data, TRAPS) {\n+  \/\/ The stream format described in fieldInfo.hpp is:\n+  \/\/   FieldInfoStream := j=num_java_fields k=num_injected_fields Field[j+k] End\n+  \/\/   Field := name sig offset access flags Optionals(flags)\n+  \/\/   Optionals(i) := initval?[i&is_init]     \/\/ ConstantValue attr\n+  \/\/                   gsig?[i&is_generic]     \/\/ signature attr\n+  \/\/                   group?[i&is_contended]  \/\/ Contended anno (group)\n+  \/\/   End = 0\n+\n+  using StreamSizer = UNSIGNED5::Sizer<>;\n+  using StreamFieldSizer = Mapper<StreamSizer>;\n+  StreamSizer s;\n+  StreamFieldSizer sizer(&s);\n+\n+  sizer.consumer()->accept_uint(java_fields);\n+  sizer.consumer()->accept_uint(injected_fields);\n+  for (int i = 0; i < fields->length(); i++) {\n+    FieldInfo* fi = fields->adr_at(i);\n+    sizer.map_field_info(*fi);\n+  }\n+  int storage_size = sizer.consumer()->position() + 1;\n+  Array<u1>* const fis = MetadataFactory::new_array<u1>(loader_data, storage_size, CHECK_NULL);\n+\n+  using StreamWriter = UNSIGNED5::Writer<Array<u1>*, int, ArrayHelper<Array<u1>*, int>>;\n+  using StreamFieldWriter = Mapper<StreamWriter>;\n+  StreamWriter w(fis);\n+  StreamFieldWriter writer(&w);\n+\n+  writer.consumer()->accept_uint(java_fields);\n+  writer.consumer()->accept_uint(injected_fields);\n+  for (int i = 0; i < fields->length(); i++) {\n+    FieldInfo* fi = fields->adr_at(i);\n+    writer.map_field_info(*fi);\n+  }\n+\n+#ifdef ASSERT\n+  FieldInfoReader r(fis);\n+  u2 jfc = r.next_uint();\n+  assert(jfc == java_fields, \"Must be\");\n+  int ifc = r.next_uint();\n+  assert(ifc == injected_fields, \"Must be\");\n+  for (int i = 0; i < jfc + ifc; i++) {\n+    FieldInfo fi;\n+    r.read_field_info(fi);\n+    FieldInfo* fi_ref = fields->adr_at(i);\n+    if (fi_ref->is_multifield()) {\n+      assert(fi_ref->secondary_index() == fi.secondary_index(), \"Must be\");\n+    } else {\n+      assert(fi_ref->name_index() == fi.name_index(), \"Must be\");\n+    }\n+    assert(fi_ref->signature_index() == fi.signature_index(), \"Must be\");\n+    assert(fi_ref->offset() == fi.offset(), \"Must be\");\n+    assert(fi_ref->access_flags().as_int() == fi.access_flags().as_int(), \"Must be\");\n+    assert(fi_ref->field_flags().as_uint() == fi.field_flags().as_uint(), \" Must be\");\n+    if(fi_ref->field_flags().is_initialized()) {\n+      assert(fi_ref->initializer_index() == fi.initializer_index(), \"Must be\");\n+    }\n+    if (fi_ref->field_flags().is_generic()) {\n+      assert(fi_ref->generic_signature_index() == fi.generic_signature_index(), \"Must be\");\n+    }\n+    if (fi_ref->field_flags().is_contended()) {\n+      assert(fi_ref->contended_group() == fi.contended_group(), \"Must be\");\n+    }\n+  }\n+#endif \/\/ ASSERT\n+\n+  return fis;\n+}\n+\n+GrowableArray<FieldInfo>* FieldInfoStream::create_FieldInfoArray(const Array<u1>* fis, int* java_fields_count, int* injected_fields_count) {\n+  int length = FieldInfoStream::num_total_fields(fis);\n+  GrowableArray<FieldInfo>* array = new GrowableArray<FieldInfo>(length);\n+  FieldInfoReader r(fis);\n+  *java_fields_count = r.next_uint();\n+  *injected_fields_count = r.next_uint();\n+  while (r.has_next()) {\n+    FieldInfo fi;\n+    r.read_field_info(fi);\n+    array->append(fi);\n+  }\n+  assert(array->length() == length, \"Must be\");\n+  assert(array->length() == *java_fields_count + *injected_fields_count, \"Must be\");\n+  return array;\n+}\n+\n+void FieldInfoStream::print_from_fieldinfo_stream(Array<u1>* fis, outputStream* os, ConstantPool* cp) {\n+  int length = FieldInfoStream::num_total_fields(fis);\n+  FieldInfoReader r(fis);\n+  int java_field_count = r.next_uint();\n+  int injected_fields_count = r.next_uint();\n+  while (r.has_next()) {\n+    FieldInfo fi;\n+    r.read_field_info(fi);\n+    fi.print(os, cp);\n+  }\n+}\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.cpp","additions":118,"deletions":13,"binary":false,"changes":131,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,2 +28,1 @@\n-#include \"oops\/constantPool.hpp\"\n-#include \"oops\/symbol.hpp\"\n+#include \"memory\/allocation.hpp\"\n@@ -31,0 +30,1 @@\n+#include \"utilities\/unsigned5.hpp\"\n@@ -34,0 +34,15 @@\n+static constexpr u4 flag_mask(int pos) {\n+  return (u4)1 << pos;\n+}\n+\n+\n+\/\/ Helper class for access to the underlying Array<u1> used to\n+\/\/ store the compressed stream of FieldInfo\n+template<typename ARR, typename OFF>\n+struct ArrayHelper {\n+  uint8_t operator()(ARR a, OFF i) const { return a->at(i); };\n+  void operator()(ARR a, OFF i, uint8_t b) const { a->at_put(i,b); };\n+  \/\/ So, an expression ArrayWriterHelper() acts like these lambdas:\n+  \/\/ auto get = [&](ARR a, OFF i){ return a[i]; };\n+  \/\/ auto set = [&](ARR a, OFF i, uint8_t x){ a[i] = x; };\n+};\n@@ -46,1 +61,4 @@\n-  friend class FieldLayout;\n+  friend class FieldInfoStream;\n+  friend class FieldStreamBase;\n+  friend class FieldInfoReader;\n+  friend class VMStructs;\n@@ -49,37 +67,35 @@\n-  \/\/ fields\n-  \/\/ Field info extracted from the class file and stored\n-  \/\/ as an array of 6 shorts.\n-\n-#define FIELDINFO_TAG_SIZE             5\n-#define FIELDINFO_TAG_OFFSET           1 << 0\n-#define FIELDINFO_TAG_CONTENDED        1 << 1\n-#define FIELDINFO_TAG_INLINED          1 << 2\n-#define FIELDINFO_TAG_MULTIFIELD       1 << 3\n-#define FIELDINFO_TAG_MULTIFIELD_BASE  1 << 4\n-\n-  \/\/ Packed field has the tag, and can be either of:\n-  \/\/    hi bits <--------------------------- lo bits\n-  \/\/   |---------high---------|---------low---------|\n-  \/\/    ..........................................CO\n-  \/\/    .......................................BMI00  - non-contended field\n-  \/\/    [--contention_group--].................B0I10  - contended field with contention group\n-  \/\/    [------------------offset-------------]BMI01  - real field offset\n-\n-  \/\/ Bit O indicates if the packed field contains an offset (O=1) or not (O=0)\n-  \/\/ Bit C indicates if the field is contended (C=1) or not (C=0)\n-  \/\/       (if it is contended, the high packed field contains the contention group)\n-  \/\/ Bit I indicates if the field has been inlined  (I=1) or not (I=0)\n-  \/\/ Bit M indicates the field is an injected multifield\n-  \/\/ Bit B indicates the field is a multifield base field\n-\n-  enum FieldOffset {\n-    access_flags_offset      = 0,\n-    name_index_offset        = 1,\n-    signature_index_offset   = 2,\n-    initval_index_offset     = 3,\n-    low_packed_offset        = 4,\n-    high_packed_offset       = 5,\n-    field_slots              = 6\n-  };\n- private:\n-  u2 _shorts[field_slots];\n+  class FieldFlags {\n+    friend class VMStructs;\n+    friend class JVMCIVMStructs;\n+\n+    \/\/ The ordering of this enum is totally internal.  More frequent\n+    \/\/ flags should come earlier than less frequent ones, because\n+    \/\/ earlier ones compress better.\n+    enum FieldFlagBitPosition {\n+      _ff_inlined,           \/\/ or \"flattened\"\n+      _ff_initialized,       \/\/ has ConstantValue initializer attribute\n+      _ff_injected,          \/\/ internal field injected by the JVM\n+      _ff_generic,           \/\/ has a generic signature\n+      _ff_stable,            \/\/ trust as stable b\/c declared as @Stable\n+      _ff_contended,         \/\/ is contended, may have contention-group\n+      _ff_multifield,        \/\/ carry a multifield annotation.\n+      _ff_multifield_base,   \/\/ is a base field of multifield bundle.\n+    };\n+\n+    \/\/ Some but not all of the flag bits signal the presence of an\n+    \/\/ additional 32-bit item in the field record.\n+    static const u4 _optional_item_bit_mask =\n+      flag_mask((int)_ff_initialized) |\n+      flag_mask((int)_ff_generic)     |\n+      flag_mask((int)_ff_contended);\n+\n+    \/\/ boilerplate:\n+    u4 _flags;\n+\n+    bool test_flag(FieldFlagBitPosition pos) const {\n+      return (_flags & flag_mask(pos)) != 0;\n+    }\n+    void update_flag(FieldFlagBitPosition pos, bool z) {\n+      if (z)    _flags |=  flag_mask(pos);\n+      else      _flags &= ~flag_mask(pos);\n+    }\n@@ -88,3 +104,8 @@\n-  void set_name_index(u2 val)                    { _shorts[name_index_offset] = val;         }\n-  void set_signature_index(u2 val)               { _shorts[signature_index_offset] = val;    }\n-  void set_initval_index(u2 val)                 { _shorts[initval_index_offset] = val;      }\n+   public:\n+    FieldFlags(u4 flags) {\n+      _flags = flags;\n+    }\n+    u4 as_uint() const { return _flags; }\n+    bool has_any_optionals() const {\n+      return (_flags & _optional_item_bit_mask) != 0;\n+    }\n@@ -92,4 +113,35 @@\n-  u2 name_index() const                          { assert(!is_multifield(), \"wrong call\"); return _shorts[name_index_offset]; }\n-  u2 signature_index() const                     { return _shorts[signature_index_offset];   }\n-  u2 initval_index() const                       { return _shorts[initval_index_offset];     }\n-  u2 secondary_index() const                     { assert( is_multifield(), \"wrong call\"); return _shorts[name_index_offset]; }\n+    bool is_initialized() const     { return test_flag(_ff_initialized); }\n+    bool is_inlined() const         { return test_flag(_ff_inlined); }\n+    bool is_injected() const        { return test_flag(_ff_injected); }\n+    bool is_generic() const         { return test_flag(_ff_generic); }\n+    bool is_stable() const          { return test_flag(_ff_stable); }\n+    bool is_contended() const       { return test_flag(_ff_contended); }\n+    bool is_multifield() const      { return test_flag(_ff_multifield); }\n+    bool is_multifield_base() const { return test_flag(_ff_multifield_base); }\n+\n+    void update_initialized(bool z)      { update_flag(_ff_initialized, z); }\n+    void update_inlined(bool z)          { update_flag(_ff_inlined, z); }\n+    void update_injected(bool z)         { update_flag(_ff_injected, z); }\n+    void update_generic(bool z)          { update_flag(_ff_generic, z); }\n+    void update_stable(bool z)           { update_flag(_ff_stable, z); }\n+    void update_contended(bool z)        { update_flag(_ff_contended, z); }\n+    void update_multifield(bool z)       { update_flag(_ff_multifield, z); }\n+    void update_multifield_base(bool z)  { update_flag(_ff_multifield_base, z); }\n+  };\n+\n+ private:\n+  \/\/ The following items are the unpacked bitwise information content\n+  \/\/ of a field record.  Per-field metadata extracted from the class\n+  \/\/ file are stored logically as a group of these items.  The\n+  \/\/ classfile parser produces these records in a temporary array, and\n+  \/\/ then compresses them into a FieldInfoStream.\n+  \/\/\n+  u4 _index;                    \/\/ which field it is\n+  u2 _name_index;               \/\/ index in CP of name\n+  u2 _signature_index;          \/\/ index in CP of descriptor\n+  u4 _offset;                   \/\/ offset in object layout\n+  AccessFlags _access_flags;    \/\/ access flags (JVM spec)\n+  FieldFlags _field_flags;      \/\/ VM defined flags (not JVM spec)\n+  u2 _initializer_index;        \/\/ index from ConstantValue attr (or 0)\n+  u2 _generic_signature_index;  \/\/ index from GenericSignature attr (or 0)\n+  u2 _contention_group;         \/\/ index from @Contended group item (or 0)\n@@ -98,23 +150,40 @@\n-  static FieldInfo* from_field_array(Array<u2>* fields, int index) {\n-    return ((FieldInfo*)fields->adr_at(index * field_slots));\n-  }\n-  static FieldInfo* from_field_array(u2* fields, int index) {\n-    return ((FieldInfo*)(fields + index * field_slots));\n-  }\n-  void initialize(u2 access_flags,\n-                  u2 name_index,\n-                  u2 signature_index,\n-                  u2 initval_index) {\n-    _shorts[access_flags_offset] = access_flags;\n-    _shorts[name_index_offset] = name_index;\n-    _shorts[signature_index_offset] = signature_index;\n-    _shorts[initval_index_offset] = initval_index;\n-    _shorts[low_packed_offset] = 0;\n-    _shorts[high_packed_offset] = 0;\n-  }\n-\n-  u2 access_flags() const                        { return _shorts[access_flags_offset];            }\n-  u4 offset() const {\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) != 0, \"Offset must have been set\");\n-    return build_int_from_shorts(_shorts[low_packed_offset], _shorts[high_packed_offset]) >> FIELDINFO_TAG_SIZE;\n-  }\n+  FieldInfo() : _name_index(0),\n+                _signature_index(0),\n+                _offset(0),\n+                _access_flags(AccessFlags(0)),\n+                _field_flags(FieldFlags(0)),\n+                _initializer_index(0),\n+                _generic_signature_index(0),\n+                _contention_group(0) { }\n+\n+  FieldInfo(AccessFlags access_flags, u2 name_index, u2 signature_index, u2 initval_index, FieldInfo::FieldFlags fflags) :\n+            _name_index(name_index),\n+            _signature_index(signature_index),\n+            _offset(0),\n+            _access_flags(access_flags),\n+            _field_flags(fflags),\n+            _initializer_index(initval_index),\n+            _generic_signature_index(0),\n+            _contention_group(0) {\n+              if (initval_index != 0) {\n+                _field_flags.update_initialized(true);\n+              }\n+            }\n+\n+  u4 index() const                           { return _index; }\n+  void set_index(u4 index)                   { _index = index; }\n+  u2 name_index() const                      { assert(!_field_flags.is_multifield(), \"wrong call\"); return _name_index; }\n+  void set_name_index(u2 index)              { _name_index = index; }\n+  u2 signature_index() const                 { return _signature_index; }\n+  void set_signature_index(u2 index)         { _signature_index = index; }\n+  u4 offset() const                          { return _offset; }\n+  void set_offset(u4 offset)                 { _offset = offset; }\n+  AccessFlags access_flags() const           { return _access_flags; }\n+  FieldFlags field_flags() const             { return _field_flags; }\n+  FieldFlags* field_flags_addr()             { return &_field_flags; }\n+  u2 initializer_index() const               { return _initializer_index; }\n+  void set_initializer_index(u2 index)       { _initializer_index = index; }\n+  u2 generic_signature_index() const         { return _generic_signature_index; }\n+  void set_generic_signature_index(u2 index) { _generic_signature_index = index; }\n+  u2 contention_group() const                { return _contention_group; }\n+  u2 secondary_index() const                 { assert(_field_flags.is_multifield(), \"wrong call\"); return _name_index; }\n@@ -124,1 +193,1 @@\n-    return (_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) != 0;\n+    return _field_flags.is_contended();\n@@ -128,1 +197,1 @@\n-    return (_shorts[low_packed_offset] & FIELDINFO_TAG_MULTIFIELD) != 0;\n+    return _field_flags.is_multifield();\n@@ -132,1 +201,1 @@\n-    return (_shorts[low_packed_offset] & FIELDINFO_TAG_MULTIFIELD_BASE) != 0;\n+    return _field_flags.is_multifield_base();\n@@ -136,4 +205,8 @@\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) == 0, \"Offset must not have been set\");\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) != 0, \"Field must be contended\");\n-    return _shorts[high_packed_offset];\n- }\n+    assert(is_contended(), \"\");\n+    return _contention_group;\n+  }\n+\n+  void set_contended_group(u2 group) {\n+    _field_flags.update_contended(true);\n+    _contention_group = group;\n+  }\n@@ -142,1 +215,1 @@\n-    return (_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET)!= 0;\n+    return _offset != 0;\n@@ -145,0 +218,6 @@\n+  inline Symbol* name(Array<MultiFieldInfo>* multifield_info, ConstantPool* cp) const;\n+\n+  inline Symbol* signature(ConstantPool* cp) const;\n+\n+  inline Symbol* lookup_symbol(int symbol_index) const;\n+\n@@ -147,10 +226,1 @@\n-  Symbol* name(Array<MultiFieldInfo>* multifield_info, ConstantPool* cp) const {\n-    if (is_multifield()) {\n-      return get_multifield_name(multifield_info);\n-    }\n-    int index = name_index();\n-    if (is_internal()) {\n-      return lookup_symbol(index);\n-    }\n-    return cp->symbol_at(index);\n-  }\n+  inline u2 multifield_base(Array<MultiFieldInfo>* multifield_info) const;\n@@ -158,7 +228,1 @@\n-  Symbol* signature(ConstantPool* cp) const {\n-    int index = signature_index();\n-    if (is_internal()) {\n-      return lookup_symbol(index);\n-    }\n-    return cp->symbol_at(index);\n-  }\n+  inline jbyte multifield_index(Array<MultiFieldInfo>* multifield_info) const;\n@@ -166,13 +230,3 @@\n-  void set_access_flags(u2 val)                  { _shorts[access_flags_offset] = val;             }\n-  void set_offset(u4 val)                        {\n-    val = val << FIELDINFO_TAG_SIZE; \/\/ make room for tag\n-    bool inlined = is_inlined();\n-    bool multifield = is_multifield();\n-    bool multifield_base = is_multifield_base();\n-    _shorts[low_packed_offset] = extract_low_short_from_int(val) | FIELDINFO_TAG_OFFSET;\n-    if (inlined) set_inlined(true);\n-    if (multifield) set_multifield(true);\n-    if (multifield_base) set_multifield_base(true);\n-    _shorts[high_packed_offset] = extract_high_short_from_int(val);\n-    assert(is_inlined() || !inlined, \"just checking\");\n-  }\n+  void print(outputStream* os, ConstantPool* cp);\n+  void static print_from_growable_array(outputStream* os, GrowableArray<FieldInfo>* array, ConstantPool* cp);\n+};\n@@ -180,7 +234,0 @@\n-  void set_inlined(bool b) {\n-    if (b) {\n-      _shorts[low_packed_offset] |= FIELDINFO_TAG_INLINED;\n-    } else {\n-      _shorts[low_packed_offset] &= ~FIELDINFO_TAG_INLINED;\n-    }\n-  }\n@@ -188,3 +235,1 @@\n-  bool is_inlined() {\n-    return (_shorts[low_packed_offset] & FIELDINFO_TAG_INLINED) != 0;\n-  }\n+class FieldInfoStream;\n@@ -192,6 +237,12 @@\n-  void set_contended_group(u2 val) {\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_OFFSET) == 0, \"Offset must not have been set\");\n-    assert((_shorts[low_packed_offset] & FIELDINFO_TAG_CONTENDED) == 0, \"Overwriting contended group\");\n-    _shorts[low_packed_offset] |= FIELDINFO_TAG_CONTENDED;\n-    _shorts[high_packed_offset] = val;\n-  }\n+\/\/ Gadget for sizing and\/or writing a stream of field records.\n+template<typename CON>\n+class Mapper {\n+  CON* _consumer;  \/\/ can be UNSIGNED5::Writer or UNSIGNED5::Sizer\n+  int _next_index;\n+public:\n+  Mapper(CON* consumer) : _consumer(consumer) { _next_index = 0; }\n+  int next_index() const { return _next_index; }\n+  void set_next_index(int next_index) { _next_index = next_index; }\n+  CON* consumer() const { return _consumer; }\n+  void map_field_info(const FieldInfo& fi);\n+};\n@@ -199,14 +250,6 @@\n-  void set_multifield(bool b) {\n-    if (b) {\n-      _shorts[low_packed_offset] |= FIELDINFO_TAG_MULTIFIELD;\n-    } else {\n-      _shorts[low_packed_offset] &= ~FIELDINFO_TAG_MULTIFIELD;\n-    }\n-  }\n-  void set_multifield_base(bool b) {\n-    if (b) {\n-      _shorts[low_packed_offset] |= FIELDINFO_TAG_MULTIFIELD_BASE;\n-    } else {\n-      _shorts[low_packed_offset] &= ~FIELDINFO_TAG_MULTIFIELD_BASE;\n-    }\n-  }\n+\/\/ Gadget for decoding and reading the stream of field records.\n+class FieldInfoReader {\n+  friend class FieldInfoStream;\n+  friend class ClassFileParser;\n+  friend class FieldStreamBase;\n+  friend class FieldInfo;\n@@ -215,2 +258,2 @@\n-  u2 multifield_base(Array<MultiFieldInfo>* multifield_info) const;\n-  jbyte multifield_index(Array<MultiFieldInfo>* multifield_info) const;\n+  UNSIGNED5::Reader<const u1*, int> _r;\n+  int _next_index;\n@@ -218,3 +261,2 @@\n-  bool is_internal() const {\n-    return (access_flags() & JVM_ACC_FIELD_INTERNAL) != 0;\n-  }\n+  public:\n+  FieldInfoReader(const Array<u1>* fi);\n@@ -222,7 +264,3 @@\n-  bool is_stable() const {\n-    return (access_flags() & JVM_ACC_FIELD_STABLE) != 0;\n-  }\n-  void set_stable(bool z) {\n-    if (z) _shorts[access_flags_offset] |=  JVM_ACC_FIELD_STABLE;\n-    else   _shorts[access_flags_offset] &= ~JVM_ACC_FIELD_STABLE;\n-  }\n+  private:\n+  uint32_t next_uint() { return _r.next_uint(); }\n+  void skip(int n) { int s = _r.try_skip(n); assert(s == n,\"\"); }\n@@ -230,4 +268,72 @@\n-  Symbol* lookup_symbol(int symbol_index) const {\n-    assert(is_internal(), \"only internal fields\");\n-    return Symbol::vm_symbol_at(static_cast<vmSymbolID>(symbol_index));\n-  }\n+public:\n+  int has_next() { return _r.has_next(); }\n+  int position() { return _r.position(); }\n+  int next_index() { return _next_index; }\n+  void read_field_info(FieldInfo& fi);\n+  \/\/ skip a whole field record, both required and optional bits\n+  FieldInfoReader&  skip_field_info();\n+\n+  \/\/ Skip to the nth field.  If the reader is freshly initialized to\n+  \/\/ the zero index, this will call skip_field_info() n times.\n+  FieldInfoReader& skip_to_field_info(int n);\n+\n+  \/\/ for random access, if you know where to go up front:\n+  FieldInfoReader& set_position_and_next_index(int position, int next_index);\n+};\n+\n+\/\/ The format of the stream, after decompression, is a series of\n+\/\/ integers organized like this:\n+\/\/\n+\/\/   FieldInfoStream := j=num_java_fields k=num_injected_fields Field[j+k] End\n+\/\/   Field := name sig offset access flags Optionals(flags)\n+\/\/   Optionals(i) := initval?[i&is_init]     \/\/ ConstantValue attr\n+\/\/                   gsig?[i&is_generic]     \/\/ signature attr\n+\/\/                   group?[i&is_contended]  \/\/ Contended anno (group)\n+\/\/   End = 0\n+\/\/\n+class FieldInfoStream : AllStatic {\n+  friend class fieldDescriptor;\n+  friend class JavaFieldStream;\n+  friend class FieldStreamBase;\n+  friend class ClassFileParser;\n+\n+ public:\n+  static int num_java_fields(const Array<u1>* fis);\n+  static int num_injected_java_fields(const Array<u1>* fis);\n+  static int num_total_fields(const Array<u1>* fis);\n+\n+  static Array<u1>* create_FieldInfoStream(GrowableArray<FieldInfo>* fields, int java_fields, int injected_fields,\n+                                                          ClassLoaderData* loader_data, TRAPS);\n+  static GrowableArray<FieldInfo>* create_FieldInfoArray(const Array<u1>* fis, int* java_fields_count, int* injected_fields_count);\n+  static void print_from_fieldinfo_stream(Array<u1>* fis, outputStream* os, ConstantPool* cp);\n+};\n+\n+class FieldStatus {\n+  enum FieldStatusBitPosition {\n+    _fs_access_watched,       \/\/ field access is watched by JVMTI\n+    _fs_modification_watched, \/\/ field modification is watched by JVMTI\n+    _initialized_final_update \/\/ (static) final field updated outside (class) initializer\n+  };\n+\n+  \/\/ boilerplate:\n+  u1 _flags;\n+  static constexpr u1 flag_mask(FieldStatusBitPosition pos) { return (u1)1 << (int)pos; }\n+  bool test_flag(FieldStatusBitPosition pos) { return (_flags & flag_mask(pos)) != 0; }\n+  \/\/ this performs an atomic update on a live status byte!\n+  void update_flag(FieldStatusBitPosition pos, bool z);\n+  \/\/ out-of-line functions do a CAS-loop\n+  static void atomic_set_bits(u1& flags, u1 mask);\n+  static void atomic_clear_bits(u1& flags, u1 mask);\n+\n+  public:\n+  FieldStatus() { _flags = 0; }\n+  FieldStatus(u1 flags) { _flags = flags; }\n+  u1 as_uint() { return _flags; }\n+\n+  bool is_access_watched()        { return test_flag(_fs_access_watched); }\n+  bool is_modification_watched()  { return test_flag(_fs_modification_watched); }\n+  bool is_initialized_final_update() { return test_flag(_initialized_final_update); }\n+\n+  void update_access_watched(bool z);\n+  void update_modification_watched(bool z);\n+  void update_initialized_final_update(bool z);\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.hpp","additions":261,"deletions":155,"binary":false,"changes":416,"status":"modified"},{"patch":"@@ -0,0 +1,189 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_OOPS_FIELDINFO_INLINE_HPP\n+#define SHARE_OOPS_FIELDINFO_INLINE_HPP\n+\n+#include \"oops\/fieldInfo.hpp\"\n+\n+#include \"memory\/metadataFactory.hpp\"\n+#include \"oops\/constantPool.hpp\"\n+#include \"oops\/symbol.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+\n+inline Symbol* FieldInfo::name(Array<MultiFieldInfo>* multifield_info, ConstantPool* cp) const {\n+  if (multifield_info && is_multifield()) {\n+    return get_multifield_name(multifield_info);\n+  }\n+  int index = _name_index;\n+  if (_field_flags.is_injected()) {\n+    return lookup_symbol(index);\n+  }\n+  return cp->symbol_at(index);\n+}\n+\n+inline Symbol* FieldInfo::signature(ConstantPool* cp) const {\n+  int index = _signature_index;\n+  if (_field_flags.is_injected()) {\n+    return lookup_symbol(index);\n+  }\n+  return cp->symbol_at(index);\n+}\n+\n+inline Symbol* FieldInfo::lookup_symbol(int symbol_index) const {\n+  assert(_field_flags.is_injected(), \"only injected fields\");\n+  return Symbol::vm_symbol_at(static_cast<vmSymbolID>(symbol_index));\n+}\n+\n+inline int FieldInfoStream::num_injected_java_fields(const Array<u1>* fis) {\n+  FieldInfoReader fir(fis);\n+  fir.skip(1);\n+  return fir.next_uint();\n+}\n+\n+inline int FieldInfoStream::num_total_fields(const Array<u1>* fis) {\n+  FieldInfoReader fir(fis);\n+  return fir.next_uint() + fir.next_uint();\n+}\n+\n+inline int FieldInfoStream::num_java_fields(const Array<u1>* fis) { return FieldInfoReader(fis).next_uint(); }\n+\n+inline Symbol* FieldInfo::get_multifield_name(Array<MultiFieldInfo>* multifield_info) const {\n+  assert(is_multifield(), \"Sanity check\");\n+  return multifield_info->at(secondary_index()).name();\n+}\n+\n+inline u2 FieldInfo::multifield_base(Array<MultiFieldInfo>* multifield_info) const {\n+  assert(is_multifield() || is_multifield_base(), \"Must be\");\n+  return is_multifield() ? multifield_info->at(secondary_index()).base_index() : index();\n+}\n+\n+inline jbyte FieldInfo::multifield_index(Array<MultiFieldInfo>* multifield_info) const {\n+  assert(is_multifield() || is_multifield_base(), \"Sanity check\");\n+  return is_multifield() ? multifield_info->at(secondary_index()).multifield_index() : (jbyte)-1;\n+}\n+\n+template<typename CON>\n+inline void Mapper<CON>::map_field_info(const FieldInfo& fi) {\n+  _next_index++;  \/\/ pre-increment\n+  _consumer->accept_uint(!fi.is_multifield() ? fi.name_index() : fi.secondary_index());\n+  _consumer->accept_uint(fi.signature_index());\n+  _consumer->accept_uint(fi.offset());\n+  _consumer->accept_uint(fi.access_flags().as_int());\n+  _consumer->accept_uint(fi.field_flags().as_uint());\n+  if(fi.field_flags().has_any_optionals()) {\n+    if (fi.field_flags().is_initialized()) {\n+      _consumer->accept_uint(fi.initializer_index());\n+    }\n+    if (fi.field_flags().is_generic()) {\n+      _consumer->accept_uint(fi.generic_signature_index());\n+    }\n+    if (fi.field_flags().is_contended()) {\n+      _consumer->accept_uint(fi.contention_group());\n+    }\n+  } else {\n+    assert(fi.initializer_index() == 0, \"\");\n+    assert(fi.generic_signature_index() == 0, \"\");\n+    assert(fi.contention_group() == 0, \"\");\n+  }\n+}\n+\n+\n+inline FieldInfoReader::FieldInfoReader(const Array<u1>* fi)\n+  : _r(fi->data(), 0),\n+    _next_index(0) { }\n+\n+inline void FieldInfoReader::read_field_info(FieldInfo& fi) {\n+  fi._index = _next_index++;\n+  fi._name_index = next_uint();\n+  fi._signature_index = next_uint();\n+  fi._offset = next_uint();\n+  fi._access_flags = AccessFlags(next_uint());\n+  fi._field_flags = FieldInfo::FieldFlags(next_uint());\n+  if (fi._field_flags.is_initialized()) {\n+    fi._initializer_index = next_uint();\n+  } else {\n+    fi._initializer_index = 0;\n+  }\n+  if (fi._field_flags.is_generic()) {\n+    fi._generic_signature_index = next_uint();\n+  } else {\n+    fi._generic_signature_index = 0;\n+  }\n+  if (fi._field_flags.is_contended()) {\n+    fi._contention_group = next_uint();\n+  } else {\n+    fi._contention_group = 0;\n+  }\n+}\n+\n+inline FieldInfoReader&  FieldInfoReader::skip_field_info() {\n+  _next_index++;\n+  const int name_sig_af_off = 4;  \/\/ four items\n+  skip(name_sig_af_off);\n+  FieldInfo::FieldFlags ff(next_uint());\n+  if (ff.has_any_optionals()) {\n+    const int init_gen_cont = (ff.is_initialized() +\n+                                ff.is_generic() +\n+                                ff.is_contended());\n+    skip(init_gen_cont);  \/\/ up to three items\n+  }\n+  return *this;\n+}\n+\n+\/\/ Skip to the nth field.  If the reader is freshly initialized to\n+\/\/ the zero index, this will call skip_field_info() n times.\n+inline FieldInfoReader& FieldInfoReader::skip_to_field_info(int n) {\n+  assert(n >= _next_index, \"already past that index\");\n+  const int count = n - _next_index;\n+  for (int i = 0; i < count; i++)  skip_field_info();\n+  assert(_next_index == n, \"\");\n+  return *this;\n+}\n+\n+\/\/ for random access, if you know where to go up front:\n+inline FieldInfoReader& FieldInfoReader::set_position_and_next_index(int position, int next_index) {\n+  _r.set_position(position);\n+  _next_index = next_index;\n+  return *this;\n+}\n+\n+inline void FieldStatus::atomic_set_bits(u1& flags, u1 mask) {\n+  Atomic::fetch_then_or(&flags, mask);\n+}\n+\n+inline void FieldStatus::atomic_clear_bits(u1& flags, u1 mask) {\n+  Atomic::fetch_then_and(&flags, (u1)(~mask));\n+}\n+\n+inline void FieldStatus::update_flag(FieldStatusBitPosition pos, bool z) {\n+  if (z) atomic_set_bits(_flags, flag_mask(pos));\n+  else atomic_clear_bits(_flags, flag_mask(pos));\n+}\n+\n+inline void FieldStatus::update_access_watched(bool z) { update_flag(_fs_access_watched, z); }\n+inline void FieldStatus::update_modification_watched(bool z) { update_flag(_fs_modification_watched, z); }\n+inline void FieldStatus::update_initialized_final_update(bool z) { update_flag(_initialized_final_update, z); }\n+\n+#endif \/\/ SHARE_OOPS_FIELDINFO_INLINE_HPP\n","filename":"src\/hotspot\/share\/oops\/fieldInfo.inline.hpp","additions":189,"deletions":0,"binary":false,"changes":189,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,1 +43,2 @@\n-  Array<u2>*          _fields;\n+  const Array<u1>*    _fieldinfo_stream;\n+  FieldInfoReader     _reader;\n@@ -48,1 +49,2 @@\n-  int                 _generic_signature_slot;\n+\n+  FieldInfo           _fi_buf;\n@@ -51,30 +53,3 @@\n-  FieldInfo* field() const { return FieldInfo::from_field_array(_fields, _index); }\n-\n-  int init_generic_signature_start_slot() {\n-    int length = _fields->length();\n-    int num_fields = _index;\n-    int skipped_generic_signature_slots = 0;\n-    FieldInfo* fi;\n-    AccessFlags flags;\n-    \/* Scan from 0 to the current _index. Count the number of generic\n-       signature slots for field[0] to field[_index - 1]. *\/\n-    for (int i = 0; i < _index; i++) {\n-      fi = FieldInfo::from_field_array(_fields, i);\n-      flags.set_flags(fi->access_flags());\n-      if (flags.field_has_generic_signature()) {\n-        length --;\n-        skipped_generic_signature_slots ++;\n-      }\n-    }\n-    \/* Scan from the current _index. *\/\n-    for (int i = _index; i*FieldInfo::field_slots < length; i++) {\n-      fi = FieldInfo::from_field_array(_fields, i);\n-      flags.set_flags(fi->access_flags());\n-      if (flags.field_has_generic_signature()) {\n-        length --;\n-      }\n-      num_fields ++;\n-    }\n-    _generic_signature_slot = length + skipped_generic_signature_slots;\n-    assert(_generic_signature_slot <= _fields->length(), \"\");\n-    return num_fields;\n+  FieldInfo const * field() const {\n+    assert(!done(), \"no more fields\");\n+    return &_fi_buf;\n@@ -83,1 +58,3 @@\n-  inline FieldStreamBase(Array<u2>* fields, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info, int start, int limit );\n+  inline FieldStreamBase(const Array<u1>* fieldinfo_stream, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info, int start, int limit);\n+\n+  inline FieldStreamBase(Array<u1>* fieldinfo_stream, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info);\n@@ -85,1 +62,9 @@\n-  inline FieldStreamBase(Array<u2>* fields, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info);\n+  private:\n+   void initialize() {\n+    int java_fields_count = _reader.next_uint();\n+    int injected_fields_count = _reader.next_uint();\n+    assert( _limit <= java_fields_count + injected_fields_count, \"Safety check\");\n+    if (_limit != 0) {\n+      _reader.read_field_info(_fi_buf);\n+    }\n+   }\n@@ -94,4 +79,2 @@\n-    if (access_flags().field_has_generic_signature()) {\n-      _generic_signature_slot ++;\n-      assert(_generic_signature_slot <= _fields->length(), \"\");\n-    }\n+    if (done()) return;\n+    _reader.read_field_info(_fi_buf);\n@@ -104,7 +87,1 @@\n-    AccessFlags flags;\n-    flags.set_flags(field()->access_flags());\n-    return flags;\n-  }\n-\n-  void set_access_flags(u2 flags) const {\n-    field()->set_access_flags(flags);\n+    return field()->access_flags();\n@@ -113,2 +90,2 @@\n-  void set_access_flags(AccessFlags flags) const {\n-    set_access_flags(flags.as_short());\n+  FieldInfo::FieldFlags field_flags() const {\n+    return field()->field_flags();\n@@ -130,4 +107,2 @@\n-    if (access_flags().field_has_generic_signature()) {\n-      assert(_generic_signature_slot < _fields->length(), \"out of bounds\");\n-      int index = _fields->at(_generic_signature_slot);\n-      return _constants->symbol_at(index);\n+    if (field()->field_flags().is_generic()) {\n+      return _constants->symbol_at(field()->generic_signature_index());\n@@ -135,1 +110,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -144,1 +119,1 @@\n-    return field()->is_inlined();\n+    return field()->field_flags().is_inlined();\n@@ -147,2 +122,2 @@\n-  void set_inlined(bool b) {\n-    field()->set_inlined(b);\n+  bool is_contended() const {\n+    return field()->is_contended();\n@@ -151,2 +126,2 @@\n-  void set_offset(int offset) {\n-    field()->set_offset(offset);\n+  int contended_group() const {\n+    return field()->contended_group();\n@@ -155,3 +130,1 @@\n-  bool is_offset_set() const {\n-    return field()->is_offset_set();\n-  }\n+  \/\/ Convenient methods\n@@ -159,2 +132,2 @@\n-  bool is_contended() const {\n-    return field()->is_contended();\n+  FieldInfo to_FieldInfo() {\n+    return _fi_buf;\n@@ -173,5 +146,1 @@\n-    if (field()->is_multifield_base()) {\n-      return index();\n-    } else {\n-      return _multifield_info->at(field()->secondary_index()).base_index();\n-    }\n+    return field()->is_multifield() ? _multifield_info->at(field()->secondary_index()).base_index() : index();\n@@ -182,5 +151,1 @@\n-    if (field()->is_multifield_base()) {\n-      return 0;\n-    } else {\n-      return _multifield_info->at(field()->secondary_index()).multifield_index();\n-    }\n+    return field()->is_multifield() ? _multifield_info->at(field()->secondary_index()).multifield_index() : (jbyte)0;\n@@ -189,2 +154,2 @@\n-  int contended_group() const {\n-    return field()->contended_group();\n+  int num_total_fields() const {\n+    return FieldInfoStream::num_total_fields(_fieldinfo_stream);\n@@ -204,1 +169,1 @@\n-  JavaFieldStream(const InstanceKlass* k): FieldStreamBase(k->fields(), k->constants(), k->multifield_info(), 0, k->java_fields_count()) {}\n+  JavaFieldStream(const InstanceKlass* k): FieldStreamBase(k->fieldinfo_stream(), k->constants(), k->multifield_info(), 0, k->java_fields_count()) {}\n@@ -207,1 +172,1 @@\n-    assert(!field()->is_internal(), \"regular only\");\n+    assert(!field()->field_flags().is_injected(), \"regular only\");\n@@ -210,4 +175,1 @@\n-  void set_name_index(int index) {\n-    assert(!field()->is_internal(), \"regular only\");\n-    field()->set_name_index(index);\n-  }\n+\n@@ -215,1 +177,1 @@\n-    assert(!field()->is_internal(), \"regular only\");\n+    assert(!field()->field_flags().is_injected(), \"regular only\");\n@@ -217,0 +179,1 @@\n+    return -1;\n@@ -218,4 +181,1 @@\n-  void set_signature_index(int index) {\n-    assert(!field()->is_internal(), \"regular only\");\n-    field()->set_signature_index(index);\n-  }\n+\n@@ -223,13 +183,3 @@\n-    assert(!field()->is_internal(), \"regular only\");\n-    if (access_flags().field_has_generic_signature()) {\n-      assert(_generic_signature_slot < _fields->length(), \"out of bounds\");\n-      return _fields->at(_generic_signature_slot);\n-    } else {\n-      return 0;\n-    }\n-  }\n-  void set_generic_signature_index(int index) {\n-    assert(!field()->is_internal(), \"regular only\");\n-    if (access_flags().field_has_generic_signature()) {\n-      assert(_generic_signature_slot < _fields->length(), \"out of bounds\");\n-      _fields->at_put(_generic_signature_slot, index);\n+    assert(!field()->field_flags().is_injected(), \"regular only\");\n+    if (field()->field_flags().is_generic()) {\n+      return field()->generic_signature_index();\n@@ -237,0 +187,1 @@\n+    return 0;\n@@ -238,0 +189,1 @@\n+\n@@ -239,6 +191,2 @@\n-    assert(!field()->is_internal(), \"regular only\");\n-    return field()->initval_index();\n-  }\n-  void set_initval_index(int index) {\n-    assert(!field()->is_internal(), \"regular only\");\n-    return field()->set_initval_index(index);\n+    assert(!field()->field_flags().is_injected(), \"regular only\");\n+    return field()->initializer_index();\n@@ -248,1 +196,0 @@\n-\n@@ -252,1 +199,1 @@\n-  InternalFieldStream(InstanceKlass* k): FieldStreamBase(k->fields(), k->constants(), k->multifield_info(), k->java_fields_count(), 0) {}\n+  InternalFieldStream(InstanceKlass* k): FieldStreamBase(k->fieldinfo_stream(), k->constants(), k->multifield_info(), k->java_fields_count(), 0) {}\n@@ -258,2 +205,2 @@\n-  AllFieldStream(Array<u2>* fields, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info): FieldStreamBase(fields, constants, multifield_info) {}\n-  AllFieldStream(InstanceKlass* k):      FieldStreamBase(k->fields(), k->constants(), k->multifield_info()) {}\n+  AllFieldStream(Array<u1>* fieldinfo, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info): FieldStreamBase(fieldinfo, constants, multifield_info) {}\n+  AllFieldStream(const InstanceKlass* k):      FieldStreamBase(k->fieldinfo_stream(), k->constants(), k->multifield_info()) {}\n","filename":"src\/hotspot\/share\/oops\/fieldStreams.hpp","additions":56,"deletions":109,"binary":false,"changes":165,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"oops\/fieldInfo.hpp\"\n@@ -32,2 +33,6 @@\n-FieldStreamBase::FieldStreamBase(Array<u2>* fields, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info, int start, int limit) : _fields(fields),\n-         _constants(constantPoolHandle(Thread::current(), constants)), _multifield_info(multifield_info), _index(start) {\n+FieldStreamBase::FieldStreamBase(const Array<u1>* fieldinfo_stream, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info, int start, int limit) :\n+         _fieldinfo_stream(fieldinfo_stream),\n+         _reader(FieldInfoReader(_fieldinfo_stream)),\n+         _constants(constantPoolHandle(Thread::current(), constants)),\n+         _multifield_info(multifield_info),\n+         _index(start) {\n@@ -35,2 +40,1 @@\n-  int num_fields = init_generic_signature_start_slot();\n-    _limit = num_fields;\n+    _limit = FieldInfoStream::num_total_fields(_fieldinfo_stream);\n@@ -41,0 +45,1 @@\n+  initialize();\n@@ -43,3 +48,8 @@\n-FieldStreamBase::FieldStreamBase(Array<u2>* fields, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info) : _fields(fields),\n-         _constants(constantPoolHandle(Thread::current(), constants)), _multifield_info(multifield_info), _index(0) {\n-  _limit = init_generic_signature_start_slot();\n+FieldStreamBase::FieldStreamBase(Array<u1>* fieldinfo_stream, ConstantPool* constants, Array<MultiFieldInfo>* multifield_info) :\n+        _fieldinfo_stream(fieldinfo_stream),\n+        _reader(FieldInfoReader(_fieldinfo_stream)),\n+        _constants(constantPoolHandle(Thread::current(), constants)),\n+        _multifield_info(multifield_info),\n+        _index(0),\n+        _limit(FieldInfoStream::num_total_fields(_fieldinfo_stream)) {\n+  initialize();\n@@ -48,4 +58,7 @@\n-FieldStreamBase::FieldStreamBase(InstanceKlass* klass) : _fields(klass->fields()),\n-         _constants(constantPoolHandle(Thread::current(), klass->constants())), _multifield_info(klass->multifield_info()),_index(0),\n-         _limit(klass->java_fields_count()) {\n-  init_generic_signature_start_slot();\n+FieldStreamBase::FieldStreamBase(InstanceKlass* klass) :\n+         _fieldinfo_stream(klass->fieldinfo_stream()),\n+         _reader(FieldInfoReader(_fieldinfo_stream)),\n+         _constants(constantPoolHandle(Thread::current(), klass->constants())),\n+         _multifield_info(klass->multifield_info()),\n+         _index(0),\n+         _limit(FieldInfoStream::num_total_fields(_fieldinfo_stream)) {\n@@ -53,0 +66,1 @@\n+  initialize();\n","filename":"src\/hotspot\/share\/oops\/fieldStreams.inline.hpp","additions":26,"deletions":12,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -55,0 +55,6 @@\n+  set_prototype_header(markWord::inline_type_prototype());\n+  assert(is_inline_klass(), \"sanity\");\n+  assert(prototype_header().is_inline_type(), \"sanity\");\n+}\n+\n+void InlineKlass::init_fixed_block() {\n@@ -65,3 +71,0 @@\n-  set_prototype_header(markWord::inline_type_prototype());\n-  assert(is_inline_klass(), \"sanity\");\n-  assert(prototype_header().is_inline_type(), \"sanity\");\n@@ -491,1 +494,1 @@\n-    \/\/ Oop is tagged, must be an InlineKlass oop\n+    \/\/ Return value is tagged, must be an InlineKlass pointer\n@@ -498,6 +501,3 @@\n-#ifdef ASSERT\n-  \/\/ Oop is not tagged, must be a valid oop\n-  if (VerifyOops) {\n-    oopDesc::verify(cast_to_oop(ptr));\n-  }\n-#endif\n+  \/\/ Return value is not tagged, must be a valid oop\n+  assert(oopDesc::is_oop_or_null(cast_to_oop(ptr), true),\n+         \"Bad oop return: \" PTR_FORMAT, ptr);\n@@ -513,1 +513,0 @@\n-  it->push_internal_pointer(&this_ptr, (intptr_t*)&_adr_inlineklass_fixed_block);\n@@ -539,0 +538,4 @@\n+  \/\/ We are no longer bookkeeping pointer to InlineKlassFixedBlock during serialization, hence re-initializing\n+  \/\/ fixed block address since InstanceKlass::size() already take into account its size, thus it will anyways\n+  \/\/ be part of shared archive.\n+  _adr_inlineklass_fixed_block = inlineklass_static_block();\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":14,"deletions":11,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -78,0 +78,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -115,1 +116,1 @@\n-    char* data = NULL;                                           \\\n+    char* data = nullptr;                                        \\\n@@ -118,1 +119,1 @@\n-    if (clss_name != NULL) {                                     \\\n+    if (clss_name != nullptr) {                                  \\\n@@ -128,1 +129,1 @@\n-    char* data = NULL;                                           \\\n+    char* data = nullptr;                                        \\\n@@ -131,1 +132,1 @@\n-    if (clss_name != NULL) {                                     \\\n+    if (clss_name != nullptr) {                                  \\\n@@ -150,1 +151,1 @@\n-  assert(class_name != NULL, \"invariant\");\n+  assert(class_name != nullptr, \"invariant\");\n@@ -158,1 +159,1 @@\n-    if (super_klass != NULL) {\n+    if (super_klass != nullptr) {\n@@ -167,3 +168,3 @@\n-  FieldInfo* MultiFieldInfo::base_field_info(InstanceKlass* ik) {\n-    return ik->field(_base_index);\n-  }\n+FieldInfo MultiFieldInfo::base_field_info(InstanceKlass* ik) {\n+  return ik->field(_base_index);\n+}\n@@ -171,3 +172,3 @@\n-  void MultiFieldInfo::metaspace_pointers_do(MetaspaceClosure* it) {\n-    it->push(&_name);\n-  }\n+void MultiFieldInfo::metaspace_pointers_do(MetaspaceClosure* it) {\n+  it->push(&_name);\n+}\n@@ -175,1 +176,3 @@\n-bool InstanceKlass::field_is_null_free_inline_type(int index) const { return Signature::basic_type(field(index)->signature(constants())) == T_PRIMITIVE_OBJECT; }\n+bool InstanceKlass::field_is_null_free_inline_type(int index) const {\n+  return Signature::basic_type(field_signature(index)) == T_PRIMITIVE_OBJECT;\n+}\n@@ -188,1 +191,1 @@\n-  if (_nest_members == NULL || _nest_members == Universe::the_empty_short_array()) {\n+  if (_nest_members == nullptr || _nest_members == Universe::the_empty_short_array()) {\n@@ -220,2 +223,2 @@\n-  assert(k != NULL, \"sanity check\");\n-  assert(_permitted_subclasses != NULL && _permitted_subclasses != Universe::the_empty_short_array(),\n+  assert(k != nullptr, \"sanity check\");\n+  assert(_permitted_subclasses != nullptr && _permitted_subclasses != Universe::the_empty_short_array(),\n@@ -259,1 +262,1 @@\n-\/\/ (such as a native JIT thread) then we simply return NULL, which in turn\n+\/\/ (such as a native JIT thread) then we simply return null, which in turn\n@@ -266,2 +269,2 @@\n-\/\/ VirtualMachineErrors are propagated with a NULL return.\n-\/\/ Under any conditions where the _nest_host can be set to non-NULL the resulting\n+\/\/ VirtualMachineErrors are propagated with a null return.\n+\/\/ Under any conditions where the _nest_host can be set to non-null the resulting\n@@ -272,1 +275,1 @@\n-  if (nest_host_k != NULL) {\n+  if (nest_host_k != nullptr) {\n@@ -285,1 +288,1 @@\n-      return NULL; \/\/ sentinel to say \"try again from a different context\"\n+      return nullptr; \/\/ sentinel to say \"try again from a different context\"\n@@ -295,1 +298,1 @@\n-        return NULL; \/\/ propagate VMEs\n+        return nullptr; \/\/ propagate VMEs\n@@ -312,1 +315,1 @@\n-      const char* error = NULL;\n+      const char* error = nullptr;\n@@ -374,3 +377,3 @@\n-  assert(host != NULL, \"NULL nest host specified\");\n-  assert(_nest_host == NULL, \"current class has resolved nest-host\");\n-  assert(nest_host_error() == NULL, \"unexpected nest host resolution error exists: %s\",\n+  assert(host != nullptr, \"null nest host specified\");\n+  assert(_nest_host == nullptr, \"current class has resolved nest-host\");\n+  assert(nest_host_error() == nullptr, \"unexpected nest host resolution error exists: %s\",\n@@ -378,1 +381,1 @@\n-  assert((host->_nest_host == NULL && host->_nest_host_index == 0) ||\n+  assert((host->_nest_host == nullptr && host->_nest_host_index == 0) ||\n@@ -389,1 +392,1 @@\n-    } else if (_nest_members != NULL && _nest_members != Universe::the_empty_short_array()) {\n+    } else if (_nest_members != nullptr && _nest_members != Universe::the_empty_short_array()) {\n@@ -401,1 +404,1 @@\n-  assert(this_key != NULL, \"sanity\");\n+  assert(this_key != nullptr, \"sanity\");\n@@ -417,1 +420,1 @@\n-  if (cur_host == NULL) {\n+  if (cur_host == nullptr) {\n@@ -422,1 +425,1 @@\n-  if (k_nest_host == NULL) {\n+  if (k_nest_host == nullptr) {\n@@ -438,1 +441,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -454,1 +457,1 @@\n-  assert(class_name != NULL, \"invariant\");\n+  assert(class_name != nullptr, \"invariant\");\n@@ -456,1 +459,1 @@\n-  assert(loader_data != NULL, \"invariant\");\n+  assert(loader_data != nullptr, \"invariant\");\n@@ -484,1 +487,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -488,1 +491,0 @@\n-  assert(ik->size() == size, \"\");\n@@ -499,2 +501,2 @@\n-  const char* bad = NULL;\n-  address end = NULL;\n+  const char* bad = nullptr;\n+  address end = nullptr;\n@@ -523,1 +525,1 @@\n-  if (m != NULL) {\n+  if (m != nullptr) {\n@@ -537,1 +539,1 @@\n-  assert(default_vtable_indices() == NULL, \"only create once\");\n+  assert(default_vtable_indices() == nullptr, \"only create once\");\n@@ -548,5 +550,5 @@\n-  _nest_members(NULL),\n-  _nest_host(NULL),\n-  _permitted_subclasses(NULL),\n-  _record_components(NULL),\n-  _multifield_info(NULL),\n+  _nest_members(nullptr),\n+  _nest_host(nullptr),\n+  _permitted_subclasses(nullptr),\n+  _record_components(nullptr),\n+  _multifield_info(nullptr),\n@@ -560,4 +562,4 @@\n-  _init_thread(NULL),\n-  _inline_type_field_klasses(NULL),\n-  _preload_classes(NULL),\n-  _adr_inlineklass_fixed_block(NULL)\n+  _init_thread(nullptr),\n+  _inline_type_field_klasses(nullptr),\n+  _preload_classes(nullptr),\n+  _adr_inlineklass_fixed_block(nullptr)\n@@ -570,4 +572,3 @@\n-    if (parser.has_inline_fields()) {\n-      set_has_inline_type_fields();\n-    }\n-    _java_fields_count = parser.java_fields_count();\n+  if (parser.has_inline_fields()) {\n+    set_has_inline_type_fields();\n+  }\n@@ -575,1 +576,1 @@\n-  assert(NULL == _methods, \"underlying memory not zeroed?\");\n+  assert(nullptr == _methods, \"underlying memory not zeroed?\");\n@@ -586,1 +587,1 @@\n-  if (methods != NULL && methods != Universe::the_empty_method_array() &&\n+  if (methods != nullptr && methods != Universe::the_empty_method_array() &&\n@@ -590,1 +591,1 @@\n-      if (method == NULL) continue;  \/\/ maybe null if error processing\n+      if (method == nullptr) continue;  \/\/ maybe null if error processing\n@@ -609,1 +610,1 @@\n-    Array<InstanceKlass*>* sti = (super_klass == NULL) ? NULL :\n+    Array<InstanceKlass*>* sti = (super_klass == nullptr) ? nullptr :\n@@ -611,1 +612,1 @@\n-    if (ti != sti && ti != NULL && !ti->is_shared()) {\n+    if (ti != sti && ti != nullptr && !ti->is_shared()) {\n@@ -618,1 +619,1 @@\n-      local_interfaces != NULL && !local_interfaces->is_shared()) {\n+      local_interfaces != nullptr && !local_interfaces->is_shared()) {\n@@ -625,1 +626,1 @@\n-  if (record_components != NULL && !record_components->is_shared()) {\n+  if (record_components != nullptr && !record_components->is_shared()) {\n@@ -638,2 +639,2 @@\n-  if (java_mirror() != NULL) {\n-    java_lang_Class::set_klass(java_mirror(), NULL);\n+  if (java_mirror() != nullptr) {\n+    java_lang_Class::set_klass(java_mirror(), nullptr);\n@@ -652,1 +653,1 @@\n-  assert(array_klasses() == NULL, \"array classes shouldn't be created for this class yet\");\n+  assert(array_klasses() == nullptr, \"array classes shouldn't be created for this class yet\");\n@@ -656,4 +657,4 @@\n-  \/\/ Can't release the constant pool here because the constant pool can be\n-  \/\/ deallocated separately from the InstanceKlass for default methods and\n-  \/\/ redefine classes.\n-  release_C_heap_structures(\/* release_constant_pool *\/ false);\n+  \/\/ Can't release the constant pool or MethodData C heap data here because the constant\n+  \/\/ pool can be deallocated separately from the InstanceKlass for default methods and\n+  \/\/ redefine classes.  MethodData can also be released separately.\n+  release_C_heap_structures(\/* release_sub_metadata *\/ false);\n@@ -662,1 +663,1 @@\n-  set_methods(NULL);\n+  set_methods(nullptr);\n@@ -665,1 +666,1 @@\n-  set_record_components(NULL);\n+  set_record_components(nullptr);\n@@ -667,1 +668,1 @@\n-  if (method_ordering() != NULL &&\n+  if (method_ordering() != nullptr &&\n@@ -672,1 +673,1 @@\n-  set_method_ordering(NULL);\n+  set_method_ordering(nullptr);\n@@ -675,1 +676,1 @@\n-  if (default_methods() != NULL &&\n+  if (default_methods() != nullptr &&\n@@ -681,1 +682,1 @@\n-  set_default_methods(NULL);\n+  set_default_methods(nullptr);\n@@ -684,1 +685,1 @@\n-  if (default_vtable_indices() != NULL &&\n+  if (default_vtable_indices() != nullptr &&\n@@ -688,1 +689,1 @@\n-  set_default_vtable_indices(NULL);\n+  set_default_vtable_indices(nullptr);\n@@ -694,1 +695,1 @@\n-  if (secondary_supers() != NULL &&\n+  if (secondary_supers() != nullptr &&\n@@ -701,1 +702,1 @@\n-  set_secondary_supers(NULL);\n+  set_secondary_supers(nullptr);\n@@ -704,2 +705,7 @@\n-  set_transitive_interfaces(NULL);\n-  set_local_interfaces(NULL);\n+  set_transitive_interfaces(nullptr);\n+  set_local_interfaces(nullptr);\n+\n+  if (fieldinfo_stream() != nullptr && !fieldinfo_stream()->is_shared()) {\n+    MetadataFactory::free_array<u1>(loader_data, fieldinfo_stream());\n+  }\n+  set_fieldinfo_stream(nullptr);\n@@ -707,2 +713,2 @@\n-  if (fields() != NULL && !fields()->is_shared()) {\n-    MetadataFactory::free_array<jushort>(loader_data, fields());\n+  if (fields_status() != nullptr && !fields_status()->is_shared()) {\n+    MetadataFactory::free_array<FieldStatus>(loader_data, fields_status());\n@@ -710,1 +716,1 @@\n-  set_fields(NULL, 0);\n+  set_fields_status(nullptr);\n@@ -714,1 +720,1 @@\n-  if (constants() != NULL) {\n+  if (constants() != nullptr) {\n@@ -722,1 +728,1 @@\n-    set_constants(NULL);\n+    set_constants(nullptr);\n@@ -725,1 +731,1 @@\n-  if (inner_classes() != NULL &&\n+  if (inner_classes() != nullptr &&\n@@ -730,1 +736,1 @@\n-  set_inner_classes(NULL);\n+  set_inner_classes(nullptr);\n@@ -732,1 +738,1 @@\n-  if (nest_members() != NULL &&\n+  if (nest_members() != nullptr &&\n@@ -737,1 +743,1 @@\n-  set_nest_members(NULL);\n+  set_nest_members(nullptr);\n@@ -739,1 +745,1 @@\n-  if (permitted_subclasses() != NULL &&\n+  if (permitted_subclasses() != nullptr &&\n@@ -744,1 +750,1 @@\n-  set_permitted_subclasses(NULL);\n+  set_permitted_subclasses(nullptr);\n@@ -746,1 +752,1 @@\n-  if (preload_classes() != NULL &&\n+  if (preload_classes() != nullptr &&\n@@ -753,1 +759,1 @@\n-  if (annotations() != NULL && !annotations()->is_shared()) {\n+  if (annotations() != nullptr && !annotations()->is_shared()) {\n@@ -756,1 +762,1 @@\n-  set_annotations(NULL);\n+  set_annotations(nullptr);\n@@ -763,0 +769,6 @@\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+  if (DumpSharedSpaces) {\n+    HeapShared::remove_scratch_objects(this);\n+  }\n+#endif\n@@ -766,1 +778,1 @@\n-  return _record_components != NULL &&\n+  return _record_components != nullptr &&\n@@ -772,1 +784,1 @@\n-  return _permitted_subclasses != NULL &&\n+  return _permitted_subclasses != nullptr &&\n@@ -881,1 +893,1 @@\n-  if (super_klass != NULL) {\n+  if (super_klass != nullptr) {\n@@ -947,1 +959,1 @@\n-              if (klass == NULL) {\n+              if (klass == nullptr) {\n@@ -963,1 +975,1 @@\n-    if (preload_classes() != NULL) {\n+    if (preload_classes() != nullptr) {\n@@ -975,1 +987,1 @@\n-        if (klass != NULL) {\n+        if (klass != nullptr) {\n@@ -1123,3 +1135,4 @@\n-  Handle cause = java_lang_Throwable::get_cause_with_stack_trace(exception, THREAD);\n-  if (HAS_PENDING_EXCEPTION || cause.is_null()) {\n-    CLEAR_PENDING_EXCEPTION;\n+  Handle init_error = java_lang_Throwable::create_initialization_error(current, exception);\n+  ResourceMark rm(THREAD);\n+  if (init_error.is_null()) {\n+    log_trace(class, init)(\"Initialization error is null for class %s\", external_name());\n@@ -1130,2 +1143,2 @@\n-  OopHandle elem = OopHandle(Universe::vm_global(), cause());\n-  bool created = false;\n+  OopHandle elem = OopHandle(Universe::vm_global(), init_error());\n+  bool created;\n@@ -1134,1 +1147,0 @@\n-  ResourceMark rm(THREAD);\n@@ -1186,1 +1198,1 @@\n-      jt->set_class_to_be_initialized(NULL);\n+      jt->set_class_to_be_initialized(nullptr);\n@@ -1252,1 +1264,1 @@\n-    if (super_klass != NULL && super_klass->should_be_initialized()) {\n+    if (super_klass != nullptr && super_klass->should_be_initialized()) {\n@@ -1285,1 +1297,1 @@\n-        if (fs.access_flags().is_static() && klass == NULL) {\n+        if (fs.access_flags().is_static() && klass == nullptr) {\n@@ -1294,1 +1306,1 @@\n-          assert(klass != NULL, \"Must  be\");\n+          assert(klass != nullptr, \"Must  be\");\n@@ -1297,1 +1309,1 @@\n-            if (java_mirror()->obj_field(fs.offset()) == NULL) {\n+            if (java_mirror()->obj_field(fs.offset()) == nullptr) {\n@@ -1323,1 +1335,1 @@\n-    if (class_initializer() != NULL) {\n+    if (class_initializer() != nullptr) {\n@@ -1380,3 +1392,5 @@\n-  \/\/ Now flush all code that assume the class is not linked.\n-  \/\/ Set state under the Compile_lock also.\n-    MutexLocker ml(current, Compile_lock);\n+    DeoptimizationScope deopt_scope;\n+    {\n+      \/\/ Now mark all code that assumes the class is not linked.\n+      \/\/ Set state under the Compile_lock also.\n+      MutexLocker ml(current, Compile_lock);\n@@ -1385,2 +1399,2 @@\n-    set_init_thread(NULL); \/\/ reset _init_thread before changing _init_state\n-    set_init_state(state);\n+      set_init_thread(nullptr); \/\/ reset _init_thread before changing _init_state\n+      set_init_state(state);\n@@ -1388,1 +1402,4 @@\n-    CodeCache::flush_dependents_on(this);\n+      CodeCache::mark_dependents_on(&deopt_scope, this);\n+    }\n+    \/\/ Perform the deopt handshake outside Compile_lock.\n+    deopt_scope.deoptimize_marked();\n@@ -1390,1 +1407,1 @@\n-    set_init_thread(NULL); \/\/ reset _init_thread before changing _init_state\n+    set_init_thread(nullptr); \/\/ reset _init_thread before changing _init_state\n@@ -1396,0 +1413,40 @@\n+\/\/ Update hierarchy. This is done before the new klass has been added to the SystemDictionary. The Compile_lock\n+\/\/ is grabbed, to ensure that the compiler is not using the class hierarchy.\n+void InstanceKlass::add_to_hierarchy(JavaThread* current) {\n+  assert(!SafepointSynchronize::is_at_safepoint(), \"must NOT be at safepoint\");\n+\n+  \/\/ In case we are not using CHA based vtables we need to make sure the loaded\n+  \/\/ deopt is completed before anyone links this class.\n+  \/\/ Linking is done with _init_monitor held, by loading and deopting with it\n+  \/\/ held we make sure the deopt is completed before linking.\n+  if (!UseVtableBasedCHA) {\n+    init_monitor()->lock();\n+  }\n+\n+  DeoptimizationScope deopt_scope;\n+  {\n+    MutexLocker ml(current, Compile_lock);\n+\n+    set_init_state(InstanceKlass::loaded);\n+    \/\/ make sure init_state store is already done.\n+    \/\/ The compiler reads the hierarchy outside of the Compile_lock.\n+    \/\/ Access ordering is used to add to hierarchy.\n+\n+    \/\/ Link into hierarchy.\n+    append_to_sibling_list();                    \/\/ add to superklass\/sibling list\n+    process_interfaces();                        \/\/ handle all \"implements\" declarations\n+\n+    \/\/ Now mark all code that depended on old class hierarchy.\n+    \/\/ Note: must be done *after* linking k into the hierarchy (was bug 12\/9\/97)\n+    if (Universe::is_fully_initialized()) {\n+      CodeCache::mark_dependents_on(&deopt_scope, this);\n+    }\n+  }\n+  \/\/ Perform the deopt handshake outside Compile_lock.\n+  deopt_scope.deoptimize_marked();\n+\n+  if (!UseVtableBasedCHA) {\n+    init_monitor()->unlock();\n+  }\n+}\n+\n@@ -1398,2 +1455,2 @@\n-  if (ik == NULL) {\n-    return NULL;\n+  if (ik == nullptr) {\n+    return nullptr;\n@@ -1403,2 +1460,2 @@\n-    if (ikls != NULL && !ikls->is_loader_alive()) {\n-      return NULL;  \/\/ don't return unloaded class\n+    if (ikls != nullptr && !ikls->is_loader_alive()) {\n+      return nullptr;  \/\/ don't return unloaded class\n@@ -1416,2 +1473,2 @@\n-  assert(addr != NULL, \"null addr\");\n-  if (addr != NULL) {\n+  assert(addr != nullptr, \"null addr\");\n+  if (addr != nullptr) {\n@@ -1424,1 +1481,1 @@\n-  if (ik == NULL) {\n+  if (ik == nullptr) {\n@@ -1437,1 +1494,1 @@\n-\/\/   NULL                  - no implementor\n+\/\/   null                  - no implementor\n@@ -1455,1 +1512,1 @@\n-  if (super_ik != NULL && super_ik->implements_interface(this))\n+  if (super_ik != nullptr && super_ik->implements_interface(this))\n@@ -1462,1 +1519,1 @@\n-  if (iklass == NULL) {\n+  if (iklass == nullptr) {\n@@ -1478,1 +1535,1 @@\n-    set_implementor(NULL);\n+    set_implementor(nullptr);\n@@ -1508,1 +1565,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1516,1 +1573,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1589,0 +1646,12 @@\n+instanceOop InstanceKlass::allocate_instance(oop java_class, TRAPS) {\n+  Klass* k = java_lang_Class::as_Klass(java_class);\n+  if (k == nullptr) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), nullptr);\n+  }\n+  InstanceKlass* ik = cast(k);\n+  ik->check_valid_for_instantiation(false, CHECK_NULL);\n+  ik->initialize(CHECK_NULL);\n+  return ik->allocate_instance(THREAD);\n+}\n+\n@@ -1608,1 +1677,1 @@\n-  if (array_klasses_acquire() == NULL) {\n+  if (array_klasses_acquire() == nullptr) {\n@@ -1616,1 +1685,1 @@\n-      if (array_klasses() == NULL) {\n+      if (array_klasses() == nullptr) {\n@@ -1632,2 +1701,2 @@\n-  if (ak == NULL) {\n-    return NULL;\n+  if (ak == nullptr) {\n+    return nullptr;\n@@ -1652,1 +1721,1 @@\n-  if (clinit != NULL && clinit->is_class_initializer()) {\n+  if (clinit != nullptr && clinit->is_class_initializer()) {\n@@ -1655,1 +1724,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1661,1 +1730,1 @@\n-       (ReplaySuppressInitializers >= 2 && class_loader() != NULL))) {\n+       (ReplaySuppressInitializers >= 2 && class_loader() != nullptr))) {\n@@ -1685,1 +1754,1 @@\n-    ls.print_cr(\"%s (\" PTR_FORMAT \")\", h_method() == NULL ? \"(no method)\" : \"\", p2i(this));\n+    ls.print_cr(\"%s (\" PTR_FORMAT \")\", h_method() == nullptr ? \"(no method)\" : \"\", p2i(this));\n@@ -1687,1 +1756,1 @@\n-  if (h_method() != NULL) {\n+  if (h_method() != nullptr) {\n@@ -1700,1 +1769,1 @@\n-  if (oop_map_cache == NULL) {\n+  if (oop_map_cache == nullptr) {\n@@ -1703,1 +1772,1 @@\n-    if ((oop_map_cache = _oop_map_cache) == NULL) {\n+    if ((oop_map_cache = _oop_map_cache) == nullptr) {\n@@ -1713,0 +1782,11 @@\n+\n+FieldInfo InstanceKlass::field(int index) const {\n+  for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+    if (fs.index() == index) {\n+      return fs.to_FieldInfo();\n+    }\n+  }\n+  fatal(\"Field not found\");\n+  return FieldInfo();\n+}\n+\n@@ -1738,1 +1818,1 @@\n-    if (intf2 != NULL) return intf2;\n+    if (intf2 != nullptr) return intf2;\n@@ -1741,1 +1821,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1753,1 +1833,1 @@\n-    if (intf != NULL) return intf;\n+    if (intf != nullptr) return intf;\n@@ -1757,1 +1837,1 @@\n-    if (supr != NULL) return InstanceKlass::cast(supr)->find_field(name, sig, fd);\n+    if (supr != nullptr) return InstanceKlass::cast(supr)->find_field(name, sig, fd);\n@@ -1760,1 +1840,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1773,1 +1853,1 @@\n-    if (intf != NULL) return intf;\n+    if (intf != nullptr) return intf;\n@@ -1777,1 +1857,1 @@\n-    if (supr != NULL) return InstanceKlass::cast(supr)->find_field(name, sig, is_static, fd);\n+    if (supr != nullptr) return InstanceKlass::cast(supr)->find_field(name, sig, is_static, fd);\n@@ -1780,1 +1860,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1806,1 +1886,1 @@\n-  while (klass != NULL) {\n+  while (klass != nullptr) {\n@@ -1854,1 +1934,1 @@\n-  if (super != NULL) {\n+  if (super != nullptr) {\n@@ -1874,1 +1954,1 @@\n-  if (super != NULL) {\n+  if (super != nullptr) {\n@@ -2000,1 +2080,1 @@\n-  assert(((meth == NULL) || !meth->is_static()),\n+  assert(((meth == nullptr) || !meth->is_static()),\n@@ -2068,1 +2148,1 @@\n-  return hit >= 0 ? methods->at(hit): NULL;\n+  return hit >= 0 ? methods->at(hit): nullptr;\n@@ -2154,1 +2234,1 @@\n-  assert(end_ptr != NULL, \"just checking\");\n+  assert(end_ptr != nullptr, \"just checking\");\n@@ -2175,1 +2255,1 @@\n-  while (klass != NULL) {\n+  while (klass != nullptr) {\n@@ -2181,1 +2261,1 @@\n-    if (method != NULL) {\n+    if (method != nullptr) {\n@@ -2191,1 +2271,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2199,1 +2279,1 @@\n-  while (klass != NULL) {\n+  while (klass != nullptr) {\n@@ -2213,2 +2293,2 @@\n-  Method* m = NULL;\n-  if (default_methods() != NULL) {\n+  Method* m = nullptr;\n+  if (default_methods() != nullptr) {\n@@ -2218,1 +2298,1 @@\n-  if (m == NULL) {\n+  if (m == nullptr) {\n@@ -2232,1 +2312,1 @@\n-  InstanceKlass *ik = NULL;\n+  InstanceKlass *ik = nullptr;\n@@ -2236,1 +2316,1 @@\n-    if (m != NULL && m->is_public() && !m->is_static() &&\n+    if (m != nullptr && m->is_public() && !m->is_static() &&\n@@ -2241,1 +2321,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2271,1 +2351,0 @@\n-  if (k->has_final_method()) buf[i++] = 'f';\n@@ -2274,0 +2353,1 @@\n+    if (ik->has_final_method()) buf[i++] = 'f';\n@@ -2293,2 +2373,2 @@\n-  JNIid* probe = jni_ids() == NULL ? NULL : jni_ids()->find(offset);\n-  if (probe == NULL) {\n+  JNIid* probe = jni_ids() == nullptr ? nullptr : jni_ids()->find(offset);\n+  if (probe == nullptr) {\n@@ -2304,1 +2384,1 @@\n-  if (inner_class_list == NULL) {\n+  if (inner_class_list == nullptr) {\n@@ -2319,1 +2399,1 @@\n-  assert (inner_class_list != NULL, \"_inner_classes list is not set up\");\n+  assert (inner_class_list != nullptr, \"_inner_classes list is not set up\");\n@@ -2339,1 +2419,1 @@\n-  jmethodID id = NULL;\n+  jmethodID id = nullptr;\n@@ -2343,1 +2423,1 @@\n-  \/\/ transitions from NULL to non-NULL which is safe because we use\n+  \/\/ transitions from null to non-null which is safe because we use\n@@ -2354,1 +2434,1 @@\n-  \/\/ grow and we'll have transitions from non-NULL to bigger non-NULL.\n+  \/\/ grow and we'll have transitions from non-null to bigger non-null.\n@@ -2359,1 +2439,1 @@\n-  if (jmeths != NULL) {\n+  if (jmeths != nullptr) {\n@@ -2365,9 +2445,2 @@\n-      \/\/ cache can grow so we have to be more careful\n-      if (Threads::number_of_threads() == 0 ||\n-          SafepointSynchronize::is_at_safepoint()) {\n-        \/\/ we're single threaded or at a safepoint - no locking needed\n-        get_jmethod_id_length_value(jmeths, idnum, &length, &id);\n-      } else {\n-        MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n-        get_jmethod_id_length_value(jmeths, idnum, &length, &id);\n-      }\n+      MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n+      get_jmethod_id_length_value(jmeths, idnum, &length, &id);\n@@ -2379,3 +2452,3 @@\n-  if (jmeths == NULL ||   \/\/ no cache yet\n-      length <= idnum ||  \/\/ cache is too short\n-      id == NULL) {       \/\/ cache doesn't contain entry\n+  if (jmeths == nullptr ||   \/\/ no cache yet\n+      length <= idnum ||     \/\/ cache is too short\n+      id == nullptr) {       \/\/ cache doesn't contain entry\n@@ -2383,2 +2456,2 @@\n-    \/\/ This function can be called by the VMThread so we have to do all\n-    \/\/ things that might block on a safepoint before grabbing the lock.\n+    \/\/ This function can be called by the VMThread or GC worker threads so we\n+    \/\/ have to do all things that might block on a safepoint before grabbing the lock.\n@@ -2388,2 +2461,2 @@\n-    jmethodID  to_dealloc_id     = NULL;\n-    jmethodID* to_dealloc_jmeths = NULL;\n+    jmethodID  to_dealloc_id     = nullptr;\n+    jmethodID* to_dealloc_jmeths = nullptr;\n@@ -2392,1 +2465,1 @@\n-    jmethodID* new_jmeths = NULL;\n+    jmethodID* new_jmeths = nullptr;\n@@ -2403,18 +2476,1 @@\n-    jmethodID new_id = NULL;\n-    if (method_h->is_old() && !method_h->is_obsolete()) {\n-      \/\/ The method passed in is old (but not obsolete), we need to use the current version\n-      Method* current_method = method_with_idnum((int)idnum);\n-      assert(current_method != NULL, \"old and but not obsolete, so should exist\");\n-      new_id = Method::make_jmethod_id(class_loader_data(), current_method);\n-    } else {\n-      \/\/ It is the current version of the method or an obsolete method,\n-      \/\/ use the version passed in\n-      new_id = Method::make_jmethod_id(class_loader_data(), method_h());\n-    }\n-\n-    if (Threads::number_of_threads() == 0 ||\n-        SafepointSynchronize::is_at_safepoint()) {\n-      \/\/ we're single threaded or at a safepoint - no locking needed\n-      id = get_jmethod_id_fetch_or_update(idnum, new_id, new_jmeths,\n-                                          &to_dealloc_id, &to_dealloc_jmeths);\n-    } else {\n+    {\n@@ -2422,0 +2478,12 @@\n+      jmethodID new_id = nullptr;\n+      if (method_h->is_old() && !method_h->is_obsolete()) {\n+        \/\/ The method passed in is old (but not obsolete), we need to use the current version\n+        Method* current_method = method_with_idnum((int)idnum);\n+        assert(current_method != nullptr, \"old and but not obsolete, so should exist\");\n+        new_id = Method::make_jmethod_id(class_loader_data(), current_method);\n+      } else {\n+        \/\/ It is the current version of the method or an obsolete method,\n+        \/\/ use the version passed in\n+        new_id = Method::make_jmethod_id(class_loader_data(), method_h());\n+      }\n+\n@@ -2428,1 +2496,1 @@\n-    if (to_dealloc_jmeths != NULL) {\n+    if (to_dealloc_jmeths != nullptr) {\n@@ -2432,1 +2500,1 @@\n-    if (to_dealloc_id != NULL) {\n+    if (to_dealloc_id != nullptr) {\n@@ -2450,1 +2518,1 @@\n-    if (id == NULL) {\n+    if (id == nullptr) {\n@@ -2468,6 +2536,4 @@\n-  assert(new_id != NULL, \"sanity check\");\n-  assert(to_dealloc_id_p != NULL, \"sanity check\");\n-  assert(to_dealloc_jmeths_p != NULL, \"sanity check\");\n-  assert(Threads::number_of_threads() == 0 ||\n-         SafepointSynchronize::is_at_safepoint() ||\n-         JmethodIdCreation_lock->owned_by_self(), \"sanity check\");\n+  assert(new_id != nullptr, \"sanity check\");\n+  assert(to_dealloc_id_p != nullptr, \"sanity check\");\n+  assert(to_dealloc_jmeths_p != nullptr, \"sanity check\");\n+  assert(JmethodIdCreation_lock->owned_by_self(), \"sanity check\");\n@@ -2477,1 +2543,1 @@\n-  jmethodID  id     = NULL;\n+  jmethodID  id     = nullptr;\n@@ -2480,1 +2546,1 @@\n-  if (jmeths == NULL ||                         \/\/ no cache yet\n+  if (jmeths == nullptr ||                      \/\/ no cache yet\n@@ -2482,1 +2548,1 @@\n-    if (jmeths != NULL) {\n+    if (jmeths != nullptr) {\n@@ -2495,1 +2561,1 @@\n-  if (id == NULL) {\n+  if (id == nullptr) {\n@@ -2518,3 +2584,3 @@\n-  assert(cache != NULL, \"sanity check\");\n-  assert(length_p != NULL, \"sanity check\");\n-  assert(id_p != NULL, \"sanity check\");\n+  assert(cache != nullptr, \"sanity check\");\n+  assert(length_p != nullptr, \"sanity check\");\n+  assert(id_p != nullptr, \"sanity check\");\n@@ -2525,1 +2591,1 @@\n-    *id_p = NULL;\n+    *id_p = nullptr;\n@@ -2532,1 +2598,1 @@\n-\/\/ Lookup a jmethodID, NULL if not found.  Do no blocking, no allocations, no handles\n+\/\/ Lookup a jmethodID, null if not found.  Do no blocking, no allocations, no handles\n@@ -2537,2 +2603,2 @@\n-  jmethodID id = NULL;\n-  if (jmeths != NULL &&                         \/\/ If there is a cache\n+  jmethodID id = nullptr;\n+  if (jmeths != nullptr &&                      \/\/ If there is a cache\n@@ -2540,1 +2606,1 @@\n-    id = jmeths[idnum+1];                       \/\/ Look up the id (may be NULL)\n+    id = jmeths[idnum+1];                       \/\/ Look up the id (may be null)\n@@ -2550,2 +2616,2 @@\n-int InstanceKlass::mark_dependent_nmethods(KlassDepChange& changes) {\n-  return dependencies().mark_dependent_nmethods(changes);\n+void InstanceKlass::mark_dependent_nmethods(DeoptimizationScope* deopt_scope, KlassDepChange& changes) {\n+  dependencies().mark_dependent_nmethods(deopt_scope, changes);\n@@ -2584,2 +2650,2 @@\n-      if (impl != NULL && !impl->is_loader_alive()) {\n-        \/\/ NULL this field, might be an unloaded instance klass or NULL\n+      if (impl != nullptr && !impl->is_loader_alive()) {\n+        \/\/ null this field, might be an unloaded instance klass or null\n@@ -2587,1 +2653,1 @@\n-        if (Atomic::cmpxchg(iklass, impl, (InstanceKlass*)NULL) == impl) {\n+        if (Atomic::cmpxchg(iklass, impl, (InstanceKlass*)nullptr) == impl) {\n@@ -2605,2 +2671,2 @@\n-    if (mdo != NULL) {\n-      MutexLocker ml(SafepointSynchronize::is_at_safepoint() ? NULL : mdo->extra_data_lock());\n+    if (mdo != nullptr) {\n+      MutexLocker ml(SafepointSynchronize::is_at_safepoint() ? nullptr : mdo->extra_data_lock());\n@@ -2631,1 +2697,15 @@\n-  it->push(&_methods);\n+#if INCLUDE_CDS\n+  \/\/ For \"old\" classes with methods containing the jsr bytecode, the _methods array will\n+  \/\/ be rewritten during runtime (see Rewriter::rewrite_jsrs()). So setting the _methods to\n+  \/\/ be writable. The length check on the _methods is necessary because classes which\n+  \/\/ don't have any methods share the Universe::_the_empty_method_array which is in the RO region.\n+  if (_methods != nullptr && _methods->length() > 0 &&\n+      !can_be_verified_at_dumptime() && methods_contain_jsr_bytecode()) {\n+    \/\/ To handle jsr bytecode, new Method* maybe stored into _methods\n+    it->push(&_methods, MetaspaceClosure::_writable);\n+  } else {\n+#endif\n+    it->push(&_methods);\n+#if INCLUDE_CDS\n+  }\n+#endif\n@@ -2642,2 +2722,3 @@\n-  \/\/ _fields might be written into by Rewriter::scan_method() -> fd.set_has_initialized_final_update()\n-  it->push(&_fields, MetaspaceClosure::_writable);\n+  it->push(&_fieldinfo_stream);\n+  \/\/ _fields_status might be written into by Rewriter::scan_method() -> fd.set_has_initialized_final_update()\n+  it->push(&_fields_status, MetaspaceClosure::_writable);\n@@ -2652,1 +2733,1 @@\n-      if (ioe->interface_klass() != NULL) {\n+      if (ioe->interface_klass() != nullptr) {\n@@ -2699,1 +2780,1 @@\n-  \/\/ being added to class hierarchy (see SystemDictionary:::add_to_hierarchy()).\n+  \/\/ being added to class hierarchy (see InstanceKlass:::add_to_hierarchy()).\n@@ -2715,1 +2796,1 @@\n-  if (array_klasses() != NULL) {\n+  if (array_klasses() != nullptr) {\n@@ -2727,4 +2808,4 @@\n-  \/\/ These are not allocated from metaspace. They are safe to set to NULL.\n-  _source_debug_extension = NULL;\n-  _dep_context = NULL;\n-  _osr_nmethods_head = NULL;\n+  \/\/ These are not allocated from metaspace. They are safe to set to nullptr.\n+  _source_debug_extension = nullptr;\n+  _dep_context = nullptr;\n+  _osr_nmethods_head = nullptr;\n@@ -2732,4 +2813,4 @@\n-  _breakpoints = NULL;\n-  _previous_versions = NULL;\n-  _cached_class_file = NULL;\n-  _jvmti_cached_class_field_map = NULL;\n+  _breakpoints = nullptr;\n+  _previous_versions = nullptr;\n+  _cached_class_file = nullptr;\n+  _jvmti_cached_class_field_map = nullptr;\n@@ -2738,4 +2819,4 @@\n-  _init_thread = NULL;\n-  _methods_jmethod_ids = NULL;\n-  _jni_ids = NULL;\n-  _oop_map_cache = NULL;\n+  _init_thread = nullptr;\n+  _methods_jmethod_ids = nullptr;\n+  _jni_ids = nullptr;\n+  _oop_map_cache = nullptr;\n@@ -2743,1 +2824,1 @@\n-  _nest_host = NULL;\n+  _nest_host = nullptr;\n@@ -2746,1 +2827,13 @@\n-  _init_monitor = NULL;\n+  _init_monitor = nullptr;\n+\n+  remove_unshareable_flags();\n+}\n+\n+void InstanceKlass::remove_unshareable_flags() {\n+  \/\/ clear all the flags\/stats that shouldn't be in the archived version\n+  assert(!is_scratch_class(), \"must be\");\n+  assert(!has_been_redefined(), \"must be\");\n+#if INCLUDE_JVMTI\n+  set_is_being_redefined(false);\n+#endif\n+  set_has_resolved_methods(false);\n@@ -2753,1 +2846,1 @@\n-  if (array_klasses() != NULL) {\n+  if (array_klasses() != nullptr) {\n@@ -2760,1 +2853,1 @@\n-  _package_entry = NULL;\n+  _package_entry = nullptr;\n@@ -2763,1 +2856,1 @@\n-    _package_entry = NULL;\n+    _package_entry = nullptr;\n@@ -2766,1 +2859,1 @@\n-      _package_entry = NULL;\n+      _package_entry = nullptr;\n@@ -2770,1 +2863,1 @@\n-      _package_entry = NULL;\n+      _package_entry = nullptr;\n@@ -2779,0 +2872,10 @@\n+void InstanceKlass::compute_has_loops_flag_for_methods() {\n+  Array<Method*>* methods = this->methods();\n+  for (int index = 0; index < methods->length(); ++index) {\n+    Method* m = methods->at(index);\n+    if (!m->is_overpass()) { \/\/ work around JDK-8305771\n+      m->compute_has_loops_flag();\n+    }\n+  }\n+}\n+\n@@ -2781,1 +2884,1 @@\n-  \/\/ SystemDictionary::add_to_hierarchy() sets the init_state to loaded\n+  \/\/ InstanceKlass::add_to_hierarchy() sets the init_state to loaded\n@@ -2817,1 +2920,1 @@\n-  if (array_klasses() != NULL) {\n+  if (array_klasses() != nullptr) {\n@@ -2849,1 +2952,1 @@\n-  if (java_super() != NULL && !java_super()->can_be_verified_at_dumptime()) {\n+  if (java_super() != nullptr && !java_super()->can_be_verified_at_dumptime()) {\n@@ -2861,0 +2964,15 @@\n+\n+bool InstanceKlass::methods_contain_jsr_bytecode() const {\n+  Thread* thread = Thread::current();\n+  for (int i = 0; i < _methods->length(); i++) {\n+    methodHandle m(thread, _methods->at(i));\n+    BytecodeStream bcs(m);\n+    while (!bcs.is_last_bytecode()) {\n+      Bytecodes::Code opcode = bcs.next();\n+      if (opcode == Bytecodes::_jsr || opcode == Bytecodes::_jsr_w) {\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n@@ -2891,1 +3009,1 @@\n-  assert(ik != NULL, \"invariant\");\n+  assert(ik != nullptr, \"invariant\");\n@@ -2903,2 +3021,2 @@\n-\/\/ Called also by InstanceKlass::deallocate_contents, with false for release_constant_pool.\n-void InstanceKlass::release_C_heap_structures(bool release_constant_pool) {\n+\/\/ Called also by InstanceKlass::deallocate_contents, with false for release_sub_metadata.\n+void InstanceKlass::release_C_heap_structures(bool release_sub_metadata) {\n@@ -2909,1 +3027,3 @@\n-  methods_do(method_release_C_heap_structures);\n+  if (release_sub_metadata) {\n+    methods_do(method_release_C_heap_structures);\n+  }\n@@ -2915,1 +3035,1 @@\n-  if (_oop_map_cache != NULL) {\n+  if (_oop_map_cache != nullptr) {\n@@ -2917,1 +3037,1 @@\n-    _oop_map_cache = NULL;\n+    _oop_map_cache = nullptr;\n@@ -2922,1 +3042,1 @@\n-  set_jni_ids(NULL);\n+  set_jni_ids(nullptr);\n@@ -2925,2 +3045,2 @@\n-  if (jmeths != (jmethodID*)NULL) {\n-    release_set_methods_jmethod_ids(NULL);\n+  if (jmeths != (jmethodID*)nullptr) {\n+    release_set_methods_jmethod_ids(nullptr);\n@@ -2930,1 +3050,1 @@\n-  assert(_dep_context == NULL,\n+  assert(_dep_context == nullptr,\n@@ -2941,1 +3061,1 @@\n-  if (_cached_class_file != NULL) {\n+  if (_cached_class_file != nullptr) {\n@@ -2943,1 +3063,1 @@\n-    _cached_class_file = NULL;\n+    _cached_class_file = nullptr;\n@@ -2949,1 +3069,1 @@\n-  if (release_constant_pool) {\n+  if (release_sub_metadata) {\n@@ -2955,2 +3075,2 @@\n-  if (array == NULL) {\n-    _source_debug_extension = NULL;\n+  if (array == nullptr) {\n+    _source_debug_extension = nullptr;\n@@ -3001,1 +3121,1 @@\n-  \/\/ Add the semicolon and the NULL\n+  \/\/ Add the semicolon and the null\n@@ -3044,1 +3164,1 @@\n-  if (is_shared() && _package_entry != NULL) {\n+  if (is_shared() && _package_entry != nullptr) {\n@@ -3050,1 +3170,1 @@\n-      _package_entry = NULL;\n+      _package_entry = nullptr;\n@@ -3057,1 +3177,1 @@\n-      (pkg_entry != NULL) ? NULL : ClassLoader::package_from_class_name(name());\n+      (pkg_entry != nullptr) ? nullptr : ClassLoader::package_from_class_name(name());\n@@ -3060,1 +3180,1 @@\n-  if (pkg_entry != NULL) {\n+  if (pkg_entry != nullptr) {\n@@ -3066,1 +3186,1 @@\n-  if (pkg_name != NULL && loader_data != NULL) {\n+  if (pkg_name != nullptr && loader_data != nullptr) {\n@@ -3069,1 +3189,1 @@\n-    _package_entry = pkg_entry != NULL ? pkg_entry : loader_data->packages()->lookup_only(pkg_name);\n+    _package_entry = pkg_entry != nullptr ? pkg_entry : loader_data->packages()->lookup_only(pkg_name);\n@@ -3074,1 +3194,1 @@\n-    if (_package_entry == NULL) {\n+    if (_package_entry == nullptr) {\n@@ -3081,1 +3201,1 @@\n-        assert(ModuleEntryTable::javabase_moduleEntry() != NULL, JAVA_BASE_NAME \" module is NULL\");\n+        assert(ModuleEntryTable::javabase_moduleEntry() != nullptr, JAVA_BASE_NAME \" module is null\");\n@@ -3084,1 +3204,1 @@\n-        assert(loader_data->unnamed_module() != NULL, \"unnamed module is NULL\");\n+        assert(loader_data->unnamed_module() != nullptr, \"unnamed module is null\");\n@@ -3090,1 +3210,1 @@\n-      assert(_package_entry != NULL, \"Package entry for class %s not found, loader %s\",\n+      assert(_package_entry != nullptr, \"Package entry for class %s not found, loader %s\",\n@@ -3107,1 +3227,1 @@\n-                      (loader_data != NULL) ? loader_data->loader_name_and_id() : \"NULL\",\n+                      (loader_data != nullptr) ? loader_data->loader_name_and_id() : \"null\",\n@@ -3122,1 +3242,1 @@\n-  if (_package_entry != NULL) {\n+  if (_package_entry != nullptr) {\n@@ -3146,2 +3266,2 @@\n-    classloader2 = NULL;\n-    classpkg2 = NULL;\n+    classloader2 = nullptr;\n+    classpkg2 = nullptr;\n@@ -3180,2 +3300,2 @@\n-    \/\/ Check that package_from_class_name() returns NULL, not \"\", if there is no package.\n-    assert(other_pkg == NULL || other_pkg->utf8_length() > 0, \"package name is empty string\");\n+    \/\/ Check that package_from_class_name() returns null, not \"\", if there is no package.\n+    assert(other_pkg == nullptr || other_pkg->utf8_length() > 0, \"package name is empty string\");\n@@ -3184,1 +3304,1 @@\n-      this->package() != NULL ? this->package()->name() : NULL;\n+      this->package() != nullptr ? this->package()->name() : nullptr;\n@@ -3186,1 +3306,1 @@\n-    if (this_package_name == NULL || other_pkg == NULL) {\n+    if (this_package_name == nullptr || other_pkg == nullptr) {\n@@ -3215,1 +3335,1 @@\n-      class_name != NULL && class_name->utf8_length() >= 5) {\n+      class_name != nullptr && class_name->utf8_length() >= 5) {\n@@ -3227,1 +3347,1 @@\n-      assert(pkg_name != NULL, \"Error in parsing package name starting with 'java\/'\");\n+      assert(pkg_name != nullptr, \"Error in parsing package name starting with 'java\/'\");\n@@ -3263,1 +3383,1 @@\n-  InstanceKlass* outer_klass = NULL;\n+  InstanceKlass* outer_klass = nullptr;\n@@ -3281,1 +3401,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -3286,1 +3406,1 @@\n-    if (NULL == outer_klass) {\n+    if (nullptr == outer_klass) {\n@@ -3298,1 +3418,1 @@\n-  if (NULL == outer_klass) return NULL;\n+  if (nullptr == outer_klass) return nullptr;\n@@ -3351,1 +3471,1 @@\n-  if (m != NULL) {\n+  if (m != nullptr) {\n@@ -3386,1 +3506,1 @@\n-  return NULL; \/\/ offset entry not found\n+  return nullptr; \/\/ offset entry not found\n@@ -3399,1 +3519,1 @@\n-  if (!intf_method->is_abstract() && default_methods() != NULL) {\n+  if (!intf_method->is_abstract() && default_methods() != nullptr) {\n@@ -3424,1 +3544,1 @@\n-  if (default_methods() != NULL) {\n+  if (default_methods() != nullptr) {\n@@ -3427,1 +3547,1 @@\n-      if (old_method == NULL || !old_method->is_old()) {\n+      if (old_method == nullptr || !old_method->is_old()) {\n@@ -3456,1 +3576,1 @@\n-  assert(prev == NULL || !prev->is_in_use() COMPILER2_PRESENT(|| StressRecompilation),\n+  assert(prev == nullptr || !prev->is_in_use() COMPILER2_PRESENT(|| StressRecompilation),\n@@ -3469,1 +3589,1 @@\n-    if (inv != NULL && inv->is_in_use()) {\n+    if (inv != nullptr && inv->is_in_use()) {\n@@ -3478,1 +3598,1 @@\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock\n@@ -3481,1 +3601,1 @@\n-  nmethod* last = NULL;\n+  nmethod* last = nullptr;\n@@ -3487,1 +3607,1 @@\n-  while(cur != NULL && cur != n) {\n+  while(cur != nullptr && cur != n) {\n@@ -3495,1 +3615,1 @@\n-  nmethod* next = NULL;\n+  nmethod* next = nullptr;\n@@ -3499,1 +3619,1 @@\n-    if (last == NULL) {\n+    if (last == nullptr) {\n@@ -3506,1 +3626,1 @@\n-  n->set_osr_link(NULL);\n+  n->set_osr_link(nullptr);\n@@ -3508,1 +3628,1 @@\n-  while (cur != NULL) {\n+  while (cur != nullptr) {\n@@ -3519,2 +3639,2 @@\n-int InstanceKlass::mark_osr_nmethods(const Method* m) {\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock,\n+int InstanceKlass::mark_osr_nmethods(DeoptimizationScope* deopt_scope, const Method* m) {\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock,\n@@ -3524,1 +3644,1 @@\n-  while (osr != NULL) {\n+  while (osr != nullptr) {\n@@ -3527,1 +3647,1 @@\n-      osr->mark_for_deoptimization();\n+      deopt_scope->mark(osr);\n@@ -3536,1 +3656,1 @@\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock,\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock,\n@@ -3539,2 +3659,2 @@\n-  nmethod* best = NULL;\n-  while (osr != NULL) {\n+  nmethod* best = nullptr;\n+  while (osr != nullptr) {\n@@ -3556,1 +3676,1 @@\n-        if (best == NULL || (osr->comp_level() > best->comp_level())) {\n+        if (best == nullptr || (osr->comp_level() > best->comp_level())) {\n@@ -3568,2 +3688,2 @@\n-  assert(match_level == false || best == NULL, \"shouldn't pick up anything if match_level is set\");\n-  if (best != NULL && best->comp_level() >= comp_level) {\n+  assert(match_level == false || best == nullptr, \"shouldn't pick up anything if match_level is set\");\n+  if (best != nullptr && best->comp_level() >= comp_level) {\n@@ -3572,1 +3692,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -3599,1 +3719,1 @@\n-    } else if (self != NULL && e > 0 && e < 0x10000) {\n+    } else if (self != nullptr && e > 0 && e < 0x10000) {\n@@ -3611,1 +3731,1 @@\n-  return print_vtable(NULL, reinterpret_cast<intptr_t*>(start), len, st);\n+  return print_vtable(nullptr, reinterpret_cast<intptr_t*>(start), len, st);\n@@ -3616,1 +3736,1 @@\n-   if (array == NULL) { st->print_cr(\"NULL\"); return; }\n+   if (array == nullptr) { st->print_cr(\"nullptr\"); return; }\n@@ -3626,1 +3746,1 @@\n-  if (array == NULL) { st->print_cr(\"NULL\"); return; }\n+  if (array == nullptr) { st->print_cr(\"nullptr\"); return; }\n@@ -3636,1 +3756,1 @@\n-  return state_names[_init_state];\n+  return state_names[init_state()];\n@@ -3646,1 +3766,1 @@\n-  st->print(BULLET\"misc flags:        0x%x\", _misc_status.flags());               st->cr();\n+  st->print(BULLET\"flags:             \"); _misc_flags.print_on(st);               st->cr();\n@@ -3653,1 +3773,1 @@\n-  for (n = 0; sub != NULL; n++, sub = sub->next_sibling()) {\n+  for (n = 0; sub != nullptr; n++, sub = sub->next_sibling()) {\n@@ -3676,1 +3796,1 @@\n-  if (default_vtable_indices() != NULL) {\n+  if (default_vtable_indices() != nullptr) {\n@@ -3682,1 +3802,1 @@\n-  if (class_loader_data() != NULL) {\n+  if (class_loader_data() != nullptr) {\n@@ -3687,1 +3807,1 @@\n-  if (source_file_name() != NULL) {\n+  if (source_file_name() != nullptr) {\n@@ -3692,1 +3812,1 @@\n-  if (source_debug_extension() != NULL) {\n+  if (source_debug_extension() != nullptr) {\n@@ -3705,1 +3825,1 @@\n-         pv_node != NULL;\n+         pv_node != nullptr;\n@@ -3715,1 +3835,1 @@\n-  if (generic_signature() != NULL) {\n+  if (generic_signature() != nullptr) {\n@@ -3722,1 +3842,1 @@\n-  if (record_components() != NULL) {\n+  if (record_components() != nullptr) {\n@@ -3727,1 +3847,1 @@\n-  if (java_mirror() != NULL) {\n+  if (java_mirror() != nullptr) {\n@@ -3732,1 +3852,1 @@\n-    st->print_cr(BULLET\"java mirror:       NULL\");\n+    st->print_cr(BULLET\"java mirror:       null\");\n@@ -3737,1 +3857,1 @@\n-  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(NULL, start_of_itable(), itable_length(), st);\n+  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(nullptr, start_of_itable(), itable_length(), st);\n@@ -3764,1 +3884,1 @@\n-   if (_obj == NULL) {\n+   if (_obj == nullptr) {\n@@ -3780,1 +3900,1 @@\n-    if (value != NULL &&\n+    if (value != nullptr &&\n@@ -3798,1 +3918,1 @@\n-    if (real_klass != NULL && real_klass->is_instance_klass()) {\n+    if (real_klass != nullptr && real_klass->is_instance_klass()) {\n@@ -3824,1 +3944,1 @@\n-      && java_lang_String::value(obj) != NULL) {\n+      && java_lang_String::value(obj) != nullptr) {\n@@ -3835,1 +3955,1 @@\n-    if (k != NULL) {\n+    if (k != nullptr) {\n@@ -3849,1 +3969,1 @@\n-    if (vmentry != NULL) {\n+    if (vmentry != nullptr) {\n@@ -3855,1 +3975,1 @@\n-    if (vmtarget != NULL) {\n+    if (vmtarget != nullptr) {\n@@ -3861,1 +3981,1 @@\n-      if (clazz != NULL) {\n+      if (clazz != nullptr) {\n@@ -3864,1 +3984,1 @@\n-        st->print(\"NULL\");\n+        st->print(\"null\");\n@@ -3867,1 +3987,1 @@\n-      if (name != NULL) {\n+      if (name != nullptr) {\n@@ -3870,1 +3990,1 @@\n-        st->print(\"NULL\");\n+        st->print(\"null\");\n@@ -3899,4 +4019,4 @@\n-  if (cfs != NULL) {\n-    if (cfs->source() != NULL) {\n-      const char* module_name = (module_entry->name() == NULL) ? UNNAMED_MODULE : module_entry->name()->as_C_string();\n-      if (module_name != NULL) {\n+  if (cfs != nullptr) {\n+    if (cfs->source() != nullptr) {\n+      const char* module_name = (module_entry->name() == nullptr) ? UNNAMED_MODULE : module_entry->name()->as_C_string();\n+      if (module_name != nullptr) {\n@@ -3917,3 +4037,3 @@\n-        NULL;\n-      \/\/ caller can be NULL, for example, during a JVMTI VM_Init hook\n-      if (caller != NULL) {\n+        nullptr;\n+      \/\/ caller can be null, for example, during a JVMTI VM_Init hook\n+      if (caller != nullptr) {\n@@ -3947,1 +4067,1 @@\n-    if (local_interfaces() != NULL && local_interfaces()->length() > 0) {\n+    if (local_interfaces() != nullptr && local_interfaces()->length() > 0) {\n@@ -4012,1 +4132,1 @@\n-  if (subklass() != NULL) {\n+  if (subklass() != nullptr) {\n@@ -4019,1 +4139,1 @@\n-  if (sib != NULL) {\n+  if (sib != nullptr) {\n@@ -4038,1 +4158,1 @@\n-  if (transitive_interfaces() != NULL) {\n+  if (transitive_interfaces() != nullptr) {\n@@ -4047,1 +4167,1 @@\n-  if (methods() != NULL) {\n+  if (methods() != nullptr) {\n@@ -4060,1 +4180,1 @@\n-  if (method_ordering() != NULL) {\n+  if (method_ordering() != nullptr) {\n@@ -4081,1 +4201,1 @@\n-  if (default_methods() != NULL) {\n+  if (default_methods() != nullptr) {\n@@ -4094,1 +4214,1 @@\n-  if (jni_ids() != NULL) {\n+  if (jni_ids() != nullptr) {\n@@ -4099,1 +4219,1 @@\n-  if (constants() != NULL) {\n+  if (constants() != nullptr) {\n@@ -4125,1 +4245,1 @@\n-  while (current != NULL) {\n+  while (current != nullptr) {\n@@ -4129,1 +4249,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4133,1 +4253,1 @@\n-  while (current != NULL) {\n+  while (current != nullptr) {\n@@ -4147,1 +4267,1 @@\n-  while (current != NULL) {\n+  while (current != nullptr) {\n@@ -4169,2 +4289,2 @@\n-  assert(_init_thread == NULL, \"should be cleared before state change\");\n-  _init_state = state;\n+  assert(_init_thread == nullptr, \"should be cleared before state change\");\n+  Atomic::store(&_init_state, state);\n@@ -4180,1 +4300,1 @@\n-bool InstanceKlass::_has_previous_versions = false;\n+bool InstanceKlass::_should_clean_previous_versions = false;\n@@ -4187,3 +4307,3 @@\n-bool InstanceKlass::has_previous_versions_and_reset() {\n-  bool ret = _has_previous_versions;\n-  log_trace(redefine, class, iklass, purge)(\"Class unloading: has_previous_versions = %s\",\n+bool InstanceKlass::should_clean_previous_versions_and_reset() {\n+  bool ret = _should_clean_previous_versions;\n+  log_trace(redefine, class, iklass, purge)(\"Class unloading: should_clean_previous_versions = %s\",\n@@ -4191,1 +4311,1 @@\n-  _has_previous_versions = false;\n+  _should_clean_previous_versions = false;\n@@ -4202,1 +4322,1 @@\n-  if (previous_versions() == NULL) {\n+  if (previous_versions() == nullptr) {\n@@ -4212,1 +4332,1 @@\n-  assert(loader_data != NULL, \"should never be null\");\n+  assert(loader_data != nullptr, \"should never be null\");\n@@ -4223,1 +4343,1 @@\n-  for (; pv_node != NULL; ) {\n+  for (; pv_node != nullptr; ) {\n@@ -4226,1 +4346,1 @@\n-    assert(pvcp != NULL, \"cp ref was unexpectedly cleared\");\n+    assert(pvcp != nullptr, \"cp ref was unexpectedly cleared\");\n@@ -4238,1 +4358,1 @@\n-      pv_node->link_previous_versions(NULL);   \/\/ point next to NULL\n+      pv_node->link_previous_versions(nullptr);   \/\/ point next to null\n@@ -4248,2 +4368,1 @@\n-      log_trace(redefine, class, iklass, purge)(\"previous version \" PTR_FORMAT \" is alive\", p2i(pv_node));\n-      assert(pvcp->pool_holder() != NULL, \"Constant pool with no holder\");\n+      assert(pvcp->pool_holder() != nullptr, \"Constant pool with no holder\");\n@@ -4252,2 +4371,8 @@\n-      \/\/ found a previous version for next time we do class unloading\n-      _has_previous_versions = true;\n+      if (pvcp->is_shared()) {\n+        \/\/ Shared previous versions can never be removed so no cleaning is needed.\n+        log_trace(redefine, class, iklass, purge)(\"previous version \" PTR_FORMAT \" is shared\", p2i(pv_node));\n+      } else {\n+        \/\/ Previous version alive, set that clean is needed for next time.\n+        _should_clean_previous_versions = true;\n+        log_trace(redefine, class, iklass, purge)(\"previous version \" PTR_FORMAT \" is alive\", p2i(pv_node));\n+      }\n@@ -4270,1 +4395,1 @@\n-      _previous_versions != NULL) {\n+      _previous_versions != nullptr) {\n@@ -4284,1 +4409,1 @@\n-             prev_version != NULL;\n+             prev_version != nullptr;\n@@ -4353,5 +4478,3 @@\n-  \/\/ Add previous version if any methods are still running.\n-  \/\/ Set has_previous_version flag for processing during class unloading.\n-  _has_previous_versions = true;\n-  log_trace(redefine, class, iklass, add) (\"scratch class added; one of its methods is on_stack.\");\n-  assert(scratch_class->previous_versions() == NULL, \"shouldn't have a previous version\");\n+  \/\/ Add previous version if any methods are still running or if this is\n+  \/\/ a shared class which should never be removed.\n+  assert(scratch_class->previous_versions() == nullptr, \"shouldn't have a previous version\");\n@@ -4360,0 +4483,8 @@\n+  if (cp_ref->is_shared()) {\n+    log_trace(redefine, class, iklass, add) (\"scratch class added; class is shared\");\n+  } else {\n+    \/\/  We only set clean_previous_versions flag for processing during class\n+    \/\/ unloading for non-shared classes.\n+    _should_clean_previous_versions = true;\n+    log_trace(redefine, class, iklass, add) (\"scratch class added; one of its methods is on_stack.\");\n+  }\n@@ -4365,1 +4496,1 @@\n-  Method* m = NULL;\n+  Method* m = nullptr;\n@@ -4369,1 +4500,1 @@\n-  if (m == NULL || m->method_idnum() != idnum) {\n+  if (m == nullptr || m->method_idnum() != idnum) {\n@@ -4377,1 +4508,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -4385,1 +4516,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -4388,1 +4519,1 @@\n-  if (m != NULL && m->orig_method_idnum() == idnum) {\n+  if (m != nullptr && m->orig_method_idnum() == idnum) {\n@@ -4399,1 +4530,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4405,2 +4536,2 @@\n-  if (holder == NULL) {\n-    return NULL; \/\/ The version of klass is gone, no method is found\n+  if (holder == nullptr) {\n+    return nullptr; \/\/ The version of klass is gone, no method is found\n@@ -4429,2 +4560,2 @@\n-  assert(_current != NULL, \"required\");\n-  if (_visit_subclasses && _current->subklass() != NULL) {\n+  assert(_current != nullptr, \"required\");\n+  if (_visit_subclasses && _current->subklass() != nullptr) {\n@@ -4435,1 +4566,1 @@\n-  while (_current->next_sibling() == NULL && _current != _root) {\n+  while (_current->next_sibling() == nullptr && _current != _root) {\n@@ -4440,1 +4571,1 @@\n-    _current = NULL;\n+    _current = nullptr;\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":546,"deletions":415,"binary":false,"changes":961,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,1 @@\n+#include \"oops\/constantPool.hpp\"\n@@ -33,1 +34,1 @@\n-#include \"oops\/instanceKlassMiscStatus.hpp\"\n+#include \"oops\/instanceKlassFlags.hpp\"\n@@ -43,0 +44,1 @@\n+class DeoptimizationScope;\n@@ -85,1 +87,1 @@\n-\/\/ If \"obj\" argument to constructor is NULL, prints static fields, otherwise prints non-static fields.\n+\/\/ If \"obj\" argument to constructor is null, prints static fields, otherwise prints non-static fields.\n@@ -90,1 +92,1 @@\n-   FieldPrinter(outputStream* st, oop obj = NULL) : _obj(obj), _st(st) {}\n+   FieldPrinter(outputStream* st, oop obj = nullptr) : _obj(obj), _st(st) {}\n@@ -142,1 +144,1 @@\n-  MultiFieldInfo() : _name(NULL), _base_index(0), _multifield_index(-1) {}\n+  MultiFieldInfo() : _name(nullptr), _base_index(0), _multifield_index(-1) {}\n@@ -147,1 +149,1 @@\n-  FieldInfo* base_field_info(InstanceKlass* ik);\n+  FieldInfo base_field_info(InstanceKlass* ik);\n@@ -152,13 +154,12 @@\n-class InlineKlassFixedBlock {\n-  Array<SigEntry>** _extended_sig;\n-  Array<VMRegPair>** _return_regs;\n-  address* _pack_handler;\n-  address* _pack_handler_jobject;\n-  address* _unpack_handler;\n-  int* _default_value_offset;\n-  ArrayKlass** _null_free_inline_array_klasses;\n-  int _alignment;\n-  int _first_field_offset;\n-  int _exact_size_in_bytes;\n-\n-  friend class InlineKlass;\n+class InlineKlassFixedBlock : public MetaspaceObj {\n+   Array<SigEntry>** _extended_sig;\n+   Array<VMRegPair>** _return_regs;\n+   address* _pack_handler;\n+   address* _pack_handler_jobject;\n+   address* _unpack_handler;\n+   int* _default_value_offset;\n+   ArrayKlass** _null_free_inline_array_klasses;\n+   int _alignment;\n+   int _first_field_offset;\n+   int _exact_size_in_bytes;\n+   friend class InlineKlass;\n@@ -245,1 +246,1 @@\n-  \/\/ the source debug extension for this klass, NULL if not specified.\n+  \/\/ the source debug extension for this klass, null if not specified.\n@@ -247,1 +248,1 @@\n-  \/\/ it is stored in the instanceklass as a NULL-terminated UTF-8 string\n+  \/\/ it is stored in the instanceklass as a null-terminated UTF-8 string\n@@ -262,1 +263,0 @@\n-  u2              _java_fields_count;       \/\/ The number of declared Java fields\n@@ -266,5 +266,1 @@\n-  \/\/ _is_marked_dependent can be set concurrently, thus cannot be part of the\n-  \/\/ _misc_status right now.\n-  bool            _is_marked_dependent;     \/\/ used for marking during flushing and deoptimization\n-\n-  ClassState      _init_state;              \/\/ state of class\n+  volatile ClassState _init_state;          \/\/ state of class\n@@ -274,2 +270,2 @@\n-  \/\/ State is set while executing, eventually atomically to not disturb other state\n-  InstanceKlassMiscStatus _misc_status;\n+  \/\/ State is set either at parse time or while executing, atomically to not disturb other state\n+  InstanceKlassFlags _misc_flags;\n@@ -277,2 +273,2 @@\n-  Monitor*        _init_monitor;         \/\/ mutual exclusion to _init_state and _init_thread.\n-  Thread*         _init_thread;          \/\/ Pointer to current thread doing initialization (to handle recursive initialization)\n+  Monitor*             _init_monitor;       \/\/ mutual exclusion to _init_state and _init_thread.\n+  JavaThread* volatile _init_thread;        \/\/ Pointer to current thread doing initialization (to handle recursive initialization)\n@@ -282,1 +278,1 @@\n-  jmethodID*      volatile _methods_jmethod_ids;  \/\/ jmethodIDs corresponding to method_idnum, or NULL if none\n+  jmethodID*      volatile _methods_jmethod_ids;  \/\/ jmethodIDs corresponding to method_idnum, or null if none\n@@ -300,0 +296,1 @@\n+  NOT_PRODUCT(volatile int _shared_class_load_count;) \/\/ ensure a shared class is loaded only once\n@@ -315,14 +312,4 @@\n-  \/\/ Instance and static variable information, starts with 6-tuples of shorts\n-  \/\/ [access, name index, sig index, initval index, low_offset, high_offset]\n-  \/\/ for all fields, followed by the generic signature data at the end of\n-  \/\/ the array. Only fields with generic signature attributes have the generic\n-  \/\/ signature data set in the array. The fields array looks like following:\n-  \/\/\n-  \/\/ f1: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/ f2: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/      ...\n-  \/\/ fn: [access, name index, sig index, initial value index, low_offset, high_offset]\n-  \/\/     [generic signature index]\n-  \/\/     [generic signature index]\n-  \/\/     ...\n-  Array<u2>*      _fields;\n+  \/\/ Fields information is stored in an UNSIGNED5 encoded stream (see fieldInfo.hpp)\n+  Array<u1>*          _fieldinfo_stream;\n+  Array<FieldStatus>* _fields_status;\n+\n@@ -331,1 +318,1 @@\n-  const InlineKlassFixedBlock* _adr_inlineklass_fixed_block;\n+  InlineKlassFixedBlock* _adr_inlineklass_fixed_block;\n@@ -341,1 +328,1 @@\n-  \/\/     NULL: no implementor.\n+  \/\/     null: no implementor.\n@@ -362,3 +349,3 @@\n-  bool is_shared_boot_class() const { return _misc_status.is_shared_boot_class(); }\n-  bool is_shared_platform_class() const { return _misc_status.is_shared_platform_class(); }\n-  bool is_shared_app_class() const {  return _misc_status.is_shared_app_class(); }\n+  bool is_shared_boot_class() const { return _misc_flags.is_shared_boot_class(); }\n+  bool is_shared_platform_class() const { return _misc_flags.is_shared_platform_class(); }\n+  bool is_shared_app_class() const {  return _misc_flags.is_shared_app_class(); }\n@@ -366,1 +353,1 @@\n-  bool is_shared_unregistered_class() const { return _misc_status.is_shared_unregistered_class(); }\n+  bool is_shared_unregistered_class() const { return _misc_flags.is_shared_unregistered_class(); }\n@@ -371,1 +358,1 @@\n-  bool shared_loading_failed() const { return _misc_status.shared_loading_failed(); }\n+  bool shared_loading_failed() const { return _misc_flags.shared_loading_failed(); }\n@@ -373,1 +360,1 @@\n-  void set_shared_loading_failed() { _misc_status.set_shared_loading_failed(true); }\n+  void set_shared_loading_failed() { _misc_flags.set_shared_loading_failed(true); }\n@@ -376,2 +363,2 @@\n-  void set_shared_class_loader_type(s2 loader_type) { _misc_status.set_shared_class_loader_type(loader_type); }\n-  void assign_class_loader_type() { _misc_status.assign_class_loader_type(_class_loader_data); }\n+  void set_shared_class_loader_type(s2 loader_type) { _misc_flags.set_shared_class_loader_type(loader_type); }\n+  void assign_class_loader_type() { _misc_flags.assign_class_loader_type(_class_loader_data); }\n@@ -380,2 +367,5 @@\n-  bool has_nonstatic_fields() const        { return _misc_status.has_nonstatic_fields(); }\n-  void set_has_nonstatic_fields(bool b)    { _misc_status.set_has_nonstatic_fields(b); }\n+  bool has_nonstatic_fields() const        { return _misc_flags.has_nonstatic_fields(); }\n+  void set_has_nonstatic_fields(bool b)    { _misc_flags.set_has_nonstatic_fields(b); }\n+\n+  bool has_localvariable_table() const     { return _misc_flags.has_localvariable_table(); }\n+  void set_has_localvariable_table(bool b) { _misc_flags.set_has_localvariable_table(b); }\n@@ -383,2 +373,2 @@\n-  bool has_inline_type_fields() const { return _misc_status.has_inline_type_fields(); }\n-  void set_has_inline_type_fields()   { _misc_status.set_has_inline_type_fields(true); }\n+  bool has_inline_type_fields() const { return _misc_flags.has_inline_type_fields(); }\n+  void set_has_inline_type_fields()   { _misc_flags.set_has_inline_type_fields(true); }\n@@ -386,2 +376,2 @@\n-  bool is_empty_inline_type() const   { return _misc_status.is_empty_inline_type(); }\n-  void set_is_empty_inline_type()     { _misc_status.set_is_empty_inline_type(true); }\n+  bool is_empty_inline_type() const   { return _misc_flags.is_empty_inline_type(); }\n+  void set_is_empty_inline_type()     { _misc_flags.set_is_empty_inline_type(true); }\n@@ -394,2 +384,2 @@\n-  bool is_naturally_atomic() const  { return _misc_status.is_naturally_atomic(); }\n-  void set_is_naturally_atomic()    { _misc_status.set_is_naturally_atomic(true); }\n+  bool is_naturally_atomic() const  { return _misc_flags.is_naturally_atomic(); }\n+  void set_is_naturally_atomic()    { _misc_flags.set_is_naturally_atomic(true); }\n@@ -402,2 +392,2 @@\n-  bool is_declared_atomic() const { return _misc_status.is_declared_atomic(); }\n-  void set_is_declared_atomic()   { _misc_status.set_is_declared_atomic(true); }\n+  bool is_declared_atomic() const { return _misc_flags.is_declared_atomic(); }\n+  void set_is_declared_atomic()   { _misc_flags.set_is_declared_atomic(true); }\n@@ -405,2 +395,2 @@\n-  bool carries_value_modifier() const { return _misc_status.carries_value_modifier(); }\n-  void set_carries_value_modifier()   { _misc_status.set_carries_value_modifier(true); }\n+  bool carries_value_modifier() const { return _misc_flags.carries_value_modifier(); }\n+  void set_carries_value_modifier()   { _misc_flags.set_carries_value_modifier(true); }\n@@ -408,2 +398,2 @@\n-  bool carries_identity_modifier() const  { return _misc_status.carries_identity_modifier(); }\n-  void set_carries_identity_modifier()    { _misc_status.set_carries_identity_modifier(true); }\n+  bool carries_identity_modifier() const  { return _misc_flags.carries_identity_modifier(); }\n+  void set_carries_identity_modifier()    { _misc_flags.set_carries_identity_modifier(true); }\n@@ -454,1 +444,1 @@\n-    guarantee(_local_interfaces == NULL || a == NULL, \"Just checking\");\n+    guarantee(_local_interfaces == nullptr || a == nullptr, \"Just checking\");\n@@ -459,1 +449,1 @@\n-    guarantee(_transitive_interfaces == NULL || a == NULL, \"Just checking\");\n+    guarantee(_transitive_interfaces == nullptr || a == nullptr, \"Just checking\");\n@@ -466,1 +456,1 @@\n-  FieldInfo* field(int index) const { return FieldInfo::from_field_array(_fields, index); }\n+  FieldInfo field(int index) const;\n@@ -469,5 +459,7 @@\n-  int     field_offset      (int index) const { return field(index)->offset(); }\n-  int     field_access_flags(int index) const { return field(index)->access_flags(); }\n-  Symbol* field_name        (int index) const { return field(index)->name(multifield_info(), constants()); }\n-  Symbol* field_signature   (int index) const { return field(index)->signature(constants()); }\n-  bool    field_is_inlined(int index) const { return field(index)->is_inlined(); }\n+  int     field_offset      (int index) const { return field(index).offset(); }\n+  int     field_access_flags(int index) const { return field(index).access_flags().as_int(); }\n+  FieldInfo::FieldFlags field_flags(int index) const { return field(index).field_flags(); }\n+  FieldStatus field_status(int index)   const { return fields_status()->at(index); }\n+  inline Symbol* field_name        (int index) const;\n+  inline Symbol* field_signature   (int index) const;\n+  bool    field_is_inlined(int index) const { return field_flags(index).is_inlined(); }\n@@ -477,1 +469,2 @@\n-  int java_fields_count() const           { return (int)_java_fields_count; }\n+  int java_fields_count() const;\n+  int total_fields_count() const;\n@@ -479,6 +472,5 @@\n-  Array<u2>* fields() const            { return _fields; }\n-  void set_fields(Array<u2>* f, u2 java_fields_count) {\n-    guarantee(_fields == NULL || f == NULL, \"Just checking\");\n-    _fields = f;\n-    _java_fields_count = java_fields_count;\n-  }\n+  Array<u1>* fieldinfo_stream() const { return _fieldinfo_stream; }\n+  void set_fieldinfo_stream(Array<u1>* fis) { _fieldinfo_stream = fis; }\n+\n+  Array<FieldStatus>* fields_status() const {return _fields_status; }\n+  void set_fields_status(Array<FieldStatus>* array) { _fields_status = array; }\n@@ -533,1 +525,1 @@\n-    assert(_nest_host != NULL, \"must be\");\n+    assert(_nest_host != nullptr, \"must be\");\n@@ -538,1 +530,1 @@\n-  \/\/ Returns NULL if there was no error.\n+  \/\/ Returns null if there was no error.\n@@ -541,1 +533,1 @@\n-  \/\/ Returns NULL if resolution is not possible from the calling context.\n+  \/\/ Returns null if resolution is not possible from the calling context.\n@@ -567,1 +559,1 @@\n-  bool in_unnamed_package() const   { return (_package_entry == NULL); }\n+  bool in_unnamed_package() const   { return (_package_entry == nullptr); }\n@@ -600,1 +592,1 @@\n-  bool is_init_thread(Thread *thread)      { return thread == _init_thread; }\n+  bool is_init_thread(JavaThread *thread)  { return thread == Atomic::load(&_init_thread); }\n@@ -603,1 +595,1 @@\n-  bool is_rewritten() const                { return _misc_status.rewritten(); }\n+  bool is_rewritten() const                { return _misc_flags.rewritten(); }\n@@ -624,2 +616,2 @@\n-  bool should_verify_class() const         { return _misc_status.should_verify_class(); }\n-  void set_should_verify_class(bool value) { _misc_status.set_should_verify_class(value); }\n+  bool should_verify_class() const         { return _misc_flags.should_verify_class(); }\n+  void set_should_verify_class(bool value) { _misc_flags.set_should_verify_class(value); }\n@@ -628,2 +620,2 @@\n-  bool is_marked_dependent() const         { return _is_marked_dependent; }\n-  void set_is_marked_dependent(bool value) { _is_marked_dependent = value; }\n+  bool is_marked_dependent() const         { return _misc_flags.is_marked_dependent(); }\n+  void set_is_marked_dependent(bool value) { _misc_flags.set_is_marked_dependent(value); }\n@@ -632,1 +624,1 @@\n-  static ByteSize misc_status_offset() { return in_ByteSize(offset_of(InstanceKlass, _misc_status)); }\n+  static ByteSize misc_flags_offset() { return in_ByteSize(offset_of(InstanceKlass, _misc_flags)); }\n@@ -650,1 +642,1 @@\n-  static ByteSize reference_type_offset() { return in_ByteSize(offset_of(InstanceKlass, _reference_type)); }\n+  static ByteSize reference_type_offset() { return byte_offset_of(InstanceKlass, _reference_type); }\n@@ -675,1 +667,1 @@\n-  \/\/ find a local method (returns NULL if not found)\n+  \/\/ find a local method (returns null if not found)\n@@ -689,1 +681,1 @@\n-  \/\/ find a local method (returns NULL if not found)\n+  \/\/ find a local method (returns null if not found)\n@@ -696,1 +688,1 @@\n-  \/\/ find a local method from given methods array (returns NULL if not found)\n+  \/\/ find a local method from given methods array (returns null if not found)\n@@ -712,1 +704,1 @@\n-  \/\/ lookup operation (returns NULL if not found)\n+  \/\/ lookup operation (returns null if not found)\n@@ -719,1 +711,1 @@\n-  \/\/ (returns NULL if not found)\n+  \/\/ (returns null if not found)\n@@ -723,1 +715,1 @@\n-  \/\/ (returns NULL if not found)\n+  \/\/ (returns null if not found)\n@@ -744,2 +736,2 @@\n-  bool is_contended() const                { return _misc_status.is_contended(); }\n-  void set_is_contended(bool value)        { _misc_status.set_is_contended(value); }\n+  bool is_contended() const                { return _misc_flags.is_contended(); }\n+  void set_is_contended(bool value)        { _misc_flags.set_is_contended(value); }\n@@ -774,2 +766,2 @@\n-  bool has_contended_annotations() const { return _misc_status.has_contended_annotations(); }\n-  void set_has_contended_annotations(bool value)  { _misc_status.set_has_contended_annotations(value); }\n+  bool has_contended_annotations() const { return _misc_flags.has_contended_annotations(); }\n+  void set_has_contended_annotations(bool value)  { _misc_flags.set_has_contended_annotations(value); }\n@@ -781,10 +773,2 @@\n-  bool is_being_redefined() const          {\n-    return _access_flags.is_being_redefined();\n-  }\n-  void set_is_being_redefined(bool value)  {\n-    if (value) {\n-      _access_flags.set_is_being_redefined();\n-    } else {\n-      _access_flags.clear_is_being_redefined();\n-    }\n-  }\n+  bool is_being_redefined() const          { return _misc_flags.is_being_redefined(); }\n+  void set_is_being_redefined(bool value)  { _misc_flags.set_is_being_redefined(value); }\n@@ -798,1 +782,1 @@\n-  InstanceKlass* previous_versions() const { return NULL; }\n+  InstanceKlass* previous_versions() const { return nullptr; }\n@@ -802,1 +786,1 @@\n-    for (InstanceKlass* ik = this; ik != NULL; ik = ik->previous_versions()) {\n+    for (InstanceKlass* ik = this; ik != nullptr; ik = ik->previous_versions()) {\n@@ -807,1 +791,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -810,2 +794,2 @@\n-  bool has_been_redefined() const { return _misc_status.has_been_redefined(); }\n-  void set_has_been_redefined() { _misc_status.set_has_been_redefined(true); }\n+  bool has_been_redefined() const { return _misc_flags.has_been_redefined(); }\n+  void set_has_been_redefined() { _misc_flags.set_has_been_redefined(true); }\n@@ -813,6 +797,2 @@\n-  bool is_scratch_class() const { return _misc_status.is_scratch_class(); }\n-  void set_is_scratch_class() { _misc_status.set_is_scratch_class(true); }\n-\n-  bool has_resolved_methods() const {\n-    return _access_flags.has_resolved_methods();\n-  }\n+  bool is_scratch_class() const { return _misc_flags.is_scratch_class(); }\n+  void set_is_scratch_class() { _misc_flags.set_is_scratch_class(true); }\n@@ -820,3 +800,3 @@\n-  void set_has_resolved_methods() {\n-    _access_flags.set_has_resolved_methods();\n-  }\n+  bool has_resolved_methods() const { return _misc_flags.has_resolved_methods(); }\n+  void set_has_resolved_methods()   { _misc_flags.set_has_resolved_methods(true); }\n+  void set_has_resolved_methods(bool value)   { _misc_flags.set_has_resolved_methods(value); }\n@@ -828,1 +808,1 @@\n-    _previous_versions = NULL;\n+    _previous_versions = nullptr;\n@@ -832,1 +812,1 @@\n-  static bool  _has_previous_versions;\n+  static bool  _should_clean_previous_versions;\n@@ -840,2 +820,2 @@\n-  static bool has_previous_versions_and_reset();\n-  static bool has_previous_versions() { return _has_previous_versions; }\n+  static bool should_clean_previous_versions_and_reset();\n+  static bool should_clean_previous_versions() { return _should_clean_previous_versions; }\n@@ -861,1 +841,1 @@\n-  static bool has_previous_versions_and_reset() { return false; }\n+  static bool should_clean_previous_versions_and_reset() { return false; }\n@@ -864,1 +844,1 @@\n-    assert(data == NULL, \"unexpected call with JVMTI disabled\");\n+    assert(data == nullptr, \"unexpected call with JVMTI disabled\");\n@@ -866,1 +846,1 @@\n-  JvmtiCachedClassFileData * get_cached_class_file() { return (JvmtiCachedClassFileData *)NULL; }\n+  JvmtiCachedClassFileData * get_cached_class_file() { return (JvmtiCachedClassFileData *)nullptr; }\n@@ -870,2 +850,5 @@\n-  bool has_nonstatic_concrete_methods() const { return _misc_status.has_nonstatic_concrete_methods(); }\n-  void set_has_nonstatic_concrete_methods(bool b) { _misc_status.set_has_nonstatic_concrete_methods(b); }\n+  bool has_nonstatic_concrete_methods() const { return _misc_flags.has_nonstatic_concrete_methods(); }\n+  void set_has_nonstatic_concrete_methods(bool b) { _misc_flags.set_has_nonstatic_concrete_methods(b); }\n+\n+  bool declares_nonstatic_concrete_methods() const { return _misc_flags.declares_nonstatic_concrete_methods(); }\n+  void set_declares_nonstatic_concrete_methods(bool b) { _misc_flags.set_declares_nonstatic_concrete_methods(b); }\n@@ -873,2 +856,6 @@\n-  bool declares_nonstatic_concrete_methods() const { return _misc_status.declares_nonstatic_concrete_methods(); }\n-  void set_declares_nonstatic_concrete_methods(bool b) { _misc_status.set_declares_nonstatic_concrete_methods(b); }\n+  bool has_vanilla_constructor() const  { return _misc_flags.has_vanilla_constructor(); }\n+  void set_has_vanilla_constructor()    { _misc_flags.set_has_vanilla_constructor(true); }\n+  bool has_miranda_methods () const     { return _misc_flags.has_miranda_methods(); }\n+  void set_has_miranda_methods()        { _misc_flags.set_has_miranda_methods(true); }\n+  bool has_final_method() const         { return _misc_flags.has_final_method(); }\n+  void set_has_final_method()           { _misc_flags.set_has_final_method(true); }\n@@ -911,1 +898,1 @@\n-    return (_annotations != NULL) ? _annotations->class_annotations() : NULL;\n+    return (_annotations != nullptr) ? _annotations->class_annotations() : nullptr;\n@@ -914,1 +901,1 @@\n-    return (_annotations != NULL) ? _annotations->fields_annotations() : NULL;\n+    return (_annotations != nullptr) ? _annotations->fields_annotations() : nullptr;\n@@ -917,1 +904,1 @@\n-    return (_annotations != NULL) ? _annotations->class_type_annotations() : NULL;\n+    return (_annotations != nullptr) ? _annotations->class_type_annotations() : nullptr;\n@@ -920,1 +907,1 @@\n-    return (_annotations != NULL) ? _annotations->fields_type_annotations() : NULL;\n+    return (_annotations != nullptr) ? _annotations->fields_type_annotations() : nullptr;\n@@ -953,1 +940,1 @@\n-  int  mark_dependent_nmethods(KlassDepChange& changes);\n+  void mark_dependent_nmethods(DeoptimizationScope* deopt_scope, KlassDepChange& changes);\n@@ -956,0 +943,2 @@\n+  \/\/ Setup link to hierarchy and deoptimize\n+  void add_to_hierarchy(JavaThread* current);\n@@ -962,1 +951,1 @@\n-  int mark_osr_nmethods(const Method* m);\n+  int mark_osr_nmethods(DeoptimizationScope* deopt_scope, const Method* m);\n@@ -972,1 +961,1 @@\n-  static ByteSize init_state_offset()  { return in_ByteSize(offset_of(InstanceKlass, _init_state)); }\n+  static ByteSize init_state_offset()  { return byte_offset_of(InstanceKlass, _init_state); }\n@@ -974,1 +963,1 @@\n-  static ByteSize init_thread_offset() { return in_ByteSize(offset_of(InstanceKlass, _init_thread)); }\n+  static ByteSize init_thread_offset() { return byte_offset_of(InstanceKlass, _init_thread); }\n@@ -995,0 +984,1 @@\n+ private:\n@@ -998,0 +988,1 @@\n+ public:\n@@ -1020,1 +1011,1 @@\n-    assert(k != NULL, \"k should not be null\");\n+    assert(k != nullptr, \"k should not be null\");\n@@ -1026,1 +1017,1 @@\n-    return (super() == NULL) ? NULL : cast(super());\n+    return (super() == nullptr) ? nullptr : cast(super());\n@@ -1122,1 +1113,1 @@\n-  virtual void release_C_heap_structures(bool release_constant_pool = true);\n+  virtual void release_C_heap_structures(bool release_sub_metadata = true);\n@@ -1184,4 +1175,5 @@\n-  void set_rewritten()                  { _misc_status.set_rewritten(true); }\n-  void set_init_thread(Thread *thread)  {\n-    assert(thread == nullptr || _init_thread == nullptr, \"Only one thread is allowed to own initialization\");\n-    _init_thread = thread;\n+  void set_rewritten()                  { _misc_flags.set_rewritten(true); }\n+  void set_init_thread(JavaThread *thread)  {\n+    assert((thread == JavaThread::current() && _init_thread == nullptr) ||\n+           (thread == nullptr && _init_thread == JavaThread::current()), \"Only one thread is allowed to own initialization\");\n+    Atomic::store(&_init_thread, thread);\n@@ -1193,1 +1185,1 @@\n-  \/\/ going from NULL to non-NULL.\n+  \/\/ going from null to non-null.\n@@ -1221,1 +1213,1 @@\n-  \/\/ find a local method (returns NULL if not found)\n+  \/\/ find a local method (returns null if not found)\n@@ -1247,0 +1239,1 @@\n+  void remove_unshareable_flags();\n@@ -1251,0 +1244,2 @@\n+  bool methods_contain_jsr_bytecode() const;\n+  void compute_has_loops_flag_for_methods();\n@@ -1354,1 +1349,1 @@\n-    if (k->inner_classes() != NULL) {\n+    if (k->inner_classes() != nullptr) {\n@@ -1440,1 +1435,1 @@\n-    return (_current == NULL);\n+    return (_current == nullptr);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":156,"deletions":161,"binary":false,"changes":317,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,1 @@\n+#include \"memory\/memRegion.hpp\"\n@@ -33,0 +34,1 @@\n+#include \"oops\/fieldInfo.inline.hpp\"\n@@ -36,1 +38,0 @@\n-#include \"utilities\/debug.hpp\"\n@@ -39,1 +40,0 @@\n-#include \"utilities\/macros.hpp\"\n@@ -48,0 +48,6 @@\n+inline Symbol* InstanceKlass::field_name(int index) const { return field(index).name(multifield_info(), constants()); }\n+inline Symbol* InstanceKlass::field_signature(int index) const { return field(index).signature(constants()); }\n+\n+inline int InstanceKlass::java_fields_count() const { return FieldInfoStream::num_java_fields(fieldinfo_stream()); }\n+inline int InstanceKlass::total_fields_count() const { return FieldInfoStream::num_total_fields(fieldinfo_stream()); }\n+\n@@ -61,1 +67,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -233,12 +239,0 @@\n-inline instanceOop InstanceKlass::allocate_instance(oop java_class, TRAPS) {\n-  Klass* k = java_lang_Class::as_Klass(java_class);\n-  if (k == NULL) {\n-    ResourceMark rm(THREAD);\n-    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);\n-  }\n-  InstanceKlass* ik = cast(k);\n-  ik->check_valid_for_instantiation(false, CHECK_NULL);\n-  ik->initialize(CHECK_NULL);\n-  return ik->allocate_instance(THREAD);\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.inline.hpp","additions":10,"deletions":16,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -106,6 +106,1 @@\n-  set_force_inline(false);\n-  set_hidden(false);\n-  set_dont_inline(false);\n-  set_changes_current_thread(false);\n-  set_has_injected_profile(false);\n-  set_method_data(NULL);\n+  set_method_data(nullptr);\n@@ -116,2 +111,2 @@\n-  set_interpreter_entry(NULL); \/\/ sets i2i entry and from_int\n-  set_adapter_entry(NULL);\n+  set_interpreter_entry(nullptr); \/\/ sets i2i entry and from_int\n+  set_adapter_entry(nullptr);\n@@ -122,1 +117,1 @@\n-    set_signature_handler(NULL);\n+    set_signature_handler(nullptr);\n@@ -133,1 +128,1 @@\n-  set_constMethod(NULL);\n+  set_constMethod(nullptr);\n@@ -135,1 +130,1 @@\n-  set_method_data(NULL);\n+  set_method_data(nullptr);\n@@ -139,1 +134,1 @@\n-  if (code() != NULL) _code = NULL;\n+  if (code() != nullptr) _code = nullptr;\n@@ -144,4 +139,3 @@\n-#if INCLUDE_JVMCI\n-    FailedSpeculation::free_failed_speculations(method_data()->get_failed_speculations_address());\n-#endif\n-    \/\/ Destroy MethodData\n+    method_data()->release_C_heap_structures();\n+\n+    \/\/ Destroy MethodData embedded lock\n@@ -153,1 +147,1 @@\n-  assert(adapter() != NULL, \"must have\");\n+  assert(adapter() != nullptr, \"must have\");\n@@ -158,1 +152,1 @@\n-  assert(adapter() != NULL, \"must have\");\n+  assert(adapter() != nullptr, \"must have\");\n@@ -163,1 +157,1 @@\n-  assert(adapter() != NULL, \"must have\");\n+  assert(adapter() != nullptr, \"must have\");\n@@ -168,1 +162,1 @@\n-  assert(adapter() != NULL, \"must have\");\n+  assert(adapter() != nullptr, \"must have\");\n@@ -173,1 +167,1 @@\n-  assert(adapter() != NULL, \"must have\");\n+  assert(adapter() != nullptr, \"must have\");\n@@ -179,1 +173,1 @@\n-  assert(adapter() != NULL, \"must have\");\n+  assert(adapter() != nullptr, \"must have\");\n@@ -247,1 +241,1 @@\n-                          ex_klass == NULL ? \"NULL\" : ex_klass->external_name(), mh->name()->as_C_string());\n+                          ex_klass == nullptr ? \"null\" : ex_klass->external_name(), mh->name()->as_C_string());\n@@ -274,1 +268,1 @@\n-                               ex_klass == NULL ? \"NULL\" : ex_klass->external_name(), mh->name()->as_C_string(), handler_bci);\n+                               ex_klass == nullptr ? \"null\" : ex_klass->external_name(), mh->name()->as_C_string(), handler_bci);\n@@ -277,1 +271,1 @@\n-      } else if (ex_klass == NULL) {\n+      } else if (ex_klass == nullptr) {\n@@ -281,1 +275,1 @@\n-          log_info(exceptions)(\"NULL exception class is implicitly caught by handler in method \\\"%s\\\" at BCI: %d\",\n+          log_info(exceptions)(\"null exception class is implicitly caught by handler in method \\\"%s\\\" at BCI: %d\",\n@@ -303,1 +297,1 @@\n-        assert(k != NULL, \"klass not loaded\");\n+        assert(k != nullptr, \"klass not loaded\");\n@@ -308,1 +302,1 @@\n-                                 ex_klass == NULL ? \"NULL\" : ex_klass->external_name(), mh->name()->as_C_string(), handler_bci);\n+                                 ex_klass == nullptr ? \"null\" : ex_klass->external_name(), mh->name()->as_C_string(), handler_bci);\n@@ -383,1 +377,1 @@\n-  if (is_native() && bcp == NULL) {\n+  if (is_native() && bcp == nullptr) {\n@@ -427,0 +421,1 @@\n+  assert(!queued_for_compilation(), \"method's queued_for_compilation flag should not be set\");\n@@ -478,1 +473,1 @@\n-    if (trial_name == NULL) {\n+    if (trial_name == nullptr) {\n@@ -482,1 +477,1 @@\n-    if (method == NULL) {\n+    if (method == nullptr) {\n@@ -494,1 +489,1 @@\n-  return NULL; \/\/ not found\n+  return nullptr; \/\/ not found\n@@ -499,1 +494,1 @@\n-  if (method == NULL) {\n+  if (method == nullptr) {\n@@ -510,1 +505,1 @@\n-    if (method == NULL) {\n+    if (method == nullptr) {\n@@ -520,1 +515,1 @@\n-  if (entry != NULL) {\n+  if (entry != nullptr) {\n@@ -538,1 +533,1 @@\n-  if (is_accessor() || is_empty_method() || (code() != NULL)) {\n+  if (is_accessor() || is_empty_method() || (code() != nullptr)) {\n@@ -543,1 +538,1 @@\n-  else if ((method_counters() != NULL &&\n+  else if ((method_counters() != nullptr &&\n@@ -545,1 +540,1 @@\n-           (method_data() != NULL &&\n+           (method_data() != nullptr &&\n@@ -582,1 +577,1 @@\n-  if (method_data() != NULL) {\n+  if (method_data() != nullptr) {\n@@ -628,1 +623,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -647,1 +642,1 @@\n-  if (counters == NULL) {\n+  if (counters == nullptr) {\n@@ -650,1 +645,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -764,1 +759,3 @@\n-        if (bcs.dest() < bcs.next_bci()) _access_flags.set_has_loops();\n+        if (bcs.dest() < bcs.next_bci()) {\n+          return set_has_loops();\n+        }\n@@ -769,1 +766,3 @@\n-        if (bcs.dest_w() < bcs.next_bci()) _access_flags.set_has_loops();\n+        if (bcs.dest_w() < bcs.next_bci()) {\n+          return set_has_loops();\n+        }\n@@ -775,1 +774,1 @@\n-          _access_flags.set_has_loops();\n+          return set_has_loops();\n@@ -780,2 +779,1 @@\n-              _access_flags.set_has_loops();\n-              break;\n+              return set_has_loops();\n@@ -790,1 +788,1 @@\n-          _access_flags.set_has_loops();\n+          return set_has_loops();\n@@ -794,1 +792,1 @@\n-              _access_flags.set_has_loops();\n+              return set_has_loops();\n@@ -804,2 +802,3 @@\n-  _access_flags.set_loops_flag_init();\n-  return _access_flags.has_loops();\n+\n+  _flags.set_has_loops_flag_init(true);\n+  return false;\n@@ -821,1 +820,1 @@\n-  if (method_holder() != NULL &&\n+  if (method_holder() != nullptr &&\n@@ -1012,1 +1011,1 @@\n-    return SystemDictionary::find_instance_klass(thread, klass_name, loader, prot) != NULL;\n+    return SystemDictionary::find_instance_klass(thread, klass_name, loader, prot) != nullptr;\n@@ -1019,2 +1018,2 @@\n-bool Method::is_klass_loaded(int refinfo_index, bool must_be_resolved) const {\n-  int klass_index = constants()->klass_ref_index_at(refinfo_index);\n+bool Method::is_klass_loaded(int refinfo_index, Bytecodes::Code bc, bool must_be_resolved) const {\n+  int klass_index = constants()->klass_ref_index_at(refinfo_index, bc);\n@@ -1032,1 +1031,1 @@\n-  assert(function != NULL, \"use clear_native_function to unregister natives\");\n+  assert(function != nullptr, \"use clear_native_function to unregister natives\");\n@@ -1041,1 +1040,1 @@\n-      function != NULL) {\n+      function != nullptr) {\n@@ -1056,1 +1055,1 @@\n-  if (nm != NULL) {\n+  if (nm != nullptr) {\n@@ -1066,1 +1065,1 @@\n-  return (func != NULL && func != SharedRuntime::native_method_throw_unsatisfied_link_error_entry());\n+  return (func != nullptr && func != SharedRuntime::native_method_throw_unsatisfied_link_error_entry());\n@@ -1086,1 +1085,1 @@\n-  assert(reason != NULL, \"must provide a reason\");\n+  assert(reason != nullptr, \"must provide a reason\");\n@@ -1100,1 +1099,1 @@\n-    if (reason != NULL) {\n+    if (reason != nullptr) {\n@@ -1105,1 +1104,1 @@\n-  if ((TraceDeoptimization || LogCompilation) && (xtty != NULL)) {\n+  if ((TraceDeoptimization || LogCompilation) && (xtty != nullptr)) {\n@@ -1109,1 +1108,1 @@\n-    if (reason != NULL) {\n+    if (reason != nullptr) {\n@@ -1151,2 +1150,2 @@\n-    set_not_c1_compilable();\n-    set_not_c2_compilable();\n+    set_is_not_c1_compilable();\n+    set_is_not_c2_compilable();\n@@ -1155,1 +1154,1 @@\n-      set_not_c1_compilable();\n+      set_is_not_c1_compilable();\n@@ -1157,1 +1156,1 @@\n-      set_not_c2_compilable();\n+      set_is_not_c2_compilable();\n@@ -1177,2 +1176,2 @@\n-    set_not_c1_osr_compilable();\n-    set_not_c2_osr_compilable();\n+    set_is_not_c1_osr_compilable();\n+    set_is_not_c2_osr_compilable();\n@@ -1181,1 +1180,1 @@\n-      set_not_c1_osr_compilable();\n+      set_is_not_c1_osr_compilable();\n@@ -1183,1 +1182,1 @@\n-      set_not_c2_osr_compilable();\n+      set_is_not_c2_osr_compilable();\n@@ -1190,1 +1189,1 @@\n-  \/\/ this may be NULL if c2i adapters have not been made yet\n+  \/\/ this may be null if c2i adapters have not been made yet\n@@ -1192,4 +1191,4 @@\n-  if (adapter() == NULL) {\n-    _from_compiled_entry    = NULL;\n-    _from_compiled_inline_entry = NULL;\n-    _from_compiled_inline_ro_entry = NULL;\n+  if (adapter() == nullptr) {\n+    _from_compiled_entry    = nullptr;\n+    _from_compiled_inline_entry = nullptr;\n+    _from_compiled_inline_ro_entry = nullptr;\n@@ -1204,1 +1203,1 @@\n-  _code = NULL;\n+  _code = nullptr;\n@@ -1208,1 +1207,1 @@\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock, Mutex::_no_safepoint_check_flag);\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock, Mutex::_no_safepoint_check_flag);\n@@ -1219,1 +1218,1 @@\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock, Mutex::_no_safepoint_check_flag);\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock, Mutex::_no_safepoint_check_flag);\n@@ -1227,7 +1226,7 @@\n-  _code = NULL;\n-  _adapter = NULL;\n-  _i2i_entry = NULL;\n-  _from_compiled_entry = NULL;\n-  _from_compiled_inline_entry = NULL;\n-  _from_compiled_inline_ro_entry = NULL;\n-  _from_interpreted_entry = NULL;\n+  _code = nullptr;\n+  _adapter = nullptr;\n+  _i2i_entry = nullptr;\n+  _from_compiled_entry = nullptr;\n+  _from_compiled_inline_entry = nullptr;\n+  _from_compiled_inline_ro_entry = nullptr;\n+  _from_interpreted_entry = nullptr;\n@@ -1236,2 +1235,2 @@\n-    *native_function_addr() = NULL;\n-    set_signature_handler(NULL);\n+    *native_function_addr() = nullptr;\n+    set_signature_handler(nullptr);\n@@ -1241,1 +1240,1 @@\n-  set_method_data(NULL);\n+  set_method_data(nullptr);\n@@ -1243,0 +1242,15 @@\n+  remove_unshareable_flags();\n+}\n+\n+void Method::remove_unshareable_flags() {\n+  \/\/ clear all the flags that shouldn't be in the archived version\n+  assert(!is_old(), \"must be\");\n+  assert(!is_obsolete(), \"must be\");\n+  assert(!is_deleted(), \"must be\");\n+\n+  set_is_prefixed_native(false);\n+  set_queued_for_compilation(false);\n+  set_is_not_c2_compilable(false);\n+  set_is_not_c1_compilable(false);\n+  set_is_not_c2_osr_compilable(false);\n+  set_on_stack_flag(false);\n@@ -1251,1 +1265,1 @@\n-  if (adapter() != NULL) {\n+  if (adapter() != nullptr) {\n@@ -1254,1 +1268,1 @@\n-  assert( _code == NULL, \"nothing compiled yet\" );\n+  assert( _code == nullptr, \"nothing compiled yet\" );\n@@ -1259,1 +1273,1 @@\n-  assert(adapter() == NULL, \"init'd to NULL\");\n+  assert(adapter() == nullptr, \"init'd to null\");\n@@ -1261,1 +1275,1 @@\n-  assert(entry != NULL, \"interpreter entry must be non-null\");\n+  assert(entry != nullptr, \"interpreter entry must be non-null\");\n@@ -1271,2 +1285,2 @@\n-  if (InlineTypeReturnedAsFields && returns_inline_type(THREAD)) {\n-    set_has_scalarized_return(true);\n+  if (InlineTypeReturnedAsFields && returns_inline_type(THREAD) && returns_inline_type(THREAD)->can_be_returned_as_fields()) {\n+    set_has_scalarized_return();\n@@ -1289,3 +1303,3 @@\n-    _from_interpreted_entry = NULL;\n-    _from_compiled_entry = NULL;\n-    _i2i_entry = NULL;\n+    _from_interpreted_entry = nullptr;\n+    _from_compiled_entry = nullptr;\n+    _i2i_entry = nullptr;\n@@ -1300,1 +1314,1 @@\n-  if (adapter == NULL ) {\n+  if (adapter == nullptr ) {\n@@ -1327,1 +1341,1 @@\n-  assert(_from_compiled_entry != NULL, \"must be set\");\n+  assert(_from_compiled_entry != nullptr, \"must be set\");\n@@ -1333,1 +1347,1 @@\n-  assert(_from_compiled_inline_entry != NULL, \"must be set\");\n+  assert(_from_compiled_inline_entry != nullptr, \"must be set\");\n@@ -1339,1 +1353,1 @@\n-  assert(_from_compiled_inline_ro_entry != NULL, \"must be set\");\n+  assert(_from_compiled_inline_ro_entry != nullptr, \"must be set\");\n@@ -1349,1 +1363,1 @@\n-  return code == NULL || (code->method() == NULL) || (code->method() == (Method*)this && !code->is_osr_method());\n+  return code == nullptr || (code->method() == nullptr) || (code->method() == (Method*)this && !code->is_osr_method());\n@@ -1358,1 +1372,1 @@\n-  guarantee(mh->adapter() != NULL, \"Adapter blob must already exist!\");\n+  guarantee(mh->adapter() != nullptr, \"Adapter blob must already exist!\");\n@@ -1379,1 +1393,1 @@\n-    assert(mh->_from_interpreted_entry == NULL, \"initialized incorrectly\"); \/\/ see link_method\n+    assert(mh->_from_interpreted_entry == nullptr, \"initialized incorrectly\"); \/\/ see link_method\n@@ -1407,1 +1421,1 @@\n-    if (ik->lookup_method(name(), signature()) == NULL) {\n+    if (ik->lookup_method(name(), signature()) == nullptr) {\n@@ -1564,1 +1578,1 @@\n-  if (klass != NULL && klass->class_loader() != NULL) {\n+  if (klass != nullptr && klass->class_loader() != nullptr) {\n@@ -1569,1 +1583,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1682,1 +1696,1 @@\n-  \/\/ if loader is not the default loader (i.e., != NULL), we can't know the intrinsics\n+  \/\/ if loader is not the default loader (i.e., non-null), we can't know the intrinsics\n@@ -1687,1 +1701,1 @@\n-  if ((ik->class_loader() != NULL) && !SystemDictionary::is_platform_class_loader(ik->class_loader())) {\n+  if ((ik->class_loader() != nullptr) && !SystemDictionary::is_platform_class_loader(ik->class_loader())) {\n@@ -1731,1 +1745,1 @@\n-      set_force_inline(true);\n+      set_force_inline();\n@@ -1781,1 +1795,1 @@\n-      if( klass == NULL) { sig_is_loaded = false; }\n+      if( klass == nullptr) { sig_is_loaded = false; }\n@@ -1812,1 +1826,1 @@\n-    if (func == NULL) {\n+    if (func == nullptr) {\n@@ -1913,1 +1927,1 @@\n-  for (; bp != NULL; bp = bp->next()) {\n+  for (; bp != nullptr; bp = bp->next()) {\n@@ -1928,1 +1942,1 @@\n-  for (; bp != NULL; bp = bp->next()) {\n+  for (; bp != nullptr; bp = bp->next()) {\n@@ -1947,1 +1961,1 @@\n-  BreakpointInfo* prev_bp = NULL;\n+  BreakpointInfo* prev_bp = nullptr;\n@@ -1949,1 +1963,1 @@\n-  for (BreakpointInfo* bp = ik->breakpoints(); bp != NULL; bp = next_bp) {\n+  for (BreakpointInfo* bp = ik->breakpoints(); bp != nullptr; bp = next_bp) {\n@@ -1956,1 +1970,1 @@\n-      if (prev_bp != NULL)\n+      if (prev_bp != nullptr)\n@@ -1995,2 +2009,2 @@\n-  if (((mcs != NULL) ? mcs->invocation_counter()->carry() : false) ||\n-      ((mdo != NULL) ? mdo->invocation_counter()->carry() : false)) {\n+  if (((mcs != nullptr) ? mcs->invocation_counter()->carry() : false) ||\n+      ((mdo != nullptr) ? mdo->invocation_counter()->carry() : false)) {\n@@ -1999,2 +2013,2 @@\n-    return ((mcs != NULL) ? mcs->invocation_counter()->count() : 0) +\n-           ((mdo != NULL) ? mdo->invocation_counter()->count() : 0);\n+    return ((mcs != nullptr) ? mcs->invocation_counter()->count() : 0) +\n+           ((mdo != nullptr) ? mdo->invocation_counter()->count() : 0);\n@@ -2007,2 +2021,2 @@\n-  if (((mcs != NULL) ? mcs->backedge_counter()->carry() : false) ||\n-      ((mdo != NULL) ? mdo->backedge_counter()->carry() : false)) {\n+  if (((mcs != nullptr) ? mcs->backedge_counter()->carry() : false) ||\n+      ((mdo != nullptr) ? mdo->backedge_counter()->carry() : false)) {\n@@ -2011,2 +2025,2 @@\n-    return ((mcs != NULL) ? mcs->backedge_counter()->count() : 0) +\n-           ((mdo != NULL) ? mdo->backedge_counter()->count() : 0);\n+    return ((mcs != nullptr) ? mcs->backedge_counter()->count() : 0) +\n+           ((mdo != nullptr) ? mdo->backedge_counter()->count() : 0);\n@@ -2018,1 +2032,1 @@\n-  if (mcs != NULL) {\n+  if (mcs != nullptr) {\n@@ -2027,1 +2041,1 @@\n-  if (mcs != NULL) {\n+  if (mcs != nullptr) {\n@@ -2036,1 +2050,1 @@\n-  if (mcs != NULL) {\n+  if (mcs != nullptr) {\n@@ -2043,1 +2057,1 @@\n-  if (mcs != NULL) {\n+  if (mcs != nullptr) {\n@@ -2057,1 +2071,1 @@\n-  _next = NULL;\n+  _next = nullptr;\n@@ -2076,1 +2090,1 @@\n-    CodeCache::flush_dependents_on_method(mh);\n+    CodeCache::mark_dependents_on_method_for_breakpoint(mh);\n@@ -2117,1 +2131,1 @@\n-    if (_next == NULL) {\n+    if (_next == nullptr) {\n@@ -2139,1 +2153,1 @@\n-    for (JNIMethodBlockNode* b = _last_free; b != NULL; b = b->_next) {\n+    for (JNIMethodBlockNode* b = _last_free; b != nullptr; b = b->_next) {\n@@ -2161,1 +2175,1 @@\n-      if (b->_next == NULL) {\n+      if (b->_next == nullptr) {\n@@ -2166,1 +2180,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -2170,2 +2184,2 @@\n-    if (m == NULL) return false;\n-    for (JNIMethodBlockNode* b = &_head; b != NULL; b = b->_next) {\n+    if (m == nullptr) return false;\n+    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n@@ -2201,1 +2215,1 @@\n-    for (JNIMethodBlockNode* b = &_head; b != NULL; b = b->_next) {\n+    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n@@ -2203,1 +2217,1 @@\n-        b->_methods[i] = NULL;\n+        b->_methods[i] = nullptr;\n@@ -2211,1 +2225,1 @@\n-    for (JNIMethodBlockNode* b = &_head; b != NULL; b = b->_next) {\n+    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n@@ -2224,1 +2238,1 @@\n-JNIMethodBlockNode::JNIMethodBlockNode(int num_methods) : _top(0), _next(NULL) {\n+JNIMethodBlockNode::JNIMethodBlockNode(int num_methods) : _top(0), _next(nullptr) {\n@@ -2232,12 +2246,7 @@\n-void Method::ensure_jmethod_ids(ClassLoaderData* loader_data, int capacity) {\n-  ClassLoaderData* cld = loader_data;\n-  if (!SafepointSynchronize::is_at_safepoint()) {\n-    \/\/ Have to add jmethod_ids() to class loader data thread-safely.\n-    \/\/ Also have to add the method to the list safely, which the lock\n-    \/\/ protects as well.\n-    MutexLocker ml(JmethodIdCreation_lock,  Mutex::_no_safepoint_check_flag);\n-    if (cld->jmethod_ids() == NULL) {\n-      cld->set_jmethod_ids(new JNIMethodBlock(capacity));\n-    } else {\n-      cld->jmethod_ids()->ensure_methods(capacity);\n-    }\n+void Method::ensure_jmethod_ids(ClassLoaderData* cld, int capacity) {\n+  \/\/ Have to add jmethod_ids() to class loader data thread-safely.\n+  \/\/ Also have to add the method to the list safely, which the lock\n+  \/\/ protects as well.\n+  MutexLocker ml(JmethodIdCreation_lock,  Mutex::_no_safepoint_check_flag);\n+  if (cld->jmethod_ids() == nullptr) {\n+    cld->set_jmethod_ids(new JNIMethodBlock(capacity));\n@@ -2245,6 +2254,1 @@\n-    \/\/ At safepoint, we are single threaded and can set this.\n-    if (cld->jmethod_ids() == NULL) {\n-      cld->set_jmethod_ids(new JNIMethodBlock(capacity));\n-    } else {\n-      cld->jmethod_ids()->ensure_methods(capacity);\n-    }\n+    cld->jmethod_ids()->ensure_methods(capacity);\n@@ -2255,20 +2259,7 @@\n-jmethodID Method::make_jmethod_id(ClassLoaderData* loader_data, Method* m) {\n-  ClassLoaderData* cld = loader_data;\n-\n-  if (!SafepointSynchronize::is_at_safepoint()) {\n-    \/\/ Have to add jmethod_ids() to class loader data thread-safely.\n-    \/\/ Also have to add the method to the list safely, which the lock\n-    \/\/ protects as well.\n-    MutexLocker ml(JmethodIdCreation_lock,  Mutex::_no_safepoint_check_flag);\n-    if (cld->jmethod_ids() == NULL) {\n-      cld->set_jmethod_ids(new JNIMethodBlock());\n-    }\n-    \/\/ jmethodID is a pointer to Method*\n-    return (jmethodID)cld->jmethod_ids()->add_method(m);\n-  } else {\n-    \/\/ At safepoint, we are single threaded and can set this.\n-    if (cld->jmethod_ids() == NULL) {\n-      cld->set_jmethod_ids(new JNIMethodBlock());\n-    }\n-    \/\/ jmethodID is a pointer to Method*\n-    return (jmethodID)cld->jmethod_ids()->add_method(m);\n+jmethodID Method::make_jmethod_id(ClassLoaderData* cld, Method* m) {\n+  \/\/ Have to add jmethod_ids() to class loader data thread-safely.\n+  \/\/ Also have to add the method to the list safely, which the lock\n+  \/\/ protects as well.\n+  assert(JmethodIdCreation_lock->owned_by_self(), \"sanity check\");\n+  if (cld->jmethod_ids() == nullptr) {\n+    cld->set_jmethod_ids(new JNIMethodBlock());\n@@ -2276,0 +2267,2 @@\n+  \/\/ jmethodID is a pointer to Method*\n+  return (jmethodID)cld->jmethod_ids()->add_method(m);\n@@ -2285,2 +2278,1 @@\n-void Method::destroy_jmethod_id(ClassLoaderData* loader_data, jmethodID m) {\n-  ClassLoaderData* cld = loader_data;\n+void Method::destroy_jmethod_id(ClassLoaderData* cld, jmethodID m) {\n@@ -2288,1 +2280,1 @@\n-  assert(cld->jmethod_ids() != NULL, \"should have method handles\");\n+  assert(cld->jmethod_ids() != nullptr, \"should have method handles\");\n@@ -2297,1 +2289,1 @@\n-           new_method->method_holder()->class_loader() == NULL, \/\/ allow Unsafe substitution\n+           new_method->method_holder()->class_loader() == nullptr, \/\/ allow Unsafe substitution\n@@ -2305,1 +2297,1 @@\n-  assert(m != NULL, \"should be called with non-null method\");\n+  assert(m != nullptr, \"should be called with non-null method\");\n@@ -2308,1 +2300,1 @@\n-  if (cld->jmethod_ids() == NULL) return false;\n+  if (cld->jmethod_ids() == nullptr) return false;\n@@ -2313,1 +2305,1 @@\n-  if (mid == NULL) return NULL;\n+  if (mid == nullptr) return nullptr;\n@@ -2315,2 +2307,2 @@\n-  if (o == NULL || o == JNIMethodBlock::_free_method) {\n-    return NULL;\n+  if (o == nullptr || o == JNIMethodBlock::_free_method) {\n+    return nullptr;\n@@ -2321,1 +2313,1 @@\n-  \/\/ unloaded, we need to return NULL here too because after a safepoint, its memory\n+  \/\/ unloaded, we need to return null here too because after a safepoint, its memory\n@@ -2323,1 +2315,1 @@\n-  return o->method_holder()->is_loader_alive() ? o : NULL;\n+  return o->method_holder()->is_loader_alive() ? o : nullptr;\n@@ -2331,2 +2323,2 @@\n-  bool already_set = on_stack();\n-  _access_flags.set_on_stack(value);\n+  bool already_set = on_stack_flag();\n+  set_on_stack_flag(value);\n@@ -2358,1 +2350,1 @@\n-  if (m == NULL) {\n+  if (m == nullptr) {\n@@ -2419,0 +2411,1 @@\n+  st->print   (\" - flags:             0x%x  \", _flags.as_int()); _flags.print_on(st); st->cr();\n@@ -2437,1 +2430,1 @@\n-  if (a == NULL)\n+  if (a == nullptr)\n@@ -2449,1 +2442,1 @@\n-  if (method_data() != NULL) {\n+  if (method_data() != nullptr) {\n@@ -2487,1 +2480,1 @@\n-  if (code() != NULL) {\n+  if (code() != nullptr) {\n@@ -2521,1 +2514,1 @@\n-  if (WizardMode && code() != NULL) st->print(\" ((nmethod*)%p)\", code());\n+  if (WizardMode && code() != nullptr) st->print(\" ((nmethod*)%p)\", code());\n@@ -2530,1 +2523,1 @@\n-  guarantee(md == NULL ||\n+  guarantee(md == nullptr ||\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":193,"deletions":200,"binary":false,"changes":393,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -78,1 +78,1 @@\n-    assert(InlineTree::check_can_parse(method) == NULL, \"parse must be possible\");\n+    assert(InlineTree::check_can_parse(method) == nullptr, \"parse must be possible\");\n@@ -97,1 +97,1 @@\n-    return NULL;  \/\/ bailing out of the compile; do not try to parse\n+    return nullptr;  \/\/ bailing out of the compile; do not try to parse\n@@ -105,2 +105,2 @@\n-    while (exits.pop_exception_state() != NULL) ;\n-    return NULL;\n+    while (exits.pop_exception_state() != nullptr) ;\n+    return nullptr;\n@@ -131,1 +131,1 @@\n-      _call_node(NULL),\n+      _call_node(nullptr),\n@@ -161,1 +161,1 @@\n-  if (kit.C->log() != NULL) {\n+  if (kit.C->log() != nullptr) {\n@@ -212,1 +212,1 @@\n-    : CallGenerator(method), _vtable_index(vtable_index), _separate_io_proj(separate_io_proj), _call_node(NULL)\n+    : CallGenerator(method), _vtable_index(vtable_index), _separate_io_proj(separate_io_proj), _call_node(nullptr)\n@@ -235,1 +235,1 @@\n-  if (kit.C->log() != NULL) {\n+  if (kit.C->log() != nullptr) {\n@@ -251,1 +251,1 @@\n-                      NULL, \"null receiver\");\n+                      nullptr, \"null receiver\");\n@@ -260,1 +260,1 @@\n-  ciMethodData *caller_md = (caller == NULL) ? NULL : caller->method_data();\n+  ciMethodData *caller_md = (caller == nullptr) ? nullptr : caller->method_data();\n@@ -307,1 +307,1 @@\n-  if (InlineTree::check_can_parse(m) != NULL)  return NULL;\n+  if (InlineTree::check_can_parse(m) != nullptr)  return nullptr;\n@@ -315,1 +315,1 @@\n-  if (InlineTree::check_can_parse(m) != NULL)  return NULL;\n+  if (InlineTree::check_can_parse(m) != nullptr)  return nullptr;\n@@ -411,1 +411,1 @@\n-    LateInlineCallGenerator(callee, NULL), _caller(caller), _input_not_const(input_not_const) {}\n+    LateInlineCallGenerator(callee, nullptr), _caller(caller), _input_not_const(input_not_const) {}\n@@ -452,1 +452,1 @@\n-  if (cg != NULL) {\n+  if (cg != nullptr) {\n@@ -458,1 +458,1 @@\n-      assert(cg != NULL, \"inline call generator expected\");\n+      assert(cg != nullptr, \"inline call generator expected\");\n@@ -497,1 +497,1 @@\n-    _unique_id(0), _inline_cg(NULL), _callee(NULL), _is_pure_call(false), _prof_factor(prof_factor) {\n+    _unique_id(0), _inline_cg(nullptr), _callee(nullptr), _is_pure_call(false), _prof_factor(prof_factor) {\n@@ -509,1 +509,1 @@\n-    assert(_callee == NULL, \"repeated inlining attempt\");\n+    assert(_callee == nullptr, \"repeated inlining attempt\");\n@@ -519,1 +519,1 @@\n-    if (call_node() != NULL) {\n+    if (call_node() != nullptr) {\n@@ -579,1 +579,1 @@\n-                                        NULL \/*speculative_receiver_type*\/,\n+                                        nullptr \/*speculative_receiver_type*\/,\n@@ -582,1 +582,1 @@\n-  if (cg != NULL) {\n+  if (cg != nullptr) {\n@@ -609,1 +609,1 @@\n-  assert(_callee != NULL, \"required\"); \/\/ set up in CallDynamicJavaNode::Ideal\n+  assert(_callee != nullptr, \"required\"); \/\/ set up in CallDynamicJavaNode::Ideal\n@@ -618,2 +618,2 @@\n-  if (call == NULL || call->outcnt() == 0 ||\n-      call->in(0) == NULL || call->in(0)->is_top()) {\n+  if (call == nullptr || call->outcnt() == 0 ||\n+      call->in(0) == nullptr || call->in(0)->is_top()) {\n@@ -650,1 +650,1 @@\n-      (callprojs->exobj != NULL && call->find_edge(callprojs->exobj) != -1)) {\n+      (callprojs->exobj != nullptr && call->find_edge(callprojs->exobj) != -1)) {\n@@ -663,1 +663,1 @@\n-    if (callprojs->resproj[i] != NULL) {\n+    if (callprojs->resproj[i] != nullptr) {\n@@ -713,1 +713,1 @@\n-      if (t->is_inlinetypeptr() && method()->is_scalarized_arg(arg_num)) {\n+      if (t->is_inlinetypeptr() && !method()->get_Method()->mismatch() && method()->is_scalarized_arg(arg_num)) {\n@@ -742,1 +742,1 @@\n-    Node* buffer_oop = NULL;\n+    Node* buffer_oop = nullptr;\n@@ -756,1 +756,1 @@\n-        buffer_oop = arg_kit.new_instance(klass_node, NULL, NULL, \/* deoptimize_on_exception *\/ true);\n+        buffer_oop = arg_kit.new_instance(klass_node, nullptr, nullptr, \/* deoptimize_on_exception *\/ true);\n@@ -763,1 +763,1 @@\n-    if (old_nn != NULL) {\n+    if (old_nn != nullptr) {\n@@ -771,1 +771,1 @@\n-    if (new_jvms == NULL)  return;  \/\/ no change\n+    if (new_jvms == nullptr)  return;  \/\/ no change\n@@ -795,1 +795,1 @@\n-    if (vt != NULL && !result->is_VectorBox()) {\n+    if (vt != nullptr && !result->is_VectorBox()) {\n@@ -801,1 +801,1 @@\n-          assert(buffer_oop != NULL, \"should have allocated a buffer\");\n+          assert(buffer_oop != nullptr, \"should have allocated a buffer\");\n@@ -820,1 +820,1 @@\n-          assert(alloc != NULL, \"must have an allocation node\");\n+          assert(alloc != nullptr, \"must have an allocation node\");\n@@ -828,1 +828,1 @@\n-          vt->set_is_buffered();\n+          vt->set_is_buffered(kit.gvn());\n@@ -840,1 +840,1 @@\n-      DEBUG_ONLY(buffer_oop = NULL);\n+      DEBUG_ONLY(buffer_oop = nullptr);\n@@ -844,1 +844,1 @@\n-    assert(buffer_oop == NULL, \"unused buffer allocation\");\n+    assert(buffer_oop == nullptr, \"unused buffer allocation\");\n@@ -996,1 +996,1 @@\n-  if (log != NULL) {\n+  if (log != nullptr) {\n@@ -1011,1 +1011,1 @@\n-  Node* slow_ctl = NULL;\n+  Node* slow_ctl = nullptr;\n@@ -1020,2 +1020,2 @@\n-  SafePointNode* slow_map = NULL;\n-  JVMState* slow_jvms = NULL;\n+  SafePointNode* slow_map = nullptr;\n+  JVMState* slow_jvms = nullptr;\n@@ -1027,2 +1027,2 @@\n-        return NULL;  \/\/ might happen because of NodeCountInliningCutoff\n-      assert(slow_jvms != NULL, \"must be\");\n+        return nullptr;  \/\/ might happen because of NodeCountInliningCutoff\n+      assert(slow_jvms != nullptr, \"must be\");\n@@ -1047,1 +1047,1 @@\n-  if (new_jvms == NULL) {\n+  if (new_jvms == nullptr) {\n@@ -1057,1 +1057,1 @@\n-  if (slow_map == NULL) {\n+  if (slow_map == nullptr) {\n@@ -1138,1 +1138,1 @@\n-  if (cg != NULL) {\n+  if (cg != nullptr) {\n@@ -1194,1 +1194,1 @@\n-        if (recv_toop != NULL) {\n+        if (recv_toop != nullptr) {\n@@ -1201,1 +1201,1 @@\n-            return NULL;\n+            return nullptr;\n@@ -1239,1 +1239,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -1268,1 +1268,1 @@\n-        ciKlass* speculative_receiver_type = NULL;\n+        ciKlass* speculative_receiver_type = nullptr;\n@@ -1283,1 +1283,1 @@\n-          speculative_receiver_type = (receiver_type != NULL) ? receiver_type->speculative_type() : NULL;\n+          speculative_receiver_type = (receiver_type != nullptr) ? receiver_type->speculative_type() : nullptr;\n@@ -1307,1 +1307,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1341,1 +1341,1 @@\n-  \/\/    if (receiver == NULL)\n+  \/\/    if (receiver == nullptr)\n@@ -1356,1 +1356,1 @@\n-  if (log != NULL) {\n+  if (log != nullptr) {\n@@ -1400,1 +1400,1 @@\n-      if (new_jvms == NULL) {\n+      if (new_jvms == nullptr) {\n@@ -1411,1 +1411,1 @@\n-    if (else_ctrl == NULL) {\n+    if (else_ctrl == nullptr) {\n@@ -1426,2 +1426,2 @@\n-      return NULL;  \/\/ might happen because of NodeCountInliningCutoff\n-    assert(new_jvms != NULL, \"must be\");\n+      return nullptr;  \/\/ might happen because of NodeCountInliningCutoff\n+    assert(new_jvms != nullptr, \"must be\");\n@@ -1490,1 +1490,1 @@\n-      Node* m = NULL;\n+      Node* m = nullptr;\n@@ -1560,1 +1560,1 @@\n-    kit.uncommon_trap(_reason, _action, NULL, \"monomorphic vcall checkcast\", false, keep_exact_action);\n+    kit.uncommon_trap(_reason, _action, nullptr, \"monomorphic vcall checkcast\", false, keep_exact_action);\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":60,"deletions":60,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -43,1 +43,1 @@\n-  if (dom != NULL) {\n+  if (dom != nullptr) {\n@@ -56,1 +56,15 @@\n-  const Type* ft = phase->type(in(1))->filter_speculative(_type);\n+\n+  const Type* in_type = phase->type(in(1));\n+  const Type* ft = in_type->filter_speculative(_type);\n+\n+  \/\/ Check if both _type and in_type had a speculative type, but for the just\n+  \/\/ computed ft the speculative type was dropped.\n+  if (ft->speculative() == nullptr &&\n+      _type->speculative() != nullptr &&\n+      in_type->speculative() != nullptr) {\n+    \/\/ Speculative type may have disagreed between cast and input, and was\n+    \/\/ dropped in filtering. Recompute so that ft can take speculative type\n+    \/\/ of in_type. If we did not do it now, a subsequent ::Value call would\n+    \/\/ do it, and violate idempotence of ::Value.\n+    ft = in_type->filter_speculative(ft);\n+  }\n@@ -64,4 +78,7 @@\n-      const Type* t1 = phase->type(in(1));\n-      if( t1 == Type::TOP )  assert(ft == Type::TOP, \"special case #1\");\n-      const Type* rt = t1->join_speculative(_type);\n-      if (rt->empty())       assert(ft == Type::TOP, \"special case #2\");\n+      if (in_type == Type::TOP) {\n+        assert(ft == Type::TOP, \"special case #1\");\n+      }\n+      const Type* rt = in_type->join_speculative(_type);\n+      if (rt->empty()) {\n+        assert(ft == Type::TOP, \"special case #2\");\n+      }\n@@ -71,4 +88,5 @@\n-    if (phase->type(in(1)) == TypePtr::NULL_PTR &&\n-        _type->isa_ptr() && _type->is_ptr()->_ptr == TypePtr::NotNull)\n-    assert(ft == Type::TOP, \"special case #3\");\n-    break;\n+    if (in_type == TypePtr::NULL_PTR &&\n+        _type->isa_ptr() && _type->is_ptr()->_ptr == TypePtr::NotNull) {\n+      assert(ft == Type::TOP, \"special case #3\");\n+      break;\n+    }\n@@ -90,9 +108,7 @@\n-  if (in(1)->is_InlineType() && !in(1)->is_VectorBox()) {\n-    InlineTypeNode* vt = in(1)->as_InlineType();\n-    if (phase->type(vt)->filter_speculative(_type) != Type::TOP) {\n-      Node* cast = clone();\n-      cast->set_req(1, vt->get_oop());\n-      vt = vt->clone()->as_InlineType();\n-      vt->set_oop(phase->transform(cast));\n-      return vt;\n-    }\n+  InlineTypeNode* vt = in(1)->isa_InlineType();\n+  if (vt != nullptr && !vt->is_VectorBox() && phase->type(vt)->filter_speculative(_type) != Type::TOP) {\n+    Node* cast = clone();\n+    cast->set_req(1, vt->get_oop());\n+    vt = vt->clone()->as_InlineType();\n+    vt->set_oop(phase->transform(cast));\n+    return vt;\n@@ -101,1 +117,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -148,1 +164,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -162,1 +178,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -167,1 +183,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -172,2 +188,2 @@\n-  if (ctl == NULL) {\n-    return NULL;\n+  if (ctl == nullptr) {\n+    return nullptr;\n@@ -179,1 +195,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -181,2 +197,2 @@\n-  if (type()->isa_rawptr() && (gvn->type_or_null(val) == NULL || gvn->type(val)->isa_oopptr())) {\n-    return NULL;\n+  if (type()->isa_rawptr() && (gvn->type_or_null(val) == nullptr || gvn->type(val)->isa_oopptr())) {\n+    return nullptr;\n@@ -189,1 +205,1 @@\n-        u->in(0) != NULL &&\n+        u->in(0) != nullptr &&\n@@ -203,1 +219,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -232,4 +248,18 @@\n-  \/\/ Try to improve the type of the CastII if we recognize a CmpI\/If\n-  \/\/ pattern.\n-  if (_dependency != RegularDependency) {\n-    if (in(0) != NULL && in(0)->in(0) != NULL && in(0)->in(0)->is_If()) {\n+  \/\/ Try to improve the type of the CastII if we recognize a CmpI\/If pattern.\n+  \/\/\n+  \/\/ in1  in2\n+  \/\/  |    |\n+  \/\/  +--- | --+\n+  \/\/  |    |   |\n+  \/\/ CmpINode  |\n+  \/\/    |      |\n+  \/\/ BoolNode  |\n+  \/\/    |      |\n+  \/\/  IfNode   |\n+  \/\/    |      |\n+  \/\/  IfProj   |\n+  \/\/    |      |\n+  \/\/   CastIINode\n+  \/\/\n+  if (carry_dependency()) {\n+    if (in(0) != nullptr && in(0)->in(0) != nullptr && in(0)->in(0)->is_If()) {\n@@ -297,1 +327,1 @@\n-  if (existing != NULL) {\n+  if (existing != nullptr) {\n@@ -306,1 +336,1 @@\n-  if (progress != NULL) {\n+  if (progress != nullptr) {\n@@ -316,1 +346,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -363,1 +393,1 @@\n-  if (progress != NULL) {\n+  if (progress != nullptr) {\n@@ -366,1 +396,1 @@\n-  if (can_reshape && !phase->C->post_loop_opts_phase()) {\n+  if (!phase->C->post_loop_opts_phase()) {\n@@ -373,1 +403,1 @@\n-  if (in1 != NULL && in1->Opcode() == Op_ConvI2L) {\n+  if (in1 != nullptr && in1->Opcode() == Op_ConvI2L) {\n@@ -400,18 +430,1 @@\n-  Node* dom = dominating_cast(phase, phase);\n-  if (dom != NULL) {\n-    return dom;\n-  }\n-  if (_dependency != RegularDependency) {\n-    return this;\n-  }\n-  const Type* t = phase->type(in(1));\n-  if (EnableVectorReboxing && in(1)->Opcode() == Op_VectorBox) {\n-    if (t->higher_equal_speculative(phase->type(this))) {\n-      return in(1);\n-    }\n-  } else if (t == phase->type(this)) {\n-    \/\/ Toned down to rescue meeting at a Phi 3 different oops all implementing\n-    \/\/ the same interface.\n-    return in(1);\n-  }\n-  return this;\n+  return ConstraintCastNode::Identity(phase);\n@@ -428,2 +441,6 @@\n-  const TypePtr *in_type   = inn->isa_ptr();\n-  const TypePtr *my_type   = _type->isa_ptr();\n+  if (inn->isa_oopptr() && _type->isa_oopptr()) {\n+    return ConstraintCastNode::Value(phase);\n+  }\n+\n+  const TypePtr *in_type = inn->isa_ptr();\n+  const TypePtr *my_type = _type->isa_ptr();\n@@ -431,1 +448,2 @@\n-  if (in_type != NULL && my_type != NULL) {\n+  if (in_type != nullptr && my_type != nullptr) {\n+    \/\/ TODO 8302672\n@@ -437,1 +455,1 @@\n-      if (my_type == NULL) {\n+      if (my_type == nullptr) {\n@@ -444,12 +462,2 @@\n-    } else if (in_ptr == TypePtr::Constant) {\n-      if (my_type->isa_rawptr()) {\n-        result = my_type;\n-      } else {\n-        const TypeOopPtr *jptr = my_type->isa_oopptr();\n-        assert(jptr, \"\");\n-        result = !in_type->higher_equal(_type)\n-          ? my_type->cast_to_ptr_type(TypePtr::NotNull)\n-          : in_type;\n-      }\n-    } else {\n-      result =  my_type->cast_to_ptr_type( my_type->join_ptr(in_ptr) );\n+    } else if (in_ptr != TypePtr::Constant) {\n+      result = my_type->cast_to_ptr_type(my_type->join_ptr(in_ptr));\n@@ -459,55 +467,1 @@\n-  \/\/ This is the code from TypePtr::xmeet() that prevents us from\n-  \/\/ having 2 ways to represent the same type. We have to replicate it\n-  \/\/ here because we don't go through meet\/join.\n-  if (result->remove_speculative() == result->speculative()) {\n-    result = result->remove_speculative();\n-  }\n-\n-  \/\/ Same as above: because we don't go through meet\/join, remove the\n-  \/\/ speculative type if we know we won't use it.\n-  return result->cleanup_speculative();\n-\n-  \/\/ JOIN NOT DONE HERE BECAUSE OF INTERFACE ISSUES.\n-  \/\/ FIX THIS (DO THE JOIN) WHEN UNION TYPES APPEAR!\n-\n-  \/\/\n-  \/\/ Remove this code after overnight run indicates no performance\n-  \/\/ loss from not performing JOIN at CheckCastPPNode\n-  \/\/\n-  \/\/ const TypeInstPtr *in_oop = in->isa_instptr();\n-  \/\/ const TypeInstPtr *my_oop = _type->isa_instptr();\n-  \/\/ \/\/ If either input is an 'interface', return destination type\n-  \/\/ assert (in_oop == NULL || in_oop->klass() != NULL, \"\");\n-  \/\/ assert (my_oop == NULL || my_oop->klass() != NULL, \"\");\n-  \/\/ if( (in_oop && in_oop->klass()->is_interface())\n-  \/\/   ||(my_oop && my_oop->klass()->is_interface()) ) {\n-  \/\/   TypePtr::PTR  in_ptr = in->isa_ptr() ? in->is_ptr()->_ptr : TypePtr::BotPTR;\n-  \/\/   \/\/ Preserve cast away nullness for interfaces\n-  \/\/   if( in_ptr == TypePtr::NotNull && my_oop && my_oop->_ptr == TypePtr::BotPTR ) {\n-  \/\/     return my_oop->cast_to_ptr_type(TypePtr::NotNull);\n-  \/\/   }\n-  \/\/   return _type;\n-  \/\/ }\n-  \/\/\n-  \/\/ \/\/ Neither the input nor the destination type is an interface,\n-  \/\/\n-  \/\/ \/\/ history: JOIN used to cause weird corner case bugs\n-  \/\/ \/\/          return (in == TypeOopPtr::NULL_PTR) ? in : _type;\n-  \/\/ \/\/ JOIN picks up NotNull in common instance-of\/check-cast idioms, both oops.\n-  \/\/ \/\/ JOIN does not preserve NotNull in other cases, e.g. RawPtr vs InstPtr\n-  \/\/ const Type *join = in->join(_type);\n-  \/\/ \/\/ Check if join preserved NotNull'ness for pointers\n-  \/\/ if( join->isa_ptr() && _type->isa_ptr() ) {\n-  \/\/   TypePtr::PTR join_ptr = join->is_ptr()->_ptr;\n-  \/\/   TypePtr::PTR type_ptr = _type->is_ptr()->_ptr;\n-  \/\/   \/\/ If there isn't any NotNull'ness to preserve\n-  \/\/   \/\/ OR if join preserved NotNull'ness then return it\n-  \/\/   if( type_ptr == TypePtr::BotPTR  || type_ptr == TypePtr::Null ||\n-  \/\/       join_ptr == TypePtr::NotNull || join_ptr == TypePtr::Constant ) {\n-  \/\/     return join;\n-  \/\/   }\n-  \/\/   \/\/ ELSE return same old type as before\n-  \/\/   return _type;\n-  \/\/ }\n-  \/\/ \/\/ Not joining two pointers\n-  \/\/ return join;\n+  return result;\n@@ -578,1 +532,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -616,1 +570,1 @@\n-  return (in(0) && remove_dead_region(phase, can_reshape)) ? this : NULL;\n+  return (in(0) && remove_dead_region(phase, can_reshape)) ? this : nullptr;\n@@ -626,1 +580,1 @@\n-  Node* cast= NULL;\n+  Node* cast= nullptr;\n@@ -647,2 +601,2 @@\n-  const TypeInteger* rx = NULL;\n-  const TypeInteger* ry = NULL;\n+  const TypeInteger* rx = nullptr;\n+  const TypeInteger* ry = nullptr;\n@@ -651,1 +605,1 @@\n-    if (igvn == NULL) {\n+    if (igvn == nullptr) {\n@@ -655,1 +609,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -669,1 +623,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -671,1 +625,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -680,1 +634,1 @@\n-  if (in_type != NULL &&\n+  if (in_type != nullptr &&\n","filename":"src\/hotspot\/share\/opto\/castnode.cpp","additions":93,"deletions":139,"binary":false,"changes":232,"status":"modified"},{"patch":"@@ -81,2 +81,2 @@\n-    return NULL;\n-  Node *progress = NULL;        \/\/ Progress flag\n+    return nullptr;\n+  Node *progress = nullptr;        \/\/ Progress flag\n@@ -95,1 +95,1 @@\n-          return NULL;        \/\/ Only flatten if no Phi users\n+          return nullptr;        \/\/ Only flatten if no Phi users\n@@ -130,1 +130,1 @@\n-\/\/ Helper function: Return any PhiNode that uses this region or NULL\n+\/\/ Helper function: Return any PhiNode that uses this region or null\n@@ -140,1 +140,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -145,1 +145,1 @@\n-\/\/ Helper function: Return the only PhiNode that uses this region or NULL\n+\/\/ Helper function: Return the only PhiNode that uses this region or null\n@@ -148,1 +148,1 @@\n-  PhiNode* only_phi = NULL;\n+  PhiNode* only_phi = nullptr;\n@@ -153,1 +153,1 @@\n-      if (only_phi == NULL) {\n+      if (only_phi == nullptr) {\n@@ -156,1 +156,1 @@\n-        return NULL;  \/\/ multiple phis\n+        return nullptr;  \/\/ multiple phis\n@@ -169,3 +169,3 @@\n-  min     = NULL;\n-  max     = NULL;\n-  val     = NULL;\n+  min     = nullptr;\n+  max     = nullptr;\n+  val     = nullptr;\n@@ -183,2 +183,2 @@\n-          if( min == NULL ) {\n-            min     = n->Opcode() == Op_ConI ? (ConNode*)n : NULL;\n+          if( min == nullptr ) {\n+            min     = n->Opcode() == Op_ConI ? (ConNode*)n : nullptr;\n@@ -187,1 +187,1 @@\n-            max     = n->Opcode() == Op_ConI ? (ConNode*)n : NULL;\n+            max     = n->Opcode() == Op_ConI ? (ConNode*)n : nullptr;\n@@ -224,2 +224,2 @@\n-  top_if = NULL;\n-  bot_if = NULL;\n+  top_if = nullptr;\n+  bot_if = nullptr;\n@@ -237,3 +237,3 @@\n-    if( in10 != NULL && in10->is_If() &&\n-        in20 != NULL && in20->is_If() &&\n-        in30 != NULL && in30->is_If() && in10 == in20 &&\n+    if( in10 != nullptr && in10->is_If() &&\n+        in20 != nullptr && in20->is_If() &&\n+        in30 != nullptr && in30->is_If() && in10 == in20 &&\n@@ -242,1 +242,1 @@\n-      Node *in1000 = (in100 != NULL && in100->is_Proj()) ? in100->in(0) : NULL;\n+      Node *in1000 = (in100 != nullptr && in100->is_Proj()) ? in100->in(0) : nullptr;\n@@ -244,1 +244,1 @@\n-      if( in1000 != NULL && in1000->is_If() &&\n+      if( in1000 != nullptr && in1000->is_If() &&\n@@ -253,1 +253,1 @@\n-  return (top_if != NULL);\n+  return (top_if != nullptr);\n@@ -261,1 +261,1 @@\n-  convf2i = NULL;\n+  convf2i = nullptr;\n@@ -322,1 +322,1 @@\n-  assert(req() == 2 || (req() == 3 && in(1) != NULL && in(2) == top), \"sanity check arguments\");\n+  assert(req() == 2 || (req() == 3 && in(1) != nullptr && in(2) == top), \"sanity check arguments\");\n@@ -346,1 +346,1 @@\n-    if (n != NULL && n->is_Phi()) {\n+    if (n != nullptr && n->is_Phi()) {\n@@ -356,1 +356,1 @@\n-        if (u != NULL && (u->is_Phi() || u->is_CFG())) {\n+        if (u != nullptr && (u->is_Phi() || u->is_CFG())) {\n@@ -386,1 +386,1 @@\n-      if (m != NULL && m->is_CFG()) {\n+      if (m != nullptr && m->is_CFG()) {\n@@ -398,0 +398,53 @@\n+#ifdef ASSERT\n+\/\/ Is this region in an infinite subgraph?\n+\/\/ (no path to root except through false NeverBranch exit)\n+bool RegionNode::is_in_infinite_subgraph() {\n+  ResourceMark rm;\n+  Unique_Node_List worklist;\n+  worklist.push(this);\n+  return RegionNode::are_all_nodes_in_infinite_subgraph(worklist);\n+}\n+\n+\/\/ Are all nodes in worklist in infinite subgraph?\n+\/\/ (no path to root except through false NeverBranch exit)\n+\/\/ worklist is directly used for the traversal\n+bool RegionNode::are_all_nodes_in_infinite_subgraph(Unique_Node_List& worklist) {\n+  \/\/ BFS traversal down the CFG, except through NeverBranch exits\n+  for (uint i = 0; i < worklist.size(); ++i) {\n+    Node* n = worklist.at(i);\n+    assert(n->is_CFG(), \"only traverse CFG\");\n+    if (n->is_Root()) {\n+      \/\/ Found root -> there was an exit!\n+      return false;\n+    } else if (n->is_NeverBranch()) {\n+      \/\/ Only follow the loop-internal projection, not the NeverBranch exit\n+      ProjNode* proj = n->as_NeverBranch()->proj_out_or_null(0);\n+      assert(proj != nullptr, \"must find loop-internal projection of NeverBranch\");\n+      worklist.push(proj);\n+    } else {\n+      \/\/ Traverse all CFG outputs\n+      for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+        Node* use = n->fast_out(i);\n+        if (use->is_CFG()) {\n+          worklist.push(use);\n+        }\n+      }\n+    }\n+  }\n+  \/\/ No exit found for any loop -> all are infinite\n+  return true;\n+}\n+#endif \/\/ASSERT\n+\n+void RegionNode::set_loop_status(RegionNode::LoopStatus status) {\n+  assert(loop_status() == RegionNode::LoopStatus::NeverIrreducibleEntry, \"why set our status again?\");\n+  _loop_status = status;\n+}\n+\n+#ifdef ASSERT\n+void RegionNode::verify_can_be_irreducible_entry() const {\n+  assert(loop_status() == RegionNode::LoopStatus::MaybeIrreducibleEntry, \"must be marked irreducible\");\n+  assert(!is_Loop(), \"LoopNode cannot be irreducible loop entry\");\n+}\n+#endif \/\/ASSERT\n+\n@@ -419,1 +472,1 @@\n-    MergeMemNode* m = NULL;\n+    MergeMemNode* m = nullptr;\n@@ -437,1 +490,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -444,1 +497,1 @@\n-  if( !can_reshape && !in(0) ) return NULL;     \/\/ Already degraded to a Copy\n+  if( !can_reshape && !in(0) ) return nullptr;     \/\/ Already degraded to a Copy\n@@ -451,1 +504,1 @@\n-    has_phis = (has_phi() != NULL);       \/\/ Cache result\n+    has_phis = (has_phi() != nullptr);       \/\/ Cache result\n@@ -454,1 +507,1 @@\n-      if (phi != NULL) {\n+      if (phi != nullptr) {\n@@ -456,1 +509,1 @@\n-        if (m != NULL) {\n+        if (m != nullptr) {\n@@ -476,1 +529,1 @@\n-            set_req(j, NULL);\n+            set_req(j, nullptr);\n@@ -484,1 +537,1 @@\n-  \/\/ Remove TOP or NULL input paths. If only 1 input path remains, this Region\n+  \/\/ Remove TOP or null input paths. If only 1 input path remains, this Region\n@@ -490,0 +543,1 @@\n+  DEBUG_ONLY( uint outcnt_orig = outcnt(); )\n@@ -491,0 +545,1 @@\n+  bool found_top = false; \/\/ irreducible loops need to check reachability if we find TOP\n@@ -494,1 +549,1 @@\n-    if( n != NULL ) {\n+    if( n != nullptr ) {\n@@ -512,1 +567,1 @@\n-        set_req_X(i, NULL, phase); \/\/ Ignore TOP inputs\n+        set_req_X(i, nullptr, phase); \/\/ Ignore TOP inputs\n@@ -514,0 +569,1 @@\n+        found_top = true;\n@@ -518,1 +574,0 @@\n-\n@@ -523,18 +578,9 @@\n-      uint max = outcnt();\n-      DUIterator j;\n-      bool progress = true;\n-      while(progress) {         \/\/ Need to establish property over all users\n-        progress = false;\n-        for (j = outs(); has_out(j); j++) {\n-          Node *n = out(j);\n-          if( n->req() != req() && n->is_Phi() ) {\n-            assert( n->in(0) == this, \"\" );\n-            igvn->hash_delete(n); \/\/ Yank from hash before hacking edges\n-            n->set_req_X(i,NULL,igvn);\/\/ Correct DU info\n-            n->del_req(i);        \/\/ Yank path from Phis\n-            if( max != outcnt() ) {\n-              progress = true;\n-              j = refresh_out_pos(j);\n-              max = outcnt();\n-            }\n-          }\n+\n+      for (DUIterator_Fast jmax, j = fast_outs(jmax); j < jmax; j++) {\n+        Node* use = fast_out(j);\n+\n+        if (use->req() != req() && use->is_Phi()) {\n+          assert(use->in(0) == this, \"unexpected control input\");\n+          igvn->hash_delete(use);          \/\/ Yank from hash before hacking edges\n+          use->set_req_X(i, nullptr, igvn);\/\/ Correct DU info\n+          use->del_req(i);                 \/\/ Yank path from Phis\n@@ -543,2 +589,6 @@\n-      add_to_worklist = false;\n-      phase->is_IterGVN()->add_users_to_worklist(this);\n+\n+      if (add_to_worklist) {\n+        igvn->add_users_to_worklist(this);\n+        add_to_worklist = false;\n+      }\n+\n@@ -549,1 +599,16 @@\n-  if (can_reshape && cnt == 1) {\n+  assert(outcnt() == outcnt_orig, \"not expect to remove any use\");\n+\n+  if (can_reshape && found_top && loop_status() == RegionNode::LoopStatus::MaybeIrreducibleEntry) {\n+    \/\/ Is it a dead irreducible loop?\n+    \/\/ If an irreducible loop loses one of the multiple entries\n+    \/\/ that went into the loop head, or any secondary entries,\n+    \/\/ we need to verify if the irreducible loop is still reachable,\n+    \/\/ as the special logic in is_unreachable_region only works\n+    \/\/ for reducible loops.\n+    if (is_unreachable_from_root(phase)) {\n+      \/\/ The irreducible loop is dead - must remove it\n+      PhaseIterGVN* igvn = phase->is_IterGVN();\n+      remove_unreachable_subgraph(igvn);\n+      return nullptr;\n+    }\n+  } else if (can_reshape && cnt == 1) {\n@@ -559,42 +624,2 @@\n-      \/\/ This region and therefore all nodes on the input control path(s) are unreachable\n-      \/\/ from root. To avoid incomplete removal of unreachable subgraphs, walk up the CFG\n-      \/\/ and aggressively replace all nodes by top.\n-      Node* top = phase->C->top();\n-      ResourceMark rm;\n-      Node_List nstack;\n-      VectorSet visited;\n-      nstack.push(this);\n-      visited.set(_idx);\n-      while (nstack.size() != 0) {\n-        Node* n = nstack.pop();\n-        for (uint i = 0; i < n->req(); ++i) {\n-          Node* m = n->in(i);\n-          assert(m != (Node*)phase->C->root(), \"Should be unreachable from root\");\n-          if (m != NULL && m->is_CFG() && !visited.test_set(m->_idx)) {\n-            nstack.push(m);\n-          }\n-        }\n-        if (n->is_Region()) {\n-          \/\/ Eagerly replace phis with top to avoid regionless phis.\n-          n->set_req(0, NULL);\n-          bool progress = true;\n-          uint max = n->outcnt();\n-          DUIterator j;\n-          while (progress) {\n-            progress = false;\n-            for (j = n->outs(); n->has_out(j); j++) {\n-              Node* u = n->out(j);\n-              if (u->is_Phi()) {\n-                igvn->replace_node(u, top);\n-                if (max != n->outcnt()) {\n-                  progress = true;\n-                  j = n->refresh_out_pos(j);\n-                  max = n->outcnt();\n-                }\n-              }\n-            }\n-          }\n-        }\n-        igvn->replace_node(n, top);\n-      }\n-      return NULL;\n+      remove_unreachable_subgraph(igvn);\n+      return nullptr;\n@@ -606,1 +631,1 @@\n-    set_req(0, NULL);           \/\/ Null control input for region copy\n+    set_req(0, nullptr);        \/\/ Null control input for region copy\n@@ -608,2 +633,2 @@\n-      \/\/ No inputs or all inputs are NULL.\n-      return NULL;\n+      \/\/ No inputs or all inputs are null.\n+      return nullptr;\n@@ -617,1 +642,1 @@\n-        if (outer_sfpt != NULL && outer_out != NULL) {\n+        if (outer_sfpt != nullptr && outer_out != nullptr) {\n@@ -626,1 +651,1 @@\n-        if (opaq != NULL) {\n+        if (opaq != nullptr) {\n@@ -644,1 +669,1 @@\n-        assert(parent_ctrl != NULL, \"Region is a copy of some non-null control\");\n+        assert(parent_ctrl != nullptr, \"Region is a copy of some non-null control\");\n@@ -667,1 +692,1 @@\n-            assert( n->req() == 2 &&  n->in(1) != NULL, \"Only one data input expected\" );\n+            assert( n->req() == 2 &&  n->in(1) != nullptr, \"Only one data input expected\" );\n@@ -693,1 +718,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -702,1 +727,1 @@\n-    if (m != NULL)  return m;\n+    if (m != nullptr)  return m;\n@@ -709,1 +734,1 @@\n-    if (phi != NULL) {          \/\/ One Phi user\n+    if (phi != nullptr) {          \/\/ One Phi user\n@@ -722,2 +747,2 @@\n-          Node   *top_in = NULL;   \/\/ value being compared against\n-          Node   *bot_in = NULL;\n+          Node   *top_in = nullptr;   \/\/ value being compared against\n+          Node   *bot_in = nullptr;\n@@ -728,1 +753,1 @@\n-              assert( gvn != NULL, \"Only had DefUse info in IterGVN\");\n+              assert( gvn != nullptr, \"Only had DefUse info in IterGVN\");\n@@ -770,1 +795,54 @@\n-  return modified ? this : NULL;\n+  return modified ? this : nullptr;\n+}\n+\n+\/\/--------------------------remove_unreachable_subgraph----------------------\n+\/\/ This region and therefore all nodes on the input control path(s) are unreachable\n+\/\/ from root. To avoid incomplete removal of unreachable subgraphs, walk up the CFG\n+\/\/ and aggressively replace all nodes by top.\n+\/\/ If a control node \"def\" with a single control output \"use\" has its single output\n+\/\/ \"use\" replaced with top, then \"use\" removes itself. This has the consequence that\n+\/\/ when we visit \"use\", it already has all inputs removed. They are lost and we cannot\n+\/\/ traverse them. This is why we fist find all unreachable nodes, and then remove\n+\/\/ them in a second step.\n+void RegionNode::remove_unreachable_subgraph(PhaseIterGVN* igvn) {\n+  Node* top = igvn->C->top();\n+  ResourceMark rm;\n+  Unique_Node_List unreachable; \/\/ visit each only once\n+  unreachable.push(this);\n+  \/\/ Recursively find all control inputs.\n+  for (uint i = 0; i < unreachable.size(); i++) {\n+    Node* n = unreachable.at(i);\n+    for (uint i = 0; i < n->req(); ++i) {\n+      Node* m = n->in(i);\n+      assert(m == nullptr || !m->is_Root(), \"Should be unreachable from root\");\n+      if (m != nullptr && m->is_CFG()) {\n+        unreachable.push(m);\n+      }\n+    }\n+  }\n+  \/\/ Remove all unreachable nodes.\n+  for (uint i = 0; i < unreachable.size(); i++) {\n+    Node* n = unreachable.at(i);\n+    if (n->is_Region()) {\n+      \/\/ Eagerly replace phis with top to avoid regionless phis.\n+      n->set_req(0, nullptr);\n+      bool progress = true;\n+      uint max = n->outcnt();\n+      DUIterator j;\n+      while (progress) {\n+        progress = false;\n+        for (j = n->outs(); n->has_out(j); j++) {\n+          Node* u = n->out(j);\n+          if (u->is_Phi()) {\n+            igvn->replace_node(u, top);\n+            if (max != n->outcnt()) {\n+              progress = true;\n+              j = n->refresh_out_pos(j);\n+              max = n->outcnt();\n+            }\n+          }\n+        }\n+      }\n+    }\n+    igvn->replace_node(n, top);\n+  }\n@@ -805,2 +883,2 @@\n-  Node* region = NULL;\n-  if (req() == 3 && in(1) != NULL && in(2) != NULL) {\n+  Node* region = nullptr;\n+  if (req() == 3 && in(1) != nullptr && in(2) != nullptr) {\n@@ -810,1 +888,1 @@\n-    if (region == NULL || region->outcnt() != 2 || region->req() != 3) {\n+    if (region == nullptr || region->outcnt() != 2 || region->req() != 3) {\n@@ -817,1 +895,1 @@\n-    if (phi == NULL) {\n+    if (phi == nullptr) {\n@@ -832,1 +910,1 @@\n-  if (region == NULL || region->in(idx1) == NULL || region->in(idx2) == NULL) {\n+  if (region == nullptr || region->in(idx1) == nullptr || region->in(idx2) == nullptr) {\n@@ -839,2 +917,2 @@\n-  if (proj1 == NULL || proj1->outcnt() != 1 ||\n-      proj2 == NULL || proj2->outcnt() != 1) {\n+  if (proj1 == nullptr || proj1->outcnt() != 1 ||\n+      proj2 == nullptr || proj2->outcnt() != 1) {\n@@ -846,2 +924,2 @@\n-  if (iff1 == NULL || iff1->outcnt() != 2 ||\n-      iff2 == NULL || iff2->outcnt() != 2) {\n+  if (iff1 == nullptr || iff1->outcnt() != 2 ||\n+      iff2 == nullptr || iff2->outcnt() != 2) {\n@@ -858,1 +936,1 @@\n-  if (bol1 == NULL || bol2 == NULL) {\n+  if (bol1 == nullptr || bol2 == nullptr) {\n@@ -922,0 +1000,16 @@\n+#ifndef PRODUCT\n+void RegionNode::dump_spec(outputStream* st) const {\n+  Node::dump_spec(st);\n+  switch (loop_status()) {\n+  case RegionNode::LoopStatus::MaybeIrreducibleEntry:\n+    st->print(\"#irreducible \");\n+    break;\n+  case RegionNode::LoopStatus::Reducible:\n+    st->print(\"#reducible \");\n+    break;\n+  case RegionNode::LoopStatus::NeverIrreducibleEntry:\n+    break; \/\/ nothing\n+  }\n+}\n+#endif\n+\n@@ -929,1 +1023,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -944,1 +1038,1 @@\n-  if (at == NULL || at == TypePtr::BOTTOM)  return at;\n+  if (at == nullptr || at == TypePtr::BOTTOM)  return at;\n@@ -956,1 +1050,1 @@\n-    if (r->in(j) != NULL)\n+    if (r->in(j) != nullptr)\n@@ -963,1 +1057,1 @@\n-  const TypePtr* at = NULL;\n+  const TypePtr* at = nullptr;\n@@ -969,1 +1063,1 @@\n-  const TypePtr* at = NULL;\n+  const TypePtr* at = nullptr;\n@@ -992,9 +1086,1 @@\n-  assert(t_oop != NULL && t_oop->is_known_instance(), \"expecting instance oopptr\");\n-  const TypePtr *t = adr_type();\n-  assert(type() == Type::MEMORY &&\n-         (t == TypePtr::BOTTOM || t == TypeRawPtr::BOTTOM ||\n-          t->isa_oopptr() && !t->is_oopptr()->is_known_instance() &&\n-          t->is_oopptr()->cast_to_exactness(true)\n-           ->is_oopptr()->cast_to_ptr_type(t_oop->ptr())\n-           ->is_oopptr()->cast_to_instance_id(t_oop->instance_id()) == t_oop),\n-         \"bottom or raw memory required\");\n+  assert(t_oop != nullptr && t_oop->is_known_instance(), \"expecting instance oopptr\");\n@@ -1029,1 +1115,1 @@\n-      if (in == NULL || igvn->type(in) == Type::TOP)\n+      if (in == nullptr || igvn->type(in) == Type::TOP)\n@@ -1031,3 +1117,3 @@\n-      Node *opt = MemNode::optimize_simple_memory_chain(in, t_oop, NULL, igvn);\n-      PhiNode *optphi = opt->is_Phi() ? opt->as_Phi() : NULL;\n-      if (optphi != NULL && optphi->adr_type() == TypePtr::BOTTOM) {\n+      Node *opt = MemNode::optimize_simple_memory_chain(in, t_oop, nullptr, igvn);\n+      PhiNode *optphi = opt->is_Phi() ? opt->as_Phi() : nullptr;\n+      if (optphi != nullptr && optphi->adr_type() == TypePtr::BOTTOM) {\n@@ -1035,1 +1121,1 @@\n-        if (opt == NULL) {\n+        if (opt == nullptr) {\n@@ -1066,1 +1152,1 @@\n-    if (n == NULL)  continue;\n+    if (n == nullptr)  continue;\n@@ -1076,1 +1162,1 @@\n-      assert((nat != NULL) == (at != NULL), \"\");\n+      assert((nat != nullptr) == (at != nullptr), \"\");\n@@ -1088,1 +1174,1 @@\n-  assert((_type == Type::MEMORY) == (_adr_type != NULL), \"adr_type for memory phis only\");\n+  assert((_type == Type::MEMORY) == (_adr_type != nullptr), \"adr_type for memory phis only\");\n@@ -1092,1 +1178,1 @@\n-  assert(_adr_type == NULL || _adr_type->isa_aryptr() == NULL ||\n+  assert(_adr_type == nullptr || _adr_type->isa_aryptr() == nullptr ||\n@@ -1124,1 +1210,1 @@\n-  BaseCountedLoopNode* l = r->is_BaseCountedLoop() ? r->as_BaseCountedLoop() : NULL;\n+  BaseCountedLoopNode* l = r->is_BaseCountedLoop() ? r->as_BaseCountedLoop() : nullptr;\n@@ -1126,1 +1212,1 @@\n-    \/\/ protect against init_trip() or limit() returning NULL\n+    \/\/ protect against init_trip() or limit() returning null\n@@ -1131,1 +1217,1 @@\n-      if (init != NULL && limit != NULL && stride != NULL) {\n+      if (init != nullptr && limit != nullptr && stride != nullptr) {\n@@ -1135,1 +1221,1 @@\n-        if (lo != NULL && hi != NULL && stride_t != NULL) { \/\/ Dying loops might have TOP here\n+        if (lo != nullptr && hi != nullptr && stride_t != nullptr) { \/\/ Dying loops might have TOP here\n@@ -1189,2 +1275,2 @@\n-    } else if (l->in(LoopNode::LoopBackControl) != NULL &&\n-               in(LoopNode::EntryControl) != NULL &&\n+    } else if (l->in(LoopNode::LoopBackControl) != nullptr &&\n+               in(LoopNode::EntryControl) != nullptr &&\n@@ -1200,16 +1286,0 @@\n-  \/\/ Until we have harmony between classes and interfaces in the type\n-  \/\/ lattice, we must tread carefully around phis which implicitly\n-  \/\/ convert the one to the other.\n-  const TypePtr* ttp = _type->make_ptr();\n-  const TypeInstPtr* ttip = (ttp != NULL) ? ttp->isa_instptr() : NULL;\n-  const TypeInstKlassPtr* ttkp = (ttp != NULL) ? ttp->isa_instklassptr() : NULL;\n-  bool is_intf = false;\n-  if (ttip != NULL) {\n-    if (ttip->is_interface())\n-      is_intf = true;\n-  }\n-  if (ttkp != NULL) {\n-    if (ttkp->is_interface())\n-      is_intf = true;\n-  }\n-\n@@ -1222,14 +1292,0 @@\n-      \/\/ We assume that each input of an interface-valued Phi is a true\n-      \/\/ subtype of that interface.  This might not be true of the meet\n-      \/\/ of all the input types.  The lattice is not distributive in\n-      \/\/ such cases.  Ward off asserts in type.cpp by refusing to do\n-      \/\/ meets between interfaces and proper classes.\n-      const TypePtr* tip = ti->make_ptr();\n-      const TypeInstPtr* tiip = (tip != NULL) ? tip->isa_instptr() : NULL;\n-      if (tiip) {\n-        bool ti_is_intf = false;\n-        if (tiip->is_interface())\n-          ti_is_intf = true;\n-        if (is_intf != ti_is_intf)\n-          { t = _type; break; }\n-      }\n@@ -1259,25 +1315,3 @@\n-\n-    \/\/ Check for evil case of 't' being a class and '_type' expecting an\n-    \/\/ interface.  This can happen because the bytecodes do not contain\n-    \/\/ enough type info to distinguish a Java-level interface variable\n-    \/\/ from a Java-level object variable.  If we meet 2 classes which\n-    \/\/ both implement interface I, but their meet is at 'j\/l\/O' which\n-    \/\/ doesn't implement I, we have no way to tell if the result should\n-    \/\/ be 'I' or 'j\/l\/O'.  Thus we'll pick 'j\/l\/O'.  If this then flows\n-    \/\/ into a Phi which \"knows\" it's an Interface type we'll have to\n-    \/\/ uplift the type.\n-    if (!t->empty() && ttip && ttip->is_interface()) {\n-      assert(ft == _type, \"\"); \/\/ Uplift to interface\n-    } else if (!t->empty() && ttkp && ttkp->is_interface()) {\n-      assert(ft == _type, \"\"); \/\/ Uplift to interface\n-    } else {\n-      \/\/ We also have to handle 'evil cases' of interface- vs. class-arrays\n-      Type::get_arrays_base_elements(jt, _type, NULL, &ttip);\n-      if (!t->empty() && ttip != NULL && ttip->is_interface()) {\n-          assert(ft == _type, \"\");   \/\/ Uplift to array of interface\n-      } else {\n-        \/\/ Otherwise it's something stupid like non-overlapping int ranges\n-        \/\/ found on dying counted loops.\n-        assert(ft == Type::TOP, \"\"); \/\/ Canonical empty value\n-      }\n-    }\n+    \/\/ Otherwise it's something stupid like non-overlapping int ranges\n+    \/\/ found on dying counted loops.\n+    assert(ft == Type::TOP, \"\"); \/\/ Canonical empty value\n@@ -1288,25 +1322,0 @@\n-    \/\/ If we have an interface-typed Phi and we narrow to a class type, the join\n-    \/\/ should report back the class.  However, if we have a J\/L\/Object\n-    \/\/ class-typed Phi and an interface flows in, it's possible that the meet &\n-    \/\/ join report an interface back out.  This isn't possible but happens\n-    \/\/ because the type system doesn't interact well with interfaces.\n-    const TypePtr *jtp = jt->make_ptr();\n-    const TypeInstPtr *jtip = (jtp != NULL) ? jtp->isa_instptr() : NULL;\n-    const TypeInstKlassPtr *jtkp = (jtp != NULL) ? jtp->isa_instklassptr() : NULL;\n-    if (jtip && ttip) {\n-      if (jtip->is_interface() &&\n-          !ttip->is_interface()) {\n-        assert(ft == ttip->cast_to_ptr_type(jtip->ptr()) ||\n-               ft->isa_narrowoop() && ft->make_ptr() == ttip->cast_to_ptr_type(jtip->ptr()), \"\");\n-        jt = ft;\n-      }\n-    }\n-    if (jtkp && ttkp) {\n-      if (jtkp->is_interface() &&\n-          !jtkp->klass_is_exact() && \/\/ Keep exact interface klass (6894807)\n-          ttkp->is_loaded() && !ttkp->is_interface()) {\n-        assert(ft == ttkp->cast_to_ptr_type(jtkp->ptr()) ||\n-               ft->isa_narrowklass() && ft->make_ptr() == ttkp->cast_to_ptr_type(jtkp->ptr()), \"\");\n-        jt = ft;\n-      }\n-    }\n@@ -1334,2 +1343,1 @@\n-  ft = phase->saturate(ft, phase->type_or_null(this), _type);\n-\n+  ft = phase->saturate_and_maybe_push_to_igvn_worklist(this, ft);\n@@ -1395,2 +1403,2 @@\n-  if (id == NULL)\n-    return NULL;\n+  if (id == nullptr)\n+    return nullptr;\n@@ -1402,1 +1410,1 @@\n-  if (ctl != NULL && ctl->in(0) == iff) {\n+  if (ctl != nullptr && ctl->in(0) == iff) {\n@@ -1407,1 +1415,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -1417,0 +1425,3 @@\n+  if (must_wait_for_region_in_irreducible_loop(phase)) {\n+    return this;\n+  }\n@@ -1423,1 +1434,1 @@\n-  if (uin != NULL) {\n+  if (uin != nullptr) {\n@@ -1431,1 +1442,1 @@\n-    if (id != NULL) {\n+    if (id != nullptr) {\n@@ -1438,1 +1449,1 @@\n-    if (m != NULL) {\n+    if (m != nullptr) {\n@@ -1457,1 +1468,1 @@\n-            u = NULL;\n+            u = nullptr;\n@@ -1461,1 +1472,1 @@\n-        if (u != NULL) {\n+        if (u != nullptr) {\n@@ -1487,1 +1498,1 @@\n-  Node* input = NULL; \/\/ The unique direct input (maybe uncasted = ConstraintCasts removed)\n+  Node* input = nullptr; \/\/ The unique direct input (maybe uncasted = ConstraintCasts removed)\n@@ -1491,1 +1502,1 @@\n-    if (rc == NULL || phase->type(rc) == Type::TOP)\n+    if (rc == nullptr || phase->type(rc) == Type::TOP)\n@@ -1494,1 +1505,1 @@\n-    if (n == NULL)\n+    if (n == nullptr)\n@@ -1501,1 +1512,1 @@\n-      while (un != NULL && un->req() == 2 && un->is_ConstraintCast()) {\n+      while (un != nullptr && un->req() == 2 && un->is_ConstraintCast()) {\n@@ -1511,1 +1522,1 @@\n-    if (un == NULL || un == this || phase->type(un) == Type::TOP) {\n+    if (un == nullptr || un == this || phase->type(un) == Type::TOP) {\n@@ -1515,1 +1526,1 @@\n-    if (input == NULL) {\n+    if (input == nullptr) {\n@@ -1521,1 +1532,1 @@\n-  if (input == NULL) {\n+  if (input == nullptr) {\n@@ -1530,1 +1541,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1560,1 +1571,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -1567,1 +1578,1 @@\n-    } else return NULL;\n+    } else return nullptr;\n@@ -1571,2 +1582,2 @@\n-    } else return NULL;\n-  } else return NULL;\n+    } else return nullptr;\n+  } else return nullptr;\n@@ -1578,1 +1589,1 @@\n-  } else return NULL;\n+  } else return nullptr;\n@@ -1607,1 +1618,1 @@\n-  if (region->has_unique_phi() != phi)  return NULL;\n+  if (region->has_unique_phi() != phi)  return nullptr;\n@@ -1611,2 +1622,2 @@\n-  if (region->in(1)->outcnt() != 1) return NULL;\n-  if (region->in(2)->outcnt() != 1) return NULL;\n+  if (region->in(1)->outcnt() != 1) return nullptr;\n+  if (region->in(2)->outcnt() != 1) return nullptr;\n@@ -1615,2 +1626,2 @@\n-  if (b->_test._test != BoolTest::lt)  return NULL;\n-  if (cmp->Opcode() != Op_CmpI)        return NULL;\n+  if (b->_test._test != BoolTest::lt)  return nullptr;\n+  if (cmp->Opcode() != Op_CmpI)        return nullptr;\n@@ -1629,1 +1640,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1632,1 +1643,1 @@\n-  Node *y = NULL;\n+  Node *y = nullptr;\n@@ -1637,1 +1648,1 @@\n-  } else return NULL;\n+  } else return nullptr;\n@@ -1641,1 +1652,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1672,1 +1683,1 @@\n-    default:           return NULL;                              break;\n+    default:           return nullptr;                           break;\n@@ -1680,1 +1691,1 @@\n-    default:           return NULL;                              break;\n+    default:           return nullptr;                           break;\n@@ -1685,1 +1696,1 @@\n-  const Type *tzero = NULL;\n+  const Type *tzero = nullptr;\n@@ -1691,1 +1702,1 @@\n-  default: return NULL;\n+  default: return nullptr;\n@@ -1695,1 +1706,1 @@\n-  Node *x = NULL;\n+  Node *x = nullptr;\n@@ -1704,1 +1715,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1709,1 +1720,1 @@\n-  if( phi_root->in(phi_x_idx) != x ) return NULL;\n+  if( phi_root->in(phi_x_idx) != x ) return nullptr;\n@@ -1718,1 +1729,1 @@\n-  if (!is_sub || phase->type(sub->in(1)) != tzero || sub->in(2) != x) return NULL;\n+  if (!is_sub || phase->type(sub->in(1)) != tzero || sub->in(2) != x) return nullptr;\n@@ -1740,1 +1751,1 @@\n-  } else return NULL;\n+  } else return nullptr;\n@@ -1772,0 +1783,12 @@\n+  \/\/ This optimization tries to find two or more inputs of phi with the same constant value\n+  \/\/ It then splits them into a separate Phi, and according Region. If this is a loop-entry,\n+  \/\/ and the loop entry has multiple fall-in edges, and some of those fall-in edges have that\n+  \/\/ constant, and others not, we may split the fall-in edges into separate Phi's, and create\n+  \/\/ an irreducible loop. For reducible loops, this never seems to happen, as the multiple\n+  \/\/ fall-in edges are already merged before the loop head during parsing. But with irreducible\n+  \/\/ loops present the order or merging during parsing can sometimes prevent this.\n+  if (phase->C->has_irreducible_loop()) {\n+    \/\/ Avoid this optimization if any irreducible loops are present. Else we may create\n+    \/\/ an irreducible loop that we do not detect.\n+    return nullptr;\n+  }\n@@ -1774,1 +1797,1 @@\n-    return NULL;                \/\/ Bail out on funny non-value stuff\n+    return nullptr;             \/\/ Bail out on funny non-value stuff\n@@ -1776,1 +1799,1 @@\n-    return NULL;                \/\/ third unequal input to be worth doing\n+    return nullptr;             \/\/ third unequal input to be worth doing\n@@ -1782,2 +1805,2 @@\n-    if( !n ) return NULL;\n-    if( phase->type(n) == Type::TOP ) return NULL;\n+    if( !n ) return nullptr;\n+    if( phase->type(n) == Type::TOP ) return nullptr;\n@@ -1788,1 +1811,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1796,2 +1819,2 @@\n-    if( !n ) return NULL;\n-    if( phase->type(n) == Type::TOP ) return NULL;\n+    if( !n ) return nullptr;\n+    if( phase->type(n) == Type::TOP ) return nullptr;\n@@ -1800,2 +1823,2 @@\n-      if (PhaseIdealLoop::find_predicate(r->in(i)) != NULL) {\n-        return NULL;            \/\/ don't split loop entry path\n+      if (PhaseIdealLoop::find_parse_predicate(r->in(i)) != nullptr) {\n+        return nullptr;            \/\/ don't split loop entry path\n@@ -1808,1 +1831,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1861,1 +1884,1 @@\n-  if (in != NULL && !in->is_dead_loop_safe()) {\n+  if (in != nullptr && !in->is_dead_loop_safe()) {\n@@ -1870,1 +1893,1 @@\n-      if (m != NULL && !m->is_dead_loop_safe()) {\n+      if (m != nullptr && !m->is_dead_loop_safe()) {\n@@ -1873,1 +1896,1 @@\n-        Node *m1 = (m->is_AddP() && m->req() > 3) ? m->in(1) : NULL;\n+        Node *m1 = (m->is_AddP() && m->req() > 3) ? m->in(1) : nullptr;\n@@ -1876,1 +1899,1 @@\n-        if (m1 != NULL && m1 == m->in(2) &&\n+        if (m1 != nullptr && m1 == m->in(2) &&\n@@ -1919,1 +1942,1 @@\n-      if (m != NULL && !m->is_dead_loop_safe()) { \/\/ Only look for unsafe cases.\n+      if (m != nullptr && !m->is_dead_loop_safe()) { \/\/ Only look for unsafe cases.\n@@ -1938,1 +1961,1 @@\n-    if (rc != NULL &&\n+    if (rc != nullptr &&\n@@ -1942,1 +1965,1 @@\n-      } else if (rc->in(0) != NULL &&\n+      } else if (rc->in(0) != nullptr &&\n@@ -1946,1 +1969,1 @@\n-        } else if (rc->in(0)->in(1) != NULL &&\n+        } else if (rc->in(0)->in(1) != nullptr &&\n@@ -1950,1 +1973,1 @@\n-          } else if (rc->in(0)->in(1)->in(1) != NULL &&\n+          } else if (rc->in(0)->in(1)->in(1) != nullptr &&\n@@ -2010,0 +2033,25 @@\n+\/\/ If the Phi's Region is in an irreducible loop, and the Region\n+\/\/ has had an input removed, but not yet transformed, it could be\n+\/\/ that the Region (and this Phi) are not reachable from Root.\n+\/\/ If we allow the Phi to collapse before the Region, this may lead\n+\/\/ to dead-loop data. Wait for the Region to check for reachability,\n+\/\/ and potentially remove the dead code.\n+bool PhiNode::must_wait_for_region_in_irreducible_loop(PhaseGVN* phase) const {\n+  RegionNode* region = in(0)->as_Region();\n+  if (region->loop_status() == RegionNode::LoopStatus::MaybeIrreducibleEntry) {\n+    Node* top = phase->C->top();\n+    for (uint j = 1; j < req(); j++) {\n+      Node* rc = region->in(j); \/\/ for each control input\n+      if (rc == nullptr || phase->type(rc) == Type::TOP) {\n+        \/\/ Region is missing a control input\n+        Node* n = in(j);\n+        if (n != nullptr && n != top) {\n+          \/\/ Phi still has its input, so region just lost its input\n+          return true;\n+        }\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -2015,2 +2063,2 @@\n-  assert(r != NULL && r->is_Region(), \"this phi must have a region\");\n-  assert(r->in(0) == NULL || !r->in(0)->is_Root(), \"not a specially hidden merge\");\n+  assert(r != nullptr && r->is_Region(), \"this phi must have a region\");\n+  assert(r->in(0) == nullptr || !r->in(0)->is_Root(), \"not a specially hidden merge\");\n@@ -2021,1 +2069,1 @@\n-    return NULL;                \/\/ No change\n+    return nullptr;                \/\/ No change\n@@ -2027,1 +2075,5 @@\n-    return NULL;\n+    return nullptr;\n+\n+  if (must_wait_for_region_in_irreducible_loop(phase)) {\n+    return nullptr;\n+  }\n@@ -2034,1 +2086,1 @@\n-  Node* progress = NULL;        \/\/ Record if any progress made\n+  Node* progress = nullptr;        \/\/ Record if any progress made\n@@ -2039,1 +2091,1 @@\n-    if (rc == NULL || phase->type(rc) == Type::TOP) {\n+    if (rc == nullptr || phase->type(rc) == Type::TOP) {\n@@ -2042,1 +2094,1 @@\n-        if (can_reshape && igvn != NULL) {\n+        if (can_reshape && igvn != nullptr) {\n@@ -2060,1 +2112,1 @@\n-  if (uin == NULL && can_reshape &&\n+  if (uin == nullptr && can_reshape &&\n@@ -2071,3 +2123,3 @@\n-      return NULL;              \/\/ Identity will return TOP\n-  } else if (uin != NULL) {\n-    \/\/ Only one not-NULL unique input path is left.\n+      return nullptr;              \/\/ Identity will return TOP\n+  } else if (uin != nullptr) {\n+    \/\/ Only one not-null unique input path is left.\n@@ -2076,1 +2128,1 @@\n-    if (outcnt() > 0 && r->in(0) != NULL) {\n+    if (outcnt() > 0 && r->in(0) != nullptr) {\n@@ -2085,1 +2137,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -2097,1 +2149,1 @@\n-      Node* cast = NULL;\n+      Node* cast = nullptr;\n@@ -2119,1 +2171,1 @@\n-            if (cast != NULL) {\n+            if (cast != nullptr) {\n@@ -2125,1 +2177,1 @@\n-          if (cast == NULL) {\n+          if (cast == nullptr) {\n@@ -2132,1 +2184,1 @@\n-      assert(cast != NULL, \"cast should be set\");\n+      assert(cast != nullptr, \"cast should be set\");\n@@ -2146,1 +2198,1 @@\n-    if (ident != uin && !ident->is_top()) {\n+    if (ident != uin && !ident->is_top() && !must_wait_for_region_in_irreducible_loop(phase)) {\n@@ -2154,2 +2206,3 @@\n-    assert(ident == uin || ident->is_top(), \"Identity must clean this up\");\n-    return NULL;\n+    \/\/ Identity may not return the expected uin, if it has to wait for the region, in irreducible case\n+    assert(ident == uin || ident->is_top() || must_wait_for_region_in_irreducible_loop(phase), \"Identity must clean this up\");\n+    return nullptr;\n@@ -2158,1 +2211,1 @@\n-  Node* opt = NULL;\n+  Node* opt = nullptr;\n@@ -2168,1 +2221,1 @@\n-    if( unsafe_id != NULL && is_unsafe_data_reference(unsafe_id) )\n+    if( unsafe_id != nullptr && is_unsafe_data_reference(unsafe_id) )\n@@ -2172,1 +2225,1 @@\n-    if( opt == NULL )\n+    if( opt == nullptr )\n@@ -2176,1 +2229,1 @@\n-    if( opt == NULL )\n+    if( opt == nullptr )\n@@ -2180,1 +2233,1 @@\n-    if( opt == NULL && can_reshape )\n+    if( opt == nullptr && can_reshape )\n@@ -2185,1 +2238,1 @@\n-    if( opt != NULL ) {\n+    if( opt != nullptr ) {\n@@ -2195,1 +2248,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2206,2 +2259,2 @@\n-    assert(opt == NULL || opt == this, \"do not elide phi\");\n-    if (opt != NULL)  return opt;\n+    assert(opt == nullptr || opt == this, \"do not elide phi\");\n+    if (opt != nullptr)  return opt;\n@@ -2210,1 +2263,1 @@\n-  if (in(1) != NULL && in(1)->Opcode() == Op_AddP && can_reshape) {\n+  if (in(1) != nullptr && in(1)->Opcode() == Op_AddP && can_reshape) {\n@@ -2226,1 +2279,1 @@\n-    if (base != NULL && address != NULL && offset != NULL &&\n+    if (base != nullptr && address != nullptr && offset != nullptr &&\n@@ -2234,1 +2287,1 @@\n-        if (in(i) == NULL ||\n+        if (in(i) == nullptr ||\n@@ -2236,3 +2289,3 @@\n-            in(i)->in(AddPNode::Base) == NULL ||\n-            in(i)->in(AddPNode::Address) == NULL ||\n-            in(i)->in(AddPNode::Offset) == NULL ||\n+            in(i)->in(AddPNode::Base) == nullptr ||\n+            in(i)->in(AddPNode::Address) == nullptr ||\n+            in(i)->in(AddPNode::Offset) == nullptr ||\n@@ -2246,1 +2299,1 @@\n-          base = NULL;\n+          base = nullptr;\n@@ -2249,1 +2302,1 @@\n-          offset = NULL;\n+          offset = nullptr;\n@@ -2252,1 +2305,1 @@\n-          address = NULL;\n+          address = nullptr;\n@@ -2258,1 +2311,1 @@\n-      if (doit && base == NULL) {\n+      if (doit && base == nullptr) {\n@@ -2265,2 +2318,2 @@\n-            if (base2 != NULL && !base2->is_top()) {\n-              if (base == NULL)\n+            if (base2 != nullptr && !base2->is_top()) {\n+              if (base == nullptr)\n@@ -2275,2 +2328,2 @@\n-        if (base == NULL) {\n-          base = new PhiNode(in(0), base_type, NULL);\n+        if (base == nullptr) {\n+          base = new PhiNode(in(0), base_type, nullptr);\n@@ -2282,2 +2335,2 @@\n-        if (address == NULL) {\n-          address = new PhiNode(in(0), address_type, NULL);\n+        if (address == nullptr) {\n+          address = new PhiNode(in(0), address_type, nullptr);\n@@ -2289,2 +2342,2 @@\n-        if (offset == NULL) {\n-          offset = new PhiNode(in(0), TypeX_X, NULL);\n+        if (offset == nullptr) {\n+          offset = new PhiNode(in(0), TypeX_X, nullptr);\n@@ -2307,1 +2360,1 @@\n-  if (progress == NULL && can_reshape && type() == Type::MEMORY) {\n+  if (progress == nullptr && can_reshape && type() == Type::MEMORY) {\n@@ -2319,1 +2372,1 @@\n-        return NULL; \/\/ Delay optimization until graph is cleaned.\n+        return nullptr; \/\/ Delay optimization until graph is cleaned.\n@@ -2390,1 +2443,1 @@\n-        assert(igvn != NULL, \"sanity check\");\n+        assert(igvn != nullptr, \"sanity check\");\n@@ -2455,1 +2508,1 @@\n-      Node *new_in = MemNode::optimize_memory_chain(ii, at, NULL, phase);\n+      Node *new_in = MemNode::optimize_memory_chain(ii, at, nullptr, phase);\n@@ -2466,1 +2519,1 @@\n-  if ((UseCompressedOops || UseCompressedClassPointers) && can_reshape && progress == NULL) {\n+  if ((UseCompressedOops || UseCompressedClassPointers) && can_reshape && progress == nullptr) {\n@@ -2496,1 +2549,1 @@\n-        Node* new_ii = NULL;\n+        Node* new_ii = nullptr;\n@@ -2528,1 +2581,1 @@\n-  if (EnableValhalla && (_type->isa_ptr() || _type->isa_inlinetype()) && req() > 2) {\n+  if (EnableValhalla && _type->isa_ptr() && req() > 2) {\n@@ -2533,1 +2586,1 @@\n-    ciInlineKlass* vk = NULL;\n+    ciInlineKlass* vk = nullptr;\n@@ -2538,4 +2591,1 @@\n-    \/\/ TODO 8284443 We need to prevent endless pushing through\n-    \/\/ TODO 8284443 We could revisit the same node over and over again, right?\n-    \/\/ TestLWorld -XX:+UseZGC -DScenarios=0 -DTest=test69\n-    \/\/ TestLWorld -XX:-TieredCompilation -XX:-DoEscapeAnalysis -XX:+AlwaysIncrementalInline\n+    \/\/ TODO 8302217 We need to prevent endless pushing through\n@@ -2560,1 +2610,1 @@\n-        if (n == NULL) {\n+        if (n == nullptr) {\n@@ -2565,1 +2615,1 @@\n-          if (n->in(0) != NULL && n->in(0)->is_top()) {\n+          if (n->in(0) != nullptr && n->in(0)->is_top()) {\n@@ -2584,2 +2634,6 @@\n-        if (n->is_InlineType() && !n->is_VectorBox() && (vk == NULL || vk == t->inline_klass())) {\n-          vk = (vk == NULL) ? t->inline_klass() : vk;\n+        if (n->is_VectorBox()) {\n+          can_optimize = false;\n+          break;\n+        }\n+        if (n->is_InlineType() && (vk == nullptr || vk == t->inline_klass())) {\n+          vk = (vk == nullptr) ? t->inline_klass() : vk;\n@@ -2589,1 +2643,1 @@\n-        } else if (n->is_Phi() && can_reshape && (n->bottom_type()->isa_ptr() || n->bottom_type()->isa_inlinetype())) {\n+        } else if (n->is_Phi() && can_reshape && n->bottom_type()->isa_ptr()) {\n@@ -2600,1 +2654,1 @@\n-    while (casts.size() != 0 && can_optimize && t != NULL) {\n+    while (casts.size() != 0 && can_optimize && t != nullptr) {\n@@ -2606,2 +2660,2 @@\n-    if (can_optimize && vk != NULL) {\n-\/\/ TODO 8275400\n+    if (can_optimize && vk != nullptr) {\n+\/\/ TODO 8302217\n@@ -2614,1 +2668,1 @@\n-  if (EnableVectorReboxing && can_reshape && progress == NULL && type()->isa_oopptr()) {\n+  if (EnableVectorReboxing && can_reshape && progress == nullptr && type()->isa_oopptr()) {\n@@ -2639,1 +2693,1 @@\n-      if (def == NULL) {\n+      if (def == nullptr) {\n@@ -2655,1 +2709,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2674,1 +2728,1 @@\n-  VectorBoxNode* cached_vbox = NULL;\n+  VectorBoxNode* cached_vbox = nullptr;\n@@ -2681,1 +2735,1 @@\n-      if (in == NULL) {\n+      if (in == nullptr) {\n@@ -2689,1 +2743,1 @@\n-        if (cached_vbox == NULL) {\n+        if (cached_vbox == nullptr) {\n@@ -2694,1 +2748,1 @@\n-          return NULL; \/\/ not optimizable: vector type mismatch\n+          return nullptr; \/\/ not optimizable: vector type mismatch\n@@ -2697,1 +2751,1 @@\n-          return NULL; \/\/ not optimizable: box type mismatch\n+          return nullptr; \/\/ not optimizable: box type mismatch\n@@ -2700,1 +2754,1 @@\n-        return NULL; \/\/ not optimizable: neither Phi nor VectorBox\n+        return nullptr; \/\/ not optimizable: neither Phi nor VectorBox\n@@ -2706,2 +2760,5 @@\n-\n-  assert(cached_vbox != NULL, \"sanity\");\n+  if (cached_vbox == nullptr) {\n+    \/\/ We have a Phi dead-loop (no data-input). Phi nodes are considered safe,\n+    \/\/ so just avoid this optimization.\n+    return nullptr;\n+  }\n@@ -2710,0 +2767,1 @@\n+  const Type*        ptype = cached_vbox->field_value(0)->bottom_type();\n@@ -2711,3 +2769,3 @@\n-  Node* new_payload_phi = clone_through_phi(root_phi, cached_vbox->field_value(0)->bottom_type(), 3, igvn);\n-  Node* new_vector_phi = clone_through_phi(new_payload_phi, vtype, 3, igvn);\n-  Node* new_vbox_phi = clone_through_phi(root_phi, btype, 1, igvn);\n+  Node* new_payload_phi = clone_through_phi(root_phi, ptype, InlineTypeNode::get_Values_idx(), igvn);\n+  Node* new_vector_phi = clone_through_phi(new_payload_phi, vtype, InlineTypeNode::get_Values_idx(), igvn);\n+  Node* new_vbox_phi = clone_through_phi(root_phi, btype, InlineTypeNode::get_Oop_idx(), igvn);\n@@ -2736,1 +2794,1 @@\n-  return (in(0) != NULL && in(0)->is_BaseCountedLoop() &&\n+  return (in(0) != nullptr && in(0)->is_BaseCountedLoop() &&\n@@ -2821,1 +2879,1 @@\n-  return remove_dead_region(phase, can_reshape) ? this : NULL;\n+  return remove_dead_region(phase, can_reshape) ? this : nullptr;\n@@ -2858,1 +2916,1 @@\n-  \/\/ () virtual or interface call with NULL receiver\n+  \/\/ () virtual or interface call with null receiver\n@@ -2916,1 +2974,1 @@\n-  \/\/ a NULL receiver to a v-call, or passing bad types to a slow-check-cast.\n+  \/\/ a null receiver to a v-call, or passing bad types to a slow-check-cast.\n@@ -2951,0 +3009,4 @@\n+  if (phase->type(in(0)->in(0)) == Type::TOP) {\n+    assert(in(0)->is_CatchProj(), \"control is CatchProj\");\n+    return phase->C->top(); \/\/ dead code\n+  }\n@@ -2981,1 +3043,1 @@\n-    if (fallthru != NULL) {\n+    if (fallthru != nullptr) {\n@@ -2986,1 +3048,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -3001,1 +3063,1 @@\n-    if (n != NULL && OptoReg::is_valid(ra->get_reg_first(n))) {\n+    if (n != nullptr && OptoReg::is_valid(ra->get_reg_first(n))) {\n@@ -3008,1 +3070,1 @@\n-      ra->dump_register(n, buf);\n+      ra->dump_register(n, buf, sizeof(buf));\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":447,"deletions":385,"binary":false,"changes":832,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -61,0 +61,4 @@\n+\/\/ The success projection of a Parse Predicate is always an IfTrueNode and the uncommon projection an IfFalseNode\n+typedef IfTrueNode ParsePredicateSuccessProj;\n+typedef IfFalseNode ParsePredicateUncommonProj;\n+\n@@ -68,0 +72,12 @@\n+public:\n+  enum LoopStatus {\n+    \/\/ No guarantee: the region may be an irreducible loop entry, thus we have to\n+    \/\/ be careful when removing entry control to it.\n+    MaybeIrreducibleEntry,\n+    \/\/ Limited guarantee: this region may be (nested) inside an irreducible loop,\n+    \/\/ but it will never be an irreducible loop entry.\n+    NeverIrreducibleEntry,\n+    \/\/ Strong guarantee: this region is not (nested) inside an irreducible loop.\n+    Reducible,\n+  };\n+\n@@ -70,0 +86,1 @@\n+  LoopStatus _loop_status;\n@@ -79,1 +96,5 @@\n-  RegionNode(uint required) : Node(required), _is_unreachable_region(false) {\n+  RegionNode(uint required)\n+    : Node(required),\n+      _is_unreachable_region(false),\n+      _loop_status(LoopStatus::NeverIrreducibleEntry)\n+  {\n@@ -86,1 +107,1 @@\n-    if (r == NULL)\n+    if (r == nullptr)\n@@ -88,1 +109,1 @@\n-    return NULL;  \/\/ not a copy!\n+    return nullptr;  \/\/ not a copy!\n@@ -90,2 +111,2 @@\n-  PhiNode* has_phi() const;        \/\/ returns an arbitrary phi user, or NULL\n-  PhiNode* has_unique_phi() const; \/\/ returns the unique phi user, or NULL\n+  PhiNode* has_phi() const;        \/\/ returns an arbitrary phi user, or null\n+  PhiNode* has_unique_phi() const; \/\/ returns the unique phi user, or null\n@@ -94,0 +115,8 @@\n+#ifdef ASSERT\n+  bool is_in_infinite_subgraph();\n+  static bool are_all_nodes_in_infinite_subgraph(Unique_Node_List& worklist);\n+#endif \/\/ASSERT\n+  LoopStatus loop_status() const { return _loop_status; };\n+  void set_loop_status(LoopStatus status);\n+  DEBUG_ONLY(void verify_can_be_irreducible_entry() const;)\n+\n@@ -104,0 +133,1 @@\n+  void remove_unreachable_subgraph(PhaseIterGVN* igvn);\n@@ -106,0 +136,1 @@\n+  NOT_PRODUCT(virtual void dump_spec(outputStream* st) const;)\n@@ -149,0 +180,2 @@\n+  bool must_wait_for_region_in_irreducible_loop(PhaseGVN* phase) const;\n+\n@@ -155,1 +188,1 @@\n-  PhiNode( Node *r, const Type *t, const TypePtr* at = NULL,\n+  PhiNode( Node *r, const Type *t, const TypePtr* at = nullptr,\n@@ -174,1 +207,1 @@\n-  static PhiNode* make( Node* r, Node* x, const Type *t, const TypePtr* at = NULL );\n+  static PhiNode* make( Node* r, Node* x, const Type *t, const TypePtr* at = nullptr );\n@@ -187,1 +220,1 @@\n-  \/\/ Ignore casts if it helps.  Return NULL on failure.\n+  \/\/ Ignore casts if it helps.  Return null on failure.\n@@ -191,1 +224,1 @@\n-    if (uin == NULL) {\n+    if (uin == nullptr) {\n@@ -402,1 +435,1 @@\n-  \/\/ Returns NULL is it couldn't improve the type.\n+  \/\/ Returns null is it couldn't improve the type.\n@@ -598,1 +631,4 @@\n-  NeverBranchNode( Node *ctrl ) : MultiBranchNode(1) { init_req(0,ctrl); }\n+  NeverBranchNode(Node* ctrl) : MultiBranchNode(1) {\n+    init_req(0, ctrl);\n+    init_class_id(Class_NeverBranch);\n+  }\n@@ -619,0 +655,1 @@\n+    init_class_id(Class_Blackhole);\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":49,"deletions":12,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -89,1 +89,1 @@\n-  if (_mach_constant_base_node == NULL) {\n+  if (_mach_constant_base_node == nullptr) {\n@@ -157,1 +157,1 @@\n-    if (cg != NULL) {\n+    if (cg != nullptr) {\n@@ -165,1 +165,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -232,1 +232,1 @@\n-  if (xtty != NULL)  xtty->head(\"statistics type='intrinsic'\");\n+  if (xtty != nullptr)  xtty->head(\"statistics type='intrinsic'\");\n@@ -246,1 +246,1 @@\n-  if (xtty != NULL)  xtty->tail(\"statistics\");\n+  if (xtty != nullptr)  xtty->tail(\"statistics\");\n@@ -251,1 +251,1 @@\n-    if (xtty != NULL)  xtty->head(\"statistics type='opto'\");\n+    if (xtty != nullptr)  xtty->head(\"statistics type='opto'\");\n@@ -261,1 +261,1 @@\n-    if (xtty != NULL)  xtty->tail(\"statistics\");\n+    if (xtty != nullptr)  xtty->tail(\"statistics\");\n@@ -299,1 +299,1 @@\n-  useful.map( estimated_worklist_size, NULL );  \/\/ preallocate space\n+  useful.map( estimated_worklist_size, nullptr );  \/\/ preallocate space\n@@ -302,1 +302,1 @@\n-  if (root() != NULL)     { useful.push(root()); }\n+  if (root() != nullptr)  { useful.push(root()); }\n@@ -304,1 +304,1 @@\n-  if( cached_top_node() ) { useful.push(cached_top_node()); }\n+  if (cached_top_node())  { useful.push(cached_top_node()); }\n@@ -352,1 +352,1 @@\n-  assert(dead != NULL && dead->is_Call(), \"sanity\");\n+  assert(dead != nullptr && dead->is_Call(), \"sanity\");\n@@ -391,1 +391,1 @@\n-    remove_skeleton_predicate_opaq(dead);\n+    remove_template_assertion_predicate_opaq(dead);\n@@ -445,2 +445,2 @@\n-  remove_useless_nodes(_predicate_opaqs,    useful); \/\/ remove useless predicate opaque nodes\n-  remove_useless_nodes(_skeleton_predicate_opaqs, useful);\n+  remove_useless_nodes(_parse_predicate_opaqs, useful); \/\/ remove useless Parse Predicate opaque nodes\n+  remove_useless_nodes(_template_assertion_predicate_opaqs, useful); \/\/ remove useless Assertion Predicate opaque nodes\n@@ -451,1 +451,1 @@\n-  if (_modified_nodes != NULL) {\n+  if (_modified_nodes != nullptr) {\n@@ -458,1 +458,1 @@\n-  if (_modified_nodes != NULL) {\n+  if (_modified_nodes != nullptr) {\n@@ -487,1 +487,1 @@\n-  assert(env->compiler_data() == NULL, \"compile already active?\");\n+  assert(env->compiler_data() == nullptr, \"compile already active?\");\n@@ -491,1 +491,1 @@\n-  compile->set_type_dict(NULL);\n+  compile->set_type_dict(nullptr);\n@@ -495,3 +495,3 @@\n-  compile->set_last_tf(NULL, NULL);\n-  compile->set_indexSet_arena(NULL);\n-  compile->set_indexSet_free_block_list(NULL);\n+  compile->set_last_tf(nullptr, nullptr);\n+  compile->set_indexSet_arena(nullptr);\n+  compile->set_indexSet_free_block_list(nullptr);\n@@ -508,1 +508,1 @@\n-  _compile->env()->set_compiler_data(NULL);\n+  _compile->env()->set_compiler_data(nullptr);\n@@ -571,1 +571,1 @@\n-  if (xtty != NULL) {\n+  if (xtty != nullptr) {\n@@ -586,1 +586,1 @@\n-  if (xtty != NULL) {\n+  if (xtty != nullptr) {\n@@ -594,1 +594,0 @@\n-debug_only( int Compile::_debug_idx = 100000; )\n@@ -607,4 +606,4 @@\n-                  _ilt(NULL),\n-                  _stub_function(NULL),\n-                  _stub_name(NULL),\n-                  _stub_entry_point(NULL),\n+                  _ilt(nullptr),\n+                  _stub_function(nullptr),\n+                  _stub_name(nullptr),\n+                  _stub_entry_point(nullptr),\n@@ -617,0 +616,1 @@\n+                  _has_circular_inline_type(false),\n@@ -629,12 +629,12 @@\n-                  _failure_reason(NULL),\n-                  _intrinsics        (comp_arena(), 0, 0, NULL),\n-                  _macro_nodes       (comp_arena(), 8, 0, NULL),\n-                  _predicate_opaqs   (comp_arena(), 8, 0, NULL),\n-                  _skeleton_predicate_opaqs (comp_arena(), 8, 0, NULL),\n-                  _expensive_nodes   (comp_arena(), 8, 0, NULL),\n-                  _for_post_loop_igvn(comp_arena(), 8, 0, NULL),\n-                  _inline_type_nodes (comp_arena(), 8, 0, NULL),\n-                  _unstable_if_traps (comp_arena(), 8, 0, NULL),\n-                  _coarsened_locks   (comp_arena(), 8, 0, NULL),\n-                  _congraph(NULL),\n-                  NOT_PRODUCT(_igv_printer(NULL) COMMA)\n+                  _failure_reason(nullptr),\n+                  _intrinsics        (comp_arena(), 0, 0, nullptr),\n+                  _macro_nodes       (comp_arena(), 8, 0, nullptr),\n+                  _parse_predicate_opaqs (comp_arena(), 8, 0, nullptr),\n+                  _template_assertion_predicate_opaqs (comp_arena(), 8, 0, nullptr),\n+                  _expensive_nodes   (comp_arena(), 8, 0, nullptr),\n+                  _for_post_loop_igvn(comp_arena(), 8, 0, nullptr),\n+                  _inline_type_nodes (comp_arena(), 8, 0, nullptr),\n+                  _unstable_if_traps (comp_arena(), 8, 0, nullptr),\n+                  _coarsened_locks   (comp_arena(), 8, 0, nullptr),\n+                  _congraph(nullptr),\n+                  NOT_PRODUCT(_igv_printer(nullptr) COMMA)\n@@ -645,1 +645,1 @@\n-                  _mach_constant_base_node(NULL),\n+                  _mach_constant_base_node(nullptr),\n@@ -647,6 +647,6 @@\n-                  _initial_gvn(NULL),\n-                  _for_igvn(NULL),\n-                  _late_inlines(comp_arena(), 2, 0, NULL),\n-                  _string_late_inlines(comp_arena(), 2, 0, NULL),\n-                  _boxing_late_inlines(comp_arena(), 2, 0, NULL),\n-                  _vector_reboxing_late_inlines(comp_arena(), 2, 0, NULL),\n+                  _initial_gvn(nullptr),\n+                  _for_igvn(nullptr),\n+                  _late_inlines(comp_arena(), 2, 0, nullptr),\n+                  _string_late_inlines(comp_arena(), 2, 0, nullptr),\n+                  _boxing_late_inlines(comp_arena(), 2, 0, nullptr),\n+                  _vector_reboxing_late_inlines(comp_arena(), 2, 0, nullptr),\n@@ -656,1 +656,1 @@\n-                  _print_inlining_list(NULL),\n+                  _print_inlining_list(nullptr),\n@@ -658,2 +658,2 @@\n-                  _print_inlining_output(NULL),\n-                  _replay_inline_data(NULL),\n+                  _print_inlining_output(nullptr),\n+                  _replay_inline_data(nullptr),\n@@ -663,1 +663,1 @@\n-                  _output(NULL)\n+                  _output(nullptr)\n@@ -679,1 +679,1 @@\n-  TraceTime t2(NULL, &_t_methodCompilation, CITime, false);\n+  TraceTime t2(nullptr, &_t_methodCompilation, CITime, false);\n@@ -739,1 +739,1 @@\n-    CallGenerator* cg = NULL;\n+    CallGenerator* cg = nullptr;\n@@ -760,1 +760,1 @@\n-      if (cg == NULL) {\n+      if (cg == nullptr) {\n@@ -767,2 +767,6 @@\n-    if (cg == NULL) {\n-      record_method_not_compilable(\"cannot parse method\");\n+    if (cg == nullptr) {\n+      const char* reason = InlineTree::check_can_parse(method());\n+      assert(reason != nullptr, \"expect reason for parse failure\");\n+      stringStream ss;\n+      ss.print(\"cannot parse method: %s\", reason);\n+      record_method_not_compilable(ss.as_string());\n@@ -771,0 +775,3 @@\n+\n+    gvn.set_type(root(), root()->bottom_type());\n+\n@@ -772,1 +779,1 @@\n-    if ((jvms = cg->generate(jvms)) == NULL) {\n+    if ((jvms = cg->generate(jvms)) == nullptr) {\n@@ -774,1 +781,4 @@\n-        record_method_not_compilable(\"method parse failed\");\n+        assert(failure_reason() != nullptr, \"expect reason for parse failure\");\n+        stringStream ss;\n+        ss.print(\"method parse failed: %s\", failure_reason());\n+        record_method_not_compilable(ss.as_string());\n@@ -816,1 +826,1 @@\n-  set_default_node_notes(NULL);\n+  set_default_node_notes(nullptr);\n@@ -836,1 +846,1 @@\n-    if (_log != NULL) {\n+    if (_log != nullptr) {\n@@ -861,1 +871,1 @@\n-  if (directive->DumpInlineOption && (ilt() != NULL)) {\n+  if (directive->DumpInlineOption && (ilt() != nullptr)) {\n@@ -901,1 +911,1 @@\n-    _method(NULL),\n+    _method(nullptr),\n@@ -905,1 +915,1 @@\n-    _stub_entry_point(NULL),\n+    _stub_entry_point(nullptr),\n@@ -911,0 +921,1 @@\n+    _has_circular_inline_type(false),\n@@ -923,3 +934,3 @@\n-    _failure_reason(NULL),\n-    _congraph(NULL),\n-    NOT_PRODUCT(_igv_printer(NULL) COMMA)\n+    _failure_reason(nullptr),\n+    _congraph(nullptr),\n+    NOT_PRODUCT(_igv_printer(nullptr) COMMA)\n@@ -930,1 +941,1 @@\n-    _mach_constant_base_node(NULL),\n+    _mach_constant_base_node(nullptr),\n@@ -932,2 +943,2 @@\n-    _initial_gvn(NULL),\n-    _for_igvn(NULL),\n+    _initial_gvn(nullptr),\n+    _for_igvn(nullptr),\n@@ -936,1 +947,1 @@\n-    _print_inlining_list(NULL),\n+    _print_inlining_list(nullptr),\n@@ -938,2 +949,2 @@\n-    _print_inlining_output(NULL),\n-    _replay_inline_data(NULL),\n+    _print_inlining_output(nullptr),\n+    _replay_inline_data(nullptr),\n@@ -943,1 +954,1 @@\n-    _output(NULL),\n+    _output(nullptr),\n@@ -950,2 +961,2 @@\n-  TraceTime t1(NULL, &_t_totalCompilation, CITime, false);\n-  TraceTime t2(NULL, &_t_stubCompilation, CITime, false);\n+  TraceTime t1(nullptr, &_t_totalCompilation, CITime, false);\n+  TraceTime t2(nullptr, &_t_stubCompilation, CITime, false);\n@@ -987,1 +998,1 @@\n-  _regalloc = NULL;\n+  _regalloc = nullptr;\n@@ -989,4 +1000,4 @@\n-  _tf      = NULL;  \/\/ filled in later\n-  _top     = NULL;  \/\/ cached later\n-  _matcher = NULL;  \/\/ filled in later\n-  _cfg     = NULL;  \/\/ filled in later\n+  _tf      = nullptr;  \/\/ filled in later\n+  _top     = nullptr;  \/\/ cached later\n+  _matcher = nullptr;  \/\/ filled in later\n+  _cfg     = nullptr;  \/\/ filled in later\n@@ -996,3 +1007,5 @@\n-  _node_note_array = NULL;\n-  _default_node_notes = NULL;\n-  DEBUG_ONLY( _modified_nodes = NULL; ) \/\/ Used in Optimize()\n+  _node_note_array = nullptr;\n+  _default_node_notes = nullptr;\n+  DEBUG_ONLY( _modified_nodes = nullptr; ) \/\/ Used in Optimize()\n+\n+  _immutable_memory = nullptr; \/\/ filled in at first inquiry\n@@ -1000,1 +1013,5 @@\n-  _immutable_memory = NULL; \/\/ filled in at first inquiry\n+#ifdef ASSERT\n+  _phase_optimize_finished = false;\n+  _exception_backedge = false;\n+  _type_verify = nullptr;\n+#endif\n@@ -1003,2 +1020,2 @@\n-  \/\/ First set TOP to NULL to give safe behavior during creation of RootNode\n-  set_cached_top_node(NULL);\n+  \/\/ First set TOP to null to give safe behavior during creation of RootNode\n+  set_cached_top_node(nullptr);\n@@ -1008,1 +1025,1 @@\n-  set_recent_alloc(NULL, NULL);\n+  set_recent_alloc(nullptr, nullptr);\n@@ -1058,1 +1075,1 @@\n-  if (UseRTMLocking && has_method() && (method()->method_data_or_null() != NULL)) {\n+  if (UseRTMLocking && has_method() && (method()->method_data_or_null() != nullptr)) {\n@@ -1078,1 +1095,1 @@\n-                        (comp_arena(), 8, 0, NULL));\n+                        (comp_arena(), 8, 0, nullptr));\n@@ -1091,1 +1108,1 @@\n-  _alias_types[AliasIdxTop]->Init(AliasIdxTop, NULL);\n+  _alias_types[AliasIdxTop]->Init(AliasIdxTop, nullptr);\n@@ -1097,8 +1114,2 @@\n-  \/\/ A NULL adr_type hits in the cache right away.  Preload the right answer.\n-  probe_alias_cache(NULL)->_index = AliasIdxTop;\n-\n-#ifdef ASSERT\n-  _type_verify_symmetry = true;\n-  _phase_optimize_finished = false;\n-  _exception_backedge = false;\n-#endif\n+  \/\/ A null adr_type hits in the cache right away.  Preload the right answer.\n+  probe_alias_cache(nullptr)->_index = AliasIdxTop;\n@@ -1129,1 +1140,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1135,1 +1146,1 @@\n-  if (_immutable_memory != NULL) {\n+  if (_immutable_memory != nullptr) {\n@@ -1147,1 +1158,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1153,1 +1164,1 @@\n-  if (tn != NULL)  verify_top(tn);\n+  if (tn != nullptr)  verify_top(tn);\n@@ -1158,3 +1169,3 @@\n-  if (_top != NULL)     _top->setup_is_top();\n-  if (old_top != NULL)  old_top->setup_is_top();\n-  assert(_top == NULL || top()->is_top(), \"\");\n+  if (_top != nullptr)     _top->setup_is_top();\n+  if (old_top != nullptr)  old_top->setup_is_top();\n+  assert(_top == nullptr || top()->is_top(), \"\");\n@@ -1173,2 +1184,2 @@\n-  \/\/ Return if CompileLog is NULL and PrintIdealNodeCount is false.\n-  if ((_log == NULL) && (! PrintIdealNodeCount)) {\n+  \/\/ Return if CompileLog is null and PrintIdealNodeCount is false.\n+  if ((_log == nullptr) && (! PrintIdealNodeCount)) {\n@@ -1192,1 +1203,1 @@\n-    if (_log != NULL) {\n+    if (_log != nullptr) {\n@@ -1202,1 +1213,1 @@\n-          if (_log != NULL) {\n+          if (_log != nullptr) {\n@@ -1213,1 +1224,1 @@\n-        if (_log != NULL) {\n+        if (_log != nullptr) {\n@@ -1222,1 +1233,1 @@\n-    if (_log != NULL) {\n+    if (_log != nullptr) {\n@@ -1228,1 +1239,1 @@\n-  if (_modified_nodes != NULL && !_inlining_incrementally && !n->is_Con()) {\n+  if (_modified_nodes != nullptr && !_inlining_incrementally && !n->is_Con()) {\n@@ -1234,1 +1245,1 @@\n-  if (_modified_nodes != NULL) {\n+  if (_modified_nodes != nullptr) {\n@@ -1242,1 +1253,1 @@\n-  if (tn != NULL) {\n+  if (tn != nullptr) {\n@@ -1245,1 +1256,1 @@\n-    assert(tn->in(0) != NULL, \"must have live top node\");\n+    assert(tn->in(0) != nullptr, \"must have live top node\");\n@@ -1254,1 +1265,1 @@\n-  guarantee(arr != NULL, \"\");\n+  guarantee(arr != nullptr, \"\");\n@@ -1269,1 +1280,1 @@\n-  if (source == NULL || dest == NULL)  return false;\n+  if (source == nullptr || dest == nullptr)  return false;\n@@ -1276,1 +1287,1 @@\n-  if (dest != NULL && dest != source && dest->debug_orig() == NULL) {\n+  if (dest != nullptr && dest != source && dest->debug_orig() == nullptr) {\n@@ -1281,1 +1292,1 @@\n-  if (node_note_array() == NULL)\n+  if (node_note_array() == nullptr)\n@@ -1287,1 +1298,1 @@\n-  if (source_notes == NULL || source_notes->is_clear())  return false;\n+  if (source_notes == nullptr || source_notes->is_clear())  return false;\n@@ -1289,1 +1300,1 @@\n-  if (dest_notes == NULL || dest_notes->is_clear()) {\n+  if (dest_notes == nullptr || dest_notes->is_clear()) {\n@@ -1323,1 +1334,1 @@\n-  bool is_known_inst = tj->isa_oopptr() != NULL &&\n+  bool is_known_inst = tj->isa_oopptr() != nullptr &&\n@@ -1406,1 +1417,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), ta->field_offset());\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), ta->field_offset());\n@@ -1410,1 +1421,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), ta->field_offset());\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), ta->field_offset());\n@@ -1413,3 +1424,3 @@\n-    if (ta->is_flat() && ta->elem() != TypeInlineType::BOTTOM && _flattened_accesses_share_alias) {\n-      const TypeAry *tary = TypeAry::make(TypeInlineType::BOTTOM, ta->size());\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), Type::Offset(Type::OffsetBot));\n+    if (ta->is_flat() && ta->elem() != TypeInstPtr::BOTTOM && _flattened_accesses_share_alias) {\n+      const TypeAry* tary = TypeAry::make(TypeInstPtr::BOTTOM, ta->size(), \/* stable= *\/ false, \/* flat= *\/ true);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,nullptr,false,Type::Offset(offset), Type::Offset(Type::OffsetBot));\n@@ -1427,1 +1438,1 @@\n-    if (ptr == TypePtr::NotNull || ta->klass_is_exact() || ta->speculative() != NULL) {\n+    if (ptr == TypePtr::NotNull || ta->klass_is_exact() || ta->speculative() != nullptr) {\n@@ -1464,1 +1475,1 @@\n-    if (to->speculative() != NULL) {\n+    if (to->speculative() != nullptr) {\n@@ -1472,1 +1483,1 @@\n-        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, NULL, Type::Offset(offset));\n+        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, nullptr, Type::Offset(offset));\n@@ -1478,1 +1489,1 @@\n-        to = NULL;\n+        to = nullptr;\n@@ -1487,1 +1498,1 @@\n-          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, true, NULL, Type::Offset(offset), canonical_holder->flatten_array(), to->instance_id());\n+          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, true, nullptr, Type::Offset(offset), to->instance_id());\n@@ -1489,1 +1500,1 @@\n-          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, false, NULL, Type::Offset(offset));\n+          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, false, nullptr, Type::Offset(offset));\n@@ -1516,1 +1527,0 @@\n-\n@@ -1566,2 +1576,2 @@\n-  _field = NULL;\n-  _element = NULL;\n+  _field = nullptr;\n+  _element = nullptr;\n@@ -1569,2 +1579,2 @@\n-  const TypeOopPtr *atoop = (at != NULL) ? at->isa_oopptr() : NULL;\n-  if (atoop != NULL && atoop->is_known_instance()) {\n+  const TypeOopPtr *atoop = (at != nullptr) ? at->isa_oopptr() : nullptr;\n+  if (atoop != nullptr && atoop->is_known_instance()) {\n@@ -1579,1 +1589,1 @@\n-  if (element() != NULL) {\n+  if (element() != nullptr) {\n@@ -1582,1 +1592,1 @@\n-  } if (field() != NULL) {\n+  } if (field() != nullptr) {\n@@ -1603,1 +1613,1 @@\n-  if (field() != NULL && tjp) {\n+  if (field() != nullptr && tjp) {\n@@ -1651,1 +1661,1 @@\n-  AliasCacheEntry* ace = NULL;\n+  AliasCacheEntry* ace = nullptr;\n@@ -1660,1 +1670,1 @@\n-  if (adr_type == NULL)             return alias_type(AliasIdxTop);\n+  if (adr_type == nullptr)          return alias_type(AliasIdxTop);\n@@ -1693,1 +1703,1 @@\n-    if (no_create)  return NULL;\n+    if (no_create)  return nullptr;\n@@ -1706,1 +1716,1 @@\n-    ciField* field = NULL;\n+    ciField* field = nullptr;\n@@ -1718,1 +1728,1 @@\n-      if (elemtype->isa_inlinetype() &&\n+      if (flat->is_flat() &&\n@@ -1746,1 +1756,1 @@\n-      if (tinst->const_oop() != NULL &&\n+      if (tinst->const_oop() != nullptr &&\n@@ -1761,2 +1771,2 @@\n-    assert(field == NULL ||\n-           original_field == NULL ||\n+    assert(field == nullptr ||\n+           original_field == nullptr ||\n@@ -1764,1 +1774,1 @@\n-            field->offset() == original_field->offset() &&\n+            field->offset_in_bytes() == original_field->offset_in_bytes() &&\n@@ -1767,1 +1777,1 @@\n-    if (field != NULL) {\n+    if (field != nullptr) {\n@@ -1771,1 +1781,1 @@\n-        assert(flat->is_aryptr()->is_flat(), \"must be a flat array\");\n+        assert(flat->is_flat(), \"must be a flat array\");\n@@ -1785,1 +1795,1 @@\n-    if (face->_adr_type == NULL) {\n+    if (face->_adr_type == nullptr) {\n@@ -1816,1 +1826,1 @@\n-  if (adr_type == NULL)             return true;\n+  if (adr_type == nullptr)             return true;\n@@ -1819,1 +1829,1 @@\n-  return find_alias_type(adr_type, true, NULL) != NULL;\n+  return find_alias_type(adr_type, true, nullptr) != nullptr;\n@@ -1826,1 +1836,1 @@\n-  if (adr_type == NULL)                 return true;  \/\/ NULL serves as TypePtr::TOP\n+  if (adr_type == nullptr)              return true;  \/\/ null serves as TypePtr::TOP\n@@ -1844,1 +1854,1 @@\n-  if (adr_type == NULL)                 return false; \/\/ NULL serves as TypePtr::TOP\n+  if (adr_type == nullptr)              return false; \/\/ null serves as TypePtr::TOP\n@@ -1855,7 +1865,8 @@\n-\/\/---------------------cleanup_loop_predicates-----------------------\n-\/\/ Remove the opaque nodes that protect the predicates so that all unused\n-\/\/ checks and uncommon_traps will be eliminated from the ideal graph\n-void Compile::cleanup_loop_predicates(PhaseIterGVN &igvn) {\n-  if (predicate_count()==0) return;\n-  for (int i = predicate_count(); i > 0; i--) {\n-    Node * n = predicate_opaque1_node(i-1);\n+\/\/ Remove the opaque nodes that protect the Parse Predicates so that all unused\n+\/\/ checks and uncommon_traps will be eliminated from the ideal graph.\n+void Compile::cleanup_parse_predicates(PhaseIterGVN& igvn) const {\n+  if (parse_predicate_count() == 0) {\n+    return;\n+  }\n+  for (int i = parse_predicate_count(); i > 0; i--) {\n+    Node* n = parse_predicate_opaque1_node(i - 1);\n@@ -1865,1 +1876,1 @@\n-  assert(predicate_count()==0, \"should be clean!\");\n+  assert(parse_predicate_count() == 0, \"should be clean!\");\n@@ -1926,1 +1937,0 @@\n-    assert(n == ret_val || !n->is_InlineType(), \"chain of inline type nodes\");\n@@ -1950,1 +1960,1 @@\n-    Node* ret = NULL;\n+    Node* ret = nullptr;\n@@ -1954,1 +1964,1 @@\n-        assert(ret == NULL, \"only one return\");\n+        assert(ret == nullptr, \"only one return\");\n@@ -1958,1 +1968,1 @@\n-    if (ret != NULL) {\n+    if (ret != nullptr) {\n@@ -2023,0 +2033,2 @@\n+        } else if (u->is_Phi()) {\n+          \/\/ TODO 8302217 Remove this once InlineTypeNodes are reliably pushed through\n@@ -2027,1 +2039,2 @@\n-          vt->dump(-3);\n+          vt->dump(0);\n+          u->dump(0);\n@@ -2063,1 +2076,1 @@\n-      const TypePtr* adr_type = NULL;\n+      const TypePtr* adr_type = nullptr;\n@@ -2080,1 +2093,1 @@\n-      if (m != NULL) {\n+      if (m != nullptr) {\n@@ -2094,5 +2107,4 @@\n-      if (ace->_adr_type != NULL &&\n-          ace->_adr_type->isa_aryptr() &&\n-          ace->_adr_type->is_aryptr()->is_flat()) {\n-        ace->_adr_type = NULL;\n-        ace->_index = (i != 0) ? 0 : AliasIdxTop; \/\/ Make sure the NULL adr_type resolves to AliasIdxTop\n+      if (ace->_adr_type != nullptr &&\n+          ace->_adr_type->is_flat()) {\n+        ace->_adr_type = nullptr;\n+        ace->_index = (i != 0) ? 0 : AliasIdxTop; \/\/ Make sure the nullptr adr_type resolves to AliasIdxTop\n@@ -2108,1 +2120,1 @@\n-      const TypePtr* adr_type = NULL;\n+      const TypePtr* adr_type = nullptr;\n@@ -2142,1 +2154,1 @@\n-      MergeMemNode* mm = NULL;\n+      MergeMemNode* mm = nullptr;\n@@ -2161,1 +2173,1 @@\n-            Node* place_holder = NULL;\n+            Node* place_holder = nullptr;\n@@ -2173,1 +2185,1 @@\n-                    if (place_holder == NULL) {\n+                    if (place_holder == nullptr) {\n@@ -2221,2 +2233,2 @@\n-                  const Type* adr_type = get_adr_type(j);\n-                  if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat() || j == (uint)index) {\n+                  const TypePtr* adr_type = get_adr_type(j);\n+                  if (!adr_type->isa_aryptr() || !adr_type->is_flat() || j == (uint)index) {\n@@ -2251,2 +2263,2 @@\n-                const Type* adr_type = get_adr_type(j);\n-                if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat() || j == (uint)index) {\n+                const TypePtr* adr_type = get_adr_type(j);\n+                if (!adr_type->isa_aryptr() || !adr_type->is_flat() || j == (uint)index) {\n@@ -2255,1 +2267,1 @@\n-                MemBarNode* mb = new MemBarCPUOrderNode(this, j, NULL);\n+                MemBarNode* mb = new MemBarCPUOrderNode(this, j, nullptr);\n@@ -2277,1 +2289,1 @@\n-              if (place_holder != NULL) {\n+              if (place_holder != nullptr) {\n@@ -2294,2 +2306,2 @@\n-        const Type* adr_type = get_adr_type(j);\n-        if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat()) {\n+        const TypePtr* adr_type = get_adr_type(j);\n+        if (!adr_type->isa_aryptr() || !adr_type->is_flat()) {\n@@ -2314,1 +2326,1 @@\n-        if (m != NULL) {\n+        if (m != nullptr) {\n@@ -2556,1 +2568,1 @@\n-        if (do_print_inlining || log() != NULL) {\n+        if (do_print_inlining || log() != nullptr) {\n@@ -2609,1 +2621,1 @@\n-  \/\/ Tracking and verification of modified nodes is disabled by setting \"_modified_nodes == NULL\"\n+  \/\/ Tracking and verification of modified nodes is disabled by setting \"_modified_nodes == nullptr\"\n@@ -2614,1 +2626,1 @@\n-  _modified_nodes = NULL;\n+  _modified_nodes = nullptr;\n@@ -2651,1 +2663,1 @@\n-  if (r != NULL) {\n+  if (r != nullptr) {\n@@ -2654,1 +2666,1 @@\n-      if (n != NULL && n->is_SafePoint()) {\n+      if (n != nullptr && n->is_SafePoint()) {\n@@ -2801,1 +2813,1 @@\n-      if (congraph() != NULL && macro_count() > 0) {\n+      if (congraph() != nullptr && macro_count() > 0) {\n@@ -2927,1 +2939,1 @@\n-  DEBUG_ONLY( _modified_nodes = NULL; )\n+  DEBUG_ONLY( _modified_nodes = nullptr; )\n@@ -3102,1 +3114,1 @@\n-  Node* mask = pn->is_predicated_vector() ? pn->in(pn->req()-1) : NULL;\n+  Node* mask = pn->is_predicated_vector() ? pn->in(pn->req()-1) : nullptr;\n@@ -3148,1 +3160,1 @@\n-  assert(n != NULL, \"\");\n+  assert(n != nullptr, \"\");\n@@ -3264,3 +3276,3 @@\n-  Node* parent_pred = parent_is_predicated ? n->in(n->req()-1) : NULL;\n-  Node* left_child_pred = left_child_predicated ? n->in(1)->in(n->in(1)->req()-1) : NULL;\n-  Node* right_child_pred = right_child_predicated ? n->in(1)->in(n->in(1)->req()-1) : NULL;\n+  Node* parent_pred = parent_is_predicated ? n->in(n->req()-1) : nullptr;\n+  Node* left_child_pred = left_child_predicated ? n->in(1)->in(n->in(1)->req()-1) : nullptr;\n+  Node* right_child_pred = right_child_predicated ? n->in(1)->in(n->in(1)->req()-1) : nullptr;\n@@ -3333,2 +3345,2 @@\n-    Node* mask = pn->is_predicated_vector() ? pn->in(pn->req()-1) : NULL;\n-    if (mask == NULL ||\n+    Node* mask = pn->is_predicated_vector() ? pn->in(pn->req()-1) : nullptr;\n+    if (mask == nullptr ||\n@@ -3337,6 +3349,1 @@\n-#ifdef ASSERT\n-      if (TraceNewVectors) {\n-        tty->print(\"new Vector node: \");\n-        macro_logic->dump();\n-      }\n-#endif\n+      VectorNode::trace_new_vector(macro_logic, \"MacroLogic\");\n@@ -3536,1 +3543,1 @@\n-            if (mem->in(i) != NULL) {\n+            if (mem->in(i) != nullptr) {\n@@ -3590,1 +3597,1 @@\n-    assert( n->in(0) != NULL || alias_idx != Compile::AliasIdxRaw ||\n+    assert( n->in(0) != nullptr || alias_idx != Compile::AliasIdxRaw ||\n@@ -3712,2 +3719,2 @@\n-          const Type* adr_type = get_adr_type(i);\n-          if (adr_type->isa_aryptr() && adr_type->is_aryptr()->is_flat()) {\n+          const TypePtr* adr_type = get_adr_type(i);\n+          if (adr_type->is_flat()) {\n@@ -3795,2 +3802,2 @@\n-      bool is_oop   = t->isa_oopptr() != NULL;\n-      bool is_klass = t->isa_klassptr() != NULL;\n+      bool is_oop   = t->isa_oopptr() != nullptr;\n+      bool is_klass = t->isa_klassptr() != nullptr;\n@@ -3800,1 +3807,1 @@\n-        Node* nn = NULL;\n+        Node* nn = nullptr;\n@@ -3809,1 +3816,1 @@\n-          if (m!= NULL && m->Opcode() == op &&\n+          if (m!= nullptr && m->Opcode() == op &&\n@@ -3815,1 +3822,1 @@\n-        if (nn != NULL) {\n+        if (nn != nullptr) {\n@@ -3832,1 +3839,1 @@\n-                assert(out_j == NULL || !out_j->is_AddP() || out_j->in(AddPNode::Base) != addp,\n+                assert(out_j == nullptr || !out_j->is_AddP() || out_j->in(AddPNode::Base) != addp,\n@@ -3856,1 +3863,1 @@\n-    if (n->in(0) != NULL) {\n+    if (n->in(0) != nullptr) {\n@@ -3891,1 +3898,1 @@\n-        \/\/ a narrow oop directly and do implicit NULL check in address:\n+        \/\/ a narrow oop directly and do implicit null check in address:\n@@ -3897,1 +3904,1 @@\n-        \/\/ use it to do implicit NULL check in address:\n+        \/\/ use it to do implicit null check in address:\n@@ -3904,1 +3911,1 @@\n-        \/\/ to keep the information to which NULL check the new DecodeN node\n+        \/\/ to keep the information to which null check the new DecodeN node\n@@ -3935,1 +3942,1 @@\n-      Node* new_in2 = NULL;\n+      Node* new_in2 = nullptr;\n@@ -3950,1 +3957,1 @@\n-          \/\/ will generated code for implicit NULL checks for compressed oops.\n+          \/\/ will generated code for implicit null checks for compressed oops.\n@@ -3956,1 +3963,1 @@\n-          \/\/    CmpP base_reg, NULL\n+          \/\/    CmpP base_reg, nullptr\n@@ -3963,1 +3970,1 @@\n-          \/\/    CmpN narrow_oop_reg, NULL\n+          \/\/    CmpN narrow_oop_reg, nullptr\n@@ -3967,1 +3974,1 @@\n-          \/\/ and the uncommon path (== NULL) will use narrow_oop_reg directly\n+          \/\/ and the uncommon path (== nullptr) will use narrow_oop_reg directly\n@@ -3991,1 +3998,1 @@\n-      if (new_in2 != NULL) {\n+      if (new_in2 != nullptr) {\n@@ -4009,1 +4016,1 @@\n-    assert(n->in(0) == NULL || (UseCompressedOops && !Matcher::narrow_oop_use_complex_address()), \"no control\");\n+    assert(n->in(0) == nullptr || (UseCompressedOops && !Matcher::narrow_oop_use_complex_address()), \"no control\");\n@@ -4044,1 +4051,1 @@\n-        if (non_io_proj  != NULL) {\n+        if (non_io_proj  != nullptr) {\n@@ -4057,1 +4064,1 @@\n-      assert(unique_in != NULL, \"\");\n+      assert(unique_in != nullptr, \"\");\n@@ -4061,1 +4068,1 @@\n-        assert(m != NULL, \"\");\n+        assert(m != nullptr, \"\");\n@@ -4063,1 +4070,1 @@\n-          unique_in = NULL;\n+          unique_in = nullptr;\n@@ -4065,1 +4072,1 @@\n-      if (unique_in != NULL) {\n+      if (unique_in != nullptr) {\n@@ -4225,1 +4232,1 @@\n-      if (t != NULL && t->is_con()) {\n+      if (t != nullptr && t->is_con()) {\n@@ -4231,1 +4238,1 @@\n-        if (t == NULL || t->_lo < 0 || t->_hi > (int)mask) {\n+        if (t == nullptr || t->_lo < 0 || t->_hi > (int)mask) {\n@@ -4285,1 +4292,1 @@\n-          if (k == NULL) {\n+          if (k == nullptr) {\n@@ -4349,2 +4356,2 @@\n-      if (m != NULL && !frc._visited.test_set(m->_idx)) {\n-        if (m->is_SafePoint() && m->as_SafePoint()->jvms() != NULL) {\n+      if (m != nullptr && !frc._visited.test_set(m->_idx)) {\n+        if (m->is_SafePoint() && m->as_SafePoint()->jvms() != nullptr) {\n@@ -4384,1 +4391,1 @@\n-    assert(jvms != NULL, \"sanity\");\n+    assert(jvms != nullptr, \"sanity\");\n@@ -4445,0 +4452,2 @@\n+    \/\/ Do not compile method that is only a trivial infinite loop,\n+    \/\/ since the content of the loop may have been eliminated.\n@@ -4455,1 +4464,1 @@\n-    _expensive_nodes.at(i)->set_req(0, NULL);\n+    _expensive_nodes.at(i)->set_req(0, nullptr);\n@@ -4510,0 +4519,1 @@\n+\n@@ -4512,0 +4522,2 @@\n+        DEBUG_ONLY( n->dump_bfs(1, 0, \"-\"); );\n+        assert(false, \"malformed control flow\");\n@@ -4548,1 +4560,1 @@\n-        if (in != NULL) {\n+        if (in != nullptr) {\n@@ -4586,1 +4598,1 @@\n-  ciMethod* m = Deoptimization::reason_is_speculate(reason) ? this->method() : NULL;\n+  ciMethod* m = Deoptimization::reason_is_speculate(reason) ? this->method() : nullptr;\n@@ -4609,1 +4621,1 @@\n-      int mcount = (logmd == NULL)? -1: (int)logmd->trap_count(reason);\n+      int mcount = (logmd == nullptr)? -1: (int)logmd->trap_count(reason);\n@@ -4640,1 +4652,1 @@\n-  ciMethod* m = Deoptimization::reason_is_speculate(reason) ? this->method() : NULL;\n+  ciMethod* m = Deoptimization::reason_is_speculate(reason) ? this->method() : nullptr;\n@@ -4744,1 +4756,1 @@\n-      if (in != NULL && !visited.member(in)) {\n+      if (in != nullptr && !visited.member(in)) {\n@@ -4747,1 +4759,1 @@\n-      if (in != NULL && !in->is_top()) {\n+      if (in != nullptr && !in->is_top()) {\n@@ -4764,1 +4776,1 @@\n-      } else if (in == NULL) {\n+      } else if (in == nullptr) {\n@@ -4824,1 +4836,1 @@\n-  if (log() != NULL) {\n+  if (log() != nullptr) {\n@@ -4827,1 +4839,1 @@\n-  if (_failure_reason == NULL) {\n+  if (_failure_reason == nullptr) {\n@@ -4835,1 +4847,1 @@\n-  _root = NULL;  \/\/ flush the graph, too\n+  _root = nullptr;  \/\/ flush the graph, too\n@@ -4846,2 +4858,2 @@\n-    C = NULL;\n-    _log = NULL;\n+    C = nullptr;\n+    _log = nullptr;\n@@ -4849,1 +4861,1 @@\n-  if (_log != NULL) {\n+  if (_log != nullptr) {\n@@ -4862,1 +4874,1 @@\n-    _log = NULL;\n+    _log = nullptr;\n@@ -4876,1 +4888,1 @@\n-  if (_log != NULL) {\n+  if (_log != nullptr) {\n@@ -4887,2 +4899,2 @@\n-Compile::SubTypeCheckResult Compile::static_subtype_check(const TypeKlassPtr* superk, const TypeKlassPtr* subk) {\n-  if (StressReflectiveCode) {\n+Compile::SubTypeCheckResult Compile::static_subtype_check(const TypeKlassPtr* superk, const TypeKlassPtr* subk, bool skip) {\n+  if (skip) {\n@@ -4947,1 +4959,1 @@\n-  if (sizetype != NULL) index_max = sizetype->_hi - 1;\n+  if (sizetype != nullptr) index_max = sizetype->_hi - 1;\n@@ -4956,1 +4968,1 @@\n-  if (ctrl != NULL) {\n+  if (ctrl != nullptr) {\n@@ -5018,1 +5030,1 @@\n-          (print_inlining_current()->cg() != NULL ||\n+          (print_inlining_current()->cg() != nullptr ||\n@@ -5025,1 +5037,1 @@\n-      if (print_inlining_current()->cg() != NULL) {\n+      if (print_inlining_current()->cg() != nullptr) {\n@@ -5067,1 +5079,1 @@\n-    assert(_print_inlining_list != NULL, \"process_print_inlining should be called only once.\");\n+    assert(_print_inlining_list != nullptr, \"process_print_inlining should be called only once.\");\n@@ -5072,1 +5084,1 @@\n-      DEBUG_ONLY(_print_inlining_list->at_put(i, NULL));\n+      DEBUG_ONLY(_print_inlining_list->at_put(i, nullptr));\n@@ -5076,1 +5088,1 @@\n-    _print_inlining_list = NULL;\n+    _print_inlining_list = nullptr;\n@@ -5087,1 +5099,1 @@\n-  if (_print_inlining_output != NULL) {\n+  if (_print_inlining_output != nullptr) {\n@@ -5093,1 +5105,1 @@\n-  if (log() != NULL) {\n+  if (log() != nullptr) {\n@@ -5097,1 +5109,1 @@\n-    while (p != NULL) {\n+    while (p != nullptr) {\n@@ -5107,1 +5119,1 @@\n-  if (log() != NULL) {\n+  if (log() != nullptr) {\n@@ -5113,1 +5125,1 @@\n-  if (log() != NULL) {\n+  if (log() != nullptr) {\n@@ -5128,1 +5140,1 @@\n-  if (C->log() != NULL) {\n+  if (C->log() != nullptr) {\n@@ -5138,1 +5150,1 @@\n-  if (inl_tree != NULL) {\n+  if (inl_tree != nullptr) {\n@@ -5148,1 +5160,1 @@\n-  if (inl_tree == NULL) {\n+  if (inl_tree == nullptr) {\n@@ -5268,1 +5280,1 @@\n-      igvn.replace_input_of(n, 0, NULL);\n+      igvn.replace_input_of(n, 0, nullptr);\n@@ -5277,1 +5289,1 @@\n-    igvn.replace_input_of(n, 0, NULL);\n+    igvn.replace_input_of(n, 0, nullptr);\n@@ -5296,1 +5308,1 @@\n-    n->set_req(0, NULL);\n+    n->set_req(0, nullptr);\n@@ -5444,1 +5456,1 @@\n-      assert((t == NULL) || (t == t->remove_speculative()), \"no more speculative types\");\n+      assert((t == nullptr) || (t == t->remove_speculative()), \"no more speculative types\");\n@@ -5466,1 +5478,1 @@\n-  if (!EnableValhalla || ta == NULL || tb == NULL ||\n+  if (!EnableValhalla || ta == nullptr || tb == nullptr ||\n@@ -5473,1 +5485,1 @@\n-    \/\/ new acmp will only return true if both operands are NULL.\n+    \/\/ new acmp will only return true if both operands are nullptr.\n@@ -5475,2 +5487,2 @@\n-    a = phase->transform(new CastP2XNode(NULL, a));\n-    b = phase->transform(new CastP2XNode(NULL, b));\n+    a = phase->transform(new CastP2XNode(nullptr, a));\n+    b = phase->transform(new CastP2XNode(nullptr, b));\n@@ -5481,1 +5493,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -5627,1 +5639,1 @@\n-  if (_method != NULL && should_print_igv(1)) {\n+  if (_method != nullptr && should_print_igv(1)) {\n@@ -5642,1 +5654,1 @@\n-  if (_method != NULL && should_print_igv(1)) {\n+  if (_method != nullptr && should_print_igv(1)) {\n@@ -5675,2 +5687,2 @@\n-IdealGraphPrinter* Compile::_debug_file_printer = NULL;\n-IdealGraphPrinter* Compile::_debug_network_printer = NULL;\n+IdealGraphPrinter* Compile::_debug_file_printer = nullptr;\n+IdealGraphPrinter* Compile::_debug_network_printer = nullptr;\n@@ -5728,1 +5740,1 @@\n-  if (_debug_file_printer == NULL) {\n+  if (_debug_file_printer == nullptr) {\n@@ -5738,1 +5750,1 @@\n-  if (_debug_network_printer == NULL) {\n+  if (_debug_network_printer == nullptr) {\n@@ -5749,1 +5761,1 @@\n-  if (type != NULL && phase->type(value)->higher_equal(type)) {\n+  if (type != nullptr && phase->type(value)->higher_equal(type)) {\n@@ -5752,1 +5764,1 @@\n-  Node* result = NULL;\n+  Node* result = nullptr;\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":306,"deletions":294,"binary":false,"changes":600,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -63,1 +63,1 @@\n-    _gvn((gvn != NULL) ? *gvn : *C->initial_gvn()),\n+    _gvn((gvn != nullptr) ? *gvn : *C->initial_gvn()),\n@@ -66,1 +66,1 @@\n-  assert(gvn == NULL || !gvn->is_IterGVN() || gvn->is_IterGVN()->delay_transform(), \"delay transform should be enabled\");\n+  assert(gvn == nullptr || !gvn->is_IterGVN() || gvn->is_IterGVN()->delay_transform(), \"delay transform should be enabled\");\n@@ -68,1 +68,1 @@\n-  if (_exceptions != NULL)  jvms->map()->set_next_exception(NULL);\n+  if (_exceptions != nullptr)  jvms->map()->set_next_exception(nullptr);\n@@ -71,1 +71,1 @@\n-  if (_gvn.is_IterGVN() != NULL) {\n+  if (_gvn.is_IterGVN() != nullptr) {\n@@ -86,2 +86,2 @@\n-  _exceptions = NULL;\n-  set_map(NULL);\n+  _exceptions = nullptr;\n+  set_map(nullptr);\n@@ -134,1 +134,1 @@\n-  if (parse == NULL) {\n+  if (parse == nullptr) {\n@@ -154,1 +154,1 @@\n-  if (reg == NULL)  return false;\n+  if (reg == nullptr)  return false;\n@@ -157,1 +157,1 @@\n-    if (reg == NULL)  return false;\n+    if (reg == nullptr)  return false;\n@@ -159,1 +159,1 @@\n-  return reg->is_Region() && reg->in(0) != NULL && reg->in(0)->is_Root();\n+  return reg->is_Region() && reg->in(0) != nullptr && reg->in(0)->is_Root();\n@@ -163,1 +163,1 @@\n-  if (map() == NULL)  return;  \/\/ null map is OK\n+  if (map() == nullptr)  return;  \/\/ null map is OK\n@@ -170,1 +170,1 @@\n-  assert(ex_map->next_exception() == NULL, \"not already part of a chain\");\n+  assert(ex_map->next_exception() == nullptr, \"not already part of a chain\");\n@@ -176,1 +176,1 @@\n-\/\/ Set _map to NULL, signalling a stop to further bytecode execution.\n+\/\/ Set _map to null, signalling a stop to further bytecode execution.\n@@ -180,1 +180,1 @@\n-  if (dead_map != NULL) {\n+  if (dead_map != nullptr) {\n@@ -188,1 +188,1 @@\n-\/\/ Tell if _map is NULL, or control is top.\n+\/\/ Tell if _map is null, or control is top.\n@@ -190,1 +190,1 @@\n-  if (map() == NULL)           return true;\n+  if (map() == nullptr)        return true;\n@@ -199,1 +199,1 @@\n-  for (JVMState* jvmsp = jvms(); jvmsp != NULL; jvmsp = jvmsp->caller()) {\n+  for (JVMState* jvmsp = jvms(); jvmsp != nullptr; jvmsp = jvmsp->caller()) {\n@@ -255,1 +255,1 @@\n-  if (ex_map == NULL || ex_map->control() == top()) {\n+  if (ex_map == nullptr || ex_map->control() == top()) {\n@@ -274,1 +274,1 @@\n-  for (SafePointNode* e2 = _exceptions; e2 != NULL; e2 = e2->next_exception()) {\n+  for (SafePointNode* e2 = _exceptions; e2 != nullptr; e2 = e2->next_exception()) {\n@@ -292,3 +292,3 @@\n-  if (ex_map != NULL) {\n-    jvms->map()->set_next_exception(NULL);\n-    for (SafePointNode* next_map; ex_map != NULL; ex_map = next_map) {\n+  if (ex_map != nullptr) {\n+    jvms->map()->set_next_exception(nullptr);\n+    for (SafePointNode* next_map; ex_map != nullptr; ex_map = next_map) {\n@@ -296,1 +296,1 @@\n-      ex_map->set_next_exception(NULL);\n+      ex_map->set_next_exception(nullptr);\n@@ -304,1 +304,1 @@\n-  if (map() == NULL) {\n+  if (map() == nullptr) {\n@@ -310,1 +310,1 @@\n-      _map->set_next_exception(NULL);\n+      _map->set_next_exception(nullptr);\n@@ -315,1 +315,1 @@\n-      JVMState* jvms = new (C) JVMState(_method, NULL);\n+      JVMState* jvms = new (C) JVMState(_method, nullptr);\n@@ -330,1 +330,1 @@\n-  _exceptions = NULL;   \/\/ done with this set of exceptions\n+  _exceptions = nullptr;   \/\/ done with this set of exceptions\n@@ -352,1 +352,1 @@\n-\/\/ having a control input of its exception map, rather than NULL.  Such\n+\/\/ having a control input of its exception map, rather than null.  Such\n@@ -504,1 +504,1 @@\n-  if (method != NULL && bci != InvocationEntryBci)\n+  if (method != nullptr && bci != InvocationEntryBci)\n@@ -534,1 +534,1 @@\n-                    (ciKlass*)NULL, (char*)NULL, must_throw);\n+                    (ciKlass*)nullptr, (char*)nullptr, must_throw);\n@@ -581,1 +581,1 @@\n-    ciInstance* ex_obj = NULL;\n+    ciInstance* ex_obj = nullptr;\n@@ -602,1 +602,1 @@\n-    if (ex_obj != NULL) {\n+    if (ex_obj != nullptr) {\n@@ -611,1 +611,1 @@\n-      if (C->log() != NULL)\n+      if (C->log() != nullptr)\n@@ -647,1 +647,1 @@\n-  ciMethod* m = Deoptimization::reason_is_speculate(reason) ? C->method() : NULL;\n+  ciMethod* m = Deoptimization::reason_is_speculate(reason) ? C->method() : nullptr;\n@@ -653,1 +653,1 @@\n-    if (C->log() != NULL)\n+    if (C->log() != nullptr)\n@@ -665,1 +665,1 @@\n-  uncommon_trap(reason, action, (ciKlass*)NULL, (char*)NULL, must_throw);\n+  uncommon_trap(reason, action, (ciKlass*)nullptr, (char*)nullptr, must_throw);\n@@ -675,1 +675,1 @@\n-  kit->set_map(clone_map ? kit->clone_map() : NULL);\n+  kit->set_map(clone_map ? kit->clone_map() : nullptr);\n@@ -679,1 +679,1 @@\n-  int block = (parser == NULL || parser->block() == NULL) ? -1 : parser->block()->rpo();\n+  int block = (parser == nullptr || parser->block() == nullptr) ? -1 : parser->block()->rpo();\n@@ -688,1 +688,1 @@\n-  int block = (parser == NULL || parser->block() == NULL) ? -1 : parser->block()->rpo();\n+  int block = (parser == nullptr || parser->block() == nullptr) ? -1 : parser->block()->rpo();\n@@ -733,1 +733,1 @@\n-  if (map() == NULL)  return NULL;\n+  if (map() == nullptr)  return nullptr;\n@@ -750,0 +750,23 @@\n+\/\/-----------------------------destruct_map_clone------------------------------\n+\/\/\n+\/\/ Order of destruct is important to increase the likelyhood that memory can be re-used. We need\n+\/\/ to destruct\/free\/delete in the exact opposite order as clone_map().\n+void GraphKit::destruct_map_clone(SafePointNode* sfp) {\n+  if (sfp == nullptr) return;\n+\n+  Node* mem = sfp->memory();\n+  JVMState* jvms = sfp->jvms();\n+\n+  if (jvms != nullptr) {\n+    delete jvms;\n+  }\n+\n+  remove_for_igvn(sfp);\n+  gvn().clear_type(sfp);\n+  sfp->destruct(&_gvn);\n+\n+  if (mem != nullptr) {\n+    gvn().clear_type(mem);\n+    mem->destruct(&_gvn);\n+  }\n+}\n@@ -755,1 +778,1 @@\n-  _map->set_next_exception(NULL);\n+  _map->set_next_exception(nullptr);\n@@ -778,1 +801,1 @@\n-  if (method() == NULL || method()->code_size() == 0) {\n+  if (method() == nullptr || method()->code_size() == 0) {\n@@ -806,1 +829,1 @@\n-  if (method() == NULL || method()->code_size() == 0) {\n+  if (method() == nullptr || method()->code_size() == 0) {\n@@ -813,1 +836,1 @@\n-  for (JVMState* jvms = this->jvms(); jvms != NULL; jvms = jvms->caller()) {\n+  for (JVMState* jvms = this->jvms(); jvms != nullptr; jvms = jvms->caller()) {\n@@ -846,1 +869,1 @@\n-  if (cur_method != NULL && cur_bci != InvocationEntryBci) {\n+  if (cur_method != nullptr && cur_bci != InvocationEntryBci) {\n@@ -940,1 +963,1 @@\n-  for (JVMState* in_jvms = youngest_jvms; in_jvms != NULL; ) {\n+  for (JVMState* in_jvms = youngest_jvms; in_jvms != nullptr; ) {\n@@ -1034,3 +1057,0 @@\n-  BasicType rtype = T_ILLEGAL;\n-  int       rsize = 0;\n-\n@@ -1039,3 +1059,0 @@\n-    rtype = Bytecodes::result_type(code); \/\/ checkcast=P, athrow=V\n-    if (rtype < T_CONFLICT)\n-      rsize = type2size[rtype];\n@@ -1044,0 +1061,6 @@\n+  auto rsize = [&]() {\n+    assert(code != Bytecodes::_illegal, \"code is illegal!\");\n+    BasicType rtype = Bytecodes::result_type(code); \/\/ checkcast=P, athrow=V\n+    return (rtype < T_CONFLICT) ? type2size[rtype] : 0;\n+  };\n+\n@@ -1070,3 +1093,1 @@\n-      int size = field->is_multifield_base() ?\n-                   (InlineTypeNode::is_multifield_scalarized(field) ? field->type()->elem_word_count() : 1)\n-                   : field->type()->size();\n+      int size = InlineTypeNode::stack_size_for_field(field);\n@@ -1091,1 +1112,1 @@\n-      ciSignature* declared_signature = NULL;\n+      ciSignature* declared_signature = nullptr;\n@@ -1093,1 +1114,1 @@\n-      assert(declared_signature != NULL, \"cannot be null\");\n+      assert(declared_signature != nullptr, \"cannot be null\");\n@@ -1106,2 +1127,2 @@\n-      assert(rsize == 1, \"\");\n-      depth = rsize - inputs;\n+      assert(rsize() == 1, \"\");\n+      depth = 1 - inputs;\n@@ -1114,3 +1135,1 @@\n-    int size = field->is_multifield_base() ?\n-                 (InlineTypeNode::is_multifield_scalarized(field) ? field->type()->elem_word_count() : 1)\n-                   : field->type()->size();\n+    int size = InlineTypeNode::stack_size_for_field(field);\n@@ -1118,1 +1137,1 @@\n-    depth = rsize - inputs;\n+    depth = rsize() - inputs;\n@@ -1127,2 +1146,2 @@\n-    assert(rsize == -depth, \"\");\n-    inputs = rsize;\n+    assert(rsize() == -depth, \"\");\n+    inputs = -depth;\n@@ -1139,1 +1158,1 @@\n-    inputs = rsize - depth;\n+    inputs = rsize() - depth;\n@@ -1202,1 +1221,1 @@\n-  if (akls != NULL)  return akls;\n+  if (akls != nullptr)  return akls;\n@@ -1204,1 +1223,1 @@\n-  return _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n+  return _gvn.transform(LoadKlassNode::make(_gvn, nullptr, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n@@ -1212,1 +1231,1 @@\n-  if (alloc == NULL) {\n+  if (alloc == nullptr) {\n@@ -1242,2 +1261,2 @@\n-\/\/ Helper function to do a NULL pointer check.  Returned value is\n-\/\/ the incoming address with NULL casted away.  You are allowed to use the\n+\/\/ Helper function to do a null pointer check.  Returned value is\n+\/\/ the incoming address with null casted away.  You are allowed to use the\n@@ -1255,1 +1274,1 @@\n-  assert(!assert_null || null_control == NULL, \"not both at once\");\n+  assert(!assert_null || null_control == nullptr, \"not both at once\");\n@@ -1277,1 +1296,1 @@\n-    bool do_replace_in_map = (null_control == NULL || (*null_control) == top());\n+    bool do_replace_in_map = (null_control == nullptr || (*null_control) == top());\n@@ -1281,2 +1300,2 @@\n-  \/\/ Construct NULL check\n-  Node *chk = NULL;\n+  \/\/ Construct null check\n+  Node *chk = nullptr;\n@@ -1293,1 +1312,1 @@\n-      if (tp != NULL && !tp->is_loaded()\n+      if (tp != nullptr && !tp->is_loaded()\n@@ -1295,1 +1314,1 @@\n-          && !assert_null && null_control == NULL) {\n+          && !assert_null && null_control == nullptr) {\n@@ -1325,2 +1344,2 @@\n-        \/\/ See if mixing in the NULL pointer changes type.\n-        \/\/ If so, then the NULL pointer was not allowed in the original\n+        \/\/ See if mixing in the null pointer changes type.\n+        \/\/ If so, then the null pointer was not allowed in the original\n@@ -1341,1 +1360,1 @@\n-  assert(chk != NULL, \"sanity check\");\n+  assert(chk != nullptr, \"sanity check\");\n@@ -1374,1 +1393,1 @@\n-      if (cfg == NULL)  break;  \/\/ Quit at region nodes\n+      if (cfg == nullptr)  break;  \/\/ Quit at region nodes\n@@ -1399,1 +1418,1 @@\n-  if (null_control != NULL || too_many_traps(reason)) {\n+  if (null_control != nullptr || too_many_traps(reason)) {\n@@ -1404,1 +1423,1 @@\n-             method() != NULL &&\n+             method() != nullptr &&\n@@ -1410,1 +1429,1 @@\n-  if (null_control != NULL) {\n+  if (null_control != nullptr) {\n@@ -1429,1 +1448,1 @@\n-                    NULL, \"assert_null\");\n+                    nullptr, \"assert_null\");\n@@ -1451,1 +1470,1 @@\n-    if (null_control == NULL || (*null_control) == top())\n+    if (null_control == nullptr || (*null_control) == top())\n@@ -1556,1 +1575,1 @@\n-  debug_only( map()->set_memory((Node*)NULL) );\n+  debug_only( map()->set_memory((Node*)nullptr) );\n@@ -1592,1 +1611,1 @@\n-  const TypePtr* adr_type = NULL; \/\/ debug-mode-only argument\n+  const TypePtr* adr_type = nullptr; \/\/ debug-mode-only argument\n@@ -1611,1 +1630,2 @@\n-                                bool unsafe) {\n+                                bool unsafe,\n+                                int barrier_data) {\n@@ -1613,1 +1633,1 @@\n-  const TypePtr* adr_type = NULL;\n+  const TypePtr* adr_type = nullptr;\n@@ -1626,0 +1646,1 @@\n+  st->as_Store()->set_barrier_data(barrier_data);\n@@ -1644,1 +1665,1 @@\n-  \/\/ Transformation of a value which could be NULL pointer (CastPP #NULL)\n+  \/\/ Transformation of a value which could be null pointer (CastPP #null)\n@@ -1655,1 +1676,1 @@\n-  assert(val != NULL, \"not dead path\");\n+  assert(val != nullptr, \"not dead path\");\n@@ -1703,1 +1724,1 @@\n-  C2ParseAccess access(this, decorators | C2_READ_ACCESS, bt, NULL, addr);\n+  C2ParseAccess access(this, decorators | C2_READ_ACCESS, bt, nullptr, addr);\n@@ -1841,1 +1862,2 @@\n-    if (t->is_inlinetypeptr() && call->method()->is_scalarized_arg(arg_num)) {\n+    \/\/ TODO 8284443 A static call to a mismatched method should still be scalarized\n+    if (t->is_inlinetypeptr() && !call->method()->get_Method()->mismatch() && call->method()->is_scalarized_arg(arg_num)) {\n@@ -1853,0 +1875,3 @@\n+      \/\/ Register an evol dependency on the callee method to make sure that this method is deoptimized and\n+      \/\/ re-compiled with a non-scalarized calling convention if the callee method is later marked as mismatched.\n+      C->dependencies()->assert_evol_method(call->method());\n@@ -1918,1 +1943,1 @@\n-  if (call->method() == NULL || call->method()->return_type()->basic_type() == T_VOID) {\n+  if (call->method() == nullptr || call->method()->return_type()->basic_type() == T_VOID) {\n@@ -1928,0 +1953,3 @@\n+    if (call->method()->return_type()->is_inlinetype()) {\n+      ret = InlineTypeNode::make_from_oop(this, ret, call->method()->return_type()->as_inline_klass(), call->method()->signature()->returns_null_free_inline_type());\n+    }\n@@ -1946,1 +1974,1 @@\n-  Node* m = narrow_mem == NULL ? memory : narrow_mem;\n+  Node* m = narrow_mem == nullptr ? memory : narrow_mem;\n@@ -1957,1 +1985,1 @@\n-\/\/ If keep_mem is not NULL, use it for the output state,\n+\/\/ If keep_mem is not null, use it for the output state,\n@@ -1959,1 +1987,1 @@\n-\/\/ If hook_mem is NULL, this call produces no memory effects at all.\n+\/\/ If hook_mem is null, this call produces no memory effects at all.\n@@ -1973,1 +2001,1 @@\n-    if (hook_mem != NULL) {\n+    if (hook_mem != nullptr) {\n@@ -1987,1 +2015,1 @@\n-    assert(hook_mem == NULL, \"\");\n+    assert(hook_mem == nullptr, \"\");\n@@ -2008,1 +2036,1 @@\n-  JVMState* ejvms = NULL;\n+  JVMState* ejvms = nullptr;\n@@ -2029,1 +2057,1 @@\n-  if (callprojs->fallthrough_catchproj != NULL) {\n+  if (callprojs->fallthrough_catchproj != nullptr) {\n@@ -2032,1 +2060,1 @@\n-  if (callprojs->fallthrough_memproj != NULL) {\n+  if (callprojs->fallthrough_memproj != nullptr) {\n@@ -2040,1 +2068,1 @@\n-  if (callprojs->fallthrough_ioproj != NULL) {\n+  if (callprojs->fallthrough_ioproj != nullptr) {\n@@ -2045,1 +2073,1 @@\n-  if (callprojs->resproj[0] != NULL && result != NULL) {\n+  if (callprojs->resproj[0] != nullptr && result != nullptr) {\n@@ -2053,1 +2081,1 @@\n-  if (ejvms == NULL) {\n+  if (ejvms == nullptr) {\n@@ -2055,1 +2083,1 @@\n-    if (callprojs->catchall_catchproj != NULL) {\n+    if (callprojs->catchall_catchproj != nullptr) {\n@@ -2058,1 +2086,1 @@\n-    if (callprojs->catchall_memproj != NULL) {\n+    if (callprojs->catchall_memproj != nullptr) {\n@@ -2061,1 +2089,1 @@\n-    if (callprojs->catchall_ioproj != NULL) {\n+    if (callprojs->catchall_ioproj != nullptr) {\n@@ -2065,1 +2093,1 @@\n-    if (callprojs->exobj != NULL) {\n+    if (callprojs->exobj != nullptr) {\n@@ -2077,1 +2105,1 @@\n-    if (callprojs->catchall_catchproj != NULL) {\n+    if (callprojs->catchall_catchproj != nullptr) {\n@@ -2081,1 +2109,1 @@\n-    if (callprojs->catchall_memproj != NULL) {\n+    if (callprojs->catchall_memproj != nullptr) {\n@@ -2086,1 +2114,1 @@\n-    if (callprojs->catchall_ioproj != NULL) {\n+    if (callprojs->catchall_ioproj != nullptr) {\n@@ -2091,1 +2119,1 @@\n-    if (callprojs->exobj != NULL) {\n+    if (callprojs->exobj != nullptr) {\n@@ -2106,1 +2134,1 @@\n-  if (callprojs->fallthrough_catchproj != NULL && !final_ctl->is_top() && do_replaced_nodes) {\n+  if (callprojs->fallthrough_catchproj != nullptr && !final_ctl->is_top() && do_replaced_nodes) {\n@@ -2141,1 +2169,1 @@\n-  if (stopped())  return NULL; \/\/ trap reachable?\n+  if (stopped())  return nullptr; \/\/ trap reachable?\n@@ -2174,1 +2202,1 @@\n-      if (C->log() != NULL) {\n+      if (C->log() != nullptr) {\n@@ -2206,2 +2234,2 @@\n-  if (log != NULL) {\n-    int kid = (klass == NULL)? -1: log->identify(klass);\n+  if (log != nullptr) {\n+    int kid = (klass == nullptr)? -1: log->identify(klass);\n@@ -2213,1 +2241,1 @@\n-    if (comment != NULL)  log->print(\" comment='%s'\", comment);\n+    if (comment != nullptr)  log->print(\" comment='%s'\", comment);\n@@ -2219,1 +2247,1 @@\n-  if (i0 != NULL && i0->is_If()) {        \/\/ Found a guarding if test?\n+  if (i0 != nullptr && i0->is_If()) {        \/\/ Found a guarding if test?\n@@ -2236,1 +2264,1 @@\n-  const TypePtr* no_memory_effects = NULL;\n+  const TypePtr* no_memory_effects = nullptr;\n@@ -2271,1 +2299,1 @@\n-  if (ctrl != NULL && ctrl->is_Region() && ctrl->req() == 2 &&\n+  if (ctrl != nullptr && ctrl->is_Region() && ctrl->req() == 2 &&\n@@ -2278,1 +2306,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2300,1 +2328,1 @@\n-    const TypeKlassPtr* tklass = TypeKlassPtr::make(exact_kls);\n+    const TypeKlassPtr* tklass = TypeKlassPtr::make(exact_kls, Type::trust_interfaces);\n@@ -2317,1 +2345,1 @@\n-      if (speculative != NULL) {\n+      if (speculative != nullptr) {\n@@ -2361,1 +2389,1 @@\n-    if (data != NULL) {\n+    if (data != nullptr) {\n@@ -2363,2 +2391,2 @@\n-        ciKlass* array_type = NULL;\n-        ciKlass* element_type = NULL;\n+        ciKlass* array_type = nullptr;\n+        ciKlass* element_type = nullptr;\n@@ -2380,1 +2408,1 @@\n-            if (receiver != NULL) {\n+            if (receiver != nullptr) {\n@@ -2410,1 +2438,1 @@\n-      ciKlass* better_type = NULL;\n+      ciKlass* better_type = nullptr;\n@@ -2430,1 +2458,1 @@\n-      ciKlass* better_type = NULL;\n+      ciKlass* better_type = nullptr;\n@@ -2448,1 +2476,1 @@\n-  ciKlass* better_type = NULL;\n+  ciKlass* better_type = nullptr;\n@@ -2507,1 +2535,1 @@\n-\/\/              [in]     NULL\n+\/\/              [in]     null\n@@ -2545,1 +2573,1 @@\n-  \/\/ Initial NULL check taken path\n+  \/\/ Initial null check taken path\n@@ -2552,1 +2580,1 @@\n-    \/\/ recompile; the offending check-cast will be compiled to handle NULLs.\n+    \/\/ recompile; the offending check-cast will be compiled to handle nulls.\n@@ -2554,1 +2582,1 @@\n-    \/\/ method will be compiled to handle NULLs.\n+    \/\/ method will be compiled to handle nulls.\n@@ -2561,1 +2589,1 @@\n-    (*null_control) = top();    \/\/ NULL path is dead\n+    (*null_control) = top();    \/\/ null path is dead\n@@ -2592,1 +2620,1 @@\n-                                  \/\/ The first NULL ends the list.\n+                                  \/\/ The first null ends the list.\n@@ -2597,1 +2625,1 @@\n-  assert(call_addr != NULL, \"must not call NULL targets\");\n+  assert(call_addr != nullptr, \"must not call null targets\");\n@@ -2602,1 +2630,1 @@\n-  if (call_name == NULL) {\n+  if (call_name == nullptr) {\n@@ -2625,1 +2653,1 @@\n-  Node* prev_mem = NULL;\n+  Node* prev_mem = nullptr;\n@@ -2634,9 +2662,9 @@\n-  \/\/ Hook each parm in order.  Stop looking at the first NULL.\n-  if (parm0 != NULL) { call->init_req(TypeFunc::Parms+0, parm0);\n-  if (parm1 != NULL) { call->init_req(TypeFunc::Parms+1, parm1);\n-  if (parm2 != NULL) { call->init_req(TypeFunc::Parms+2, parm2);\n-  if (parm3 != NULL) { call->init_req(TypeFunc::Parms+3, parm3);\n-  if (parm4 != NULL) { call->init_req(TypeFunc::Parms+4, parm4);\n-  if (parm5 != NULL) { call->init_req(TypeFunc::Parms+5, parm5);\n-  if (parm6 != NULL) { call->init_req(TypeFunc::Parms+6, parm6);\n-  if (parm7 != NULL) { call->init_req(TypeFunc::Parms+7, parm7);\n+  \/\/ Hook each parm in order.  Stop looking at the first null.\n+  if (parm0 != nullptr) { call->init_req(TypeFunc::Parms+0, parm0);\n+  if (parm1 != nullptr) { call->init_req(TypeFunc::Parms+1, parm1);\n+  if (parm2 != nullptr) { call->init_req(TypeFunc::Parms+2, parm2);\n+  if (parm3 != nullptr) { call->init_req(TypeFunc::Parms+3, parm3);\n+  if (parm4 != nullptr) { call->init_req(TypeFunc::Parms+4, parm4);\n+  if (parm5 != nullptr) { call->init_req(TypeFunc::Parms+5, parm5);\n+  if (parm6 != nullptr) { call->init_req(TypeFunc::Parms+6, parm6);\n+  if (parm7 != nullptr) { call->init_req(TypeFunc::Parms+7, parm7);\n@@ -2644,1 +2672,1 @@\n-  assert(call->in(call->req()-1) != NULL, \"must initialize all parms\");\n+  assert(call->in(call->req()-1) != nullptr, \"must initialize all parms\");\n@@ -2705,1 +2733,1 @@\n-          phi = PhiNode::make(region, NULL, Type::MEMORY, mms.adr_type(C));\n+          phi = PhiNode::make(region, nullptr, Type::MEMORY, mms.adr_type(C));\n@@ -2760,1 +2788,1 @@\n-  Node* cmp = NULL;\n+  Node* cmp = nullptr;\n@@ -2766,1 +2794,1 @@\n-  gvn.transform(cmp);\n+  cmp = gvn.transform(cmp);\n@@ -2837,1 +2865,1 @@\n-  Node *chk_off = gvn.transform(new LoadINode(NULL, m, p1, gvn.type(p1)->is_ptr(), TypeInt::INT, MemNode::unordered));\n+  Node *chk_off = gvn.transform(new LoadINode(nullptr, m, p1, gvn.type(p1)->is_ptr(), TypeInt::INT, MemNode::unordered));\n@@ -2845,2 +2873,2 @@\n-  \/\/ Worst-case type is a little odd: NULL is allowed as a result (usually\n-  \/\/ klass loads can never produce a NULL).\n+  \/\/ Worst-case type is a little odd: null is allowed as a result (usually\n+  \/\/ klass loads can never produce a null).\n@@ -2861,1 +2889,1 @@\n-  if (might_be_cache && mem != NULL) {\n+  if (might_be_cache && mem != nullptr) {\n@@ -2864,1 +2892,1 @@\n-  Node *nkls = gvn.transform(LoadKlassNode::make(gvn, NULL, kmem, p2, gvn.type(p2)->is_ptr(), TypeInstKlassPtr::OBJECT_OR_NULL));\n+  Node *nkls = gvn.transform(LoadKlassNode::make(gvn, nullptr, kmem, p2, gvn.type(p2)->is_ptr(), TypeInstKlassPtr::OBJECT_OR_NULL));\n@@ -2947,1 +2975,1 @@\n-  if (sub_t->make_oopptr() != NULL && sub_t->make_oopptr()->is_inlinetypeptr()) {\n+  if (sub_t->make_oopptr() != nullptr && sub_t->make_oopptr()->is_inlinetypeptr()) {\n@@ -2988,1 +3016,1 @@\n-  const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);\n+  const TypeKlassPtr* tklass = TypeKlassPtr::make(klass, Type::trust_interfaces);\n@@ -3028,1 +3056,1 @@\n-  const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);\n+  const TypeKlassPtr* tklass = TypeKlassPtr::make(klass, Type::trust_interfaces)->try_improve();\n@@ -3037,1 +3065,1 @@\n-    if (receiver_type != NULL && !receiver_type->higher_equal(recv_type)) { \/\/ ignore redundant casts\n+    if (receiver_type != nullptr && !receiver_type->higher_equal(recv_type)) { \/\/ ignore redundant casts\n@@ -3052,1 +3080,1 @@\n-\/\/ recompile; the offending check will be recompiled to handle NULLs.\n+\/\/ recompile; the offending check will be recompiled to handle nulls.\n@@ -3065,1 +3093,1 @@\n-    if (data == NULL)\n+    if (data == nullptr)\n@@ -3084,1 +3112,1 @@\n-  Node* init_state = LoadNode::make(_gvn, NULL, immutable_memory(), adr,\n+  Node* init_state = LoadNode::make(_gvn, nullptr, immutable_memory(), adr,\n@@ -3103,1 +3131,1 @@\n-  Node* init_thread = LoadNode::make(_gvn, NULL, immutable_memory(), adr,\n+  Node* init_thread = LoadNode::make(_gvn, nullptr, immutable_memory(), adr,\n@@ -3131,1 +3159,1 @@\n-                  NULL);\n+                  nullptr);\n@@ -3142,1 +3170,1 @@\n-  if (!UseTypeProfile || !TypeProfileCasts) return NULL;\n+  if (!UseTypeProfile || !TypeProfileCasts) return nullptr;\n@@ -3144,1 +3172,1 @@\n-  Deoptimization::DeoptReason reason = Deoptimization::reason_class_check(spec_klass != NULL);\n+  Deoptimization::DeoptReason reason = Deoptimization::reason_class_check(spec_klass != nullptr);\n@@ -3148,1 +3176,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3155,1 +3183,1 @@\n-  if (exact_kls == NULL) {\n+  if (exact_kls == nullptr) {\n@@ -3157,2 +3185,2 @@\n-      ciKlass* array_type = NULL;\n-      ciKlass* element_type = NULL;\n+      ciKlass* array_type = nullptr;\n+      ciKlass* element_type = nullptr;\n@@ -3168,3 +3196,3 @@\n-  if (exact_kls != NULL) {\/\/ no cast failures here\n-    if (require_klass == NULL ||\n-        C->static_subtype_check(require_klass, TypeKlassPtr::make(exact_kls)) == Compile::SSC_always_true) {\n+  if (exact_kls != nullptr) {\/\/ no cast failures here\n+    if (require_klass == nullptr ||\n+        C->static_subtype_check(require_klass, TypeKlassPtr::make(exact_kls, Type::trust_interfaces)) == Compile::SSC_always_true) {\n@@ -3192,1 +3220,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -3210,2 +3238,2 @@\n-  \/\/ type == NULL if profiling tells us this object is always null\n-  if (type != NULL) {\n+  \/\/ type is null if profiling tells us this object is always null\n+  if (type != nullptr) {\n@@ -3217,1 +3245,1 @@\n-      Node* not_null_obj = NULL;\n+      Node* not_null_obj = nullptr;\n@@ -3265,1 +3293,1 @@\n-  ciProfileData* data = NULL;\n+  ciProfileData* data = nullptr;\n@@ -3278,1 +3306,1 @@\n-  if (stopped()) {              \/\/ Doing instance-of on a NULL?\n+  if (stopped()) {              \/\/ Doing instance-of on a null?\n@@ -3297,1 +3325,1 @@\n-    if (subk != NULL && subk->is_loaded()) {\n+    if (subk != nullptr && subk->is_loaded()) {\n@@ -3308,2 +3336,2 @@\n-    if (spec_obj_type != NULL || (ProfileDynamicTypes && data != NULL)) {\n-      Node* cast_obj = maybe_cast_profiled_receiver(not_null_obj, NULL, spec_obj_type, safe_for_replace);\n+    if (spec_obj_type != nullptr || (ProfileDynamicTypes && data != nullptr)) {\n+      Node* cast_obj = maybe_cast_profiled_receiver(not_null_obj, nullptr, spec_obj_type, safe_for_replace);\n@@ -3314,1 +3342,1 @@\n-      if (cast_obj != NULL) {\n+      if (cast_obj != nullptr) {\n@@ -3355,3 +3383,3 @@\n-  const TypeKlassPtr* tk = _gvn.type(superklass)->is_klassptr();\n-  const TypeOopPtr* toop = tk->cast_to_exactness(false)->as_instance_type();\n-  bool safe_for_replace = (failure_control == NULL);\n+  const TypeKlassPtr *tk = _gvn.type(superklass)->is_klassptr()->try_improve();\n+  const TypeOopPtr *toop = tk->cast_to_exactness(false)->as_instance_type();\n+  bool safe_for_replace = (failure_control == nullptr);\n@@ -3367,1 +3395,1 @@\n-    const TypeKlassPtr* kptr = NULL;\n+    const TypeKlassPtr* kptr = nullptr;\n@@ -3373,1 +3401,1 @@\n-      kptr = TypeInstKlassPtr::make(TypePtr::NotNull, vk, Type::Offset(0), vk->flatten_array());\n+      kptr = TypeInstKlassPtr::make(TypePtr::NotNull, vk, Type::Offset(0));\n@@ -3375,1 +3403,1 @@\n-    if (kptr != NULL) {\n+    if (kptr != nullptr) {\n@@ -3394,1 +3422,1 @@\n-        if (t->isa_oopptr() != NULL && !t->is_oopptr()->maybe_null()) {\n+        if (t->isa_oopptr() != nullptr && !t->is_oopptr()->maybe_null()) {\n@@ -3410,2 +3438,2 @@\n-  ciProfileData* data = NULL;\n-  if (failure_control == NULL) {        \/\/ use MDO in regular case only\n+  ciProfileData* data = nullptr;\n+  if (failure_control == nullptr) {        \/\/ use MDO in regular case only\n@@ -3431,1 +3459,1 @@\n-  bool never_see_null = ((failure_control == NULL)  \/\/ regular case only\n+  bool never_see_null = ((failure_control == nullptr)  \/\/ regular case only\n@@ -3443,1 +3471,1 @@\n-  Node* not_null_obj = NULL;\n+  Node* not_null_obj = nullptr;\n@@ -3452,1 +3480,1 @@\n-  if (stopped()) {              \/\/ Doing instance-of on a NULL?\n+  if (stopped()) {              \/\/ Doing instance-of on a null?\n@@ -3469,1 +3497,1 @@\n-  Node* cast_obj = NULL;\n+  Node* cast_obj = nullptr;\n@@ -3479,1 +3507,1 @@\n-    if (spec_obj_type != NULL || data != NULL) {\n+    if (spec_obj_type != nullptr || data != nullptr) {\n@@ -3481,2 +3509,2 @@\n-      if (cast_obj != NULL) {\n-        if (failure_control != NULL) \/\/ failure is now impossible\n+      if (cast_obj != nullptr) {\n+        if (failure_control != nullptr) \/\/ failure is now impossible\n@@ -3490,1 +3518,1 @@\n-  if (cast_obj == NULL) {\n+  if (cast_obj == nullptr) {\n@@ -3497,1 +3525,1 @@\n-    if (failure_control == NULL) {\n+    if (failure_control == nullptr) {\n@@ -3501,1 +3529,1 @@\n-        Node* obj_klass = NULL;\n+        Node* obj_klass = nullptr;\n@@ -3520,1 +3548,1 @@\n-  \/\/ A merge of NULL or Casted-NotNull obj\n+  \/\/ A merge of null or Casted-NotNull obj\n@@ -3542,1 +3570,1 @@\n-    Node* array = NULL;\n+    Node* array = nullptr;\n@@ -3551,1 +3579,1 @@\n-      if (region->req() == 3 && region->in(2) != NULL && region->in(2)->in(0) != NULL) {\n+      if (region->req() == 3 && region->in(2) != nullptr && region->in(2)->in(0) != nullptr) {\n@@ -3553,1 +3581,1 @@\n-        if (iff != NULL) {\n+        if (iff != nullptr) {\n@@ -3558,1 +3586,1 @@\n-    if (array != NULL) {\n+    if (array != nullptr) {\n@@ -3560,1 +3588,1 @@\n-      if (ary_t != NULL) {\n+      if (ary_t != nullptr) {\n@@ -3591,1 +3619,1 @@\n-  Node* mark = make_load(NULL, mark_adr, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n+  Node* mark = make_load(nullptr, mark_adr, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n@@ -3608,1 +3636,1 @@\n-  Node* lh_val = _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), lh_adr, lh_adr->bottom_type()->is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));\n+  Node* lh_val = _gvn.transform(LoadNode::make(_gvn, nullptr, immutable_memory(), lh_adr, lh_adr->bottom_type()->is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));\n@@ -3725,1 +3753,1 @@\n-    return NULL;                \/\/ Not locking things?\n+    return nullptr;                \/\/ Not locking things?\n@@ -3728,1 +3756,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3828,1 +3856,1 @@\n-\/\/ and return (Node*)NULL.  Otherwise, load the non-constant\n+\/\/ and return null.  Otherwise, load the non-constant\n@@ -3834,1 +3862,1 @@\n-  if (!StressReflectiveCode && inst_klass != NULL) {\n+  if (!StressReflectiveCode && inst_klass != nullptr) {\n@@ -3838,1 +3866,1 @@\n-    if (UseFlatArray && !xklass && ary_type != NULL && !ary_type->is_null_free()) {\n+    if (UseFlatArray && !xklass && ary_type != nullptr && !ary_type->is_null_free()) {\n@@ -3858,1 +3886,1 @@\n-        return (Node*) NULL;\n+        return (Node*) nullptr;\n@@ -3864,1 +3892,1 @@\n-  return make_load(NULL, lhp, TypeInt::INT, T_INT, MemNode::unordered);\n+  return make_load(nullptr, lhp, TypeInt::INT, T_INT, MemNode::unordered);\n@@ -3877,1 +3905,1 @@\n-  if (init_out_raw != NULL) {\n+  if (init_out_raw != nullptr) {\n@@ -3937,1 +3965,1 @@\n-          if (field->offset() >= TrackedInitializationLimit * HeapWordSize)\n+          if (field->offset_in_bytes() >= TrackedInitializationLimit * HeapWordSize)\n@@ -3939,1 +3967,1 @@\n-          int off_in_vt = field->offset() - vk->first_field_offset();\n+          int off_in_vt = field->offset_in_bytes() - vk->first_field_offset();\n@@ -3942,1 +3970,1 @@\n-          \/\/ Pass NULL for init_out. Having per flat array element field memory edges as uses of the Initialize node\n+          \/\/ Pass nullptr for init_out. Having per flat array element field memory edges as uses of the Initialize node\n@@ -3945,1 +3973,1 @@\n-          hook_memory_on_init(*this, fieldidx, minit_in, NULL);\n+          hook_memory_on_init(*this, fieldidx, minit_in, nullptr);\n@@ -3959,1 +3987,1 @@\n-        if (field->offset() >= TrackedInitializationLimit * HeapWordSize)\n+        if (field->offset_in_bytes() >= TrackedInitializationLimit * HeapWordSize)\n@@ -4014,1 +4042,1 @@\n-  bool  layout_is_con = (layout_val == NULL);\n+  bool  layout_is_con = (layout_val == nullptr);\n@@ -4016,1 +4044,1 @@\n-  if (extra_slow_test == NULL)  extra_slow_test = intcon(0);\n+  if (extra_slow_test == nullptr)  extra_slow_test = intcon(0);\n@@ -4018,1 +4046,1 @@\n-  \/\/ Node for 1) or NEVER (return a NULL) or perhaps (in the reflective\n+  \/\/ Node for 1) or NEVER (return a null) or perhaps (in the reflective\n@@ -4020,1 +4048,1 @@\n-  Node* initial_slow_test = NULL;\n+  Node* initial_slow_test = nullptr;\n@@ -4039,1 +4067,1 @@\n-  Node* size = NULL;\n+  Node* size = nullptr;\n@@ -4051,1 +4079,1 @@\n-  if (return_size_val != NULL) {\n+  if (return_size_val != nullptr) {\n@@ -4088,1 +4116,1 @@\n-  bool  layout_is_con = (layout_val == NULL);\n+  bool  layout_is_con = (layout_val == nullptr);\n@@ -4103,1 +4131,1 @@\n-    layout_val = NULL;\n+    layout_val = nullptr;\n@@ -4130,1 +4158,1 @@\n-  Node* header_size = NULL;\n+  Node* header_size = nullptr;\n@@ -4152,1 +4180,1 @@\n-  Node* elem_shift = NULL;\n+  Node* elem_shift = nullptr;\n@@ -4169,1 +4197,1 @@\n-    if (tilen != NULL && tilen->_lo < 0) {\n+    if (tilen != nullptr && tilen->_lo < 0) {\n@@ -4206,1 +4234,1 @@\n-  if (elem_shift != NULL)\n+  if (elem_shift != nullptr)\n@@ -4215,1 +4243,1 @@\n-  if (return_size_val != NULL) {\n+  if (return_size_val != nullptr) {\n@@ -4242,3 +4270,3 @@\n-  Node* default_value = NULL;\n-  Node* raw_default_value = NULL;\n-  if (ary_ptr != NULL && ary_ptr->klass_is_exact()) {\n+  Node* default_value = nullptr;\n+  Node* raw_default_value = nullptr;\n+  if (ary_ptr != nullptr && ary_ptr->klass_is_exact()) {\n@@ -4247,1 +4275,1 @@\n-      ciInlineKlass* vk = ary_ptr->elem()->make_oopptr()->inline_klass();\n+      ciInlineKlass* vk = ary_ptr->elem()->inline_klass();\n@@ -4280,1 +4308,1 @@\n-  if (default_value != NULL) {\n+  if (default_value != nullptr) {\n@@ -4313,1 +4341,1 @@\n-  if (ary_type->isa_aryptr() && length_type != NULL) {\n+  if (ary_type->isa_aryptr() && length_type != nullptr) {\n@@ -4330,2 +4358,2 @@\n-  if (ptr == NULL) {     \/\/ reduce dumb test in callers\n-    return NULL;\n+  if (ptr == nullptr) {     \/\/ reduce dumb test in callers\n+    return nullptr;\n@@ -4339,1 +4367,1 @@\n-    if (ptr == NULL) return NULL;\n+    if (ptr == nullptr) return nullptr;\n@@ -4341,1 +4369,1 @@\n-  \/\/ Return NULL for allocations with several casts:\n+  \/\/ Return null for allocations with several casts:\n@@ -4347,1 +4375,1 @@\n-    if (allo != NULL && allo->is_Allocate()) {\n+    if (allo != nullptr && allo->is_Allocate()) {\n@@ -4352,1 +4380,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4359,1 +4387,1 @@\n-  if (base == NULL)  return NULL;\n+  if (base == nullptr)  return nullptr;\n@@ -4372,1 +4400,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4378,1 +4406,1 @@\n-  if (rawoop == NULL)  return NULL;\n+  if (rawoop == nullptr)  return nullptr;\n@@ -4386,1 +4414,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4389,4 +4417,2 @@\n-\/\/----------------------------- loop predicates ---------------------------\n-\n-\/\/------------------------------add_predicate_impl----------------------------\n-void GraphKit::add_empty_predicate_impl(Deoptimization::DeoptReason reason, int nargs) {\n+\/\/ Add a Parse Predicate with an uncommon trap on the failing\/false path. Normal control will continue on the true path.\n+void GraphKit::add_parse_predicate(Deoptimization::DeoptReason reason, const int nargs) {\n@@ -4405,1 +4431,1 @@\n-    \/\/ do not generate predicate.\n+    \/\/ do not generate Parse Predicate.\n@@ -4409,1 +4435,1 @@\n-  Node *cont    = _gvn.intcon(1);\n+  Node* cont    = _gvn.intcon(1);\n@@ -4411,1 +4437,1 @@\n-  Node *bol     = _gvn.transform(new Conv2BNode(opq));\n+  Node* bol     = _gvn.transform(new Conv2BNode(opq));\n@@ -4414,1 +4440,1 @@\n-  C->add_predicate_opaq(opq);\n+  C->add_parse_predicate_opaq(opq);\n@@ -4425,5 +4451,3 @@\n-\/\/------------------------------add_predicate---------------------------------\n-void GraphKit::add_empty_predicates(int nargs) {\n-  \/\/ These loop predicates remain empty. All concrete loop predicates are inserted above the corresponding\n-  \/\/ empty loop predicate later by 'PhaseIdealLoop::create_new_if_for_predicate'. All concrete loop predicates of\n-  \/\/ a specific kind (normal, profile or limit check) share the same uncommon trap as the empty loop predicate.\n+\/\/ Add Parse Predicates which serve as placeholders to create new Runtime Predicates above them. All\n+\/\/ Runtime Predicates inside a Runtime Predicate block share the same uncommon trap as the Parse Predicate.\n+void GraphKit::add_parse_predicates(int nargs) {\n@@ -4431,1 +4455,1 @@\n-    add_empty_predicate_impl(Deoptimization::Reason_predicate, nargs);\n+    add_parse_predicate(Deoptimization::Reason_predicate, nargs);\n@@ -4434,1 +4458,1 @@\n-    add_empty_predicate_impl(Deoptimization::Reason_profile_predicate, nargs);\n+    add_parse_predicate(Deoptimization::Reason_profile_predicate, nargs);\n@@ -4436,2 +4460,2 @@\n-  \/\/ loop's limit check predicate should be near the loop.\n-  add_empty_predicate_impl(Deoptimization::Reason_loop_limit_check, nargs);\n+  \/\/ Loop Limit Check Predicate should be near the loop.\n+  add_parse_predicate(Deoptimization::Reason_loop_limit_check, nargs);\n@@ -4461,1 +4485,1 @@\n-                                                     false, NULL, Type::Offset(0));\n+                                                     false, nullptr, Type::Offset(0));\n@@ -4464,1 +4488,1 @@\n-                                                  TypeAry::make(TypeInt::BYTE, TypeInt::POS, false, true, true),\n+                                                  TypeAry::make(TypeInt::BYTE, TypeInt::POS, false, false, true, true),\n@@ -4478,1 +4502,1 @@\n-                                                     false, NULL, Type::Offset(0));\n+                                                     false, nullptr, Type::Offset(0));\n@@ -4490,1 +4514,1 @@\n-                                                     false, NULL, Type::Offset(0));\n+                                                     false, nullptr, Type::Offset(0));\n@@ -4500,1 +4524,1 @@\n-                                                     false, NULL, Type::Offset(0));\n+                                                     false, nullptr, Type::Offset(0));\n@@ -4561,1 +4585,1 @@\n-  add_empty_predicates();\n+  add_parse_predicates();\n@@ -4601,1 +4625,1 @@\n-    return NULL; \/\/ Field not marked as constant.\n+    return nullptr; \/\/ Field not marked as constant.\n@@ -4603,1 +4627,1 @@\n-  ciInstance* holder = NULL;\n+  ciInstance* holder = nullptr;\n@@ -4606,1 +4630,1 @@\n-    if (const_oop != NULL && const_oop->is_instance()) {\n+    if (const_oop != nullptr && const_oop->is_instance()) {\n@@ -4612,1 +4636,1 @@\n-  if (con_type != NULL) {\n+  if (con_type != nullptr) {\n@@ -4621,1 +4645,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4628,1 +4652,1 @@\n-  Node* load = make_load(NULL, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n+  Node* load = make_load(nullptr, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":311,"deletions":287,"binary":false,"changes":598,"status":"modified"},{"patch":"@@ -37,10 +37,4 @@\n-uint InlineTypeNode::size_of() const {\n-  return sizeof(*this);\n-}\n-\n-uint InlineTypeNode::hash() const {\n-  return TypeNode::hash() + _is_buffered;\n-}\n-\n-bool InlineTypeNode::cmp(const Node& n) const {\n-  return TypeNode::cmp(n) && ((InlineTypeNode&)n)._is_buffered == _is_buffered;\n+int  InlineTypeNode::stack_size_for_field(ciField* field) {\n+  return field->is_multifield_base()\n+             ? field->type()->elem_word_count()\n+             : field->type()->size();\n@@ -50,0 +44,3 @@\n+  if (!field->is_multifield_base()) {\n+    return true;\n+  }\n@@ -52,4 +49,3 @@\n-  if (field_count > 1 &&\n-      (!Matcher::match_rule_supported_vector(Op_LoadVector, field_count, bt) ||\n-       !Matcher::match_rule_supported_vector(Op_StoreVector, field_count, bt) ||\n-       !Matcher::match_rule_supported_vector(VectorNode::replicate_opcode(bt), field_count, bt))) {\n+  if (!Matcher::match_rule_supported_vector(Op_LoadVector, field_count, bt)  ||\n+      !Matcher::match_rule_supported_vector(Op_StoreVector, field_count, bt) ||\n+      !Matcher::match_rule_supported_vector(VectorNode::replicate_opcode(bt), field_count, bt)) {\n@@ -81,6 +77,3 @@\n-  if (vt->is_InlineType()) {\n-    \/\/ Use nullable type\n-    const Type* t = Type::get_const_type(inline_klass());\n-    gvn->set_type(vt, t);\n-    vt->as_InlineType()->set_type(t);\n-  }\n+  const Type* t = Type::get_const_type(inline_klass());\n+  gvn->set_type(vt, t);\n+  vt->as_InlineType()->set_type(t);\n@@ -89,3 +82,2 @@\n-  const Type* phi_type = Type::get_const_type(inline_klass());\n-  PhiNode* oop = PhiNode::make(region, vt->get_oop(), phi_type);\n-  gvn->set_type(oop, phi_type);\n+  PhiNode* oop = PhiNode::make(region, vt->get_oop(), t);\n+  gvn->set_type(oop, t);\n@@ -95,0 +87,7 @@\n+  \/\/ Create a PhiNode for merging the is_buffered values\n+  t = Type::get_const_basic_type(T_BOOLEAN);\n+  Node* is_buffered_node = PhiNode::make(region, vt->get_is_buffered(), t);\n+  gvn->set_type(is_buffered_node, t);\n+  gvn->record_for_igvn(is_buffered_node);\n+  vt->set_req(IsBuffered, is_buffered_node);\n+\n@@ -100,3 +99,3 @@\n-    phi_type = Type::get_const_basic_type(T_BOOLEAN);\n-    is_init_node = PhiNode::make(region, vt->get_is_init(), phi_type);\n-    gvn->set_type(is_init_node, phi_type);\n+    t = Type::get_const_basic_type(T_BOOLEAN);\n+    is_init_node = PhiNode::make(region, vt->get_is_init(), t);\n+    gvn->set_type(is_init_node, t);\n@@ -111,1 +110,5 @@\n-    if (value->is_InlineType()) {\n+    \/\/ We limit scalarization for inline types with circular fields and can therefore observe nodes\n+    \/\/ of the same type but with different scalarization depth during IGVN. To avoid inconsistencies\n+    \/\/ during merging, make sure that we only create Phis for fields that are guaranteed to be scalarized.\n+    bool no_circularity = !gvn->C->has_circular_inline_type() || !gvn->is_IterGVN() || field_is_flattened(i);\n+    if (value->is_InlineType() && no_circularity) {\n@@ -115,1 +118,1 @@\n-      phi_type = Type::get_const_type(type);\n+      t = Type::get_const_type(type);\n@@ -118,1 +121,1 @@\n-        phi_type = TypeVect::make(phi_type, vt->secondary_fields_count(i));\n+        t = TypeVect::make(t, vt->secondary_fields_count(i));\n@@ -120,2 +123,2 @@\n-      value = PhiNode::make(region, value, phi_type);\n-      gvn->set_type(value, phi_type);\n+      value = PhiNode::make(region, value, t);\n+      gvn->set_type(value, t);\n@@ -126,1 +129,0 @@\n-  gvn->set_type(vt, vt->bottom_type());\n@@ -155,1 +157,0 @@\n-  _is_buffered = _is_buffered && other->_is_buffered;\n@@ -163,0 +164,8 @@\n+  \/\/ Merge is_buffered inputs\n+  phi = get_is_buffered()->as_Phi();\n+  phi->set_req(pnum, other->get_is_buffered());\n+  if (transform) {\n+    set_req(IsBuffered, gvn->transform(phi));\n+  }\n+\n+  \/\/ Merge is_init inputs\n@@ -199,0 +208,4 @@\n+  phi = get_is_buffered()->as_Phi();\n+  phi->add_req(NULL);\n+  assert(phi->req() == region->req(), \"must be same size as region\");\n+\n@@ -255,1 +268,1 @@\n-  return inline_klass()->declared_nonstatic_field_at(index)->offset();\n+  return inline_klass()->declared_nonstatic_field_at(index)->offset_in_bytes();\n@@ -299,0 +312,8 @@\n+static bool is_vector_payload(ciKlass* klass) {\n+  return klass->is_subclass_of(ciEnv::current()->vector_VectorPayload_klass());\n+}\n+\n+static bool is_vector_payload_mf(ciKlass* klass) {\n+  return klass->is_subclass_of(ciEnv::current()->vector_VectorPayloadMF_klass());\n+}\n+\n@@ -302,0 +323,9 @@\n+  \/\/ Number of fields for VectorPayload* class which a safepoint node tracks\n+  \/\/ should depend on actual field_count of InlineTypeNode, this is because\n+  \/\/ we may scalarize multifield bundle if corresponding vector size is not\n+  \/\/ supported by target.\n+  if (is_vector_payload_mf(vk)) {\n+     nfields = field_count();\n+  } else if (is_vector_payload(vk)) {\n+     nfields = field_value(0)->as_InlineType()->field_count();\n+  }\n@@ -325,0 +355,2 @@\n+  int cnt = 0;\n+  ciMultiField* mfield = nullptr;\n@@ -326,1 +358,9 @@\n-    int offset = vk->nonstatic_field_at(j)->offset();\n+    ciField* field = mfield != nullptr ? mfield->secondary_field_at(cnt++) : vk->nonstatic_field_at(j);\n+    if (field->is_multifield_base()) {\n+      mfield = static_cast<ciMultiField*>(field);\n+    }\n+    if (mfield && ((mfield->secondary_fields_count() - 1) == cnt)) {\n+      mfield = nullptr;\n+      cnt = 0;\n+    }\n+    int offset = field->offset_in_bytes();\n@@ -411,5 +451,11 @@\n-void InlineTypeNode::load(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) {\n-  \/\/ FIXME: It is possible that \"base\" is a constant NULL_PTR, which is\n-  \/\/ created by \"gvn.zerocon(T_PRIMITIVE_OBJECT)\". It has to do special\n-  \/\/ handling for such cases.\n-  assert(!kit->gvn().type(base)->maybe_null(), \"the memory cannot be null\");\n+\/\/ We limit scalarization for inline types with circular fields and can therefore observe\n+\/\/ nodes of same type but with different scalarization depth during GVN. This method adjusts\n+\/\/ the scalarization depth to avoid inconsistencies during merging.\n+InlineTypeNode* InlineTypeNode::adjust_scalarization_depth(GraphKit* kit) {\n+  if (!kit->C->has_circular_inline_type()) {\n+    return this;\n+  }\n+  GrowableArray<ciType*> visited;\n+  visited.push(inline_klass());\n+  return adjust_scalarization_depth_impl(kit, visited);\n+}\n@@ -417,0 +463,32 @@\n+InlineTypeNode* InlineTypeNode::adjust_scalarization_depth_impl(GraphKit* kit, GrowableArray<ciType*>& visited) {\n+  InlineTypeNode* val = this;\n+  for (uint i = 0; i < field_count(); ++i) {\n+    Node* value = field_value(i);\n+    Node* new_value = value;\n+    ciType* ft = field_type(i);\n+    if (value->is_InlineType()) {\n+      if (!field_is_flattened(i) && visited.contains(ft)) {\n+        new_value = value->as_InlineType()->buffer(kit)->get_oop();\n+      } else {\n+        int old_len = visited.length();\n+        visited.push(ft);\n+        new_value = value->as_InlineType()->adjust_scalarization_depth_impl(kit, visited);\n+        visited.trunc_to(old_len);\n+      }\n+    } else if (ft->is_inlinetype() && !visited.contains(ft)) {\n+      int old_len = visited.length();\n+      visited.push(ft);\n+      new_value = make_from_oop_impl(kit, value, ft->as_inline_klass(), field_is_null_free(i), visited);\n+      visited.trunc_to(old_len);\n+    }\n+    if (value != new_value) {\n+      if (val == this) {\n+        val = clone()->as_InlineType();\n+      }\n+      val->set_field_value(i, new_value);\n+    }\n+  }\n+  return (val == this) ? this : kit->gvn().transform(val)->as_InlineType();\n+}\n+\n+void InlineTypeNode::load(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, GrowableArray<ciType*>& visited, int holder_offset, DecoratorSet decorators) {\n@@ -426,1 +504,1 @@\n-      value = InlineTypeNode::make_default(kit->gvn(), ft->as_inline_klass());\n+      value = make_default_impl(kit->gvn(), ft->as_inline_klass(), visited);\n@@ -429,1 +507,1 @@\n-      value = InlineTypeNode::make_from_flattened(kit, ft->as_inline_klass(), base, ptr, holder, offset, decorators);\n+      value = make_from_flattened_impl(kit, ft->as_inline_klass(), base, ptr, holder, offset, decorators, visited);\n@@ -452,0 +530,1 @@\n+        ciField* field = holder->get_field_by_offset(offset, false);\n@@ -456,5 +535,1 @@\n-        if (is_array) {\n-          decorators |= IS_ARRAY;\n-        }\n-        int bundle_size = ft->bundle_size();\n-        bool load_bundle = bundle_size > 1 ? Matcher::match_rule_supported_vector(Op_LoadVector, bundle_size, bt): false;\n+        bool load_bundle = !InlineTypeNode::is_multifield_scalarized(field);\n@@ -462,1 +537,1 @@\n-          value = kit->gvn().transform(LoadVectorNode::make(0, kit->control(), kit->memory(adr), adr, adr_type, bundle_size, bt));\n+          value = kit->gvn().transform(LoadVectorNode::make(0, kit->control(), kit->memory(adr), adr, adr_type, ft->bundle_size(), bt));\n@@ -464,1 +539,1 @@\n-          value = kit->access_load_at(base, adr, adr_type, val_type, bt, decorators);\n+          value = kit->access_load_at(base, adr, adr_type, val_type, bt, is_array ? (decorators | IS_ARRAY) : decorators);\n@@ -468,2 +543,7 @@\n-      if (ft->is_inlinetype()) {\n-        value = InlineTypeNode::make_from_oop(kit, value, ft->as_inline_klass(), null_free);\n+      if (visited.contains(ft)) {\n+        kit->C->set_has_circular_inline_type(true);\n+      } else if (ft->is_inlinetype()) {\n+        int old_len = visited.length();\n+        visited.push(ft);\n+        value = make_from_oop_impl(kit, value, ft->as_inline_klass(), null_free, visited);\n+        visited.trunc_to(old_len);\n@@ -497,4 +577,1 @@\n-      if (!value->is_InlineType()) {\n-        \/\/ Recursively store the flattened inline type field\n-        value = InlineTypeNode::make_from_oop(kit, value, ft->as_inline_klass());\n-      }\n+      \/\/ Recursively store the flattened inline type field\n@@ -513,5 +590,2 @@\n-        const TypeAryPtr* ary_type = kit->gvn().type(base)->isa_aryptr();\n-        if (ary_type != NULL) {\n-          decorators |= IS_ARRAY;\n-        }\n-        kit->access_store_at(base, adr, adr_type, value, val_type, bt, decorators);\n+        bool is_array = (kit->gvn().type(base)->isa_aryptr() != nullptr);\n+        kit->access_store_at(base, adr, adr_type, value, val_type, bt, is_array ? (decorators | IS_ARRAY) : decorators);\n@@ -525,1 +599,1 @@\n-  if (_is_buffered) {\n+  if (kit->gvn().find_int_con(get_is_buffered(), 0) == 1) {\n@@ -536,1 +610,1 @@\n-    vt->_is_buffered = true;\n+    vt->set_is_buffered(kit->gvn());\n@@ -607,1 +681,1 @@\n-  vt->_is_buffered = true;\n+  vt->set_is_buffered(kit->gvn());\n@@ -620,1 +694,1 @@\n-  if (_is_buffered) {\n+  if (phase->find_int_con(get_is_buffered(), 0) == 1) {\n@@ -654,1 +728,1 @@\n-      field = field_value_by_offset(f->offset(), true);\n+      field = field_value_by_offset(f->offset_in_bytes(), true);\n@@ -712,5 +786,3 @@\n-  \/\/ An InlineTypeNode in larval state is up for updation and\n-  \/\/ should not be replaced by precomputed default oops.\n-  Node* alloc = AllocateNode::Ideal_allocation(oop, phase);\n-  bool is_larval_alloc = alloc && alloc->as_Allocate()->_larval == true;\n-  if (!is_larval_alloc && is_default(phase) && inline_klass()->is_initialized() &&\n+  if (!is_larval(phase) &&\n+      is_default(phase) &&\n+      inline_klass()->is_initialized() &&\n@@ -726,0 +798,1 @@\n+    set_is_buffered(*phase);\n@@ -772,1 +845,2 @@\n-  InlineTypeNode* vt = new InlineTypeNode(vk, oop, null_free, vk->is_empty() && vk->is_initialized());\n+  InlineTypeNode* vt = new InlineTypeNode(vk, oop, null_free);\n+  vt->set_is_buffered(gvn, vk->is_empty() && vk->is_initialized());\n@@ -794,0 +868,6 @@\n+  GrowableArray<ciType*> visited;\n+  visited.push(vk);\n+  return make_default_impl(gvn, vk, visited);\n+}\n+\n+InlineTypeNode* InlineTypeNode::make_default_impl(PhaseGVN& gvn, ciInlineKlass* vk, GrowableArray<ciType*>& visited) {\n@@ -796,1 +876,2 @@\n-  InlineTypeNode* vt = new InlineTypeNode(vk, oop, true, vk->is_initialized());\n+  InlineTypeNode* vt = new InlineTypeNode(vk, oop, \/* null_free= *\/ true);\n+  vt->set_is_buffered(gvn, vk->is_initialized());\n@@ -799,4 +880,8 @@\n-    ciType* field_type = vt->field_type(i);\n-    Node* value = default_value(gvn, field_type);\n-    if (field_type->is_inlinetype()) {\n-      ciInlineKlass* vk = field_type->as_inline_klass();\n+    ciType* ft = vt->field_type(i);\n+    Node* value = default_value(gvn, ft);\n+    if (!vt->field_is_flattened(i) && visited.contains(ft)) {\n+      gvn.C->set_has_circular_inline_type(true);\n+    } else if (ft->is_inlinetype()) {\n+      int old_len = visited.length();\n+      visited.push(ft);\n+      ciInlineKlass* vk = ft->as_inline_klass();\n@@ -804,1 +889,1 @@\n-        value = make_default(gvn, vk);\n+        value = make_default_impl(gvn, vk, visited);\n@@ -806,1 +891,1 @@\n-        value = InlineTypeNode::make_null(gvn, vk);\n+        value = make_null_impl(gvn, vk, visited);\n@@ -808,0 +893,1 @@\n+      visited.trunc_to(old_len);\n@@ -841,0 +927,6 @@\n+  GrowableArray<ciType*> visited;\n+  visited.push(vk);\n+  return make_from_oop_impl(kit, oop, vk, null_free, visited);\n+}\n+\n+InlineTypeNode* InlineTypeNode::make_from_oop_impl(GraphKit* kit, Node* oop, ciInlineKlass* vk, bool null_free, GrowableArray<ciType*>& visited) {\n@@ -844,1 +936,1 @@\n-    InlineTypeNode* def = make_default(gvn, vk);\n+    InlineTypeNode* def = make_default_impl(gvn, vk, visited);\n@@ -862,1 +954,1 @@\n-        vt = make_default(gvn, vk);\n+        vt = make_default_impl(gvn, vk, visited);\n@@ -864,1 +956,1 @@\n-        vt = InlineTypeNode::make_null(gvn, vk);\n+        vt = make_null_impl(gvn, vk, visited);\n@@ -869,1 +961,2 @@\n-    vt = new InlineTypeNode(vk, not_null_oop, null_free, true);\n+    vt = new InlineTypeNode(vk, not_null_oop, null_free);\n+    vt->set_is_buffered(gvn);\n@@ -871,1 +964,1 @@\n-    vt->load(kit, not_null_oop, not_null_oop, vk, \/* holder_offset *\/ 0);\n+    vt->load(kit, not_null_oop, not_null_oop, vk, visited);\n@@ -876,1 +969,1 @@\n-        null_vt = make_default(gvn, vk);\n+        null_vt = make_default_impl(gvn, vk, visited);\n@@ -878,1 +971,1 @@\n-        null_vt = InlineTypeNode::make_null(gvn, vk);\n+        null_vt = make_null_impl(gvn, vk, visited);\n@@ -893,1 +986,1 @@\n-    vt = new InlineTypeNode(vk, oop, \/* null_free= *\/ true, true);\n+    vt = new InlineTypeNode(vk, oop, \/* null_free= *\/ true);\n@@ -895,0 +988,1 @@\n+    vt->set_is_buffered(gvn);\n@@ -896,1 +990,1 @@\n-    vt->load(kit, oop, oop, vk, \/* holder_offset *\/ 0);\n+    vt->load(kit, oop, oop, vk, visited);\n@@ -906,1 +1000,7 @@\n-\/\/ GraphKit wrapper for the 'make_from_flattened' method\n+  GrowableArray<ciType*> visited;\n+  visited.push(vk);\n+  return make_from_flattened_impl(kit, vk, obj, ptr, holder, holder_offset, decorators, visited);\n+}\n+\n+\/\/ GraphKit wrapper for the 'make_from_flattened' method\n+InlineTypeNode* InlineTypeNode::make_from_flattened_impl(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators, GrowableArray<ciType*>& visited) {\n@@ -917,1 +1017,1 @@\n-  vt->load(kit, obj, ptr, holder, holder_offset, decorators);\n+  vt->load(kit, obj, ptr, holder, visited, holder_offset, decorators);\n@@ -929,1 +1029,3 @@\n-  vt->initialize_fields(kit, multi, base_input, in, null_free);\n+  GrowableArray<ciType*> visited;\n+  visited.push(vk);\n+  vt->initialize_fields(kit, multi, base_input, in, null_free, NULL, visited);\n@@ -935,1 +1037,1 @@\n-  InlineTypeNode* res = InlineTypeNode::make_uninitialized(kit->gvn(), vk);\n+  InlineTypeNode* res = make_uninitialized(kit->gvn(), vk);\n@@ -973,1 +1075,1 @@\n-  InlineTypeNode* res = InlineTypeNode::make_uninitialized(kit->gvn(), vk);\n+  InlineTypeNode* res = make_uninitialized(kit->gvn(), vk);\n@@ -983,0 +1085,10 @@\n+bool InlineTypeNode::is_larval(PhaseGVN* gvn) const {\n+  if (!is_allocated(gvn)) {\n+    return false;\n+  }\n+\n+  Node* oop = get_oop();\n+  AllocateNode* alloc = AllocateNode::Ideal_allocation(oop, gvn);\n+  return alloc != NULL && alloc->_larval;\n+}\n+\n@@ -1080,1 +1192,1 @@\n-void InlineTypeNode::initialize_fields(GraphKit* kit, MultiNode* multi, uint& base_input, bool in, bool null_free, Node* null_check_region) {\n+void InlineTypeNode::initialize_fields(GraphKit* kit, MultiNode* multi, uint& base_input, bool in, bool null_free, Node* null_check_region, GrowableArray<ciType*>& visited) {\n@@ -1118,1 +1230,1 @@\n-      vt->initialize_fields(kit, multi, base_input, in, true, null_check_region);\n+      vt->initialize_fields(kit, multi, base_input, in, true, null_check_region, visited);\n@@ -1121,1 +1233,3 @@\n-      if (type->bundle_size() > 1) {\n+      ciInlineKlass* ik = inline_klass();\n+      ciField* field = ik->declared_nonstatic_field_at(i);\n+      if (!InlineTypeNode::is_multifield_scalarized(field)) {\n@@ -1123,1 +1237,0 @@\n-        ciInlineKlass* ik = inline_klass();\n@@ -1131,1 +1244,1 @@\n-          load(kit, not_null_oop, not_null_oop, ik, \/* holder_offset *\/ 0);\n+          load(kit, not_null_oop, not_null_oop, ik, visited, \/* holder_offset *\/ 0);\n@@ -1150,0 +1263,3 @@\n+          if (parm->is_InlineType() && kit->C->has_circular_inline_type()) {\n+            parm = parm->as_InlineType()->get_oop();\n+          }\n@@ -1155,1 +1271,8 @@\n-        parm = make_from_oop(kit, parm, type->as_inline_klass(), field_is_null_free(i));\n+        if (visited.contains(type)) {\n+          kit->C->set_has_circular_inline_type(true);\n+        } else if (!parm->is_InlineType()) {\n+          int old_len = visited.length();\n+          visited.push(type);\n+          parm = make_from_oop_impl(kit, parm, type->as_inline_klass(), field_is_null_free(i), visited);\n+          visited.trunc_to(old_len);\n+        }\n@@ -1167,1 +1290,1 @@\n-    is_init= gvn.transform(new ProjNode(multi->as_Call(), base_input));\n+    is_init = gvn.transform(new ProjNode(multi->as_Call(), base_input));\n@@ -1214,7 +1337,19 @@\n-  InlineTypeNode* ptr = new InlineTypeNode(vk, gvn.zerocon(T_OBJECT), \/* null_free= *\/ false, true);\n-  ptr->set_req(IsInit, gvn.intcon(0));\n-  for (uint i = 0; i < ptr->field_count(); i++) {\n-    ciType* field_type = ptr->field_type(i);\n-    Node* value = default_value(gvn, field_type);\n-    if (field_type->is_inlinetype()) {\n-      value = InlineTypeNode::make_null(gvn, field_type->as_inline_klass());\n+  GrowableArray<ciType*> visited;\n+  visited.push(vk);\n+  return make_null_impl(gvn, vk, visited);\n+}\n+\n+InlineTypeNode* InlineTypeNode::make_null_impl(PhaseGVN& gvn, ciInlineKlass* vk, GrowableArray<ciType*>& visited) {\n+  InlineTypeNode* vt = new InlineTypeNode(vk, gvn.zerocon(T_OBJECT), \/* null_free= *\/ false);\n+  vt->set_is_buffered(gvn);\n+  vt->set_is_init(gvn, false);\n+  for (uint i = 0; i < vt->field_count(); i++) {\n+    ciType* ft = vt->field_type(i);\n+    Node* value = default_value(gvn, ft);\n+    if (!vt->field_is_flattened(i) && visited.contains(ft)) {\n+      gvn.C->set_has_circular_inline_type(true);\n+    } else if (ft->is_inlinetype()) {\n+      int old_len = visited.length();\n+      visited.push(ft);\n+      value = make_null_impl(gvn, ft->as_inline_klass(), visited);\n+      visited.trunc_to(old_len);\n@@ -1222,1 +1357,1 @@\n-    ptr->set_field_value(i, value);\n+    vt->set_field_value(i, value);\n@@ -1224,1 +1359,1 @@\n-  return gvn.transform(ptr)->as_InlineType();\n+  return gvn.transform(vt)->as_InlineType();\n@@ -1250,0 +1385,3 @@\n+  if (tinit == Type::TOP) {\n+    return Type::TOP;\n+  }\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.cpp","additions":246,"deletions":108,"binary":false,"changes":354,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,7 +39,2 @@\n-  virtual uint hash() const;\n-  virtual bool cmp(const Node &n) const;\n-  virtual uint size_of() const;\n-  bool _is_buffered;\n-\n-  InlineTypeNode(ciInlineKlass* vk, Node* oop, bool null_free, bool is_buffered)\n-      : TypeNode(TypeInstPtr::make(null_free ? TypePtr::NotNull : TypePtr::BotPTR, vk), Values + vk->nof_declared_nonstatic_fields()), _is_buffered(is_buffered) {\n+  InlineTypeNode(ciInlineKlass* vk, Node* oop, bool null_free)\n+      : TypeNode(TypeInstPtr::make(null_free ? TypePtr::NotNull : TypePtr::BotPTR, vk), Values + vk->nof_declared_nonstatic_fields()) {\n@@ -52,5 +47,6 @@\n-  enum { Control,   \/\/ Control input.\n-         Oop,       \/\/ Oop to heap allocated buffer (NULL if not buffered).\n-         IsInit,    \/\/ Needs to be checked for NULL before using the field values.\n-         Values     \/\/ Nodes corresponding to values of the inline type's fields.\n-                    \/\/ Nodes are connected in increasing order of the index of the field they correspond to.\n+  enum { Control,    \/\/ Control input.\n+         Oop,        \/\/ Oop to heap allocated buffer.\n+         IsBuffered, \/\/ True if inline type is heap allocated (or NULL), false otherwise.\n+         IsInit,     \/\/ Needs to be checked for NULL before using the field values.\n+         Values      \/\/ Nodes corresponding to values of the inline type's fields.\n+                     \/\/ Nodes are connected in increasing order of the index of the field they correspond to.\n@@ -68,0 +64,3 @@\n+  \/\/ Checks if the inline type oop is an allocated buffer with larval state\n+  bool is_larval(PhaseGVN* gvn) const;\n+\n@@ -72,1 +71,1 @@\n-  void initialize_fields(GraphKit* kit, MultiNode* multi, uint& base_input, bool in, bool null_free = true, Node* null_check_region = NULL);\n+  void initialize_fields(GraphKit* kit, MultiNode* multi, uint& base_input, bool in, bool null_free, Node* null_check_region, GrowableArray<ciType*>& visited);\n@@ -77,0 +76,1 @@\n+  InlineTypeNode* adjust_scalarization_depth_impl(GraphKit* kit, GrowableArray<ciType*>& visited);\n@@ -78,0 +78,6 @@\n+  static InlineTypeNode* make_default_impl(PhaseGVN& gvn, ciInlineKlass* vk, GrowableArray<ciType*>& visited);\n+  static InlineTypeNode* make_from_oop_impl(GraphKit* kit, Node* oop, ciInlineKlass* vk, bool null_free, GrowableArray<ciType*>& visited);\n+  static InlineTypeNode* make_null_impl(PhaseGVN& gvn, ciInlineKlass* vk, GrowableArray<ciType*>& visited);\n+  static InlineTypeNode* make_from_flattened_impl(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators, GrowableArray<ciType*>& visited);\n+\n+public:\n@@ -88,1 +94,1 @@\n-\n+  \/\/ Create with null field values\n@@ -93,0 +99,2 @@\n+  static int stack_size_for_field(ciField* field);\n+\n@@ -108,3 +116,7 @@\n-  void  set_is_init(PhaseGVN& gvn) { set_req(IsInit, gvn.intcon(1)); }\n-  void  set_is_buffered() { _is_buffered = true; }\n-  bool  is_buffered() { return _is_buffered; }\n+  void  set_is_init(PhaseGVN& gvn, bool init = true) { set_req(IsInit, gvn.intcon(init ? 1 : 0)); }\n+  Node* get_is_buffered() const { return in(IsBuffered); }\n+  void  set_is_buffered(PhaseGVN& gvn, bool buffered = true) { set_req(IsBuffered, gvn.intcon(buffered ? 1 : 0)); }\n+\n+  \/\/ Get indices for inputs.\n+  static int   get_Oop_idx()    { return InlineTypeNode::Oop; }\n+  static int   get_Values_idx() { return InlineTypeNode::Values; }\n@@ -137,1 +149,3 @@\n-  void load(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset = 0, DecoratorSet decorators = IN_HEAP | MO_UNORDERED);\n+  void load(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, GrowableArray<ciType*>& visited, int holder_offset = 0, DecoratorSet decorators = IN_HEAP | MO_UNORDERED);\n+  \/\/ Make sure that inline type is fully scalarized\n+  InlineTypeNode* adjust_scalarization_depth(GraphKit* kit);\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.hpp","additions":33,"deletions":19,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+#include \"prims\/jvmtiThreadState.hpp\"\n@@ -55,0 +56,1 @@\n+#include \"runtime\/jniHandles.inline.hpp\"\n@@ -68,1 +70,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -80,4 +82,4 @@\n-    is_available = compiler != NULL && compiler->is_intrinsic_supported(mh, is_virtual) &&\n-                   !C->directive()->is_intrinsic_disabled(mh) &&\n-                   !vmIntrinsics::is_disabled_by_flags(mh);\n-\n+    is_available = compiler != nullptr && compiler->is_intrinsic_available(mh, C->directive());\n+    if (is_available && is_virtual) {\n+      is_available = vmIntrinsics::does_virtual_dispatch(id);\n+    }\n@@ -94,1 +96,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -167,1 +169,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -201,1 +203,1 @@\n-    return slow_ctl; \/\/ Could be NULL if the check folds.\n+    return slow_ctl; \/\/ Could be null if the check folds.\n@@ -226,1 +228,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -311,0 +313,2 @@\n+  case vmIntrinsics::_vectorizedHashCode:       return inline_vectorizedHashCode();\n+\n@@ -483,0 +487,12 @@\n+#if INCLUDE_JVMTI\n+  case vmIntrinsics::_notifyJvmtiVThreadStart:   return inline_native_notify_jvmti_funcs(CAST_FROM_FN_PTR(address, OptoRuntime::notify_jvmti_vthread_start()),\n+                                                                                         \"notifyJvmtiStart\", true, false);\n+  case vmIntrinsics::_notifyJvmtiVThreadEnd:     return inline_native_notify_jvmti_funcs(CAST_FROM_FN_PTR(address, OptoRuntime::notify_jvmti_vthread_end()),\n+                                                                                         \"notifyJvmtiEnd\", false, true);\n+  case vmIntrinsics::_notifyJvmtiVThreadMount:   return inline_native_notify_jvmti_funcs(CAST_FROM_FN_PTR(address, OptoRuntime::notify_jvmti_vthread_mount()),\n+                                                                                         \"notifyJvmtiMount\", false, false);\n+  case vmIntrinsics::_notifyJvmtiVThreadUnmount: return inline_native_notify_jvmti_funcs(CAST_FROM_FN_PTR(address, OptoRuntime::notify_jvmti_vthread_unmount()),\n+                                                                                         \"notifyJvmtiUnmount\", false, false);\n+  case vmIntrinsics::_notifyJvmtiVThreadHideFrames: return inline_native_notify_jvmti_hide();\n+#endif\n+\n@@ -695,2 +711,0 @@\n-  case vmIntrinsics::_VectorShuffleIota:\n-    return inline_vector_shuffle_iota();\n@@ -699,2 +713,0 @@\n-  case vmIntrinsics::_VectorShuffleToVector:\n-    return inline_vector_shuffle_to_vector();\n@@ -735,0 +747,2 @@\n+  case vmIntrinsics::_IndexPartiallyInUpperRange:\n+    return inline_index_partially_in_upper_range();\n@@ -811,2 +825,2 @@\n-\/\/ or NULL if it is obvious that the slow path can never be taken.\n-\/\/ Also, if region and the slow control are not NULL, the slow edge\n+\/\/ or null if it is obvious that the slow path can never be taken.\n+\/\/ Also, if region and the slow control are not null, the slow edge\n@@ -817,1 +831,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -824,1 +838,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -832,1 +846,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -835,1 +849,1 @@\n-  if (region != NULL)\n+  if (region != nullptr)\n@@ -854,1 +868,1 @@\n-    return NULL;                \/\/ already stopped\n+    return nullptr;                \/\/ already stopped\n@@ -856,1 +870,1 @@\n-    return NULL;                \/\/ index is already adequately typed\n+    return nullptr;                \/\/ index is already adequately typed\n@@ -860,1 +874,1 @@\n-  if (is_neg != NULL && pos_index != NULL) {\n+  if (is_neg != nullptr && pos_index != nullptr) {\n@@ -888,1 +902,1 @@\n-    return NULL;                \/\/ already stopped\n+    return nullptr;                \/\/ already stopped\n@@ -891,1 +905,1 @@\n-    return NULL;                \/\/ common case of whole-array copy\n+    return nullptr;                \/\/ common case of whole-array copy\n@@ -939,1 +953,1 @@\n-      ? LoadNode::make(_gvn, NULL, immutable_memory(), p, p->bottom_type()->is_ptr(),\n+      ? LoadNode::make(_gvn, nullptr, immutable_memory(), p, p->bottom_type()->is_ptr(),\n@@ -941,1 +955,1 @@\n-      : make_load(NULL, p, p->bottom_type()->is_ptr(), T_ADDRESS, MemNode::unordered));\n+      : make_load(nullptr, p, p->bottom_type()->is_ptr(), T_ADDRESS, MemNode::unordered));\n@@ -969,1 +983,1 @@\n-  Node* result = NULL;\n+  Node* result = nullptr;\n@@ -987,1 +1001,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1043,2 +1057,2 @@\n-    Node* if_ne = generate_slow_guard(bol, NULL);\n-    if (if_ne != NULL) {\n+    Node* if_ne = generate_slow_guard(bol, nullptr);\n+    if (if_ne != nullptr) {\n@@ -1079,0 +1093,1 @@\n+\n@@ -1196,1 +1211,1 @@\n-  if (result != NULL) {\n+  if (result != nullptr) {\n@@ -1242,1 +1257,1 @@\n-  if (result != NULL) {\n+  if (result != nullptr) {\n@@ -1248,2 +1263,2 @@\n-    Node* if_lt = generate_slow_guard(bol, NULL);\n-    if (if_lt != NULL) {\n+    Node* if_lt = generate_slow_guard(bol, nullptr);\n+    if (if_lt != nullptr) {\n@@ -1275,2 +1290,2 @@\n-  Node* if_gt = generate_slow_guard(bol, NULL);\n-  if (if_gt != NULL) {\n+  Node* if_gt = generate_slow_guard(bol, nullptr);\n+  if (if_gt != nullptr) {\n@@ -1284,2 +1299,2 @@\n-    Node* if_zero = generate_slow_guard(bol, NULL);\n-    if (if_zero != NULL) {\n+    Node* if_zero = generate_slow_guard(bol, nullptr);\n+    if (if_zero != nullptr) {\n@@ -1293,1 +1308,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1306,1 +1321,1 @@\n-  Node* tgt         = argument(1); \/\/ tgt is int ch\n+  Node* int_ch      = argument(1);\n@@ -1318,0 +1333,9 @@\n+\n+  \/\/ Check for int_ch >= 0\n+  Node* int_ch_cmp = _gvn.transform(new CmpINode(int_ch, intcon(0)));\n+  Node* int_ch_bol = _gvn.transform(new BoolNode(int_ch_cmp, BoolTest::ge));\n+  {\n+    BuildCutout unless(this, int_ch_bol, PROB_MAX);\n+    uncommon_trap(Deoptimization::Reason_intrinsic,\n+                  Deoptimization::Action_maybe_recompile);\n+  }\n@@ -1325,1 +1349,1 @@\n-  Node* result = new StrIndexOfCharNode(control(), memory(TypeAryPtr::BYTES), src_start, src_count, tgt, ae);\n+  Node* result = new StrIndexOfCharNode(control(), memory(TypeAryPtr::BYTES), src_start, src_count, int_ch, ae);\n@@ -1332,2 +1356,2 @@\n-  Node* if_lt = generate_slow_guard(bol, NULL);\n-  if (if_lt != NULL) {\n+  Node* if_lt = generate_slow_guard(bol, nullptr);\n+  if (if_lt != nullptr) {\n@@ -1374,4 +1398,7 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const Type* dst_type = dst->Value(&_gvn);\n-  BasicType src_elem = src_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType dst_elem = dst_type->isa_aryptr()->elem()->array_element_basic_type();\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* dst_type = dst->Value(&_gvn)->isa_aryptr();\n+  if (src_type == nullptr || dst_type == nullptr) {\n+    return false;\n+  }\n+  BasicType src_elem = src_type->elem()->array_element_basic_type();\n+  BasicType dst_elem = dst_type->elem()->array_element_basic_type();\n@@ -1405,1 +1432,1 @@\n-  Node* count = NULL;\n+  Node* count = nullptr;\n@@ -1412,1 +1439,1 @@\n-  if (alloc != NULL) {\n+  if (alloc != nullptr) {\n@@ -1455,1 +1482,1 @@\n-  Node* newcopy = NULL;\n+  Node* newcopy = nullptr;\n@@ -1489,1 +1516,1 @@\n-    guarantee(alloc != NULL, \"created above\");\n+    guarantee(alloc != nullptr, \"created above\");\n@@ -1589,1 +1616,1 @@\n-    if (alloc != NULL) {\n+    if (alloc != nullptr) {\n@@ -1622,1 +1649,1 @@\n-  Node* ch = is_store ? argument(2) : NULL;\n+  Node* ch = is_store ? argument(2) : nullptr;\n@@ -1650,1 +1677,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -1666,1 +1693,1 @@\n-      n = _gvn.transform(new RoundDoubleNode(NULL, n));\n+      n = _gvn.transform(new RoundDoubleNode(nullptr, n));\n@@ -1683,1 +1710,1 @@\n-  Node* n = NULL;\n+  Node* n = nullptr;\n@@ -1707,1 +1734,1 @@\n-  Node* n = NULL;\n+  Node* n = nullptr;\n@@ -1728,1 +1755,1 @@\n-  Node* b = (call_type == OptoRuntime::Math_DD_D_Type()) ? round_double_node(argument(2)) : NULL;\n+  Node* b = (call_type == OptoRuntime::Math_DD_D_Type()) ? round_double_node(argument(2)) : nullptr;\n@@ -1730,1 +1757,1 @@\n-  const TypePtr* no_memory_effects = NULL;\n+  const TypePtr* no_memory_effects = nullptr;\n@@ -1733,1 +1760,1 @@\n-                                 a, top(), b, b ? top() : NULL);\n+                                 a, top(), b, b ? top() : nullptr);\n@@ -1748,1 +1775,1 @@\n-  if (d != NULL) {\n+  if (d != nullptr) {\n@@ -1768,1 +1795,1 @@\n-      Node* if_pow = generate_slow_guard(test, NULL);\n+      Node* if_pow = generate_slow_guard(test, nullptr);\n@@ -1773,1 +1800,1 @@\n-      if (if_pow != NULL) {\n+      if (if_pow != nullptr) {\n@@ -1775,1 +1802,1 @@\n-        address target = StubRoutines::dpow() != NULL ? StubRoutines::dpow() :\n+        address target = StubRoutines::dpow() != nullptr ? StubRoutines::dpow() :\n@@ -1777,1 +1804,1 @@\n-        const TypePtr* no_memory_effects = NULL;\n+        const TypePtr* no_memory_effects = nullptr;\n@@ -1798,1 +1825,1 @@\n-  return StubRoutines::dpow() != NULL ?\n+  return StubRoutines::dpow() != nullptr ?\n@@ -1807,1 +1834,1 @@\n-    return StubRoutines::dsin() != NULL ?\n+    return StubRoutines::dsin() != nullptr ?\n@@ -1811,1 +1838,1 @@\n-    return StubRoutines::dcos() != NULL ?\n+    return StubRoutines::dcos() != nullptr ?\n@@ -1815,1 +1842,1 @@\n-    return StubRoutines::dtan() != NULL ?\n+    return StubRoutines::dtan() != nullptr ?\n@@ -1819,1 +1846,1 @@\n-    return StubRoutines::dexp() != NULL ?\n+    return StubRoutines::dexp() != nullptr ?\n@@ -1823,1 +1850,1 @@\n-    return StubRoutines::dlog() != NULL ?\n+    return StubRoutines::dlog() != nullptr ?\n@@ -1827,1 +1854,1 @@\n-    return StubRoutines::dlog10() != NULL ?\n+    return StubRoutines::dlog10() != nullptr ?\n@@ -1870,1 +1897,1 @@\n-  Node* call = make_runtime_call(RC_NO_LEAF, ftype, func, NULL, TypeRawPtr::BOTTOM, argument(0));\n+  Node* call = make_runtime_call(RC_NO_LEAF, ftype, func, nullptr, TypeRawPtr::BOTTOM, argument(0));\n@@ -1959,1 +1986,1 @@\n-  Node* result_val = NULL;\n+  Node* result_val = nullptr;\n@@ -1979,2 +2006,2 @@\n-  if (base != NULL)  base_type = _gvn.type(base)->isa_ptr();\n-  if (base_type == NULL) {\n+  if (base != nullptr)  base_type = _gvn.type(base)->isa_ptr();\n+  if (base_type == nullptr) {\n@@ -1984,1 +2011,1 @@\n-    \/\/ Since this is a NULL+long form, we have to switch to a rawptr.\n+    \/\/ Since this is a null+long form, we have to switch to a rawptr.\n@@ -1997,1 +2024,1 @@\n-    if (offset_type != NULL &&\n+    if (offset_type != nullptr &&\n@@ -2002,1 +2029,1 @@\n-    } else if (type == T_OBJECT) {\n+    } else if (type == T_OBJECT || type == T_PRIMITIVE_OBJECT) {\n@@ -2007,1 +2034,1 @@\n-    \/\/ Otherwise, it might either be oop+off or NULL+addr.\n+    \/\/ Otherwise, it might either be oop+off or null+addr.\n@@ -2072,1 +2099,1 @@\n-  Node* n = NULL;\n+  Node* n = nullptr;\n@@ -2098,1 +2125,1 @@\n-  Node* n = NULL;\n+  Node* n = nullptr;\n@@ -2116,1 +2143,1 @@\n-  Node* n = NULL;\n+  Node* n = nullptr;\n@@ -2132,1 +2159,1 @@\n-  Node* n = NULL;\n+  Node* n = nullptr;\n@@ -2180,1 +2207,1 @@\n-  ciKlass* sharpened_klass = NULL;\n+  ciKlass* sharpened_klass = nullptr;\n@@ -2184,1 +2211,1 @@\n-  if (alias_type->field() != NULL) {\n+  if (alias_type->field() != nullptr) {\n@@ -2191,1 +2218,1 @@\n-  const TypeOopPtr* result = NULL;\n+  const TypeOopPtr* result = nullptr;\n@@ -2197,1 +2224,1 @@\n-      if (elem_type != NULL && elem_type->is_loaded()) {\n+      if (elem_type != nullptr && elem_type->is_loaded()) {\n@@ -2206,1 +2233,1 @@\n-  if (result == NULL && sharpened_klass != NULL && sharpened_klass->is_loaded()) {\n+  if (result == nullptr && sharpened_klass != nullptr && sharpened_klass->is_loaded()) {\n@@ -2213,1 +2240,1 @@\n-  if (result != NULL) {\n+  if (result != nullptr) {\n@@ -2300,1 +2327,1 @@\n-  ciInlineKlass* inline_klass = NULL;\n+  ciInlineKlass* inline_klass = nullptr;\n@@ -2303,1 +2330,1 @@\n-    if (cls == NULL || cls->const_oop() == NULL) {\n+    if (cls == nullptr || cls->const_oop() == nullptr) {\n@@ -2340,2 +2367,2 @@\n-        if (field != NULL && !VectorSupport::is_vector_payload_mf(vk->get_InlineKlass())) {\n-          BasicType bt = field->layout_type();\n+        if (field != nullptr && !VectorSupport::is_vector_payload_mf(vk->get_InlineKlass())) {\n+          BasicType bt = type2field[field->type()->basic_type()];\n@@ -2346,1 +2373,5 @@\n-            set_result(vt->field_value_by_offset(off, false));\n+            Node* value = vt->field_value_by_offset(off, false);\n+            if (value->is_InlineType()) {\n+              value = value->as_InlineType()->adjust_scalarization_depth(this);\n+            }\n+            set_result(value);\n@@ -2371,1 +2402,1 @@\n-    if (type != T_OBJECT && (inline_klass == NULL || !inline_klass->has_object_fields())) {\n+    if (type != T_OBJECT && (inline_klass == nullptr || !inline_klass->has_object_fields())) {\n@@ -2382,1 +2413,1 @@\n-  \/\/ Can base be NULL? Otherwise, always on-heap access.\n+  \/\/ Can base be null? Otherwise, always on-heap access.\n@@ -2389,1 +2420,1 @@\n-  Node* val = is_store ? argument(4 + (type == T_PRIMITIVE_OBJECT ? 1 : 0)) : NULL;\n+  Node* val = is_store ? argument(4 + (type == T_PRIMITIVE_OBJECT ? 1 : 0)) : nullptr;\n@@ -2411,1 +2442,1 @@\n-  ciField* field = NULL;\n+  ciField* field = nullptr;\n@@ -2416,1 +2447,1 @@\n-    if (instptr->const_oop() != NULL &&\n+    if (instptr->const_oop() != nullptr &&\n@@ -2424,2 +2455,2 @@\n-    if (field != NULL) {\n-      bt = field->layout_type();\n+    if (field != nullptr) {\n+      bt = type2field[field->type()->basic_type()];\n@@ -2428,1 +2459,1 @@\n-    if (field != NULL && bt == T_PRIMITIVE_OBJECT && !field->is_flattened()) {\n+    if (field != nullptr && bt == T_PRIMITIVE_OBJECT && !field->is_flattened()) {\n@@ -2437,0 +2468,3 @@\n+    if (adr_type->is_flat()) {\n+      bt = T_PRIMITIVE_OBJECT;\n+    }\n@@ -2459,1 +2493,1 @@\n-      if (field == NULL || field->type() != inline_klass) {\n+      if (field == nullptr || field->type() != inline_klass) {\n@@ -2464,3 +2498,1 @@\n-      if (!elem->isa_inlinetype()) {\n-        mismatched = true;\n-      } else if (elem->inline_klass() != inline_klass) {\n+      if (!adr_type->is_flat() || elem->inline_klass() != inline_klass) {\n@@ -2474,1 +2506,1 @@\n-      if (!(val_t->isa_inlinetype() || val_t->is_inlinetypeptr()) || val_t->inline_klass() != inline_klass) {\n+      if (!val_t->is_inlinetypeptr() || val_t->inline_klass() != inline_klass) {\n@@ -2482,1 +2514,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -2498,1 +2530,1 @@\n-      if (tjp != NULL) {\n+      if (tjp != nullptr) {\n@@ -2502,1 +2534,1 @@\n-      value_type = NULL;\n+      value_type = nullptr;\n@@ -2516,1 +2548,1 @@\n-    Node* p = NULL;\n+    Node* p = nullptr;\n@@ -2519,1 +2551,1 @@\n-    if (heap_base_oop != top() && field != NULL && field->is_constant() && !field->is_flattened() && !mismatched) {\n+    if (heap_base_oop != top() && field != nullptr && field->is_constant() && !field->is_flattened() && !mismatched) {\n@@ -2524,1 +2556,1 @@\n-    if (p == NULL) { \/\/ Could not constant fold the load\n+    if (p == nullptr) { \/\/ Could not constant fold the load\n@@ -2531,1 +2563,1 @@\n-          p = InlineTypeNode::make_from_flattened(this, inline_klass, base, adr, NULL, 0, decorators);\n+          p = InlineTypeNode::make_from_flattened(this, inline_klass, base, adr, nullptr, 0, decorators);\n@@ -2536,1 +2568,1 @@\n-        if (ptr != NULL && ptr->is_inlinetypeptr()) {\n+        if (ptr != nullptr && ptr->is_inlinetypeptr()) {\n@@ -2544,2 +2576,2 @@\n-           heap_base_oop == top() ||                  \/\/ - heap_base_oop is NULL or\n-           (can_access_non_heap && field == NULL))    \/\/ - heap_base_oop is potentially NULL\n+           heap_base_oop == top() ||                  \/\/ - heap_base_oop is null or\n+           (can_access_non_heap && field == nullptr)) \/\/ - heap_base_oop is potentially null\n@@ -2564,1 +2596,1 @@\n-      p = gvn().transform(new CastP2XNode(NULL, p));\n+      p = gvn().transform(new CastP2XNode(nullptr, p));\n@@ -2584,1 +2616,1 @@\n-        val->as_InlineType()->store_flattened(this, base, adr, NULL, 0, decorators);\n+        val->as_InlineType()->store_flattened(this, base, adr, nullptr, 0, decorators);\n@@ -2627,1 +2659,1 @@\n-  if (AllocateNode::Ideal_allocation(vt->get_oop(), &_gvn) == NULL) {\n+  if (AllocateNode::Ideal_allocation(vt->get_oop(), &_gvn) == nullptr) {\n@@ -2755,5 +2787,5 @@\n-  Node* receiver = NULL;\n-  Node* base     = NULL;\n-  Node* offset   = NULL;\n-  Node* oldval   = NULL;\n-  Node* newval   = NULL;\n+  Node* receiver = nullptr;\n+  Node* base     = nullptr;\n+  Node* offset   = nullptr;\n+  Node* oldval   = nullptr;\n+  Node* newval   = nullptr;\n@@ -2777,1 +2809,1 @@\n-      oldval   = NULL;\n+      oldval   = nullptr;\n@@ -2808,1 +2840,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -2820,1 +2852,1 @@\n-        if (tjp != NULL) {\n+        if (tjp != nullptr) {\n@@ -2845,1 +2877,1 @@\n-    if (oldval != NULL && oldval->is_InlineType()) {\n+    if (oldval != nullptr && oldval->is_InlineType()) {\n@@ -2851,1 +2883,1 @@\n-    if (newval != NULL && newval->is_InlineType()) {\n+    if (newval != nullptr && newval->is_InlineType()) {\n@@ -2858,1 +2890,1 @@\n-    \/\/ Transformation of a value which could be NULL pointer (CastPP #NULL)\n+    \/\/ Transformation of a value which could be null pointer (CastPP #null)\n@@ -2864,1 +2896,1 @@\n-    if (oldval != NULL && _gvn.type(oldval) == TypePtr::NULL_PTR) {\n+    if (oldval != nullptr && _gvn.type(oldval) == TypePtr::NULL_PTR) {\n@@ -2870,1 +2902,1 @@\n-  Node* result = NULL;\n+  Node* result = nullptr;\n@@ -2936,1 +2968,1 @@\n-  if (klsptr == NULL) {\n+  if (klsptr == nullptr) {\n@@ -3002,1 +3034,1 @@\n-  Node* kls = load_klass_from_mirror(cls, false, NULL, 0);\n+  Node* kls = load_klass_from_mirror(cls, false, nullptr, 0);\n@@ -3006,1 +3038,1 @@\n-  Node* test = NULL;\n+  Node* test = nullptr;\n@@ -3014,1 +3046,1 @@\n-    Node* inst = make_load(NULL, insp, TypeInt::UBYTE, T_BOOLEAN, MemNode::unordered);\n+    Node* inst = make_load(nullptr, insp, TypeInt::UBYTE, T_BOOLEAN, MemNode::unordered);\n@@ -3019,1 +3051,1 @@\n-  Node* obj = NULL;\n+  Node* obj = nullptr;\n@@ -3021,1 +3053,1 @@\n-  if (tkls != NULL && tkls->instance_klass()->is_inlinetype()) {\n+  if (tkls != nullptr && tkls->instance_klass()->is_inlinetype()) {\n@@ -3035,1 +3067,1 @@\n-  const TypePtr* no_memory_effects = NULL;\n+  const TypePtr* no_memory_effects = nullptr;\n@@ -3046,0 +3078,68 @@\n+\n+#if INCLUDE_JVMTI\n+\n+\/\/ When notifications are disabled then just update the VTMS transition bit and return.\n+\/\/ Otherwise, the bit is updated in the given function call implementing JVMTI notification protocol.\n+bool LibraryCallKit::inline_native_notify_jvmti_funcs(address funcAddr, const char* funcName, bool is_start, bool is_end) {\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    return true;\n+  }\n+  IdealKit ideal(this);\n+\n+  Node* ONE = ideal.ConI(1);\n+  Node* hide = is_start ? ideal.ConI(0) : (is_end ? ideal.ConI(1) : _gvn.transform(argument(1)));\n+  Node* addr = makecon(TypeRawPtr::make((address)&JvmtiVTMSTransitionDisabler::_VTMS_notify_jvmti_events));\n+  Node* notify_jvmti_enabled = ideal.load(ideal.ctrl(), addr, TypeInt::BOOL, T_BOOLEAN, Compile::AliasIdxRaw);\n+\n+  ideal.if_then(notify_jvmti_enabled, BoolTest::eq, ONE); {\n+    \/\/ if notifyJvmti enabled then make a call to the given SharedRuntime function\n+    const TypeFunc* tf = OptoRuntime::notify_jvmti_vthread_Type();\n+    Node* vt_oop = _gvn.transform(must_be_not_null(argument(0), true)); \/\/ VirtualThread this argument\n+\n+    sync_kit(ideal);\n+    make_runtime_call(RC_NO_LEAF, tf, funcAddr, funcName, TypePtr::BOTTOM, vt_oop, hide);\n+    ideal.sync_kit(this);\n+  } ideal.else_(); {\n+    \/\/ set hide value to the VTMS transition bit in current JavaThread and VirtualThread object\n+    Node* vt_oop = _gvn.transform(argument(0)); \/\/ this argument - VirtualThread oop\n+    Node* thread = ideal.thread();\n+    Node* jt_addr = basic_plus_adr(thread, in_bytes(JavaThread::is_in_VTMS_transition_offset()));\n+    Node* vt_addr = basic_plus_adr(vt_oop, java_lang_Thread::is_in_VTMS_transition_offset());\n+    const TypePtr *addr_type = _gvn.type(addr)->isa_ptr();\n+\n+    sync_kit(ideal);\n+    access_store_at(nullptr, jt_addr, addr_type, hide, _gvn.type(hide), T_BOOLEAN, IN_NATIVE | MO_UNORDERED);\n+    access_store_at(nullptr, vt_addr, addr_type, hide, _gvn.type(hide), T_BOOLEAN, IN_NATIVE | MO_UNORDERED);\n+\n+    ideal.sync_kit(this);\n+  } ideal.end_if();\n+  final_sync(ideal);\n+\n+  return true;\n+}\n+\n+\/\/ Always update the temporary VTMS transition bit.\n+bool LibraryCallKit::inline_native_notify_jvmti_hide() {\n+  if (!DoJVMTIVirtualThreadTransitions) {\n+    return true;\n+  }\n+  IdealKit ideal(this);\n+\n+  {\n+    \/\/ unconditionally update the temporary VTMS transition bit in current JavaThread\n+    Node* thread = ideal.thread();\n+    Node* hide = _gvn.transform(argument(1)); \/\/ hide argument for temporary VTMS transition notification\n+    Node* addr = basic_plus_adr(thread, in_bytes(JavaThread::is_in_tmp_VTMS_transition_offset()));\n+    const TypePtr *addr_type = _gvn.type(addr)->isa_ptr();\n+\n+    sync_kit(ideal);\n+    access_store_at(nullptr, addr, addr_type, hide, _gvn.type(hide), T_BOOLEAN, IN_NATIVE | MO_UNORDERED);\n+    ideal.sync_kit(this);\n+  }\n+  final_sync(ideal);\n+\n+  return true;\n+}\n+\n+#endif \/\/ INCLUDE_JVMTI\n+\n@@ -3071,1 +3171,1 @@\n-  Node* kls = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(),\n+  Node* kls = _gvn.transform(LoadKlassNode::make(_gvn, nullptr, immutable_memory(),\n@@ -3101,1 +3201,1 @@\n-    Node* array_kls = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(),\n+    Node* array_kls = _gvn.transform(LoadKlassNode::make(_gvn, nullptr, immutable_memory(),\n@@ -3132,2 +3232,2 @@\n- * if (h_event_writer == NULL) {\n- *   return NULL;\n+ * if (h_event_writer == nullptr) {\n+ *   return nullptr;\n@@ -3344,1 +3444,2 @@\n-  Node* event_writer = access_load(jobj, xtype, T_OBJECT, IN_NATIVE | C2_CONTROL_DEPENDENT_LOAD);\n+  Node* jobj_untagged = _gvn.transform(new AddPNode(top(), jobj, _gvn.MakeConX(-JNIHandles::TypeTag::global)));\n+  Node* event_writer = access_load(jobj_untagged, xtype, T_OBJECT, IN_NATIVE | C2_CONTROL_DEPENDENT_LOAD);\n@@ -3408,1 +3509,1 @@\n-  result_value->init_req(_false_path, null()); \/\/ return NULL\n+  result_value->init_req(_false_path, null()); \/\/ return null\n@@ -3550,1 +3651,1 @@\n-  Node* junk = NULL;\n+  Node* junk = nullptr;\n@@ -3557,1 +3658,1 @@\n-  Node* junk = NULL;\n+  Node* junk = nullptr;\n@@ -3570,1 +3671,1 @@\n-    = make_load(NULL, p, p->bottom_type()->is_ptr(), T_OBJECT, MemNode::unordered);\n+    = make_load(nullptr, p, p->bottom_type()->is_ptr(), T_OBJECT, MemNode::unordered);\n@@ -3573,3 +3674,1 @@\n-  \/\/ Stores of oops to native memory not supported yet by BarrierSetC2::store_at_resolved\n-  \/\/ access_store_at(NULL, thread_obj_handle, adr_type, arr, _gvn.type(arr), T_OBJECT, IN_NATIVE | MO_UNORDERED);\n-  store_to_memory(control(), thread_obj_handle, arr, T_OBJECT, adr_type, MemNode::unordered);\n+  access_store_at(nullptr, thread_obj_handle, adr_type, arr, _gvn.type(arr), T_OBJECT, IN_NATIVE | MO_UNORDERED);\n@@ -3591,1 +3690,1 @@\n-  \/\/ return _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), p, p->bottom_type()->is_ptr(),\n+  \/\/ return _gvn.transform(LoadNode::make(_gvn, nullptr, immutable_memory(), p, p->bottom_type()->is_ptr(),\n@@ -3593,1 +3692,1 @@\n-  return make_load(NULL, p, p->bottom_type()->is_ptr(), T_ADDRESS, MemNode::unordered);\n+  return make_load(nullptr, p, p->bottom_type()->is_ptr(), T_ADDRESS, MemNode::unordered);\n@@ -3618,2 +3717,1 @@\n-  store_to_memory(control(), cache_obj_handle, arr, T_OBJECT, adr_type,\n-                  MemNode::unordered);\n+  access_store_at(nullptr, cache_obj_handle, adr_type, arr, _gvn.type(arr), T_OBJECT, IN_NATIVE | MO_UNORDERED);\n@@ -3630,1 +3728,1 @@\n-\/\/ If the region is NULL, force never_see_null = true.\n+\/\/ If the region is null, force never_see_null = true.\n@@ -3636,1 +3734,1 @@\n-  if (region == NULL)  never_see_null = true;\n+  if (region == nullptr)  never_see_null = true;\n@@ -3639,1 +3737,1 @@\n-  Node* kls = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, TypeRawPtr::BOTTOM, kls_type));\n+  Node* kls = _gvn.transform(LoadKlassNode::make(_gvn, nullptr, immutable_memory(), p, TypeRawPtr::BOTTOM, kls_type));\n@@ -3642,1 +3740,1 @@\n-  if (region != NULL) {\n+  if (region != nullptr) {\n@@ -3658,1 +3756,1 @@\n-  Node* mods = make_load(NULL, modp, TypeInt::INT, T_INT, MemNode::unordered);\n+  Node* mods = make_load(nullptr, modp, TypeInt::INT, T_INT, MemNode::unordered);\n@@ -3725,1 +3823,1 @@\n-  if (mirror_con == NULL)  return false;  \/\/ cannot happen?\n+  if (mirror_con == nullptr)  return false;  \/\/ cannot happen?\n@@ -3778,1 +3876,1 @@\n-    query_value = make_load(NULL, p, TypeInt::INT, T_INT, MemNode::unordered);\n+    query_value = make_load(nullptr, p, TypeInt::INT, T_INT, MemNode::unordered);\n@@ -3783,1 +3881,1 @@\n-    if (generate_interface_guard(kls, region) != NULL)\n+    if (generate_interface_guard(kls, region) != nullptr)\n@@ -3792,1 +3890,1 @@\n-    if (generate_array_guard(kls, region) != NULL)\n+    if (generate_array_guard(kls, region) != nullptr)\n@@ -3805,1 +3903,1 @@\n-    if (generate_hidden_class_guard(kls, region) != NULL)\n+    if (generate_hidden_class_guard(kls, region) != nullptr)\n@@ -3820,1 +3918,1 @@\n-    if (generate_interface_guard(kls, region) != NULL)\n+    if (generate_interface_guard(kls, region) != nullptr)\n@@ -3823,1 +3921,1 @@\n-    if (generate_array_guard(kls, region) != NULL)\n+    if (generate_array_guard(kls, region) != nullptr)\n@@ -3828,1 +3926,1 @@\n-    kls = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, TypeRawPtr::BOTTOM, TypeInstKlassPtr::OBJECT_OR_NULL));\n+    kls = _gvn.transform(LoadKlassNode::make(_gvn, nullptr, immutable_memory(), p, TypeRawPtr::BOTTOM, TypeInstKlassPtr::OBJECT_OR_NULL));\n@@ -3843,1 +3941,1 @@\n-    query_value = make_load(NULL, p, TypeInt::INT, T_INT, MemNode::unordered);\n+    query_value = make_load(nullptr, p, TypeInt::INT, T_INT, MemNode::unordered);\n@@ -3868,1 +3966,1 @@\n-  if (mirror_con == NULL) {\n+  if (mirror_con == nullptr) {\n@@ -3874,1 +3972,1 @@\n-  if (tm != NULL) {\n+  if (tm != nullptr) {\n@@ -3896,1 +3994,1 @@\n-  if (mirror_con == NULL) {\n+  if (mirror_con == nullptr) {\n@@ -3899,1 +3997,1 @@\n-  if (obj == NULL || obj->is_top()) {\n+  if (obj == nullptr || obj->is_top()) {\n@@ -3908,2 +4006,2 @@\n-  if (tm != NULL && tm->is_klass() &&\n-      tp != NULL) {\n+  if (tm != nullptr && tm->is_klass() &&\n+      tp != nullptr) {\n@@ -3914,1 +4012,1 @@\n-      int static_res = C->static_subtype_check(TypeKlassPtr::make(tm->as_klass()), tp->as_klass_type());\n+      int static_res = C->static_subtype_check(TypeKlassPtr::make(tm->as_klass(), Type::trust_interfaces), tp->as_klass_type());\n@@ -3949,1 +4047,1 @@\n-  \/\/ Not-subtype or the mirror's klass ptr is NULL (in case it is a primitive).\n+  \/\/ Not-subtype or the mirror's klass ptr is nullptr (in case it is a primitive).\n@@ -3965,2 +4063,2 @@\n-      Node* ctrl_val_mirror = generate_fair_guard(is_val_mirror(mirror), NULL);\n-      if (ctrl_val_mirror != NULL) {\n+      Node* ctrl_val_mirror = generate_fair_guard(is_val_mirror(mirror), nullptr);\n+      if (ctrl_val_mirror != nullptr) {\n@@ -4049,1 +4147,1 @@\n-    Node* kls = LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, adr_type, kls_type);\n+    Node* kls = LoadKlassNode::make(_gvn, nullptr, immutable_memory(), p, adr_type, kls_type);\n@@ -4106,1 +4204,1 @@\n-    if (ctl == NULL || ctl == top()) {\n+    if (ctl == nullptr || ctl == top()) {\n@@ -4109,1 +4207,1 @@\n-    } else if (phi->in(i) == NULL) {\n+    } else if (phi->in(i) == nullptr) {\n@@ -4123,1 +4221,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -4129,1 +4227,1 @@\n-  if (layout_val == NULL) {\n+  if (layout_val == nullptr) {\n@@ -4141,1 +4239,1 @@\n-      return NULL;                       \/\/ never a branch\n+      return nullptr;                       \/\/ never a branch\n@@ -4144,1 +4242,1 @@\n-      if (region != NULL)\n+      if (region != nullptr)\n@@ -4217,1 +4315,1 @@\n-    CallJavaNode* slow_call = NULL;\n+    CallJavaNode* slow_call = nullptr;\n@@ -4269,1 +4367,1 @@\n-  Node* non_array = generate_non_array_guard(load_object_klass(array), NULL);\n+  Node* non_array = generate_non_array_guard(load_object_klass(array), nullptr);\n@@ -4271,1 +4369,1 @@\n-  if (non_array != NULL) {\n+  if (non_array != nullptr) {\n@@ -4302,1 +4400,1 @@\n-  Node* newcopy = NULL;\n+  Node* newcopy = nullptr;\n@@ -4317,1 +4415,1 @@\n-    Node* klass_node = load_klass_from_mirror(array_type_mirror, false, NULL, 0);\n+    Node* klass_node = load_klass_from_mirror(array_type_mirror, false, nullptr, 0);\n@@ -4334,1 +4432,1 @@\n-                        (orig_t == NULL || (!orig_t->is_not_flat() && (!orig_t->is_flat() || orig_t->elem()->inline_klass()->contains_oops()))) &&\n+                        (orig_t == nullptr || (!orig_t->is_not_flat() && (!orig_t->is_flat() || orig_t->elem()->inline_klass()->contains_oops()))) &&\n@@ -4338,1 +4436,1 @@\n-    if (not_objArray != NULL) {\n+    if (not_objArray != nullptr) {\n@@ -4366,1 +4464,1 @@\n-      if (orig_t != NULL && orig_t->is_flat()) {\n+      if (orig_t != nullptr && orig_t->is_flat()) {\n@@ -4375,1 +4473,1 @@\n-      } else if (UseFlatArray && (orig_t == NULL || !orig_t->is_not_flat()) &&\n+      } else if (UseFlatArray && (orig_t == nullptr || !orig_t->is_not_flat()) &&\n@@ -4381,1 +4479,1 @@\n-        if (orig_t != NULL) {\n+        if (orig_t != nullptr) {\n@@ -4427,1 +4525,1 @@\n-          if (t_original->speculative_type() != NULL) {\n+          if (t_original->speculative_type() != nullptr) {\n@@ -4489,1 +4587,1 @@\n-                     vtableEntry::method_offset_in_bytes();\n+                     in_bytes(vtableEntry::method_offset());\n@@ -4491,1 +4589,1 @@\n-  Node* target_call = make_load(NULL, entry_addr, TypePtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n+  Node* target_call = make_load(nullptr, entry_addr, TypePtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n@@ -4623,1 +4721,1 @@\n-  \/\/ The control of the load must be NULL. Otherwise, the load can move before\n+  \/\/ The control of the load must be null. Otherwise, the load can move before\n@@ -4625,1 +4723,1 @@\n-  Node* no_ctrl = NULL;\n+  Node* no_ctrl = nullptr;\n@@ -4742,1 +4840,1 @@\n-  for (int n = 1; caller_jvms != NULL; caller_jvms = caller_jvms->caller(), n++) {\n+  for (int n = 1; caller_jvms != nullptr; caller_jvms = caller_jvms->caller(), n++) {\n@@ -4799,1 +4897,1 @@\n-  Node* result = NULL;\n+  Node* result = nullptr;\n@@ -4901,1 +4999,1 @@\n-  Node* result = NULL;\n+  Node* result = nullptr;\n@@ -4939,1 +5037,1 @@\n-    bool is_prim_array = (addr_t != NULL) && (addr_t->elem() != Type::BOTTOM);\n+    bool is_prim_array = (addr_t != nullptr) && (addr_t->elem() != Type::BOTTOM);\n@@ -5009,1 +5107,1 @@\n-  assert(obj_size != NULL, \"\");\n+  assert(obj_size != nullptr, \"\");\n@@ -5013,1 +5111,1 @@\n-  AllocateNode* alloc = NULL;\n+  AllocateNode* alloc = nullptr;\n@@ -5019,1 +5117,1 @@\n-    guarantee(alloc != NULL && alloc->maybe_set_complete(&_gvn), \"\");\n+    guarantee(alloc != nullptr && alloc->maybe_set_complete(&_gvn), \"\");\n@@ -5030,1 +5128,1 @@\n-  if (alloc != NULL) {\n+  if (alloc != nullptr) {\n@@ -5080,1 +5178,1 @@\n-        obj_type->speculative_type() != NULL &&\n+        obj_type->speculative_type() != nullptr &&\n@@ -5117,2 +5215,2 @@\n-    Node* array_ctl = generate_array_guard(obj_klass, (RegionNode*)NULL);\n-    if (array_ctl != NULL) {\n+    Node* array_ctl = generate_array_guard(obj_klass, (RegionNode*)nullptr);\n+    if (array_ctl != nullptr) {\n@@ -5127,1 +5225,1 @@\n-          (ary_ptr == NULL || (!ary_ptr->is_not_flat() && (!ary_ptr->is_flat() || ary_ptr->elem()->inline_klass()->contains_oops())))) {\n+          (ary_ptr == nullptr || (!ary_ptr->is_not_flat() && (!ary_ptr->is_flat() || ary_ptr->elem()->inline_klass()->contains_oops())))) {\n@@ -5135,1 +5233,1 @@\n-        Node* obj_size  = NULL;\n+        Node* obj_size  = nullptr;\n@@ -5142,2 +5240,2 @@\n-          Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);\n-          if (is_obja != NULL) {\n+          Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)nullptr);\n+          if (is_obja != nullptr) {\n@@ -5206,1 +5304,1 @@\n-      Node* obj_size  = NULL;\n+      Node* obj_size  = nullptr;\n@@ -5210,1 +5308,1 @@\n-      Node* alloc_obj = new_instance(obj_klass, NULL, &obj_size, \/*deoptimize_on_exception=*\/true);\n+      Node* alloc_obj = new_instance(obj_klass, nullptr, &obj_size, \/*deoptimize_on_exception=*\/true);\n@@ -5254,1 +5352,1 @@\n-  if (alloc != NULL) {\n+  if (alloc != nullptr) {\n@@ -5286,18 +5384,1 @@\n-        JVMState* old_jvms = alloc->jvms()->clone_shallow(C);\n-        uint size = alloc->req();\n-        SafePointNode* sfpt = new SafePointNode(size, old_jvms);\n-        old_jvms->set_map(sfpt);\n-        for (uint i = 0; i < size; i++) {\n-          sfpt->init_req(i, alloc->in(i));\n-        }\n-        \/\/ re-push array length for deoptimization\n-        sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp(), alloc->in(AllocateNode::ALength));\n-        old_jvms->set_sp(old_jvms->sp()+1);\n-        old_jvms->set_monoff(old_jvms->monoff()+1);\n-        old_jvms->set_scloff(old_jvms->scloff()+1);\n-        old_jvms->set_endoff(old_jvms->endoff()+1);\n-        old_jvms->set_should_reexecute(true);\n-\n-        sfpt->set_i_o(map()->i_o());\n-        sfpt->set_memory(map()->memory());\n-        sfpt->set_control(map()->control());\n+        SafePointNode* sfpt = create_safepoint_with_state_before_array_allocation(alloc);\n@@ -5315,1 +5396,25 @@\n-  return NULL;\n+  return nullptr;\n+}\n+\n+\/\/ Clone the JVMState of the array allocation and create a new safepoint with it. Re-push the array length to the stack\n+\/\/ such that uncommon traps can be emitted to re-execute the array allocation in the interpreter.\n+SafePointNode* LibraryCallKit::create_safepoint_with_state_before_array_allocation(const AllocateArrayNode* alloc) const {\n+  JVMState* old_jvms = alloc->jvms()->clone_shallow(C);\n+  uint size = alloc->req();\n+  SafePointNode* sfpt = new SafePointNode(size, old_jvms);\n+  old_jvms->set_map(sfpt);\n+  for (uint i = 0; i < size; i++) {\n+    sfpt->init_req(i, alloc->in(i));\n+  }\n+  \/\/ re-push array length for deoptimization\n+  sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp(), alloc->in(AllocateNode::ALength));\n+  old_jvms->set_sp(old_jvms->sp()+1);\n+  old_jvms->set_monoff(old_jvms->monoff()+1);\n+  old_jvms->set_scloff(old_jvms->scloff()+1);\n+  old_jvms->set_endoff(old_jvms->endoff()+1);\n+  old_jvms->set_should_reexecute(true);\n+\n+  sfpt->set_i_o(map()->i_o());\n+  sfpt->set_memory(map()->memory());\n+  sfpt->set_control(map()->control());\n+  return sfpt;\n@@ -5325,1 +5430,1 @@\n-void LibraryCallKit::arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms,\n+void LibraryCallKit::arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms_before_guards,\n@@ -5327,2 +5432,4 @@\n-  if (saved_jvms != NULL && !stopped()) {\n-    assert(alloc != NULL, \"only with a tightly coupled allocation\");\n+  if (saved_jvms_before_guards != nullptr && !stopped()) {\n+    replace_unrelated_uncommon_traps_with_alloc_state(alloc, saved_jvms_before_guards);\n+\n+    assert(alloc != nullptr, \"only with a tightly coupled allocation\");\n@@ -5330,3 +5437,3 @@\n-    saved_jvms->map()->set_control(map()->control());\n-    assert(saved_jvms->map()->memory() == map()->memory(), \"memory state changed?\");\n-    assert(saved_jvms->map()->i_o() == map()->i_o(), \"IO state changed?\");\n+    saved_jvms_before_guards->map()->set_control(map()->control());\n+    assert(saved_jvms_before_guards->map()->memory() == map()->memory(), \"memory state changed?\");\n+    assert(saved_jvms_before_guards->map()->i_o() == map()->i_o(), \"IO state changed?\");\n@@ -5335,2 +5442,2 @@\n-    map()->replaced_nodes().apply(saved_jvms->map(), new_idx);\n-    set_jvms(saved_jvms);\n+    map()->replaced_nodes().apply(saved_jvms_before_guards->map(), new_idx);\n+    set_jvms(saved_jvms_before_guards);\n@@ -5356,1 +5463,1 @@\n-    Node* prev_cast = NULL;\n+    Node* prev_cast = nullptr;\n@@ -5362,1 +5469,1 @@\n-        if (prev_cast == NULL) {\n+        if (prev_cast == nullptr) {\n@@ -5390,1 +5497,1 @@\n-    if (ary_type->isa_aryptr() && length_type != NULL) {\n+    if (ary_type->isa_aryptr() && length_type != nullptr) {\n@@ -5411,0 +5518,52 @@\n+\/\/ Unrelated UCTs between the array allocation and the array copy, which are considered safe by tightly_coupled_allocation(),\n+\/\/ need to be replaced by an UCT with a state before the array allocation (including the array length). This is necessary\n+\/\/ because we could hit one of these UCTs (which are executed before the emitted array copy guards and the actual array\n+\/\/ allocation which is moved down in arraycopy_move_allocation_here()). When later resuming execution in the interpreter,\n+\/\/ we would have wrongly skipped the array allocation. To prevent this, we resume execution at the array allocation in\n+\/\/ the interpreter similar to what we are doing for the newly emitted guards for the array copy.\n+void LibraryCallKit::replace_unrelated_uncommon_traps_with_alloc_state(AllocateArrayNode* alloc,\n+                                                                       JVMState* saved_jvms_before_guards) {\n+  if (saved_jvms_before_guards->map()->control()->is_IfProj()) {\n+    \/\/ There is at least one unrelated uncommon trap which needs to be replaced.\n+    SafePointNode* sfpt = create_safepoint_with_state_before_array_allocation(alloc);\n+\n+    JVMState* saved_jvms = jvms();\n+    const int saved_reexecute_sp = _reexecute_sp;\n+    set_jvms(sfpt->jvms());\n+    _reexecute_sp = jvms()->sp();\n+\n+    replace_unrelated_uncommon_traps_with_alloc_state(saved_jvms_before_guards);\n+\n+    \/\/ Restore state\n+    set_jvms(saved_jvms);\n+    _reexecute_sp = saved_reexecute_sp;\n+  }\n+}\n+\n+\/\/ Replace the unrelated uncommon traps with new uncommon trap nodes by reusing the action and reason. The new uncommon\n+\/\/ traps will have the state of the array allocation. Let the old uncommon trap nodes die.\n+void LibraryCallKit::replace_unrelated_uncommon_traps_with_alloc_state(JVMState* saved_jvms_before_guards) {\n+  Node* if_proj = saved_jvms_before_guards->map()->control(); \/\/ Start the search right before the newly emitted guards\n+  while (if_proj->is_IfProj()) {\n+    CallStaticJavaNode* uncommon_trap = get_uncommon_trap_from_success_proj(if_proj);\n+    if (uncommon_trap != nullptr) {\n+      create_new_uncommon_trap(uncommon_trap);\n+    }\n+    assert(if_proj->in(0)->is_If(), \"must be If\");\n+    if_proj = if_proj->in(0)->in(0);\n+  }\n+  assert(if_proj->is_Proj() && if_proj->in(0)->is_Initialize(),\n+         \"must have reached control projection of init node\");\n+}\n+\n+void LibraryCallKit::create_new_uncommon_trap(CallStaticJavaNode* uncommon_trap_call) {\n+  const int trap_request = uncommon_trap_call->uncommon_trap_request();\n+  assert(trap_request != 0, \"no valid UCT trap request\");\n+  PreserveJVMState pjvms(this);\n+  set_control(uncommon_trap_call->in(0));\n+  uncommon_trap(Deoptimization::trap_request_reason(trap_request),\n+                Deoptimization::trap_request_action(trap_request));\n+  assert(stopped(), \"Should be stopped\");\n+  _gvn.hash_delete(uncommon_trap_call);\n+  uncommon_trap_call->set_req(0, top()); \/\/ not used anymore, kill it\n+}\n@@ -5431,1 +5590,1 @@\n-  JVMState* saved_jvms = arraycopy_restore_alloc_state(alloc, saved_reexecute_sp);\n+  JVMState* saved_jvms_before_guards = arraycopy_restore_alloc_state(alloc, saved_reexecute_sp);\n@@ -5433,4 +5592,4 @@\n-  \/\/ if alloc == NULL we don't have to worry about a tightly coupled allocation so we can emit all needed guards\n-  \/\/ if saved_jvms != NULL (then alloc != NULL) then we can handle guards and a tightly coupled allocation\n-  \/\/ if saved_jvms == NULL and alloc != NULL, we can't emit any guards\n-  bool can_emit_guards = (alloc == NULL || saved_jvms != NULL);\n+  \/\/ if alloc == null we don't have to worry about a tightly coupled allocation so we can emit all needed guards\n+  \/\/ if saved_jvms_before_guards is not null (then alloc is not null) then we can handle guards and a tightly coupled allocation\n+  \/\/ if saved_jvms_before_guards is null and alloc is not null, we can't emit any guards\n+  bool can_emit_guards = (alloc == nullptr || saved_jvms_before_guards != nullptr);\n@@ -5452,1 +5611,1 @@\n-  src  = saved_jvms != NULL ? null_check_oop(src, &null_ctl, true, true) : null_check(src,  T_ARRAY);\n+  src  = saved_jvms_before_guards != nullptr ? null_check_oop(src, &null_ctl, true, true) : null_check(src, T_ARRAY);\n@@ -5457,1 +5616,1 @@\n-    \/\/ if saved_jvms == NULL and alloc != NULL, we don't emit any\n+    \/\/ if saved_jvms_before_guards is null and alloc is not null, we don't emit any\n@@ -5475,1 +5634,1 @@\n-  bool has_src = (top_src != NULL && top_src->elem() != Type::BOTTOM);\n+  bool has_src = (top_src != nullptr && top_src->elem() != Type::BOTTOM);\n@@ -5477,1 +5636,1 @@\n-  bool has_dest = (top_dest != NULL && top_dest->elem() != Type::BOTTOM);\n+  bool has_dest = (top_dest != nullptr && top_dest->elem() != Type::BOTTOM);\n@@ -5493,1 +5652,1 @@\n-    ciKlass* src_k = NULL;\n+    ciKlass* src_k = nullptr;\n@@ -5496,1 +5655,1 @@\n-      if (src_k != NULL && src_k->is_array_klass()) {\n+      if (src_k != nullptr && src_k->is_array_klass()) {\n@@ -5501,1 +5660,1 @@\n-    ciKlass* dest_k = NULL;\n+    ciKlass* dest_k = nullptr;\n@@ -5504,1 +5663,1 @@\n-      if (dest_k != NULL && dest_k->is_array_klass()) {\n+      if (dest_k != nullptr && dest_k->is_array_klass()) {\n@@ -5515,1 +5674,1 @@\n-        has_src = (top_src != NULL && top_src->elem() != Type::BOTTOM);\n+        has_src = (top_src != nullptr && top_src->elem() != Type::BOTTOM);\n@@ -5522,1 +5681,1 @@\n-        has_dest = (top_dest != NULL && top_dest->elem() != Type::BOTTOM);\n+        has_dest = (top_dest != nullptr && top_dest->elem() != Type::BOTTOM);\n@@ -5534,1 +5693,1 @@\n-    if (src_elem == dest_elem && src_elem == T_OBJECT) {\n+    if (src_elem == dest_elem && top_src->is_flat() == top_dest->is_flat() && src_elem == T_OBJECT) {\n@@ -5543,2 +5702,2 @@\n-      ciKlass* src_k = NULL;\n-      ciKlass* dest_k = NULL;\n+      ciKlass* src_k = nullptr;\n+      ciKlass* dest_k = nullptr;\n@@ -5547,1 +5706,1 @@\n-        if (src_k != NULL && src_k->is_array_klass()) {\n+        if (src_k != nullptr && src_k->is_array_klass()) {\n@@ -5553,1 +5712,1 @@\n-        if (dest_k != NULL && dest_k->is_array_klass()) {\n+        if (dest_k != nullptr && dest_k->is_array_klass()) {\n@@ -5575,1 +5734,1 @@\n-  if (saved_jvms != NULL) {\n+  if (saved_jvms_before_guards != nullptr) {\n@@ -5638,2 +5797,2 @@\n-      assert(top_dest == NULL || !top_dest->is_flat() || top_src->is_flat(), \"src array must be flat\");\n-      if (top_src != NULL && top_src->is_flat()) {\n+      assert(top_dest == nullptr || !top_dest->is_flat() || top_src->is_flat(), \"src array must be flat\");\n+      if (top_src != nullptr && top_src->is_flat()) {\n@@ -5641,1 +5800,1 @@\n-        if (top_dest != NULL && !top_dest->is_flat()) {\n+        if (top_dest != nullptr && !top_dest->is_flat()) {\n@@ -5648,1 +5807,1 @@\n-      } else if (top_src == NULL || !top_src->is_not_flat()) {\n+      } else if (top_src == nullptr || !top_src->is_not_flat()) {\n@@ -5651,1 +5810,1 @@\n-        assert(top_dest == NULL || !top_dest->is_flat(), \"dest array must not be flat\");\n+        assert(top_dest == nullptr || !top_dest->is_flat(), \"dest array must not be flat\");\n@@ -5653,1 +5812,1 @@\n-        if (top_src != NULL) {\n+        if (top_src != nullptr) {\n@@ -5667,0 +5826,1 @@\n+    arraycopy_move_allocation_here(alloc, dest, saved_jvms_before_guards, saved_reexecute_sp, new_idx);\n@@ -5669,2 +5829,0 @@\n-  arraycopy_move_allocation_here(alloc, dest, saved_jvms, saved_reexecute_sp, new_idx);\n-\n@@ -5675,1 +5833,1 @@\n-  ArrayCopyNode* ac = ArrayCopyNode::make(this, true, src, src_offset, dest, dest_offset, length, alloc != NULL, negative_length_guard_generated,\n+  ArrayCopyNode* ac = ArrayCopyNode::make(this, true, src, src_offset, dest, dest_offset, length, alloc != nullptr, negative_length_guard_generated,\n@@ -5702,2 +5860,2 @@\n-  if (stopped())             return NULL;  \/\/ no fast path\n-  if (!C->do_aliasing())     return NULL;  \/\/ no MergeMems around\n+  if (stopped())             return nullptr;  \/\/ no fast path\n+  if (!C->do_aliasing())     return nullptr;  \/\/ no MergeMems around\n@@ -5706,1 +5864,1 @@\n-  if (alloc == NULL)  return NULL;\n+  if (alloc == nullptr)  return nullptr;\n@@ -5713,1 +5871,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -5717,1 +5875,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -5724,1 +5882,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -5735,20 +5893,8 @@\n-    if ((ctl->is_IfFalse() || ctl->is_IfTrue()) && ctl->in(0)->is_If()) {\n-      IfNode* iff = ctl->in(0)->as_If();\n-      Node* not_ctl = iff->proj_out_or_null(1 - ctl->as_Proj()->_con);\n-      assert(not_ctl != NULL && not_ctl != ctl, \"found alternate\");\n-      \/\/ One more try:  Various low-level checks bottom out in\n-      \/\/ uncommon traps.  If the debug-info of the trap omits\n-      \/\/ any reference to the allocation, as we've already\n-      \/\/ observed, then there can be no objection to the trap.\n-      bool found_trap = false;\n-      for (DUIterator_Fast jmax, j = not_ctl->fast_outs(jmax); j < jmax; j++) {\n-        Node* obs = not_ctl->fast_out(j);\n-        if (obs->in(0) == not_ctl && obs->is_Call() &&\n-            (obs->as_Call()->entry_point() == SharedRuntime::uncommon_trap_blob()->entry_point())) {\n-          found_trap = true; break;\n-        }\n-      }\n-      if (found_trap) {\n-        ctl = iff->in(0);       \/\/ This test feeds a harmless uncommon trap.\n-        continue;\n-      }\n+    \/\/ Various low-level checks bottom out in uncommon traps. These\n+    \/\/ are considered safe since we've already checked above that\n+    \/\/ there is no unexpected observer of this allocation.\n+    if (get_uncommon_trap_from_success_proj(ctl) != nullptr) {\n+      assert(ctl->in(0)->is_If(), \"must be If\");\n+      ctl = ctl->in(0)->in(0);\n+    } else {\n+      return nullptr;\n@@ -5756,1 +5902,0 @@\n-    return NULL;\n@@ -5767,0 +5912,14 @@\n+CallStaticJavaNode* LibraryCallKit::get_uncommon_trap_from_success_proj(Node* node) {\n+  if (node->is_IfProj()) {\n+    Node* other_proj = node->as_IfProj()->other_if_proj();\n+    for (DUIterator_Fast jmax, j = other_proj->fast_outs(jmax); j < jmax; j++) {\n+      Node* obs = other_proj->fast_out(j);\n+      if (obs->in(0) == other_proj && obs->is_CallStaticJava() &&\n+          (obs->as_CallStaticJava()->entry_point() == SharedRuntime::uncommon_trap_blob()->entry_point())) {\n+        return obs->as_CallStaticJava();\n+      }\n+    }\n+  }\n+  return nullptr;\n+}\n+\n@@ -5781,6 +5940,4 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const Type* dst_type = dst->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  const TypeAryPtr* top_dest = dst_type->isa_aryptr();\n-  if (top_src  == NULL || top_src->elem()  == Type::BOTTOM ||\n-      top_dest == NULL || top_dest->elem() == Type::BOTTOM) {\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* dst_type = dst->Value(&_gvn)->isa_aryptr();\n+  if (src_type == nullptr || src_type->elem() == Type::BOTTOM ||\n+      dst_type == nullptr || dst_type->elem() == Type::BOTTOM) {\n@@ -5792,2 +5949,2 @@\n-  BasicType src_elem = src_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType dst_elem = dst_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType src_elem = src_type->elem()->array_element_basic_type();\n+  BasicType dst_elem = dst_type->elem()->array_element_basic_type();\n@@ -5819,1 +5976,1 @@\n-  if (stubAddr == NULL) {\n+  if (stubAddr == nullptr) {\n@@ -5836,6 +5993,4 @@\n-  const Type* x_type = x->Value(&_gvn);\n-  const Type* y_type = y->Value(&_gvn);\n-  const TypeAryPtr* top_x = x_type->isa_aryptr();\n-  const TypeAryPtr* top_y = y_type->isa_aryptr();\n-  if (top_x  == NULL || top_x->elem()  == Type::BOTTOM ||\n-      top_y == NULL || top_y->elem() == Type::BOTTOM) {\n+  const TypeAryPtr* x_type = x->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* y_type = y->Value(&_gvn)->isa_aryptr();\n+  if (x_type == nullptr || x_type->elem() == Type::BOTTOM ||\n+      y_type == nullptr || y_type->elem() == Type::BOTTOM) {\n@@ -5846,2 +6001,2 @@\n-  BasicType x_elem = x_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType y_elem = y_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType x_elem = x_type->elem()->array_element_basic_type();\n+  BasicType y_elem = y_type->elem()->array_element_basic_type();\n@@ -5929,1 +6084,1 @@\n-  if (stubAddr == NULL) {\n+  if (stubAddr == nullptr) {\n@@ -5944,6 +6099,4 @@\n-  const Type* x_type = x->Value(&_gvn);\n-  const Type* z_type = z->Value(&_gvn);\n-  const TypeAryPtr* top_x = x_type->isa_aryptr();\n-  const TypeAryPtr* top_z = z_type->isa_aryptr();\n-  if (top_x  == NULL || top_x->elem()  == Type::BOTTOM ||\n-      top_z  == NULL || top_z->elem()  == Type::BOTTOM) {\n+  const TypeAryPtr* x_type = x->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* z_type = z->Value(&_gvn)->isa_aryptr();\n+  if (x_type == nullptr || x_type->elem() == Type::BOTTOM ||\n+      z_type == nullptr || z_type->elem() == Type::BOTTOM) {\n@@ -5954,2 +6107,2 @@\n-  BasicType x_elem = x_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType z_elem = z_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType x_elem = x_type->elem()->array_element_basic_type();\n+  BasicType z_elem = z_type->elem()->array_element_basic_type();\n@@ -5978,1 +6131,1 @@\n-  if (stubAddr == NULL) {\n+  if (stubAddr == nullptr) {\n@@ -5991,0 +6144,1 @@\n+  in = must_be_not_null(in, true);\n@@ -5993,6 +6147,4 @@\n-  const Type* out_type = out->Value(&_gvn);\n-  const Type* in_type = in->Value(&_gvn);\n-  const TypeAryPtr* top_out = out_type->isa_aryptr();\n-  const TypeAryPtr* top_in = in_type->isa_aryptr();\n-  if (top_out  == NULL || top_out->elem()  == Type::BOTTOM ||\n-      top_in == NULL || top_in->elem() == Type::BOTTOM) {\n+  const TypeAryPtr* out_type = out->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* in_type = in->Value(&_gvn)->isa_aryptr();\n+  if (out_type == nullptr || out_type->elem() == Type::BOTTOM ||\n+       in_type == nullptr ||  in_type->elem() == Type::BOTTOM) {\n@@ -6003,2 +6155,2 @@\n-  BasicType out_elem = out_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType in_elem = in_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType out_elem = out_type->elem()->array_element_basic_type();\n+  BasicType in_elem = in_type->elem()->array_element_basic_type();\n@@ -6026,1 +6178,1 @@\n-  if (stubAddr == NULL) {\n+  if (stubAddr == nullptr) {\n@@ -6042,12 +6194,8 @@\n-  const Type* a_type = a->Value(&_gvn);\n-  const TypeAryPtr* top_a = a_type->isa_aryptr();\n-  const Type* b_type = b->Value(&_gvn);\n-  const TypeAryPtr* top_b = b_type->isa_aryptr();\n-  const Type* n_type = a->Value(&_gvn);\n-  const TypeAryPtr* top_n = n_type->isa_aryptr();\n-  const Type* m_type = a->Value(&_gvn);\n-  const TypeAryPtr* top_m = m_type->isa_aryptr();\n-  if (top_a  == NULL || top_a->elem()  == Type::BOTTOM ||\n-      top_b == NULL || top_b->elem()  == Type::BOTTOM ||\n-      top_n == NULL || top_n->elem()  == Type::BOTTOM ||\n-      top_m == NULL || top_m->elem()  == Type::BOTTOM) {\n+  const TypeAryPtr* a_type = a->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* b_type = b->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* n_type = n->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* m_type = m->Value(&_gvn)->isa_aryptr();\n+  if (a_type == nullptr || a_type->elem() == Type::BOTTOM ||\n+      b_type == nullptr || b_type->elem() == Type::BOTTOM ||\n+      n_type == nullptr || n_type->elem() == Type::BOTTOM ||\n+      m_type == nullptr || m_type->elem() == Type::BOTTOM) {\n@@ -6058,4 +6206,4 @@\n-  BasicType a_elem = a_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType b_elem = b_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType n_elem = n_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType m_elem = m_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType a_elem = a_type->elem()->array_element_basic_type();\n+  BasicType b_elem = b_type->elem()->array_element_basic_type();\n+  BasicType n_elem = n_type->elem()->array_element_basic_type();\n+  BasicType m_elem = m_type->elem()->array_element_basic_type();\n@@ -6086,1 +6234,1 @@\n-  if (stubAddr == NULL) {\n+  if (stubAddr == nullptr) {\n@@ -6101,9 +6249,6 @@\n-  const Type* a_type = a->Value(&_gvn);\n-  const TypeAryPtr* top_a = a_type->isa_aryptr();\n-  const Type* n_type = a->Value(&_gvn);\n-  const TypeAryPtr* top_n = n_type->isa_aryptr();\n-  const Type* m_type = a->Value(&_gvn);\n-  const TypeAryPtr* top_m = m_type->isa_aryptr();\n-  if (top_a  == NULL || top_a->elem()  == Type::BOTTOM ||\n-      top_n == NULL || top_n->elem()  == Type::BOTTOM ||\n-      top_m == NULL || top_m->elem()  == Type::BOTTOM) {\n+  const TypeAryPtr* a_type = a->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* n_type = n->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* m_type = m->Value(&_gvn)->isa_aryptr();\n+  if (a_type == nullptr || a_type->elem() == Type::BOTTOM ||\n+      n_type == nullptr || n_type->elem() == Type::BOTTOM ||\n+      m_type == nullptr || m_type->elem() == Type::BOTTOM) {\n@@ -6114,3 +6259,3 @@\n-  BasicType a_elem = a_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType n_elem = n_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType m_elem = m_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType a_elem = a_type->elem()->array_element_basic_type();\n+  BasicType n_elem = n_type->elem()->array_element_basic_type();\n+  BasicType m_elem = m_type->elem()->array_element_basic_type();\n@@ -6139,2 +6284,2 @@\n-  address stubAddr = NULL;\n-  const char* stubName = NULL;\n+  address stubAddr = nullptr;\n+  const char* stubName = nullptr;\n@@ -6143,1 +6288,1 @@\n-  if (stubAddr == NULL) {\n+  if (stubAddr == nullptr) {\n@@ -6157,6 +6302,4 @@\n-  const Type* newArr_type = newArr->Value(&_gvn);\n-  const TypeAryPtr* top_newArr = newArr_type->isa_aryptr();\n-  const Type* oldArr_type = oldArr->Value(&_gvn);\n-  const TypeAryPtr* top_oldArr = oldArr_type->isa_aryptr();\n-  if (top_newArr == NULL || top_newArr->elem() == Type::BOTTOM || top_oldArr == NULL\n-      || top_oldArr->elem() == Type::BOTTOM) {\n+  const TypeAryPtr* newArr_type = newArr->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* oldArr_type = oldArr->Value(&_gvn)->isa_aryptr();\n+  if (newArr_type == nullptr || newArr_type->elem() == Type::BOTTOM ||\n+      oldArr_type == nullptr || oldArr_type->elem() == Type::BOTTOM) {\n@@ -6166,2 +6309,2 @@\n-  BasicType newArr_elem = newArr_type->isa_aryptr()->elem()->array_element_basic_type();\n-  BasicType oldArr_elem = oldArr_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType newArr_elem = newArr_type->elem()->array_element_basic_type();\n+  BasicType oldArr_elem = oldArr_type->elem()->array_element_basic_type();\n@@ -6206,2 +6349,2 @@\n-  if (obja_t == NULL || obja_t->elem() == Type::BOTTOM ||\n-      objb_t == NULL || objb_t->elem() == Type::BOTTOM ||\n+  if (obja_t == nullptr || obja_t->elem() == Type::BOTTOM ||\n+      objb_t == nullptr || objb_t->elem() == Type::BOTTOM ||\n@@ -6275,1 +6418,1 @@\n-      call_stub_path = generate_guard(bol_gt, NULL, PROB_MIN);\n+      call_stub_path = generate_guard(bol_gt, nullptr, PROB_MIN);\n@@ -6300,1 +6443,1 @@\n-  if (call_stub_path != NULL) {\n+  if (call_stub_path != nullptr) {\n@@ -6324,0 +6467,34 @@\n+\/\/------------------------------inline_vectorizedHashcode----------------------------\n+bool LibraryCallKit::inline_vectorizedHashCode() {\n+  assert(UseVectorizedHashCodeIntrinsic, \"not implemented on this platform\");\n+\n+  assert(callee()->signature()->size() == 5, \"vectorizedHashCode has 5 parameters\");\n+  Node* array          = argument(0);\n+  Node* offset         = argument(1);\n+  Node* length         = argument(2);\n+  Node* initialValue   = argument(3);\n+  Node* basic_type     = argument(4);\n+\n+  if (basic_type == top()) {\n+    return false; \/\/ failed input validation\n+  }\n+\n+  const TypeInt* basic_type_t = _gvn.type(basic_type)->is_int();\n+  if (!basic_type_t->is_con()) {\n+    return false; \/\/ Only intrinsify if mode argument is constant\n+  }\n+\n+  array = must_be_not_null(array, true);\n+\n+  BasicType bt = (BasicType)basic_type_t->get_con();\n+\n+  \/\/ Resolve address of first element\n+  Node* array_start = array_element_address(array, offset, bt);\n+\n+  set_result(_gvn.transform(new VectorizedHashCodeNode(control(), memory(TypeAryPtr::get_array_body_type(bt)),\n+    array_start, length, initialValue, basic_type)));\n+  clear_upper_avx();\n+\n+  return true;\n+}\n+\n@@ -6372,3 +6549,2 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  if (top_src  == NULL || top_src->elem()  == Type::BOTTOM) {\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  if (src_type == nullptr || src_type->elem() == Type::BOTTOM) {\n@@ -6380,1 +6556,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType src_elem = src_type->elem()->array_element_basic_type();\n@@ -6438,2 +6614,2 @@\n-  Node* table = load_field_from_object(NULL, \"byteTable\", \"[I\", \/*decorators*\/ IN_HEAP, \/*is_static*\/ true, crc32c_class);\n-  assert (table != NULL, \"wrong version of java.util.zip.CRC32C\");\n+  Node* table = load_field_from_object(nullptr, \"byteTable\", \"[I\", \/*decorators*\/ IN_HEAP, \/*is_static*\/ true, crc32c_class);\n+  assert (table != nullptr, \"wrong version of java.util.zip.CRC32C\");\n@@ -6461,3 +6637,2 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  if (top_src  == NULL || top_src->elem()  == Type::BOTTOM) {\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  if (src_type == nullptr || src_type->elem() == Type::BOTTOM) {\n@@ -6469,1 +6644,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType src_elem = src_type->elem()->array_element_basic_type();\n@@ -6554,3 +6729,2 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  if (top_src  == NULL || top_src->elem()  == Type::BOTTOM) {\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  if (src_type == nullptr || src_type->elem() == Type::BOTTOM) {\n@@ -6562,1 +6736,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType src_elem = src_type->elem()->array_element_basic_type();\n@@ -6631,2 +6805,2 @@\n-                                        decorators, \/*is_static*\/ false, NULL);\n-  if (result == NULL) return false;\n+                                        decorators, \/*is_static*\/ false, nullptr);\n+  if (result == nullptr) return false;\n@@ -6654,2 +6828,2 @@\n-                                          decorators, \/*is_static*\/ false, NULL);\n-  if (referent == NULL) return false;\n+                                          decorators, \/*is_static*\/ false, nullptr);\n+  if (referent == nullptr) return false;\n@@ -6686,1 +6860,1 @@\n-  if (fromKls == NULL) {\n+  if (fromKls == nullptr) {\n@@ -6688,1 +6862,1 @@\n-    assert(tinst != NULL, \"obj is null\");\n+    assert(tinst != nullptr, \"obj is null\");\n@@ -6698,2 +6872,2 @@\n-  assert(field != NULL, \"undefined field %s %s %s\", fieldTypeString, fromKls->name()->as_utf8(), fieldName);\n-  if (field == NULL) return (Node *) NULL;\n+  assert(field != nullptr, \"undefined field %s %s %s\", fieldTypeString, fromKls->name()->as_utf8(), fieldName);\n+  if (field == nullptr) return (Node *) nullptr;\n@@ -6734,2 +6908,2 @@\n-                                                 ciInstanceKlass * fromKls \/* NULL *\/) {\n-  if (fromKls == NULL) {\n+                                                 ciInstanceKlass * fromKls \/* nullptr *\/) {\n+  if (fromKls == nullptr) {\n@@ -6737,1 +6911,1 @@\n-    assert(tinst != NULL, \"obj is null\");\n+    assert(tinst != nullptr, \"obj is null\");\n@@ -6749,1 +6923,1 @@\n-  assert(field != NULL, \"undefined field\");\n+  assert(field != nullptr, \"undefined field\");\n@@ -6768,1 +6942,1 @@\n-  address stubAddr = NULL;\n+  address stubAddr = nullptr;\n@@ -6784,1 +6958,1 @@\n-  if (stubAddr == NULL) return false;\n+  if (stubAddr == nullptr) return false;\n@@ -6796,5 +6970,4 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const Type* dest_type = dest->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  const TypeAryPtr* top_dest = dest_type->isa_aryptr();\n-  assert (top_src  != NULL && top_src->elem()  != Type::BOTTOM &&  top_dest != NULL && top_dest->elem() != Type::BOTTOM, \"args are strange\");\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* dest_type = dest->Value(&_gvn)->isa_aryptr();\n+  assert( src_type != nullptr &&  src_type->elem() != Type::BOTTOM &&\n+         dest_type != nullptr && dest_type->elem() != Type::BOTTOM, \"args are strange\");\n@@ -6806,2 +6979,2 @@\n-  if (src_offset != NULL || dest_offset != NULL) {\n-    assert(src_offset != NULL && dest_offset != NULL, \"\");\n+  if (src_offset != nullptr || dest_offset != nullptr) {\n+    assert(src_offset != nullptr && dest_offset != nullptr, \"\");\n@@ -6815,1 +6988,1 @@\n-  if (k_start == NULL) return false;\n+  if (k_start == nullptr) return false;\n@@ -6827,2 +7000,2 @@\n-  address stubAddr = NULL;\n-  const char *stubName = NULL;\n+  address stubAddr = nullptr;\n+  const char *stubName = nullptr;\n@@ -6844,1 +7017,1 @@\n-  if (stubAddr == NULL) return false;\n+  if (stubAddr == nullptr) return false;\n@@ -6857,6 +7030,4 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const Type* dest_type = dest->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  const TypeAryPtr* top_dest = dest_type->isa_aryptr();\n-  assert (top_src  != NULL && top_src->elem()  != Type::BOTTOM\n-          &&  top_dest != NULL && top_dest->elem() != Type::BOTTOM, \"args are strange\");\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* dest_type = dest->Value(&_gvn)->isa_aryptr();\n+  assert( src_type != nullptr &&  src_type->elem() != Type::BOTTOM &&\n+         dest_type != nullptr && dest_type->elem() != Type::BOTTOM, \"args are strange\");\n@@ -6867,2 +7038,2 @@\n-  if (src_offset != NULL || dest_offset != NULL) {\n-    assert(src_offset != NULL && dest_offset != NULL, \"\");\n+  if (src_offset != nullptr || dest_offset != nullptr) {\n+    assert(src_offset != nullptr && dest_offset != nullptr, \"\");\n@@ -6879,1 +7050,1 @@\n-  if (embeddedCipherObj == NULL) return false;\n+  if (embeddedCipherObj == nullptr) return false;\n@@ -6883,1 +7054,1 @@\n-  assert(tinst != NULL, \"CBC obj is null\");\n+  assert(tinst != nullptr, \"CBC obj is null\");\n@@ -6896,1 +7067,1 @@\n-  if (k_start == NULL) return false;\n+  if (k_start == nullptr) return false;\n@@ -6900,1 +7071,1 @@\n-  if (objRvec == NULL) return false;\n+  if (objRvec == nullptr) return false;\n@@ -6917,2 +7088,2 @@\n-  address stubAddr = NULL;\n-  const char *stubName = NULL;\n+  address stubAddr = nullptr;\n+  const char *stubName = nullptr;\n@@ -6935,1 +7106,1 @@\n-  if (stubAddr == NULL) return false;\n+  if (stubAddr == nullptr) return false;\n@@ -6945,6 +7116,4 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const Type* dest_type = dest->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  const TypeAryPtr* top_dest = dest_type->isa_aryptr();\n-  assert(top_src != NULL && top_src->elem() != Type::BOTTOM\n-         &&  top_dest != NULL && top_dest->elem() != Type::BOTTOM, \"args are strange\");\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* dest_type = dest->Value(&_gvn)->isa_aryptr();\n+  assert( src_type != nullptr &&  src_type->elem() != Type::BOTTOM &&\n+         dest_type != nullptr && dest_type->elem() != Type::BOTTOM, \"args are strange\");\n@@ -6955,2 +7124,2 @@\n-  if (src_offset != NULL || dest_offset != NULL) {\n-    assert(src_offset != NULL && dest_offset != NULL, \"\");\n+  if (src_offset != nullptr || dest_offset != nullptr) {\n+    assert(src_offset != nullptr && dest_offset != nullptr, \"\");\n@@ -6967,1 +7136,1 @@\n-  if (embeddedCipherObj == NULL) return false;\n+  if (embeddedCipherObj == nullptr) return false;\n@@ -6971,1 +7140,1 @@\n-  assert(tinst != NULL, \"ECB obj is null\");\n+  assert(tinst != nullptr, \"ECB obj is null\");\n@@ -6984,1 +7153,1 @@\n-  if (k_start == NULL) return false;\n+  if (k_start == nullptr) return false;\n@@ -7003,2 +7172,2 @@\n-  address stubAddr = NULL;\n-  const char *stubName = NULL;\n+  address stubAddr = nullptr;\n+  const char *stubName = nullptr;\n@@ -7009,1 +7178,1 @@\n-  if (stubAddr == NULL) return false;\n+  if (stubAddr == nullptr) return false;\n@@ -7019,6 +7188,4 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const Type* dest_type = dest->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  const TypeAryPtr* top_dest = dest_type->isa_aryptr();\n-  assert(top_src != NULL && top_src->elem() != Type::BOTTOM &&\n-         top_dest != NULL && top_dest->elem() != Type::BOTTOM, \"args are strange\");\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* dest_type = dest->Value(&_gvn)->isa_aryptr();\n+  assert( src_type != nullptr &&  src_type->elem() != Type::BOTTOM &&\n+         dest_type != nullptr && dest_type->elem() != Type::BOTTOM, \"args are strange\");\n@@ -7029,2 +7196,2 @@\n-  if (src_offset != NULL || dest_offset != NULL) {\n-    assert(src_offset != NULL && dest_offset != NULL, \"\");\n+  if (src_offset != nullptr || dest_offset != nullptr) {\n+    assert(src_offset != nullptr && dest_offset != nullptr, \"\");\n@@ -7040,1 +7207,1 @@\n-  if (embeddedCipherObj == NULL) return false;\n+  if (embeddedCipherObj == nullptr) return false;\n@@ -7043,1 +7210,1 @@\n-  assert(tinst != NULL, \"CTR obj is null\");\n+  assert(tinst != nullptr, \"CTR obj is null\");\n@@ -7054,1 +7221,1 @@\n-  if (k_start == NULL) return false;\n+  if (k_start == nullptr) return false;\n@@ -7057,1 +7224,1 @@\n-  if (obj_counter == NULL) return false;\n+  if (obj_counter == nullptr) return false;\n@@ -7061,1 +7228,1 @@\n-  if (saved_encCounter == NULL) return false;\n+  if (saved_encCounter == nullptr) return false;\n@@ -7085,3 +7252,3 @@\n-  assert (objSessionK != NULL, \"wrong version of com.sun.crypto.provider.AESCrypt\");\n-  if (objSessionK == NULL) {\n-    return (Node *) NULL;\n+  assert (objSessionK != nullptr, \"wrong version of com.sun.crypto.provider.AESCrypt\");\n+  if (objSessionK == nullptr) {\n+    return (Node *) nullptr;\n@@ -7093,2 +7260,2 @@\n-  assert (objAESCryptKey != NULL, \"wrong version of com.sun.crypto.provider.AESCrypt\");\n-  if (objAESCryptKey == NULL) return (Node *) NULL;\n+  assert (objAESCryptKey != nullptr, \"wrong version of com.sun.crypto.provider.AESCrypt\");\n+  if (objAESCryptKey == nullptr) return (Node *) nullptr;\n@@ -7111,1 +7278,1 @@\n-  \/\/ The receiver was checked for NULL already.\n+  \/\/ The receiver was checked for null already.\n@@ -7124,1 +7291,1 @@\n-  assert(tinst != NULL, \"CBCobj is null\");\n+  assert(tinst != nullptr, \"CBCobj is null\");\n@@ -7146,1 +7313,1 @@\n-  Node* instof_false = generate_guard(bool_instof, NULL, PROB_MIN);\n+  Node* instof_false = generate_guard(bool_instof, nullptr, PROB_MIN);\n@@ -7150,1 +7317,1 @@\n-    return instof_false;  \/\/ even if it is NULL\n+    return instof_false;  \/\/ even if it is null\n@@ -7160,1 +7327,1 @@\n-  Node* src_dest_conjoint = generate_guard(bool_src_dest, NULL, PROB_MIN);\n+  Node* src_dest_conjoint = generate_guard(bool_src_dest, nullptr, PROB_MIN);\n@@ -7177,1 +7344,1 @@\n-  \/\/ The receiver was checked for NULL already.\n+  \/\/ The receiver was checked for null already.\n@@ -7187,1 +7354,1 @@\n-  assert(tinst != NULL, \"ECBobj is null\");\n+  assert(tinst != nullptr, \"ECBobj is null\");\n@@ -7204,1 +7371,1 @@\n-  Node* instof_false = generate_guard(bool_instof, NULL, PROB_MIN);\n+  Node* instof_false = generate_guard(bool_instof, nullptr, PROB_MIN);\n@@ -7208,1 +7375,1 @@\n-    return instof_false;  \/\/ even if it is NULL\n+    return instof_false;  \/\/ even if it is null\n@@ -7219,1 +7386,1 @@\n-  Node* src_dest_conjoint = generate_guard(bool_src_dest, NULL, PROB_MIN);\n+  Node* src_dest_conjoint = generate_guard(bool_src_dest, nullptr, PROB_MIN);\n@@ -7237,1 +7404,1 @@\n-  \/\/ The receiver was checked for NULL already.\n+  \/\/ The receiver was checked for null already.\n@@ -7247,1 +7414,1 @@\n-  assert(tinst != NULL, \"CTRobj is null\");\n+  assert(tinst != nullptr, \"CTRobj is null\");\n@@ -7263,1 +7430,1 @@\n-  Node* instof_false = generate_guard(bool_instof, NULL, PROB_MIN);\n+  Node* instof_false = generate_guard(bool_instof, nullptr, PROB_MIN);\n@@ -7265,1 +7432,1 @@\n-  return instof_false; \/\/ even if it is NULL\n+  return instof_false; \/\/ even if it is null\n@@ -7288,1 +7455,1 @@\n-  assert(state_start, \"state is NULL\");\n+  assert(state_start, \"state is null\");\n@@ -7290,1 +7457,1 @@\n-  assert(subkeyH_start, \"subkeyH is NULL\");\n+  assert(subkeyH_start, \"subkeyH is null\");\n@@ -7292,1 +7459,1 @@\n-  assert(data_start, \"data is NULL\");\n+  assert(data_start, \"data is null\");\n@@ -7317,1 +7484,1 @@\n-  assert(state_start, \"state is NULL\");\n+  assert(state_start, \"state is null\");\n@@ -7319,1 +7486,1 @@\n-  assert(result_start, \"result is NULL\");\n+  assert(result_start, \"result is null\");\n@@ -7352,1 +7519,1 @@\n-  assert(src_start, \"source array is NULL\");\n+  assert(src_start, \"source array is null\");\n@@ -7354,1 +7521,1 @@\n-  assert(dest_start, \"destination array is NULL\");\n+  assert(dest_start, \"destination array is null\");\n@@ -7385,1 +7552,1 @@\n-  assert(src_start, \"source array is NULL\");\n+  assert(src_start, \"source array is null\");\n@@ -7387,1 +7554,1 @@\n-  assert(dest_start, \"destination array is NULL\");\n+  assert(dest_start, \"destination array is null\");\n@@ -7401,1 +7568,1 @@\n-  assert(UsePolyIntrinsics, \"need Poly intrinsics support\");\n+  assert(UsePoly1305Intrinsics, \"need Poly intrinsics support\");\n@@ -7421,1 +7588,1 @@\n-  assert(input_start, \"input array is NULL\");\n+  assert(input_start, \"input array is null\");\n@@ -7423,1 +7590,1 @@\n-  assert(acc_start, \"acc array is NULL\");\n+  assert(acc_start, \"acc array is null\");\n@@ -7425,1 +7592,1 @@\n-  assert(r_start, \"r array is NULL\");\n+  assert(r_start, \"r array is null\");\n@@ -7458,3 +7625,2 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  if (top_src  == NULL || top_src->elem()  == Type::BOTTOM) {\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  if (src_type == nullptr || src_type->elem() == Type::BOTTOM) {\n@@ -7465,1 +7631,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType src_elem = src_type->elem()->array_element_basic_type();\n@@ -7472,2 +7638,2 @@\n-  Node* state = NULL;\n-  Node* block_size = NULL;\n+  Node* state = nullptr;\n+  Node* block_size = nullptr;\n@@ -7508,1 +7674,1 @@\n-    if (block_size == NULL) return false;\n+    if (block_size == nullptr) return false;\n@@ -7514,1 +7680,1 @@\n-  if (state == NULL) return false;\n+  if (state == nullptr) return false;\n@@ -7516,2 +7682,2 @@\n-  assert(stubAddr != NULL, \"Stub is generated\");\n-  if (stubAddr == NULL) return false;\n+  assert(stubAddr != nullptr, \"Stub %s is not generated\", stubName);\n+  if (stubAddr == nullptr) return false;\n@@ -7521,1 +7687,1 @@\n-  if (block_size == NULL) {\n+  if (block_size == nullptr) {\n@@ -7545,1 +7711,1 @@\n-  Node* digestBase_obj = argument(0); \/\/ The receiver was checked for NULL already.\n+  Node* digestBase_obj = argument(0); \/\/ The receiver was checked for null already.\n@@ -7550,3 +7716,2 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const TypeAryPtr* top_src = src_type->isa_aryptr();\n-  if (top_src  == NULL || top_src->elem()  == Type::BOTTOM) {\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  if (src_type == nullptr || src_type->elem() == Type::BOTTOM) {\n@@ -7557,1 +7722,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->elem()->array_element_basic_type();\n+  BasicType src_elem = src_type->elem()->array_element_basic_type();\n@@ -7565,3 +7730,3 @@\n-  const char* klass_digestBase_name = NULL;\n-  const char* stub_name = NULL;\n-  address     stub_addr = NULL;\n+  const char* klass_digestBase_name = nullptr;\n+  const char* stub_name = nullptr;\n+  address     stub_addr = nullptr;\n@@ -7611,3 +7776,3 @@\n-  if (klass_digestBase_name != NULL) {\n-    assert(stub_addr != NULL, \"Stub is generated\");\n-    if (stub_addr == NULL) return false;\n+  if (klass_digestBase_name != nullptr) {\n+    assert(stub_addr != nullptr, \"Stub is generated\");\n+    if (stub_addr == nullptr) return false;\n@@ -7617,1 +7782,1 @@\n-    assert(tinst != NULL, \"digestBase_obj is not instance???\");\n+    assert(tinst != nullptr, \"digestBase_obj is not instance???\");\n@@ -7633,1 +7798,1 @@\n-  const TypeOopPtr* xtype = aklass->as_instance_type()->cast_to_ptr_type(TypePtr::NotNull);\n+  const TypeOopPtr* xtype = aklass->cast_to_exactness(false)->as_instance_type()->cast_to_ptr_type(TypePtr::NotNull);\n@@ -7638,1 +7803,1 @@\n-  if (state == NULL) return false;\n+  if (state == nullptr) return false;\n@@ -7640,1 +7805,1 @@\n-  Node* block_size = NULL;\n+  Node* block_size = nullptr;\n@@ -7643,1 +7808,1 @@\n-    if (block_size == NULL) return false;\n+    if (block_size == nullptr) return false;\n@@ -7648,1 +7813,1 @@\n-  if (block_size == NULL) {\n+  if (block_size == nullptr) {\n@@ -7670,2 +7835,2 @@\n-  address stubAddr = NULL;\n-  const char *stubName = NULL;\n+  address stubAddr = nullptr;\n+  const char *stubName = nullptr;\n@@ -7675,1 +7840,1 @@\n-  if (stubAddr == NULL) return false;\n+  if (stubAddr == nullptr) return false;\n@@ -7688,9 +7853,6 @@\n-  const Type* in_type = in->Value(&_gvn);\n-  const Type* ct_type = ct->Value(&_gvn);\n-  const Type* out_type = out->Value(&_gvn);\n-  const TypeAryPtr* top_in = in_type->isa_aryptr();\n-  const TypeAryPtr* top_ct = ct_type->isa_aryptr();\n-  const TypeAryPtr* top_out = out_type->isa_aryptr();\n-  assert(top_in != NULL && top_in->elem() != Type::BOTTOM &&\n-         top_ct != NULL && top_ct->elem() != Type::BOTTOM &&\n-         top_out != NULL && top_out->elem() != Type::BOTTOM, \"args are strange\");\n+  const TypeAryPtr* in_type = in->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* ct_type = ct->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* out_type = out->Value(&_gvn)->isa_aryptr();\n+  assert( in_type != nullptr &&  in_type->elem() != Type::BOTTOM &&\n+          ct_type != nullptr &&  ct_type->elem() != Type::BOTTOM &&\n+         out_type != nullptr && out_type->elem() != Type::BOTTOM, \"args are strange\");\n@@ -7702,2 +7864,2 @@\n-  if (inOfs != NULL || ctOfs != NULL || outOfs != NULL) {\n-    assert(inOfs != NULL && ctOfs != NULL && outOfs != NULL, \"\");\n+  if (inOfs != nullptr || ctOfs != nullptr || outOfs != nullptr) {\n+    assert(inOfs != nullptr && ctOfs != nullptr && outOfs != nullptr, \"\");\n@@ -7718,1 +7880,1 @@\n-  if (embeddedCipherObj == NULL || counter == NULL || subkeyHtbl == NULL || state == NULL) {\n+  if (embeddedCipherObj == nullptr || counter == nullptr || subkeyHtbl == nullptr || state == nullptr) {\n@@ -7723,1 +7885,1 @@\n-  assert(tinst != NULL, \"GCTR obj is null\");\n+  assert(tinst != nullptr, \"GCTR obj is null\");\n@@ -7734,1 +7896,1 @@\n-  if (k_start == NULL) return false;\n+  if (k_start == nullptr) return false;\n@@ -7765,1 +7927,1 @@\n-  \/\/ The receiver was checked for NULL already.\n+  \/\/ The receiver was checked for null already.\n@@ -7769,1 +7931,1 @@\n-  assert(embeddedCipherObj != NULL, \"embeddedCipherObj is null\");\n+  assert(embeddedCipherObj != nullptr, \"embeddedCipherObj is null\");\n@@ -7775,1 +7937,1 @@\n-  assert(tinst != NULL, \"GCTR obj is null\");\n+  assert(tinst != nullptr, \"GCTR obj is null\");\n@@ -7791,1 +7953,1 @@\n-  Node* instof_false = generate_guard(bool_instof, NULL, PROB_MIN);\n+  Node* instof_false = generate_guard(bool_instof, nullptr, PROB_MIN);\n@@ -7793,1 +7955,1 @@\n-  return instof_false; \/\/ even if it is NULL\n+  return instof_false; \/\/ even if it is null\n@@ -7806,2 +7968,2 @@\n-  assert (digest_state != NULL, \"wrong version of sun.security.provider.MD5\/SHA\/SHA2\/SHA5\/SHA3\");\n-  if (digest_state == NULL) return (Node *) NULL;\n+  assert (digest_state != nullptr, \"wrong version of sun.security.provider.MD5\/SHA\/SHA2\/SHA5\/SHA3\");\n+  if (digest_state == nullptr) return (Node *) nullptr;\n@@ -7817,1 +7979,1 @@\n-  assert (block_size != NULL, \"sanity\");\n+  assert (block_size != nullptr, \"sanity\");\n@@ -7831,1 +7993,1 @@\n-  \/\/ The receiver was checked for NULL already.\n+  \/\/ The receiver was checked for null already.\n@@ -7836,1 +7998,1 @@\n-  assert(tinst != NULL, \"digestBaseObj is null\");\n+  assert(tinst != nullptr, \"digestBaseObj is null\");\n@@ -7839,1 +8001,1 @@\n-  const char* klass_name = NULL;\n+  const char* klass_name = nullptr;\n@@ -7875,2 +8037,2 @@\n-  ciKlass* klass = NULL;\n-  if (klass_name != NULL) {\n+  ciKlass* klass = nullptr;\n+  if (klass_name != nullptr) {\n@@ -7879,1 +8041,1 @@\n-  if ((klass == NULL) || !klass->is_loaded()) {\n+  if ((klass == nullptr) || !klass->is_loaded()) {\n@@ -7890,1 +8052,1 @@\n-  Node* instof_false = generate_guard(bool_instof, NULL, PROB_MIN);\n+  Node* instof_false = generate_guard(bool_instof, nullptr, PROB_MIN);\n@@ -7892,1 +8054,1 @@\n-  return instof_false;  \/\/ even if it is NULL\n+  return instof_false;  \/\/ even if it is null\n@@ -7897,4 +8059,4 @@\n-  Node *a = NULL;\n-  Node *b = NULL;\n-  Node *c = NULL;\n-  Node* result = NULL;\n+  Node *a = nullptr;\n+  Node *b = nullptr;\n+  Node *c = nullptr;\n+  Node* result = nullptr;\n@@ -7927,1 +8089,1 @@\n-  Node* n = NULL;\n+  Node* n = nullptr;\n@@ -7960,1 +8122,1 @@\n-  if ( md != NULL && md->is_mature() && md->invocation_count() > 0 ) {\n+  if ( md != nullptr && md->is_mature() && md->invocation_count() > 0 ) {\n@@ -7986,3 +8148,3 @@\n-  Node *a = NULL;\n-  Node *b = NULL;\n-  Node *n = NULL;\n+  Node *a = nullptr;\n+  Node *b = nullptr;\n+  Node *n = nullptr;\n@@ -8037,2 +8199,2 @@\n-  const TypeAryPtr* ary = NULL;\n-  ciArray* aobj = NULL;\n+  const TypeAryPtr* ary = nullptr;\n+  ciArray* aobj = nullptr;\n@@ -8040,2 +8202,2 @@\n-      && (ary = counts->bottom_type()->isa_aryptr()) != NULL\n-      && (aobj = ary->const_oop()->as_array()) != NULL\n+      && (ary = counts->bottom_type()->isa_aryptr()) != nullptr\n+      && (aobj = ary->const_oop()->as_array()) != nullptr\n@@ -8047,1 +8209,1 @@\n-    if (C->log() != NULL) {\n+    if (C->log() != nullptr) {\n@@ -8128,1 +8290,1 @@\n-  int   layout_is_con = (layout_val == NULL);\n+  int   layout_is_con = (layout_val == nullptr);\n@@ -8176,2 +8338,2 @@\n-    Node* array_ctl = generate_array_guard(klass_node, NULL);\n-    if (array_ctl != NULL) {\n+    Node* array_ctl = generate_array_guard(klass_node, nullptr);\n+    if (array_ctl != nullptr) {\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":741,"deletions":579,"binary":false,"changes":1320,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -79,1 +79,1 @@\n-      _result(NULL)\n+      _result(nullptr)\n@@ -89,1 +89,1 @@\n-      ciSignature* declared_signature = NULL;\n+      ciSignature* declared_signature = nullptr;\n@@ -110,1 +110,1 @@\n-    if (!stopped() && res != NULL) {\n+    if (!stopped() && res != nullptr) {\n@@ -130,1 +130,1 @@\n-  void  set_result(Node* n) { assert(_result == NULL, \"only set once\"); _result = n; }\n+  void  set_result(Node* n) { assert(_result == nullptr, \"only set once\"); _result = n; }\n@@ -142,1 +142,1 @@\n-                                Node* *pos_index = NULL);\n+                                Node* *pos_index = nullptr);\n@@ -209,2 +209,2 @@\n-  Node* load_field_from_object(Node* fromObj, const char* fieldName, const char* fieldTypeString, DecoratorSet decorators = IN_HEAP, bool is_static = false, ciInstanceKlass* fromKls = NULL);\n-  Node* field_address_from_object(Node* fromObj, const char* fieldName, const char* fieldTypeString, bool is_exact = true, bool is_static = false, ciInstanceKlass* fromKls = NULL);\n+  Node* load_field_from_object(Node* fromObj, const char* fieldName, const char* fieldTypeString, DecoratorSet decorators = IN_HEAP, bool is_static = false, ciInstanceKlass* fromKls = nullptr);\n+  Node* field_address_from_object(Node* fromObj, const char* fieldName, const char* fieldTypeString, bool is_exact = true, bool is_static = false, ciInstanceKlass* fromKls = nullptr);\n@@ -220,0 +220,1 @@\n+  bool inline_vectorizedHashCode();\n@@ -271,0 +272,5 @@\n+#if INCLUDE_JVMTI\n+  bool inline_native_notify_jvmti_funcs(address funcAddr, const char* funcName, bool is_start, bool is_end);\n+  bool inline_native_notify_jvmti_hide();\n+#endif\n+\n@@ -293,0 +299,5 @@\n+  static CallStaticJavaNode* get_uncommon_trap_from_success_proj(Node* node);\n+  SafePointNode* create_safepoint_with_state_before_array_allocation(const AllocateArrayNode* alloc) const;\n+  void replace_unrelated_uncommon_traps_with_alloc_state(AllocateArrayNode* alloc, JVMState* saved_jvms_before_guards);\n+  void replace_unrelated_uncommon_traps_with_alloc_state(JVMState* saved_jvms_before_guards);\n+  void create_new_uncommon_trap(CallStaticJavaNode* uncommon_trap_call);\n@@ -294,1 +305,1 @@\n-  void arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms, int saved_reexecute_sp,\n+  void arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms_before_guards, int saved_reexecute_sp,\n@@ -362,2 +373,0 @@\n-  bool inline_vector_shuffle_to_vector();\n-  bool inline_vector_shuffle_iota();\n@@ -379,0 +388,1 @@\n+  bool inline_index_partially_in_upper_range();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":21,"deletions":11,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -72,0 +72,1 @@\n+class ConINode;\n@@ -156,0 +157,1 @@\n+class ReductionNode;\n@@ -171,0 +173,1 @@\n+class UnorderedReductionNode;\n@@ -261,1 +264,1 @@\n-  \/\/ E.g.  new (C,3) FooNode( C, NULL, left, right );\n+  \/\/ E.g.  new (C,3) FooNode( C, nullptr, left, right );\n@@ -277,1 +280,1 @@\n-  Node* clone_with_data_edge(Node* in1, Node* in2 = NULL) const {\n+  Node* clone_with_data_edge(Node* in1, Node* in2 = nullptr) const {\n@@ -279,2 +282,2 @@\n-    if (in1 != NULL)  nn->set_req(1, in1);\n-    if (in2 != NULL)  nn->set_req(2, in2);\n+    if (in1 != nullptr)  nn->set_req(1, in1);\n+    if (in2 != nullptr)  nn->set_req(2, in2);\n@@ -299,1 +302,1 @@\n-  \/\/ for semantic correctness; order is important and NULLs are allowed.\n+  \/\/ for semantic correctness; order is important and nulls are allowed.\n@@ -302,1 +305,1 @@\n-  \/\/ duplicated; they have no embedded NULLs.  Edges from 0 to _cnt-1\n+  \/\/ duplicated; they have no embedded nulls.  Edges from 0 to _cnt-1\n@@ -397,2 +400,2 @@\n-  \/\/ Reference to the i'th input Node.  NULL if out of bounds.\n-  Node* lookup(uint i) const { return ((i < _max) ? _in[i] : NULL); }\n+  \/\/ Reference to the i'th input Node.  null if out of bounds.\n+  Node* lookup(uint i) const { return ((i < _max) ? _in[i] : nullptr); }\n@@ -419,1 +422,1 @@\n-#define is_not_dead(n) ((n) == NULL || !VerifyIterativeGVN || !((n)->is_dead()))\n+  static bool is_not_dead(const Node* n);\n@@ -441,1 +444,1 @@\n-    if (*p != NULL)  (*p)->del_out((Node *)this);\n+    if (*p != nullptr)  (*p)->del_out((Node *)this);\n@@ -443,1 +446,1 @@\n-    if (n != NULL)      n->add_out((Node *)this);\n+    if (n != nullptr)      n->add_out((Node *)this);\n@@ -453,1 +456,1 @@\n-    assert( _in[i] == NULL, \"sanity\");\n+    assert( _in[i] == nullptr, \"sanity\");\n@@ -455,1 +458,1 @@\n-    if (n != NULL)      n->add_out((Node *)this);\n+    if (n != nullptr)      n->add_out((Node *)this);\n@@ -463,2 +466,2 @@\n-      if (_in[i] == NULL) {\n-        DEBUG_ONLY( while ((++i) < len()) assert(_in[i] == NULL, \"Gap in prec edges!\"); )\n+      if (_in[i] == nullptr) {\n+        DEBUG_ONLY( while ((++i) < len()) assert(_in[i] == nullptr, \"Gap in prec edges!\"); )\n@@ -470,1 +473,1 @@\n-  int replace_edge(Node* old, Node* neww, PhaseGVN* gvn = NULL);\n+  int replace_edge(Node* old, Node* neww, PhaseGVN* gvn = nullptr);\n@@ -472,1 +475,1 @@\n-  \/\/ NULL out all inputs to eliminate incoming Def-Use edges.\n+  \/\/ null out all inputs to eliminate incoming Def-Use edges.\n@@ -477,2 +480,2 @@\n-    assert((this == (Node*) Compile::current()->top()) == (_out == NULL), \"\");\n-    return (_out == NULL);\n+    assert((this == (Node*) Compile::current()->top()) == (_out == nullptr), \"\");\n+    return (_out == nullptr);\n@@ -526,1 +529,1 @@\n-    Node *last = NULL;\n+    Node *last = nullptr;\n@@ -529,1 +532,1 @@\n-      if (next == NULL) break;\n+      if (next == nullptr) break;\n@@ -532,2 +535,2 @@\n-    _in[gap] = last; \/\/ Move last slot to empty one.\n-    _in[i] = NULL;   \/\/ NULL out last slot.\n+    _in[gap] = last;  \/\/ Move last slot to empty one.\n+    _in[i] = nullptr; \/\/ null out last slot.\n@@ -560,1 +563,1 @@\n-    if (n == NULL || find_prec_edge(n) != -1) {\n+    if (n == nullptr || find_prec_edge(n) != -1) {\n@@ -564,1 +567,1 @@\n-    if (_in[i] != NULL) _in[i]->del_out((Node *)this);\n+    if (_in[i] != nullptr) _in[i]->del_out((Node *)this);\n@@ -585,0 +588,6 @@\n+    \/\/ Flip swapped edges flag.\n+    if (has_swapped_edges()) {\n+      remove_flag(Node::Flag_has_swapped_edges);\n+    } else {\n+      add_flag(Node::Flag_has_swapped_edges);\n+    }\n@@ -589,1 +598,1 @@\n-  \/\/ NOTE: Required edges can contain embedded NULL pointers.\n+  \/\/ NOTE: Required edges can contain embedded null pointers.\n@@ -722,0 +731,2 @@\n+        DEFINE_CLASS_ID(Reduction, Vector, 7)\n+          DEFINE_CLASS_ID(UnorderedReduction, Reduction, 0)\n@@ -724,0 +735,3 @@\n+      DEFINE_CLASS_ID(Con, Type, 9)\n+          DEFINE_CLASS_ID(ConI, Con, 0)\n+\n@@ -777,1 +791,1 @@\n-    _max_classes  = ClassMask_Move\n+    _max_classes  = ClassMask_LShift\n@@ -794,1 +808,1 @@\n-    Flag_is_reduction                = 1 << 11,\n+    Flag_has_swapped_edges           = 1 << 11,\n@@ -847,1 +861,1 @@\n-    assert(is_##type(), \"invalid node class: %s\", Name()); \\\n+    assert(is_##type(), \"invalid node class: %s\", Name());   \\\n@@ -851,1 +865,1 @@\n-    return (is_##type()) ? as_##type() : NULL;               \\\n+    return (is_##type()) ? as_##type() : nullptr;            \\\n@@ -877,0 +891,1 @@\n+  DEFINE_CLASS_QUERY(ConI)\n@@ -940,0 +955,1 @@\n+  DEFINE_CLASS_QUERY(NeverBranch)\n@@ -947,0 +963,1 @@\n+  DEFINE_CLASS_QUERY(Reduction)\n@@ -958,0 +975,1 @@\n+  DEFINE_CLASS_QUERY(UnorderedReduction)\n@@ -1014,5 +1032,3 @@\n-  bool is_expensive() const { return (_flags & Flag_is_expensive) != 0 && in(0) != NULL; }\n-\n-  \/\/ An arithmetic node which accumulates a data in a loop.\n-  \/\/ It must have the loop's phi as input and provide a def to the phi.\n-  bool is_reduction() const { return (_flags & Flag_is_reduction) != 0; }\n+  bool is_expensive() const { return (_flags & Flag_is_expensive) != 0 && in(0) != nullptr; }\n+  \/\/ The node's original edge position is swapped.\n+  bool has_swapped_edges() const { return (_flags & Flag_has_swapped_edges) != 0; }\n@@ -1040,1 +1056,1 @@\n-  \/\/ or NULL if none.  The address type is conservatively wide.\n+  \/\/ or null if none.  The address type is conservatively wide.\n@@ -1043,1 +1059,1 @@\n-  virtual const class TypePtr *adr_type() const { return NULL; }\n+  virtual const class TypePtr *adr_type() const { return nullptr; }\n@@ -1056,1 +1072,1 @@\n-  \/\/ +VerifyIterativeGVN!\n+  \/\/ -XX:VerifyIterativeGVN=1\n@@ -1101,1 +1117,1 @@\n-  \/\/ be found; Otherwise return NULL;\n+  \/\/ be found; Otherwise return null;\n@@ -1131,1 +1147,1 @@\n-  \/\/ Return JVM State Object if this Node carries debug info, or NULL otherwise\n+  \/\/ Return JVM State Object if this Node carries debug info, or null otherwise\n@@ -1147,1 +1163,1 @@\n-    return (t != NULL && t->is_con()) ? t->get_con() : value_if_unknown;\n+    return (t != nullptr && t->is_con()) ? t->get_con() : value_if_unknown;\n@@ -1152,1 +1168,1 @@\n-    guarantee(t != NULL, \"must be con\");\n+    guarantee(t != nullptr, \"must be con\");\n@@ -1162,1 +1178,1 @@\n-    guarantee(t != NULL, \"must be con\");\n+    guarantee(t != nullptr, \"must be con\");\n@@ -1167,1 +1183,1 @@\n-    return (t != NULL && t->is_con()) ? t->get_con() : value_if_unknown;\n+    return (t != nullptr && t->is_con()) ? t->get_con() : value_if_unknown;\n@@ -1173,1 +1189,1 @@\n-    guarantee(t != NULL && t->is_con(), \"must be con\");\n+    guarantee(t != nullptr && t->is_con(), \"must be con\");\n@@ -1178,1 +1194,1 @@\n-    if (t == NULL || !t->is_con())  return value_if_unknown;\n+    if (t == nullptr || !t->is_con())  return value_if_unknown;\n@@ -1254,3 +1270,3 @@\n-  int  _debug_idx;                     \/\/ Unique value assigned to every node.\n-  int   debug_idx() const              { return _debug_idx; }\n-  void  set_debug_idx( int debug_idx ) { _debug_idx = debug_idx; }\n+  uint64_t _debug_idx;                 \/\/ Unique value assigned to every node.\n+  uint64_t debug_idx() const           { return _debug_idx; }\n+  void set_debug_idx(uint64_t debug_idx) { _debug_idx = debug_idx; }\n@@ -1272,1 +1288,1 @@\n-  if (n == NULL)                   return true;\n+  if (n == nullptr)                return true;\n@@ -1532,1 +1548,1 @@\n-\/\/ Abstractly provides an infinite array of Node*'s, initialized to NULL.\n+\/\/ Abstractly provides an infinite array of Node*'s, initialized to null.\n@@ -1549,2 +1565,2 @@\n-  Node *operator[] ( uint i ) const \/\/ Lookup, or NULL for not mapped\n-  { return (i<_max) ? _nodes[i] : (Node*)NULL; }\n+  Node *operator[] ( uint i ) const \/\/ Lookup, or null for not mapped\n+  { return (i<_max) ? _nodes[i] : (Node*)nullptr; }\n@@ -1557,1 +1573,1 @@\n-  \/\/ Clear all entries in _nodes to NULL but keep storage\n+  \/\/ Clear all entries in _nodes to null but keep storage\n@@ -1562,1 +1578,1 @@\n-  uint Size() const { return _max; }\n+  uint max() const { return _max; }\n@@ -1660,1 +1676,1 @@\n-      return; \/\/ Gracefully handle NULL, -1, 0xabababab, etc.\n+      return; \/\/ Gracefully handle null, -1, 0xabababab, etc.\n@@ -1686,0 +1702,5 @@\n+\/\/ Inline definition of Compile::remove_for_igvn must be deferred to this point.\n+inline void Compile::remove_for_igvn(Node* n) {\n+  _for_igvn->remove(n);\n+}\n+\n@@ -1765,1 +1786,1 @@\n-  Node_Notes(JVMState* jvms = NULL) {\n+  Node_Notes(JVMState* jvms = nullptr) {\n@@ -1774,1 +1795,1 @@\n-    return (_jvms == NULL);\n+    return (_jvms == nullptr);\n@@ -1779,1 +1800,1 @@\n-    _jvms = NULL;\n+    _jvms = nullptr;\n@@ -1798,2 +1819,2 @@\n-    if (source != NULL) {\n-      if (source->jvms() != NULL) {\n+    if (source != nullptr) {\n+      if (source->jvms() != nullptr) {\n@@ -1814,1 +1835,1 @@\n-  int grow_by = (block_idx - (arr == NULL? 0: arr->length()));\n+  int grow_by = (block_idx - (arr == nullptr? 0: arr->length()));\n@@ -1816,1 +1837,1 @@\n-    if (!can_grow) return NULL;\n+    if (!can_grow) return nullptr;\n@@ -1819,1 +1840,1 @@\n-  if (arr == NULL) return NULL;\n+  if (arr == nullptr) return nullptr;\n@@ -1826,1 +1847,1 @@\n-  if (value == NULL || value->is_clear())\n+  if (value == nullptr || value->is_clear())\n@@ -1829,1 +1850,1 @@\n-  assert(loc != NULL, \"\");\n+  assert(loc != nullptr, \"\");\n@@ -1844,1 +1865,1 @@\n-    assert(t != NULL, \"sanity\");\n+    assert(t != nullptr, \"sanity\");\n@@ -1850,1 +1871,1 @@\n-  const Type* type() const { assert(_type != NULL, \"sanity\"); return _type; };\n+  const Type* type() const { assert(_type != nullptr, \"sanity\"); return _type; };\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":90,"deletions":69,"binary":false,"changes":159,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -222,106 +222,0 @@\n-volatile int C2SafepointPollStubTable::_stub_size = 0;\n-\n-Label& C2SafepointPollStubTable::add_safepoint(uintptr_t safepoint_offset) {\n-  C2SafepointPollStub* entry = new (Compile::current()->comp_arena()) C2SafepointPollStub(safepoint_offset);\n-  _safepoints.append(entry);\n-  return entry->_stub_label;\n-}\n-\n-void C2SafepointPollStubTable::emit(CodeBuffer& cb) {\n-  MacroAssembler masm(&cb);\n-  for (int i = _safepoints.length() - 1; i >= 0; i--) {\n-    \/\/ Make sure there is enough space in the code buffer\n-    if (cb.insts()->maybe_expand_to_ensure_remaining(PhaseOutput::MAX_inst_size) && cb.blob() == NULL) {\n-      ciEnv::current()->record_failure(\"CodeCache is full\");\n-      return;\n-    }\n-\n-    C2SafepointPollStub* entry = _safepoints.at(i);\n-    emit_stub(masm, entry);\n-  }\n-}\n-\n-int C2SafepointPollStubTable::stub_size_lazy() const {\n-  int size = Atomic::load(&_stub_size);\n-\n-  if (size != 0) {\n-    return size;\n-  }\n-\n-  Compile* const C = Compile::current();\n-  BufferBlob* const blob = C->output()->scratch_buffer_blob();\n-  CodeBuffer cb(blob->content_begin(), C->output()->scratch_buffer_code_size());\n-  MacroAssembler masm(&cb);\n-  C2SafepointPollStub* entry = _safepoints.at(0);\n-  emit_stub(masm, entry);\n-  size += cb.insts_size();\n-\n-  Atomic::store(&_stub_size, size);\n-\n-  return size;\n-}\n-\n-int C2SafepointPollStubTable::estimate_stub_size() const {\n-  if (_safepoints.length() == 0) {\n-    return 0;\n-  }\n-\n-  int result = stub_size_lazy() * _safepoints.length();\n-\n-#ifdef ASSERT\n-  Compile* const C = Compile::current();\n-  BufferBlob* const blob = C->output()->scratch_buffer_blob();\n-  int size = 0;\n-\n-  for (int i = _safepoints.length() - 1; i >= 0; i--) {\n-    CodeBuffer cb(blob->content_begin(), C->output()->scratch_buffer_code_size());\n-    MacroAssembler masm(&cb);\n-    C2SafepointPollStub* entry = _safepoints.at(i);\n-    emit_stub(masm, entry);\n-    size += cb.insts_size();\n-  }\n-  assert(size == result, \"stubs should not have variable size\");\n-#endif\n-\n-  return result;\n-}\n-\n-\/\/ Nmethod entry barrier stubs\n-C2EntryBarrierStub* C2EntryBarrierStubTable::add_entry_barrier() {\n-  C2EntryBarrierStub* stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n-  _stubs.append(stub);\n-  return stub;\n-}\n-\n-void C2EntryBarrierStubTable::emit(CodeBuffer& cb) {\n-  if (_stubs.is_empty()) {\n-    \/\/ No stub - nothing to do\n-    return;\n-  }\n-\n-  C2_MacroAssembler masm(&cb);\n-  for (C2EntryBarrierStub* stub : _stubs) {\n-    \/\/ Make sure there is enough space in the code buffer\n-    if (cb.insts()->maybe_expand_to_ensure_remaining(PhaseOutput::MAX_inst_size) && cb.blob() == NULL) {\n-      ciEnv::current()->record_failure(\"CodeCache is full\");\n-      return;\n-    }\n-\n-    intptr_t before = masm.offset();\n-    masm.emit_entry_barrier_stub(stub);\n-    intptr_t after = masm.offset();\n-    int actual_size = (int)(after - before);\n-    int expected_size = masm.entry_barrier_stub_size();\n-    assert(actual_size == expected_size, \"Estimated size is wrong, expected %d, was %d\", expected_size, actual_size);\n-  }\n-}\n-\n-int C2EntryBarrierStubTable::estimate_stub_size() const {\n-  if (BarrierSet::barrier_set()->barrier_set_nmethod() == NULL) {\n-    \/\/ No nmethod entry barrier?\n-    return 0;\n-  }\n-\n-  return C2_MacroAssembler::entry_barrier_stub_size();\n-}\n-\n@@ -334,5 +228,4 @@\n-    _safepoint_poll_table(),\n-    _entry_barrier_table(),\n-    _oop_map_set(NULL),\n-    _scratch_buffer_blob(NULL),\n-    _scratch_locs_memory(NULL),\n+    _stub_list(),\n+    _oop_map_set(nullptr),\n+    _scratch_buffer_blob(nullptr),\n+    _scratch_locs_memory(nullptr),\n@@ -344,1 +237,1 @@\n-    _node_bundling_base(NULL),\n+    _node_bundling_base(nullptr),\n@@ -348,1 +241,1 @@\n-    _block(NULL),\n+    _block(nullptr),\n@@ -351,1 +244,1 @@\n-  if (C->stub_name() == NULL) {\n+  if (C->stub_name() == nullptr) {\n@@ -365,2 +258,2 @@\n-  C->set_output(NULL);\n-  if (_scratch_buffer_blob != NULL) {\n+  C->set_output(nullptr);\n+  if (_scratch_buffer_blob != nullptr) {\n@@ -502,1 +395,1 @@\n-  if (cb == NULL || C->failing()) {\n+  if (cb == nullptr || C->failing()) {\n@@ -523,2 +416,2 @@\n-  return (C->stub_function() == NULL &&\n-          (C->has_java_calls() || frame_size_in_bytes > os::vm_page_size()>>3\n+  return (C->stub_function() == nullptr &&\n+          (C->has_java_calls() || frame_size_in_bytes > (int)(os::vm_page_size())>>3\n@@ -533,1 +426,1 @@\n-  return (C->stub_function() == NULL && C->has_java_calls());\n+  return (C->stub_function() == nullptr && C->has_java_calls());\n@@ -653,1 +546,1 @@\n-          if (mcall->entry_point() != NULL) {\n+          if (mcall->entry_point() != nullptr) {\n@@ -741,2 +634,2 @@\n-      MachNode* mach = (idx == -1) ? NULL: block->get_node(idx)->as_Mach();\n-      if (mach != NULL && mach->may_be_short_branch()) {\n+      MachNode* mach = (idx == -1) ? nullptr: block->get_node(idx)->as_Mach();\n+      if (mach != nullptr && mach->may_be_short_branch()) {\n@@ -806,1 +699,1 @@\n-      if (mach != NULL && (mach->may_be_short_branch() ||\n+      if (mach != nullptr && (mach->may_be_short_branch() ||\n@@ -872,1 +765,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -877,1 +770,1 @@\n-  assert(sv_for_node_id(objs, sv->id()) == NULL, \"Precondition\");\n+  assert(sv_for_node_id(objs, sv->id()) == nullptr, \"Precondition\");\n@@ -906,1 +799,1 @@\n-    if (sv == NULL) {\n+    if (sv == nullptr) {\n@@ -913,2 +806,2 @@\n-      ScopeValue* is_init = NULL;\n-      ScopeValue* is_larval = NULL;\n+      ScopeValue* is_init = nullptr;\n+      ScopeValue* is_larval = nullptr;\n@@ -917,1 +810,1 @@\n-        assert(init_node != NULL, \"is_init node not found\");\n+        assert(init_node != nullptr, \"is_init node not found\");\n@@ -929,1 +822,1 @@\n-        assert(larval_node != NULL && larval_node->is_Con(), \"is_larval node not found\");\n+        assert(larval_node != nullptr && larval_node->is_Con(), \"is_larval node not found\");\n@@ -1024,1 +917,1 @@\n-      array->append(new ConstantOopWriteValue(NULL));\n+      array->append(new ConstantOopWriteValue(nullptr));\n@@ -1032,1 +925,1 @@\n-        array->append(new ConstantOopWriteValue(NULL));\n+        array->append(new ConstantOopWriteValue(nullptr));\n@@ -1125,1 +1018,1 @@\n-    mcall = NULL;\n+    mcall = nullptr;\n@@ -1151,1 +1044,1 @@\n-  \/\/ Do not skip safepoints with a NULL method, they need monitor info\n+  \/\/ Do not skip safepoints with a null method, they need monitor info\n@@ -1164,1 +1057,1 @@\n-    ciMethod* method = jvms->has_method() ? jvms->method() : NULL;\n+    ciMethod* method = jvms->has_method() ? jvms->method() : nullptr;\n@@ -1167,2 +1060,2 @@\n-    int num_locs = (method == NULL) ? 0 : jvms->loc_size();\n-    int num_exps = (method == NULL) ? 0 : jvms->stk_size();\n+    int num_locs = (method == nullptr) ? 0 : jvms->loc_size();\n+    int num_exps = (method == nullptr) ? 0 : jvms->stk_size();\n@@ -1170,1 +1063,1 @@\n-    assert(method == NULL || jvms->bci() < 0 || num_locs == method->max_locals(),\n+    assert(method == nullptr || jvms->bci() < 0 || num_locs == method->max_locals(),\n@@ -1205,1 +1098,1 @@\n-      ScopeValue *scval = NULL;\n+      ScopeValue *scval = nullptr;\n@@ -1210,1 +1103,1 @@\n-        if (scval == NULL) {\n+        if (scval == nullptr) {\n@@ -1295,1 +1188,1 @@\n-      _pending_jvms = NULL;\n+      _pending_jvms = nullptr;\n@@ -1303,2 +1196,2 @@\n-      if (nn == NULL || nn->jvms() == NULL)  return;\n-      if (_pending_jvms != NULL &&\n+      if (nn == nullptr || nn->jvms() == nullptr)  return;\n+      if (_pending_jvms != nullptr &&\n@@ -1309,1 +1202,1 @@\n-        if (_pending_jvms != NULL &&\n+        if (_pending_jvms != nullptr &&\n@@ -1313,1 +1206,1 @@\n-        _pending_jvms = NULL;\n+        _pending_jvms = nullptr;\n@@ -1315,1 +1208,1 @@\n-          \/\/ This is the only way _pending_jvms can become non-NULL:\n+          \/\/ This is the only way _pending_jvms can become non-null:\n@@ -1324,1 +1217,1 @@\n-      if (_pending_jvms != NULL &&\n+      if (_pending_jvms != nullptr &&\n@@ -1329,1 +1222,1 @@\n-      _pending_jvms = NULL;\n+      _pending_jvms = nullptr;\n@@ -1333,1 +1226,1 @@\n-      if (_pending_jvms != NULL) {\n+      if (_pending_jvms != nullptr) {\n@@ -1336,1 +1229,1 @@\n-      _pending_jvms = NULL;\n+      _pending_jvms = nullptr;\n@@ -1345,1 +1238,1 @@\n-  _pending_jvms = NULL;\n+  _pending_jvms = nullptr;\n@@ -1356,1 +1249,1 @@\n-    ciMethod* method = jvms->has_method() ? jvms->method() : NULL;\n+    ciMethod* method = jvms->has_method() ? jvms->method() : nullptr;\n@@ -1428,2 +1321,0 @@\n-  stub_req += safepoint_poll_table()->estimate_stub_size();\n-  stub_req += entry_barrier_table()->estimate_stub_size();\n@@ -1456,1 +1347,1 @@\n-  if ((cb->blob() == NULL) || (!CompileBroker::should_compile_new_jobs())) {\n+  if ((cb->blob() == nullptr) || (!CompileBroker::should_compile_new_jobs())) {\n@@ -1458,1 +1349,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1513,1 +1404,1 @@\n-  int* node_offsets      = NULL;\n+  int* node_offsets      = nullptr;\n@@ -1519,1 +1410,1 @@\n-  if (node_offsets != NULL) {\n+  if (node_offsets != nullptr) {\n@@ -1542,1 +1433,1 @@\n-  Node* delay_slot = NULL;\n+  Node* delay_slot = nullptr;\n@@ -1583,1 +1474,1 @@\n-        assert(delay_slot == NULL, \"no use of delay slot node\");\n+        assert(delay_slot == nullptr, \"no use of delay slot node\");\n@@ -1633,1 +1524,1 @@\n-          if ((cb->blob() == NULL) || (!CompileBroker::should_compile_new_jobs())) {\n+          if ((cb->blob() == nullptr) || (!CompileBroker::should_compile_new_jobs())) {\n@@ -1647,1 +1538,1 @@\n-          if (mcall->entry_point() != NULL) {\n+          if (mcall->entry_point() != nullptr) {\n@@ -1664,1 +1555,1 @@\n-            if (sfn->jvms()->method() == NULL) {\n+            if (sfn->jvms()->method() == nullptr) {\n@@ -1691,1 +1582,1 @@\n-            assert(delay_slot == NULL, \"not expecting delay slot node\");\n+            assert(delay_slot == nullptr, \"not expecting delay slot node\");\n@@ -1756,1 +1647,1 @@\n-            if (oop_store == NULL) continue;\n+            if (oop_store == nullptr) continue;\n@@ -1787,1 +1678,1 @@\n-      if ((cb->blob() == NULL) || (!CompileBroker::should_compile_new_jobs())) {\n+      if ((cb->blob() == nullptr) || (!CompileBroker::should_compile_new_jobs())) {\n@@ -1794,1 +1685,1 @@\n-      if ((node_offsets != NULL) && (n->_idx < node_offset_limit)) {\n+      if ((node_offsets != nullptr) && (n->_idx < node_offset_limit)) {\n@@ -1849,1 +1740,1 @@\n-        guarantee(delay_slot != NULL, \"expecting delay slot node\");\n+        guarantee(delay_slot != nullptr, \"expecting delay slot node\");\n@@ -1856,1 +1747,1 @@\n-        if ((node_offsets != NULL) && (delay_slot->_idx < node_offset_limit)) {\n+        if ((node_offsets != nullptr) && (delay_slot->_idx < node_offset_limit)) {\n@@ -1865,1 +1756,1 @@\n-          if (!mach->is_MachCall() && mach->as_MachSafePoint()->jvms()->method() == NULL) {\n+          if (!mach->is_MachCall() && mach->as_MachSafePoint()->jvms()->method() == nullptr) {\n@@ -1867,1 +1758,1 @@\n-            delay_slot = NULL;\n+            delay_slot = nullptr;\n@@ -1882,1 +1773,1 @@\n-        delay_slot = NULL;\n+        delay_slot = nullptr;\n@@ -1933,0 +1824,5 @@\n+  if (!cb->finalize_stubs()) {\n+    C->record_failure(\"CodeCache is full\");\n+    return;\n+  }\n+\n@@ -1937,6 +1833,2 @@\n-  \/\/ Fill in stubs for calling the runtime from safepoint polls.\n-  safepoint_poll_table()->emit(*cb);\n-  if (C->failing())  return;\n-\n-  \/\/ Fill in stubs for calling the runtime from nmethod entries.\n-  entry_barrier_table()->emit(*cb);\n+  \/\/ Fill in stubs.\n+  _stub_list.emit(*cb);\n@@ -1974,1 +1866,1 @@\n-  if ((cb->blob() == NULL) || (!CompileBroker::should_compile_new_jobs())) {\n+  if ((cb->blob() == nullptr) || (!CompileBroker::should_compile_new_jobs())) {\n@@ -1996,1 +1888,1 @@\n-      if (C->method() != NULL) {\n+      if (C->method() != nullptr) {\n@@ -2007,1 +1899,1 @@\n-      if (xtty != NULL) {\n+      if (xtty != nullptr) {\n@@ -2011,1 +1903,1 @@\n-      if (C->method() != NULL) {\n+      if (C->method() != nullptr) {\n@@ -2014,1 +1906,1 @@\n-      } else if (C->stub_name() != NULL) {\n+      } else if (C->stub_name() != nullptr) {\n@@ -2021,1 +1913,1 @@\n-      if (xtty != NULL) {\n+      if (xtty != nullptr) {\n@@ -2035,1 +1927,1 @@\n-    Node *n = NULL;\n+    Node *n = nullptr;\n@@ -2096,1 +1988,1 @@\n-      _handler_table.add_subtable(call_return, &handler_bcis, NULL, &handler_pcos);\n+      _handler_table.add_subtable(call_return, &handler_bcis, nullptr, &handler_pcos);\n@@ -2134,1 +2026,1 @@\n-          _next_node(NULL),\n+          _next_node(nullptr),\n@@ -2346,1 +2238,1 @@\n-      tty->print(\"#   ChooseNodeToBundle: NULL\\n\");\n+      tty->print(\"#   ChooseNodeToBundle: null\\n\");\n@@ -2348,1 +2240,1 @@\n-    return (NULL);\n+    return (nullptr);\n@@ -2697,1 +2589,1 @@\n-  _unconditional_delay_slot = NULL;\n+  _unconditional_delay_slot = nullptr;\n@@ -2759,1 +2651,1 @@\n-  Block *succ_bb = NULL;\n+  Block *succ_bb = nullptr;\n@@ -2858,1 +2750,1 @@\n-      guarantee(n != NULL, \"no nodes available\");\n+      guarantee(n != nullptr, \"no nodes available\");\n@@ -2933,1 +2825,1 @@\n-    _reg_node.map(def,NULL); \/\/ Kill live USEs\n+    _reg_node.map(def,nullptr); \/\/ Kill live USEs\n@@ -3010,1 +2902,1 @@\n-  if ((pinch == NULL) || _cfg->get_block_for_node(pinch) != b || \/\/ No pinch-point yet?\n+  if ((pinch == nullptr) || _cfg->get_block_for_node(pinch) != b || \/\/ No pinch-point yet?\n@@ -3020,1 +2912,1 @@\n-  Node *later_def = NULL;\n+  Node *later_def = nullptr;\n@@ -3035,0 +2927,2 @@\n+      DEBUG_ONLY( pinch->dump(); );\n+      assert(false, \"too many D-U pinch points: %d >= %d\", pinch->_idx, _regalloc->node_regs_max_index());\n@@ -3042,1 +2936,1 @@\n-      pinch->init_req(0, C->top());     \/\/ set not NULL for the next call\n+      pinch->init_req(0, C->top());     \/\/ set not null for the next call\n@@ -3044,1 +2938,1 @@\n-      later_def = NULL;           \/\/ and no later def\n+      later_def = nullptr;           \/\/ and no later def\n@@ -3063,1 +2957,1 @@\n-        pinch->set_req(0,NULL);  \/\/\n+        pinch->set_req(0,nullptr);  \/\/\n@@ -3081,1 +2975,1 @@\n-  if ((pinch != NULL) && _cfg->get_block_for_node(pinch) == b &&\n+  if ((pinch != nullptr) && _cfg->get_block_for_node(pinch) == b &&\n@@ -3133,1 +3027,1 @@\n-  \/\/ compilation.  _reg_node is lazily initialized; it either contains a NULL,\n+  \/\/ compilation.  _reg_node is lazily initialized; it either contains a null,\n@@ -3135,1 +3029,1 @@\n-  \/\/ block.  Leftover node from some prior block is treated like a NULL (no\n+  \/\/ block.  Leftover node from some prior block is treated like a null (no\n@@ -3140,1 +3034,1 @@\n-  Node* end_node         = (_bb_end-1 >= _bb_start) ? b->get_node(last_safept) : NULL;\n+  Node* end_node         = (_bb_end-1 >= _bb_start) ? b->get_node(last_safept) : nullptr;\n@@ -3212,1 +3106,1 @@\n-        if (def != NULL && def->bottom_type()->base() == Type::RawPtr) {\n+        if (def != nullptr && def->bottom_type()->base() == Type::RawPtr) {\n@@ -3269,1 +3163,1 @@\n-  for (uint k = 0; k < _reg_node.Size(); k++) {\n+  for (uint k = 0; k < _reg_node.max(); k++) {\n@@ -3271,1 +3165,1 @@\n-    if ((pinch != NULL) && pinch->Opcode() == Op_Node &&\n+    if ((pinch != nullptr) && pinch->Opcode() == Op_Node &&\n@@ -3273,1 +3167,1 @@\n-        (pinch->req() == pinch->len() || pinch->in(pinch->req()) == NULL) ) {\n+        (pinch->req() == pinch->len() || pinch->in(pinch->req()) == nullptr) ) {\n@@ -3276,1 +3170,1 @@\n-      _reg_node.map(k, NULL);\n+      _reg_node.map(k, nullptr);\n@@ -3311,1 +3205,1 @@\n-  pinch->set_req(0, NULL);\n+  pinch->set_req(0, nullptr);\n@@ -3364,1 +3258,1 @@\n-  if ((blob != NULL) && (const_size <= _scratch_const_size)) {\n+  if ((blob != nullptr) && (const_size <= _scratch_const_size)) {\n@@ -3367,1 +3261,1 @@\n-    if (blob != NULL) {\n+    if (blob != nullptr) {\n@@ -3397,1 +3291,1 @@\n-    if (scratch_buffer_blob() == NULL) {\n+    if (scratch_buffer_blob() == nullptr) {\n@@ -3427,1 +3321,1 @@\n-  assert(blob != NULL, \"Initialize BufferBlob at start\");\n+  assert(blob != nullptr, \"Initialize BufferBlob at start\");\n@@ -3436,1 +3330,1 @@\n-  assert(locs_buf != NULL, \"sanity\");\n+  assert(locs_buf != nullptr, \"sanity\");\n@@ -3449,1 +3343,1 @@\n-  Label*   saveL = NULL;\n+  Label*   saveL = nullptr;\n@@ -3477,1 +3371,1 @@\n-  } else if (C->stub_function() != NULL) {\n+  } else if (C->stub_function() != nullptr) {\n@@ -3538,1 +3432,1 @@\n-    if (C->log() != NULL) { \/\/ Print code cache state into compiler log\n+    if (C->log() != nullptr) { \/\/ Print code cache state into compiler log\n@@ -3545,1 +3439,1 @@\n-  if (code_buffer() == NULL) {\n+  if (code_buffer() == nullptr) {\n@@ -3563,1 +3457,1 @@\n-      assert(rs != NULL && rs->is_runtime_stub(), \"sanity check\");\n+      assert(rs != nullptr && rs->is_runtime_stub(), \"sanity check\");\n@@ -3606,1 +3500,1 @@\n-  if (pcs != NULL) {\n+  if (pcs != nullptr) {\n@@ -3625,1 +3519,1 @@\n-  Node *n = NULL;\n+  Node *n = nullptr;\n@@ -3636,1 +3530,1 @@\n-    if ((pcs != NULL) && (n->_idx < pc_limit)) {\n+    if ((pcs != nullptr) && (n->_idx < pc_limit)) {\n@@ -3651,1 +3545,1 @@\n-    Node *delay = NULL;\n+    Node *delay = nullptr;\n@@ -3683,1 +3577,1 @@\n-        if ((pcs != NULL) && (n->_idx < pc_limit)) {\n+        if ((pcs != nullptr) && (n->_idx < pc_limit)) {\n@@ -3700,1 +3594,1 @@\n-        guarantee(delay != NULL, \"no unconditional delay instruction\");\n+        guarantee(delay != nullptr, \"no unconditional delay instruction\");\n@@ -3705,1 +3599,1 @@\n-        if ((pcs != NULL) && (n->_idx < pc_limit)) {\n+        if ((pcs != nullptr) && (n->_idx < pc_limit)) {\n@@ -3716,1 +3610,1 @@\n-        delay = NULL;\n+        delay = nullptr;\n@@ -3727,1 +3621,1 @@\n-    assert(cut_short || delay == NULL, \"no unconditional delay branch\");\n+    assert(cut_short || delay == nullptr, \"no unconditional delay branch\");\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":123,"deletions":229,"binary":false,"changes":352,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -83,1 +83,1 @@\n-    tty->print_cr(\"%d original NULL checks - %d elided (%2d%%); optimizer leaves %d,\",\n+    tty->print_cr(\"%d original null checks - %d elided (%2d%%); optimizer leaves %d,\",\n@@ -113,1 +113,1 @@\n-    \/\/ Ptr types are mixed together with T_ADDRESS but NULL is\n+    \/\/ Ptr types are mixed together with T_ADDRESS but nullptr is\n@@ -123,1 +123,1 @@\n-  Node *l = NULL;\n+  Node *l = nullptr;\n@@ -163,1 +163,1 @@\n-      (tp != NULL && !tp->is_loaded())) {\n+      (tp != nullptr && !tp->is_loaded())) {\n@@ -179,1 +179,1 @@\n-  if (tp != NULL && !tp->is_same_java_type_as(TypeInstPtr::BOTTOM)) {\n+  if (tp != nullptr && !tp->is_same_java_type_as(TypeInstPtr::BOTTOM)) {\n@@ -181,1 +181,1 @@\n-    Node* bad_type_ctrl = NULL;\n+    Node* bad_type_ctrl = nullptr;\n@@ -229,0 +229,1 @@\n+    assert(false, \"OSR starts with an immediate trap\");\n@@ -267,0 +268,1 @@\n+    assert(false, \"OSR in empty or breakpointed method\");\n@@ -284,1 +286,1 @@\n-    if (type->isa_oopptr() != NULL) {\n+    if (type->isa_oopptr() != nullptr) {\n@@ -293,1 +295,1 @@\n-        if (C->log() != NULL) {\n+        if (C->log() != nullptr) {\n@@ -344,1 +346,1 @@\n-    if (type->isa_oopptr() != NULL) {\n+    if (type->isa_oopptr() != nullptr) {\n@@ -406,1 +408,1 @@\n-  _alloc_with_final = NULL;\n+  _alloc_with_final = nullptr;\n@@ -408,2 +410,2 @@\n-  _tf = NULL;\n-  _block = NULL;\n+  _tf = nullptr;\n+  _block = nullptr;\n@@ -437,0 +439,1 @@\n+    assert(false, \"type flow failed during parsing\");\n@@ -459,1 +462,1 @@\n-  if (log != NULL) {\n+  if (log != nullptr) {\n@@ -485,1 +488,1 @@\n-      if (log != NULL)\n+      if (log != nullptr)\n@@ -494,1 +497,1 @@\n-  if (log != NULL && method()->has_exception_handlers()) {\n+  if (log != nullptr && method()->has_exception_handlers()) {\n@@ -498,1 +501,1 @@\n-  assert(InlineTree::check_can_parse(method()) == NULL, \"Can not parse this method, cutout earlier\");\n+  assert(InlineTree::check_can_parse(method()) == nullptr, \"Can not parse this method, cutout earlier\");\n@@ -515,0 +518,3 @@\n+      \/\/ TODO Adding a trap due to an unloaded return type in ciTypeFlow::StateVector::do_invoke\n+      \/\/ can lead to this. Re-enable once 8284443 is fixed.\n+      \/\/ assert(false, \"type flow analysis failed for OSR compilation\");\n@@ -552,1 +558,0 @@\n-  gvn().set_type(root(), root()->bottom_type());\n@@ -565,1 +570,1 @@\n-  if (failing() || entry_map == NULL) {\n+  if (failing() || entry_map == nullptr) {\n@@ -612,2 +617,2 @@\n-    } else if (UseTypeSpeculation && (i == (arg_size - 1)) && !is_osr_parse() &&\n-               method()->has_vararg() && t->isa_aryptr() != NULL && !t->is_aryptr()->is_not_null_free()) {\n+    } else if (UseTypeSpeculation && (i == (arg_size - 1)) && !is_osr_parse() && method()->has_vararg() &&\n+               t->isa_aryptr() != nullptr && !t->is_aryptr()->is_null_free() && !t->is_aryptr()->is_not_null_free()) {\n@@ -616,1 +621,1 @@\n-      spec_type = (spec_type != NULL && spec_type->isa_aryptr() != NULL) ? spec_type : t->is_aryptr();\n+      spec_type = (spec_type != nullptr && spec_type->isa_aryptr() != nullptr) ? spec_type : t->is_aryptr();\n@@ -642,2 +647,0 @@\n-  C->set_default_node_notes(caller_nn);\n-\n@@ -654,0 +657,4 @@\n+  \/\/ Only reset this now, to make sure that debug information emitted\n+  \/\/ for exiting control flow still refers to the inlined method.\n+  C->set_default_node_notes(caller_nn);\n+\n@@ -699,1 +706,1 @@\n-            add_empty_predicates();\n+            add_parse_predicates();\n@@ -708,0 +715,1 @@\n+          block->copy_irreducible_status_to(r, jvms());\n@@ -825,5 +833,0 @@\n-    \/\/ Scalarize inline type when returning as fields or inlining non-incrementally\n-    if ((tf()->returns_inline_type_as_fields() || (_caller->has_method() && !Compile::current()->inlining_incrementally())) &&\n-        ret_type->is_inlinetypeptr()) {\n-      ret_type = TypeInlineType::make(ret_type->inline_klass());\n-    }\n@@ -843,1 +846,1 @@\n-\/\/ unknown caller.  The method & bci will be NULL & InvocationEntryBci.\n+\/\/ unknown caller.  The method & bci will be null & InvocationEntryBci.\n@@ -853,1 +856,1 @@\n-  if (old_nn != NULL && has_method()) {\n+  if (old_nn != nullptr && has_method()) {\n@@ -866,1 +869,1 @@\n-    Node* parm = NULL;\n+    Node* parm = nullptr;\n@@ -898,1 +901,1 @@\n-  if (caller_nn == NULL)  return NULL;\n+  if (caller_nn == nullptr)  return nullptr;\n@@ -926,1 +929,1 @@\n-      assert(vt->is_buffered(), \"\");\n+      assert(vt->get_is_buffered() && vt->get_is_buffered()->get_int() == 1, \"\");\n@@ -932,2 +935,2 @@\n-      ret->add_req_batch(NULL, tf()->range_cc()->cnt() - TypeFunc::Parms);\n-      if (vt->is_allocated(&kit.gvn()) && !StressInlineTypeReturnedAsFields) {\n+      ret->add_req_batch(nullptr, tf()->range_cc()->cnt() - TypeFunc::Parms);\n+      if (vt->is_allocated(&kit.gvn()) && !StressCallingConvention) {\n@@ -988,1 +991,1 @@\n-    while (pop_exception_state() != NULL) ;\n+    while (pop_exception_state() != nullptr) ;\n@@ -995,1 +998,1 @@\n-  while ((ex_map = pop_exception_state()) != NULL) {\n+  while ((ex_map = pop_exception_state()) != nullptr) {\n@@ -1123,0 +1126,10 @@\n+#ifdef ASSERT\n+      tty->print_cr(\"# Can't determine return type.\");\n+      tty->print_cr(\"# exit control\");\n+      _exits.control()->dump(2);\n+      tty->print_cr(\"# ret phi type\");\n+      _gvn.type(ret_phi)->dump();\n+      tty->print_cr(\"# ret phi\");\n+      ret_phi->dump(2);\n+#endif \/\/ ASSERT\n+      assert(false, \"Can't determine return type.\");\n@@ -1148,1 +1161,1 @@\n-    while ((ex_map = kit.pop_exception_state()) != NULL) {\n+    while ((ex_map = kit.pop_exception_state()) != nullptr) {\n@@ -1183,1 +1196,1 @@\n-    while ((ex_map = caller.pop_exception_state()) != NULL) {\n+    while ((ex_map = caller.pop_exception_state()) != nullptr) {\n@@ -1198,0 +1211,1 @@\n+    \/\/ Bailout expected, this is a very rare edge case.\n@@ -1199,1 +1213,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1213,1 +1227,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -1217,1 +1231,1 @@\n-  assert(method() != NULL, \"parser must have a method\");\n+  assert(method() != nullptr, \"parser must have a method\");\n@@ -1220,1 +1234,1 @@\n-  JVMState* jvms = new (C) JVMState(method(), _caller->has_method() ? _caller : NULL);\n+  JVMState* jvms = new (C) JVMState(method(), _caller->has_method() ? _caller : nullptr);\n@@ -1227,1 +1241,1 @@\n-  assert(inmap != NULL, \"must have inmap\");\n+  assert(inmap != nullptr, \"must have inmap\");\n@@ -1278,1 +1292,1 @@\n-    const Type* holder_type = TypeInstPtr::make(TypePtr::BotPTR, callee_holder);\n+    const Type* holder_type = TypeInstPtr::make(TypePtr::BotPTR, callee_holder, Type::trust_interfaces);\n@@ -1283,1 +1297,1 @@\n-    if (receiver_type != NULL && !receiver_type->higher_equal(holder_type)) {\n+    if (receiver_type != nullptr && !receiver_type->higher_equal(holder_type)) {\n@@ -1291,1 +1305,1 @@\n-      Node* holder_klass = _gvn.makecon(TypeKlassPtr::make(callee_holder));\n+      Node* holder_klass = _gvn.makecon(TypeKlassPtr::make(callee_holder, Type::trust_interfaces));\n@@ -1313,1 +1327,1 @@\n-    Node *lock_obj = NULL;\n+    Node *lock_obj = nullptr;\n@@ -1362,1 +1376,1 @@\n-  _start_map = NULL;\n+  _start_map = nullptr;\n@@ -1366,1 +1380,1 @@\n-  _successors = NULL;\n+  _successors = nullptr;\n@@ -1385,1 +1399,1 @@\n-  _successors = (ns+ne == 0) ? NULL : NEW_RESOURCE_ARRAY(Block*, ns+ne);\n+  _successors = (ns+ne == 0) ? nullptr : NEW_RESOURCE_ARRAY(Block*, ns+ne);\n@@ -1428,1 +1442,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1582,1 +1596,6 @@\n-    if (b->is_loop_head()) tty->print(\"  lphd\");\n+    if (b->is_loop_head()) {\n+      tty->print(\"  lphd\");\n+    }\n+    if (b->is_irreducible_loop_entry()) {\n+      tty->print(\"  irreducible\");\n+    }\n@@ -1608,1 +1627,1 @@\n-    if (log != NULL) {\n+    if (log != nullptr) {\n@@ -1643,1 +1662,1 @@\n-    if (log != NULL)\n+    if (log != nullptr)\n@@ -1658,1 +1677,1 @@\n-  if (nn == NULL)  return;\n+  if (nn == nullptr)  return;\n@@ -1667,1 +1686,1 @@\n-  if (jvms != NULL && jvms->bci() != bci) {\n+  if (jvms != nullptr && jvms->bci() != bci) {\n@@ -1679,1 +1698,1 @@\n-  if (target == NULL) { handle_missing_successor(target_bci); return; }\n+  if (target == nullptr) { handle_missing_successor(target_bci); return; }\n@@ -1689,1 +1708,1 @@\n-  if (target == NULL) { handle_missing_successor(target_bci); return; }\n+  if (target == nullptr) { handle_missing_successor(target_bci); return; }\n@@ -1706,1 +1725,1 @@\n-  if (target == NULL) { handle_missing_successor(target_bci); return; }\n+  if (target == nullptr) { handle_missing_successor(target_bci); return; }\n@@ -1747,1 +1766,1 @@\n-      const Type* t = NULL;\n+      const Type* t = nullptr;\n@@ -1753,1 +1772,1 @@\n-      if (t != NULL && t != Type::BOTTOM) {\n+      if (t != nullptr && t != Type::BOTTOM) {\n@@ -1791,1 +1810,1 @@\n-          \/\/ Add loop predicate for the special case when\n+          \/\/ Add Parse Predicates for the special case when\n@@ -1793,1 +1812,1 @@\n-          add_empty_predicates();\n+          add_parse_predicates();\n@@ -1803,2 +1822,2 @@\n-      \/\/ zap all inputs to NULL for debugging (done in Node(uint) constructor)\n-      \/\/ for (int j = 1; j < edges+1; j++) { r->init_req(j, NULL); }\n+      \/\/ zap all inputs to null for debugging (done in Node(uint) constructor)\n+      \/\/ for (int j = 1; j < edges+1; j++) { r->init_req(j, nullptr); }\n@@ -1807,0 +1826,1 @@\n+      target->copy_irreducible_status_to(r, jvms());\n@@ -1845,1 +1865,1 @@\n-      if (!block()->flow()->is_irreducible_entry()) {\n+      if (!block()->flow()->is_irreducible_loop_secondary_entry()) {\n@@ -1867,1 +1887,1 @@\n-        phi = NULL;\n+        phi = nullptr;\n@@ -1876,1 +1896,1 @@\n-          assert(phi == NULL, \"the merge contains phis, not vice versa\");\n+          assert(phi == nullptr, \"the merge contains phis, not vice versa\");\n@@ -1880,1 +1900,1 @@\n-          if (phi == NULL) {\n+          if (phi == nullptr) {\n@@ -1903,1 +1923,1 @@\n-      if (phi != NULL && phi->bottom_type()->is_inlinetypeptr()) {\n+      if (phi != nullptr && phi->bottom_type()->is_inlinetypeptr()) {\n@@ -1925,1 +1945,1 @@\n-      } else if (phi != NULL) {\n+      } else if (phi != nullptr) {\n@@ -1970,1 +1990,1 @@\n-  assert(n != NULL, \"\");\n+  assert(n != nullptr, \"\");\n@@ -1977,2 +1997,2 @@\n-  PhiNode* base = NULL;\n-  MergeMemNode* remerge = NULL;\n+  PhiNode* base = nullptr;\n+  MergeMemNode* remerge = nullptr;\n@@ -1986,3 +2006,3 @@\n-      if (remerge == NULL) {\n-        guarantee(base != NULL, \"\");\n-        assert(base->in(0) != NULL, \"should not be xformed away\");\n+      if (remerge == nullptr) {\n+        guarantee(base != nullptr, \"\");\n+        assert(base->in(0) != nullptr, \"should not be xformed away\");\n@@ -2004,1 +2024,1 @@\n-        phi = NULL;\n+        phi = nullptr;\n@@ -2007,1 +2027,1 @@\n-    if (phi != NULL) {\n+    if (phi != nullptr) {\n@@ -2021,1 +2041,1 @@\n-  if (base != NULL && pnum == 1) {\n+  if (base != nullptr && pnum == 1) {\n@@ -2080,1 +2100,1 @@\n-  r->add_req(NULL);\n+  r->add_req(nullptr);\n@@ -2090,1 +2110,1 @@\n-          phi->add_req(NULL);\n+          phi->add_req(nullptr);\n@@ -2096,1 +2116,1 @@\n-        n->add_req(NULL);\n+        n->add_req(nullptr);\n@@ -2114,1 +2134,1 @@\n-  assert(o != NULL, \"\");\n+  assert(o != nullptr, \"\");\n@@ -2116,1 +2136,1 @@\n-  if (o == top())  return NULL; \/\/ TOP always merges into TOP\n+  if (o == top())  return nullptr; \/\/ TOP always merges into TOP\n@@ -2122,1 +2142,1 @@\n-  if (vt != NULL && vt->has_phi_inputs(region)) {\n+  if (vt != nullptr && vt->has_phi_inputs(region)) {\n@@ -2129,1 +2149,1 @@\n-  const Type* t = NULL;\n+  const Type* t = nullptr;\n@@ -2148,1 +2168,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -2155,1 +2175,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -2158,1 +2178,1 @@\n-  if (vt != NULL && t->is_inlinetypeptr()) {\n+  if (vt != nullptr && t->is_inlinetypeptr()) {\n@@ -2182,1 +2202,1 @@\n-  assert(o != NULL && o != top(), \"\");\n+  assert(o != nullptr && o != top(), \"\");\n@@ -2216,1 +2236,1 @@\n-  assert(receiver != NULL && receiver->bottom_type()->isa_instptr() != NULL,\n+  assert(receiver != nullptr && receiver->bottom_type()->isa_instptr() != nullptr,\n@@ -2220,1 +2240,1 @@\n-  if (tinst != NULL && tinst->is_loaded() && !tinst->klass_is_exact()) {\n+  if (tinst != nullptr && tinst->is_loaded() && !tinst->klass_is_exact()) {\n@@ -2234,1 +2254,1 @@\n-  Node* klass = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), klass_addr, TypeInstPtr::KLASS));\n+  Node* klass = _gvn.transform(LoadKlassNode::make(_gvn, nullptr, immutable_memory(), klass_addr, TypeInstPtr::KLASS));\n@@ -2237,1 +2257,1 @@\n-  Node* access_flags = make_load(NULL, access_flags_addr, TypeInt::INT, T_INT, MemNode::unordered);\n+  Node* access_flags = make_load(nullptr, access_flags_addr, TypeInt::INT, T_INT, MemNode::unordered);\n@@ -2260,1 +2280,1 @@\n-                                   NULL, TypePtr::BOTTOM,\n+                                   nullptr, TypePtr::BOTTOM,\n@@ -2290,1 +2310,1 @@\n-  Node* holder = makecon(TypeKlassPtr::make(method()->holder()));\n+  Node* holder = makecon(TypeKlassPtr::make(method()->holder(), Type::trust_interfaces));\n@@ -2308,1 +2328,1 @@\n-    int offset = MethodData::rtm_state_offset_in_bytes();\n+    int offset = in_bytes(MethodData::rtm_state_offset());\n@@ -2350,1 +2370,1 @@\n-  if (value != NULL) {\n+  if (value != nullptr) {\n@@ -2354,2 +2374,2 @@\n-    \/\/ The return_type is set in Parse::build_exits().\n-    if (return_type->isa_inlinetype()) {\n+    if ((tf()->returns_inline_type_as_fields() || (_caller->has_method() && !Compile::current()->inlining_incrementally())) &&\n+        return_type->is_inlinetypeptr()) {\n@@ -2383,20 +2403,3 @@\n-    } else if (tr && tr->isa_instptr() && tr->is_loaded() && tr->is_interface()) {\n-      \/\/ If returning oops to an interface-return, there is a silent free\n-      \/\/ cast from oop to interface allowed by the Verifier. Make it explicit here.\n-      const TypeInstPtr* tp = value->bottom_type()->isa_instptr();\n-      if (tp && tp->is_loaded() && !tp->is_interface()) {\n-        \/\/ sharpen the type eagerly; this eases certain assert checking\n-        if (tp->higher_equal(TypeInstPtr::NOTNULL)) {\n-          tr = tr->join_speculative(TypeInstPtr::NOTNULL)->is_instptr();\n-        }\n-        value = _gvn.transform(new CheckCastPPNode(0, value, tr));\n-      }\n-    } else {\n-      \/\/ Handle returns of oop-arrays to an arrays-of-interface return\n-      const TypeInstPtr* phi_tip;\n-      const TypeInstPtr* val_tip;\n-      Type::get_arrays_base_elements(return_type, value->bottom_type(), &phi_tip, &val_tip);\n-      if (phi_tip != NULL && phi_tip->is_loaded() && phi_tip->is_interface() &&\n-          val_tip != NULL && val_tip->is_loaded() && !val_tip->is_interface()) {\n-        value = _gvn.transform(new CheckCastPPNode(0, value, return_type));\n-      }\n+    \/\/ ...else\n+    \/\/ If returning oops to an interface-return, there is a silent free\n+    \/\/ cast from oop to interface allowed by the Verifier. Make it explicit here.\n@@ -2443,1 +2446,1 @@\n-  SafePointNode *sfpnt = new SafePointNode(parms, NULL);\n+  SafePointNode *sfpnt = new SafePointNode(parms, nullptr);\n@@ -2485,1 +2488,1 @@\n-    assert(C->root() != NULL, \"Expect parse is still valid\");\n+    assert(C->root() != nullptr, \"Expect parse is still valid\");\n@@ -2493,2 +2496,2 @@\n-  InlineTree* ilt = NULL;\n-  if (C->ilt() != NULL) {\n+  InlineTree* ilt = nullptr;\n+  if (C->ilt() != nullptr) {\n@@ -2559,1 +2562,1 @@\n-  if( method() != NULL ) {\n+  if( method() != nullptr ) {\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":132,"deletions":129,"binary":false,"changes":261,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -77,1 +77,1 @@\n-  \/\/ _from_ is not loaded, and value is not null.  If the value _is_ NULL,\n+  \/\/ _from_ is not loaded, and value is not null.  If the value _is_ null,\n@@ -82,1 +82,1 @@\n-    if (C->log() != NULL) {\n+    if (C->log() != nullptr) {\n@@ -99,1 +99,1 @@\n-  Node* res = gen_checkcast(obj, makecon(TypeKlassPtr::make(klass)), NULL, null_free);\n+  Node* res = gen_checkcast(obj, makecon(TypeKlassPtr::make(klass, Type::trust_interfaces)), nullptr, null_free);\n@@ -122,1 +122,1 @@\n-    if (C->log() != NULL) {\n+    if (C->log() != nullptr) {\n@@ -138,1 +138,1 @@\n-  Node* res = gen_instanceof(peek(), makecon(TypeKlassPtr::make(klass)), true);\n+  Node* res = gen_instanceof(peek(), makecon(TypeKlassPtr::make(klass, Type::trust_interfaces)), true);\n@@ -176,1 +176,1 @@\n-    const TypeKlassPtr* extak = NULL;\n+    const TypeKlassPtr* extak = nullptr;\n@@ -182,1 +182,1 @@\n-    if (ary_spec != NULL && !too_many_traps(Deoptimization::Reason_speculate_class_check)) {\n+    if (ary_spec != nullptr && !too_many_traps(Deoptimization::Reason_speculate_class_check)) {\n@@ -189,2 +189,2 @@\n-        ciKlass* array_type = NULL;\n-        ciKlass* element_type = NULL;\n+        ciKlass* array_type = nullptr;\n+        ciKlass* element_type = nullptr;\n@@ -195,1 +195,1 @@\n-        if (array_type != NULL) {\n+        if (array_type != nullptr) {\n@@ -221,1 +221,1 @@\n-    if (extak != NULL && extak->exact_klass(true) != NULL) {\n+    if (extak != nullptr && extak->exact_klass(true) != nullptr) {\n@@ -246,1 +246,1 @@\n-        if (log != NULL) {\n+        if (log != nullptr) {\n@@ -263,1 +263,1 @@\n-  Node* a_e_klass = _gvn.transform(LoadKlassNode::make(_gvn, always_see_exact_class ? control() : NULL,\n+  Node* a_e_klass = _gvn.transform(LoadKlassNode::make(_gvn, always_see_exact_class ? control() : nullptr,\n@@ -267,3 +267,1 @@\n-  if (!elemtype->isa_inlinetype()) {\n-    elemtype = elemtype->make_oopptr();\n-  }\n+  const TypeAryPtr* arytype = _gvn.type(ary)->is_aryptr();\n@@ -271,1 +269,1 @@\n-  if (elemtype->isa_inlinetype() != NULL || elemtype->is_inlinetypeptr()) {\n+  if (elemtype->make_ptr()->is_inlinetypeptr()) {\n@@ -273,1 +271,1 @@\n-    null_free = elemtype->isa_inlinetype() || !elemtype->maybe_null();\n+    null_free = arytype->is_flat() || !elemtype->make_ptr()->maybe_null();\n@@ -278,1 +276,1 @@\n-  return gen_checkcast(obj, a_e_klass, NULL, null_free);\n+  return gen_checkcast(obj, a_e_klass, nullptr, null_free);\n@@ -368,4 +366,3 @@\n-  InlineTypeNode* new_vt = InlineTypeNode::make_uninitialized(gvn(), gvn().type(holder)->inline_klass());\n-  for (uint i = 2; i < holder->req(); ++i) {\n-    new_vt->set_req(i, holder->in(i));\n-  }\n+  InlineTypeNode* new_vt = holder->clone()->as_InlineType();\n+  new_vt->set_oop(gvn().zerocon(T_PRIMITIVE_OBJECT));\n+  new_vt->set_is_buffered(gvn(), false);\n@@ -378,1 +375,1 @@\n-      new_vt->set_field_value_by_offset(field->offset() + i * type2aelembytes(bt), val);\n+      new_vt->set_field_value_by_offset(field->offset_in_bytes() + i * type2aelembytes(bt), val);\n@@ -382,1 +379,9 @@\n-    new_vt->set_field_value_by_offset(field->offset(), val);\n+    new_vt->set_field_value_by_offset(field->offset_in_bytes(), val);\n+  }\n+\n+  {\n+    PreserveReexecuteState preexecs(this);\n+    jvms()->set_should_reexecute(true);\n+    int nargs = 1 + InlineTypeNode::stack_size_for_field(field);\n+    inc_sp(nargs);\n+    new_vt = new_vt->adjust_scalarization_depth(this);\n@@ -392,2 +397,2 @@\n-  MergeMemNode *mem = map() == NULL ? NULL : (map()->memory()->is_MergeMem() ?\n-                                      map()->memory()->as_MergeMem() : NULL);\n+  MergeMemNode *mem = map() == nullptr ? nullptr : (map()->memory()->is_MergeMem() ?\n+                                      map()->memory()->as_MergeMem() : nullptr);\n","filename":"src\/hotspot\/share\/opto\/parseHelper.cpp","additions":33,"deletions":28,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -206,1 +206,1 @@\n-      Node* new_vbox = NULL;\n+      Node* new_vbox = nullptr;\n@@ -235,0 +235,1 @@\n+    VectorSet visited;\n@@ -237,1 +238,4 @@\n-    Node* result = expand_vbox_node_helper(vbox, vect, vec_box->box_type(), vec_box->vec_type());\n+\n+    Node* result = expand_vbox_node_helper(vbox, vect, vec_box->box_type(),\n+                                           vec_box->vec_type(), visited);\n+\n@@ -247,1 +251,23 @@\n-                                           const TypeVect* vect_type) {\n+                                           const TypeVect* vect_type,\n+                                           VectorSet &visited) {\n+  \/\/ JDK-8304948 shows an example that there may be a cycle in the graph.\n+  if (visited.test_set(vbox->_idx)) {\n+    assert(vbox->is_Phi(), \"should be phi\");\n+    return vbox; \/\/ already visited\n+  }\n+\n+  \/\/ Handle the case when the allocation input to VectorBoxNode is a Proj.\n+  \/\/ This is the normal case before expanding.\n+  if (vbox->is_Proj() && vbox->in(0)->Opcode() == Op_VectorBoxAllocate) {\n+    VectorBoxAllocateNode* vbox_alloc = static_cast<VectorBoxAllocateNode*>(vbox->in(0));\n+    return expand_vbox_alloc_node(vbox_alloc, vect, box_type, vect_type);\n+  }\n+\n+  \/\/ Handle the case when both the allocation input and vector input to\n+  \/\/ VectorBoxNode are Phi. This case is generated after the transformation of\n+  \/\/ Phi: Phi (VectorBox1 VectorBox2) => VectorBox (Phi1 Phi2).\n+  \/\/ With this optimization, the relative two allocation inputs of VectorBox1 and\n+  \/\/ VectorBox2 are gathered into Phi1 now. Similarly, the original vector\n+  \/\/ inputs of two VectorBox nodes are in Phi2.\n+  \/\/\n+  \/\/ See PhiNode::merge_through_phi in cfg.cpp for more details.\n@@ -250,3 +276,6 @@\n-    Node* new_phi = new PhiNode(vbox->as_Phi()->region(), box_type);\n-      Node* new_box = expand_vbox_node_helper(vbox->in(i), vect->in(i), box_type, vect_type);\n-      new_phi->set_req(i, new_box);\n+      Node* new_box = expand_vbox_node_helper(vbox->in(i), vect->in(i),\n+                                              box_type, vect_type, visited);\n+      if (!new_box->is_Phi()) {\n+        C->initial_gvn()->hash_delete(vbox);\n+        vbox->set_req(i, new_box);\n+      }\n@@ -255,11 +284,11 @@\n-    new_phi = C->initial_gvn()->transform(new_phi);\n-    return new_phi;\n-  } else if (vbox->is_Phi() && (vect->is_Vector() || vect->is_LoadVector())) {\n-    \/\/ Handle the case when the allocation input to VectorBoxNode is a phi\n-    \/\/ but the vector input is not, which can definitely be the case if the\n-    \/\/ vector input has been value-numbered. It seems to be safe to do by\n-    \/\/ construction because VectorBoxNode and VectorBoxAllocate come in a\n-    \/\/ specific order as a result of expanding an intrinsic call. After that, if\n-    \/\/ any of the inputs to VectorBoxNode are value-numbered they can only\n-    \/\/ move up and are guaranteed to dominate.\n-    Node* new_phi = new PhiNode(vbox->as_Phi()->region(), box_type);\n+    return C->initial_gvn()->transform(vbox);\n+  }\n+\n+  \/\/ Handle the case when the allocation input to VectorBoxNode is a phi\n+  \/\/ but the vector input is not, which can definitely be the case if the\n+  \/\/ vector input has been value-numbered. It seems to be safe to do by\n+  \/\/ construction because VectorBoxNode and VectorBoxAllocate come in a\n+  \/\/ specific order as a result of expanding an intrinsic call. After that, if\n+  \/\/ any of the inputs to VectorBoxNode are value-numbered they can only\n+  \/\/ move up and are guaranteed to dominate.\n+  if (vbox->is_Phi() && (vect->is_Vector() || vect->is_LoadVector())) {\n@@ -267,2 +296,6 @@\n-      Node* new_box = expand_vbox_node_helper(vbox->in(i), vect, box_type, vect_type);\n-      new_phi->set_req(i, new_box);\n+      Node* new_box = expand_vbox_node_helper(vbox->in(i), vect,\n+                                              box_type, vect_type, visited);\n+      if (!new_box->is_Phi()) {\n+        C->initial_gvn()->hash_delete(vbox);\n+        vbox->set_req(i, new_box);\n+      }\n@@ -270,9 +303,1 @@\n-    new_phi = C->initial_gvn()->transform(new_phi);\n-    return new_phi;\n-  } else if (vbox->is_Proj() && vbox->in(0)->Opcode() == Op_VectorBoxAllocate) {\n-    VectorBoxAllocateNode* vbox_alloc = static_cast<VectorBoxAllocateNode*>(vbox->in(0));\n-    return expand_vbox_alloc_node(vbox_alloc, vect, box_type, vect_type);\n-  } else {\n-    assert(!vbox->is_Phi(), \"\");\n-    \/\/ TODO: assert that expanded vbox is initialized with the same value (vect).\n-    return vbox; \/\/ already expanded\n+    return C->initial_gvn()->transform(vbox);\n@@ -280,0 +305,4 @@\n+\n+  assert(!vbox->is_Phi(), \"should be expanded\");\n+  \/\/ TODO: assert that expanded vbox is initialized with the same value (vect).\n+  return vbox; \/\/ already expanded\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":57,"deletions":28,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -43,1 +43,2 @@\n-                                const TypeVect* vect_type);\n+                                const TypeVect* vect_type,\n+                                VectorSet &visited);\n","filename":"src\/hotspot\/share\/opto\/vector.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -38,4 +38,0 @@\n-static bool is_vector_shuffle(ciKlass* klass) {\n-  return klass->is_subclass_of(ciEnv::current()->vector_VectorShuffle_klass());\n-}\n-\n@@ -54,1 +50,1 @@\n-  assert(fd1 != NULL, \"element type info is missing\");\n+  assert(fd1 != nullptr, \"element type info is missing\");\n@@ -61,1 +57,1 @@\n-  assert(fd2 != NULL, \"vector length info is missing\");\n+  assert(fd2 != nullptr, \"vector length info is missing\");\n@@ -131,2 +127,1 @@\n-    default:\n-      assert(false, \"Unexpected type\");\n+    default: fatal(\"Unexpected type: %s\", type2name(elem_bt));\n@@ -160,4 +155,0 @@\n-  if (is_vector_shuffle(vbox_type->instance_klass())) {\n-    assert(elem_bt == T_BYTE, \"must be consistent with shuffle representation\");\n-  }\n-\n@@ -181,1 +172,1 @@\n-    return NULL; \/\/ arguments don't agree on vector shapes\n+    return nullptr; \/\/ arguments don't agree on vector shapes\n@@ -184,1 +175,1 @@\n-    return NULL; \/\/ no nulls are allowed\n+    return nullptr; \/\/ no nulls are allowed\n@@ -344,1 +335,1 @@\n-  if (vec_klass->const_oop() == NULL) {\n+  if (vec_klass->const_oop() == nullptr) {\n@@ -347,1 +338,1 @@\n-  assert(vec_klass->const_oop()->as_instance()->java_lang_Class_klass() != NULL, \"klass instance expected\");\n+  assert(vec_klass->const_oop()->as_instance()->java_lang_Class_klass() != nullptr, \"klass instance expected\");\n@@ -383,2 +374,2 @@\n-  if (opr == NULL || vector_klass == NULL || elem_klass == NULL || vlen == NULL ||\n-      !opr->is_con() || vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (opr == nullptr || vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr ||\n+      !opr->is_con() || vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -414,1 +405,1 @@\n-    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+    if (mask_klass == nullptr || mask_klass->const_oop() == nullptr) {\n@@ -506,1 +497,1 @@\n-  Node* opd1 = NULL; Node* opd2 = NULL; Node* opd3 = NULL;\n+  Node* opd1 = nullptr; Node* opd2 = nullptr; Node* opd3 = nullptr;\n@@ -510,1 +501,1 @@\n-      if (opd3 == NULL) {\n+      if (opd3 == nullptr) {\n@@ -521,1 +512,1 @@\n-      if (opd2 == NULL) {\n+      if (opd2 == nullptr) {\n@@ -532,1 +523,1 @@\n-      if (opd1 == NULL) {\n+      if (opd1 == nullptr) {\n@@ -544,1 +535,1 @@\n-  Node* mask = NULL;\n+  Node* mask = nullptr;\n@@ -550,1 +541,1 @@\n-    if (mask == NULL) {\n+    if (mask == nullptr) {\n@@ -559,1 +550,1 @@\n-  Node* operation = NULL;\n+  Node* operation = nullptr;\n@@ -563,1 +554,1 @@\n-    if (operation == NULL) {\n+    if (operation == nullptr) {\n@@ -588,1 +579,1 @@\n-  if (is_masked_op && mask != NULL) {\n+  if (is_masked_op && mask != nullptr) {\n@@ -607,97 +598,0 @@\n-\/\/ <Sh extends VectorShuffle<E>,  E>\n-\/\/  Sh ShuffleIota(Class<?> E, Class<?> shuffleClass, Vector.Species<E> s, int length,\n-\/\/                  int start, int step, int wrap, ShuffleIotaOperation<Sh, E> defaultImpl)\n-bool LibraryCallKit::inline_vector_shuffle_iota() {\n-  const TypeInstPtr* shuffle_klass = gvn().type(argument(1))->isa_instptr();\n-  const TypeInt*     vlen          = gvn().type(argument(3))->isa_int();\n-  const TypeInt*     start_val     = gvn().type(argument(4))->isa_int();\n-  const TypeInt*     step_val      = gvn().type(argument(5))->isa_int();\n-  const TypeInt*     wrap          = gvn().type(argument(6))->isa_int();\n-\n-  Node* start = argument(4);\n-  Node* step  = argument(5);\n-\n-  if (shuffle_klass == NULL || vlen == NULL || start_val == NULL || step_val == NULL || wrap == NULL) {\n-    return false; \/\/ dead code\n-  }\n-  if (!vlen->is_con() || !is_power_of_2(vlen->get_con()) ||\n-      shuffle_klass->const_oop() == NULL || !wrap->is_con()) {\n-    return false; \/\/ not enough info for intrinsification\n-  }\n-  if (!is_klass_initialized(shuffle_klass)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** klass argument not initialized\");\n-    }\n-    return false;\n-  }\n-\n-  int do_wrap = wrap->get_con();\n-  int num_elem = vlen->get_con();\n-  BasicType elem_bt = T_BYTE;\n-\n-  if (!arch_supports_vector(VectorNode::replicate_opcode(elem_bt), num_elem, elem_bt, VecMaskNotUsed)) {\n-    return false;\n-  }\n-  if (!arch_supports_vector(Op_AddVB, num_elem, elem_bt, VecMaskNotUsed)) {\n-    return false;\n-  }\n-  if (!arch_supports_vector(Op_AndV, num_elem, elem_bt, VecMaskNotUsed)) {\n-    return false;\n-  }\n-  if (!arch_supports_vector(Op_VectorLoadConst, num_elem, elem_bt, VecMaskNotUsed)) {\n-    return false;\n-  }\n-  if (!arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)) {\n-    return false;\n-  }\n-  if (!arch_supports_vector(Op_VectorMaskCmp, num_elem, elem_bt, VecMaskUseStore)) {\n-    return false;\n-  }\n-\n-  const Type * type_bt = Type::get_const_basic_type(elem_bt);\n-  const TypeVect * vt  = TypeVect::make(type_bt, num_elem);\n-\n-  Node* res =  gvn().transform(new VectorLoadConstNode(gvn().makecon(TypeInt::ZERO), vt));\n-\n-  if(!step_val->is_con() || !is_power_of_2(step_val->get_con())) {\n-    Node* bcast_step     = gvn().transform(VectorNode::scalar2vector(step, num_elem, type_bt));\n-    res = gvn().transform(VectorNode::make(Op_MulI, res, bcast_step, num_elem, elem_bt));\n-  } else if (step_val->get_con() > 1) {\n-    Node* cnt = gvn().makecon(TypeInt::make(log2i_exact(step_val->get_con())));\n-    Node* shift_cnt = vector_shift_count(cnt, Op_LShiftI, elem_bt, num_elem);\n-    res = gvn().transform(VectorNode::make(Op_LShiftVB, res, shift_cnt, vt));\n-  }\n-\n-  if (!start_val->is_con() || start_val->get_con() != 0) {\n-    Node* bcast_start    = gvn().transform(VectorNode::scalar2vector(start, num_elem, type_bt));\n-    res = gvn().transform(VectorNode::make(Op_AddI, res, bcast_start, num_elem, elem_bt));\n-  }\n-\n-  Node * mod_val = gvn().makecon(TypeInt::make(num_elem-1));\n-  Node * bcast_mod  = gvn().transform(VectorNode::scalar2vector(mod_val, num_elem, type_bt));\n-  if(do_wrap)  {\n-    \/\/ Wrap the indices greater than lane count.\n-    res = gvn().transform(VectorNode::make(Op_AndI, res, bcast_mod, num_elem, elem_bt));\n-  } else {\n-    ConINode* pred_node = (ConINode*)gvn().makecon(TypeInt::make(BoolTest::ge));\n-    Node * lane_cnt  = gvn().makecon(TypeInt::make(num_elem));\n-    Node * bcast_lane_cnt = gvn().transform(VectorNode::scalar2vector(lane_cnt, num_elem, type_bt));\n-    const TypeVect* vmask_type = TypeVect::makemask(elem_bt, num_elem);\n-    Node* mask = gvn().transform(new VectorMaskCmpNode(BoolTest::ge, bcast_lane_cnt, res, pred_node, vmask_type));\n-\n-    \/\/ Make the indices greater than lane count as -ve values. This matches the java side implementation.\n-    res = gvn().transform(VectorNode::make(Op_AndI, res, bcast_mod, num_elem, elem_bt));\n-    Node * biased_val = gvn().transform(VectorNode::make(Op_SubI, res, bcast_lane_cnt, num_elem, elem_bt));\n-    res = gvn().transform(new VectorBlendNode(biased_val, res, mask));\n-  }\n-\n-  ciKlass* sbox_klass = shuffle_klass->const_oop()->as_instance()->java_lang_Class_klass();\n-  const TypeInstPtr* shuffle_box_type = TypeInstPtr::make_exact(TypePtr::NotNull, sbox_klass);\n-\n-  \/\/ Wrap it up in VectorBox to keep object type information.\n-  res = box_vector(res, shuffle_box_type, elem_bt, num_elem);\n-  set_result(res);\n-  C->set_max_vector_size(MAX2(C->max_vector_size(), (uint)(num_elem * type2aelembytes(elem_bt))));\n-  return true;\n-}\n-\n@@ -714,1 +608,1 @@\n-  if (mask_klass == NULL || elem_klass == NULL || mask->is_top() || vlen == NULL) {\n+  if (mask_klass == nullptr || elem_klass == nullptr || mask->is_top() || vlen == nullptr) {\n@@ -742,1 +636,1 @@\n-  if (mask_vec == NULL) {\n+  if (mask_vec == nullptr) {\n@@ -750,1 +644,1 @@\n-  if (mask_vec->bottom_type()->isa_vectmask() == NULL) {\n+  if (mask_vec->bottom_type()->isa_vectmask() == nullptr) {\n@@ -764,66 +658,0 @@\n-\/\/ public static\n-\/\/ <V,\n-\/\/  Sh extends VectorShuffle<E>,\n-\/\/  E>\n-\/\/ V shuffleToVector(Class<? extends Vector<E>> vclass, Class<E> elementType,\n-\/\/                   Class<? extends Sh> shuffleClass, Sh s, int length,\n-\/\/                   ShuffleToVectorOperation<V, Sh, E> defaultImpl)\n-bool LibraryCallKit::inline_vector_shuffle_to_vector() {\n-  const TypeInstPtr* vector_klass  = gvn().type(argument(0))->isa_instptr();\n-  const TypeInstPtr* elem_klass    = gvn().type(argument(1))->isa_instptr();\n-  const TypeInstPtr* shuffle_klass = gvn().type(argument(2))->isa_instptr();\n-  Node*              shuffle       = argument(3);\n-  const TypeInt*     vlen          = gvn().type(argument(4))->isa_int();\n-\n-  if (vector_klass == NULL || elem_klass == NULL || shuffle_klass == NULL || shuffle->is_top() || vlen == NULL) {\n-    return false; \/\/ dead code\n-  }\n-  if (!vlen->is_con() || vector_klass->const_oop() == NULL || shuffle_klass->const_oop() == NULL) {\n-    return false; \/\/ not enough info for intrinsification\n-  }\n-  if (!is_klass_initialized(shuffle_klass) || !is_klass_initialized(vector_klass) ) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** klass argument not initialized\");\n-    }\n-    return false;\n-  }\n-\n-  int num_elem = vlen->get_con();\n-  ciType* elem_type = elem_klass->const_oop()->as_instance()->java_mirror_type();\n-  BasicType elem_bt = elem_type->basic_type();\n-\n-  if (num_elem < 4) {\n-    return false;\n-  }\n-\n-  int cast_vopc = VectorCastNode::opcode(-1, T_BYTE); \/\/ from shuffle of type T_BYTE\n-  \/\/ Make sure that cast is implemented to particular type\/size combination.\n-  if (!arch_supports_vector(cast_vopc, num_elem, elem_bt, VecMaskNotUsed)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** not supported: arity=1 op=cast#%d\/3 vlen2=%d etype2=%s\",\n-        cast_vopc, num_elem, type2name(elem_bt));\n-    }\n-    return false;\n-  }\n-\n-  ciKlass* sbox_klass = shuffle_klass->const_oop()->as_instance()->java_lang_Class_klass();\n-  const TypeInstPtr* shuffle_box_type = TypeInstPtr::make_exact(TypePtr::NotNull, sbox_klass);\n-\n-  Node* shuffle_vec = unbox_vector(shuffle, shuffle_box_type, T_BYTE, num_elem);\n-  if (shuffle_vec == NULL) {\n-    return false;\n-  }\n-\n-  \/\/ cast byte to target element type\n-  shuffle_vec = gvn().transform(VectorCastNode::make(cast_vopc, shuffle_vec, elem_bt, num_elem));\n-\n-  ciKlass* vbox_klass = vector_klass->const_oop()->as_instance()->java_lang_Class_klass();\n-  const TypeInstPtr* vec_box_type = TypeInstPtr::make_exact(TypePtr::NotNull, vbox_klass);\n-\n-  \/\/ Box vector\n-  Node* res = box_vector(shuffle_vec, vec_box_type, elem_bt, num_elem);\n-  set_result(res);\n-  C->set_max_vector_size(MAX2(C->max_vector_size(), (uint)(num_elem * type2aelembytes(elem_bt))));\n-  return true;\n-}\n-\n@@ -847,2 +675,2 @@\n-  if (vector_klass == NULL || elem_klass == NULL || vlen == NULL || mode == NULL ||\n-      bits_type == NULL || vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL ||\n+  if (vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr || mode == nullptr ||\n+      bits_type == nullptr || vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr ||\n@@ -893,1 +721,1 @@\n-  Node* broadcast = NULL;\n+  Node* broadcast = nullptr;\n@@ -942,1 +770,1 @@\n-  assert(arr_type != NULL, \"unexpected\");\n+  assert(arr_type != nullptr, \"unexpected\");\n@@ -981,2 +809,2 @@\n-  if (vector_klass == NULL || elem_klass == NULL || vlen == NULL ||\n-      vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr ||\n+      vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -1042,1 +870,1 @@\n-  const bool is_mismatched_access = in_heap && (addr_type->isa_aryptr() == NULL);\n+  const bool is_mismatched_access = in_heap && (addr_type->isa_aryptr() == nullptr);\n@@ -1047,1 +875,1 @@\n-  bool using_byte_array = arr_type != NULL && arr_type->elem()->array_element_basic_type() == T_BYTE && elem_bt != T_BYTE;\n+  bool using_byte_array = arr_type != nullptr && arr_type->elem()->array_element_basic_type() == T_BYTE && elem_bt != T_BYTE;\n@@ -1050,1 +878,1 @@\n-  if (arr_type != NULL && !using_byte_array && !is_mask && !elem_consistent_with_arr(elem_bt, arr_type)) {\n+  if (arr_type != nullptr && !using_byte_array && !is_mask && !elem_consistent_with_arr(elem_bt, arr_type)) {\n@@ -1099,1 +927,1 @@\n-    if (val == NULL) {\n+    if (val == nullptr) {\n@@ -1120,1 +948,1 @@\n-    Node* vload = NULL;\n+    Node* vload = nullptr;\n@@ -1139,1 +967,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -1177,3 +1005,3 @@\n-  if (vector_klass == NULL || mask_klass == NULL || elem_klass == NULL || vlen == NULL ||\n-      vector_klass->const_oop() == NULL || mask_klass->const_oop() == NULL ||\n-      elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (vector_klass == nullptr || mask_klass == nullptr || elem_klass == nullptr || vlen == nullptr ||\n+      vector_klass->const_oop() == nullptr || mask_klass->const_oop() == nullptr ||\n+      elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -1226,1 +1054,1 @@\n-  bool using_byte_array = arr_type != NULL && arr_type->elem()->array_element_basic_type() == T_BYTE && elem_bt != T_BYTE;\n+  bool using_byte_array = arr_type != nullptr && arr_type->elem()->array_element_basic_type() == T_BYTE && elem_bt != T_BYTE;\n@@ -1228,1 +1056,1 @@\n-  if (arr_type != NULL && !using_byte_array && !elem_consistent_with_arr(elem_bt, arr_type)) {\n+  if (arr_type != nullptr && !using_byte_array && !elem_consistent_with_arr(elem_bt, arr_type)) {\n@@ -1319,1 +1147,1 @@\n-  \/\/ Can base be NULL? Otherwise, always on-heap access.\n+  \/\/ Can base be null? Otherwise, always on-heap access.\n@@ -1332,1 +1160,1 @@\n-  if (mask == NULL) {\n+  if (mask == nullptr) {\n@@ -1345,1 +1173,1 @@\n-    if (val == NULL) {\n+    if (val == nullptr) {\n@@ -1368,1 +1196,1 @@\n-    Node* vload = NULL;\n+    Node* vload = nullptr;\n@@ -1398,1 +1226,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -1439,2 +1267,2 @@\n-  if (vector_klass == NULL || elem_klass == NULL || vector_idx_klass == NULL || vlen == NULL ||\n-      vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || vector_idx_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (vector_klass == nullptr || elem_klass == nullptr || vector_idx_klass == nullptr || vlen == nullptr ||\n+      vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || vector_idx_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -1472,1 +1300,1 @@\n-    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+    if (mask_klass == nullptr || mask_klass->const_oop() == nullptr) {\n@@ -1538,1 +1366,1 @@\n-  if (arr_type == NULL || (arr_type != NULL && !elem_consistent_with_arr(elem_bt, arr_type))) {\n+  if (arr_type == nullptr || (arr_type != nullptr && !elem_consistent_with_arr(elem_bt, arr_type))) {\n@@ -1552,1 +1380,1 @@\n-  if (vbox_idx_klass == NULL) {\n+  if (vbox_idx_klass == nullptr) {\n@@ -1560,1 +1388,1 @@\n-  if (index_vect == NULL) {\n+  if (index_vect == nullptr) {\n@@ -1566,1 +1394,1 @@\n-  Node* mask = NULL;\n+  Node* mask = nullptr;\n@@ -1571,1 +1399,1 @@\n-    if (mask == NULL) {\n+    if (mask == nullptr) {\n@@ -1586,1 +1414,1 @@\n-    if (val == NULL) {\n+    if (val == nullptr) {\n@@ -1593,2 +1421,2 @@\n-    Node* vstore = NULL;\n-    if (mask != NULL) {\n+    Node* vstore = nullptr;\n+    if (mask != nullptr) {\n@@ -1601,2 +1429,2 @@\n-    Node* vload = NULL;\n-    if (mask != NULL) {\n+    Node* vload = nullptr;\n+    if (mask != nullptr) {\n@@ -1611,1 +1439,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -1631,2 +1459,2 @@\n-  if (opr == NULL || vector_klass == NULL || elem_klass == NULL || vlen == NULL ||\n-      !opr->is_con() || vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (opr == nullptr || vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr ||\n+      !opr->is_con() || vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -1659,1 +1487,1 @@\n-    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+    if (mask_klass == nullptr || mask_klass->const_oop() == nullptr) {\n@@ -1709,1 +1537,1 @@\n-  if (opd == NULL) {\n+  if (opd == nullptr) {\n@@ -1713,1 +1541,1 @@\n-  Node* mask = NULL;\n+  Node* mask = nullptr;\n@@ -1719,1 +1547,1 @@\n-    if (mask == NULL) {\n+    if (mask == nullptr) {\n@@ -1728,3 +1556,3 @@\n-  Node* init = ReductionNode::make_reduction_input(gvn(), opc, elem_bt);\n-  Node* value = NULL;\n-  if (mask == NULL) {\n+  Node* init = ReductionNode::make_identity_con_scalar(gvn(), opc, elem_bt);\n+  Node* value = nullptr;\n+  if (mask == nullptr) {\n@@ -1732,1 +1560,1 @@\n-    value = ReductionNode::make(opc, NULL, init, opd, elem_bt);\n+    value = ReductionNode::make(opc, nullptr, init, opd, elem_bt);\n@@ -1735,1 +1563,1 @@\n-      value = ReductionNode::make(opc, NULL, init, opd, elem_bt);\n+      value = ReductionNode::make(opc, nullptr, init, opd, elem_bt);\n@@ -1741,1 +1569,1 @@\n-      value = ReductionNode::make(opc, NULL, init, value, elem_bt);\n+      value = ReductionNode::make(opc, nullptr, init, value, elem_bt);\n@@ -1746,1 +1574,1 @@\n-  Node* bits = NULL;\n+  Node* bits = nullptr;\n@@ -1784,2 +1612,2 @@\n-  if (cond == NULL || vector_klass == NULL || elem_klass == NULL || vlen == NULL ||\n-      !cond->is_con() || vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (cond == nullptr || vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr ||\n+      !cond->is_con() || vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -1824,2 +1652,8 @@\n-  Node* opd2 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n-  if (opd1 == NULL || opd2 == NULL) {\n+  Node* opd2;\n+  if (Matcher::vectortest_needs_second_argument(booltest == BoolTest::overflow,\n+                                                opd1->bottom_type()->isa_vectmask())) {\n+    opd2 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n+  } else {\n+    opd2 = opd1;\n+  }\n+  if (opd1 == nullptr || opd2 == nullptr) {\n@@ -1828,3 +1662,7 @@\n-  Node* test = new VectorTestNode(opd1, opd2, booltest);\n-  test = gvn().transform(test);\n-  set_result(test);\n+  Node* cmp = gvn().transform(new VectorTestNode(opd1, opd2, booltest));\n+  BoolTest::mask test = Matcher::vectortest_mask(booltest == BoolTest::overflow,\n+                                                 opd1->bottom_type()->isa_vectmask(), num_elem);\n+  Node* bol = gvn().transform(new BoolNode(cmp, test));\n+  Node* res = gvn().transform(new CMoveINode(bol, gvn().intcon(0), gvn().intcon(1), TypeInt::BOOL));\n+\n+  set_result(res);\n@@ -1849,1 +1687,1 @@\n-  if (mask_klass == NULL || vector_klass == NULL || elem_klass == NULL || vlen == NULL) {\n+  if (mask_klass == nullptr || vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr) {\n@@ -1852,2 +1690,2 @@\n-  if (mask_klass->const_oop() == NULL || vector_klass->const_oop() == NULL ||\n-      elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (mask_klass->const_oop() == nullptr || vector_klass->const_oop() == nullptr ||\n+      elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -1897,1 +1735,1 @@\n-  if (v1 == NULL || v2 == NULL || mask == NULL) {\n+  if (v1 == nullptr || v2 == nullptr || mask == nullptr) {\n@@ -1923,1 +1761,1 @@\n-  if (cond == NULL || vector_klass == NULL || mask_klass == NULL || elem_klass == NULL || vlen == NULL) {\n+  if (cond == nullptr || vector_klass == nullptr || mask_klass == nullptr || elem_klass == nullptr || vlen == nullptr) {\n@@ -1926,2 +1764,2 @@\n-  if (!cond->is_con() || vector_klass->const_oop() == NULL || mask_klass->const_oop() == NULL ||\n-      elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (!cond->is_con() || vector_klass->const_oop() == nullptr || mask_klass->const_oop() == nullptr ||\n+      elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -1984,2 +1822,2 @@\n-  Node* mask = is_masked_op ? unbox_vector(argument(7), mbox_type, elem_bt, num_elem) : NULL;\n-  if (is_masked_op && mask == NULL) {\n+  Node* mask = is_masked_op ? unbox_vector(argument(7), mbox_type, elem_bt, num_elem) : nullptr;\n+  if (is_masked_op && mask == nullptr) {\n@@ -2002,1 +1840,1 @@\n-  if (v1 == NULL || v2 == NULL) {\n+  if (v1 == nullptr || v2 == nullptr) {\n@@ -2044,1 +1882,1 @@\n-  if (vector_klass == NULL  || shuffle_klass == NULL ||  elem_klass == NULL || vlen == NULL) {\n+  if (vector_klass == nullptr  || shuffle_klass == nullptr ||  elem_klass == nullptr || vlen == nullptr) {\n@@ -2047,3 +1885,3 @@\n-  if (shuffle_klass->const_oop() == NULL ||\n-      vector_klass->const_oop()  == NULL ||\n-      elem_klass->const_oop()    == NULL ||\n+  if (shuffle_klass->const_oop() == nullptr ||\n+      vector_klass->const_oop()  == nullptr ||\n+      elem_klass->const_oop()    == nullptr ||\n@@ -2074,0 +1912,1 @@\n+\n@@ -2075,0 +1914,7 @@\n+  BasicType shuffle_bt = elem_bt;\n+  if (shuffle_bt == T_FLOAT) {\n+    shuffle_bt = T_INT;\n+  } else if (shuffle_bt == T_DOUBLE) {\n+    shuffle_bt = T_LONG;\n+  }\n+\n@@ -2076,0 +1922,1 @@\n+  bool need_load_shuffle = Matcher::vector_needs_load_shuffle(shuffle_bt, num_elem);\n@@ -2077,1 +1924,1 @@\n-  if (!arch_supports_vector(Op_VectorLoadShuffle, num_elem, elem_bt, VecMaskNotUsed)) {\n+  if (need_load_shuffle && !arch_supports_vector(Op_VectorLoadShuffle, num_elem, shuffle_bt, VecMaskNotUsed)) {\n@@ -2080,1 +1927,1 @@\n-                    num_elem, type2name(elem_bt));\n+                    num_elem, type2name(shuffle_bt));\n@@ -2088,2 +1935,2 @@\n-      (mask_klass == NULL ||\n-       mask_klass->const_oop() == NULL ||\n+      (mask_klass == nullptr ||\n+       mask_klass->const_oop() == nullptr ||\n@@ -2116,2 +1963,5 @@\n-  Node* shuffle = unbox_vector(argument(6), shbox_type, T_BYTE, num_elem);\n-  if (v1 == NULL || shuffle == NULL) {\n+  Node* shuffle = unbox_vector(argument(6), shbox_type, shuffle_bt, num_elem);\n+  const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+  const TypeVect* st = TypeVect::make(shuffle_bt, num_elem);\n+\n+  if (v1 == nullptr || shuffle == nullptr) {\n@@ -2121,1 +1971,1 @@\n-  Node* mask = NULL;\n+  Node* mask = nullptr;\n@@ -2126,1 +1976,1 @@\n-    if (mask == NULL) {\n+    if (mask == nullptr) {\n@@ -2135,1 +1985,4 @@\n-  shuffle = gvn().transform(new VectorLoadShuffleNode(shuffle, TypeVect::make(elem_bt, num_elem)));\n+  if (need_load_shuffle) {\n+    shuffle = gvn().transform(new VectorLoadShuffleNode(shuffle, st));\n+  }\n+\n@@ -2142,1 +1995,0 @@\n-      const TypeVect* vt = v1->bottom_type()->is_vect();\n@@ -2158,1 +2010,1 @@\n-  address addr = NULL;\n+  address addr = nullptr;\n@@ -2160,1 +2012,1 @@\n-  assert(name_ptr != NULL, \"unexpected\");\n+  assert(name_ptr != nullptr, \"unexpected\");\n@@ -2180,1 +2032,1 @@\n-      addr = NULL;\n+      addr = nullptr;\n@@ -2191,1 +2043,1 @@\n-  assert(opd1 != NULL, \"must not be null\");\n+  assert(opd1 != nullptr, \"must not be null\");\n@@ -2193,1 +2045,1 @@\n-  const TypeFunc* call_type = OptoRuntime::Math_Vector_Vector_Type(opd2 != NULL ? 2 : 1, vt, vt);\n+  const TypeFunc* call_type = OptoRuntime::Math_Vector_Vector_Type(opd2 != nullptr ? 2 : 1, vt, vt);\n@@ -2199,2 +2051,2 @@\n-  if (addr == NULL) {\n-    return NULL;\n+  if (addr == nullptr) {\n+    return nullptr;\n@@ -2203,1 +2055,1 @@\n-  assert(name != NULL, \"name must not be null\");\n+  assert(name[0] != '\\0', \"name must not be null\");\n@@ -2229,1 +2081,1 @@\n-  if (opr == NULL || vector_klass == NULL || elem_klass == NULL || vlen == NULL) {\n+  if (opr == nullptr || vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr) {\n@@ -2232,1 +2084,1 @@\n-  if (!opr->is_con() || vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (!opr->is_con() || vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n@@ -2252,1 +2104,1 @@\n-    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+    if (mask_klass == nullptr || mask_klass->const_oop() == nullptr) {\n@@ -2332,1 +2184,1 @@\n-  Node* opd2 = NULL;\n+  Node* opd2 = nullptr;\n@@ -2347,1 +2199,1 @@\n-  if (opd1 == NULL || opd2 == NULL) {\n+  if (opd1 == nullptr || opd2 == nullptr) {\n@@ -2351,1 +2203,1 @@\n-  Node* mask = NULL;\n+  Node* mask = nullptr;\n@@ -2356,1 +2208,1 @@\n-    if (mask == NULL) {\n+    if (mask == nullptr) {\n@@ -2365,1 +2217,1 @@\n-  if (is_masked_op && mask != NULL) {\n+  if (is_masked_op && mask != nullptr) {\n@@ -2401,3 +2253,3 @@\n-  if (opr == NULL ||\n-      vector_klass_from == NULL || elem_klass_from == NULL || vlen_from == NULL ||\n-      vector_klass_to   == NULL || elem_klass_to   == NULL || vlen_to   == NULL) {\n+  if (opr == nullptr ||\n+      vector_klass_from == nullptr || elem_klass_from == nullptr || vlen_from == nullptr ||\n+      vector_klass_to   == nullptr || elem_klass_to   == nullptr || vlen_to   == nullptr) {\n@@ -2407,2 +2259,2 @@\n-      vector_klass_from->const_oop() == NULL || elem_klass_from->const_oop() == NULL || !vlen_from->is_con() ||\n-      vector_klass_to->const_oop() == NULL || elem_klass_to->const_oop() == NULL || !vlen_to->is_con()) {\n+      vector_klass_from->const_oop() == nullptr || elem_klass_from->const_oop() == nullptr || !vlen_from->is_con() ||\n+      vector_klass_to->const_oop() == nullptr || elem_klass_to->const_oop() == nullptr || !vlen_to->is_con()) {\n@@ -2436,3 +2288,1 @@\n-  if (is_vector_shuffle(vbox_klass_from)) {\n-    return false; \/\/ vector shuffles aren't supported\n-  }\n+\n@@ -2492,1 +2342,1 @@\n-  if (opd1 == NULL) {\n+  if (opd1 == nullptr) {\n@@ -2505,2 +2355,2 @@\n-      ((src_type->isa_vectmask() == NULL && dst_type->isa_vectmask()) ||\n-       (dst_type->isa_vectmask() == NULL && src_type->isa_vectmask()))) {\n+      ((src_type->isa_vectmask() == nullptr && dst_type->isa_vectmask()) ||\n+       (dst_type->isa_vectmask() == nullptr && src_type->isa_vectmask()))) {\n@@ -2606,1 +2456,1 @@\n-  if (vector_klass == NULL || elem_klass == NULL || vlen == NULL || idx == NULL) {\n+  if (vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr || idx == nullptr) {\n@@ -2609,1 +2459,1 @@\n-  if (vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || !vlen->is_con() || !idx->is_con()) {\n+  if (vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || !vlen->is_con() || !idx->is_con()) {\n@@ -2646,1 +2496,1 @@\n-  if (opd == NULL) {\n+  if (opd == nullptr) {\n@@ -2651,1 +2501,1 @@\n-  assert(gvn().type(insert_val)->isa_long() != NULL, \"expected to be long\");\n+  assert(gvn().type(insert_val)->isa_long() != nullptr, \"expected to be long\");\n@@ -2699,1 +2549,1 @@\n-  if (vector_klass == NULL || elem_klass == NULL || vlen == NULL || idx == NULL) {\n+  if (vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr || idx == nullptr) {\n@@ -2702,1 +2552,1 @@\n-  if (vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || !vlen->is_con() || !idx->is_con()) {\n+  if (vector_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || !vlen->is_con() || !idx->is_con()) {\n@@ -2740,1 +2590,1 @@\n-  if (opd == NULL) {\n+  if (opd == nullptr) {\n@@ -2744,1 +2594,2 @@\n-  Node* operation = gvn().transform(ExtractNode::make(opd, idx->get_con(), elem_bt));\n+  ConINode* idx_con = gvn().intcon(idx->get_con())->as_ConI();\n+  Node* operation = gvn().transform(ExtractNode::make(opd, idx_con, elem_bt));\n@@ -2746,1 +2597,1 @@\n-  Node* bits = NULL;\n+  Node* bits = nullptr;\n@@ -2789,3 +2640,3 @@\n-  if (vector_klass == NULL || elem_klass == NULL || mask_klass == NULL || vlen == NULL ||\n-      vector_klass->const_oop() == NULL || mask_klass->const_oop() == NULL ||\n-      elem_klass->const_oop() == NULL || !vlen->is_con() || !opr->is_con()) {\n+  if (vector_klass == nullptr || elem_klass == nullptr || mask_klass == nullptr || vlen == nullptr ||\n+      vector_klass->const_oop() == nullptr || mask_klass->const_oop() == nullptr ||\n+      elem_klass->const_oop() == nullptr || !vlen->is_con() || !opr->is_con()) {\n@@ -2830,2 +2681,2 @@\n-  Node* opd1 = NULL;\n-  const TypeInstPtr* vbox_type = NULL;\n+  Node* opd1 = nullptr;\n+  const TypeInstPtr* vbox_type = nullptr;\n@@ -2836,1 +2687,1 @@\n-    if (opd1 == NULL) {\n+    if (opd1 == nullptr) {\n@@ -2850,1 +2701,1 @@\n-  if (mask == NULL) {\n+  if (mask == nullptr) {\n@@ -2882,3 +2733,3 @@\n-  if (vector_klass == NULL || elem_klass == NULL || vlen == NULL ||\n-      vector_klass->const_oop() == NULL || !vlen->is_con() ||\n-      elem_klass->const_oop() == NULL) {\n+  if (vector_klass == nullptr || elem_klass == nullptr || vlen == nullptr ||\n+      vector_klass->const_oop() == nullptr || !vlen->is_con() ||\n+      elem_klass->const_oop() == nullptr) {\n@@ -2954,1 +2805,1 @@\n-  if (opd == NULL) {\n+  if (opd == nullptr) {\n@@ -3020,0 +2871,128 @@\n+\n+\/\/ public static\n+\/\/ <E,\n+\/\/  M extends VectorMask<E>>\n+\/\/ M indexPartiallyInUpperRange(Class<? extends M> mClass, Class<E> eClass, int length,\n+\/\/                              long offset, long limit,\n+\/\/                              IndexPartiallyInUpperRangeOperation<E, M> defaultImpl)\n+bool LibraryCallKit::inline_index_partially_in_upper_range() {\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(0))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(1))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(2))->isa_int();\n+\n+  if (mask_klass == nullptr || elem_klass == nullptr || vlen == nullptr ||\n+      mask_klass->const_oop() == nullptr || elem_klass->const_oop() == nullptr || !vlen->is_con()) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** missing constant: mclass=%s etype=%s vlen=%s\",\n+                    NodeClassNames[argument(0)->Opcode()],\n+                    NodeClassNames[argument(1)->Opcode()],\n+                    NodeClassNames[argument(2)->Opcode()]);\n+    }\n+    return false; \/\/ not enough info for intrinsification\n+  }\n+\n+  if (!is_klass_initialized(mask_klass)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** klass argument not initialized\");\n+    }\n+    return false;\n+  }\n+\n+  ciType* elem_type = elem_klass->const_oop()->as_instance()->java_mirror_type();\n+  if (!elem_type->is_primitive_type()) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not a primitive bt=%d\", elem_type->basic_type());\n+    }\n+    return false; \/\/ should be primitive type\n+  }\n+\n+  int num_elem = vlen->get_con();\n+  BasicType elem_bt = elem_type->basic_type();\n+\n+  \/\/ Check whether the necessary ops are supported by current hardware.\n+  bool supports_mask_gen = arch_supports_vector(Op_VectorMaskGen, num_elem, elem_bt, VecMaskUseStore);\n+  if (!supports_mask_gen) {\n+    if (!arch_supports_vector(Op_VectorLoadConst, num_elem, elem_bt, VecMaskNotUsed) ||\n+        !arch_supports_vector(VectorNode::replicate_opcode(elem_bt), num_elem, elem_bt, VecMaskNotUsed) ||\n+        !arch_supports_vector(Op_VectorMaskCmp, num_elem, elem_bt, VecMaskUseStore)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: vlen=%d etype=%s\", num_elem, type2name(elem_bt));\n+      }\n+      return false; \/\/ not supported\n+    }\n+\n+    \/\/ Check whether the scalar cast operation is supported by current hardware.\n+    if (elem_bt != T_LONG) {\n+      int cast_op = is_integral_type(elem_bt) ? Op_ConvL2I\n+                                              : (elem_bt == T_FLOAT ? Op_ConvL2F : Op_ConvL2D);\n+      if (!Matcher::match_rule_supported(cast_op)) {\n+        if (C->print_intrinsics()) {\n+          tty->print_cr(\"  ** Rejected op (%s) because architecture does not support it\",\n+                        NodeClassNames[cast_op]);\n+        }\n+        return false; \/\/ not supported\n+      }\n+    }\n+  }\n+\n+  Node* offset = argument(3);\n+  Node* limit = argument(5);\n+  if (offset == nullptr || limit == nullptr) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** offset or limit argument is null\");\n+    }\n+    return false; \/\/ not supported\n+  }\n+\n+  ciKlass* box_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+  assert(is_vector_mask(box_klass), \"argument(0) should be a mask class\");\n+  const TypeInstPtr* box_type = TypeInstPtr::make_exact(TypePtr::NotNull, box_klass);\n+\n+  \/\/ We assume \"offset > 0 && limit >= offset && limit - offset < num_elem\".\n+  \/\/ So directly get indexLimit with \"indexLimit = limit - offset\".\n+  Node* indexLimit = gvn().transform(new SubLNode(limit, offset));\n+  Node* mask = nullptr;\n+  if (supports_mask_gen) {\n+    mask = gvn().transform(VectorMaskGenNode::make(indexLimit, elem_bt, num_elem));\n+  } else {\n+    \/\/ Generate the vector mask based on \"mask = iota < indexLimit\".\n+    \/\/ Broadcast \"indexLimit\" to a vector.\n+    switch (elem_bt) {\n+      case T_BOOLEAN: \/\/ fall-through\n+      case T_BYTE:    \/\/ fall-through\n+      case T_SHORT:   \/\/ fall-through\n+      case T_CHAR:    \/\/ fall-through\n+      case T_INT: {\n+        indexLimit = gvn().transform(new ConvL2INode(indexLimit));\n+        break;\n+      }\n+      case T_DOUBLE: {\n+        indexLimit = gvn().transform(new ConvL2DNode(indexLimit));\n+        break;\n+      }\n+      case T_FLOAT: {\n+        indexLimit = gvn().transform(new ConvL2FNode(indexLimit));\n+        break;\n+      }\n+      case T_LONG: {\n+        \/\/ no conversion needed\n+        break;\n+      }\n+      default: fatal(\"%s\", type2name(elem_bt));\n+    }\n+    indexLimit = gvn().transform(VectorNode::scalar2vector(indexLimit, num_elem, Type::get_const_basic_type(elem_bt)));\n+\n+    \/\/ Load the \"iota\" vector.\n+    const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+    Node* iota = gvn().transform(new VectorLoadConstNode(gvn().makecon(TypeInt::ZERO), vt));\n+\n+    \/\/ Compute the vector mask with \"mask = iota < indexLimit\".\n+    ConINode* pred_node = (ConINode*)gvn().makecon(TypeInt::make(BoolTest::lt));\n+    const TypeVect* vmask_type = TypeVect::makemask(elem_bt, num_elem);\n+    mask = gvn().transform(new VectorMaskCmpNode(BoolTest::lt, iota, indexLimit, pred_node, vmask_type));\n+  }\n+  Node* vbox = box_vector(mask, box_type, elem_bt, num_elem);\n+  set_result(vbox);\n+  C->set_max_vector_size(MAX2(C->max_vector_size(), (uint)(num_elem * type2aelembytes(elem_bt))));\n+  return true;\n+}\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":300,"deletions":321,"binary":false,"changes":621,"status":"modified"},{"patch":"@@ -38,1 +38,1 @@\n-\/\/ and vector length.\n+\/\/ and basic type.\n@@ -186,2 +186,1 @@\n-    \/\/ Not implemented. Returning 0 temporarily\n-    return 0;\n+    return (bt == T_INT || bt == T_LONG ? Op_CompressBitsV : 0);\n@@ -189,2 +188,1 @@\n-    \/\/ Not implemented. Returning 0 temporarily\n-    return 0;\n+    return (bt == T_INT || bt == T_LONG ? Op_ExpandBitsV : 0);\n@@ -280,0 +278,111 @@\n+\/\/ Return the scalar opcode for the specified vector opcode\n+\/\/ and basic type.\n+int VectorNode::scalar_opcode(int sopc, BasicType bt) {\n+  switch (sopc) {\n+    case Op_AddReductionVI:\n+    case Op_AddVI:\n+      return Op_AddI;\n+    case Op_AddReductionVL:\n+    case Op_AddVL:\n+      return Op_AddL;\n+    case Op_MulReductionVI:\n+    case Op_MulVI:\n+      return Op_MulI;\n+    case Op_MulReductionVL:\n+    case Op_MulVL:\n+      return Op_MulL;\n+    case Op_AndReductionV:\n+    case Op_AndV:\n+      switch (bt) {\n+        case T_BOOLEAN:\n+        case T_CHAR:\n+        case T_BYTE:\n+        case T_SHORT:\n+        case T_INT:\n+          return Op_AndI;\n+        case T_LONG:\n+          return Op_AndL;\n+        default:\n+          assert(false, \"basic type not handled\");\n+          return 0;\n+      }\n+    case Op_OrReductionV:\n+    case Op_OrV:\n+      switch (bt) {\n+        case T_BOOLEAN:\n+        case T_CHAR:\n+        case T_BYTE:\n+        case T_SHORT:\n+        case T_INT:\n+          return Op_OrI;\n+        case T_LONG:\n+          return Op_OrL;\n+        default:\n+          assert(false, \"basic type not handled\");\n+          return 0;\n+      }\n+    case Op_XorReductionV:\n+    case Op_XorV:\n+      switch (bt) {\n+        case T_BOOLEAN:\n+        case T_CHAR:\n+        case T_BYTE:\n+        case T_SHORT:\n+        case T_INT:\n+          return Op_XorI;\n+        case T_LONG:\n+          return Op_XorL;\n+        default:\n+          assert(false, \"basic type not handled\");\n+          return 0;\n+      }\n+    case Op_MinReductionV:\n+    case Op_MinV:\n+      switch (bt) {\n+        case T_BOOLEAN:\n+        case T_CHAR:\n+          assert(false, \"boolean and char are signed, not implemented for Min\");\n+          return 0;\n+        case T_BYTE:\n+        case T_SHORT:\n+        case T_INT:\n+          return Op_MinI;\n+        case T_LONG:\n+          return Op_MinL;\n+        case T_FLOAT:\n+          return Op_MinF;\n+        case T_DOUBLE:\n+          return Op_MinD;\n+        default:\n+          assert(false, \"basic type not handled\");\n+          return 0;\n+      }\n+    case Op_MaxReductionV:\n+    case Op_MaxV:\n+      switch (bt) {\n+        case T_BOOLEAN:\n+        case T_CHAR:\n+          assert(false, \"boolean and char are signed, not implemented for Max\");\n+          return 0;\n+        case T_BYTE:\n+        case T_SHORT:\n+        case T_INT:\n+          return Op_MaxI;\n+        case T_LONG:\n+          return Op_MaxL;\n+        case T_FLOAT:\n+          return Op_MaxF;\n+        case T_DOUBLE:\n+          return Op_MaxD;\n+        default:\n+          assert(false, \"basic type not handled\");\n+          return 0;\n+      }\n+    default:\n+      assert(false,\n+             \"Vector node %s is not handled in VectorNode::scalar_opcode\",\n+             NodeClassNames[sopc]);\n+      return 0; \/\/ Unimplemented\n+  }\n+}\n+\n@@ -302,3 +411,4 @@\n-bool VectorNode::vector_size_supported(BasicType bt, uint vlen) {\n-  return (Matcher::vector_size_supported(bt, vlen) &&\n-          (vlen * type2aelembytes(bt) <= (uint)SuperWordMaxVectorSize));\n+\/\/ Limits on vector size (number of elements) for auto-vectorization.\n+bool VectorNode::vector_size_supported_superword(const BasicType bt, int size) {\n+  return Matcher::superword_max_vector_size(bt) >= size &&\n+         Matcher::min_vector_size(bt) <= size;\n@@ -312,1 +422,1 @@\n-      vector_size_supported(bt, vlen)) {\n+      vector_size_supported_superword(bt, vlen)) {\n@@ -555,0 +665,1 @@\n+  case Op_RoundDoubleMode:\n@@ -558,0 +669,7 @@\n+  case Op_RotateLeft:\n+  case Op_RotateRight:\n+    \/\/ Rotate shift could have 1 or 2 vector operand(s), depending on\n+    \/\/ whether shift distance is a supported constant or not.\n+    *start = 1;\n+    *end   = (n->is_Con() && Matcher::supports_vector_constant_rotates(n->get_int())) ? 2 : 3;\n+    break;\n@@ -605,1 +723,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -697,1 +815,3 @@\n-  case Op_CompressM: assert(n1 == NULL, \"\"); return new CompressMNode(n2, vt);\n+  case Op_CompressM: assert(n1 == nullptr, \"\"); return new CompressMNode(n2, vt);\n+  case Op_CompressBitsV: return new CompressBitsVNode(n1, n2, vt);\n+  case Op_ExpandBitsV: return new ExpandBitsVNode(n1, n2, vt);\n@@ -702,1 +822,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -726,1 +846,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -766,1 +886,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -786,1 +906,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -898,1 +1018,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -901,1 +1021,1 @@\n-  Node* mask = NULL;\n+  Node* mask = nullptr;\n@@ -908,1 +1028,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -942,1 +1062,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -965,1 +1085,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1001,1 +1121,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -1093,3 +1213,2 @@\n-Node* ExtractNode::make(Node* v, uint position, BasicType bt) {\n-  assert((int)position < Matcher::max_vector_size(bt), \"pos in range\");\n-  ConINode* pos = ConINode::make((int)position);\n+Node* ExtractNode::make(Node* v, ConINode* pos, BasicType bt) {\n+  assert(pos->get_int() < Matcher::max_vector_size(bt), \"pos in range\");\n@@ -1107,1 +1226,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1288,1 +1407,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1297,1 +1416,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1364,1 +1483,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -1402,1 +1521,1 @@\n-      VectorNode::vector_size_supported(dst_type, vlen)) {\n+      VectorNode::vector_size_supported_superword(dst_type, vlen)) {\n@@ -1420,3 +1539,3 @@\n-Node* ReductionNode::make_reduction_input(PhaseGVN& gvn, int opc, BasicType bt) {\n-  int vopc = opcode(opc, bt);\n-  guarantee(vopc != opc, \"Vector reduction for '%s' is not implemented\", NodeClassNames[opc]);\n+Node* ReductionNode::make_identity_con_scalar(PhaseGVN& gvn, int sopc, BasicType bt) {\n+  int vopc = opcode(sopc, bt);\n+  guarantee(vopc != sopc, \"Vector reduction for '%s' is not implemented\", NodeClassNames[sopc]);\n@@ -1435,1 +1554,1 @@\n-          return NULL;\n+          return nullptr;\n@@ -1467,1 +1586,1 @@\n-          default: Unimplemented(); return NULL;\n+          default: Unimplemented(); return nullptr;\n@@ -1484,1 +1603,1 @@\n-          default: Unimplemented(); return NULL;\n+          default: Unimplemented(); return nullptr;\n@@ -1489,1 +1608,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -1496,1 +1615,1 @@\n-      VectorNode::vector_size_supported(bt, vlen)) {\n+      VectorNode::vector_size_supported_superword(bt, vlen)) {\n@@ -1534,2 +1653,2 @@\n-  Node* shiftRCnt = NULL;\n-  Node* shiftLCnt = NULL;\n+  Node* shiftRCnt = nullptr;\n+  Node* shiftLCnt = nullptr;\n@@ -1564,2 +1683,2 @@\n-    Node* shift_mask_node = NULL;\n-    Node* const_one_node = NULL;\n+    Node* shift_mask_node = nullptr;\n+    Node* const_one_node = nullptr;\n@@ -1613,1 +1732,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1623,1 +1742,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1722,1 +1841,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1730,1 +1849,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1750,1 +1869,1 @@\n-     if (dst_type->isa_vectmask() == NULL) {\n+     if (dst_type->isa_vectmask() == nullptr) {\n@@ -1752,1 +1871,1 @@\n-         return NULL;\n+         return nullptr;\n@@ -1758,1 +1877,1 @@\n-         ((src_type->isa_vectmask() == NULL && dst_type->isa_vectmask() == NULL) ||\n+         ((src_type->isa_vectmask() == nullptr && dst_type->isa_vectmask() == nullptr) ||\n@@ -1763,1 +1882,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1775,2 +1894,2 @@\n-      Node* const_minus_one = NULL;\n-      Node* const_one = NULL;\n+      Node* const_minus_one = nullptr;\n+      Node* const_one = nullptr;\n@@ -1800,1 +1919,1 @@\n-  Node* const_zero = NULL;\n+  Node* const_zero = nullptr;\n@@ -1826,1 +1945,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1975,1 +2094,1 @@\n-                                     bottom_type()->isa_vectmask() != NULL);\n+                                     bottom_type()->isa_vectmask() != nullptr);\n@@ -1977,1 +2096,1 @@\n-  return NULL;\n+  return nullptr;\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":174,"deletions":55,"binary":false,"changes":229,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"opto\/cfgnode.hpp\"\n@@ -29,0 +30,1 @@\n+#include \"opto\/loopnode.hpp\"\n@@ -94,1 +96,2 @@\n-  static int  opcode(int opc, BasicType bt);\n+  static int opcode(int sopc, BasicType bt);         \/\/ scalar_opc -> vector_opc\n+  static int scalar_opcode(int vopc, BasicType bt);  \/\/ vector_opc -> scalar_opc\n@@ -96,1 +99,3 @@\n-  static bool vector_size_supported(BasicType bt, uint vlen);\n+\n+  \/\/ Limits on vector size (number of elements) for auto-vectorization.\n+  static bool vector_size_supported_superword(const BasicType bt, int size);\n@@ -132,0 +137,9 @@\n+\n+  static void trace_new_vector(Node* n, const char* context) {\n+#ifdef ASSERT\n+    if (TraceNewVectors) {\n+      tty->print(\"TraceNewVectors [%s]: \", context);\n+      n->dump();\n+    }\n+#endif\n+  }\n@@ -193,1 +207,3 @@\n-               _vect_type(in2->bottom_type()->is_vect()) {}\n+               _vect_type(in2->bottom_type()->is_vect()) {\n+    init_class_id(Class_Reduction);\n+  }\n@@ -195,1 +211,1 @@\n-  static ReductionNode* make(int opc, Node *ctrl, Node* in1, Node* in2, BasicType bt);\n+  static ReductionNode* make(int opc, Node* ctrl, Node* in1, Node* in2, BasicType bt);\n@@ -198,1 +214,2 @@\n-  static Node* make_reduction_input(PhaseGVN& gvn, int opc, BasicType bt);\n+  \/\/ Make an identity scalar (zero for add, one for mul, etc) for scalar opc.\n+  static Node* make_identity_con_scalar(PhaseGVN& gvn, int sopc, BasicType bt);\n@@ -218,0 +235,9 @@\n+\/\/---------------------------UnorderedReductionNode-------------------------------------\n+\/\/ Order of reduction does not matter. Example int add. Not true for float add.\n+class UnorderedReductionNode : public ReductionNode {\n+public:\n+  UnorderedReductionNode(Node * ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {\n+    init_class_id(Class_UnorderedReduction);\n+  }\n+};\n+\n@@ -220,1 +246,1 @@\n-class AddReductionVINode : public ReductionNode {\n+class AddReductionVINode : public UnorderedReductionNode {\n@@ -222,1 +248,1 @@\n-  AddReductionVINode(Node * ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  AddReductionVINode(Node * ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n@@ -228,1 +254,1 @@\n-class AddReductionVLNode : public ReductionNode {\n+class AddReductionVLNode : public UnorderedReductionNode {\n@@ -230,1 +256,1 @@\n-  AddReductionVLNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  AddReductionVLNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n@@ -388,1 +414,1 @@\n-class MulReductionVINode : public ReductionNode {\n+class MulReductionVINode : public UnorderedReductionNode {\n@@ -390,1 +416,1 @@\n-  MulReductionVINode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  MulReductionVINode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n@@ -396,1 +422,1 @@\n-class MulReductionVLNode : public ReductionNode {\n+class MulReductionVLNode : public UnorderedReductionNode {\n@@ -398,1 +424,1 @@\n-  MulReductionVLNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  MulReductionVLNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n@@ -739,1 +765,1 @@\n-class AndReductionVNode : public ReductionNode {\n+class AndReductionVNode : public UnorderedReductionNode {\n@@ -741,1 +767,1 @@\n-  AndReductionVNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  AndReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n@@ -756,1 +782,1 @@\n-class OrReductionVNode : public ReductionNode {\n+class OrReductionVNode : public UnorderedReductionNode {\n@@ -758,9 +784,1 @@\n-  OrReductionVNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n-  virtual int Opcode() const;\n-};\n-\n-\/\/------------------------------XorReductionVNode--------------------------------------\n-\/\/ Vector and int, long as a reduction\n-class XorReductionVNode : public ReductionNode {\n- public:\n-  XorReductionVNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  OrReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n@@ -779,0 +797,8 @@\n+\/\/------------------------------XorReductionVNode--------------------------------------\n+\/\/ Vector and int, long as a reduction\n+class XorReductionVNode : public UnorderedReductionNode {\n+ public:\n+  XorReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  virtual int Opcode() const;\n+};\n+\n@@ -781,1 +807,1 @@\n-class MinReductionVNode : public ReductionNode {\n+class MinReductionVNode : public UnorderedReductionNode {\n@@ -783,1 +809,1 @@\n-  MinReductionVNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  MinReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n@@ -789,1 +815,1 @@\n-class MaxReductionVNode : public ReductionNode {\n+class MaxReductionVNode : public UnorderedReductionNode {\n@@ -791,1 +817,1 @@\n-  MaxReductionVNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  MaxReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n@@ -1274,1 +1300,1 @@\n-  ExtractNode(Node* src, ConINode* pos) : Node(NULL, src, (Node*)pos) {\n+  ExtractNode(Node* src, ConINode* pos) : Node(nullptr, src, (Node*)pos) {\n@@ -1280,1 +1306,1 @@\n-  static Node* make(Node* v, uint position, BasicType bt);\n+  static Node* make(Node* v, ConINode* pos, BasicType bt);\n@@ -1290,1 +1316,1 @@\n-  virtual const Type *bottom_type() const { return TypeInt::INT; }\n+  virtual const Type* bottom_type() const { return TypeInt::BYTE; }\n@@ -1300,1 +1326,1 @@\n-  virtual const Type *bottom_type() const { return TypeInt::INT; }\n+  virtual const Type* bottom_type() const { return TypeInt::UBYTE; }\n@@ -1426,1 +1452,1 @@\n-class VectorTestNode : public Node {\n+class VectorTestNode : public CmpNode {\n@@ -1434,1 +1460,1 @@\n-  VectorTestNode(Node* in1, Node* in2, BoolTest::mask predicate) : Node(NULL, in1, in2), _predicate(predicate) {\n+  VectorTestNode(Node* in1, Node* in2, BoolTest::mask predicate) : CmpNode(in1, in2), _predicate(predicate) {\n@@ -1439,0 +1465,4 @@\n+  virtual const Type* Value(PhaseGVN* phase) const { return TypeInt::CC; }\n+  virtual const Type* sub(const Type*, const Type*) const { return TypeInt::CC; }\n+  BoolTest::mask get_predicate() const { return _predicate; }\n+\n@@ -1442,4 +1472,0 @@\n-  virtual const Type *bottom_type() const { return TypeInt::BOOL; }\n-  virtual uint ideal_reg() const { return Op_RegI; }  \/\/ TODO Should be RegFlags but due to missing comparison flags for BoolTest\n-                                                      \/\/ in middle-end, we make it boolean result directly.\n-  BoolTest::mask get_predicate() const { return _predicate; }\n@@ -1476,3 +1502,1 @@\n-    : VectorNode(in, vt) {\n-    assert(in->bottom_type()->is_vect()->element_basic_type() == T_BYTE, \"must be BYTE\");\n-  }\n+    : VectorNode(in, vt) {}\n@@ -1480,1 +1504,0 @@\n-  int GetOutShuffleSize() const { return type2aelembytes(vect_type()->element_basic_type()); }\n@@ -1679,2 +1702,2 @@\n-  VectorBoxNode(Compile* C, ciInlineKlass* vk, Node* oop, const TypeInstPtr* box_type, const TypeVect* vt, bool null_free, bool is_buffered) :\n-    InlineTypeNode(vk, oop, null_free, is_buffered) {\n+  VectorBoxNode(Compile* C, ciInlineKlass* vk, Node* oop, const TypeInstPtr* box_type, const TypeVect* vt, bool null_free) :\n+    InlineTypeNode(vk, oop, null_free) {\n@@ -1691,0 +1714,2 @@\n+    VectorBoxNode* box_node = new VectorBoxNode(C, vk, box, box_type, vt, false);\n+\n@@ -1696,1 +1721,0 @@\n-    VectorBoxNode* box_node = new VectorBoxNode(C, vk, box, box_type, vt, false, vk->is_empty() && vk->is_initialized());\n@@ -1699,0 +1723,1 @@\n+\n@@ -1702,2 +1727,2 @@\n-  const  TypeInstPtr* box_type() const { assert(_box_type != NULL, \"\"); return _box_type; };\n-  const  TypeVect*    vec_type() const { assert(_vec_type != NULL, \"\"); return _vec_type; };\n+  const  TypeInstPtr* box_type() const { assert(_box_type != nullptr, \"\"); return _box_type; };\n+  const  TypeVect*    vec_type() const { assert(_vec_type != nullptr, \"\"); return _vec_type; };\n@@ -1721,1 +1746,1 @@\n-    : CallStaticJavaNode(C, VectorBoxNode::vec_box_type(vbox_type), NULL, NULL) {\n+    : CallStaticJavaNode(C, VectorBoxNode::vec_box_type(vbox_type), nullptr, nullptr) {\n@@ -1823,0 +1848,14 @@\n+class CompressBitsVNode : public VectorNode {\n+public:\n+  CompressBitsVNode(Node* in, Node* mask, const TypeVect* vt)\n+  : VectorNode(in, mask, vt) {}\n+  virtual int Opcode() const;\n+};\n+\n+class ExpandBitsVNode : public VectorNode {\n+public:\n+  ExpandBitsVNode(Node* in, Node* mask, const TypeVect* vt)\n+  : VectorNode(in, mask, vt) {}\n+  virtual int Opcode() const;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":88,"deletions":49,"binary":false,"changes":137,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -98,1 +99,1 @@\n-  assert(holder != NULL, \"sanity\");\n+  assert(holder != nullptr, \"sanity\");\n@@ -102,3 +103,1 @@\n-  if (is_vector_shuffle(ik)) {\n-    return T_BYTE;\n-  } else if (is_vector_mask(ik)) {\n+  if (is_vector_mask(ik)) {\n@@ -118,1 +117,1 @@\n-  assert(holder != NULL, \"sanity\");\n+  assert(holder != nullptr, \"sanity\");\n@@ -127,1 +126,1 @@\n-Handle VectorSupport::allocate_vector_payload_helper(InstanceKlass* ik, int num_elem, BasicType elem_bt, frame* fr, RegisterMap* reg_map, Location location, int larval, TRAPS) {\n+Handle VectorSupport::allocate_vector_payload_helper(InstanceKlass* ik, int num_elem, BasicType elem_bt, int larval, TRAPS) {\n@@ -137,21 +136,0 @@\n-\n-  int ffo = InlineKlass::cast(payload_kls)->first_field_offset();\n-  int elem_size = type2aelembytes(elem_bt);\n-\n-  if (location.is_register()) {\n-    \/\/ Value was in a callee-saved register.\n-    VMReg vreg = VMRegImpl::as_VMReg(location.register_number());\n-    int vec_size = num_elem * elem_size;\n-    for (int i = 0; i < vec_size; i++) {\n-      int vslot = i \/ VMRegImpl::stack_slot_size;\n-      int off   = i % VMRegImpl::stack_slot_size;\n-      address elem_addr = reg_map->location(vreg, vslot) + off; \/\/ assumes little endian element order\n-      obj->byte_field_put(ffo + i, *(jbyte*)elem_addr);\n-    }\n-  } else {\n-    \/\/ Value was directly saved on the stack.\n-    address base_addr = ((address)fr->unextended_sp()) + location.stack_offset();\n-    for (int i = 0; i < elem_size * num_elem; i++) {\n-      obj->byte_field_put(ffo + i, *(jbyte*)(base_addr + i));\n-    }\n-  }\n@@ -302,1 +280,0 @@\n-  ScopeValue* payload = ov->field_at(0);\n@@ -305,22 +282,2 @@\n-\n-  if (payload->is_location()) {\n-    Location location = payload->as_LocationValue()->location();\n-    if (location.type() == Location::vector) {\n-      \/\/ Vector payload value in an aligned adjacent tuple (8, 16, 32 or 64 bytes).\n-      return allocate_vector_payload_helper(ik, num_elem, elem_bt, fr, reg_map, location, larval, THREAD); \/\/ safepoint\n-    }\n-#ifdef ASSERT\n-    \/\/ Other payload values are: 'oop' type location and scalar-replaced boxed vector representation.\n-    \/\/ They will be processed in Deoptimization::reassign_fields() after all objects are reallocated.\n-    else {\n-      Location::Type loc_type = location.type();\n-      assert(loc_type == Location::oop || loc_type == Location::narrowoop,\n-             \"expected 'oop'(%d) or 'narrowoop'(%d) types location but got: %d\", Location::oop, Location::narrowoop, loc_type);\n-    }\n-  } else if (!payload->is_object() && !payload->is_constant_oop()) {\n-    stringStream ss;\n-    payload->print_on(&ss);\n-    assert(false, \"expected 'object' value for scalar-replaced boxed vector but got: %s\", ss.freeze());\n-#endif\n-  }\n-  return Handle(THREAD, nullptr);\n+  \/\/ Vector payload value in an aligned adjacent tuple (8, 16, 32 or 64 bytes).\n+  return allocate_vector_payload_helper(ik, num_elem, elem_bt, larval, THREAD); \/\/ safepoint\n@@ -331,1 +288,0 @@\n-  assert(ov->field_size() == 1, \"%s not a vector\", ik->name()->as_C_string());\n@@ -351,1 +307,0 @@\n-  assert(ov->field_size() == 1, \"%s not a vector\", ik->name()->as_C_string());\n@@ -357,0 +312,4 @@\n+\n+  InstanceKlass* payload_class = InstanceKlass::cast(payload_instance()->klass());\n+  Deoptimization::reassign_fields_by_klass(payload_class, fr, reg_map, ov, 0, payload_instance(), true, 0, CHECK_NULL);\n+\n","filename":"src\/hotspot\/share\/prims\/vectorSupport.cpp","additions":11,"deletions":52,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,1 +41,1 @@\n-  static Handle allocate_vector_payload_helper(InstanceKlass* ik, int num_elem, BasicType elem_bt, frame* fr, RegisterMap* reg_map, Location location, int larval, TRAPS);\n+  static Handle allocate_vector_payload_helper(InstanceKlass* ik, int num_elem, BasicType elem_bt, int larval, TRAPS);\n","filename":"src\/hotspot\/share\/prims\/vectorSupport.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,0 +46,1 @@\n+#include \"prims\/jvmtiAgentList.hpp\"\n@@ -67,0 +68,1 @@\n+#include \"utilities\/systemMemoryBarrier.hpp\"\n@@ -72,0 +74,1 @@\n+#include <string.h>\n@@ -73,1 +76,1 @@\n-#define DEFAULT_JAVA_LAUNCHER  \"generic\"\n+static const char _default_java_launcher[] = \"generic\";\n@@ -75,2 +78,4 @@\n-char*  Arguments::_jvm_flags_file               = NULL;\n-char** Arguments::_jvm_flags_array              = NULL;\n+#define DEFAULT_JAVA_LAUNCHER _default_java_launcher\n+\n+char*  Arguments::_jvm_flags_file               = nullptr;\n+char** Arguments::_jvm_flags_array              = nullptr;\n@@ -78,1 +83,1 @@\n-char** Arguments::_jvm_args_array               = NULL;\n+char** Arguments::_jvm_args_array               = nullptr;\n@@ -80,2 +85,2 @@\n-char*  Arguments::_java_command                 = NULL;\n-SystemProperty* Arguments::_system_properties   = NULL;\n+char*  Arguments::_java_command                 = nullptr;\n+SystemProperty* Arguments::_system_properties   = nullptr;\n@@ -84,2 +89,1 @@\n-bool   Arguments::_java_compiler                = false;\n-const char*  Arguments::_java_vendor_url_bug    = NULL;\n+const char*  Arguments::_java_vendor_url_bug    = nullptr;\n@@ -99,2 +103,3 @@\n-char*  Arguments::SharedArchivePath             = NULL;\n-char*  Arguments::SharedDynamicArchivePath      = NULL;\n+char*  Arguments::_default_shared_archive_path  = nullptr;\n+char*  Arguments::SharedArchivePath             = nullptr;\n+char*  Arguments::SharedDynamicArchivePath      = nullptr;\n@@ -104,3 +109,0 @@\n-AgentLibraryList Arguments::_libraryList;\n-AgentLibraryList Arguments::_agentList;\n-\n@@ -110,3 +112,3 @@\n-abort_hook_t     Arguments::_abort_hook         = NULL;\n-exit_hook_t      Arguments::_exit_hook          = NULL;\n-vfprintf_hook_t  Arguments::_vfprintf_hook      = NULL;\n+abort_hook_t     Arguments::_abort_hook         = nullptr;\n+exit_hook_t      Arguments::_exit_hook          = nullptr;\n+vfprintf_hook_t  Arguments::_vfprintf_hook      = nullptr;\n@@ -115,6 +117,6 @@\n-SystemProperty *Arguments::_sun_boot_library_path = NULL;\n-SystemProperty *Arguments::_java_library_path = NULL;\n-SystemProperty *Arguments::_java_home = NULL;\n-SystemProperty *Arguments::_java_class_path = NULL;\n-SystemProperty *Arguments::_jdk_boot_class_path_append = NULL;\n-SystemProperty *Arguments::_vm_info = NULL;\n+SystemProperty *Arguments::_sun_boot_library_path = nullptr;\n+SystemProperty *Arguments::_java_library_path = nullptr;\n+SystemProperty *Arguments::_java_home = nullptr;\n+SystemProperty *Arguments::_java_class_path = nullptr;\n+SystemProperty *Arguments::_jdk_boot_class_path_append = nullptr;\n+SystemProperty *Arguments::_vm_info = nullptr;\n@@ -122,2 +124,2 @@\n-GrowableArray<ModulePatchPath*> *Arguments::_patch_mod_prefix = NULL;\n-PathString *Arguments::_boot_class_path = NULL;\n+GrowableArray<ModulePatchPath*> *Arguments::_patch_mod_prefix = nullptr;\n+PathString *Arguments::_boot_class_path = nullptr;\n@@ -126,1 +128,1 @@\n-char* Arguments::_ext_dirs = NULL;\n+char* Arguments::_ext_dirs = nullptr;\n@@ -133,1 +135,1 @@\n-  if (new_value == NULL) {\n+  if (new_value == nullptr) {\n@@ -137,1 +139,1 @@\n-  if (_value != NULL) {\n+  if (_value != nullptr) {\n@@ -148,1 +150,1 @@\n-  if (value != NULL) {\n+  if (value != nullptr) {\n@@ -150,1 +152,1 @@\n-    if (_value != NULL) {\n+    if (_value != nullptr) {\n@@ -154,3 +156,3 @@\n-    assert(sp != NULL, \"Unable to allocate space for new append path value\");\n-    if (sp != NULL) {\n-      if (_value != NULL) {\n+    assert(sp != nullptr, \"Unable to allocate space for new append path value\");\n+    if (sp != nullptr) {\n+      if (_value != nullptr) {\n@@ -170,2 +172,2 @@\n-  if (value == NULL) {\n-    _value = NULL;\n+  if (value == nullptr) {\n+    _value = nullptr;\n@@ -179,1 +181,1 @@\n-  if (_value != NULL) {\n+  if (_value != nullptr) {\n@@ -181,1 +183,1 @@\n-    _value = NULL;\n+    _value = nullptr;\n@@ -186,1 +188,1 @@\n-  assert(module_name != NULL && path != NULL, \"Invalid module name or path value\");\n+  assert(module_name != nullptr && path != nullptr, \"Invalid module name or path value\");\n@@ -194,1 +196,1 @@\n-  if (_module_name != NULL) {\n+  if (_module_name != nullptr) {\n@@ -196,1 +198,1 @@\n-    _module_name = NULL;\n+    _module_name = nullptr;\n@@ -198,1 +200,1 @@\n-  if (_path != NULL) {\n+  if (_path != nullptr) {\n@@ -200,1 +202,1 @@\n-    _path = NULL;\n+    _path = nullptr;\n@@ -205,2 +207,2 @@\n-  if (key == NULL) {\n-    _key = NULL;\n+  if (key == nullptr) {\n+    _key = nullptr;\n@@ -211,1 +213,1 @@\n-  _next = NULL;\n+  _next = nullptr;\n@@ -216,19 +218,0 @@\n-AgentLibrary::AgentLibrary(const char* name, const char* options,\n-               bool is_absolute_path, void* os_lib,\n-               bool instrument_lib) {\n-  _name = AllocateHeap(strlen(name)+1, mtArguments);\n-  strcpy(_name, name);\n-  if (options == NULL) {\n-    _options = NULL;\n-  } else {\n-    _options = AllocateHeap(strlen(options)+1, mtArguments);\n-    strcpy(_options, options);\n-  }\n-  _is_absolute_path = is_absolute_path;\n-  _os_lib = os_lib;\n-  _next = NULL;\n-  _state = agent_invalid;\n-  _is_static_lib = false;\n-  _is_instrument_lib = instrument_lib;\n-}\n-\n@@ -250,1 +233,1 @@\n-  const char* tail = NULL;\n+  const char* tail = nullptr;\n@@ -252,1 +235,1 @@\n-  if (tail != NULL && *tail == '\\0') {\n+  if (tail != nullptr && *tail == '\\0') {\n@@ -264,1 +247,1 @@\n-  for (\/* empty *\/; *names != NULL; ++names) {\n+  for (\/* empty *\/; *names != nullptr; ++names) {\n@@ -279,2 +262,2 @@\n-  assert((*option)->optionString != NULL, \"invariant\");\n-  char* tail = NULL;\n+  assert((*option)->optionString != nullptr, \"invariant\");\n+  char* tail = nullptr;\n@@ -325,17 +308,0 @@\n-void Arguments::add_init_library(const char* name, char* options) {\n-  _libraryList.add(new AgentLibrary(name, options, false, NULL));\n-}\n-\n-void Arguments::add_init_agent(const char* name, char* options, bool absolute_path) {\n-  _agentList.add(new AgentLibrary(name, options, absolute_path, NULL));\n-}\n-\n-void Arguments::add_instrument_agent(const char* name, char* options, bool absolute_path) {\n-  _agentList.add(new AgentLibrary(name, options, absolute_path, NULL, true));\n-}\n-\n-\/\/ Late-binding agents not started via arguments\n-void Arguments::add_loaded_agent(AgentLibrary *agentLib) {\n-  _agentList.add(agentLib);\n-}\n-\n@@ -398,1 +364,1 @@\n-  _boot_class_path = new PathString(NULL);\n+  _boot_class_path = new PathString(nullptr);\n@@ -410,1 +376,1 @@\n-  \/\/ Properties values are set to NULL and they are\n+  \/\/ Properties values are set to nullptr and they are\n@@ -412,3 +378,3 @@\n-  _sun_boot_library_path = new SystemProperty(\"sun.boot.library.path\", NULL,  true);\n-  _java_library_path = new SystemProperty(\"java.library.path\", NULL,  true);\n-  _java_home =  new SystemProperty(\"java.home\", NULL,  true);\n+  _sun_boot_library_path = new SystemProperty(\"sun.boot.library.path\", nullptr,  true);\n+  _java_library_path = new SystemProperty(\"java.library.path\", nullptr,  true);\n+  _java_home =  new SystemProperty(\"java.home\", nullptr,  true);\n@@ -420,1 +386,1 @@\n-  _jdk_boot_class_path_append = new SystemProperty(\"jdk.boot.class.path.append\", NULL, false, true);\n+  _jdk_boot_class_path_append = new SystemProperty(\"jdk.boot.class.path.append\", nullptr, false, true);\n@@ -542,1 +508,0 @@\n-  { \"EnableWaitForParallelLoad\",    JDK_Version::jdk(20), JDK_Version::jdk(21), JDK_Version::jdk(22) },\n@@ -551,7 +516,1 @@\n-  { \"ExtendedDTraceProbes\",         JDK_Version::jdk(19), JDK_Version::jdk(20), JDK_Version::jdk(21) },\n-  { \"UseContainerCpuShares\",        JDK_Version::jdk(19), JDK_Version::jdk(20), JDK_Version::jdk(21) },\n-  { \"PreferContainerQuotaForCPUCount\", JDK_Version::jdk(19), JDK_Version::jdk(20), JDK_Version::jdk(21) },\n-  { \"AliasLevel\",                   JDK_Version::jdk(19), JDK_Version::jdk(20), JDK_Version::jdk(21) },\n-  { \"UseCodeAging\",                 JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(21) },\n-  { \"PrintSharedDictionary\",          JDK_Version::undefined(), JDK_Version::jdk(20), JDK_Version::jdk(21) },\n-\n+  { \"EnableWaitForParallelLoad\",    JDK_Version::jdk(20), JDK_Version::jdk(21), JDK_Version::jdk(22) },\n@@ -565,0 +524,6 @@\n+  { \"G1UsePreventiveGC\",            JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::jdk(22) },\n+  { \"G1ConcRSLogCacheSize\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n+  { \"G1ConcRSHotCardLimit\",         JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n+  { \"RefDiscoveryPolicy\",           JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n+  { \"MetaspaceReclaimPolicy\",       JDK_Version::undefined(), JDK_Version::jdk(21), JDK_Version::undefined() },\n+\n@@ -580,1 +545,1 @@\n-  { NULL, JDK_Version(0), JDK_Version(0) }\n+  { nullptr, JDK_Version(0), JDK_Version(0) }\n@@ -592,1 +557,1 @@\n-  { NULL, NULL}\n+  { nullptr, nullptr}\n@@ -606,1 +571,1 @@\n-  for (size_t i = 0; special_jvm_flags[i].name != NULL; i++) {\n+  for (size_t i = 0; special_jvm_flags[i].name != nullptr; i++) {\n@@ -616,1 +581,1 @@\n-  assert(version != NULL, \"Must provide a version buffer\");\n+  assert(version != nullptr, \"Must provide a version buffer\");\n@@ -627,1 +592,1 @@\n-        if (real_flag != NULL) {\n+        if (real_flag != nullptr) {\n@@ -642,1 +607,1 @@\n-  assert(version != NULL, \"Must provide a version buffer\");\n+  assert(version != nullptr, \"Must provide a version buffer\");\n@@ -659,1 +624,1 @@\n-  for (size_t i = 0; aliased_jvm_flags[i].alias_name != NULL; i++) {\n+  for (size_t i = 0; aliased_jvm_flags[i].alias_name != nullptr; i++) {\n@@ -670,1 +635,1 @@\n-  for (size_t i = 0; special_jvm_flags[i].name != NULL; i++) {\n+  for (size_t i = 0; special_jvm_flags[i].name != nullptr; i++) {\n@@ -699,1 +664,1 @@\n-  for (size_t i = 0; special_jvm_flags[i].name != NULL; i++) {\n+  for (size_t i = 0; special_jvm_flags[i].name != nullptr; i++) {\n@@ -732,1 +697,1 @@\n-        if (JVMFlag::find_declared_flag(flag.name) != NULL) {\n+        if (JVMFlag::find_declared_flag(flag.name) != nullptr) {\n@@ -747,1 +712,1 @@\n-        if (JVMFlag::find_declared_flag(flag.name) != NULL) {\n+        if (JVMFlag::find_declared_flag(flag.name) != nullptr) {\n@@ -856,1 +821,1 @@\n-    value = NULL;\n+    value = nullptr;\n@@ -867,1 +832,1 @@\n-  size_t old_len = old_value != NULL ? strlen(old_value) : 0;\n+  size_t old_len = old_value != nullptr ? strlen(old_value) : 0;\n@@ -870,1 +835,1 @@\n-  char* free_this_too = NULL;\n+  char* free_this_too = nullptr;\n@@ -904,1 +869,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -922,1 +887,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -931,1 +896,1 @@\n-      return NULL;\n+      return nullptr;\n@@ -940,2 +905,2 @@\n-  if (real_name == NULL) {\n-    return NULL;\n+  if (real_name == nullptr) {\n+    return nullptr;\n@@ -973,1 +938,1 @@\n-  if (flag == NULL) {\n+  if (flag == nullptr) {\n@@ -1010,1 +975,1 @@\n-  assert(bldarray != NULL, \"illegal argument\");\n+  assert(bldarray != nullptr, \"illegal argument\");\n@@ -1012,1 +977,1 @@\n-  if (arg == NULL) {\n+  if (arg == nullptr) {\n@@ -1019,1 +984,1 @@\n-  if (*bldarray == NULL) {\n+  if (*bldarray == nullptr) {\n@@ -1039,2 +1004,2 @@\n-  if (args == NULL || count == 0) {\n-    return NULL;\n+  if (args == nullptr || count == 0) {\n+    return nullptr;\n@@ -1044,1 +1009,1 @@\n-    length += strlen(args[i]) + 1; \/\/ add 1 for a space or NULL terminating character\n+    length += strlen(args[i]) + 1; \/\/ add 1 for a space or null terminating character\n@@ -1049,2 +1014,2 @@\n-    size_t offset = strlen(args[j]) + 1; \/\/ add 1 for a space or NULL terminating character\n-    jio_snprintf(dst, length, \"%s \", args[j]); \/\/ jio_snprintf will replace the last space character with NULL character\n+    size_t offset = strlen(args[j]) + 1; \/\/ add 1 for a space or null terminating character\n+    jio_snprintf(dst, length, \"%s \", args[j]); \/\/ jio_snprintf will replace the last space character with null character\n@@ -1068,1 +1033,1 @@\n-  if (_java_class_path != NULL) {\n+  if (_java_class_path != nullptr) {\n@@ -1097,1 +1062,1 @@\n-  if (java_command() != NULL) {\n+  if (java_command() != nullptr) {\n@@ -1134,1 +1099,1 @@\n-  if (equal_sign == NULL) {\n+  if (equal_sign == nullptr) {\n@@ -1156,1 +1121,1 @@\n-  if (found_flag != NULL) {\n+  if (found_flag != nullptr) {\n@@ -1187,1 +1152,1 @@\n-    if (fuzzy_matched != NULL) {\n+    if (fuzzy_matched != nullptr) {\n@@ -1202,1 +1167,1 @@\n-  if (stream == NULL) {\n+  if (stream == nullptr) {\n@@ -1276,1 +1241,1 @@\n-  if (eq == NULL) {\n+  if (eq == nullptr) {\n@@ -1306,2 +1271,8 @@\n-    process_java_compiler_argument(value);\n-    \/\/ Record value in Arguments, but let it get passed to Java.\n+    \/\/ we no longer support java.compiler system property, log a warning and let it get\n+    \/\/ passed to Java, like any other system property\n+    if (strlen(value) == 0 || strcasecmp(value, \"NONE\") == 0) {\n+        \/\/ for applications using NONE or empty value, log a more informative message\n+        warning(\"The java.compiler system property is obsolete and no longer supported, use -Xint\");\n+    } else {\n+        warning(\"The java.compiler system property is obsolete and no longer supported.\");\n+    }\n@@ -1320,1 +1291,1 @@\n-      if (old_java_command != NULL) {\n+      if (old_java_command != nullptr) {\n@@ -1333,1 +1304,1 @@\n-      if (old_java_vendor_url_bug != NULL) {\n+      if (old_java_vendor_url_bug != nullptr) {\n@@ -1365,1 +1336,1 @@\n-  while (sp != NULL) {\n+  while (sp != nullptr) {\n@@ -1384,1 +1355,1 @@\n-  if (ArchiveClassesAtExit != NULL) {\n+  if (ArchiveClassesAtExit != nullptr) {\n@@ -1392,1 +1363,1 @@\n-    if (get_property(unsupported_properties[i]) != NULL) {\n+    if (get_property(unsupported_properties[i]) != nullptr) {\n@@ -1412,1 +1383,0 @@\n-  set_java_compiler(false);\n@@ -1485,1 +1455,1 @@\n-  \/\/ We need to fit both the NULL page and the heap into the memory budget, while\n+  \/\/ We need to fit both the null page and the heap into the memory budget, while\n@@ -1487,1 +1457,1 @@\n-  \/\/ NULL page is located before the heap, we pad the NULL page to the conservative\n+  \/\/ null page is located before the heap, we pad the null page to the conservative\n@@ -1489,1 +1459,1 @@\n-  size_t displacement_due_to_null_page = align_up((size_t)os::vm_page_size(),\n+  size_t displacement_due_to_null_page = align_up(os::vm_page_size(),\n@@ -1511,3 +1481,0 @@\n-      if (COMPRESSED_CLASS_POINTERS_DEPENDS_ON_COMPRESSED_OOPS) {\n-        FLAG_SET_DEFAULT(UseCompressedClassPointers, false);\n-      }\n@@ -1519,3 +1486,0 @@\n-\n-\/\/ NOTE: set_use_compressed_klass_ptrs() must be called after calling\n-\/\/ set_use_compressed_oops().\n@@ -1524,25 +1488,2 @@\n-  \/\/ On some architectures, the use of UseCompressedClassPointers implies the use of\n-  \/\/ UseCompressedOops. The reason is that the rheap_base register of said platforms\n-  \/\/ is reused to perform some optimized spilling, in order to use rheap_base as a\n-  \/\/ temp register. But by treating it as any other temp register, spilling can typically\n-  \/\/ be completely avoided instead. So it is better not to perform this trick. And by\n-  \/\/ not having that reliance, large heaps, or heaps not supporting compressed oops,\n-  \/\/ can still use compressed class pointers.\n-  if (COMPRESSED_CLASS_POINTERS_DEPENDS_ON_COMPRESSED_OOPS && !UseCompressedOops) {\n-    if (UseCompressedClassPointers) {\n-      warning(\"UseCompressedClassPointers requires UseCompressedOops\");\n-    }\n-    FLAG_SET_DEFAULT(UseCompressedClassPointers, false);\n-  } else {\n-    \/\/ Turn on UseCompressedClassPointers too\n-    if (FLAG_IS_DEFAULT(UseCompressedClassPointers)) {\n-      FLAG_SET_ERGO(UseCompressedClassPointers, true);\n-    }\n-    \/\/ Check the CompressedClassSpaceSize to make sure we use compressed klass ptrs.\n-    if (UseCompressedClassPointers) {\n-      if (CompressedClassSpaceSize > KlassEncodingMetaspaceMax) {\n-        warning(\"CompressedClassSpaceSize is too large for UseCompressedClassPointers\");\n-        FLAG_SET_DEFAULT(UseCompressedClassPointers, false);\n-      }\n-    }\n-  }\n+  assert(!UseCompressedClassPointers || CompressedClassSpaceSize <= KlassEncodingMetaspaceMax,\n+         \"CompressedClassSpaceSize is too large for UseCompressedClassPointers\");\n@@ -1558,1 +1499,1 @@\n-                                          (size_t)os::vm_allocation_granularity(),\n+                                          os::vm_allocation_granularity(),\n@@ -1570,3 +1511,0 @@\n-\n-  \/\/ set_use_compressed_klass_ptrs() must be called after calling\n-  \/\/ set_use_compressed_oops().\n@@ -1711,3 +1649,0 @@\n-          if (COMPRESSED_CLASS_POINTERS_DEPENDS_ON_COMPRESSED_OOPS) {\n-            FLAG_SET_ERGO(UseCompressedClassPointers, false);\n-          }\n@@ -1902,10 +1837,0 @@\n-\/\/ Parsing of java.compiler property\n-\n-void Arguments::process_java_compiler_argument(const char* arg) {\n-  \/\/ For backwards compatibility, Djava.compiler=NONE or \"\"\n-  \/\/ causes us to switch to -Xint mode UNLESS -Xdebug\n-  \/\/ is also specified.\n-  if (strlen(arg) == 0 || strcasecmp(arg, \"NONE\") == 0) {\n-    set_java_compiler(true);    \/\/ \"-Djava.compiler[=...]\" most recently seen.\n-  }\n-}\n@@ -1914,0 +1839,3 @@\n+  if (_sun_java_launcher != _default_java_launcher) {\n+    os::free(const_cast<char*>(_sun_java_launcher));\n+  }\n@@ -1918,1 +1846,1 @@\n-  assert(_sun_java_launcher != NULL, \"property must have value\");\n+  assert(_sun_java_launcher != nullptr, \"property must have value\");\n@@ -1933,1 +1861,0 @@\n-unsigned int patch_mod_count = 0;\n@@ -1990,1 +1917,8 @@\n-#if !defined(X86) && !defined(AARCH64) && !defined(PPC64) && !defined(RISCV64)\n+\n+#if !defined(X86) && !defined(AARCH64) && !defined(RISCV64) && !defined(ARM)\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    FLAG_SET_CMDLINE(LockingMode, LM_LEGACY);\n+    warning(\"New lightweight locking not supported on this platform\");\n+  }\n+#endif\n+\n@@ -1992,0 +1926,10 @@\n+    if (FLAG_IS_CMDLINE(LockingMode) && LockingMode != LM_MONITOR) {\n+      jio_fprintf(defaultStream::error_stream(),\n+                  \"Conflicting -XX:+UseHeavyMonitors and -XX:LockingMode=%d flags\", LockingMode);\n+      return false;\n+    }\n+    FLAG_SET_CMDLINE(LockingMode, LM_MONITOR);\n+  }\n+\n+#if !defined(X86) && !defined(AARCH64) && !defined(PPC64) && !defined(RISCV64) && !defined(S390)\n+  if (LockingMode == LM_MONITOR) {\n@@ -1993,1 +1937,1 @@\n-                \"UseHeavyMonitors is not fully implemented on this architecture\");\n+                \"LockingMode == 0 (LM_MONITOR) is not fully implemented on this architecture\");\n@@ -1998,1 +1942,1 @@\n-  if (UseHeavyMonitors && UseRTMForStackLocks) {\n+  if (LockingMode == LM_MONITOR && UseRTMForStackLocks) {\n@@ -2000,1 +1944,1 @@\n-                \"-XX:+UseHeavyMonitors and -XX:+UseRTMForStackLocks are mutually exclusive\");\n+                \"LockingMode == 0 (LM_MONITOR) and -XX:+UseRTMForStackLocks are mutually exclusive\");\n@@ -2005,1 +1949,1 @@\n-  if (VerifyHeavyMonitors && !UseHeavyMonitors) {\n+  if (VerifyHeavyMonitors && LockingMode != LM_MONITOR) {\n@@ -2007,1 +1951,1 @@\n-                \"-XX:+VerifyHeavyMonitors requires -XX:+UseHeavyMonitors\");\n+                \"-XX:+VerifyHeavyMonitors requires LockingMode == 0 (LM_MONITOR)\");\n@@ -2010,1 +1954,0 @@\n-\n@@ -2019,1 +1962,1 @@\n-  if (option_type == NULL) {\n+  if (option_type == nullptr) {\n@@ -2110,2 +2053,0 @@\n-  bool patch_mod_javabase = false;\n-\n@@ -2125,1 +2066,1 @@\n-  jint result = parse_each_vm_init_arg(vm_options_args, &patch_mod_javabase, JVMFlagOrigin::JIMAGE_RESOURCE);\n+  jint result = parse_each_vm_init_arg(vm_options_args, JVMFlagOrigin::JIMAGE_RESOURCE);\n@@ -2132,1 +2073,1 @@\n-  result = parse_each_vm_init_arg(java_tool_options_args, &patch_mod_javabase, JVMFlagOrigin::ENVIRON_VAR);\n+  result = parse_each_vm_init_arg(java_tool_options_args, JVMFlagOrigin::ENVIRON_VAR);\n@@ -2138,1 +2079,1 @@\n-  result = parse_each_vm_init_arg(cmd_line_args, &patch_mod_javabase, JVMFlagOrigin::COMMAND_LINE);\n+  result = parse_each_vm_init_arg(cmd_line_args, JVMFlagOrigin::COMMAND_LINE);\n@@ -2145,1 +2086,1 @@\n-  result = parse_each_vm_init_arg(java_options_args, &patch_mod_javabase, JVMFlagOrigin::ENVIRON_VAR);\n+  result = parse_each_vm_init_arg(java_options_args, JVMFlagOrigin::ENVIRON_VAR);\n@@ -2150,0 +2091,5 @@\n+  \/\/ Disable CDS for exploded image\n+  if (!has_jimage()) {\n+    no_shared_spaces(\"CDS disabled on exploded JDK\");\n+  }\n+\n@@ -2158,0 +2104,2 @@\n+  SystemMemoryBarrier::initialize();\n+\n@@ -2159,1 +2107,1 @@\n-  result = finalize_vm_init_args(patch_mod_javabase);\n+  result = finalize_vm_init_args();\n@@ -2177,1 +2125,1 @@\n-    if ((_name = strrchr(name, (int) *os::file_separator())) == NULL) {\n+    if ((_name = strrchr(name, (int) *os::file_separator())) == nullptr) {\n@@ -2212,1 +2160,1 @@\n-int Arguments::process_patch_mod_option(const char* patch_mod_tail, bool* patch_mod_javabase) {\n+int Arguments::process_patch_mod_option(const char* patch_mod_tail) {\n@@ -2214,1 +2162,1 @@\n-  assert(patch_mod_tail != NULL, \"Unexpected NULL patch-module value\");\n+  assert(patch_mod_tail != nullptr, \"Unexpected null patch-module value\");\n@@ -2217,1 +2165,1 @@\n-  if (module_equal == NULL) {\n+  if (module_equal == nullptr) {\n@@ -2224,1 +2172,1 @@\n-    if (module_name != NULL) {\n+    if (module_name != nullptr) {\n@@ -2228,1 +2176,1 @@\n-      add_patch_mod_prefix(module_name, module_equal + 1, patch_mod_javabase);\n+      add_patch_mod_prefix(module_name, module_equal + 1, false \/* no append *\/);\n@@ -2230,3 +2178,0 @@\n-      if (!create_numbered_module_property(\"jdk.module.patch\", patch_mod_tail, patch_mod_count++)) {\n-        return JNI_ENOMEM;\n-      }\n@@ -2240,0 +2185,64 @@\n+\/\/ VALUECLASS_STR must match string used in the build\n+#define VALUECLASS_STR \"valueclasses\"\n+#define VALUECLASS_JAR \"-\" VALUECLASS_STR \".jar\"\n+\n+\/\/ Finalize --patch-module args and --enable-preview related to value class module patches.\n+\/\/ Create all numbered properties passing module patches.\n+int Arguments::finalize_patch_module() {\n+  \/\/ If --enable-preview and EnableValhalla is true, each module may have value classes that\n+  \/\/ are to be patched into the module.\n+  \/\/ For each <module>-valueclasses.jar in <JAVA_HOME>\/lib\/valueclasses\/\n+  \/\/ appends the equivalent of --patch-module <module>=<JAVA_HOME>\/lib\/valueclasses\/<module>-valueclasses.jar\n+  if (enable_preview() && EnableValhalla) {\n+    char * valueclasses_dir = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+    const char * fileSep = os::file_separator();\n+\n+    jio_snprintf(valueclasses_dir, JVM_MAXPATHLEN, \"%s%slib%s\" VALUECLASS_STR \"%s\",\n+                 Arguments::get_java_home(), fileSep, fileSep, fileSep);\n+    DIR* dir = os::opendir(valueclasses_dir);\n+    if (dir != nullptr) {\n+      char * module_name = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+      char * path = AllocateHeap(JVM_MAXPATHLEN, mtArguments);\n+\n+      for (dirent * entry = os::readdir(dir); entry != nullptr; entry = os::readdir(dir)) {\n+        \/\/ Test if file ends-with \"-valueclasses.jar\"\n+        int len = (int)strlen(entry->d_name) - (sizeof(VALUECLASS_JAR) - 1);\n+        if (len <= 0 || strcmp(&entry->d_name[len], VALUECLASS_JAR) != 0) {\n+          continue;         \/\/ too short or not the expected suffix\n+        }\n+\n+        strcpy(module_name, entry->d_name);\n+        module_name[len] = '\\0';     \/\/ truncate to just module-name\n+\n+        jio_snprintf(path, JVM_MAXPATHLEN, \"%s%s\", valueclasses_dir, &entry->d_name);\n+        add_patch_mod_prefix(module_name, path, true \/* append *\/);\n+        log_info(class)(\"--enable-preview appending value classes for module %s: %s\", module_name, entry->d_name);\n+      }\n+      FreeHeap(module_name);\n+      FreeHeap(path);\n+      os::closedir(dir);\n+    }\n+    FreeHeap(valueclasses_dir);\n+  }\n+\n+  \/\/ Create numbered properties for each module that has been patched either\n+  \/\/ by --patch-module or --enable-preview\n+  \/\/ Format is \"jdk.module.patch.<n>=<module_name>=<path>\"\n+  if (_patch_mod_prefix != nullptr) {\n+    char * prop_value = AllocateHeap(JVM_MAXPATHLEN + JVM_MAXPATHLEN + 1, mtArguments);\n+    unsigned int patch_mod_count = 0;\n+\n+    for (GrowableArrayIterator<ModulePatchPath *> it = _patch_mod_prefix->begin();\n+            it != _patch_mod_prefix->end(); ++it) {\n+      jio_snprintf(prop_value, JVM_MAXPATHLEN + JVM_MAXPATHLEN + 1, \"%s=%s\",\n+                   (*it)->module_name(), (*it)->path_string());\n+      if (!create_numbered_module_property(\"jdk.module.patch\", prop_value, patch_mod_count++)) {\n+        FreeHeap(prop_value);\n+        return JNI_ENOMEM;\n+      }\n+    }\n+    FreeHeap(prop_value);\n+  }\n+  return JNI_OK;\n+}\n+\n@@ -2263,1 +2272,1 @@\n-    bool silent = (option == NULL); \/\/ Allow testing to silence error messages\n+    bool silent = (option == nullptr); \/\/ Allow testing to silence error messages\n@@ -2295,1 +2304,1 @@\n-  return strstr(\"jdk.incubator.vector\", prop_value);\n+  return strstr(prop_value, \"jdk.incubator.vector\");\n@@ -2298,1 +2307,1 @@\n-jint Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, bool* patch_mod_javabase, JVMFlagOrigin origin) {\n+jint Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, JVMFlagOrigin origin) {\n@@ -2369,1 +2378,1 @@\n-      if (tail != NULL) {\n+      if (tail != nullptr) {\n@@ -2371,1 +2380,1 @@\n-        size_t len = (pos == NULL) ? strlen(tail) : pos - tail;\n+        size_t len = (pos == nullptr) ? strlen(tail) : pos - tail;\n@@ -2375,2 +2384,2 @@\n-        char *options = NULL;\n-        if(pos != NULL) {\n+        char *options = nullptr;\n+        if(pos != nullptr) {\n@@ -2387,1 +2396,3 @@\n-        add_init_library(name, options);\n+        JvmtiAgentList::add_xrun(name, options, false);\n+        FREE_C_HEAP_ARRAY(char, name);\n+        FREE_C_HEAP_ARRAY(char, options);\n@@ -2426,1 +2437,1 @@\n-      int res = process_patch_mod_option(tail, patch_mod_javabase);\n+      int res = process_patch_mod_option(tail);\n@@ -2437,1 +2448,1 @@\n-      if(tail != NULL) {\n+      if(tail != nullptr) {\n@@ -2440,1 +2451,1 @@\n-        if (pos == NULL) {\n+        if (pos == nullptr) {\n@@ -2449,2 +2460,2 @@\n-        char *options = NULL;\n-        if(pos != NULL) {\n+        char *options = nullptr;\n+        if(pos != nullptr) {\n@@ -2460,1 +2471,3 @@\n-        add_init_agent(name, options, is_absolute_path);\n+        JvmtiAgentList::add(name, options, is_absolute_path);\n+        os::free(name);\n+        os::free(options);\n@@ -2469,1 +2482,1 @@\n-      if (tail != NULL) {\n+      if (tail != nullptr) {\n@@ -2473,1 +2486,3 @@\n-        add_instrument_agent(\"instrument\", options, false);\n+        JvmtiAgentList::add(\"instrument\", options, false);\n+        FREE_C_HEAP_ARRAY(char, options);\n+\n@@ -2904,1 +2919,1 @@\n-      if (jvmciFlag != NULL && jvmciFlag->is_unlocked()) {\n+      if (jvmciFlag != nullptr && jvmciFlag->is_unlocked()) {\n@@ -2955,12 +2970,3 @@\n-void Arguments::add_patch_mod_prefix(const char* module_name, const char* path, bool* patch_mod_javabase) {\n-  \/\/ For java.base check for duplicate --patch-module options being specified on the command line.\n-  \/\/ This check is only required for java.base, all other duplicate module specifications\n-  \/\/ will be checked during module system initialization.  The module system initialization\n-  \/\/ will throw an ExceptionInInitializerError if this situation occurs.\n-  if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n-    if (*patch_mod_javabase) {\n-      vm_exit_during_initialization(\"Cannot specify \" JAVA_BASE_NAME \" more than once to --patch-module\");\n-    } else {\n-      *patch_mod_javabase = true;\n-    }\n-  }\n+bool match_module(void *module_name, ModulePatchPath *patch) {\n+  return (strcmp((char *)module_name, patch->module_name()) == 0);\n+}\n@@ -2968,0 +2974,5 @@\n+bool Arguments::patch_mod_javabase() {\n+    return _patch_mod_prefix != nullptr && _patch_mod_prefix->find((void*)JAVA_BASE_NAME, match_module) >= 0;\n+}\n+\n+void Arguments::add_patch_mod_prefix(const char* module_name, const char* path, bool allow_append) {\n@@ -2969,1 +2980,1 @@\n-  if (_patch_mod_prefix == NULL) {\n+  if (_patch_mod_prefix == nullptr) {\n@@ -2973,1 +2984,16 @@\n-  _patch_mod_prefix->push(new ModulePatchPath(module_name, path));\n+  \/\/ Scan patches for matching module\n+  int i = _patch_mod_prefix->find((void*)module_name, match_module);\n+  if (i == -1) {\n+    _patch_mod_prefix->push(new ModulePatchPath(module_name, path));\n+  } else {\n+    if (allow_append) {\n+      \/\/ append path to existing module entry\n+      _patch_mod_prefix->at(i)->append_path(path);\n+    } else {\n+      if (strcmp(module_name, JAVA_BASE_NAME) == 0) {\n+        vm_exit_during_initialization(\"Cannot specify \" JAVA_BASE_NAME \" more than once to --patch-module\");\n+      } else {\n+        vm_exit_during_initialization(\"Cannot specify a module more than once to --patch-module\", module_name);\n+      }\n+    }\n+  }\n@@ -3016,1 +3042,1 @@\n-jint Arguments::finalize_vm_init_args(bool patch_mod_javabase) {\n+jint Arguments::finalize_vm_init_args() {\n@@ -3023,1 +3049,1 @@\n-  if (dir != NULL) {\n+  if (dir != nullptr) {\n@@ -3033,1 +3059,1 @@\n-  if (dir != NULL) {\n+  if (dir != nullptr) {\n@@ -3051,9 +3077,0 @@\n-  \/\/ This must be done after all arguments have been processed.\n-  \/\/ java_compiler() true means set to \"NONE\" or empty.\n-  if (java_compiler() && !xdebug_mode()) {\n-    \/\/ For backwards compatibility, we switch to interpreted mode if\n-    \/\/ -Djava.compiler=\"NONE\" or \"\" is specified AND \"-Xdebug\" was\n-    \/\/ not specified.\n-    set_mode_flags(_int);\n-  }\n-\n@@ -3099,0 +3116,5 @@\n+  \/\/ finalize --module-patch and related --enable-preview\n+  if (finalize_patch_module() != JNI_OK) {\n+    return JNI_ERR;\n+  }\n+\n@@ -3109,0 +3131,5 @@\n+\n+    \/\/ String deduplication may cause CDS to iterate the strings in different order from one\n+    \/\/ run to another which resulting in non-determinstic CDS archives.\n+    \/\/ Disable UseStringDeduplication while dumping CDS archive.\n+    UseStringDeduplication = false;\n@@ -3112,1 +3139,1 @@\n-  if (ArchiveClassesAtExit != NULL && RecordDynamicDumpInfo) {\n+  if (ArchiveClassesAtExit != nullptr && RecordDynamicDumpInfo) {\n@@ -3118,1 +3145,1 @@\n-  if (ArchiveClassesAtExit == NULL && !RecordDynamicDumpInfo) {\n+  if (ArchiveClassesAtExit == nullptr && !RecordDynamicDumpInfo) {\n@@ -3125,1 +3152,1 @@\n-    if (SharedArchiveFile == NULL) {\n+    if (SharedArchiveFile == nullptr) {\n@@ -3129,1 +3156,1 @@\n-    if (ArchiveClassesAtExit != NULL) {\n+    if (ArchiveClassesAtExit != nullptr) {\n@@ -3135,1 +3162,1 @@\n-  if (UseSharedSpaces && patch_mod_javabase) {\n+  if (UseSharedSpaces && patch_mod_javabase()) {\n@@ -3172,1 +3199,1 @@\n-    _args.options = NULL;\n+    _args.options = nullptr;\n@@ -3176,1 +3203,1 @@\n-    _vm_options_file_arg = NULL;\n+    _vm_options_file_arg = nullptr;\n@@ -3188,1 +3215,1 @@\n-    if (options_arr == NULL) {\n+    if (options_arr == nullptr) {\n@@ -3196,1 +3223,1 @@\n-      if (options_arr[i].optionString == NULL) {\n+      if (options_arr[i].optionString == nullptr) {\n@@ -3211,1 +3238,1 @@\n-  bool  found_vm_options_file_arg() { return _vm_options_file_arg != NULL; }\n+  bool  found_vm_options_file_arg() { return _vm_options_file_arg != nullptr; }\n@@ -3215,1 +3242,1 @@\n-    if (_vm_options_file_arg != NULL) {\n+    if (_vm_options_file_arg != nullptr) {\n@@ -3222,1 +3249,1 @@\n-    if (_vm_options_file_arg != NULL) {\n+    if (_vm_options_file_arg != nullptr) {\n@@ -3225,1 +3252,1 @@\n-    if (_args.options == NULL) return;\n+    if (_args.options == nullptr) return;\n@@ -3237,1 +3264,1 @@\n-    assert(_args.options == NULL, \"shouldn't be set yet\");\n+    assert(_args.options == nullptr, \"shouldn't be set yet\");\n@@ -3274,1 +3301,1 @@\n-  if (buffer == NULL || os::have_special_privileges()) {\n+  if (buffer == nullptr || os::have_special_privileges()) {\n@@ -3278,1 +3305,1 @@\n-  if ((buffer = os::strdup(buffer)) == NULL) {\n+  if ((buffer = os::strdup(buffer)) == nullptr) {\n@@ -3317,1 +3344,1 @@\n-  \/\/ '+ 1' for NULL termination even with max bytes\n+  \/\/ '+ 1' for null termination even with max bytes\n@@ -3321,1 +3348,1 @@\n-  if (NULL == buf) {\n+  if (nullptr == buf) {\n@@ -3401,1 +3428,1 @@\n-    \/\/ steal a white space character and set it to NULL\n+    \/\/ steal a white space character and set it to null\n@@ -3407,1 +3434,1 @@\n-    option.extraInfo = NULL;\n+    option.extraInfo = nullptr;\n@@ -3440,13 +3467,14 @@\n-  char *default_archive_path;\n-  char jvm_path[JVM_MAXPATHLEN];\n-  os::jvm_path(jvm_path, sizeof(jvm_path));\n-  char *end = strrchr(jvm_path, *os::file_separator());\n-  if (end != NULL) *end = '\\0';\n-  size_t jvm_path_len = strlen(jvm_path);\n-  size_t file_sep_len = strlen(os::file_separator());\n-  const size_t len = jvm_path_len + file_sep_len + 20;\n-  default_archive_path = NEW_C_HEAP_ARRAY(char, len, mtArguments);\n-  jio_snprintf(default_archive_path, len,\n-               LP64_ONLY(!UseCompressedOops ? \"%s%sclasses_nocoops.jsa\":) \"%s%sclasses.jsa\",\n-               jvm_path, os::file_separator());\n-  return default_archive_path;\n+  if (_default_shared_archive_path == nullptr) {\n+    char jvm_path[JVM_MAXPATHLEN];\n+    os::jvm_path(jvm_path, sizeof(jvm_path));\n+    char *end = strrchr(jvm_path, *os::file_separator());\n+    if (end != nullptr) *end = '\\0';\n+    size_t jvm_path_len = strlen(jvm_path);\n+    size_t file_sep_len = strlen(os::file_separator());\n+    const size_t len = jvm_path_len + file_sep_len + 20;\n+    _default_shared_archive_path = NEW_C_HEAP_ARRAY(char, len, mtArguments);\n+    jio_snprintf(_default_shared_archive_path, len,\n+                LP64_ONLY(!UseCompressedOops ? \"%s%sclasses_nocoops.jsa\":) \"%s%sclasses.jsa\",\n+                jvm_path, os::file_separator());\n+  }\n+  return _default_shared_archive_path;\n@@ -3456,1 +3484,1 @@\n-  if (archive_path == NULL) {\n+  if (archive_path == nullptr) {\n@@ -3475,1 +3503,1 @@\n-  if (end_ptr == NULL || end_ptr == begin_ptr) {\n+  if (end_ptr == nullptr || end_ptr == begin_ptr) {\n@@ -3489,1 +3517,1 @@\n-  assert(end_ptr != NULL, \"sanity\");\n+  assert(end_ptr != nullptr, \"sanity\");\n@@ -3504,1 +3532,1 @@\n-    if (os::same_files((const char*)get_default_shared_archive_path(), ArchiveClassesAtExit)) {\n+    if (os::same_files(get_default_shared_archive_path(), ArchiveClassesAtExit)) {\n@@ -3541,1 +3569,1 @@\n-        char* base_archive_path = NULL;\n+        char* base_archive_path = nullptr;\n@@ -3559,1 +3587,1 @@\n-        } else if (base_archive_path == NULL) {\n+        } else if (base_archive_path == nullptr) {\n@@ -3570,2 +3598,2 @@\n-        if (SharedArchivePath == NULL) {\n-          assert(SharedDynamicArchivePath == NULL, \"must be\");\n+        if (SharedArchivePath == nullptr) {\n+          assert(SharedDynamicArchivePath == nullptr, \"must be\");\n@@ -3604,1 +3632,1 @@\n-      PrintAssembly || TraceDeoptimization || TraceDependencies ||\n+      PrintAssembly || TraceDeoptimization ||\n@@ -3784,1 +3812,1 @@\n-    return LogConfiguration::parse_log_arguments(_legacyGCLogging.file, gc_conf, NULL, NULL, &errstream);\n+    return LogConfiguration::parse_log_arguments(_legacyGCLogging.file, gc_conf, nullptr, nullptr, &errstream);\n@@ -3856,1 +3884,1 @@\n-  if (vmoptions != NULL) {\n+  if (vmoptions != nullptr) {\n@@ -3893,1 +3921,1 @@\n-  settings_file_specified = (flags_file != NULL);\n+  settings_file_specified = (flags_file != nullptr);\n@@ -3991,1 +4019,1 @@\n-  if (DumpLoadedClassList != NULL) {\n+  if (DumpLoadedClassList != nullptr) {\n@@ -4009,1 +4037,1 @@\n-                \"Syntax error, expecting -XX:NativeMemoryTracking=[off|summary|detail]\", NULL);\n+                \"Syntax error, expecting -XX:NativeMemoryTracking=[off|summary|detail]\", nullptr);\n@@ -4017,4 +4045,3 @@\n-  if (TraceDependencies && VerifyDependencies) {\n-    if (!FLAG_IS_DEFAULT(TraceDependencies)) {\n-      warning(\"TraceDependencies results may be inflated by VerifyDependencies\");\n-    }\n+  bool trace_dependencies = log_is_enabled(Debug, dependencies);\n+  if (trace_dependencies && VerifyDependencies) {\n+    warning(\"dependency logging results may be inflated by VerifyDependencies\");\n@@ -4149,1 +4176,1 @@\n-  while(pl != NULL) {\n+  while(pl != nullptr) {\n@@ -4159,1 +4186,1 @@\n-  while(pl != NULL) {\n+  while(pl != nullptr) {\n@@ -4169,1 +4196,1 @@\n-  assert(key != NULL, \"just checking\");\n+  assert(key != nullptr, \"just checking\");\n@@ -4171,1 +4198,1 @@\n-  for (prop = pl; prop != NULL; prop = prop->next()) {\n+  for (prop = pl; prop != nullptr; prop = prop->next()) {\n@@ -4174,1 +4201,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4179,1 +4206,1 @@\n-  assert(key != NULL, \"just checking\");\n+  assert(key != nullptr, \"just checking\");\n@@ -4183,1 +4210,1 @@\n-  for (prop = pl; prop != NULL; prop = prop->next()) {\n+  for (prop = pl; prop != nullptr; prop = prop->next()) {\n@@ -4190,2 +4217,2 @@\n-        \/\/ Property is internal and not jdk.boot.class.path.append so return NULL.\n-        return NULL;\n+        \/\/ Property is internal and not jdk.boot.class.path.append so return null.\n+        return nullptr;\n@@ -4195,1 +4222,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -4200,1 +4227,1 @@\n-  if (p == NULL) {\n+  if (p == nullptr) {\n@@ -4203,1 +4230,1 @@\n-    while (p->next() != NULL) {\n+    while (p->next() != nullptr) {\n@@ -4212,1 +4239,1 @@\n-  if (plist == NULL)\n+  if (plist == nullptr)\n@@ -4227,1 +4254,1 @@\n-  if (plist == NULL)\n+  if (plist == nullptr)\n@@ -4233,1 +4260,1 @@\n-  for (prop = *plist; prop != NULL; prop = prop->next()) {\n+  for (prop = *plist; prop != nullptr; prop = prop->next()) {\n@@ -4252,1 +4279,1 @@\n-\/\/ NULL terminator character is not long enough for holding the expanded\n+\/\/ null terminator character is not long enough for holding the expanded\n@@ -4300,75 +4327,0 @@\n-\n-bool Arguments::parse_malloc_limit_size(const char* s, size_t* out) {\n-  julong limit = 0;\n-  Arguments::ArgsRange range = parse_memory_size(s, &limit, 1, SIZE_MAX);\n-  switch (range) {\n-  case ArgsRange::arg_in_range:\n-    *out = (size_t)limit;\n-    return true;\n-  case ArgsRange::arg_too_big: \/\/ only possible on 32-bit\n-    vm_exit_during_initialization(\"MallocLimit: too large\", s);\n-    break;\n-  case ArgsRange::arg_too_small:\n-    vm_exit_during_initialization(\"MallocLimit: limit must be > 0\");\n-    break;\n-  default:\n-    break;\n-  }\n-  return false;\n-}\n-\n-\/\/ Helper for parse_malloc_limits\n-void Arguments::parse_single_category_limit(char* expression, size_t limits[mt_number_of_types]) {\n-  \/\/ <category>:<limit>\n-  char* colon = ::strchr(expression, ':');\n-  if (colon == nullptr) {\n-    vm_exit_during_initialization(\"MallocLimit: colon missing\", expression);\n-  }\n-  *colon = '\\0';\n-  MEMFLAGS f = NMTUtil::string_to_flag(expression);\n-  if (f == mtNone) {\n-    vm_exit_during_initialization(\"MallocLimit: invalid nmt category\", expression);\n-  }\n-  if (parse_malloc_limit_size(colon + 1, limits + (int)f) == false) {\n-    vm_exit_during_initialization(\"Invalid MallocLimit size\", colon + 1);\n-  }\n-}\n-\n-void Arguments::parse_malloc_limits(size_t* total_limit, size_t limits[mt_number_of_types]) {\n-\n-  \/\/ Reset output to 0\n-  *total_limit = 0;\n-  for (int i = 0; i < mt_number_of_types; i ++) {\n-    limits[i] = 0;\n-  }\n-\n-  \/\/ We are done if the option is not given.\n-  if (MallocLimit == nullptr) {\n-    return;\n-  }\n-\n-  \/\/ Global form?\n-  if (parse_malloc_limit_size(MallocLimit, total_limit)) {\n-    return;\n-  }\n-\n-  \/\/ No. So it must be in category-specific form: MallocLimit=<nmt category>:<size>[,<nmt category>:<size> ..]\n-  char* copy = os::strdup(MallocLimit);\n-  if (copy == nullptr) {\n-    vm_exit_out_of_memory(strlen(MallocLimit), OOM_MALLOC_ERROR, \"MallocLimit\");\n-  }\n-\n-  char* p = copy, *q;\n-  do {\n-    q = p;\n-    p = ::strchr(q, ',');\n-    if (p != nullptr) {\n-      *p = '\\0';\n-      p ++;\n-    }\n-    parse_single_category_limit(q, limits);\n-  } while (p != nullptr);\n-\n-  os::free(copy);\n-\n-}\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":357,"deletions":405,"binary":false,"changes":762,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -58,1 +58,1 @@\n-    const char* file;        \/\/ NULL -> stdout\n+    const char* file;        \/\/ null -> stdout\n@@ -91,0 +91,1 @@\n+  inline void append_path(const char* path) { _path->append_value(path); }\n@@ -116,1 +117,1 @@\n-                          value() != NULL);\n+                          value() != nullptr);\n@@ -141,92 +142,0 @@\n-\n-\/\/ For use by -agentlib, -agentpath and -Xrun\n-class AgentLibrary : public CHeapObj<mtArguments> {\n-  friend class AgentLibraryList;\n-public:\n-  \/\/ Is this library valid or not. Don't rely on os_lib == NULL as statically\n-  \/\/ linked lib could have handle of RTLD_DEFAULT which == 0 on some platforms\n-  enum AgentState {\n-    agent_invalid = 0,\n-    agent_valid   = 1\n-  };\n-\n- private:\n-  char*           _name;\n-  char*           _options;\n-  void*           _os_lib;\n-  bool            _is_absolute_path;\n-  bool            _is_static_lib;\n-  bool            _is_instrument_lib;\n-  AgentState      _state;\n-  AgentLibrary*   _next;\n-\n- public:\n-  \/\/ Accessors\n-  const char* name() const                  { return _name; }\n-  char* options() const                     { return _options; }\n-  bool is_absolute_path() const             { return _is_absolute_path; }\n-  void* os_lib() const                      { return _os_lib; }\n-  void set_os_lib(void* os_lib)             { _os_lib = os_lib; }\n-  AgentLibrary* next() const                { return _next; }\n-  bool is_static_lib() const                { return _is_static_lib; }\n-  bool is_instrument_lib() const            { return _is_instrument_lib; }\n-  void set_static_lib(bool is_static_lib)   { _is_static_lib = is_static_lib; }\n-  bool valid()                              { return (_state == agent_valid); }\n-  void set_valid()                          { _state = agent_valid; }\n-\n-  \/\/ Constructor\n-  AgentLibrary(const char* name, const char* options, bool is_absolute_path,\n-               void* os_lib, bool instrument_lib=false);\n-};\n-\n-\/\/ maintain an order of entry list of AgentLibrary\n-class AgentLibraryList {\n- private:\n-  AgentLibrary*   _first;\n-  AgentLibrary*   _last;\n- public:\n-  bool is_empty() const                     { return _first == NULL; }\n-  AgentLibrary* first() const               { return _first; }\n-\n-  \/\/ add to the end of the list\n-  void add(AgentLibrary* lib) {\n-    if (is_empty()) {\n-      _first = _last = lib;\n-    } else {\n-      _last->_next = lib;\n-      _last = lib;\n-    }\n-    lib->_next = NULL;\n-  }\n-\n-  \/\/ search for and remove a library known to be in the list\n-  void remove(AgentLibrary* lib) {\n-    AgentLibrary* curr;\n-    AgentLibrary* prev = NULL;\n-    for (curr = first(); curr != NULL; prev = curr, curr = curr->next()) {\n-      if (curr == lib) {\n-        break;\n-      }\n-    }\n-    assert(curr != NULL, \"always should be found\");\n-\n-    if (curr != NULL) {\n-      \/\/ it was found, by-pass this library\n-      if (prev == NULL) {\n-        _first = curr->_next;\n-      } else {\n-        prev->_next = curr->_next;\n-      }\n-      if (curr == _last) {\n-        _last = prev;\n-      }\n-      curr->_next = NULL;\n-    }\n-  }\n-\n-  AgentLibraryList() {\n-    _first = NULL;\n-    _last = NULL;\n-  }\n-};\n-\n@@ -334,12 +243,0 @@\n-  \/\/ -Xrun arguments\n-  static AgentLibraryList _libraryList;\n-  static void add_init_library(const char* name, char* options);\n-\n-  \/\/ -agentlib and -agentpath arguments\n-  static AgentLibraryList _agentList;\n-  static void add_init_agent(const char* name, char* options, bool absolute_path);\n-  static void add_instrument_agent(const char* name, char* options, bool absolute_path);\n-\n-  \/\/ Late-binding agents not started via arguments\n-  static void add_loaded_agent(AgentLibrary *agentLib);\n-\n@@ -349,3 +246,0 @@\n-  static bool _java_compiler;\n-  static void set_java_compiler(bool arg) { _java_compiler = arg; }\n-  static bool java_compiler()   { return _java_compiler; }\n@@ -398,1 +292,1 @@\n-  static int process_patch_mod_option(const char* patch_mod_tail, bool* patch_mod_javabase);\n+  static int process_patch_mod_option(const char* patch_mod_tail);\n@@ -409,1 +303,0 @@\n-  static void process_java_compiler_argument(const char* arg);\n@@ -436,2 +329,2 @@\n-  static jint parse_each_vm_init_arg(const JavaVMInitArgs* args, bool* patch_mod_javabase, JVMFlagOrigin origin);\n-  static jint finalize_vm_init_args(bool patch_mod_javabase);\n+  static jint parse_each_vm_init_arg(const JavaVMInitArgs* args, JVMFlagOrigin origin);\n+  static jint finalize_vm_init_args();\n@@ -441,1 +334,1 @@\n-    return is_bad_option(option, ignore, NULL);\n+    return is_bad_option(option, ignore, nullptr);\n@@ -472,1 +365,1 @@\n-  \/\/ Return NULL if the arg has expired.\n+  \/\/ Return nullptr if the arg has expired.\n@@ -475,0 +368,1 @@\n+  static char*  _default_shared_archive_path;\n@@ -482,4 +376,0 @@\n-  \/\/ Helpers for parse_malloc_limits\n-  static bool parse_malloc_limit_size(const char* s, size_t* out);\n-  static void parse_single_category_limit(char* expression, size_t limits[mt_number_of_types]);\n-\n@@ -525,1 +415,1 @@\n-    if (_jvm_flags_file != NULL) {\n+    if (_jvm_flags_file != nullptr) {\n@@ -550,11 +440,0 @@\n-  \/\/ -Xrun\n-  static AgentLibrary* libraries()          { return _libraryList.first(); }\n-  static bool init_libraries_at_startup()   { return !_libraryList.is_empty(); }\n-  static void convert_library_to_agent(AgentLibrary* lib)\n-                                            { _libraryList.remove(lib);\n-                                              _agentList.add(lib); }\n-\n-  \/\/ -agentlib -agentpath\n-  static AgentLibrary* agents()             { return _agentList.first(); }\n-  static bool init_agents_at_startup()      { return !_agentList.is_empty(); }\n-\n@@ -605,1 +484,3 @@\n-  static void add_patch_mod_prefix(const char *module_name, const char *path, bool* patch_mod_javabase);\n+  static void add_patch_mod_prefix(const char *module_name, const char *path, bool allow_append);\n+  static bool patch_mod_javabase();\n+  static int finalize_patch_module();\n@@ -608,1 +489,1 @@\n-    assert(get_boot_class_path() == NULL, \"Boot class path previously set\");\n+    assert(get_boot_class_path() == nullptr, \"Boot class path previously set\");\n@@ -626,1 +507,1 @@\n-  static char* get_default_shared_archive_path() NOT_CDS_RETURN_(NULL);\n+  static char* get_default_shared_archive_path() NOT_CDS_RETURN_(nullptr);\n@@ -656,10 +537,0 @@\n-  \/\/ Parse diagnostic NMT switch \"MallocLimit\" and return the found limits.\n-  \/\/ 1) If option is not given, it will set all limits to 0 (aka \"no limit\").\n-  \/\/ 2) If option is given in the global form (-XX:MallocLimit=<size>), it\n-  \/\/    will return the size in *total_limit.\n-  \/\/ 3) If option is given in its per-NMT-category form (-XX:MallocLimit=<category>:<size>[,<category>:<size>]),\n-  \/\/    it will return all found limits in the limits array.\n-  \/\/ 4) If option is malformed, it will exit the VM.\n-  \/\/ For (2) and (3), limits not affected by the switch will be set to 0.\n-  static void parse_malloc_limits(size_t* total_limit, size_t limits[mt_number_of_types]);\n-\n@@ -681,5 +552,5 @@\n-\/\/ similar to UNSUPPORTED_OPTION but sets flag to NULL\n-#define UNSUPPORTED_OPTION_NULL(opt)                     \\\n-do {                                                     \\\n-  if (opt) {                                             \\\n-    if (FLAG_IS_CMDLINE(opt)) {                          \\\n+\/\/ similar to UNSUPPORTED_OPTION but sets flag to nullptr\n+#define UNSUPPORTED_OPTION_NULL(opt)                         \\\n+do {                                                         \\\n+  if (opt) {                                                 \\\n+    if (FLAG_IS_CMDLINE(opt)) {                              \\\n@@ -687,3 +558,3 @@\n-    }                                                    \\\n-    FLAG_SET_DEFAULT(opt, NULL);                         \\\n-  }                                                      \\\n+    }                                                        \\\n+    FLAG_SET_DEFAULT(opt, nullptr);                          \\\n+  }                                                          \\\n","filename":"src\/hotspot\/share\/runtime\/arguments.hpp","additions":24,"deletions":153,"binary":false,"changes":177,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -104,0 +104,115 @@\n+uint64_t DeoptimizationScope::_committed_deopt_gen = 0;\n+uint64_t DeoptimizationScope::_active_deopt_gen    = 1;\n+bool     DeoptimizationScope::_committing_in_progress = false;\n+\n+DeoptimizationScope::DeoptimizationScope() : _required_gen(0) {\n+  DEBUG_ONLY(_deopted = false;)\n+\n+  MutexLocker ml(CompiledMethod_lock, Mutex::_no_safepoint_check_flag);\n+  \/\/ If there is nothing to deopt _required_gen is the same as comitted.\n+  _required_gen = DeoptimizationScope::_committed_deopt_gen;\n+}\n+\n+DeoptimizationScope::~DeoptimizationScope() {\n+  assert(_deopted, \"Deopt not executed\");\n+}\n+\n+void DeoptimizationScope::mark(CompiledMethod* cm, bool inc_recompile_counts) {\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock,\n+                 Mutex::_no_safepoint_check_flag);\n+\n+  \/\/ If it's already marked but we still need it to be deopted.\n+  if (cm->is_marked_for_deoptimization()) {\n+    dependent(cm);\n+    return;\n+  }\n+\n+  CompiledMethod::DeoptimizationStatus status =\n+    inc_recompile_counts ? CompiledMethod::deoptimize : CompiledMethod::deoptimize_noupdate;\n+  Atomic::store(&cm->_deoptimization_status, status);\n+\n+  \/\/ Make sure active is not committed\n+  assert(DeoptimizationScope::_committed_deopt_gen < DeoptimizationScope::_active_deopt_gen, \"Must be\");\n+  assert(cm->_deoptimization_generation == 0, \"Is already marked\");\n+\n+  cm->_deoptimization_generation = DeoptimizationScope::_active_deopt_gen;\n+  _required_gen                  = DeoptimizationScope::_active_deopt_gen;\n+}\n+\n+void DeoptimizationScope::dependent(CompiledMethod* cm) {\n+  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock,\n+                 Mutex::_no_safepoint_check_flag);\n+  \/\/ A method marked by someone else may have a _required_gen lower than what we marked with.\n+  \/\/ Therefore only store it if it's higher than _required_gen.\n+  if (_required_gen < cm->_deoptimization_generation) {\n+    _required_gen = cm->_deoptimization_generation;\n+  }\n+}\n+\n+void DeoptimizationScope::deoptimize_marked() {\n+  assert(!_deopted, \"Already deopted\");\n+\n+  \/\/ We are not alive yet.\n+  if (!Universe::is_fully_initialized()) {\n+    DEBUG_ONLY(_deopted = true;)\n+    return;\n+  }\n+\n+  \/\/ Safepoints are a special case, handled here.\n+  if (SafepointSynchronize::is_at_safepoint()) {\n+    DeoptimizationScope::_committed_deopt_gen = DeoptimizationScope::_active_deopt_gen;\n+    DeoptimizationScope::_active_deopt_gen++;\n+    Deoptimization::deoptimize_all_marked();\n+    DEBUG_ONLY(_deopted = true;)\n+    return;\n+  }\n+\n+  uint64_t comitting = 0;\n+  bool wait = false;\n+  while (true) {\n+    {\n+      MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock,\n+                 Mutex::_no_safepoint_check_flag);\n+      \/\/ First we check if we or someone else already deopted the gen we want.\n+      if (DeoptimizationScope::_committed_deopt_gen >= _required_gen) {\n+        DEBUG_ONLY(_deopted = true;)\n+        return;\n+      }\n+      if (!_committing_in_progress) {\n+        \/\/ The version we are about to commit.\n+        comitting = DeoptimizationScope::_active_deopt_gen;\n+        \/\/ Make sure new marks use a higher gen.\n+        DeoptimizationScope::_active_deopt_gen++;\n+        _committing_in_progress = true;\n+        wait = false;\n+      } else {\n+        \/\/ Another thread is handshaking and committing a gen.\n+        wait = true;\n+      }\n+    }\n+    if (wait) {\n+      \/\/ Wait and let the concurrent handshake be performed.\n+      ThreadBlockInVM tbivm(JavaThread::current());\n+      os::naked_yield();\n+    } else {\n+      \/\/ Performs the handshake.\n+      Deoptimization::deoptimize_all_marked(); \/\/ May safepoint and an additional deopt may have occurred.\n+      DEBUG_ONLY(_deopted = true;)\n+      {\n+        MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock,\n+                       Mutex::_no_safepoint_check_flag);\n+        \/\/ Make sure that committed doesn't go backwards.\n+        \/\/ Should only happen if we did a deopt during a safepoint above.\n+        if (DeoptimizationScope::_committed_deopt_gen < comitting) {\n+          DeoptimizationScope::_committed_deopt_gen = comitting;\n+        }\n+        _committing_in_progress = false;\n+\n+        assert(DeoptimizationScope::_committed_deopt_gen >= _required_gen, \"Must be\");\n+\n+        return;\n+      }\n+    }\n+  }\n+}\n+\n@@ -218,1 +333,1 @@\n-  assert (chunk->at(0)->scope() != NULL,\"expect only compiled java frames\");\n+  assert (chunk->at(0)->scope() != nullptr,\"expect only compiled java frames\");\n@@ -240,1 +355,1 @@\n-  InlineKlass* vk = NULL;\n+  InlineKlass* vk = nullptr;\n@@ -243,1 +358,1 @@\n-    if (vk != NULL) {\n+    if (vk != nullptr) {\n@@ -260,1 +375,1 @@\n-  if (objects != NULL || vk != NULL) {\n+  if (objects != nullptr || vk != nullptr) {\n@@ -265,1 +380,1 @@\n-      if (vk != NULL) {\n+      if (vk != nullptr) {\n@@ -268,1 +383,1 @@\n-      if (objects != NULL) {\n+      if (objects != nullptr) {\n@@ -270,1 +385,1 @@\n-        bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n+        bool skip_internal = (compiled_method != nullptr) && !compiled_method->is_compiled_by_jvmci();\n@@ -277,1 +392,1 @@\n-      if (vk != NULL) {\n+      if (vk != nullptr) {\n@@ -280,1 +395,1 @@\n-      if (objects != NULL) {\n+      if (objects != nullptr) {\n@@ -282,1 +397,1 @@\n-        bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n+        bool skip_internal = (compiled_method != nullptr) && !compiled_method->is_compiled_by_jvmci();\n@@ -291,1 +406,1 @@\n-  if (save_oop_result || vk != NULL) {\n+  if (save_oop_result || vk != nullptr) {\n@@ -310,1 +425,1 @@\n-    assert (cvf->scope() != NULL,\"expect only compiled java frames\");\n+    assert (cvf->scope() != nullptr,\"expect only compiled java frames\");\n@@ -329,1 +444,1 @@\n-              if (monitor != NULL && monitor->object() == mi->owner()) {\n+              if (monitor != nullptr && monitor->object() == mi->owner()) {\n@@ -392,1 +507,1 @@\n-  assert(current->deopt_mark() == NULL, \"Pending deopt!\");\n+  assert(current->deopt_mark() == nullptr, \"Pending deopt!\");\n@@ -407,1 +522,1 @@\n-  assert(current->deopt_compiled_method() == NULL, \"Pending deopt!\");\n+  assert(current->deopt_compiled_method() == nullptr, \"Pending deopt!\");\n@@ -466,1 +581,1 @@\n-    guarantee(expressions != NULL && expressions->length() > 0, \"must have exception to throw\");\n+    guarantee(expressions != nullptr && expressions->length() > 0, \"must have exception to throw\");\n@@ -469,1 +584,1 @@\n-    guarantee(exceptionObject() != NULL, \"exception oop can not be null\");\n+    guarantee(exceptionObject() != nullptr, \"exception oop can not be null\");\n@@ -481,1 +596,1 @@\n-  assert(current->vframe_array_head() == NULL, \"Pending deopt!\");\n+  assert(current->vframe_array_head() == nullptr, \"Pending deopt!\");\n@@ -499,1 +614,1 @@\n-  if (deoptee_nm != NULL && deoptee_nm->is_method_handle_return(deoptee.pc()))\n+  if (deoptee_nm != nullptr && deoptee_nm->is_method_handle_return(deoptee.pc()))\n@@ -638,1 +753,1 @@\n-  assert(CodeCache::find_blob(frame_pcs[0]) != NULL, \"bad pc\");\n+  assert(CodeCache::find_blob(frame_pcs[0]) != nullptr, \"bad pc\");\n@@ -641,1 +756,1 @@\n-  if (exceptionObject() != NULL) {\n+  if (exceptionObject() != nullptr) {\n@@ -689,1 +804,1 @@\n-  if (array == NULL) {\n+  if (array == nullptr) {\n@@ -692,1 +807,1 @@\n-  thread->set_vframe_array_head(NULL);\n+  thread->set_vframe_array_head(nullptr);\n@@ -698,1 +813,1 @@\n-  if (old_array != NULL) {\n+  if (old_array != nullptr) {\n@@ -700,1 +815,1 @@\n-    old_array->set_unroll_block(NULL);\n+    old_array->set_unroll_block(nullptr);\n@@ -709,2 +824,2 @@\n-  thread->set_deopt_mark(NULL);\n-  thread->set_deopt_compiled_method(NULL);\n+  thread->set_deopt_mark(nullptr);\n+  thread->set_deopt_compiled_method(nullptr);\n@@ -789,1 +904,1 @@\n-  thread->frame_anchor()->set_last_Java_sp(NULL);\n+  thread->frame_anchor()->set_last_Java_sp(nullptr);\n@@ -949,1 +1064,1 @@\n-void Deoptimization::deoptimize_all_marked(nmethod* nmethod_only) {\n+void Deoptimization::deoptimize_all_marked() {\n@@ -953,7 +1068,1 @@\n-  if (nmethod_only != NULL) {\n-    nmethod_only->mark_for_deoptimization();\n-    nmethod_only->make_not_entrant();\n-    CodeCache::make_nmethod_deoptimized(nmethod_only);\n-  } else {\n-    CodeCache::make_marked_nmethods_deoptimized();\n-  }\n+  CodeCache::make_marked_nmethods_deoptimized();\n@@ -980,3 +1089,5 @@\n-    guarantee(ik != NULL, \"%s must be loaded\", klass_name_str);\n-    guarantee(ik->is_initialized(), \"%s must be initialized\", klass_name_str);\n-    CacheType::compute_offsets(ik);\n+    guarantee(ik != nullptr, \"%s must be loaded\", klass_name_str);\n+    if (!ik->is_in_error_state()) {\n+      guarantee(ik->is_initialized(), \"%s must be initialized\", klass_name_str);\n+      CacheType::compute_offsets(ik);\n+    }\n@@ -995,5 +1106,11 @@\n-    objArrayOop cache = CacheType::cache(ik);\n-    assert(cache->length() > 0, \"Empty cache\");\n-    _low = BoxType::value(cache->obj_at(0));\n-    _high = _low + cache->length() - 1;\n-    _cache = JNIHandles::make_global(Handle(thread, cache));\n+    if (ik->is_in_error_state()) {\n+      _low = 1;\n+      _high = 0;\n+      _cache = nullptr;\n+    } else {\n+      objArrayOop cache = CacheType::cache(ik);\n+      assert(cache->length() > 0, \"Empty cache\");\n+      _low = BoxType::value(cache->obj_at(0));\n+      _high = _low + cache->length() - 1;\n+      _cache = JNIHandles::make_global(Handle(thread, cache));\n+    }\n@@ -1006,1 +1123,1 @@\n-    if (_singleton == NULL) {\n+    if (_singleton == nullptr) {\n@@ -1019,1 +1136,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -1021,1 +1138,5 @@\n-  oop lookup_raw(intptr_t raw_value) {\n+  oop lookup_raw(intptr_t raw_value, bool& cache_init_error) {\n+    if (_cache == nullptr) {\n+      cache_init_error = true;\n+      return nullptr;\n+    }\n@@ -1038,5 +1159,5 @@\n-template<> BoxCache<jint, java_lang_Integer_IntegerCache, java_lang_Integer>* BoxCache<jint, java_lang_Integer_IntegerCache, java_lang_Integer>::_singleton = NULL;\n-template<> BoxCache<jlong, java_lang_Long_LongCache, java_lang_Long>* BoxCache<jlong, java_lang_Long_LongCache, java_lang_Long>::_singleton = NULL;\n-template<> BoxCache<jchar, java_lang_Character_CharacterCache, java_lang_Character>* BoxCache<jchar, java_lang_Character_CharacterCache, java_lang_Character>::_singleton = NULL;\n-template<> BoxCache<jshort, java_lang_Short_ShortCache, java_lang_Short>* BoxCache<jshort, java_lang_Short_ShortCache, java_lang_Short>::_singleton = NULL;\n-template<> BoxCache<jbyte, java_lang_Byte_ByteCache, java_lang_Byte>* BoxCache<jbyte, java_lang_Byte_ByteCache, java_lang_Byte>::_singleton = NULL;\n+template<> BoxCache<jint, java_lang_Integer_IntegerCache, java_lang_Integer>* BoxCache<jint, java_lang_Integer_IntegerCache, java_lang_Integer>::_singleton = nullptr;\n+template<> BoxCache<jlong, java_lang_Long_LongCache, java_lang_Long>* BoxCache<jlong, java_lang_Long_LongCache, java_lang_Long>::_singleton = nullptr;\n+template<> BoxCache<jchar, java_lang_Character_CharacterCache, java_lang_Character>* BoxCache<jchar, java_lang_Character_CharacterCache, java_lang_Character>::_singleton = nullptr;\n+template<> BoxCache<jshort, java_lang_Short_ShortCache, java_lang_Short>* BoxCache<jshort, java_lang_Short_ShortCache, java_lang_Short>::_singleton = nullptr;\n+template<> BoxCache<jbyte, java_lang_Byte_ByteCache, java_lang_Byte>* BoxCache<jbyte, java_lang_Byte_ByteCache, java_lang_Byte>::_singleton = nullptr;\n@@ -1051,2 +1172,7 @@\n-    _true_cache = JNIHandles::make_global(Handle(thread, java_lang_Boolean::get_TRUE(ik)));\n-    _false_cache = JNIHandles::make_global(Handle(thread, java_lang_Boolean::get_FALSE(ik)));\n+    if (ik->is_in_error_state()) {\n+      _true_cache = nullptr;\n+      _false_cache = nullptr;\n+    } else {\n+      _true_cache = JNIHandles::make_global(Handle(thread, java_lang_Boolean::get_TRUE(ik)));\n+      _false_cache = JNIHandles::make_global(Handle(thread, java_lang_Boolean::get_FALSE(ik)));\n+    }\n@@ -1060,1 +1186,1 @@\n-    if (_singleton == NULL) {\n+    if (_singleton == nullptr) {\n@@ -1068,1 +1194,5 @@\n-  oop lookup_raw(intptr_t raw_value) {\n+  oop lookup_raw(intptr_t raw_value, bool& cache_in_error) {\n+    if (_true_cache == nullptr) {\n+      cache_in_error = true;\n+      return nullptr;\n+    }\n@@ -1081,1 +1211,1 @@\n-BooleanBoxCache* BooleanBoxCache::_singleton = NULL;\n+BooleanBoxCache* BooleanBoxCache::_singleton = nullptr;\n@@ -1083,1 +1213,1 @@\n-oop Deoptimization::get_cached_box(AutoBoxObjectValue* bv, frame* fr, RegisterMap* reg_map, TRAPS) {\n+oop Deoptimization::get_cached_box(AutoBoxObjectValue* bv, frame* fr, RegisterMap* reg_map, bool& cache_init_error, TRAPS) {\n@@ -1089,6 +1219,6 @@\n-       case T_INT:     return IntegerBoxCache::singleton(THREAD)->lookup_raw(value->get_int());\n-       case T_CHAR:    return CharacterBoxCache::singleton(THREAD)->lookup_raw(value->get_int());\n-       case T_SHORT:   return ShortBoxCache::singleton(THREAD)->lookup_raw(value->get_int());\n-       case T_BYTE:    return ByteBoxCache::singleton(THREAD)->lookup_raw(value->get_int());\n-       case T_BOOLEAN: return BooleanBoxCache::singleton(THREAD)->lookup_raw(value->get_int());\n-       case T_LONG:    return LongBoxCache::singleton(THREAD)->lookup_raw(value->get_int());\n+       case T_INT:     return IntegerBoxCache::singleton(THREAD)->lookup_raw(value->get_int(), cache_init_error);\n+       case T_CHAR:    return CharacterBoxCache::singleton(THREAD)->lookup_raw(value->get_int(), cache_init_error);\n+       case T_SHORT:   return ShortBoxCache::singleton(THREAD)->lookup_raw(value->get_int(), cache_init_error);\n+       case T_BYTE:    return ByteBoxCache::singleton(THREAD)->lookup_raw(value->get_int(), cache_init_error);\n+       case T_BOOLEAN: return BooleanBoxCache::singleton(THREAD)->lookup_raw(value->get_int(), cache_init_error);\n+       case T_LONG:    return LongBoxCache::singleton(THREAD)->lookup_raw(value->get_int(), cache_init_error);\n@@ -1098,1 +1228,1 @@\n-   return NULL;\n+   return nullptr;\n@@ -1127,1 +1257,2 @@\n-    oop obj = NULL;\n+    oop obj = nullptr;\n+    bool cache_init_error = false;\n@@ -1133,2 +1264,2 @@\n-        obj = get_cached_box(abv, fr, reg_map, THREAD);\n-        if (obj != NULL) {\n+        obj = get_cached_box(abv, fr, reg_map, cache_init_error, THREAD);\n+        if (obj != nullptr) {\n@@ -1137,0 +1268,4 @@\n+        } else if (cache_init_error) {\n+          \/\/ Results in an OOME which is valid (as opposed to a class initialization error)\n+          \/\/ and is fine for the rare case a cache initialization failing.\n+          failures = true;\n@@ -1142,1 +1277,1 @@\n-      if (obj == NULL) {\n+      if (obj == nullptr && !cache_init_error) {\n@@ -1169,1 +1304,1 @@\n-    if (obj == NULL) {\n+    if (obj == nullptr) {\n@@ -1174,1 +1309,1 @@\n-    assert(obj != NULL || HAS_PENDING_EXCEPTION, \"allocation should succeed or we should get an exception\");\n+    assert(obj != nullptr || HAS_PENDING_EXCEPTION || cache_init_error, \"allocation should succeed or we should get an exception\");\n@@ -1194,1 +1329,1 @@\n-  if (new_vt == NULL) {\n+  if (new_vt == nullptr) {\n@@ -1376,0 +1511,1 @@\n+  int _secondary_fields_count;\n@@ -1380,1 +1516,2 @@\n-    _klass = NULL;\n+    _klass = nullptr;\n+    _secondary_fields_count = 0;\n@@ -1388,0 +1525,36 @@\n+static void init_multi_field(oop obj, int offset, BasicType elem_bt, address addr) {\n+  switch (elem_bt) {\n+    case T_BOOLEAN: obj->bool_field_put(offset, *(jboolean*)addr); break;\n+    case T_BYTE:    obj->byte_field_put(offset, *(jbyte*)addr); break;\n+    case T_SHORT:   obj->short_field_put(offset, *(jshort*)addr); break;\n+    case T_INT:     obj->int_field_put(offset, *(jint*)addr); break;\n+    case T_FLOAT:   obj->float_field_put(offset, *(jfloat*)addr); break;\n+    case T_LONG:    obj->long_field_put(offset, *(jlong*)addr); break;\n+    case T_DOUBLE:  obj->double_field_put(offset, *(jdouble*)addr); break;\n+    default: fatal(\"unsupported: %s\", type2name(elem_bt));\n+  }\n+}\n+\n+static void reassign_multi_fields(frame* fr, RegisterMap* reg_map, Location location, oop obj, int offset, BasicType elem_bt, int fields_count) {\n+  int elem_size = type2aelembytes(elem_bt);\n+  if (location.is_register()) {\n+    \/\/ Value was in a callee-saved register.\n+    VMReg vreg = VMRegImpl::as_VMReg(location.register_number());\n+\n+    for (int i = 0; i < fields_count; i++) {\n+      int vslot = (i * elem_size) \/ VMRegImpl::stack_slot_size;\n+      int off   = (i * elem_size) % VMRegImpl::stack_slot_size;\n+      address elem_addr = reg_map->location(vreg, vslot) + off; \/\/ assumes little endian element order\n+      int second_offset = offset + i * elem_size;\n+      init_multi_field(obj, second_offset, elem_bt, elem_addr);\n+    }\n+  } else {\n+    \/\/ Value was directly saved on the stack.\n+    address base_addr = ((address)fr->unextended_sp()) + location.stack_offset();\n+    for (int i = 0; i < fields_count; i++) {\n+      int second_offset = offset + i * elem_size;\n+      init_multi_field(obj, second_offset, elem_bt, base_addr + i * elem_size);\n+    }\n+  }\n+}\n+\n@@ -1390,1 +1563,1 @@\n-static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {\n+int Deoptimization::reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {\n@@ -1393,1 +1566,1 @@\n-  while (ik != NULL) {\n+  while (ik != nullptr) {\n@@ -1395,1 +1568,1 @@\n-      if (!fs.access_flags().is_static() && (!skip_internal || !fs.access_flags().is_internal())) {\n+      if (!fs.access_flags().is_static() && !fs.field_descriptor().is_multifield() && (!skip_internal || !fs.field_flags().is_injected())) {\n@@ -1399,0 +1572,1 @@\n+        field._secondary_fields_count = fs.is_multifield_base() ? fs.field_descriptor().secondary_fields_count(fs.index()) : 1;\n@@ -1420,1 +1594,1 @@\n-      assert(vk != NULL, \"must be resolved\");\n+      assert(vk != nullptr, \"must be resolved\");\n@@ -1425,19 +1599,36 @@\n-    intptr_t val;\n-    ScopeValue* scope_field = sv->field_at(svIndex);\n-    StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);\n-    switch (type) {\n-      case T_OBJECT:\n-      case T_ARRAY:\n-        assert(value->type() == T_OBJECT, \"Agreement.\");\n-        obj->obj_field_put(offset, value->get_obj()());\n-        break;\n-\n-      \/\/ Have to cast to INT (32 bits) pointer to avoid little\/big-endian problem.\n-      case T_INT: case T_FLOAT: { \/\/ 4 bytes.\n-        assert(value->type() == T_INT, \"Agreement.\");\n-        bool big_value = false;\n-        if (i+1 < fields->length() && fields->at(i+1)._type == T_INT) {\n-          if (scope_field->is_location()) {\n-            Location::Type type = ((LocationValue*) scope_field)->location().type();\n-            if (type == Location::dbl || type == Location::lng) {\n-              big_value = true;\n+\n+    Location location;\n+    if (sv->field_at(svIndex)->is_location()) {\n+      location = sv->field_at(svIndex)->as_LocationValue()->location();\n+    }\n+    int secondary_fields_count = fields->at(i)._secondary_fields_count;\n+    if (secondary_fields_count > 1 && location.type() == Location::vector) {\n+      \/\/ Re-assign vectorized multi-fields\n+      reassign_multi_fields(fr, reg_map, location, obj, offset, type, secondary_fields_count);\n+      svIndex++;\n+      continue;\n+    }\n+\n+    assert(secondary_fields_count <= sv->field_size(), \"\");\n+    for (int j = 0; j < secondary_fields_count; j++) {\n+      intptr_t val;\n+      ScopeValue* scope_field = sv->field_at(svIndex);\n+      StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);\n+      offset += j * type2aelembytes(type);\n+      switch (type) {\n+        case T_OBJECT:\n+        case T_ARRAY:\n+          assert(value->type() == T_OBJECT, \"Agreement.\");\n+          obj->obj_field_put(offset, value->get_obj()());\n+          break;\n+\n+        \/\/ Have to cast to INT (32 bits) pointer to avoid little\/big-endian problem.\n+        case T_INT: case T_FLOAT: { \/\/ 4 bytes.\n+          assert(value->type() == T_INT, \"Agreement.\");\n+          bool big_value = false;\n+          if (i+1 < fields->length() && fields->at(i+1)._type == T_INT) {\n+            if (scope_field->is_location()) {\n+              Location::Type type = ((LocationValue*) scope_field)->location().type();\n+              if (type == Location::dbl || type == Location::lng) {\n+                big_value = true;\n+              }\n@@ -1445,5 +1636,5 @@\n-          }\n-          if (scope_field->is_constant_int()) {\n-            ScopeValue* next_scope_field = sv->field_at(svIndex + 1);\n-            if (next_scope_field->is_constant_long() || next_scope_field->is_constant_double()) {\n-              big_value = true;\n+            if (scope_field->is_constant_int()) {\n+              ScopeValue* next_scope_field = sv->field_at(svIndex + 1);\n+              if (next_scope_field->is_constant_long() || next_scope_field->is_constant_double()) {\n+                big_value = true;\n+              }\n@@ -1452,0 +1643,10 @@\n+\n+          if (big_value) {\n+            i++;\n+            assert(i < fields->length(), \"second T_INT field needed\");\n+            assert(fields->at(i)._type == T_INT, \"T_INT field needed\");\n+          } else {\n+            val = value->get_int();\n+            obj->int_field_put(offset, (jint)*((jint*)&val));\n+            break;\n+          }\n@@ -1453,0 +1654,1 @@\n+          \/* no break *\/\n@@ -1454,7 +1656,9 @@\n-        if (big_value) {\n-          i++;\n-          assert(i < fields->length(), \"second T_INT field needed\");\n-          assert(fields->at(i)._type == T_INT, \"T_INT field needed\");\n-        } else {\n-          val = value->get_int();\n-          obj->int_field_put(offset, (jint)*((jint*)&val));\n+        case T_LONG: case T_DOUBLE: {\n+          assert(value->type() == T_INT, \"Agreement.\");\n+          StackValue* low = StackValue::create_stack_value(fr, reg_map, sv->field_at(++svIndex));\n+  #ifdef _LP64\n+          jlong res = (jlong)low->get_int();\n+  #else\n+          jlong res = jlong_from((jint)value->get_int(), (jint)low->get_int());\n+  #endif\n+          obj->long_field_put(offset, res);\n@@ -1463,19 +1667,5 @@\n-      }\n-        \/* no break *\/\n-\n-      case T_LONG: case T_DOUBLE: {\n-        assert(value->type() == T_INT, \"Agreement.\");\n-        StackValue* low = StackValue::create_stack_value(fr, reg_map, sv->field_at(++svIndex));\n-#ifdef _LP64\n-        jlong res = (jlong)low->get_int();\n-#else\n-        jlong res = jlong_from((jint)value->get_int(), (jint)low->get_int());\n-#endif\n-        obj->long_field_put(offset, res);\n-        break;\n-      }\n-      case T_SHORT:\n-        assert(value->type() == T_INT, \"Agreement.\");\n-        val = value->get_int();\n-        obj->short_field_put(offset, (jshort)*((jint*)&val));\n-        break;\n+        case T_SHORT:\n+          assert(value->type() == T_INT, \"Agreement.\");\n+          val = value->get_int();\n+          obj->short_field_put(offset, (jshort)*((jint*)&val));\n+          break;\n@@ -1484,5 +1674,5 @@\n-      case T_CHAR:\n-        assert(value->type() == T_INT, \"Agreement.\");\n-        val = value->get_int();\n-        obj->char_field_put(offset, (jchar)*((jint*)&val));\n-        break;\n+        case T_CHAR:\n+          assert(value->type() == T_INT, \"Agreement.\");\n+          val = value->get_int();\n+          obj->char_field_put(offset, (jchar)*((jint*)&val));\n+          break;\n@@ -1490,5 +1680,5 @@\n-      case T_BYTE:\n-        assert(value->type() == T_INT, \"Agreement.\");\n-        val = value->get_int();\n-        obj->byte_field_put(offset, (jbyte)*((jint*)&val));\n-        break;\n+        case T_BYTE:\n+          assert(value->type() == T_INT, \"Agreement.\");\n+          val = value->get_int();\n+          obj->byte_field_put(offset, (jbyte)*((jint*)&val));\n+          break;\n@@ -1496,5 +1686,5 @@\n-      case T_BOOLEAN:\n-        assert(value->type() == T_INT, \"Agreement.\");\n-        val = value->get_int();\n-        obj->bool_field_put(offset, (jboolean)*((jint*)&val));\n-        break;\n+        case T_BOOLEAN:\n+          assert(value->type() == T_INT, \"Agreement.\");\n+          val = value->get_int();\n+          obj->bool_field_put(offset, (jboolean)*((jint*)&val));\n+          break;\n@@ -1502,2 +1692,4 @@\n-      default:\n-        ShouldNotReachHere();\n+        default:\n+          ShouldNotReachHere();\n+      }\n+      svIndex++;\n@@ -1505,1 +1697,0 @@\n-    svIndex++;\n@@ -1549,4 +1740,0 @@\n-      assert(sv->field_size() == 1, \"%s not a vector\", k->name()->as_C_string());\n-      ScopeValue* payload = sv->field_at(0);\n-      if (payload->is_location() &&\n-          payload->as_LocationValue()->location().type() == Location::vector) {\n@@ -1563,1 +1750,0 @@\n-      }\n@@ -1597,1 +1783,1 @@\n-          if (mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n+          if (LockingMode == LM_LEGACY && mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n@@ -1601,1 +1787,1 @@\n-            mark.locker()->set_displaced_header(markWord::encode((BasicLock*) NULL));\n+            mark.locker()->set_displaced_header(markWord::encode((BasicLock*) nullptr));\n@@ -1607,1 +1793,1 @@\n-            if (waiting_monitor != NULL && waiting_monitor->object() == obj()) {\n+            if (waiting_monitor != nullptr && waiting_monitor->object() == obj()) {\n@@ -1687,1 +1873,1 @@\n-    if (monitors != NULL) {\n+    if (monitors != nullptr) {\n@@ -1690,1 +1876,1 @@\n-        if (src->obj() != NULL) {\n+        if (src->obj() != nullptr) {\n@@ -1708,1 +1894,1 @@\n-  if (LogCompilation && xtty != NULL) {\n+  if (LogCompilation && xtty != nullptr) {\n@@ -1710,1 +1896,1 @@\n-    assert(cm != NULL, \"only compiled methods can deopt\");\n+    assert(cm != nullptr, \"only compiled methods can deopt\");\n@@ -1764,3 +1950,3 @@\n-  if (imm_mdo != NULL) {\n-    ProfileData* pdata = imm_mdo->allocate_bci_to_data(imm_scope->bci(), NULL);\n-    if (pdata != NULL && pdata->is_BitData()) {\n+  if (imm_mdo != nullptr) {\n+    ProfileData* pdata = imm_mdo->allocate_bci_to_data(imm_scope->bci(), nullptr);\n+    if (pdata != nullptr && pdata->is_BitData()) {\n@@ -1775,1 +1961,1 @@\n-  if (trap_mdo != NULL) {\n+  if (trap_mdo != nullptr) {\n@@ -1828,1 +2014,1 @@\n-  if (mdo == NULL && create_if_missing && !HAS_PENDING_EXCEPTION) {\n+  if (mdo == nullptr && create_if_missing && !HAS_PENDING_EXCEPTION) {\n@@ -1915,2 +2101,2 @@\n-  assert(nm != NULL, \"invariant\");\n-  assert(method != NULL, \"invariant\");\n+  assert(nm != nullptr, \"invariant\");\n+  assert(method != nullptr, \"invariant\");\n@@ -2072,1 +2258,1 @@\n-      if (xtty != NULL) {\n+      if (xtty != nullptr) {\n@@ -2083,1 +2269,1 @@\n-      Symbol* class_name = NULL;\n+      Symbol* class_name = nullptr;\n@@ -2090,1 +2276,1 @@\n-          if (xtty != NULL)\n+          if (xtty != nullptr)\n@@ -2095,1 +2281,1 @@\n-        if (xtty != NULL)\n+        if (xtty != nullptr)\n@@ -2098,1 +2284,1 @@\n-      if (xtty != NULL && trap_mdo != NULL && (int)reason < (int)MethodData::_trap_hist_limit) {\n+      if (xtty != nullptr && trap_mdo != nullptr && (int)reason < (int)MethodData::_trap_hist_limit) {\n@@ -2106,1 +2292,1 @@\n-        int dos = (pdata == NULL)? 0: pdata->trap_state();\n+        int dos = (pdata == nullptr)? 0: pdata->trap_state();\n@@ -2116,1 +2302,1 @@\n-      if (xtty != NULL) {\n+      if (xtty != nullptr) {\n@@ -2129,1 +2315,1 @@\n-          if (installed_code_name != NULL) {\n+          if (installed_code_name != nullptr) {\n@@ -2144,1 +2330,1 @@\n-        if (class_name != NULL) {\n+        if (class_name != nullptr) {\n@@ -2151,1 +2337,1 @@\n-      if (xtty != NULL) {\n+      if (xtty != nullptr) {\n@@ -2280,2 +2466,2 @@\n-    ProfileData* pdata = NULL;\n-    if (ProfileTraps && CompilerConfig::is_c2_or_jvmci_compiler_enabled() && update_trap_state && trap_mdo != NULL) {\n+    ProfileData* pdata = nullptr;\n+    if (ProfileTraps && CompilerConfig::is_c2_or_jvmci_compiler_enabled() && update_trap_state && trap_mdo != nullptr) {\n@@ -2362,1 +2548,1 @@\n-      if (pdata != NULL) {\n+      if (pdata != nullptr) {\n@@ -2375,1 +2561,1 @@\n-      if ((reason != Reason_rtm_state_change) && (trap_mdo != NULL) &&\n+      if ((reason != Reason_rtm_state_change) && (trap_mdo != nullptr) &&\n@@ -2382,1 +2568,1 @@\n-      if (reason == Reason_tenured && trap_mdo != NULL) {\n+      if (reason == Reason_tenured && trap_mdo != nullptr) {\n@@ -2452,1 +2638,1 @@\n-  ProfileData* pdata = NULL;\n+  ProfileData* pdata = nullptr;\n@@ -2462,1 +2648,1 @@\n-    pdata = trap_mdo->allocate_bci_to_data(trap_bci, reason_is_speculate(reason) ? compiled_method : NULL);\n+    pdata = trap_mdo->allocate_bci_to_data(trap_bci, reason_is_speculate(reason) ? compiled_method : nullptr);\n@@ -2464,1 +2650,1 @@\n-    if (pdata != NULL) {\n+    if (pdata != nullptr) {\n@@ -2466,1 +2652,1 @@\n-        if (LogCompilation && xtty != NULL) {\n+        if (LogCompilation && xtty != nullptr) {\n@@ -2487,1 +2673,1 @@\n-      if (LogCompilation && xtty != NULL) {\n+      if (LogCompilation && xtty != nullptr) {\n@@ -2518,1 +2704,1 @@\n-                           NULL,\n+                           nullptr,\n@@ -2682,1 +2868,1 @@\n-  sprintf(buf, \"reason%d\", reason);\n+  os::snprintf_checked(buf, sizeof(buf), \"reason%d\", reason);\n@@ -2692,1 +2878,1 @@\n-  sprintf(buf, \"action%d\", action);\n+  os::snprintf_checked(buf, sizeof(buf), \"action%d\", action);\n@@ -2742,1 +2928,1 @@\n-  juint* bc_counter_addr = NULL;\n+  juint* bc_counter_addr = nullptr;\n@@ -2749,1 +2935,1 @@\n-      if ((counter == 0 && bc_counter_addr == NULL)\n+      if ((counter == 0 && bc_counter_addr == nullptr)\n@@ -2757,1 +2943,1 @@\n-  if (bc_counter_addr == NULL) {\n+  if (bc_counter_addr == nullptr) {\n@@ -2774,1 +2960,1 @@\n-  if (reason_str == NULL && action_str == NULL) {\n+  if (reason_str == nullptr && action_str == nullptr) {\n@@ -2779,1 +2965,1 @@\n-    if (reason_str == NULL || !strcmp(reason_str, trap_reason_name(reason))) {\n+    if (reason_str == nullptr || !strcmp(reason_str, trap_reason_name(reason))) {\n@@ -2781,1 +2967,1 @@\n-        if (action_str == NULL || !strcmp(action_str, trap_action_name(action))) {\n+        if (action_str == nullptr || !strcmp(action_str, trap_action_name(action))) {\n@@ -2798,1 +2984,1 @@\n-    if (xtty != NULL)  xtty->head(\"statistics type='deoptimization'\");\n+    if (xtty != nullptr)  xtty->head(\"statistics type='deoptimization'\");\n@@ -2815,1 +3001,1 @@\n-            sprintf(name, \"%s\/%s\/%s\",\n+            os::snprintf_checked(name, sizeof(name), \"%s\/%s\/%s\",\n@@ -2830,1 +3016,1 @@\n-    if (xtty != NULL)  xtty->tail(\"statistics\");\n+    if (xtty != nullptr)  xtty->tail(\"statistics\");\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":383,"deletions":197,"binary":false,"changes":580,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,26 @@\n+class DeoptimizationScope {\n+ private:\n+  \/\/ What gen we have done the deopt handshake for.\n+  static uint64_t _committed_deopt_gen;\n+  \/\/ What gen to mark a method with, hence larger than _committed_deopt_gen.\n+  static uint64_t _active_deopt_gen;\n+  \/\/ Indicate an in-progress deopt handshake.\n+  static bool     _committing_in_progress;\n+\n+  \/\/ The required gen we need to execute\/wait for\n+  uint64_t _required_gen;\n+  DEBUG_ONLY(bool _deopted;)\n+\n+ public:\n+  DeoptimizationScope();\n+  ~DeoptimizationScope();\n+  \/\/ Mark a method, if already marked as dependent.\n+  void mark(CompiledMethod* cm, bool inc_recompile_counts = true);\n+  \/\/ Record this as a dependent method.\n+  void dependent(CompiledMethod* cm);\n+\n+  \/\/ Execute the deoptimization.\n+  \/\/ Make the nmethods not entrant, stackwalks and patch return pcs and sets post call nops.\n+  void deoptimize_marked();\n+};\n+\n@@ -152,2 +178,1 @@\n-  \/\/ activations using those nmethods.  If an nmethod is passed as an argument then it is\n-  \/\/ marked_for_deoptimization and made not_entrant.  Otherwise a scan of the code cache is done to\n+  \/\/ activations using those nmethods. Scan of the code cache is done to\n@@ -155,1 +180,1 @@\n-  static void deoptimize_all_marked(nmethod* nmethod_only = NULL);\n+  static void deoptimize_all_marked();\n@@ -163,1 +188,1 @@\n-  static oop get_cached_box(AutoBoxObjectValue* bv, frame* fr, RegisterMap* reg_map, TRAPS);\n+  static oop get_cached_box(AutoBoxObjectValue* bv, frame* fr, RegisterMap* reg_map, bool& cache_init_error, TRAPS);\n@@ -185,0 +210,2 @@\n+  static int  reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS);\n+\n@@ -244,10 +271,10 @@\n-    static int size_of_deoptimized_frame_offset_in_bytes() { return offset_of(UnrollBlock, _size_of_deoptimized_frame); }\n-    static int caller_adjustment_offset_in_bytes()         { return offset_of(UnrollBlock, _caller_adjustment);         }\n-    static int number_of_frames_offset_in_bytes()          { return offset_of(UnrollBlock, _number_of_frames);          }\n-    static int frame_sizes_offset_in_bytes()               { return offset_of(UnrollBlock, _frame_sizes);               }\n-    static int total_frame_sizes_offset_in_bytes()         { return offset_of(UnrollBlock, _total_frame_sizes);         }\n-    static int frame_pcs_offset_in_bytes()                 { return offset_of(UnrollBlock, _frame_pcs);                 }\n-    static int counter_temp_offset_in_bytes()              { return offset_of(UnrollBlock, _counter_temp);              }\n-    static int initial_info_offset_in_bytes()              { return offset_of(UnrollBlock, _initial_info);              }\n-    static int unpack_kind_offset_in_bytes()               { return offset_of(UnrollBlock, _unpack_kind);               }\n-    static int sender_sp_temp_offset_in_bytes()            { return offset_of(UnrollBlock, _sender_sp_temp);            }\n+    static ByteSize size_of_deoptimized_frame_offset() { return byte_offset_of(UnrollBlock, _size_of_deoptimized_frame); }\n+    static ByteSize caller_adjustment_offset()         { return byte_offset_of(UnrollBlock, _caller_adjustment);         }\n+    static ByteSize number_of_frames_offset()          { return byte_offset_of(UnrollBlock, _number_of_frames);          }\n+    static ByteSize frame_sizes_offset()               { return byte_offset_of(UnrollBlock, _frame_sizes);               }\n+    static ByteSize total_frame_sizes_offset()         { return byte_offset_of(UnrollBlock, _total_frame_sizes);         }\n+    static ByteSize frame_pcs_offset()                 { return byte_offset_of(UnrollBlock, _frame_pcs);                 }\n+    static ByteSize counter_temp_offset()              { return byte_offset_of(UnrollBlock, _counter_temp);              }\n+    static ByteSize initial_info_offset()              { return byte_offset_of(UnrollBlock, _initial_info);              }\n+    static ByteSize unpack_kind_offset()               { return byte_offset_of(UnrollBlock, _unpack_kind);               }\n+    static ByteSize sender_sp_temp_offset()            { return byte_offset_of(UnrollBlock, _sender_sp_temp);            }\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.hpp","additions":42,"deletions":15,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,1 +41,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -43,12 +43,1 @@\n-\n-  int idx = 0;\n-  InstanceKlass* ik = field_holder();\n-  for (AllFieldStream fs(ik); !fs.done(); fs.next()) {\n-    if (idx == _index) {\n-      return fs.generic_signature();\n-    } else {\n-      idx ++;\n-    }\n-  }\n-  assert(false, \"should never happen\");\n-  return vmSymbols::void_signature(); \/\/ return a default value (for code analyzers)\n+  return _cp->symbol_at(_fieldinfo.generic_signature_index());\n@@ -65,2 +54,2 @@\n-  if (md == NULL)\n-    return NULL;\n+  if (md == nullptr)\n+    return nullptr;\n@@ -73,2 +62,2 @@\n-  if (type_annos == NULL)\n-    return NULL;\n+  if (type_annos == nullptr)\n+    return nullptr;\n@@ -106,1 +95,3 @@\n-    assert(field_holder() == ik, \"must be already initialized to this class\");\n+    \/\/ If the class is a scratch class, the constant pool points to the original class,\n+    \/\/ but that's ok because of constant pool merging.\n+    assert(field_holder() == ik || ik->is_scratch_class(), \"must be already initialized to this class\");\n@@ -108,2 +99,2 @@\n-  FieldInfo* f = ik->field(index);\n-  _access_flags = accessFlags_from(f->access_flags());\n+  _fieldinfo= ik->field(index);\n+  assert((int)_fieldinfo.index() == index, \"just checking\");\n@@ -111,3 +102,1 @@\n-  guarantee(\/*f->name_index() != 0 &&*\/ f->signature_index() != 0, \"bad constant pool index for fieldDescriptor\");\n-  _index = index;\n-  verify();\n+  guarantee(\/*_fieldinfo.name_index() != 0 &&*\/ _fieldinfo.signature_index() != 0, \"bad constant pool index for fieldDescriptor\");\n@@ -116,14 +105,0 @@\n-#ifndef PRODUCT\n-\n-void fieldDescriptor::verify() const {\n-  if (_cp.is_null()) {\n-    assert(_index == badInt, \"constructor must be called\");  \/\/ see constructor\n-  } else {\n-    assert(_index >= 0, \"good index\");\n-    assert(access_flags().is_internal() ||\n-           _index < field_holder()->java_fields_count(), \"oob\");\n-  }\n-}\n-\n-#endif \/* PRODUCT *\/\n-\n@@ -132,1 +107,1 @@\n-  if (access_flags().is_internal()) st->print(\"internal \");\n+  if (field_flags().is_injected()) st->print(\"injected \");\n@@ -203,1 +178,1 @@\n-      if (obj->obj_field(offset()) != NULL) {\n+      if (obj->obj_field(offset()) != nullptr) {\n@@ -206,1 +181,1 @@\n-        st->print(\"NULL\");\n+        st->print(\"nullptr\");\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.cpp","additions":16,"deletions":41,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,2 +41,1 @@\n-  AccessFlags         _access_flags;\n-  int                 _index; \/\/ the field index\n+  FieldInfo           _fieldinfo;\n@@ -45,4 +44,1 @@\n-  \/\/ update the access_flags for the field in the klass\n-  inline void update_klass_field_access_flag();\n-\n-  inline FieldInfo* field() const;\n+  inline FieldInfo field() const { return _fieldinfo; };\n@@ -51,3 +47,1 @@\n-  fieldDescriptor() {\n-    DEBUG_ONLY(_index = badInt);\n-  }\n+  fieldDescriptor() {}\n@@ -55,1 +49,0 @@\n-    DEBUG_ONLY(_index = badInt);\n@@ -60,1 +53,1 @@\n-  inline InstanceKlass* field_holder() const;\n+  inline InstanceKlass* field_holder() const {return _cp->pool_holder(); };\n@@ -63,1 +56,4 @@\n-  AccessFlags access_flags()      const    { return _access_flags; }\n+  AccessFlags access_flags()      const    { return _fieldinfo.access_flags(); }\n+  FieldInfo::FieldFlags field_flags() const { return _fieldinfo.field_flags(); }\n+  FieldStatus field_status()      const    { return field_holder()->fields_status()->at(_fieldinfo.index()); }\n+  oop loader()                    const;\n@@ -67,1 +63,1 @@\n-  int index()                     const    { return _index; }\n+  int index()                     const    { return _fieldinfo.index(); }\n@@ -90,2 +86,4 @@\n-  bool is_stable()                const    { return access_flags().is_stable(); }\n-  inline bool is_inlined() const;\n+  bool is_stable()                const    { return field_flags().is_stable(); }\n+  bool is_volatile()              const    { return access_flags().is_volatile(); }\n+  bool is_transient()             const    { return access_flags().is_transient(); }\n+  inline bool is_inlined()        const;\n@@ -101,1 +99,1 @@\n-  bool is_field_access_watched()  const    { return access_flags().is_field_access_watched(); }\n+  bool is_field_access_watched()  const    { return field_status().is_access_watched(); }\n@@ -103,3 +101,3 @@\n-                                           { return access_flags().is_field_modification_watched(); }\n-  bool has_initialized_final_update() const { return access_flags().has_field_initialized_final_update(); }\n-  bool has_generic_signature()    const    { return access_flags().field_has_generic_signature(); }\n+                                           { return field_status().is_modification_watched(); }\n+  bool has_initialized_final_update() const { return field_status().is_initialized_final_update(); }\n+  bool has_generic_signature()    const    { return field_flags().is_generic(); }\n@@ -120,1 +118,0 @@\n-  void verify() const                           PRODUCT_RETURN;\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.hpp","additions":18,"deletions":21,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"oops\/fieldInfo.inline.hpp\"\n@@ -37,1 +38,1 @@\n-  return field()->name(field_holder()->multifield_info(),  _cp());\n+  return field().name(field_holder()->multifield_info(),  _cp());\n@@ -41,5 +42,1 @@\n-  return field()->signature(_cp());\n-}\n-\n-inline InstanceKlass* fieldDescriptor::field_holder() const {\n-  return _cp->pool_holder();\n+  return field().signature(_cp());\n@@ -52,13 +49,3 @@\n-inline FieldInfo* fieldDescriptor::field() const {\n-  InstanceKlass* ik = field_holder();\n-  return ik->field(_index);\n-}\n-\n-inline int fieldDescriptor::offset()                    const    { return field()->offset(); }\n-inline bool fieldDescriptor::has_initial_value()        const    { return field()->initval_index() != 0; }\n-inline int fieldDescriptor::initial_value_index()       const    { return field()->initval_index(); }\n-\n-inline void fieldDescriptor::update_klass_field_access_flag() {\n-  InstanceKlass* ik = field_holder();\n-  ik->field(index())->set_access_flags(_access_flags.as_short());\n-}\n+inline int fieldDescriptor::offset()                    const    { return field().offset(); }\n+inline bool fieldDescriptor::has_initial_value()        const    { return field().field_flags().is_initialized(); }\n+inline int fieldDescriptor::initial_value_index()       const    { return field().initializer_index(); }\n@@ -67,2 +54,1 @@\n-  _access_flags.set_is_field_access_watched(value);\n-  update_klass_field_access_flag();\n+  field_holder()->fields_status()->adr_at(index())->update_access_watched(value);\n@@ -72,2 +58,1 @@\n-  _access_flags.set_is_field_modification_watched(value);\n-  update_klass_field_access_flag();\n+  field_holder()->fields_status()->adr_at(index())->update_modification_watched(value);\n@@ -77,2 +62,1 @@\n-  _access_flags.set_has_field_initialized_final_update(value);\n-  update_klass_field_access_flag();\n+  field_holder()->fields_status()->adr_at(index())->update_initialized_final_update(value);\n@@ -85,2 +69,2 @@\n-inline bool fieldDescriptor::is_inlined()  const  { return field()->is_inlined(); }\n-inline bool fieldDescriptor::is_inline_type() const { return Signature::basic_type(field()->signature(_cp())) == T_PRIMITIVE_OBJECT; }\n+inline bool fieldDescriptor::is_inlined()  const  { return field().field_flags().is_inlined(); }\n+inline bool fieldDescriptor::is_inline_type() const { return field_type() == T_PRIMITIVE_OBJECT; }\n@@ -88,4 +72,8 @@\n-inline bool fieldDescriptor::is_multifield() const { return field()->is_multifield(); }\n-inline bool fieldDescriptor::is_multifield_base() const { return field()->is_multifield_base(); }\n-inline u2   fieldDescriptor::multifield_base() const { return field_holder()->multifield_info(field()->secondary_index()).base_index(); }\n-inline jbyte fieldDescriptor::multifield_index() const { return  field_holder()->multifield_info(field()->secondary_index()).multifield_index(); }\n+inline bool fieldDescriptor::is_multifield() const { return field().is_multifield(); }\n+inline bool fieldDescriptor::is_multifield_base() const { return field().is_multifield_base(); }\n+inline u2   fieldDescriptor::multifield_base() const {\n+  return is_multifield() ? field_holder()->multifield_info(field().secondary_index()).base_index() : index();\n+}\n+inline jbyte fieldDescriptor::multifield_index() const {\n+ return  is_multifield() ? field_holder()->multifield_info(field().secondary_index()).multifield_index() : (jbyte)0;\n+}\n@@ -95,1 +83,1 @@\n-  if (!is_multifield_base() || NULL == multifield_info) {\n+  if (!is_multifield_base() || nullptr == multifield_info) {\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.inline.hpp","additions":21,"deletions":33,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -52,0 +52,1 @@\n+#include \"metaprogramming\/primitiveConversions.hpp\"\n@@ -61,0 +62,1 @@\n+#include \"prims\/jvmtiThreadState.hpp\"\n@@ -71,0 +73,1 @@\n+#include \"runtime\/jniHandles.inline.hpp\"\n@@ -235,0 +238,1 @@\n+#ifdef _WIN64\n@@ -239,0 +243,1 @@\n+#endif\n@@ -240,1 +245,2 @@\n-JRT_LEAF(jfloat, SharedRuntime::frem(jfloat  x, jfloat  y))\n+#if !defined(X86) || !defined(TARGET_COMPILER_gcc) || defined(_WIN64)\n+JRT_LEAF(jfloat, SharedRuntime::frem(jfloat x, jfloat y))\n@@ -244,3 +250,2 @@\n-  union { jfloat f; juint i; } xbits, ybits;\n-  xbits.f = x;\n-  ybits.f = y;\n+  juint xbits = PrimitiveConversions::cast<juint>(x);\n+  juint ybits = PrimitiveConversions::cast<juint>(y);\n@@ -248,2 +253,2 @@\n-  if (((xbits.i & float_sign_mask) != float_infinity) &&\n-       ((ybits.i & float_sign_mask) == float_infinity) ) {\n+  if (((xbits & float_sign_mask) != float_infinity) &&\n+       ((ybits & float_sign_mask) == float_infinity) ) {\n@@ -258,1 +263,0 @@\n-\n@@ -261,3 +265,2 @@\n-  union { jdouble d; julong l; } xbits, ybits;\n-  xbits.d = x;\n-  ybits.d = y;\n+  julong xbits = PrimitiveConversions::cast<julong>(x);\n+  julong ybits = PrimitiveConversions::cast<julong>(y);\n@@ -265,2 +268,2 @@\n-  if (((xbits.l & double_sign_mask) != double_infinity) &&\n-       ((ybits.l & double_sign_mask) == double_infinity) ) {\n+  if (((xbits & double_sign_mask) != double_infinity) &&\n+       ((ybits & double_sign_mask) == double_infinity) ) {\n@@ -274,0 +277,1 @@\n+#endif \/\/ !X86 || !TARGET_COMPILER_gcc || _WIN64\n@@ -452,91 +456,0 @@\n-\/\/ Reference implementation at src\/java.base\/share\/classes\/java\/lang\/Float.java:floatToFloat16\n-JRT_LEAF(jshort, SharedRuntime::f2hf(jfloat  x))\n-  union {jfloat f; jint i;} bits;\n-  bits.f = x;\n-  jint doppel = bits.i;\n-  jshort sign_bit = (jshort) ((doppel & 0x80000000) >> 16);\n-  if (g_isnan(x))\n-    return (jshort)(sign_bit | 0x7c00 | (doppel & 0x007fe000) >> 13 | (doppel & 0x00001ff0) >> 4 | (doppel & 0x0000000f));\n-\n-  jfloat abs_f = (x >= 0.0f) ? x : (x * -1.0f);\n-\n-  \/\/ Overflow threshold is halffloat max value + 1\/2 ulp\n-  if (abs_f >= (65504.0f + 16.0f)) {\n-    return (jshort)(sign_bit | 0x7c00); \/\/ Positive or negative infinity\n-  }\n-\n-  \/\/ Smallest magnitude of Halffloat is 0x1.0p-24, half-way or smaller rounds to zero\n-  if (abs_f <= (pow(2, -24) * 0.5f)) { \/\/ Covers float zeros and subnormals.\n-    return sign_bit; \/\/ Positive or negative zero\n-  }\n-\n-  jint exp = ((0x7f800000 & doppel) >> (24 - 1)) - 127;\n-\n-  \/\/ For binary16 subnormals, beside forcing exp to -15, retain\n-  \/\/ the difference exp_delta = E_min - exp.  This is the excess\n-  \/\/ shift value, in addition to 13, to be used in the\n-  \/\/ computations below. Further the (hidden) msb with value 1\n-  \/\/ in f must be involved as well\n-  jint exp_delta = 0;\n-  jint msb = 0x00000000;\n-  if (exp < -14) {\n-    exp_delta = -14 - exp;\n-    exp = -15;\n-    msb = 0x00800000;\n-  }\n-  jint f_signif_bits = ((doppel & 0x007fffff) | msb);\n-\n-  \/\/ Significand bits as if using rounding to zero\n-  jshort signif_bits = (jshort)(f_signif_bits >> (13 + exp_delta));\n-\n-  jint lsb = f_signif_bits & (1 << (13 + exp_delta));\n-  jint round  = f_signif_bits & (1 << (12 + exp_delta));\n-  jint sticky = f_signif_bits & ((1 << (12 + exp_delta)) - 1);\n-\n-  if (round != 0 && ((lsb | sticky) != 0 )) {\n-    signif_bits++;\n-  }\n-\n-  return (jshort)(sign_bit | ( ((exp + 15) << 10) + signif_bits ) );\n-JRT_END\n-\n-\/\/ Reference implementation at src\/java.base\/share\/classes\/java\/lang\/Float.java:float16ToFloat\n-JRT_LEAF(jfloat, SharedRuntime::hf2f(jshort x))\n-  \/\/ Halffloat format has 1 signbit, 5 exponent bits and\n-  \/\/ 10 significand bits\n-  union {jfloat f; jint i;} bits;\n-  jint hf_arg = (jint)x;\n-  jint hf_sign_bit = 0x8000 & hf_arg;\n-  jint hf_exp_bits = 0x7c00 & hf_arg;\n-  jint hf_significand_bits = 0x03ff & hf_arg;\n-\n-  jint significand_shift = 13; \/\/difference between float and halffloat precision\n-\n-  jfloat sign = (hf_sign_bit != 0) ? -1.0f : 1.0f;\n-\n-  \/\/ Extract halffloat exponent, remove its bias\n-  jint hf_exp = (hf_exp_bits >> 10) - 15;\n-\n-  if (hf_exp == -15) {\n-    \/\/ For subnormal values, return 2^-24 * significand bits\n-    return (sign * (pow(2,-24)) * hf_significand_bits);\n-  } else if (hf_exp == 16) {\n-    if (hf_significand_bits == 0) {\n-      bits.i = 0x7f800000;\n-      return sign * bits.f;\n-    } else {\n-      bits.i = (hf_sign_bit << 16) | 0x7f800000 |\n-               (hf_significand_bits << significand_shift);\n-      return bits.f;\n-    }\n-  }\n-\n-  \/\/ Add the bias of float exponent and shift\n-  jint float_exp_bits = (hf_exp + 127) << (24 - 1);\n-\n-  \/\/ Combine sign, exponent and significand bits\n-  bits.i = (hf_sign_bit << 16) | float_exp_bits |\n-           (hf_significand_bits << significand_shift);\n-\n-  return bits.f;\n-JRT_END\n@@ -566,1 +479,1 @@\n-  current->set_exception_pc(NULL);\n+  current->set_exception_pc(nullptr);\n@@ -575,2 +488,2 @@\n-  CompiledMethod* nm = (blob != NULL) ? blob->as_compiled_method_or_null() : NULL;\n-  if (nm != NULL) {\n+  CompiledMethod* nm = (blob != nullptr) ? blob->as_compiled_method_or_null() : nullptr;\n+  if (nm != nullptr) {\n@@ -610,1 +523,1 @@\n-  if (blob != NULL && blob->is_upcall_stub()) {\n+  if (blob != nullptr && blob->is_upcall_stub()) {\n@@ -620,2 +533,2 @@\n-  guarantee(blob == NULL || !blob->is_runtime_stub(), \"caller should have skipped stub\");\n-  guarantee(!VtableStubs::contains(return_address), \"NULL exceptions in vtables should have been handled already!\");\n+  guarantee(blob == nullptr || !blob->is_runtime_stub(), \"caller should have skipped stub\");\n+  guarantee(!VtableStubs::contains(return_address), \"null exceptions in vtables should have been handled already!\");\n@@ -633,1 +546,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -651,1 +564,1 @@\n-  guarantee(cb != NULL && cb->is_compiled(), \"safepoint polling: pc must refer to an nmethod\");\n+  guarantee(cb != nullptr && cb->is_compiled(), \"safepoint polling: pc must refer to an nmethod\");\n@@ -668,1 +581,1 @@\n-    assert(SharedRuntime::polling_page_return_handler_blob() != NULL,\n+    assert(SharedRuntime::polling_page_return_handler_blob() != nullptr,\n@@ -672,1 +585,1 @@\n-    assert(SharedRuntime::polling_page_vectors_safepoint_handler_blob() != NULL,\n+    assert(SharedRuntime::polling_page_vectors_safepoint_handler_blob() != nullptr,\n@@ -676,1 +589,1 @@\n-    assert(SharedRuntime::polling_page_safepoint_handler_blob() != NULL,\n+    assert(SharedRuntime::polling_page_safepoint_handler_blob() != nullptr,\n@@ -701,1 +614,1 @@\n-    if (trap_mdo != NULL) {\n+    if (trap_mdo != nullptr) {\n@@ -706,2 +619,2 @@\n-        ProfileData* pdata = trap_mdo->allocate_bci_to_data(bci, NULL);\n-        if (pdata != NULL && pdata->is_BitData()) {\n+        ProfileData* pdata = trap_mdo->allocate_bci_to_data(bci, nullptr);\n+        if (pdata != nullptr && pdata->is_BitData()) {\n@@ -724,0 +637,28 @@\n+#if INCLUDE_JVMTI\n+JRT_ENTRY(void, SharedRuntime::notify_jvmti_vthread_start(oopDesc* vt, jboolean hide, JavaThread* current))\n+  assert(hide == JNI_FALSE, \"must be VTMS transition finish\");\n+  jobject vthread = JNIHandles::make_local(const_cast<oopDesc*>(vt));\n+  JvmtiVTMSTransitionDisabler::VTMS_vthread_start(vthread);\n+  JNIHandles::destroy_local(vthread);\n+JRT_END\n+\n+JRT_ENTRY(void, SharedRuntime::notify_jvmti_vthread_end(oopDesc* vt, jboolean hide, JavaThread* current))\n+  assert(hide == JNI_TRUE, \"must be VTMS transition start\");\n+  jobject vthread = JNIHandles::make_local(const_cast<oopDesc*>(vt));\n+  JvmtiVTMSTransitionDisabler::VTMS_vthread_end(vthread);\n+  JNIHandles::destroy_local(vthread);\n+JRT_END\n+\n+JRT_ENTRY(void, SharedRuntime::notify_jvmti_vthread_mount(oopDesc* vt, jboolean hide, JavaThread* current))\n+  jobject vthread = JNIHandles::make_local(const_cast<oopDesc*>(vt));\n+  JvmtiVTMSTransitionDisabler::VTMS_vthread_mount(vthread, hide);\n+  JNIHandles::destroy_local(vthread);\n+JRT_END\n+\n+JRT_ENTRY(void, SharedRuntime::notify_jvmti_vthread_unmount(oopDesc* vt, jboolean hide, JavaThread* current))\n+  jobject vthread = JNIHandles::make_local(const_cast<oopDesc*>(vt));\n+  JvmtiVTMSTransitionDisabler::VTMS_vthread_unmount(vthread, hide);\n+  JNIHandles::destroy_local(vthread);\n+JRT_END\n+#endif \/\/ INCLUDE_JVMTI\n+\n@@ -745,1 +686,1 @@\n-  assert(cm != NULL, \"must exist\");\n+  assert(cm != nullptr, \"must exist\");\n@@ -754,1 +695,1 @@\n-    if (t != NULL) {\n+    if (t != nullptr) {\n@@ -801,1 +742,1 @@\n-        if (sd != NULL) {\n+        if (sd != nullptr) {\n@@ -806,1 +747,1 @@\n-    } while (recursive_exception || (!top_frame_only && handler_bci < 0 && sd != NULL));\n+    } while (recursive_exception || (!top_frame_only && handler_bci < 0 && sd != nullptr));\n@@ -814,1 +755,1 @@\n-  if (t == NULL && (nm->is_compiled_by_c1() || handler_bci != -1)) {\n+  if (t == nullptr && (nm->is_compiled_by_c1() || handler_bci != -1)) {\n@@ -825,2 +766,2 @@\n-  if (t == NULL && nm->is_compiled_by_c1()) {\n-    assert(nm->unwind_handler_begin() != NULL, \"\");\n+  if (t == nullptr && nm->is_compiled_by_c1()) {\n+    assert(nm->unwind_handler_begin() != nullptr, \"\");\n@@ -831,1 +772,1 @@\n-  if (t == NULL) {\n+  if (t == nullptr) {\n@@ -842,1 +783,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -863,1 +804,1 @@\n-  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), NULL);\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), nullptr);\n@@ -869,1 +810,1 @@\n-  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), NULL);\n+  throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException(), nullptr);\n@@ -907,1 +848,1 @@\n-  address target_pc = NULL;\n+  address target_pc = nullptr;\n@@ -929,1 +870,1 @@\n-        assert(current->deopt_mark() == NULL, \"no stack overflow from deopt blob\/uncommon trap\");\n+        assert(current->deopt_mark() == nullptr, \"no stack overflow from deopt blob\/uncommon trap\");\n@@ -942,2 +883,2 @@\n-          \/\/ If vt_stub is NULL, then return NULL to signal handler to report the SEGV error.\n-          if (vt_stub == NULL) return NULL;\n+          \/\/ If vt_stub is null, then return null to signal handler to report the SEGV error.\n+          if (vt_stub == nullptr) return nullptr;\n@@ -962,2 +903,2 @@\n-          \/\/ If code blob is NULL, then return NULL to signal handler to report the SEGV error.\n-          if (cb == NULL) return NULL;\n+          \/\/ If code blob is null, then return null to signal handler to report the SEGV error.\n+          if (cb == nullptr) return nullptr;\n@@ -974,1 +915,1 @@\n-              return NULL;\n+              return nullptr;\n@@ -1002,1 +943,1 @@\n-          \/\/ If there's an unexpected fault, target_pc might be NULL,\n+          \/\/ If there's an unexpected fault, target_pc might be null,\n@@ -1013,1 +954,1 @@\n-        guarantee(cm != NULL, \"must have containing compiled method for implicit division-by-zero exceptions\");\n+        guarantee(cm != nullptr, \"must have containing compiled method for implicit division-by-zero exceptions\");\n@@ -1018,1 +959,1 @@\n-        \/\/ If there's an unexpected fault, target_pc might be NULL,\n+        \/\/ If there's an unexpected fault, target_pc might be null,\n@@ -1046,1 +987,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1086,2 +1027,2 @@\n-  assert(thread != NULL, \"No thread\");\n-  if (thread == NULL) {\n+  assert(thread != nullptr, \"No thread\");\n+  if (thread == nullptr) {\n@@ -1093,1 +1034,1 @@\n-  return (obj == NULL) ? 0 : java_lang_Thread::thread_id(obj);\n+  return (obj == nullptr) ? 0 : java_lang_Thread::thread_id(obj);\n@@ -1173,1 +1114,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -1251,1 +1192,1 @@\n-        attached_method = methodHandle(current, NULL);\n+        attached_method = methodHandle(current, nullptr);\n@@ -1274,5 +1215,0 @@\n-    bool caller_is_c1 = false;\n-\n-    if (callerFrame.is_compiled_frame()) {\n-      caller_is_c1 = callerFrame.cb()->is_compiled_by_c1();\n-    }\n@@ -1281,1 +1217,1 @@\n-    if (callee == NULL) {\n+    if (callee == nullptr) {\n@@ -1283,1 +1219,1 @@\n-      if (callee == NULL) {\n+      if (callee == nullptr) {\n@@ -1287,0 +1223,1 @@\n+    bool caller_is_c1 = callerFrame.is_compiled_frame() && callerFrame.cb()->is_compiled_by_c1();\n@@ -1290,0 +1227,1 @@\n+      assert(!callee->mismatch(), \"calls with inline type receivers should never mismatch\");\n@@ -1320,1 +1258,1 @@\n-    Klass* rk = NULL;\n+    Klass* rk = nullptr;\n@@ -1327,1 +1265,1 @@\n-      rk = constants->klass_ref_at(bytecode_index, CHECK_NH);\n+      rk = constants->klass_ref_at(bytecode_index, bc, CHECK_NH);\n@@ -1345,1 +1283,1 @@\n-methodHandle SharedRuntime::find_callee_method(TRAPS) {\n+methodHandle SharedRuntime::find_callee_method(bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1371,0 +1309,4 @@\n+    \/\/ Calls via mismatching methods are always non-scalarized\n+    if (callinfo.resolved_method()->mismatch() && !is_optimized) {\n+      caller_is_c1 = true;\n+    }\n@@ -1378,1 +1320,1 @@\n-methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS) {\n+methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1405,1 +1347,1 @@\n-                                                CompiledMethod* caller_nm, bool is_virtual, bool is_optimized,\n+                                                CompiledMethod* caller_nm, bool is_virtual, bool is_optimized, bool& caller_is_c1,\n@@ -1414,1 +1356,1 @@\n-  if (callee != NULL) {\n+  if (callee != nullptr) {\n@@ -1418,1 +1360,1 @@\n-  if (callee != NULL && !callee->is_in_use()) {\n+  if (callee != nullptr && !callee->is_in_use()) {\n@@ -1420,1 +1362,1 @@\n-    callee = NULL;\n+    callee = nullptr;\n@@ -1423,1 +1365,1 @@\n-  address dest_entry_point = callee == NULL ? 0 : callee->entry_point(); \/\/ used below\n+  address dest_entry_point = callee == nullptr ? 0 : callee->entry_point(); \/\/ used below\n@@ -1427,1 +1369,0 @@\n-  bool caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1430,1 +1371,1 @@\n-    Klass* receiver_klass = NULL;\n+    Klass* receiver_klass = nullptr;\n@@ -1436,1 +1377,1 @@\n-      receiver_klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver->klass();\n+      receiver_klass = invoke_code == Bytecodes::_invokehandle ? nullptr : receiver->klass();\n@@ -1460,1 +1401,1 @@\n-        (callee == NULL || (callee->is_in_use() && callee_method->code() == callee))) {\n+        (callee == nullptr || (callee->is_in_use() && callee_method->code() == callee))) {\n@@ -1466,1 +1407,1 @@\n-        assert((cb != NULL) && cb->is_compiled() && (((CompiledMethod*)cb) == callee),\n+        assert((cb != nullptr) && cb->is_compiled() && (((CompiledMethod*)cb) == callee),\n@@ -1481,1 +1422,1 @@\n-            callee != NULL && callee->is_compiled_by_jvmci()) {\n+            callee != nullptr && callee->is_compiled_by_jvmci()) {\n@@ -1497,1 +1438,1 @@\n-methodHandle SharedRuntime::resolve_sub_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS) {\n+methodHandle SharedRuntime::resolve_sub_helper(bool is_virtual, bool is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1507,1 +1448,1 @@\n-  guarantee(caller_cb != NULL && caller_cb->is_compiled(), \"must be called from compiled method\");\n+  guarantee(caller_cb != nullptr && caller_cb->is_compiled(), \"must be called from compiled method\");\n@@ -1509,1 +1450,0 @@\n-  *caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1512,2 +1452,2 @@\n-  \/\/ note: a) receiver is NULL for static calls\n-  \/\/       b) an exception is thrown if receiver is NULL for non-static calls\n+  \/\/ note: a) receiver is null for static calls\n+  \/\/       b) an exception is thrown if receiver is null for non-static calls\n@@ -1518,0 +1458,4 @@\n+  \/\/ Calls via mismatching methods are always non-scalarized\n+  if (caller_nm->is_compiled_by_c1() || (call_info.resolved_method()->mismatch() && !is_optimized)) {\n+    caller_is_c1 = true;\n+  }\n@@ -1582,1 +1526,1 @@\n-                                                  is_virtual, is_optimized, receiver,\n+                                                  is_virtual, is_optimized, caller_is_c1, receiver,\n@@ -1643,1 +1587,1 @@\n-    guarantee(callee != NULL && callee->is_method(), \"bad handshake\");\n+    guarantee(callee != nullptr && callee->is_method(), \"bad handshake\");\n@@ -1645,1 +1589,1 @@\n-    current->set_callee_target(NULL);\n+    current->set_callee_target(nullptr);\n@@ -1705,1 +1649,1 @@\n-      Klass *recv_klass = (recv != NULL) ? recv->klass() : NULL;\n+      Klass *recv_klass = (recv != nullptr) ? recv->klass() : nullptr;\n@@ -1717,1 +1661,1 @@\n-  bool caller_is_c1;\n+  bool caller_is_c1 = false;\n@@ -1720,1 +1664,1 @@\n-    callee_method = SharedRuntime::resolve_helper(false, false, &caller_is_c1, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(false, false, caller_is_c1, CHECK_NULL);\n@@ -1731,1 +1675,1 @@\n-      enter_special = caller.cb() != NULL && caller.cb()->is_compiled()\n+      enter_special = caller.cb() != nullptr && caller.cb()->is_compiled()\n@@ -1750,1 +1694,1 @@\n-  assert(entry != NULL, \"Jump to zero!\");\n+  assert(entry != nullptr, \"Jump to zero!\");\n@@ -1758,1 +1702,1 @@\n-  bool caller_is_c1;\n+  bool caller_is_c1 = false;\n@@ -1760,1 +1704,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, false, &caller_is_c1, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, false, caller_is_c1, CHECK_NULL);\n@@ -1766,1 +1710,1 @@\n-  assert(entry != NULL, \"Jump to zero!\");\n+  assert(entry != nullptr, \"Jump to zero!\");\n@@ -1775,1 +1719,1 @@\n-  bool caller_is_c1;\n+  bool caller_is_c1 = false;\n@@ -1777,1 +1721,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, true, &caller_is_c1, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, true, caller_is_c1, CHECK_NULL);\n@@ -1783,1 +1727,1 @@\n-  assert(entry != NULL, \"Jump to zero!\");\n+  assert(entry != nullptr, \"Jump to zero!\");\n@@ -1810,1 +1754,1 @@\n-    if (ic_oop != NULL) {\n+    if (ic_oop != nullptr) {\n@@ -1821,1 +1765,1 @@\n-        \/\/ We can't assert for callee_method->code() != NULL because it\n+        \/\/ We can't assert for callee_method->code() != nullptr because it\n@@ -1844,1 +1788,1 @@\n-                                            caller_nm->is_compiled_by_c1(),\n+                                            caller_is_c1,\n@@ -1875,1 +1819,1 @@\n-  \/\/ receiver is NULL for static calls. An exception is thrown for NULL\n+  \/\/ receiver is null for static calls. An exception is thrown for null\n@@ -1950,1 +1894,4 @@\n-  caller_is_c1 = caller_nm->is_compiled_by_c1();\n+  \/\/ Calls via mismatching methods are always non-scalarized\n+  if (caller_nm->is_compiled_by_c1() || call_info.resolved_method()->mismatch()) {\n+    caller_is_c1 = true;\n+  }\n@@ -2031,1 +1978,1 @@\n-    address call_addr = NULL;\n+    address call_addr = nullptr;\n@@ -2042,1 +1989,1 @@\n-    if (call_addr != NULL) {\n+    if (call_addr != nullptr) {\n@@ -2080,1 +2027,1 @@\n-  methodHandle callee_method = find_callee_method(CHECK_(methodHandle()));\n+  methodHandle callee_method = find_callee_method(is_optimized, caller_is_c1, CHECK_(methodHandle()));\n@@ -2139,1 +2086,1 @@\n-    if (callee != NULL && (callee == cb || callee->is_adapter_blob())) {\n+    if (callee != nullptr && (callee == cb || callee->is_adapter_blob())) {\n@@ -2191,1 +2138,1 @@\n-  if (callee == NULL) {\n+  if (callee == nullptr) {\n@@ -2196,1 +2143,1 @@\n-  if (cb == NULL || !cb->is_compiled() || callee->is_unloading()) {\n+  if (cb == nullptr || !cb->is_compiled() || callee->is_unloading()) {\n@@ -2213,2 +2160,2 @@\n-  \/\/ call site with the same old data. clear_code will set code() to NULL\n-  \/\/ at the end of it. If we happen to see that NULL then we can skip trying\n+  \/\/ call site with the same old data. clear_code will set code() to null\n+  \/\/ at the end of it. If we happen to see that null then we can skip trying\n@@ -2216,1 +2163,1 @@\n-  \/\/ from_compiled_entry and the NULL isn't present yet then we lose the race\n+  \/\/ from_compiled_entry and the null isn't present yet then we lose the race\n@@ -2219,1 +2166,1 @@\n-  if (moop->code() == NULL) return;\n+  if (moop->code() == nullptr) return;\n@@ -2272,1 +2219,1 @@\n-  if (src == NULL || dest == NULL) {\n+  if (src == nullptr || dest == nullptr) {\n@@ -2298,2 +2245,2 @@\n-  Symbol* target_klass_name = NULL;\n-  if (target_klass == NULL) {\n+  Symbol* target_klass_name = nullptr;\n+  if (target_klass == nullptr) {\n@@ -2313,2 +2260,2 @@\n-  assert(target_klass != NULL || target_klass_name != NULL, \"one must be provided\");\n-  const char* target_name = target_klass == NULL ? target_klass_name->as_klass_external_name() :\n+  assert(target_klass != nullptr || target_klass_name != nullptr, \"one must be provided\");\n+  const char* target_name = target_klass == nullptr ? target_klass_name->as_klass_external_name() :\n@@ -2322,1 +2269,1 @@\n-  if (target_klass != NULL && caster_klass->module() == target_klass->module()) {\n+  if (target_klass != nullptr && caster_klass->module() == target_klass->module()) {\n@@ -2326,2 +2273,2 @@\n-    target_klass_description = (target_klass != NULL) ? target_klass->class_in_module_of_loader() : \"\";\n-    klass_separator = (target_klass != NULL) ? \"; \" : \"\";\n+    target_klass_description = (target_klass != nullptr) ? target_klass->class_in_module_of_loader() : \"\";\n+    klass_separator = (target_klass != nullptr) ? \"; \" : \"\";\n@@ -2334,1 +2281,1 @@\n-  if (message == NULL) {\n+  if (message == nullptr) {\n@@ -2404,1 +2351,1 @@\n-  if (xtty != NULL)  xtty->head(\"statistics type='SharedRuntime'\");\n+  if (xtty != nullptr)  xtty->head(\"statistics type='SharedRuntime'\");\n@@ -2441,1 +2388,1 @@\n-  if (xtty != NULL)  xtty->tail(\"statistics\");\n+  if (xtty != nullptr)  xtty->tail(\"statistics\");\n@@ -2460,2 +2407,2 @@\n-    Method* method = (nm == NULL) ? NULL : nm->method();\n-    if (method != NULL) {\n+    Method* method = (nm == nullptr) ? nullptr : nm->method();\n+    if (method != nullptr) {\n@@ -2620,1 +2567,1 @@\n-    int total_args_passed = (sig != NULL) ? sig->length() : 0;\n+    int total_args_passed = (sig != nullptr) ? sig->length() : 0;\n@@ -2818,6 +2765,6 @@\n-AdapterHandlerEntry* AdapterHandlerLibrary::_abstract_method_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_no_arg_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_int_arg_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_obj_arg_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_obj_int_arg_handler = NULL;\n-AdapterHandlerEntry* AdapterHandlerLibrary::_obj_obj_arg_handler = NULL;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_abstract_method_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_no_arg_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_int_arg_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_arg_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_int_arg_handler = nullptr;\n+AdapterHandlerEntry* AdapterHandlerLibrary::_obj_obj_arg_handler = nullptr;\n@@ -2825,1 +2772,1 @@\n-BufferBlob* AdapterHandlerLibrary::_buffer = NULL;\n+BufferBlob* AdapterHandlerLibrary::_buffer = nullptr;\n@@ -2852,5 +2799,5 @@\n-  AdapterBlob* no_arg_blob = NULL;\n-  AdapterBlob* int_arg_blob = NULL;\n-  AdapterBlob* obj_arg_blob = NULL;\n-  AdapterBlob* obj_int_arg_blob = NULL;\n-  AdapterBlob* obj_obj_arg_blob = NULL;\n+  AdapterBlob* no_arg_blob = nullptr;\n+  AdapterBlob* int_arg_blob = nullptr;\n+  AdapterBlob* obj_arg_blob = nullptr;\n+  AdapterBlob* obj_int_arg_blob = nullptr;\n+  AdapterBlob* obj_obj_arg_blob = nullptr;\n@@ -2866,1 +2813,1 @@\n-    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),\n+    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(nullptr),\n@@ -2877,1 +2824,1 @@\n-    SigEntry::add_entry(&obj_args.sig(), T_OBJECT, NULL);\n+    SigEntry::add_entry(obj_args.sig(), T_OBJECT, nullptr);\n@@ -2882,1 +2829,1 @@\n-    SigEntry::add_entry(&int_args.sig(), T_INT, NULL);\n+    SigEntry::add_entry(int_args.sig(), T_INT, nullptr);\n@@ -2887,2 +2834,2 @@\n-    SigEntry::add_entry(&obj_int_args.sig(), T_OBJECT, NULL);\n-    SigEntry::add_entry(&obj_int_args.sig(), T_INT, NULL);\n+    SigEntry::add_entry(obj_int_args.sig(), T_OBJECT, nullptr);\n+    SigEntry::add_entry(obj_int_args.sig(), T_INT, nullptr);\n@@ -2893,2 +2840,2 @@\n-    SigEntry::add_entry(&obj_obj_args.sig(), T_OBJECT, NULL);\n-    SigEntry::add_entry(&obj_obj_args.sig(), T_OBJECT, NULL);\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT, nullptr);\n+    SigEntry::add_entry(obj_obj_args.sig(), T_OBJECT, nullptr);\n@@ -2898,5 +2845,5 @@\n-    assert(no_arg_blob != NULL &&\n-          obj_arg_blob != NULL &&\n-          int_arg_blob != NULL &&\n-          obj_int_arg_blob != NULL &&\n-          obj_obj_arg_blob != NULL, \"Initial adapters must be properly created\");\n+    assert(no_arg_blob != nullptr &&\n+          obj_arg_blob != nullptr &&\n+          int_arg_blob != nullptr &&\n+          obj_int_arg_blob != nullptr &&\n+          obj_obj_arg_blob != nullptr, \"Initial adapters must be properly created\");\n@@ -2928,1 +2875,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -2936,1 +2883,1 @@\n-        return NULL;\n+        return nullptr;\n@@ -2945,2 +2892,2 @@\n-          if (vk != NULL) {\n-            return NULL;\n+          if (vk != nullptr) {\n+            return nullptr;\n@@ -2967,2 +2914,2 @@\n-          if (vk != NULL) {\n-            return NULL;\n+          if (vk != nullptr) {\n+            return nullptr;\n@@ -2983,1 +2930,1 @@\n-  return NULL;\n+  return nullptr;\n@@ -2988,1 +2935,1 @@\n-  _regs(NULL), _regs_cc(NULL), _regs_cc_ro(NULL),\n+  _regs(nullptr), _regs_cc(nullptr), _regs_cc_ro(nullptr),\n@@ -2990,4 +2937,4 @@\n-  _c1_needs_stack_repair(false), _c2_needs_stack_repair(false) {\n-  _sig = new GrowableArray<SigEntry>((method != NULL) ? method->size_of_parameters() : 1);\n-  _sig_cc = new GrowableArray<SigEntry>((method != NULL) ? method->size_of_parameters() : 1);\n-  _sig_cc_ro = new GrowableArray<SigEntry>((method != NULL) ? method->size_of_parameters() : 1);\n+  _c1_needs_stack_repair(false), _c2_needs_stack_repair(false), _supers(nullptr) {\n+  _sig = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+  _sig_cc = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n+  _sig_cc_ro = new GrowableArray<SigEntry>((method != nullptr) ? method->size_of_parameters() : 1);\n@@ -3035,0 +2982,44 @@\n+\/\/ Returns all super methods (transitive) in classes and interfaces that are overridden by the current method.\n+GrowableArray<Method*>* CompiledEntrySignature::get_supers() {\n+  if (_supers != nullptr) {\n+    return _supers;\n+  }\n+  _supers = new GrowableArray<Method*>();\n+  \/\/ Skip private, static, and <init> methods\n+  if (_method->is_private() || _method->is_static() || _method->is_object_constructor()) {\n+    return _supers;\n+  }\n+  Symbol* name = _method->name();\n+  Symbol* signature = _method->signature();\n+  const Klass* holder = _method->method_holder()->super();\n+  Symbol* holder_name = holder->name();\n+  ThreadInVMfromUnknown tiv;\n+  JavaThread* current = JavaThread::current();\n+  HandleMark hm(current);\n+  Handle loader(current, _method->method_holder()->class_loader());\n+\n+  \/\/ Walk up the class hierarchy and search for super methods\n+  while (holder != nullptr) {\n+    Method* super_method = holder->lookup_method(name, signature);\n+    if (super_method == nullptr) {\n+      break;\n+    }\n+    if (!super_method->is_static() && !super_method->is_private() &&\n+        (!super_method->is_package_private() ||\n+         super_method->method_holder()->is_same_class_package(loader(), holder_name))) {\n+      _supers->push(super_method);\n+    }\n+    holder = super_method->method_holder()->super();\n+  }\n+  \/\/ Search interfaces for super methods\n+  Array<InstanceKlass*>* interfaces = _method->method_holder()->transitive_interfaces();\n+  for (int i = 0; i < interfaces->length(); ++i) {\n+    Method* m = interfaces->at(i)->lookup_method(name, signature);\n+    if (m != nullptr && !m->is_static() && m->is_public()) {\n+      _supers->push(m);\n+    }\n+  }\n+  return _supers;\n+}\n+\n+\/\/ Iterate over arguments and compute scalarized and non-scalarized signatures\n@@ -3036,2 +3027,1 @@\n-  \/\/ Iterate over arguments and compute scalarized and non-scalarized signatures\n-  if (_method != NULL) {\n+  if (_method != nullptr) {\n@@ -3059,12 +3049,57 @@\n-        \/\/ TODO 8284443 Mismatch handling, we need to check parent method args (look at klassVtable::needs_new_vtable_entry)\n-        if (vk != NULL && vk->can_be_passed_as_fields() && (init || _method->is_scalarized_arg(arg_num))) {\n-          _num_inline_args++;\n-          has_scalarized = true;\n-          int last = _sig_cc->length();\n-          int last_ro = _sig_cc_ro->length();\n-          _sig_cc->appendAll(vk->extended_sig());\n-          _sig_cc_ro->appendAll(vk->extended_sig());\n-          if (bt == T_OBJECT) {\n-            \/\/ Nullable inline type argument, insert InlineTypeNode::IsInit field right after T_PRIMITIVE_OBJECT\n-            _sig_cc->insert_before(last+1, SigEntry(T_BOOLEAN, -1, NULL));\n-            _sig_cc_ro->insert_before(last_ro+1, SigEntry(T_BOOLEAN, -1, NULL));\n+        if (vk != nullptr && vk->can_be_passed_as_fields() && (init || _method->is_scalarized_arg(arg_num))) {\n+          \/\/ Check for a calling convention mismatch with super method(s)\n+          bool scalar_super = false;\n+          bool non_scalar_super = false;\n+          GrowableArray<Method*>* supers = get_supers();\n+          for (int i = 0; i < supers->length(); ++i) {\n+            Method* super_method = supers->at(i);\n+            if (super_method->is_scalarized_arg(arg_num)) {\n+              scalar_super = true;\n+            } else {\n+              non_scalar_super = true;\n+            }\n+          }\n+#ifdef ASSERT\n+          \/\/ Randomly enable below code paths for stress testing\n+          bool stress = init && StressCallingConvention;\n+          if (stress && (os::random() & 1) == 1) {\n+            non_scalar_super = true;\n+            if ((os::random() & 1) == 1) {\n+              scalar_super = true;\n+            }\n+          }\n+#endif\n+          if (non_scalar_super) {\n+            \/\/ Found a super method with a non-scalarized argument. Fall back to the non-scalarized calling convention.\n+            if (scalar_super) {\n+              \/\/ Found non-scalar *and* scalar super methods. We can't handle both.\n+              \/\/ Mark the scalar method as mismatch and re-compile call sites to use non-scalarized calling convention.\n+              for (int i = 0; i < supers->length(); ++i) {\n+                Method* super_method = supers->at(i);\n+                if (super_method->is_scalarized_arg(arg_num) debug_only(|| (stress && (os::random() & 1) == 1))) {\n+                  super_method->set_mismatch();\n+                  MutexLocker ml(Compile_lock, Mutex::_safepoint_check_flag);\n+                  JavaThread* thread = JavaThread::current();\n+                  HandleMark hm(thread);\n+                  methodHandle mh(thread, super_method);\n+                  DeoptimizationScope deopt_scope;\n+                  CodeCache::mark_for_deoptimization(&deopt_scope, mh());\n+                  deopt_scope.deoptimize_marked();\n+                }\n+              }\n+            }\n+            \/\/ Fall back to non-scalarized calling convention\n+            SigEntry::add_entry(_sig_cc, T_OBJECT, ss.as_symbol());\n+            SigEntry::add_entry(_sig_cc_ro, T_OBJECT, ss.as_symbol());\n+          } else {\n+            _num_inline_args++;\n+            has_scalarized = true;\n+            int last = _sig_cc->length();\n+            int last_ro = _sig_cc_ro->length();\n+            _sig_cc->appendAll(vk->extended_sig());\n+            _sig_cc_ro->appendAll(vk->extended_sig());\n+            if (bt == T_OBJECT) {\n+              \/\/ Nullable inline type argument, insert InlineTypeNode::IsInit field right after T_PRIMITIVE_OBJECT\n+              _sig_cc->insert_before(last+1, SigEntry(T_BOOLEAN, -1, nullptr));\n+              _sig_cc_ro->insert_before(last_ro+1, SigEntry(T_BOOLEAN, -1, nullptr));\n+            }\n@@ -3129,1 +3164,1 @@\n-  if (entry != NULL) {\n+  if (entry != nullptr) {\n@@ -3134,1 +3169,1 @@\n-  AdapterBlob* new_adapter = NULL;\n+  AdapterBlob* new_adapter = nullptr;\n@@ -3139,3 +3174,7 @@\n-    method->set_has_scalarized_args(true);\n-    method->set_c1_needs_stack_repair(ces.c1_needs_stack_repair());\n-    method->set_c2_needs_stack_repair(ces.c2_needs_stack_repair());\n+    method->set_has_scalarized_args();\n+    if (ces.c1_needs_stack_repair()) {\n+      method->set_c1_needs_stack_repair();\n+    }\n+    if (ces.c2_needs_stack_repair()) {\n+      method->set_c2_needs_stack_repair();\n+    }\n@@ -3152,1 +3191,1 @@\n-      entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),\n+      entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(nullptr),\n@@ -3156,2 +3195,2 @@\n-      GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc_ro().length(), mtInternal);\n-      heap_sig->appendAll(&ces.sig_cc_ro());\n+      GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc_ro()->length(), mtInternal);\n+      heap_sig->appendAll(ces.sig_cc_ro());\n@@ -3163,1 +3202,1 @@\n-    entry = lookup(&ces.sig_cc(), ces.has_inline_recv());\n+    entry = lookup(ces.sig_cc(), ces.has_inline_recv());\n@@ -3165,1 +3204,1 @@\n-    if (entry != NULL) {\n+    if (entry != nullptr) {\n@@ -3168,1 +3207,1 @@\n-        AdapterBlob* comparison_blob = NULL;\n+        AdapterBlob* comparison_blob = nullptr;\n@@ -3170,1 +3209,1 @@\n-        assert(comparison_blob == NULL, \"no blob should be created when creating an adapter for comparison\");\n+        assert(comparison_blob == nullptr, \"no blob should be created when creating an adapter for comparison\");\n@@ -3183,1 +3222,1 @@\n-  if (new_adapter != NULL) {\n+  if (new_adapter != nullptr) {\n@@ -3193,5 +3232,5 @@\n-  \/\/ StubRoutines::code2() is initialized after this function can be called. As a result,\n-  \/\/ VerifyAdapterCalls and VerifyAdapterSharing can fail if we re-use code that generated\n-  \/\/ prior to StubRoutines::code2() being set. Checks refer to checks generated in an I2C\n-  \/\/ stub that ensure that an I2C stub is called from an interpreter frame.\n-  bool contains_all_checks = StubRoutines::code2() != NULL;\n+  \/\/ StubRoutines::_final_stubs_code is initialized after this function can be called. As a result,\n+  \/\/ VerifyAdapterCalls and VerifyAdapterSharing can fail if we re-use code that generated prior\n+  \/\/ to all StubRoutines::_final_stubs_code being set. Checks refer to runtime range checks generated\n+  \/\/ in an I2C stub that ensure that an I2C stub is called from an interpreter frame or stubs.\n+  bool contains_all_checks = StubRoutines::final_stubs_code() != nullptr;\n@@ -3206,1 +3245,1 @@\n-  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(&ces.sig_cc(), ces.has_inline_recv());\n+  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(ces.sig_cc(), ces.has_inline_recv());\n@@ -3210,1 +3249,1 @@\n-                                                &ces.sig(),\n+                                                ces.sig(),\n@@ -3212,1 +3251,1 @@\n-                                                &ces.sig_cc(),\n+                                                ces.sig_cc(),\n@@ -3214,1 +3253,1 @@\n-                                                &ces.sig_cc_ro(),\n+                                                ces.sig_cc_ro(),\n@@ -3222,2 +3261,2 @@\n-    GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc().length(), mtInternal);\n-    heap_sig->appendAll(&ces.sig_cc());\n+    GrowableArray<SigEntry>* heap_sig = new (mtInternal) GrowableArray<SigEntry>(ces.sig_cc()->length(), mtInternal);\n+    heap_sig->appendAll(ces.sig_cc());\n@@ -3237,1 +3276,1 @@\n-  if (new_adapter == NULL) {\n+  if (new_adapter == nullptr) {\n@@ -3241,1 +3280,1 @@\n-    return NULL;\n+    return nullptr;\n@@ -3255,1 +3294,1 @@\n-      if (first_pc != NULL) {\n+      if (first_pc != nullptr) {\n@@ -3275,7 +3314,7 @@\n-  if (base == NULL)  base = _c2i_entry;\n-  assert(base <= _c2i_entry || _c2i_entry == NULL, \"\");\n-  assert(base <= _c2i_inline_entry || _c2i_inline_entry == NULL, \"\");\n-  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == NULL, \"\");\n-  assert(base <= _c2i_unverified_entry || _c2i_unverified_entry == NULL, \"\");\n-  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == NULL, \"\");\n-  assert(base <= _c2i_no_clinit_check_entry || _c2i_no_clinit_check_entry == NULL, \"\");\n+  if (base == nullptr)  base = _c2i_entry;\n+  assert(base <= _c2i_entry || _c2i_entry == nullptr, \"\");\n+  assert(base <= _c2i_inline_entry || _c2i_inline_entry == nullptr, \"\");\n+  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == nullptr, \"\");\n+  assert(base <= _c2i_unverified_entry || _c2i_unverified_entry == nullptr, \"\");\n+  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == nullptr, \"\");\n+  assert(base <= _c2i_no_clinit_check_entry || _c2i_no_clinit_check_entry == nullptr, \"\");\n@@ -3287,1 +3326,1 @@\n-  assert(old_base != NULL, \"\");\n+  assert(old_base != nullptr, \"\");\n@@ -3289,1 +3328,1 @@\n-  if (_i2c_entry != NULL)\n+  if (_i2c_entry != nullptr)\n@@ -3291,1 +3330,1 @@\n-  if (_c2i_entry != NULL)\n+  if (_c2i_entry != nullptr)\n@@ -3293,1 +3332,1 @@\n-  if (_c2i_inline_entry != NULL)\n+  if (_c2i_inline_entry != nullptr)\n@@ -3295,1 +3334,1 @@\n-  if (_c2i_inline_ro_entry != NULL)\n+  if (_c2i_inline_ro_entry != nullptr)\n@@ -3297,1 +3336,1 @@\n-  if (_c2i_unverified_entry != NULL)\n+  if (_c2i_unverified_entry != nullptr)\n@@ -3299,1 +3338,1 @@\n-  if (_c2i_unverified_inline_entry != NULL)\n+  if (_c2i_unverified_inline_entry != nullptr)\n@@ -3301,1 +3340,1 @@\n-  if (_c2i_no_clinit_check_entry != NULL)\n+  if (_c2i_no_clinit_check_entry != nullptr)\n@@ -3309,1 +3348,1 @@\n-  if (_sig_cc != NULL) {\n+  if (_sig_cc != nullptr) {\n@@ -3330,1 +3369,1 @@\n-  assert(_saved_code != NULL && other->_saved_code != NULL, \"code not saved\");\n+  assert(_saved_code != nullptr && other->_saved_code != nullptr, \"code not saved\");\n@@ -3349,1 +3388,1 @@\n-  nmethod* nm = NULL;\n+  nmethod* nm = nullptr;\n@@ -3362,1 +3401,1 @@\n-    if (method->code() != NULL) {\n+    if (method->code() != nullptr) {\n@@ -3372,1 +3411,1 @@\n-    if (buf != NULL) {\n+    if (buf != nullptr) {\n@@ -3423,1 +3462,1 @@\n-      if (nm != NULL) {\n+      if (nm != nullptr) {\n@@ -3442,1 +3481,1 @@\n-  if (nm != NULL) {\n+  if (nm != nullptr) {\n@@ -3560,1 +3599,1 @@\n-    if (kptr->obj() != NULL) active_monitor_count++;\n+    if (kptr->obj() != nullptr) active_monitor_count++;\n@@ -3584,1 +3623,1 @@\n-    if (kptr2->obj() != NULL) {         \/\/ Avoid 'holes' in the monitor array\n+    if (kptr2->obj() != nullptr) {         \/\/ Avoid 'holes' in the monitor array\n@@ -3646,1 +3685,1 @@\n-  if (get_i2c_entry() != NULL) {\n+  if (get_i2c_entry() != nullptr) {\n@@ -3649,1 +3688,1 @@\n-  if (get_c2i_entry() != NULL) {\n+  if (get_c2i_entry() != nullptr) {\n@@ -3652,1 +3691,1 @@\n-  if (get_c2i_entry() != NULL) {\n+  if (get_c2i_entry() != nullptr) {\n@@ -3655,1 +3694,1 @@\n-  if (get_c2i_entry() != NULL) {\n+  if (get_c2i_entry() != nullptr) {\n@@ -3658,1 +3697,1 @@\n-  if (get_c2i_unverified_entry() != NULL) {\n+  if (get_c2i_unverified_entry() != nullptr) {\n@@ -3661,1 +3700,1 @@\n-  if (get_c2i_unverified_entry() != NULL) {\n+  if (get_c2i_unverified_entry() != nullptr) {\n@@ -3664,1 +3703,1 @@\n-  if (get_c2i_no_clinit_check_entry() != NULL) {\n+  if (get_c2i_no_clinit_check_entry() != nullptr) {\n@@ -3688,1 +3727,1 @@\n-  CompiledMethod* nm = NULL;\n+  CompiledMethod* nm = nullptr;\n@@ -3702,1 +3741,1 @@\n-    Method* method = NULL;\n+    Method* method = nullptr;\n@@ -3706,1 +3745,1 @@\n-      if (method != NULL && method->has_reserved_stack_access()) {\n+      if (method != nullptr && method->has_reserved_stack_access()) {\n@@ -3711,1 +3750,1 @@\n-      if (cb != NULL && cb->is_compiled()) {\n+      if (cb != nullptr && cb->is_compiled()) {\n@@ -3716,1 +3755,1 @@\n-        for (ScopeDesc *sd = nm->scope_desc_near(fr.pc()); sd != NULL; sd = sd->sender()) {\n+        for (ScopeDesc *sd = nm->scope_desc_near(fr.pc()); sd != nullptr; sd = sd->sender()) {\n@@ -3718,1 +3757,1 @@\n-          if (method != NULL && method->has_reserved_stack_access()) {\n+          if (method != nullptr && method->has_reserved_stack_access()) {\n@@ -3746,1 +3785,1 @@\n-  if (new_obj == NULL) return;\n+  if (new_obj == nullptr) return;\n@@ -3789,1 +3828,1 @@\n-      assert(vk != NULL, \"Unexpected klass\");\n+      assert(vk != nullptr, \"Unexpected klass\");\n@@ -3826,1 +3865,1 @@\n-  if (regs == NULL) {\n+  if (regs == nullptr) {\n@@ -3922,1 +3961,1 @@\n-    assert(verif_vk == NULL, \"broken calling convention\");\n+    assert(verif_vk == nullptr, \"broken calling convention\");\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":372,"deletions":333,"binary":false,"changes":705,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -53,1 +53,1 @@\n-                                          CompiledMethod* caller_nm, bool is_virtual, bool is_optimized,\n+                                          CompiledMethod* caller_nm, bool is_virtual, bool is_optimized, bool& caller_is_c1,\n@@ -55,1 +55,1 @@\n-  static methodHandle resolve_sub_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS);\n+  static methodHandle resolve_sub_helper(bool is_virtual, bool is_optimized, bool& caller_is_c1, TRAPS);\n@@ -132,2 +132,0 @@\n-  static jfloat  hf2f(jshort  x);\n-  static jshort  f2hf(jfloat  x);\n@@ -221,1 +219,1 @@\n-    assert(_ic_miss_blob!= NULL, \"oops\");\n+    assert(_ic_miss_blob!= nullptr, \"oops\");\n@@ -226,1 +224,1 @@\n-    assert(_wrong_method_blob!= NULL, \"oops\");\n+    assert(_wrong_method_blob!= nullptr, \"oops\");\n@@ -231,1 +229,1 @@\n-    assert(_wrong_method_abstract_blob!= NULL, \"oops\");\n+    assert(_wrong_method_abstract_blob!= nullptr, \"oops\");\n@@ -241,1 +239,1 @@\n-    assert(_resolve_opt_virtual_call_blob != NULL, \"oops\");\n+    assert(_resolve_opt_virtual_call_blob != nullptr, \"oops\");\n@@ -245,1 +243,1 @@\n-    assert(_resolve_virtual_call_blob != NULL, \"oops\");\n+    assert(_resolve_virtual_call_blob != nullptr, \"oops\");\n@@ -249,1 +247,1 @@\n-    assert(_resolve_static_call_blob != NULL, \"oops\");\n+    assert(_resolve_static_call_blob != nullptr, \"oops\");\n@@ -269,1 +267,9 @@\n-  static void throw_and_post_jvmti_exception(JavaThread* current, Symbol* name, const char *message = NULL);\n+  static void throw_and_post_jvmti_exception(JavaThread* current, Symbol* name, const char *message = nullptr);\n+\n+#if INCLUDE_JVMTI\n+  \/\/ Functions for JVMTI notifications\n+  static void notify_jvmti_vthread_start(oopDesc* vt, jboolean hide, JavaThread* current);\n+  static void notify_jvmti_vthread_end(oopDesc* vt, jboolean hide, JavaThread* current);\n+  static void notify_jvmti_vthread_mount(oopDesc* vt, jboolean hide, JavaThread* current);\n+  static void notify_jvmti_vthread_unmount(oopDesc* vt, jboolean hide, JavaThread* current);\n+#endif\n@@ -320,1 +326,1 @@\n-  static char* generate_class_cast_message(Klass* caster_klass, Klass* target_klass, Symbol* target_klass_name = NULL);\n+  static char* generate_class_cast_message(Klass* caster_klass, Klass* target_klass, Symbol* target_klass_name = nullptr);\n@@ -324,1 +330,1 @@\n-  static methodHandle resolve_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS);\n+  static methodHandle resolve_helper(bool is_virtual, bool is_optimized, bool& caller_is_c1, TRAPS);\n@@ -345,1 +351,1 @@\n-  static methodHandle find_callee_method(TRAPS);\n+  static methodHandle find_callee_method(bool is_optimized, bool& caller_is_c1, TRAPS);\n@@ -352,3 +358,3 @@\n-    assert(callee_method->verified_code_entry() != NULL, \"Jump to zero!\");\n-    assert(callee_method->verified_inline_code_entry() != NULL, \"Jump to zero!\");\n-    assert(callee_method->verified_inline_ro_code_entry() != NULL, \"Jump to zero!\");\n+    assert(callee_method->verified_code_entry() != nullptr, \"Jump to zero!\");\n+    assert(callee_method->verified_inline_code_entry() != nullptr, \"Jump to zero!\");\n+    assert(callee_method->verified_inline_ro_code_entry() != nullptr, \"Jump to zero!\");\n@@ -405,1 +411,1 @@\n-  \/\/ NULL is being passed as the second VMRegPair array, so arguments are either\n+  \/\/ null is being passed as the second VMRegPair array, so arguments are either\n@@ -680,1 +686,1 @@\n-    _sig_cc(NULL)\n+    _sig_cc(nullptr)\n@@ -739,1 +745,1 @@\n-                                        address c2i_unverified_entry, address c2i_unverified_inline_entry, address c2i_no_clinit_check_entry = NULL);\n+                                        address c2i_unverified_entry, address c2i_unverified_inline_entry, address c2i_no_clinit_check_entry = nullptr);\n@@ -761,3 +767,3 @@\n-  GrowableArray<SigEntry> *_sig;\n-  GrowableArray<SigEntry> *_sig_cc;\n-  GrowableArray<SigEntry> *_sig_cc_ro;\n+  GrowableArray<SigEntry>* _sig;\n+  GrowableArray<SigEntry>* _sig_cc;\n+  GrowableArray<SigEntry>* _sig_cc_ro;\n@@ -775,0 +781,2 @@\n+  GrowableArray<Method*>* _supers;\n+\n@@ -779,1 +787,1 @@\n-  GrowableArray<SigEntry>& sig()       const { return *_sig; }\n+  GrowableArray<SigEntry>* sig()       const { return _sig; }\n@@ -782,1 +790,1 @@\n-  GrowableArray<SigEntry>& sig_cc()    const { return *_sig_cc; }\n+  GrowableArray<SigEntry>* sig_cc()    const { return _sig_cc; }\n@@ -785,1 +793,1 @@\n-  GrowableArray<SigEntry>& sig_cc_ro() const { return *_sig_cc_ro; }\n+  GrowableArray<SigEntry>* sig_cc_ro() const { return _sig_cc_ro; }\n@@ -803,1 +811,3 @@\n-  CompiledEntrySignature(Method* method = NULL);\n+  GrowableArray<Method*>* get_supers();\n+\n+  CompiledEntrySignature(Method* method = nullptr);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":38,"deletions":28,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -661,3 +661,3 @@\n-    public interface ShuffleIotaOperation<S extends VectorSpecies<?>,\n-                                          SH extends VectorShuffle<?>> {\n-        SH apply(int length, int start, int step, S s);\n+    public interface IndexPartiallyInUpperRangeOperation<E,\n+                                                         M extends VectorMask<E>> {\n+        M apply(long offset, long limit);\n@@ -669,25 +669,6 @@\n-     S extends VectorSpecies<E>,\n-     SH extends VectorShuffle<E>>\n-    SH shuffleIota(Class<E> eClass, Class<? extends SH> shClass, S s,\n-                   int length,\n-                   int start, int step, int wrap,\n-                   ShuffleIotaOperation<S, SH> defaultImpl) {\n-       assert isNonCapturingLambda(defaultImpl) : defaultImpl;\n-       return defaultImpl.apply(length, start, step, s);\n-    }\n-\n-    public interface ShuffleToVectorOperation<V extends Vector<?>,\n-                                              SH extends VectorShuffle<?>> {\n-       V apply(SH sh);\n-    }\n-\n-    @IntrinsicCandidate\n-    public static\n-    <V extends Vector<E>,\n-     SH extends VectorShuffle<E>,\n-     E>\n-    V shuffleToVector(Class<? extends Vector<E>> vClass, Class<E> eClass, Class<? extends SH> shClass, SH sh,\n-                      int length,\n-                      ShuffleToVectorOperation<V, SH> defaultImpl) {\n-      assert isNonCapturingLambda(defaultImpl) : defaultImpl;\n-      return defaultImpl.apply(sh);\n+     M extends VectorMask<E>>\n+    M indexPartiallyInUpperRange(Class<? extends M> mClass, Class<E> eClass,\n+                                 int length, long offset, long limit,\n+                                 IndexPartiallyInUpperRangeOperation<E, M> defaultImpl) {\n+        assert isNonCapturingLambda(defaultImpl) : defaultImpl;\n+        return defaultImpl.apply(offset, limit);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/vm\/vector\/VectorSupport.java","additions":9,"deletions":28,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -214,1 +214,2 @@\n-    public VectorMask<E> andNot(VectorMask<E> m) {\n+    @ForceInline\n+    public final VectorMask<E> andNot(VectorMask<E> m) {\n@@ -218,0 +219,6 @@\n+    @Override\n+    @ForceInline\n+    public final VectorMask<E> eq(VectorMask<E> m) {\n+        return xor(m.not());\n+    }\n+\n@@ -284,1 +291,1 @@\n-    @Override\n+    \/*package-private*\/\n@@ -286,1 +293,1 @@\n-    public VectorMask<E> indexInRange(int offset, int limit) {\n+    VectorMask<E> indexPartiallyInRange(int offset, int limit) {\n@@ -290,1 +297,1 @@\n-        return this.andNot(badMask);\n+        return badMask.not();\n@@ -293,1 +300,1 @@\n-    @Override\n+    \/*package-private*\/\n@@ -295,1 +302,1 @@\n-    public VectorMask<E> indexInRange(long offset, long limit) {\n+    VectorMask<E> indexPartiallyInRange(long offset, long limit) {\n@@ -299,1 +306,1 @@\n-        return this.andNot(badMask);\n+        return badMask.not();\n@@ -302,0 +309,27 @@\n+    @Override\n+    @ForceInline\n+    public VectorMask<E> indexInRange(int offset, int limit) {\n+        if (offset < 0) {\n+            return this.and(indexPartiallyInRange(offset, limit));\n+        } else if (offset >= limit) {\n+            return vectorSpecies().maskAll(false);\n+        } else if (limit - offset >= length()) {\n+            return this;\n+        }\n+        return this.and(indexPartiallyInUpperRange(offset, limit));\n+    }\n+\n+    @ForceInline\n+    public VectorMask<E> indexInRange(long offset, long limit) {\n+        if (offset < 0) {\n+            return this.and(indexPartiallyInRange(offset, limit));\n+        } else if (offset >= limit) {\n+            return vectorSpecies().maskAll(false);\n+        } else if (limit - offset >= length()) {\n+            return this;\n+        }\n+        return this.and(indexPartiallyInUpperRange(offset, limit));\n+    }\n+\n+    abstract VectorMask<E> indexPartiallyInUpperRange(long offset, long limit);\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/AbstractMask.java","additions":41,"deletions":7,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+import jdk.internal.vm.vector.VectorSupport;\n@@ -36,1 +37,1 @@\n-    \/\/ Internal representation allows for a maximum index of 256\n+    \/\/ Internal representation allows for a maximum index of E.MAX_VALUE - 1\n@@ -39,26 +40,0 @@\n-    static VectorPayloadMF prepare(int length, int[] reorder, int offset) {\n-        VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, length);\n-        payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n-        long mf_offset = payload.multiFieldOffset();\n-        for (int i = 0; i < length; i++) {\n-            int si = reorder[offset + i];\n-            si = partiallyWrapIndex(si, length);\n-            Unsafe.getUnsafe().putByte(payload, mf_offset + i * Byte.BYTES, (byte) si);\n-        }\n-        payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n-        return payload;\n-    }\n-\n-    static VectorPayloadMF prepare(int length, IntUnaryOperator f) {\n-        VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, length);\n-        payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n-        long offset = payload.multiFieldOffset();\n-        for (int i = 0; i < length; i++) {\n-            int si = f.applyAsInt(i);\n-            si = partiallyWrapIndex(si, length);\n-            Unsafe.getUnsafe().putByte(payload, offset + i * Byte.BYTES, (byte) si);\n-        }\n-        payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n-        return payload;\n-    }\n-\n@@ -66,1 +41,1 @@\n-    abstract VectorPayloadMF reorder();\n+    abstract VectorPayloadMF indices();\n@@ -77,0 +52,16 @@\n+    \/*package-private*\/\n+    abstract AbstractVector<?> toBitsVector();\n+\n+    final AbstractVector<?> toBitsVectorTemplate() {\n+        AbstractSpecies<?> dsp = vspecies().asIntegral();\n+        Class<?> etype = dsp.elementType();\n+        Class<?> rvtype = dsp.dummyVectorMF().getClass();\n+        return VectorSupport.convert(VectorSupport.VECTOR_OP_REINTERPRET,\n+                                     getClass(), etype, length(),\n+                                     rvtype, etype, length(),\n+                                     this, dsp,\n+                                     (v, s) -> v.toBitsVector0());\n+    }\n+\n+    abstract AbstractVector<?> toBitsVector0();\n+\n@@ -79,9 +70,2 @@\n-    public void intoArray(int[] a, int offset) {\n-        VectorPayloadMF reorder = reorder();\n-        int vlen = reorder.length();\n-        long mf_offset = reorder.multiFieldOffset();\n-        for (int i = 0; i < vlen; i++) {\n-            int sourceIndex = Unsafe.getUnsafe().getByte(reorder, mf_offset + i * Byte.BYTES);\n-            assert(sourceIndex >= -vlen && sourceIndex < vlen);\n-            a[offset + i] = sourceIndex;\n-        }\n+    public final Vector<E> toVector() {\n+        return toBitsVector().castShape(vspecies(), 0);\n@@ -92,3 +76,2 @@\n-    public int[] toArray() {\n-        VectorPayloadMF reorder = reorder();\n-        int[] a = new int[reorder.length()];\n+    public final int[] toArray() {\n+        int[] a = new int[length()];\n@@ -99,1 +82,1 @@\n-    \/*package-private*\/\n+    @Override\n@@ -101,9 +84,5 @@\n-    final\n-    AbstractVector<E>\n-    toVectorTemplate() {\n-        \/\/ Note that the values produced by laneSource\n-        \/\/ are already clipped.  At this point we convert\n-        \/\/ them from internal ints (or bytes) into the ETYPE.\n-        \/\/ FIXME: Use a conversion intrinsic for this operation.\n-        \/\/ https:\/\/bugs.openjdk.org\/browse\/JDK-8225740\n-        return (AbstractVector<E>) vspecies().fromIntValues(toArray());\n+    public final <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n+        if (length() != s.length()) {\n+            throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n+        }\n+        return toBitsVector().toShuffle((AbstractSpecies<F>) s);\n@@ -112,0 +91,1 @@\n+    @Override\n@@ -117,2 +97,2 @@\n-        Vector<E> shufvec = this.toVector();\n-        VectorMask<E> vecmask = shufvec.compare(VectorOperators.LT, vspecies().zero());\n+        Vector<?> shufvec = this.toBitsVector();\n+        VectorMask<?> vecmask = shufvec.compare(VectorOperators.LT, 0);\n@@ -120,3 +100,2 @@\n-            VectorPayloadMF reorder = reorder();\n-            long offset = reorder.multiFieldOffset();\n-            throw checkIndexFailed(Unsafe.getUnsafe().getByte(reorder, offset + vecmask.firstTrue() * Byte.BYTES), length());\n+            int[] indices = toArray();\n+            throw checkIndexFailed(indices[vecmask.firstTrue()], length());\n@@ -127,0 +106,1 @@\n+    @Override\n@@ -128,9 +108,4 @@\n-    public final VectorShuffle<E> wrapIndexes() {\n-        Vector<E> shufvec = this.toVector();\n-        VectorMask<E> vecmask = shufvec.compare(VectorOperators.LT, vspecies().zero());\n-        if (vecmask.anyTrue()) {\n-            \/\/ FIXME: vectorize this\n-            VectorPayloadMF reorder = reorder();\n-            return wrapAndRebuild(reorder);\n-        }\n-        return this;\n+    public final VectorMask<E> laneIsValid() {\n+        Vector<?> shufvec = this.toBitsVector();\n+        return shufvec.compare(VectorOperators.GE, 0)\n+                      .cast(vspecies());\n@@ -140,19 +115,7 @@\n-    public final VectorShuffle<E> wrapAndRebuild(VectorPayloadMF oldReorder) {\n-        int length = oldReorder.length();\n-        VectorPayloadMF reorder = VectorPayloadMF.newInstanceFactory(byte.class, length);\n-        long offset = oldReorder.multiFieldOffset();\n-        reorder = Unsafe.getUnsafe().makePrivateBuffer(reorder);\n-        for (int i = 0; i < length; i++) {\n-            int si = Unsafe.getUnsafe().getByte(oldReorder, offset + i * Byte.BYTES);\n-            \/\/ FIXME: This does not work unless it's a power of 2.\n-            if ((length & (length - 1)) == 0) {\n-                si += si & length;  \/\/ power-of-two optimization\n-            } else if (si < 0) {\n-                \/\/ non-POT code requires a conditional add\n-                si += length;\n-            }\n-            assert(si >= 0 && si < length);\n-            Unsafe.getUnsafe().putByte(reorder, offset + i * Byte.BYTES, (byte) si);\n-        }\n-        reorder = Unsafe.getUnsafe().finishPrivateBuffer(reorder);\n-        return vspecies().dummyVectorMF().shuffleFromBytes(reorder);\n+    @Override\n+    @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n+    public final VectorShuffle<E> rearrange(VectorShuffle<E> shuffle) {\n+        Vector v = toBitsVector();\n+        return (VectorShuffle<E>) v.rearrange(shuffle.cast(vspecies().asIntegral()))\n+                                   .toShuffle()\n+                                   .cast(vspecies());\n@@ -162,3 +125,11 @@\n-    public final VectorMask<E> laneIsValid() {\n-        Vector<E> shufvec = this.toVector();\n-        return shufvec.compare(VectorOperators.GE, vspecies().zero());\n+    @Override\n+    @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n+    public final VectorShuffle<E> wrapIndexes() {\n+        Vector v = toBitsVector();\n+        if ((length() & (length() - 1)) == 0) {\n+            v = v.lanewise(VectorOperators.AND, length() - 1);\n+        } else {\n+            v = v.blend(v.lanewise(VectorOperators.ADD, length()),\n+                        v.compare(VectorOperators.LT, 0));\n+        }\n+        return (VectorShuffle<E>) v.toShuffle().cast(vspecies());\n@@ -218,19 +189,0 @@\n-\n-    static boolean indexesInRange(VectorPayloadMF reorder) {\n-        int length = reorder.length();\n-        long offset = reorder.multiFieldOffset();\n-        for (int i = 0; i < length; i++) {\n-            byte si = Unsafe.getUnsafe().getByte(reorder, offset + i * Byte.BYTES);\n-            if (si >= length || si < -length) {\n-                boolean assertsEnabled = false;\n-                assert(assertsEnabled = true);\n-                if (assertsEnabled) {\n-                    String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n-                            reorder.toString());\n-                    throw new AssertionError(msg);\n-                }\n-                return false;\n-            }\n-        }\n-        return true;\n-    }\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/AbstractShuffle.java","additions":57,"deletions":105,"binary":false,"changes":162,"status":"modified"},{"patch":"@@ -55,0 +55,2 @@\n+    final Class<? extends AbstractShuffle<E>> shuffleType;\n+    @Stable\n@@ -68,0 +70,1 @@\n+                    Class<? extends AbstractShuffle<E>> shuffleType,\n@@ -73,0 +76,1 @@\n+        this.shuffleType = shuffleType;\n@@ -172,0 +176,5 @@\n+    @ForceInline\n+    final Class<? extends AbstractShuffle<E>> shuffleType() {\n+        return shuffleType;\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/AbstractSpecies.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -192,1 +192,1 @@\n-    abstract AbstractShuffle<E> iotaShuffle();\n+    abstract <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp);\n@@ -194,1 +194,23 @@\n-    abstract AbstractShuffle<E> iotaShuffle(int start, int step, boolean wrap);\n+    \/*package-private*\/\n+    @ForceInline\n+    final <F> VectorShuffle<F> toShuffleTemplate(AbstractSpecies<F> dsp) {\n+        Class<?> etype = vspecies().elementType();\n+        Class<?> dvtype = dsp.shuffleType();\n+        Class<?> dtype = dsp.asIntegral().elementType();\n+        int dlength = dsp.dummyVectorMF().length();\n+        return VectorSupport.convert(VectorSupport.VECTOR_OP_CAST,\n+                                     getClass(), etype, length(),\n+                                     dvtype, dtype, dlength,\n+                                     this, dsp,\n+                                     AbstractVector::toShuffle0);\n+    }\n+\n+    abstract <F> VectorShuffle<F> toShuffle0(AbstractSpecies<F> dsp);\n+\n+    @ForceInline\n+    public final\n+    VectorShuffle<E> toShuffle() {\n+        return toShuffle(vspecies());\n+    }\n+\n+    abstract VectorShuffle<E> iotaShuffle();\n@@ -196,2 +218,25 @@\n-    \/*do not alias this byte array*\/\n-    abstract AbstractShuffle<E> shuffleFromBytes(VectorPayloadMF reorder);\n+    @ForceInline\n+    @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n+    final VectorShuffle<E> iotaShuffle(int start, int step, boolean wrap) {\n+        if (start == 0 && step == 1) {\n+            return iotaShuffle();\n+        }\n+\n+        if ((length() & (length() - 1)) != 0) {\n+            return wrap ? shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i * step + start, length())))\n+                        : shuffleFromOp(i -> i * step + start);\n+        }\n+\n+        AbstractSpecies<?> species = vspecies().asIntegral();\n+        Vector iota = species.iota();\n+        iota = iota.lanewise(VectorOperators.MUL, step)\n+                   .lanewise(VectorOperators.ADD, start);\n+        Vector wrapped = iota.lanewise(VectorOperators.AND, length() - 1);\n+\n+        if (!wrap) {\n+            Vector wrappedEx = wrapped.lanewise(VectorOperators.SUB, length());\n+            VectorMask<?> mask = wrapped.compare(VectorOperators.EQ, iota);\n+            wrapped = wrappedEx.blend(wrapped, mask);\n+        }\n+        return ((AbstractVector) wrapped).toShuffle(vspecies());\n+    }\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/AbstractVector.java","additions":49,"deletions":4,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Byte128Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Byte128Shuffle)VectorSupport.shuffleIota(ETYPE, Byte128Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Byte128Shuffle)VectorSupport.shuffleIota(ETYPE, Byte128Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Byte128Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Byte128Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Byte128Shuffle shuffleFromArray(int[] indexes, int i) { return new Byte128Shuffle(indexes, i); }\n+    Byte128Shuffle shuffleFromArray(int[] indices, int i) { return new Byte128Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Byte> toShuffle() {\n-        return super.toShuffleTemplate(Byte128Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -627,4 +614,5 @@\n-        public Byte128Mask eq(VectorMask<Byte> mask) {\n-            Objects.requireNonNull(mask);\n-            Byte128Mask m = (Byte128Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Byte128Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Byte128Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Byte128Mask.class, byte.class, VLENGTH, offset, limit,\n+                (o, l) -> (Byte128Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -672,0 +660,1 @@\n+        @Override\n@@ -673,2 +662,1 @@\n-        \/* package-private *\/\n-        Byte128Mask xor(VectorMask<Byte> mask) {\n+        public Byte128Mask xor(VectorMask<Byte> mask) {\n@@ -753,4 +741,4 @@\n-        Byte128Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF128B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Byte128Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF128B) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -759,2 +747,2 @@\n-        public Byte128Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Byte128Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -763,6 +751,2 @@\n-        public Byte128Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Byte128Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Byte128Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -773,1 +757,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -778,0 +762,1 @@\n+        @ForceInline\n@@ -792,3 +777,2 @@\n-        public Byte128Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Byte128Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Byte128Vector)(((AbstractShuffle<Byte>)(s)).toVectorTemplate())));\n+        Byte128Vector toBitsVector() {\n+            return (Byte128Vector) super.toBitsVectorTemplate();\n@@ -799,6 +783,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        ByteVector toBitsVector0() {\n+            return Byte128Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -807,0 +787,1 @@\n+        @Override\n@@ -808,0 +789,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -809,7 +794,22 @@\n-        public Byte128Shuffle rearrange(VectorShuffle<Byte> shuffle) {\n-            Byte128Shuffle s = (Byte128Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            VectorSpecies<Integer> species = IntVector.SPECIES_128;\n+            Vector<Byte> v = toBitsVector();\n+            v.convertShape(VectorOperators.B2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.B2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+            v.convertShape(VectorOperators.B2I, species, 2)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 2);\n+            v.convertShape(VectorOperators.B2I, species, 3)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 3);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -817,3 +817,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putByte(payload, mfOffset + i * Byte.BYTES, (byte) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putByte(payload, offset + i * Byte.BYTES, (byte) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                byte si = Unsafe.getUnsafe().getByte(indices, offset + i * Byte.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -821,2 +855,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Byte128Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte128Vector.java","additions":91,"deletions":58,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Byte256Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Byte256Shuffle)VectorSupport.shuffleIota(ETYPE, Byte256Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Byte256Shuffle)VectorSupport.shuffleIota(ETYPE, Byte256Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Byte256Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Byte256Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Byte256Shuffle shuffleFromArray(int[] indexes, int i) { return new Byte256Shuffle(indexes, i); }\n+    Byte256Shuffle shuffleFromArray(int[] indices, int i) { return new Byte256Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Byte> toShuffle() {\n-        return super.toShuffleTemplate(Byte256Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -659,4 +646,5 @@\n-        public Byte256Mask eq(VectorMask<Byte> mask) {\n-            Objects.requireNonNull(mask);\n-            Byte256Mask m = (Byte256Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Byte256Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Byte256Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Byte256Mask.class, byte.class, VLENGTH, offset, limit,\n+                (o, l) -> (Byte256Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -704,0 +692,1 @@\n+        @Override\n@@ -705,2 +694,1 @@\n-        \/* package-private *\/\n-        Byte256Mask xor(VectorMask<Byte> mask) {\n+        public Byte256Mask xor(VectorMask<Byte> mask) {\n@@ -785,4 +773,4 @@\n-        Byte256Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF256B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Byte256Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF256B) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -791,2 +779,2 @@\n-        public Byte256Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Byte256Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -795,6 +783,2 @@\n-        public Byte256Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Byte256Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Byte256Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -805,1 +789,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -810,0 +794,1 @@\n+        @ForceInline\n@@ -824,3 +809,2 @@\n-        public Byte256Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Byte256Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Byte256Vector)(((AbstractShuffle<Byte>)(s)).toVectorTemplate())));\n+        Byte256Vector toBitsVector() {\n+            return (Byte256Vector) super.toBitsVectorTemplate();\n@@ -831,6 +815,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        ByteVector toBitsVector0() {\n+            return Byte256Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -839,0 +819,1 @@\n+        @Override\n@@ -840,0 +821,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -841,7 +826,22 @@\n-        public Byte256Shuffle rearrange(VectorShuffle<Byte> shuffle) {\n-            Byte256Shuffle s = (Byte256Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            VectorSpecies<Integer> species = IntVector.SPECIES_256;\n+            Vector<Byte> v = toBitsVector();\n+            v.convertShape(VectorOperators.B2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.B2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+            v.convertShape(VectorOperators.B2I, species, 2)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 2);\n+            v.convertShape(VectorOperators.B2I, species, 3)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 3);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -849,3 +849,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putByte(payload, mfOffset + i * Byte.BYTES, (byte) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putByte(payload, offset + i * Byte.BYTES, (byte) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                byte si = Unsafe.getUnsafe().getByte(indices, offset + i * Byte.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -853,2 +887,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Byte256Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte256Vector.java","additions":91,"deletions":58,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Byte512Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Byte512Shuffle)VectorSupport.shuffleIota(ETYPE, Byte512Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Byte512Shuffle)VectorSupport.shuffleIota(ETYPE, Byte512Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Byte512Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Byte512Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Byte512Shuffle shuffleFromArray(int[] indexes, int i) { return new Byte512Shuffle(indexes, i); }\n+    Byte512Shuffle shuffleFromArray(int[] indices, int i) { return new Byte512Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Byte> toShuffle() {\n-        return super.toShuffleTemplate(Byte512Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -723,4 +710,5 @@\n-        public Byte512Mask eq(VectorMask<Byte> mask) {\n-            Objects.requireNonNull(mask);\n-            Byte512Mask m = (Byte512Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Byte512Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Byte512Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Byte512Mask.class, byte.class, VLENGTH, offset, limit,\n+                (o, l) -> (Byte512Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -768,0 +756,1 @@\n+        @Override\n@@ -769,2 +758,1 @@\n-        \/* package-private *\/\n-        Byte512Mask xor(VectorMask<Byte> mask) {\n+        public Byte512Mask xor(VectorMask<Byte> mask) {\n@@ -849,4 +837,4 @@\n-        Byte512Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF512B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Byte512Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF512B) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -855,2 +843,2 @@\n-        public Byte512Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Byte512Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -859,6 +847,2 @@\n-        public Byte512Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Byte512Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Byte512Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -869,1 +853,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -874,0 +858,1 @@\n+        @ForceInline\n@@ -888,3 +873,2 @@\n-        public Byte512Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Byte512Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Byte512Vector)(((AbstractShuffle<Byte>)(s)).toVectorTemplate())));\n+        Byte512Vector toBitsVector() {\n+            return (Byte512Vector) super.toBitsVectorTemplate();\n@@ -895,6 +879,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        ByteVector toBitsVector0() {\n+            return Byte512Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -903,0 +883,1 @@\n+        @Override\n@@ -904,0 +885,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -905,7 +890,22 @@\n-        public Byte512Shuffle rearrange(VectorShuffle<Byte> shuffle) {\n-            Byte512Shuffle s = (Byte512Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            VectorSpecies<Integer> species = IntVector.SPECIES_512;\n+            Vector<Byte> v = toBitsVector();\n+            v.convertShape(VectorOperators.B2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.B2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+            v.convertShape(VectorOperators.B2I, species, 2)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 2);\n+            v.convertShape(VectorOperators.B2I, species, 3)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 3);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -913,3 +913,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putByte(payload, mfOffset + i * Byte.BYTES, (byte) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putByte(payload, offset + i * Byte.BYTES, (byte) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                byte si = Unsafe.getUnsafe().getByte(indices, offset + i * Byte.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -917,2 +951,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Byte512Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte512Vector.java","additions":91,"deletions":58,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Byte64Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Byte64Shuffle)VectorSupport.shuffleIota(ETYPE, Byte64Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Byte64Shuffle)VectorSupport.shuffleIota(ETYPE, Byte64Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Byte64Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Byte64Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Byte64Shuffle shuffleFromArray(int[] indexes, int i) { return new Byte64Shuffle(indexes, i); }\n+    Byte64Shuffle shuffleFromArray(int[] indices, int i) { return new Byte64Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Byte> toShuffle() {\n-        return super.toShuffleTemplate(Byte64Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -611,4 +598,5 @@\n-        public Byte64Mask eq(VectorMask<Byte> mask) {\n-            Objects.requireNonNull(mask);\n-            Byte64Mask m = (Byte64Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Byte64Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Byte64Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Byte64Mask.class, byte.class, VLENGTH, offset, limit,\n+                (o, l) -> (Byte64Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -656,0 +644,1 @@\n+        @Override\n@@ -657,2 +646,1 @@\n-        \/* package-private *\/\n-        Byte64Mask xor(VectorMask<Byte> mask) {\n+        public Byte64Mask xor(VectorMask<Byte> mask) {\n@@ -737,4 +725,4 @@\n-        Byte64Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF64B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Byte64Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF64B) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -743,2 +731,2 @@\n-        public Byte64Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Byte64Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -747,6 +735,2 @@\n-        public Byte64Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Byte64Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Byte64Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -757,1 +741,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -762,0 +746,1 @@\n+        @ForceInline\n@@ -776,3 +761,2 @@\n-        public Byte64Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Byte64Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Byte64Vector)(((AbstractShuffle<Byte>)(s)).toVectorTemplate())));\n+        Byte64Vector toBitsVector() {\n+            return (Byte64Vector) super.toBitsVectorTemplate();\n@@ -783,6 +767,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        ByteVector toBitsVector0() {\n+            return Byte64Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -791,0 +771,1 @@\n+        @Override\n@@ -792,0 +773,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -793,7 +778,22 @@\n-        public Byte64Shuffle rearrange(VectorShuffle<Byte> shuffle) {\n-            Byte64Shuffle s = (Byte64Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            VectorSpecies<Integer> species = IntVector.SPECIES_64;\n+            Vector<Byte> v = toBitsVector();\n+            v.convertShape(VectorOperators.B2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.B2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+            v.convertShape(VectorOperators.B2I, species, 2)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 2);\n+            v.convertShape(VectorOperators.B2I, species, 3)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 3);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -801,3 +801,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putByte(payload, mfOffset + i * Byte.BYTES, (byte) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putByte(payload, offset + i * Byte.BYTES, (byte) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                byte si = Unsafe.getUnsafe().getByte(indices, offset + i * Byte.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -805,2 +839,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Byte64Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte64Vector.java","additions":91,"deletions":58,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-    static final ValueLayout.OfByte ELEMENT_LAYOUT = ValueLayout.JAVA_BYTE.withBitAlignment(8);\n+    static final ValueLayout.OfByte ELEMENT_LAYOUT = ValueLayout.JAVA_BYTE.withByteAlignment(1);\n@@ -1189,1 +1189,1 @@\n-   \/**\n+    \/**\n@@ -2598,2 +2598,2 @@\n-    private final\n-    VectorShuffle<Byte> toShuffle0(ByteSpecies dsp) {\n+    final <F>\n+    VectorShuffle<F> toShuffle0(AbstractSpecies<F> dsp) {\n@@ -2608,12 +2608,0 @@\n-    \/*package-private*\/\n-    @ForceInline\n-    final\n-    VectorShuffle<Byte> toShuffleTemplate(Class<?> shuffleType) {\n-        ByteSpecies vsp = vspecies();\n-        return VectorSupport.convert(VectorSupport.VECTOR_OP_CAST,\n-                                     getClass(), byte.class, length(),\n-                                     shuffleType, byte.class, length(),\n-                                     this, vsp,\n-                                     ByteVector::toShuffle0);\n-    }\n-\n@@ -3432,1 +3420,1 @@\n-     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_BYTE.withBitAlignment(8), n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_BYTE.withByteAlignment(1), n);\n@@ -4215,0 +4203,1 @@\n+                Class<? extends AbstractShuffle<Byte>> shuffleType,\n@@ -4217,1 +4206,1 @@\n-                  vectorType, maskType,\n+                  vectorType, maskType, shuffleType,\n@@ -4513,0 +4502,1 @@\n+                            Byte64Vector.Byte64Shuffle.class,\n@@ -4520,0 +4510,1 @@\n+                            Byte128Vector.Byte128Shuffle.class,\n@@ -4527,0 +4518,1 @@\n+                            Byte256Vector.Byte256Shuffle.class,\n@@ -4534,0 +4526,1 @@\n+                            Byte512Vector.Byte512Shuffle.class,\n@@ -4542,0 +4535,1 @@\n+                            ByteMaxVector.ByteMaxShuffle.class,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteVector.java","additions":12,"deletions":18,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -144,11 +144,0 @@\n-    @ForceInline\n-    Double128Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Double128Shuffle)VectorSupport.shuffleIota(ETYPE, Double128Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Double128Shuffle)VectorSupport.shuffleIota(ETYPE, Double128Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n@@ -157,5 +146,1 @@\n-    Double128Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Double128Shuffle(reorder); }\n-\n-    @Override\n-    @ForceInline\n-    Double128Shuffle shuffleFromArray(int[] indexes, int i) { return new Double128Shuffle(indexes, i); }\n+    Double128Shuffle shuffleFromArray(int[] indices, int i) { return new Double128Shuffle(indices, i); }\n@@ -347,0 +332,1 @@\n+    @Override\n@@ -348,2 +334,3 @@\n-    public VectorShuffle<Double> toShuffle() {\n-        return super.toShuffleTemplate(Double128Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -588,4 +575,5 @@\n-        public Double128Mask eq(VectorMask<Double> mask) {\n-            Objects.requireNonNull(mask);\n-            Double128Mask m = (Double128Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Double128Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Double128Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Double128Mask.class, double.class, VLENGTH, offset, limit,\n+                (o, l) -> (Double128Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -633,0 +621,1 @@\n+        @Override\n@@ -634,2 +623,1 @@\n-        \/* package-private *\/\n-        Double128Mask xor(VectorMask<Double> mask) {\n+        public Double128Mask xor(VectorMask<Double> mask) {\n@@ -710,1 +698,1 @@\n-        static final Class<Double> ETYPE = double.class; \/\/ used by the JVM\n+        static final Class<Long> ETYPE = long.class; \/\/ used by the JVM\n@@ -712,1 +700,1 @@\n-        private final VectorPayloadMF16B payload;\n+        private final VectorPayloadMF128L payload;\n@@ -714,4 +702,4 @@\n-        Double128Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF16B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Double128Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF128L) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -720,2 +708,2 @@\n-        public Double128Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Double128Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -724,6 +712,2 @@\n-        public Double128Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Double128Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Double128Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -734,1 +718,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -739,0 +723,1 @@\n+        @ForceInline\n@@ -746,2 +731,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Long.MAX_VALUE);\n+            assert(Long.MIN_VALUE <= -VLENGTH);\n@@ -753,3 +738,2 @@\n-        public Double128Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Double128Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Double128Vector)(((AbstractShuffle<Double>)(s)).toVectorTemplate())));\n+        Long128Vector toBitsVector() {\n+            return (Long128Vector) super.toBitsVectorTemplate();\n@@ -760,6 +744,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        LongVector toBitsVector0() {\n+            return Long128Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -768,0 +748,1 @@\n+        @Override\n@@ -769,0 +750,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -770,7 +755,46 @@\n-        public Double128Shuffle rearrange(VectorShuffle<Double> shuffle) {\n-            Double128Shuffle s = (Double128Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, mfOffset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -778,3 +802,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, offset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                long si = Unsafe.getUnsafe().getLong(indices, offset + i * Long.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -782,2 +827,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Double128Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double128Vector.java","additions":106,"deletions":62,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -144,11 +144,0 @@\n-    @ForceInline\n-    Double256Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Double256Shuffle)VectorSupport.shuffleIota(ETYPE, Double256Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Double256Shuffle)VectorSupport.shuffleIota(ETYPE, Double256Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n@@ -157,5 +146,1 @@\n-    Double256Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Double256Shuffle(reorder); }\n-\n-    @Override\n-    @ForceInline\n-    Double256Shuffle shuffleFromArray(int[] indexes, int i) { return new Double256Shuffle(indexes, i); }\n+    Double256Shuffle shuffleFromArray(int[] indices, int i) { return new Double256Shuffle(indices, i); }\n@@ -347,0 +332,1 @@\n+    @Override\n@@ -348,2 +334,3 @@\n-    public VectorShuffle<Double> toShuffle() {\n-        return super.toShuffleTemplate(Double256Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -592,4 +579,5 @@\n-        public Double256Mask eq(VectorMask<Double> mask) {\n-            Objects.requireNonNull(mask);\n-            Double256Mask m = (Double256Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Double256Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Double256Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Double256Mask.class, double.class, VLENGTH, offset, limit,\n+                (o, l) -> (Double256Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -637,0 +625,1 @@\n+        @Override\n@@ -638,2 +627,1 @@\n-        \/* package-private *\/\n-        Double256Mask xor(VectorMask<Double> mask) {\n+        public Double256Mask xor(VectorMask<Double> mask) {\n@@ -714,1 +702,1 @@\n-        static final Class<Double> ETYPE = double.class; \/\/ used by the JVM\n+        static final Class<Long> ETYPE = long.class; \/\/ used by the JVM\n@@ -716,1 +704,1 @@\n-        private final VectorPayloadMF32B payload;\n+        private final VectorPayloadMF256L payload;\n@@ -718,4 +706,4 @@\n-        Double256Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF32B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Double256Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF256L) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -724,2 +712,2 @@\n-        public Double256Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Double256Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -728,6 +716,2 @@\n-        public Double256Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Double256Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Double256Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -738,1 +722,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -743,0 +727,1 @@\n+        @ForceInline\n@@ -750,2 +735,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Long.MAX_VALUE);\n+            assert(Long.MIN_VALUE <= -VLENGTH);\n@@ -757,3 +742,2 @@\n-        public Double256Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Double256Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Double256Vector)(((AbstractShuffle<Double>)(s)).toVectorTemplate())));\n+        Long256Vector toBitsVector() {\n+            return (Long256Vector) super.toBitsVectorTemplate();\n@@ -764,6 +748,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        LongVector toBitsVector0() {\n+            return Long256Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -772,0 +752,1 @@\n+        @Override\n@@ -773,0 +754,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -774,7 +759,46 @@\n-        public Double256Shuffle rearrange(VectorShuffle<Double> shuffle) {\n-            Double256Shuffle s = (Double256Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, mfOffset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -782,3 +806,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, offset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                long si = Unsafe.getUnsafe().getLong(indices, offset + i * Long.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -786,2 +831,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Double256Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double256Vector.java","additions":106,"deletions":62,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -144,11 +144,0 @@\n-    @ForceInline\n-    Double512Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Double512Shuffle)VectorSupport.shuffleIota(ETYPE, Double512Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Double512Shuffle)VectorSupport.shuffleIota(ETYPE, Double512Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n@@ -157,5 +146,1 @@\n-    Double512Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Double512Shuffle(reorder); }\n-\n-    @Override\n-    @ForceInline\n-    Double512Shuffle shuffleFromArray(int[] indexes, int i) { return new Double512Shuffle(indexes, i); }\n+    Double512Shuffle shuffleFromArray(int[] indices, int i) { return new Double512Shuffle(indices, i); }\n@@ -347,0 +332,1 @@\n+    @Override\n@@ -348,2 +334,3 @@\n-    public VectorShuffle<Double> toShuffle() {\n-        return super.toShuffleTemplate(Double512Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -600,4 +587,5 @@\n-        public Double512Mask eq(VectorMask<Double> mask) {\n-            Objects.requireNonNull(mask);\n-            Double512Mask m = (Double512Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Double512Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Double512Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Double512Mask.class, double.class, VLENGTH, offset, limit,\n+                (o, l) -> (Double512Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -645,0 +633,1 @@\n+        @Override\n@@ -646,2 +635,1 @@\n-        \/* package-private *\/\n-        Double512Mask xor(VectorMask<Double> mask) {\n+        public Double512Mask xor(VectorMask<Double> mask) {\n@@ -722,1 +710,1 @@\n-        static final Class<Double> ETYPE = double.class; \/\/ used by the JVM\n+        static final Class<Long> ETYPE = long.class; \/\/ used by the JVM\n@@ -724,1 +712,1 @@\n-        private final VectorPayloadMF64B payload;\n+        private final VectorPayloadMF512L payload;\n@@ -726,4 +714,4 @@\n-        Double512Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF64B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Double512Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF512L) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -732,2 +720,2 @@\n-        public Double512Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Double512Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -736,6 +724,2 @@\n-        public Double512Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Double512Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Double512Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -746,1 +730,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -751,0 +735,1 @@\n+        @ForceInline\n@@ -758,2 +743,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Long.MAX_VALUE);\n+            assert(Long.MIN_VALUE <= -VLENGTH);\n@@ -765,3 +750,2 @@\n-        public Double512Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Double512Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Double512Vector)(((AbstractShuffle<Double>)(s)).toVectorTemplate())));\n+        Long512Vector toBitsVector() {\n+            return (Long512Vector) super.toBitsVectorTemplate();\n@@ -772,6 +756,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        LongVector toBitsVector0() {\n+            return Long512Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -780,0 +760,1 @@\n+        @Override\n@@ -781,0 +762,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -782,7 +767,46 @@\n-        public Double512Shuffle rearrange(VectorShuffle<Double> shuffle) {\n-            Double512Shuffle s = (Double512Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, mfOffset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -790,3 +814,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, offset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                long si = Unsafe.getUnsafe().getLong(indices, offset + i * Long.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -794,2 +839,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Double512Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double512Vector.java","additions":106,"deletions":62,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -144,11 +144,0 @@\n-    @ForceInline\n-    Double64Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Double64Shuffle)VectorSupport.shuffleIota(ETYPE, Double64Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Double64Shuffle)VectorSupport.shuffleIota(ETYPE, Double64Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n@@ -157,5 +146,1 @@\n-    Double64Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Double64Shuffle(reorder); }\n-\n-    @Override\n-    @ForceInline\n-    Double64Shuffle shuffleFromArray(int[] indexes, int i) { return new Double64Shuffle(indexes, i); }\n+    Double64Shuffle shuffleFromArray(int[] indices, int i) { return new Double64Shuffle(indices, i); }\n@@ -347,0 +332,1 @@\n+    @Override\n@@ -348,2 +334,3 @@\n-    public VectorShuffle<Double> toShuffle() {\n-        return super.toShuffleTemplate(Double64Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -586,4 +573,5 @@\n-        public Double64Mask eq(VectorMask<Double> mask) {\n-            Objects.requireNonNull(mask);\n-            Double64Mask m = (Double64Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Double64Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Double64Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Double64Mask.class, double.class, VLENGTH, offset, limit,\n+                (o, l) -> (Double64Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -631,0 +619,1 @@\n+        @Override\n@@ -632,2 +621,1 @@\n-        \/* package-private *\/\n-        Double64Mask xor(VectorMask<Double> mask) {\n+        public Double64Mask xor(VectorMask<Double> mask) {\n@@ -708,1 +696,1 @@\n-        static final Class<Double> ETYPE = double.class; \/\/ used by the JVM\n+        static final Class<Long> ETYPE = long.class; \/\/ used by the JVM\n@@ -710,1 +698,1 @@\n-        private final VectorPayloadMF8B payload;\n+        private final VectorPayloadMF64L payload;\n@@ -712,4 +700,4 @@\n-        Double64Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF8B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Double64Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF64L) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -718,2 +706,2 @@\n-        public Double64Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Double64Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -722,6 +710,2 @@\n-        public Double64Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Double64Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Double64Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -732,1 +716,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -737,0 +721,1 @@\n+        @ForceInline\n@@ -744,2 +729,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Long.MAX_VALUE);\n+            assert(Long.MIN_VALUE <= -VLENGTH);\n@@ -751,3 +736,2 @@\n-        public Double64Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Double64Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Double64Vector)(((AbstractShuffle<Double>)(s)).toVectorTemplate())));\n+        Long64Vector toBitsVector() {\n+            return (Long64Vector) super.toBitsVectorTemplate();\n@@ -758,6 +742,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        LongVector toBitsVector0() {\n+            return Long64Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -766,0 +746,1 @@\n+        @Override\n@@ -767,0 +748,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -768,7 +753,46 @@\n-        public Double64Shuffle rearrange(VectorShuffle<Double> shuffle) {\n-            Double64Shuffle s = (Double64Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, mfOffset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -776,3 +800,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, offset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                long si = Unsafe.getUnsafe().getLong(indices, offset + i * Long.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -780,2 +825,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Double64Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double64Vector.java","additions":106,"deletions":62,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-    static final ValueLayout.OfDouble ELEMENT_LAYOUT = ValueLayout.JAVA_DOUBLE.withBitAlignment(8);\n+    static final ValueLayout.OfDouble ELEMENT_LAYOUT = ValueLayout.JAVA_DOUBLE.withByteAlignment(1);\n@@ -1063,1 +1063,1 @@\n-   \/**\n+    \/**\n@@ -2432,2 +2432,2 @@\n-    private final\n-    VectorShuffle<Double> toShuffle0(DoubleSpecies dsp) {\n+    final <F>\n+    VectorShuffle<F> toShuffle0(AbstractSpecies<F> dsp) {\n@@ -2442,12 +2442,0 @@\n-    \/*package-private*\/\n-    @ForceInline\n-    final\n-    VectorShuffle<Double> toShuffleTemplate(Class<?> shuffleType) {\n-        DoubleSpecies vsp = vspecies();\n-        return VectorSupport.convert(VectorSupport.VECTOR_OP_CAST,\n-                                     getClass(), double.class, length(),\n-                                     shuffleType, byte.class, length(),\n-                                     this, vsp,\n-                                     DoubleVector::toShuffle0);\n-    }\n-\n@@ -3109,1 +3097,1 @@\n-     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_DOUBLE.withBitAlignment(8), n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_DOUBLE.withByteAlignment(1), n);\n@@ -3819,0 +3807,1 @@\n+                Class<? extends AbstractShuffle<Double>> shuffleType,\n@@ -3821,1 +3810,1 @@\n-                  vectorType, maskType,\n+                  vectorType, maskType, shuffleType,\n@@ -4117,0 +4106,1 @@\n+                            Double64Vector.Double64Shuffle.class,\n@@ -4124,0 +4114,1 @@\n+                            Double128Vector.Double128Shuffle.class,\n@@ -4131,0 +4122,1 @@\n+                            Double256Vector.Double256Shuffle.class,\n@@ -4138,0 +4130,1 @@\n+                            Double512Vector.Double512Shuffle.class,\n@@ -4146,0 +4139,1 @@\n+                            DoubleMaxVector.DoubleMaxShuffle.class,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleVector.java","additions":12,"deletions":18,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Float128Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Float128Shuffle)VectorSupport.shuffleIota(ETYPE, Float128Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Float128Shuffle)VectorSupport.shuffleIota(ETYPE, Float128Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Float128Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Float128Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Float128Shuffle shuffleFromArray(int[] indexes, int i) { return new Float128Shuffle(indexes, i); }\n+    Float128Shuffle shuffleFromArray(int[] indices, int i) { return new Float128Shuffle(indices, i); }\n@@ -347,0 +332,1 @@\n+    @Override\n@@ -348,2 +334,3 @@\n-    public VectorShuffle<Float> toShuffle() {\n-        return super.toShuffleTemplate(Float128Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -592,4 +579,5 @@\n-        public Float128Mask eq(VectorMask<Float> mask) {\n-            Objects.requireNonNull(mask);\n-            Float128Mask m = (Float128Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Float128Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Float128Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Float128Mask.class, float.class, VLENGTH, offset, limit,\n+                (o, l) -> (Float128Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -637,0 +625,1 @@\n+        @Override\n@@ -638,2 +627,1 @@\n-        \/* package-private *\/\n-        Float128Mask xor(VectorMask<Float> mask) {\n+        public Float128Mask xor(VectorMask<Float> mask) {\n@@ -714,3 +702,1 @@\n-        static final Class<Float> ETYPE = float.class; \/\/ used by the JVM\n-\n-        private final VectorPayloadMF32B payload;\n+        static final Class<Integer> ETYPE = int.class; \/\/ used by the JVM\n@@ -718,5 +704,1 @@\n-        Float128Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF32B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n-        }\n+        private final VectorPayloadMF128I payload;\n@@ -724,2 +706,4 @@\n-        public Float128Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Float128Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF128I) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -728,2 +712,2 @@\n-        public Float128Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n+        Float128Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -732,2 +716,2 @@\n-        public Float128Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Float128Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -738,1 +722,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -743,0 +727,1 @@\n+        @ForceInline\n@@ -750,2 +735,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Integer.MAX_VALUE);\n+            assert(Integer.MIN_VALUE <= -VLENGTH);\n@@ -757,3 +742,2 @@\n-        public Float128Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Float128Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Float128Vector)(((AbstractShuffle<Float>)(s)).toVectorTemplate())));\n+        Int128Vector toBitsVector() {\n+            return (Int128Vector) super.toBitsVectorTemplate();\n@@ -764,6 +748,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        IntVector toBitsVector0() {\n+            return Int128Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -772,0 +752,1 @@\n+        @Override\n@@ -773,0 +754,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -774,7 +759,22 @@\n-        public Float128Shuffle rearrange(VectorShuffle<Float> shuffle) {\n-            Float128Shuffle s = (Float128Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            toBitsVector().intoArray(a, offset);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, mfOffset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -782,3 +782,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, offset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                int si = Unsafe.getUnsafe().getInt(indices, offset + i * Integer.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -786,2 +807,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Float128Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float128Vector.java","additions":82,"deletions":62,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Float256Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Float256Shuffle)VectorSupport.shuffleIota(ETYPE, Float256Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Float256Shuffle)VectorSupport.shuffleIota(ETYPE, Float256Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Float256Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Float256Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Float256Shuffle shuffleFromArray(int[] indexes, int i) { return new Float256Shuffle(indexes, i); }\n+    Float256Shuffle shuffleFromArray(int[] indices, int i) { return new Float256Shuffle(indices, i); }\n@@ -347,0 +332,1 @@\n+    @Override\n@@ -348,2 +334,3 @@\n-    public VectorShuffle<Float> toShuffle() {\n-        return super.toShuffleTemplate(Float256Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -600,4 +587,5 @@\n-        public Float256Mask eq(VectorMask<Float> mask) {\n-            Objects.requireNonNull(mask);\n-            Float256Mask m = (Float256Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Float256Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Float256Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Float256Mask.class, float.class, VLENGTH, offset, limit,\n+                (o, l) -> (Float256Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -645,0 +633,1 @@\n+        @Override\n@@ -646,2 +635,1 @@\n-        \/* package-private *\/\n-        Float256Mask xor(VectorMask<Float> mask) {\n+        public Float256Mask xor(VectorMask<Float> mask) {\n@@ -722,3 +710,1 @@\n-        static final Class<Float> ETYPE = float.class; \/\/ used by the JVM\n-\n-        private final VectorPayloadMF64B payload;\n+        static final Class<Integer> ETYPE = int.class; \/\/ used by the JVM\n@@ -726,5 +712,1 @@\n-        Float256Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF64B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n-        }\n+        private final VectorPayloadMF256I payload;\n@@ -732,2 +714,4 @@\n-        public Float256Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Float256Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF256I) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -736,2 +720,2 @@\n-        public Float256Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n+        Float256Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -740,2 +724,2 @@\n-        public Float256Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Float256Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -746,1 +730,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -751,0 +735,1 @@\n+        @ForceInline\n@@ -758,2 +743,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Integer.MAX_VALUE);\n+            assert(Integer.MIN_VALUE <= -VLENGTH);\n@@ -765,3 +750,2 @@\n-        public Float256Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Float256Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Float256Vector)(((AbstractShuffle<Float>)(s)).toVectorTemplate())));\n+        Int256Vector toBitsVector() {\n+            return (Int256Vector) super.toBitsVectorTemplate();\n@@ -772,6 +756,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        IntVector toBitsVector0() {\n+            return Int256Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -780,0 +760,1 @@\n+        @Override\n@@ -781,0 +762,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -782,7 +767,22 @@\n-        public Float256Shuffle rearrange(VectorShuffle<Float> shuffle) {\n-            Float256Shuffle s = (Float256Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            toBitsVector().intoArray(a, offset);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, mfOffset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -790,3 +790,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, offset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                int si = Unsafe.getUnsafe().getInt(indices, offset + i * Integer.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -794,2 +815,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Float256Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float256Vector.java","additions":82,"deletions":62,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Float512Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Float512Shuffle)VectorSupport.shuffleIota(ETYPE, Float512Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Float512Shuffle)VectorSupport.shuffleIota(ETYPE, Float512Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Float512Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Float512Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Float512Shuffle shuffleFromArray(int[] indexes, int i) { return new Float512Shuffle(indexes, i); }\n+    Float512Shuffle shuffleFromArray(int[] indices, int i) { return new Float512Shuffle(indices, i); }\n@@ -347,0 +332,1 @@\n+    @Override\n@@ -348,2 +334,3 @@\n-    public VectorShuffle<Float> toShuffle() {\n-        return super.toShuffleTemplate(Float512Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -616,4 +603,5 @@\n-        public Float512Mask eq(VectorMask<Float> mask) {\n-            Objects.requireNonNull(mask);\n-            Float512Mask m = (Float512Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Float512Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Float512Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Float512Mask.class, float.class, VLENGTH, offset, limit,\n+                (o, l) -> (Float512Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -661,0 +649,1 @@\n+        @Override\n@@ -662,2 +651,1 @@\n-        \/* package-private *\/\n-        Float512Mask xor(VectorMask<Float> mask) {\n+        public Float512Mask xor(VectorMask<Float> mask) {\n@@ -738,3 +726,1 @@\n-        static final Class<Float> ETYPE = float.class; \/\/ used by the JVM\n-\n-        private final VectorPayloadMF128B payload;\n+        static final Class<Integer> ETYPE = int.class; \/\/ used by the JVM\n@@ -742,5 +728,1 @@\n-        Float512Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF128B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n-        }\n+        private final VectorPayloadMF512I payload;\n@@ -748,2 +730,4 @@\n-        public Float512Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Float512Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF512I) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -752,2 +736,2 @@\n-        public Float512Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n+        Float512Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -756,2 +740,2 @@\n-        public Float512Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Float512Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -762,1 +746,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -767,0 +751,1 @@\n+        @ForceInline\n@@ -774,2 +759,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Integer.MAX_VALUE);\n+            assert(Integer.MIN_VALUE <= -VLENGTH);\n@@ -781,3 +766,2 @@\n-        public Float512Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Float512Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Float512Vector)(((AbstractShuffle<Float>)(s)).toVectorTemplate())));\n+        Int512Vector toBitsVector() {\n+            return (Int512Vector) super.toBitsVectorTemplate();\n@@ -788,6 +772,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        IntVector toBitsVector0() {\n+            return Int512Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -796,0 +776,1 @@\n+        @Override\n@@ -797,0 +778,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -798,7 +783,22 @@\n-        public Float512Shuffle rearrange(VectorShuffle<Float> shuffle) {\n-            Float512Shuffle s = (Float512Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            toBitsVector().intoArray(a, offset);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, mfOffset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -806,3 +806,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, offset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                int si = Unsafe.getUnsafe().getInt(indices, offset + i * Integer.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -810,2 +831,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Float512Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float512Vector.java","additions":82,"deletions":62,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Float64Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Float64Shuffle)VectorSupport.shuffleIota(ETYPE, Float64Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Float64Shuffle)VectorSupport.shuffleIota(ETYPE, Float64Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Float64Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Float64Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Float64Shuffle shuffleFromArray(int[] indexes, int i) { return new Float64Shuffle(indexes, i); }\n+    Float64Shuffle shuffleFromArray(int[] indices, int i) { return new Float64Shuffle(indices, i); }\n@@ -347,0 +332,1 @@\n+    @Override\n@@ -348,2 +334,3 @@\n-    public VectorShuffle<Float> toShuffle() {\n-        return super.toShuffleTemplate(Float64Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -588,4 +575,5 @@\n-        public Float64Mask eq(VectorMask<Float> mask) {\n-            Objects.requireNonNull(mask);\n-            Float64Mask m = (Float64Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Float64Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Float64Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Float64Mask.class, float.class, VLENGTH, offset, limit,\n+                (o, l) -> (Float64Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -633,0 +621,1 @@\n+        @Override\n@@ -634,2 +623,1 @@\n-        \/* package-private *\/\n-        Float64Mask xor(VectorMask<Float> mask) {\n+        public Float64Mask xor(VectorMask<Float> mask) {\n@@ -710,3 +698,1 @@\n-        static final Class<Float> ETYPE = float.class; \/\/ used by the JVM\n-\n-        private final VectorPayloadMF16B payload;\n+        static final Class<Integer> ETYPE = int.class; \/\/ used by the JVM\n@@ -714,5 +700,1 @@\n-        Float64Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF16B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n-        }\n+        private final VectorPayloadMF64I payload;\n@@ -720,2 +702,4 @@\n-        public Float64Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Float64Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF64I) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -724,2 +708,2 @@\n-        public Float64Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n+        Float64Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -728,2 +712,2 @@\n-        public Float64Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Float64Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -734,1 +718,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -739,0 +723,1 @@\n+        @ForceInline\n@@ -746,2 +731,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Integer.MAX_VALUE);\n+            assert(Integer.MIN_VALUE <= -VLENGTH);\n@@ -753,3 +738,2 @@\n-        public Float64Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Float64Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Float64Vector)(((AbstractShuffle<Float>)(s)).toVectorTemplate())));\n+        Int64Vector toBitsVector() {\n+            return (Int64Vector) super.toBitsVectorTemplate();\n@@ -760,6 +744,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        IntVector toBitsVector0() {\n+            return Int64Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -768,0 +748,1 @@\n+        @Override\n@@ -769,0 +750,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -770,7 +755,22 @@\n-        public Float64Shuffle rearrange(VectorShuffle<Float> shuffle) {\n-            Float64Shuffle s = (Float64Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            toBitsVector().intoArray(a, offset);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, mfOffset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -778,3 +778,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, offset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                int si = Unsafe.getUnsafe().getInt(indices, offset + i * Integer.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -782,2 +803,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Float64Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float64Vector.java","additions":82,"deletions":62,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-    static final ValueLayout.OfFloat ELEMENT_LAYOUT = ValueLayout.JAVA_FLOAT.withBitAlignment(8);\n+    static final ValueLayout.OfFloat ELEMENT_LAYOUT = ValueLayout.JAVA_FLOAT.withByteAlignment(1);\n@@ -1063,1 +1063,1 @@\n-   \/**\n+    \/**\n@@ -2444,2 +2444,2 @@\n-    private final\n-    VectorShuffle<Float> toShuffle0(FloatSpecies dsp) {\n+    final <F>\n+    VectorShuffle<F> toShuffle0(AbstractSpecies<F> dsp) {\n@@ -2454,12 +2454,0 @@\n-    \/*package-private*\/\n-    @ForceInline\n-    final\n-    VectorShuffle<Float> toShuffleTemplate(Class<?> shuffleType) {\n-        FloatSpecies vsp = vspecies();\n-        return VectorSupport.convert(VectorSupport.VECTOR_OP_CAST,\n-                                     getClass(), float.class, length(),\n-                                     shuffleType, byte.class, length(),\n-                                     this, vsp,\n-                                     FloatVector::toShuffle0);\n-    }\n-\n@@ -3113,1 +3101,1 @@\n-     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_FLOAT.withBitAlignment(8), n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_FLOAT.withByteAlignment(1), n);\n@@ -3760,0 +3748,1 @@\n+                Class<? extends AbstractShuffle<Float>> shuffleType,\n@@ -3762,1 +3751,1 @@\n-                  vectorType, maskType,\n+                  vectorType, maskType, shuffleType,\n@@ -4058,0 +4047,1 @@\n+                            Float64Vector.Float64Shuffle.class,\n@@ -4065,0 +4055,1 @@\n+                            Float128Vector.Float128Shuffle.class,\n@@ -4072,0 +4063,1 @@\n+                            Float256Vector.Float256Shuffle.class,\n@@ -4079,0 +4071,1 @@\n+                            Float512Vector.Float512Shuffle.class,\n@@ -4087,0 +4080,1 @@\n+                            FloatMaxVector.FloatMaxShuffle.class,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatVector.java","additions":12,"deletions":18,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Int128Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Int128Shuffle)VectorSupport.shuffleIota(ETYPE, Int128Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Int128Shuffle)VectorSupport.shuffleIota(ETYPE, Int128Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Int128Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Int128Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Int128Shuffle shuffleFromArray(int[] indexes, int i) { return new Int128Shuffle(indexes, i); }\n+    Int128Shuffle shuffleFromArray(int[] indices, int i) { return new Int128Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Integer> toShuffle() {\n-        return super.toShuffleTemplate(Int128Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -603,4 +590,5 @@\n-        public Int128Mask eq(VectorMask<Integer> mask) {\n-            Objects.requireNonNull(mask);\n-            Int128Mask m = (Int128Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Int128Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Int128Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Int128Mask.class, int.class, VLENGTH, offset, limit,\n+                (o, l) -> (Int128Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -648,0 +636,1 @@\n+        @Override\n@@ -649,2 +638,1 @@\n-        \/* package-private *\/\n-        Int128Mask xor(VectorMask<Integer> mask) {\n+        public Int128Mask xor(VectorMask<Integer> mask) {\n@@ -727,1 +715,1 @@\n-        private final VectorPayloadMF32B payload;\n+        private final VectorPayloadMF128I payload;\n@@ -729,4 +717,4 @@\n-        Int128Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF32B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Int128Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF128I) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -735,2 +723,2 @@\n-        public Int128Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Int128Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -739,6 +727,2 @@\n-        public Int128Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Int128Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Int128Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -749,1 +733,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -754,0 +738,1 @@\n+        @ForceInline\n@@ -761,2 +746,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Integer.MAX_VALUE);\n+            assert(Integer.MIN_VALUE <= -VLENGTH);\n@@ -768,3 +753,2 @@\n-        public Int128Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Int128Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Int128Vector)(((AbstractShuffle<Integer>)(s)).toVectorTemplate())));\n+        Int128Vector toBitsVector() {\n+            return (Int128Vector) super.toBitsVectorTemplate();\n@@ -775,6 +759,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        IntVector toBitsVector0() {\n+            return Int128Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -783,0 +763,1 @@\n+        @Override\n@@ -784,0 +765,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -785,7 +770,9 @@\n-        public Int128Shuffle rearrange(VectorShuffle<Integer> shuffle) {\n-            Int128Shuffle s = (Int128Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            toBitsVector().intoArray(a, offset);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -793,3 +780,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, mfOffset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, offset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                int si = Unsafe.getUnsafe().getInt(indices, offset + i * Integer.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -797,2 +818,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Int128Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int128Vector.java","additions":81,"deletions":61,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Int256Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Int256Shuffle)VectorSupport.shuffleIota(ETYPE, Int256Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Int256Shuffle)VectorSupport.shuffleIota(ETYPE, Int256Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Int256Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Int256Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Int256Shuffle shuffleFromArray(int[] indexes, int i) { return new Int256Shuffle(indexes, i); }\n+    Int256Shuffle shuffleFromArray(int[] indices, int i) { return new Int256Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Integer> toShuffle() {\n-        return super.toShuffleTemplate(Int256Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -611,4 +598,5 @@\n-        public Int256Mask eq(VectorMask<Integer> mask) {\n-            Objects.requireNonNull(mask);\n-            Int256Mask m = (Int256Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Int256Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Int256Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Int256Mask.class, int.class, VLENGTH, offset, limit,\n+                (o, l) -> (Int256Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -656,0 +644,1 @@\n+        @Override\n@@ -657,2 +646,1 @@\n-        \/* package-private *\/\n-        Int256Mask xor(VectorMask<Integer> mask) {\n+        public Int256Mask xor(VectorMask<Integer> mask) {\n@@ -735,1 +723,1 @@\n-        private final VectorPayloadMF64B payload;\n+        private final VectorPayloadMF256I payload;\n@@ -737,4 +725,4 @@\n-        Int256Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF64B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Int256Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF256I) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -743,2 +731,2 @@\n-        public Int256Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Int256Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -747,6 +735,2 @@\n-        public Int256Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Int256Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Int256Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -757,1 +741,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -762,0 +746,1 @@\n+        @ForceInline\n@@ -769,2 +754,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Integer.MAX_VALUE);\n+            assert(Integer.MIN_VALUE <= -VLENGTH);\n@@ -776,3 +761,2 @@\n-        public Int256Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Int256Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Int256Vector)(((AbstractShuffle<Integer>)(s)).toVectorTemplate())));\n+        Int256Vector toBitsVector() {\n+            return (Int256Vector) super.toBitsVectorTemplate();\n@@ -783,6 +767,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        IntVector toBitsVector0() {\n+            return Int256Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -791,0 +771,1 @@\n+        @Override\n@@ -792,0 +773,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -793,7 +778,9 @@\n-        public Int256Shuffle rearrange(VectorShuffle<Integer> shuffle) {\n-            Int256Shuffle s = (Int256Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            toBitsVector().intoArray(a, offset);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -801,3 +788,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, mfOffset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, offset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                int si = Unsafe.getUnsafe().getInt(indices, offset + i * Integer.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -805,2 +826,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Int256Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int256Vector.java","additions":81,"deletions":61,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Int512Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Int512Shuffle)VectorSupport.shuffleIota(ETYPE, Int512Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Int512Shuffle)VectorSupport.shuffleIota(ETYPE, Int512Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Int512Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Int512Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Int512Shuffle shuffleFromArray(int[] indexes, int i) { return new Int512Shuffle(indexes, i); }\n+    Int512Shuffle shuffleFromArray(int[] indices, int i) { return new Int512Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Integer> toShuffle() {\n-        return super.toShuffleTemplate(Int512Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -627,4 +614,5 @@\n-        public Int512Mask eq(VectorMask<Integer> mask) {\n-            Objects.requireNonNull(mask);\n-            Int512Mask m = (Int512Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Int512Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Int512Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Int512Mask.class, int.class, VLENGTH, offset, limit,\n+                (o, l) -> (Int512Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -672,0 +660,1 @@\n+        @Override\n@@ -673,2 +662,1 @@\n-        \/* package-private *\/\n-        Int512Mask xor(VectorMask<Integer> mask) {\n+        public Int512Mask xor(VectorMask<Integer> mask) {\n@@ -751,1 +739,1 @@\n-        private final VectorPayloadMF128B payload;\n+        private final VectorPayloadMF512I payload;\n@@ -753,4 +741,4 @@\n-        Int512Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF128B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Int512Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF512I) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -759,2 +747,2 @@\n-        public Int512Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Int512Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -763,6 +751,2 @@\n-        public Int512Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Int512Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Int512Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -773,1 +757,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -778,0 +762,1 @@\n+        @ForceInline\n@@ -785,2 +770,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Integer.MAX_VALUE);\n+            assert(Integer.MIN_VALUE <= -VLENGTH);\n@@ -792,3 +777,2 @@\n-        public Int512Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Int512Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Int512Vector)(((AbstractShuffle<Integer>)(s)).toVectorTemplate())));\n+        Int512Vector toBitsVector() {\n+            return (Int512Vector) super.toBitsVectorTemplate();\n@@ -799,6 +783,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        IntVector toBitsVector0() {\n+            return Int512Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -807,0 +787,1 @@\n+        @Override\n@@ -808,0 +789,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -809,7 +794,9 @@\n-        public Int512Shuffle rearrange(VectorShuffle<Integer> shuffle) {\n-            Int512Shuffle s = (Int512Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            toBitsVector().intoArray(a, offset);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -817,3 +804,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, mfOffset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, offset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                int si = Unsafe.getUnsafe().getInt(indices, offset + i * Integer.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -821,2 +842,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Int512Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int512Vector.java","additions":81,"deletions":61,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Int64Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Int64Shuffle)VectorSupport.shuffleIota(ETYPE, Int64Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Int64Shuffle)VectorSupport.shuffleIota(ETYPE, Int64Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Int64Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Int64Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Int64Shuffle shuffleFromArray(int[] indexes, int i) { return new Int64Shuffle(indexes, i); }\n+    Int64Shuffle shuffleFromArray(int[] indices, int i) { return new Int64Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Integer> toShuffle() {\n-        return super.toShuffleTemplate(Int64Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -599,4 +586,5 @@\n-        public Int64Mask eq(VectorMask<Integer> mask) {\n-            Objects.requireNonNull(mask);\n-            Int64Mask m = (Int64Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Int64Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Int64Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Int64Mask.class, int.class, VLENGTH, offset, limit,\n+                (o, l) -> (Int64Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -644,0 +632,1 @@\n+        @Override\n@@ -645,2 +634,1 @@\n-        \/* package-private *\/\n-        Int64Mask xor(VectorMask<Integer> mask) {\n+        public Int64Mask xor(VectorMask<Integer> mask) {\n@@ -723,1 +711,1 @@\n-        private final VectorPayloadMF16B payload;\n+        private final VectorPayloadMF64I payload;\n@@ -725,4 +713,4 @@\n-        Int64Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF16B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Int64Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF64I) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -731,2 +719,2 @@\n-        public Int64Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Int64Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -735,6 +723,2 @@\n-        public Int64Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Int64Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Int64Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -745,1 +729,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -750,0 +734,1 @@\n+        @ForceInline\n@@ -757,2 +742,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Integer.MAX_VALUE);\n+            assert(Integer.MIN_VALUE <= -VLENGTH);\n@@ -764,3 +749,2 @@\n-        public Int64Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Int64Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Int64Vector)(((AbstractShuffle<Integer>)(s)).toVectorTemplate())));\n+        Int64Vector toBitsVector() {\n+            return (Int64Vector) super.toBitsVectorTemplate();\n@@ -771,6 +755,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        IntVector toBitsVector0() {\n+            return Int64Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -779,0 +759,1 @@\n+        @Override\n@@ -780,0 +761,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -781,7 +766,9 @@\n-        public Int64Shuffle rearrange(VectorShuffle<Integer> shuffle) {\n-            Int64Shuffle s = (Int64Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            toBitsVector().intoArray(a, offset);\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -789,3 +776,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, mfOffset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(int.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putInt(payload, offset + i * Integer.BYTES, (int) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                int si = Unsafe.getUnsafe().getInt(indices, offset + i * Integer.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -793,2 +814,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Int64Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int64Vector.java","additions":81,"deletions":61,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-    static final ValueLayout.OfInt ELEMENT_LAYOUT = ValueLayout.JAVA_INT.withBitAlignment(8);\n+    static final ValueLayout.OfInt ELEMENT_LAYOUT = ValueLayout.JAVA_INT.withByteAlignment(1);\n@@ -1196,1 +1196,1 @@\n-   \/**\n+    \/**\n@@ -2587,2 +2587,2 @@\n-    private final\n-    VectorShuffle<Integer> toShuffle0(IntSpecies dsp) {\n+    final <F>\n+    VectorShuffle<F> toShuffle0(AbstractSpecies<F> dsp) {\n@@ -2597,12 +2597,0 @@\n-    \/*package-private*\/\n-    @ForceInline\n-    final\n-    VectorShuffle<Integer> toShuffleTemplate(Class<?> shuffleType) {\n-        IntSpecies vsp = vspecies();\n-        return VectorSupport.convert(VectorSupport.VECTOR_OP_CAST,\n-                                     getClass(), int.class, length(),\n-                                     shuffleType, byte.class, length(),\n-                                     this, vsp,\n-                                     IntVector::toShuffle0);\n-    }\n-\n@@ -3281,1 +3269,1 @@\n-     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_INT.withBitAlignment(8), n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_INT.withByteAlignment(1), n);\n@@ -3928,0 +3916,1 @@\n+                Class<? extends AbstractShuffle<Integer>> shuffleType,\n@@ -3930,1 +3919,1 @@\n-                  vectorType, maskType,\n+                  vectorType, maskType, shuffleType,\n@@ -4226,0 +4215,1 @@\n+                            Int64Vector.Int64Shuffle.class,\n@@ -4233,0 +4223,1 @@\n+                            Int128Vector.Int128Shuffle.class,\n@@ -4240,0 +4231,1 @@\n+                            Int256Vector.Int256Shuffle.class,\n@@ -4247,0 +4239,1 @@\n+                            Int512Vector.Int512Shuffle.class,\n@@ -4255,0 +4248,1 @@\n+                            IntMaxVector.IntMaxShuffle.class,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntVector.java","additions":12,"deletions":18,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -139,15 +139,0 @@\n-    @ForceInline\n-    Long128Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Long128Shuffle)VectorSupport.shuffleIota(ETYPE, Long128Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Long128Shuffle)VectorSupport.shuffleIota(ETYPE, Long128Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Long128Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Long128Shuffle(reorder); }\n-\n@@ -156,1 +141,1 @@\n-    Long128Shuffle shuffleFromArray(int[] indexes, int i) { return new Long128Shuffle(indexes, i); }\n+    Long128Shuffle shuffleFromArray(int[] indices, int i) { return new Long128Shuffle(indices, i); }\n@@ -355,0 +340,1 @@\n+    @Override\n@@ -356,2 +342,3 @@\n-    public VectorShuffle<Long> toShuffle() {\n-        return super.toShuffleTemplate(Long128Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -589,4 +576,5 @@\n-        public Long128Mask eq(VectorMask<Long> mask) {\n-            Objects.requireNonNull(mask);\n-            Long128Mask m = (Long128Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Long128Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Long128Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Long128Mask.class, long.class, VLENGTH, offset, limit,\n+                (o, l) -> (Long128Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -634,0 +622,1 @@\n+        @Override\n@@ -635,2 +624,1 @@\n-        \/* package-private *\/\n-        Long128Mask xor(VectorMask<Long> mask) {\n+        public Long128Mask xor(VectorMask<Long> mask) {\n@@ -713,1 +701,1 @@\n-        private final VectorPayloadMF16B payload;\n+        private final VectorPayloadMF128L payload;\n@@ -715,4 +703,4 @@\n-        Long128Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF16B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Long128Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF128L) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -721,2 +709,2 @@\n-        public Long128Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Long128Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -725,6 +713,2 @@\n-        public Long128Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Long128Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Long128Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -735,1 +719,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -740,0 +724,1 @@\n+        @ForceInline\n@@ -747,2 +732,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Long.MAX_VALUE);\n+            assert(Long.MIN_VALUE <= -VLENGTH);\n@@ -754,3 +739,2 @@\n-        public Long128Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Long128Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Long128Vector)(((AbstractShuffle<Long>)(s)).toVectorTemplate())));\n+        Long128Vector toBitsVector() {\n+            return (Long128Vector) super.toBitsVectorTemplate();\n@@ -761,6 +745,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        LongVector toBitsVector0() {\n+            return Long128Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -769,0 +749,1 @@\n+        @Override\n@@ -770,0 +751,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -771,7 +756,46 @@\n-        public Long128Shuffle rearrange(VectorShuffle<Long> shuffle) {\n-            Long128Shuffle s = (Long128Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, mfOffset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -779,3 +803,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, offset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                long si = Unsafe.getUnsafe().getLong(indices, offset + i * Long.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -783,2 +828,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Long128Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long128Vector.java","additions":105,"deletions":61,"binary":false,"changes":166,"status":"modified"},{"patch":"@@ -139,15 +139,0 @@\n-    @ForceInline\n-    Long256Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Long256Shuffle)VectorSupport.shuffleIota(ETYPE, Long256Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Long256Shuffle)VectorSupport.shuffleIota(ETYPE, Long256Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Long256Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Long256Shuffle(reorder); }\n-\n@@ -156,1 +141,1 @@\n-    Long256Shuffle shuffleFromArray(int[] indexes, int i) { return new Long256Shuffle(indexes, i); }\n+    Long256Shuffle shuffleFromArray(int[] indices, int i) { return new Long256Shuffle(indices, i); }\n@@ -355,0 +340,1 @@\n+    @Override\n@@ -356,2 +342,3 @@\n-    public VectorShuffle<Long> toShuffle() {\n-        return super.toShuffleTemplate(Long256Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -593,4 +580,5 @@\n-        public Long256Mask eq(VectorMask<Long> mask) {\n-            Objects.requireNonNull(mask);\n-            Long256Mask m = (Long256Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Long256Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Long256Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Long256Mask.class, long.class, VLENGTH, offset, limit,\n+                (o, l) -> (Long256Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -638,0 +626,1 @@\n+        @Override\n@@ -639,2 +628,1 @@\n-        \/* package-private *\/\n-        Long256Mask xor(VectorMask<Long> mask) {\n+        public Long256Mask xor(VectorMask<Long> mask) {\n@@ -717,1 +705,1 @@\n-        private final VectorPayloadMF32B payload;\n+        private final VectorPayloadMF256L payload;\n@@ -719,4 +707,4 @@\n-        Long256Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF32B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Long256Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF256L) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -725,2 +713,2 @@\n-        public Long256Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Long256Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -729,6 +717,2 @@\n-        public Long256Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Long256Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Long256Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -739,1 +723,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -744,0 +728,1 @@\n+        @ForceInline\n@@ -751,2 +736,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Long.MAX_VALUE);\n+            assert(Long.MIN_VALUE <= -VLENGTH);\n@@ -758,3 +743,2 @@\n-        public Long256Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Long256Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Long256Vector)(((AbstractShuffle<Long>)(s)).toVectorTemplate())));\n+        Long256Vector toBitsVector() {\n+            return (Long256Vector) super.toBitsVectorTemplate();\n@@ -765,6 +749,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        LongVector toBitsVector0() {\n+            return Long256Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -773,0 +753,1 @@\n+        @Override\n@@ -774,0 +755,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -775,7 +760,46 @@\n-        public Long256Shuffle rearrange(VectorShuffle<Long> shuffle) {\n-            Long256Shuffle s = (Long256Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, mfOffset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -783,3 +807,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, offset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                long si = Unsafe.getUnsafe().getLong(indices, offset + i * Long.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -787,2 +832,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Long256Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long256Vector.java","additions":105,"deletions":61,"binary":false,"changes":166,"status":"modified"},{"patch":"@@ -139,15 +139,0 @@\n-    @ForceInline\n-    Long512Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Long512Shuffle)VectorSupport.shuffleIota(ETYPE, Long512Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Long512Shuffle)VectorSupport.shuffleIota(ETYPE, Long512Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Long512Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Long512Shuffle(reorder); }\n-\n@@ -156,1 +141,1 @@\n-    Long512Shuffle shuffleFromArray(int[] indexes, int i) { return new Long512Shuffle(indexes, i); }\n+    Long512Shuffle shuffleFromArray(int[] indices, int i) { return new Long512Shuffle(indices, i); }\n@@ -355,0 +340,1 @@\n+    @Override\n@@ -356,2 +342,3 @@\n-    public VectorShuffle<Long> toShuffle() {\n-        return super.toShuffleTemplate(Long512Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -601,4 +588,5 @@\n-        public Long512Mask eq(VectorMask<Long> mask) {\n-            Objects.requireNonNull(mask);\n-            Long512Mask m = (Long512Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Long512Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Long512Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Long512Mask.class, long.class, VLENGTH, offset, limit,\n+                (o, l) -> (Long512Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -646,0 +634,1 @@\n+        @Override\n@@ -647,2 +636,1 @@\n-        \/* package-private *\/\n-        Long512Mask xor(VectorMask<Long> mask) {\n+        public Long512Mask xor(VectorMask<Long> mask) {\n@@ -725,1 +713,1 @@\n-        private final VectorPayloadMF64B payload;\n+        private final VectorPayloadMF512L payload;\n@@ -727,4 +715,4 @@\n-        Long512Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF64B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Long512Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF512L) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -733,2 +721,2 @@\n-        public Long512Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Long512Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -737,6 +725,2 @@\n-        public Long512Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Long512Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Long512Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -747,1 +731,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -752,0 +736,1 @@\n+        @ForceInline\n@@ -759,2 +744,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Long.MAX_VALUE);\n+            assert(Long.MIN_VALUE <= -VLENGTH);\n@@ -766,3 +751,2 @@\n-        public Long512Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Long512Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Long512Vector)(((AbstractShuffle<Long>)(s)).toVectorTemplate())));\n+        Long512Vector toBitsVector() {\n+            return (Long512Vector) super.toBitsVectorTemplate();\n@@ -773,6 +757,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        LongVector toBitsVector0() {\n+            return Long512Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -781,0 +761,1 @@\n+        @Override\n@@ -782,0 +763,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -783,7 +768,46 @@\n-        public Long512Shuffle rearrange(VectorShuffle<Long> shuffle) {\n-            Long512Shuffle s = (Long512Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, mfOffset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -791,3 +815,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, offset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                long si = Unsafe.getUnsafe().getLong(indices, offset + i * Long.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -795,2 +840,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Long512Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long512Vector.java","additions":105,"deletions":61,"binary":false,"changes":166,"status":"modified"},{"patch":"@@ -139,15 +139,0 @@\n-    @ForceInline\n-    Long64Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Long64Shuffle)VectorSupport.shuffleIota(ETYPE, Long64Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Long64Shuffle)VectorSupport.shuffleIota(ETYPE, Long64Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Long64Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Long64Shuffle(reorder); }\n-\n@@ -156,1 +141,1 @@\n-    Long64Shuffle shuffleFromArray(int[] indexes, int i) { return new Long64Shuffle(indexes, i); }\n+    Long64Shuffle shuffleFromArray(int[] indices, int i) { return new Long64Shuffle(indices, i); }\n@@ -355,0 +340,1 @@\n+    @Override\n@@ -356,2 +342,3 @@\n-    public VectorShuffle<Long> toShuffle() {\n-        return super.toShuffleTemplate(Long64Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -587,4 +574,5 @@\n-        public Long64Mask eq(VectorMask<Long> mask) {\n-            Objects.requireNonNull(mask);\n-            Long64Mask m = (Long64Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Long64Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Long64Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Long64Mask.class, long.class, VLENGTH, offset, limit,\n+                (o, l) -> (Long64Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -632,0 +620,1 @@\n+        @Override\n@@ -633,2 +622,1 @@\n-        \/* package-private *\/\n-        Long64Mask xor(VectorMask<Long> mask) {\n+        public Long64Mask xor(VectorMask<Long> mask) {\n@@ -711,1 +699,1 @@\n-        private final VectorPayloadMF8B payload;\n+        private final VectorPayloadMF64L payload;\n@@ -713,4 +701,4 @@\n-        Long64Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF8B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Long64Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF64L) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -719,2 +707,2 @@\n-        public Long64Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Long64Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -723,6 +711,2 @@\n-        public Long64Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Long64Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Long64Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -733,1 +717,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -738,0 +722,1 @@\n+        @ForceInline\n@@ -745,2 +730,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Long.MAX_VALUE);\n+            assert(Long.MIN_VALUE <= -VLENGTH);\n@@ -752,3 +737,2 @@\n-        public Long64Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Long64Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Long64Vector)(((AbstractShuffle<Long>)(s)).toVectorTemplate())));\n+        Long64Vector toBitsVector() {\n+            return (Long64Vector) super.toBitsVectorTemplate();\n@@ -759,6 +743,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        LongVector toBitsVector0() {\n+            return Long64Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -767,0 +747,1 @@\n+        @Override\n@@ -768,0 +749,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -769,7 +754,46 @@\n-        public Long64Shuffle rearrange(VectorShuffle<Long> shuffle) {\n-            Long64Shuffle s = (Long64Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, mfOffset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(long.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -777,3 +801,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putLong(payload, offset + i * Long.BYTES, (long) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                long si = Unsafe.getUnsafe().getLong(indices, offset + i * Long.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -781,2 +826,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Long64Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long64Vector.java","additions":105,"deletions":61,"binary":false,"changes":166,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-    static final ValueLayout.OfLong ELEMENT_LAYOUT = ValueLayout.JAVA_LONG.withBitAlignment(8);\n+    static final ValueLayout.OfLong ELEMENT_LAYOUT = ValueLayout.JAVA_LONG.withByteAlignment(1);\n@@ -1109,1 +1109,1 @@\n-   \/**\n+    \/**\n@@ -2453,2 +2453,2 @@\n-    private final\n-    VectorShuffle<Long> toShuffle0(LongSpecies dsp) {\n+    final <F>\n+    VectorShuffle<F> toShuffle0(AbstractSpecies<F> dsp) {\n@@ -2463,12 +2463,0 @@\n-    \/*package-private*\/\n-    @ForceInline\n-    final\n-    VectorShuffle<Long> toShuffleTemplate(Class<?> shuffleType) {\n-        LongSpecies vsp = vspecies();\n-        return VectorSupport.convert(VectorSupport.VECTOR_OP_CAST,\n-                                     getClass(), long.class, length(),\n-                                     shuffleType, byte.class, length(),\n-                                     this, vsp,\n-                                     LongVector::toShuffle0);\n-    }\n-\n@@ -3162,1 +3150,1 @@\n-     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_LONG.withBitAlignment(8), n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_LONG.withByteAlignment(1), n);\n@@ -3872,0 +3860,1 @@\n+                Class<? extends AbstractShuffle<Long>> shuffleType,\n@@ -3874,1 +3863,1 @@\n-                  vectorType, maskType,\n+                  vectorType, maskType, shuffleType,\n@@ -4161,0 +4150,1 @@\n+                            Long64Vector.Long64Shuffle.class,\n@@ -4168,0 +4158,1 @@\n+                            Long128Vector.Long128Shuffle.class,\n@@ -4175,0 +4166,1 @@\n+                            Long256Vector.Long256Shuffle.class,\n@@ -4182,0 +4174,1 @@\n+                            Long512Vector.Long512Shuffle.class,\n@@ -4190,0 +4183,1 @@\n+                            LongMaxVector.LongMaxShuffle.class,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongVector.java","additions":12,"deletions":18,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Short128Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Short128Shuffle)VectorSupport.shuffleIota(ETYPE, Short128Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Short128Shuffle)VectorSupport.shuffleIota(ETYPE, Short128Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Short128Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Short128Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Short128Shuffle shuffleFromArray(int[] indexes, int i) { return new Short128Shuffle(indexes, i); }\n+    Short128Shuffle shuffleFromArray(int[] indices, int i) { return new Short128Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Short> toShuffle() {\n-        return super.toShuffleTemplate(Short128Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -611,4 +598,5 @@\n-        public Short128Mask eq(VectorMask<Short> mask) {\n-            Objects.requireNonNull(mask);\n-            Short128Mask m = (Short128Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Short128Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Short128Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Short128Mask.class, short.class, VLENGTH, offset, limit,\n+                (o, l) -> (Short128Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -656,0 +644,1 @@\n+        @Override\n@@ -657,2 +646,1 @@\n-        \/* package-private *\/\n-        Short128Mask xor(VectorMask<Short> mask) {\n+        public Short128Mask xor(VectorMask<Short> mask) {\n@@ -735,1 +723,1 @@\n-        private final VectorPayloadMF64B payload;\n+        private final VectorPayloadMF128S payload;\n@@ -737,4 +725,4 @@\n-        Short128Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF64B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Short128Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF128S) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -743,2 +731,2 @@\n-        public Short128Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Short128Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -747,6 +735,2 @@\n-        public Short128Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Short128Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Short128Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -757,1 +741,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -762,0 +746,1 @@\n+        @ForceInline\n@@ -769,2 +754,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Short.MAX_VALUE);\n+            assert(Short.MIN_VALUE <= -VLENGTH);\n@@ -776,3 +761,2 @@\n-        public Short128Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Short128Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Short128Vector)(((AbstractShuffle<Short>)(s)).toVectorTemplate())));\n+        Short128Vector toBitsVector() {\n+            return (Short128Vector) super.toBitsVectorTemplate();\n@@ -783,6 +767,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        ShortVector toBitsVector0() {\n+            return Short128Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -791,0 +771,1 @@\n+        @Override\n@@ -792,0 +773,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -793,7 +778,16 @@\n-        public Short128Shuffle rearrange(VectorShuffle<Short> shuffle) {\n-            Short128Shuffle s = (Short128Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            VectorSpecies<Integer> species = IntVector.SPECIES_128;\n+            Vector<Short> v = toBitsVector();\n+            v.convertShape(VectorOperators.S2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.S2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(short.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -801,3 +795,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putShort(payload, mfOffset + i * Short.BYTES, (short) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(short.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putShort(payload, offset + i * Short.BYTES, (short) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                short si = Unsafe.getUnsafe().getShort(indices, offset + i * Short.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -805,2 +833,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Short128Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short128Vector.java","additions":88,"deletions":61,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Short256Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Short256Shuffle)VectorSupport.shuffleIota(ETYPE, Short256Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Short256Shuffle)VectorSupport.shuffleIota(ETYPE, Short256Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Short256Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Short256Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Short256Shuffle shuffleFromArray(int[] indexes, int i) { return new Short256Shuffle(indexes, i); }\n+    Short256Shuffle shuffleFromArray(int[] indices, int i) { return new Short256Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Short> toShuffle() {\n-        return super.toShuffleTemplate(Short256Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -627,4 +614,5 @@\n-        public Short256Mask eq(VectorMask<Short> mask) {\n-            Objects.requireNonNull(mask);\n-            Short256Mask m = (Short256Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Short256Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Short256Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Short256Mask.class, short.class, VLENGTH, offset, limit,\n+                (o, l) -> (Short256Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -672,0 +660,1 @@\n+        @Override\n@@ -673,2 +662,1 @@\n-        \/* package-private *\/\n-        Short256Mask xor(VectorMask<Short> mask) {\n+        public Short256Mask xor(VectorMask<Short> mask) {\n@@ -751,1 +739,1 @@\n-        private final VectorPayloadMF128B payload;\n+        private final VectorPayloadMF256S payload;\n@@ -753,4 +741,4 @@\n-        Short256Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF128B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Short256Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF256S) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -759,2 +747,2 @@\n-        public Short256Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Short256Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -763,6 +751,2 @@\n-        public Short256Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Short256Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Short256Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -773,1 +757,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -778,0 +762,1 @@\n+        @ForceInline\n@@ -785,2 +770,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Short.MAX_VALUE);\n+            assert(Short.MIN_VALUE <= -VLENGTH);\n@@ -792,3 +777,2 @@\n-        public Short256Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Short256Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Short256Vector)(((AbstractShuffle<Short>)(s)).toVectorTemplate())));\n+        Short256Vector toBitsVector() {\n+            return (Short256Vector) super.toBitsVectorTemplate();\n@@ -799,6 +783,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        ShortVector toBitsVector0() {\n+            return Short256Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -807,0 +787,1 @@\n+        @Override\n@@ -808,0 +789,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -809,7 +794,16 @@\n-        public Short256Shuffle rearrange(VectorShuffle<Short> shuffle) {\n-            Short256Shuffle s = (Short256Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            VectorSpecies<Integer> species = IntVector.SPECIES_256;\n+            Vector<Short> v = toBitsVector();\n+            v.convertShape(VectorOperators.S2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.S2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(short.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -817,3 +811,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putShort(payload, mfOffset + i * Short.BYTES, (short) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(short.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putShort(payload, offset + i * Short.BYTES, (short) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                short si = Unsafe.getUnsafe().getShort(indices, offset + i * Short.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -821,2 +849,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Short256Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short256Vector.java","additions":88,"deletions":61,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Short512Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Short512Shuffle)VectorSupport.shuffleIota(ETYPE, Short512Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Short512Shuffle)VectorSupport.shuffleIota(ETYPE, Short512Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Short512Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Short512Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Short512Shuffle shuffleFromArray(int[] indexes, int i) { return new Short512Shuffle(indexes, i); }\n+    Short512Shuffle shuffleFromArray(int[] indices, int i) { return new Short512Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Short> toShuffle() {\n-        return super.toShuffleTemplate(Short512Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -659,4 +646,5 @@\n-        public Short512Mask eq(VectorMask<Short> mask) {\n-            Objects.requireNonNull(mask);\n-            Short512Mask m = (Short512Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Short512Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Short512Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Short512Mask.class, short.class, VLENGTH, offset, limit,\n+                (o, l) -> (Short512Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -704,0 +692,1 @@\n+        @Override\n@@ -705,2 +694,1 @@\n-        \/* package-private *\/\n-        Short512Mask xor(VectorMask<Short> mask) {\n+        public Short512Mask xor(VectorMask<Short> mask) {\n@@ -783,1 +771,1 @@\n-        private final VectorPayloadMF256B payload;\n+        private final VectorPayloadMF512S payload;\n@@ -785,4 +773,4 @@\n-        Short512Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF256B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Short512Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF512S) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -791,2 +779,2 @@\n-        public Short512Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Short512Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -795,6 +783,2 @@\n-        public Short512Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Short512Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Short512Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -805,1 +789,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -810,0 +794,1 @@\n+        @ForceInline\n@@ -817,2 +802,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Short.MAX_VALUE);\n+            assert(Short.MIN_VALUE <= -VLENGTH);\n@@ -824,3 +809,2 @@\n-        public Short512Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Short512Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Short512Vector)(((AbstractShuffle<Short>)(s)).toVectorTemplate())));\n+        Short512Vector toBitsVector() {\n+            return (Short512Vector) super.toBitsVectorTemplate();\n@@ -831,6 +815,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        ShortVector toBitsVector0() {\n+            return Short512Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -839,0 +819,1 @@\n+        @Override\n@@ -840,0 +821,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -841,7 +826,16 @@\n-        public Short512Shuffle rearrange(VectorShuffle<Short> shuffle) {\n-            Short512Shuffle s = (Short512Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            VectorSpecies<Integer> species = IntVector.SPECIES_512;\n+            Vector<Short> v = toBitsVector();\n+            v.convertShape(VectorOperators.S2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.S2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(short.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -849,3 +843,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putShort(payload, mfOffset + i * Short.BYTES, (short) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(short.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putShort(payload, offset + i * Short.BYTES, (short) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                short si = Unsafe.getUnsafe().getShort(indices, offset + i * Short.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -853,2 +881,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Short512Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short512Vector.java","additions":88,"deletions":61,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -144,15 +144,0 @@\n-    @ForceInline\n-    Short64Shuffle iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return (Short64Shuffle)VectorSupport.shuffleIota(ETYPE, Short64Shuffle.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return (Short64Shuffle)VectorSupport.shuffleIota(ETYPE, Short64Shuffle.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n-    @Override\n-    @ForceInline\n-    Short64Shuffle shuffleFromBytes(VectorPayloadMF reorder) { return new Short64Shuffle(reorder); }\n-\n@@ -161,1 +146,1 @@\n-    Short64Shuffle shuffleFromArray(int[] indexes, int i) { return new Short64Shuffle(indexes, i); }\n+    Short64Shuffle shuffleFromArray(int[] indices, int i) { return new Short64Shuffle(indices, i); }\n@@ -360,0 +345,1 @@\n+    @Override\n@@ -361,2 +347,3 @@\n-    public VectorShuffle<Short> toShuffle() {\n-        return super.toShuffleTemplate(Short64Shuffle.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -603,4 +590,5 @@\n-        public Short64Mask eq(VectorMask<Short> mask) {\n-            Objects.requireNonNull(mask);\n-            Short64Mask m = (Short64Mask)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        Short64Mask indexPartiallyInUpperRange(long offset, long limit) {\n+            return (Short64Mask) VectorSupport.indexPartiallyInUpperRange(\n+                Short64Mask.class, short.class, VLENGTH, offset, limit,\n+                (o, l) -> (Short64Mask) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -648,0 +636,1 @@\n+        @Override\n@@ -649,2 +638,1 @@\n-        \/* package-private *\/\n-        Short64Mask xor(VectorMask<Short> mask) {\n+        public Short64Mask xor(VectorMask<Short> mask) {\n@@ -727,1 +715,1 @@\n-        private final VectorPayloadMF32B payload;\n+        private final VectorPayloadMF64S payload;\n@@ -729,4 +717,4 @@\n-        Short64Shuffle(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF32B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        Short64Shuffle(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF64S) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -735,2 +723,2 @@\n-        public Short64Shuffle(int[] reorder) {\n-            this(reorder, 0);\n+        Short64Shuffle(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -739,6 +727,2 @@\n-        public Short64Shuffle(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public Short64Shuffle(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        Short64Shuffle(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -749,1 +733,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -754,0 +738,1 @@\n+        @ForceInline\n@@ -761,2 +746,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < Short.MAX_VALUE);\n+            assert(Short.MIN_VALUE <= -VLENGTH);\n@@ -768,3 +753,2 @@\n-        public Short64Vector toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, Short64Shuffle.class, this, VLENGTH,\n-                                                    (s) -> ((Short64Vector)(((AbstractShuffle<Short>)(s)).toVectorTemplate())));\n+        Short64Vector toBitsVector() {\n+            return (Short64Vector) super.toBitsVectorTemplate();\n@@ -775,6 +759,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        ShortVector toBitsVector0() {\n+            return Short64Vector.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -783,0 +763,1 @@\n+        @Override\n@@ -784,0 +765,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -785,7 +770,16 @@\n-        public Short64Shuffle rearrange(VectorShuffle<Short> shuffle) {\n-            Short64Shuffle s = (Short64Shuffle) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+            VectorSpecies<Integer> species = IntVector.SPECIES_64;\n+            Vector<Short> v = toBitsVector();\n+            v.convertShape(VectorOperators.S2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.S2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(short.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n@@ -793,3 +787,37 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putShort(payload, mfOffset + i * Short.BYTES, (short) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory(short.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().putShort(payload, offset + i * Short.BYTES, (short) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                short si = Unsafe.getUnsafe().getShort(indices, offset + i * Short.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -797,2 +825,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new Short64Shuffle(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short64Vector.java","additions":88,"deletions":61,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-    static final ValueLayout.OfShort ELEMENT_LAYOUT = ValueLayout.JAVA_SHORT.withBitAlignment(8);\n+    static final ValueLayout.OfShort ELEMENT_LAYOUT = ValueLayout.JAVA_SHORT.withByteAlignment(1);\n@@ -1189,1 +1189,1 @@\n-   \/**\n+    \/**\n@@ -2599,2 +2599,2 @@\n-    private final\n-    VectorShuffle<Short> toShuffle0(ShortSpecies dsp) {\n+    final <F>\n+    VectorShuffle<F> toShuffle0(AbstractSpecies<F> dsp) {\n@@ -2609,12 +2609,0 @@\n-    \/*package-private*\/\n-    @ForceInline\n-    final\n-    VectorShuffle<Short> toShuffleTemplate(Class<?> shuffleType) {\n-        ShortSpecies vsp = vspecies();\n-        return VectorSupport.convert(VectorSupport.VECTOR_OP_CAST,\n-                                     getClass(), short.class, length(),\n-                                     shuffleType, byte.class, length(),\n-                                     this, vsp,\n-                                     ShortVector::toShuffle0);\n-    }\n-\n@@ -3426,1 +3414,1 @@\n-     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_SHORT.withBitAlignment(8), n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_SHORT.withByteAlignment(1), n);\n@@ -4209,0 +4197,1 @@\n+                Class<? extends AbstractShuffle<Short>> shuffleType,\n@@ -4211,1 +4200,1 @@\n-                  vectorType, maskType,\n+                  vectorType, maskType, shuffleType,\n@@ -4507,0 +4496,1 @@\n+                            Short64Vector.Short64Shuffle.class,\n@@ -4514,0 +4504,1 @@\n+                            Short128Vector.Short128Shuffle.class,\n@@ -4521,0 +4512,1 @@\n+                            Short256Vector.Short256Shuffle.class,\n@@ -4528,0 +4520,1 @@\n+                            Short512Vector.Short512Shuffle.class,\n@@ -4536,0 +4529,1 @@\n+                            ShortMaxVector.ShortMaxShuffle.class,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortVector.java","additions":12,"deletions":18,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -405,3 +405,2 @@\n-     * Determines logical equivalence of this mask\n-     * to a second input mask (as boolean {@code a==b}\n-     * or {@code a^~b}).\n+     * Determines logical symmetric difference\n+     * (as {@code a^b}) of this mask and a second input mask.\n@@ -409,4 +408,3 @@\n-     * This is a lane-wise binary operation tests each\n-     * corresponding pair of mask bits for equality.\n-     * It is also equivalent to a inverse {@code XOR}\n-     * operation ({@code ^~}) on the mask bits.\n+     * This is a lane-wise binary operation which applies\n+     * the logical {@code XOR} operation\n+     * ({@code ^}) to each corresponding pair of mask bits.\n@@ -415,2 +413,2 @@\n-     * @return a mask showing where the two input masks were equal\n-     * @see #equals\n+     * @return the result of logically disjunctively disjoining the two\n+     * input masks\n@@ -418,1 +416,1 @@\n-    public abstract VectorMask<E> eq(VectorMask<E> m);\n+    public abstract VectorMask<E> xor(VectorMask<E> m);\n@@ -433,0 +431,17 @@\n+    \/**\n+     * Determines logical equivalence of this mask\n+     * to a second input mask (as boolean {@code a==b}\n+     * or {@code a^~b}).\n+     * <p>\n+     * This is a lane-wise binary operation tests each\n+     * corresponding pair of mask bits for equality.\n+     * It is also equivalent to the logical {@code XNOR}\n+     * operation ({@code ^~}) to each corresponding pair\n+     * of mask bits.\n+     *\n+     * @param m the input mask\n+     * @return a mask showing where the two input masks were equal\n+     * @see #equals\n+     *\/\n+    public abstract VectorMask<E> eq(VectorMask<E> m);\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/VectorMask.java","additions":25,"deletions":10,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -560,1 +560,1 @@\n-    public int laneSource(int i) { return toArray()[i]; }\n+    public abstract int laneSource(int i);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/VectorShuffle.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -64,1 +64,1 @@\n-    static final ValueLayout.Of$Type$ ELEMENT_LAYOUT = ValueLayout.JAVA_$TYPE$.withBitAlignment(8);\n+    static final ValueLayout.Of$Type$ ELEMENT_LAYOUT = ValueLayout.JAVA_$TYPE$.withByteAlignment(1);\n@@ -1340,1 +1340,1 @@\n-   \/**\n+    \/**\n@@ -2993,2 +2993,2 @@\n-    private final\n-    VectorShuffle<$Boxtype$> toShuffle0($Type$Species dsp) {\n+    final <F>\n+    VectorShuffle<F> toShuffle0(AbstractSpecies<F> dsp) {\n@@ -3003,12 +3003,0 @@\n-    \/*package-private*\/\n-    @ForceInline\n-    final\n-    VectorShuffle<$Boxtype$> toShuffleTemplate(Class<?> shuffleType) {\n-        $Type$Species vsp = vspecies();\n-        return VectorSupport.convert(VectorSupport.VECTOR_OP_CAST,\n-                                     getClass(), $type$.class, length(),\n-                                     shuffleType, byte.class, length(),\n-                                     this, vsp,\n-                                     $Type$Vector::toShuffle0);\n-    }\n-\n@@ -4248,1 +4236,1 @@\n-     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_$TYPE$.withBitAlignment(8), n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_$TYPE$.withByteAlignment(1), n);\n@@ -5494,0 +5482,1 @@\n+                Class<? extends AbstractShuffle<$Boxtype$>> shuffleType,\n@@ -5496,1 +5485,1 @@\n-                  vectorType, maskType,\n+                  vectorType, maskType, shuffleType,\n@@ -5799,0 +5788,1 @@\n+                            $Type$64Vector.$Type$64Shuffle.class,\n@@ -5806,0 +5796,1 @@\n+                            $Type$128Vector.$Type$128Shuffle.class,\n@@ -5813,0 +5804,1 @@\n+                            $Type$256Vector.$Type$256Shuffle.class,\n@@ -5820,0 +5812,1 @@\n+                            $Type$512Vector.$Type$512Shuffle.class,\n@@ -5828,0 +5821,1 @@\n+                            $Type$MaxVector.$Type$MaxShuffle.class,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-Vector.java.template","additions":12,"deletions":18,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -146,11 +146,0 @@\n-    @ForceInline\n-    $shuffletype$ iotaShuffle(int start, int step, boolean wrap) {\n-      if (wrap) {\n-        return ($shuffletype$)VectorSupport.shuffleIota(ETYPE, $shuffletype$.class, VSPECIES, VLENGTH, start, step, 1,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (VectorIntrinsics.wrapToRange(i*lstep + lstart, l))));\n-      } else {\n-        return ($shuffletype$)VectorSupport.shuffleIota(ETYPE, $shuffletype$.class, VSPECIES, VLENGTH, start, step, 0,\n-                (l, lstart, lstep, s) -> s.shuffleFromOp(i -> (i*lstep + lstart)));\n-      }\n-    }\n-\n@@ -159,5 +148,1 @@\n-    $shuffletype$ shuffleFromBytes(VectorPayloadMF reorder) { return new $shuffletype$(reorder); }\n-\n-    @Override\n-    @ForceInline\n-    $shuffletype$ shuffleFromArray(int[] indexes, int i) { return new $shuffletype$(indexes, i); }\n+    $shuffletype$ shuffleFromArray(int[] indices, int i) { return new $shuffletype$(indices, i); }\n@@ -364,0 +349,1 @@\n+    @Override\n@@ -365,2 +351,3 @@\n-    public VectorShuffle<$Boxtype$> toShuffle() {\n-        return super.toShuffleTemplate($shuffletype$.class); \/\/ specialize\n+    public final\n+    <F> VectorShuffle<F> toShuffle(AbstractSpecies<F> dsp) {\n+        return super.toShuffleTemplate(dsp);\n@@ -874,4 +861,5 @@\n-        public $masktype$ eq(VectorMask<$Boxtype$> mask) {\n-            Objects.requireNonNull(mask);\n-            $masktype$ m = ($masktype$)mask;\n-            return xor(m.not());\n+        \/*package-private*\/\n+        $masktype$ indexPartiallyInUpperRange(long offset, long limit) {\n+            return ($masktype$) VectorSupport.indexPartiallyInUpperRange(\n+                $masktype$.class, $type$.class, VLENGTH, offset, limit,\n+                (o, l) -> ($masktype$) TRUE_MASK.indexPartiallyInRange(o, l));\n@@ -919,0 +907,1 @@\n+        @Override\n@@ -920,2 +909,1 @@\n-        \/* package-private *\/\n-        $masktype$ xor(VectorMask<$Boxtype$> mask) {\n+        public $masktype$ xor(VectorMask<$Boxtype$> mask) {\n@@ -1014,1 +1002,1 @@\n-        static final Class<$Boxtype$> ETYPE = $type$.class; \/\/ used by the JVM\n+        static final Class<$Boxbitstype$> ETYPE = $bitstype$.class; \/\/ used by the JVM\n@@ -1016,1 +1004,1 @@\n-        private final VectorPayloadMF$vectorsizeinbytes$B payload;\n+        private final VectorPayloadMF$bits$$Boxbitsinitials$ payload;\n@@ -1018,4 +1006,4 @@\n-        $shuffletype$(VectorPayloadMF reorder) {\n-            this.payload = (VectorPayloadMF$vectorsizeinbytes$B) reorder;\n-            assert(VLENGTH == reorder.length());\n-            assert(indexesInRange(reorder));\n+        $shuffletype$(VectorPayloadMF payload) {\n+            this.payload = (VectorPayloadMF$bits$$Boxbitsinitials$) payload;\n+            assert(VLENGTH == payload.length());\n+            assert(indicesInRange(payload));\n@@ -1024,2 +1012,2 @@\n-        public $shuffletype$(int[] reorder) {\n-            this(reorder, 0);\n+        $shuffletype$(int[] indices, int i) {\n+            this(prepare(indices, i));\n@@ -1028,6 +1016,2 @@\n-        public $shuffletype$(int[] reorder, int i) {\n-            this(prepare(VLENGTH, reorder, i));\n-        }\n-\n-        public $shuffletype$(IntUnaryOperator fn) {\n-            this(prepare(VLENGTH, fn));\n+        $shuffletype$(IntUnaryOperator fn) {\n+            this(prepare(fn));\n@@ -1038,1 +1022,1 @@\n-        protected final VectorPayloadMF reorder() {\n+        protected final VectorPayloadMF indices() {\n@@ -1043,0 +1027,1 @@\n+        @ForceInline\n@@ -1050,2 +1035,2 @@\n-            assert(VLENGTH < Byte.MAX_VALUE);\n-            assert(Byte.MIN_VALUE <= -VLENGTH);\n+            assert(VLENGTH < $Boxbitstype$.MAX_VALUE);\n+            assert($Boxbitstype$.MIN_VALUE <= -VLENGTH);\n@@ -1057,3 +1042,2 @@\n-        public $vectortype$ toVector() {\n-            return VectorSupport.shuffleToVector(VCLASS, ETYPE, $shuffletype$.class, this, VLENGTH,\n-                                                    (s) -> (($vectortype$)(((AbstractShuffle<$Boxtype$>)(s)).toVectorTemplate())));\n+        $bitsvectortype$ toBitsVector() {\n+            return ($bitsvectortype$) super.toBitsVectorTemplate();\n@@ -1064,6 +1048,2 @@\n-        public <F> VectorShuffle<F> cast(VectorSpecies<F> s) {\n-            AbstractSpecies<F> species = (AbstractSpecies<F>) s;\n-            if (length() != species.laneCount())\n-                throw new IllegalArgumentException(\"VectorShuffle length and species length differ\");\n-            int[] shuffleArray = toArray();\n-            return s.shuffleFromArray(shuffleArray, 0).check(s);\n+        $Bitstype$Vector toBitsVector0() {\n+            return $bitsvectortype$.VSPECIES.dummyVectorMF().vectorFactory(indices());\n@@ -1072,0 +1052,1 @@\n+        @Override\n@@ -1073,0 +1054,4 @@\n+        public int laneSource(int i) {\n+            return (int)toBitsVector().lane(i);\n+        }\n+\n@@ -1074,7 +1059,77 @@\n-        public $shuffletype$ rearrange(VectorShuffle<$Boxtype$> shuffle) {\n-            $shuffletype$ s = ($shuffletype$) shuffle;\n-            VectorPayloadMF reorder1 = reorder();\n-            VectorPayloadMF reorder2 = s.reorder();\n-            VectorPayloadMF r = VectorPayloadMF.newInstanceFactory(byte.class, VLENGTH);\n-            r = Unsafe.getUnsafe().makePrivateBuffer(r);\n-            long offset = r.multiFieldOffset();\n+        @ForceInline\n+        public void intoArray(int[] a, int offset) {\n+#if[byte]\n+            VectorSpecies<Integer> species = IntVector.SPECIES_$BITS$;\n+            Vector<Byte> v = toBitsVector();\n+            v.convertShape(VectorOperators.B2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.B2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+            v.convertShape(VectorOperators.B2I, species, 2)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 2);\n+            v.convertShape(VectorOperators.B2I, species, 3)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length() * 3);\n+#end[byte]\n+#if[short]\n+            VectorSpecies<Integer> species = IntVector.SPECIES_$BITS$;\n+            Vector<Short> v = toBitsVector();\n+            v.convertShape(VectorOperators.S2I, species, 0)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset);\n+            v.convertShape(VectorOperators.S2I, species, 1)\n+                    .reinterpretAsInts()\n+                    .intoArray(a, offset + species.length());\n+#end[short]\n+#if[intOrFloat]\n+            toBitsVector().intoArray(a, offset);\n+#end[intOrFloat]\n+#if[longOrDouble]\n+            switch (length()) {\n+                case 1 -> a[offset] = laneSource(0);\n+                case 2 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_64, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 4 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_128, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 8 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_256, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                case 16 -> toBitsVector()\n+                        .convertShape(VectorOperators.L2I, IntVector.SPECIES_512, 0)\n+                        .reinterpretAsInts()\n+                        .intoArray(a, offset);\n+                default -> {\n+                    VectorIntrinsics.checkFromIndexSize(offset, length(), a.length);\n+                    for (int i = 0; i < length(); i++) {\n+                        a[offset + i] = laneSource(i);\n+                    }\n+                }\n+            }\n+#end[longOrDouble]\n+        }\n+\n+        private static VectorPayloadMF prepare(int[] indices, int offset) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory($bitstype$.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long mfOffset = payload.multiFieldOffset();\n+            for (int i = 0; i < VLENGTH; i++) {\n+                int si = indices[offset + i];\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().put$Bitstype$(payload, mfOffset + i * $Boxbitstype$.BYTES, ($bitstype$) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+        private static VectorPayloadMF prepare(IntUnaryOperator f) {\n+            VectorPayloadMF payload = VectorPayloadMF.newInstanceFactory($bitstype$.class, VLENGTH);\n+            payload = Unsafe.getUnsafe().makePrivateBuffer(payload);\n+            long offset = payload.multiFieldOffset();\n@@ -1082,3 +1137,24 @@\n-                int ssi = Unsafe.getUnsafe().getByte(reorder2, offset + i * Byte.BYTES);\n-                int si = Unsafe.getUnsafe().getByte(reorder1, offset + ssi * Byte.BYTES);\n-                Unsafe.getUnsafe().putByte(r, offset + i * Byte.BYTES, (byte) si);\n+                int si = f.applyAsInt(i);\n+                si = partiallyWrapIndex(si, VLENGTH);\n+                Unsafe.getUnsafe().put$Bitstype$(payload, offset + i * $Boxbitstype$.BYTES, ($bitstype$) si);\n+            }\n+            payload = Unsafe.getUnsafe().finishPrivateBuffer(payload);\n+            return payload;\n+        }\n+\n+\n+        private static boolean indicesInRange(VectorPayloadMF indices) {\n+            int length = indices.length();\n+            long offset = indices.multiFieldOffset();\n+            for (int i = 0; i < length; i++) {\n+                $bitstype$ si = Unsafe.getUnsafe().get$Bitstype$(indices, offset + i * $Boxbitstype$.BYTES);\n+                if (si >= length || si < -length) {\n+                    boolean assertsEnabled = false;\n+                    assert(assertsEnabled = true);\n+                    if (assertsEnabled) {\n+                        String msg = (\"index \"+si+\"out of range [\"+length+\"] in \"+\n+                                indices.toString());\n+                        throw new AssertionError(msg);\n+                    }\n+                    return false;\n+                }\n@@ -1086,2 +1162,1 @@\n-            r = Unsafe.getUnsafe().finishPrivateBuffer(r);\n-            return new $shuffletype$(r);\n+            return true;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-VectorBits.java.template","additions":137,"deletions":62,"binary":false,"changes":199,"status":"modified"},{"patch":"@@ -61,0 +61,1 @@\n+  Boxbitsinitials=$Boxinitials\n@@ -110,0 +111,1 @@\n+      Boxbitsinitials=I\n@@ -118,0 +120,1 @@\n+      Boxbitsinitials=L\n@@ -123,1 +126,1 @@\n-  args=\"$args -K$kind -DBoxtype=$Boxtype -DBoxinitials=$Boxinitials -DWideboxtype=$Wideboxtype\"\n+  args=\"$args -K$kind -DBoxtype=$Boxtype -DBoxinitials=$Boxinitials -DBoxbitsinitials=$Boxbitsinitials -DWideboxtype=$Wideboxtype\"\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/gen-src.sh","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -5857,0 +5857,76 @@\n+    static boolean band(boolean a, boolean b) {\n+        return a & b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndByteMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.and(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, ByteMaxVectorTests::band);\n+    }\n+\n+    static boolean bor(boolean a, boolean b) {\n+        return a | b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskOrByteMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.or(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, ByteMaxVectorTests::bor);\n+    }\n+\n+    static boolean bxor(boolean a, boolean b) {\n+        return a != b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskXorByteMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.xor(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, ByteMaxVectorTests::bxor);\n+    }\n+\n+    static boolean bandNot(boolean a, boolean b) {\n+        return a & !b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndNotByteMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.andNot(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, ByteMaxVectorTests::bandNot);\n+    }\n+\n","filename":"test\/jdk\/jdk\/incubator\/vector\/ByteMaxVectorTests.java","additions":76,"deletions":0,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -4888,0 +4888,76 @@\n+    static boolean band(boolean a, boolean b) {\n+        return a & b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndDoubleMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.and(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, DoubleMaxVectorTests::band);\n+    }\n+\n+    static boolean bor(boolean a, boolean b) {\n+        return a | b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskOrDoubleMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.or(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, DoubleMaxVectorTests::bor);\n+    }\n+\n+    static boolean bxor(boolean a, boolean b) {\n+        return a != b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskXorDoubleMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.xor(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, DoubleMaxVectorTests::bxor);\n+    }\n+\n+    static boolean bandNot(boolean a, boolean b) {\n+        return a & !b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndNotDoubleMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.andNot(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, DoubleMaxVectorTests::bandNot);\n+    }\n+\n","filename":"test\/jdk\/jdk\/incubator\/vector\/DoubleMaxVectorTests.java","additions":76,"deletions":0,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -5890,0 +5890,76 @@\n+    static boolean band(boolean a, boolean b) {\n+        return a & b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndIntMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.and(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, IntMaxVectorTests::band);\n+    }\n+\n+    static boolean bor(boolean a, boolean b) {\n+        return a | b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskOrIntMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.or(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, IntMaxVectorTests::bor);\n+    }\n+\n+    static boolean bxor(boolean a, boolean b) {\n+        return a != b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskXorIntMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.xor(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, IntMaxVectorTests::bxor);\n+    }\n+\n+    static boolean bandNot(boolean a, boolean b) {\n+        return a & !b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndNotIntMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.andNot(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, IntMaxVectorTests::bandNot);\n+    }\n+\n","filename":"test\/jdk\/jdk\/incubator\/vector\/IntMaxVectorTests.java","additions":76,"deletions":0,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -5776,0 +5776,76 @@\n+    static boolean band(boolean a, boolean b) {\n+        return a & b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndLongMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.and(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, LongMaxVectorTests::band);\n+    }\n+\n+    static boolean bor(boolean a, boolean b) {\n+        return a | b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskOrLongMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.or(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, LongMaxVectorTests::bor);\n+    }\n+\n+    static boolean bxor(boolean a, boolean b) {\n+        return a != b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskXorLongMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.xor(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, LongMaxVectorTests::bxor);\n+    }\n+\n+    static boolean bandNot(boolean a, boolean b) {\n+        return a & !b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndNotLongMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.andNot(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, LongMaxVectorTests::bandNot);\n+    }\n+\n","filename":"test\/jdk\/jdk\/incubator\/vector\/LongMaxVectorTests.java","additions":76,"deletions":0,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -5837,0 +5837,76 @@\n+    static boolean band(boolean a, boolean b) {\n+        return a & b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndShortMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.and(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, ShortMaxVectorTests::band);\n+    }\n+\n+    static boolean bor(boolean a, boolean b) {\n+        return a | b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskOrShortMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.or(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, ShortMaxVectorTests::bor);\n+    }\n+\n+    static boolean bxor(boolean a, boolean b) {\n+        return a != b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskXorShortMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.xor(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, ShortMaxVectorTests::bxor);\n+    }\n+\n+    static boolean bandNot(boolean a, boolean b) {\n+        return a & !b;\n+    }\n+\n+    @Test(dataProvider = \"maskCompareOpProvider\")\n+    static void maskAndNotShortMaxVectorTestsSmokeTest(IntFunction<boolean[]> fa, IntFunction<boolean[]> fb) {\n+        boolean[] a = fa.apply(SPECIES.length());\n+        boolean[] b = fb.apply(SPECIES.length());\n+        boolean[] r = new boolean[a.length];\n+\n+        for (int i = 0; i < a.length; i += SPECIES.length()) {\n+            var av = SPECIES.loadMask(a, i);\n+            var bv = SPECIES.loadMask(b, i);\n+            var cv = av.andNot(bv);\n+            cv.intoArray(r, i);\n+        }\n+        assertArraysEquals(r, a, b, ShortMaxVectorTests::bandNot);\n+    }\n+\n","filename":"test\/jdk\/jdk\/incubator\/vector\/ShortMaxVectorTests.java","additions":76,"deletions":0,"binary":false,"changes":76,"status":"modified"}]}