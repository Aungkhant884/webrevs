{"files":[{"patch":"@@ -1425,0 +1425,1 @@\n+        args = concat(args, \"--with-version-pre=\" + version_numbers.get(\"DEFAULT_PROMOTED_VERSION_PRE\"));\n","filename":"make\/conf\/jib-profiles.js","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -51,1 +51,1 @@\n-                       bcEscapeAnalyzer.cpp ciTypeFlow.cpp\n+                       bcEscapeAnalyzer.cpp ciTypeFlow.cpp macroAssembler_common.cpp\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -106,0 +107,6 @@\n+void LIRGenerator::init_temps_for_substitutability_check(LIR_Opr& tmp1, LIR_Opr& tmp2) {\n+  tmp1 = new_register(T_INT);\n+  tmp2 = LIR_OprFact::illegalOpr;\n+}\n+\n+\n@@ -317,0 +324,5 @@\n+  \/\/ Need a scratch register for inline type\n+  LIR_Opr scratch = LIR_OprFact::illegalOpr;\n+  if (EnableValhalla && x->maybe_inlinetype()) {\n+    scratch = new_register(T_INT);\n+  }\n@@ -322,0 +334,6 @@\n+\n+  CodeStub* throw_imse_stub =\n+      x->maybe_inlinetype() ?\n+      new SimpleExceptionStub(Runtime1::throw_illegal_monitor_state_exception_id, LIR_OprFact::illegalOpr, state_for(x)) :\n+      NULL;\n+\n@@ -325,2 +343,2 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n-                        x->monitor_no(), info_for_exception, info);\n+  monitor_enter(obj.result(), lock, syncTempOpr(), scratch,\n+                        x->monitor_no(), info_for_exception, info, throw_imse_stub);\n@@ -1112,5 +1130,22 @@\n-                       FrameMap::r10_oop_opr,\n-                       FrameMap::r11_oop_opr,\n-                       FrameMap::r4_oop_opr,\n-                       LIR_OprFact::illegalOpr,\n-                       FrameMap::r3_metadata_opr, info);\n+               \/* allow_inline *\/ false,\n+               FrameMap::r10_oop_opr,\n+               FrameMap::r11_oop_opr,\n+               FrameMap::r4_oop_opr,\n+               LIR_OprFact::illegalOpr,\n+               FrameMap::r3_metadata_opr, info);\n+  LIR_Opr result = rlock_result(x);\n+  __ move(reg, result);\n+}\n+\n+void LIRGenerator::do_NewInlineTypeInstance(NewInlineTypeInstance* x) {\n+  \/\/ Mapping to do_NewInstance (same code) but use state_before for reexecution.\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+  x->set_to_object_type();\n+  LIR_Opr reg = result_register_for(x->type());\n+  new_instance(reg, x->klass(), false,\n+               \/* allow_inline *\/ true,\n+               FrameMap::r10_oop_opr,\n+               FrameMap::r11_oop_opr,\n+               FrameMap::r4_oop_opr,\n+               LIR_OprFact::illegalOpr,\n+               FrameMap::r3_metadata_opr, info);\n@@ -1119,0 +1154,1 @@\n+\n@@ -1166,2 +1202,2 @@\n-  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info);\n-  ciKlass* obj = (ciKlass*) ciObjArrayKlass::make(x->klass());\n+  ciKlass* obj = (ciKlass*) x->exact_type();\n+  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, x->is_null_free());\n@@ -1171,0 +1207,1 @@\n+\n@@ -1172,1 +1209,5 @@\n-  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);\n+  if (x->is_null_free()) {\n+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_PRIMITIVE_OBJECT, klass_reg, slow_path);\n+  } else {\n+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);\n+  }\n@@ -1248,0 +1289,3 @@\n+  if (x->is_null_free()) {\n+    __ null_check(obj.result(), new CodeEmitInfo(info_for_exception));\n+  }\n@@ -1266,0 +1310,2 @@\n+\n+\n@@ -1269,1 +1315,2 @@\n-               x->profiled_method(), x->profiled_bci());\n+               x->profiled_method(), x->profiled_bci(), x->is_null_free());\n+\n@@ -1347,1 +1394,6 @@\n-  __ cmp(lir_cond(cond), left, right);\n+  if (x->substitutability_check()) {\n+    substitutability_check(x, *xin, *yin);\n+  } else {\n+    __ cmp(lir_cond(cond), left, right);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":64,"deletions":12,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -157,1 +157,21 @@\n-  __ push_call_clobbered_registers();\n+  \/\/ save the live input values\n+  RegSet saved = RegSet::of(pre_val);\n+  FloatRegSet fsaved;\n+\n+  \/\/ Barriers might be emitted when converting between (scalarized) calling\n+  \/\/ conventions for inline types. Save all argument registers before calling\n+  \/\/ into the runtime.\n+  if (EnableValhalla && InlineTypePassFieldsAsArgs) {\n+    if (tosca_live) saved += RegSet::of(r0);\n+    if (obj != noreg) saved += RegSet::of(obj);\n+    saved += RegSet::of(j_rarg0, j_rarg1, j_rarg2, j_rarg3);\n+    saved += RegSet::of(j_rarg4, j_rarg5, j_rarg6, j_rarg7);\n+\n+    fsaved += FloatRegSet::of(j_farg0, j_farg1, j_farg2, j_farg3);\n+    fsaved += FloatRegSet::of(j_farg4, j_farg5, j_farg6, j_farg7);\n+\n+    __ push(saved, sp);\n+    __ push_fp(fsaved, sp);\n+  } else {\n+    __ push_call_clobbered_registers();\n+  }\n@@ -178,1 +198,6 @@\n-  __ pop_call_clobbered_registers();\n+  if (EnableValhalla && InlineTypePassFieldsAsArgs) {\n+  __ pop_fp(fsaved, sp);\n+  __ pop(saved, sp);\n+  } else {\n+    __ pop_call_clobbered_registers();\n+  }\n@@ -191,2 +216,1 @@\n-  assert_different_registers(store_addr, new_val, thread, tmp, tmp2,\n-                             rscratch1);\n+  assert_different_registers(store_addr, new_val, thread, tmp, rscratch1);\n@@ -218,0 +242,2 @@\n+  assert_different_registers(store_addr, thread, tmp, tmp2, rscratch1);\n+\n@@ -251,0 +277,1 @@\n+\n@@ -253,0 +280,13 @@\n+  FloatRegSet fsaved;\n+\n+  \/\/ Barriers might be emitted when converting between (scalarized) calling\n+  \/\/ conventions for inline types. Save all argument registers before calling\n+  \/\/ into the runtime.\n+  if (EnableValhalla && InlineTypePassFieldsAsArgs) {\n+    saved += RegSet::of(j_rarg0, j_rarg1, j_rarg2, j_rarg3);\n+    saved += RegSet::of(j_rarg4, j_rarg5, j_rarg6, j_rarg7);\n+\n+    fsaved += FloatRegSet::of(j_farg0, j_farg1, j_farg2, j_farg3);\n+    fsaved += FloatRegSet::of(j_farg4, j_farg5, j_farg6, j_farg7);\n+  }\n+\n@@ -254,0 +294,1 @@\n+  __ push_fp(fsaved, sp);\n@@ -255,0 +296,1 @@\n+  __ pop_fp(fsaved, sp);\n@@ -285,0 +327,10 @@\n+\n+  bool in_heap = (decorators & IN_HEAP) != 0;\n+  bool as_normal = (decorators & AS_NORMAL) != 0;\n+  bool dest_uninitialized = (decorators & IS_DEST_UNINITIALIZED) != 0;\n+\n+  bool needs_pre_barrier = as_normal && !dest_uninitialized;\n+  bool needs_post_barrier = (val != noreg && in_heap);\n+\n+  assert_different_registers(val, tmp1, tmp2, tmp3);\n+\n@@ -294,7 +346,9 @@\n-  g1_write_barrier_pre(masm,\n-                       tmp3 \/* obj *\/,\n-                       tmp2 \/* pre_val *\/,\n-                       rthread \/* thread *\/,\n-                       tmp1  \/* tmp *\/,\n-                       val != noreg \/* tosca_live *\/,\n-                       false \/* expand_call *\/);\n+  if (needs_pre_barrier) {\n+    g1_write_barrier_pre(masm,\n+                         tmp3 \/* obj *\/,\n+                         tmp2 \/* pre_val *\/,\n+                         rthread \/* thread *\/,\n+                         tmp1  \/* tmp *\/,\n+                         val != noreg \/* tosca_live *\/,\n+                         false \/* expand_call *\/);\n+  }\n@@ -307,3 +361,5 @@\n-    if (UseCompressedOops) {\n-      new_val = rscratch2;\n-      __ mov(new_val, val);\n+    if (needs_post_barrier) {\n+      if (UseCompressedOops) {\n+        new_val = rscratch2;\n+        __ mov(new_val, val);\n+      }\n@@ -311,0 +367,1 @@\n+\n@@ -312,6 +369,9 @@\n-    g1_write_barrier_post(masm,\n-                          tmp3 \/* store_adr *\/,\n-                          new_val \/* new_val *\/,\n-                          rthread \/* thread *\/,\n-                          tmp1 \/* tmp *\/,\n-                          tmp2 \/* tmp2 *\/);\n+\n+    if (needs_post_barrier) {\n+      g1_write_barrier_post(masm,\n+                            tmp3 \/* store_adr *\/,\n+                            new_val \/* new_val *\/,\n+                            rthread \/* thread *\/,\n+                            tmp1 \/* tmp *\/,\n+                            tmp2 \/* tmp2 *\/);\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1BarrierSetAssembler_aarch64.cpp","additions":80,"deletions":20,"binary":false,"changes":100,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -56,0 +57,1 @@\n+#include \"runtime\/signature_cc.hpp\"\n@@ -58,0 +60,1 @@\n+#include \"vmreg_aarch64.inline.hpp\"\n@@ -1120,0 +1123,35 @@\n+void MacroAssembler::get_default_value_oop(Register inline_klass, Register temp_reg, Register obj) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_inline_type(inline_klass, temp_reg, done_check);\n+    stop(\"get_default_value_oop from non inline type klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  Register offset = temp_reg;\n+  \/\/ Getting the offset of the pre-allocated default value\n+  ldr(offset, Address(inline_klass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())));\n+  ldr(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())));\n+\n+  \/\/ Getting the mirror\n+  ldr(obj, Address(inline_klass, in_bytes(Klass::java_mirror_offset())));\n+  resolve_oop_handle(obj, inline_klass);\n+\n+  \/\/ Getting the pre-allocated default value from the mirror\n+  Address field(obj, offset);\n+  load_heap_oop(obj, field);\n+}\n+\n+void MacroAssembler::get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_empty_inline_type(inline_klass, temp_reg, done_check);\n+    stop(\"get_empty_value from non-empty inline klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  get_default_value_oop(inline_klass, temp_reg, obj);\n+}\n+\n@@ -1470,1 +1508,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -1503,1 +1545,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -1585,0 +1631,1 @@\n+  assert_different_registers(arg_1, c_rarg0);\n@@ -1592,0 +1639,2 @@\n+  assert_different_registers(arg_1, c_rarg0);\n+  assert_different_registers(arg_2, c_rarg0, c_rarg1);\n@@ -1598,0 +1647,4 @@\n+void MacroAssembler::super_call_VM_leaf(address entry_point) {\n+  MacroAssembler::call_VM_leaf_base(entry_point, 1);\n+}\n+\n@@ -1647,0 +1700,110 @@\n+void MacroAssembler::test_markword_is_inline_type(Register markword, Label& is_inline_type) {\n+  assert_different_registers(markword, rscratch2);\n+  andr(markword, markword, markWord::inline_type_mask_in_place);\n+  mov(rscratch2, markWord::inline_type_pattern);\n+  cmp(markword, rscratch2);\n+  br(Assembler::EQ, is_inline_type);\n+}\n+\n+void MacroAssembler::test_klass_is_inline_type(Register klass, Register temp_reg, Label& is_inline_type) {\n+  ldrw(temp_reg, Address(klass, Klass::access_flags_offset()));\n+  andr(temp_reg, temp_reg, JVM_ACC_VALUE);\n+  cbnz(temp_reg, is_inline_type);\n+}\n+\n+void MacroAssembler::test_oop_is_not_inline_type(Register object, Register tmp, Label& not_inline_type) {\n+  assert_different_registers(tmp, rscratch1);\n+  cbz(object, not_inline_type);\n+  const int is_inline_type_mask = markWord::inline_type_pattern;\n+  ldr(tmp, Address(object, oopDesc::mark_offset_in_bytes()));\n+  mov(rscratch1, is_inline_type_mask);\n+  andr(tmp, tmp, rscratch1);\n+  cmp(tmp, rscratch1);\n+  br(Assembler::NE, not_inline_type);\n+}\n+\n+void MacroAssembler::test_klass_is_empty_inline_type(Register klass, Register temp_reg, Label& is_empty_inline_type) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_inline_type(klass, temp_reg, done_check);\n+    stop(\"test_klass_is_empty_inline_type with non inline type klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  ldrw(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));\n+  andr(temp_reg, temp_reg, InstanceKlass::misc_flag_is_empty_inline_type());\n+  cbnz(temp_reg, is_empty_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_null_free_inline_type(Register flags, Register temp_reg, Label& is_null_free_inline_type) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbnz(flags, ConstantPoolCacheEntry::is_null_free_inline_type_shift, is_null_free_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_not_null_free_inline_type(Register flags, Register temp_reg, Label& not_null_free_inline_type) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbz(flags, ConstantPoolCacheEntry::is_null_free_inline_type_shift, not_null_free_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_inlined(Register flags, Register temp_reg, Label& is_flattened) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbnz(flags, ConstantPoolCacheEntry::is_inlined_shift, is_flattened);\n+}\n+\n+void MacroAssembler::test_oop_prototype_bit(Register oop, Register temp_reg, int32_t test_bit, bool jmp_set, Label& jmp_label) {\n+  Label test_mark_word;\n+  \/\/ load mark word\n+  ldr(temp_reg, Address(oop, oopDesc::mark_offset_in_bytes()));\n+  \/\/ check displaced\n+  tst(temp_reg, markWord::unlocked_value);\n+  br(Assembler::NE, test_mark_word);\n+  \/\/ slow path use klass prototype\n+  load_prototype_header(temp_reg, oop);\n+\n+  bind(test_mark_word);\n+  andr(temp_reg, temp_reg, test_bit);\n+  if (jmp_set) {\n+    cbnz(temp_reg, jmp_label);\n+  } else {\n+    cbz(temp_reg, jmp_label);\n+  }\n+}\n+\n+void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg, Label& is_flattened_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::flat_array_bit_in_place, true, is_flattened_array);\n+}\n+\n+void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,\n+                                                  Label&is_non_flattened_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::flat_array_bit_in_place, false, is_non_flattened_array);\n+}\n+\n+void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label& is_null_free_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::null_free_array_bit_in_place, true, is_null_free_array);\n+}\n+\n+void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&is_non_null_free_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::null_free_array_bit_in_place, false, is_non_null_free_array);\n+}\n+\n+void MacroAssembler::test_flattened_array_layout(Register lh, Label& is_flattened_array) {\n+  tst(lh, Klass::_lh_array_tag_flat_value_bit_inplace);\n+  br(Assembler::NE, is_flattened_array);\n+}\n+\n+void MacroAssembler::test_non_flattened_array_layout(Register lh, Label& is_non_flattened_array) {\n+  tst(lh, Klass::_lh_array_tag_flat_value_bit_inplace);\n+  br(Assembler::EQ, is_non_flattened_array);\n+}\n+\n+void MacroAssembler::test_null_free_array_layout(Register lh, Label& is_null_free_array) {\n+  tst(lh, Klass::_lh_null_free_array_bit_inplace);\n+  br(Assembler::NE, is_null_free_array);\n+}\n+\n+void MacroAssembler::test_non_null_free_array_layout(Register lh, Label& is_non_null_free_array) {\n+  tst(lh, Klass::_lh_null_free_array_bit_inplace);\n+  br(Assembler::EQ, is_non_null_free_array);\n+}\n+\n@@ -4049,0 +4212,8 @@\n+void MacroAssembler::load_metadata(Register dst, Register src) {\n+  if (UseCompressedClassPointers) {\n+    ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  } else {\n+    ldr(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n+\n@@ -4108,0 +4279,5 @@\n+void MacroAssembler::load_prototype_header(Register dst, Register src) {\n+  load_klass(dst, src);\n+  ldr(dst, Address(dst, Klass::prototype_header_offset()));\n+}\n+\n@@ -4432,0 +4608,40 @@\n+void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,\n+                                       Register inline_klass) {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->value_copy(this, decorators, src, dst, inline_klass);\n+}\n+\n+void MacroAssembler::first_field_offset(Register inline_klass, Register offset) {\n+  ldr(offset, Address(inline_klass, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+  ldrw(offset, Address(offset, InlineKlass::first_field_offset_offset()));\n+}\n+\n+void MacroAssembler::data_for_oop(Register oop, Register data, Register inline_klass) {\n+  \/\/ ((address) (void*) o) + vk->first_field_offset();\n+  Register offset = (data == oop) ? rscratch1 : data;\n+  first_field_offset(inline_klass, offset);\n+  if (data == oop) {\n+    add(data, data, offset);\n+  } else {\n+    lea(data, Address(oop, offset));\n+  }\n+}\n+\n+void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,\n+                                                Register index, Register data) {\n+  assert_different_registers(array, array_klass, index);\n+  assert_different_registers(rscratch1, array, index);\n+\n+  \/\/ array->base() + (index << Klass::layout_helper_log2_element_size(lh));\n+  ldrw(rscratch1, Address(array_klass, Klass::layout_helper_offset()));\n+\n+  \/\/ Klass::layout_helper_log2_element_size(lh)\n+  \/\/ (lh >> _lh_log2_element_size_shift) & _lh_log2_element_size_mask;\n+  lsr(rscratch1, rscratch1, Klass::_lh_log2_element_size_shift);\n+  andr(rscratch1, rscratch1, Klass::_lh_log2_element_size_mask);\n+  lslv(index, index, rscratch1);\n+\n+  add(data, array, index);\n+  add(data, data, arrayOopDesc::base_offset_in_bytes(T_PRIMITIVE_OBJECT));\n+}\n+\n@@ -4508,0 +4724,96 @@\n+\/\/ Object \/ value buffer allocation...\n+void MacroAssembler::allocate_instance(Register klass, Register new_obj,\n+                                       Register t1, Register t2,\n+                                       bool clear_fields, Label& alloc_failed)\n+{\n+  Label done, initialize_header, initialize_object, slow_case, slow_case_no_pop;\n+  Register layout_size = t1;\n+  assert(new_obj == r0, \"needs to be r0\");\n+  assert_different_registers(klass, new_obj, t1, t2);\n+\n+  \/\/ get instance_size in InstanceKlass (scaled to a count of bytes)\n+  ldrw(layout_size, Address(klass, Klass::layout_helper_offset()));\n+  \/\/ test to see if it has a finalizer or is malformed in some way\n+  tst(layout_size, Klass::_lh_instance_slow_path_bit);\n+  br(Assembler::NE, slow_case_no_pop);\n+\n+  \/\/ Allocate the instance:\n+  \/\/  If TLAB is enabled:\n+  \/\/    Try to allocate in the TLAB.\n+  \/\/    If fails, go to the slow path.\n+  \/\/    Initialize the allocation.\n+  \/\/    Exit.\n+  \/\/\n+  \/\/  Go to slow path.\n+\n+  if (UseTLAB) {\n+    push(klass);\n+    tlab_allocate(new_obj, layout_size, 0, klass, t2, slow_case);\n+    if (ZeroTLAB || (!clear_fields)) {\n+      \/\/ the fields have been already cleared\n+      b(initialize_header);\n+    } else {\n+      \/\/ initialize both the header and fields\n+      b(initialize_object);\n+    }\n+\n+    if (clear_fields) {\n+      \/\/ The object is initialized before the header.  If the object size is\n+      \/\/ zero, go directly to the header initialization.\n+      bind(initialize_object);\n+      subs(layout_size, layout_size, sizeof(oopDesc));\n+      br(Assembler::EQ, initialize_header);\n+\n+      \/\/ Initialize topmost object field, divide size by 8, check if odd and\n+      \/\/ test if zero.\n+\n+  #ifdef ASSERT\n+      \/\/ make sure instance_size was multiple of 8\n+      Label L;\n+      tst(layout_size, 7);\n+      br(Assembler::EQ, L);\n+      stop(\"object size is not multiple of 8 - adjust this code\");\n+      bind(L);\n+      \/\/ must be > 0, no extra check needed here\n+  #endif\n+\n+      lsr(layout_size, layout_size, LogBytesPerLong);\n+\n+      \/\/ initialize remaining object fields: instance_size was a multiple of 8\n+      {\n+        Label loop;\n+        Register base = t2;\n+\n+        bind(loop);\n+        add(rscratch1, new_obj, layout_size, Assembler::LSL, LogBytesPerLong);\n+        str(zr, Address(rscratch1, sizeof(oopDesc) - 1*oopSize));\n+        subs(layout_size, layout_size, 1);\n+        br(Assembler::NE, loop);\n+      }\n+    } \/\/ clear_fields\n+\n+    \/\/ initialize object header only.\n+    bind(initialize_header);\n+    pop(klass);\n+    Register mark_word = t2;\n+    ldr(mark_word, Address(klass, Klass::prototype_header_offset()));\n+    str(mark_word, Address(new_obj, oopDesc::mark_offset_in_bytes ()));\n+    store_klass_gap(new_obj, zr);  \/\/ zero klass gap for compressed oops\n+    mov(t2, klass);         \/\/ preserve klass\n+    store_klass(new_obj, t2);  \/\/ src klass reg is potentially compressed\n+\n+    \/\/ TODO: Valhalla removed SharedRuntime::dtrace_object_alloc from here ?\n+\n+    b(done);\n+  }\n+\n+  if (UseTLAB) {\n+    bind(slow_case);\n+    pop(klass);\n+  }\n+  bind(slow_case_no_pop);\n+  b(alloc_failed);\n+\n+  bind(done);\n+}\n+\n@@ -4547,0 +4859,13 @@\n+void MacroAssembler::get_inline_type_field_klass(Register klass, Register index, Register inline_klass) {\n+  ldr(inline_klass, Address(klass, InstanceKlass::inline_type_field_klasses_offset()));\n+#ifdef ASSERT\n+  {\n+    Label done;\n+    cbnz(inline_klass, done);\n+    stop(\"get_inline_type_field_klass contains no inline klass\");\n+    bind(done);\n+  }\n+#endif\n+  ldr(inline_klass, Address(inline_klass, index, Address::lsl(3)));\n+}\n+\n@@ -4672,0 +4997,51 @@\n+void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair) {\n+  if (needs_stack_repair) {\n+    \/\/ Remove the extension of the caller's frame used for inline type unpacking\n+    \/\/\n+    \/\/ Right now the stack looks like this:\n+    \/\/\n+    \/\/ | Arguments from caller     |\n+    \/\/ |---------------------------|  <-- caller's SP\n+    \/\/ | Saved LR #1               |\n+    \/\/ | Saved FP #1               |\n+    \/\/ |---------------------------|\n+    \/\/ | Extension space for       |\n+    \/\/ |   inline arg (un)packing  |\n+    \/\/ |---------------------------|  <-- start of this method's frame\n+    \/\/ | Saved LR #2               |\n+    \/\/ | Saved FP #2               |\n+    \/\/ |---------------------------|  <-- FP\n+    \/\/ | sp_inc                    |\n+    \/\/ | method locals             |\n+    \/\/ |---------------------------|  <-- SP\n+    \/\/\n+    \/\/ There are two copies of FP and LR on the stack. They will be identical\n+    \/\/ unless the caller has been deoptimized, in which case LR #1 will be patched\n+    \/\/ to point at the deopt blob, and LR #2 will still point into the old method.\n+    \/\/\n+    \/\/ The sp_inc stack slot holds the total size of the frame including the\n+    \/\/ extension space minus two words for the saved FP and LR.\n+\n+    int sp_inc_offset = initial_framesize - 3 * wordSize;  \/\/ Immediately below saved LR and FP\n+\n+    ldr(rscratch1, Address(sp, sp_inc_offset));\n+    add(sp, sp, rscratch1);\n+    ldp(rfp, lr, Address(post(sp, 2 * wordSize)));\n+  } else {\n+    remove_frame(initial_framesize);\n+  }\n+}\n+\n+void MacroAssembler::save_stack_increment(int sp_inc, int frame_size) {\n+  int real_frame_size = frame_size + sp_inc;\n+  assert(sp_inc == 0 || sp_inc > 2*wordSize, \"invalid sp_inc value\");\n+  assert(real_frame_size >= 2*wordSize, \"frame size must include FP\/LR space\");\n+  assert((real_frame_size & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n+\n+  int sp_inc_offset = frame_size - 3 * wordSize;  \/\/ Immediately below saved LR and FP\n+\n+  \/\/ Subtract two words for the saved FP and LR as these will be popped\n+  \/\/ separately. See remove_frame above.\n+  mov(rscratch1, real_frame_size - 2*wordSize);\n+  str(rscratch1, Address(sp, sp_inc_offset));\n+}\n@@ -5580,0 +5956,432 @@\n+#ifdef COMPILER2\n+\/\/ C2 compiled method's prolog code\n+\/\/ Moved here from aarch64.ad to support Valhalla code belows\n+void MacroAssembler::verified_entry(Compile* C, int sp_inc) {\n+\n+  \/\/ n.b. frame size includes space for return pc and rfp\n+  const long framesize = C->output()->frame_size_in_bytes();\n+\n+  \/\/ insert a nop at the start of the prolog so we can patch in a\n+  \/\/ branch if we need to invalidate the method later\n+  nop();\n+\n+  int bangsize = C->output()->bang_size_in_bytes();\n+  if (C->output()->need_stack_bang(bangsize))\n+    generate_stack_overflow_check(bangsize);\n+\n+  build_frame(framesize);\n+\n+  if (C->needs_stack_repair()) {\n+    save_stack_increment(sp_inc, framesize);\n+  }\n+\n+  if (VerifyStackAtCalls) {\n+    Unimplemented();\n+  }\n+}\n+#endif \/\/ COMPILER2\n+\n+int MacroAssembler::store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter) {\n+  assert(InlineTypeReturnedAsFields, \"Inline types should never be returned as fields\");\n+  \/\/ An inline type might be returned. If fields are in registers we\n+  \/\/ need to allocate an inline type instance and initialize it with\n+  \/\/ the value of the fields.\n+  Label skip;\n+  \/\/ We only need a new buffered inline type if a new one is not returned\n+  tbz(r0, 0, skip);\n+  int call_offset = -1;\n+\n+  \/\/ Be careful not to clobber r1-7 which hold returned fields\n+  \/\/ Also do not use callee-saved registers as these may be live in the interpreter\n+  Register tmp1 = r13, tmp2 = r14, klass = r15, r0_preserved = r12;\n+\n+  \/\/ The following code is similar to allocate_instance but has some slight differences,\n+  \/\/ e.g. object size is always not zero, sometimes it's constant; storing klass ptr after\n+  \/\/ allocating is not necessary if vk != NULL, etc. allocate_instance is not aware of these.\n+  Label slow_case;\n+  \/\/ 1. Try to allocate a new buffered inline instance either from TLAB or eden space\n+  mov(r0_preserved, r0); \/\/ save r0 for slow_case since *_allocate may corrupt it when allocation failed\n+\n+  if (vk != NULL) {\n+    \/\/ Called from C1, where the return type is statically known.\n+    movptr(klass, (intptr_t)vk->get_InlineKlass());\n+    jint obj_size = vk->layout_helper();\n+    assert(obj_size != Klass::_lh_neutral_value, \"inline class in return type must have been resolved\");\n+    if (UseTLAB) {\n+      tlab_allocate(r0, noreg, obj_size, tmp1, tmp2, slow_case);\n+    } else {\n+      b(slow_case);\n+    }\n+  } else {\n+    \/\/ Call from interpreter. R0 contains ((the InlineKlass* of the return type) | 0x01)\n+    andr(klass, r0, -2);\n+    ldrw(tmp2, Address(klass, Klass::layout_helper_offset()));\n+    if (UseTLAB) {\n+      tlab_allocate(r0, tmp2, 0, tmp1, tmp2, slow_case);\n+    } else {\n+      b(slow_case);\n+    }\n+  }\n+  if (UseTLAB) {\n+    \/\/ 2. Initialize buffered inline instance header\n+    Register buffer_obj = r0;\n+    mov(rscratch1, (intptr_t)markWord::inline_type_prototype().value());\n+    str(rscratch1, Address(buffer_obj, oopDesc::mark_offset_in_bytes()));\n+    store_klass_gap(buffer_obj, zr);\n+    if (vk == NULL) {\n+      \/\/ store_klass corrupts klass, so save it for later use (interpreter case only).\n+      mov(tmp1, klass);\n+    }\n+    store_klass(buffer_obj, klass);\n+    \/\/ 3. Initialize its fields with an inline class specific handler\n+    if (vk != NULL) {\n+      far_call(RuntimeAddress(vk->pack_handler())); \/\/ no need for call info as this will not safepoint.\n+    } else {\n+      \/\/ tmp1 holds klass preserved above\n+      ldr(tmp1, Address(tmp1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      ldr(tmp1, Address(tmp1, InlineKlass::pack_handler_offset()));\n+      blr(tmp1);\n+    }\n+\n+    membar(Assembler::StoreStore);\n+    b(skip);\n+  } else {\n+    \/\/ Must have already branched to slow_case above.\n+    DEBUG_ONLY(should_not_reach_here());\n+  }\n+  bind(slow_case);\n+  \/\/ We failed to allocate a new inline type, fall back to a runtime\n+  \/\/ call. Some oop field may be live in some registers but we can't\n+  \/\/ tell. That runtime call will take care of preserving them\n+  \/\/ across a GC if there's one.\n+  mov(r0, r0_preserved);\n+\n+  if (from_interpreter) {\n+    super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());\n+  } else {\n+    far_call(RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));\n+    call_offset = offset();\n+  }\n+  membar(Assembler::StoreStore);\n+\n+  bind(skip);\n+  return call_offset;\n+}\n+\n+\/\/ Move a value between registers\/stack slots and update the reg_state\n+bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]) {\n+  assert(from->is_valid() && to->is_valid(), \"source and destination must be valid\");\n+  if (reg_state[to->value()] == reg_written) {\n+    return true; \/\/ Already written\n+  }\n+\n+  if (from != to && bt != T_VOID) {\n+    if (reg_state[to->value()] == reg_readonly) {\n+      return false; \/\/ Not yet writable\n+    }\n+    if (from->is_reg()) {\n+      if (to->is_reg()) {\n+        if (from->is_Register() && to->is_Register()) {\n+          mov(to->as_Register(), from->as_Register());\n+        } else if (from->is_FloatRegister() && to->is_FloatRegister()) {\n+          fmovd(to->as_FloatRegister(), from->as_FloatRegister());\n+        } else {\n+          ShouldNotReachHere();\n+        }\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size;\n+        Address to_addr = Address(sp, st_off);\n+        if (from->is_FloatRegister()) {\n+          if (bt == T_DOUBLE) {\n+             strd(from->as_FloatRegister(), to_addr);\n+          } else {\n+             assert(bt == T_FLOAT, \"must be float\");\n+             strs(from->as_FloatRegister(), to_addr);\n+          }\n+        } else {\n+          str(from->as_Register(), to_addr);\n+        }\n+      }\n+    } else {\n+      Address from_addr = Address(sp, from->reg2stack() * VMRegImpl::stack_slot_size);\n+      if (to->is_reg()) {\n+        if (to->is_FloatRegister()) {\n+          if (bt == T_DOUBLE) {\n+            ldrd(to->as_FloatRegister(), from_addr);\n+          } else {\n+            assert(bt == T_FLOAT, \"must be float\");\n+            ldrs(to->as_FloatRegister(), from_addr);\n+          }\n+        } else {\n+          ldr(to->as_Register(), from_addr);\n+        }\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size;\n+        ldr(rscratch1, from_addr);\n+        str(rscratch1, Address(sp, st_off));\n+      }\n+    }\n+  }\n+\n+  \/\/ Update register states\n+  reg_state[from->value()] = reg_writable;\n+  reg_state[to->value()] = reg_written;\n+  return true;\n+}\n+\n+\/\/ Calculate the extra stack space required for packing or unpacking inline\n+\/\/ args and adjust the stack pointer\n+int MacroAssembler::extend_stack_for_inline_args(int args_on_stack) {\n+  int sp_inc = args_on_stack * VMRegImpl::stack_slot_size;\n+  sp_inc = align_up(sp_inc, StackAlignmentInBytes);\n+  assert(sp_inc > 0, \"sanity\");\n+\n+  \/\/ Save a copy of the FP and LR here for deoptimization patching and frame walking\n+  stp(rfp, lr, Address(pre(sp, -2 * wordSize)));\n+\n+  \/\/ Adjust the stack pointer. This will be repaired on return by MacroAssembler::remove_frame\n+  if (sp_inc < (1 << 9)) {\n+    sub(sp, sp, sp_inc);   \/\/ Fits in an immediate\n+  } else {\n+    mov(rscratch1, sp_inc);\n+    sub(sp, sp, rscratch1);\n+  }\n+\n+  return sp_inc + 2 * wordSize;  \/\/ Account for the FP\/LR space\n+}\n+\n+\/\/ Read all fields from an inline type oop and store the values in registers\/stack slots\n+bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                                          VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                                          RegState reg_state[]) {\n+  assert(sig->at(sig_index)._bt == T_VOID, \"should be at end delimiter\");\n+  assert(from->is_valid(), \"source must be valid\");\n+  bool progress = false;\n+#ifdef ASSERT\n+  const int start_offset = offset();\n+#endif\n+\n+  Label L_null, L_notNull;\n+  \/\/ Don't use r14 as tmp because it's used for spilling (see MacroAssembler::spill_reg_for)\n+  Register tmp1 = r10;\n+  Register tmp2 = r11;\n+  Register fromReg = noreg;\n+  ScalarizedInlineArgsStream stream(sig, sig_index, to, to_count, to_index, -1);\n+  bool done = true;\n+  bool mark_done = true;\n+  VMReg toReg;\n+  BasicType bt;\n+  \/\/ Check if argument requires a null check\n+  bool null_check = false;\n+  VMReg nullCheckReg;\n+  while (stream.next(nullCheckReg, bt)) {\n+    if (sig->at(stream.sig_index())._offset == -1) {\n+      null_check = true;\n+      break;\n+    }\n+  }\n+  stream.reset(sig_index, to_index);\n+  while (stream.next(toReg, bt)) {\n+    assert(toReg->is_valid(), \"destination must be valid\");\n+    int idx = (int)toReg->value();\n+    if (reg_state[idx] == reg_readonly) {\n+      if (idx != from->value()) {\n+        mark_done = false;\n+      }\n+      done = false;\n+      continue;\n+    } else if (reg_state[idx] == reg_written) {\n+      continue;\n+    }\n+    assert(reg_state[idx] == reg_writable, \"must be writable\");\n+    reg_state[idx] = reg_written;\n+    progress = true;\n+\n+    if (fromReg == noreg) {\n+      if (from->is_reg()) {\n+        fromReg = from->as_Register();\n+      } else {\n+        int st_off = from->reg2stack() * VMRegImpl::stack_slot_size;\n+        ldr(tmp1, Address(sp, st_off));\n+        fromReg = tmp1;\n+      }\n+      if (null_check) {\n+        \/\/ Nullable inline type argument, emit null check\n+        cbz(fromReg, L_null);\n+      }\n+    }\n+    int off = sig->at(stream.sig_index())._offset;\n+    if (off == -1) {\n+      assert(null_check, \"Missing null check at\");\n+      if (toReg->is_stack()) {\n+        int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size;\n+        mov(tmp2, 1);\n+        str(tmp2, Address(sp, st_off));\n+      } else {\n+        mov(toReg->as_Register(), 1);\n+      }\n+      continue;\n+    }\n+    assert(off > 0, \"offset in object should be positive\");\n+    Address fromAddr = Address(fromReg, off);\n+    if (!toReg->is_FloatRegister()) {\n+      Register dst = toReg->is_stack() ? tmp2 : toReg->as_Register();\n+      if (is_reference_type(bt)) {\n+        load_heap_oop(dst, fromAddr);\n+      } else {\n+        bool is_signed = (bt != T_CHAR) && (bt != T_BOOLEAN);\n+        load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);\n+      }\n+      if (toReg->is_stack()) {\n+        int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size;\n+        str(dst, Address(sp, st_off));\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      ldrd(toReg->as_FloatRegister(), fromAddr);\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      ldrs(toReg->as_FloatRegister(), fromAddr);\n+    }\n+  }\n+  if (progress && null_check) {\n+    if (done) {\n+      b(L_notNull);\n+      bind(L_null);\n+      \/\/ Set IsInit field to zero to signal that the argument is null.\n+      \/\/ Also set all oop fields to zero to make the GC happy.\n+      stream.reset(sig_index, to_index);\n+      while (stream.next(toReg, bt)) {\n+        if (sig->at(stream.sig_index())._offset == -1 ||\n+            bt == T_OBJECT || bt == T_ARRAY) {\n+          if (toReg->is_stack()) {\n+            int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size;\n+            str(zr, Address(sp, st_off));\n+          } else {\n+            mov(toReg->as_Register(), zr);\n+          }\n+        }\n+      }\n+      bind(L_notNull);\n+    } else {\n+      bind(L_null);\n+    }\n+  }\n+\n+  sig_index = stream.sig_index();\n+  to_index = stream.regs_index();\n+\n+  if (mark_done && reg_state[from->value()] != reg_written) {\n+    \/\/ This is okay because no one else will write to that slot\n+    reg_state[from->value()] = reg_writable;\n+  }\n+  from_index--;\n+  assert(progress || (start_offset == offset()), \"should not emit code\");\n+  return done;\n+}\n+\n+\/\/ Pack fields back into an inline type oop\n+bool MacroAssembler::pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                                        VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                                        RegState reg_state[], Register val_array) {\n+  assert(sig->at(sig_index)._bt == T_PRIMITIVE_OBJECT, \"should be at end delimiter\");\n+  assert(to->is_valid(), \"destination must be valid\");\n+\n+  if (reg_state[to->value()] == reg_written) {\n+    skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n+    return true; \/\/ Already written\n+  }\n+\n+  \/\/ The GC barrier expanded by store_heap_oop below may call into the\n+  \/\/ runtime so use callee-saved registers for any values that need to be\n+  \/\/ preserved. The GC barrier assembler should take care of saving the\n+  \/\/ Java argument registers.\n+  \/\/ TODO 8284443 Isn't it an issue if below code uses r14 as tmp when it contains a spilled value?\n+  \/\/ Be careful with r14 because it's used for spilling (see MacroAssembler::spill_reg_for).\n+  Register val_obj_tmp = r21;\n+  Register from_reg_tmp = r22;\n+  Register tmp1 = r14;\n+  Register tmp2 = r13;\n+  Register tmp3 = r12;\n+  Register val_obj = to->is_stack() ? val_obj_tmp : to->as_Register();\n+\n+  assert_different_registers(val_obj_tmp, from_reg_tmp, tmp1, tmp2, tmp3, val_array);\n+\n+  if (reg_state[to->value()] == reg_readonly) {\n+    if (!is_reg_in_unpacked_fields(sig, sig_index, to, from, from_count, from_index)) {\n+      skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n+      return false; \/\/ Not yet writable\n+    }\n+    val_obj = val_obj_tmp;\n+  }\n+\n+  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_PRIMITIVE_OBJECT);\n+  load_heap_oop(val_obj, Address(val_array, index));\n+\n+  ScalarizedInlineArgsStream stream(sig, sig_index, from, from_count, from_index);\n+  VMReg fromReg;\n+  BasicType bt;\n+  Label L_null;\n+  while (stream.next(fromReg, bt)) {\n+    assert(fromReg->is_valid(), \"source must be valid\");\n+    reg_state[fromReg->value()] = reg_writable;\n+\n+    int off = sig->at(stream.sig_index())._offset;\n+    if (off == -1) {\n+      \/\/ Nullable inline type argument, emit null check\n+      Label L_notNull;\n+      if (fromReg->is_stack()) {\n+        int ld_off = fromReg->reg2stack() * VMRegImpl::stack_slot_size;\n+        ldr(tmp2, Address(sp, ld_off));\n+        cbnz(tmp2, L_notNull);\n+      } else {\n+        cbnz(fromReg->as_Register(), L_notNull);\n+      }\n+      mov(val_obj, 0);\n+      b(L_null);\n+      bind(L_notNull);\n+      continue;\n+    }\n+\n+    assert(off > 0, \"offset in object should be positive\");\n+    size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;\n+\n+    \/\/ Pack the scalarized field into the value object.\n+    Address dst(val_obj, off);\n+\n+    if (!fromReg->is_FloatRegister()) {\n+      Register src;\n+      if (fromReg->is_stack()) {\n+        src = from_reg_tmp;\n+        int ld_off = fromReg->reg2stack() * VMRegImpl::stack_slot_size;\n+        load_sized_value(src, Address(sp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+      } else {\n+        src = fromReg->as_Register();\n+      }\n+      assert_different_registers(dst.base(), src, tmp1, tmp2, tmp3, val_array);\n+      if (is_reference_type(bt)) {\n+        store_heap_oop(dst, src, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      } else {\n+        store_sized_value(dst, src, size_in_bytes);\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      strd(fromReg->as_FloatRegister(), dst);\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      strs(fromReg->as_FloatRegister(), dst);\n+    }\n+  }\n+  bind(L_null);\n+  sig_index = stream.sig_index();\n+  from_index = stream.regs_index();\n+\n+  assert(reg_state[to->value()] == reg_writable, \"must have already been read\");\n+  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state);\n+  assert(success, \"to register must be writeable\");\n+\n+  return true;\n+}\n+\n+VMReg MacroAssembler::spill_reg_for(VMReg reg) {\n+  return (reg->is_FloatRegister()) ? v0->as_VMReg() : r14->as_VMReg();\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":810,"deletions":2,"binary":false,"changes":812,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"classfile\/symbolTable.hpp\"\n@@ -350,0 +351,1 @@\n+    case T_PRIMITIVE_OBJECT:\n@@ -383,0 +385,80 @@\n+\n+const uint SharedRuntime::java_return_convention_max_int = Argument::n_int_register_parameters_j;\n+const uint SharedRuntime::java_return_convention_max_float = Argument::n_float_register_parameters_j;\n+\n+int SharedRuntime::java_return_convention(const BasicType *sig_bt, VMRegPair *regs, int total_args_passed) {\n+\n+  \/\/ Create the mapping between argument positions and registers.\n+\n+  static const Register INT_ArgReg[java_return_convention_max_int] = {\n+    r0 \/* j_rarg7 *\/, j_rarg6, j_rarg5, j_rarg4, j_rarg3, j_rarg2, j_rarg1, j_rarg0\n+  };\n+\n+  static const FloatRegister FP_ArgReg[java_return_convention_max_float] = {\n+    j_farg0, j_farg1, j_farg2, j_farg3, j_farg4, j_farg5, j_farg6, j_farg7\n+  };\n+\n+  uint int_args = 0;\n+  uint fp_args = 0;\n+\n+  for (int i = 0; i < total_args_passed; i++) {\n+    switch (sig_bt[i]) {\n+    case T_BOOLEAN:\n+    case T_CHAR:\n+    case T_BYTE:\n+    case T_SHORT:\n+    case T_INT:\n+      if (int_args < SharedRuntime::java_return_convention_max_int) {\n+        regs[i].set1(INT_ArgReg[int_args]->as_VMReg());\n+        int_args ++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_VOID:\n+      \/\/ halves of T_LONG or T_DOUBLE\n+      assert(i != 0 && (sig_bt[i - 1] == T_LONG || sig_bt[i - 1] == T_DOUBLE), \"expecting half\");\n+      regs[i].set_bad();\n+      break;\n+    case T_LONG:\n+      assert((i + 1) < total_args_passed && sig_bt[i + 1] == T_VOID, \"expecting half\");\n+      \/\/ fall through\n+    case T_OBJECT:\n+    case T_ARRAY:\n+    case T_ADDRESS:\n+      \/\/ Should T_METADATA be added to java_calling_convention as well ?\n+    case T_METADATA:\n+    case T_PRIMITIVE_OBJECT:\n+      if (int_args < SharedRuntime::java_return_convention_max_int) {\n+        regs[i].set2(INT_ArgReg[int_args]->as_VMReg());\n+        int_args ++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_FLOAT:\n+      if (fp_args < SharedRuntime::java_return_convention_max_float) {\n+        regs[i].set1(FP_ArgReg[fp_args]->as_VMReg());\n+        fp_args ++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_DOUBLE:\n+      assert((i + 1) < total_args_passed && sig_bt[i + 1] == T_VOID, \"expecting half\");\n+      if (fp_args < SharedRuntime::java_return_convention_max_float) {\n+        regs[i].set2(FP_ArgReg[fp_args]->as_VMReg());\n+        fp_args ++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+      break;\n+    }\n+  }\n+\n+  return int_args + fp_args;\n+}\n+\n@@ -417,0 +499,109 @@\n+\/\/ For each inline type argument, sig includes the list of fields of\n+\/\/ the inline type. This utility function computes the number of\n+\/\/ arguments for the call if inline types are passed by reference (the\n+\/\/ calling convention the interpreter expects).\n+static int compute_total_args_passed_int(const GrowableArray<SigEntry>* sig_extended) {\n+  int total_args_passed = 0;\n+  if (InlineTypePassFieldsAsArgs) {\n+     for (int i = 0; i < sig_extended->length(); i++) {\n+       BasicType bt = sig_extended->at(i)._bt;\n+       if (bt == T_PRIMITIVE_OBJECT) {\n+         \/\/ In sig_extended, an inline type argument starts with:\n+         \/\/ T_PRIMITIVE_OBJECT, followed by the types of the fields of the\n+         \/\/ inline type and T_VOID to mark the end of the value\n+         \/\/ type. Inline types are flattened so, for instance, in the\n+         \/\/ case of an inline type with an int field and an inline type\n+         \/\/ field that itself has 2 fields, an int and a long:\n+         \/\/ T_PRIMITIVE_OBJECT T_INT T_PRIMITIVE_OBJECT T_INT T_LONG T_VOID (second\n+         \/\/ slot for the T_LONG) T_VOID (inner T_PRIMITIVE_OBJECT) T_VOID\n+         \/\/ (outer T_PRIMITIVE_OBJECT)\n+         total_args_passed++;\n+         int vt = 1;\n+         do {\n+           i++;\n+           BasicType bt = sig_extended->at(i)._bt;\n+           BasicType prev_bt = sig_extended->at(i-1)._bt;\n+           if (bt == T_PRIMITIVE_OBJECT) {\n+             vt++;\n+           } else if (bt == T_VOID &&\n+                      prev_bt != T_LONG &&\n+                      prev_bt != T_DOUBLE) {\n+             vt--;\n+           }\n+         } while (vt != 0);\n+       } else {\n+         total_args_passed++;\n+       }\n+     }\n+  } else {\n+    total_args_passed = sig_extended->length();\n+  }\n+\n+  return total_args_passed;\n+}\n+\n+\n+static void gen_c2i_adapter_helper(MacroAssembler* masm,\n+                                   BasicType bt,\n+                                   BasicType prev_bt,\n+                                   size_t size_in_bytes,\n+                                   const VMRegPair& reg_pair,\n+                                   const Address& to,\n+                                   Register tmp1,\n+                                   Register tmp2,\n+                                   Register tmp3,\n+                                   int extraspace,\n+                                   bool is_oop) {\n+  assert(bt != T_PRIMITIVE_OBJECT || !InlineTypePassFieldsAsArgs, \"no inline type here\");\n+  if (bt == T_VOID) {\n+    assert(prev_bt == T_LONG || prev_bt == T_DOUBLE, \"missing half\");\n+    return;\n+  }\n+\n+  \/\/ Say 4 args:\n+  \/\/ i   st_off\n+  \/\/ 0   32 T_LONG\n+  \/\/ 1   24 T_VOID\n+  \/\/ 2   16 T_OBJECT\n+  \/\/ 3    8 T_BOOL\n+  \/\/ -    0 return address\n+  \/\/\n+  \/\/ However to make thing extra confusing. Because we can fit a Java long\/double in\n+  \/\/ a single slot on a 64 bt vm and it would be silly to break them up, the interpreter\n+  \/\/ leaves one slot empty and only stores to a single slot. In this case the\n+  \/\/ slot that is occupied is the T_VOID slot. See I said it was confusing.\n+\n+  bool wide = (size_in_bytes == wordSize);\n+  VMReg r_1 = reg_pair.first();\n+  VMReg r_2 = reg_pair.second();\n+  assert(r_2->is_valid() == wide, \"invalid size\");\n+  if (!r_1->is_valid()) {\n+    assert(!r_2->is_valid(), \"\");\n+    return;\n+  }\n+\n+  if (!r_1->is_FloatRegister()) {\n+    Register val = r25;\n+    if (r_1->is_stack()) {\n+      \/\/ memory to memory use r25 (scratch registers is used by store_heap_oop)\n+      int ld_off = r_1->reg2stack() * VMRegImpl::stack_slot_size + extraspace;\n+      __ load_sized_value(val, Address(sp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+    } else {\n+      val = r_1->as_Register();\n+    }\n+    assert_different_registers(to.base(), val, tmp1, tmp2, tmp3);\n+    if (is_oop) {\n+      __ store_heap_oop(to, val, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+    } else {\n+      __ store_sized_value(to, val, size_in_bytes);\n+    }\n+  } else {\n+    if (wide) {\n+      __ strd(r_1->as_FloatRegister(), to);\n+    } else {\n+      \/\/ only a float use just part of the slot\n+      __ strs(r_1->as_FloatRegister(), to);\n+    }\n+  }\n+}\n+\n@@ -418,3 +609,1 @@\n-                            int total_args_passed,\n-                            int comp_args_on_stack,\n-                            const BasicType *sig_bt,\n+                            const GrowableArray<SigEntry>* sig_extended,\n@@ -422,1 +611,7 @@\n-                            Label& skip_fixup) {\n+                            Label& skip_fixup,\n+                            address start,\n+                            OopMapSet* oop_maps,\n+                            int& frame_complete,\n+                            int& frame_size_in_words,\n+                            bool alloc_inline_receiver) {\n+\n@@ -432,1 +627,22 @@\n-  int words_pushed = 0;\n+  \/\/ Name some registers to be used in the following code. We can use\n+  \/\/ anything except r0-r7 which are arguments in the Java calling\n+  \/\/ convention, rmethod (r12), and r13 which holds the outgoing sender\n+  \/\/ SP for the interpreter.\n+  Register buf_array = r10;   \/\/ Array of buffered inline types\n+  Register buf_oop = r11;     \/\/ Buffered inline type oop\n+  Register tmp1 = r15;\n+  Register tmp2 = r16;\n+  Register tmp3 = r17;\n+\n+  if (InlineTypePassFieldsAsArgs) {\n+    \/\/ Is there an inline type argument?\n+    bool has_inline_argument = false;\n+    for (int i = 0; i < sig_extended->length() && !has_inline_argument; i++) {\n+      has_inline_argument = (sig_extended->at(i)._bt == T_PRIMITIVE_OBJECT);\n+    }\n+    if (has_inline_argument) {\n+      \/\/ There is at least an inline type argument: we're coming from\n+      \/\/ compiled code so we have no buffers to back the inline types\n+      \/\/ Allocate the buffers here with a runtime call.\n+      RegisterSaver reg_save(false \/* save_vectors *\/);\n+      OopMap* map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -434,2 +650,2 @@\n-  \/\/ Since all args are passed on the stack, total_args_passed *\n-  \/\/ Interpreter::stackElementSize is the space we need.\n+      frame_complete = __ offset();\n+      address the_pc = __ pc();\n@@ -437,1 +653,2 @@\n-  int extraspace = total_args_passed * Interpreter::stackElementSize;\n+      Label retaddr;\n+      __ set_last_Java_frame(sp, noreg, retaddr, rscratch1);\n@@ -439,1 +656,3 @@\n-  __ mov(r19_sender_sp, sp);\n+      __ mov(c_rarg0, rthread);\n+      __ mov(c_rarg1, rmethod);\n+      __ mov(c_rarg2, (int64_t)alloc_inline_receiver);\n@@ -441,2 +660,3 @@\n-  \/\/ stack is aligned, keep it that way\n-  extraspace = align_up(extraspace, 2*wordSize);\n+      __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::allocate_inline_types)));\n+      __ blr(rscratch1);\n+      __ bind(retaddr);\n@@ -444,2 +664,2 @@\n-  if (extraspace)\n-    __ sub(sp, sp, extraspace);\n+      oop_maps->add_gc_map(__ pc() - start, map);\n+      __ reset_last_Java_frame(false);\n@@ -447,6 +667,1 @@\n-  \/\/ Now write the args into the outgoing interpreter space\n-  for (int i = 0; i < total_args_passed; i++) {\n-    if (sig_bt[i] == T_VOID) {\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n-      continue;\n-    }\n+      reg_save.restore_live_registers(masm);\n@@ -454,16 +669,3 @@\n-    \/\/ offset to start parameters\n-    int st_off   = (total_args_passed - i - 1) * Interpreter::stackElementSize;\n-    int next_off = st_off - Interpreter::stackElementSize;\n-\n-    \/\/ Say 4 args:\n-    \/\/ i   st_off\n-    \/\/ 0   32 T_LONG\n-    \/\/ 1   24 T_VOID\n-    \/\/ 2   16 T_OBJECT\n-    \/\/ 3    8 T_BOOL\n-    \/\/ -    0 return address\n-    \/\/\n-    \/\/ However to make thing extra confusing. Because we can fit a Java long\/double in\n-    \/\/ a single slot on a 64 bt vm and it would be silly to break them up, the interpreter\n-    \/\/ leaves one slot empty and only stores to a single slot. In this case the\n-    \/\/ slot that is occupied is the T_VOID slot. See I said it was confusing.\n+      Label no_exception;\n+      __ ldr(rscratch1, Address(rthread, Thread::pending_exception_offset()));\n+      __ cbz(rscratch1, no_exception);\n@@ -471,5 +673,9 @@\n-    VMReg r_1 = regs[i].first();\n-    VMReg r_2 = regs[i].second();\n-    if (!r_1->is_valid()) {\n-      assert(!r_2->is_valid(), \"\");\n-      continue;\n+      __ str(zr, Address(rthread, JavaThread::vm_result_offset()));\n+      __ ldr(r0, Address(rthread, Thread::pending_exception_offset()));\n+      __ b(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+      __ bind(no_exception);\n+\n+      \/\/ We get an array of objects from the runtime call\n+      __ get_vm_result(buf_array, rthread);\n+      __ get_vm_result_2(rmethod, rthread); \/\/ TODO: required to keep the callee Method live?\n@@ -477,9 +683,1 @@\n-    if (r_1->is_stack()) {\n-      \/\/ memory to memory use rscratch1\n-      int ld_off = (r_1->reg2stack() * VMRegImpl::stack_slot_size\n-                    + extraspace\n-                    + words_pushed * wordSize);\n-      if (!r_2->is_valid()) {\n-        \/\/ sign extend??\n-        __ ldrw(rscratch1, Address(sp, ld_off));\n-        __ str(rscratch1, Address(sp, st_off));\n+  }\n@@ -487,1 +685,11 @@\n-      } else {\n+  \/\/ Since all args are passed on the stack, total_args_passed *\n+  \/\/ Interpreter::stackElementSize is the space we need.\n+\n+  int total_args_passed = compute_total_args_passed_int(sig_extended);\n+  int extraspace = total_args_passed * Interpreter::stackElementSize;\n+\n+  \/\/ stack is aligned, keep it that way\n+  extraspace = align_up(extraspace, StackAlignmentInBytes);\n+\n+  \/\/ set senderSP value\n+  __ mov(r19_sender_sp, sp);\n@@ -489,1 +697,1 @@\n-        __ ldr(rscratch1, Address(sp, ld_off));\n+  __ sub(sp, sp, extraspace);\n@@ -491,6 +699,26 @@\n-        \/\/ Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG\n-        \/\/ T_DOUBLE and T_LONG use two slots in the interpreter\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n-          \/\/ ld_off == LSW, ld_off+wordSize == MSW\n-          \/\/ st_off == MSW, next_off == LSW\n-          __ str(rscratch1, Address(sp, next_off));\n+  \/\/ Now write the args into the outgoing interpreter space\n+\n+  \/\/ next_arg_comp is the next argument from the compiler point of\n+  \/\/ view (inline type fields are passed in registers\/on the stack). In\n+  \/\/ sig_extended, an inline type argument starts with: T_PRIMITIVE_OBJECT,\n+  \/\/ followed by the types of the fields of the inline type and T_VOID\n+  \/\/ to mark the end of the inline type. ignored counts the number of\n+  \/\/ T_PRIMITIVE_OBJECT\/T_VOID. next_vt_arg is the next inline type argument:\n+  \/\/ used to get the buffer for that argument from the pool of buffers\n+  \/\/ we allocated above and want to pass to the\n+  \/\/ interpreter. next_arg_int is the next argument from the\n+  \/\/ interpreter point of view (inline types are passed by reference).\n+  for (int next_arg_comp = 0, ignored = 0, next_vt_arg = 0, next_arg_int = 0;\n+       next_arg_comp < sig_extended->length(); next_arg_comp++) {\n+    assert(ignored <= next_arg_comp, \"shouldn't skip over more slots than there are arguments\");\n+    assert(next_arg_int <= total_args_passed, \"more arguments for the interpreter than expected?\");\n+    BasicType bt = sig_extended->at(next_arg_comp)._bt;\n+    int st_off = (total_args_passed - next_arg_int - 1) * Interpreter::stackElementSize;\n+    if (!InlineTypePassFieldsAsArgs || bt != T_PRIMITIVE_OBJECT) {\n+      int next_off = st_off - Interpreter::stackElementSize;\n+      const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : st_off;\n+      const VMRegPair reg_pair = regs[next_arg_comp-ignored];\n+      size_t size_in_bytes = reg_pair.second()->is_valid() ? 8 : 4;\n+      gen_c2i_adapter_helper(masm, bt, next_arg_comp > 0 ? sig_extended->at(next_arg_comp-1)._bt : T_ILLEGAL,\n+                             size_in_bytes, reg_pair, Address(sp, offset), tmp1, tmp2, tmp3, extraspace, false);\n+      next_arg_int++;\n@@ -498,7 +726,4 @@\n-          \/\/ Overwrite the unused slot with known junk\n-          __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaaaull);\n-          __ str(rscratch1, Address(sp, st_off));\n-#endif \/* ASSERT *\/\n-        } else {\n-          __ str(rscratch1, Address(sp, st_off));\n-        }\n+      if (bt == T_LONG || bt == T_DOUBLE) {\n+        \/\/ Overwrite the unused slot with known junk\n+        __ mov(rscratch1, CONST64(0xdeadffffdeadaaaa));\n+        __ str(rscratch1, Address(sp, st_off));\n@@ -506,16 +731,24 @@\n-    } else if (r_1->is_Register()) {\n-      Register r = r_1->as_Register();\n-      if (!r_2->is_valid()) {\n-        \/\/ must be only an int (or less ) so move only 32bits to slot\n-        \/\/ why not sign extend??\n-        __ str(r, Address(sp, st_off));\n-      } else {\n-        \/\/ Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG\n-        \/\/ T_DOUBLE and T_LONG use two slots in the interpreter\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n-          \/\/ jlong\/double in gpr\n-#ifdef ASSERT\n-          \/\/ Overwrite the unused slot with known junk\n-          __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaabull);\n-          __ str(rscratch1, Address(sp, st_off));\n-          __ str(r, Address(sp, next_off));\n+    } else {\n+      ignored++;\n+      \/\/ get the buffer from the just allocated pool of buffers\n+      int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_PRIMITIVE_OBJECT);\n+      __ load_heap_oop(buf_oop, Address(buf_array, index));\n+      next_vt_arg++; next_arg_int++;\n+      int vt = 1;\n+      \/\/ write fields we get from compiled code in registers\/stack\n+      \/\/ slots to the buffer: we know we are done with that inline type\n+      \/\/ argument when we hit the T_VOID that acts as an end of inline\n+      \/\/ type delimiter for this inline type. Inline types are flattened\n+      \/\/ so we might encounter embedded inline types. Each entry in\n+      \/\/ sig_extended contains a field offset in the buffer.\n+      Label L_null;\n+      do {\n+        next_arg_comp++;\n+        BasicType bt = sig_extended->at(next_arg_comp)._bt;\n+        BasicType prev_bt = sig_extended->at(next_arg_comp - 1)._bt;\n+        if (bt == T_PRIMITIVE_OBJECT) {\n+          vt++;\n+          ignored++;\n+        } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+          vt--;\n+          ignored++;\n@@ -524,1 +757,22 @@\n-          __ str(r, Address(sp, st_off));\n+          int off = sig_extended->at(next_arg_comp)._offset;\n+          if (off == -1) {\n+            \/\/ Nullable inline type argument, emit null check\n+            VMReg reg = regs[next_arg_comp-ignored].first();\n+            Label L_notNull;\n+            if (reg->is_stack()) {\n+              int ld_off = reg->reg2stack() * VMRegImpl::stack_slot_size + extraspace;\n+              __ ldr(tmp1, Address(sp, ld_off));\n+              __ cbnz(tmp1, L_notNull);\n+            } else {\n+              __ cbnz(reg->as_Register(), L_notNull);\n+            }\n+            __ str(zr, Address(sp, st_off));\n+            __ b(L_null);\n+            __ bind(L_notNull);\n+            continue;\n+          }\n+          assert(off > 0, \"offset in object should be positive\");\n+          size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;\n+          bool is_oop = is_reference_type(bt);\n+          gen_c2i_adapter_helper(masm, bt, next_arg_comp > 0 ? sig_extended->at(next_arg_comp-1)._bt : T_ILLEGAL,\n+                                 size_in_bytes, regs[next_arg_comp-ignored], Address(buf_oop, off), tmp1, tmp2, tmp3, extraspace, is_oop);\n@@ -526,14 +780,4 @@\n-      }\n-    } else {\n-      assert(r_1->is_FloatRegister(), \"\");\n-      if (!r_2->is_valid()) {\n-        \/\/ only a float use just part of the slot\n-        __ strs(r_1->as_FloatRegister(), Address(sp, st_off));\n-      } else {\n-#ifdef ASSERT\n-        \/\/ Overwrite the unused slot with known junk\n-        __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaacull);\n-        __ str(rscratch1, Address(sp, st_off));\n-#endif \/* ASSERT *\/\n-        __ strd(r_1->as_FloatRegister(), Address(sp, next_off));\n-      }\n+      } while (vt != 0);\n+      \/\/ pass the buffer to the interpreter\n+      __ str(buf_oop, Address(sp, st_off));\n+      __ bind(L_null);\n@@ -549,0 +793,1 @@\n+void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm, int comp_args_on_stack, const GrowableArray<SigEntry>* sig, const VMRegPair *regs) {\n@@ -550,5 +795,0 @@\n-void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm,\n-                                    int total_args_passed,\n-                                    int comp_args_on_stack,\n-                                    const BasicType *sig_bt,\n-                                    const VMRegPair *regs) {\n@@ -612,1 +852,1 @@\n-  int comp_words_on_stack = align_up(comp_args_on_stack*VMRegImpl::stack_slot_size, wordSize)>>LogBytesPerWord;\n+  int comp_words_on_stack = 0;\n@@ -614,2 +854,3 @@\n-    __ sub(rscratch1, sp, comp_words_on_stack * wordSize);\n-    __ andr(sp, rscratch1, -16);\n+     comp_words_on_stack = align_up(comp_args_on_stack * VMRegImpl::stack_slot_size, wordSize) >> LogBytesPerWord;\n+     __ sub(rscratch1, sp, comp_words_on_stack * wordSize);\n+     __ andr(sp, rscratch1, -16);\n@@ -620,1 +861,1 @@\n-  __ ldr(rscratch1, Address(rmethod, in_bytes(Method::from_compiled_offset())));\n+  __ ldr(rscratch1, Address(rmethod, in_bytes(Method::from_compiled_inline_offset())));\n@@ -634,0 +875,2 @@\n+  int total_args_passed = sig->length();\n+\n@@ -636,2 +879,5 @@\n-    if (sig_bt[i] == T_VOID) {\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n+    BasicType bt = sig->at(i)._bt;\n+\n+    assert(bt != T_PRIMITIVE_OBJECT, \"i2c adapter doesn't unpack inline typ args\");\n+    if (bt == T_VOID) {\n+      assert(i > 0 && (sig->at(i - 1)._bt == T_LONG || sig->at(i - 1)._bt == T_DOUBLE), \"missing half\");\n@@ -642,0 +888,1 @@\n+    assert(!regs[i].second()->is_valid() || regs[i].first()->next() == regs[i].second(), \"scrambled load targets?\");\n@@ -643,3 +890,1 @@\n-    assert(!regs[i].second()->is_valid() || regs[i].first()->next() == regs[i].second(),\n-            \"scrambled load targets?\");\n-    int ld_off = (total_args_passed - i - 1)*Interpreter::stackElementSize;\n+    int ld_off = (total_args_passed - i - 1) * Interpreter::stackElementSize;\n@@ -660,1 +905,1 @@\n-      int st_off = regs[i].first()->reg2stack()*VMRegImpl::stack_slot_size;\n+      int st_off = regs[i].first()->reg2stack() * VMRegImpl::stack_slot_size;\n@@ -677,2 +922,1 @@\n-        const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n-                           next_off : ld_off;\n+        const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : ld_off;\n@@ -681,14 +925,28 @@\n-        __ str(rscratch2, Address(sp, st_off));\n-      }\n-    } else if (r_1->is_Register()) {  \/\/ Register argument\n-      Register r = r_1->as_Register();\n-      if (r_2->is_valid()) {\n-        \/\/\n-        \/\/ We are using two VMRegs. This can be either T_OBJECT,\n-        \/\/ T_ADDRESS, T_LONG, or T_DOUBLE the interpreter allocates\n-        \/\/ two slots but only uses one for thr T_LONG or T_DOUBLE case\n-        \/\/ So we must adjust where to pick up the data to match the\n-        \/\/ interpreter.\n-\n-        const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n-                           next_off : ld_off;\n+         __ str(rscratch2, Address(sp, st_off));\n+       }\n+     } else if (r_1->is_Register()) {  \/\/ Register argument\n+       Register r = r_1->as_Register();\n+       if (r_2->is_valid()) {\n+         \/\/\n+         \/\/ We are using two VMRegs. This can be either T_OBJECT,\n+         \/\/ T_ADDRESS, T_LONG, or T_DOUBLE the interpreter allocates\n+         \/\/ two slots but only uses one for thr T_LONG or T_DOUBLE case\n+         \/\/ So we must adjust where to pick up the data to match the\n+         \/\/ interpreter.\n+\n+        const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : ld_off;\n+\n+         \/\/ this can be a misaligned move\n+         __ ldr(r, Address(esp, offset));\n+       } else {\n+         \/\/ sign extend and use a full word?\n+         __ ldrw(r, Address(esp, ld_off));\n+       }\n+     } else {\n+       if (!r_2->is_valid()) {\n+         __ ldrs(r_1->as_FloatRegister(), Address(esp, ld_off));\n+       } else {\n+         __ ldrd(r_1->as_FloatRegister(), Address(esp, next_off));\n+       }\n+     }\n+   }\n@@ -696,14 +954,0 @@\n-        \/\/ this can be a misaligned move\n-        __ ldr(r, Address(esp, offset));\n-      } else {\n-        \/\/ sign extend and use a full word?\n-        __ ldrw(r, Address(esp, ld_off));\n-      }\n-    } else {\n-      if (!r_2->is_valid()) {\n-        __ ldrs(r_1->as_FloatRegister(), Address(esp, ld_off));\n-      } else {\n-        __ ldrd(r_1->as_FloatRegister(), Address(esp, next_off));\n-      }\n-    }\n-  }\n@@ -726,1 +970,0 @@\n-\n@@ -730,13 +973,1 @@\n-\/\/ ---------------------------------------------------------------\n-AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler *masm,\n-                                                            int total_args_passed,\n-                                                            int comp_args_on_stack,\n-                                                            const BasicType *sig_bt,\n-                                                            const VMRegPair *regs,\n-                                                            AdapterFingerPrint* fingerprint) {\n-  address i2c_entry = __ pc();\n-\n-  gen_i2c_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs);\n-\n-  address c2i_unverified_entry = __ pc();\n-  Label skip_fixup;\n+static void gen_inline_cache_check(MacroAssembler *masm, Label& skip_fixup) {\n@@ -777,0 +1008,2 @@\n+}\n+\n@@ -778,0 +1011,33 @@\n+\/\/ ---------------------------------------------------------------\n+AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler* masm,\n+                                                            int comp_args_on_stack,\n+                                                            const GrowableArray<SigEntry>* sig,\n+                                                            const VMRegPair* regs,\n+                                                            const GrowableArray<SigEntry>* sig_cc,\n+                                                            const VMRegPair* regs_cc,\n+                                                            const GrowableArray<SigEntry>* sig_cc_ro,\n+                                                            const VMRegPair* regs_cc_ro,\n+                                                            AdapterFingerPrint* fingerprint,\n+                                                            AdapterBlob*& new_adapter,\n+                                                            bool allocate_code_blob) {\n+\n+  address i2c_entry = __ pc();\n+  gen_i2c_adapter(masm, comp_args_on_stack, sig, regs);\n+\n+  address c2i_unverified_entry = __ pc();\n+  Label skip_fixup;\n+\n+  gen_inline_cache_check(masm, skip_fixup);\n+\n+  OopMapSet* oop_maps = new OopMapSet();\n+  int frame_complete = CodeOffsets::frame_never_safe;\n+  int frame_size_in_words = 0;\n+\n+  \/\/ Scalarized c2i adapter with non-scalarized receiver (i.e., don't pack receiver)\n+  address c2i_inline_ro_entry = __ pc();\n+  if (regs_cc != regs_cc_ro) {\n+    gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);\n+    skip_fixup.reset();\n+  }\n+\n+  \/\/ Scalarized c2i adapter\n@@ -802,1 +1068,14 @@\n-  gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);\n+  gen_c2i_adapter(masm, sig_cc, regs_cc, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, true);\n+\n+  address c2i_unverified_inline_entry = c2i_unverified_entry;\n+\n+  \/\/ Non-scalarized c2i adapter\n+  address c2i_inline_entry = c2i_entry;\n+  if (regs != regs_cc) {\n+    Label inline_entry_skip_fixup;\n+    c2i_unverified_inline_entry = __ pc();\n+    gen_inline_cache_check(masm, inline_entry_skip_fixup);\n+\n+    c2i_inline_entry = __ pc();\n+    gen_c2i_adapter(masm, sig, regs, inline_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);\n+  }\n@@ -805,1 +1084,9 @@\n-  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+\n+  \/\/ The c2i adapter might safepoint and trigger a GC. The caller must make sure that\n+  \/\/ the GC knows about the location of oop argument locations passed to the c2i adapter.\n+  if (allocate_code_blob) {\n+    bool caller_must_gc_arguments = (regs != regs_cc);\n+    new_adapter = AdapterBlob::create(masm->code(), frame_complete, frame_size_in_words, oop_maps, caller_must_gc_arguments);\n+  }\n+\n+  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry, c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -853,0 +1140,1 @@\n+      case T_PRIMITIVE_OBJECT:\n@@ -1588,0 +1876,1 @@\n+      case T_PRIMITIVE_OBJECT:\n@@ -1702,0 +1991,4 @@\n+      if (EnableValhalla) {\n+        \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+        __ andr(swap_reg, swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+      }\n@@ -1767,0 +2060,1 @@\n+  case T_PRIMITIVE_OBJECT:           \/\/ Really a handle\n@@ -3016,0 +3310,121 @@\n+\n+BufferedInlineTypeBlob* SharedRuntime::generate_buffered_inline_type_adapter(const InlineKlass* vk) {\n+  BufferBlob* buf = BufferBlob::create(\"inline types pack\/unpack\", 16 * K);\n+  CodeBuffer buffer(buf);\n+  short buffer_locs[20];\n+  buffer.insts()->initialize_shared_locs((relocInfo*)buffer_locs,\n+                                         sizeof(buffer_locs)\/sizeof(relocInfo));\n+\n+  MacroAssembler _masm(&buffer);\n+  MacroAssembler* masm = &_masm;\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  int pack_fields_jobject_off = __ offset();\n+  \/\/ Resolve pre-allocated buffer from JNI handle.\n+  \/\/ We cannot do this in generate_call_stub() because it requires GC code to be initialized.\n+  Register Rresult = r14;  \/\/ See StubGenerator::generate_call_stub().\n+  __ ldr(r0, Address(Rresult));\n+  __ resolve_jobject(r0 \/* value *\/,\n+                     rthread \/* thread *\/,\n+                     r12 \/* tmp *\/);\n+  __ str(r0, Address(Rresult));\n+\n+  int pack_fields_off = __ offset();\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_PRIMITIVE_OBJECT) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    VMRegPair pair = regs->at(j);\n+    VMReg r_1 = pair.first();\n+    VMReg r_2 = pair.second();\n+    Address to(r0, off);\n+    if (bt == T_FLOAT) {\n+      __ strs(r_1->as_FloatRegister(), to);\n+    } else if (bt == T_DOUBLE) {\n+      __ strd(r_1->as_FloatRegister(), to);\n+    } else if (bt == T_OBJECT || bt == T_ARRAY) {\n+      Register val = r_1->as_Register();\n+      assert_different_registers(r0, val);\n+      \/\/ We don't need barriers because the destination is a newly allocated object.\n+      \/\/ Also, we cannot use store_heap_oop(to, val) because it uses r8 as tmp.\n+      if (UseCompressedOops) {\n+        __ encode_heap_oop(val);\n+        __ str(val, to);\n+      } else {\n+        __ str(val, to);\n+      }\n+    } else {\n+      assert(is_java_primitive(bt), \"unexpected basic type\");\n+      assert_different_registers(r0, r_1->as_Register());\n+      size_t size_in_bytes = type2aelembytes(bt);\n+      __ store_sized_value(to, r_1->as_Register(), size_in_bytes);\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+  __ ret(lr);\n+\n+  int unpack_fields_off = __ offset();\n+\n+  Label skip;\n+  __ cbz(r0, skip);\n+\n+  j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_PRIMITIVE_OBJECT) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    VMReg r_1 = pair.first();\n+    VMReg r_2 = pair.second();\n+    Address from(r0, off);\n+    if (bt == T_FLOAT) {\n+      __ ldrs(r_1->as_FloatRegister(), from);\n+    } else if (bt == T_DOUBLE) {\n+      __ ldrd(r_1->as_FloatRegister(), from);\n+    } else if (bt == T_OBJECT || bt == T_ARRAY) {\n+      assert_different_registers(r0, r_1->as_Register());\n+      __ load_heap_oop(r_1->as_Register(), from);\n+    } else {\n+      assert(is_java_primitive(bt), \"unexpected basic type\");\n+      assert_different_registers(r0, r_1->as_Register());\n+\n+      size_t size_in_bytes = type2aelembytes(bt);\n+      __ load_sized_value(r_1->as_Register(), from, size_in_bytes, bt != T_CHAR && bt != T_BOOLEAN);\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+  __ bind(skip);\n+\n+  __ ret(lr);\n+\n+  __ flush();\n+\n+  return BufferedInlineTypeBlob::create(&buffer, pack_fields_off, pack_fields_jobject_off, unpack_fields_off);\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":571,"deletions":156,"binary":false,"changes":727,"status":"modified"},{"patch":"@@ -320,1 +320,1 @@\n-    \/\/ T_OBJECT, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n+    \/\/ T_OBJECT, T_PRIMITIVE_OBJECT, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n@@ -323,4 +323,13 @@\n-    __ ldr(j_rarg2, result);\n-    Label is_long, is_float, is_double, exit;\n-    __ ldr(j_rarg1, result_type);\n-    __ cmp(j_rarg1, (u1)T_OBJECT);\n+    \/\/ All of j_rargN may be used to return inline type fields so be careful\n+    \/\/ not to clobber those.\n+    \/\/ SharedRuntime::generate_buffered_inline_type_adapter() knows the register\n+    \/\/ assignment of Rresult below.\n+    Register Rresult = r14, Rresult_type = r15;\n+    __ ldr(Rresult, result);\n+    Label is_long, is_float, is_double, check_prim, exit;\n+    __ ldr(Rresult_type, result_type);\n+    __ cmp(Rresult_type, (u1)T_OBJECT);\n+    __ br(Assembler::EQ, check_prim);\n+    __ cmp(Rresult_type, (u1)T_PRIMITIVE_OBJECT);\n+    __ br(Assembler::EQ, check_prim);\n+    __ cmp(Rresult_type, (u1)T_LONG);\n@@ -328,3 +337,1 @@\n-    __ cmp(j_rarg1, (u1)T_LONG);\n-    __ br(Assembler::EQ, is_long);\n-    __ cmp(j_rarg1, (u1)T_FLOAT);\n+    __ cmp(Rresult_type, (u1)T_FLOAT);\n@@ -332,1 +339,1 @@\n-    __ cmp(j_rarg1, (u1)T_DOUBLE);\n+    __ cmp(Rresult_type, (u1)T_DOUBLE);\n@@ -336,1 +343,1 @@\n-    __ strw(r0, Address(j_rarg2));\n+    __ strw(r0, Address(Rresult));\n@@ -384,0 +391,11 @@\n+    __ BIND(check_prim);\n+    if (InlineTypeReturnedAsFields) {\n+      \/\/ Check for scalarized return value\n+      __ tbz(r0, 0, is_long);\n+      \/\/ Load pack handler address\n+      __ andr(rscratch1, r0, -2);\n+      __ ldr(rscratch1, Address(rscratch1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      __ ldr(rscratch1, Address(rscratch1, InlineKlass::pack_handler_jobject_offset()));\n+      __ blr(rscratch1);\n+      __ b(exit);\n+    }\n@@ -386,1 +404,1 @@\n-    __ str(r0, Address(j_rarg2, 0));\n+    __ str(r0, Address(Rresult, 0));\n@@ -390,1 +408,1 @@\n-    __ strs(j_farg0, Address(j_rarg2, 0));\n+    __ strs(j_farg0, Address(Rresult, 0));\n@@ -394,1 +412,1 @@\n-    __ strd(j_farg0, Address(j_rarg2, 0));\n+    __ strd(j_farg0, Address(Rresult, 0));\n@@ -2103,0 +2121,8 @@\n+    \/\/ Check for flat inline type array -> return -1\n+    __ tst(lh, Klass::_lh_array_tag_flat_value_bit_inplace);\n+    __ br(Assembler::NE, L_failed);\n+\n+    \/\/ Check for null-free (non-flat) inline type array -> handle as object array\n+    __ tst(lh, Klass::_lh_null_free_array_bit_inplace);\n+    __ br(Assembler::NE, L_failed);\n+\n@@ -7765,0 +7791,128 @@\n+  \/\/ Call here from the interpreter or compiled code to either load\n+  \/\/ multiple returned values from the inline type instance being\n+  \/\/ returned to registers or to store returned values to a newly\n+  \/\/ allocated inline type instance.\n+  address generate_return_value_stub(address destination, const char* name, bool has_res) {\n+    \/\/ We need to save all registers the calling convention may use so\n+    \/\/ the runtime calls read or update those registers. This needs to\n+    \/\/ be in sync with SharedRuntime::java_return_convention().\n+    \/\/ n.b. aarch64 asserts that frame::arg_reg_save_area_bytes == 0\n+    enum layout {\n+      j_rarg7_off = 0, j_rarg7_2,    \/\/ j_rarg7 is r0\n+      j_rarg6_off, j_rarg6_2,\n+      j_rarg5_off, j_rarg5_2,\n+      j_rarg4_off, j_rarg4_2,\n+      j_rarg3_off, j_rarg3_2,\n+      j_rarg2_off, j_rarg2_2,\n+      j_rarg1_off, j_rarg1_2,\n+      j_rarg0_off, j_rarg0_2,\n+\n+      j_farg7_off, j_farg7_2,\n+      j_farg6_off, j_farg6_2,\n+      j_farg5_off, j_farg5_2,\n+      j_farg4_off, j_farg4_2,\n+      j_farg3_off, j_farg3_2,\n+      j_farg2_off, j_farg2_2,\n+      j_farg1_off, j_farg1_2,\n+      j_farg0_off, j_farg0_2,\n+\n+      rfp_off, rfp_off2,\n+      return_off, return_off2,\n+\n+      framesize \/\/ inclusive of return address\n+    };\n+\n+    CodeBuffer code(name, 512, 64);\n+    MacroAssembler* masm = new MacroAssembler(&code);\n+\n+    int frame_size_in_bytes = align_up(framesize*BytesPerInt, 16);\n+    assert(frame_size_in_bytes == framesize*BytesPerInt, \"misaligned\");\n+    int frame_size_in_slots = frame_size_in_bytes \/ BytesPerInt;\n+    int frame_size_in_words = frame_size_in_bytes \/ wordSize;\n+\n+    OopMapSet* oop_maps = new OopMapSet();\n+    OopMap* map = new OopMap(frame_size_in_slots, 0);\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg7_off), j_rarg7->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg6_off), j_rarg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+    address start = __ pc();\n+\n+    __ enter(); \/\/ Save FP and LR before call\n+\n+    __ stpd(j_farg1, j_farg0, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg3, j_farg2, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg5, j_farg4, Address(__ pre(sp, -2 * wordSize)));\n+    __ stpd(j_farg7, j_farg6, Address(__ pre(sp, -2 * wordSize)));\n+\n+    __ stp(j_rarg1, j_rarg0, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg3, j_rarg2, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg5, j_rarg4, Address(__ pre(sp, -2 * wordSize)));\n+    __ stp(j_rarg7, j_rarg6, Address(__ pre(sp, -2 * wordSize)));\n+\n+    int frame_complete = __ offset();\n+\n+    \/\/ Set up last_Java_sp and last_Java_fp\n+    address the_pc = __ pc();\n+    __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n+\n+    \/\/ Call runtime\n+    __ mov(c_rarg1, r0);\n+    __ mov(c_rarg0, rthread);\n+\n+    __ mov(rscratch1, destination);\n+    __ blr(rscratch1);\n+\n+    oop_maps->add_gc_map(the_pc - start, map);\n+\n+    __ reset_last_Java_frame(false);\n+\n+    __ ldp(j_rarg7, j_rarg6, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg5, j_rarg4, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg3, j_rarg2, Address(__ post(sp, 2 * wordSize)));\n+    __ ldp(j_rarg1, j_rarg0, Address(__ post(sp, 2 * wordSize)));\n+\n+    __ ldpd(j_farg7, j_farg6, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg5, j_farg4, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg3, j_farg2, Address(__ post(sp, 2 * wordSize)));\n+    __ ldpd(j_farg1, j_farg0, Address(__ post(sp, 2 * wordSize)));\n+\n+    __ leave();\n+\n+    \/\/ check for pending exceptions\n+    Label pending;\n+    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    __ cbnz(rscratch1, pending);\n+\n+    if (has_res) {\n+      __ get_vm_result(r0, rthread);\n+    }\n+\n+    __ ret(lr);\n+\n+    __ bind(pending);\n+    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+    \/\/ -------------\n+    \/\/ make sure all code is generated\n+    masm->flush();\n+\n+    RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &code, frame_complete, frame_size_in_words, oop_maps, false);\n+    return stub->entry_point();\n+  }\n+\n@@ -7814,0 +7968,7 @@\n+\n+    if (InlineTypeReturnedAsFields) {\n+      StubRoutines::_load_inline_type_fields_in_regs =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), \"load_inline_type_fields_in_regs\", false);\n+      StubRoutines::_store_inline_type_fields_to_buf =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), \"store_inline_type_fields_to_buf\", true);\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":174,"deletions":13,"binary":false,"changes":187,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -437,0 +438,5 @@\n+\n+  if (state == atos && InlineTypeReturnedAsFields) {\n+    __ store_inline_type_fields_to_buf(NULL, true);\n+  }\n+\n@@ -542,0 +548,1 @@\n+  case T_PRIMITIVE_OBJECT: \/\/ fall through (value types are handled with oops)\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -119,0 +120,13 @@\n+void LIRGenerator::init_temps_for_substitutability_check(LIR_Opr& tmp1, LIR_Opr& tmp2) {\n+  \/\/ We just need one 32-bit temp register for x86\/x64, to check whether both\n+  \/\/ oops have markWord::always_locked_pattern. See LIR_Assembler::emit_opSubstitutabilityCheck().\n+  \/\/ @temp = %r10d\n+  \/\/ mov $0x405, %r10d\n+  \/\/ and (%left), %r10d   \/* if need to check left *\/\n+  \/\/ and (%right), %r10d  \/* if need to check right *\/\n+  \/\/ cmp $0x405, $r10d\n+  \/\/ jne L_oops_not_equal\n+  tmp1 = new_register(T_INT);\n+  tmp2 = LIR_OprFact::illegalOpr;\n+}\n+\n@@ -314,0 +328,5 @@\n+  \/\/ Need a scratch register for inline types on x86\n+  LIR_Opr scratch = LIR_OprFact::illegalOpr;\n+  if (EnableValhalla && x->maybe_inlinetype()) {\n+    scratch = new_register(T_INT);\n+  }\n@@ -319,0 +338,6 @@\n+\n+  CodeStub* throw_imse_stub = x->maybe_inlinetype() ?\n+      new SimpleExceptionStub(Runtime1::throw_illegal_monitor_state_exception_id,\n+                              LIR_OprFact::illegalOpr, state_for(x))\n+    : NULL;\n+\n@@ -322,2 +347,2 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n-                        x->monitor_no(), info_for_exception, info);\n+  monitor_enter(obj.result(), lock, syncTempOpr(), scratch,\n+                x->monitor_no(), info_for_exception, info, throw_imse_stub);\n@@ -1289,5 +1314,6 @@\n-                       FrameMap::rcx_oop_opr,\n-                       FrameMap::rdi_oop_opr,\n-                       FrameMap::rsi_oop_opr,\n-                       LIR_OprFact::illegalOpr,\n-                       FrameMap::rdx_metadata_opr, info);\n+               \/* allow_inline *\/ false,\n+               FrameMap::rcx_oop_opr,\n+               FrameMap::rdi_oop_opr,\n+               FrameMap::rsi_oop_opr,\n+               LIR_OprFact::illegalOpr,\n+               FrameMap::rdx_metadata_opr, info);\n@@ -1298,0 +1324,15 @@\n+void LIRGenerator::do_NewInlineTypeInstance(NewInlineTypeInstance* x) {\n+  \/\/ Mapping to do_NewInstance (same code) but use state_before for reexecution.\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+  x->set_to_object_type();\n+  LIR_Opr reg = result_register_for(x->type());\n+  new_instance(reg, x->klass(), false,\n+               \/* allow_inline *\/ true,\n+               FrameMap::rcx_oop_opr,\n+               FrameMap::rdi_oop_opr,\n+               FrameMap::rsi_oop_opr,\n+               LIR_OprFact::illegalOpr,\n+               FrameMap::rdx_metadata_opr, info);\n+  LIR_Opr result = rlock_result(x);\n+  __ move(reg, result);\n+}\n@@ -1345,2 +1386,2 @@\n-  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info);\n-  ciKlass* obj = (ciKlass*) ciObjArrayKlass::make(x->klass());\n+  ciKlass* obj = (ciKlass*) x->exact_type();\n+  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, x->is_null_free());\n@@ -1351,1 +1392,5 @@\n-  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);\n+  if (x->is_null_free()) {\n+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_PRIMITIVE_OBJECT, klass_reg, slow_path);\n+  } else {\n+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);\n+  }\n@@ -1430,0 +1475,4 @@\n+  if (x->is_null_free()) {\n+    __ null_check(obj.result(), new CodeEmitInfo(info_for_exception));\n+  }\n+\n@@ -1448,1 +1497,1 @@\n-               x->profiled_method(), x->profiled_bci());\n+               x->profiled_method(), x->profiled_bci(), x->is_null_free());\n@@ -1499,1 +1548,1 @@\n-  } else if (tag == longTag || tag == floatTag || tag == doubleTag) {\n+  } else if (tag == longTag || tag == floatTag || tag == doubleTag || x->substitutability_check()) {\n@@ -1519,1 +1568,5 @@\n-  __ cmp(lir_cond(cond), left, right);\n+  if (x->substitutability_check()) {\n+    substitutability_check(x, *xin, *yin);\n+  } else {\n+    __ cmp(lir_cond(cond), left, right);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":66,"deletions":13,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -213,1 +213,0 @@\n-\n@@ -228,2 +227,18 @@\n-  \/\/ Determine and save the live input values\n-  __ push_call_clobbered_registers();\n+  if (EnableValhalla && InlineTypePassFieldsAsArgs) {\n+    \/\/ Barriers might be emitted when converting between (scalarized) calling conventions for inline\n+    \/\/ types. Save all argument registers before calling into the runtime.\n+    \/\/ TODO: use push_set() (see JDK-8283327 push\/pop_call_clobbered_registers & aarch64 )\n+    __ pusha();\n+    __ subptr(rsp, 64);\n+    __ movdbl(Address(rsp, 0),  j_farg0);\n+    __ movdbl(Address(rsp, 8),  j_farg1);\n+    __ movdbl(Address(rsp, 16), j_farg2);\n+    __ movdbl(Address(rsp, 24), j_farg3);\n+    __ movdbl(Address(rsp, 32), j_farg4);\n+    __ movdbl(Address(rsp, 40), j_farg5);\n+    __ movdbl(Address(rsp, 48), j_farg6);\n+    __ movdbl(Address(rsp, 56), j_farg7);\n+  } else {\n+    \/\/ Determine and save the live input values\n+    __ push_call_clobbered_registers();\n+  }\n@@ -261,1 +276,15 @@\n-  __ pop_call_clobbered_registers();\n+  if (EnableValhalla && InlineTypePassFieldsAsArgs) {\n+    \/\/ Restore registers\n+    __ movdbl(j_farg0, Address(rsp, 0));\n+    __ movdbl(j_farg1, Address(rsp, 8));\n+    __ movdbl(j_farg2, Address(rsp, 16));\n+    __ movdbl(j_farg3, Address(rsp, 24));\n+    __ movdbl(j_farg4, Address(rsp, 32));\n+    __ movdbl(j_farg5, Address(rsp, 40));\n+    __ movdbl(j_farg6, Address(rsp, 48));\n+    __ movdbl(j_farg7, Address(rsp, 56));\n+    __ addptr(rsp, 64);\n+    __ popa();\n+  } else {\n+    __ pop_call_clobbered_registers();\n+  }\n@@ -334,3 +363,18 @@\n-  \/\/ save the live input values\n-  RegSet saved = RegSet::of(store_addr NOT_LP64(COMMA thread));\n-  __ push_set(saved);\n+  \/\/ Barriers might be emitted when converting between (scalarized) calling conventions for inline\n+  \/\/ types. Save all argument registers before calling into the runtime.\n+  \/\/ TODO: use push_set() (see JDK-8283327 push\/pop_call_clobbered_registers & aarch64)\n+  __ pusha();\n+  __ subptr(rsp, 64);\n+  __ movdbl(Address(rsp, 0),  j_farg0);\n+  __ movdbl(Address(rsp, 8),  j_farg1);\n+  __ movdbl(Address(rsp, 16), j_farg2);\n+  __ movdbl(Address(rsp, 24), j_farg3);\n+  __ movdbl(Address(rsp, 32), j_farg4);\n+  __ movdbl(Address(rsp, 40), j_farg5);\n+  __ movdbl(Address(rsp, 48), j_farg6);\n+  __ movdbl(Address(rsp, 56), j_farg7);\n+\n+#ifdef _LP64\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry), card_addr, r15_thread);\n+#else\n+  __ push(thread);\n@@ -338,1 +382,14 @@\n-  __ pop_set(saved);\n+  __ pop(thread);\n+#endif\n+\n+  \/\/ Restore registers\n+  __ movdbl(j_farg0, Address(rsp, 0));\n+  __ movdbl(j_farg1, Address(rsp, 8));\n+  __ movdbl(j_farg2, Address(rsp, 16));\n+  __ movdbl(j_farg3, Address(rsp, 24));\n+  __ movdbl(j_farg4, Address(rsp, 32));\n+  __ movdbl(j_farg5, Address(rsp, 40));\n+  __ movdbl(j_farg6, Address(rsp, 48));\n+  __ movdbl(j_farg7, Address(rsp, 56));\n+  __ addptr(rsp, 64);\n+  __ popa();\n@@ -347,0 +404,1 @@\n+  bool dest_uninitialized = (decorators & IS_DEST_UNINITIALIZED) != 0;\n@@ -348,1 +406,1 @@\n-  bool needs_pre_barrier = as_normal;\n+  bool needs_pre_barrier = as_normal && !dest_uninitialized;\n","filename":"src\/hotspot\/cpu\/x86\/gc\/g1\/g1BarrierSetAssembler_x86.cpp","additions":67,"deletions":9,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"runtime\/signature.hpp\"\n@@ -36,0 +37,2 @@\n+class ciInlineKlass;\n+\n@@ -105,0 +108,31 @@\n+  \/\/ markWord tests, kills markWord reg\n+  void test_markword_is_inline_type(Register markword, Label& is_inline_type);\n+\n+  \/\/ inlineKlass queries, kills temp_reg\n+  void test_klass_is_inline_type(Register klass, Register temp_reg, Label& is_inline_type);\n+  void test_klass_is_empty_inline_type(Register klass, Register temp_reg, Label& is_empty_inline_type);\n+  void test_oop_is_not_inline_type(Register object, Register tmp, Label& not_inline_type);\n+\n+  \/\/ Get the default value oop for the given InlineKlass\n+  void get_default_value_oop(Register inline_klass, Register temp_reg, Register obj);\n+  \/\/ The empty value oop, for the given InlineKlass (\"empty\" as in no instance fields)\n+  \/\/ get_default_value_oop with extra assertion for empty inline klass\n+  void get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj);\n+\n+  void test_field_is_null_free_inline_type(Register flags, Register temp_reg, Label& is_null_free);\n+  void test_field_is_not_null_free_inline_type(Register flags, Register temp_reg, Label& not_null_free);\n+  void test_field_is_inlined(Register flags, Register temp_reg, Label& is_inlined);\n+\n+  \/\/ Check oops for special arrays, i.e. flattened and\/or null-free\n+  void test_oop_prototype_bit(Register oop, Register temp_reg, int32_t test_bit, bool jmp_set, Label& jmp_label);\n+  void test_flattened_array_oop(Register oop, Register temp_reg, Label&is_flattened_array);\n+  void test_non_flattened_array_oop(Register oop, Register temp_reg, Label&is_non_flattened_array);\n+  void test_null_free_array_oop(Register oop, Register temp_reg, Label&is_null_free_array);\n+  void test_non_null_free_array_oop(Register oop, Register temp_reg, Label&is_non_null_free_array);\n+\n+  \/\/ Check array klass layout helper for flatten or null-free arrays...\n+  void test_flattened_array_layout(Register lh, Label& is_flattened_array);\n+  void test_non_flattened_array_layout(Register lh, Label& is_non_flattened_array);\n+  void test_null_free_array_layout(Register lh, Label& is_null_free_array);\n+  void test_non_null_free_array_layout(Register lh, Label& is_non_null_free_array);\n+\n@@ -350,0 +384,1 @@\n+  void load_metadata(Register dst, Register src);\n@@ -358,0 +393,10 @@\n+  void access_value_copy(DecoratorSet decorators, Register src, Register dst, Register inline_klass);\n+\n+  \/\/ inline type data payload offsets...\n+  void first_field_offset(Register inline_klass, Register offset);\n+  void data_for_oop(Register oop, Register data, Register inline_klass);\n+  \/\/ get data payload ptr a flat value array at index, kills rcx and index\n+  void data_for_value_array_index(Register array, Register array_klass,\n+                                  Register index, Register data);\n+\n+\n@@ -369,0 +414,2 @@\n+  void load_prototype_header(Register dst, Register src, Register tmp);\n+\n@@ -570,0 +617,9 @@\n+\n+  \/\/ Object \/ value buffer allocation...\n+  \/\/ Allocate instance of klass, assumes klass initialized by caller\n+  \/\/ new_obj prefers to be rax\n+  \/\/ Kills t1 and t2, perserves klass, return allocation in new_obj (rsi on LP64)\n+  void allocate_instance(Register klass, Register new_obj,\n+                         Register t1, Register t2,\n+                         bool clear_fields, Label& alloc_failed);\n+\n@@ -581,0 +637,3 @@\n+  \/\/ For field \"index\" within \"klass\", return inline_klass ...\n+  void get_inline_type_field_klass(Register klass, Register index, Register inline_klass);\n+\n@@ -731,1 +790,2 @@\n-  void andptr(Register src1, Register src2) { LP64_ONLY(andq(src1, src2)) NOT_LP64(andl(src1, src2)) ; }\n+  void andptr(Register dst, Register src) { LP64_ONLY(andq(dst, src)) NOT_LP64(andl(dst, src)) ; }\n+  void andptr(Register dst, Address src) { LP64_ONLY(andq(dst, src)) NOT_LP64(andl(dst, src)) ; }\n@@ -1842,0 +1902,15 @@\n+  \/\/ Inline type specific methods\n+  #include \"asm\/macroAssembler_common.hpp\"\n+\n+  int store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter = true);\n+  bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]);\n+  bool unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                            VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                            RegState reg_state[]);\n+  bool pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                          VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                          RegState reg_state[], Register val_array);\n+  int extend_stack_for_inline_args(int args_on_stack);\n+  void remove_frame(int initial_framesize, bool needs_stack_repair);\n+  VMReg spill_reg_for(VMReg reg);\n+\n@@ -1844,1 +1919,1 @@\n-  void clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp, bool is_large, KRegister mask=knoreg);\n+  void clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only, KRegister mask=knoreg);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":77,"deletions":2,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"classfile\/symbolTable.hpp\"\n@@ -526,0 +527,1 @@\n+    case T_PRIMITIVE_OBJECT:\n@@ -559,0 +561,82 @@\n+\/\/ Same as java_calling_convention() but for multiple return\n+\/\/ values. There's no way to store them on the stack so if we don't\n+\/\/ have enough registers, multiple values can't be returned.\n+const uint SharedRuntime::java_return_convention_max_int = Argument::n_int_register_parameters_j+1;\n+const uint SharedRuntime::java_return_convention_max_float = Argument::n_float_register_parameters_j;\n+int SharedRuntime::java_return_convention(const BasicType *sig_bt,\n+                                          VMRegPair *regs,\n+                                          int total_args_passed) {\n+  \/\/ Create the mapping between argument positions and\n+  \/\/ registers.\n+  static const Register INT_ArgReg[java_return_convention_max_int] = {\n+    rax, j_rarg5, j_rarg4, j_rarg3, j_rarg2, j_rarg1, j_rarg0\n+  };\n+  static const XMMRegister FP_ArgReg[java_return_convention_max_float] = {\n+    j_farg0, j_farg1, j_farg2, j_farg3,\n+    j_farg4, j_farg5, j_farg6, j_farg7\n+  };\n+\n+\n+  uint int_args = 0;\n+  uint fp_args = 0;\n+\n+  for (int i = 0; i < total_args_passed; i++) {\n+    switch (sig_bt[i]) {\n+    case T_BOOLEAN:\n+    case T_CHAR:\n+    case T_BYTE:\n+    case T_SHORT:\n+    case T_INT:\n+      if (int_args < Argument::n_int_register_parameters_j+1) {\n+        regs[i].set1(INT_ArgReg[int_args]->as_VMReg());\n+        int_args++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_VOID:\n+      \/\/ halves of T_LONG or T_DOUBLE\n+      assert(i != 0 && (sig_bt[i - 1] == T_LONG || sig_bt[i - 1] == T_DOUBLE), \"expecting half\");\n+      regs[i].set_bad();\n+      break;\n+    case T_LONG:\n+      assert(sig_bt[i + 1] == T_VOID, \"expecting half\");\n+      \/\/ fall through\n+    case T_OBJECT:\n+    case T_PRIMITIVE_OBJECT:\n+    case T_ARRAY:\n+    case T_ADDRESS:\n+    case T_METADATA:\n+      if (int_args < Argument::n_int_register_parameters_j+1) {\n+        regs[i].set2(INT_ArgReg[int_args]->as_VMReg());\n+        int_args++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_FLOAT:\n+      if (fp_args < Argument::n_float_register_parameters_j) {\n+        regs[i].set1(FP_ArgReg[fp_args]->as_VMReg());\n+        fp_args++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_DOUBLE:\n+      assert(sig_bt[i + 1] == T_VOID, \"expecting half\");\n+      if (fp_args < Argument::n_float_register_parameters_j) {\n+        regs[i].set2(FP_ArgReg[fp_args]->as_VMReg());\n+        fp_args++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+      break;\n+    }\n+  }\n+\n+  return int_args + fp_args;\n+}\n+\n@@ -601,0 +685,106 @@\n+\/\/ For each inline type argument, sig includes the list of fields of\n+\/\/ the inline type. This utility function computes the number of\n+\/\/ arguments for the call if inline types are passed by reference (the\n+\/\/ calling convention the interpreter expects).\n+static int compute_total_args_passed_int(const GrowableArray<SigEntry>* sig_extended) {\n+  int total_args_passed = 0;\n+  if (InlineTypePassFieldsAsArgs) {\n+    for (int i = 0; i < sig_extended->length(); i++) {\n+      BasicType bt = sig_extended->at(i)._bt;\n+      if (bt == T_PRIMITIVE_OBJECT) {\n+        \/\/ In sig_extended, an inline type argument starts with:\n+        \/\/ T_PRIMITIVE_OBJECT, followed by the types of the fields of the\n+        \/\/ inline type and T_VOID to mark the end of the value\n+        \/\/ type. Inline types are flattened so, for instance, in the\n+        \/\/ case of an inline type with an int field and an inline type\n+        \/\/ field that itself has 2 fields, an int and a long:\n+        \/\/ T_PRIMITIVE_OBJECT T_INT T_PRIMITIVE_OBJECT T_INT T_LONG T_VOID (second\n+        \/\/ slot for the T_LONG) T_VOID (inner T_PRIMITIVE_OBJECT) T_VOID\n+        \/\/ (outer T_PRIMITIVE_OBJECT)\n+        total_args_passed++;\n+        int vt = 1;\n+        do {\n+          i++;\n+          BasicType bt = sig_extended->at(i)._bt;\n+          BasicType prev_bt = sig_extended->at(i-1)._bt;\n+          if (bt == T_PRIMITIVE_OBJECT) {\n+            vt++;\n+          } else if (bt == T_VOID &&\n+                     prev_bt != T_LONG &&\n+                     prev_bt != T_DOUBLE) {\n+            vt--;\n+          }\n+        } while (vt != 0);\n+      } else {\n+        total_args_passed++;\n+      }\n+    }\n+  } else {\n+    total_args_passed = sig_extended->length();\n+  }\n+  return total_args_passed;\n+}\n+\n+\n+static void gen_c2i_adapter_helper(MacroAssembler* masm,\n+                                   BasicType bt,\n+                                   BasicType prev_bt,\n+                                   size_t size_in_bytes,\n+                                   const VMRegPair& reg_pair,\n+                                   const Address& to,\n+                                   int extraspace,\n+                                   bool is_oop) {\n+  assert(bt != T_PRIMITIVE_OBJECT || !InlineTypePassFieldsAsArgs, \"no inline type here\");\n+  if (bt == T_VOID) {\n+    assert(prev_bt == T_LONG || prev_bt == T_DOUBLE, \"missing half\");\n+    return;\n+  }\n+\n+  \/\/ Say 4 args:\n+  \/\/ i   st_off\n+  \/\/ 0   32 T_LONG\n+  \/\/ 1   24 T_VOID\n+  \/\/ 2   16 T_OBJECT\n+  \/\/ 3    8 T_BOOL\n+  \/\/ -    0 return address\n+  \/\/\n+  \/\/ However to make thing extra confusing. Because we can fit a long\/double in\n+  \/\/ a single slot on a 64 bt vm and it would be silly to break them up, the interpreter\n+  \/\/ leaves one slot empty and only stores to a single slot. In this case the\n+  \/\/ slot that is occupied is the T_VOID slot. See I said it was confusing.\n+\n+  bool wide = (size_in_bytes == wordSize);\n+  VMReg r_1 = reg_pair.first();\n+  VMReg r_2 = reg_pair.second();\n+  assert(r_2->is_valid() == wide, \"invalid size\");\n+  if (!r_1->is_valid()) {\n+    assert(!r_2->is_valid(), \"must be invalid\");\n+    return;\n+  }\n+\n+  if (!r_1->is_XMMRegister()) {\n+    Register val = rax;\n+    if (r_1->is_stack()) {\n+      int ld_off = r_1->reg2stack() * VMRegImpl::stack_slot_size + extraspace;\n+      __ load_sized_value(val, Address(rsp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+    } else {\n+      val = r_1->as_Register();\n+    }\n+    assert_different_registers(to.base(), val, rscratch1);\n+    if (is_oop) {\n+      __ push(r13);\n+      __ push(rbx);\n+      __ store_heap_oop(to, val, rscratch1, r13, rbx, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      __ pop(rbx);\n+      __ pop(r13);\n+    } else {\n+      __ store_sized_value(to, val, size_in_bytes);\n+    }\n+  } else {\n+    if (wide) {\n+      __ movdbl(to, r_1->as_XMMRegister());\n+    } else {\n+      __ movflt(to, r_1->as_XMMRegister());\n+    }\n+  }\n+}\n@@ -603,3 +793,1 @@\n-                            int total_args_passed,\n-                            int comp_args_on_stack,\n-                            const BasicType *sig_bt,\n+                            const GrowableArray<SigEntry>* sig_extended,\n@@ -607,1 +795,6 @@\n-                            Label& skip_fixup) {\n+                            Label& skip_fixup,\n+                            address start,\n+                            OopMapSet* oop_maps,\n+                            int& frame_complete,\n+                            int& frame_size_in_words,\n+                            bool alloc_inline_receiver) {\n@@ -617,2 +810,20 @@\n-  \/\/ Since all args are passed on the stack, total_args_passed *\n-  \/\/ Interpreter::stackElementSize is the space we need.\n+  if (InlineTypePassFieldsAsArgs) {\n+    \/\/ Is there an inline type argument?\n+    bool has_inline_argument = false;\n+    for (int i = 0; i < sig_extended->length() && !has_inline_argument; i++) {\n+      has_inline_argument = (sig_extended->at(i)._bt == T_PRIMITIVE_OBJECT);\n+    }\n+    if (has_inline_argument) {\n+      \/\/ There is at least an inline type argument: we're coming from\n+      \/\/ compiled code so we have no buffers to back the inline types.\n+      \/\/ Allocate the buffers here with a runtime call.\n+      OopMap* map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ false);\n+\n+      frame_complete = __ offset();\n+\n+      __ set_last_Java_frame(noreg, noreg, NULL, rscratch1);\n+\n+      __ mov(c_rarg0, r15_thread);\n+      __ mov(c_rarg1, rbx);\n+      __ mov64(c_rarg2, (int64_t)alloc_inline_receiver);\n+      __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::allocate_inline_types)));\n@@ -620,0 +831,23 @@\n+      oop_maps->add_gc_map((int)(__ pc() - start), map);\n+      __ reset_last_Java_frame(false);\n+\n+      RegisterSaver::restore_live_registers(masm);\n+\n+      Label no_exception;\n+      __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), NULL_WORD);\n+      __ jcc(Assembler::equal, no_exception);\n+\n+      __ movptr(Address(r15_thread, JavaThread::vm_result_offset()), NULL_WORD);\n+      __ movptr(rax, Address(r15_thread, Thread::pending_exception_offset()));\n+      __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+      __ bind(no_exception);\n+\n+      \/\/ We get an array of objects from the runtime call\n+      __ get_vm_result(rscratch2, r15_thread); \/\/ Use rscratch2 (r11) as temporary because rscratch1 (r10) is trashed by movptr()\n+      __ get_vm_result_2(rbx, r15_thread); \/\/ TODO: required to keep the callee Method live?\n+    }\n+  }\n+\n+  \/\/ Since all args are passed on the stack, total_args_passed *\n+  int total_args_passed = compute_total_args_passed_int(sig_extended);\n@@ -621,0 +855,1 @@\n+  \/\/ Interpreter::stackElementSize is the space we need.\n@@ -654,46 +889,24 @@\n-  for (int i = 0; i < total_args_passed; i++) {\n-    if (sig_bt[i] == T_VOID) {\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n-      continue;\n-    }\n-\n-    \/\/ offset to start parameters\n-    int st_off   = (total_args_passed - i) * Interpreter::stackElementSize;\n-    int next_off = st_off - Interpreter::stackElementSize;\n-\n-    \/\/ Say 4 args:\n-    \/\/ i   st_off\n-    \/\/ 0   32 T_LONG\n-    \/\/ 1   24 T_VOID\n-    \/\/ 2   16 T_OBJECT\n-    \/\/ 3    8 T_BOOL\n-    \/\/ -    0 return address\n-    \/\/\n-    \/\/ However to make thing extra confusing. Because we can fit a long\/double in\n-    \/\/ a single slot on a 64 bt vm and it would be silly to break them up, the interpreter\n-    \/\/ leaves one slot empty and only stores to a single slot. In this case the\n-    \/\/ slot that is occupied is the T_VOID slot. See I said it was confusing.\n-\n-    VMReg r_1 = regs[i].first();\n-    VMReg r_2 = regs[i].second();\n-    if (!r_1->is_valid()) {\n-      assert(!r_2->is_valid(), \"\");\n-      continue;\n-    }\n-    if (r_1->is_stack()) {\n-      \/\/ memory to memory use rax\n-      int ld_off = r_1->reg2stack() * VMRegImpl::stack_slot_size + extraspace;\n-      if (!r_2->is_valid()) {\n-        \/\/ sign extend??\n-        __ movl(rax, Address(rsp, ld_off));\n-        __ movptr(Address(rsp, st_off), rax);\n-\n-      } else {\n-\n-        __ movq(rax, Address(rsp, ld_off));\n-        \/\/ Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG\n-        \/\/ T_DOUBLE and T_LONG use two slots in the interpreter\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n-          \/\/ ld_off == LSW, ld_off+wordSize == MSW\n-          \/\/ st_off == MSW, next_off == LSW\n-          __ movq(Address(rsp, next_off), rax);\n+  \/\/ next_arg_comp is the next argument from the compiler point of\n+  \/\/ view (inline type fields are passed in registers\/on the stack). In\n+  \/\/ sig_extended, an inline type argument starts with: T_PRIMITIVE_OBJECT,\n+  \/\/ followed by the types of the fields of the inline type and T_VOID\n+  \/\/ to mark the end of the inline type. ignored counts the number of\n+  \/\/ T_PRIMITIVE_OBJECT\/T_VOID. next_vt_arg is the next inline type argument:\n+  \/\/ used to get the buffer for that argument from the pool of buffers\n+  \/\/ we allocated above and want to pass to the\n+  \/\/ interpreter. next_arg_int is the next argument from the\n+  \/\/ interpreter point of view (inline types are passed by reference).\n+  for (int next_arg_comp = 0, ignored = 0, next_vt_arg = 0, next_arg_int = 0;\n+       next_arg_comp < sig_extended->length(); next_arg_comp++) {\n+    assert(ignored <= next_arg_comp, \"shouldn't skip over more slots than there are arguments\");\n+    assert(next_arg_int <= total_args_passed, \"more arguments for the interpreter than expected?\");\n+    BasicType bt = sig_extended->at(next_arg_comp)._bt;\n+    int st_off = (total_args_passed - next_arg_int) * Interpreter::stackElementSize;\n+    if (!InlineTypePassFieldsAsArgs || bt != T_PRIMITIVE_OBJECT) {\n+      int next_off = st_off - Interpreter::stackElementSize;\n+      const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : st_off;\n+      const VMRegPair reg_pair = regs[next_arg_comp-ignored];\n+      size_t size_in_bytes = reg_pair.second()->is_valid() ? 8 : 4;\n+      gen_c2i_adapter_helper(masm, bt, next_arg_comp > 0 ? sig_extended->at(next_arg_comp-1)._bt : T_ILLEGAL,\n+                             size_in_bytes, reg_pair, Address(rsp, offset), extraspace, false);\n+      next_arg_int++;\n@@ -702,7 +915,4 @@\n-          \/\/ Overwrite the unused slot with known junk\n-          __ mov64(rax, CONST64(0xdeadffffdeadaaaa));\n-          __ movptr(Address(rsp, st_off), rax);\n-#endif \/* ASSERT *\/\n-        } else {\n-          __ movq(Address(rsp, st_off), rax);\n-        }\n+      if (bt == T_LONG || bt == T_DOUBLE) {\n+        \/\/ Overwrite the unused slot with known junk\n+        __ mov64(rax, CONST64(0xdeadffffdeadaaaa));\n+        __ movptr(Address(rsp, st_off), rax);\n@@ -710,16 +920,26 @@\n-    } else if (r_1->is_Register()) {\n-      Register r = r_1->as_Register();\n-      if (!r_2->is_valid()) {\n-        \/\/ must be only an int (or less ) so move only 32bits to slot\n-        \/\/ why not sign extend??\n-        __ movl(Address(rsp, st_off), r);\n-      } else {\n-        \/\/ Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG\n-        \/\/ T_DOUBLE and T_LONG use two slots in the interpreter\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n-          \/\/ long\/double in gpr\n-#ifdef ASSERT\n-          \/\/ Overwrite the unused slot with known junk\n-          __ mov64(rax, CONST64(0xdeadffffdeadaaab));\n-          __ movptr(Address(rsp, st_off), rax);\n-          __ movq(Address(rsp, next_off), r);\n+    } else {\n+      ignored++;\n+      \/\/ get the buffer from the just allocated pool of buffers\n+      int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_PRIMITIVE_OBJECT);\n+      __ load_heap_oop(r14, Address(rscratch2, index));\n+      next_vt_arg++; next_arg_int++;\n+      int vt = 1;\n+      \/\/ write fields we get from compiled code in registers\/stack\n+      \/\/ slots to the buffer: we know we are done with that inline type\n+      \/\/ argument when we hit the T_VOID that acts as an end of inline\n+      \/\/ type delimiter for this inline type. Inline types are flattened\n+      \/\/ so we might encounter embedded inline types. Each entry in\n+      \/\/ sig_extended contains a field offset in the buffer.\n+      Label L_null;\n+      do {\n+        next_arg_comp++;\n+        BasicType bt = sig_extended->at(next_arg_comp)._bt;\n+        BasicType prev_bt = sig_extended->at(next_arg_comp-1)._bt;\n+        if (bt == T_PRIMITIVE_OBJECT) {\n+          vt++;\n+          ignored++;\n+        } else if (bt == T_VOID &&\n+                   prev_bt != T_LONG &&\n+                   prev_bt != T_DOUBLE) {\n+          vt--;\n+          ignored++;\n@@ -728,1 +948,22 @@\n-          __ movptr(Address(rsp, st_off), r);\n+          int off = sig_extended->at(next_arg_comp)._offset;\n+          if (off == -1) {\n+            \/\/ Nullable inline type argument, emit null check\n+            VMReg reg = regs[next_arg_comp-ignored].first();\n+            Label L_notNull;\n+            if (reg->is_stack()) {\n+              int ld_off = reg->reg2stack() * VMRegImpl::stack_slot_size + extraspace;\n+              __ testb(Address(rsp, ld_off), 1);\n+            } else {\n+              __ testb(reg->as_Register(), 1);\n+            }\n+            __ jcc(Assembler::notZero, L_notNull);\n+            __ movptr(Address(rsp, st_off), 0);\n+            __ jmp(L_null);\n+            __ bind(L_notNull);\n+            continue;\n+          }\n+          assert(off > 0, \"offset in object should be positive\");\n+          size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;\n+          bool is_oop = is_reference_type(bt);\n+          gen_c2i_adapter_helper(masm, bt, next_arg_comp > 0 ? sig_extended->at(next_arg_comp-1)._bt : T_ILLEGAL,\n+                                 size_in_bytes, regs[next_arg_comp-ignored], Address(r14, off), extraspace, is_oop);\n@@ -730,14 +971,4 @@\n-      }\n-    } else {\n-      assert(r_1->is_XMMRegister(), \"\");\n-      if (!r_2->is_valid()) {\n-        \/\/ only a float use just part of the slot\n-        __ movflt(Address(rsp, st_off), r_1->as_XMMRegister());\n-      } else {\n-#ifdef ASSERT\n-        \/\/ Overwrite the unused slot with known junk\n-        __ mov64(rax, CONST64(0xdeadffffdeadaaac));\n-        __ movptr(Address(rsp, st_off), rax);\n-#endif \/* ASSERT *\/\n-        __ movdbl(Address(rsp, next_off), r_1->as_XMMRegister());\n-      }\n+      } while (vt != 0);\n+      \/\/ pass the buffer to the interpreter\n+      __ movptr(Address(rsp, st_off), r14);\n+      __ bind(L_null);\n@@ -766,2 +997,1 @@\n-                                    int total_args_passed,\n-                                    const BasicType *sig_bt,\n+                                    const GrowableArray<SigEntry>* sig,\n@@ -853,1 +1083,1 @@\n-  __ movptr(r11, Address(rbx, in_bytes(Method::from_compiled_offset())));\n+  __ movptr(r11, Address(rbx, in_bytes(Method::from_compiled_inline_offset())));\n@@ -867,0 +1097,2 @@\n+  int total_args_passed = sig->length();\n+\n@@ -870,1 +1102,3 @@\n-    if (sig_bt[i] == T_VOID) {\n+    BasicType bt = sig->at(i)._bt;\n+    assert(bt != T_PRIMITIVE_OBJECT, \"i2c adapter doesn't unpack inline type args\");\n+    if (bt == T_VOID) {\n@@ -873,1 +1107,2 @@\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n+      BasicType prev_bt = (i > 0) ? sig->at(i-1)._bt : T_ILLEGAL;\n+      assert(i > 0 && (prev_bt == T_LONG || prev_bt == T_DOUBLE), \"missing half\");\n@@ -915,1 +1150,1 @@\n-        const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n+        const int offset = (bt==T_LONG||bt==T_DOUBLE)?\n@@ -930,1 +1165,1 @@\n-        const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n+        const int offset = (bt==T_LONG||bt==T_DOUBLE)?\n@@ -963,1 +1198,1 @@\n-  \/\/ only needed because eof c2 resolve stubs return Method* as a result in\n+  \/\/ only needed because of c2 resolve stubs return Method* as a result in\n@@ -969,0 +1204,22 @@\n+static void gen_inline_cache_check(MacroAssembler *masm, Label& skip_fixup) {\n+  Label ok;\n+\n+  Register holder = rax;\n+  Register receiver = j_rarg0;\n+  Register temp = rbx;\n+\n+  __ load_klass(temp, receiver, rscratch1);\n+  __ cmpptr(temp, Address(holder, CompiledICHolder::holder_klass_offset()));\n+  __ movptr(rbx, Address(holder, CompiledICHolder::holder_metadata_offset()));\n+  __ jcc(Assembler::equal, ok);\n+  __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+\n+  __ bind(ok);\n+  \/\/ Method might have been compiled since the call site was patched to\n+  \/\/ interpreted if that is the case treat it as a miss so we can get\n+  \/\/ the call site corrected.\n+  __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), NULL_WORD);\n+  __ jcc(Assembler::equal, skip_fixup);\n+  __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+}\n+\n@@ -970,2 +1227,1 @@\n-AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler *masm,\n-                                                            int total_args_passed,\n+AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler* masm,\n@@ -973,3 +1229,9 @@\n-                                                            const BasicType *sig_bt,\n-                                                            const VMRegPair *regs,\n-                                                            AdapterFingerPrint* fingerprint) {\n+                                                            const GrowableArray<SigEntry>* sig,\n+                                                            const VMRegPair* regs,\n+                                                            const GrowableArray<SigEntry>* sig_cc,\n+                                                            const VMRegPair* regs_cc,\n+                                                            const GrowableArray<SigEntry>* sig_cc_ro,\n+                                                            const VMRegPair* regs_cc_ro,\n+                                                            AdapterFingerPrint* fingerprint,\n+                                                            AdapterBlob*& new_adapter,\n+                                                            bool allocate_code_blob) {\n@@ -977,2 +1239,1 @@\n-\n-  gen_i2c_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs);\n+  gen_i2c_adapter(masm, comp_args_on_stack, sig, regs);\n@@ -991,4 +1252,1 @@\n-  Label ok;\n-  Register holder = rax;\n-  Register receiver = j_rarg0;\n-  Register temp = rbx;\n+  gen_inline_cache_check(masm, skip_fixup);\n@@ -997,6 +1255,3 @@\n-  {\n-    __ load_klass(temp, receiver, rscratch1);\n-    __ cmpptr(temp, Address(holder, CompiledICHolder::holder_klass_offset()));\n-    __ movptr(rbx, Address(holder, CompiledICHolder::holder_metadata_offset()));\n-    __ jcc(Assembler::equal, ok);\n-    __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+  OopMapSet* oop_maps = new OopMapSet();\n+  int frame_complete = CodeOffsets::frame_never_safe;\n+  int frame_size_in_words = 0;\n@@ -1004,7 +1259,5 @@\n-    __ bind(ok);\n-    \/\/ Method might have been compiled since the call site was patched to\n-    \/\/ interpreted if that is the case treat it as a miss so we can get\n-    \/\/ the call site corrected.\n-    __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), NULL_WORD);\n-    __ jcc(Assembler::equal, skip_fixup);\n-    __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+  \/\/ Scalarized c2i adapter with non-scalarized receiver (i.e., don't pack receiver)\n+  address c2i_inline_ro_entry = __ pc();\n+  if (regs_cc != regs_cc_ro) {\n+    gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);\n+    skip_fixup.reset();\n@@ -1013,0 +1266,1 @@\n+  \/\/ Scalarized c2i adapter\n@@ -1041,1 +1295,14 @@\n-  gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);\n+  gen_c2i_adapter(masm, sig_cc, regs_cc, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, true);\n+\n+  address c2i_unverified_inline_entry = c2i_unverified_entry;\n+\n+  \/\/ Non-scalarized c2i adapter\n+  address c2i_inline_entry = c2i_entry;\n+  if (regs != regs_cc) {\n+    Label inline_entry_skip_fixup;\n+    c2i_unverified_inline_entry = __ pc();\n+    gen_inline_cache_check(masm, inline_entry_skip_fixup);\n+\n+    c2i_inline_entry = __ pc();\n+    gen_c2i_adapter(masm, sig, regs, inline_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);\n+  }\n@@ -1044,1 +1311,9 @@\n-  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+\n+  \/\/ The c2i adapters might safepoint and trigger a GC. The caller must make sure that\n+  \/\/ the GC knows about the location of oop argument locations passed to the c2i adapter.\n+  if (allocate_code_blob) {\n+    bool caller_must_gc_arguments = (regs != regs_cc);\n+    new_adapter = AdapterBlob::create(masm->code(), frame_complete, frame_size_in_words, oop_maps, caller_must_gc_arguments);\n+  }\n+\n+  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry, c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -1102,0 +1377,1 @@\n+      case T_PRIMITIVE_OBJECT:\n@@ -1916,0 +2192,1 @@\n+      case T_PRIMITIVE_OBJECT:\n@@ -2041,0 +2318,4 @@\n+      if (EnableValhalla) {\n+        \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+        __ andptr(swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+      }\n@@ -2102,0 +2383,1 @@\n+  case T_PRIMITIVE_OBJECT:           \/\/ Really a handle\n@@ -3591,0 +3873,110 @@\n+BufferedInlineTypeBlob* SharedRuntime::generate_buffered_inline_type_adapter(const InlineKlass* vk) {\n+  BufferBlob* buf = BufferBlob::create(\"inline types pack\/unpack\", 16 * K);\n+  CodeBuffer buffer(buf);\n+  short buffer_locs[20];\n+  buffer.insts()->initialize_shared_locs((relocInfo*)buffer_locs,\n+                                         sizeof(buffer_locs)\/sizeof(relocInfo));\n+\n+  MacroAssembler* masm = new MacroAssembler(&buffer);\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  int pack_fields_jobject_off = __ offset();\n+  \/\/ Resolve pre-allocated buffer from JNI handle.\n+  \/\/ We cannot do this in generate_call_stub() because it requires GC code to be initialized.\n+  __ movptr(rax, Address(r13, 0));\n+  __ resolve_jobject(rax \/* value *\/,\n+                     r15_thread \/* thread *\/,\n+                     r12 \/* tmp *\/);\n+  __ movptr(Address(r13, 0), rax);\n+\n+  int pack_fields_off = __ offset();\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_PRIMITIVE_OBJECT) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    VMReg r_1 = pair.first();\n+    VMReg r_2 = pair.second();\n+    Address to(rax, off);\n+    if (bt == T_FLOAT) {\n+      __ movflt(to, r_1->as_XMMRegister());\n+    } else if (bt == T_DOUBLE) {\n+      __ movdbl(to, r_1->as_XMMRegister());\n+    } else {\n+      Register val = r_1->as_Register();\n+      assert_different_registers(to.base(), val, r14, r13, rbx, rscratch1);\n+      if (is_reference_type(bt)) {\n+        __ store_heap_oop(to, val, r14, r13, rbx, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      } else {\n+        __ store_sized_value(to, r_1->as_Register(), type2aelembytes(bt));\n+      }\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+  __ ret(0);\n+\n+  int unpack_fields_off = __ offset();\n+\n+  Label skip;\n+  __ testptr(rax, rax);\n+  __ jcc(Assembler::zero, skip);\n+\n+  j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_PRIMITIVE_OBJECT) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    VMReg r_1 = pair.first();\n+    VMReg r_2 = pair.second();\n+    Address from(rax, off);\n+    if (bt == T_FLOAT) {\n+      __ movflt(r_1->as_XMMRegister(), from);\n+    } else if (bt == T_DOUBLE) {\n+      __ movdbl(r_1->as_XMMRegister(), from);\n+    } else if (bt == T_OBJECT || bt == T_ARRAY) {\n+      assert_different_registers(rax, r_1->as_Register());\n+      __ load_heap_oop(r_1->as_Register(), from);\n+    } else {\n+      assert(is_java_primitive(bt), \"unexpected basic type\");\n+      assert_different_registers(rax, r_1->as_Register());\n+      size_t size_in_bytes = type2aelembytes(bt);\n+      __ load_sized_value(r_1->as_Register(), from, size_in_bytes, bt != T_CHAR && bt != T_BOOLEAN);\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+  __ bind(skip);\n+  __ ret(0);\n+\n+  __ flush();\n+\n+  return BufferedInlineTypeBlob::create(&buffer, pack_fields_off, pack_fields_jobject_off, unpack_fields_off);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":516,"deletions":124,"binary":false,"changes":640,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"asm\/assembler.hpp\"\n@@ -38,0 +39,2 @@\n+#include \"utilities\/macros.hpp\"\n+#include \"vmreg_x86.inline.hpp\"\n@@ -320,5 +323,9 @@\n-  \/\/ T_OBJECT, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n-  __ movptr(c_rarg0, result);\n-  Label is_long, is_float, is_double, exit;\n-  __ movl(c_rarg1, result_type);\n-  __ cmpl(c_rarg1, T_OBJECT);\n+  \/\/ T_OBJECT, T_PRIMITIVE_OBJECT, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n+  __ movptr(r13, result);\n+  Label is_long, is_float, is_double, check_prim, exit;\n+  __ movl(rbx, result_type);\n+  __ cmpl(rbx, T_OBJECT);\n+  __ jcc(Assembler::equal, check_prim);\n+  __ cmpl(rbx, T_PRIMITIVE_OBJECT);\n+  __ jcc(Assembler::equal, check_prim);\n+  __ cmpl(rbx, T_LONG);\n@@ -326,3 +333,1 @@\n-  __ cmpl(c_rarg1, T_LONG);\n-  __ jcc(Assembler::equal, is_long);\n-  __ cmpl(c_rarg1, T_FLOAT);\n+  __ cmpl(rbx, T_FLOAT);\n@@ -330,1 +335,1 @@\n-  __ cmpl(c_rarg1, T_DOUBLE);\n+  __ cmpl(rbx, T_DOUBLE);\n@@ -334,1 +339,1 @@\n-  __ movl(Address(c_rarg0, 0), rax);\n+  __ movl(Address(r13, 0), rax);\n@@ -398,0 +403,13 @@\n+  __ BIND(check_prim);\n+  if (InlineTypeReturnedAsFields) {\n+    \/\/ Check for scalarized return value\n+    __ testptr(rax, 1);\n+    __ jcc(Assembler::zero, is_long);\n+    \/\/ Load pack handler address\n+    __ andptr(rax, -2);\n+    __ movptr(rax, Address(rax, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+    __ movptr(rbx, Address(rax, InlineKlass::pack_handler_jobject_offset()));\n+    \/\/ Call pack handler to initialize the buffer\n+    __ call(rbx);\n+    __ jmp(exit);\n+  }\n@@ -399,1 +417,1 @@\n-  __ movq(Address(c_rarg0, 0), rax);\n+  __ movq(Address(r13, 0), rax);\n@@ -403,1 +421,1 @@\n-  __ movflt(Address(c_rarg0, 0), xmm0);\n+  __ movflt(Address(r13, 0), xmm0);\n@@ -407,1 +425,1 @@\n-  __ movdbl(Address(c_rarg0, 0), xmm0);\n+  __ movdbl(Address(r13, 0), xmm0);\n@@ -5349,0 +5367,10 @@\n+  \/\/ Generate these first because they are called from other stubs\n+  if (InlineTypeReturnedAsFields) {\n+    StubRoutines::_load_inline_type_fields_in_regs =\n+      generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs),\n+                                 \"load_inline_type_fields_in_regs\", false);\n+    StubRoutines::_store_inline_type_fields_to_buf =\n+      generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf),\n+                                 \"store_inline_type_fields_to_buf\", true);\n+  }\n+\n@@ -5402,0 +5430,144 @@\n+\/\/ Call here from the interpreter or compiled code to either load\n+\/\/ multiple returned values from the inline type instance being\n+\/\/ returned to registers or to store returned values to a newly\n+\/\/ allocated inline type instance.\n+\/\/ Register is a class, but it would be assigned numerical value.\n+\/\/ \"0\" is assigned for xmm0. Thus we need to ignore -Wnonnull.\n+PRAGMA_DIAG_PUSH\n+PRAGMA_NONNULL_IGNORED\n+address StubGenerator::generate_return_value_stub(address destination, const char* name, bool has_res) {\n+  \/\/ We need to save all registers the calling convention may use so\n+  \/\/ the runtime calls read or update those registers. This needs to\n+  \/\/ be in sync with SharedRuntime::java_return_convention().\n+  enum layout {\n+    pad_off = frame::arg_reg_save_area_bytes\/BytesPerInt, pad_off_2,\n+    rax_off, rax_off_2,\n+    j_rarg5_off, j_rarg5_2,\n+    j_rarg4_off, j_rarg4_2,\n+    j_rarg3_off, j_rarg3_2,\n+    j_rarg2_off, j_rarg2_2,\n+    j_rarg1_off, j_rarg1_2,\n+    j_rarg0_off, j_rarg0_2,\n+    j_farg0_off, j_farg0_2,\n+    j_farg1_off, j_farg1_2,\n+    j_farg2_off, j_farg2_2,\n+    j_farg3_off, j_farg3_2,\n+    j_farg4_off, j_farg4_2,\n+    j_farg5_off, j_farg5_2,\n+    j_farg6_off, j_farg6_2,\n+    j_farg7_off, j_farg7_2,\n+    rbp_off, rbp_off_2,\n+    return_off, return_off_2,\n+\n+    framesize\n+  };\n+\n+  CodeBuffer buffer(name, 1000, 512);\n+  MacroAssembler* _masm = new MacroAssembler(&buffer);\n+\n+  int frame_size_in_bytes = align_up(framesize*BytesPerInt, 16);\n+  assert(frame_size_in_bytes == framesize*BytesPerInt, \"misaligned\");\n+  int frame_size_in_slots = frame_size_in_bytes \/ BytesPerInt;\n+  int frame_size_in_words = frame_size_in_bytes \/ wordSize;\n+\n+  OopMapSet *oop_maps = new OopMapSet();\n+  OopMap* map = new OopMap(frame_size_in_slots, 0);\n+\n+  map->set_callee_saved(VMRegImpl::stack2reg(rax_off), rax->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+  map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+  int start = __ offset();\n+\n+  __ subptr(rsp, frame_size_in_bytes - 8 \/* return address*\/);\n+\n+  __ movptr(Address(rsp, rbp_off * BytesPerInt), rbp);\n+  __ movdbl(Address(rsp, j_farg7_off * BytesPerInt), j_farg7);\n+  __ movdbl(Address(rsp, j_farg6_off * BytesPerInt), j_farg6);\n+  __ movdbl(Address(rsp, j_farg5_off * BytesPerInt), j_farg5);\n+  __ movdbl(Address(rsp, j_farg4_off * BytesPerInt), j_farg4);\n+  __ movdbl(Address(rsp, j_farg3_off * BytesPerInt), j_farg3);\n+  __ movdbl(Address(rsp, j_farg2_off * BytesPerInt), j_farg2);\n+  __ movdbl(Address(rsp, j_farg1_off * BytesPerInt), j_farg1);\n+  __ movdbl(Address(rsp, j_farg0_off * BytesPerInt), j_farg0);\n+\n+  __ movptr(Address(rsp, j_rarg0_off * BytesPerInt), j_rarg0);\n+  __ movptr(Address(rsp, j_rarg1_off * BytesPerInt), j_rarg1);\n+  __ movptr(Address(rsp, j_rarg2_off * BytesPerInt), j_rarg2);\n+  __ movptr(Address(rsp, j_rarg3_off * BytesPerInt), j_rarg3);\n+  __ movptr(Address(rsp, j_rarg4_off * BytesPerInt), j_rarg4);\n+  __ movptr(Address(rsp, j_rarg5_off * BytesPerInt), j_rarg5);\n+  __ movptr(Address(rsp, rax_off * BytesPerInt), rax);\n+\n+  int frame_complete = __ offset();\n+\n+  __ set_last_Java_frame(noreg, noreg, NULL, rscratch1);\n+\n+  __ mov(c_rarg0, r15_thread);\n+  __ mov(c_rarg1, rax);\n+\n+  __ call(RuntimeAddress(destination));\n+\n+  \/\/ Set an oopmap for the call site.\n+\n+  oop_maps->add_gc_map( __ offset() - start, map);\n+\n+  \/\/ clear last_Java_sp\n+  __ reset_last_Java_frame(false);\n+\n+  __ movptr(rbp, Address(rsp, rbp_off * BytesPerInt));\n+  __ movdbl(j_farg7, Address(rsp, j_farg7_off * BytesPerInt));\n+  __ movdbl(j_farg6, Address(rsp, j_farg6_off * BytesPerInt));\n+  __ movdbl(j_farg5, Address(rsp, j_farg5_off * BytesPerInt));\n+  __ movdbl(j_farg4, Address(rsp, j_farg4_off * BytesPerInt));\n+  __ movdbl(j_farg3, Address(rsp, j_farg3_off * BytesPerInt));\n+  __ movdbl(j_farg2, Address(rsp, j_farg2_off * BytesPerInt));\n+  __ movdbl(j_farg1, Address(rsp, j_farg1_off * BytesPerInt));\n+  __ movdbl(j_farg0, Address(rsp, j_farg0_off * BytesPerInt));\n+\n+  __ movptr(j_rarg0, Address(rsp, j_rarg0_off * BytesPerInt));\n+  __ movptr(j_rarg1, Address(rsp, j_rarg1_off * BytesPerInt));\n+  __ movptr(j_rarg2, Address(rsp, j_rarg2_off * BytesPerInt));\n+  __ movptr(j_rarg3, Address(rsp, j_rarg3_off * BytesPerInt));\n+  __ movptr(j_rarg4, Address(rsp, j_rarg4_off * BytesPerInt));\n+  __ movptr(j_rarg5, Address(rsp, j_rarg5_off * BytesPerInt));\n+  __ movptr(rax, Address(rsp, rax_off * BytesPerInt));\n+\n+  __ addptr(rsp, frame_size_in_bytes-8);\n+\n+  \/\/ check for pending exceptions\n+  Label pending;\n+  __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), (int32_t)NULL_WORD);\n+  __ jcc(Assembler::notEqual, pending);\n+\n+  if (has_res) {\n+    __ get_vm_result(rax, r15_thread);\n+  }\n+\n+  __ ret(0);\n+\n+  __ bind(pending);\n+\n+  __ movptr(rax, Address(r15_thread, Thread::pending_exception_offset()));\n+  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+  \/\/ -------------\n+  \/\/ make sure all code is generated\n+  _masm->flush();\n+\n+  RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &buffer, frame_complete, frame_size_in_words, oop_maps, false);\n+  return stub->entry_point();\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":185,"deletions":13,"binary":false,"changes":198,"status":"modified"},{"patch":"@@ -486,0 +486,3 @@\n+  \/\/ interpreter or compiled code marshalling registers to\/from inline type instance\n+  address generate_return_value_stub(address destination, const char* name, bool has_res);\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2371,0 +2371,8 @@\n+  \/\/ Check for flat inline type array -> return -1\n+  __ testl(rax_lh, Klass::_lh_array_tag_flat_value_bit_inplace);\n+  __ jcc(Assembler::notZero, L_failed);\n+\n+  \/\/ Check for null-free (non-flat) inline type array -> handle as object array\n+  __ testl(rax_lh, Klass::_lh_null_free_array_bit_inplace);\n+  __ jcc(Assembler::notZero, L_objArray);\n+\n@@ -2380,2 +2388,4 @@\n-    __ cmpl(rax_lh, (Klass::_lh_array_tag_type_value << Klass::_lh_array_tag_shift));\n-    __ jcc(Assembler::greaterEqual, L);\n+    __ movl(rklass_tmp, rax_lh);\n+    __ sarl(rklass_tmp, Klass::_lh_array_tag_shift);\n+    __ cmpl(rklass_tmp, Klass::_lh_array_tag_type_value);\n+    __ jcc(Assembler::equal, L);\n@@ -2489,0 +2499,1 @@\n+    \/\/ This check also fails for flat\/null-free arrays which are not supported.\n@@ -2492,0 +2503,13 @@\n+#ifdef ASSERT\n+    {\n+      BLOCK_COMMENT(\"assert not null-free array {\");\n+      Label L;\n+      __ movl(rklass_tmp, Address(rax, lh_offset));\n+      __ testl(rklass_tmp, Klass::_lh_null_free_array_bit_inplace);\n+      __ jcc(Assembler::zero, L);\n+      __ stop(\"unexpected null-free array\");\n+      __ bind(L);\n+      BLOCK_COMMENT(\"} assert not null-free array\");\n+    }\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_arraycopy.cpp","additions":26,"deletions":2,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -63,1 +64,1 @@\n-int TemplateInterpreter::InterpreterCodeSize = JVMCI_ONLY(268) NOT_JVMCI(256) * 1024;\n+int TemplateInterpreter::InterpreterCodeSize = JVMCI_ONLY(280) NOT_JVMCI(268) * 1024;\n@@ -211,0 +212,4 @@\n+  if (state == atos && InlineTypeReturnedAsFields) {\n+    __ store_inline_type_fields_to_buf(NULL);\n+  }\n+\n@@ -353,0 +358,1 @@\n+  case T_PRIMITIVE_OBJECT: \/\/ fall through (inline types are handled with oops)\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -99,0 +100,1 @@\n+    case T_PRIMITIVE_OBJECT:\n@@ -155,0 +157,1 @@\n+    case T_PRIMITIVE_OBJECT:\n@@ -292,1 +295,1 @@\n-                                 CodeStub* stub)\n+                                 CodeStub* stub, bool need_null_check)\n@@ -308,0 +311,1 @@\n+  , _need_null_check(need_null_check)\n@@ -335,0 +339,1 @@\n+  , _need_null_check(true)\n@@ -344,0 +349,31 @@\n+LIR_OpFlattenedArrayCheck::LIR_OpFlattenedArrayCheck(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub)\n+  : LIR_Op(lir_flattened_array_check, LIR_OprFact::illegalOpr, NULL)\n+  , _array(array)\n+  , _value(value)\n+  , _tmp(tmp)\n+  , _stub(stub) {}\n+\n+\n+LIR_OpNullFreeArrayCheck::LIR_OpNullFreeArrayCheck(LIR_Opr array, LIR_Opr tmp)\n+  : LIR_Op(lir_null_free_array_check, LIR_OprFact::illegalOpr, NULL)\n+  , _array(array)\n+  , _tmp(tmp) {}\n+\n+\n+LIR_OpSubstitutabilityCheck::LIR_OpSubstitutabilityCheck(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,\n+                                                         LIR_Opr tmp1, LIR_Opr tmp2,\n+                                                         ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,\n+                                                         CodeEmitInfo* info, CodeStub* stub)\n+  : LIR_Op(lir_substitutability_check, result, info)\n+  , _left(left)\n+  , _right(right)\n+  , _equal_result(equal_result)\n+  , _not_equal_result(not_equal_result)\n+  , _tmp1(tmp1)\n+  , _tmp2(tmp2)\n+  , _left_klass(left_klass)\n+  , _right_klass(right_klass)\n+  , _left_klass_op(left_klass_op)\n+  , _right_klass_op(right_klass_op)\n+  , _stub(stub) {}\n+\n@@ -410,0 +446,1 @@\n+    case lir_check_orig_pc:            \/\/ result and info always invalid\n@@ -804,0 +841,1 @@\n+      do_stub(opLock->_throw_imse_stub);\n@@ -840,0 +878,45 @@\n+\/\/ LIR_OpFlattenedArrayCheck\n+    case lir_flattened_array_check: {\n+      assert(op->as_OpFlattenedArrayCheck() != NULL, \"must be\");\n+      LIR_OpFlattenedArrayCheck* opFlattenedArrayCheck = (LIR_OpFlattenedArrayCheck*)op;\n+\n+      if (opFlattenedArrayCheck->_array->is_valid()) do_input(opFlattenedArrayCheck->_array);\n+      if (opFlattenedArrayCheck->_value->is_valid()) do_input(opFlattenedArrayCheck->_value);\n+      if (opFlattenedArrayCheck->_tmp->is_valid())   do_temp(opFlattenedArrayCheck->_tmp);\n+                                                     do_stub(opFlattenedArrayCheck->_stub);\n+\n+      break;\n+    }\n+\n+\/\/ LIR_OpNullFreeArrayCheck\n+    case lir_null_free_array_check: {\n+      assert(op->as_OpNullFreeArrayCheck() != NULL, \"must be\");\n+      LIR_OpNullFreeArrayCheck* opNullFreeArrayCheck = (LIR_OpNullFreeArrayCheck*)op;\n+\n+      if (opNullFreeArrayCheck->_array->is_valid()) do_input(opNullFreeArrayCheck->_array);\n+      if (opNullFreeArrayCheck->_tmp->is_valid())   do_temp(opNullFreeArrayCheck->_tmp);\n+      break;\n+    }\n+\n+\/\/ LIR_OpSubstitutabilityCheck\n+    case lir_substitutability_check: {\n+      assert(op->as_OpSubstitutabilityCheck() != NULL, \"must be\");\n+      LIR_OpSubstitutabilityCheck* opSubstitutabilityCheck = (LIR_OpSubstitutabilityCheck*)op;\n+                                                                do_input(opSubstitutabilityCheck->_left);\n+                                                                do_temp (opSubstitutabilityCheck->_left);\n+                                                                do_input(opSubstitutabilityCheck->_right);\n+                                                                do_temp (opSubstitutabilityCheck->_right);\n+                                                                do_input(opSubstitutabilityCheck->_equal_result);\n+                                                                do_temp (opSubstitutabilityCheck->_equal_result);\n+                                                                do_input(opSubstitutabilityCheck->_not_equal_result);\n+                                                                do_temp (opSubstitutabilityCheck->_not_equal_result);\n+      if (opSubstitutabilityCheck->_tmp1->is_valid())           do_temp(opSubstitutabilityCheck->_tmp1);\n+      if (opSubstitutabilityCheck->_tmp2->is_valid())           do_temp(opSubstitutabilityCheck->_tmp2);\n+      if (opSubstitutabilityCheck->_left_klass_op->is_valid())  do_temp(opSubstitutabilityCheck->_left_klass_op);\n+      if (opSubstitutabilityCheck->_right_klass_op->is_valid()) do_temp(opSubstitutabilityCheck->_right_klass_op);\n+      if (opSubstitutabilityCheck->_result->is_valid())         do_output(opSubstitutabilityCheck->_result);\n+                                                                do_info(opSubstitutabilityCheck->_info);\n+                                                                do_stub(opSubstitutabilityCheck->_stub);\n+      break;\n+    }\n+\n@@ -916,1 +999,12 @@\n-  default:\n+\n+    \/\/ LIR_OpProfileInlineType:\n+    case lir_profile_inline_type: {\n+      assert(op->as_OpProfileInlineType() != NULL, \"must be\");\n+      LIR_OpProfileInlineType* opProfileInlineType = (LIR_OpProfileInlineType*)op;\n+\n+      do_input(opProfileInlineType->_mdp); do_temp(opProfileInlineType->_mdp);\n+      do_input(opProfileInlineType->_obj);\n+      do_temp(opProfileInlineType->_tmp);\n+      break;\n+    }\n+default:\n@@ -989,0 +1083,28 @@\n+bool LIR_OpJavaCall::maybe_return_as_fields(ciInlineKlass** vk_ret) const {\n+  ciType* return_type = method()->return_type();\n+  if (InlineTypeReturnedAsFields) {\n+    if (return_type->is_inlinetype()) {\n+      ciInlineKlass* vk = return_type->as_inline_klass();\n+      if (vk->can_be_returned_as_fields()) {\n+        if (vk_ret != NULL) {\n+          *vk_ret = vk;\n+        }\n+        return true;\n+      }\n+    } else if (return_type->is_instance_klass() &&\n+               (method()->is_method_handle_intrinsic() ||\n+                (!return_type->is_loaded() && !method()->holder()->is_loaded()))) {\n+      \/\/ An inline type might be returned from the call but we don't know its type.\n+      \/\/ This can happen with method handle intrinsics or when both the return type\n+      \/\/ and the method holder are unloaded (and therefore the preload logic did not\n+      \/\/ get a chance to load the return type). If an inline type is returned, we\n+      \/\/ either get an oop to a buffer and nothing needs to be done or one of the\n+      \/\/ values being returned is the klass of the inline type (RAX on x64, with LSB\n+      \/\/ set to 1) and we need to allocate an inline type instance of that type and\n+      \/\/ initialize it with other values being returned (in other registers).\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -1049,0 +1171,18 @@\n+void LIR_OpFlattenedArrayCheck::emit_code(LIR_Assembler* masm) {\n+  masm->emit_opFlattenedArrayCheck(this);\n+  if (stub() != NULL) {\n+    masm->append_code_stub(stub());\n+  }\n+}\n+\n+void LIR_OpNullFreeArrayCheck::emit_code(LIR_Assembler* masm) {\n+  masm->emit_opNullFreeArrayCheck(this);\n+}\n+\n+void LIR_OpSubstitutabilityCheck::emit_code(LIR_Assembler* masm) {\n+  masm->emit_opSubstitutabilityCheck(this);\n+  if (stub() != NULL) {\n+    masm->append_code_stub(stub());\n+  }\n+}\n+\n@@ -1066,0 +1206,3 @@\n+  if (throw_imse_stub()) {\n+    masm->append_code_stub(throw_imse_stub());\n+  }\n@@ -1090,0 +1233,4 @@\n+void LIR_OpProfileInlineType::emit_code(LIR_Assembler* masm) {\n+  masm->emit_profile_inline_type(this);\n+}\n+\n@@ -1407,1 +1554,1 @@\n-void LIR_List::lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info) {\n+void LIR_List::lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info, CodeStub* throw_imse_stub) {\n@@ -1415,1 +1562,2 @@\n-                    info));\n+                    info,\n+                    throw_imse_stub));\n@@ -1440,1 +1588,4 @@\n-                          ciMethod* profiled_method, int profiled_bci) {\n+                          ciMethod* profiled_method, int profiled_bci, bool is_null_free) {\n+  \/\/ If klass is non-nullable,  LIRGenerator::do_CheckCast has already performed null-check\n+  \/\/ on the object.\n+  bool need_null_check = !is_null_free;\n@@ -1442,1 +1593,2 @@\n-                                           tmp1, tmp2, tmp3, fast_check, info_for_exception, info_for_patch, stub);\n+                                           tmp1, tmp2, tmp3, fast_check, info_for_exception, info_for_patch, stub,\n+                                           need_null_check);\n@@ -1464,0 +1616,1 @@\n+  \/\/ FIXME -- if the types of the array and\/or the object are known statically, we can avoid loading the klass\n@@ -1485,0 +1638,21 @@\n+void LIR_List::check_flattened_array(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub) {\n+  LIR_OpFlattenedArrayCheck* c = new LIR_OpFlattenedArrayCheck(array, value, tmp, stub);\n+  append(c);\n+}\n+\n+void LIR_List::check_null_free_array(LIR_Opr array, LIR_Opr tmp) {\n+  LIR_OpNullFreeArrayCheck* c = new LIR_OpNullFreeArrayCheck(array, tmp);\n+  append(c);\n+}\n+\n+void LIR_List::substitutability_check(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,\n+                                      LIR_Opr tmp1, LIR_Opr tmp2,\n+                                      ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,\n+                                      CodeEmitInfo* info, CodeStub* stub) {\n+  LIR_OpSubstitutabilityCheck* c = new LIR_OpSubstitutabilityCheck(result, left, right, equal_result, not_equal_result,\n+                                                                   tmp1, tmp2,\n+                                                                   left_klass, right_klass, left_klass_op, right_klass_op,\n+                                                                   info, stub);\n+  append(c);\n+}\n+\n@@ -1701,0 +1875,1 @@\n+     case lir_check_orig_pc:         s = \"check_orig_pc\"; break;\n@@ -1767,0 +1942,6 @@\n+     \/\/ LIR_OpFlattenedArrayCheck\n+     case lir_flattened_array_check: s = \"flattened_array_check\"; break;\n+     \/\/ LIR_OpNullFreeArrayCheck\n+     case lir_null_free_array_check: s = \"null_free_array_check\"; break;\n+     \/\/ LIR_OpSubstitutabilityCheck\n+     case lir_substitutability_check: s = \"substitutability_check\"; break;\n@@ -1775,0 +1956,2 @@\n+     \/\/ LIR_OpProfileInlineType\n+     case lir_profile_inline_type:   s = \"profile_inline_type\"; break;\n@@ -2006,0 +2189,38 @@\n+void LIR_OpFlattenedArrayCheck::print_instr(outputStream* out) const {\n+  array()->print(out);                   out->print(\" \");\n+  value()->print(out);                   out->print(\" \");\n+  tmp()->print(out);                     out->print(\" \");\n+  if (stub() != NULL) {\n+    out->print(\"[label:\" INTPTR_FORMAT \"]\", p2i(stub()->entry()));\n+  }\n+}\n+\n+void LIR_OpNullFreeArrayCheck::print_instr(outputStream* out) const {\n+  array()->print(out);                   out->print(\" \");\n+  tmp()->print(out);                     out->print(\" \");\n+}\n+\n+void LIR_OpSubstitutabilityCheck::print_instr(outputStream* out) const {\n+  result_opr()->print(out);              out->print(\" \");\n+  left()->print(out);                    out->print(\" \");\n+  right()->print(out);                   out->print(\" \");\n+  equal_result()->print(out);            out->print(\" \");\n+  not_equal_result()->print(out);        out->print(\" \");\n+  tmp1()->print(out);                    out->print(\" \");\n+  tmp2()->print(out);                    out->print(\" \");\n+  if (left_klass() == NULL) {\n+    out->print(\"unknown \");\n+  } else {\n+    left_klass()->print(out);            out->print(\" \");\n+  }\n+  if (right_klass() == NULL) {\n+    out->print(\"unknown \");\n+  } else {\n+    right_klass()->print(out);           out->print(\" \");\n+  }\n+  left_klass_op()->print(out);           out->print(\" \");\n+  right_klass_op()->print(out);          out->print(\" \");\n+  if (stub() != NULL) {\n+    out->print(\"[label:\" INTPTR_FORMAT \"]\", p2i(stub()->entry()));\n+  }\n+}\n@@ -2081,0 +2302,8 @@\n+\/\/ LIR_OpProfileInlineType\n+void LIR_OpProfileInlineType::print_instr(outputStream* out) const {\n+  out->print(\" flag = %x \", flag());\n+  mdp()->print(out);          out->print(\" \");\n+  obj()->print(out);          out->print(\" \");\n+  tmp()->print(out);          out->print(\" \");\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":235,"deletions":6,"binary":false,"changes":241,"status":"modified"},{"patch":"@@ -34,0 +34,2 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -214,0 +216,2 @@\n+  assert(!_gen->in_conditional_code(), \"LIRItem cannot be loaded in conditional code\");\n+\n@@ -609,1 +613,2 @@\n-void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n+void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no,\n+                                 CodeEmitInfo* info_for_exception, CodeEmitInfo* info, CodeStub* throw_imse_stub) {\n@@ -612,1 +617,1 @@\n-  CodeStub* slow_path = new MonitorEnterStub(object, lock, info);\n+  CodeStub* slow_path = new MonitorEnterStub(object, lock, info, throw_imse_stub, scratch);\n@@ -615,1 +620,1 @@\n-  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception);\n+  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception, throw_imse_stub);\n@@ -639,4 +644,9 @@\n-void LIRGenerator::new_instance(LIR_Opr dst, ciInstanceKlass* klass, bool is_unresolved, LIR_Opr scratch1, LIR_Opr scratch2, LIR_Opr scratch3, LIR_Opr scratch4, LIR_Opr klass_reg, CodeEmitInfo* info) {\n-  klass2reg_with_patching(klass_reg, klass, info, is_unresolved);\n-  \/\/ If klass is not loaded we do not know if the klass has finalizers:\n-  if (UseFastNewInstance && klass->is_loaded()\n+void LIRGenerator::new_instance(LIR_Opr dst, ciInstanceKlass* klass, bool is_unresolved, bool allow_inline, LIR_Opr scratch1, LIR_Opr scratch2, LIR_Opr scratch3, LIR_Opr scratch4, LIR_Opr klass_reg, CodeEmitInfo* info) {\n+  if (allow_inline) {\n+    assert(!is_unresolved && klass->is_loaded(), \"inline type klass should be resolved\");\n+    __ metadata2reg(klass->constant_encoding(), klass_reg);\n+  } else {\n+    klass2reg_with_patching(klass_reg, klass, info, is_unresolved);\n+  }\n+  \/\/ If klass is not loaded we do not know if the klass has finalizers or is an unexpected inline klass\n+  if (UseFastNewInstance && klass->is_loaded() && (allow_inline || !klass->is_inlinetype())\n@@ -656,2 +666,2 @@\n-    CodeStub* slow_path = new NewInstanceStub(klass_reg, dst, klass, info, Runtime1::new_instance_id);\n-    __ branch(lir_cond_always, slow_path);\n+    CodeStub* slow_path = new NewInstanceStub(klass_reg, dst, klass, info, allow_inline ? Runtime1::new_instance_id : Runtime1::new_instance_no_inline_id);\n+    __ jump(slow_path);\n@@ -757,0 +767,10 @@\n+  if (!src->is_loaded_flattened_array() && !dst->is_loaded_flattened_array()) {\n+    flags &= ~LIR_OpArrayCopy::always_slow_path;\n+  }\n+  if (!src->maybe_flattened_array()) {\n+    flags &= ~LIR_OpArrayCopy::src_inlinetype_check;\n+  }\n+  if (!dst->maybe_flattened_array() && !dst->maybe_null_free_array()) {\n+    flags &= ~LIR_OpArrayCopy::dst_inlinetype_check;\n+  }\n+\n@@ -1561,2 +1581,4 @@\n-  _constants.append(c);\n-  _reg_for_constants.append(result);\n+  if (!in_conditional_code()) {\n+    _constants.append(c);\n+    _reg_for_constants.append(result);\n+  }\n@@ -1566,0 +1588,6 @@\n+void LIRGenerator::set_in_conditional_code(bool v) {\n+  assert(v != _in_conditional_code, \"must change state\");\n+  _in_conditional_code = v;\n+}\n+\n+\n@@ -1657,0 +1685,5 @@\n+  if (!inline_type_field_access_prolog(x)) {\n+    \/\/ Field store will always deopt due to unloaded field or holder klass\n+    return;\n+  }\n+\n@@ -1678,0 +1711,173 @@\n+\/\/ FIXME -- I can't find any other way to pass an address to access_load_at().\n+class TempResolvedAddress: public Instruction {\n+ public:\n+  TempResolvedAddress(ValueType* type, LIR_Opr addr) : Instruction(type) {\n+    set_operand(addr);\n+  }\n+  virtual void input_values_do(ValueVisitor*) {}\n+  virtual void visit(InstructionVisitor* v)   {}\n+  virtual const char* name() const  { return \"TempResolvedAddress\"; }\n+};\n+\n+LIR_Opr LIRGenerator::get_and_load_element_address(LIRItem& array, LIRItem& index) {\n+  ciType* array_type = array.value()->declared_type();\n+  ciFlatArrayKlass* flat_array_klass = array_type->as_flat_array_klass();\n+  assert(flat_array_klass->is_loaded(), \"must be\");\n+\n+  int array_header_size = flat_array_klass->array_header_in_bytes();\n+  int shift = flat_array_klass->log2_element_size();\n+\n+#ifndef _LP64\n+  LIR_Opr index_op = new_register(T_INT);\n+  \/\/ FIXME -- on 32-bit, the shift below can overflow, so we need to check that\n+  \/\/ the top (shift+1) bits of index_op must be zero, or\n+  \/\/ else throw ArrayIndexOutOfBoundsException\n+  if (index.result()->is_constant()) {\n+    jint const_index = index.result()->as_jint();\n+    __ move(LIR_OprFact::intConst(const_index << shift), index_op);\n+  } else {\n+    __ shift_left(index_op, shift, index.result());\n+  }\n+#else\n+  LIR_Opr index_op = new_register(T_LONG);\n+  if (index.result()->is_constant()) {\n+    jint const_index = index.result()->as_jint();\n+    __ move(LIR_OprFact::longConst(const_index << shift), index_op);\n+  } else {\n+    __ convert(Bytecodes::_i2l, index.result(), index_op);\n+    \/\/ Need to shift manually, as LIR_Address can scale only up to 3.\n+    __ shift_left(index_op, shift, index_op);\n+  }\n+#endif\n+\n+  LIR_Opr elm_op = new_pointer_register();\n+  LIR_Address* elm_address = generate_address(array.result(), index_op, 0, array_header_size, T_ADDRESS);\n+  __ leal(LIR_OprFact::address(elm_address), elm_op);\n+  return elm_op;\n+}\n+\n+void LIRGenerator::access_sub_element(LIRItem& array, LIRItem& index, LIR_Opr& result, ciField* field, int sub_offset) {\n+  assert(field != NULL, \"Need a subelement type specified\");\n+\n+  \/\/ Find the starting address of the source (inside the array)\n+  LIR_Opr elm_op = get_and_load_element_address(array, index);\n+\n+  BasicType subelt_type = field->type()->basic_type();\n+  TempResolvedAddress* elm_resolved_addr = new TempResolvedAddress(as_ValueType(subelt_type), elm_op);\n+  LIRItem elm_item(elm_resolved_addr, this);\n+\n+  DecoratorSet decorators = IN_HEAP;\n+  access_load_at(decorators, subelt_type,\n+                     elm_item, LIR_OprFact::intConst(sub_offset), result,\n+                     NULL, NULL);\n+\n+  if (field->is_null_free()) {\n+    assert(field->type()->is_loaded(), \"Must be\");\n+    assert(field->type()->is_inlinetype(), \"Must be if loaded\");\n+    assert(field->type()->as_inline_klass()->is_initialized(), \"Must be\");\n+    LabelObj* L_end = new LabelObj();\n+    __ cmp(lir_cond_notEqual, result, LIR_OprFact::oopConst(NULL));\n+    __ branch(lir_cond_notEqual, L_end->label());\n+    set_in_conditional_code(true);\n+    Constant* default_value = new Constant(new InstanceConstant(field->type()->as_inline_klass()->default_instance()));\n+    if (default_value->is_pinned()) {\n+      __ move(LIR_OprFact::value_type(default_value->type()), result);\n+    } else {\n+      __ move(load_constant(default_value), result);\n+    }\n+    __ branch_destination(L_end->label());\n+    set_in_conditional_code(false);\n+  }\n+}\n+\n+void LIRGenerator::access_flattened_array(bool is_load, LIRItem& array, LIRItem& index, LIRItem& obj_item,\n+                                          ciField* field, int sub_offset) {\n+  assert(sub_offset == 0 || field != NULL, \"Sanity check\");\n+\n+  \/\/ Find the starting address of the source (inside the array)\n+  LIR_Opr elm_op = get_and_load_element_address(array, index);\n+\n+  ciInlineKlass* elem_klass = NULL;\n+  if (field != NULL) {\n+    elem_klass = field->type()->as_inline_klass();\n+  } else {\n+    elem_klass = array.value()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+  }\n+  for (int i = 0; i < elem_klass->nof_nonstatic_fields(); i++) {\n+    ciField* inner_field = elem_klass->nonstatic_field_at(i);\n+    assert(!inner_field->is_flattened(), \"flattened fields must have been expanded\");\n+    int obj_offset = inner_field->offset();\n+    int elm_offset = obj_offset - elem_klass->first_field_offset() + sub_offset; \/\/ object header is not stored in array.\n+    BasicType field_type = inner_field->type()->basic_type();\n+\n+    \/\/ Types which are smaller than int are still passed in an int register.\n+    BasicType reg_type = field_type;\n+    switch (reg_type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+    case T_SHORT:\n+    case T_CHAR:\n+      reg_type = T_INT;\n+      break;\n+    default:\n+      break;\n+    }\n+\n+    LIR_Opr temp = new_register(reg_type);\n+    TempResolvedAddress* elm_resolved_addr = new TempResolvedAddress(as_ValueType(field_type), elm_op);\n+    LIRItem elm_item(elm_resolved_addr, this);\n+\n+    DecoratorSet decorators = IN_HEAP;\n+    if (is_load) {\n+      access_load_at(decorators, field_type,\n+                     elm_item, LIR_OprFact::intConst(elm_offset), temp,\n+                     NULL, NULL);\n+      access_store_at(decorators, field_type,\n+                      obj_item, LIR_OprFact::intConst(obj_offset), temp,\n+                      NULL, NULL);\n+    } else {\n+      access_load_at(decorators, field_type,\n+                     obj_item, LIR_OprFact::intConst(obj_offset), temp,\n+                     NULL, NULL);\n+      access_store_at(decorators, field_type,\n+                      elm_item, LIR_OprFact::intConst(elm_offset), temp,\n+                      NULL, NULL);\n+    }\n+  }\n+}\n+\n+void LIRGenerator::check_flattened_array(LIR_Opr array, LIR_Opr value, CodeStub* slow_path) {\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_flattened_array(array, value, tmp, slow_path);\n+}\n+\n+void LIRGenerator::check_null_free_array(LIRItem& array, LIRItem& value, CodeEmitInfo* info) {\n+  LabelObj* L_end = new LabelObj();\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_null_free_array(array.result(), tmp);\n+  __ branch(lir_cond_equal, L_end->label());\n+  __ null_check(value.result(), info);\n+  __ branch_destination(L_end->label());\n+}\n+\n+bool LIRGenerator::needs_flattened_array_store_check(StoreIndexed* x) {\n+  if (x->elt_type() == T_OBJECT && x->array()->maybe_flattened_array()) {\n+    ciType* type = x->value()->declared_type();\n+    if (type != NULL && type->is_klass()) {\n+      ciKlass* klass = type->as_klass();\n+      if (!klass->can_be_inline_klass() || (klass->is_inlinetype() && !klass->as_inline_klass()->flatten_array())) {\n+        \/\/ This is known to be a non-flattened object. If the array is flattened,\n+        \/\/ it will be caught by the code generated by array_store_check().\n+        return false;\n+      }\n+    }\n+    \/\/ We're not 100% sure, so let's do the flattened_array_store_check.\n+    return true;\n+  }\n+  return false;\n+}\n+\n+bool LIRGenerator::needs_null_free_array_store_check(StoreIndexed* x) {\n+  return x->elt_type() == T_OBJECT && x->array()->maybe_null_free_array();\n+}\n+\n@@ -1680,0 +1886,2 @@\n+  assert(x->elt_type() != T_ARRAY, \"never used\");\n+  bool is_loaded_flattened_array = x->array()->is_loaded_flattened_array();\n@@ -1683,3 +1891,3 @@\n-  bool needs_store_check = obj_store && (x->value()->as_Constant() == NULL ||\n-                                         !get_jobject_constant(x->value())->is_null_object() ||\n-                                         x->should_profile());\n+  bool needs_store_check = obj_store && !(is_loaded_flattened_array && x->is_exact_flattened_array_store()) &&\n+                                        (x->value()->as_Constant() == NULL ||\n+                                         !get_jobject_constant(x->value())->is_null_object());\n@@ -1698,2 +1906,3 @@\n-\n-  if (needs_store_check || x->check_boolean()) {\n+\n+  if (needs_store_check || x->check_boolean()\n+      || is_loaded_flattened_array || needs_flattened_array_store_check(x) || needs_null_free_array_store_check(x)) {\n@@ -1728,0 +1937,16 @@\n+  if (x->should_profile()) {\n+    if (x->array()->is_loaded_flattened_array()) {\n+      \/\/ No need to profile a store to a flattened array of known type. This can happen if\n+      \/\/ the type only became known after optimizations (for example, after the PhiSimplifier).\n+      x->set_should_profile(false);\n+    } else {\n+      ciMethodData* md = NULL;\n+      ciArrayLoadStoreData* load_store = NULL;\n+      profile_array_type(x, md, load_store);\n+      if (x->array()->maybe_null_free_array()) {\n+        profile_null_free_array(array, md, load_store);\n+      }\n+      profile_element_type(x->value(), md, load_store);\n+    }\n+  }\n+\n@@ -1730,1 +1955,1 @@\n-    array_store_check(value.result(), array.result(), store_check_info, x->profiled_method(), x->profiled_bci());\n+    array_store_check(value.result(), array.result(), store_check_info, NULL, -1);\n@@ -1733,4 +1958,21 @@\n-  DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n-  if (x->check_boolean()) {\n-    decorators |= C1_MASK_BOOLEAN;\n-  }\n+  if (is_loaded_flattened_array) {\n+    if (!x->value()->is_null_free()) {\n+      __ null_check(value.result(), new CodeEmitInfo(range_check_info));\n+    }\n+    \/\/ If array element is an empty inline type, no need to copy anything\n+    if (!x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass()->is_empty()) {\n+      access_flattened_array(false, array, index, value);\n+    }\n+  } else {\n+    StoreFlattenedArrayStub* slow_path = NULL;\n+\n+    if (needs_flattened_array_store_check(x)) {\n+      \/\/ Check if we indeed have a flattened array\n+      index.load_item();\n+      slow_path = new StoreFlattenedArrayStub(array.result(), index.result(), value.result(), state_for(x, x->state_before()));\n+      check_flattened_array(array.result(), value.result(), slow_path);\n+      set_in_conditional_code(true);\n+    } else if (needs_null_free_array_store_check(x)) {\n+      CodeEmitInfo* info = new CodeEmitInfo(range_check_info);\n+      check_null_free_array(array, value, info);\n+    }\n@@ -1738,2 +1980,12 @@\n-  access_store_at(decorators, x->elt_type(), array, index.result(), value.result(),\n-                  NULL, null_check_info);\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    if (x->check_boolean()) {\n+      decorators |= C1_MASK_BOOLEAN;\n+    }\n+\n+    access_store_at(decorators, x->elt_type(), array, index.result(), value.result(),\n+                    NULL, null_check_info);\n+    if (slow_path != NULL) {\n+      __ branch_destination(slow_path->continuation());\n+      set_in_conditional_code(false);\n+    }\n+  }\n@@ -1820,0 +2072,25 @@\n+bool LIRGenerator::inline_type_field_access_prolog(AccessField* x) {\n+  ciField* field = x->field();\n+  assert(!field->is_flattened(), \"Flattened field access should have been expanded\");\n+  if (!field->is_null_free()) {\n+    return true; \/\/ Not an inline type field\n+  }\n+  \/\/ Deoptimize if the access is non-static and requires patching (holder not loaded\n+  \/\/ or not accessible) because then we only have partial field information and the\n+  \/\/ field could be flattened (see ciField constructor).\n+  bool could_be_flat = !x->is_static() && x->needs_patching();\n+  \/\/ Deoptimize if we load from a static field with an uninitialized type because we\n+  \/\/ need to throw an exception if initialization of the type failed.\n+  bool not_initialized = x->is_static() && x->as_LoadField() != NULL &&\n+      !field->type()->as_instance_klass()->is_initialized();\n+  if (could_be_flat || not_initialized) {\n+    CodeEmitInfo* info = state_for(x, x->state_before());\n+    CodeStub* stub = new DeoptimizeStub(new CodeEmitInfo(info),\n+                                        Deoptimization::Reason_unloaded,\n+                                        Deoptimization::Action_make_not_entrant);\n+    __ jump(stub);\n+    return false;\n+  }\n+  return true;\n+}\n+\n@@ -1849,0 +2126,7 @@\n+  if (!inline_type_field_access_prolog(x)) {\n+    \/\/ Field load will always deopt due to unloaded field or holder klass\n+    LIR_Opr result = rlock_result(x, field_type);\n+    __ move(LIR_OprFact::oopConst(NULL), result);\n+    return;\n+  }\n+\n@@ -1877,0 +2161,33 @@\n+\n+  ciField* field = x->field();\n+  if (field->is_null_free()) {\n+    \/\/ Load from non-flattened inline type field requires\n+    \/\/ a null check to replace null with the default value.\n+    ciInstanceKlass* holder = field->holder();\n+    if (field->is_static() && holder->is_loaded()) {\n+      ciObject* val = holder->java_mirror()->field_value(field).as_object();\n+      if (!val->is_null_object()) {\n+        \/\/ Static field is initialized, we don't need to perform a null check.\n+        return;\n+      }\n+    }\n+    ciInlineKlass* inline_klass = field->type()->as_inline_klass();\n+    if (inline_klass->is_initialized()) {\n+      LabelObj* L_end = new LabelObj();\n+      __ cmp(lir_cond_notEqual, result, LIR_OprFact::oopConst(NULL));\n+      __ branch(lir_cond_notEqual, L_end->label());\n+      set_in_conditional_code(true);\n+      Constant* default_value = new Constant(new InstanceConstant(inline_klass->default_instance()));\n+      if (default_value->is_pinned()) {\n+        __ move(LIR_OprFact::value_type(default_value->type()), result);\n+      } else {\n+        __ move(load_constant(default_value), result);\n+      }\n+      __ branch_destination(L_end->label());\n+      set_in_conditional_code(false);\n+    } else {\n+      __ cmp(lir_cond_equal, result, LIR_OprFact::oopConst(NULL));\n+      __ branch(lir_cond_equal, new DeoptimizeStub(info, Deoptimization::Reason_uninitialized,\n+                                                         Deoptimization::Action_make_not_entrant));\n+    }\n+  }\n@@ -2021,1 +2338,68 @@\n-  DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+  ciMethodData* md = NULL;\n+  ciArrayLoadStoreData* load_store = NULL;\n+  if (x->should_profile()) {\n+    if (x->array()->is_loaded_flattened_array()) {\n+      \/\/ No need to profile a load from a flattened array of known type. This can happen if\n+      \/\/ the type only became known after optimizations (for example, after the PhiSimplifier).\n+      x->set_should_profile(false);\n+    } else {\n+      profile_array_type(x, md, load_store);\n+    }\n+  }\n+\n+  Value element;\n+  if (x->vt() != NULL) {\n+    assert(x->array()->is_loaded_flattened_array(), \"must be\");\n+    \/\/ Find the destination address (of the NewInlineTypeInstance).\n+    LIRItem obj_item(x->vt(), this);\n+\n+    access_flattened_array(true, array, index, obj_item,\n+                           x->delayed() == NULL ? 0 : x->delayed()->field(),\n+                           x->delayed() == NULL ? 0 : x->delayed()->offset());\n+    set_no_result(x);\n+  } else if (x->delayed() != NULL) {\n+    assert(x->array()->is_loaded_flattened_array(), \"must be\");\n+    LIR_Opr result = rlock_result(x, x->delayed()->field()->type()->basic_type());\n+    access_sub_element(array, index, result, x->delayed()->field(), x->delayed()->offset());\n+  } else if (x->array() != NULL && x->array()->is_loaded_flattened_array() &&\n+             x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass()->is_initialized() &&\n+             x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass()->is_empty()) {\n+    \/\/ Load the default instance instead of reading the element\n+    ciInlineKlass* elem_klass = x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+    LIR_Opr result = rlock_result(x, x->elt_type());\n+    assert(elem_klass->is_initialized(), \"Must be\");\n+    Constant* default_value = new Constant(new InstanceConstant(elem_klass->default_instance()));\n+    if (default_value->is_pinned()) {\n+      __ move(LIR_OprFact::value_type(default_value->type()), result);\n+    } else {\n+      __ move(load_constant(default_value), result);\n+    }\n+  } else {\n+    LIR_Opr result = rlock_result(x, x->elt_type());\n+    LoadFlattenedArrayStub* slow_path = NULL;\n+\n+    if (x->should_profile() && x->array()->maybe_null_free_array()) {\n+      profile_null_free_array(array, md, load_store);\n+    }\n+\n+    if (x->elt_type() == T_OBJECT && x->array()->maybe_flattened_array()) {\n+      assert(x->delayed() == NULL, \"Delayed LoadIndexed only apply to loaded_flattened_arrays\");\n+      index.load_item();\n+      \/\/ if we are loading from flattened array, load it using a runtime call\n+      slow_path = new LoadFlattenedArrayStub(array.result(), index.result(), result, state_for(x, x->state_before()));\n+      check_flattened_array(array.result(), LIR_OprFact::illegalOpr, slow_path);\n+      set_in_conditional_code(true);\n+    }\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    access_load_at(decorators, x->elt_type(),\n+                   array, index.result(), result,\n+                   NULL, null_check_info);\n+\n+    if (slow_path != NULL) {\n+      __ branch_destination(slow_path->continuation());\n+      set_in_conditional_code(false);\n+    }\n+\n+    element = x;\n+  }\n@@ -2023,4 +2407,3 @@\n-  LIR_Opr result = rlock_result(x, x->elt_type());\n-  access_load_at(decorators, x->elt_type(),\n-                 array, index.result(), result,\n-                 NULL, null_check_info);\n+  if (x->should_profile()) {\n+    profile_element_type(element, md, load_store);\n+  }\n@@ -2029,0 +2412,12 @@\n+void LIRGenerator::do_Deoptimize(Deoptimize* x) {\n+  \/\/ This happens only when a class X uses the withfield\/aconst_init bytecode\n+  \/\/ to refer to an inline class V, where V has not yet been loaded\/resolved.\n+  \/\/ This is not a common case. Let's just deoptimize.\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+  CodeStub* stub = new DeoptimizeStub(new CodeEmitInfo(info),\n+                                      Deoptimization::Reason_unloaded,\n+                                      Deoptimization::Action_make_not_entrant);\n+  __ jump(stub);\n+  LIR_Opr reg = rlock_result(x, T_OBJECT);\n+  __ move(LIR_OprFact::oopConst(NULL), reg);\n+}\n@@ -2527,1 +2922,1 @@\n-  if (do_update) {\n+  if (do_update && signature_at_call_k != NULL) {\n@@ -2612,0 +3007,46 @@\n+void LIRGenerator::profile_flags(ciMethodData* md, ciProfileData* data, int flag, LIR_Condition condition) {\n+  assert(md != NULL && data != NULL, \"should have been initialized\");\n+  LIR_Opr mdp = new_register(T_METADATA);\n+  __ metadata2reg(md->constant_encoding(), mdp);\n+  LIR_Address* addr = new LIR_Address(mdp, md->byte_offset_of_slot(data, DataLayout::flags_offset()), T_BYTE);\n+  LIR_Opr flags = new_register(T_INT);\n+  __ move(addr, flags);\n+  if (condition != lir_cond_always) {\n+    LIR_Opr update = new_register(T_INT);\n+    __ cmove(condition, LIR_OprFact::intConst(0), LIR_OprFact::intConst(flag), update, T_INT);\n+  } else {\n+    __ logical_or(flags, LIR_OprFact::intConst(flag), flags);\n+  }\n+  __ store(flags, addr);\n+}\n+\n+void LIRGenerator::profile_null_free_array(LIRItem array, ciMethodData* md, ciArrayLoadStoreData* load_store) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  LabelObj* L_end = new LabelObj();\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_null_free_array(array.result(), tmp);\n+\n+  profile_flags(md, load_store, ArrayLoadStoreData::null_free_array_byte_constant(), lir_cond_equal);\n+}\n+\n+void LIRGenerator::profile_array_type(AccessIndexed* x, ciMethodData*& md, ciArrayLoadStoreData*& load_store) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  int bci = x->profiled_bci();\n+  md = x->profiled_method()->method_data();\n+  assert(md != NULL, \"Sanity\");\n+  ciProfileData* data = md->bci_to_data(bci);\n+  assert(data != NULL && data->is_ArrayLoadStoreData(), \"incorrect profiling entry\");\n+  load_store = (ciArrayLoadStoreData*)data;\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(load_store, ArrayLoadStoreData::array_offset()), 0,\n+               load_store->array()->type(), x->array(), mdp, true, NULL, NULL);\n+}\n+\n+void LIRGenerator::profile_element_type(Value element, ciMethodData* md, ciArrayLoadStoreData* load_store) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  assert(md != NULL && load_store != NULL, \"should have been initialized\");\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(load_store, ArrayLoadStoreData::element_offset()), 0,\n+               load_store->element()->type(), element, mdp, false, NULL, NULL);\n+}\n+\n@@ -2692,0 +3133,8 @@\n+  if (method()->has_scalarized_args()) {\n+    \/\/ Check if deoptimization was triggered (i.e. orig_pc was set) while buffering scalarized inline type arguments\n+    \/\/ in the entry point (see comments in frame::deoptimize). If so, deoptimize only now that we have the right state.\n+    CodeEmitInfo* info = new CodeEmitInfo(scope()->start()->state()->copy(ValueStack::StateBefore, 0), NULL, false);\n+    CodeStub* deopt_stub = new DeoptimizeStub(info, Deoptimization::Reason_none, Deoptimization::Action_none);\n+    __ append(new LIR_Op0(lir_check_orig_pc));\n+    __ branch(lir_cond_notEqual, deopt_stub);\n+  }\n@@ -2707,0 +3156,14 @@\n+void LIRGenerator::invoke_load_one_argument(LIRItem* param, LIR_Opr loc) {\n+  if (loc->is_register()) {\n+    param->load_item_force(loc);\n+  } else {\n+    LIR_Address* addr = loc->as_address_ptr();\n+    param->load_for_store(addr->type());\n+    assert(addr->type() != T_PRIMITIVE_OBJECT, \"not supported yet\");\n+    if (addr->type() == T_OBJECT) {\n+      __ move_wide(param->result(), addr);\n+    } else {\n+      __ move(param->result(), addr);\n+    }\n+  }\n+}\n@@ -2714,10 +3177,1 @@\n-    if (loc->is_register()) {\n-      param->load_item_force(loc);\n-    } else {\n-      LIR_Address* addr = loc->as_address_ptr();\n-      param->load_for_store(addr->type());\n-      if (addr->type() == T_OBJECT) {\n-        __ move_wide(param->result(), addr);\n-      } else\n-        __ move(param->result(), addr);\n-    }\n+    invoke_load_one_argument(param, loc);\n@@ -2889,1 +3343,1 @@\n-  if (can_inline_as_constant(right.value())) {\n+  if (can_inline_as_constant(right.value()) && !x->substitutability_check()) {\n@@ -2892,0 +3346,1 @@\n+    \/\/ substitutability_check() needs to use right as a base register.\n@@ -2899,3 +3354,60 @@\n-  LIR_Opr reg = rlock_result(x);\n-  __ cmp(lir_cond(x->cond()), left.result(), right.result());\n-  __ cmove(lir_cond(x->cond()), t_val.result(), f_val.result(), reg, as_BasicType(x->x()->type()));\n+  if (x->substitutability_check()) {\n+    substitutability_check(x, left, right, t_val, f_val);\n+  } else {\n+    LIR_Opr reg = rlock_result(x);\n+    __ cmp(lir_cond(x->cond()), left.result(), right.result());\n+    __ cmove(lir_cond(x->cond()), t_val.result(), f_val.result(), reg, as_BasicType(x->x()->type()));\n+  }\n+}\n+\n+void LIRGenerator::substitutability_check(IfOp* x, LIRItem& left, LIRItem& right, LIRItem& t_val, LIRItem& f_val) {\n+  assert(x->cond() == If::eql || x->cond() == If::neq, \"must be\");\n+  bool is_acmpeq = (x->cond() == If::eql);\n+  LIR_Opr equal_result     = is_acmpeq ? t_val.result() : f_val.result();\n+  LIR_Opr not_equal_result = is_acmpeq ? f_val.result() : t_val.result();\n+  LIR_Opr result = rlock_result(x);\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+\n+  substitutability_check_common(x->x(), x->y(), left, right, equal_result, not_equal_result, result, info);\n+}\n+\n+void LIRGenerator::substitutability_check(If* x, LIRItem& left, LIRItem& right) {\n+  LIR_Opr equal_result     = LIR_OprFact::intConst(1);\n+  LIR_Opr not_equal_result = LIR_OprFact::intConst(0);\n+  LIR_Opr result = new_register(T_INT);\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+\n+  substitutability_check_common(x->x(), x->y(), left, right, equal_result, not_equal_result, result, info);\n+\n+  assert(x->cond() == If::eql || x->cond() == If::neq, \"must be\");\n+  __ cmp(lir_cond(x->cond()), result, equal_result);\n+}\n+\n+void LIRGenerator::substitutability_check_common(Value left_val, Value right_val, LIRItem& left, LIRItem& right,\n+                                                 LIR_Opr equal_result, LIR_Opr not_equal_result, LIR_Opr result,\n+                                                 CodeEmitInfo* info) {\n+  LIR_Opr tmp1 = LIR_OprFact::illegalOpr;\n+  LIR_Opr tmp2 = LIR_OprFact::illegalOpr;\n+  LIR_Opr left_klass_op = LIR_OprFact::illegalOpr;\n+  LIR_Opr right_klass_op = LIR_OprFact::illegalOpr;\n+\n+  ciKlass* left_klass  = left_val ->as_loaded_klass_or_null();\n+  ciKlass* right_klass = right_val->as_loaded_klass_or_null();\n+\n+  if ((left_klass == NULL || right_klass == NULL) ||\/\/ The klass is still unloaded, or came from a Phi node.\n+      !left_klass->is_inlinetype() || !right_klass->is_inlinetype()) {\n+    init_temps_for_substitutability_check(tmp1, tmp2);\n+  }\n+\n+  if (left_klass != NULL && left_klass->is_inlinetype() && left_klass == right_klass) {\n+    \/\/ No need to load klass -- the operands are statically known to be the same inline klass.\n+  } else {\n+    BasicType t_klass = UseCompressedOops ? T_INT : T_METADATA;\n+    left_klass_op = new_register(t_klass);\n+    right_klass_op = new_register(t_klass);\n+  }\n+\n+  CodeStub* slow_path = new SubstitutabilityCheckStub(left.result(), right.result(), info);\n+  __ substitutability_check(result, left.result(), right.result(), equal_result, not_equal_result,\n+                            tmp1, tmp2,\n+                            left_klass, right_klass, left_klass_op, right_klass_op, info, slow_path);\n@@ -3172,1 +3684,1 @@\n-    ciReturnTypeEntry* ret = data->is_CallTypeData() ? ((ciCallTypeData*)data)->ret() : ((ciVirtualCallTypeData*)data)->ret();\n+    ciSingleTypeEntry* ret = data->is_CallTypeData() ? ((ciCallTypeData*)data)->ret() : ((ciVirtualCallTypeData*)data)->ret();\n@@ -3193,0 +3705,47 @@\n+bool LIRGenerator::profile_inline_klass(ciMethodData* md, ciProfileData* data, Value value, int flag) {\n+  ciKlass* klass = value->as_loaded_klass_or_null();\n+  if (klass != NULL) {\n+    if (klass->is_inlinetype()) {\n+      profile_flags(md, data, flag, lir_cond_always);\n+    } else if (klass->can_be_inline_klass()) {\n+      return false;\n+    }\n+  } else {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+\n+void LIRGenerator::do_ProfileACmpTypes(ProfileACmpTypes* x) {\n+  ciMethod* method = x->method();\n+  assert(method != NULL, \"method should be set if branch is profiled\");\n+  ciMethodData* md = method->method_data_or_null();\n+  assert(md != NULL, \"Sanity\");\n+  ciProfileData* data = md->bci_to_data(x->bci());\n+  assert(data != NULL, \"must have profiling data\");\n+  assert(data->is_ACmpData(), \"need BranchData for two-way branches\");\n+  ciACmpData* acmp = (ciACmpData*)data;\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(acmp, ACmpData::left_offset()), 0,\n+               acmp->left()->type(), x->left(), mdp, !x->left_maybe_null(), NULL, NULL);\n+  int flags_offset = md->byte_offset_of_slot(data, DataLayout::flags_offset());\n+  if (!profile_inline_klass(md, acmp, x->left(), ACmpData::left_inline_type_byte_constant())) {\n+    LIR_Opr mdp = new_register(T_METADATA);\n+    __ metadata2reg(md->constant_encoding(), mdp);\n+    LIRItem value(x->left(), this);\n+    value.load_item();\n+    __ profile_inline_type(new LIR_Address(mdp, flags_offset, T_INT), value.result(), ACmpData::left_inline_type_byte_constant(), new_register(T_INT), !x->left_maybe_null());\n+  }\n+  profile_type(md, md->byte_offset_of_slot(acmp, ACmpData::left_offset()),\n+               in_bytes(ACmpData::right_offset()) - in_bytes(ACmpData::left_offset()),\n+               acmp->right()->type(), x->right(), mdp, !x->right_maybe_null(), NULL, NULL);\n+  if (!profile_inline_klass(md, acmp, x->right(), ACmpData::right_inline_type_byte_constant())) {\n+    LIR_Opr mdp = new_register(T_METADATA);\n+    __ metadata2reg(md->constant_encoding(), mdp);\n+    LIRItem value(x->right(), this);\n+    value.load_item();\n+    __ profile_inline_type(new LIR_Address(mdp, flags_offset, T_INT), value.result(), ACmpData::right_inline_type_byte_constant(), new_register(T_INT), !x->left_maybe_null());\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":603,"deletions":44,"binary":false,"changes":647,"status":"modified"},{"patch":"@@ -172,0 +172,1 @@\n+  bool          _in_conditional_code;\n@@ -198,0 +199,1 @@\n+  void set_in_conditional_code(bool v);\n@@ -217,0 +219,1 @@\n+  bool in_conditional_code() { return _in_conditional_code; }\n@@ -275,0 +278,14 @@\n+  bool inline_type_field_access_prolog(AccessField* x);\n+  void access_flattened_array(bool is_load, LIRItem& array, LIRItem& index, LIRItem& obj_item, ciField* field = NULL, int offset = 0);\n+  void access_sub_element(LIRItem& array, LIRItem& index, LIR_Opr& result, ciField* field, int sub_offset);\n+  LIR_Opr get_and_load_element_address(LIRItem& array, LIRItem& index);\n+  bool needs_flattened_array_store_check(StoreIndexed* x);\n+  void check_flattened_array(LIR_Opr array, LIR_Opr value, CodeStub* slow_path);\n+  bool needs_null_free_array_store_check(StoreIndexed* x);\n+  void check_null_free_array(LIRItem& array, LIRItem& value,  CodeEmitInfo* info);\n+  void substitutability_check(IfOp* x, LIRItem& left, LIRItem& right, LIRItem& t_val, LIRItem& f_val);\n+  void substitutability_check(If* x, LIRItem& left, LIRItem& right);\n+  void substitutability_check_common(Value left_val, Value right_val, LIRItem& left, LIRItem& right,\n+                                     LIR_Opr equal_result, LIR_Opr not_equal_result, LIR_Opr result, CodeEmitInfo* info);\n+  void init_temps_for_substitutability_check(LIR_Opr& tmp1, LIR_Opr& tmp2);\n+\n@@ -329,1 +346,1 @@\n-\n+  void invoke_load_one_argument(LIRItem* param, LIR_Opr loc);\n@@ -365,1 +382,1 @@\n-  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info);\n+  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info, CodeStub* throw_imse_stub);\n@@ -368,1 +385,1 @@\n-  void new_instance    (LIR_Opr  dst, ciInstanceKlass* klass, bool is_unresolved, LIR_Opr  scratch1, LIR_Opr  scratch2, LIR_Opr  scratch3,  LIR_Opr scratch4, LIR_Opr  klass_reg, CodeEmitInfo* info);\n+  void new_instance(LIR_Opr dst, ciInstanceKlass* klass, bool is_unresolved, bool allow_inline, LIR_Opr scratch1, LIR_Opr scratch2, LIR_Opr scratch3, LIR_Opr scratch4, LIR_Opr klass_reg, CodeEmitInfo* info);\n@@ -484,0 +501,5 @@\n+  void profile_flags(ciMethodData* md, ciProfileData* load_store, int flag, LIR_Condition condition = lir_cond_always);\n+  void profile_null_free_array(LIRItem array, ciMethodData* md, ciArrayLoadStoreData* load_store);\n+  void profile_array_type(AccessIndexed* x, ciMethodData*& md, ciArrayLoadStoreData*& load_store);\n+  void profile_element_type(Value element, ciMethodData* md, ciArrayLoadStoreData* load_store);\n+  bool profile_inline_klass(ciMethodData* md, ciProfileData* data, Value value, int flag);\n@@ -511,0 +533,1 @@\n+    , _in_conditional_code(false)\n@@ -564,0 +587,1 @@\n+  virtual void do_NewInlineTypeInstance(NewInlineTypeInstance* x);\n@@ -567,0 +591,1 @@\n+  virtual void do_Deoptimize     (Deoptimize*      x);\n@@ -589,0 +614,1 @@\n+  virtual void do_ProfileACmpTypes(ProfileACmpTypes* x);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":29,"deletions":3,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -56,0 +56,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n@@ -125,0 +127,1 @@\n+int Runtime1::_new_flat_array_slowcase_cnt = 0;\n@@ -127,0 +130,5 @@\n+int Runtime1::_load_flattened_array_slowcase_cnt = 0;\n+int Runtime1::_store_flattened_array_slowcase_cnt = 0;\n+int Runtime1::_substitutability_check_slowcase_cnt = 0;\n+int Runtime1::_buffer_inline_args_slowcase_cnt = 0;\n+int Runtime1::_buffer_inline_args_no_receiver_slowcase_cnt = 0;\n@@ -136,0 +144,1 @@\n+int Runtime1::_throw_illegal_monitor_state_exception_count = 0;\n@@ -351,2 +360,1 @@\n-\n-JRT_ENTRY(void, Runtime1::new_instance(JavaThread* current, Klass* klass))\n+static void allocate_instance(JavaThread* current, Klass* klass, TRAPS) {\n@@ -355,1 +363,1 @@\n-    _new_instance_slowcase_cnt++;\n+    Runtime1::_new_instance_slowcase_cnt++;\n@@ -369,0 +377,12 @@\n+JRT_ENTRY(void, Runtime1::new_instance(JavaThread* current, Klass* klass))\n+  allocate_instance(current, klass, CHECK);\n+JRT_END\n+\n+\/\/ Same as new_instance but throws error for inline klasses\n+JRT_ENTRY(void, Runtime1::new_instance_no_inline(JavaThread* current, Klass* klass))\n+  if (klass->is_inline_klass()) {\n+    SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_InstantiationError());\n+  } else {\n+    allocate_instance(current, klass, CHECK);\n+  }\n+JRT_END\n@@ -403,1 +423,1 @@\n-  Klass* elem_klass = ObjArrayKlass::cast(array_klass)->element_klass();\n+  Klass* elem_klass = ArrayKlass::cast(array_klass)->element_klass();\n@@ -414,0 +434,22 @@\n+JRT_ENTRY(void, Runtime1::new_flat_array(JavaThread* current, Klass* array_klass, jint length))\n+  NOT_PRODUCT(_new_flat_array_slowcase_cnt++;)\n+\n+  \/\/ Note: no handle for klass needed since they are not used\n+  \/\/       anymore after new_objArray() and no GC can happen before.\n+  \/\/       (This may have to change if this code changes!)\n+  assert(array_klass->is_klass(), \"not a class\");\n+  Handle holder(THREAD, array_klass->klass_holder()); \/\/ keep the klass alive\n+  Klass* elem_klass = ArrayKlass::cast(array_klass)->element_klass();\n+  assert(elem_klass->is_inline_klass(), \"must be\");\n+  \/\/ Logically creates elements, ensure klass init\n+  elem_klass->initialize(CHECK);\n+  arrayOop obj = oopFactory::new_valueArray(elem_klass, length, CHECK);\n+  current->set_vm_result(obj);\n+  \/\/ This is pretty rare but this runtime patch is stressful to deoptimization\n+  \/\/ if we deoptimize here so force a deopt to stress the path.\n+  if (DeoptimizeALot) {\n+    deopt_caller(current);\n+  }\n+JRT_END\n+\n+\n@@ -428,0 +470,81 @@\n+static void profile_flat_array(JavaThread* current) {\n+  ResourceMark rm(current);\n+  vframeStream vfst(current, true);\n+  assert(!vfst.at_end(), \"Java frame must exist\");\n+  \/\/ Check if array access profiling is enabled\n+  if (vfst.nm()->comp_level() != CompLevel_full_profile || !C1UpdateMethodData) {\n+    return;\n+  }\n+  int bci = vfst.bci();\n+  Method* method = vfst.method();\n+  MethodData* md = method->method_data();\n+  if (md != NULL) {\n+    ProfileData* data = md->bci_to_data(bci);\n+    assert(data != NULL && data->is_ArrayLoadStoreData(), \"incorrect profiling entry\");\n+    ArrayLoadStoreData* load_store = (ArrayLoadStoreData*)data;\n+    load_store->set_flat_array();\n+  }\n+}\n+\n+JRT_ENTRY(void, Runtime1::load_flattened_array(JavaThread* current, flatArrayOopDesc* array, int index))\n+  assert(array->klass()->is_flatArray_klass(), \"should not be called\");\n+  profile_flat_array(current);\n+\n+  NOT_PRODUCT(_load_flattened_array_slowcase_cnt++;)\n+  assert(array->length() > 0 && index < array->length(), \"already checked\");\n+  flatArrayHandle vah(current, array);\n+  oop obj = flatArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK);\n+  current->set_vm_result(obj);\n+JRT_END\n+\n+\n+JRT_ENTRY(void, Runtime1::store_flattened_array(JavaThread* current, flatArrayOopDesc* array, int index, oopDesc* value))\n+  if (array->klass()->is_flatArray_klass()) {\n+    profile_flat_array(current);\n+  }\n+\n+  NOT_PRODUCT(_store_flattened_array_slowcase_cnt++;)\n+  if (value == NULL) {\n+    assert(array->klass()->is_flatArray_klass() || array->klass()->is_null_free_array_klass(), \"should not be called\");\n+    SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException());\n+  } else {\n+    assert(array->klass()->is_flatArray_klass(), \"should not be called\");\n+    array->value_copy_to_index(value, index);\n+  }\n+JRT_END\n+\n+\n+JRT_ENTRY(int, Runtime1::substitutability_check(JavaThread* current, oopDesc* left, oopDesc* right))\n+  NOT_PRODUCT(_substitutability_check_slowcase_cnt++;)\n+  JavaCallArguments args;\n+  args.push_oop(Handle(THREAD, left));\n+  args.push_oop(Handle(THREAD, right));\n+  JavaValue result(T_BOOLEAN);\n+  JavaCalls::call_static(&result,\n+                         vmClasses::PrimitiveObjectMethods_klass(),\n+                         vmSymbols::isSubstitutable_name(),\n+                         vmSymbols::object_object_boolean_signature(),\n+                         &args, CHECK_0);\n+  return result.get_jboolean() ? 1 : 0;\n+JRT_END\n+\n+\n+extern \"C\" void ps();\n+\n+void Runtime1::buffer_inline_args_impl(JavaThread* current, Method* m, bool allocate_receiver) {\n+  JavaThread* THREAD = current;\n+  methodHandle method(current, m); \/\/ We are inside the verified_entry or verified_inline_ro_entry of this method.\n+  oop obj = SharedRuntime::allocate_inline_types_impl(current, method, allocate_receiver, CHECK);\n+  current->set_vm_result(obj);\n+}\n+\n+JRT_ENTRY(void, Runtime1::buffer_inline_args(JavaThread* current, Method* method))\n+  NOT_PRODUCT(_buffer_inline_args_slowcase_cnt++;)\n+  buffer_inline_args_impl(current, method, true);\n+JRT_END\n+\n+JRT_ENTRY(void, Runtime1::buffer_inline_args_no_receiver(JavaThread* current, Method* method))\n+  NOT_PRODUCT(_buffer_inline_args_no_receiver_slowcase_cnt++;)\n+  buffer_inline_args_impl(current, method, false);\n+JRT_END\n+\n@@ -751,0 +874,6 @@\n+JRT_ENTRY(void, Runtime1::throw_illegal_monitor_state_exception(JavaThread* current))\n+  NOT_PRODUCT(_throw_illegal_monitor_state_exception_count++;)\n+  ResourceMark rm(current);\n+  SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_IllegalMonitorStateException());\n+JRT_END\n+\n@@ -971,0 +1100,1 @@\n+    assert(!result.is_inlined(), \"Can not patch access to flattened field\");\n@@ -1013,0 +1143,5 @@\n+      case Bytecodes::_aconst_init:\n+        { Bytecode_aconst_init baconst_init(caller_method(), caller_method->bcp_from(bci));\n+          k = caller_method->constants()->klass_at(baconst_init.index(), CHECK);\n+        }\n+        break;\n@@ -1016,0 +1151,4 @@\n+          if (k->name()->is_Q_array_signature()) {\n+            \/\/ Logically creates elements, ensure klass init\n+            k->initialize(CHECK);\n+          }\n@@ -1494,0 +1633,1 @@\n+  tty->print_cr(\" _new_flat_array_slowcase_cnt:    %d\", _new_flat_array_slowcase_cnt);\n@@ -1496,0 +1636,6 @@\n+  tty->print_cr(\" _load_flattened_array_slowcase_cnt:   %d\", _load_flattened_array_slowcase_cnt);\n+  tty->print_cr(\" _store_flattened_array_slowcase_cnt:  %d\", _store_flattened_array_slowcase_cnt);\n+  tty->print_cr(\" _substitutability_check_slowcase_cnt: %d\", _substitutability_check_slowcase_cnt);\n+  tty->print_cr(\" _buffer_inline_args_slowcase_cnt:%d\", _buffer_inline_args_slowcase_cnt);\n+  tty->print_cr(\" _buffer_inline_args_no_receiver_slowcase_cnt:%d\", _buffer_inline_args_no_receiver_slowcase_cnt);\n+\n@@ -1506,0 +1652,1 @@\n+  tty->print_cr(\" _throw_illegal_monitor_state_exception_count:  %d:\", _throw_illegal_monitor_state_exception_count);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":151,"deletions":4,"binary":false,"changes":155,"status":"modified"},{"patch":"@@ -135,0 +135,65 @@\n+inline void CDSMustMatchFlags::do_print(outputStream* st, bool v) {\n+  st->print(\"%s\", v ? \"true\" : \"false\");\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, intx v) {\n+  st->print(INTX_FORMAT, v);\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, uintx v) {\n+  st->print(UINTX_FORMAT, v);\n+}\n+\n+inline void CDSMustMatchFlags::do_print(outputStream* st, double v) {\n+  st->print(\"%f\", v);\n+}\n+\n+void CDSMustMatchFlags::init() {\n+  Arguments::assert_is_dumping_archive();\n+  _max_name_width = 0;\n+\n+#define INIT_CDS_MUST_MATCH_FLAG(n) \\\n+  _v_##n = n; \\\n+  _max_name_width = MAX2(_max_name_width,strlen(#n));\n+  CDS_MUST_MATCH_FLAGS_DO(INIT_CDS_MUST_MATCH_FLAG);\n+#undef INIT_CDS_MUST_MATCH_FLAG\n+}\n+\n+bool CDSMustMatchFlags::runtime_check() const {\n+#define CHECK_CDS_MUST_MATCH_FLAG(n) \\\n+  if (_v_##n != n) { \\\n+    ResourceMark rm; \\\n+    stringStream ss; \\\n+    ss.print(\"VM option %s is different between dumptime (\", #n);  \\\n+    do_print(&ss, _v_ ## n); \\\n+    ss.print(\") and runtime (\"); \\\n+    do_print(&ss, n); \\\n+    ss.print(\")\"); \\\n+    FileMapInfo::fail_continue(\"%s\", ss.as_string()); \\\n+    return false; \\\n+  }\n+  CDS_MUST_MATCH_FLAGS_DO(CHECK_CDS_MUST_MATCH_FLAG);\n+#undef CHECK_CDS_MUST_MATCH_FLAG\n+\n+  return true;\n+}\n+\n+void CDSMustMatchFlags::print_info() const {\n+  LogTarget(Info, cds) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+    ls.print_cr(\"Recorded VM flags during dumptime:\");\n+    print(&ls);\n+  }\n+}\n+\n+void CDSMustMatchFlags::print(outputStream* st) const {\n+#define PRINT_CDS_MUST_MATCH_FLAG(n) \\\n+  st->print(\"- %-s \", #n);                   \\\n+  st->sp(int(_max_name_width - strlen(#n))); \\\n+  do_print(st, _v_##n);                      \\\n+  st->cr();\n+  CDS_MUST_MATCH_FLAGS_DO(PRINT_CDS_MUST_MATCH_FLAG);\n+#undef PRINT_CDS_MUST_MATCH_FLAG\n+}\n+\n@@ -294,0 +359,1 @@\n+  _must_match.init();\n@@ -355,0 +421,1 @@\n+  _must_match.print(st);\n@@ -1403,0 +1470,4 @@\n+  if (!header()->check_must_match_flags()) {\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":71,"deletions":0,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -290,3 +290,4 @@\n-    int hash_original = obj->identity_hash();\n-    archived_oop->set_mark(markWord::prototype().copy_set_hash(hash_original));\n-    assert(archived_oop->mark().is_unlocked(), \"sanity\");\n+    if (!(EnableValhalla && obj->mark().is_inline_type())) {\n+      int hash_original = obj->identity_hash();\n+      archived_oop->set_mark(archived_oop->klass()->prototype_header().copy_set_hash(hash_original));\n+      assert(archived_oop->mark().is_unlocked(), \"sanity\");\n@@ -294,2 +295,3 @@\n-    DEBUG_ONLY(int hash_archived = archived_oop->identity_hash());\n-    assert(hash_original == hash_archived, \"Different hash codes: original %x, archived %x\", hash_original, hash_archived);\n+      DEBUG_ONLY(int hash_archived = archived_oop->identity_hash());\n+      assert(hash_original == hash_archived, \"Different hash codes: original %x, archived %x\", hash_original, hash_archived);\n+    }\n@@ -531,1 +533,1 @@\n-    oopDesc::set_mark(mem, markWord::prototype());\n+    oopDesc::set_mark(mem, k->prototype_header());\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":8,"deletions":6,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -63,0 +63,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -544,1 +545,3 @@\n-      (sym->char_at(1) == JVM_SIGNATURE_ARRAY || sym->char_at(1) == JVM_SIGNATURE_CLASS)) {\n+      (sym->char_at(1) == JVM_SIGNATURE_ARRAY ||\n+       sym->char_at(1) == JVM_SIGNATURE_CLASS ||\n+       sym->char_at(1) == JVM_SIGNATURE_PRIMITIVE_OBJECT )) {\n@@ -557,1 +560,2 @@\n-      return ciObjArrayKlass::make_impl(elem_klass);\n+      bool null_free_array = sym->is_Q_array_signature() && sym->char_at(1) == JVM_SIGNATURE_PRIMITIVE_OBJECT;\n+      return ciArrayKlass::make(elem_klass, null_free_array);\n@@ -583,0 +587,15 @@\n+  int i = 0;\n+  while (sym->char_at(i) == JVM_SIGNATURE_ARRAY) {\n+    i++;\n+  }\n+  if (i > 0 && sym->char_at(i) == JVM_SIGNATURE_PRIMITIVE_OBJECT) {\n+    \/\/ An unloaded array class of inline types is an ObjArrayKlass, an\n+    \/\/ unloaded inline type class is an InstanceKlass. For consistency,\n+    \/\/ make the signature of the unloaded array of inline type use L\n+    \/\/ rather than Q.\n+    char* new_name = name_buffer(sym->utf8_length()+1);\n+    strncpy(new_name, (char*)sym->base(), sym->utf8_length());\n+    new_name[i] = JVM_SIGNATURE_CLASS;\n+    new_name[sym->utf8_length()] = '\\0';\n+    return get_unloaded_klass(accessing_klass, ciSymbol::make(new_name));\n+  }\n@@ -669,0 +688,8 @@\n+\/\/ ------------------------------------------------------------------\n+\/\/ ciEnv::is_inline_klass\n+\/\/\n+\/\/ Check if the klass is an inline klass.\n+bool ciEnv::has_Q_signature(const constantPoolHandle& cpool, int index) {\n+  GUARDED_VM_ENTRY(return cpool->klass_name_at(index)->is_Q_signature();)\n+}\n+\n@@ -765,1 +792,5 @@\n-    return ciConstant(T_OBJECT, mirror);\n+    if (klass->is_loaded() && tag.is_Qdescriptor_klass()) {\n+      return ciConstant(T_OBJECT, klass->as_inline_klass()->val_mirror());\n+    } else {\n+      return ciConstant(T_OBJECT, mirror);\n+    }\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":34,"deletions":3,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -303,1 +303,1 @@\n-void ciReturnTypeEntry::translate_type_data_from(const ReturnTypeEntry* ret) {\n+void ciSingleTypeEntry::translate_type_data_from(const SingleTypeEntry* ret) {\n@@ -308,1 +308,1 @@\n-    set_type(ReturnTypeEntry::with_status((Klass*)NULL, k));\n+    set_type(SingleTypeEntry::with_status((Klass*)NULL, k));\n@@ -359,0 +359,4 @@\n+  case DataLayout::array_load_store_data_tag:\n+    return new ciArrayLoadStoreData(data_layout);\n+  case DataLayout::acmp_data_tag:\n+    return new ciACmpData(data_layout);\n@@ -750,0 +754,13 @@\n+      } else if (pdata->is_ArrayLoadStoreData()) {\n+        ciArrayLoadStoreData* array_load_store_data = (ciArrayLoadStoreData*)pdata;\n+        dump_replay_data_type_helper(out, round, count, array_load_store_data, ciArrayLoadStoreData::array_offset(),\n+                                     array_load_store_data->array()->valid_type());\n+        dump_replay_data_type_helper(out, round, count, array_load_store_data, ciArrayLoadStoreData::element_offset(),\n+                                     array_load_store_data->element()->valid_type());\n+      } else if (pdata->is_ACmpData()) {\n+        ciACmpData* acmp_data = (ciACmpData*)pdata;\n+        dump_replay_data_type_helper(out, round, count, acmp_data, ciACmpData::left_offset(),\n+                                     acmp_data->left()->valid_type());\n+        dump_replay_data_type_helper(out, round, count, acmp_data, ciACmpData::right_offset(),\n+                                     acmp_data->right()->valid_type());\n+\n@@ -832,1 +849,1 @@\n-void ciReturnTypeEntry::print_data_on(outputStream* st) const {\n+void ciSingleTypeEntry::print_data_on(outputStream* st) const {\n@@ -905,0 +922,21 @@\n+\n+void ciArrayLoadStoreData::print_data_on(outputStream* st, const char* extra) const {\n+  print_shared(st, \"ciArrayLoadStoreData\", extra);\n+  tab(st, true);\n+  st->print(\"array\");\n+  array()->print_data_on(st);\n+  tab(st, true);\n+  st->print(\"element\");\n+  element()->print_data_on(st);\n+}\n+\n+void ciACmpData::print_data_on(outputStream* st, const char* extra) const {\n+  BranchData::print_data_on(st, extra);\n+  st->cr();\n+  tab(st, true);\n+  st->print(\"left\");\n+  left()->print_data_on(st);\n+  tab(st, true);\n+  st->print(\"right\");\n+  right()->print_data_on(st);\n+}\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.cpp","additions":41,"deletions":3,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -24,0 +24,1 @@\n+\n@@ -52,0 +53,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -85,0 +87,1 @@\n+#include \"utilities\/stringUtils.hpp\"\n@@ -146,0 +149,2 @@\n+#define CONSTANT_CLASS_DESCRIPTORS        64\n+\n@@ -185,1 +190,1 @@\n-      case JVM_CONSTANT_Class : {\n+      case JVM_CONSTANT_Class: {\n@@ -506,1 +511,8 @@\n-        cp->unresolved_klass_at_put(index, class_index, num_klasses++);\n+\n+        Symbol* const name = cp->symbol_at(class_index);\n+        const unsigned int name_len = name->utf8_length();\n+        if (name->is_Q_signature()) {\n+          cp->unresolved_qdescriptor_at_put(index, class_index, num_klasses++);\n+        } else {\n+          cp->unresolved_klass_at_put(index, class_index, num_klasses++);\n+        }\n@@ -706,1 +718,2 @@\n-          \/\/ If a class method name begins with '<', it must be \"<init>\" and have void signature.\n+          \/\/ If a class method name begins with '<', it must be \"<init>\" and have void signature\n+          \/\/ unless it's an inline type.\n@@ -715,2 +728,6 @@\n-            } else if (!Signature::is_void_method(signature)) { \/\/ must have void signature.\n-              throwIllegalSignature(\"Method\", name, signature, CHECK);\n+            } else if (!Signature::is_void_method(signature)) {\n+              \/\/ if return type is non-void then it cannot be a basic primitive\n+              \/\/ and primitve types must be supported.\n+              if (!signature->ends_with(JVM_SIGNATURE_ENDCLASS) || !EnableValhalla) {\n+                throwIllegalSignature(\"Method\", name, signature, CHECK);\n+              }\n@@ -735,2 +752,2 @@\n-            if (ref_kind == JVM_REF_newInvokeSpecial) {\n-              if (name != vmSymbols::object_initializer_name()) {\n+            if (name != vmSymbols::object_initializer_name()) {\n+              if (ref_kind == JVM_REF_newInvokeSpecial) {\n@@ -743,1 +760,12 @@\n-              if (name == vmSymbols::object_initializer_name()) {\n+              \/\/ The allowed invocation mode of <init> depends on its signature.\n+              \/\/ This test corresponds to verify_invoke_instructions in the verifier.\n+              const int signature_ref_index =\n+                cp->signature_ref_index_at(name_and_type_ref_index);\n+              const Symbol* const signature = cp->symbol_at(signature_ref_index);\n+              if (signature->is_void_method_signature()\n+                  && ref_kind == JVM_REF_newInvokeSpecial) {\n+                \/\/ OK, could be a constructor call\n+              } else if (!signature->is_void_method_signature()\n+                         && ref_kind == JVM_REF_invokeStatic) {\n+                \/\/ also OK, could be a static factory call\n+              } else {\n@@ -820,4 +848,31 @@\n-\/\/ Side-effects: populates the _local_interfaces field\n-void ClassFileParser::parse_interfaces(const ClassFileStream* const stream,\n-                                       const int itfs_len,\n-                                       ConstantPool* const cp,\n+static void check_identity_and_value_modifiers(ClassFileParser* current, const InstanceKlass* super_type, TRAPS) {\n+  assert(super_type != NULL,\"Method doesn't support null super type\");\n+  if (super_type->carries_identity_modifier()) {\n+    if (current->carries_value_modifier()) {\n+        ResourceMark rm(THREAD);\n+        Exceptions::fthrow(\n+          THREAD_AND_LOCATION,\n+          vmSymbols::java_lang_IncompatibleClassChangeError(),\n+          \"Value type %s has an identity type as supertype\",\n+          current->class_name()->as_klass_external_name());\n+        return;\n+      }\n+    current->set_carries_identity_modifier();\n+  }\n+  if (super_type->carries_value_modifier()) {\n+    if (current->carries_identity_modifier()) {\n+      ResourceMark rm(THREAD);\n+      Exceptions::fthrow(\n+        THREAD_AND_LOCATION,\n+        vmSymbols::java_lang_IncompatibleClassChangeError(),\n+        \"Identity type %s has a value type as supertype\",\n+        current->class_name()->as_klass_external_name());\n+      return;\n+    }\n+    current->set_carries_value_modifier();\n+  }\n+}\n+\n+void ClassFileParser::parse_interfaces(const ClassFileStream* stream,\n+                                       int itfs_len,\n+                                       ConstantPool* cp,\n@@ -825,0 +880,7 @@\n+                                       \/\/ FIXME: lots of these functions\n+                                       \/\/ declare their parameters as const,\n+                                       \/\/ which adds only noise to the code.\n+                                       \/\/ Remove the spurious const modifiers.\n+                                       \/\/ Many are of the form \"const int x\"\n+                                       \/\/ or \"T* const x\".\n+                                       bool* const is_declared_atomic,\n@@ -832,0 +894,1 @@\n+\n@@ -834,3 +897,2 @@\n-    _local_interfaces = MetadataFactory::new_array<InstanceKlass*>(_loader_data, itfs_len, NULL, CHECK);\n-\n-    int index;\n+    _local_interface_indexes = new GrowableArray<u2>(itfs_len, mtNone);\n+    int index = 0;\n@@ -839,1 +901,0 @@\n-      Klass* interf;\n@@ -844,32 +905,1 @@\n-      if (cp->tag_at(interface_index).is_klass()) {\n-        interf = cp->resolved_klass_at(interface_index);\n-      } else {\n-        Symbol* const unresolved_klass  = cp->klass_name_at(interface_index);\n-\n-        \/\/ Don't need to check legal name because it's checked when parsing constant pool.\n-        \/\/ But need to make sure it's not an array type.\n-        guarantee_property(unresolved_klass->char_at(0) != JVM_SIGNATURE_ARRAY,\n-                           \"Bad interface name in class file %s\", CHECK);\n-\n-        \/\/ Call resolve_super so class circularity is checked\n-        interf = SystemDictionary::resolve_super_or_fail(\n-                                                  _class_name,\n-                                                  unresolved_klass,\n-                                                  Handle(THREAD, _loader_data->class_loader()),\n-                                                  _protection_domain,\n-                                                  false,\n-                                                  CHECK);\n-      }\n-\n-      if (!interf->is_interface()) {\n-        THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n-                  err_msg(\"class %s can not implement %s, because it is not an interface (%s)\",\n-                          _class_name->as_klass_external_name(),\n-                          interf->external_name(),\n-                          interf->class_in_module_of_loader()));\n-      }\n-\n-      if (InstanceKlass::cast(interf)->has_nonstatic_concrete_methods()) {\n-        *has_nonstatic_concrete_methods = true;\n-      }\n-      _local_interfaces->at_put(index, InstanceKlass::cast(interf));\n+      _local_interface_indexes->at_put_grow(index, interface_index);\n@@ -893,2 +923,1 @@\n-        const InstanceKlass* const k = _local_interfaces->at(index);\n-        name = k->name();\n+        name = cp->klass_name_at(_local_interface_indexes->at(index));\n@@ -1380,0 +1409,1 @@\n+  STATIC_INLINE,        \/\/ inline type field\n@@ -1385,0 +1415,1 @@\n+  NONSTATIC_INLINE,\n@@ -1404,6 +1435,7 @@\n-  BAD_ALLOCATION_TYPE, \/\/ T_VOID        = 14,\n-  BAD_ALLOCATION_TYPE, \/\/ T_ADDRESS     = 15,\n-  BAD_ALLOCATION_TYPE, \/\/ T_NARROWOOP   = 16,\n-  BAD_ALLOCATION_TYPE, \/\/ T_METADATA    = 17,\n-  BAD_ALLOCATION_TYPE, \/\/ T_NARROWKLASS = 18,\n-  BAD_ALLOCATION_TYPE, \/\/ T_CONFLICT    = 19,\n+  NONSTATIC_OOP,       \/\/ T_PRIMITIVE_OBJECT = 14,\n+  BAD_ALLOCATION_TYPE, \/\/ T_VOID        = 15,\n+  BAD_ALLOCATION_TYPE, \/\/ T_ADDRESS     = 16,\n+  BAD_ALLOCATION_TYPE, \/\/ T_NARROWOOP   = 17,\n+  BAD_ALLOCATION_TYPE, \/\/ T_METADATA    = 18,\n+  BAD_ALLOCATION_TYPE, \/\/ T_NARROWKLASS = 19,\n+  BAD_ALLOCATION_TYPE, \/\/ T_CONFLICT    = 20,\n@@ -1424,6 +1456,7 @@\n-  BAD_ALLOCATION_TYPE, \/\/ T_VOID        = 14,\n-  BAD_ALLOCATION_TYPE, \/\/ T_ADDRESS     = 15,\n-  BAD_ALLOCATION_TYPE, \/\/ T_NARROWOOP   = 16,\n-  BAD_ALLOCATION_TYPE, \/\/ T_METADATA    = 17,\n-  BAD_ALLOCATION_TYPE, \/\/ T_NARROWKLASS = 18,\n-  BAD_ALLOCATION_TYPE, \/\/ T_CONFLICT    = 19,\n+  STATIC_OOP,          \/\/ T_PRIMITIVE_OBJECT = 14,\n+  BAD_ALLOCATION_TYPE, \/\/ T_VOID        = 15,\n+  BAD_ALLOCATION_TYPE, \/\/ T_ADDRESS     = 16,\n+  BAD_ALLOCATION_TYPE, \/\/ T_NARROWOOP   = 17,\n+  BAD_ALLOCATION_TYPE, \/\/ T_METADATA    = 18,\n+  BAD_ALLOCATION_TYPE, \/\/ T_NARROWKLASS = 19,\n+  BAD_ALLOCATION_TYPE, \/\/ T_CONFLICT    = 20\n@@ -1432,1 +1465,1 @@\n-static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type) {\n+static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_inline_type) {\n@@ -1436,0 +1469,3 @@\n+  if (is_inline_type) {\n+    result = is_static ? STATIC_INLINE : NONSTATIC_INLINE;\n+  }\n@@ -1449,2 +1485,2 @@\n-  void update(bool is_static, BasicType type) {\n-    FieldAllocationType atype = basic_type_to_atype(is_static, type);\n+  void update(bool is_static, BasicType type, bool is_inline_type) {\n+    FieldAllocationType atype = basic_type_to_atype(is_static, type, is_inline_type);\n@@ -1462,1 +1498,1 @@\n-                                   bool is_interface,\n+                                   AccessFlags class_access_flags,\n@@ -1478,0 +1514,1 @@\n+  bool is_inline_type = class_access_flags.is_value_class() && !class_access_flags.is_abstract();\n@@ -1485,1 +1522,5 @@\n-  const int total_fields = length + num_injected;\n+\n+  \/\/ two more slots are required for inline classes:\n+  \/\/ one for the static field with a reference to the pre-allocated default value\n+  \/\/ one for the field the JVM injects when detecting an empty inline class\n+  const int total_fields = length + num_injected + (is_inline_type ? 2 : 0);\n@@ -1515,0 +1556,1 @@\n+  int instance_fields_count = 0;\n@@ -1519,0 +1561,4 @@\n+    jint recognized_modifiers = JVM_RECOGNIZED_FIELD_MODIFIERS;\n+\n+    const jint flags = cfs->get_u2_fast() & recognized_modifiers;\n+    verify_legal_field_modifiers(flags, class_access_flags, CHECK);\n@@ -1520,2 +1566,0 @@\n-    const jint flags = cfs->get_u2_fast() & JVM_RECOGNIZED_FIELD_MODIFIERS;\n-    verify_legal_field_modifiers(flags, is_interface, CHECK);\n@@ -1537,0 +1581,1 @@\n+    if (!access_flags.is_static()) instance_fields_count++;\n@@ -1596,1 +1641,1 @@\n-    fac->update(is_static, type);\n+    fac->update(is_static, type, type == T_PRIMITIVE_OBJECT);\n@@ -1640,1 +1685,1 @@\n-      fac->update(false, type);\n+      fac->update(false, type, false);\n@@ -1645,0 +1690,27 @@\n+  if (is_inline_type) {\n+    FieldInfo* const field = FieldInfo::from_field_array(fa, index);\n+    field->initialize(JVM_ACC_FIELD_INTERNAL | JVM_ACC_STATIC,\n+                      (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(default_value_name)),\n+                      (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(object_signature)),\n+                      0);\n+    const BasicType type = Signature::basic_type(vmSymbols::object_signature());\n+    fac->update(true, type, false);\n+    index++;\n+  }\n+\n+  if (is_inline_type && instance_fields_count == 0) {\n+    _is_empty_inline_type = true;\n+    FieldInfo* const field = FieldInfo::from_field_array(fa, index);\n+    field->initialize(JVM_ACC_FIELD_INTERNAL,\n+        (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(empty_marker_name)),\n+        (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(byte_signature)),\n+        0);\n+    const BasicType type = Signature::basic_type(vmSymbols::byte_signature());\n+    fac->update(false, type, false);\n+    index++;\n+  }\n+\n+  if (instance_fields_count > 0) {\n+    _has_nonstatic_fields = true;\n+  }\n+\n@@ -1962,0 +2034,5 @@\n+  const char* class_note = \"\";\n+  if (is_inline_type() && name == vmSymbols::object_initializer_name()) {\n+    class_note = \" (an inline class)\";\n+  }\n+\n@@ -1965,2 +2042,2 @@\n-      \"%s \\\"%s\\\" in class %s has illegal signature \\\"%s\\\"\", type,\n-      name->as_C_string(), _class_name->as_C_string(), sig->as_C_string());\n+      \"%s \\\"%s\\\" in class %s%s has illegal signature \\\"%s\\\"\", type,\n+      name->as_C_string(), _class_name->as_C_string(), class_note, sig->as_C_string());\n@@ -2269,0 +2346,2 @@\n+                                      bool is_value_class,\n+                                      bool is_abstract_class,\n@@ -2310,1 +2389,1 @@\n-    verify_legal_method_modifiers(flags, is_interface, name, CHECK_NULL);\n+    verify_legal_method_modifiers(flags, access_flags() , name, CHECK_NULL);\n@@ -2313,3 +2392,57 @@\n-  if (name == vmSymbols::object_initializer_name() && is_interface) {\n-    classfile_parse_error(\"Interface cannot have a method named <init>, class file %s\", THREAD);\n-    return NULL;\n+  if (name == vmSymbols::object_initializer_name()) {\n+    if (is_interface) {\n+      classfile_parse_error(\"Interface cannot have a method named <init>, class file %s\", THREAD);\n+      return NULL;\n+    } else if ((!is_value_class || is_abstract_class) && signature->is_void_method_signature()) {\n+      \/\/ OK, a constructor\n+    } else if (is_value_class && !signature->is_void_method_signature()) {\n+      \/\/ also OK, a static factory, as long as the return value is good\n+      bool ok = false;\n+      SignatureStream ss((Symbol*) signature, true);\n+      while (!ss.at_return_type())  ss.next();\n+      if (ss.is_reference()) {\n+        Symbol* ret = ss.as_symbol();\n+        const Symbol* required = class_name();\n+        if (is_hidden()) {\n+          \/\/ The original class name in hidden classes gets changed.  So using\n+          \/\/ the original name in the return type is no longer valid.\n+          \/\/ Note that expecting the return type for inline hidden class factory\n+          \/\/ methods to be java.lang.Object works around a JVM Spec issue for\n+          \/\/ hidden classes.\n+          required = vmSymbols::java_lang_Object();\n+        }\n+        ok = (ret == required);\n+      }\n+      if (!ok) {\n+        throwIllegalSignature(\"Method\", name, signature, CHECK_0);\n+      }\n+    } else {\n+      \/\/ not OK, so throw the same error as in verify_legal_method_signature.\n+      throwIllegalSignature(\"Method\", name, signature, CHECK_0);\n+    }\n+    \/\/ A declared <init> method must always be either a non-static\n+    \/\/ object constructor, with a void return, or else it must be a\n+    \/\/ static factory method, with a non-void return.  No other\n+    \/\/ definition of <init> is possible.\n+    \/\/\n+    \/\/ The verifier (in verify_invoke_instructions) will inspect the\n+    \/\/ signature of any attempt to invoke <init>, and ensures that it\n+    \/\/ returns non-void if and only if it is being invoked by\n+    \/\/ invokestatic, and void if and only if it is being invoked by\n+    \/\/ invokespecial.\n+    \/\/\n+    \/\/ When a symbolic reference to <init> is resolved for a\n+    \/\/ particular invocation mode (special or static), the mode is\n+    \/\/ matched to the JVM_ACC_STATIC modifier of the <init> method.\n+    \/\/ Thus, it is impossible to statically invoke a constructor, and\n+    \/\/ impossible to \"new + invokespecial\" a static factory, either\n+    \/\/ through bytecode or through reflection.\n+  }\n+\n+  if (EnableValhalla) {\n+    if (((flags & JVM_ACC_SYNCHRONIZED) == JVM_ACC_SYNCHRONIZED)\n+        && ((flags & JVM_ACC_STATIC) == 0 )\n+        && !carries_identity_modifier()) {\n+      classfile_parse_error(\"Invalid synchronized method in non-identity class %s\", THREAD);\n+        return NULL;\n+    }\n@@ -2885,0 +3018,2 @@\n+                                    bool is_value_class,\n+                                    bool is_abstract_type,\n@@ -2909,0 +3044,2 @@\n+                                    is_value_class,\n+                                    is_abstract_type,\n@@ -3185,2 +3322,2 @@\n-    \/\/ Access flags\n-    jint flags;\n+\n+    jint recognized_modifiers = RECOGNIZED_INNER_CLASS_MODIFIERS;\n@@ -3189,3 +3326,5 @@\n-      flags = cfs->get_u2_fast() & (RECOGNIZED_INNER_CLASS_MODIFIERS | JVM_ACC_MODULE);\n-    } else {\n-      flags = cfs->get_u2_fast() & RECOGNIZED_INNER_CLASS_MODIFIERS;\n+      recognized_modifiers |= JVM_ACC_MODULE;\n+    }\n+    \/\/ JVM_ACC_VALUE, JVM_ACC_PRIMITIVE, and JVM_ACC_IDENTITY are defined for class file version 62 and later\n+    if (supports_inline_types()) {\n+      recognized_modifiers |= JVM_ACC_PRIMITIVE | JVM_ACC_VALUE | JVM_ACC_IDENTITY;\n@@ -3193,0 +3332,4 @@\n+\n+    \/\/ Access flags\n+    jint flags = cfs->get_u2_fast() & recognized_modifiers;\n+\n@@ -3197,1 +3340,13 @@\n-    verify_legal_class_modifiers(flags, CHECK_0);\n+\n+    if (EnableValhalla) {\n+      if (!supports_inline_types()) {\n+        const bool is_module = (flags & JVM_ACC_MODULE) != 0;\n+        const bool is_interface = (flags & JVM_ACC_INTERFACE) != 0;\n+        if (!is_module && !is_interface) {\n+          flags |= JVM_ACC_IDENTITY;\n+        }\n+      }\n+    }\n+\n+    const char* name = inner_name_index == 0 ? \"unnamed\" : cp->symbol_at(inner_name_index)->as_utf8();\n+    verify_legal_class_modifiers(flags, name, false, CHECK_0);\n@@ -3301,0 +3456,33 @@\n+u2 ClassFileParser::parse_classfile_preload_attribute(const ClassFileStream* const cfs,\n+                                                                   const u1* const preload_attribute_start,\n+                                                                   TRAPS) {\n+  const u1* const current_mark = cfs->current();\n+  u2 length = 0;\n+  if (preload_attribute_start != NULL) {\n+    cfs->set_current(preload_attribute_start);\n+    cfs->guarantee_more(2, CHECK_0);  \/\/ length\n+    length = cfs->get_u2_fast();\n+  }\n+  const int size = length;\n+  Array<u2>* const preload_classes = MetadataFactory::new_array<u2>(_loader_data, size, CHECK_0);\n+  _preload_classes = preload_classes;\n+  if (length > 0) {\n+    int index = 0;\n+    cfs->guarantee_more(2 * length, CHECK_0);\n+    for (int n = 0; n < length; n++) {\n+      const u2 class_info_index = cfs->get_u2_fast();\n+      check_property(\n+        valid_klass_reference_at(class_info_index),\n+        \"Preload class_info_index %u has bad constant type in class file %s\",\n+        class_info_index, CHECK_0);\n+      preload_classes->at_put(index++, class_info_index);\n+    }\n+    assert(index == size, \"wrong size\");\n+  }\n+\n+  \/\/ Restore buffer's current position.\n+  cfs->set_current(current_mark);\n+\n+  return length;\n+}\n+\n@@ -3585,0 +3773,2 @@\n+  \/\/ Set _preload_classes attribute to default sentinel\n+  _preload_classes = Universe::the_empty_short_array();\n@@ -3591,0 +3781,1 @@\n+  bool parsed_preload_attribute = false;\n@@ -3616,0 +3807,2 @@\n+  const u1* preload_attribute_start = NULL;\n+  u4  preload_attribute_length = 0;\n@@ -3842,0 +4035,9 @@\n+            if (EnableValhalla && tag == vmSymbols::tag_preload()) {\n+              if (parsed_preload_attribute) {\n+                classfile_parse_error(\"Multiple Preload attributes in class file %s\", CHECK);\n+                return;\n+              }\n+              parsed_preload_attribute = true;\n+              preload_attribute_start = cfs->current();\n+              preload_attribute_length = attribute_length;\n+            }\n@@ -3922,0 +4124,12 @@\n+  if (parsed_preload_attribute) {\n+    const u2 num_classes = parse_classfile_preload_attribute(\n+                            cfs,\n+                            preload_attribute_start,\n+                            CHECK);\n+    if (_need_verify) {\n+      guarantee_property(\n+        preload_attribute_length == sizeof(num_classes) + sizeof(u2) * num_classes,\n+        \"Wrong Preload attribute length in class file %s\", CHECK);\n+    }\n+  }\n+\n@@ -3986,0 +4200,1 @@\n+  this_klass->set_preload_classes(_preload_classes);\n@@ -4037,2 +4252,1 @@\n-                   \"Invalid superclass index %u in class file %s\",\n-                   super_class_index,\n+                   \"Invalid superclass index 0 in class file %s\",\n@@ -4047,1 +4261,0 @@\n-    bool is_array = false;\n@@ -4050,4 +4263,0 @@\n-      if (need_verify)\n-        is_array = super_klass->is_array_klass();\n-    } else if (need_verify) {\n-      is_array = (cp->klass_name_at(super_class_index)->char_at(0) == JVM_SIGNATURE_ARRAY);\n@@ -4056,0 +4265,1 @@\n+      bool is_array = (cp->klass_name_at(super_class_index)->char_at(0) == JVM_SIGNATURE_ARRAY);\n@@ -4179,0 +4389,19 @@\n+void ClassFileParser::throwInlineTypeLimitation(THREAD_AND_LOCATION_DECL,\n+                                                const char* msg,\n+                                                const Symbol* name,\n+                                                const Symbol* sig) const {\n+\n+  ResourceMark rm(THREAD);\n+  if (name == NULL || sig == NULL) {\n+    Exceptions::fthrow(THREAD_AND_LOCATION_ARGS,\n+        vmSymbols::java_lang_ClassFormatError(),\n+        \"class: %s - %s\", _class_name->as_C_string(), msg);\n+  }\n+  else {\n+    Exceptions::fthrow(THREAD_AND_LOCATION_ARGS,\n+        vmSymbols::java_lang_ClassFormatError(),\n+        \"\\\"%s\\\" sig: \\\"%s\\\" class: %s - %s\", name->as_C_string(), sig->as_C_string(),\n+        _class_name->as_C_string(), msg);\n+  }\n+}\n+\n@@ -4213,0 +4442,5 @@\n+      if (ik->is_inline_klass()) {\n+        JavaThread *THREAD = JavaThread::current();\n+        throwInlineTypeLimitation(THREAD_AND_LOCATION, \"Inline Types do not support Cloneable\");\n+        return;\n+      }\n@@ -4253,0 +4487,6 @@\n+bool ClassFileParser::supports_inline_types() const {\n+  \/\/ Inline types are only supported by class file version 61.65535 and later\n+  return _major_version > JAVA_20_VERSION ||\n+         (_major_version == JAVA_20_VERSION \/*&& _minor_version == JAVA_PREVIEW_MINOR_VERSION*\/); \/\/ JAVA_PREVIEW_MINOR_VERSION not yet implemented by javac, check JVMS draft\n+}\n+\n@@ -4296,3 +4536,4 @@\n-  } else if (max_transitive_size == local_size) {\n-    \/\/ only local interfaces added, share local interface array\n-    return local_ifs;\n+    \/\/ The three lines below are commented to work around bug JDK-8245487\n+\/\/  } else if (max_transitive_size == local_size) {\n+\/\/    \/\/ only local interfaces added, share local interface array\n+\/\/    return local_ifs;\n@@ -4319,0 +4560,1 @@\n+\n@@ -4347,0 +4589,10 @@\n+    \/\/ The JVMS says that super classes for value types must not have the ACC_IDENTITY\n+    \/\/ flag set. But, java.lang.Object must still be allowed to be a direct super class\n+    \/\/ for a value classes.  So, it is treated as a special case for now.\n+    if (this_klass->access_flags().is_value_class() &&\n+        super_ik->name() != vmSymbols::java_lang_Object() &&\n+        super_ik->is_identity_class()) {\n+      classfile_icce_error(\"value class %s cannot inherit from class %s\", super_ik, THREAD);\n+      return;\n+    }\n+\n@@ -4530,1 +4782,1 @@\n-void ClassFileParser::verify_legal_class_modifiers(jint flags, TRAPS) const {\n+void ClassFileParser::verify_legal_class_modifiers(jint flags, const char* name, bool is_Object, TRAPS) const {\n@@ -4532,0 +4784,4 @@\n+  const bool is_value_class = (flags & JVM_ACC_VALUE) != 0;\n+  const bool is_primitive_class = (flags & JVM_ACC_PRIMITIVE) != 0;\n+  const bool is_identity_class = (flags & JVM_ACC_IDENTITY) != 0;\n+  const bool is_inner_class = name != NULL;\n@@ -4533,0 +4789,2 @@\n+  assert(supports_inline_types() || !is_value_class, \"JVM_ACC_VALUE should not be set\");\n+  assert(supports_inline_types() || !is_primitive_class, \"JVM_ACC_PRIMITIVE should not be set\");\n@@ -4543,1 +4801,15 @@\n-  if (!_need_verify) { return; }\n+  if (!EnableValhalla) {\n+    if (is_value_class || is_primitive_class) {\n+      const char* bad_flag = is_primitive_class ? \"ACC_PRIMITIVE\" : \"ACC_VALUE\";\n+      ResourceMark rm(THREAD);\n+      Exceptions::fthrow(\n+        THREAD_AND_LOCATION,\n+        vmSymbols::java_lang_ClassFormatError(),\n+        \"Class modifier %s in class %s requires option -XX:+EnableValhalla\",\n+        bad_flag, _class_name->as_C_string()\n+      );\n+    }\n+    return;\n+  }\n+\n+  \/\/ if (!_need_verify) { return; }\n@@ -4555,2 +4827,6 @@\n-      (is_interface && major_gte_1_5 && (is_super || is_enum)) ||\n-      (!is_interface && major_gte_1_5 && is_annotation)) {\n+      (is_interface && major_gte_1_5 && ((is_super && !supports_inline_types()) || is_enum)) ||   \/\/  ACC_SUPER (now ACC_IDENTITY) was illegal for interfaces\n+      (!is_interface && major_gte_1_5 && is_annotation) ||\n+      (is_value_class && is_enum) ||\n+      (is_identity_class && is_value_class) ||\n+      (supports_inline_types() && !is_module && !is_abstract && !is_Object && !(is_identity_class || is_value_class) && !is_inner_class) ||\n+      (supports_inline_types() && is_primitive_class && (!is_value_class || !is_final || is_interface || is_abstract))) {\n@@ -4558,7 +4834,21 @@\n-    Exceptions::fthrow(\n-      THREAD_AND_LOCATION,\n-      vmSymbols::java_lang_ClassFormatError(),\n-      \"Illegal class modifiers in class %s: 0x%X\",\n-      _class_name->as_C_string(), flags\n-    );\n-    return;\n+    const char* class_note = \"\";\n+    if (is_value_class)  class_note = \" (a value class)\";\n+    if (is_primitive_class)  class_note = \" (a primitive class)\";\n+    if (is_value_class && is_identity_class) class_note = \" (a value and identity class)\";\n+    if (name == NULL) { \/\/ Not an inner class\n+      Exceptions::fthrow(\n+        THREAD_AND_LOCATION,\n+        vmSymbols::java_lang_ClassFormatError(),\n+        \"Illegal class modifiers in class %s%s: 0x%X\",\n+        _class_name->as_C_string(), class_note, flags\n+      );\n+      return;\n+    } else {\n+      Exceptions::fthrow(\n+        THREAD_AND_LOCATION,\n+        vmSymbols::java_lang_ClassFormatError(),\n+        \"Illegal class modifiers in declaration of inner class %s%s of class %s: 0x%X\",\n+        name, class_note, _class_name->as_C_string(), flags\n+      );\n+      return;\n+    }\n@@ -4630,2 +4920,2 @@\n-void ClassFileParser::verify_legal_field_modifiers(jint flags,\n-                                                   bool is_interface,\n+void ClassFileParser:: verify_legal_field_modifiers(jint flags,\n+                                                   AccessFlags class_access_flags,\n@@ -4645,0 +4935,5 @@\n+  const bool is_interface = class_access_flags.is_interface();\n+  const bool is_abstract = class_access_flags.is_abstract();\n+  const bool is_value_class = class_access_flags.is_value_class();\n+  const bool is_identity_class = class_access_flags.is_identity_class();\n+\n@@ -4656,0 +4951,6 @@\n+    } else {\n+      if (is_value_class && !is_abstract && !is_static && !is_final) {\n+        is_illegal = true;\n+      } else if (is_abstract && !is_identity_class && !is_static) {\n+        is_illegal = true;\n+      }\n@@ -4671,1 +4972,1 @@\n-                                                    bool is_interface,\n+                                                    AccessFlags class_access_flags,\n@@ -4690,0 +4991,4 @@\n+  const bool is_interface    = class_access_flags.is_interface();\n+  const bool is_value_class  = class_access_flags.is_value_class();\n+  const bool is_identity_class = class_access_flags.is_identity_class();\n+  const bool is_abstract_class = class_access_flags.is_abstract();\n@@ -4693,0 +4998,1 @@\n+  const char* class_note = \"\";\n@@ -4727,1 +5033,1 @@\n-        if (is_static || is_final || is_synchronized || is_native ||\n+        if (is_final || is_synchronized || is_native ||\n@@ -4731,0 +5037,9 @@\n+        if (!is_static && (!is_value_class || is_abstract_class)) {\n+          \/\/ OK, an object constructor in a regular class or an abstract value class\n+        } else if (is_static && is_value_class) {\n+          \/\/ OK, a static init factory in an inline class\n+        } else {\n+          \/\/ but no other combinations are allowed\n+          is_illegal = true;\n+          class_note = (is_value_class ? \" (a value class)\" : \" (not a value class)\");\n+        }\n@@ -4732,4 +5047,9 @@\n-        if (is_abstract) {\n-          if ((is_final || is_native || is_private || is_static ||\n-              (major_gte_1_5 && (is_synchronized || (!major_gte_17 && is_strict))))) {\n-            is_illegal = true;\n+        if (!is_identity_class && is_synchronized && !is_static) {\n+          is_illegal = true;\n+          class_note = \" (not an identity class)\";\n+        } else {\n+          if (is_abstract) {\n+            if ((is_final || is_native || is_private || is_static ||\n+                (major_gte_1_5 && (is_synchronized || (!major_gte_17 && is_strict))))) {\n+              is_illegal = true;\n+            }\n@@ -4747,2 +5067,2 @@\n-      \"Method %s in class %s has illegal modifiers: 0x%X\",\n-      name->as_C_string(), _class_name->as_C_string(), flags);\n+      \"Method %s in class %s%s has illegal modifiers: 0x%X\",\n+      name->as_C_string(), _class_name->as_C_string(), class_note, flags);\n@@ -4906,1 +5226,12 @@\n-    case JVM_SIGNATURE_CLASS: {\n+    case JVM_SIGNATURE_PRIMITIVE_OBJECT:\n+      \/\/ Can't enable this check fully until JDK upgrades the bytecode generators.\n+      \/\/ For now, compare to class file version 51 so old verifier doesn't see Q signatures.\n+      if (_major_version < 51 \/* CONSTANT_CLASS_DESCRIPTORS *\/ ) {\n+        classfile_parse_error(\"Class name contains illegal Q-signature \"\n+                              \"in descriptor in class file %s\",\n+                              CHECK_0);\n+        return NULL;\n+      }\n+      \/\/ fall through\n+    case JVM_SIGNATURE_CLASS:\n+    {\n@@ -4917,1 +5248,1 @@\n-        \/\/ Skip leading 'L' and ignore first appearance of ';'\n+        \/\/ Skip leading 'L' or 'Q' and ignore first appearance of ';'\n@@ -4973,0 +5304,4 @@\n+    } else if ((_major_version >= CONSTANT_CLASS_DESCRIPTORS || _class_name->starts_with(\"jdk\/internal\/reflect\/\"))\n+                   && bytes[length - 1] == ';' ) {\n+      \/\/ Support for L...; and Q...; descriptors\n+      legal = verify_unqualified_name(bytes + 1, length - 2, LegalClass);\n@@ -5070,0 +5405,3 @@\n+  if (!supports_inline_types() && (signature->is_Q_signature() || signature->is_Q_array_signature())) {\n+    throwIllegalSignature(\"Field\", name, signature, CHECK);\n+  }\n@@ -5097,2 +5435,3 @@\n-  int sig_length = signature->utf8_length();\n-  if (name->utf8_length() > 0 &&\n+  if (!is_value_class()) {\n+    int sig_length = signature->utf8_length();\n+    if (name->utf8_length() > 0 &&\n@@ -5102,1 +5441,2 @@\n-    throwIllegalSignature(\"Method\", name, signature, THREAD);\n+      throwIllegalSignature(\"Method\", name, signature, THREAD);\n+    }\n@@ -5278,1 +5618,0 @@\n-\n@@ -5314,0 +5653,10 @@\n+  if (_field_info->_is_naturally_atomic && ik->is_inline_klass()) {\n+    ik->set_is_naturally_atomic();\n+  }\n+\n+  if (carries_identity_modifier()) {\n+    ik->set_carries_identity_modifier();\n+  } else if (carries_value_modifier()) {\n+    ik->set_carries_value_modifier();\n+  }\n+\n@@ -5315,1 +5664,1 @@\n-  ik->set_static_oop_field_count(_fac->count[STATIC_OOP]);\n+  ik->set_static_oop_field_count(_fac->count[STATIC_OOP] + _fac->count[STATIC_INLINE]);\n@@ -5332,0 +5681,1 @@\n+  assert(NULL == _preload_classes, \"invariant\");\n@@ -5365,0 +5715,3 @@\n+  if (_is_declared_atomic) {\n+    ik->set_is_declared_atomic();\n+  }\n@@ -5472,0 +5825,27 @@\n+  bool all_fields_empty = true;\n+  for (AllFieldStream fs(ik->fields(), ik->constants()); !fs.done(); fs.next()) {\n+    if (!fs.access_flags().is_static()) {\n+      if (fs.field_descriptor().is_inline_type()) {\n+        Klass* k = _inline_type_field_klasses->at(fs.index());\n+        ik->set_inline_type_field_klass(fs.index(), k);\n+        if (!InlineKlass::cast(k)->is_empty_inline_type()) { all_fields_empty = false; }\n+      } else {\n+        all_fields_empty = false;\n+      }\n+    } else if (is_inline_type() && (fs.name() == vmSymbols::default_value_name())) {\n+      InlineKlass::cast(ik)->set_default_value_offset(ik->field_offset(fs.index()));\n+    }\n+  }\n+\n+  if (_is_empty_inline_type || (is_inline_type() && all_fields_empty)) {\n+    ik->set_is_empty_inline_type();\n+  }\n+\n+  if (is_inline_type()) {\n+    InlineKlass* vk = InlineKlass::cast(ik);\n+    vk->set_alignment(_alignment);\n+    vk->set_first_field_offset(_first_field_offset);\n+    vk->set_exact_size_in_bytes(_exact_size_in_bytes);\n+    InlineKlass::cast(ik)->initialize_calling_convention(CHECK);\n+  }\n+\n@@ -5562,0 +5942,1 @@\n+  _preload_classes(NULL),\n@@ -5564,0 +5945,1 @@\n+  _local_interface_indexes(NULL),\n@@ -5575,0 +5957,1 @@\n+  _inline_type_field_klasses(NULL),\n@@ -5601,0 +5984,7 @@\n+  _has_inline_type_fields(false),\n+  _has_nonstatic_fields(false),\n+  _is_empty_inline_type(false),\n+  _is_naturally_atomic(false),\n+  _is_declared_atomic(false),\n+  _carries_value_modifier(false),\n+  _carries_identity_modifier(false),\n@@ -5650,0 +6040,1 @@\n+  _preload_classes = NULL;\n@@ -5667,0 +6058,4 @@\n+  if (_inline_type_field_klasses != NULL) {\n+     MetadataFactory::free_array<InlineKlass*>(_loader_data, _inline_type_field_klasses);\n+  }\n+\n@@ -5689,0 +6084,4 @@\n+  if (_preload_classes != NULL && _preload_classes != Universe::the_empty_short_array()) {\n+    MetadataFactory::free_array<u2>(_loader_data, _preload_classes);\n+  }\n+\n@@ -5773,2 +6172,1 @@\n-  \/\/ Access flags\n-  jint flags;\n+  jint recognized_modifiers = JVM_RECOGNIZED_CLASS_MODIFIERS;\n@@ -5777,3 +6175,5 @@\n-    flags = stream->get_u2_fast() & (JVM_RECOGNIZED_CLASS_MODIFIERS | JVM_ACC_MODULE);\n-  } else {\n-    flags = stream->get_u2_fast() & JVM_RECOGNIZED_CLASS_MODIFIERS;\n+    recognized_modifiers |= JVM_ACC_MODULE;\n+  }\n+  \/\/ JVM_ACC_VALUE and JVM_ACC_PRIMITIVE are defined for class file version 55 and later\n+  if (supports_inline_types()) {\n+    recognized_modifiers |= JVM_ACC_PRIMITIVE | JVM_ACC_VALUE;\n@@ -5782,0 +6182,3 @@\n+  \/\/ Access flags\n+  jint flags = stream->get_u2_fast() & recognized_modifiers;\n+\n@@ -5787,12 +6190,0 @@\n-  verify_legal_class_modifiers(flags, CHECK);\n-\n-  short bad_constant = class_bad_constant_seen();\n-  if (bad_constant != 0) {\n-    \/\/ Do not throw CFE until after the access_flags are checked because if\n-    \/\/ ACC_MODULE is set in the access flags, then NCDFE must be thrown, not CFE.\n-    classfile_parse_error(\"Unknown constant tag %u in class file %s\", bad_constant, THREAD);\n-    return;\n-  }\n-\n-  _access_flags.set_flags(flags);\n-\n@@ -5810,0 +6201,32 @@\n+  bool is_java_lang_Object = class_name_in_cp == vmSymbols::java_lang_Object();\n+\n+  verify_legal_class_modifiers(flags, NULL, is_java_lang_Object, CHECK);\n+\n+  if (EnableValhalla) {\n+    if(!supports_inline_types()) {\n+      const bool is_module = (flags & JVM_ACC_MODULE) != 0;\n+      const bool is_interface = (flags & JVM_ACC_INTERFACE) != 0;\n+      if (!is_module && !is_interface && !is_java_lang_Object) {\n+        flags |= JVM_ACC_IDENTITY;\n+      }\n+    }\n+  }\n+\n+  _access_flags.set_flags(flags);\n+\n+  if (EnableValhalla) {\n+    if (_access_flags.is_identity_class()) set_carries_identity_modifier();\n+    if (_access_flags.is_value_class()) set_carries_value_modifier();\n+    if (carries_identity_modifier() && carries_value_modifier()) {\n+      classfile_parse_error(\"Class %s has both ACC_IDENTITY and ACC_VALUE modifiers\", THREAD);\n+    }\n+  }\n+\n+  short bad_constant = class_bad_constant_seen();\n+  if (bad_constant != 0) {\n+    \/\/ Do not throw CFE until after the access_flags are checked because if\n+    \/\/ ACC_MODULE is set in the access flags, then NCDFE must be thrown, not CFE.\n+    classfile_parse_error(\"Unknown constant tag %u in class file %s\", bad_constant, THREAD);\n+    return;\n+  }\n+\n@@ -5887,0 +6310,1 @@\n+                   &_is_declared_atomic,\n@@ -5889,2 +6313,0 @@\n-  assert(_local_interfaces != NULL, \"invariant\");\n-\n@@ -5894,1 +6316,1 @@\n-               _access_flags.is_interface(),\n+               _access_flags,\n@@ -5906,1 +6328,3 @@\n-                _access_flags.is_interface(),\n+                is_interface(),\n+                is_value_class(),\n+                is_abstract_class(),\n@@ -5989,2 +6413,2 @@\n-                   \"java.lang.Object cannot implement an interface in class file %s\",\n-                   CHECK);\n+        \"java.lang.Object cannot implement an interface in class file %s\",\n+        CHECK);\n@@ -5995,1 +6419,1 @@\n-    if (_access_flags.is_interface()) {\n+    if (is_interface()) {\n@@ -6013,0 +6437,9 @@\n+    if (_super_klass->is_interface()) {\n+      classfile_icce_error(\"class %s has interface %s as super class\", _super_klass, THREAD);\n+      return;\n+    }\n+\n+    if (EnableValhalla) {\n+      check_identity_and_value_modifiers(this, _super_klass, CHECK);\n+    }\n+\n@@ -6016,0 +6449,4 @@\n+    if (_super_klass->is_declared_atomic()) {\n+      _is_declared_atomic = true;\n+    }\n+  }\n@@ -6017,3 +6454,58 @@\n-    if (_super_klass->is_interface()) {\n-      classfile_icce_error(\"class %s has interface %s as super class\", _super_klass, THREAD);\n-      return;\n+  if (_class_name == vmSymbols::java_lang_NonTearable() && _loader_data->class_loader() == NULL) {\n+    \/\/ This is the original source of this condition.\n+    \/\/ It propagates by inheritance, as if testing \"instanceof NonTearable\".\n+    _is_declared_atomic = true;\n+  } else if (*ForceNonTearable != '\\0') {\n+    \/\/ Allow a command line switch to force the same atomicity property:\n+    const char* class_name_str = _class_name->as_C_string();\n+    if (StringUtils::class_list_match(ForceNonTearable, class_name_str)) {\n+      _is_declared_atomic = true;\n+    }\n+  }\n+\n+  int itfs_len = _local_interface_indexes == NULL ? 0 : _local_interface_indexes->length();\n+  _local_interfaces = MetadataFactory::new_array<InstanceKlass*>(_loader_data, itfs_len, NULL, CHECK);\n+  if (_local_interface_indexes != NULL) {\n+    for (int i = 0; i < _local_interface_indexes->length(); i++) {\n+      u2 interface_index = _local_interface_indexes->at(i);\n+      Klass* interf;\n+      if (cp->tag_at(interface_index).is_klass()) {\n+        interf = cp->resolved_klass_at(interface_index);\n+      } else {\n+        Symbol* const unresolved_klass  = cp->klass_name_at(interface_index);\n+\n+        \/\/ Don't need to check legal name because it's checked when parsing constant pool.\n+        \/\/ But need to make sure it's not an array type.\n+        guarantee_property(unresolved_klass->char_at(0) != JVM_SIGNATURE_ARRAY,\n+                            \"Bad interface name in class file %s\", CHECK);\n+\n+        \/\/ Call resolve_super so class circularity is checked\n+        interf = SystemDictionary::resolve_super_or_fail(\n+                                                  _class_name,\n+                                                  unresolved_klass,\n+                                                  Handle(THREAD, _loader_data->class_loader()),\n+                                                  _protection_domain,\n+                                                  false,\n+                                                  CHECK);\n+      }\n+\n+      if (!interf->is_interface()) {\n+        THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                  err_msg(\"class %s can not implement %s, because it is not an interface (%s)\",\n+                          _class_name->as_klass_external_name(),\n+                          interf->external_name(),\n+                          interf->class_in_module_of_loader()));\n+      }\n+\n+      if (EnableValhalla) {\n+        \/\/ Check modifiers and set carries_identity_modifier\/carries_value_modifier flags\n+        check_identity_and_value_modifiers(this, InstanceKlass::cast(interf), CHECK);\n+      }\n+\n+      if (InstanceKlass::cast(interf)->has_nonstatic_concrete_methods()) {\n+        _has_nonstatic_concrete_methods = true;\n+      }\n+      if (InstanceKlass::cast(interf)->is_declared_atomic()) {\n+        _is_declared_atomic = true;\n+      }\n+      _local_interfaces->at_put(i, InstanceKlass::cast(interf));\n@@ -6022,0 +6514,1 @@\n+  assert(_local_interfaces != NULL, \"invariant\");\n@@ -6050,1 +6543,1 @@\n-  _itable_size = _access_flags.is_interface() ? 0 :\n+  _itable_size = is_interface() ? 0 :\n@@ -6056,0 +6549,26 @@\n+\n+  if (EnableValhalla) {\n+    _inline_type_field_klasses = MetadataFactory::new_array<InlineKlass*>(_loader_data,\n+                                                   java_fields_count(),\n+                                                   NULL,\n+                                                   CHECK);\n+    for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_PRIMITIVE_OBJECT && !fs.access_flags().is_static()) {\n+        \/\/ Pre-load inline class\n+        Klass* klass = SystemDictionary::resolve_inline_type_field_or_fail(&fs,\n+            Handle(THREAD, _loader_data->class_loader()),\n+            _protection_domain, true, CHECK);\n+        assert(klass != NULL, \"Sanity check\");\n+        if (!klass->access_flags().is_value_class()) {\n+          assert(klass->is_instance_klass(), \"Sanity check\");\n+          ResourceMark rm(THREAD);\n+            THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                      err_msg(\"Class %s expects class %s to be an inline type, but it is not\",\n+                      _class_name->as_C_string(),\n+                      InstanceKlass::cast(klass)->external_name()));\n+        }\n+        _inline_type_field_klasses->at_put(fs.index(), InlineKlass::cast(klass));\n+      }\n+    }\n+  }\n+\n@@ -6058,2 +6577,9 @@\n-                        _parsed_annotations->is_contended(), _field_info);\n-  lb.build_layout();\n+      _parsed_annotations->is_contended(), is_inline_type(),\n+      _field_info, _inline_type_field_klasses);\n+  lb.build_layout(CHECK);\n+  if (is_inline_type()) {\n+    _alignment = lb.get_alignment();\n+    _first_field_offset = lb.get_first_field_offset();\n+    _exact_size_in_bytes = lb.get_exact_size_in_byte();\n+  }\n+  _has_inline_type_fields = _field_info->_has_inline_fields;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":677,"deletions":151,"binary":false,"changes":828,"status":"modified"},{"patch":"@@ -77,0 +77,2 @@\n+  bool  _is_naturally_atomic;\n+  bool _has_inline_fields;\n@@ -130,0 +132,1 @@\n+  Array<u2>* _preload_classes;\n@@ -132,0 +135,1 @@\n+  GrowableArray<u2>* _local_interface_indexes;\n@@ -144,0 +148,1 @@\n+  Array<InlineKlass*>* _inline_type_field_klasses;\n@@ -156,0 +161,4 @@\n+  int _alignment;\n+  int _first_field_offset;\n+  int _exact_size_in_bytes;\n+\n@@ -193,0 +202,8 @@\n+  bool _has_inline_type_fields;\n+  bool _has_nonstatic_fields;\n+  bool _is_empty_inline_type;\n+  bool _is_naturally_atomic;\n+  bool _is_declared_atomic;\n+  bool _carries_value_modifier;      \/\/ Has ACC_VALUE mddifier or one of its super types has\n+  bool _carries_identity_modifier;   \/\/ Has ACC_IDENTITY modifier or one of its super types has\n+\n@@ -240,0 +257,1 @@\n+                        bool* is_declared_atomic,\n@@ -259,1 +277,1 @@\n-                    bool is_interface,\n+                    AccessFlags class_access_flags,\n@@ -269,0 +287,2 @@\n+                       bool is_value_class,\n+                       bool is_abstract_class,\n@@ -275,0 +295,2 @@\n+                     bool is_value_class,\n+                     bool is_abstract_class,\n@@ -329,0 +351,4 @@\n+  u2 parse_classfile_preload_attribute(const ClassFileStream* const cfs,\n+                                                    const u1* const preload_attribute_start,\n+                                                    TRAPS);\n+\n@@ -447,0 +473,5 @@\n+  void throwInlineTypeLimitation(THREAD_AND_LOCATION_DECL,\n+                                 const char* msg,\n+                                 const Symbol* name = NULL,\n+                                 const Symbol* sig  = NULL) const;\n+\n@@ -469,2 +500,4 @@\n-  void verify_legal_class_modifiers(jint flags, TRAPS) const;\n-  void verify_legal_field_modifiers(jint flags, bool is_interface, TRAPS) const;\n+  void verify_legal_class_modifiers(jint flags, const char* name, bool is_Object, TRAPS) const;\n+  void verify_legal_field_modifiers(jint flags,\n+                                    AccessFlags class_access_flags,\n+                                    TRAPS) const;\n@@ -472,1 +505,1 @@\n-                                     bool is_interface,\n+                                     AccessFlags class_access_flags,\n@@ -530,0 +563,3 @@\n+  \/\/ Check if the class file supports inline types\n+  bool supports_inline_types() const;\n+\n@@ -557,0 +593,12 @@\n+  bool is_inline_type() const { return _access_flags.is_value_class() && !_access_flags.is_interface() && !_access_flags.is_abstract(); }\n+  bool is_value_class() const { return _access_flags.is_value_class(); }\n+  bool is_abstract_class() const { return _access_flags.is_abstract(); }\n+  bool is_identity_class() const { return _access_flags.is_identity_class(); }\n+  bool is_value_capable_class() const;\n+  bool has_inline_fields() const { return _has_inline_type_fields; }\n+  bool carries_identity_modifier() const { return _carries_identity_modifier; }\n+  void set_carries_identity_modifier() { _carries_identity_modifier = true; }\n+  bool carries_value_modifier() const { return _carries_value_modifier; }\n+  void set_carries_value_modifier() { _carries_value_modifier = true; }\n+\n+  u2 java_fields_count() const { return _java_fields_count; }\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":52,"deletions":4,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -207,1 +207,1 @@\n-    if (*start == JVM_SIGNATURE_CLASS) {\n+    if (*start == JVM_SIGNATURE_CLASS || *start == JVM_SIGNATURE_PRIMITIVE_OBJECT) {\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -54,0 +54,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -55,1 +57,1 @@\n-#include \"oops\/instanceMirrorKlass.hpp\"\n+#include \"oops\/instanceMirrorKlass.inline.hpp\"\n@@ -783,0 +785,2 @@\n+int java_lang_Class::_primary_mirror_offset;\n+int java_lang_Class::_secondary_mirror_offset;\n@@ -1006,1 +1010,6 @@\n-      if (k->is_typeArray_klass()) {\n+      if (k->is_flatArray_klass()) {\n+        Klass* element_klass = (Klass*) FlatArrayKlass::cast(k)->element_klass();\n+        assert(element_klass->is_inline_klass(), \"Must be inline type component\");\n+        InlineKlass* vk = InlineKlass::cast(element_klass);\n+        comp_mirror = Handle(THREAD, vk->val_mirror());\n+      } else if (k->is_typeArray_klass()) {\n@@ -1013,1 +1022,6 @@\n-        comp_mirror = Handle(THREAD, element_klass->java_mirror());\n+        oop comp_oop = element_klass->java_mirror();\n+        if (element_klass->is_inline_klass()) {\n+          InlineKlass* ik = InlineKlass::cast(element_klass);\n+          comp_oop = k->name()->is_Q_array_signature() ? ik->val_mirror() : ik->ref_mirror();\n+        }\n+        comp_mirror = Handle(THREAD, comp_oop);\n@@ -1053,0 +1067,6 @@\n+\n+    if (k->is_inline_klass()) {\n+      oop secondary_mirror = create_secondary_mirror(k, mirror, CHECK);\n+      set_primary_mirror(mirror(), mirror());\n+      set_secondary_mirror(mirror(), secondary_mirror);\n+    }\n@@ -1058,0 +1078,19 @@\n+\/\/ Create the secondary mirror for inline class. Sets all the fields of this java.lang.Class\n+\/\/ instance with the same value as the primary mirror\n+oop java_lang_Class::create_secondary_mirror(Klass* k, Handle mirror, TRAPS) {\n+  assert(k->is_inline_klass(), \"primitive class\");\n+  \/\/ Allocate mirror (java.lang.Class instance)\n+  oop mirror_oop = InstanceMirrorKlass::cast(vmClasses::Class_klass())->allocate_instance(k, CHECK_0);\n+  Handle secondary_mirror(THREAD, mirror_oop);\n+\n+  java_lang_Class::set_klass(secondary_mirror(), k);\n+  java_lang_Class::set_static_oop_field_count(secondary_mirror(), static_oop_field_count(mirror()));\n+\n+  set_protection_domain(secondary_mirror(), protection_domain(mirror()));\n+  set_class_loader(secondary_mirror(), class_loader(mirror()));\n+  \/\/ ## handle if java.base is not yet defined\n+  set_module(secondary_mirror(), module(mirror()));\n+  set_primary_mirror(secondary_mirror(), mirror());\n+  set_secondary_mirror(secondary_mirror(), secondary_mirror());\n+  return secondary_mirror();\n+}\n@@ -1105,0 +1144,1 @@\n+      case T_PRIMITIVE_OBJECT:\n@@ -1200,0 +1240,6 @@\n+  if (k->is_inline_klass()) {\n+    \/\/ Inline types have a primary mirror and a secondary mirror. Don't handle this for now. TODO:CDS\n+    k->clear_java_mirror_handle();\n+    return NULL;\n+  }\n+\n@@ -1399,0 +1445,20 @@\n+oop java_lang_Class::primary_mirror(oop java_class) {\n+  assert(_primary_mirror_offset != 0, \"must be set\");\n+  return java_class->obj_field(_primary_mirror_offset);\n+}\n+\n+void java_lang_Class::set_primary_mirror(oop java_class, oop mirror) {\n+  assert(_primary_mirror_offset != 0, \"must be set\");\n+  java_class->obj_field_put(_primary_mirror_offset, mirror);\n+}\n+\n+oop java_lang_Class::secondary_mirror(oop java_class) {\n+  assert(_secondary_mirror_offset != 0, \"must be set\");\n+  return java_class->obj_field(_secondary_mirror_offset);\n+}\n+\n+void java_lang_Class::set_secondary_mirror(oop java_class, oop mirror) {\n+  assert(_secondary_mirror_offset != 0, \"must be set\");\n+  java_class->obj_field_put(_secondary_mirror_offset, mirror);\n+}\n+\n@@ -1483,0 +1549,1 @@\n+  bool is_Q_descriptor = false;\n@@ -1488,0 +1555,1 @@\n+    is_Q_descriptor = k->is_inline_klass() && is_secondary_mirror(java_class);\n@@ -1494,1 +1562,3 @@\n-  if (is_instance)  st->print(\"L\");\n+  if (is_instance)  {\n+    st->print(is_Q_descriptor ? \"Q\" : \"L\");\n+  }\n@@ -1515,2 +1585,7 @@\n-      const char* sigstr = k->signature_name();\n-      int         siglen = (int) strlen(sigstr);\n+      const char* sigstr;\n+      if (k->is_inline_klass() && is_secondary_mirror(java_class)) {\n+        sigstr = InlineKlass::cast(k)->val_signature_name();\n+      } else {\n+        sigstr = k->signature_name();\n+      }\n+      int siglen = (int) strlen(sigstr);\n@@ -1596,0 +1671,2 @@\n+  macro(_primary_mirror_offset,      k, \"primaryType\",         class_signature,       false); \\\n+  macro(_secondary_mirror_offset,    k, \"secondaryType\",       class_signature,       false); \\\n@@ -2843,1 +2920,1 @@\n-      if (method->name() == vmSymbols::object_initializer_name() &&\n+      if (method->is_object_constructor() &&\n@@ -4429,1 +4506,1 @@\n-  return (flags(mname) & (MN_IS_METHOD | MN_IS_CONSTRUCTOR)) > 0;\n+  return (flags(mname) & (MN_IS_METHOD | MN_IS_OBJECT_CONSTRUCTOR)) > 0;\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":85,"deletions":8,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -231,0 +231,3 @@\n+  static int _primary_mirror_offset;\n+  static int _secondary_mirror_offset;\n+\n@@ -244,0 +247,3 @@\n+  static void set_primary_mirror(oop java_class, oop comp_mirror);\n+  static void set_secondary_mirror(oop java_class, oop comp_mirror);\n+\n@@ -256,0 +262,1 @@\n+  static oop  create_secondary_mirror(Klass* k, Handle mirror, TRAPS);\n@@ -290,0 +297,3 @@\n+  static int component_mirror_offset()     { CHECK_INIT(_component_mirror_offset); }\n+  static int primary_mirror_offset()       { CHECK_INIT(_primary_mirror_offset); }\n+  static int secondary_mirror_offset()     { CHECK_INIT(_secondary_mirror_offset); }\n@@ -297,0 +307,5 @@\n+  static oop  primary_mirror(oop java_class);\n+  static oop  secondary_mirror(oop java_class);\n+  static bool is_primary_mirror(oop java_class);\n+  static bool is_secondary_mirror(oop java_class);\n+\n@@ -302,2 +317,0 @@\n-  static int component_mirror_offset() { return _component_mirror_offset; }\n-\n@@ -1311,1 +1324,1 @@\n-    MN_IS_CONSTRUCTOR        = 0x00020000, \/\/ constructor\n+    MN_IS_OBJECT_CONSTRUCTOR = 0x00020000, \/\/ constructor\n@@ -1316,0 +1329,1 @@\n+    MN_FLATTENED             = 0x00400000, \/\/ flattened field\n@@ -1854,1 +1868,0 @@\n-\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -306,0 +306,18 @@\n+inline bool java_lang_Class::is_primary_mirror(oop java_class) {\n+  Klass* k = as_Klass(java_class);\n+  if (k->is_inline_klass()) {\n+    return java_class == primary_mirror(java_class);\n+  } else {\n+    return true;\n+  }\n+}\n+\n+inline bool java_lang_Class::is_secondary_mirror(oop java_class) {\n+  Klass* k = as_Klass(java_class);\n+  if (k->is_inline_klass()) {\n+    return java_class == secondary_mirror(java_class);\n+  } else {\n+    return false;\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.inline.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -64,0 +64,2 @@\n+\/\/ For INLINE_FIELD, set when loading inline type fields for\n+\/\/ class circularity checking.\n@@ -104,0 +106,3 @@\n+    case PlaceholderTable::PRIMITIVE_OBJECT_FIELD:\n+       queuehead = _inlineTypeFieldQ;\n+       break;\n@@ -120,0 +125,3 @@\n+    case PlaceholderTable::PRIMITIVE_OBJECT_FIELD:\n+       _inlineTypeFieldQ = seenthread;\n+       break;\n@@ -234,0 +242,1 @@\n+  case PlaceholderTable::PRIMITIVE_OBJECT_FIELD: return \"PRIMITIVE_OBJECT_FIELD\";\n@@ -297,1 +306,2 @@\n-        && (probe->defineThreadQ() == NULL) && (probe->definer() == NULL)) {\n+        && (probe->defineThreadQ() == NULL) && (probe->definer() == NULL)\n+        && (probe->inlineTypeFieldQ() == NULL)) {\n@@ -333,0 +343,3 @@\n+  st->print(\"inlineTypeFieldQ threads:\");\n+  inlineTypeFieldQ()->print_action_queue(st);\n+  st->cr();\n","filename":"src\/hotspot\/share\/classfile\/placeholders.cpp","additions":14,"deletions":1,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -70,0 +71,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -77,0 +79,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -330,1 +333,1 @@\n-      \/\/ Ignore wrapping L and ;.\n+      \/\/ Ignore wrapping L and ; (and Q and ; for value types).\n@@ -359,1 +362,8 @@\n-      k = k->array_klass(ndims, CHECK_NULL);\n+      if (class_name->is_Q_array_signature()) {\n+        if (!k->is_inline_klass()) {\n+          THROW_MSG_NULL(vmSymbols::java_lang_IncompatibleClassChangeError(), \"L\/Q mismatch on bottom type\");\n+        }\n+        k = InlineKlass::cast(k)->value_array_klass(ndims, CHECK_NULL);\n+      } else {\n+        k = k->array_klass(ndims, CHECK_NULL);\n+      }\n@@ -486,0 +496,43 @@\n+Klass* SystemDictionary::resolve_inline_type_field_or_fail(AllFieldStream* fs,\n+                                                           Handle class_loader,\n+                                                           Handle protection_domain,\n+                                                           bool throw_error,\n+                                                           TRAPS) {\n+  Symbol* class_name = fs->signature()->fundamental_name(THREAD);\n+  class_loader = Handle(THREAD, java_lang_ClassLoader::non_reflection_class_loader(class_loader()));\n+  ClassLoaderData* loader_data = class_loader_data(class_loader);\n+  bool throw_circularity_error = false;\n+  PlaceholderEntry* oldprobe;\n+\n+  {\n+    MutexLocker mu(THREAD, SystemDictionary_lock);\n+    oldprobe = PlaceholderTable::get_entry(class_name, loader_data);\n+    if (oldprobe != NULL &&\n+      oldprobe->check_seen_thread(THREAD, PlaceholderTable::PRIMITIVE_OBJECT_FIELD)) {\n+      throw_circularity_error = true;\n+\n+    } else {\n+      PlaceholderTable::find_and_add(class_name, loader_data,\n+                                   PlaceholderTable::PRIMITIVE_OBJECT_FIELD, NULL, THREAD);\n+    }\n+  }\n+\n+  Klass* klass = NULL;\n+  if (!throw_circularity_error) {\n+    klass = SystemDictionary::resolve_or_fail(class_name, class_loader,\n+                                               protection_domain, true, THREAD);\n+  } else {\n+    ResourceMark rm(THREAD);\n+    THROW_MSG_NULL(vmSymbols::java_lang_ClassCircularityError(), class_name->as_C_string());\n+  }\n+\n+  {\n+    MutexLocker mu(THREAD, SystemDictionary_lock);\n+    PlaceholderTable::find_and_remove(class_name, loader_data,\n+                                      PlaceholderTable::PRIMITIVE_OBJECT_FIELD, THREAD);\n+  }\n+\n+  class_name->decrement_refcount();\n+  return klass;\n+}\n+\n@@ -839,1 +892,1 @@\n-    if (t != T_OBJECT) {\n+    if (t != T_OBJECT && t != T_PRIMITIVE_OBJECT) {\n@@ -845,1 +898,5 @@\n-      k = k->array_klass_or_null(ndims);\n+      if (class_name->is_Q_array_signature()) {\n+        k = InlineKlass::cast(k)->value_array_klass_or_null(ndims);\n+      } else {\n+        k = k->array_klass_or_null(ndims);\n+      }\n@@ -1196,0 +1253,18 @@\n+\n+  if (ik->has_inline_type_fields()) {\n+    for (AllFieldStream fs(ik->fields(), ik->constants()); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_PRIMITIVE_OBJECT) {\n+        if (!fs.access_flags().is_static()) {\n+          \/\/ Pre-load inline class\n+          Klass* real_k = SystemDictionary::resolve_inline_type_field_or_fail(&fs,\n+            class_loader, protection_domain, true, CHECK_NULL);\n+          Klass* k = ik->get_inline_type_field_klass_or_null(fs.index());\n+          if (real_k != k) {\n+            \/\/ oops, the app has substituted a different version of k!\n+            return NULL;\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1231,0 +1306,1 @@\n+\n@@ -1819,1 +1895,1 @@\n-    if (t != T_OBJECT) {\n+    if (t != T_OBJECT && t != T_PRIMITIVE_OBJECT) {\n@@ -1827,1 +1903,5 @@\n-      klass = klass->array_klass_or_null(ndims);\n+      if (class_name->is_Q_array_signature()) {\n+        klass = InlineKlass::cast(klass)->value_array_klass_or_null(ndims);\n+      } else {\n+        klass = klass->array_klass_or_null(ndims);\n+      }\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":86,"deletions":6,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+class AllFieldStream;\n@@ -135,0 +136,6 @@\n+  static Klass* resolve_inline_type_field_or_fail(AllFieldStream* fs,\n+                                                  Handle class_loader,\n+                                                  Handle protection_domain,\n+                                                  bool throw_error,\n+                                                  TRAPS);\n+\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -249,0 +249,2 @@\n+  case vmIntrinsics::_asPrimaryType:\n+  case vmIntrinsics::_asValueType:\n@@ -319,0 +321,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:\n+  case vmIntrinsics::_finishPrivateBuffer:\n@@ -328,0 +332,1 @@\n+  case vmIntrinsics::_getValue:\n@@ -337,0 +342,1 @@\n+  case vmIntrinsics::_putValue:\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -290,0 +290,4 @@\n+  do_intrinsic(_asPrimaryType,            java_lang_Class,        asPrimaryType_name, void_class_signature,      F_R)   \\\n+   do_name(     asPrimaryType_name,                              \"asPrimaryType\")                                       \\\n+  do_intrinsic(_asValueType,              java_lang_Class,        asValueType_name, void_class_signature,        F_R)   \\\n+   do_name(     asValueType_name,                                \"asValueType\")                                         \\\n@@ -626,0 +630,2 @@\n+  do_signature(getValue_signature,        \"(Ljava\/lang\/Object;JLjava\/lang\/Class;)Ljava\/lang\/Object;\")                   \\\n+  do_signature(putValue_signature,        \"(Ljava\/lang\/Object;JLjava\/lang\/Class;Ljava\/lang\/Object;)V\")                  \\\n@@ -636,0 +642,3 @@\n+  do_name(getValue_name,\"getValue\")             do_name(putValue_name,\"putValue\")                                       \\\n+  do_name(makePrivateBuffer_name,\"makePrivateBuffer\")                                                                   \\\n+  do_name(finishPrivateBuffer_name,\"finishPrivateBuffer\")                                                               \\\n@@ -646,0 +655,1 @@\n+  do_intrinsic(_getValue,           jdk_internal_misc_Unsafe,     getValue_name, getValue_signature,             F_RN)  \\\n@@ -655,0 +665,4 @@\n+  do_intrinsic(_putValue,           jdk_internal_misc_Unsafe,     putValue_name, putValue_signature,             F_RN)  \\\n+                                                                                                                        \\\n+  do_intrinsic(_makePrivateBuffer,  jdk_internal_misc_Unsafe,     makePrivateBuffer_name, object_object_signature, F_RN)   \\\n+  do_intrinsic(_finishPrivateBuffer,  jdk_internal_misc_Unsafe,   finishPrivateBuffer_name, object_object_signature, F_RN) \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -649,0 +649,6 @@\n+\n+    assert(!method->has_scalarized_args(), \"scalarized native wrappers not supported yet\"); \/\/ for the next 3 fields\n+    _inline_entry_point       = _entry_point;\n+    _verified_inline_entry_point = _verified_entry_point;\n+    _verified_inline_ro_entry_point = _verified_entry_point;\n+\n@@ -824,0 +830,3 @@\n+    _inline_entry_point       = code_begin()         + offsets->value(CodeOffsets::Inline_Entry);\n+    _verified_inline_entry_point = code_begin()      + offsets->value(CodeOffsets::Verified_Inline_Entry);\n+    _verified_inline_ro_entry_point = code_begin()   + offsets->value(CodeOffsets::Verified_Inline_Entry_RO);\n@@ -2941,0 +2950,1 @@\n+  if (pos == inline_entry_point())                                      label = \"[Inline Entry Point]\";\n@@ -2942,0 +2952,2 @@\n+  if (pos == verified_inline_entry_point())                             label = \"[Verified Inline Entry Point]\";\n+  if (pos == verified_inline_ro_entry_point())                          label = \"[Verified Inline Entry Point (RO)]\";\n@@ -2951,0 +2963,10 @@\n+static int maybe_print_entry_label(outputStream* stream, address pos, address entry, const char* label) {\n+  if (pos == entry) {\n+    stream->bol();\n+    stream->print_cr(\"%s\", label);\n+    return 1;\n+  } else {\n+    return 0;\n+  }\n+}\n+\n@@ -2953,33 +2975,12 @@\n-    const char* label = nmethod_section_label(block_begin);\n-    if (label != NULL) {\n-      stream->bol();\n-      stream->print_cr(\"%s\", label);\n-    }\n-  }\n-\n-  if (block_begin == entry_point()) {\n-    Method* m = method();\n-    if (m != NULL) {\n-      stream->print(\"  # \");\n-      m->print_value_on(stream);\n-      stream->cr();\n-    }\n-    if (m != NULL && !is_osr_method()) {\n-      ResourceMark rm;\n-      int sizeargs = m->size_of_parameters();\n-      BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sizeargs);\n-      VMRegPair* regs   = NEW_RESOURCE_ARRAY(VMRegPair, sizeargs);\n-      {\n-        int sig_index = 0;\n-        if (!m->is_static())\n-          sig_bt[sig_index++] = T_OBJECT; \/\/ 'this'\n-        for (SignatureStream ss(m->signature()); !ss.at_return_type(); ss.next()) {\n-          BasicType t = ss.type();\n-          sig_bt[sig_index++] = t;\n-          if (type2size[t] == 2) {\n-            sig_bt[sig_index++] = T_VOID;\n-          } else {\n-            assert(type2size[t] == 1, \"size is 1 or 2\");\n-          }\n-        }\n-        assert(sig_index == sizeargs, \"\");\n+    int n = 0;\n+    \/\/ Multiple entry points may be at the same position. Print them all.\n+    n += maybe_print_entry_label(stream, block_begin, entry_point(),                    \"[Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, inline_entry_point(),             \"[Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_entry_point(),           \"[Verified Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_entry_point(),    \"[Verified Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_ro_entry_point(), \"[Verified Inline Entry Point (RO)]\");\n+    if (n == 0) {\n+      const char* label = nmethod_section_label(block_begin);\n+      if (label != NULL) {\n+        stream->bol();\n+        stream->print_cr(\"%s\", label);\n@@ -2987,54 +2988,63 @@\n-      const char* spname = \"sp\"; \/\/ make arch-specific?\n-      intptr_t out_preserve = SharedRuntime::java_calling_convention(sig_bt, regs, sizeargs);\n-      int stack_slot_offset = this->frame_size() * wordSize;\n-      int tab1 = 14, tab2 = 24;\n-      int sig_index = 0;\n-      int arg_index = (m->is_static() ? 0 : -1);\n-      bool did_old_sp = false;\n-      for (SignatureStream ss(m->signature()); !ss.at_return_type(); ) {\n-        bool at_this = (arg_index == -1);\n-        bool at_old_sp = false;\n-        BasicType t = (at_this ? T_OBJECT : ss.type());\n-        assert(t == sig_bt[sig_index], \"sigs in sync\");\n-        if (at_this)\n-          stream->print(\"  # this: \");\n-        else\n-          stream->print(\"  # parm%d: \", arg_index);\n-        stream->move_to(tab1);\n-        VMReg fst = regs[sig_index].first();\n-        VMReg snd = regs[sig_index].second();\n-        if (fst->is_reg()) {\n-          stream->print(\"%s\", fst->name());\n-          if (snd->is_valid())  {\n-            stream->print(\":%s\", snd->name());\n-          }\n-        } else if (fst->is_stack()) {\n-          int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n-          if (offset == stack_slot_offset)  at_old_sp = true;\n-          stream->print(\"[%s+0x%x]\", spname, offset);\n-        } else {\n-          stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n-        }\n-        stream->print(\" \");\n-        stream->move_to(tab2);\n-        stream->print(\"= \");\n-        if (at_this) {\n-          m->method_holder()->print_value_on(stream);\n-        } else {\n-          bool did_name = false;\n-          if (!at_this && ss.is_reference()) {\n-            Symbol* name = ss.as_symbol();\n-            name->print_value_on(stream);\n-            did_name = true;\n-          }\n-          if (!did_name)\n-            stream->print(\"%s\", type2name(t));\n-        }\n-        if (at_old_sp) {\n-          stream->print(\"  (%s of caller)\", spname);\n-          did_old_sp = true;\n-        }\n-        stream->cr();\n-        sig_index += type2size[t];\n-        arg_index += 1;\n-        if (!at_this)  ss.next();\n+    }\n+  }\n+\n+  Method* m = method();\n+  if (m == NULL || is_osr_method()) {\n+    return;\n+  }\n+\n+  \/\/ Print the name of the method (only once)\n+  address low = MIN4(entry_point(), verified_entry_point(), verified_inline_entry_point(), verified_inline_ro_entry_point());\n+  low = MIN2(low, inline_entry_point());\n+  assert(low != 0, \"sanity\");\n+  if (block_begin == low) {\n+    stream->print(\"  # \");\n+    m->print_value_on(stream);\n+    stream->cr();\n+  }\n+\n+  \/\/ Print the arguments for the 3 types of verified entry points\n+  CompiledEntrySignature ces(m);\n+  ces.compute_calling_conventions();\n+  const GrowableArray<SigEntry>* sig_cc;\n+  const VMRegPair* regs;\n+  if (block_begin == verified_entry_point()) {\n+    sig_cc = &ces.sig_cc();\n+    regs = ces.regs_cc();\n+  } else if (block_begin == verified_inline_entry_point()) {\n+    sig_cc = &ces.sig();\n+    regs = ces.regs();\n+  } else if (block_begin == verified_inline_ro_entry_point()) {\n+    sig_cc = &ces.sig_cc_ro();\n+    regs = ces.regs_cc_ro();\n+  } else {\n+    return;\n+  }\n+\n+  bool has_this = !m->is_static();\n+  if (ces.has_inline_recv() && block_begin == verified_entry_point()) {\n+    \/\/ <this> argument is scalarized for verified_entry_point()\n+    has_this = false;\n+  }\n+  const char* spname = \"sp\"; \/\/ make arch-specific?\n+  int stack_slot_offset = this->frame_size() * wordSize;\n+  int tab1 = 14, tab2 = 24;\n+  int sig_index = 0;\n+  int arg_index = has_this ? -1 : 0;\n+  bool did_old_sp = false;\n+  for (ExtendedSignature sig = ExtendedSignature(sig_cc, SigEntryFilter()); !sig.at_end(); ++sig) {\n+    bool at_this = (arg_index == -1);\n+    bool at_old_sp = false;\n+    BasicType t = (*sig)._bt;\n+    if (at_this) {\n+      stream->print(\"  # this: \");\n+    } else {\n+      stream->print(\"  # parm%d: \", arg_index);\n+    }\n+    stream->move_to(tab1);\n+    VMReg fst = regs[sig_index].first();\n+    VMReg snd = regs[sig_index].second();\n+    if (fst->is_reg()) {\n+      stream->print(\"%s\", fst->name());\n+      if (snd->is_valid())  {\n+        stream->print(\":%s\", snd->name());\n@@ -3042,6 +3052,18 @@\n-      if (!did_old_sp) {\n-        stream->print(\"  # \");\n-        stream->move_to(tab1);\n-        stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n-        stream->print(\"  (%s of caller)\", spname);\n-        stream->cr();\n+    } else if (fst->is_stack()) {\n+      int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n+      if (offset == stack_slot_offset)  at_old_sp = true;\n+      stream->print(\"[%s+0x%x]\", spname, offset);\n+    } else {\n+      stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n+    }\n+    stream->print(\" \");\n+    stream->move_to(tab2);\n+    stream->print(\"= \");\n+    if (at_this) {\n+      m->method_holder()->print_value_on(stream);\n+    } else {\n+      bool did_name = false;\n+      if (is_reference_type(t)) {\n+        Symbol* name = (*sig)._symbol;\n+        name->print_value_on(stream);\n+        did_name = true;\n@@ -3049,0 +3071,2 @@\n+      if (!did_name)\n+        stream->print(\"%s\", type2name(t));\n@@ -3050,0 +3074,14 @@\n+    if (at_old_sp) {\n+      stream->print(\"  (%s of caller)\", spname);\n+      did_old_sp = true;\n+    }\n+    stream->cr();\n+    sig_index += type2size[t];\n+    arg_index += 1;\n+  }\n+  if (!did_old_sp) {\n+    stream->print(\"  # \");\n+    stream->move_to(tab1);\n+    stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n+    stream->print(\"  (%s of caller)\", spname);\n+    stream->cr();\n@@ -3173,1 +3211,1 @@\n-      st->print(\" {reexecute=%d rethrow=%d return_oop=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop());\n+      st->print(\" {reexecute=%d rethrow=%d return_oop=%d return_scalarized=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop(), sd->return_scalarized());\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":132,"deletions":94,"binary":false,"changes":226,"status":"modified"},{"patch":"@@ -518,1 +518,2 @@\n-    if (klass->is_array_klass()) {\n+    \/\/ CMH: Valhalla flat arrays can split this work up, but for now, doesn't\n+    if (klass->is_array_klass() && !klass->is_flatArray_klass()) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -71,0 +71,1 @@\n+#include \"oops\/flatArrayKlass.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -107,1 +107,1 @@\n-    number_of_result_handlers = 10                              \/\/ number of result handlers for native calls\n+    number_of_result_handlers = 11                              \/\/ number of result handlers for native calls\n","filename":"src\/hotspot\/share\/interpreter\/abstractInterpreter.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -963,0 +963,1 @@\n+         byte == Bytecodes::_withfield ||\n@@ -967,1 +968,2 @@\n-  bool is_put    = (byte == Bytecodes::_putfield  || byte == Bytecodes::_putstatic || byte == Bytecodes::_nofast_putfield);\n+  bool is_put    = (byte == Bytecodes::_putfield  || byte == Bytecodes::_putstatic ||\n+                    byte == Bytecodes::_nofast_putfield || byte == Bytecodes::_withfield);\n@@ -978,0 +980,14 @@\n+  if (byte == Bytecodes::_withfield && !resolved_klass->is_inline_klass()) {\n+    ResourceMark rm(THREAD);\n+    char msg[200];\n+    jio_snprintf(msg, sizeof(msg), \"Bytecode withfield cannot be used on identity class %s\", resolved_klass->external_name());\n+    THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(), msg);\n+  }\n+\n+  if (is_put && !is_static && byte != Bytecodes::_withfield && resolved_klass->is_inline_klass()) {\n+    ResourceMark rm(THREAD);\n+    char msg[200];\n+    jio_snprintf(msg, sizeof(msg), \"Bytecode putfield cannot be used on primitive class %s\", resolved_klass->external_name());\n+    THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(), msg);\n+  }\n+\n@@ -1005,0 +1021,2 @@\n+    \/\/ (3) by withfield when field is in a value type and the\n+    \/\/     selected class and current class are nest mates.\n@@ -1008,6 +1026,15 @@\n-        ResourceMark rm(THREAD);\n-        stringStream ss;\n-        ss.print(\"Update to %s final field %s.%s attempted from a different class (%s) than the field's declaring class\",\n-                 is_static ? \"static\" : \"non-static\", resolved_klass->external_name(), fd.name()->as_C_string(),\n-                current_klass->external_name());\n-        THROW_MSG(vmSymbols::java_lang_IllegalAccessError(), ss.as_string());\n+        \/\/ If byte code is a withfield check if they are nestmates.\n+        bool are_nestmates = false;\n+        if (sel_klass->is_instance_klass() &&\n+            InstanceKlass::cast(sel_klass)->is_inline_klass() &&\n+            current_klass->is_instance_klass()) {\n+          are_nestmates = InstanceKlass::cast(current_klass)->has_nestmate_access_to(InstanceKlass::cast(sel_klass), THREAD);\n+        }\n+        if (!are_nestmates) {\n+          ResourceMark rm(THREAD);\n+          stringStream ss;\n+          ss.print(\"Update to %s final field %s.%s attempted from a different class (%s) than the field's declaring class\",\n+                   is_static ? \"static\" : \"non-static\", resolved_klass->external_name(), fd.name()->as_C_string(),\n+                    current_klass->external_name());\n+          THROW_MSG(vmSymbols::java_lang_IllegalAccessError(), ss.as_string());\n+        }\n@@ -1021,1 +1048,1 @@\n-                                                   !m->is_static_initializer());\n+                                                   !m->is_class_initializer());\n@@ -1024,1 +1051,1 @@\n-                                                     !m->is_object_initializer());\n+                                                     !m->is_object_constructor());\n@@ -1152,0 +1179,2 @@\n+  \/\/ Since this method is never inherited from a super, any appearance here under\n+  \/\/ the wrong class would be an error.\n@@ -1222,1 +1251,1 @@\n-      \/\/ check if the method is not <init>\n+      \/\/ check if the method is not <init>, which is never inherited\n@@ -1644,2 +1673,2 @@\n-                             const methodHandle& attached_method,\n-                             Bytecodes::Code byte, TRAPS) {\n+                                  const methodHandle& attached_method,\n+                                  Bytecodes::Code byte, bool check_null_and_abstract, TRAPS) {\n@@ -1650,0 +1679,1 @@\n+  Klass* recv_klass = recv.is_null() ? defc : recv->klass();\n@@ -1652,2 +1682,2 @@\n-      resolve_virtual_call(result, recv, recv->klass(), link_info,\n-                           \/*check_null_and_abstract=*\/true, CHECK);\n+      resolve_virtual_call(result, recv, recv_klass, link_info,\n+                           check_null_and_abstract, CHECK);\n@@ -1656,2 +1686,2 @@\n-      resolve_interface_call(result, recv, recv->klass(), link_info,\n-                             \/*check_null_and_abstract=*\/true, CHECK);\n+      resolve_interface_call(result, recv, recv_klass, link_info,\n+                             check_null_and_abstract, CHECK);\n","filename":"src\/hotspot\/share\/interpreter\/linkResolver.cpp","additions":46,"deletions":16,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -84,1 +84,1 @@\n-  assert(number_of_states == 10, \"check the code below\");\n+  assert(number_of_states == 10 , \"check the code below\");\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreter.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -53,1 +53,2 @@\n-  T_OBJECT\n+  T_OBJECT ,\n+  T_PRIMITIVE_OBJECT\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreterGenerator.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -161,1 +161,1 @@\n-  nonstatic_field(InstanceKlass,               _misc_flags,                                   u2)                                    \\\n+  nonstatic_field(InstanceKlass,               _misc_flags,                                   u4)                                    \\\n@@ -598,0 +598,2 @@\n+  declare_constant(DataLayout::array_load_store_data_tag)                 \\\n+  declare_constant(DataLayout::acmp_data_tag)                             \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -134,0 +134,2 @@\n+LatestMethodCache* Universe::_is_substitutable_cache  = NULL;\n+LatestMethodCache* Universe::_primitive_type_hash_code_cache = NULL;\n@@ -237,0 +239,2 @@\n+  _is_substitutable_cache->metaspace_pointers_do(it);\n+  _primitive_type_hash_code_cache->metaspace_pointers_do(it);\n@@ -285,0 +289,2 @@\n+  _is_substitutable_cache->serialize(f);\n+  _primitive_type_hash_code_cache->serialize(f);\n@@ -365,0 +371,1 @@\n+\n@@ -779,1 +786,0 @@\n-\n@@ -799,0 +805,2 @@\n+  Universe::_is_substitutable_cache = new LatestMethodCache();\n+  Universe::_primitive_type_hash_code_cache = new LatestMethodCache();\n@@ -966,0 +974,11 @@\n+\n+  \/\/ Set up substitutability testing\n+  ResourceMark rm;\n+  initialize_known_method(_is_substitutable_cache,\n+                          vmClasses::PrimitiveObjectMethods_klass(),\n+                          vmSymbols::isSubstitutable_name()->as_C_string(),\n+                          vmSymbols::object_object_boolean_signature(), true, CHECK);\n+  initialize_known_method(_primitive_type_hash_code_cache,\n+                          vmClasses::PrimitiveObjectMethods_klass(),\n+                          vmSymbols::primitiveObjectHashCode_name()->as_C_string(),\n+                          vmSymbols::object_int_signature(), true, CHECK);\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":20,"deletions":1,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -233,1 +234,1 @@\n-      \/\/ All of these should have been reverted back to ClassIndex before calling\n+      \/\/ All of these should have been reverted back to Unresolved before calling\n@@ -252,0 +253,1 @@\n+  assert(!k->name()->is_Q_signature(), \"Q-type without JVM_CONSTANT_QDescBit\");\n@@ -393,0 +395,1 @@\n+    jbyte qdesc_bit = tag_at(index).is_Qdescriptor_klass() ? (jbyte) JVM_CONSTANT_QDescBit : 0;\n@@ -394,1 +397,1 @@\n-      tag_at_put(index, JVM_CONSTANT_UnresolvedClass);\n+      tag_at_put(index, JVM_CONSTANT_UnresolvedClass | qdesc_bit);\n@@ -419,1 +422,1 @@\n-        tag_at_put(index, JVM_CONSTANT_UnresolvedClass);\n+        tag_at_put(index, JVM_CONSTANT_UnresolvedClass | qdesc_bit);\n@@ -471,0 +474,6 @@\n+void check_is_inline_type(Klass* k, TRAPS) {\n+  if (!k->is_inline_klass()) {\n+    THROW(vmSymbols::java_lang_IncompatibleClassChangeError());\n+  }\n+}\n+\n@@ -508,0 +517,5 @@\n+  bool inline_type_signature = false;\n+  if (name->is_Q_signature()) {\n+    name = name->fundamental_name(THREAD);\n+    inline_type_signature = true;\n+  }\n@@ -517,0 +531,3 @@\n+  if (inline_type_signature) {\n+    name->decrement_refcount();\n+  }\n@@ -525,0 +542,16 @@\n+  if (!HAS_PENDING_EXCEPTION && inline_type_signature) {\n+    check_is_inline_type(k, THREAD);\n+  }\n+\n+  if (!HAS_PENDING_EXCEPTION) {\n+    Klass* bottom_klass = NULL;\n+    if (k->is_objArray_klass()) {\n+      bottom_klass = ObjArrayKlass::cast(k)->bottom_klass();\n+      assert(bottom_klass != NULL, \"Should be set\");\n+      assert(bottom_klass->is_instance_klass() || bottom_klass->is_typeArray_klass(), \"Sanity check\");\n+    } else if (k->is_flatArray_klass()) {\n+      bottom_klass = FlatArrayKlass::cast(k)->element_klass();\n+      assert(bottom_klass != NULL, \"Should be set\");\n+    }\n+  }\n+\n@@ -528,1 +561,5 @@\n-    save_and_throw_exception(this_cp, which, constantTag(JVM_CONSTANT_UnresolvedClass), CHECK_NULL);\n+    jbyte tag = JVM_CONSTANT_UnresolvedClass;\n+    if (this_cp->tag_at(which).is_Qdescriptor_klass()) {\n+      tag |= JVM_CONSTANT_QDescBit;\n+    }\n+    save_and_throw_exception(this_cp, which, constantTag(tag), CHECK_NULL);\n@@ -547,0 +584,4 @@\n+  jbyte tag = JVM_CONSTANT_Class;\n+  if (this_cp->tag_at(which).is_Qdescriptor_klass()) {\n+    tag |= JVM_CONSTANT_QDescBit;\n+  }\n@@ -551,1 +592,1 @@\n-                                  (jbyte)JVM_CONSTANT_Class);\n+                                  tag);\n@@ -984,1 +1025,3 @@\n-      result_oop = resolved->java_mirror();\n+      result_oop = tag.is_Qdescriptor_klass()\n+                      ? InlineKlass::cast(resolved)->val_mirror()\n+                      : resolved->java_mirror();\n@@ -1902,0 +1945,6 @@\n+      case (JVM_CONSTANT_Class | JVM_CONSTANT_QDescBit): {\n+        idx1 = Bytes::get_Java_u2(bytes);\n+        printf(\"qclass        #%03d\", idx1);\n+        ent_size = 2;\n+        break;\n+      }\n@@ -1944,0 +1993,4 @@\n+      case (JVM_CONSTANT_UnresolvedClass | JVM_CONSTANT_QDescBit): {\n+        printf(\"UnresolvedQClass: %s\", WARN_MSG);\n+        break;\n+      }\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":59,"deletions":6,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -72,0 +72,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -166,0 +167,2 @@\n+bool InstanceKlass::field_is_null_free_inline_type(int index) const { return Signature::basic_type(field(index)->signature(constants())) == T_PRIMITIVE_OBJECT; }\n+\n@@ -437,1 +440,3 @@\n-                                       parser.is_interface());\n+                                       parser.is_interface(),\n+                                       parser.has_inline_fields() ? parser.java_fields_count() : 0,\n+                                       parser.is_inline_type());\n@@ -459,0 +464,3 @@\n+  } else if (parser.is_inline_type()) {\n+    \/\/ inline type\n+    ik = new (loader_data, size, THREAD) InlineKlass(parser);\n@@ -470,0 +478,7 @@\n+#ifdef ASSERT\n+  assert(ik->size() == size, \"\");\n+  ik->bounds_check((address) ik->start_of_vtable(), false, size);\n+  ik->bounds_check((address) ik->start_of_itable(), false, size);\n+  ik->bounds_check((address) ik->end_of_itable(), true, size);\n+  ik->bounds_check((address) ik->end_of_nonstatic_oop_maps(), true, size);\n+#endif \/\/ASSERT\n@@ -473,0 +488,23 @@\n+#ifndef PRODUCT\n+bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {\n+  const char* bad = NULL;\n+  address end = NULL;\n+  if (addr < (address)this) {\n+    bad = \"before\";\n+  } else if (addr == (address)this) {\n+    if (edge_ok)  return true;\n+    bad = \"just before\";\n+  } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes < 0 ? size() : size_in_bytes))) {\n+    if (edge_ok)  return true;\n+    bad = \"just after\";\n+  } else if (addr > end) {\n+    bad = \"after\";\n+  } else {\n+    return true;\n+  }\n+  tty->print_cr(\"%s object bounds: \" INTPTR_FORMAT \" [\" INTPTR_FORMAT \"..\" INTPTR_FORMAT \"]\",\n+      bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);\n+  Verbose = WizardMode = true; this->print(); \/\/@@\n+  return false;\n+}\n+#endif \/\/PRODUCT\n@@ -512,1 +550,4 @@\n-  _init_thread(NULL)\n+  _init_thread(NULL),\n+  _inline_type_field_klasses(NULL),\n+  _preload_classes(NULL),\n+  _adr_inlineklass_fixed_block(NULL)\n@@ -519,0 +560,4 @@\n+    if (parser.has_inline_fields()) {\n+      set_has_inline_type_fields();\n+    }\n+    _java_fields_count = parser.java_fields_count();\n@@ -523,0 +568,4 @@\n+\n+  if (has_inline_type_fields()) {\n+    _inline_type_field_klasses = (const Klass**) adr_inline_type_field_klasses();\n+  }\n@@ -687,0 +736,6 @@\n+  if (preload_classes() != NULL &&\n+      preload_classes() != Universe::the_empty_short_array() &&\n+      !preload_classes()->is_shared()) {\n+    MetadataFactory::free_array<jushort>(loader_data, preload_classes());\n+  }\n+\n@@ -837,0 +892,76 @@\n+\n+  \/\/ If a class declares a method that uses an inline class as an argument\n+  \/\/ type or return inline type, this inline class must be loaded during the\n+  \/\/ linking of this class because size and properties of the inline class\n+  \/\/ must be known in order to be able to perform inline type optimizations.\n+  \/\/ The implementation below is an approximation of this rule, the code\n+  \/\/ iterates over all methods of the current class (including overridden\n+  \/\/ methods), not only the methods declared by this class. This\n+  \/\/ approximation makes the code simpler, and doesn't change the semantic\n+  \/\/ because classes declaring methods overridden by the current class are\n+  \/\/ linked (and have performed their own pre-loading) before the linking\n+  \/\/ of the current class.\n+\n+\n+  \/\/ Note:\n+  \/\/ Inline class types are loaded during\n+  \/\/ the loading phase (see ClassFileParser::post_process_parsed_stream()).\n+  \/\/ Inline class types used as element types for array creation\n+  \/\/ are not pre-loaded. Their loading is triggered by either anewarray\n+  \/\/ or multianewarray bytecodes.\n+\n+  \/\/ Could it be possible to do the following processing only if the\n+  \/\/ class uses inline types?\n+  if (EnableValhalla) {\n+    ResourceMark rm(THREAD);\n+    for (int i = 0; i < methods()->length(); i++) {\n+      Method* m = methods()->at(i);\n+      for (SignatureStream ss(m->signature()); !ss.is_done(); ss.next()) {\n+        if (ss.is_reference()) {\n+          if (ss.is_array()) {\n+            continue;\n+          }\n+          if (ss.type() == T_PRIMITIVE_OBJECT) {\n+            Symbol* symb = ss.as_symbol();\n+            if (symb == name()) continue;\n+            oop loader = class_loader();\n+            oop protection_domain = this->protection_domain();\n+            Klass* klass = SystemDictionary::resolve_or_fail(symb,\n+                                                             Handle(THREAD, loader), Handle(THREAD, protection_domain), true,\n+                                                             CHECK_false);\n+            if (klass == NULL) {\n+              THROW_(vmSymbols::java_lang_LinkageError(), false);\n+            }\n+            if (!klass->is_inline_klass()) {\n+              Exceptions::fthrow(\n+                THREAD_AND_LOCATION,\n+                vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                \"class %s is not an inline type\",\n+                klass->external_name());\n+            }\n+          }\n+        }\n+      }\n+    }\n+    \/\/ Aggressively preloading all classes from the Preload attribute\n+    if (preload_classes() != NULL) {\n+      for (int i = 0; i < preload_classes()->length(); i++) {\n+        if (constants()->tag_at(preload_classes()->at(i)).is_klass()) continue;\n+        Symbol* class_name = constants()->klass_at_noresolve(preload_classes()->at(i));\n+        if (class_name == name()) continue;\n+        oop loader = class_loader();\n+        oop protection_domain = this->protection_domain();\n+        Klass* klass = SystemDictionary::resolve_or_null(class_name,\n+                                                          Handle(THREAD, loader), Handle(THREAD, protection_domain), THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+          CLEAR_PENDING_EXCEPTION;\n+        }\n+        if (klass != NULL) {\n+          log_info(class, preload)(\"Preloading class %s during linking of class %s because of its Preload attribute\", class_name->as_C_string(), name()->as_C_string());\n+        } else {\n+          log_warning(class, preload)(\"Preloading of class %s during linking of class %s (Preload attribute) failed\", class_name->as_C_string(), name()->as_C_string());\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1081,0 +1212,19 @@\n+  \/\/ Pre-allocating an instance of the default value\n+  if (is_inline_klass()) {\n+      InlineKlass* vk = InlineKlass::cast(this);\n+      oop val = vk->allocate_instance(THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          {\n+              EXCEPTION_MARK;\n+              add_initialization_error(THREAD, e);\n+              \/\/ Locks object, set state, and notify all waiting threads\n+              set_initialization_state_and_notify(initialization_error, THREAD);\n+              CLEAR_PENDING_EXCEPTION;\n+          }\n+          THROW_OOP(e());\n+      }\n+      vk->set_default_value(val);\n+  }\n+\n@@ -1113,1 +1263,41 @@\n-\n+  \/\/ Initialize classes of inline fields\n+  if (EnableValhalla) {\n+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_PRIMITIVE_OBJECT) {\n+        Klass* klass = get_inline_type_field_klass_or_null(fs.index());\n+        if (fs.access_flags().is_static() && klass == NULL) {\n+          klass = SystemDictionary::resolve_or_fail(field_signature(fs.index())->fundamental_name(THREAD),\n+              Handle(THREAD, class_loader()),\n+              Handle(THREAD, protection_domain()),\n+              true, THREAD);\n+          set_inline_type_field_klass(fs.index(), klass);\n+        }\n+\n+        if (!HAS_PENDING_EXCEPTION) {\n+          assert(klass != NULL, \"Must  be\");\n+          InstanceKlass::cast(klass)->initialize(THREAD);\n+          if (fs.access_flags().is_static()) {\n+            if (java_mirror()->obj_field(fs.offset()) == NULL) {\n+              java_mirror()->obj_field_put(fs.offset(), InlineKlass::cast(klass)->default_value());\n+            }\n+          }\n+        }\n+\n+        if (HAS_PENDING_EXCEPTION) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          {\n+            EXCEPTION_MARK;\n+            add_initialization_error(THREAD, e);\n+            \/\/ Locks object, set state, and notify all waiting threads\n+            set_initialization_state_and_notify(initialization_error, THREAD);\n+            CLEAR_PENDING_EXCEPTION;\n+          }\n+          THROW_OOP(e());\n+        }\n+      }\n+    }\n+  }\n+\n+\n+  \/\/ Step 9\n@@ -1136,1 +1326,1 @@\n-  \/\/ Step 9\n+  \/\/ Step 10\n@@ -1142,1 +1332,1 @@\n-    \/\/ Step 10 and 11\n+    \/\/ Step 11 and 12\n@@ -1411,1 +1601,2 @@\n-        ObjArrayKlass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, CHECK_NULL);\n+        ObjArrayKlass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this,\n+                                                                  false, false, CHECK_NULL);\n@@ -1418,2 +1609,2 @@\n-  ObjArrayKlass* oak = array_klasses();\n-  return oak->array_klass(n, THREAD);\n+  ArrayKlass* ak = array_klasses();\n+  return ak->array_klass(n, THREAD);\n@@ -1424,2 +1615,2 @@\n-  ObjArrayKlass* oak = array_klasses_acquire();\n-  if (oak == NULL) {\n+  ArrayKlass* ak = array_klasses_acquire();\n+  if (ak == NULL) {\n@@ -1428,1 +1619,1 @@\n-    return oak->array_klass_or_null(n);\n+    return ak->array_klass_or_null(n);\n@@ -1445,1 +1636,1 @@\n-  if (clinit != NULL && clinit->has_valid_initializer_flags()) {\n+  if (clinit != NULL && clinit->is_class_initializer()) {\n@@ -1494,1 +1685,1 @@\n-    MutexLocker x(OopMapCacheAlloc_lock);\n+    MutexLocker x(OopMapCacheAlloc_lock,  Mutex::_no_safepoint_check_flag);\n@@ -1506,5 +1697,0 @@\n-bool InstanceKlass::contains_field_offset(int offset) {\n-  fieldDescriptor fd;\n-  return find_field_from_offset(offset, false, &fd);\n-}\n-\n@@ -1581,0 +1767,9 @@\n+bool InstanceKlass::contains_field_offset(int offset) {\n+  if (this->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(this);\n+    return offset >= vk->first_field_offset() && offset < (vk->first_field_offset() + vk->get_exact_size_in_bytes());\n+  } else {\n+    fieldDescriptor fd;\n+    return find_field_from_offset(offset, false, &fd);\n+  }\n+}\n@@ -1973,0 +2168,3 @@\n+    if (name == vmSymbols::object_initializer_name()) {\n+      break;  \/\/ <init> is never inherited, not even as a static factory\n+    }\n@@ -2450,0 +2648,1 @@\n+  it->push(&_preload_classes);\n@@ -2451,0 +2650,6 @@\n+\n+  if (has_inline_type_fields()) {\n+    for (int i = 0; i < java_fields_count(); i++) {\n+      it->push(&((Klass**)adr_inline_type_field_klasses())[i]);\n+    }\n+  }\n@@ -2494,0 +2699,8 @@\n+  if (has_inline_type_fields()) {\n+    for (AllFieldStream fs(fields(), constants()); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_PRIMITIVE_OBJECT) {\n+        reset_inline_type_field_klass(fs.index());\n+      }\n+    }\n+  }\n+\n@@ -2556,0 +2769,4 @@\n+  if (is_inline_klass()) {\n+    InlineKlass::cast(this)->initialize_calling_convention(CHECK);\n+  }\n+\n@@ -2766,0 +2983,4 @@\n+  return signature_name_of_carrier(JVM_SIGNATURE_CLASS);\n+}\n+\n+const char* InstanceKlass::signature_name_of_carrier(char c) const {\n@@ -2775,1 +2996,1 @@\n-  \/\/ Add L as type indicator\n+  \/\/ Add L or Q as type indicator\n@@ -2777,1 +2998,1 @@\n-  dest[dest_index++] = JVM_SIGNATURE_CLASS;\n+  dest[dest_index++] = c;\n@@ -3124,2 +3345,1 @@\n-  \/\/ Remember to strip ACC_SUPER bit\n-  return (access & (~JVM_ACC_SUPER)) & JVM_ACC_WRITTEN_FLAGS;\n+  return (access & JVM_ACC_WRITTEN_FLAGS);\n@@ -3382,1 +3602,4 @@\n-static void print_vtable(intptr_t* start, int len, outputStream* st) {\n+static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {\n+  ResourceMark rm;\n+  int* forward_refs = NEW_RESOURCE_ARRAY(int, len);\n+  for (int i = 0; i < len; i++)  forward_refs[i] = 0;\n@@ -3386,0 +3609,5 @@\n+    if (forward_refs[i] != 0) {\n+      int from = forward_refs[i];\n+      int off = (int) start[from];\n+      st->print(\" (offset %d <= [%d])\", off, from);\n+    }\n@@ -3389,0 +3617,6 @@\n+    } else if (self != NULL && e > 0 && e < 0x10000) {\n+      address location = self + e;\n+      int index = (int)((intptr_t*)location - start);\n+      st->print(\" (offset %d => [%d])\", (int)e, index);\n+      if (index >= 0 && index < len)\n+        forward_refs[index] = i;\n@@ -3395,1 +3629,22 @@\n-  return print_vtable(reinterpret_cast<intptr_t*>(start), len, st);\n+  return print_vtable(NULL, reinterpret_cast<intptr_t*>(start), len, st);\n+}\n+\n+template<typename T>\n+ static void print_array_on(outputStream* st, Array<T>* array) {\n+   if (array == NULL) { st->print_cr(\"NULL\"); return; }\n+   array->print_value_on(st); st->cr();\n+   if (Verbose || WizardMode) {\n+     for (int i = 0; i < array->length(); i++) {\n+       st->print(\"%d : \", i); array->at(i)->print_value_on(st); st->cr();\n+     }\n+   }\n+ }\n+\n+static void print_array_on(outputStream* st, Array<int>* array) {\n+  if (array == NULL) { st->print_cr(\"NULL\"); return; }\n+  array->print_value_on(st); st->cr();\n+  if (Verbose || WizardMode) {\n+    for (int i = 0; i < array->length(); i++) {\n+      st->print(\"%d : %d\", i, array->at(i)); st->cr();\n+    }\n+  }\n@@ -3409,0 +3664,1 @@\n+  st->print(BULLET\"misc flags:        0x%x\", _misc_flags);                        st->cr();\n@@ -3435,15 +3691,3 @@\n-  st->print(BULLET\"methods:           \"); methods()->print_value_on(st);                  st->cr();\n-  if (Verbose || WizardMode) {\n-    Array<Method*>* method_array = methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n-  st->print(BULLET\"method ordering:   \"); method_ordering()->print_value_on(st);      st->cr();\n-  st->print(BULLET\"default_methods:   \"); default_methods()->print_value_on(st);      st->cr();\n-  if (Verbose && default_methods() != NULL) {\n-    Array<Method*>* method_array = default_methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n+  st->print(BULLET\"methods:           \"); print_array_on(st, methods());\n+  st->print(BULLET\"method ordering:   \"); print_array_on(st, method_ordering());\n+  st->print(BULLET\"default_methods:   \"); print_array_on(st, default_methods());\n@@ -3451,1 +3695,1 @@\n-    st->print(BULLET\"default vtable indices:   \"); default_vtable_indices()->print_value_on(st);       st->cr();\n+    st->print(BULLET\"default vtable indices:   \"); print_array_on(st, default_vtable_indices());\n@@ -3453,2 +3697,2 @@\n-  st->print(BULLET\"local interfaces:  \"); local_interfaces()->print_value_on(st);      st->cr();\n-  st->print(BULLET\"trans. interfaces: \"); transitive_interfaces()->print_value_on(st); st->cr();\n+  st->print(BULLET\"local interfaces:  \"); print_array_on(st, local_interfaces());\n+  st->print(BULLET\"trans. interfaces: \"); print_array_on(st, transitive_interfaces());\n@@ -3500,0 +3744,1 @@\n+  st->print(BULLET\"preload classes:     \"); preload_classes()->print_value_on(st); st->cr();\n@@ -3510,1 +3755,1 @@\n-  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(start_of_itable(), itable_length(), st);\n+  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(NULL, start_of_itable(), itable_length(), st);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":288,"deletions":43,"binary":false,"changes":331,"status":"modified"},{"patch":"@@ -207,1 +207,2 @@\n-                           _shared_class_path_index(-1) {\n+                               _prototype_header(markWord::prototype()),\n+                               _shared_class_path_index(-1) {\n@@ -221,1 +222,1 @@\n-  int lh = array_layout_helper(tag, hsize, etype, exact_log2(esize));\n+  int lh = array_layout_helper(tag, false, hsize, etype, exact_log2(esize));\n@@ -751,0 +752,2 @@\n+     st->print(BULLET\"prototype_header: \" INTPTR_FORMAT, _prototype_header.value());\n+     st->cr();\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -123,1 +124,0 @@\n-\n@@ -162,0 +162,5 @@\n+address Method::get_c2i_inline_entry() {\n+  assert(adapter() != NULL, \"must have\");\n+  return adapter()->get_c2i_inline_entry();\n+}\n+\n@@ -167,0 +172,5 @@\n+address Method::get_c2i_unverified_inline_entry() {\n+  assert(adapter() != NULL, \"must have\");\n+  return adapter()->get_c2i_unverified_inline_entry();\n+}\n+\n@@ -674,0 +684,13 @@\n+\/\/ InlineKlass the method is declared to return. This must not\n+\/\/ safepoint as it is called with references live on the stack at\n+\/\/ locations the GC is unaware of.\n+InlineKlass* Method::returns_inline_type(Thread* thread) const {\n+  assert(InlineTypeReturnedAsFields, \"Inline types should never be returned as fields\");\n+  NoSafepointVerifier nsv;\n+  SignatureStream ss(signature());\n+  while (!ss.at_return_type()) {\n+    ss.next();\n+  }\n+  return ss.as_inline_klass(method_holder());\n+}\n+\n@@ -679,1 +702,1 @@\n-  \/\/   aload_0\n+  \/\/   aload_0, _fast_aload_0, or _nofast_aload_0\n@@ -703,1 +726,2 @@\n-  if (cb[0] != Bytecodes::_aload_0 || cb[1] != Bytecodes::_invokespecial || cb[last] != Bytecodes::_return) {\n+  if ((cb[0] != Bytecodes::_aload_0 && cb[0] != Bytecodes::_fast_aload_0 && cb[0] != Bytecodes::_nofast_aload_0) ||\n+       cb[1] != Bytecodes::_invokespecial || cb[last] != Bytecodes::_return) {\n@@ -861,0 +885,5 @@\n+  if (has_scalarized_return()) {\n+    \/\/ Don't treat this as (trivial) getter method because the\n+    \/\/ inline type should be returned in a scalarized form.\n+    return false;\n+  }\n@@ -882,0 +911,5 @@\n+  if (has_scalarized_args()) {\n+    \/\/ Don't treat this as (trivial) setter method because the\n+    \/\/ inline type argument should be passed in a scalarized form.\n+    return false;\n+  }\n@@ -892,5 +926,2 @@\n-          Bytecodes::is_return(java_code_at(last_index)));\n-}\n-\n-bool Method::is_initializer() const {\n-  return is_object_initializer() || is_static_initializer();\n+          Bytecodes::is_return(java_code_at(last_index)) &&\n+          !has_scalarized_args());\n@@ -899,3 +930,2 @@\n-bool Method::has_valid_initializer_flags() const {\n-  return (is_static() ||\n-          method_holder()->major_version() < 51);\n+bool Method::is_object_constructor_or_class_initializer() const {\n+  return (is_object_constructor() || is_class_initializer());\n@@ -904,1 +934,1 @@\n-bool Method::is_static_initializer() const {\n+bool Method::is_class_initializer() const {\n@@ -908,2 +938,3 @@\n-  return name() == vmSymbols::class_initializer_name() &&\n-         has_valid_initializer_flags();\n+  return (name() == vmSymbols::class_initializer_name() &&\n+          (is_static() ||\n+           method_holder()->major_version() < 51));\n@@ -912,2 +943,8 @@\n-bool Method::is_object_initializer() const {\n-   return name() == vmSymbols::object_initializer_name();\n+\/\/ A method named <init>, if non-static, is a classic object constructor.\n+bool Method::is_object_constructor() const {\n+   return name() == vmSymbols::object_initializer_name() && !is_static();\n+}\n+\n+\/\/ A static method named <init> is a factory for an inline class.\n+bool Method::is_static_init_factory() const {\n+   return name() == vmSymbols::object_initializer_name() && is_static();\n@@ -971,1 +1008,1 @@\n-  if( constants()->tag_at(klass_index).is_unresolved_klass() ) {\n+  if( constants()->tag_at(klass_index).is_unresolved_klass()) {\n@@ -987,1 +1024,3 @@\n-    if (constants()->tag_at(klass_index).is_unresolved_klass()) return false;\n+    if (constants()->tag_at(klass_index).is_unresolved_klass()) {\n+      return false;\n+    }\n@@ -1156,0 +1195,2 @@\n+    _from_compiled_inline_entry = NULL;\n+    _from_compiled_inline_ro_entry = NULL;\n@@ -1158,0 +1199,2 @@\n+    _from_compiled_inline_entry = adapter()->get_c2i_inline_entry();\n+    _from_compiled_inline_ro_entry = adapter()->get_c2i_inline_ro_entry();\n@@ -1189,0 +1232,2 @@\n+  _from_compiled_inline_entry = NULL;\n+  _from_compiled_inline_ro_entry = NULL;\n@@ -1227,0 +1272,3 @@\n+  if (InlineTypeReturnedAsFields && returns_inline_type(THREAD)) {\n+    set_has_scalarized_return(true);\n+  }\n@@ -1266,0 +1314,2 @@\n+  mh->_from_compiled_inline_entry = adapter->get_c2i_inline_entry();\n+  mh->_from_compiled_inline_ro_entry = adapter->get_c2i_inline_ro_entry();\n@@ -1269,1 +1319,1 @@\n-address Method::from_compiled_entry_no_trampoline() const {\n+address Method::from_compiled_entry_no_trampoline(bool caller_is_c1) const {\n@@ -1271,2 +1321,7 @@\n-  if (code) {\n-    return code->verified_entry_point();\n+  if (caller_is_c1) {\n+    \/\/ C1 - inline type arguments are passed as objects\n+    if (code) {\n+      return code->verified_inline_entry_point();\n+    } else {\n+      return adapter()->get_c2i_inline_entry();\n+    }\n@@ -1274,1 +1329,6 @@\n-    return adapter()->get_c2i_entry();\n+    \/\/ C2 - inline type arguments may be passed as fields\n+    if (code) {\n+      return code->verified_entry_point();\n+    } else {\n+      return adapter()->get_c2i_entry();\n+    }\n@@ -1291,0 +1351,12 @@\n+address Method::verified_inline_code_entry() {\n+  debug_only(NoSafepointVerifier nsv;)\n+  assert(_from_compiled_inline_entry != NULL, \"must be set\");\n+  return _from_compiled_inline_entry;\n+}\n+\n+address Method::verified_inline_ro_code_entry() {\n+  debug_only(NoSafepointVerifier nsv;)\n+  assert(_from_compiled_inline_ro_entry != NULL, \"must be set\");\n+  return _from_compiled_inline_ro_entry;\n+}\n+\n@@ -1322,0 +1394,2 @@\n+  mh->_from_compiled_inline_entry = code->verified_inline_entry_point();\n+  mh->_from_compiled_inline_ro_entry = code->verified_inline_ro_entry_point();\n@@ -2335,0 +2409,25 @@\n+bool Method::is_scalarized_arg(int idx) const {\n+  if (!has_scalarized_args()) {\n+    return false;\n+  }\n+  \/\/ Search through signature and check if argument is wrapped in T_PRIMITIVE_OBJECT\/T_VOID\n+  int depth = 0;\n+  const GrowableArray<SigEntry>* sig = adapter()->get_sig_cc();\n+  for (int i = 0; i < sig->length(); i++) {\n+    BasicType bt = sig->at(i)._bt;\n+    if (bt == T_PRIMITIVE_OBJECT) {\n+      depth++;\n+    }\n+    if (idx == 0) {\n+      break; \/\/ Argument found\n+    }\n+    if (bt == T_VOID && (sig->at(i-1)._bt != T_LONG && sig->at(i-1)._bt != T_DOUBLE)) {\n+      depth--;\n+    }\n+    if (depth == 0 && bt != T_LONG && bt != T_DOUBLE) {\n+      idx--; \/\/ Advance to next argument\n+    }\n+  }\n+  return depth != 0;\n+}\n+\n@@ -2366,0 +2465,4 @@\n+#ifdef ASSERT\n+  if (valid_itable_index())\n+    st->print_cr(\" - itable index:      %d\",   itable_index());\n+#endif\n@@ -2373,1 +2476,3 @@\n-  st->print_cr(\" - compiled entry     \" INTPTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled entry           \" INTPTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled inline entry    \" INTPTR_FORMAT, p2i(from_compiled_inline_entry()));\n+  st->print_cr(\" - compiled inline ro entry \" INTPTR_FORMAT, p2i(from_compiled_inline_ro_entry()));\n@@ -2443,0 +2548,1 @@\n+  if (WizardMode) access_flags().print_on(st);\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":129,"deletions":23,"binary":false,"changes":152,"status":"modified"},{"patch":"@@ -94,3 +94,7 @@\n-    _scoped                 = 1 << 7,\n-    _changes_current_thread = 1 << 8,\n-    _jvmti_mount_transition = 1 << 9,\n+    _scalarized_args        = 1 << 7,\n+    _scalarized_return      = 1 << 8,\n+    _c1_needs_stack_repair  = 1 << 9,\n+    _c2_needs_stack_repair  = 1 << 10,\n+    _scoped                 = 1 << 11,\n+    _changes_current_thread = 1 << 12,\n+    _jvmti_mount_transition = 1 << 13,\n@@ -111,1 +115,3 @@\n-  volatile address _from_compiled_entry;        \/\/ Cache of: _code ? _code->entry_point() : _adapter->c2i_entry()\n+  volatile address _from_compiled_entry;           \/\/ Cache of: _code ? _code->verified_entry_point()           : _adapter->c2i_entry()\n+  volatile address _from_compiled_inline_ro_entry; \/\/ Cache of: _code ? _code->verified_inline_ro_entry_point() : _adapter->c2i_inline_ro_entry()\n+  volatile address _from_compiled_inline_entry;    \/\/ Cache of: _code ? _code->verified_inline_entry_point()    : _adapter->c2i_inline_entry()\n@@ -150,1 +156,3 @@\n-  address from_compiled_entry_no_trampoline() const;\n+  address from_compiled_inline_ro_entry() const;\n+  address from_compiled_inline_entry() const;\n+  address from_compiled_entry_no_trampoline(bool caller_is_c1) const;\n@@ -432,0 +440,2 @@\n+  address verified_inline_code_entry();\n+  address verified_inline_ro_code_entry();\n@@ -450,1 +460,7 @@\n-    _from_compiled_entry =  entry;\n+    _from_compiled_entry = entry;\n+  }\n+  void set_from_compiled_inline_ro_entry(address entry) {\n+    _from_compiled_inline_ro_entry = entry;\n+  }\n+  void set_from_compiled_inline_entry(address entry) {\n+    _from_compiled_inline_entry = entry;\n@@ -455,0 +471,1 @@\n+  address get_c2i_inline_entry();\n@@ -456,0 +473,1 @@\n+  address get_c2i_unverified_inline_entry();\n@@ -569,1 +587,1 @@\n-  bool is_returning_fp() const                   { BasicType r = result_type(); return (r == T_FLOAT || r == T_DOUBLE); }\n+  InlineKlass* returns_inline_type(Thread* thread) const;\n@@ -644,6 +662,0 @@\n-  \/\/ returns true if the method is an initializer (<init> or <clinit>).\n-  bool is_initializer() const;\n-\n-  \/\/ returns true if the method is static OR if the classfile version < 51\n-  bool has_valid_initializer_flags() const;\n-\n@@ -652,1 +664,8 @@\n-  bool is_static_initializer() const;\n+  bool is_class_initializer() const;\n+\n+  \/\/ returns true if the method name is <init> and the method is not a static factory\n+  bool is_object_constructor() const;\n+\n+  \/\/ returns true if the method is an object constructor or class initializer\n+  \/\/ (non-static <init> or <clinit>), but false for factories (static <init>).\n+  bool is_object_constructor_or_class_initializer() const;\n@@ -654,2 +673,2 @@\n-  \/\/ returns true if the method name is <init>\n-  bool is_object_initializer() const;\n+  \/\/ returns true if the method name is <init> and the method is static\n+  bool is_static_init_factory() const;\n@@ -677,0 +696,2 @@\n+  static ByteSize from_compiled_inline_offset()  { return byte_offset_of(Method, _from_compiled_inline_entry); }\n+  static ByteSize from_compiled_inline_ro_offset(){ return byte_offset_of(Method, _from_compiled_inline_ro_entry); }\n@@ -678,0 +699,1 @@\n+  static ByteSize flags_offset()                 { return byte_offset_of(Method, _flags); }\n@@ -896,0 +918,34 @@\n+  bool has_scalarized_args() const {\n+    return (_flags & _scalarized_args) != 0;\n+  }\n+\n+  void set_has_scalarized_args(bool x) {\n+    _flags = x ? (_flags | _scalarized_args) : (_flags & ~_scalarized_args);\n+  }\n+\n+  bool has_scalarized_return() const {\n+    return (_flags & _scalarized_return) != 0;\n+  }\n+\n+  void set_has_scalarized_return(bool x) {\n+    _flags = x ? (_flags | _scalarized_return) : (_flags & ~_scalarized_return);\n+  }\n+\n+  bool is_scalarized_arg(int idx) const;\n+\n+  bool c1_needs_stack_repair() {\n+    return (_flags & _c1_needs_stack_repair) != 0;\n+  }\n+\n+  bool c2_needs_stack_repair() {\n+    return (_flags & _c2_needs_stack_repair) != 0;\n+  }\n+\n+  void set_c1_needs_stack_repair(bool x) {\n+    _flags = x ? (_flags | _c1_needs_stack_repair) : (_flags & ~_c1_needs_stack_repair);\n+  }\n+\n+  void set_c2_needs_stack_repair(bool x) {\n+    _flags = x ? (_flags | _c2_needs_stack_repair) : (_flags & ~_c2_needs_stack_repair);\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":72,"deletions":16,"binary":false,"changes":88,"status":"modified"},{"patch":"@@ -37,0 +37,8 @@\n+inline address Method::from_compiled_inline_ro_entry() const {\n+  return Atomic::load_acquire(&_from_compiled_inline_ro_entry);\n+}\n+\n+inline address Method::from_compiled_inline_entry() const {\n+  return Atomic::load_acquire(&_from_compiled_inline_entry);\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/method.inline.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -764,0 +764,6 @@\n+  product(bool, UseArrayLoadStoreProfile, true,                             \\\n+          \"Take advantage of profiling at array load\/store\")                \\\n+                                                                            \\\n+  product(bool, UseACmpProfile, true,                                       \\\n+          \"Take advantage of profiling at acmp\")                            \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -584,0 +584,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:\n+  case vmIntrinsics::_finishPrivateBuffer:\n@@ -593,0 +595,1 @@\n+  case vmIntrinsics::_getValue:\n@@ -602,0 +605,1 @@\n+  case vmIntrinsics::_putValue:\n@@ -686,0 +690,2 @@\n+  case vmIntrinsics::_asPrimaryType:\n+  case vmIntrinsics::_asValueType:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -37,0 +38,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -46,0 +48,1 @@\n+#include \"runtime\/stubRoutines.hpp\"\n@@ -81,1 +84,1 @@\n-Node *StartNode::match( const ProjNode *proj, const Matcher *match ) {\n+Node *StartNode::match(const ProjNode *proj, const Matcher *match, const RegMask* mask) {\n@@ -105,11 +108,0 @@\n-\/\/------------------------------StartOSRNode----------------------------------\n-\/\/ The method start node for an on stack replacement adapter\n-\n-\/\/------------------------------osr_domain-----------------------------\n-const TypeTuple *StartOSRNode::osr_domain() {\n-  const Type **fields = TypeTuple::fields(2);\n-  fields[TypeFunc::Parms+0] = TypeRawPtr::BOTTOM;  \/\/ address of osr buffer\n-\n-  return TypeTuple::make(TypeFunc::Parms+1, fields);\n-}\n-\n@@ -501,0 +493,8 @@\n+      } else if (cik->is_flat_array_klass()) {\n+        ciKlass* cie = cik->as_flat_array_klass()->base_element_klass();\n+        cie->print_name_on(st);\n+        st->print(\"[%d]\", spobj->n_fields());\n+        int ndim = cik->as_array_klass()->dimension() - 1;\n+        while (ndim-- > 0) {\n+          st->print(\"[]\");\n+        }\n@@ -506,0 +506,7 @@\n+        if (iklass != NULL && iklass->is_inlinetype()) {\n+          Node* init_node = mcall->in(first_ind++);\n+          if (!init_node->is_top()) {\n+            st->print(\" [is_init\");\n+            format_helper(regalloc, st, init_node, \":\", -1, NULL);\n+          }\n+        }\n@@ -719,1 +726,1 @@\n-const Type *CallNode::bottom_type() const { return tf()->range(); }\n+const Type *CallNode::bottom_type() const { return tf()->range_cc(); }\n@@ -721,2 +728,4 @@\n-  if (phase->type(in(0)) == Type::TOP)  return Type::TOP;\n-  return tf()->range();\n+  if (!in(0) || phase->type(in(0)) == Type::TOP) {\n+    return Type::TOP;\n+  }\n+  return tf()->range_cc();\n@@ -727,0 +736,7 @@\n+  if (_entry_point == StubRoutines::store_inline_type_fields_to_buf()) {\n+    \/\/ The call to that stub is a special case: its inputs are\n+    \/\/ multiple values returned from a call and so it should follow\n+    \/\/ the return convention.\n+    SharedRuntime::java_return_convention(sig_bt, parm_regs, argcnt);\n+    return;\n+  }\n@@ -735,27 +751,26 @@\n-Node *CallNode::match( const ProjNode *proj, const Matcher *match ) {\n-  switch (proj->_con) {\n-  case TypeFunc::Control:\n-  case TypeFunc::I_O:\n-  case TypeFunc::Memory:\n-    return new MachProjNode(this,proj->_con,RegMask::Empty,MachProjNode::unmatched_proj);\n-\n-  case TypeFunc::Parms+1:       \/\/ For LONG & DOUBLE returns\n-    assert(tf()->range()->field_at(TypeFunc::Parms+1) == Type::HALF, \"\");\n-    \/\/ 2nd half of doubles and longs\n-    return new MachProjNode(this,proj->_con, RegMask::Empty, (uint)OptoReg::Bad);\n-\n-  case TypeFunc::Parms: {       \/\/ Normal returns\n-    uint ideal_reg = tf()->range()->field_at(TypeFunc::Parms)->ideal_reg();\n-    OptoRegPair regs = Opcode() == Op_CallLeafVector\n-      ? match->vector_return_value(ideal_reg)      \/\/ Calls into assembly vector routine\n-      : is_CallRuntime()\n-        ? match->c_return_value(ideal_reg)  \/\/ Calls into C runtime\n-        : match->  return_value(ideal_reg); \/\/ Calls into compiled Java code\n-    RegMask rm = RegMask(regs.first());\n-\n-    if (Opcode() == Op_CallLeafVector) {\n-      \/\/ If the return is in vector, compute appropriate regmask taking into account the whole range\n-      if(ideal_reg >= Op_VecS && ideal_reg <= Op_VecZ) {\n-        if(OptoReg::is_valid(regs.second())) {\n-          for (OptoReg::Name r = regs.first(); r <= regs.second(); r = OptoReg::add(r, 1)) {\n-            rm.Insert(r);\n+Node *CallNode::match(const ProjNode *proj, const Matcher *match, const RegMask* mask) {\n+  uint con = proj->_con;\n+  const TypeTuple* range_cc = tf()->range_cc();\n+  if (con >= TypeFunc::Parms) {\n+    if (tf()->returns_inline_type_as_fields()) {\n+      \/\/ The call returns multiple values (inline type fields): we\n+      \/\/ create one projection per returned value.\n+      assert(con <= TypeFunc::Parms+1 || InlineTypeReturnedAsFields, \"only for multi value return\");\n+      uint ideal_reg = range_cc->field_at(con)->ideal_reg();\n+      return new MachProjNode(this, con, mask[con-TypeFunc::Parms], ideal_reg);\n+    } else {\n+      if (con == TypeFunc::Parms) {\n+        uint ideal_reg = range_cc->field_at(TypeFunc::Parms)->ideal_reg();\n+        OptoRegPair regs = Opcode() == Op_CallLeafVector\n+          ? match->vector_return_value(ideal_reg)      \/\/ Calls into assembly vector routine\n+          : match->c_return_value(ideal_reg);\n+        RegMask rm = RegMask(regs.first());\n+\n+        if (Opcode() == Op_CallLeafVector) {\n+          \/\/ If the return is in vector, compute appropriate regmask taking into account the whole range\n+          if(ideal_reg >= Op_VecS && ideal_reg <= Op_VecZ) {\n+            if(OptoReg::is_valid(regs.second())) {\n+              for (OptoReg::Name r = regs.first(); r <= regs.second(); r = OptoReg::add(r, 1)) {\n+                rm.Insert(r);\n+              }\n+            }\n@@ -764,0 +779,9 @@\n+\n+        if (OptoReg::is_valid(regs.second())) {\n+          rm.Insert(regs.second());\n+        }\n+        return new MachProjNode(this,con,rm,ideal_reg);\n+      } else {\n+        assert(con == TypeFunc::Parms+1, \"only one return value\");\n+        assert(range_cc->field_at(TypeFunc::Parms+1) == Type::HALF, \"\");\n+        return new MachProjNode(this,con, RegMask::Empty, (uint)OptoReg::Bad);\n@@ -766,4 +790,0 @@\n-\n-    if( OptoReg::is_valid(regs.second()) )\n-      rm.Insert( regs.second() );\n-    return new MachProjNode(this,proj->_con,rm,ideal_reg);\n@@ -772,0 +792,6 @@\n+  switch (con) {\n+  case TypeFunc::Control:\n+  case TypeFunc::I_O:\n+  case TypeFunc::Memory:\n+    return new MachProjNode(this,proj->_con,RegMask::Empty,MachProjNode::unmatched_proj);\n+\n@@ -792,1 +818,1 @@\n-    const TypeTuple* args = _tf->domain();\n+    const TypeTuple* args = _tf->domain_sig();\n@@ -841,1 +867,1 @@\n-      const TypeTuple* d = tf()->domain();\n+      const TypeTuple* d = tf()->domain_cc();\n@@ -856,2 +882,2 @@\n-bool CallNode::has_non_debug_use(Node *n) {\n-  const TypeTuple * d = tf()->domain();\n+bool CallNode::has_non_debug_use(Node* n) {\n+  const TypeTuple* d = tf()->domain_cc();\n@@ -859,2 +885,1 @@\n-    Node *arg = in(i);\n-    if (arg == n) {\n+    if (in(i) == n) {\n@@ -867,0 +892,11 @@\n+bool CallNode::has_debug_use(Node* n) {\n+  if (jvms() != NULL) {\n+    for (uint i = jvms()->debug_start(); i < jvms()->debug_end(); i++) {\n+      if (in(i) == n) {\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -898,10 +934,15 @@\n-void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) {\n-  projs->fallthrough_proj      = NULL;\n-  projs->fallthrough_catchproj = NULL;\n-  projs->fallthrough_ioproj    = NULL;\n-  projs->catchall_ioproj       = NULL;\n-  projs->catchall_catchproj    = NULL;\n-  projs->fallthrough_memproj   = NULL;\n-  projs->catchall_memproj      = NULL;\n-  projs->resproj               = NULL;\n-  projs->exobj                 = NULL;\n+CallProjections* CallNode::extract_projections(bool separate_io_proj, bool do_asserts) {\n+  uint max_res = TypeFunc::Parms-1;\n+  for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+    ProjNode *pn = fast_out(i)->as_Proj();\n+    max_res = MAX2(max_res, pn->_con);\n+  }\n+\n+  assert(max_res < _tf->range_cc()->cnt(), \"result out of bounds\");\n+\n+  uint projs_size = sizeof(CallProjections);\n+  if (max_res > TypeFunc::Parms) {\n+    projs_size += (max_res-TypeFunc::Parms)*sizeof(Node*);\n+  }\n+  char* projs_storage = resource_allocate_bytes(projs_size);\n+  CallProjections* projs = new(projs_storage)CallProjections(max_res - TypeFunc::Parms + 1);\n@@ -953,1 +994,1 @@\n-      projs->resproj = pn;\n+      projs->resproj[0] = pn;\n@@ -956,1 +997,3 @@\n-      assert(false, \"unexpected projection from allocation node.\");\n+      assert(pn->_con <= max_res, \"unexpected projection from allocation node.\");\n+      projs->resproj[pn->_con-TypeFunc::Parms] = pn;\n+      break;\n@@ -963,1 +1006,1 @@\n-  assert(projs->fallthrough_proj      != NULL, \"must be found\");\n+  assert(!do_asserts || projs->fallthrough_proj      != NULL, \"must be found\");\n@@ -973,0 +1016,1 @@\n+  return projs;\n@@ -1004,2 +1048,2 @@\n-  uint old_dbg_start = sfpt->is_Call() ? sfpt->as_Call()->tf()->domain()->cnt() : (uint)TypeFunc::Parms+1;\n-  uint new_dbg_start = tf()->domain()->cnt();\n+  uint old_dbg_start = sfpt->is_Call() ? sfpt->as_Call()->tf()->domain_sig()->cnt() : (uint)TypeFunc::Parms+1;\n+  uint new_dbg_start = tf()->domain_sig()->cnt();\n@@ -1046,0 +1090,4 @@\n+  Bytecodes::Code bc = jvms()->method()->java_code_at_bci(jvms()->bci());\n+  if (EnableValhalla && (bc == Bytecodes::_if_acmpeq || bc == Bytecodes::_if_acmpne)) {\n+    return true;\n+  }\n@@ -1079,0 +1127,10 @@\n+  if (can_reshape && uncommon_trap_request() != 0) {\n+    if (remove_useless_allocation(phase, in(0), in(TypeFunc::Memory), in(TypeFunc::Parms))) {\n+      if (!in(0)->is_Region()) {\n+        PhaseIterGVN* igvn = phase->is_IterGVN();\n+        igvn->replace_input_of(this, 0, phase->C->top());\n+      }\n+      return this;\n+    }\n+  }\n+\n@@ -1128,0 +1186,124 @@\n+bool CallStaticJavaNode::remove_useless_allocation(PhaseGVN *phase, Node* ctl, Node* mem, Node* unc_arg) {\n+  \/\/ Split if can cause the flattened array branch of an array load to\n+  \/\/ end in an uncommon trap. In that case, the allocation of the\n+  \/\/ loaded value and its initialization is useless. Eliminate it. use\n+  \/\/ the jvm state of the allocation to create a new uncommon trap\n+  \/\/ call at the load.\n+  if (ctl == NULL || ctl->is_top() || mem == NULL || mem->is_top() || !mem->is_MergeMem()) {\n+    return false;\n+  }\n+  PhaseIterGVN* igvn = phase->is_IterGVN();\n+  if (ctl->is_Region()) {\n+    bool res = false;\n+    for (uint i = 1; i < ctl->req(); i++) {\n+      MergeMemNode* mm = mem->clone()->as_MergeMem();\n+      for (MergeMemStream mms(mm); mms.next_non_empty(); ) {\n+        Node* m = mms.memory();\n+        if (m->is_Phi() && m->in(0) == ctl) {\n+          mms.set_memory(m->in(i));\n+        }\n+      }\n+      if (remove_useless_allocation(phase, ctl->in(i), mm, unc_arg)) {\n+        res = true;\n+        if (!ctl->in(i)->is_Region()) {\n+          igvn->replace_input_of(ctl, i, phase->C->top());\n+        }\n+      }\n+      igvn->remove_dead_node(mm);\n+    }\n+    return res;\n+  }\n+  \/\/ verify the control flow is ok\n+  Node* call = ctl;\n+  MemBarNode* membar = NULL;\n+  for (;;) {\n+    if (call == NULL || call->is_top()) {\n+      return false;\n+    }\n+    if (call->is_Proj() || call->is_Catch() || call->is_MemBar()) {\n+      call = call->in(0);\n+    } else if (call->Opcode() == Op_CallStaticJava &&\n+               call->as_Call()->entry_point() == OptoRuntime::load_unknown_inline_Java()) {\n+      assert(call->in(0)->is_Proj() && call->in(0)->in(0)->is_MemBar(), \"missing membar\");\n+      membar = call->in(0)->in(0)->as_MemBar();\n+      break;\n+    } else {\n+      return false;\n+    }\n+  }\n+\n+  JVMState* jvms = call->jvms();\n+  if (phase->C->too_many_traps(jvms->method(), jvms->bci(), Deoptimization::trap_request_reason(uncommon_trap_request()))) {\n+    return false;\n+  }\n+\n+  Node* alloc_mem = call->in(TypeFunc::Memory);\n+  if (alloc_mem == NULL || alloc_mem->is_top()) {\n+    return false;\n+  }\n+  if (!alloc_mem->is_MergeMem()) {\n+    alloc_mem = MergeMemNode::make(alloc_mem);\n+    igvn->register_new_node_with_optimizer(alloc_mem);\n+  }\n+\n+  \/\/ and that there's no unexpected side effect\n+  for (MergeMemStream mms2(mem->as_MergeMem(), alloc_mem->as_MergeMem()); mms2.next_non_empty2(); ) {\n+    Node* m1 = mms2.is_empty() ? mms2.base_memory() : mms2.memory();\n+    Node* m2 = mms2.memory2();\n+\n+    for (uint i = 0; i < 100; i++) {\n+      if (m1 == m2) {\n+        break;\n+      } else if (m1->is_Proj()) {\n+        m1 = m1->in(0);\n+      } else if (m1->is_MemBar()) {\n+        m1 = m1->in(TypeFunc::Memory);\n+      } else if (m1->Opcode() == Op_CallStaticJava &&\n+                 m1->as_Call()->entry_point() == OptoRuntime::load_unknown_inline_Java()) {\n+        if (m1 != call) {\n+          return false;\n+        }\n+        break;\n+      } else if (m1->is_MergeMem()) {\n+        MergeMemNode* mm = m1->as_MergeMem();\n+        int idx = mms2.alias_idx();\n+        if (idx == Compile::AliasIdxBot) {\n+          m1 = mm->base_memory();\n+        } else {\n+          m1 = mm->memory_at(idx);\n+        }\n+      } else {\n+        return false;\n+      }\n+    }\n+  }\n+  if (alloc_mem->outcnt() == 0) {\n+    igvn->remove_dead_node(alloc_mem);\n+  }\n+\n+  \/\/ Remove membar preceding the call\n+  membar->remove(igvn);\n+\n+  address call_addr = SharedRuntime::uncommon_trap_blob()->entry_point();\n+  CallNode* unc = new CallStaticJavaNode(OptoRuntime::uncommon_trap_Type(), call_addr, \"uncommon_trap\", NULL);\n+  unc->init_req(TypeFunc::Control, call->in(0));\n+  unc->init_req(TypeFunc::I_O, call->in(TypeFunc::I_O));\n+  unc->init_req(TypeFunc::Memory, call->in(TypeFunc::Memory));\n+  unc->init_req(TypeFunc::FramePtr,  call->in(TypeFunc::FramePtr));\n+  unc->init_req(TypeFunc::ReturnAdr, call->in(TypeFunc::ReturnAdr));\n+  unc->init_req(TypeFunc::Parms+0, unc_arg);\n+  unc->set_cnt(PROB_UNLIKELY_MAG(4));\n+  unc->copy_call_debug_info(igvn, call->as_CallStaticJava());\n+\n+  igvn->replace_input_of(call, 0, phase->C->top());\n+\n+  igvn->register_new_node_with_optimizer(unc);\n+\n+  Node* ctrl = phase->transform(new ProjNode(unc, TypeFunc::Control));\n+  Node* halt = phase->transform(new HaltNode(ctrl, call->in(TypeFunc::FramePtr), \"uncommon trap returned which should never happen\"));\n+  phase->C->root()->add_req(halt);\n+\n+  return true;\n+}\n+\n+\n@@ -1232,0 +1414,7 @@\n+  if (_entry_point == NULL) {\n+    \/\/ The call to that stub is a special case: its inputs are\n+    \/\/ multiple values returned from a call and so it should follow\n+    \/\/ the return convention.\n+    SharedRuntime::java_return_convention(sig_bt, parm_regs, argcnt);\n+    return;\n+  }\n@@ -1237,1 +1426,1 @@\n-  assert(tf()->range()->field_at(TypeFunc::Parms)->is_vect()->length_in_bytes() * BitsPerByte == _num_bits,\n+  assert(tf()->range_sig()->field_at(TypeFunc::Parms)->is_vect()->length_in_bytes() * BitsPerByte == _num_bits,\n@@ -1239,1 +1428,1 @@\n-  const TypeTuple* d = tf()->domain();\n+  const TypeTuple* d = tf()->domain_sig();\n@@ -1263,0 +1452,6 @@\n+uint CallLeafNoFPNode::match_edge(uint idx) const {\n+  \/\/ Null entry point is a special case for which the target is in a\n+  \/\/ register. Need to match that edge.\n+  return entry_point() == NULL && idx == TypeFunc::Parms;\n+}\n+\n@@ -1313,1 +1508,14 @@\n-  return remove_dead_region(phase, can_reshape) ? this : NULL;\n+  if (remove_dead_region(phase, can_reshape)) {\n+    return this;\n+  }\n+  \/\/ Scalarize inline types in safepoint debug info.\n+  \/\/ Delay this until all inlining is over to avoid getting inconsistent debug info.\n+  if (phase->C->scalarize_in_safepoints() && can_reshape && jvms() != NULL) {\n+    for (uint i = jvms()->debug_start(); i < jvms()->debug_end(); i++) {\n+      Node* n = in(i)->uncast();\n+      if (n->is_InlineTypeBase()) {\n+        n->as_InlineTypeBase()->make_scalar_in_safepoints(phase->is_IterGVN());\n+      }\n+    }\n+  }\n+  return NULL;\n@@ -1477,1 +1685,1 @@\n-  if (!alloc->is_Allocate()\n+  if (alloc != NULL && !alloc->is_Allocate()\n@@ -1535,1 +1743,3 @@\n-                           Node *size, Node *klass_node, Node *initial_test)\n+                           Node *size, Node *klass_node,\n+                           Node* initial_test,\n+                           InlineTypeBaseNode* inline_type_node)\n@@ -1543,0 +1753,1 @@\n+  _larval = false;\n@@ -1554,0 +1765,3 @@\n+  init_req( InlineTypeNode     , inline_type_node);\n+  \/\/ DefaultValue defaults to NULL\n+  \/\/ RawDefaultValue defaults to NULL\n@@ -1560,3 +1774,2 @@\n-         initializer->is_initializer() &&\n-         !initializer->is_static(),\n-             \"unexpected initializer method\");\n+         initializer->is_object_constructor_or_class_initializer(),\n+         \"unexpected initializer method\");\n@@ -1573,1 +1786,2 @@\n-Node *AllocateNode::make_ideal_mark(PhaseGVN *phase, Node* obj, Node* control, Node* mem) {\n+\n+Node* AllocateNode::make_ideal_mark(PhaseGVN* phase, Node* control, Node* mem) {\n@@ -1575,3 +1789,10 @@\n-  \/\/ For now only enable fast locking for non-array types\n-  mark_node = phase->MakeConX(markWord::prototype().value());\n-  return mark_node;\n+  if (EnableValhalla) {\n+    Node* klass_node = in(AllocateNode::KlassNode);\n+    Node* proto_adr = phase->transform(new AddPNode(klass_node, klass_node, phase->MakeConX(in_bytes(Klass::prototype_header_offset()))));\n+    mark_node = LoadNode::make(*phase, control, mem, proto_adr, TypeRawPtr::BOTTOM, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n+  } else {\n+    mark_node = phase->MakeConX(markWord::prototype().value());\n+  }\n+  mark_node = phase->transform(mark_node);\n+  \/\/ Avoid returning a constant (old node) here because this method is used by LoadNode::Ideal\n+  return new OrXNode(mark_node, phase->MakeConX(_larval ? markWord::larval_bit_in_place : 0));\n@@ -2004,1 +2225,3 @@\n-  if (can_reshape && EliminateLocks && !is_non_esc_obj()) {\n+  const Type* obj_type = phase->type(obj_node());\n+  if (can_reshape && EliminateLocks && !is_non_esc_obj() &&\n+      !obj_type->isa_inlinetype() && !obj_type->is_inlinetypeptr()) {\n@@ -2200,1 +2423,3 @@\n-  if (can_reshape && EliminateLocks && !is_non_esc_obj()) {\n+  const Type* obj_type = phase->type(obj_node());\n+  if (can_reshape && EliminateLocks && !is_non_esc_obj() &&\n+      !obj_type->isa_inlinetype() && !obj_type->is_inlinetypeptr()) {\n@@ -2280,1 +2505,2 @@\n-    dest_t = dest_t->add_offset(Type::OffsetBot)->is_oopptr();\n+    dest_t = dest_t->is_aryptr()->with_field_offset(Type::OffsetBot)->add_offset(Type::OffsetBot)->is_oopptr();\n+    t_oop = t_oop->is_aryptr()->with_field_offset(Type::OffsetBot);\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":308,"deletions":82,"binary":false,"changes":390,"status":"modified"},{"patch":"@@ -79,1 +79,1 @@\n-  virtual Node *match( const ProjNode *proj, const Matcher *m );\n+  virtual Node *match(const ProjNode *proj, const Matcher *m, const RegMask* mask);\n@@ -93,1 +93,0 @@\n-  static  const TypeTuple *osr_domain();\n@@ -562,1 +561,1 @@\n-class CallProjections : public StackObj {\n+class CallProjections {\n@@ -571,1 +570,19 @@\n-  Node* resproj;\n+  uint nb_resproj;\n+  Node* resproj[1]; \/\/ at least one projection\n+\n+  CallProjections(uint nbres) {\n+    fallthrough_proj      = NULL;\n+    fallthrough_catchproj = NULL;\n+    fallthrough_memproj   = NULL;\n+    fallthrough_ioproj    = NULL;\n+    catchall_catchproj    = NULL;\n+    catchall_memproj      = NULL;\n+    catchall_ioproj       = NULL;\n+    exobj                 = NULL;\n+    nb_resproj            = nbres;\n+    resproj[0]            = NULL;\n+    for (uint i = 1; i < nb_resproj; i++) {\n+      resproj[i]          = NULL;\n+    }\n+  }\n+\n@@ -594,1 +611,1 @@\n-    : SafePointNode(tf->domain()->cnt(), jvms, adr_type),\n+    : SafePointNode(tf->domain_cc()->cnt(), jvms, adr_type),\n@@ -621,1 +638,1 @@\n-  virtual Node*       match(const ProjNode* proj, const Matcher* m);\n+  virtual Node*       match(const ProjNode* proj, const Matcher* m, const RegMask* mask);\n@@ -635,0 +652,1 @@\n+  bool                has_debug_use(Node* n);\n@@ -641,2 +659,3 @@\n-    const TypeTuple* r = tf()->range();\n-    return (r->cnt() > TypeFunc::Parms &&\n+    const TypeTuple* r = tf()->range_sig();\n+    return (!tf()->returns_inline_type_as_fields() &&\n+            r->cnt() > TypeFunc::Parms &&\n@@ -649,1 +668,1 @@\n-  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true);\n+  CallProjections* extract_projections(bool separate_io_proj, bool do_asserts = true);\n@@ -719,0 +738,3 @@\n+\n+  bool remove_useless_allocation(PhaseGVN *phase, Node* ctl, Node* mem, Node* unc_arg);\n+\n@@ -727,0 +749,11 @@\n+    const TypeTuple *r = tf->range_sig();\n+    if (InlineTypeReturnedAsFields &&\n+        method != NULL &&\n+        method->is_method_handle_intrinsic() &&\n+        r->cnt() > TypeFunc::Parms &&\n+        r->field_at(TypeFunc::Parms)->isa_oopptr() &&\n+        r->field_at(TypeFunc::Parms)->is_oopptr()->can_be_inline_type()) {\n+      \/\/ Make sure this call is processed by PhaseMacroExpand::expand_mh_intrinsic_return\n+      init_flags(Flag_is_macro);\n+      C->add_macro_node(this);\n+    }\n@@ -836,0 +869,1 @@\n+  virtual uint match_edge(uint idx) const;\n@@ -877,0 +911,3 @@\n+    InlineTypeNode,                   \/\/ InlineTypeNode if this is an inline type allocation\n+    DefaultValue,                     \/\/ default value in case of non-flattened inline type array\n+    RawDefaultValue,                  \/\/ same as above but as raw machine word\n@@ -886,0 +923,3 @@\n+    fields[InlineTypeNode] = Type::BOTTOM;\n+    fields[DefaultValue] = TypeInstPtr::NOTNULL;\n+    fields[RawDefaultValue] = TypeX_X;\n@@ -903,0 +943,1 @@\n+  bool _larval;\n@@ -906,1 +947,2 @@\n-               Node *size, Node *klass_node, Node *initial_test);\n+               Node *size, Node *klass_node, Node *initial_test,\n+               InlineTypeBaseNode* inline_type_node = NULL);\n@@ -971,1 +1013,1 @@\n-  Node* make_ideal_mark(PhaseGVN *phase, Node* obj, Node* control, Node* mem);\n+  Node* make_ideal_mark(PhaseGVN* phase, Node* control, Node* mem);\n@@ -982,1 +1024,2 @@\n-                    Node* count_val\n+                    Node* count_val,\n+                    Node* default_value, Node* raw_default_value\n@@ -989,0 +1032,2 @@\n+    init_req(AllocateNode::DefaultValue,  default_value);\n+    init_req(AllocateNode::RawDefaultValue, raw_default_value);\n@@ -1109,1 +1154,1 @@\n-    return TypeFunc::make(domain,range);\n+    return TypeFunc::make(domain, range);\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":58,"deletions":13,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -396,1 +397,1 @@\n-bool RegionNode::try_clean_mem_phi(PhaseGVN *phase) {\n+Node* PhiNode::try_clean_mem_phi(PhaseGVN *phase) {\n@@ -416,2 +417,1 @@\n-  PhiNode* phi = has_unique_phi();\n-  if (phi && phi->type() == Type::MEMORY && req() == 3 && phi->is_diamond_phi(true)) {\n+  if (type() == Type::MEMORY && is_diamond_phi(true)) {\n@@ -419,1 +419,2 @@\n-    assert(phi->req() == 3, \"same as region\");\n+    assert(req() == 3, \"same as region\");\n+    Node* r = in(0);\n@@ -421,2 +422,2 @@\n-      Node *mem = phi->in(i);\n-      if (mem && mem->is_MergeMem() && in(i)->outcnt() == 1) {\n+      Node *mem = in(i);\n+      if (mem && mem->is_MergeMem() && r->in(i)->outcnt() == 1) {\n@@ -426,1 +427,1 @@\n-        Node* other = phi->in(j);\n+        Node* other = in(j);\n@@ -430,2 +431,1 @@\n-          phase->is_IterGVN()->replace_node(phi, m);\n-          return true;\n+          return m;\n@@ -436,1 +436,1 @@\n-  return false;\n+  return NULL;\n@@ -451,2 +451,9 @@\n-    if (has_phis && try_clean_mem_phi(phase)) {\n-      has_phis = false;\n+    if (has_phis) {\n+      PhiNode* phi = has_unique_phi();\n+      if (phi != NULL) {\n+        Node* m = phi->try_clean_mem_phi(phase);\n+        if (m != NULL) {\n+          phase->is_IterGVN()->replace_node(phi, m);\n+          has_phis = false;\n+        }\n+      }\n@@ -862,1 +869,2 @@\n-             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck()) {\n+             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck() ||\n+             cmp1->is_FlatArrayCheck() || cmp2->is_FlatArrayCheck()) {\n@@ -943,1 +951,1 @@\n-  assert(t != Type::MEMORY || at == flatten_phi_adr_type(at), \"flatten at\");\n+  assert(t != Type::MEMORY || at == flatten_phi_adr_type(at) || (flatten_phi_adr_type(at) == TypeAryPtr::INLINES && Compile::current()->flattened_accesses_share_alias()), \"flatten at\");\n@@ -1080,0 +1088,8 @@\n+  \/\/ Flat array element shouldn't get their own memory slice until flattened_accesses_share_alias is cleared.\n+  \/\/ It could be the graph has no loads\/stores and flattened_accesses_share_alias is never cleared. EA could still\n+  \/\/ creates per element Phis but that wouldn't be a problem as there are no memory accesses for that array.\n+  assert(_adr_type == NULL || _adr_type->isa_aryptr() == NULL ||\n+         _adr_type->is_aryptr()->is_known_instance() ||\n+         !_adr_type->is_aryptr()->is_flat() ||\n+         !Compile::current()->flattened_accesses_share_alias() ||\n+         _adr_type == TypeAryPtr::INLINES, \"flat array element shouldn't get its own slice yet\");\n@@ -1419,0 +1435,8 @@\n+  if (phase->is_IterGVN()) {\n+    Node* m = try_clean_mem_phi(phase);\n+    if (m != NULL) {\n+      return m;\n+    }\n+  }\n+\n+\n@@ -1941,0 +1965,48 @@\n+\/\/ Push inline type input nodes (and null) down through the phi recursively (can handle data loops).\n+InlineTypeBaseNode* PhiNode::push_inline_types_through(PhaseGVN* phase, bool can_reshape, ciInlineKlass* vk, bool is_init) {\n+  InlineTypeBaseNode* vt = NULL;\n+  if (_type->isa_ptr()) {\n+    vt = InlineTypePtrNode::make_null(*phase, vk)->clone_with_phis(phase, in(0), is_init);\n+  } else {\n+    vt = InlineTypeNode::make_null(*phase, vk)->clone_with_phis(phase, in(0), is_init);\n+  }\n+  if (can_reshape) {\n+    \/\/ Replace phi right away to be able to use the inline\n+    \/\/ type node when reaching the phi again through data loops.\n+    PhaseIterGVN* igvn = phase->is_IterGVN();\n+    for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+      Node* u = fast_out(i);\n+      igvn->rehash_node_delayed(u);\n+      imax -= u->replace_edge(this, vt);\n+      --i;\n+    }\n+    assert(outcnt() == 0, \"should be dead now\");\n+  }\n+  ResourceMark rm;\n+  Node_List casts;\n+  for (uint i = 1; i < req(); ++i) {\n+    Node* n = in(i);\n+    while (n->is_ConstraintCast()) {\n+      casts.push(n);\n+      n = n->in(1);\n+    }\n+    if (phase->type(n)->is_zero_type()) {\n+      n = InlineTypePtrNode::make_null(*phase, vk);\n+    } else if (n->is_Phi()) {\n+      assert(can_reshape, \"can only handle phis during IGVN\");\n+      n = phase->transform(n->as_Phi()->push_inline_types_through(phase, can_reshape, vk, is_init));\n+    }\n+    while (casts.size() != 0) {\n+      \/\/ Push the cast(s) through the InlineTypePtrNode\n+      Node* cast = casts.pop()->clone();\n+      cast->set_req_X(1, n->as_InlineTypePtr()->get_oop(), phase);\n+      n = n->clone();\n+      n->as_InlineTypePtr()->set_oop(phase->transform(cast));\n+      n = phase->transform(n);\n+    }\n+    bool transform = !can_reshape && (i == (req()-1)); \/\/ Transform phis on last merge\n+    vt->merge_with(phase, n->as_InlineTypeBase(), i, transform);\n+  }\n+  return vt;\n+}\n+\n@@ -2242,0 +2314,2 @@\n+    \/\/ TODO revisit this with JDK-8247216\n+    bool mergemem_only = true;\n@@ -2254,0 +2328,2 @@\n+      } else {\n+        mergemem_only = false;\n@@ -2258,1 +2334,1 @@\n-    if (!saw_self && adr_type() == TypePtr::BOTTOM)  merge_width = 0;\n+    if (!mergemem_only && !saw_self && adr_type() == TypePtr::BOTTOM)  merge_width = 0;\n@@ -2329,0 +2405,5 @@\n+            if (igvn) {\n+              \/\/ TODO revisit this with JDK-8247216\n+              \/\/ Put 'n' on the worklist because it might be modified by MergeMemStream::iteration_setup\n+              igvn->_worklist.push(n);\n+            }\n@@ -2447,0 +2528,72 @@\n+  \/\/ Check recursively if inputs are either an inline type, constant null\n+  \/\/ or another Phi (including self references through data loops). If so,\n+  \/\/ push the inline types down through the phis to enable folding of loads.\n+  if (EnableValhalla && (_type->isa_ptr() || _type->isa_inlinetype()) && req() > 2) {\n+    ResourceMark rm;\n+    Unique_Node_List worklist;\n+    worklist.push(this);\n+    bool can_optimize = true;\n+    ciInlineKlass* vk = NULL;\n+    \/\/ true if all IsInit inputs of all InlineType* nodes are true\n+    bool is_init = true;\n+    Node_List casts;\n+\n+    \/\/ TODO 8284443 We need to prevent endless pushing through\n+    \/\/ TestLWorld -XX:+UseZGC -DScenarios=0 -DTest=test69\n+    \/\/ TestLWorld -XX:-TieredCompilation -XX:-DoEscapeAnalysis -XX:+AlwaysIncrementalInline\n+    for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+      Node* n = fast_out(i);\n+      if (n->is_InlineTypePtr() && n->in(1) == this) {\n+        can_optimize = false;\n+        break;\n+      }\n+    }\n+    \/\/ TODO 8284443 We could revisit the same node over and over again, right?\n+    for (uint next = 0; next < worklist.size() && can_optimize; next++) {\n+      Node* phi = worklist.at(next);\n+      for (uint i = 1; i < phi->req() && can_optimize; i++) {\n+        Node* n = phi->in(i);\n+        if (n == NULL) {\n+          can_optimize = false;\n+          break;\n+        }\n+        while (n->is_ConstraintCast()) {\n+          if (n->in(0) != NULL && n->in(0)->is_top()) {\n+            \/\/ Will die, don't optimize\n+            can_optimize = false;\n+            break;\n+          }\n+          casts.push(n);\n+          n = n->in(1);\n+        }\n+        const Type* t = phase->type(n);\n+        if (n->is_InlineTypeBase() && n->as_InlineTypeBase()->can_merge() &&\n+            (vk == NULL || vk == t->inline_klass())) {\n+          vk = (vk == NULL) ? t->inline_klass() : vk;\n+          if (phase->find_int_con(n->as_InlineTypeBase()->get_is_init(), 0) != 1) {\n+            is_init = false;\n+          }\n+        } else if (n->is_Phi() && can_reshape && (n->bottom_type()->isa_ptr() || n->bottom_type()->isa_inlinetype())) {\n+          worklist.push(n);\n+        } else if (t->is_zero_type()) {\n+          is_init = false;\n+        } else {\n+          can_optimize = false;\n+        }\n+      }\n+    }\n+    \/\/ Check if cast nodes can be pushed through\n+    const Type* t = Type::get_const_type(vk);\n+    while (casts.size() != 0 && can_optimize && t != NULL) {\n+      Node* cast = casts.pop();\n+      if (t->filter(cast->bottom_type()) == Type::TOP) {\n+        can_optimize = false;\n+      }\n+    }\n+    if (can_optimize && vk != NULL) {\n+\/\/ TODO 8275400\n+\/\/      assert(!_type->isa_ptr() || _type->maybe_null() || is_init, \"Phi not null but a possible null was seen\");\n+      return push_inline_types_through(phase, can_reshape, vk, is_init);\n+    }\n+  }\n+\n@@ -2539,0 +2692,1 @@\n+\n@@ -2772,0 +2926,6 @@\n+\n+  \/\/ CheckCastPPNode::Ideal() for inline types reuses the exception\n+  \/\/ paths of a call to perform an allocation: we can see a Phi here.\n+  if (in(1)->is_Phi()) {\n+    return this;\n+  }\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":175,"deletions":15,"binary":false,"changes":190,"status":"modified"},{"patch":"@@ -104,1 +104,0 @@\n-  bool try_clean_mem_phi(PhaseGVN* phase);\n@@ -220,0 +219,3 @@\n+  Node* try_clean_mem_phi(PhaseGVN *phase);\n+\n+  InlineTypeBaseNode* push_inline_types_through(PhaseGVN* phase, bool can_reshape, ciInlineKlass* vk, bool is_init);\n@@ -402,0 +404,2 @@\n+  bool is_flat_array_check(PhaseTransform* phase, Node** array = NULL);\n+\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -394,0 +395,3 @@\n+  if (dead->is_InlineTypeBase()) {\n+    remove_inline_type(dead);\n+  }\n@@ -434,0 +438,3 @@\n+    if (n->outcnt() == 0) {\n+      record_for_igvn(n);\n+    }\n@@ -441,0 +448,6 @@\n+  remove_useless_nodes(_inline_type_nodes,  useful); \/\/ remove useless inline type nodes\n+#ifdef ASSERT\n+  if (_modified_nodes != NULL) {\n+    _modified_nodes->remove_useless_nodes(useful.member_set());\n+  }\n+#endif\n@@ -615,0 +628,1 @@\n+                  _inline_type_nodes (comp_arena(), 8, 0, NULL),\n@@ -720,4 +734,2 @@\n-      const TypeTuple *domain = StartOSRNode::osr_domain();\n-      const TypeTuple *range = TypeTuple::make_range(method()->signature());\n-      init_tf(TypeFunc::make(domain, range));\n-      StartNode* s = new StartOSRNode(root(), domain);\n+      init_tf(TypeFunc::make(method(), \/* is_osr_compilation = *\/ true));\n+      StartNode* s = new StartOSRNode(root(), tf()->domain_sig());\n@@ -730,1 +742,1 @@\n-      StartNode* s = new StartNode(root(), tf()->domain());\n+      StartNode* s = new StartNode(root(), tf()->domain_cc());\n@@ -849,0 +861,10 @@\n+  if (needs_stack_repair()) {\n+    \/\/ One extra slot for the special stack increment value\n+    next_slot += 2;\n+  }\n+  \/\/ TODO 8284443 Only reserve extra slot if needed\n+  if (InlineTypeReturnedAsFields) {\n+    \/\/ One extra slot to hold the IsInit information for a nullable\n+    \/\/ inline type return if we run out of registers.\n+    next_slot += 2;\n+  }\n@@ -1000,0 +1022,4 @@\n+  _has_flattened_accesses = false;\n+  _flattened_accesses_share_alias = true;\n+  _scalarize_in_safepoints = false;\n+\n@@ -1303,1 +1329,2 @@\n-    assert(InlineUnsafeOps || StressReflectiveCode, \"indeterminate pointers come only from unsafe ops\");\n+    bool default_value_load = EnableValhalla && tj->is_instptr()->instance_klass() == ciEnv::current()->Class_klass();\n+    assert(InlineUnsafeOps || StressReflectiveCode || default_value_load, \"indeterminate pointers come only from unsafe ops\");\n@@ -1316,0 +1343,9 @@\n+  if (ta && ta->is_not_flat()) {\n+    \/\/ Erase not flat property for alias analysis.\n+    tj = ta = ta->cast_to_not_flat(false);\n+  }\n+  if (ta && ta->is_not_null_free()) {\n+    \/\/ Erase not null free property for alias analysis.\n+    tj = ta = ta->cast_to_not_null_free(false);\n+  }\n+\n@@ -1329,0 +1365,2 @@\n+    \/\/ For flattened inline type array, each field has its own slice so\n+    \/\/ we must include the field offset.\n@@ -1369,1 +1407,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), ta->field_offset());\n@@ -1373,1 +1411,6 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), ta->field_offset());\n+    }\n+    \/\/ Initially all flattened array accesses share a single slice\n+    if (ta->is_flat() && ta->elem() != TypeInlineType::BOTTOM && _flattened_accesses_share_alias) {\n+      const TypeAry *tary = TypeAry::make(TypeInlineType::BOTTOM, ta->size());\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), Type::Offset(Type::OffsetBot));\n@@ -1380,1 +1423,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,aklass,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,aklass,false,Type::Offset(offset), ta->field_offset());\n@@ -1430,1 +1473,1 @@\n-        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, NULL, offset);\n+        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, NULL, Type::Offset(offset));\n@@ -1445,1 +1488,1 @@\n-          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, true, NULL, offset, to->instance_id());\n+          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, true, NULL, Type::Offset(offset), canonical_holder->flatten_array(), to->instance_id());\n@@ -1447,1 +1490,1 @@\n-          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, false, NULL, offset);\n+          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, false, NULL, Type::Offset(offset));\n@@ -1463,1 +1506,1 @@\n-                                       offset);\n+                                       Type::Offset(offset));\n@@ -1469,1 +1512,1 @@\n-        tj = tk = TypeInstKlassPtr::make(TypePtr::NotNull, env()->Object_klass(), offset);\n+        tj = tk = TypeInstKlassPtr::make(TypePtr::NotNull, env()->Object_klass(), Type::Offset(offset));\n@@ -1471,1 +1514,1 @@\n-        tj = tk = TypeAryKlassPtr::make(TypePtr::NotNull, tk->is_aryklassptr()->elem(), k, offset);\n+        tj = tk = TypeAryKlassPtr::make(TypePtr::NotNull, tk->is_aryklassptr()->elem(), k, Type::Offset(offset), tk->is_not_flat(), tk->is_not_null_free(), tk->is_null_free());\n@@ -1629,1 +1672,1 @@\n-Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field) {\n+Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field, bool uncached) {\n@@ -1633,3 +1676,6 @@\n-  AliasCacheEntry* ace = probe_alias_cache(adr_type);\n-  if (ace->_adr_type == adr_type) {\n-    return alias_type(ace->_index);\n+  AliasCacheEntry* ace = NULL;\n+  if (!uncached) {\n+    ace = probe_alias_cache(adr_type);\n+    if (ace->_adr_type == adr_type) {\n+      return alias_type(ace->_index);\n+    }\n@@ -1685,0 +1731,1 @@\n+    ciField* field = NULL;\n@@ -1691,0 +1738,1 @@\n+      const Type* elemtype = flat->is_aryptr()->elem();\n@@ -1692,1 +1740,8 @@\n-        alias_type(idx)->set_element(flat->is_aryptr()->elem());\n+        alias_type(idx)->set_element(elemtype);\n+      }\n+      int field_offset = flat->is_aryptr()->field_offset().get();\n+      if (elemtype->isa_inlinetype() &&\n+          field_offset != Type::OffsetBot) {\n+        ciInlineKlass* vk = elemtype->inline_klass();\n+        field_offset += vk->first_field_offset();\n+        field = vk->get_field_by_offset(field_offset, false);\n@@ -1704,0 +1759,2 @@\n+      if (flat->offset() == in_bytes(Klass::layout_helper_offset()))\n+        alias_type(idx)->set_rewritable(false);\n@@ -1714,1 +1771,0 @@\n-      ciField* field;\n@@ -1721,0 +1777,4 @@\n+      } else if (tinst->is_inlinetypeptr()) {\n+        \/\/ Inline type field\n+        ciInlineKlass* vk = tinst->inline_klass();\n+        field = vk->get_field_by_offset(tinst->offset(), false);\n@@ -1725,7 +1785,14 @@\n-      assert(field == NULL ||\n-             original_field == NULL ||\n-             (field->holder() == original_field->holder() &&\n-              field->offset() == original_field->offset() &&\n-              field->is_static() == original_field->is_static()), \"wrong field?\");\n-      \/\/ Set field() and is_rewritable() attributes.\n-      if (field != NULL)  alias_type(idx)->set_field(field);\n+    }\n+    assert(field == NULL ||\n+           original_field == NULL ||\n+           (field->holder() == original_field->holder() &&\n+            field->offset() == original_field->offset() &&\n+            field->is_static() == original_field->is_static()), \"wrong field?\");\n+    \/\/ Set field() and is_rewritable() attributes.\n+    if (field != NULL) {\n+      alias_type(idx)->set_field(field);\n+      if (flat->isa_aryptr()) {\n+        \/\/ Fields of flat arrays are rewritable although they are declared final\n+        assert(flat->is_aryptr()->is_flat(), \"must be a flat array\");\n+        alias_type(idx)->set_rewritable(true);\n+      }\n@@ -1736,3 +1803,4 @@\n-  ace->_adr_type = adr_type;\n-  ace->_index    = idx;\n-  assert(alias_type(adr_type) == alias_type(idx),  \"type must be installed\");\n+  if (!uncached) {\n+    ace->_adr_type = adr_type;\n+    ace->_index    = idx;\n+    assert(alias_type(adr_type) == alias_type(idx),  \"type must be installed\");\n@@ -1740,6 +1808,7 @@\n-  \/\/ Might as well try to fill the cache for the flattened version, too.\n-  AliasCacheEntry* face = probe_alias_cache(flat);\n-  if (face->_adr_type == NULL) {\n-    face->_adr_type = flat;\n-    face->_index    = idx;\n-    assert(alias_type(flat) == alias_type(idx), \"flat type must work too\");\n+    \/\/ Might as well try to fill the cache for the flattened version, too.\n+    AliasCacheEntry* face = probe_alias_cache(flat);\n+    if (face->_adr_type == NULL) {\n+      face->_adr_type = flat;\n+      face->_index    = idx;\n+      assert(alias_type(flat) == alias_type(idx), \"flat type must work too\");\n+    }\n@@ -1862,0 +1931,405 @@\n+void Compile::add_inline_type(Node* n) {\n+  assert(n->is_InlineTypeBase(), \"unexpected node\");\n+  _inline_type_nodes.push(n);\n+}\n+\n+void Compile::remove_inline_type(Node* n) {\n+  assert(n->is_InlineTypeBase(), \"unexpected node\");\n+  if (_inline_type_nodes.contains(n)) {\n+    _inline_type_nodes.remove(n);\n+  }\n+}\n+\n+\/\/ Does the return value keep otherwise useless inline type allocations alive?\n+static bool return_val_keeps_allocations_alive(Node* ret_val) {\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(ret_val);\n+  bool some_allocations = false;\n+  for (uint i = 0; i < wq.size(); i++) {\n+    Node* n = wq.at(i);\n+    assert(!n->is_InlineType(), \"chain of inline type nodes\");\n+    if (n->outcnt() > 1) {\n+      \/\/ Some other use for the allocation\n+      return false;\n+    } else if (n->is_InlineTypePtr()) {\n+      wq.push(n->in(1));\n+    } else if (n->is_Phi()) {\n+      for (uint j = 1; j < n->req(); j++) {\n+        wq.push(n->in(j));\n+      }\n+    } else if (n->is_CheckCastPP() &&\n+               n->in(1)->is_Proj() &&\n+               n->in(1)->in(0)->is_Allocate()) {\n+      some_allocations = true;\n+    } else if (n->is_CheckCastPP()) {\n+      wq.push(n->in(1));\n+    }\n+  }\n+  return some_allocations;\n+}\n+\n+void Compile::process_inline_types(PhaseIterGVN &igvn, bool remove) {\n+  \/\/ Make sure that the return value does not keep an otherwise unused allocation alive\n+  if (tf()->returns_inline_type_as_fields()) {\n+    Node* ret = NULL;\n+    for (uint i = 1; i < root()->req(); i++) {\n+      Node* in = root()->in(i);\n+      if (in->Opcode() == Op_Return) {\n+        assert(ret == NULL, \"only one return\");\n+        ret = in;\n+      }\n+    }\n+    if (ret != NULL) {\n+      Node* ret_val = ret->in(TypeFunc::Parms);\n+      if (igvn.type(ret_val)->isa_oopptr() &&\n+          return_val_keeps_allocations_alive(ret_val)) {\n+        igvn.replace_input_of(ret, TypeFunc::Parms, InlineTypeNode::tagged_klass(igvn.type(ret_val)->inline_klass(), igvn));\n+        assert(ret_val->outcnt() == 0, \"should be dead now\");\n+        igvn.remove_dead_node(ret_val);\n+      }\n+    }\n+  }\n+  if (_inline_type_nodes.length() == 0) {\n+    return;\n+  }\n+  \/\/ Scalarize inline types in safepoint debug info.\n+  \/\/ Delay this until all inlining is over to avoid getting inconsistent debug info.\n+  set_scalarize_in_safepoints(true);\n+  for (int i = _inline_type_nodes.length()-1; i >= 0; i--) {\n+    _inline_type_nodes.at(i)->as_InlineTypeBase()->make_scalar_in_safepoints(&igvn);\n+  }\n+  if (remove) {\n+    \/\/ Remove inline type nodes\n+    while (_inline_type_nodes.length() > 0) {\n+      InlineTypeBaseNode* vt = _inline_type_nodes.pop()->as_InlineTypeBase();\n+      if (vt->outcnt() == 0) {\n+        igvn.remove_dead_node(vt);\n+      } else if (vt->is_InlineTypePtr()) {\n+        igvn.replace_node(vt, vt->get_oop());\n+      } else {\n+        \/\/ Check if any users are blackholes. If so, rewrite them to use either the\n+        \/\/ allocated buffer, or individual components, instead of the inline type node\n+        \/\/ that goes away.\n+        for (DUIterator i = vt->outs(); vt->has_out(i); i++) {\n+          if (vt->out(i)->is_Blackhole()) {\n+            BlackholeNode* bh = vt->out(i)->as_Blackhole();\n+\n+            \/\/ Unlink the old input\n+            int idx = bh->find_edge(vt);\n+            assert(idx != -1, \"The edge should be there\");\n+            bh->del_req(idx);\n+            --i;\n+\n+            if (vt->is_allocated(&igvn)) {\n+              \/\/ Already has the allocated instance, blackhole that\n+              bh->add_req(vt->get_oop());\n+            } else {\n+              \/\/ Not allocated yet, blackhole the components\n+              for (uint c = 0; c < vt->field_count(); c++) {\n+                bh->add_req(vt->field_value(c));\n+              }\n+            }\n+\n+            \/\/ Node modified, record for IGVN\n+            igvn.record_for_igvn(bh);\n+          }\n+        }\n+\n+#ifdef ASSERT\n+        for (DUIterator_Fast imax, i = vt->fast_outs(imax); i < imax; i++) {\n+          assert(vt->fast_out(i)->is_InlineTypeBase(), \"Unexpected inline type user\");\n+        }\n+#endif\n+        igvn.replace_node(vt, igvn.C->top());\n+      }\n+    }\n+  }\n+  igvn.optimize();\n+}\n+\n+void Compile::adjust_flattened_array_access_aliases(PhaseIterGVN& igvn) {\n+  if (!_has_flattened_accesses) {\n+    return;\n+  }\n+  \/\/ Initially, all flattened array accesses share the same slice to\n+  \/\/ keep dependencies with Object[] array accesses (that could be\n+  \/\/ to a flattened array) correct. We're done with parsing so we\n+  \/\/ now know all flattened array accesses in this compile\n+  \/\/ unit. Let's move flattened array accesses to their own slice,\n+  \/\/ one per element field. This should help memory access\n+  \/\/ optimizations.\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(root());\n+\n+  Node_List mergememnodes;\n+  Node_List memnodes;\n+\n+  \/\/ Alias index currently shared by all flattened memory accesses\n+  int index = get_alias_index(TypeAryPtr::INLINES);\n+\n+  \/\/ Find MergeMem nodes and flattened array accesses\n+  for (uint i = 0; i < wq.size(); i++) {\n+    Node* n = wq.at(i);\n+    if (n->is_Mem()) {\n+      const TypePtr* adr_type = NULL;\n+      if (n->Opcode() == Op_StoreCM) {\n+        adr_type = get_adr_type(get_alias_index(n->in(MemNode::OopStore)->adr_type()));\n+      } else {\n+        adr_type = get_adr_type(get_alias_index(n->adr_type()));\n+      }\n+      if (adr_type == TypeAryPtr::INLINES) {\n+        memnodes.push(n);\n+      }\n+    } else if (n->is_MergeMem()) {\n+      MergeMemNode* mm = n->as_MergeMem();\n+      if (mm->memory_at(index) != mm->base_memory()) {\n+        mergememnodes.push(n);\n+      }\n+    }\n+    for (uint j = 0; j < n->req(); j++) {\n+      Node* m = n->in(j);\n+      if (m != NULL) {\n+        wq.push(m);\n+      }\n+    }\n+  }\n+\n+  if (memnodes.size() > 0) {\n+    _flattened_accesses_share_alias = false;\n+\n+    \/\/ We are going to change the slice for the flattened array\n+    \/\/ accesses so we need to clear the cache entries that refer to\n+    \/\/ them.\n+    for (uint i = 0; i < AliasCacheSize; i++) {\n+      AliasCacheEntry* ace = &_alias_cache[i];\n+      if (ace->_adr_type != NULL &&\n+          ace->_adr_type->isa_aryptr() &&\n+          ace->_adr_type->is_aryptr()->is_flat()) {\n+        ace->_adr_type = NULL;\n+        ace->_index = (i != 0) ? 0 : AliasIdxTop; \/\/ Make sure the NULL adr_type resolves to AliasIdxTop\n+      }\n+    }\n+\n+    \/\/ Find what aliases we are going to add\n+    int start_alias = num_alias_types()-1;\n+    int stop_alias = 0;\n+\n+    for (uint i = 0; i < memnodes.size(); i++) {\n+      Node* m = memnodes.at(i);\n+      const TypePtr* adr_type = NULL;\n+      if (m->Opcode() == Op_StoreCM) {\n+        adr_type = m->in(MemNode::OopStore)->adr_type();\n+        if (adr_type != TypeAryPtr::INLINES) {\n+          \/\/ store was optimized out and we lost track of the adr_type\n+          Node* clone = new StoreCMNode(m->in(MemNode::Control), m->in(MemNode::Memory), m->in(MemNode::Address),\n+                                        m->adr_type(), m->in(MemNode::ValueIn), m->in(MemNode::OopStore),\n+                                        get_alias_index(adr_type));\n+          igvn.register_new_node_with_optimizer(clone);\n+          igvn.replace_node(m, clone);\n+        }\n+      } else {\n+        adr_type = m->adr_type();\n+#ifdef ASSERT\n+        m->as_Mem()->set_adr_type(adr_type);\n+#endif\n+      }\n+      int idx = get_alias_index(adr_type);\n+      start_alias = MIN2(start_alias, idx);\n+      stop_alias = MAX2(stop_alias, idx);\n+    }\n+\n+    assert(stop_alias >= start_alias, \"should have expanded aliases\");\n+\n+    Node_Stack stack(0);\n+#ifdef ASSERT\n+    VectorSet seen(Thread::current()->resource_area());\n+#endif\n+    \/\/ Now let's fix the memory graph so each flattened array access\n+    \/\/ is moved to the right slice. Start from the MergeMem nodes.\n+    uint last = unique();\n+    for (uint i = 0; i < mergememnodes.size(); i++) {\n+      MergeMemNode* current = mergememnodes.at(i)->as_MergeMem();\n+      Node* n = current->memory_at(index);\n+      MergeMemNode* mm = NULL;\n+      do {\n+        \/\/ Follow memory edges through memory accesses, phis and\n+        \/\/ narrow membars and push nodes on the stack. Once we hit\n+        \/\/ bottom memory, we pop element off the stack one at a\n+        \/\/ time, in reverse order, and move them to the right slice\n+        \/\/ by changing their memory edges.\n+        if ((n->is_Phi() && n->adr_type() != TypePtr::BOTTOM) || n->is_Mem() || n->adr_type() == TypeAryPtr::INLINES) {\n+          assert(!seen.test_set(n->_idx), \"\");\n+          \/\/ Uses (a load for instance) will need to be moved to the\n+          \/\/ right slice as well and will get a new memory state\n+          \/\/ that we don't know yet. The use could also be the\n+          \/\/ backedge of a loop. We put a place holder node between\n+          \/\/ the memory node and its uses. We replace that place\n+          \/\/ holder with the correct memory state once we know it,\n+          \/\/ i.e. when nodes are popped off the stack. Using the\n+          \/\/ place holder make the logic work in the presence of\n+          \/\/ loops.\n+          if (n->outcnt() > 1) {\n+            Node* place_holder = NULL;\n+            assert(!n->has_out_with(Op_Node), \"\");\n+            for (DUIterator k = n->outs(); n->has_out(k); k++) {\n+              Node* u = n->out(k);\n+              if (u != current && u->_idx < last) {\n+                bool success = false;\n+                for (uint l = 0; l < u->req(); l++) {\n+                  if (!stack.is_empty() && u == stack.node() && l == stack.index()) {\n+                    continue;\n+                  }\n+                  Node* in = u->in(l);\n+                  if (in == n) {\n+                    if (place_holder == NULL) {\n+                      place_holder = new Node(1);\n+                      place_holder->init_req(0, n);\n+                    }\n+                    igvn.replace_input_of(u, l, place_holder);\n+                    success = true;\n+                  }\n+                }\n+                if (success) {\n+                  --k;\n+                }\n+              }\n+            }\n+          }\n+          if (n->is_Phi()) {\n+            stack.push(n, 1);\n+            n = n->in(1);\n+          } else if (n->is_Mem()) {\n+            stack.push(n, n->req());\n+            n = n->in(MemNode::Memory);\n+          } else {\n+            assert(n->is_Proj() && n->in(0)->Opcode() == Op_MemBarCPUOrder, \"\");\n+            stack.push(n, n->req());\n+            n = n->in(0)->in(TypeFunc::Memory);\n+          }\n+        } else {\n+          assert(n->adr_type() == TypePtr::BOTTOM || (n->Opcode() == Op_Node && n->_idx >= last) || (n->is_Proj() && n->in(0)->is_Initialize()), \"\");\n+          \/\/ Build a new MergeMem node to carry the new memory state\n+          \/\/ as we build it. IGVN should fold extraneous MergeMem\n+          \/\/ nodes.\n+          mm = MergeMemNode::make(n);\n+          igvn.register_new_node_with_optimizer(mm);\n+          while (stack.size() > 0) {\n+            Node* m = stack.node();\n+            uint idx = stack.index();\n+            if (m->is_Mem()) {\n+              \/\/ Move memory node to its new slice\n+              const TypePtr* adr_type = m->adr_type();\n+              int alias = get_alias_index(adr_type);\n+              Node* prev = mm->memory_at(alias);\n+              igvn.replace_input_of(m, MemNode::Memory, prev);\n+              mm->set_memory_at(alias, m);\n+            } else if (m->is_Phi()) {\n+              \/\/ We need as many new phis as there are new aliases\n+              igvn.replace_input_of(m, idx, mm);\n+              if (idx == m->req()-1) {\n+                Node* r = m->in(0);\n+                for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+                  const Type* adr_type = get_adr_type(j);\n+                  if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat() || j == (uint)index) {\n+                    continue;\n+                  }\n+                  Node* phi = new PhiNode(r, Type::MEMORY, get_adr_type(j));\n+                  igvn.register_new_node_with_optimizer(phi);\n+                  for (uint k = 1; k < m->req(); k++) {\n+                    phi->init_req(k, m->in(k)->as_MergeMem()->memory_at(j));\n+                  }\n+                  mm->set_memory_at(j, phi);\n+                }\n+                Node* base_phi = new PhiNode(r, Type::MEMORY, TypePtr::BOTTOM);\n+                igvn.register_new_node_with_optimizer(base_phi);\n+                for (uint k = 1; k < m->req(); k++) {\n+                  base_phi->init_req(k, m->in(k)->as_MergeMem()->base_memory());\n+                }\n+                mm->set_base_memory(base_phi);\n+              }\n+            } else {\n+              \/\/ This is a MemBarCPUOrder node from\n+              \/\/ Parse::array_load()\/Parse::array_store(), in the\n+              \/\/ branch that handles flattened arrays hidden under\n+              \/\/ an Object[] array. We also need one new membar per\n+              \/\/ new alias to keep the unknown access that the\n+              \/\/ membars protect properly ordered with accesses to\n+              \/\/ known flattened array.\n+              assert(m->is_Proj(), \"projection expected\");\n+              Node* ctrl = m->in(0)->in(TypeFunc::Control);\n+              igvn.replace_input_of(m->in(0), TypeFunc::Control, top());\n+              for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+                const Type* adr_type = get_adr_type(j);\n+                if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat() || j == (uint)index) {\n+                  continue;\n+                }\n+                MemBarNode* mb = new MemBarCPUOrderNode(this, j, NULL);\n+                igvn.register_new_node_with_optimizer(mb);\n+                Node* mem = mm->memory_at(j);\n+                mb->init_req(TypeFunc::Control, ctrl);\n+                mb->init_req(TypeFunc::Memory, mem);\n+                ctrl = new ProjNode(mb, TypeFunc::Control);\n+                igvn.register_new_node_with_optimizer(ctrl);\n+                mem = new ProjNode(mb, TypeFunc::Memory);\n+                igvn.register_new_node_with_optimizer(mem);\n+                mm->set_memory_at(j, mem);\n+              }\n+              igvn.replace_node(m->in(0)->as_Multi()->proj_out(TypeFunc::Control), ctrl);\n+            }\n+            if (idx < m->req()-1) {\n+              idx += 1;\n+              stack.set_index(idx);\n+              n = m->in(idx);\n+              break;\n+            }\n+            \/\/ Take care of place holder nodes\n+            if (m->has_out_with(Op_Node)) {\n+              Node* place_holder = m->find_out_with(Op_Node);\n+              if (place_holder != NULL) {\n+                Node* mm_clone = mm->clone();\n+                igvn.register_new_node_with_optimizer(mm_clone);\n+                Node* hook = new Node(1);\n+                hook->init_req(0, mm);\n+                igvn.replace_node(place_holder, mm_clone);\n+                hook->destruct(&igvn);\n+              }\n+              assert(!m->has_out_with(Op_Node), \"place holder should be gone now\");\n+            }\n+            stack.pop();\n+          }\n+        }\n+      } while(stack.size() > 0);\n+      \/\/ Fix the memory state at the MergeMem we started from\n+      igvn.rehash_node_delayed(current);\n+      for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+        const Type* adr_type = get_adr_type(j);\n+        if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat()) {\n+          continue;\n+        }\n+        current->set_memory_at(j, mm);\n+      }\n+      current->set_memory_at(index, current->base_memory());\n+    }\n+    igvn.optimize();\n+  }\n+  print_method(PHASE_SPLIT_INLINES_ARRAY, 2);\n+#ifdef ASSERT\n+  if (!_flattened_accesses_share_alias) {\n+    wq.clear();\n+    wq.push(root());\n+    for (uint i = 0; i < wq.size(); i++) {\n+      Node* n = wq.at(i);\n+      assert(n->adr_type() != TypeAryPtr::INLINES, \"should have been removed from the graph\");\n+      for (uint j = 0; j < n->req(); j++) {\n+        Node* m = n->in(j);\n+        if (m != NULL) {\n+          wq.push(m);\n+        }\n+      }\n+    }\n+  }\n+#endif\n+}\n+\n@@ -2151,1 +2625,4 @@\n-  assert(_modified_nodes == NULL, \"not allowed\");\n+#ifdef ASSERT\n+  Unique_Node_List* modified_nodes = _modified_nodes;\n+  _modified_nodes = NULL;\n+#endif\n@@ -2165,0 +2642,1 @@\n+  DEBUG_ONLY( _modified_nodes = modified_nodes; )\n@@ -2308,0 +2786,5 @@\n+  \/\/ Process inline type nodes now that all inlining is over\n+  process_inline_types(igvn);\n+\n+  adjust_flattened_array_access_aliases(igvn);\n+\n@@ -2421,0 +2904,8 @@\n+  assert(_late_inlines.length() == 0 || IncrementalInlineMH || IncrementalInlineVirtual, \"not empty\");\n+\n+  if (_late_inlines.length() > 0) {\n+    \/\/ More opportunities to optimize virtual and MH calls.\n+    \/\/ Though it's maybe too late to perform inlining, strength-reducing them to direct calls is still an option.\n+    process_late_inline_calls_no_inline(igvn);\n+  }\n+\n@@ -2431,0 +2922,4 @@\n+  \/\/ Process inline type nodes again and remove them. From here\n+  \/\/ on we don't need to keep track of field values anymore.\n+  process_inline_types(igvn, \/* remove= *\/ true);\n+\n@@ -2446,0 +2941,1 @@\n+  DEBUG_ONLY( _late_inlines.clear(); )\n@@ -2448,8 +2944,0 @@\n-\n-  assert(_late_inlines.length() == 0 || IncrementalInlineMH || IncrementalInlineVirtual, \"not empty\");\n-\n-  if (_late_inlines.length() > 0) {\n-    \/\/ More opportunities to optimize virtual and MH calls.\n-    \/\/ Though it's maybe too late to perform inlining, strength-reducing them to direct calls is still an option.\n-    process_late_inline_calls_no_inline(igvn);\n-  }\n@@ -3079,0 +3567,1 @@\n+\n@@ -3232,1 +3721,16 @@\n-      n->add_prec(prec);\n+      if (prec->is_MergeMem()) {\n+        MergeMemNode* mm = prec->as_MergeMem();\n+        Node* base = mm->base_memory();\n+        for (int i = AliasIdxRaw + 1; i < num_alias_types(); i++) {\n+          const Type* adr_type = get_adr_type(i);\n+          if (adr_type->isa_aryptr() && adr_type->is_aryptr()->is_flat()) {\n+            Node* m = mm->memory_at(i);\n+            n->add_prec(m);\n+          }\n+        }\n+        if (mm->outcnt() == 0) {\n+          mm->disconnect_inputs(this);\n+        }\n+      } else {\n+        n->add_prec(prec);\n+      }\n@@ -3842,0 +4346,8 @@\n+#ifdef ASSERT\n+  case Op_InlineTypePtr:\n+  case Op_InlineType: {\n+    n->dump(-1);\n+    assert(false, \"inline type node was not removed\");\n+    break;\n+  }\n+#endif\n@@ -4189,2 +4701,2 @@\n-      if (accessing_method->is_static_initializer() ||\n-          accessing_method->is_object_initializer() ||\n+      if (accessing_method->is_class_initializer() ||\n+          accessing_method->is_object_constructor() ||\n@@ -4198,1 +4710,1 @@\n-      if (accessing_method->is_static_initializer()) {\n+      if (accessing_method->is_class_initializer()) {\n@@ -4335,0 +4847,8 @@\n+\n+    \/\/ Do not fold the subtype check to an array klass pointer comparison for [V? arrays.\n+    \/\/ [QMyValue is a subtype of [LMyValue but the klass for [QMyValue is not equal to\n+    \/\/ the klass for [LMyValue. Perform a full test.\n+    if (!superk->is_aryklassptr()->is_null_free() && superk->is_aryklassptr()->elem()->isa_instklassptr() &&\n+        superk->is_aryklassptr()->elem()->is_instklassptr()->instance_klass()->is_inlinetype()) {\n+      return SSC_full_test;\n+    }\n@@ -4867,0 +5387,21 @@\n+Node* Compile::optimize_acmp(PhaseGVN* phase, Node* a, Node* b) {\n+  const TypeInstPtr* ta = phase->type(a)->isa_instptr();\n+  const TypeInstPtr* tb = phase->type(b)->isa_instptr();\n+  if (!EnableValhalla || ta == NULL || tb == NULL ||\n+      ta->is_zero_type() || tb->is_zero_type() ||\n+      !ta->can_be_inline_type() || !tb->can_be_inline_type()) {\n+    \/\/ Use old acmp if one operand is null or not an inline type\n+    return new CmpPNode(a, b);\n+  } else if (ta->is_inlinetypeptr() || tb->is_inlinetypeptr()) {\n+    \/\/ We know that one operand is an inline type. Therefore,\n+    \/\/ new acmp will only return true if both operands are NULL.\n+    \/\/ Check if both operands are null by or'ing the oops.\n+    a = phase->transform(new CastP2XNode(NULL, a));\n+    b = phase->transform(new CastP2XNode(NULL, b));\n+    a = phase->transform(new OrXNode(a, b));\n+    return new CmpXNode(a, phase->MakeConX(0));\n+  }\n+  \/\/ Use new acmp\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":591,"deletions":50,"binary":false,"changes":641,"status":"modified"},{"patch":"@@ -1234,0 +1234,17 @@\n+\/\/ Returns true if this IfNode belongs to a flat array check\n+\/\/ and returns the corresponding array in the 'array' parameter.\n+bool IfNode::is_flat_array_check(PhaseTransform* phase, Node** array) {\n+  Node* bol = in(1);\n+  if (!bol->is_Bool()) {\n+    return false;\n+  }\n+  Node* cmp = bol->in(1);\n+  if (cmp->isa_FlatArrayCheck()) {\n+    if (array != NULL) {\n+      *array = cmp->in(FlatArrayCheckNode::ArrayOrKlass);\n+    }\n+    return true;\n+  }\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/ifnode.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -278,1 +278,1 @@\n-        if (offset == Type::OffsetBot || tptr->_offset == Type::OffsetBot)\n+        if (offset == Type::OffsetBot || tptr->offset() == Type::OffsetBot)\n@@ -280,1 +280,1 @@\n-        offset += tptr->_offset; \/\/ correct if base is offsetted\n+        offset += tptr->offset(); \/\/ correct if base is offsetted\n@@ -317,1 +317,5 @@\n-      Block *inb = get_block_for_node(mach->in(j));\n+      Block* inb = get_block_for_node(mach->in(j));\n+      if (mach->in(j)->is_Con() && mach->in(j)->req() == 1 && inb == get_block_for_node(mach)) {\n+        \/\/ Ignore constant loads scheduled in the same block (we can simply hoist them as well)\n+        continue;\n+      }\n@@ -410,0 +414,21 @@\n+\n+  \/\/ Hoist constant load inputs as well.\n+  for (uint i = 1; i < best->req(); ++i) {\n+    Node* n = best->in(i);\n+    if (n->is_Con() && get_block_for_node(n) == get_block_for_node(best)) {\n+      get_block_for_node(n)->find_remove(n);\n+      block->add_inst(n);\n+      map_node_to_block(n, block);\n+      \/\/ Constant loads may kill flags (for example, when XORing a register).\n+      \/\/ Check for flag-killing projections that also need to be hoisted.\n+      for (DUIterator_Fast jmax, j = n->fast_outs(jmax); j < jmax; j++) {\n+        Node* proj = n->fast_out(j);\n+        if (proj->is_MachProj()) {\n+          get_block_for_node(proj)->find_remove(proj);\n+          block->add_inst(proj);\n+          map_node_to_block(proj, block);\n+        }\n+      }\n+    }\n+  }\n+\n@@ -881,1 +906,1 @@\n-  uint r_cnt = mcall->tf()->range()->cnt();\n+  uint r_cnt = mcall->tf()->range_cc()->cnt();\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":29,"deletions":4,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -320,0 +321,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:        return inline_unsafe_make_private_buffer();\n+  case vmIntrinsics::_finishPrivateBuffer:      return inline_unsafe_finish_private_buffer();\n@@ -329,0 +332,1 @@\n+  case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_PRIMITIVE_OBJECT,Relaxed, false);\n@@ -339,0 +343,1 @@\n+  case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_PRIMITIVE_OBJECT,Relaxed, false);\n@@ -512,0 +517,3 @@\n+  case vmIntrinsics::_asPrimaryType:\n+  case vmIntrinsics::_asValueType:              return inline_primitive_Class_conversion(intrinsic_id());\n+\n@@ -2166,0 +2174,1 @@\n+  bool null_free = false;\n@@ -2171,0 +2180,1 @@\n+      null_free = alias_type->field()->is_null_free();\n@@ -2179,0 +2189,1 @@\n+      null_free = adr_type->is_aryptr()->is_null_free();\n@@ -2191,0 +2202,3 @@\n+    if (null_free) {\n+      result = result->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n@@ -2245,2 +2259,2 @@\n-      assert(rtype == type, \"getter must return the expected value\");\n-      assert(sig->count() == 2, \"oop getter has 2 arguments\");\n+      assert(rtype == type || (rtype == T_OBJECT && type == T_PRIMITIVE_OBJECT), \"getter must return the expected value\");\n+      assert(sig->count() == 2 || (type == T_PRIMITIVE_OBJECT && sig->count() == 3), \"oop getter has 2 or 3 arguments\");\n@@ -2252,1 +2266,1 @@\n-      assert(sig->count() == 3, \"oop putter has 3 arguments\");\n+      assert(sig->count() == 3 || (type == T_PRIMITIVE_OBJECT && sig->count() == 4), \"oop putter has 3 arguments\");\n@@ -2256,1 +2270,1 @@\n-      assert(vtype == type, \"putter must accept the expected value\");\n+      assert(vtype == type || (type == T_PRIMITIVE_OBJECT && vtype == T_OBJECT), \"putter must accept the expected value\");\n@@ -2278,0 +2292,51 @@\n+\n+  ciInlineKlass* inline_klass = NULL;\n+  if (type == T_PRIMITIVE_OBJECT) {\n+    const TypeInstPtr* cls = _gvn.type(argument(4))->isa_instptr();\n+    if (cls == NULL || cls->const_oop() == NULL) {\n+      return false;\n+    }\n+    ciType* mirror_type = cls->const_oop()->as_instance()->java_mirror_type();\n+    if (!mirror_type->is_inlinetype()) {\n+      return false;\n+    }\n+    inline_klass = mirror_type->as_inline_klass();\n+  }\n+\n+  if (base->is_InlineTypeBase()) {\n+    InlineTypeBaseNode* vt = base->as_InlineTypeBase();\n+    if (is_store) {\n+      if (!vt->is_allocated(&_gvn) || !_gvn.type(vt)->isa_inlinetype() || !_gvn.type(vt)->is_inlinetype()->larval()) {\n+        return false;\n+      }\n+      base = vt->get_oop();\n+    } else {\n+      if (offset->is_Con()) {\n+        long off = find_long_con(offset, 0);\n+        ciInlineKlass* vk = vt->type()->inline_klass();\n+        if ((long)(int)off != off || !vk->contains_field_offset(off)) {\n+          return false;\n+        }\n+\n+        ciField* field = vk->get_non_flattened_field_by_offset(off);\n+        if (field != NULL) {\n+          BasicType bt = field->layout_type();\n+          if (bt == T_ARRAY || bt == T_NARROWOOP || (bt == T_PRIMITIVE_OBJECT && !field->is_flattened())) {\n+            bt = T_OBJECT;\n+          }\n+          if (bt == type && (bt != T_PRIMITIVE_OBJECT || field->type() == inline_klass)) {\n+            set_result(vt->field_value_by_offset(off, false));\n+            return true;\n+          }\n+        }\n+      }\n+      if (vt->is_InlineType()) {\n+        \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+        PreserveReexecuteState preexecs(this);\n+        jvms()->set_should_reexecute(true);\n+        vt = vt->buffer(this);\n+      }\n+      base = vt->get_oop();\n+    }\n+  }\n+\n@@ -2288,1 +2353,1 @@\n-    if (type != T_OBJECT) {\n+    if (type != T_OBJECT && (inline_klass == NULL || !inline_klass->has_object_fields())) {\n@@ -2306,1 +2371,1 @@\n-  Node* val = is_store ? argument(4) : NULL;\n+  Node* val = is_store ? argument(4 + (type == T_PRIMITIVE_OBJECT ? 1 : 0)) : NULL;\n@@ -2327,1 +2392,25 @@\n-  BasicType bt = alias_type->basic_type();\n+  BasicType bt = T_ILLEGAL;\n+  ciField* field = NULL;\n+  if (adr_type->isa_instptr()) {\n+    const TypeInstPtr* instptr = adr_type->is_instptr();\n+    ciInstanceKlass* k = instptr->instance_klass();\n+    int off = instptr->offset();\n+    if (instptr->const_oop() != NULL &&\n+        k == ciEnv::current()->Class_klass() &&\n+        instptr->offset() >= (k->size_helper() * wordSize)) {\n+      k = instptr->const_oop()->as_instance()->java_lang_Class_klass()->as_instance_klass();\n+      field = k->get_field_by_offset(off, true);\n+    } else {\n+      field = k->get_non_flattened_field_by_offset(off);\n+    }\n+    if (field != NULL) {\n+      bt = field->layout_type();\n+    }\n+    assert(bt == alias_type->basic_type() || bt == T_PRIMITIVE_OBJECT, \"should match\");\n+    if (field != NULL && bt == T_PRIMITIVE_OBJECT && !field->is_flattened()) {\n+      bt = T_OBJECT;\n+    }\n+  } else {\n+    bt = alias_type->basic_type();\n+  }\n+\n@@ -2335,1 +2424,1 @@\n-    if (is_reference_type(bt, true)) {\n+    if (bt != T_PRIMITIVE_OBJECT && is_reference_type(bt, true)) {\n@@ -2350,0 +2439,25 @@\n+  if (type == T_PRIMITIVE_OBJECT) {\n+    if (adr_type->isa_instptr()) {\n+      if (field == NULL || field->type() != inline_klass) {\n+        mismatched = true;\n+      }\n+    } else if (adr_type->isa_aryptr()) {\n+      const Type* elem = adr_type->is_aryptr()->elem();\n+      if (!elem->isa_inlinetype()) {\n+        mismatched = true;\n+      } else if (elem->inline_klass() != inline_klass) {\n+        mismatched = true;\n+      }\n+    } else {\n+      mismatched = true;\n+    }\n+    if (is_store) {\n+      const Type* val_t = _gvn.type(val);\n+      if (!(val_t->isa_inlinetype() || val_t->is_inlinetypeptr()) || val_t->inline_klass() != inline_klass) {\n+        set_map(old_map);\n+        set_sp(old_sp);\n+        return false;\n+      }\n+    }\n+  }\n+\n@@ -2351,1 +2465,1 @@\n-  assert(!mismatched || alias_type->adr_type()->is_oopptr(), \"off-heap access can't be mismatched\");\n+  assert(!mismatched || type == T_PRIMITIVE_OBJECT || alias_type->adr_type()->is_oopptr(), \"off-heap access can't be mismatched\");\n@@ -2363,4 +2477,8 @@\n-  if (!is_store && type == T_OBJECT) {\n-    const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);\n-    if (tjp != NULL) {\n-      value_type = tjp;\n+  if (!is_store) {\n+    if (type == T_OBJECT) {\n+      const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);\n+      if (tjp != NULL) {\n+        value_type = tjp;\n+      }\n+    } else if (type == T_PRIMITIVE_OBJECT) {\n+      value_type = NULL;\n@@ -2382,2 +2500,2 @@\n-    ciField* field = alias_type->field();\n-    if (heap_base_oop != top() && field != NULL && field->is_constant() && !mismatched) {\n+\n+    if (heap_base_oop != top() && field != NULL && field->is_constant() && !field->is_flattened() && !mismatched) {\n@@ -2389,1 +2507,16 @@\n-      p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);\n+      if (type == T_PRIMITIVE_OBJECT) {\n+        if (adr_type->isa_instptr() && !mismatched) {\n+          ciInstanceKlass* holder = adr_type->is_instptr()->instance_klass();\n+          int offset = adr_type->is_instptr()->offset();\n+          p = InlineTypeNode::make_from_flattened(this, inline_klass, base, base, holder, offset, decorators);\n+        } else {\n+          p = InlineTypeNode::make_from_flattened(this, inline_klass, base, adr, NULL, 0, decorators);\n+        }\n+      } else {\n+        p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);\n+        const TypeOopPtr* ptr = value_type->make_oopptr();\n+        if (ptr != NULL && ptr->is_inlinetypeptr()) {\n+          \/\/ Load a non-flattened inline type from memory\n+          p = InlineTypeNode::make_from_oop(this, p, ptr->inline_klass(), !ptr->maybe_null());\n+        }\n+      }\n@@ -2427,1 +2560,17 @@\n-    access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);\n+    if (type == T_PRIMITIVE_OBJECT) {\n+      if (adr_type->isa_instptr() && !mismatched) {\n+        ciInstanceKlass* holder = adr_type->is_instptr()->instance_klass();\n+        int offset = adr_type->is_instptr()->offset();\n+        val->as_InlineTypeBase()->store_flattened(this, base, base, holder, offset, decorators);\n+      } else {\n+        val->as_InlineTypeBase()->store_flattened(this, base, adr, NULL, 0, decorators);\n+      }\n+    } else {\n+      access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);\n+    }\n+  }\n+\n+  if (argument(1)->is_InlineType() && is_store) {\n+    InlineTypeBaseNode* value = InlineTypeNode::make_from_oop(this, base, _gvn.type(base)->inline_klass());\n+    value = value->make_larval(this, false);\n+    replace_in_map(argument(1), value);\n@@ -2433,0 +2582,36 @@\n+bool LibraryCallKit::inline_unsafe_make_private_buffer() {\n+  Node* receiver = argument(0);\n+  Node* value = argument(1);\n+  if (!value->is_InlineTypeBase()) {\n+    return false;\n+  }\n+\n+  receiver = null_check(receiver);\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  set_result(value->as_InlineTypeBase()->make_larval(this, true));\n+  return true;\n+}\n+\n+bool LibraryCallKit::inline_unsafe_finish_private_buffer() {\n+  Node* receiver = argument(0);\n+  Node* buffer = argument(1);\n+  if (!buffer->is_InlineType()) {\n+    return false;\n+  }\n+  InlineTypeNode* vt = buffer->as_InlineType();\n+  if (!vt->is_allocated(&_gvn) || !_gvn.type(vt)->is_inlinetype()->larval()) {\n+    return false;\n+  }\n+\n+  receiver = null_check(receiver);\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  set_result(vt->finish_larval(this));\n+  return true;\n+}\n+\n@@ -2638,0 +2823,13 @@\n+    if (oldval != NULL && oldval->is_InlineType()) {\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      oldval = oldval->as_InlineType()->buffer(this)->get_oop();\n+    }\n+    if (newval != NULL && newval->is_InlineType()) {\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      newval = newval->as_InlineType()->buffer(this)->get_oop();\n+    }\n+\n@@ -2799,2 +2997,7 @@\n-\n-  Node* obj = new_instance(kls, test);\n+  Node* obj = NULL;\n+  const TypeInstKlassPtr* tkls = _gvn.type(kls)->isa_instklassptr();\n+  if (tkls != NULL && tkls->instance_klass()->is_inlinetype()) {\n+    obj = InlineTypeNode::make_default(_gvn, tkls->instance_klass()->as_inline_klass())->buffer(this);\n+  } else {\n+    obj = new_instance(kls, test);\n+  }\n@@ -3376,1 +3579,1 @@\n-  const Type* objects_type = TypeAryPtr::make(TypePtr::BotPTR, arr0, objects_klass, xk, 0);\n+  const Type* objects_type = TypeAryPtr::make(TypePtr::BotPTR, arr0, objects_klass, xk, TypeAryPtr::Offset(0));\n@@ -3395,9 +3598,0 @@\n-\/\/---------------------------load_mirror_from_klass----------------------------\n-\/\/ Given a klass oop, load its java mirror (a java.lang.Class oop).\n-Node* LibraryCallKit::load_mirror_from_klass(Node* klass) {\n-  Node* p = basic_plus_adr(klass, in_bytes(Klass::java_mirror_offset()));\n-  Node* load = make_load(NULL, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n-  \/\/ mirror = ((OopHandle)mirror)->resolve();\n-  return access_load(load, TypeInstPtr::MIRROR, T_OBJECT, IN_NATIVE);\n-}\n-\n@@ -3446,0 +3640,1 @@\n+\n@@ -3639,0 +3834,29 @@\n+\/\/-------------------------inline_primitive_Class_conversion-------------------\n+\/\/ public Class<T> java.lang.Class.asPrimaryType();\n+\/\/ public Class<T> java.lang.Class.asValueType()\n+bool LibraryCallKit::inline_primitive_Class_conversion(vmIntrinsics::ID id) {\n+  Node* mirror = argument(0); \/\/ Receiver Class\n+  const TypeInstPtr* mirror_con = _gvn.type(mirror)->isa_instptr();\n+  if (mirror_con == NULL) {\n+    return false;\n+  }\n+\n+  bool is_val_mirror = true;\n+  ciType* tm = mirror_con->java_mirror_type(&is_val_mirror);\n+  if (tm != NULL) {\n+    Node* result = mirror;\n+    if (id == vmIntrinsics::_asPrimaryType && is_val_mirror) {\n+      result = _gvn.makecon(TypeInstPtr::make(tm->as_inline_klass()->ref_mirror()));\n+    } else if (id == vmIntrinsics::_asValueType) {\n+      if (!tm->is_inlinetype()) {\n+        return false; \/\/ Throw UnsupportedOperationException\n+      } else if (!is_val_mirror) {\n+        result = _gvn.makecon(TypeInstPtr::make(tm->as_inline_klass()->val_mirror()));\n+      }\n+    }\n+    set_result(result);\n+    return true;\n+  }\n+  return false;\n+}\n+\n@@ -3654,1 +3878,2 @@\n-  ciType* tm = mirror_con->java_mirror_type();\n+  bool requires_null_check = false;\n+  ciType* tm = mirror_con->java_mirror_type(&requires_null_check);\n@@ -3664,0 +3889,3 @@\n+        if (requires_null_check) {\n+          obj = null_check(obj);\n+        }\n@@ -3684,0 +3912,3 @@\n+  if (requires_null_check) {\n+    obj = null_check(obj);\n+  }\n@@ -3691,1 +3922,1 @@\n-  enum { _bad_type_path = 1, _prim_path = 2, PATH_LIMIT };\n+  enum { _bad_type_path = 1, _prim_path = 2, _npe_path = 3, PATH_LIMIT };\n@@ -3702,0 +3933,21 @@\n+    if (EnableValhalla && !requires_null_check) {\n+      \/\/ Check if we are casting to QMyValue\n+      Node* ctrl_val_mirror = generate_fair_guard(is_val_mirror(mirror), NULL);\n+      if (ctrl_val_mirror != NULL) {\n+        RegionNode* r = new RegionNode(3);\n+        record_for_igvn(r);\n+        r->init_req(1, control());\n+\n+        \/\/ Casting to QMyValue, check for null\n+        set_control(ctrl_val_mirror);\n+        { \/\/ PreserveJVMState because null check replaces obj in map\n+          PreserveJVMState pjvms(this);\n+          Node* null_ctr = top();\n+          null_check_oop(obj, &null_ctr);\n+          region->init_req(_npe_path, null_ctr);\n+          r->init_req(2, control());\n+        }\n+        set_control(_gvn.transform(r));\n+      }\n+    }\n+\n@@ -3708,1 +3960,2 @@\n-      region->in(_bad_type_path) != top()) {\n+      region->in(_bad_type_path) != top() ||\n+      region->in(_npe_path) != top()) {\n@@ -3745,0 +3998,1 @@\n+  RegionNode* prim_region = new RegionNode(2);\n@@ -3747,0 +4001,1 @@\n+  record_for_igvn(prim_region);\n@@ -3771,2 +4026,5 @@\n-    int prim_path = (which_arg == 0 ? _prim_0_path : _prim_1_path);\n-    region->init_req(prim_path, null_ctl);\n+    if (which_arg == 0) {\n+      prim_region->init_req(1, null_ctl);\n+    } else {\n+      region->init_req(_prim_1_path, null_ctl);\n+    }\n@@ -3782,0 +4040,3 @@\n+    \/\/ If superc is an inline mirror, we also need to check if superc == subc because LMyValue\n+    \/\/ is not a subtype of QMyValue but due to subk == superk the subtype check will pass.\n+    generate_fair_guard(is_val_mirror(args[0]), prim_region);\n@@ -3789,1 +4050,2 @@\n-  set_control(region->in(_prim_0_path)); \/\/ go back to first null check\n+  \/\/ This path is also used if superc is a value mirror.\n+  set_control(_gvn.transform(prim_region));\n@@ -3794,1 +4056,1 @@\n-    generate_guard(bol_eq, region, PROB_FAIR);\n+    generate_fair_guard(bol_eq, region);\n@@ -3825,2 +4087,1 @@\n-Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region,\n-                                                  bool obj_array, bool not_array) {\n+Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region, ArrayKind kind) {\n@@ -3832,9 +4093,0 @@\n-  \/\/ If obj_array\/non_array==false\/false:\n-  \/\/ Branch around if the given klass is in fact an array (either obj or prim).\n-  \/\/ If obj_array\/non_array==false\/true:\n-  \/\/ Branch around if the given klass is not an array klass of any kind.\n-  \/\/ If obj_array\/non_array==true\/true:\n-  \/\/ Branch around if the kls is not an oop array (kls is int[], String, etc.)\n-  \/\/ If obj_array\/non_array==true\/false:\n-  \/\/ Branch around if the kls is an oop array (Object[] or subtype)\n-  \/\/\n@@ -3845,4 +4097,11 @@\n-    bool query = (obj_array\n-                  ? Klass::layout_helper_is_objArray(layout_con)\n-                  : Klass::layout_helper_is_array(layout_con));\n-    if (query == not_array) {\n+    bool query = 0;\n+    switch(kind) {\n+      case ObjectArray:    query = Klass::layout_helper_is_objArray(layout_con); break;\n+      case NonObjectArray: query = !Klass::layout_helper_is_objArray(layout_con); break;\n+      case TypeArray:      query = Klass::layout_helper_is_typeArray(layout_con); break;\n+      case AnyArray:       query = Klass::layout_helper_is_array(layout_con); break;\n+      case NonArray:       query = !Klass::layout_helper_is_array(layout_con); break;\n+      default:\n+        ShouldNotReachHere();\n+    }\n+    if (!query) {\n@@ -3858,0 +4117,21 @@\n+  unsigned int value = 0;\n+  BoolTest::mask btest = BoolTest::illegal;\n+  switch(kind) {\n+    case ObjectArray:\n+    case NonObjectArray: {\n+      value = Klass::_lh_array_tag_obj_value;\n+      layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+      btest = (kind == ObjectArray) ? BoolTest::eq : BoolTest::ne;\n+      break;\n+    }\n+    case TypeArray: {\n+      value = Klass::_lh_array_tag_type_value;\n+      layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+      btest = BoolTest::eq;\n+      break;\n+    }\n+    case AnyArray:    value = Klass::_lh_neutral_value; btest = BoolTest::lt; break;\n+    case NonArray:    value = Klass::_lh_neutral_value; btest = BoolTest::gt; break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n@@ -3859,4 +4139,1 @@\n-  jint  nval = (obj_array\n-                ? (jint)(Klass::_lh_array_tag_type_value\n-                   <<    Klass::_lh_array_tag_shift)\n-                : Klass::_lh_neutral_value);\n+  jint nval = (jint)value;\n@@ -3864,3 +4141,0 @@\n-  BoolTest::mask btest = BoolTest::lt;  \/\/ correct for testing is_[obj]array\n-  \/\/ invert the test if we are looking for a non-array\n-  if (not_array)  btest = BoolTest(btest).negate();\n@@ -3873,1 +4147,1 @@\n-\/\/ private static native Object java.lang.reflect.newArray(Class<?> componentType, int length);\n+\/\/ private static native Object java.lang.reflect.Array.newArray(Class<?> componentType, int length);\n@@ -4018,1 +4292,13 @@\n-    Node* not_objArray = generate_non_objArray_guard(klass_node, bailout);\n+    \/\/ Inline type array may have object field that would require a\n+    \/\/ write barrier. Conservatively, go to slow path.\n+    \/\/ TODO 8251971: Optimize for the case when flat src\/dst are later found\n+    \/\/ to not contain oops (i.e., move this check to the macro expansion phase).\n+    BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+    const TypeAryPtr* orig_t = _gvn.type(original)->isa_aryptr();\n+    const TypeKlassPtr* tklass = _gvn.type(klass_node)->is_klassptr();\n+    bool exclude_flat = UseFlatArray && bs->array_copy_requires_gc_barriers(true, T_OBJECT, false, false, BarrierSetC2::Parsing) &&\n+                        \/\/ Can src array be flat and contain oops?\n+                        (orig_t == NULL || (!orig_t->is_not_flat() && (!orig_t->is_flat() || orig_t->elem()->inline_klass()->contains_oops()))) &&\n+                        \/\/ Can dest array be flat and contain oops?\n+                        tklass->can_be_inline_array() && (!tklass->is_flat() || tklass->is_aryklassptr()->elem()->is_instklassptr()->instance_klass()->as_inline_klass()->contains_oops());\n+    Node* not_objArray = exclude_flat ? generate_non_objArray_guard(klass_node, bailout) : generate_typeArray_guard(klass_node, bailout);\n@@ -4022,1 +4308,1 @@\n-      const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, 0\/*offset*\/);\n+      const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0));\n@@ -4043,0 +4329,32 @@\n+    \/\/ Handle inline type arrays\n+    bool can_validate = !too_many_traps(Deoptimization::Reason_class_check);\n+    if (!stopped()) {\n+      orig_t = _gvn.type(original)->isa_aryptr();\n+      if (orig_t != NULL && orig_t->is_flat()) {\n+        \/\/ Src is flat, check that dest is flat as well\n+        if (exclude_flat) {\n+          \/\/ Dest can't be flat, bail out\n+          bailout->add_req(control());\n+          set_control(top());\n+        } else {\n+          generate_fair_guard(flat_array_test(klass_node, \/* flat = *\/ false), bailout);\n+        }\n+      } else if (UseFlatArray && (orig_t == NULL || !orig_t->is_not_flat()) &&\n+                 \/\/ If dest is flat, src must be flat as well (guaranteed by src <: dest check if validated).\n+                 ((!tklass->is_flat() && tklass->can_be_inline_array()) || !can_validate)) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat.\n+        generate_fair_guard(flat_array_test(load_object_klass(original)), bailout);\n+        if (orig_t != NULL) {\n+          orig_t = orig_t->cast_to_not_flat();\n+          original = _gvn.transform(new CheckCastPPNode(control(), original, orig_t));\n+        }\n+      }\n+      if (!can_validate) {\n+        \/\/ No validation. The subtype check emitted at macro expansion time will not go to the slow\n+        \/\/ path but call checkcast_arraycopy which can not handle flat\/null-free inline type arrays.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat\/null-free.\n+        generate_fair_guard(null_free_array_test(klass_node), bailout);\n+      }\n+    }\n+\n@@ -4085,1 +4403,1 @@\n-      if (!too_many_traps(Deoptimization::Reason_class_check)) {\n+      if (can_validate) {\n@@ -4224,1 +4542,6 @@\n-  Node* obj = NULL;\n+  Node* obj = argument(0);\n+\n+  if (obj->is_InlineType() || gvn().type(obj)->is_inlinetypeptr()) {\n+    return false;\n+  }\n+\n@@ -4234,1 +4557,0 @@\n-    obj = argument(0);\n@@ -4274,1 +4596,2 @@\n-  Node *lock_mask      = _gvn.MakeConX(markWord::lock_mask_in_place);\n+  \/\/ This also serves as guard against inline types\n+  Node *lock_mask      = _gvn.MakeConX(markWord::inline_type_mask_in_place);\n@@ -4340,1 +4663,10 @@\n-  Node* obj = null_check_receiver();\n+  Node* obj = argument(0);\n+  if (obj->is_InlineTypeBase()) {\n+    const Type* t = _gvn.type(obj);\n+    if (t->maybe_null()) {\n+      null_check(obj);\n+    }\n+    set_result(makecon(TypeInstPtr::make(t->inline_klass()->java_mirror())));\n+    return true;\n+  }\n+  obj = null_check_receiver();\n@@ -4697,1 +5029,6 @@\n-    Node* obj = null_check_receiver();\n+    Node* obj = argument(0);\n+    if (obj->is_InlineType()) {\n+      return false;\n+    }\n+\n+    obj = null_check_receiver();\n@@ -4707,1 +5044,2 @@\n-        obj_type->speculative_type()->is_instance_klass()) {\n+        obj_type->speculative_type()->is_instance_klass() &&\n+        !obj_type->speculative_type()->is_inlinetype()) {\n@@ -4737,0 +5075,5 @@\n+    \/\/ We only go to the fast case code if we pass a number of guards.\n+    \/\/ The paths which do not pass are accumulated in the slow_region.\n+    RegionNode* slow_region = new RegionNode(1);\n+    record_for_igvn(slow_region);\n+\n@@ -4742,3 +5085,0 @@\n-      Node* obj_length = load_array_length(obj);\n-      Node* obj_size  = NULL;\n-      Node* alloc_obj = new_array(obj_klass, obj_length, 0, &obj_size, \/*deoptimize_on_exception=*\/true);\n@@ -4747,20 +5087,7 @@\n-      if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Parsing)) {\n-        \/\/ If it is an oop array, it requires very special treatment,\n-        \/\/ because gc barriers are required when accessing the array.\n-        Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);\n-        if (is_obja != NULL) {\n-          PreserveJVMState pjvms2(this);\n-          set_control(is_obja);\n-          \/\/ Generate a direct call to the right arraycopy function(s).\n-          \/\/ Clones are always tightly coupled.\n-          ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n-          ac->set_clone_oop_array();\n-          Node* n = _gvn.transform(ac);\n-          assert(n == ac, \"cannot disappear\");\n-          ac->connect_outputs(this, \/*deoptimize_on_exception=*\/true);\n-\n-          result_reg->init_req(_objArray_path, control());\n-          result_val->init_req(_objArray_path, alloc_obj);\n-          result_i_o ->set_req(_objArray_path, i_o());\n-          result_mem ->set_req(_objArray_path, reset_memory());\n-        }\n+      const TypeAryPtr* ary_ptr = obj_type->isa_aryptr();\n+      if (UseFlatArray && bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Expansion) &&\n+          obj_type->can_be_inline_array() &&\n+          (ary_ptr == NULL || (!ary_ptr->is_not_flat() && (!ary_ptr->is_flat() || ary_ptr->elem()->inline_klass()->contains_oops())))) {\n+        \/\/ Flattened inline type array may have object field that would require a\n+        \/\/ write barrier. Conservatively, go to slow path.\n+        generate_fair_guard(flat_array_test(obj_klass), slow_region);\n@@ -4768,7 +5095,0 @@\n-      \/\/ Otherwise, there are no barriers to worry about.\n-      \/\/ (We can dispense with card marks if we know the allocation\n-      \/\/  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks\n-      \/\/  causes the non-eden paths to take compensating steps to\n-      \/\/  simulate a fresh allocation, so that no further\n-      \/\/  card marks are required in compiled code to initialize\n-      \/\/  the object.)\n@@ -4777,7 +5097,43 @@\n-        copy_to_clone(obj, alloc_obj, obj_size, true);\n-\n-        \/\/ Present the results of the copy.\n-        result_reg->init_req(_array_path, control());\n-        result_val->init_req(_array_path, alloc_obj);\n-        result_i_o ->set_req(_array_path, i_o());\n-        result_mem ->set_req(_array_path, reset_memory());\n+        Node* obj_length = load_array_length(obj);\n+        Node* obj_size  = NULL;\n+        Node* alloc_obj = new_array(obj_klass, obj_length, 0, &obj_size, \/*deoptimize_on_exception=*\/true);\n+\n+        BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+        if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, false, BarrierSetC2::Parsing)) {\n+          \/\/ If it is an oop array, it requires very special treatment,\n+          \/\/ because gc barriers are required when accessing the array.\n+          Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);\n+          if (is_obja != NULL) {\n+            PreserveJVMState pjvms2(this);\n+            set_control(is_obja);\n+            \/\/ Generate a direct call to the right arraycopy function(s).\n+            \/\/ Clones are always tightly coupled.\n+            ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n+            ac->set_clone_oop_array();\n+            Node* n = _gvn.transform(ac);\n+            assert(n == ac, \"cannot disappear\");\n+            ac->connect_outputs(this, \/*deoptimize_on_exception=*\/true);\n+\n+            result_reg->init_req(_objArray_path, control());\n+            result_val->init_req(_objArray_path, alloc_obj);\n+            result_i_o ->set_req(_objArray_path, i_o());\n+            result_mem ->set_req(_objArray_path, reset_memory());\n+          }\n+        }\n+        \/\/ Otherwise, there are no barriers to worry about.\n+        \/\/ (We can dispense with card marks if we know the allocation\n+        \/\/  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks\n+        \/\/  causes the non-eden paths to take compensating steps to\n+        \/\/  simulate a fresh allocation, so that no further\n+        \/\/  card marks are required in compiled code to initialize\n+        \/\/  the object.)\n+\n+        if (!stopped()) {\n+          copy_to_clone(obj, alloc_obj, obj_size, true);\n+\n+          \/\/ Present the results of the copy.\n+          result_reg->init_req(_array_path, control());\n+          result_val->init_req(_array_path, alloc_obj);\n+          result_i_o ->set_req(_array_path, i_o());\n+          result_mem ->set_req(_array_path, reset_memory());\n+        }\n@@ -4787,4 +5143,0 @@\n-    \/\/ We only go to the instance fast case code if we pass a number of guards.\n-    \/\/ The paths which do not pass are accumulated in the slow_region.\n-    RegionNode* slow_region = new RegionNode(1);\n-    record_for_igvn(slow_region);\n@@ -4951,2 +5303,1 @@\n-    CallProjections callprojs;\n-    alloc->extract_projections(&callprojs, true);\n+    CallProjections* callprojs = alloc->extract_projections(true);\n@@ -4955,1 +5306,1 @@\n-    C->gvn_replace_by(callprojs.fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n+    C->gvn_replace_by(callprojs->fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n@@ -4997,1 +5348,1 @@\n-    set_i_o(callprojs.fallthrough_ioproj);\n+    set_i_o(callprojs->fallthrough_ioproj);\n@@ -5173,0 +5524,2 @@\n+          src_type = _gvn.type(src);\n+          top_src = src_type->isa_aryptr();\n@@ -5176,0 +5529,2 @@\n+          dest_type = _gvn.type(dest);\n+          top_dest = dest_type->isa_aryptr();\n@@ -5191,2 +5546,1 @@\n-      can_emit_guards &&\n-      !src->is_top() && !dest->is_top()) {\n+      can_emit_guards && !src->is_top() && !dest->is_top()) {\n@@ -5235,0 +5589,2 @@\n+      slow_region->add_req(not_subtype_ctrl);\n+    }\n@@ -5236,6 +5592,31 @@\n-      if (not_subtype_ctrl != top()) {\n-        PreserveJVMState pjvms(this);\n-        set_control(not_subtype_ctrl);\n-        uncommon_trap(Deoptimization::Reason_intrinsic,\n-                      Deoptimization::Action_make_not_entrant);\n-        assert(stopped(), \"Should be stopped\");\n+    const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)->is_klassptr();\n+    const Type* toop = dest_klass_t->cast_to_exactness(false)->as_instance_type();\n+    if (toop->isa_aryptr() != NULL) {\n+      toop = toop->is_aryptr()->cast_to_not_flat(false)->cast_to_not_null_free(false);\n+    }\n+    src = _gvn.transform(new CheckCastPPNode(control(), src, toop));\n+    src_type = _gvn.type(src);\n+    top_src  = src_type->isa_aryptr();\n+\n+    \/\/ Handle flat inline type arrays (null-free arrays are handled by the subtype check above)\n+    if (!stopped() && UseFlatArray) {\n+      \/\/ If dest is flat, src must be flat as well (guaranteed by src <: dest check). Handle flat src here.\n+      assert(top_dest == NULL || !top_dest->is_flat() || top_src->is_flat(), \"src array must be flat\");\n+      if (top_src != NULL && top_src->is_flat()) {\n+        \/\/ Src is flat, check that dest is flat as well\n+        if (top_dest != NULL && !top_dest->is_flat()) {\n+          generate_fair_guard(flat_array_test(dest_klass, \/* flat = *\/ false), slow_region);\n+          \/\/ Since dest is flat and src <: dest, dest must have the same type as src.\n+          top_dest = top_src->cast_to_exactness(false);\n+          assert(top_dest->is_flat(), \"dest must be flat\");\n+          dest = _gvn.transform(new CheckCastPPNode(control(), dest, top_dest));\n+        }\n+      } else if (top_src == NULL || !top_src->is_not_flat()) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat.\n+        assert(top_dest == NULL || !top_dest->is_flat(), \"dest array must not be flat\");\n+        generate_fair_guard(flat_array_test(src), slow_region);\n+        if (top_src != NULL) {\n+          top_src = top_src->cast_to_not_flat();\n+          src = _gvn.transform(new CheckCastPPNode(control(), src, top_src));\n+        }\n@@ -5244,0 +5625,1 @@\n+\n@@ -5251,4 +5633,0 @@\n-\n-    const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)->is_klassptr();\n-    const Type *toop = dest_klass_t->cast_to_exactness(false)->as_instance_type();\n-    src = _gvn.transform(new CheckCastPPNode(control(), src, toop));\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":503,"deletions":125,"binary":false,"changes":628,"status":"modified"},{"patch":"@@ -274,0 +274,2 @@\n+  RegMask* return_values_mask(const TypeFunc* tf);\n+\n@@ -398,1 +400,1 @@\n-  RegMask                     _return_value_mask;\n+  RegMask*            _return_values_mask;\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -575,0 +575,3 @@\n+  if (n->is_InlineTypeBase()) {\n+    C->add_inline_type(n);\n+  }\n@@ -657,0 +660,3 @@\n+  if (is_InlineTypeBase()) {\n+    compile->remove_inline_type(this);\n+  }\n@@ -2706,1 +2712,3 @@\n-      assert(i >= req() || i == 0 || is_Region() || is_Phi() || is_ArrayCopy() || (is_Unlock() && i == req()-1)\n+      assert(i >= req() || i == 0 || is_Region() || is_Phi() || is_ArrayCopy() ||\n+             (is_Allocate() && i >= AllocateNode::InlineTypeNode) ||\n+             (is_Unlock() && i == req()-1)\n@@ -2708,1 +2716,1 @@\n-              \"only region, phi, arraycopy, unlock or membar nodes have null data edges\");\n+             \"only region, phi, arraycopy, allocate or unlock nodes have null data edges\");\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -84,0 +84,1 @@\n+class FlatArrayCheckNode;\n@@ -116,0 +117,1 @@\n+class MachPrologNode;\n@@ -122,0 +124,1 @@\n+class MachVEPNode;\n@@ -166,0 +169,3 @@\n+class InlineTypeBaseNode;\n+class InlineTypeNode;\n+class InlineTypePtrNode;\n@@ -666,0 +672,1 @@\n+        DEFINE_CLASS_ID(Blackhole,        MemBar, 2)\n@@ -687,0 +694,2 @@\n+      DEFINE_CLASS_ID(MachProlog,       Mach, 8)\n+      DEFINE_CLASS_ID(MachVEP,          Mach, 9)\n@@ -713,0 +722,3 @@\n+      DEFINE_CLASS_ID(InlineTypeBase, Type, 8)\n+        DEFINE_CLASS_ID(InlineType, InlineTypeBase, 0)\n+        DEFINE_CLASS_ID(InlineTypePtr, InlineTypeBase, 1)\n@@ -749,3 +761,4 @@\n-        DEFINE_CLASS_ID(FastLock,   Cmp, 0)\n-        DEFINE_CLASS_ID(FastUnlock, Cmp, 1)\n-        DEFINE_CLASS_ID(SubTypeCheck,Cmp, 2)\n+        DEFINE_CLASS_ID(FastLock,       Cmp, 0)\n+        DEFINE_CLASS_ID(FastUnlock,     Cmp, 1)\n+        DEFINE_CLASS_ID(SubTypeCheck,   Cmp, 2)\n+        DEFINE_CLASS_ID(FlatArrayCheck, Cmp, 3)\n@@ -850,0 +863,1 @@\n+  DEFINE_CLASS_QUERY(Blackhole)\n@@ -878,0 +892,1 @@\n+  DEFINE_CLASS_QUERY(FlatArrayCheck)\n@@ -910,0 +925,1 @@\n+  DEFINE_CLASS_QUERY(MachProlog)\n@@ -916,0 +932,1 @@\n+  DEFINE_CLASS_QUERY(MachVEP)\n@@ -940,0 +957,3 @@\n+  DEFINE_CLASS_QUERY(InlineType)\n+  DEFINE_CLASS_QUERY(InlineTypeBase)\n+  DEFINE_CLASS_QUERY(InlineTypePtr)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":23,"deletions":3,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -422,1 +422,1 @@\n-  Node *fetch_interpreter_state(int index, BasicType bt, Node *local_addrs, Node *local_addrs_base);\n+  Node* fetch_interpreter_state(int index, const Type* type, Node* local_addrs, Node* local_addrs_base);\n@@ -468,1 +468,1 @@\n-  void array_store_check();\n+  Node* array_store_check(Node*& adr, const Type*& elemtype);\n@@ -475,0 +475,1 @@\n+  Node* record_profile_for_speculation_at_array_load(Node* ld);\n@@ -523,1 +524,1 @@\n-  void do_get_xxx(Node* obj, ciField* field, bool is_field);\n+  void do_get_xxx(Node* obj, ciField* field);\n@@ -528,0 +529,2 @@\n+  void do_aconst_init();\n+  void do_withfield();\n@@ -529,1 +532,1 @@\n-  void do_anewarray();\n+  void do_newarray();\n@@ -544,1 +547,6 @@\n-  void    do_if(BoolTest::mask btest, Node* c);\n+  void    do_if(BoolTest::mask btest, Node* c, bool new_path = false, Node** ctrl_taken = NULL);\n+  void    do_acmp(BoolTest::mask btest, Node* left, Node* right);\n+  void    acmp_always_null_input(Node* input, const TypeOopPtr* tinput, BoolTest::mask btest, Node* eq_region);\n+  void    acmp_known_non_inline_type_input(Node* input, const TypeOopPtr* tinput, ProfilePtrKind input_ptr, ciKlass* input_type, BoolTest::mask btest, Node* eq_region);\n+  Node*   acmp_null_check(Node* input, const TypeOopPtr* tinput, ProfilePtrKind input_ptr, Node*& null_ctl);\n+  void    acmp_unknown_non_inline_type_input(Node* input, const TypeOopPtr* tinput, ProfilePtrKind input_ptr, BoolTest::mask btest, Node* eq_region);\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":13,"deletions":5,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -49,0 +49,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n@@ -112,0 +114,1 @@\n+address OptoRuntime::_load_unknown_inline                         = NULL;\n@@ -155,1 +158,0 @@\n-\n@@ -158,0 +160,1 @@\n+  gen(env, _load_unknown_inline            , load_unknown_inline_type     , load_unknown_inline             ,    0 , true,  false);\n@@ -203,1 +206,1 @@\n-JRT_BLOCK_ENTRY(void, OptoRuntime::new_instance_C(Klass* klass, JavaThread* current))\n+JRT_BLOCK_ENTRY(void, OptoRuntime::new_instance_C(Klass* klass, bool is_larval, JavaThread* current))\n@@ -223,1 +226,5 @@\n-    oop result = InstanceKlass::cast(klass)->allocate_instance(THREAD);\n+    instanceOop result = InstanceKlass::cast(klass)->allocate_instance(THREAD);\n+    if (is_larval) {\n+      \/\/ Check if this is a larval buffer allocation\n+      result->set_mark(result->mark().enter_larval_state());\n+    }\n@@ -251,1 +258,4 @@\n-  if (array_type->is_typeArray_klass()) {\n+  if (array_type->is_flatArray_klass()) {\n+    Klass* elem_type = FlatArrayKlass::cast(array_type)->element_klass();\n+    result = oopFactory::new_valueArray(elem_type, len, THREAD);\n+  } else if (array_type->is_typeArray_klass()) {\n@@ -257,5 +267,1 @@\n-    \/\/ Although the oopFactory likes to work with the elem_type,\n-    \/\/ the compiler prefers the array_type, since it must already have\n-    \/\/ that latter value in hand for the fast path.\n-    Klass* elem_type = ObjArrayKlass::cast(array_type)->element_klass();\n-    result = oopFactory::new_objArray(elem_type, len, THREAD);\n+    result = ObjArrayKlass::cast(array_type)->allocate(len, THREAD);\n@@ -456,1 +462,1 @@\n-  const Type **fields = TypeTuple::fields(1);\n+  const Type **fields = TypeTuple::fields(2);\n@@ -458,1 +464,2 @@\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+1, fields);\n+  fields[TypeFunc::Parms+1] = TypeInt::BOOL;        \/\/ is_larval\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n@@ -576,1 +583,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1588,1 +1595,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1621,1 +1628,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1637,1 +1644,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1761,0 +1768,104 @@\n+\n+const TypeFunc *OptoRuntime::store_inline_type_fields_Type() {\n+  \/\/ create input type (domain)\n+  uint total = SharedRuntime::java_return_convention_max_int + SharedRuntime::java_return_convention_max_float*2;\n+  const Type **fields = TypeTuple::fields(total);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypePtr::BOTTOM;\n+  uint i = 1;\n+  for (; i < SharedRuntime::java_return_convention_max_int; i++) {\n+    fields[TypeFunc::Parms+i] = TypeInt::INT;\n+  }\n+  for (; i < total; i+=2) {\n+    fields[TypeFunc::Parms+i] = Type::DOUBLE;\n+    fields[TypeFunc::Parms+i+1] = Type::HALF;\n+  }\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + total, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1,fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+const TypeFunc *OptoRuntime::pack_inline_type_Type() {\n+  \/\/ create input type (domain)\n+  uint total = 1 + SharedRuntime::java_return_convention_max_int + SharedRuntime::java_return_convention_max_float*2;\n+  const Type **fields = TypeTuple::fields(total);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypeRawPtr::BOTTOM;\n+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;\n+  uint i = 2;\n+  for (; i < SharedRuntime::java_return_convention_max_int+1; i++) {\n+    fields[TypeFunc::Parms+i] = TypeInt::INT;\n+  }\n+  for (; i < total; i+=2) {\n+    fields[TypeFunc::Parms+i] = Type::DOUBLE;\n+    fields[TypeFunc::Parms+i+1] = Type::HALF;\n+  }\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + total, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1,fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+JRT_BLOCK_ENTRY(void, OptoRuntime::load_unknown_inline(flatArrayOopDesc* array, int index, JavaThread* current))\n+  JRT_BLOCK;\n+  flatArrayHandle vah(current, array);\n+  oop buffer = flatArrayOopDesc::value_alloc_copy_from_index(vah, index, THREAD);\n+  deoptimize_caller_frame(current, HAS_PENDING_EXCEPTION);\n+  current->set_vm_result(buffer);\n+  JRT_BLOCK_END;\n+JRT_END\n+\n+const TypeFunc* OptoRuntime::load_unknown_inline_type() {\n+  \/\/ create input type (domain)\n+  const Type** fields = TypeTuple::fields(2);\n+  fields[TypeFunc::Parms] = TypeOopPtr::NOTNULL;\n+  fields[TypeFunc::Parms+1] = TypeInt::POS;\n+\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms+1, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+JRT_LEAF(void, OptoRuntime::store_unknown_inline(instanceOopDesc* buffer, flatArrayOopDesc* array, int index))\n+{\n+  assert(buffer != NULL, \"can't store null into flat array\");\n+  array->value_copy_to_index(buffer, index);\n+}\n+JRT_END\n+\n+const TypeFunc* OptoRuntime::store_unknown_inline_type() {\n+  \/\/ create input type (domain)\n+  const Type** fields = TypeTuple::fields(3);\n+  fields[TypeFunc::Parms] = TypeInstPtr::NOTNULL;\n+  fields[TypeFunc::Parms+1] = TypeOopPtr::NOTNULL;\n+  fields[TypeFunc::Parms+2] = TypeInt::POS;\n+\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(0);\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":126,"deletions":15,"binary":false,"changes":141,"status":"modified"},{"patch":"@@ -138,0 +138,1 @@\n+  static address _load_unknown_inline;\n@@ -144,1 +145,1 @@\n-  static void new_instance_C(Klass* instance_klass, JavaThread* current);\n+  static void new_instance_C(Klass* instance_klass, bool is_larval, JavaThread* current);\n@@ -211,0 +212,1 @@\n+  static address load_unknown_inline_Java()              { return _load_unknown_inline; }\n@@ -300,0 +302,8 @@\n+  static const TypeFunc* store_inline_type_fields_Type();\n+  static const TypeFunc* pack_inline_type_Type();\n+\n+  static void load_unknown_inline(flatArrayOopDesc* array, int index, JavaThread* current);\n+  static const TypeFunc* load_unknown_inline_type();\n+  static void store_unknown_inline(instanceOopDesc* buffer, flatArrayOopDesc* array, int index);\n+  static const TypeFunc* store_unknown_inline_type();\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -839,1 +840,8 @@\n-Node *CmpLNode::Ideal( PhaseGVN *phase, bool can_reshape ) {\n+\/\/------------------------------Ideal------------------------------------------\n+Node* CmpLNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* a = NULL;\n+  Node* b = NULL;\n+  if (is_double_null_check(phase, a, b) && (phase->type(a)->is_zero_type() || phase->type(b)->is_zero_type())) {\n+    \/\/ Degraded to a simple null check, use old acmp\n+    return new CmpPNode(a, b);\n+  }\n@@ -850,0 +858,25 @@\n+\/\/ Match double null check emitted by Compile::optimize_acmp()\n+bool CmpLNode::is_double_null_check(PhaseGVN* phase, Node*& a, Node*& b) const {\n+  if (in(1)->Opcode() == Op_OrL &&\n+      in(1)->in(1)->Opcode() == Op_CastP2X &&\n+      in(1)->in(2)->Opcode() == Op_CastP2X &&\n+      in(2)->bottom_type()->is_zero_type()) {\n+    assert(EnableValhalla, \"unexpected double null check\");\n+    a = in(1)->in(1)->in(1);\n+    b = in(1)->in(2)->in(1);\n+    return true;\n+  }\n+  return false;\n+}\n+\n+\/\/------------------------------Value------------------------------------------\n+const Type* CmpLNode::Value(PhaseGVN* phase) const {\n+  Node* a = NULL;\n+  Node* b = NULL;\n+  if (is_double_null_check(phase, a, b) && (!phase->type(a)->maybe_null() || !phase->type(b)->maybe_null())) {\n+    \/\/ One operand is never NULL, emit constant false\n+    return TypeInt::CC_GT;\n+  }\n+  return SubNode::Value(phase);\n+}\n+\n@@ -975,1 +1008,16 @@\n-\n+    if (!unrelated_classes) {\n+      \/\/ Handle inline type arrays\n+      if ((r0->flatten_array() && r1->not_flatten_array()) ||\n+          (r1->flatten_array() && r0->not_flatten_array())) {\n+        \/\/ One type is flattened in arrays but the other type is not. Must be unrelated.\n+        unrelated_classes = true;\n+      } else if ((r0->is_not_flat() && r1->is_flat()) ||\n+                 (r1->is_not_flat() && r0->is_flat())) {\n+        \/\/ One type is a non-flattened array and the other type is a flattened array. Must be unrelated.\n+        unrelated_classes = true;\n+      } else if ((r0->is_not_null_free() && r1->is_null_free()) ||\n+                 (r1->is_not_null_free() && r0->is_null_free())) {\n+        \/\/ One type is a nullable array and the other type is a null-free array. Must be unrelated.\n+        unrelated_classes = true;\n+      }\n+    }\n@@ -1060,1 +1108,8 @@\n-Node *CmpPNode::Ideal( PhaseGVN *phase, bool can_reshape ) {\n+Node* CmpPNode::Ideal(PhaseGVN *phase, bool can_reshape) {\n+  \/\/ TODO 8284443 in(1) could be cast?\n+  if (in(1)->is_InlineTypePtr() && phase->type(in(2))->is_zero_type()) {\n+    \/\/ Null checking a scalarized but nullable inline type. Check the IsInit\n+    \/\/ input instead of the oop input to avoid keeping buffer allocations alive.\n+    return new CmpINode(in(1)->as_InlineTypePtr()->get_is_init(), phase->intcon(0));\n+  }\n+\n@@ -1132,0 +1187,8 @@\n+  \/\/ Do not fold the subtype check to an array klass pointer comparison for [V? arrays.\n+  \/\/ [QMyValue is a subtype of [LMyValue but the klass for [QMyValue is not equal to\n+  \/\/ the klass for [LMyValue. Do not bypass the klass load from the primary supertype array.\n+  if (superklass->is_obj_array_klass() && !superklass->as_array_klass()->is_elem_null_free() &&\n+      superklass->as_array_klass()->element_klass()->is_inlinetype()) {\n+    return NULL;\n+  }\n+\n@@ -1275,0 +1338,37 @@\n+\/\/=============================================================================\n+\/\/------------------------------Value------------------------------------------\n+const Type* FlatArrayCheckNode::Value(PhaseGVN* phase) const {\n+  bool all_not_flat = true;\n+  for (uint i = ArrayOrKlass; i < req(); ++i) {\n+    const Type* t = phase->type(in(i));\n+    if (t == Type::TOP) {\n+      return Type::TOP;\n+    }\n+    if (t->is_ptr()->is_flat()) {\n+      \/\/ One of the input arrays is flat, check always passes\n+      return TypeInt::CC_EQ;\n+    } else if (!t->is_ptr()->is_not_flat()) {\n+      \/\/ One of the input arrays might be flat\n+      all_not_flat = false;\n+    }\n+  }\n+  if (all_not_flat) {\n+    \/\/ None of the input arrays can be flat, check always fails\n+    return TypeInt::CC_GT;\n+  }\n+  return TypeInt::CC;\n+}\n+\n+\/\/------------------------------Ideal------------------------------------------\n+Node* FlatArrayCheckNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  bool changed = false;\n+  \/\/ Remove inputs that are known to be non-flat\n+  for (uint i = ArrayOrKlass; i < req(); ++i) {\n+    const Type* t = phase->type(in(i));\n+    if (t->isa_ptr() && t->is_ptr()->is_not_flat()) {\n+      del_req(i--);\n+      changed = true;\n+    }\n+  }\n+  return changed ? this : NULL;\n+}\n","filename":"src\/hotspot\/share\/opto\/subnode.cpp","additions":103,"deletions":3,"binary":false,"changes":106,"status":"modified"},{"patch":"@@ -207,1 +207,2 @@\n-  virtual Node *Ideal(PhaseGVN *phase, bool can_reshape);\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  virtual const Type* Value(PhaseGVN* phase) const;\n@@ -209,0 +210,1 @@\n+  bool is_double_null_check(PhaseGVN* phase, Node*& a, Node*& b) const;\n@@ -299,0 +301,20 @@\n+\/\/--------------------------FlatArrayCheckNode---------------------------------\n+\/\/ Returns true if one of the input array objects or array klass ptrs (there\n+\/\/ can be multiple) is flat.\n+class FlatArrayCheckNode : public CmpNode {\n+public:\n+  enum {\n+    Control,\n+    Memory,\n+    ArrayOrKlass\n+  };\n+  FlatArrayCheckNode(Compile* C, Node* mem, Node* array_or_klass) : CmpNode(mem, array_or_klass) {\n+    init_class_id(Class_FlatArrayCheck);\n+    init_flags(Flag_is_macro);\n+    C->add_macro_node(this);\n+  }\n+  virtual int Opcode() const;\n+  virtual const Type* sub(const Type*, const Type*) const { ShouldNotReachHere(); return NULL; }\n+  const Type* Value(PhaseGVN* phase) const;\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+};\n","filename":"src\/hotspot\/share\/opto\/subnode.hpp","additions":23,"deletions":1,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -26,0 +26,3 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciField.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -51,0 +54,46 @@\n+const Type::Offset Type::Offset::top(Type::OffsetTop);\n+const Type::Offset Type::Offset::bottom(Type::OffsetBot);\n+\n+const Type::Offset Type::Offset::meet(const Type::Offset other) const {\n+  \/\/ Either is 'TOP' offset?  Return the other offset!\n+  int offset = other._offset;\n+  if (_offset == OffsetTop) return Offset(offset);\n+  if (offset == OffsetTop) return Offset(_offset);\n+  \/\/ If either is different, return 'BOTTOM' offset\n+  if (_offset != offset) return bottom;\n+  return Offset(_offset);\n+}\n+\n+const Type::Offset Type::Offset::dual() const {\n+  if (_offset == OffsetTop) return bottom;\/\/ Map 'TOP' into 'BOTTOM'\n+  if (_offset == OffsetBot) return top;\/\/ Map 'BOTTOM' into 'TOP'\n+  return Offset(_offset);               \/\/ Map everything else into self\n+}\n+\n+const Type::Offset Type::Offset::add(intptr_t offset) const {\n+  \/\/ Adding to 'TOP' offset?  Return 'TOP'!\n+  if (_offset == OffsetTop || offset == OffsetTop) return top;\n+  \/\/ Adding to 'BOTTOM' offset?  Return 'BOTTOM'!\n+  if (_offset == OffsetBot || offset == OffsetBot) return bottom;\n+  \/\/ Addition overflows or \"accidentally\" equals to OffsetTop? Return 'BOTTOM'!\n+  offset += (intptr_t)_offset;\n+  if (offset != (int)offset || offset == OffsetTop) return bottom;\n+\n+  \/\/ assert( _offset >= 0 && _offset+offset >= 0, \"\" );\n+  \/\/ It is possible to construct a negative offset during PhaseCCP\n+\n+  return Offset((int)offset);        \/\/ Sum valid offsets\n+}\n+\n+void Type::Offset::dump2(outputStream *st) const {\n+  if (_offset == 0) {\n+    return;\n+  } else if (_offset == OffsetTop) {\n+    st->print(\"+top\");\n+  }\n+  else if (_offset == OffsetBot) {\n+    st->print(\"+bot\");\n+  } else if (_offset) {\n+    st->print(\"+%d\", _offset);\n+  }\n+}\n@@ -90,0 +139,1 @@\n+  { Bad,             T_PRIMITIVE_OBJECT, \"inline:\",      false, Node::NotAMachineReg, relocInfo::none          },  \/\/ InlineType\n@@ -222,0 +272,10 @@\n+  case T_PRIMITIVE_OBJECT: {\n+    bool is_null_free = type->is_null_free();\n+    ciInlineKlass* vk = type->unwrap()->as_inline_klass();\n+    if (is_null_free) {\n+      return TypeInlineType::make(vk);\n+    } else {\n+      return TypeOopPtr::make_from_klass(vk)->join_speculative(is_null_free ? TypePtr::NOTNULL : TypePtr::BOTTOM);\n+    }\n+  }\n+\n@@ -250,0 +310,1 @@\n+    case T_PRIMITIVE_OBJECT:\n@@ -287,0 +348,1 @@\n+    case T_PRIMITIVE_OBJECT: conbt = T_OBJECT; break;\n@@ -293,0 +355,1 @@\n+    case T_PRIMITIVE_OBJECT: loadbt = T_OBJECT; break;\n@@ -528,3 +591,3 @@\n-  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, 0);\n-  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, OffsetBot);\n-  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, OffsetBot);\n+  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, Offset(0));\n+  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, Offset::bottom);\n+  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, Offset::bottom);\n@@ -547,1 +610,1 @@\n-                                           false, 0, oopDesc::mark_offset_in_bytes());\n+                                           false, 0, Offset(oopDesc::mark_offset_in_bytes()));\n@@ -549,2 +612,4 @@\n-                                           false, 0, oopDesc::klass_offset_in_bytes());\n-  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, OffsetBot, TypeOopPtr::InstanceBot);\n+                                           false, 0, Offset(oopDesc::klass_offset_in_bytes()));\n+  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, Offset::bottom, TypeOopPtr::InstanceBot);\n+\n+  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, NULL, Offset::bottom);\n@@ -552,1 +617,1 @@\n-  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, NULL, OffsetBot);\n+  TypeInlineType::BOTTOM = TypeInlineType::make(NULL);\n@@ -569,1 +634,1 @@\n-  TypeAryPtr::RANGE   = TypeAryPtr::make( TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), NULL \/* current->env()->Object_klass() *\/, false, arrayOopDesc::length_offset_in_bytes());\n+  TypeAryPtr::RANGE   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), NULL \/* current->env()->Object_klass() *\/, false, Offset(arrayOopDesc::length_offset_in_bytes()));\n@@ -571,1 +636,1 @@\n-  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Type::OffsetBot);\n+  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Offset::bottom);\n@@ -581,1 +646,1 @@\n-    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Type::OffsetBot);\n+    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Offset::bottom);\n@@ -583,7 +648,8 @@\n-  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Type::OffsetBot);\n-  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Type::OffsetBot);\n-  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Type::OffsetBot);\n-  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Type::OffsetBot);\n-  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Type::OffsetBot);\n-  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Type::OffsetBot);\n-  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Type::OffsetBot);\n+  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Offset::bottom);\n+  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Offset::bottom);\n+  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Offset::bottom);\n+  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Offset::bottom);\n+  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Offset::bottom);\n+  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Offset::bottom);\n+  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Offset::bottom);\n+  TypeAryPtr::INLINES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInlineType::BOTTOM,TypeInt::POS), NULL, false,  Offset::bottom);\n@@ -594,0 +660,1 @@\n+  TypeAryPtr::_array_body_type[T_PRIMITIVE_OBJECT] = TypeAryPtr::OOPS;\n@@ -604,2 +671,2 @@\n-  TypeInstKlassPtr::OBJECT = TypeInstKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), 0);\n-  TypeInstKlassPtr::OBJECT_OR_NULL = TypeInstKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), 0);\n+  TypeInstKlassPtr::OBJECT = TypeInstKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), Offset(0), false);\n+  TypeInstKlassPtr::OBJECT_OR_NULL = TypeInstKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), Offset(0), false);\n@@ -644,0 +711,1 @@\n+  _const_basic_type[T_PRIMITIVE_OBJECT] = TypeInstPtr::BOTTOM;\n@@ -660,0 +728,1 @@\n+  _zero_type[T_PRIMITIVE_OBJECT] = TypePtr::NULL_PTR;\n@@ -951,0 +1020,3 @@\n+  case InlineType:\n+    return t->xmeet(this);\n+\n@@ -1120,0 +1192,1 @@\n+    case Type::InlineType:\n@@ -1534,0 +1607,1 @@\n+  case InlineType:\n@@ -2021,0 +2095,12 @@\n+static void collect_inline_fields(ciInlineKlass* vk, const Type** field_array, uint& pos) {\n+  for (int j = 0; j < vk->nof_nonstatic_fields(); j++) {\n+    ciField* field = vk->nonstatic_field_at(j);\n+    BasicType bt = field->type()->basic_type();\n+    const Type* ft = Type::get_const_type(field->type());\n+    field_array[pos++] = ft;\n+    if (type2size[bt] == 2) {\n+      field_array[pos++] = Type::HALF;\n+    }\n+  }\n+}\n+\n@@ -2023,1 +2109,1 @@\n-const TypeTuple *TypeTuple::make_range(ciSignature* sig) {\n+const TypeTuple *TypeTuple::make_range(ciSignature* sig, bool ret_vt_fields) {\n@@ -2026,0 +2112,8 @@\n+  if (ret_vt_fields) {\n+    arg_cnt = return_type->as_inline_klass()->inline_arg_slots() + 1;\n+    if (!sig->returns_null_free_inline_type()) {\n+      \/\/ InlineTypeBaseNode::IsInit field used for null checking\n+      arg_cnt++;\n+    }\n+  }\n+\n@@ -2046,0 +2140,13 @@\n+  case T_PRIMITIVE_OBJECT:\n+    if (ret_vt_fields) {\n+      uint pos = TypeFunc::Parms;\n+      field_array[pos++] = get_const_type(return_type); \/\/ Oop might be null when returning as fields\n+      collect_inline_fields(return_type->as_inline_klass(), field_array, pos);\n+      if (!sig->returns_null_free_inline_type()) {\n+        \/\/ InlineTypeBaseNode::IsInit field used for null checking\n+        field_array[pos++] = get_const_basic_type(T_BOOLEAN);\n+      }\n+    } else {\n+      field_array[TypeFunc::Parms] = get_const_type(return_type)->join_speculative(sig->returns_null_free_inline_type() ? TypePtr::NOTNULL : TypePtr::BOTTOM);\n+    }\n+    break;\n@@ -2055,2 +2162,10 @@\n-const TypeTuple *TypeTuple::make_domain(ciInstanceKlass* recv, ciSignature* sig) {\n-  uint arg_cnt = sig->size();\n+const TypeTuple *TypeTuple::make_domain(ciMethod* method, bool vt_fields_as_args) {\n+  ciSignature* sig = method->signature();\n+  uint arg_cnt = sig->size() + (method->is_static() ? 0 : 1);\n+  if (vt_fields_as_args) {\n+    arg_cnt = 0;\n+    assert(method->get_sig_cc() != NULL, \"Should have scalarized signature\");\n+    for (ExtendedSignature sig_cc = ExtendedSignature(method->get_sig_cc(), SigEntryFilter()); !sig_cc.at_end(); ++sig_cc) {\n+      arg_cnt += type2size[(*sig_cc)._bt];\n+    }\n+  }\n@@ -2059,8 +2174,8 @@\n-  const Type **field_array;\n-  if (recv != NULL) {\n-    arg_cnt++;\n-    field_array = fields(arg_cnt);\n-    \/\/ Use get_const_type here because it respects UseUniqueSubclasses:\n-    field_array[pos++] = get_const_type(recv)->join_speculative(TypePtr::NOTNULL);\n-  } else {\n-    field_array = fields(arg_cnt);\n+  const Type** field_array = fields(arg_cnt);\n+  if (!method->is_static()) {\n+    ciInstanceKlass* recv = method->holder();\n+    if (vt_fields_as_args && recv->is_inlinetype() && recv->as_inline_klass()->can_be_passed_as_fields()) {\n+      collect_inline_fields(recv->as_inline_klass(), field_array, pos);\n+    } else {\n+      field_array[pos++] = get_const_type(recv)->join_speculative(TypePtr::NOTNULL);\n+    }\n@@ -2072,0 +2187,1 @@\n+    BasicType bt = type->basic_type();\n@@ -2073,1 +2189,1 @@\n-    switch (type->basic_type()) {\n+    switch (bt) {\n@@ -2094,0 +2210,12 @@\n+    case T_PRIMITIVE_OBJECT: {\n+      if (vt_fields_as_args && method->is_scalarized_arg(i + (method->is_static() ? 0 : 1))) {\n+        if (!sig->is_null_free_at(i)) {\n+          \/\/ InlineTypeBaseNode::IsInit field used for null checking\n+          field_array[pos++] = get_const_basic_type(T_BOOLEAN);\n+        }\n+        collect_inline_fields(type->as_inline_klass(), field_array, pos);\n+      } else {\n+        field_array[pos++] = get_const_type(type)->join_speculative(sig->is_null_free_at(i) ? TypePtr::NOTNULL : TypePtr::BOTTOM);\n+      }\n+      break;\n+    }\n@@ -2099,0 +2227,1 @@\n+  assert(pos == TypeFunc::Parms + arg_cnt, \"wrong number of arguments\");\n@@ -2233,1 +2362,2 @@\n-const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable) {\n+const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable,\n+                             bool not_flat, bool not_null_free) {\n@@ -2238,1 +2368,1 @@\n-  return (TypeAry*)(new TypeAry(elem,size,stable))->hashcons();\n+  return (TypeAry*)(new TypeAry(elem, size, stable, not_flat, not_null_free))->hashcons();\n@@ -2260,1 +2390,3 @@\n-                         _stable && a->_stable);\n+                         _stable && a->_stable,\n+                         _not_flat && a->_not_flat,\n+                         _not_null_free && a->_not_null_free);\n@@ -2273,1 +2405,1 @@\n-  return new TypeAry(_elem->dual(), size_dual, !_stable);\n+  return new TypeAry(_elem->dual(), size_dual, !_stable, !_not_flat, !_not_null_free);\n@@ -2282,1 +2414,4 @@\n-    _size == a->_size;\n+    _size == a->_size &&\n+    _not_flat == a->_not_flat &&\n+    _not_null_free == a->_not_null_free;\n+\n@@ -2295,1 +2430,1 @@\n-  return make(_elem->remove_speculative(), _size, _stable);\n+  return make(_elem->remove_speculative(), _size, _stable, _not_flat, _not_null_free);\n@@ -2302,1 +2437,1 @@\n-  return make(_elem->cleanup_speculative(), _size, _stable);\n+  return make(_elem->cleanup_speculative(), _size, _stable, _not_flat, _not_null_free);\n@@ -2336,0 +2471,4 @@\n+  if (Verbose) {\n+    if (_not_flat) st->print(\"not flat:\");\n+    if (_not_null_free) st->print(\"not null free:\");\n+  }\n@@ -2377,2 +2516,10 @@\n-  if (tinst)\n-    return tklass->as_instance_klass()->is_final();\n+  if (tinst) {\n+    if (tklass->as_instance_klass()->is_final()) {\n+      \/\/ Even if MyValue is exact, [LMyValue is not exact due to [QMyValue <: [LMyValue.\n+      if (tinst->is_inlinetypeptr() && (tinst->ptr() == TypePtr::BotPTR || tinst->ptr() == TypePtr::TopPTR)) {\n+        return false;\n+      }\n+      return true;\n+    }\n+    return false;\n+  }\n@@ -2389,0 +2536,127 @@\n+\/\/==============================TypeInlineType=======================================\n+\n+const TypeInlineType* TypeInlineType::BOTTOM;\n+\n+\/\/------------------------------make-------------------------------------------\n+const TypeInlineType* TypeInlineType::make(ciInlineKlass* vk, bool larval) {\n+  return (TypeInlineType*)(new TypeInlineType(vk, larval))->hashcons();\n+}\n+\n+\/\/------------------------------meet-------------------------------------------\n+\/\/ Compute the MEET of two types.  It returns a new Type object.\n+const Type* TypeInlineType::xmeet(const Type* t) const {\n+  \/\/ Perform a fast test for common case; meeting the same types together.\n+  if(this == t) return this;  \/\/ Meeting same type-rep?\n+\n+  \/\/ Current \"this->_base\" is InlineType\n+  switch (t->base()) {          \/\/ switch on original type\n+\n+  case Int:\n+  case Long:\n+  case FloatTop:\n+  case FloatCon:\n+  case FloatBot:\n+  case DoubleTop:\n+  case DoubleCon:\n+  case DoubleBot:\n+  case NarrowKlass:\n+  case Bottom:\n+    return Type::BOTTOM;\n+\n+  case OopPtr:\n+  case MetadataPtr:\n+  case KlassPtr:\n+  case RawPtr:\n+  case AnyPtr:\n+    return TypePtr::BOTTOM;\n+\n+  case Top:\n+    return this;\n+\n+  case NarrowOop: {\n+    const Type* res = t->make_ptr()->xmeet(this);\n+    if (res->isa_ptr()) {\n+      return res->make_narrowoop();\n+    }\n+    return res;\n+  }\n+\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n+  case AryPtr:\n+  case InstPtr: {\n+    return t->xmeet(this);\n+  }\n+\n+  case InlineType: {\n+    \/\/ All inline types inherit from Object\n+    const TypeInlineType* other = t->is_inlinetype();\n+    if (_vk == NULL) {\n+      return this;\n+    } else if (other->_vk == NULL) {\n+      return other;\n+    } else if (_vk == other->_vk) {\n+      if (_larval == other->_larval ||\n+          !_larval) {\n+        return this;\n+      } else {\n+        return t;\n+      }\n+    }\n+    return TypeInstPtr::NOTNULL;\n+  }\n+\n+  default:                      \/\/ All else is a mistake\n+    typerr(t);\n+\n+  }\n+  return this;\n+}\n+\n+\/\/------------------------------xdual------------------------------------------\n+const Type* TypeInlineType::xdual() const {\n+  return this;\n+}\n+\n+\/\/------------------------------eq---------------------------------------------\n+\/\/ Structural equality check for Type representations\n+bool TypeInlineType::eq(const Type* t) const {\n+  const TypeInlineType* vt = t->is_inlinetype();\n+  return (_vk == vt->inline_klass() && _larval == vt->larval());\n+}\n+\n+\/\/------------------------------hash-------------------------------------------\n+\/\/ Type-specific hashing function.\n+int TypeInlineType::hash(void) const {\n+  return (intptr_t)_vk;\n+}\n+\n+\/\/------------------------------singleton--------------------------------------\n+\/\/ TRUE if Type is a singleton type, FALSE otherwise. Singletons are simple constants.\n+bool TypeInlineType::singleton(void) const {\n+  return false;\n+}\n+\n+\/\/------------------------------empty------------------------------------------\n+\/\/ TRUE if Type is a type with no values, FALSE otherwise.\n+bool TypeInlineType::empty(void) const {\n+  return false;\n+}\n+\n+\/\/------------------------------dump2------------------------------------------\n+#ifndef PRODUCT\n+void TypeInlineType::dump2(Dict &d, uint depth, outputStream* st) const {\n+  if (_vk == NULL) {\n+    st->print(\"BOTTOM inlinetype\");\n+    return;\n+  }\n+  int count = _vk->nof_declared_nonstatic_fields();\n+  st->print(\"inlinetype[%d]:{\", count);\n+  st->print(\"%s\", count != 0 ? _vk->declared_nonstatic_field_at(0)->type()->name() : \"empty\");\n+  for (int i = 1; i < count; ++i) {\n+    st->print(\", %s\", _vk->declared_nonstatic_field_at(i)->type()->name());\n+  }\n+  st->print(\"}%s\", _larval?\" : larval\":\"\");\n+}\n+#endif\n+\n@@ -2574,1 +2848,1 @@\n-const TypePtr *TypePtr::make(TYPES t, enum PTR ptr, int offset, const TypePtr* speculative, int inline_depth) {\n+const TypePtr* TypePtr::make(TYPES t, enum PTR ptr, Offset offset, const TypePtr* speculative, int inline_depth) {\n@@ -2588,1 +2862,1 @@\n-  return _offset;\n+  return offset();\n@@ -2650,0 +2924,1 @@\n+  case InlineType:\n@@ -2659,7 +2934,2 @@\n-int TypePtr::meet_offset( int offset ) const {\n-  \/\/ Either is 'TOP' offset?  Return the other offset!\n-  if( _offset == OffsetTop ) return offset;\n-  if( offset == OffsetTop ) return _offset;\n-  \/\/ If either is different, return 'BOTTOM' offset\n-  if( _offset != offset ) return OffsetBot;\n-  return _offset;\n+Type::Offset TypePtr::meet_offset(int offset) const {\n+  return _offset.meet(Offset(offset));\n@@ -2669,4 +2939,2 @@\n-int TypePtr::dual_offset( ) const {\n-  if( _offset == OffsetTop ) return OffsetBot;\/\/ Map 'TOP' into 'BOTTOM'\n-  if( _offset == OffsetBot ) return OffsetTop;\/\/ Map 'BOTTOM' into 'TOP'\n-  return _offset;               \/\/ Map everything else into self\n+Type::Offset TypePtr::dual_offset() const {\n+  return _offset.dual();\n@@ -2685,13 +2953,2 @@\n-int TypePtr::xadd_offset( intptr_t offset ) const {\n-  \/\/ Adding to 'TOP' offset?  Return 'TOP'!\n-  if( _offset == OffsetTop || offset == OffsetTop ) return OffsetTop;\n-  \/\/ Adding to 'BOTTOM' offset?  Return 'BOTTOM'!\n-  if( _offset == OffsetBot || offset == OffsetBot ) return OffsetBot;\n-  \/\/ Addition overflows or \"accidentally\" equals to OffsetTop? Return 'BOTTOM'!\n-  offset += (intptr_t)_offset;\n-  if (offset != (int)offset || offset == OffsetTop) return OffsetBot;\n-\n-  \/\/ assert( _offset >= 0 && _offset+offset >= 0, \"\" );\n-  \/\/ It is possible to construct a negative offset during PhaseCCP\n-\n-  return (int)offset;        \/\/ Sum valid offsets\n+Type::Offset TypePtr::xadd_offset(intptr_t offset) const {\n+  return _offset.add(offset);\n@@ -2706,1 +2963,1 @@\n-  return make(AnyPtr, _ptr, offset, _speculative, _inline_depth);\n+  return make(AnyPtr, _ptr, Offset(offset), _speculative, _inline_depth);\n@@ -2713,1 +2970,1 @@\n-  return _ptr == a->ptr() && _offset == a->offset() && eq_speculative(a) && _inline_depth == a->_inline_depth;\n+  return _ptr == a->ptr() && _offset == a->_offset && eq_speculative(a) && _inline_depth == a->_inline_depth;\n@@ -2719,1 +2976,1 @@\n-  return java_add(java_add((jint)_ptr, (jint)_offset), java_add((jint)hash_speculative(), (jint)_inline_depth));\n+  return java_add(java_add((jint)_ptr, (jint)offset()), java_add((jint)hash_speculative(), (jint)_inline_depth));\n@@ -2986,3 +3243,1 @@\n-  if( _offset == OffsetTop ) st->print(\"+top\");\n-  else if( _offset == OffsetBot ) st->print(\"+bot\");\n-  else if( _offset ) st->print(\"+%d\", _offset);\n+  _offset.dump2(st);\n@@ -3023,1 +3278,1 @@\n-  return (_offset != OffsetBot) && !below_centerline(_ptr);\n+  return (_offset != Offset::bottom) && !below_centerline(_ptr);\n@@ -3027,1 +3282,1 @@\n-  return (_offset == OffsetTop) || above_centerline(_ptr);\n+  return (_offset == Offset::top) || above_centerline(_ptr);\n@@ -3171,1 +3426,1 @@\n-TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset,\n+TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset, Offset field_offset,\n@@ -3181,2 +3436,2 @@\n-      (offset > 0) && xk && (k != 0) && k->is_instance_klass()) {\n-    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset);\n+      (offset.get() > 0) && xk && (k != 0) && k->is_instance_klass()) {\n+    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset.get());\n@@ -3185,2 +3440,2 @@\n-  if (_offset > 0 || _offset == Type::OffsetTop || _offset == Type::OffsetBot) {\n-    if (_offset == oopDesc::klass_offset_in_bytes()) {\n+  if (this->offset() > 0 || this->offset() == Type::OffsetTop || this->offset() == Type::OffsetBot) {\n+    if (this->offset() == oopDesc::klass_offset_in_bytes()) {\n@@ -3192,3 +3447,12 @@\n-    } else if (this->isa_aryptr()) {\n-      _is_ptr_to_narrowoop = (UseCompressedOops && klass()->is_obj_array_klass() &&\n-                             _offset != arrayOopDesc::length_offset_in_bytes());\n+    } else if (UseCompressedOops && this->isa_aryptr() && this->offset() != arrayOopDesc::length_offset_in_bytes()) {\n+      if (klass()->is_obj_array_klass()) {\n+        _is_ptr_to_narrowoop = true;\n+      } else if (klass()->is_flat_array_klass() && field_offset != Offset::top && field_offset != Offset::bottom) {\n+        \/\/ Check if the field of the inline type array element contains oops\n+        ciInlineKlass* vk = klass()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+        int foffset = field_offset.get() + vk->first_field_offset();\n+        ciField* field = vk->get_field_by_offset(foffset, false);\n+        assert(field != NULL, \"missing field\");\n+        BasicType bt = field->layout_type();\n+        _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(bt);\n+      }\n@@ -3196,2 +3460,0 @@\n-      ciInstanceKlass* ik = klass()->as_instance_klass();\n-      ciField* field = NULL;\n@@ -3200,1 +3462,1 @@\n-      } else if (_offset == OffsetBot || _offset == OffsetTop) {\n+      } else if (_offset == Offset::bottom || _offset == Offset::top) {\n@@ -3205,3 +3467,2 @@\n-\n-            (_offset == java_lang_Class::klass_offset() ||\n-             _offset == java_lang_Class::array_klass_offset())) {\n+            (this->offset() == java_lang_Class::klass_offset() ||\n+             this->offset() == java_lang_Class::array_klass_offset())) {\n@@ -3213,1 +3474,1 @@\n-                   _offset >= InstanceMirrorKlass::offset_of_static_fields()) {\n+                   this->offset() >= InstanceMirrorKlass::offset_of_static_fields()) {\n@@ -3218,8 +3479,14 @@\n-            field = k->get_field_by_offset(_offset, true);\n-          }\n-          if (field != NULL) {\n-            BasicType basic_elem_type = field->layout_type();\n-            _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(basic_elem_type);\n-          } else {\n-            \/\/ unsafe access\n-            _is_ptr_to_narrowoop = UseCompressedOops;\n+            if (k->is_inlinetype() && this->offset() == k->as_inline_klass()->default_value_offset()) {\n+              \/\/ Special hidden field that contains the oop of the default inline type\n+              \/\/ basic_elem_type = T_PRIMITIVE_OBJECT;\n+             _is_ptr_to_narrowoop = UseCompressedOops;\n+            } else {\n+              field = k->get_field_by_offset(this->offset(), true);\n+              if (field != NULL) {\n+                BasicType basic_elem_type = field->layout_type();\n+                _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(basic_elem_type);\n+              } else {\n+                \/\/ unsafe access\n+                _is_ptr_to_narrowoop = UseCompressedOops;\n+              }\n+            }\n@@ -3229,1 +3496,2 @@\n-          field = ik->get_field_by_offset(_offset, false);\n+          ciInstanceKlass* ik = klass()->as_instance_klass();\n+          ciField* field = ik->get_field_by_offset(this->offset(), false);\n@@ -3249,2 +3517,2 @@\n-const TypeOopPtr *TypeOopPtr::make(PTR ptr, int offset, int instance_id,\n-                                     const TypePtr* speculative, int inline_depth) {\n+const TypeOopPtr *TypeOopPtr::make(PTR ptr, Offset offset, int instance_id,\n+                                   const TypePtr* speculative, int inline_depth) {\n@@ -3255,1 +3523,1 @@\n-  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, xk, o, offset, instance_id, speculative, inline_depth))->hashcons();\n+  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, xk, o, offset, Offset::bottom, instance_id, speculative, inline_depth))->hashcons();\n@@ -3280,1 +3548,0 @@\n-\n@@ -3326,1 +3593,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3368,1 +3635,1 @@\n-  return new TypeOopPtr(_base, dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n+  return new TypeOopPtr(_base, dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), Offset::bottom, dual_instance_id(), dual_speculative(), dual_inline_depth());\n@@ -3374,1 +3641,1 @@\n-  if (klass->is_instance_klass()) {\n+  if (klass->is_instance_klass() || klass->is_inlinetype()) {\n@@ -3400,1 +3667,1 @@\n-    return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, 0);\n+    return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, Offset(0));\n@@ -3402,4 +3669,18 @@\n-    \/\/ Element is an object array. Recursively call ourself.\n-    const TypeOopPtr *etype = TypeOopPtr::make_from_klass_common(klass->as_obj_array_klass()->element_klass(), false, try_for_exact);\n-    bool xk = etype->klass_is_exact();\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+    \/\/ Element is an object or inline type array. Recursively call ourself.\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), \/* klass_change= *\/ false, try_for_exact);\n+    bool null_free = klass->as_array_klass()->is_elem_null_free();\n+    if (null_free) {\n+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n+    \/\/ Determine null-free\/flattened properties\n+    const TypeOopPtr* exact_etype = etype;\n+    if (etype->can_be_inline_type()) {\n+      \/\/ Use exact type if element can be an inline type\n+      exact_etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), \/* klass_change= *\/ true, \/* try_for_exact= *\/ true);\n+    }\n+    bool not_null_free = !exact_etype->can_be_inline_type();\n+    bool not_flat = !UseFlatArray || not_null_free || (exact_etype->is_inlinetypeptr() && !exact_etype->inline_klass()->flatten_array());\n+\n+    \/\/ Even if MyValue is exact, [LMyValue is not exact due to [QMyValue <: [LMyValue.\n+    bool xk = etype->klass_is_exact() && (!etype->is_inlinetypeptr() || null_free);\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, false, not_flat, not_null_free);\n@@ -3409,1 +3690,1 @@\n-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, 0);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, Offset(0));\n@@ -3414,1 +3695,2 @@\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS,\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3417,1 +3699,6 @@\n-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, 0);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));\n+    return arr;\n+  } else if (klass->is_flat_array_klass()) {\n+    ciInlineKlass* vk = klass->as_array_klass()->element_klass()->as_inline_klass();\n+    const TypeAry* arr0 = TypeAry::make(TypeInlineType::make(vk), TypeInt::POS);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));\n@@ -3433,2 +3720,2 @@\n-  if (klass->is_instance_klass()) {\n-    \/\/ Element is an instance\n+  if (klass->is_instance_klass() || klass->is_inlinetype()) {\n+    \/\/ Element is an instance or inline type\n@@ -3438,1 +3725,1 @@\n-      return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, 0);\n+      return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, Offset(0));\n@@ -3442,3 +3729,8 @@\n-    const TypeOopPtr *etype =\n-      TypeOopPtr::make_from_klass_raw(klass->as_obj_array_klass()->element_klass());\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_raw(klass->as_array_klass()->element_klass());\n+    bool null_free = false;\n+    if (klass->as_array_klass()->is_elem_null_free()) {\n+      null_free = true;\n+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ !null_free);\n@@ -3449,1 +3741,1 @@\n-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n@@ -3451,1 +3743,1 @@\n-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n@@ -3455,3 +3747,3 @@\n-    const Type* etype =\n-      (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));\n+    const Type* etype = (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3461,1 +3753,12 @@\n-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n+    } else {\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n+    }\n+  } else if (klass->is_flat_array_klass()) {\n+    ciInlineKlass* vk = klass->as_array_klass()->element_klass()->as_inline_klass();\n+    const TypeAry* arr0 = TypeAry::make(TypeInlineType::make(vk), TypeInt::make(o->as_array()->length()));\n+    \/\/ We used to pass NotNull in here, asserting that the sub-arrays\n+    \/\/ are all not-null.  This is not true in generally, as code can\n+    \/\/ slam NULLs down in the subarrays.\n+    if (make_constant) {\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n@@ -3463,1 +3766,1 @@\n-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n@@ -3474,1 +3777,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -3476,1 +3779,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -3569,6 +3872,1 @@\n-  switch( _offset ) {\n-  case OffsetTop: st->print(\"+top\"); break;\n-  case OffsetBot: st->print(\"+any\"); break;\n-  case         0: break;\n-  default:        st->print(\"+%d\",_offset); break;\n-  }\n+  _offset.dump2(st);\n@@ -3591,1 +3889,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -3600,1 +3898,1 @@\n-  return make(_ptr, offset, _instance_id, with_offset_speculative(offset), _inline_depth);\n+  return make(_ptr, Offset(offset), _instance_id, with_offset_speculative(offset), _inline_depth);\n@@ -3691,3 +3989,4 @@\n-TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, int off,\n-                         int instance_id, const TypePtr* speculative, int inline_depth)\n-  : TypeOopPtr(InstPtr, ptr, k, xk, o, off, instance_id, speculative, inline_depth) {\n+TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset off,\n+                         bool flatten_array, int instance_id, const TypePtr* speculative, int inline_depth)\n+  : TypeOopPtr(InstPtr, ptr, k, xk, o, off, Offset::bottom, instance_id, speculative, inline_depth),\n+    _flatten_array(flatten_array) {\n@@ -3697,0 +3996,2 @@\n+   assert(!klass()->flatten_array() || flatten_array, \"Should be flat in array\");\n+   assert(!flatten_array || can_be_inline_type(), \"Only inline types can be flat in array\");\n@@ -3704,1 +4005,2 @@\n-                                     int offset,\n+                                     Offset offset,\n+                                     bool flatten_array,\n@@ -3725,0 +4027,3 @@\n+  \/\/ Check if this type is known to be flat in arrays\n+  flatten_array = flatten_array || k->flatten_array();\n+\n@@ -3727,1 +4032,1 @@\n-    (TypeInstPtr*)(new TypeInstPtr(ptr, k, xk, o ,offset, instance_id, speculative, inline_depth))->hashcons();\n+    (TypeInstPtr*)(new TypeInstPtr(ptr, k, xk, o, offset, flatten_array, instance_id, speculative, inline_depth))->hashcons();\n@@ -3760,1 +4065,1 @@\n-  return make(ptr, klass(), klass_is_exact(), ptr == Constant ? const_oop() : NULL, _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr, klass(), klass_is_exact(), ptr == Constant ? const_oop() : NULL, _offset, _flatten_array, _instance_id, _speculative, _inline_depth);\n@@ -3771,1 +4076,1 @@\n-  return make(ptr(), klass(), klass_is_exact, const_oop(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), klass(), klass_is_exact, const_oop(), _offset, _flatten_array, _instance_id, _speculative, _inline_depth);\n@@ -3777,1 +4082,1 @@\n-  return make(_ptr, klass(), _klass_is_exact, const_oop(), _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, klass(), _klass_is_exact, const_oop(), _offset, _flatten_array, instance_id, _speculative, _inline_depth);\n@@ -3784,1 +4089,1 @@\n-    int off = meet_offset(tinst->offset());\n+    Offset off = meet_offset(tinst->offset());\n@@ -3809,1 +4114,1 @@\n-      else if (loaded->ptr() == TypePtr::AnyNull) { return TypeInstPtr::make(ptr, unloaded->klass(), false, NULL, off, instance_id, speculative, depth); }\n+      else if (loaded->ptr() == TypePtr::AnyNull) { return TypeInstPtr::make(ptr, unloaded->klass(), false, NULL, off, false, instance_id, speculative, depth); }\n@@ -3870,1 +4175,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3879,1 +4184,1 @@\n-                  (ptr == Constant ? const_oop() : NULL), offset, instance_id, speculative, depth);\n+                  (ptr == Constant ? const_oop() : NULL), offset, flatten_array(), instance_id, speculative, depth);\n@@ -3895,1 +4200,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3907,1 +4212,1 @@\n-                  (ptr == Constant ? const_oop() : NULL), offset, instance_id, speculative, depth);\n+                  (ptr == Constant ? const_oop() : NULL), offset, flatten_array(), instance_id, speculative, depth);\n@@ -3935,1 +4240,1 @@\n-    int off = meet_offset(tinst->offset());\n+    Offset off = meet_offset(tinst->offset());\n@@ -3943,1 +4248,3 @@\n-    bool this_xk  = klass_is_exact();\n+    bool this_xk  = this->klass_is_exact();\n+    bool tinst_flatten_array = tinst->flatten_array();\n+    bool this_flatten_array  = this->flatten_array();\n@@ -3947,0 +4254,1 @@\n+    bool res_flatten_array = false;\n@@ -3948,1 +4256,3 @@\n-    MeetResult kind = meet_instptr(ptr, this_klass, tinst_klass, this_xk, tinst_xk, this->_ptr, tinst->_ptr, res_klass, res_xk);\n+    MeetResult kind = meet_instptr(ptr, this_klass, tinst_klass, this_xk, tinst_xk, this->_ptr, tinst->_ptr,\n+                                   this_flatten_array, tinst_flatten_array,\n+                                   res_klass, res_xk, res_flatten_array);\n@@ -3988,1 +4298,1 @@\n-      res = make(ptr, res_klass, res_xk, o, off, instance_id, speculative, depth);\n+      res = make(ptr, res_klass, res_xk, o, off, res_flatten_array, instance_id, speculative, depth);\n@@ -3995,0 +4305,21 @@\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return t;\n+      } else {\n+        return TypeInstPtr::NOTNULL;\n+      }\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return make(ptr, _klass, false, NULL, Offset(0), _flatten_array, InstanceBot, _speculative);\n+      } else {\n+        return make(ptr, ciEnv::current()->Object_klass());\n+      }\n+    }\n+  }\n+\n@@ -4000,2 +4331,5 @@\n-                                          PTR this_ptr,\n-                                          PTR tinst_ptr, ciKlass*&res_klass, bool &res_xk) {\n+                                          PTR this_ptr, PTR tinst_ptr, bool this_flatten_array, bool tinst_flatten_array,\n+                                          ciKlass*&res_klass, bool &res_xk, bool& res_flatten_array) {\n+\n+  bool this_flatten_array_orig = this_flatten_array;\n+  bool tinst_flatten_array_orig = tinst_flatten_array;\n@@ -4007,1 +4341,1 @@\n-  if (ptr != Constant && this_klass->equals(tinst_klass) && this_xk == tinst_xk) {\n+  if (ptr != Constant && this_klass->equals(tinst_klass) && this_xk == tinst_xk && this_flatten_array == tinst_flatten_array) {\n@@ -4010,0 +4344,1 @@\n+    res_flatten_array = this_flatten_array;\n@@ -4027,0 +4362,3 @@\n+    tmp2 = tinst_flatten_array;\n+    tinst_flatten_array = this_flatten_array;\n+    this_flatten_array = tmp2;\n@@ -4044,0 +4382,1 @@\n+      res_flatten_array = below_centerline(ptr) ? tinst_flatten_array    : this_flatten_array;\n@@ -4051,0 +4390,1 @@\n+      res_flatten_array = above_centerline(ptr) ? tinst_flatten_array : false;\n@@ -4086,0 +4426,1 @@\n+  bool flat_array = false;\n@@ -4089,1 +4430,2 @@\n-  } else if (!tinst_xk && this_klass->is_subtype_of(tinst_klass)) {\n+    flat_array = below_centerline(ptr) ? (this_flatten_array && tinst_flatten_array) : (this_flatten_array || tinst_flatten_array);\n+  } else if (!tinst_xk && this_klass->is_subtype_of(tinst_klass) && (!tinst_flatten_array || this_flatten_array)) {\n@@ -4092,1 +4434,2 @@\n-  } else if (!this_xk && tinst_klass->is_subtype_of(this_klass)) {\n+    flat_array = this_flatten_array;\n+  } else if (!this_xk && tinst_klass->is_subtype_of(this_klass) && (!this_flatten_array || tinst_flatten_array)) {\n@@ -4095,0 +4438,1 @@\n+    flat_array = tinst_flatten_array;\n@@ -4101,0 +4445,1 @@\n+      this_flatten_array = tinst_flatten_array = flat_array;\n@@ -4104,0 +4449,1 @@\n+      this_flatten_array = tinst_flatten_array;\n@@ -4107,0 +4453,1 @@\n+      tinst_flatten_array = this_flatten_array;\n@@ -4109,0 +4456,1 @@\n+      this_flatten_array = flat_array;\n@@ -4119,0 +4467,1 @@\n+    res_flatten_array = this_flatten_array;\n@@ -4133,0 +4482,1 @@\n+  res_flatten_array = this_flatten_array_orig && tinst_flatten_array_orig;\n@@ -4139,1 +4489,1 @@\n-ciType* TypeInstPtr::java_mirror_type() const {\n+ciType* TypeInstPtr::java_mirror_type(bool* is_val_mirror) const {\n@@ -4145,2 +4495,1 @@\n-\n-  return const_oop()->as_instance()->java_mirror_type();\n+  return const_oop()->as_instance()->java_mirror_type(is_val_mirror);\n@@ -4154,1 +4503,1 @@\n-  return new TypeInstPtr(dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n+  return new TypeInstPtr(dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), flatten_array(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n@@ -4163,0 +4512,1 @@\n+    flatten_array() == p->flatten_array() &&\n@@ -4169,1 +4519,1 @@\n-  int hash = java_add((jint)klass()->hash(), (jint)TypeOopPtr::hash());\n+  int hash = java_add(java_add((jint)klass()->hash(), (jint)TypeOopPtr::hash()), (jint)flatten_array());\n@@ -4273,5 +4623,1 @@\n-  if( _offset ) {               \/\/ Dump offset, if any\n-    if( _offset == OffsetBot )      st->print(\"+any\");\n-    else if( _offset == OffsetTop ) st->print(\"+unknown\");\n-    else st->print(\"+%d\", _offset);\n-  }\n+  _offset.dump2(st);\n@@ -4280,0 +4626,5 @@\n+\n+  if (flatten_array() && !klass()->is_inlinetype()) {\n+    st->print(\" (flatten array)\");\n+  }\n+\n@@ -4292,1 +4643,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), xadd_offset(offset),\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), xadd_offset(offset), flatten_array(),\n@@ -4297,1 +4648,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), offset,\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), Offset(offset), flatten_array(),\n@@ -4306,1 +4657,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset,\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(),\n@@ -4314,1 +4665,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, _instance_id, _speculative, depth);\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(), _instance_id, _speculative, depth);\n@@ -4319,1 +4670,5 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(), instance_id, _speculative, _inline_depth);\n+}\n+\n+const TypeInstPtr *TypeInstPtr::cast_to_flatten_array() const {\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, true, _instance_id, _speculative, _inline_depth);\n@@ -4331,1 +4686,1 @@\n-  return TypeInstKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, klass(), 0);\n+  return TypeInstKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, klass(), Offset(0), flatten_array());\n@@ -4346,0 +4701,1 @@\n+const TypeAryPtr *TypeAryPtr::INLINES;\n@@ -4348,1 +4704,1 @@\n-const TypeAryPtr *TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+const TypeAryPtr* TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,\n@@ -4354,1 +4710,1 @@\n-  return (TypeAryPtr*)(new TypeAryPtr(ptr, NULL, ary, k, xk, offset, instance_id, false, speculative, inline_depth))->hashcons();\n+  return (TypeAryPtr*)(new TypeAryPtr(ptr, NULL, ary, k, xk, offset, field_offset, instance_id, false, speculative, inline_depth))->hashcons();\n@@ -4358,1 +4714,1 @@\n-const TypeAryPtr *TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+const TypeAryPtr* TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,\n@@ -4366,1 +4722,1 @@\n-  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();\n+  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, field_offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();\n@@ -4372,1 +4728,1 @@\n-  return make(ptr, ptr == Constant ? const_oop() : NULL, _ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr, ptr == Constant ? const_oop() : NULL, _ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4380,1 +4736,7 @@\n-  return make(ptr(), const_oop(), _ary, klass(), klass_is_exact, _offset, _instance_id, _speculative, _inline_depth);\n+\n+  const TypeAry* new_ary = _ary;\n+  if (klass() != NULL && klass()->is_obj_array_klass() && klass_is_exact) {\n+    \/\/ An object array can't be flat or null-free if the klass is exact\n+    new_ary = TypeAry::make(elem(), size(), is_stable(), \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n+  }\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact, _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4386,1 +4748,1 @@\n-  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4442,2 +4804,48 @@\n-  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable());\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable(), is_not_flat(), is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/-------------------------------cast_to_not_flat------------------------------\n+const TypeAryPtr* TypeAryPtr::cast_to_not_flat(bool not_flat) const {\n+  if (not_flat == is_not_flat()) {\n+    return this;\n+  }\n+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), not_flat, is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/-------------------------------cast_to_not_null_free-------------------------\n+const TypeAryPtr* TypeAryPtr::cast_to_not_null_free(bool not_null_free) const {\n+  if (not_null_free == is_not_null_free()) {\n+    return this;\n+  }\n+  \/\/ Not null free implies not flat\n+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), not_null_free ? true : is_not_flat(), not_null_free);\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/---------------------------------update_properties---------------------------\n+const TypeAryPtr* TypeAryPtr::update_properties(const TypeAryPtr* from) const {\n+  if ((from->is_flat()          && is_not_flat()) ||\n+      (from->is_not_flat()      && is_flat()) ||\n+      (from->is_null_free()     && is_not_null_free()) ||\n+      (from->is_not_null_free() && is_null_free())) {\n+    return NULL; \/\/ Inconsistent properties\n+  } else if (from->is_not_null_free()) {\n+    return cast_to_not_null_free(); \/\/ Implies not flat\n+  } else if (from->is_not_flat()) {\n+    return cast_to_not_flat();\n+  }\n+  return this;\n+}\n+\n+jint TypeAryPtr::flat_layout_helper() const {\n+  return klass()->as_flat_array_klass()->layout_helper();\n+}\n+\n+int TypeAryPtr::flat_elem_size() const {\n+  return klass()->as_flat_array_klass()->element_byte_size();\n+}\n+\n+int TypeAryPtr::flat_log_elem_size() const {\n+  return klass()->as_flat_array_klass()->log2_element_size();\n@@ -4459,1 +4867,1 @@\n-  const TypeAry* new_ary = TypeAry::make(elem, size(), stable);\n+  const TypeAry* new_ary = TypeAry::make(elem, size(), stable, is_not_flat(), is_not_null_free());\n@@ -4461,1 +4869,1 @@\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4479,4 +4887,8 @@\n-  \/\/ The pointers in the autobox arrays are always non-null.\n-  etype = etype->cast_to_ptr_type(TypePtr::NotNull)->is_oopptr();\n-  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable());\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth, \/*is_autobox_cache=*\/true);\n+  \/\/ TODO fix with JDK-8284164\n+  \/\/ Ignore inline types to not confuse logic in TypeAryPtr::compute_klass\n+  if (!etype->is_inlinetypeptr()) {\n+    \/\/ The pointers in the autobox arrays are always non-null.\n+    etype = etype->cast_to_ptr_type(TypePtr::NotNull)->is_oopptr();\n+  }\n+  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable(), is_not_flat(), is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, \/*is_autobox_cache=*\/true);\n@@ -4491,1 +4903,2 @@\n-    TypeOopPtr::eq(p);  \/\/ Check sub-parts\n+    TypeOopPtr::eq(p) &&\/\/ Check sub-parts\n+    _field_offset == p->_field_offset;\n@@ -4497,1 +4910,1 @@\n-  return (intptr_t)_ary + TypeOopPtr::hash();\n+  return (intptr_t)_ary + TypeOopPtr::hash() + _field_offset.get();\n@@ -4597,1 +5010,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4606,1 +5019,1 @@\n-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4620,1 +5033,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4636,1 +5049,1 @@\n-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4650,1 +5063,2 @@\n-    int off = meet_offset(tap->offset());\n+    Offset off = meet_offset(tap->offset());\n+    Offset field_off = meet_field_offset(tap->field_offset());\n@@ -4659,2 +5073,8 @@\n-    const Type* elem = tary->_elem;\n-    if (meet_aryptr(ptr, elem, this->klass(), tap->klass(), this->klass_is_exact(), tap->klass_is_exact(), this->ptr(), tap->ptr(), res_klass, res_xk) == NOT_SUBTYPE) {\n+    bool res_not_flat = false;\n+    bool res_not_null_free = false;\n+    const Type* res_elem = NULL;\n+    if (meet_aryptr(ptr, _ary->_elem, tap->_ary->_elem, this->klass(), tap->klass(),\n+                    this->klass_is_exact(), tap->klass_is_exact(), this->ptr(), tap->ptr(),\n+                    this->is_not_flat(), tap->is_not_flat(),\n+                    this->is_not_null_free(), tap->is_not_null_free(),\n+                    res_elem, res_klass, res_xk, res_not_flat, res_not_null_free) == NOT_SUBTYPE) {\n@@ -4662,0 +5082,11 @@\n+    } else if (klass() != NULL && tap->klass() != NULL && klass()->is_flat_array_klass() != tap->klass()->is_flat_array_klass()) {\n+      \/\/ Meeting flattened inline type array with non-flattened array. Adjust (field) offset accordingly.\n+      if (tary->_elem->isa_inlinetype()) {\n+        \/\/ Result is flattened\n+        off = Offset(is_flat() ? offset() : tap->offset());\n+        field_off = is_flat() ? field_offset() : tap->field_offset();\n+      } else if (tary->_elem->make_oopptr() != NULL && tary->_elem->make_oopptr()->isa_instptr() && below_centerline(ptr)) {\n+        \/\/ Result is non-flattened\n+        off = Offset(flattened_offset()).meet(Offset(tap->flattened_offset()));\n+        field_off = Offset::bottom;\n+      }\n@@ -4679,1 +5110,1 @@\n-    return make(ptr, o, TypeAry::make(elem, tary->_size, tary->_stable), res_klass, res_xk, off, instance_id, speculative, depth);\n+    return make(ptr, o, TypeAry::make(res_elem, tary->_size, tary->_stable, res_not_flat, res_not_null_free), res_klass, res_xk, off, field_off, instance_id, speculative, depth);\n@@ -4685,1 +5116,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4696,2 +5127,2 @@\n-      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {\n-        return make(ptr, _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flatten_array()) {\n+        return make(ptr, _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4702,1 +5133,1 @@\n-        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL,offset, instance_id, speculative, depth);\n+        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);\n@@ -4714,1 +5145,1 @@\n-        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {\n+        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flatten_array()) {\n@@ -4717,1 +5148,1 @@\n-                      _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                      _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4728,1 +5159,1 @@\n-      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, instance_id, speculative, depth);\n+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);\n@@ -4732,0 +5163,13 @@\n+\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      return TypeInstPtr::NOTNULL;\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass());\n+    }\n+  }\n@@ -4737,1 +5181,7 @@\n-TypePtr::MeetResult TypePtr::meet_aryptr(PTR& ptr, const Type*& elem, ciKlass* this_klass, ciKlass* tap_klass, bool this_xk, bool tap_xk, PTR this_ptr, PTR tap_ptr, ciKlass*& res_klass, bool& res_xk) {\n+TypePtr::MeetResult TypePtr::meet_aryptr(PTR& ptr, const Type* this_elem, const Type* tap_elem,\n+                                         ciKlass* this_klass, ciKlass* tap_klass,\n+                                         bool this_xk, bool tap_xk, PTR this_ptr, PTR tap_ptr,\n+                                         bool this_not_flat, bool tap_not_flat,\n+                                         bool this_not_null_free, bool tap_not_null_free,\n+                                         const Type*& res_elem, ciKlass*& res_klass,\n+                                         bool& res_xk, bool& res_not_flat, bool& res_not_null_free) {\n@@ -4740,1 +5190,5 @@\n-  if (elem->isa_int()) {\n+  res_elem = this_elem->meet(tap_elem);\n+  res_not_flat = this_not_flat && tap_not_flat;\n+  res_not_null_free = this_not_null_free && tap_not_null_free;\n+\n+  if (res_elem->isa_int()) {\n@@ -4743,1 +5197,1 @@\n-    if (this_klass == NULL)\n+    if (this_klass == NULL) {\n@@ -4745,1 +5199,1 @@\n-    else if (tap_klass == NULL || tap_klass == this_klass) {\n+    } else if (tap_klass == NULL || tap_klass == this_klass) {\n@@ -4751,1 +5205,1 @@\n-      elem = Type::BOTTOM;\n+      res_elem = Type::BOTTOM;\n@@ -4766,2 +5220,3 @@\n-      if (above_centerline(ptr) || (elem->make_ptr() && above_centerline(elem->make_ptr()->_ptr))) {\n-        elem = Type::BOTTOM;\n+      if (above_centerline(ptr) || (res_elem->make_ptr() && above_centerline(res_elem->make_ptr()->_ptr)) ||\n+          res_elem->isa_inlinetype()) {\n+        res_elem = Type::BOTTOM;\n@@ -4781,0 +5236,3 @@\n+        if (this_elem->isa_inlinetype()) {\n+          res_elem = this_elem;\n+        }\n@@ -4784,1 +5242,1 @@\n-      return result;\n+      break;\n@@ -4787,1 +5245,1 @@\n-          res_xk = true;\n+        res_xk = true;\n@@ -4794,1 +5252,1 @@\n-      return result;\n+      break;\n@@ -4801,0 +5259,3 @@\n+        if (tap_elem->isa_inlinetype()) {\n+          res_elem = tap_elem;\n+        }\n@@ -4805,1 +5266,1 @@\n-      return result;\n+      break;\n@@ -4811,0 +5272,1 @@\n+\n@@ -4818,1 +5280,10 @@\n-  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(),_klass, _klass_is_exact, dual_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());\n+  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(), _klass, _klass_is_exact, dual_offset(), dual_field_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());\n+}\n+\n+Type::Offset TypeAryPtr::meet_field_offset(const Type::Offset offset) const {\n+  return _field_offset.meet(offset);\n+}\n+\n+\/\/------------------------------dual_offset------------------------------------\n+Type::Offset TypeAryPtr::dual_field_offset() const {\n+  return _field_offset.dual();\n@@ -4855,1 +5326,6 @@\n-  if( _offset != 0 ) {\n+  if (is_flat()) {\n+    st->print(\"(\");\n+    _field_offset.dump2(st);\n+    st->print(\")\");\n+  }\n+  if (offset() != 0) {\n@@ -4857,3 +5333,3 @@\n-    if( _offset == OffsetTop )       st->print(\"+undefined\");\n-    else if( _offset == OffsetBot )  st->print(\"+any\");\n-    else if( _offset < header_size ) st->print(\"+%d\", _offset);\n+    if( _offset == Offset::top )       st->print(\"+undefined\");\n+    else if( _offset == Offset::bottom )  st->print(\"+any\");\n+    else if( offset() < header_size ) st->print(\"+%d\", offset());\n@@ -4867,1 +5343,1 @@\n-        st->print(\"[%d]\", (_offset - array_base)\/elem_size);\n+        st->print(\"[%d]\", (offset() - array_base)\/elem_size);\n@@ -4889,1 +5365,1 @@\n-  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _instance_id, add_offset_speculative(offset), _inline_depth);\n+  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _field_offset, _instance_id, add_offset_speculative(offset), _inline_depth, _is_autobox_cache);\n@@ -4893,1 +5369,1 @@\n-  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, offset, _instance_id, with_offset_speculative(offset), _inline_depth);\n+  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, Offset(offset), _field_offset, _instance_id, with_offset_speculative(offset), _inline_depth, _is_autobox_cache);\n@@ -4897,1 +5373,1 @@\n-  return make(_ptr, _const_oop, ary, _klass, _klass_is_exact, _offset, _instance_id, _speculative, _inline_depth);\n+  return make(_ptr, _const_oop, ary, _klass, _klass_is_exact, _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4905,1 +5381,13 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, NULL, _inline_depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, NULL, _inline_depth, _is_autobox_cache);\n+}\n+\n+const Type* TypeAryPtr::cleanup_speculative() const {\n+  if (speculative() == NULL) {\n+    return this;\n+  }\n+  \/\/ Keep speculative part if it contains information about flat-\/nullability\n+  const TypeAryPtr* spec_aryptr = speculative()->isa_aryptr();\n+  if (spec_aryptr != NULL && (spec_aryptr->is_not_flat() || spec_aryptr->is_not_null_free())) {\n+    return this;\n+  }\n+  return TypeOopPtr::cleanup_speculative();\n@@ -4912,1 +5400,49 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, _speculative, depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, _speculative, depth, _is_autobox_cache);\n+}\n+\n+const TypeAryPtr* TypeAryPtr::with_field_offset(int offset) const {\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, Offset(offset), _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+const TypePtr* TypeAryPtr::add_field_offset_and_offset(intptr_t offset) const {\n+  int adj = 0;\n+  if (offset != Type::OffsetBot && offset != Type::OffsetTop) {\n+    const Type* elemtype = elem();\n+    if (elemtype->isa_inlinetype()) {\n+      if (_offset.get() != OffsetBot && _offset.get() != OffsetTop) {\n+        adj = _offset.get();\n+        offset += _offset.get();\n+      }\n+      uint header = arrayOopDesc::base_offset_in_bytes(T_OBJECT);\n+      if (_field_offset.get() != OffsetBot && _field_offset.get() != OffsetTop) {\n+        offset += _field_offset.get();\n+        if (_offset.get() == OffsetBot || _offset.get() == OffsetTop) {\n+          offset += header;\n+        }\n+      }\n+      if (offset >= (intptr_t)header || offset < 0) {\n+        \/\/ Try to get the field of the inline type array element we are pointing to\n+        ciKlass* arytype_klass = klass();\n+        ciFlatArrayKlass* vak = arytype_klass->as_flat_array_klass();\n+        ciInlineKlass* vk = vak->element_klass()->as_inline_klass();\n+        int shift = vak->log2_element_size();\n+        int mask = (1 << shift) - 1;\n+        intptr_t field_offset = ((offset - header) & mask);\n+        ciField* field = vk->get_field_by_offset(field_offset + vk->first_field_offset(), false);\n+        if (field != NULL) {\n+          return with_field_offset(field_offset)->add_offset(offset - field_offset - adj);\n+        }\n+      }\n+    }\n+  }\n+  return add_offset(offset - adj);\n+}\n+\n+\/\/ Return offset incremented by field_offset for flattened inline type arrays\n+const int TypeAryPtr::flattened_offset() const {\n+  int offset = _offset.get();\n+  if (offset != Type::OffsetBot && offset != Type::OffsetTop &&\n+      _field_offset != Offset::bottom && _field_offset != Offset::top) {\n+    offset += _field_offset.get();\n+  }\n+  return offset;\n@@ -4917,1 +5453,1 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth);\n@@ -4922,0 +5458,1 @@\n+\n@@ -5012,1 +5549,0 @@\n-\n@@ -5018,0 +5554,3 @@\n+  case InlineType:\n+    return t->xmeet(this);\n+\n@@ -5096,1 +5635,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -5116,1 +5655,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -5118,1 +5657,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -5169,1 +5708,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5197,1 +5736,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5230,1 +5769,1 @@\n-  switch( _offset ) {\n+  switch (offset()) {\n@@ -5234,1 +5773,1 @@\n-  default:        st->print(\"+%d\",_offset); break;\n+  default:        st->print(\"+%d\",offset()); break;\n@@ -5244,1 +5783,1 @@\n-TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset):\n+TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset):\n@@ -5249,1 +5788,1 @@\n-  return make(Constant, m, 0);\n+  return make(Constant, m, Offset(0));\n@@ -5252,1 +5791,1 @@\n-  return make(Constant, m, 0);\n+  return make(Constant, m, Offset(0));\n@@ -5257,1 +5796,1 @@\n-const TypeMetadataPtr *TypeMetadataPtr::make(PTR ptr, ciMetadata* m, int offset) {\n+const TypeMetadataPtr* TypeMetadataPtr::make(PTR ptr, ciMetadata* m, Offset offset) {\n@@ -5268,1 +5807,3 @@\n-    if (elem->is_klassptr()->klass_is_exact()) {\n+    if (elem->is_klassptr()->klass_is_exact() &&\n+        \/\/ Even if MyValue is exact, [LMyValue is not exact due to [QMyValue <: [LMyValue.\n+        (is_null_free() || !_ary->_elem->make_oopptr()->is_inlinetypeptr())) {\n@@ -5271,0 +5812,2 @@\n+  } else if (elem->isa_inlinetype() != NULL) {\n+    elem = TypeKlassPtr::make(elem->inline_klass());\n@@ -5272,1 +5815,1 @@\n-  return TypeAryKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, elem, klass(), 0);\n+  return TypeAryKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, elem, klass(), Offset(0), is_not_flat(), is_not_null_free(), is_null_free());\n@@ -5275,1 +5818,1 @@\n-const TypeKlassPtr* TypeKlassPtr::make(ciKlass *klass) {\n+const TypeKlassPtr* TypeKlassPtr::make(ciKlass* klass) {\n@@ -5282,1 +5825,1 @@\n-const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* klass, int offset) {\n+const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* klass, Offset offset) {\n@@ -5289,2 +5832,1 @@\n-\n-TypeKlassPtr::TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, int offset)\n+TypeKlassPtr::TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, Offset offset)\n@@ -5319,1 +5861,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -5331,1 +5873,1 @@\n-    if (!empty() && ktkp != NULL && ktkp->klass()->is_loaded() && ktkp->klass()->is_interface())\n+    if (!empty() && ktkp != NULL && ktkp->is_loaded() && ktkp->klass()->is_interface())\n@@ -5352,1 +5894,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert( offset() >= 0, \"\" );\n@@ -5354,1 +5896,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -5374,1 +5916,1 @@\n-void TypeKlassPtr::dump2(Dict & d, uint depth, outputStream *st) const {\n+void TypeInstKlassPtr::dump2(Dict & d, uint depth, outputStream *st) const {\n@@ -5397,5 +5939,2 @@\n-\n-  if (_offset) {               \/\/ Dump offset, if any\n-    if (_offset == OffsetBot)      { st->print(\"+any\"); }\n-    else if (_offset == OffsetTop) { st->print(\"+unknown\"); }\n-    else                            { st->print(\"+%d\", _offset); }\n+  if (Verbose) {\n+    if (_flatten_array) st->print(\":flatten array\");\n@@ -5403,1 +5942,1 @@\n-\n+  _offset.dump2(st);\n@@ -5419,0 +5958,1 @@\n+    flatten_array() == p->flatten_array() &&\n@@ -5423,1 +5963,1 @@\n-  return java_add((jint)klass()->hash(), TypeKlassPtr::hash());\n+  return java_add(java_add((jint)klass()->hash(), TypeKlassPtr::hash()), (jint)flatten_array());\n@@ -5426,1 +5966,3 @@\n-const TypeInstKlassPtr *TypeInstKlassPtr::make(PTR ptr, ciKlass* k, int offset) {\n+const TypeInstKlassPtr *TypeInstKlassPtr::make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array) {\n+  flatten_array = flatten_array || k->flatten_array();\n+\n@@ -5428,1 +5970,1 @@\n-    (TypeInstKlassPtr*)(new TypeInstKlassPtr(ptr, k, offset))->hashcons();\n+    (TypeInstKlassPtr*)(new TypeInstKlassPtr(ptr, k, offset, flatten_array))->hashcons();\n@@ -5436,1 +5978,1 @@\n-  return make( _ptr, klass(), xadd_offset(offset) );\n+  return make(_ptr, klass(), xadd_offset(offset), flatten_array());\n@@ -5440,1 +5982,1 @@\n-  return make(_ptr, klass(), offset);\n+  return make(_ptr, klass(), Offset(offset), flatten_array());\n@@ -5447,1 +5989,1 @@\n-  return make(ptr, _klass, _offset);\n+  return make(ptr, _klass, _offset, flatten_array());\n@@ -5463,1 +6005,1 @@\n-  return make(klass_is_exact ? Constant : NotNull, k, _offset);\n+  return make(klass_is_exact ? Constant : NotNull, k, _offset, flatten_array());\n@@ -5492,1 +6034,1 @@\n-  return TypeInstPtr::make(TypePtr::BotPTR, k, xk, NULL, 0);\n+  return TypeInstPtr::make(TypePtr::BotPTR, k, xk, NULL, Offset(0), flatten_array() && !klass()->is_inlinetype());\n@@ -5525,1 +6067,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5533,1 +6075,1 @@\n-      return make( ptr, klass(), offset );\n+      return make(ptr, klass(), offset, flatten_array());\n@@ -5546,1 +6088,1 @@\n-    return TypePtr::BOTTOM;\n+      return TypePtr::BOTTOM;\n@@ -5566,1 +6108,1 @@\n-    int  off     = meet_offset(tkls->offset());\n+    Offset  off     = meet_offset(tkls->offset());\n@@ -5572,0 +6114,2 @@\n+    bool tkls_flatten_array = tkls->flatten_array();\n+    bool this_flatten_array  = this->flatten_array();\n@@ -5575,1 +6119,3 @@\n-    switch(meet_instptr(ptr, this_klass, tkls_klass, this_xk, tkls_xk, this->_ptr, tkls->_ptr, res_klass, res_xk)) {\n+    bool res_flatten_array = false;\n+    switch(meet_instptr(ptr, this_klass, tkls_klass, this_xk, tkls_xk, this->_ptr, tkls->_ptr,\n+                        this_flatten_array, tkls_flatten_array, res_klass, res_xk, res_flatten_array)) {\n@@ -5583,1 +6129,1 @@\n-        const Type* res1 = make(ptr, res_klass, off);\n+        const Type* res1 = make(ptr, res_klass, off, res_flatten_array);\n@@ -5592,1 +6138,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5602,1 +6148,1 @@\n-        return TypeAryKlassPtr::make(ptr, tp->elem(), tp->klass(), offset);\n+        return TypeAryKlassPtr::make(ptr, tp->elem(), tp->klass(), offset, tp->is_not_flat(), tp->is_not_null_free(), tp->is_null_free());\n@@ -5606,1 +6152,1 @@\n-        return make(ptr, ciEnv::current()->Object_klass(), offset);\n+        return make(ptr, ciEnv::current()->Object_klass(), offset, false);\n@@ -5621,1 +6167,1 @@\n-                                       tp->elem(), tp->klass(), offset);\n+                                       tp->elem(), tp->klass(), offset, tp->is_not_flat(), tp->is_not_null_free(), tp->is_null_free());\n@@ -5628,1 +6174,1 @@\n-      return make(ptr, ciEnv::current()->Object_klass(), offset);\n+      return make(ptr, ciEnv::current()->Object_klass(), offset, false);\n@@ -5632,0 +6178,20 @@\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return t;\n+      } else {\n+        return TypeInstPtr::NOTNULL;\n+      }\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return make(ptr, _klass, Offset(0), _flatten_array);\n+      } else {\n+        return make(ptr, ciEnv::current()->Object_klass(), Offset(0));\n+      }\n+    }\n+  }\n@@ -5640,1 +6206,1 @@\n-  return new TypeInstKlassPtr(dual_ptr(), klass(), dual_offset());\n+  return new TypeInstKlassPtr(dual_ptr(), klass(), dual_offset(), flatten_array());\n@@ -5706,2 +6272,2 @@\n-const TypeAryKlassPtr *TypeAryKlassPtr::make(PTR ptr, const Type* elem, ciKlass* k, int offset) {\n-  return (TypeAryKlassPtr*)(new TypeAryKlassPtr(ptr, elem, k, offset))->hashcons();\n+const TypeAryKlassPtr* TypeAryKlassPtr::make(PTR ptr, const Type* elem, ciKlass* k, Offset offset, bool not_flat, bool not_null_free, bool null_free) {\n+  return (TypeAryKlassPtr*)(new TypeAryKlassPtr(ptr, elem, k, offset, not_flat, not_null_free, null_free))->hashcons();\n@@ -5710,1 +6276,1 @@\n-const TypeAryKlassPtr *TypeAryKlassPtr::make(PTR ptr, ciKlass* klass, int offset) {\n+const TypeAryKlassPtr* TypeAryKlassPtr::make(PTR ptr, ciKlass* klass, Offset offset, bool not_flat, bool not_null_free, bool null_free) {\n@@ -5714,2 +6280,10 @@\n-    const TypeKlassPtr *etype = TypeKlassPtr::make(eklass)->cast_to_exactness(false);\n-    return TypeAryKlassPtr::make(ptr, etype, NULL, offset);\n+    const TypeKlassPtr* etype = TypeKlassPtr::make(eklass)->cast_to_exactness(false);\n+\n+    \/\/ Even if MyValue is exact, [LMyValue is not exact due to [QMyValue <: [LMyValue.\n+    if (etype->klass_is_exact() && etype->isa_instklassptr() && etype->is_instklassptr()->klass()->is_inlinetype() && !null_free) {\n+      etype = TypeInstKlassPtr::make(NotNull, etype->is_instklassptr()->klass(), Offset(etype->is_instklassptr()->offset()), etype->is_instklassptr()->flatten_array());\n+    }\n+\n+    const TypeAryKlassPtr* res = TypeAryKlassPtr::make(ptr, etype, NULL, offset, not_flat, not_null_free, null_free);\n+    assert(res->klass() == klass, \"\");\n+    return res;\n@@ -5719,1 +6293,5 @@\n-    return TypeAryKlassPtr::make(ptr, etype, klass, offset);\n+    return TypeAryKlassPtr::make(ptr, etype, klass, offset, not_flat, not_null_free, null_free);\n+  } else if (klass->is_flat_array_klass()) {\n+    ciKlass* eklass = klass->as_flat_array_klass()->element_klass();\n+    const TypeKlassPtr* etype = TypeKlassPtr::make(eklass);\n+    return TypeAryKlassPtr::make(ptr, etype, klass, offset, not_flat, not_null_free, null_free);\n@@ -5726,0 +6304,11 @@\n+const TypeAryKlassPtr* TypeAryKlassPtr::make(PTR ptr, ciKlass* k, Offset offset) {\n+  bool null_free = k->as_array_klass()->is_elem_null_free();\n+  bool not_null_free = (ptr == Constant) ? !null_free : !k->is_flat_array_klass() && (k->is_type_array_klass() || !k->as_array_klass()->element_klass()->can_be_inline_klass(false));\n+\n+  bool not_flat = !UseFlatArray || not_null_free || (k->as_array_klass()->element_klass() != NULL &&\n+                                                     k->as_array_klass()->element_klass()->is_inlinetype() &&\n+                                                     !k->as_array_klass()->element_klass()->flatten_array());\n+\n+  return TypeAryKlassPtr::make(ptr, k, offset, not_flat, not_null_free, null_free);\n+}\n+\n@@ -5727,1 +6316,1 @@\n-  return TypeAryKlassPtr::make(Constant, klass, 0);\n+  return TypeAryKlassPtr::make(Constant, klass, Offset(0));\n@@ -5736,0 +6325,3 @@\n+    _not_flat == p->_not_flat &&\n+    _not_null_free == p->_not_null_free &&\n+    _null_free == p->_null_free &&\n@@ -5750,1 +6342,0 @@\n-  const TypeInstPtr *tinst;\n@@ -5758,3 +6349,9 @@\n-  if ((tinst = el->isa_instptr()) != NULL) {\n-    \/\/ Compute array klass from element klass\n-    k_ary = ciObjArrayKlass::make(tinst->klass());\n+  if (el->isa_instptr()) {\n+    \/\/ Compute object array klass from element klass\n+    bool null_free = el->is_inlinetypeptr() && el->isa_instptr()->ptr() != TypePtr::TopPTR && !el->isa_instptr()->maybe_null();\n+    k_ary = ciArrayKlass::make(el->is_oopptr()->klass(), null_free);\n+  } else if (el->isa_inlinetype()) {\n+    \/\/ If element type is TypeInlineType::BOTTOM, inline_klass() will be null.\n+    if (el->inline_klass() != NULL) {\n+      k_ary = ciArrayKlass::make(el->inline_klass(), \/* null_free *\/ true);\n+    }\n@@ -5825,2 +6422,2 @@\n-        _offset != 0 && _offset != arrayOopDesc::length_offset_in_bytes() &&\n-        _offset != arrayOopDesc::klass_offset_in_bytes()) {\n+        offset() != 0 && offset() != arrayOopDesc::length_offset_in_bytes() &&\n+        offset() != arrayOopDesc::klass_offset_in_bytes()) {\n@@ -5839,1 +6436,1 @@\n-    k = ciObjArrayKlass::make(k);\n+    k = ciArrayKlass::make(k, is_null_free());\n@@ -5859,1 +6456,1 @@\n-  return make(_ptr, elem(), klass(), xadd_offset(offset));\n+  return make(_ptr, elem(), klass(), xadd_offset(offset), is_not_flat(), is_not_null_free(), _null_free);\n@@ -5863,1 +6460,1 @@\n-  return make(_ptr, elem(), klass(), offset);\n+  return make(_ptr, elem(), klass(), Offset(offset), is_not_flat(), is_not_null_free(), _null_free);\n@@ -5870,1 +6467,1 @@\n-  return make(ptr, elem(), _klass, _offset);\n+  return make(ptr, elem(), _klass, _offset, is_not_flat(), is_not_null_free(), _null_free);\n@@ -5884,1 +6481,1 @@\n-  if (must_be_exact()) return this;  \/\/ cannot clear xk\n+  if (must_be_exact() && !klass_is_exact) return this;  \/\/ cannot clear xk\n@@ -5890,1 +6487,15 @@\n-  return make(klass_is_exact ? Constant : NotNull, elem, k, _offset);\n+  bool not_flat = is_not_flat();\n+  bool not_null_free = is_not_null_free();\n+  if (k != NULL && k->is_obj_array_klass()) {\n+    if (klass_is_exact) {\n+      \/\/ An object array can't be flat or null-free if the klass is exact\n+      not_flat = true;\n+      not_null_free = true;\n+    } else {\n+      \/\/ Klass is not exact (anymore), re-compute null-free\/flat properties\n+      const TypeOopPtr* exact_etype = TypeOopPtr::make_from_klass_unique(k->as_array_klass()->element_klass());\n+      not_null_free = !exact_etype->can_be_inline_type();\n+      not_flat = !UseFlatArray || not_null_free || (exact_etype->is_inlinetypeptr() && !exact_etype->inline_klass()->flatten_array());\n+    }\n+  }\n+  return make(klass_is_exact ? Constant : NotNull, elem, k, _offset, not_flat, not_null_free, _null_free);\n@@ -5899,0 +6510,1 @@\n+  assert(k != NULL, \"klass should not be NULL\");\n@@ -5907,1 +6519,10 @@\n-  return TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(el, TypeInt::POS), k, xk, 0);\n+  bool null_free = _null_free;\n+  if (null_free && el->isa_ptr()) {\n+    el = el->is_ptr()->join_speculative(TypePtr::NOTNULL);\n+  }\n+  bool not_flat = is_not_flat();\n+  bool not_null_free = is_not_null_free();\n+  if (is_flat()) {\n+    el = TypeInlineType::make(el->inline_klass());\n+  }\n+  return TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(el, TypeInt::POS, false, not_flat, not_null_free), k, xk, Offset(0));\n@@ -5941,1 +6562,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5949,1 +6570,1 @@\n-      return make( ptr, _elem, klass(), offset );\n+      return make(ptr, _elem, klass(), offset, is_not_flat(), is_not_null_free(), _null_free);\n@@ -5982,3 +6603,2 @@\n-    int off = meet_offset(tap->offset());\n-    const Type* elem = _elem->meet(tap->_elem);\n-\n+    Offset off = meet_offset(tap->offset());\n+    const Type* res_elem = NULL;\n@@ -5988,1 +6608,7 @@\n-    meet_aryptr(ptr, elem, this->klass(), tap->klass(), this->klass_is_exact(), tap->klass_is_exact(), this->ptr(), tap->ptr(), res_klass, res_xk);\n+    bool res_not_flat = false;\n+    bool res_not_null_free = false;\n+    MeetResult res = meet_aryptr(ptr, _elem, tap->_elem, this->klass(), tap->klass(),\n+                                 this->klass_is_exact(), tap->klass_is_exact(),\n+                                 this->ptr(), tap->ptr(), this->is_not_flat(), tap->is_not_flat(),\n+                                 this->is_not_null_free(), tap->is_not_null_free(),\n+                                 res_elem, res_klass, res_xk, res_not_flat, res_not_null_free);\n@@ -5990,1 +6616,11 @@\n-    return make(ptr, elem, res_klass, off);\n+    bool null_free = meet_null_free(tap->_null_free);\n+    if (res == NOT_SUBTYPE) {\n+      null_free = false;\n+    } else if (res == SUBTYPE) {\n+      if (above_centerline(tap->ptr()) && !above_centerline(this->ptr())) {\n+        null_free = _null_free;\n+      } else if (above_centerline(this->ptr()) && !above_centerline(tap->ptr())) {\n+        null_free = tap->_null_free;\n+      }\n+    }\n+    return make(ptr, res_elem, res_klass, off, res_not_flat, res_not_null_free, null_free);\n@@ -5994,1 +6630,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -6004,1 +6640,1 @@\n-        return TypeAryKlassPtr::make(ptr, _elem, _klass, offset);\n+        return TypeAryKlassPtr::make(ptr, _elem, _klass, offset, is_not_flat(), is_not_null_free(), _null_free);\n@@ -6008,1 +6644,1 @@\n-        return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), offset);\n+        return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), offset, false);\n@@ -6022,1 +6658,1 @@\n-          return make(ptr, _elem, _klass, offset);\n+          return make(ptr, _elem, _klass, offset, is_not_flat(), is_not_null_free(), _null_free);\n@@ -6029,1 +6665,1 @@\n-      return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), offset);\n+      return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), offset, false);\n@@ -6033,0 +6669,12 @@\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      return TypeInstKlassPtr::BOTTOM;\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), Offset(0));\n+    }\n+  }\n@@ -6055,0 +6703,3 @@\n+    if (other->is_null_free() && !is_null_free()) {\n+      return false; \/\/ [LMyValue is not a subtype of [QMyValue\n+    }\n@@ -6107,1 +6758,1 @@\n-  return new TypeAryKlassPtr(dual_ptr(), elem()->dual(), klass(), dual_offset());\n+  return new TypeAryKlassPtr(dual_ptr(), elem()->dual(), klass(), dual_offset(), !is_not_flat(), !is_not_null_free(), dual_null_free());\n@@ -6117,1 +6768,1 @@\n-    k = ciObjArrayKlass::make(k);\n+    k = ciArrayKlass::make(k, _null_free);\n@@ -6129,4 +6780,18 @@\n-  if (elem()->isa_klassptr()) {\n-    k = elem()->is_klassptr()->klass();\n-    if (k != NULL) {\n-      k = ciObjArrayKlass::make(k);\n+  const Type* el = elem();\n+  if (el->isa_instklassptr()) {\n+    \/\/ Compute object array klass from element klass\n+    bool null_free = el->is_instklassptr()->klass()->is_inlinetype() && el->isa_instklassptr()->ptr() != TypePtr::TopPTR && (_null_free != 0);\n+    k = ciArrayKlass::make(el->is_klassptr()->klass(), null_free);\n+    ((TypeAryKlassPtr*)this)->_klass = k;\n+  } else if (el->isa_inlinetype()) {\n+    \/\/ If element type is TypeInlineType::BOTTOM, inline_klass() will be null.\n+    if (el->inline_klass() != NULL) {\n+      k = ciArrayKlass::make(el->inline_klass(), \/* null_free *\/ true);\n+      ((TypeAryKlassPtr*)this)->_klass = k;\n+    }\n+  } else if (el->isa_aryklassptr() != NULL) {\n+    \/\/ Compute array klass from element klass\n+    ciKlass* k_elem = el->is_aryklassptr()->klass();\n+    \/\/ If element type is something like bottom[], k_elem will be null.\n+    if (k_elem != NULL) {\n+      k = ciObjArrayKlass::make(k_elem);\n@@ -6153,0 +6818,4 @@\n+      if (_elem->isa_inlinetype()) {\n+        const char *name = _elem->is_inlinetype()->inline_klass()->name()->as_utf8();\n+        st->print(\"precise %s: \" INTPTR_FORMAT \" \", name, p2i(klass()));\n+      }\n@@ -6166,5 +6835,5 @@\n-\n-  if( _offset ) {               \/\/ Dump offset, if any\n-    if( _offset == OffsetBot )      { st->print(\"+any\"); }\n-    else if( _offset == OffsetTop ) { st->print(\"+unknown\"); }\n-    else                            { st->print(\"+%d\", _offset); }\n+  if (Verbose) {\n+    if (is_flat()) st->print(\":flat\");\n+    if (_not_flat) st->print(\":not flat\");\n+    if (_not_null_free) st->print(\":not null free\");\n+    if (_null_free) st->print(\":null free\");\n@@ -6173,0 +6842,2 @@\n+  _offset.dump2(st);\n+\n@@ -6191,2 +6862,14 @@\n-const TypeFunc *TypeFunc::make( const TypeTuple *domain, const TypeTuple *range ) {\n-  return (TypeFunc*)(new TypeFunc(domain,range))->hashcons();\n+const TypeFunc *TypeFunc::make(const TypeTuple *domain_sig, const TypeTuple* domain_cc,\n+                               const TypeTuple *range_sig, const TypeTuple *range_cc) {\n+  return (TypeFunc*)(new TypeFunc(domain_sig, domain_cc, range_sig, range_cc))->hashcons();\n+}\n+\n+const TypeFunc *TypeFunc::make(const TypeTuple *domain, const TypeTuple *range) {\n+  return make(domain, domain, range, range);\n+}\n+\n+\/\/------------------------------osr_domain-----------------------------\n+const TypeTuple* osr_domain() {\n+  const Type **fields = TypeTuple::fields(2);\n+  fields[TypeFunc::Parms+0] = TypeRawPtr::BOTTOM;  \/\/ address of osr buffer\n+  return TypeTuple::make(TypeFunc::Parms+1, fields);\n@@ -6196,1 +6879,1 @@\n-const TypeFunc *TypeFunc::make(ciMethod* method) {\n+const TypeFunc* TypeFunc::make(ciMethod* method, bool is_osr_compilation) {\n@@ -6198,7 +6881,20 @@\n-  const TypeFunc* tf = C->last_tf(method); \/\/ check cache\n-  if (tf != NULL)  return tf;  \/\/ The hit rate here is almost 50%.\n-  const TypeTuple *domain;\n-  if (method->is_static()) {\n-    domain = TypeTuple::make_domain(NULL, method->signature());\n-  } else {\n-    domain = TypeTuple::make_domain(method->holder(), method->signature());\n+  const TypeFunc* tf = NULL;\n+  if (!is_osr_compilation) {\n+    tf = C->last_tf(method); \/\/ check cache\n+    if (tf != NULL)  return tf;  \/\/ The hit rate here is almost 50%.\n+  }\n+  \/\/ Inline types are not passed\/returned by reference, instead each field of\n+  \/\/ the inline type is passed\/returned as an argument. We maintain two views of\n+  \/\/ the argument\/return list here: one based on the signature (with an inline\n+  \/\/ type argument\/return as a single slot), one based on the actual calling\n+  \/\/ convention (with an inline type argument\/return as a list of its fields).\n+  bool has_scalar_args = method->has_scalarized_args() && !is_osr_compilation;\n+  const TypeTuple* domain_sig = is_osr_compilation ? osr_domain() : TypeTuple::make_domain(method, false);\n+  const TypeTuple* domain_cc = has_scalar_args ? TypeTuple::make_domain(method, true) : domain_sig;\n+  ciSignature* sig = method->signature();\n+  bool has_scalar_ret = sig->return_type()->is_inlinetype() && sig->return_type()->as_inline_klass()->can_be_returned_as_fields();\n+  const TypeTuple* range_sig = TypeTuple::make_range(sig, false);\n+  const TypeTuple* range_cc = has_scalar_ret ? TypeTuple::make_range(sig, true) : range_sig;\n+  tf = TypeFunc::make(domain_sig, domain_cc, range_sig, range_cc);\n+  if (!is_osr_compilation) {\n+    C->set_last_tf(method, tf);  \/\/ fill cache\n@@ -6206,3 +6902,0 @@\n-  const TypeTuple *range  = TypeTuple::make_range(method->signature());\n-  tf = TypeFunc::make(domain, range);\n-  C->set_last_tf(method, tf);  \/\/ fill cache\n@@ -6243,2 +6936,4 @@\n-  return _domain == a->_domain &&\n-    _range == a->_range;\n+  return _domain_sig == a->_domain_sig &&\n+    _domain_cc == a->_domain_cc &&\n+    _range_sig == a->_range_sig &&\n+    _range_cc == a->_range_cc;\n@@ -6250,1 +6945,1 @@\n-  return (intptr_t)_domain + (intptr_t)_range;\n+  return (intptr_t)_domain_sig + (intptr_t)_domain_cc + (intptr_t)_range_sig + (intptr_t)_range_cc;\n@@ -6257,1 +6952,1 @@\n-  if( _range->cnt() <= Parms )\n+  if( _range_sig->cnt() <= Parms )\n@@ -6261,2 +6956,2 @@\n-    for (i = Parms; i < _range->cnt()-1; i++) {\n-      _range->field_at(i)->dump2(d,depth,st);\n+    for (i = Parms; i < _range_sig->cnt()-1; i++) {\n+      _range_sig->field_at(i)->dump2(d,depth,st);\n@@ -6265,1 +6960,1 @@\n-    _range->field_at(i)->dump2(d,depth,st);\n+    _range_sig->field_at(i)->dump2(d,depth,st);\n@@ -6274,3 +6969,3 @@\n-  if (Parms < _domain->cnt())\n-    _domain->field_at(Parms)->dump2(d,depth-1,st);\n-  for (uint i = Parms+1; i < _domain->cnt(); i++) {\n+  if (Parms < _domain_sig->cnt())\n+    _domain_sig->field_at(Parms)->dump2(d,depth-1,st);\n+  for (uint i = Parms+1; i < _domain_sig->cnt(); i++) {\n@@ -6278,1 +6973,1 @@\n-    _domain->field_at(i)->dump2(d,depth-1,st);\n+    _domain_sig->field_at(i)->dump2(d,depth-1,st);\n@@ -6298,1 +6993,1 @@\n-  if (range()->cnt() == TypeFunc::Parms) {\n+  if (range_sig()->cnt() == TypeFunc::Parms) {\n@@ -6301,1 +6996,1 @@\n-  return range()->field_at(TypeFunc::Parms)->basic_type();\n+  return range_sig()->field_at(TypeFunc::Parms)->basic_type();\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":1043,"deletions":348,"binary":false,"changes":1391,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n@@ -56,0 +58,1 @@\n+class   TypeInlineType;\n@@ -103,0 +106,1 @@\n+    InlineType,                 \/\/ Inline type\n@@ -136,0 +140,24 @@\n+  class Offset {\n+  private:\n+    int _offset;\n+\n+  public:\n+    explicit Offset(int offset) : _offset(offset) {}\n+\n+    const Offset meet(const Offset other) const;\n+    const Offset dual() const;\n+    const Offset add(intptr_t offset) const;\n+    bool operator==(const Offset& other) const {\n+      return _offset == other._offset;\n+    }\n+    bool operator!=(const Offset& other) const {\n+      return _offset != other._offset;\n+    }\n+    int get() const { return _offset; }\n+\n+    void dump2(outputStream *st) const;\n+\n+    static const Offset top;\n+    static const Offset bottom;\n+  };\n+\n@@ -320,0 +348,2 @@\n+  const TypeInlineType* isa_inlinetype() const;  \/\/ Returns NULL if not Inline Type\n+  const TypeInlineType* is_inlinetype() const;   \/\/ Inline Type\n@@ -333,0 +363,3 @@\n+  bool is_inlinetypeptr() const;\n+  virtual ciInlineKlass* inline_klass() const;\n+\n@@ -727,2 +760,2 @@\n-  static const TypeTuple *make_range(ciSignature *sig);\n-  static const TypeTuple *make_domain(ciInstanceKlass* recv, ciSignature *sig);\n+  static const TypeTuple *make_range(ciSignature* sig, bool ret_vt_fields = false);\n+  static const TypeTuple *make_domain(ciMethod* method, bool vt_fields_as_args = false);\n@@ -757,2 +790,2 @@\n-  TypeAry(const Type* elem, const TypeInt* size, bool stable) : Type(Array),\n-      _elem(elem), _size(size), _stable(stable) {}\n+  TypeAry(const Type* elem, const TypeInt* size, bool stable, bool not_flat, bool not_null_free) : Type(Array),\n+      _elem(elem), _size(size), _stable(stable), _not_flat(not_flat), _not_null_free(not_null_free) {}\n@@ -769,0 +802,5 @@\n+\n+  \/\/ Inline type array properties\n+  const bool _not_flat;         \/\/ Array is never flattened\n+  const bool _not_null_free;    \/\/ Array is never null-free\n+\n@@ -772,1 +810,2 @@\n-  static const TypeAry* make(const Type* elem, const TypeInt* size, bool stable = false);\n+  static const TypeAry* make(const Type* elem, const TypeInt* size, bool stable = false,\n+                             bool not_flat = false, bool not_null_free = false);\n@@ -779,0 +818,1 @@\n+\n@@ -788,0 +828,39 @@\n+\n+\/\/------------------------------TypeValue---------------------------------------\n+\/\/ Class of Inline Type Types\n+class TypeInlineType : public Type {\n+private:\n+  ciInlineKlass* _vk;\n+  bool _larval;\n+\n+protected:\n+  TypeInlineType(ciInlineKlass* vk, bool larval)\n+    : Type(InlineType),\n+      _vk(vk), _larval(larval) {\n+  }\n+\n+public:\n+  static const TypeInlineType* make(ciInlineKlass* vk, bool larval = false);\n+  virtual ciInlineKlass* inline_klass() const { return _vk; }\n+  bool larval() const { return _larval; }\n+\n+  virtual bool eq(const Type* t) const;\n+  virtual int  hash() const;             \/\/ Type specific hashing\n+  virtual bool singleton(void) const;    \/\/ TRUE if type is a singleton\n+  virtual bool empty(void) const;        \/\/ TRUE if type is vacuous\n+\n+  virtual const Type* xmeet(const Type* t) const;\n+  virtual const Type* xdual() const;     \/\/ Compute dual right now.\n+\n+  virtual bool would_improve_type(ciKlass* exact_kls, int inline_depth) const { return false; }\n+  virtual bool would_improve_ptr(ProfilePtrKind ptr_kind) const { return false; }\n+\n+  virtual bool maybe_null() const { return false; }\n+\n+  static const TypeInlineType* BOTTOM;\n+\n+#ifndef PRODUCT\n+  virtual void dump2(Dict &d, uint, outputStream* st) const; \/\/ Specialized per-Type dumping\n+#endif\n+};\n+\n@@ -891,1 +970,1 @@\n-  TypePtr(TYPES t, PTR ptr, int offset,\n+  TypePtr(TYPES t, PTR ptr, Offset offset,\n@@ -948,3 +1027,7 @@\n-               PTR tinst_ptr, ciKlass*&res_klass, bool &res_xk);\n-  static MeetResult\n-  meet_aryptr(PTR& ptr, const Type*& elem, ciKlass* this_klass, ciKlass* tap_klass, bool this_xk, bool tap_xk, PTR this_ptr, PTR tap_ptr, ciKlass*& res_klass, bool& res_xk);\n+               PTR tinst_ptr, bool this_flatten_array, bool tinst_flatten_array, ciKlass*&res_klass, bool &res_xk,\n+               bool& res_flatten_array);\n+\n+  static MeetResult meet_aryptr(PTR &ptr, const Type* this_elem, const Type* tap_elem, ciKlass* this_klass, ciKlass* tap_klass,\n+                                bool this_xk, bool tap_xk, PTR this_ptr, PTR tap_ptr, bool this_not_flat, bool tap_not_flat,\n+                                bool this_not_null_free, bool tap_not_null_free, const Type*& res_elem, ciKlass*&res_klass,\n+                                bool &res_xk, bool &res_not_flat, bool &res_not_null_free);\n@@ -953,1 +1036,1 @@\n-  const int _offset;            \/\/ Offset into oop, with TOP & BOT\n+  const Offset _offset;         \/\/ Offset into oop, with TOP & BOT\n@@ -956,1 +1039,1 @@\n-  const int offset() const { return _offset; }\n+  const int offset() const { return _offset.get(); }\n@@ -959,1 +1042,1 @@\n-  static const TypePtr *make(TYPES t, PTR ptr, int offset,\n+  static const TypePtr* make(TYPES t, PTR ptr, Offset offset,\n@@ -968,1 +1051,1 @@\n-  int xadd_offset( intptr_t offset ) const;\n+  Type::Offset xadd_offset(intptr_t offset) const;\n@@ -971,0 +1054,1 @@\n+  virtual const int flattened_offset() const { return offset(); }\n@@ -978,2 +1062,2 @@\n-  int meet_offset( int offset ) const;\n-  int dual_offset( ) const;\n+  Offset meet_offset(int offset) const;\n+  Offset dual_offset() const;\n@@ -1007,0 +1091,8 @@\n+  virtual bool can_be_inline_type() const { return false; }\n+  virtual bool flatten_array()      const { return false; }\n+  virtual bool not_flatten_array()  const { return false; }\n+  virtual bool is_flat()            const { return false; }\n+  virtual bool is_not_flat()        const { return false; }\n+  virtual bool is_null_free()       const { return false; }\n+  virtual bool is_not_null_free()   const { return false; }\n+\n@@ -1024,1 +1116,1 @@\n-  TypeRawPtr( PTR ptr, address bits ) : TypePtr(RawPtr,ptr,0), _bits(bits){}\n+  TypeRawPtr(PTR ptr, address bits) : TypePtr(RawPtr,ptr,Offset(0)), _bits(bits){}\n@@ -1060,2 +1152,2 @@\n-  TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset, int instance_id,\n-             const TypePtr* speculative, int inline_depth);\n+  TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset, Offset field_offset,\n+             int instance_id, const TypePtr* speculative, int inline_depth);\n@@ -1096,1 +1188,1 @@\n-  virtual ciKlass* klass() const { return _klass;     }\n+  virtual ciKlass* klass() const { return _klass; }\n@@ -1135,1 +1227,1 @@\n-  static const TypeOopPtr* make(PTR ptr, int offset, int instance_id,\n+  static const TypeOopPtr* make(PTR ptr, Offset offset, int instance_id,\n@@ -1154,1 +1246,4 @@\n-  bool is_known_instance_field() const { return is_known_instance() && _offset >= 0; }\n+  bool is_known_instance_field() const { return is_known_instance() && _offset.get() >= 0; }\n+\n+  virtual bool can_be_inline_type() const { return (_klass == NULL || _klass->can_be_inline_klass(_klass_is_exact)); }\n+  bool can_be_inline_array() const { return (_klass == NULL || _klass->can_be_inline_array_klass()); }\n@@ -1193,2 +1288,3 @@\n-  TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset, int instance_id,\n-              const TypePtr* speculative, int inline_depth);\n+  TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset,\n+              bool flatten_array, int instance_id, const TypePtr* speculative,\n+              int inline_depth);\n@@ -1198,0 +1294,1 @@\n+  bool _flatten_array;     \/\/ Type is flat in arrays\n@@ -1216,1 +1313,1 @@\n-    return make(TypePtr::Constant, o->klass(), true, o, 0, InstanceBot);\n+    return make(TypePtr::Constant, o->klass(), true, o, Offset(0));\n@@ -1219,2 +1316,2 @@\n-  static const TypeInstPtr *make(ciObject* o, int offset) {\n-    return make(TypePtr::Constant, o->klass(), true, o, offset, InstanceBot);\n+  static const TypeInstPtr* make(ciObject* o, Offset offset) {\n+    return make(TypePtr::Constant, o->klass(), true, o, offset);\n@@ -1225,1 +1322,1 @@\n-    return make(ptr, klass, false, NULL, 0, InstanceBot);\n+    return make(ptr, klass, false, NULL, Offset(0));\n@@ -1230,1 +1327,1 @@\n-    return make(ptr, klass, true, NULL, 0, InstanceBot);\n+    return make(ptr, klass, true, NULL, Offset(0));\n@@ -1234,2 +1331,2 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* klass, int offset) {\n-    return make(ptr, klass, false, NULL, offset, InstanceBot);\n+  static const TypeInstPtr *make(PTR ptr, ciKlass* klass, Offset offset) {\n+    return make(ptr, klass, false, NULL, offset);\n@@ -1239,1 +1336,2 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset,\n+  static const TypeInstPtr* make(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset,\n+                                 bool flatten_array = false,\n@@ -1250,1 +1348,1 @@\n-  ciType* java_mirror_type() const;\n+  ciType* java_mirror_type(bool* is_val_mirror = NULL) const;\n@@ -1266,0 +1364,4 @@\n+  virtual const TypeInstPtr* cast_to_flatten_array() const;\n+  virtual bool flatten_array() const { return _flatten_array; }\n+  virtual bool not_flatten_array() const { return !can_be_inline_type() || (_klass->is_inlinetype() && !flatten_array()); }\n+\n@@ -1289,4 +1391,4 @@\n-  TypeAryPtr( PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk,\n-              int offset, int instance_id, bool is_autobox_cache,\n-              const TypePtr* speculative, int inline_depth)\n-    : TypeOopPtr(AryPtr,ptr,k,xk,o,offset, instance_id, speculative, inline_depth),\n+  TypeAryPtr(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk,\n+             Offset offset, Offset field_offset, int instance_id, bool is_autobox_cache,\n+             const TypePtr* speculative, int inline_depth)\n+    : TypeOopPtr(AryPtr, ptr, k, xk, o, offset, field_offset, instance_id, speculative, inline_depth),\n@@ -1294,1 +1396,2 @@\n-    _is_autobox_cache(is_autobox_cache)\n+    _is_autobox_cache(is_autobox_cache),\n+    _field_offset(field_offset)\n@@ -1317,0 +1420,6 @@\n+  \/\/ For flattened inline type arrays, each field of the inline type in\n+  \/\/ the array has its own memory slice so we need to keep track of\n+  \/\/ which field is accessed\n+  const Offset _field_offset;\n+  Offset meet_field_offset(const Type::Offset offset) const;\n+  Offset dual_field_offset() const;\n@@ -1340,0 +1449,6 @@\n+  \/\/ Inline type array properties\n+  bool is_flat()          const { return _ary->_elem->isa_inlinetype() != NULL; }\n+  bool is_not_flat()      const { return _ary->_not_flat; }\n+  bool is_null_free()     const { return is_flat() || (_ary->_elem->make_ptr() != NULL && _ary->_elem->make_ptr()->is_inlinetypeptr() && !_ary->_elem->make_ptr()->maybe_null()); }\n+  bool is_not_null_free() const { return _ary->_not_null_free; }\n+\n@@ -1342,1 +1457,2 @@\n-  static const TypeAryPtr *make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+  static const TypeAryPtr* make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset,\n+                                Offset field_offset = Offset::bottom,\n@@ -1347,1 +1463,2 @@\n-  static const TypeAryPtr *make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+  static const TypeAryPtr* make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset,\n+                                Offset field_offset = Offset::bottom,\n@@ -1350,1 +1467,2 @@\n-                                int inline_depth = InlineDepthBottom, bool is_autobox_cache = false);\n+                                int inline_depth = InlineDepthBottom,\n+                                bool is_autobox_cache = false);\n@@ -1369,0 +1487,1 @@\n+  virtual const Type* cleanup_speculative() const;\n@@ -1376,0 +1495,8 @@\n+  \/\/ Inline type array properties\n+  const TypeAryPtr* cast_to_not_flat(bool not_flat = true) const;\n+  const TypeAryPtr* cast_to_not_null_free(bool not_null_free = true) const;\n+  const TypeAryPtr* update_properties(const TypeAryPtr* new_type) const;\n+  jint flat_layout_helper() const;\n+  int flat_elem_size() const;\n+  int flat_log_elem_size() const;\n+\n@@ -1381,1 +1508,8 @@\n-  static jint max_array_length(BasicType etype) ;\n+  static jint max_array_length(BasicType etype);\n+\n+  const int flattened_offset() const;\n+  const Offset field_offset() const { return _field_offset; }\n+  const TypeAryPtr* with_field_offset(int offset) const;\n+  const TypePtr* add_field_offset_and_offset(intptr_t offset) const;\n+\n+  virtual bool can_be_inline_type() const { return false; }\n@@ -1395,0 +1529,1 @@\n+  static const TypeAryPtr *INLINES;\n@@ -1415,1 +1550,1 @@\n-  TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset);\n+  TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset);\n@@ -1427,1 +1562,1 @@\n-  static const TypeMetadataPtr* make(PTR ptr, ciMetadata* m, int offset);\n+  static const TypeMetadataPtr* make(PTR ptr, ciMetadata* m, Offset offset);\n@@ -1457,1 +1592,1 @@\n-  TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, int offset);\n+  TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, Offset offset);\n@@ -1492,1 +1627,1 @@\n-  static const TypeKlassPtr *make(PTR ptr, ciKlass* klass, int offset);\n+  static const TypeKlassPtr* make(PTR ptr, ciKlass* klass, Offset offset);\n@@ -1511,3 +1646,1 @@\n-#ifndef PRODUCT\n-  virtual void dump2( Dict &d, uint depth, outputStream *st ) const; \/\/ Specialized per-Type dumping\n-#endif\n+  bool can_be_inline_array() const { return (_klass == NULL || _klass->can_be_inline_array_klass()); }\n@@ -1519,2 +1652,2 @@\n-  TypeInstKlassPtr(PTR ptr, ciKlass* klass, int offset)\n-    : TypeKlassPtr(InstKlassPtr, ptr, klass, offset) {\n+  TypeInstKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flatten_array)\n+    : TypeKlassPtr(InstKlassPtr, ptr, klass, offset), _flatten_array(flatten_array) {\n@@ -1525,0 +1658,2 @@\n+  const bool _flatten_array; \/\/ Type is flat in arrays\n+\n@@ -1538,0 +1673,2 @@\n+  virtual bool can_be_inline_type() const { return (_klass == NULL || _klass->can_be_inline_klass(klass_is_exact())); }\n+\n@@ -1539,1 +1676,1 @@\n-    return make(TypePtr::Constant, k, 0);\n+    return make(TypePtr::Constant, k, Offset(0), false);\n@@ -1541,1 +1678,1 @@\n-  static const TypeInstKlassPtr *make(PTR ptr, ciKlass* k, int offset);\n+  static const TypeInstKlassPtr *make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array = false);\n@@ -1559,0 +1696,3 @@\n+  virtual bool flatten_array() const { return _flatten_array; }\n+  virtual bool not_flatten_array() const { return !_klass->can_be_inline_klass() || (_klass->is_inlinetype() && !flatten_array()); }\n+\n@@ -1562,0 +1702,4 @@\n+\n+#ifndef PRODUCT\n+  virtual void dump2( Dict &d, uint depth, outputStream *st ) const; \/\/ Specialized per-Type dumping\n+#endif\n@@ -1568,0 +1712,3 @@\n+  const bool _not_flat;      \/\/ Array is never flattened\n+  const bool _not_null_free; \/\/ Array is never null-free\n+  const bool _null_free;\n@@ -1569,2 +1716,2 @@\n-  TypeAryKlassPtr(PTR ptr, const Type *elem, ciKlass* klass, int offset)\n-    : TypeKlassPtr(AryKlassPtr, ptr, klass, offset), _elem(elem) {\n+  TypeAryKlassPtr(PTR ptr, const Type *elem, ciKlass* klass, Offset offset, bool not_flat, int not_null_free, bool null_free)\n+    : TypeKlassPtr(AryKlassPtr, ptr, klass, offset), _elem(elem), _not_flat(not_flat), _not_null_free(not_null_free), _null_free(null_free) {\n@@ -1578,0 +1725,8 @@\n+  bool dual_null_free() const {\n+    return _null_free;\n+  }\n+\n+  bool meet_null_free(bool other) const {\n+    return _null_free && other;\n+  }\n+\n@@ -1583,1 +1738,1 @@\n-  static const TypeAryKlassPtr *make(PTR ptr, ciKlass* k, int offset);\n+  static const TypeAryKlassPtr* make(PTR ptr, ciKlass* k, Offset offset, bool not_flat, bool not_null_free, bool null_free);\n@@ -1591,1 +1746,2 @@\n-  static const TypeAryKlassPtr *make(PTR ptr, const Type *elem, ciKlass* k, int offset);\n+  static const TypeAryKlassPtr* make(PTR ptr, const Type* elem, ciKlass* k, Offset offset, bool not_flat, bool not_null_free, bool null_free);\n+  static const TypeAryKlassPtr* make(PTR ptr, ciKlass* k, Offset offset);\n@@ -1616,0 +1772,5 @@\n+  bool is_flat()          const { return klass() != NULL && klass()->is_flat_array_klass(); }\n+  bool is_not_flat()      const { return _not_flat; }\n+  bool is_null_free()     const { return _null_free; }\n+  bool is_not_null_free() const { return _not_null_free; }\n+\n@@ -1749,1 +1910,2 @@\n-  TypeFunc( const TypeTuple *domain, const TypeTuple *range ) : Type(Function),  _domain(domain), _range(range) {}\n+  TypeFunc(const TypeTuple *domain_sig, const TypeTuple *domain_cc, const TypeTuple *range_sig, const TypeTuple *range_cc)\n+    : Type(Function), _domain_sig(domain_sig), _domain_cc(domain_cc), _range_sig(range_sig), _range_cc(range_cc) {}\n@@ -1755,2 +1917,13 @@\n-  const TypeTuple* const _domain;     \/\/ Domain of inputs\n-  const TypeTuple* const _range;      \/\/ Range of results\n+  \/\/ Domains of inputs: inline type arguments are not passed by\n+  \/\/ reference, instead each field of the inline type is passed as an\n+  \/\/ argument. We maintain 2 views of the argument list here: one\n+  \/\/ based on the signature (with an inline type argument as a single\n+  \/\/ slot), one based on the actual calling convention (with a value\n+  \/\/ type argument as a list of its fields).\n+  const TypeTuple* const _domain_sig;\n+  const TypeTuple* const _domain_cc;\n+  \/\/ Range of results. Similar to domains: an inline type result can be\n+  \/\/ returned in registers in which case range_cc lists all fields and\n+  \/\/ is the actual calling convention.\n+  const TypeTuple* const _range_sig;\n+  const TypeTuple* const _range_cc;\n@@ -1770,5 +1943,8 @@\n-  const TypeTuple* domain() const { return _domain; }\n-  const TypeTuple* range()  const { return _range; }\n-\n-  static const TypeFunc *make(ciMethod* method);\n-  static const TypeFunc *make(ciSignature signature, const Type* extra);\n+  const TypeTuple* domain_sig() const { return _domain_sig; }\n+  const TypeTuple* domain_cc()  const { return _domain_cc; }\n+  const TypeTuple* range_sig()  const { return _range_sig; }\n+  const TypeTuple* range_cc()   const { return _range_cc; }\n+\n+  static const TypeFunc* make(ciMethod* method, bool is_osr_compilation = false);\n+  static const TypeFunc *make(const TypeTuple* domain_sig, const TypeTuple* domain_cc,\n+                              const TypeTuple* range_sig, const TypeTuple* range_cc);\n@@ -1782,0 +1958,2 @@\n+  bool returns_inline_type_as_fields() const { return range_sig() != range_cc(); }\n+\n@@ -1953,0 +2131,9 @@\n+inline const TypeInlineType* Type::isa_inlinetype() const {\n+  return (_base == InlineType) ? (TypeInlineType*)this : NULL;\n+}\n+\n+inline const TypeInlineType* Type::is_inlinetype() const {\n+  assert(_base == InlineType, \"Not an inline type\");\n+  return (TypeInlineType*)this;\n+}\n+\n@@ -2037,0 +2224,9 @@\n+inline bool Type::is_inlinetypeptr() const {\n+  return isa_instptr() != NULL && is_instptr()->instance_klass()->is_inlinetype();\n+}\n+\n+inline ciInlineKlass* Type::inline_klass() const {\n+  assert(is_inlinetypeptr(), \"must be an inline type ptr\");\n+  return is_instptr()->instance_klass()->as_inline_klass();\n+}\n+\n@@ -2063,0 +2259,1 @@\n+#define CmpUXNode    CmpULNode\n@@ -2081,0 +2278,1 @@\n+#define Op_StoreX    Op_StoreL\n@@ -2109,0 +2307,1 @@\n+#define CmpUXNode    CmpUNode\n@@ -2127,0 +2326,1 @@\n+#define Op_StoreX    Op_StoreI\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":264,"deletions":64,"binary":false,"changes":328,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -616,1 +617,22 @@\n-  return handle == NULL ? 0 : ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)) ;\n+  if (handle == NULL) {\n+    return 0;\n+  }\n+  oop obj = JNIHandles::resolve_non_null(handle);\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+      JavaValue result(T_INT);\n+      JavaCallArguments args;\n+      Handle ho(THREAD, obj);\n+      args.push_oop(ho);\n+      methodHandle method(THREAD, Universe::primitive_type_hash_code_method());\n+      JavaCalls::call(&result, method, &args, THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in hashCode\", e, false);\n+        }\n+      }\n+      return result.get_jint();\n+  } else {\n+    return ObjectSynchronizer::FastHashCode(THREAD, obj);\n+  }\n@@ -668,0 +690,1 @@\n+       klass->is_inline_klass() ||\n@@ -1181,1 +1204,2 @@\n-    size = InstanceKlass::cast(klass)->local_interfaces()->length();\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    size = ik->local_interfaces()->length();\n@@ -1183,1 +1207,1 @@\n-    assert(klass->is_objArray_klass() || klass->is_typeArray_klass(), \"Illegal mirror klass\");\n+    assert(klass->is_objArray_klass() || klass->is_typeArray_klass() || klass->is_flatArray_klass(), \"Illegal mirror klass\");\n@@ -1194,1 +1218,2 @@\n-      Klass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);\n+      InstanceKlass* ik = InstanceKlass::cast(klass);\n+      Klass* k = ik->local_interfaces()->at(index);\n@@ -1796,0 +1821,2 @@\n+  bool is_ctor = (method->is_object_constructor() ||\n+                  method->is_static_init_factory());\n@@ -1797,1 +1824,1 @@\n-    return (method->is_initializer() && !method->is_static());\n+    return is_ctor;\n@@ -1799,1 +1826,3 @@\n-    return  (!method->is_initializer() && !method->is_overpass());\n+    return (!is_ctor &&\n+            !method->is_class_initializer() &&\n+            !method->is_overpass());\n@@ -1862,0 +1891,2 @@\n+        assert(method->is_object_constructor() ||\n+               method->is_static_init_factory(), \"must be\");\n@@ -2144,3 +2175,1 @@\n-  if (!m->is_initializer() || m->is_static()) {\n-    method = Reflection::new_method(m, true, CHECK_NULL);\n-  } else {\n+  if (m->is_object_constructor() || m->is_static_init_factory()) {\n@@ -2148,0 +2177,2 @@\n+  } else {\n+    method = Reflection::new_method(m, true, CHECK_NULL);\n@@ -2418,0 +2449,37 @@\n+\/\/ Arrays support \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(jboolean, JVM_ArrayIsAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == NULL) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  return ArrayKlass::cast(k)->element_access_is_atomic();\n+JVM_END\n+\n+JVM_ENTRY(jobject, JVM_ArrayEnsureAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == NULL) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  if (k->is_flatArray_klass()) {\n+    FlatArrayKlass* vk = FlatArrayKlass::cast(k);\n+    if (!vk->element_access_is_atomic()) {\n+      \/**\n+       * Need to decide how to implement:\n+       *\n+       * 1) Change to objArrayOop layout, therefore oop->klass() differs so\n+       * then \"<atomic>[Qfoo;\" klass needs to subclass \"[Qfoo;\" to pass through\n+       * \"checkcast\" & \"instanceof\"\n+       *\n+       * 2) Use extra header in the flatArrayOop to flag atomicity required and\n+       * possibly per instance lock structure. Said info, could be placed in\n+       * \"trailer\" rather than disturb the current arrayOop\n+       *\/\n+      Unimplemented();\n+    }\n+  }\n+  return array;\n+JVM_END\n+\n@@ -2580,1 +2648,1 @@\n-  return method->name() == vmSymbols::object_initializer_name();\n+  return method->is_object_constructor();\n@@ -3574,1 +3642,1 @@\n-    objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n+    objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3594,0 +3662,1 @@\n+  objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3595,1 +3664,0 @@\n-  objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":80,"deletions":12,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -2297,1 +2297,1 @@\n-  if (sig_type == JVM_SIGNATURE_CLASS) {\n+  if (sig_type == JVM_SIGNATURE_CLASS || sig_type == JVM_SIGNATURE_PRIMITIVE_OBJECT) {\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+#include \"memory\/iterator.inline.hpp\"\n@@ -61,0 +62,1 @@\n+#include \"oops\/compressedOops.inline.hpp\"\n@@ -67,0 +69,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -1861,0 +1864,87 @@\n+WB_ENTRY(jobjectArray, WB_getObjectsViaKlassOopMaps(JNIEnv* env, jobject wb, jobject thing))\n+  oop aoop = JNIHandles::resolve(thing);\n+  if (!aoop->is_instance()) {\n+    return NULL;\n+  }\n+  instanceHandle ih(THREAD, (instanceOop) aoop);\n+  InstanceKlass* klass = InstanceKlass::cast(ih->klass());\n+  if (klass->nonstatic_oop_map_count() == 0) {\n+    return NULL;\n+  }\n+  const OopMapBlock* map = klass->start_of_nonstatic_oop_maps();\n+  const OopMapBlock* const end = map + klass->nonstatic_oop_map_count();\n+  int oop_count = 0;\n+  while (map < end) {\n+    oop_count += map->count();\n+    map++;\n+  }\n+\n+  objArrayHandle result_array =\n+      oopFactory::new_objArray_handle(vmClasses::Object_klass(), oop_count, CHECK_NULL);\n+  map = klass->start_of_nonstatic_oop_maps();\n+  int index = 0;\n+  while (map < end) {\n+    int offset = map->offset();\n+    for (unsigned int j = 0; j < map->count(); j++) {\n+      result_array->obj_at_put(index++, ih->obj_field(offset));\n+      offset += heapOopSize;\n+    }\n+    map++;\n+  }\n+  return (jobjectArray)JNIHandles::make_local(THREAD, result_array());\n+WB_END\n+\n+class CollectOops : public BasicOopIterateClosure {\n+ public:\n+  GrowableArray<Handle>* array;\n+\n+  jobjectArray create_jni_result(JNIEnv* env, TRAPS) {\n+    objArrayHandle result_array =\n+        oopFactory::new_objArray_handle(vmClasses::Object_klass(), array->length(), CHECK_NULL);\n+    for (int i = 0 ; i < array->length(); i++) {\n+      result_array->obj_at_put(i, array->at(i)());\n+    }\n+    return (jobjectArray)JNIHandles::make_local(THREAD, result_array());\n+  }\n+\n+  void add_oop(oop o) {\n+    Handle oh = Handle(Thread::current(), o);\n+    \/\/ Value might be oop, but JLS can't see as Object, just iterate through it...\n+    if (oh != NULL && oh->is_inline_type()) {\n+      oh->oop_iterate(this);\n+    } else {\n+      array->append(oh);\n+    }\n+  }\n+\n+  void do_oop(oop* o) { add_oop(HeapAccess<>::oop_load(o)); }\n+  void do_oop(narrowOop* v) { add_oop(HeapAccess<>::oop_load(v)); }\n+};\n+\n+\n+WB_ENTRY(jobjectArray, WB_getObjectsViaOopIterator(JNIEnv* env, jobject wb, jobject thing))\n+  ResourceMark rm(thread);\n+  Handle objh(thread, JNIHandles::resolve(thing));\n+  GrowableArray<Handle>* array = new GrowableArray<Handle>(128);\n+  CollectOops collectOops;\n+  collectOops.array = array;\n+  objh->oop_iterate(&collectOops);\n+  return collectOops.create_jni_result(env, THREAD);\n+WB_END\n+\n+WB_ENTRY(jobjectArray, WB_getObjectsViaFrameOopIterator(JNIEnv* env, jobject wb, jint depth))\n+  ResourceMark rm(THREAD);\n+  GrowableArray<Handle>* array = new GrowableArray<Handle>(128);\n+  CollectOops collectOops;\n+  collectOops.array = array;\n+  StackFrameStream sfs(thread, false \/* update *\/, true \/* process_frames *\/);\n+  while (depth > 0) { \/\/ Skip the native WB API frame\n+    sfs.next();\n+    frame* f = sfs.current();\n+    f->oops_do(&collectOops, NULL, sfs.register_map());\n+    depth--;\n+  }\n+  return collectOops.create_jni_result(env, THREAD);\n+WB_END\n+\n+\n@@ -2687,0 +2777,6 @@\n+  {CC\"getObjectsViaKlassOopMaps0\",\n+      CC\"(Ljava\/lang\/Object;)[Ljava\/lang\/Object;\",    (void*)&WB_getObjectsViaKlassOopMaps},\n+  {CC\"getObjectsViaOopIterator0\",\n+          CC\"(Ljava\/lang\/Object;)[Ljava\/lang\/Object;\",(void*)&WB_getObjectsViaOopIterator},\n+  {CC\"getObjectsViaFrameOopIterator\",\n+      CC\"(I)[Ljava\/lang\/Object;\",                     (void*)&WB_getObjectsViaFrameOopIterator},\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":96,"deletions":0,"binary":false,"changes":96,"status":"modified"},{"patch":"@@ -2069,0 +2069,10 @@\n+  if (AMD64_ONLY(false &&) AARCH64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypePassFieldsAsArgs)) {\n+    FLAG_SET_CMDLINE(InlineTypePassFieldsAsArgs, false);\n+    warning(\"InlineTypePassFieldsAsArgs is not supported on this platform\");\n+  }\n+\n+  if (AMD64_ONLY(false &&) AARCH64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypeReturnedAsFields)) {\n+    FLAG_SET_CMDLINE(InlineTypeReturnedAsFields, false);\n+    warning(\"InlineTypeReturnedAsFields is not supported on this platform\");\n+  }\n+\n@@ -3026,0 +3036,18 @@\n+  if (EnableValhalla) {\n+    \/\/ create_property(\"valhalla.enableValhalla\", \"true\", InternalProperty)\n+    const char* prop_name = \"valhalla.enableValhalla\";\n+    const char* prop_value = \"true\";\n+    const size_t prop_len = strlen(prop_name) + strlen(prop_value) + 2;\n+    char* property = AllocateHeap(prop_len, mtArguments);\n+    int ret = jio_snprintf(property, prop_len, \"%s=%s\", prop_name, prop_value);\n+    if (ret < 0 || ret >= (int)prop_len) {\n+      FreeHeap(property);\n+      return JNI_ENOMEM;\n+    }\n+    bool added = add_property(property, UnwriteableProperty, InternalProperty);\n+    FreeHeap(property);\n+    if (!added) {\n+      return JNI_ENOMEM;\n+    }\n+  }\n+\n@@ -4170,0 +4198,7 @@\n+  if (!EnableValhalla || (is_interpreter_only() && !is_dumping_archive() && !UseSharedSpaces)) {\n+    \/\/ Disable calling convention optimizations if inline types are not supported.\n+    \/\/ Also these aren't useful in -Xint. However, don't disable them when dumping or using\n+    \/\/ the CDS archive, as the values must match between dumptime and runtime.\n+    InlineTypePassFieldsAsArgs = false;\n+    InlineTypeReturnedAsFields = false;\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":35,"deletions":0,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -51,0 +51,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.hpp\"\n@@ -56,0 +58,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -205,1 +208,1 @@\n-    assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n+    assert(obj.not_null() || k->is_inline_klass() || realloc_failures, \"reallocation was missed\");\n@@ -207,1 +210,5 @@\n-      st.print(\" allocation failed\");\n+      if (k->is_inline_klass()) {\n+        st.print(\" is null\");\n+      } else {\n+        st.print(\" allocation failed\");\n+      }\n@@ -241,2 +248,13 @@\n-  bool save_oop_result = chunk->at(0)->scope()->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n-  Handle return_value;\n+  ScopeDesc* scope = chunk->at(0)->scope();\n+  bool save_oop_result = scope->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n+  \/\/ In case of the return of multiple values, we must take care\n+  \/\/ of all oop return values.\n+  GrowableArray<Handle> return_oops;\n+  InlineKlass* vk = NULL;\n+  if (save_oop_result && scope->return_scalarized()) {\n+    vk = InlineKlass::returned_inline_klass(map);\n+    if (vk != NULL) {\n+      vk->save_oop_fields(map, return_oops);\n+      save_oop_result = false;\n+    }\n+  }\n@@ -248,1 +266,1 @@\n-    return_value = Handle(thread, result);\n+    return_oops.push(Handle(thread, result));\n@@ -255,1 +273,1 @@\n-  if (objects != NULL) {\n+  if (objects != NULL || vk != NULL) {\n@@ -260,1 +278,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+      if (vk != NULL) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, CHECK_AND_CLEAR_(true));\n+      }\n+      if (objects != NULL) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+        bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, CHECK_AND_CLEAR_(true));\n+      }\n@@ -265,1 +290,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+      if (vk != NULL) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, THREAD);\n+      }\n+      if (objects != NULL) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+        bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, THREAD);\n+      }\n@@ -268,2 +300,0 @@\n-    bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n-    Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal);\n@@ -274,1 +304,1 @@\n-  if (save_oop_result) {\n+  if (save_oop_result || vk != NULL) {\n@@ -276,1 +306,2 @@\n-    deoptee.set_saved_oop_result(&map, return_value());\n+    assert(return_oops.length() == 1, \"no inline type\");\n+    deoptee.set_saved_oop_result(&map, return_oops.pop()());\n@@ -614,1 +645,1 @@\n-  \/\/ If the sender is deoptimized the we must retrieve the address of the handler\n+  \/\/ If the sender is deoptimized we must retrieve the address of the handler\n@@ -1099,2 +1130,12 @@\n-\n-    oop obj = NULL;\n+    \/\/ Check if the object may be null and has an additional is_init input that needs\n+    \/\/ to be checked before using the field values. Skip re-allocation if it is null.\n+    if (sv->maybe_null()) {\n+      assert(k->is_inline_klass(), \"must be an inline klass\");\n+      intptr_t init_value = StackValue::create_stack_value(fr, reg_map, sv->is_init())->get_int();\n+      jint is_init = (jint)*((jint*)&init_value);\n+      if (is_init == 0) {\n+        continue;\n+      }\n+    }\n+\n+    oop obj = NULL;\n@@ -1128,0 +1169,4 @@\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* ak = FlatArrayKlass::cast(k);\n+      \/\/ Inline type array must be zeroed because not all memory is reassigned\n+      obj = ak->allocate(sv->field_size(), THREAD);\n@@ -1157,0 +1202,15 @@\n+\/\/ We're deoptimizing at the return of a call, inline type fields are\n+\/\/ in registers. When we go back to the interpreter, it will expect a\n+\/\/ reference to an inline type instance. Allocate and initialize it from\n+\/\/ the register values here.\n+bool Deoptimization::realloc_inline_type_result(InlineKlass* vk, const RegisterMap& map, GrowableArray<Handle>& return_oops, TRAPS) {\n+  oop new_vt = vk->realloc_result(map, return_oops, THREAD);\n+  if (new_vt == NULL) {\n+    CLEAR_PENDING_EXCEPTION;\n+    THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), true);\n+  }\n+  return_oops.clear();\n+  return_oops.push(Handle(THREAD, new_vt));\n+  return false;\n+}\n+\n@@ -1329,0 +1389,1 @@\n+  InstanceKlass* _klass;\n@@ -1333,0 +1394,1 @@\n+    _klass = NULL;\n@@ -1342,1 +1404,1 @@\n-static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal) {\n+static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {\n@@ -1351,0 +1413,8 @@\n+        if (fs.signature()->is_Q_signature()) {\n+          if (fs.is_inlined()) {\n+            \/\/ Resolve klass of flattened inline type field\n+            field._klass = InlineKlass::cast(klass->get_inline_type_field_klass(fs.index()));\n+          } else {\n+            field._type = T_OBJECT;\n+          }\n+        }\n@@ -1358,0 +1428,11 @@\n+    BasicType type = fields->at(i)._type;\n+    int offset = base_offset + fields->at(i)._offset;\n+    \/\/ Check for flattened inline type field before accessing the ScopeValue because it might not have any fields\n+    if (type == T_PRIMITIVE_OBJECT) {\n+      \/\/ Recursively re-assign flattened inline type fields\n+      InstanceKlass* vk = fields->at(i)._klass;\n+      assert(vk != NULL, \"must be resolved\");\n+      offset -= InlineKlass::cast(vk)->first_field_offset(); \/\/ Adjust offset to omit oop header\n+      svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);\n+      continue; \/\/ Continue because we don't need to increment svIndex\n+    }\n@@ -1361,3 +1442,2 @@\n-    int offset = fields->at(i)._offset;\n-    BasicType type = fields->at(i)._type;\n-      case T_OBJECT: case T_ARRAY:\n+      case T_OBJECT:\n+      case T_ARRAY:\n@@ -1444,0 +1524,14 @@\n+\/\/ restore fields of an eliminated inline type array\n+void Deoptimization::reassign_flat_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, flatArrayOop obj, FlatArrayKlass* vak, bool skip_internal, TRAPS) {\n+  InlineKlass* vk = vak->element_klass();\n+  assert(vk->flatten_array(), \"should only be used for flattened inline type arrays\");\n+  \/\/ Adjust offset to omit oop header\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(T_PRIMITIVE_OBJECT) - InlineKlass::cast(vk)->first_field_offset();\n+  \/\/ Initialize all elements of the flattened inline type array\n+  for (int i = 0; i < sv->field_size(); i++) {\n+    ScopeValue* val = sv->field_at(i);\n+    int offset = base_offset + (i << Klass::layout_helper_log2_element_size(vak->layout_helper()));\n+    reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, skip_internal, offset, CHECK);\n+  }\n+}\n+\n@@ -1445,1 +1539,1 @@\n-void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal) {\n+void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal, TRAPS) {\n@@ -1450,1 +1544,1 @@\n-    assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n+    assert(obj.not_null() || realloc_failures || sv->maybe_null(), \"reallocation was missed\");\n@@ -1490,1 +1584,4 @@\n-      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal);\n+      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, CHECK);\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* vak = FlatArrayKlass::cast(k);\n+      reassign_flat_array_elements(fr, reg_map, sv, (flatArrayOop) obj(), vak, skip_internal, CHECK);\n@@ -1650,1 +1747,1 @@\n-  \/\/ Deoptimize only if the frame comes from compile code.\n+  \/\/ Deoptimize only if the frame comes from compiled code.\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":120,"deletions":23,"binary":false,"changes":143,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -63,1 +64,1 @@\n-  return is_final() && (is_static() || ik->is_hidden() || ik->is_record());\n+  return is_final() && (is_static() || ik->is_hidden() || ik->is_record() || ik->is_inline_klass());\n@@ -158,3 +159,5 @@\n-  print_on(st);\n-  st->print(\" \");\n-\n+  if (ft != T_PRIMITIVE_OBJECT) {\n+    print_on(st);\n+    st->print(\" \");\n+  }\n+  jint as_int = 0;\n@@ -190,5 +193,10 @@\n-    case T_ARRAY:\n-      if (obj->obj_field(offset()) != NULL) {\n-        obj->obj_field(offset())->print_value_on(st);\n-      } else {\n-        st->print(\"NULL\");\n+    case T_PRIMITIVE_OBJECT:\n+      if (is_inlined()) {\n+        \/\/ Print fields of inlined fields (recursively)\n+        InlineKlass* vk = InlineKlass::cast(field_holder()->get_inline_type_field_klass(index()));\n+        int field_offset = offset() - vk->first_field_offset();\n+        obj = cast_to_oop(cast_from_oop<address>(obj) + field_offset);\n+        st->print_cr(\"Inline type field inlined '%s':\", vk->name()->as_C_string());\n+        FieldPrinter print_field(st, obj);\n+        vk->do_nonstatic_fields(&print_field);\n+        return; \/\/ Do not print underlying representation\n@@ -196,1 +204,2 @@\n-      break;\n+      \/\/ inline type field not inlined, fall through\n+    case T_ARRAY:\n@@ -235,0 +244,1 @@\n+  st->cr();\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.cpp","additions":20,"deletions":10,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -788,0 +788,18 @@\n+  notproduct(bool, PrintInlineLayout, false,                                \\\n+          \"Print field layout for each inline type\")                        \\\n+                                                                            \\\n+  notproduct(bool, PrintFlatArrayLayout, false,                             \\\n+          \"Print array layout for each inline type array\")                  \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxSize, -1,                                \\\n+          \"Max size for flattening inline array elements, <0 no limit\")     \\\n+                                                                            \\\n+  product(intx, InlineFieldMaxFlatSize, 128,                                \\\n+          \"Max size for flattening inline type fields, <0 no limit\")        \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxOops, 4,                                 \\\n+          \"Max nof embedded object references in an inline type to flatten, <0 no limit\")  \\\n+                                                                            \\\n+  product(bool, InlineArrayAtomicAccess, false,                             \\\n+          \"Atomic inline array accesses by-default, for all inline arrays\") \\\n+                                                                            \\\n@@ -1976,0 +1994,20 @@\n+  product(bool, EnableValhalla, true,                                       \\\n+          \"Enable experimental Valhalla features\")                          \\\n+                                                                            \\\n+  product_pd(bool, InlineTypePassFieldsAsArgs,                              \\\n+          \"Pass each inline type field as an argument at calls\")            \\\n+                                                                            \\\n+  product_pd(bool, InlineTypeReturnedAsFields,                              \\\n+          \"Return fields instead of an inline type reference\")              \\\n+                                                                            \\\n+  develop(bool, StressInlineTypeReturnedAsFields, false,                    \\\n+          \"Stress return of fields instead of an inline type reference\")    \\\n+                                                                            \\\n+  product(bool, UseArrayMarkWordCheck, NOT_LP64(false) LP64_ONLY(true),     \\\n+          \"Use bits in the mark word to check for flat\/null-free arrays\")   \\\n+                                                                            \\\n+  product(ccstrlist, ForceNonTearable, \"\", DIAGNOSTIC,                      \\\n+          \"List of inline classes which are forced to be atomic \"           \\\n+          \"(whitespace and commas separate names, \"                         \\\n+          \"and leading and trailing stars '*' are wildcards)\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":38,"deletions":0,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -55,0 +56,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -350,1 +352,5 @@\n-    return oopFactory::new_objArray(k, length, THREAD);\n+    if (k->is_inline_klass() && java_lang_Class::is_secondary_mirror(element_mirror)) {\n+      return oopFactory::new_valueArray(k, length, THREAD);\n+    } else {\n+      return oopFactory::new_objArray(k, length, THREAD);\n+    }\n@@ -391,1 +397,5 @@\n-  klass = klass->array_klass(dim, CHECK_NULL);\n+  if (klass->is_inline_klass() && java_lang_Class::is_secondary_mirror(element_mirror)) {\n+    klass = InlineKlass::cast(klass)->value_array_klass(dim, CHECK_NULL);\n+  } else {\n+    klass = klass->array_klass(dim, CHECK_NULL);\n+  }\n@@ -768,3 +778,0 @@\n-  if (log_is_enabled(Debug, class, resolve)) {\n-    trace_class_resolution(nt);\n-  }\n@@ -776,2 +783,1 @@\n-  assert(!method()->is_initializer() ||\n-         (for_constant_pool_access && method()->is_static()),\n+  assert(!method()->name()->starts_with('<') || for_constant_pool_access,\n@@ -826,1 +832,3 @@\n-  assert(method()->is_initializer(), \"should call new_method instead\");\n+  assert(method()->is_object_constructor() ||\n+         method()->is_static_init_factory(),\n+         \"should call new_method instead\");\n@@ -879,1 +887,2 @@\n-  java_lang_reflect_Field::set_modifiers(rh(), fd->access_flags().as_int() & JVM_RECOGNIZED_FIELD_MODIFIERS);\n+  int modifiers = fd->access_flags().as_int() & JVM_RECOGNIZED_FIELD_MODIFIERS;\n+  java_lang_reflect_Field::set_modifiers(rh(), modifiers);\n@@ -1150,0 +1159,2 @@\n+  } else if (java_lang_Class::as_Klass(return_type_mirror)->is_inline_klass()) {\n+    rtype = java_lang_Class::is_primary_mirror(return_type_mirror) ? T_OBJECT : T_PRIMITIVE_OBJECT;\n@@ -1184,0 +1195,16 @@\n+\n+  \/\/ Special case for factory methods\n+  if (!method->signature()->is_void_method_signature()) {\n+    assert(klass->is_inline_klass(), \"inline classes must use factory methods\");\n+    Handle no_receiver; \/\/ null instead of receiver\n+    BasicType rtype;\n+    if (klass->is_hidden()) {\n+      rtype = T_OBJECT;\n+    } else {\n+      rtype = T_PRIMITIVE_OBJECT;\n+    }\n+    return invoke(klass, method, no_receiver, override, ptypes, rtype, args, false, CHECK_NULL);\n+  }\n+\n+  \/\/ main branch of code creates a non-inline object:\n+  assert(!klass->is_inline_klass(), \"classic constructors are only for non-inline classes\");\n","filename":"src\/hotspot\/share\/runtime\/reflection.cpp","additions":36,"deletions":9,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"memory\/oopFactory.hpp\"\n@@ -49,0 +50,2 @@\n+#include \"oops\/access.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -53,0 +56,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -54,0 +58,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -89,1 +94,0 @@\n-address             SharedRuntime::_resolve_static_call_entry;\n@@ -110,1 +114,0 @@\n-  _resolve_static_call_entry           = _resolve_static_call_blob->entry_point();\n@@ -999,0 +1002,1 @@\n+\n@@ -1105,0 +1109,15 @@\n+  \/\/ Substitutability test implementation piggy backs on static call resolution\n+  Bytecodes::Code code = caller->java_code_at(bci);\n+  if (code == Bytecodes::_if_acmpeq || code == Bytecodes::_if_acmpne) {\n+    bc = Bytecodes::_invokestatic;\n+    methodHandle attached_method(THREAD, extract_attached_method(vfst));\n+    assert(attached_method.not_null(), \"must have attached method\");\n+    vmClasses::PrimitiveObjectMethods_klass()->initialize(CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, false, CHECK_NH);\n+#ifdef ASSERT\n+    Method* is_subst = vmClasses::PrimitiveObjectMethods_klass()->find_method(vmSymbols::isSubstitutable_name(), vmSymbols::object_object_boolean_signature());\n+    assert(callinfo.selected_method() == is_subst, \"must be isSubstitutable method\");\n+#endif\n+    return receiver;\n+  }\n+\n@@ -1140,0 +1159,6 @@\n+    } else {\n+      assert(attached_method->has_scalarized_args(), \"invalid use of attached method\");\n+      if (!attached_method->method_holder()->is_inline_klass()) {\n+        \/\/ Ignore the attached method in this case to not confuse below code\n+        attached_method = methodHandle(current, NULL);\n+      }\n@@ -1148,0 +1173,1 @@\n+  bool check_null_and_abstract = true;\n@@ -1160,0 +1186,5 @@\n+    bool caller_is_c1 = false;\n+\n+    if (callerFrame.is_compiled_frame() && !callerFrame.is_deoptimized_frame()) {\n+      caller_is_c1 = callerFrame.cb()->is_compiled_by_c1();\n+    }\n@@ -1161,2 +1192,3 @@\n-    if (attached_method.is_null()) {\n-      Method* callee = bytecode.static_target(CHECK_NH);\n+    Method* callee = attached_method();\n+    if (callee == NULL) {\n+      callee = bytecode.static_target(CHECK_NH);\n@@ -1167,7 +1199,15 @@\n-\n-    \/\/ Retrieve from a compiled argument list\n-    receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n-    assert(oopDesc::is_oop_or_null(receiver()), \"\");\n-\n-    if (receiver.is_null()) {\n-      THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+    if (!caller_is_c1 && callee->is_scalarized_arg(0)) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      \/\/ Resolve the call without receiver null checking.\n+      assert(attached_method.not_null() && !attached_method->is_abstract(), \"must have non-abstract attached method\");\n+      if (bc == Bytecodes::_invokeinterface) {\n+        bc = Bytecodes::_invokevirtual; \/\/ C2 optimistically replaces interface calls by virtual calls\n+      }\n+      check_null_and_abstract = false;\n+    } else {\n+      \/\/ Retrieve from a compiled argument list\n+      receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n+      assert(oopDesc::is_oop_or_null(receiver()), \"\");\n+      if (receiver.is_null()) {\n+        THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+      }\n@@ -1180,1 +1220,1 @@\n-    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, check_null_and_abstract, CHECK_NH);\n@@ -1189,1 +1229,1 @@\n-  if (has_receiver) {\n+  if (has_receiver && check_null_and_abstract) {\n@@ -1250,1 +1290,1 @@\n-methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, TRAPS) {\n+methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS) {\n@@ -1252,1 +1292,1 @@\n-  callee_method = resolve_sub_helper(is_virtual, is_optimized, THREAD);\n+  callee_method = resolve_sub_helper(is_virtual, is_optimized, caller_is_c1, THREAD);\n@@ -1269,1 +1309,1 @@\n-      callee_method = resolve_sub_helper(is_virtual, is_optimized, THREAD);\n+      callee_method = resolve_sub_helper(is_virtual, is_optimized, caller_is_c1, THREAD);\n@@ -1299,0 +1339,1 @@\n+  bool caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1301,1 +1342,8 @@\n-    assert(receiver.not_null() || invoke_code == Bytecodes::_invokehandle, \"sanity check\");\n+    Klass* receiver_klass = NULL;\n+    if (!caller_is_c1 && callee_method->is_scalarized_arg(0)) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      receiver_klass = callee_method->method_holder();\n+    } else {\n+      assert(receiver.not_null() || invoke_code == Bytecodes::_invokehandle, \"sanity check\");\n+      receiver_klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver->klass();\n+    }\n@@ -1303,3 +1351,2 @@\n-    Klass* klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver->klass();\n-    CompiledIC::compute_monomorphic_entry(callee_method, klass,\n-                     is_optimized, static_bound, is_nmethod, virtual_call_info,\n+    CompiledIC::compute_monomorphic_entry(callee_method, receiver_klass,\n+                     is_optimized, static_bound, is_nmethod, caller_is_c1, virtual_call_info,\n@@ -1309,1 +1356,1 @@\n-    CompiledStaticCall::compute_entry(callee_method, is_nmethod, static_call_info);\n+    CompiledStaticCall::compute_entry(callee_method, caller_nm, static_call_info);\n@@ -1362,1 +1409,1 @@\n-methodHandle SharedRuntime::resolve_sub_helper(bool is_virtual, bool is_optimized, TRAPS) {\n+methodHandle SharedRuntime::resolve_sub_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS) {\n@@ -1374,0 +1421,1 @@\n+  *caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1472,0 +1520,2 @@\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1473,1 +1523,1 @@\n-    callee_method = SharedRuntime::handle_ic_miss_helper(CHECK_NULL);\n+    callee_method = SharedRuntime::handle_ic_miss_helper(is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1478,2 +1528,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  return entry_for_handle_wrong_method(callee_method, false, is_optimized, caller_is_c1);\n@@ -1526,0 +1575,3 @@\n+  bool is_static_call = false;\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1528,1 +1580,1 @@\n-    callee_method = SharedRuntime::reresolve_call_site(CHECK_NULL);\n+    callee_method = SharedRuntime::reresolve_call_site(is_static_call, is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1532,2 +1584,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  return entry_for_handle_wrong_method(callee_method, is_static_call, is_optimized, caller_is_c1);\n@@ -1574,0 +1625,1 @@\n+  bool caller_is_c1;\n@@ -1576,1 +1628,1 @@\n-    callee_method = SharedRuntime::resolve_helper(false, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(false, false, &caller_is_c1, CHECK_NULL);\n@@ -1604,2 +1656,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1612,0 +1666,1 @@\n+  bool caller_is_c1;\n@@ -1613,1 +1668,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, false, &caller_is_c1, CHECK_NULL);\n@@ -1617,2 +1672,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_inline_ro_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1626,0 +1683,1 @@\n+  bool caller_is_c1;\n@@ -1627,1 +1685,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, true, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, true, &caller_is_c1, CHECK_NULL);\n@@ -1631,2 +1689,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1643,1 +1703,1 @@\n-                                                   bool& needs_ic_stub_refill, TRAPS) {\n+                                                   bool& needs_ic_stub_refill, bool& is_optimized, bool caller_is_c1, TRAPS) {\n@@ -1654,0 +1714,1 @@\n+    is_optimized = true;\n@@ -1691,0 +1752,1 @@\n+                                            caller_nm->is_compiled_by_c1(),\n@@ -1699,1 +1761,1 @@\n-    bool successful = inline_cache->set_to_megamorphic(&call_info, bc, needs_ic_stub_refill, CHECK_false);\n+    bool successful = inline_cache->set_to_megamorphic(&call_info, bc, needs_ic_stub_refill, caller_is_c1, CHECK_false);\n@@ -1715,1 +1777,1 @@\n-methodHandle SharedRuntime::handle_ic_miss_helper(TRAPS) {\n+methodHandle SharedRuntime::handle_ic_miss_helper(bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1735,1 +1797,3 @@\n-    methodHandle callee_method = SharedRuntime::reresolve_call_site(CHECK_(methodHandle()));\n+    bool is_static_call = false;\n+    methodHandle callee_method = SharedRuntime::reresolve_call_site(is_static_call, is_optimized, caller_is_c1, CHECK_(methodHandle()));\n+    assert(!is_static_call, \"IC miss at static call?\");\n@@ -1794,0 +1858,1 @@\n+  caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1799,1 +1864,1 @@\n-                                                     bc, call_info, needs_ic_stub_refill, CHECK_(methodHandle()));\n+                                                     bc, call_info, needs_ic_stub_refill, is_optimized, caller_is_c1, CHECK_(methodHandle()));\n@@ -1831,1 +1896,1 @@\n-methodHandle SharedRuntime::reresolve_call_site(TRAPS) {\n+methodHandle SharedRuntime::reresolve_call_site(bool& is_static_call, bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1851,1 +1916,1 @@\n-    bool is_static_call = false;\n+    caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1889,1 +1954,2 @@\n-        bool is_static_call = false;\n+        is_static_call = false;\n+        is_optimized = false;\n@@ -1896,0 +1962,1 @@\n+            is_optimized = (iter.type() == relocInfo::opt_virtual_call_type);\n@@ -1921,1 +1988,0 @@\n-\n@@ -2017,2 +2083,0 @@\n-  address entry_point = moop->from_compiled_entry_no_trampoline();\n-\n@@ -2030,1 +2094,5 @@\n-  if (cb == NULL || !cb->is_compiled() || entry_point == moop->get_c2i_entry()) {\n+  if (cb == NULL || !cb->is_compiled()) {\n+    return;\n+  }\n+  address entry_point = moop->from_compiled_entry_no_trampoline(cb->is_compiled_by_c1());\n+  if (entry_point == moop->get_c2i_entry()) {\n@@ -2423,1 +2491,1 @@\n-  static int adapter_encoding(BasicType in) {\n+  static BasicType adapter_encoding(BasicType in) {\n@@ -2429,1 +2497,1 @@\n-        \/\/ There are all promoted to T_INT in the calling convention\n+        \/\/ They are all promoted to T_INT in the calling convention\n@@ -2456,1 +2524,1 @@\n-  AdapterFingerPrint(int total_args_passed, BasicType* sig_bt) {\n+  AdapterFingerPrint(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2459,0 +2527,1 @@\n+    int total_args_passed = (sig != NULL) ? sig->length() : 0;\n@@ -2476,0 +2545,2 @@\n+    BasicType prev_bt = T_ILLEGAL;\n+    int vt_count = 0;\n@@ -2478,4 +2549,27 @@\n-      for (int byte = 0; sig_index < total_args_passed && byte < _basic_types_per_int; byte++) {\n-        int bt = adapter_encoding(sig_bt[sig_index++]);\n-        assert((bt & _basic_type_mask) == bt, \"must fit in 4 bits\");\n-        value = (value << _basic_type_bits) | bt;\n+      for (int byte = 0; byte < _basic_types_per_int; byte++) {\n+        BasicType bt = T_ILLEGAL;\n+        if (sig_index < total_args_passed) {\n+          bt = sig->at(sig_index++)._bt;\n+          if (bt == T_PRIMITIVE_OBJECT) {\n+            \/\/ Found start of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected start of inline type\");\n+            if (sig_index == 1 && has_ro_adapter) {\n+              \/\/ With a ro_adapter, replace receiver inline type delimiter by T_VOID to prevent matching\n+              \/\/ with other adapters that have the same inline type as first argument and no receiver.\n+              bt = T_VOID;\n+            }\n+            vt_count++;\n+          } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+            \/\/ Found end of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected end of inline type\");\n+            vt_count--;\n+            assert(vt_count >= 0, \"invalid vt_count\");\n+          } else if (vt_count == 0) {\n+            \/\/ Widen fields that are not part of a scalarized inline type argument\n+            bt = adapter_encoding(bt);\n+          }\n+          prev_bt = bt;\n+        }\n+        int bt_val = (bt == T_ILLEGAL) ? 0 : bt;\n+        assert((bt_val & _basic_type_mask) == bt_val, \"must fit in 4 bits\");\n+        value = (value << _basic_type_bits) | bt_val;\n@@ -2485,0 +2579,1 @@\n+    assert(vt_count == 0, \"invalid vt_count\");\n@@ -2549,8 +2644,4 @@\n-        }\n-        switch (v) {\n-          case T_INT:    st.print(\"I\");    break;\n-          case T_LONG:   long_prev = true; break;\n-          case T_FLOAT:  st.print(\"F\");    break;\n-          case T_DOUBLE: st.print(\"D\");    break;\n-          case T_VOID:   break;\n-          default: ShouldNotReachHere();\n+        } else if (v == T_LONG) {\n+          long_prev = true;\n+        } else if (v != T_VOID){\n+          st.print(\"%c\", type2char((BasicType)v));\n@@ -2603,1 +2694,1 @@\n-static AdapterHandlerEntry* lookup(int total_args_passed, BasicType* sig_bt) {\n+static AdapterHandlerEntry* lookup(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2606,1 +2697,1 @@\n-  AdapterFingerPrint fp(total_args_passed, sig_bt);\n+  AdapterFingerPrint fp(sig, has_ro_adapter);\n@@ -2640,1 +2731,1 @@\n-const int AdapterHandlerLibrary_size = 16*K;\n+const int AdapterHandlerLibrary_size = 32*K;\n@@ -2686,1 +2777,1 @@\n-    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, NULL),\n+    _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),\n@@ -2688,0 +2779,1 @@\n+                                                                wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n@@ -2689,4 +2781,3 @@\n-\n-    _no_arg_handler = create_adapter(no_arg_blob, 0, NULL, true);\n-    BasicType obj_args[] = { T_OBJECT };\n-    _obj_arg_handler = create_adapter(obj_arg_blob, 1, obj_args, true);\n+    CompiledEntrySignature no_args;\n+    no_args.compute_calling_conventions();\n+    _no_arg_handler = create_adapter(no_arg_blob, no_args, true);\n@@ -2696,2 +2787,4 @@\n-    BasicType int_args[] = { T_INT };\n-    _int_arg_handler = create_adapter(int_arg_blob, 1, int_args, true);\n+    CompiledEntrySignature obj_args;\n+    SigEntry::add_entry(&obj_args.sig(), T_OBJECT, NULL);\n+    obj_args.compute_calling_conventions();\n+    _obj_arg_handler = create_adapter(obj_arg_blob, obj_args, true);\n@@ -2699,2 +2792,4 @@\n-    BasicType obj_int_args[] = { T_OBJECT, T_INT };\n-    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, 2, obj_int_args, true);\n+    CompiledEntrySignature int_args;\n+    SigEntry::add_entry(&int_args.sig(), T_INT, NULL);\n+    int_args.compute_calling_conventions();\n+    _int_arg_handler = create_adapter(int_arg_blob, int_args, true);\n@@ -2702,2 +2797,11 @@\n-    BasicType obj_obj_args[] = { T_OBJECT, T_OBJECT };\n-    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, 2, obj_obj_args, true);\n+    CompiledEntrySignature obj_int_args;\n+    SigEntry::add_entry(&obj_int_args.sig(), T_OBJECT, NULL);\n+    SigEntry::add_entry(&obj_int_args.sig(), T_INT, NULL);\n+    obj_int_args.compute_calling_conventions();\n+    _obj_int_arg_handler = create_adapter(obj_int_arg_blob, obj_int_args, true);\n+\n+    CompiledEntrySignature obj_obj_args;\n+    SigEntry::add_entry(&obj_obj_args.sig(), T_OBJECT, NULL);\n+    SigEntry::add_entry(&obj_obj_args.sig(), T_OBJECT, NULL);\n+    obj_obj_args.compute_calling_conventions();\n+    _obj_obj_arg_handler = create_adapter(obj_obj_arg_blob, obj_obj_args, true);\n@@ -2711,0 +2815,1 @@\n+  return;\n@@ -2723,0 +2828,2 @@\n+                                                      address c2i_inline_entry,\n+                                                      address c2i_inline_ro_entry,\n@@ -2724,0 +2831,1 @@\n+                                                      address c2i_unverified_inline_entry,\n@@ -2725,3 +2833,2 @@\n-  \/\/ Insert an entry into the table\n-  return new AdapterHandlerEntry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry,\n-                                 c2i_no_clinit_check_entry);\n+  return new AdapterHandlerEntry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry,\n+                              c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -2732,1 +2839,1 @@\n-    return _abstract_method_handler;\n+    return NULL;\n@@ -2739,0 +2846,3 @@\n+      if (InlineTypePassFieldsAsArgs && method->method_holder()->is_inline_klass()) {\n+        return NULL;\n+      }\n@@ -2742,1 +2852,10 @@\n-      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_CLASS: {\n+        if (InlineTypePassFieldsAsArgs) {\n+          SignatureStream ss(method->signature());\n+          InlineKlass* vk = ss.as_inline_klass(method->method_holder());\n+          if (vk != NULL) {\n+            return NULL;\n+          }\n+        }\n+        return _obj_arg_handler;\n+      }\n@@ -2753,1 +2872,1 @@\n-             !method->is_static()) {\n+             !method->is_static() && (!InlineTypePassFieldsAsArgs || !method->method_holder()->is_inline_klass())) {\n@@ -2755,1 +2874,10 @@\n-      case JVM_SIGNATURE_CLASS:\n+      case JVM_SIGNATURE_CLASS: {\n+        if (InlineTypePassFieldsAsArgs) {\n+          SignatureStream ss(method->signature());\n+          InlineKlass* vk = ss.as_inline_klass(method->method_holder());\n+          if (vk != NULL) {\n+            return NULL;\n+          }\n+        }\n+        return _obj_obj_arg_handler;\n+      }\n@@ -2769,5 +2897,9 @@\n-class AdapterSignatureIterator : public SignatureIterator {\n- private:\n-  BasicType stack_sig_bt[16];\n-  BasicType* sig_bt;\n-  int index;\n+CompiledEntrySignature::CompiledEntrySignature(Method* method) :\n+  _method(method), _num_inline_args(0), _has_inline_recv(false),\n+  _regs(NULL), _regs_cc(NULL), _regs_cc_ro(NULL),\n+  _args_on_stack(0), _args_on_stack_cc(0), _args_on_stack_cc_ro(0),\n+  _c1_needs_stack_repair(false), _c2_needs_stack_repair(false) {\n+  _sig = new GrowableArray<SigEntry>((method != NULL) ? method->size_of_parameters() : 1);\n+  _sig_cc = new GrowableArray<SigEntry>((method != NULL) ? method->size_of_parameters() : 1);\n+  _sig_cc_ro = new GrowableArray<SigEntry>((method != NULL) ? method->size_of_parameters() : 1);\n+}\n@@ -2775,13 +2907,10 @@\n- public:\n-  AdapterSignatureIterator(Symbol* signature,\n-                           fingerprint_t fingerprint,\n-                           bool is_static,\n-                           int total_args_passed) :\n-    SignatureIterator(signature, fingerprint),\n-    index(0)\n-  {\n-    sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n-    if (!is_static) { \/\/ Pass in receiver first\n-      sig_bt[index++] = T_OBJECT;\n-    }\n-    do_parameters_on(this);\n+\/\/ See if we can save space by sharing the same entry for VIEP and VIEP(RO),\n+\/\/ or the same entry for VEP and VIEP(RO).\n+CodeOffsets::Entries CompiledEntrySignature::c1_inline_ro_entry_type() const {\n+  if (!has_scalarized_args()) {\n+    \/\/ VEP\/VIEP\/VIEP(RO) all share the same entry. There's no packing.\n+    return CodeOffsets::Verified_Entry;\n+  }\n+  if (_method->is_static()) {\n+    \/\/ Static methods don't need VIEP(RO)\n+    return CodeOffsets::Verified_Entry;\n@@ -2790,2 +2919,13 @@\n-  BasicType* basic_types() {\n-    return sig_bt;\n+  if (has_inline_recv()) {\n+    if (num_inline_args() == 1) {\n+      \/\/ Share same entry for VIEP and VIEP(RO).\n+      \/\/ This is quite common: we have an instance method in an InlineKlass that has\n+      \/\/ no inline type args other than <this>.\n+      return CodeOffsets::Verified_Inline_Entry;\n+    } else {\n+      assert(num_inline_args() > 1, \"must be\");\n+      \/\/ No sharing:\n+      \/\/   VIEP(RO) -- <this> is passed as object\n+      \/\/   VEP      -- <this> is passed as fields\n+      return CodeOffsets::Verified_Inline_Entry_RO;\n+    }\n@@ -2794,3 +2934,63 @@\n-#ifdef ASSERT\n-  int slots() {\n-    return index;\n+  \/\/ Either a static method, or <this> is not an inline type\n+  if (args_on_stack_cc() != args_on_stack_cc_ro()) {\n+    \/\/ No sharing:\n+    \/\/ Some arguments are passed on the stack, and we have inserted reserved entries\n+    \/\/ into the VEP, but we never insert reserved entries into the VIEP(RO).\n+    return CodeOffsets::Verified_Inline_Entry_RO;\n+  } else {\n+    \/\/ Share same entry for VEP and VIEP(RO).\n+    return CodeOffsets::Verified_Entry;\n+  }\n+}\n+\n+void CompiledEntrySignature::compute_calling_conventions(bool init) {\n+  \/\/ Iterate over arguments and compute scalarized and non-scalarized signatures\n+  bool has_scalarized = false;\n+  if (_method != NULL) {\n+    InstanceKlass* holder = _method->method_holder();\n+    int arg_num = 0;\n+    if (!_method->is_static()) {\n+      if (holder->is_inline_klass() && InlineKlass::cast(holder)->can_be_passed_as_fields() &&\n+          (init || _method->is_scalarized_arg(arg_num))) {\n+        _sig_cc->appendAll(InlineKlass::cast(holder)->extended_sig());\n+        has_scalarized = true;\n+        _has_inline_recv = true;\n+        _num_inline_args++;\n+      } else {\n+        SigEntry::add_entry(_sig_cc, T_OBJECT, holder->name());\n+      }\n+      SigEntry::add_entry(_sig, T_OBJECT, holder->name());\n+      SigEntry::add_entry(_sig_cc_ro, T_OBJECT, holder->name());\n+      arg_num++;\n+    }\n+    for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {\n+      BasicType bt = ss.type();\n+      if (bt == T_OBJECT || bt == T_PRIMITIVE_OBJECT) {\n+        InlineKlass* vk = ss.as_inline_klass(holder);\n+        \/\/ TODO 8284443 Mismatch handling, we need to check parent method args (look at klassVtable::needs_new_vtable_entry)\n+        if (vk != NULL && vk->can_be_passed_as_fields() && (init || _method->is_scalarized_arg(arg_num))) {\n+          _num_inline_args++;\n+          has_scalarized = true;\n+          int last = _sig_cc->length();\n+          int last_ro = _sig_cc_ro->length();\n+          _sig_cc->appendAll(vk->extended_sig());\n+          _sig_cc_ro->appendAll(vk->extended_sig());\n+          if (bt == T_OBJECT) {\n+            \/\/ Nullable inline type argument, insert InlineTypeBaseNode::IsInit field right after T_PRIMITIVE_OBJECT\n+            _sig_cc->insert_before(last+1, SigEntry(T_BOOLEAN, -1, NULL));\n+            _sig_cc_ro->insert_before(last_ro+1, SigEntry(T_BOOLEAN, -1, NULL));\n+          }\n+        } else {\n+          SigEntry::add_entry(_sig_cc, T_OBJECT, ss.as_symbol());\n+          SigEntry::add_entry(_sig_cc_ro, T_OBJECT, ss.as_symbol());\n+        }\n+        bt = T_OBJECT;\n+      } else {\n+        SigEntry::add_entry(_sig_cc, ss.type(), ss.as_symbol());\n+        SigEntry::add_entry(_sig_cc_ro, ss.type(), ss.as_symbol());\n+      }\n+      SigEntry::add_entry(_sig, bt, ss.as_symbol());\n+      if (bt != T_VOID) {\n+        arg_num++;\n+      }\n+    }\n@@ -2798,2 +2998,11 @@\n-#endif\n- private:\n+  \/\/ Compute the non-scalarized calling convention\n+  _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig->length());\n+  _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);\n+\n+  \/\/ Compute the scalarized calling conventions if there are scalarized inline types in the signature\n+  if (has_scalarized && !_method->is_native()) {\n+    _regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc->length());\n+    _args_on_stack_cc = SharedRuntime::java_calling_convention(_sig_cc, _regs_cc);\n+\n+    _regs_cc_ro = NEW_RESOURCE_ARRAY(VMRegPair, _sig_cc_ro->length());\n+    _args_on_stack_cc_ro = SharedRuntime::java_calling_convention(_sig_cc_ro, _regs_cc_ro);\n@@ -2802,5 +3011,8 @@\n-  friend class SignatureIterator;  \/\/ so do_parameters_on can call do_type\n-  void do_type(BasicType type) {\n-    sig_bt[index++] = type;\n-    if (type == T_LONG || type == T_DOUBLE) {\n-      sig_bt[index++] = T_VOID; \/\/ Longs & doubles take 2 Java slots\n+    _c1_needs_stack_repair = (_args_on_stack_cc < _args_on_stack) || (_args_on_stack_cc_ro < _args_on_stack);\n+    _c2_needs_stack_repair = (_args_on_stack_cc > _args_on_stack) || (_args_on_stack_cc > _args_on_stack_cc_ro);\n+\n+    \/\/ Upper bound on stack arguments to avoid hitting the argument limit and\n+    \/\/ bailing out of compilation (\"unsupported incoming calling sequence\").\n+    \/\/ TODO we need a reasonable limit (flag?) here\n+    if (MAX2(_args_on_stack_cc, _args_on_stack_cc_ro) <= 60) {\n+      return; \/\/ Success\n@@ -2809,1 +3021,10 @@\n-};\n+\n+  \/\/ No scalarized args\n+  _sig_cc = _sig;\n+  _regs_cc = _regs;\n+  _args_on_stack_cc = _args_on_stack;\n+\n+  _sig_cc_ro = _sig;\n+  _regs_cc_ro = _regs;\n+  _args_on_stack_cc_ro = _args_on_stack;\n+}\n@@ -2826,2 +3047,9 @@\n-  \/\/ Fill in the signature array, for the calling-convention call.\n-  int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n+  CompiledEntrySignature ces(method());\n+  ces.compute_calling_conventions();\n+  if (ces.has_scalarized_args()) {\n+    method->set_has_scalarized_args(true);\n+    method->set_c1_needs_stack_repair(ces.c1_needs_stack_repair());\n+    method->set_c2_needs_stack_repair(ces.c2_needs_stack_repair());\n+  } else if (method->is_abstract()) {\n+    return _abstract_method_handler;\n+  }\n@@ -2829,4 +3057,0 @@\n-  AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n-                              method->is_static(), total_args_passed);\n-  assert(si.slots() == total_args_passed, \"\");\n-  BasicType* sig_bt = si.basic_types();\n@@ -2836,0 +3060,13 @@\n+    if (ces.has_scalarized_args() && method->is_abstract()) {\n+      \/\/ Save a C heap allocated version of the signature for abstract methods with scalarized inline type arguments\n+      address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n+      entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),\n+                                               StubRoutines::throw_AbstractMethodError_entry(),\n+                                               wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n+                                               wrong_method_abstract, wrong_method_abstract);\n+      GrowableArray<SigEntry>* heap_sig = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<SigEntry>(ces.sig_cc_ro().length(), mtInternal);\n+      heap_sig->appendAll(&ces.sig_cc_ro());\n+      entry->set_sig_cc(heap_sig);\n+      return entry;\n+    }\n+\n@@ -2837,1 +3074,1 @@\n-    entry = lookup(total_args_passed, sig_bt);\n+    entry = lookup(&ces.sig_cc(), ces.has_inline_recv());\n@@ -2843,1 +3080,1 @@\n-        AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, total_args_passed, sig_bt, false);\n+        AdapterHandlerEntry* comparison_entry = create_adapter(comparison_blob, ces, false);\n@@ -2853,1 +3090,1 @@\n-    entry = create_adapter(new_adapter, total_args_passed, sig_bt, \/* allocate_code_blob *\/ true);\n+    entry = create_adapter(new_adapter, ces, \/* allocate_code_blob *\/ true);\n@@ -2864,2 +3101,1 @@\n-                                                           int total_args_passed,\n-                                                           BasicType* sig_bt,\n+                                                           CompiledEntrySignature& ces,\n@@ -2874,5 +3110,0 @@\n-  VMRegPair stack_regs[16];\n-  VMRegPair* regs = (total_args_passed <= 16) ? stack_regs : NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n-\n-  \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n-  int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n@@ -2886,1 +3117,1 @@\n-  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(total_args_passed, sig_bt);\n+  AdapterFingerPrint* fingerprint = new AdapterFingerPrint(&ces.sig_cc(), ces.has_inline_recv());\n@@ -2889,5 +3120,17 @@\n-                                                total_args_passed,\n-                                                comp_args_on_stack,\n-                                                sig_bt,\n-                                                regs,\n-                                                fingerprint);\n+                                                ces.args_on_stack(),\n+                                                &ces.sig(),\n+                                                ces.regs(),\n+                                                &ces.sig_cc(),\n+                                                ces.regs_cc(),\n+                                                &ces.sig_cc_ro(),\n+                                                ces.regs_cc_ro(),\n+                                                fingerprint,\n+                                                new_adapter,\n+                                                allocate_code_blob);\n+\n+  if (ces.has_scalarized_args()) {\n+    \/\/ Save a C heap allocated version of the scalarized signature and store it in the adapter\n+    GrowableArray<SigEntry>* heap_sig = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<SigEntry>(ces.sig_cc().length(), mtInternal);\n+    heap_sig->appendAll(&ces.sig_cc());\n+    entry->set_sig_cc(heap_sig);\n+  }\n@@ -2904,1 +3147,0 @@\n-  new_adapter = AdapterBlob::create(&buffer);\n@@ -2946,0 +3188,2 @@\n+  assert(base <= _c2i_inline_entry || _c2i_inline_entry == NULL, \"\");\n+  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == NULL, \"\");\n@@ -2947,0 +3191,1 @@\n+  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == NULL, \"\");\n@@ -2959,0 +3204,4 @@\n+  if (_c2i_inline_entry != NULL)\n+    _c2i_inline_entry += delta;\n+  if (_c2i_inline_ro_entry != NULL)\n+    _c2i_inline_ro_entry += delta;\n@@ -2961,0 +3210,2 @@\n+  if (_c2i_unverified_inline_entry != NULL)\n+    _c2i_unverified_inline_entry += delta;\n@@ -2969,0 +3220,3 @@\n+  if (_sig_cc != NULL) {\n+    delete _sig_cc;\n+  }\n@@ -3051,0 +3305,1 @@\n+      BasicType stack_sig_bt[16];\n@@ -3052,0 +3307,1 @@\n+      BasicType* sig_bt = (total_args_passed <= 16) ? stack_sig_bt : NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n@@ -3054,5 +3310,13 @@\n-      AdapterSignatureIterator si(method->signature(), method->constMethod()->fingerprint(),\n-                              method->is_static(), total_args_passed);\n-      BasicType* sig_bt = si.basic_types();\n-      assert(si.slots() == total_args_passed, \"\");\n-      BasicType ret_type = si.return_type();\n+      int i = 0;\n+      if (!method->is_static()) {  \/\/ Pass in receiver first\n+        sig_bt[i++] = T_OBJECT;\n+      }\n+      SignatureStream ss(method->signature());\n+      for (; !ss.at_return_type(); ss.next()) {\n+        sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n+        if (ss.type() == T_LONG || ss.type() == T_DOUBLE) {\n+          sig_bt[i++] = T_VOID;   \/\/ Longs & doubles take 2 Java slots\n+        }\n+      }\n+      assert(i == total_args_passed, \"\");\n+      BasicType ret_type = ss.type();\n@@ -3293,0 +3557,9 @@\n+  if (get_c2i_entry() != NULL) {\n+    st->print(\" c2iVE: \" INTPTR_FORMAT, p2i(get_c2i_inline_entry()));\n+  }\n+  if (get_c2i_entry() != NULL) {\n+    st->print(\" c2iVROE: \" INTPTR_FORMAT, p2i(get_c2i_inline_ro_entry()));\n+  }\n+  if (get_c2i_unverified_entry() != NULL) {\n+    st->print(\" c2iUE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+  }\n@@ -3294,1 +3567,1 @@\n-    st->print(\" c2iUV: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+    st->print(\" c2iUVE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_inline_entry()));\n@@ -3382,0 +3655,196 @@\n+\n+\/\/ We are at a compiled code to interpreter call. We need backing\n+\/\/ buffers for all inline type arguments. Allocate an object array to\n+\/\/ hold them (convenient because once we're done with it we don't have\n+\/\/ to worry about freeing it).\n+oop SharedRuntime::allocate_inline_types_impl(JavaThread* current, methodHandle callee, bool allocate_receiver, TRAPS) {\n+  assert(InlineTypePassFieldsAsArgs, \"no reason to call this\");\n+  ResourceMark rm;\n+\n+  int nb_slots = 0;\n+  InstanceKlass* holder = callee->method_holder();\n+  allocate_receiver &= !callee->is_static() && holder->is_inline_klass() && callee->is_scalarized_arg(0);\n+  if (allocate_receiver) {\n+    nb_slots++;\n+  }\n+  int arg_num = callee->is_static() ? 0 : 1;\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if ((bt == T_OBJECT || bt == T_PRIMITIVE_OBJECT) && callee->is_scalarized_arg(arg_num)) {\n+      nb_slots++;\n+    }\n+    if (bt != T_VOID) {\n+      arg_num++;\n+    }\n+  }\n+  objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);\n+  objArrayHandle array(THREAD, array_oop);\n+  arg_num = callee->is_static() ? 0 : 1;\n+  int i = 0;\n+  if (allocate_receiver) {\n+    InlineKlass* vk = InlineKlass::cast(holder);\n+    oop res = vk->allocate_instance(CHECK_NULL);\n+    array->obj_at_put(i++, res);\n+  }\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if ((bt == T_OBJECT || bt == T_PRIMITIVE_OBJECT) && callee->is_scalarized_arg(arg_num)) {\n+      InlineKlass* vk = ss.as_inline_klass(holder);\n+      assert(vk != NULL, \"Unexpected klass\");\n+      oop res = vk->allocate_instance(CHECK_NULL);\n+      array->obj_at_put(i++, res);\n+    }\n+    if (bt != T_VOID) {\n+      arg_num++;\n+    }\n+  }\n+  return array();\n+}\n+\n+JRT_ENTRY(void, SharedRuntime::allocate_inline_types(JavaThread* current, Method* callee_method, bool allocate_receiver))\n+  methodHandle callee(current, callee_method);\n+  oop array = SharedRuntime::allocate_inline_types_impl(current, callee, allocate_receiver, CHECK);\n+  current->set_vm_result(array);\n+  current->set_vm_result_2(callee()); \/\/ TODO: required to keep callee live?\n+JRT_END\n+\n+\/\/ We're returning from an interpreted method: load each field into a\n+\/\/ register following the calling convention\n+JRT_LEAF(void, SharedRuntime::load_inline_type_fields_in_regs(JavaThread* current, oopDesc* res))\n+{\n+  assert(res->klass()->is_inline_klass(), \"only inline types here\");\n+  ResourceMark rm;\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+  assert(callerFrame.is_interpreted_frame(), \"should be coming from interpreter\");\n+\n+  InlineKlass* vk = InlineKlass::cast(res->klass());\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  if (regs == NULL) {\n+    \/\/ The fields of the inline klass don't fit in registers, bail out\n+    return;\n+  }\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_PRIMITIVE_OBJECT) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    address loc = reg_map.location(pair.first(), nullptr);\n+    switch(bt) {\n+    case T_BOOLEAN:\n+      *(jboolean*)loc = res->bool_field(off);\n+      break;\n+    case T_CHAR:\n+      *(jchar*)loc = res->char_field(off);\n+      break;\n+    case T_BYTE:\n+      *(jbyte*)loc = res->byte_field(off);\n+      break;\n+    case T_SHORT:\n+      *(jshort*)loc = res->short_field(off);\n+      break;\n+    case T_INT: {\n+      *(jint*)loc = res->int_field(off);\n+      break;\n+    }\n+    case T_LONG:\n+#ifdef _LP64\n+      *(intptr_t*)loc = res->long_field(off);\n+#else\n+      Unimplemented();\n+#endif\n+      break;\n+    case T_OBJECT:\n+    case T_ARRAY: {\n+      *(oop*)loc = res->obj_field(off);\n+      break;\n+    }\n+    case T_FLOAT:\n+      *(jfloat*)loc = res->float_field(off);\n+      break;\n+    case T_DOUBLE:\n+      *(jdouble*)loc = res->double_field(off);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+#ifdef ASSERT\n+  VMRegPair pair = regs->at(0);\n+  address loc = reg_map.location(pair.first(), nullptr);\n+  assert(*(oopDesc**)loc == res, \"overwritten object\");\n+#endif\n+\n+  current->set_vm_result(res);\n+}\n+JRT_END\n+\n+\/\/ We've returned to an interpreted method, the interpreter needs a\n+\/\/ reference to an inline type instance. Allocate it and initialize it\n+\/\/ from field's values in registers.\n+JRT_BLOCK_ENTRY(void, SharedRuntime::store_inline_type_fields_to_buf(JavaThread* current, intptr_t res))\n+{\n+  ResourceMark rm;\n+  RegisterMap reg_map(current,\n+                      RegisterMap::UpdateMap::include,\n+                      RegisterMap::ProcessFrames::include,\n+                      RegisterMap::WalkContinuation::skip);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+\n+#ifdef ASSERT\n+  InlineKlass* verif_vk = InlineKlass::returned_inline_klass(reg_map);\n+#endif\n+\n+  if (!is_set_nth_bit(res, 0)) {\n+    \/\/ We're not returning with inline type fields in registers (the\n+    \/\/ calling convention didn't allow it for this inline klass)\n+    assert(!Metaspace::contains((void*)res), \"should be oop or pointer in buffer area\");\n+    current->set_vm_result((oopDesc*)res);\n+    assert(verif_vk == NULL, \"broken calling convention\");\n+    return;\n+  }\n+\n+  clear_nth_bit(res, 0);\n+  InlineKlass* vk = (InlineKlass*)res;\n+  assert(verif_vk == vk, \"broken calling convention\");\n+  assert(Metaspace::contains((void*)res), \"should be klass\");\n+\n+  \/\/ Allocate handles for every oop field so they are safe in case of\n+  \/\/ a safepoint when allocating\n+  GrowableArray<Handle> handles;\n+  vk->save_oop_fields(reg_map, handles);\n+\n+  \/\/ It's unsafe to safepoint until we are here\n+  JRT_BLOCK;\n+  {\n+    JavaThread* THREAD = current;\n+    oop vt = vk->realloc_result(reg_map, handles, CHECK);\n+    current->set_vm_result(vt);\n+  }\n+  JRT_BLOCK_END;\n+}\n+JRT_END\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":614,"deletions":145,"binary":false,"changes":759,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"asm\/codeBuffer.hpp\"\n@@ -34,0 +35,1 @@\n+#include \"runtime\/signature.hpp\"\n@@ -39,0 +41,1 @@\n+class SigEntry;\n@@ -53,1 +56,1 @@\n-  static methodHandle resolve_sub_helper(bool is_virtual, bool is_optimized, TRAPS);\n+  static methodHandle resolve_sub_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS);\n@@ -63,1 +66,0 @@\n-  static address             _resolve_static_call_entry;\n@@ -86,1 +88,0 @@\n-\n@@ -323,1 +324,1 @@\n-  static methodHandle resolve_helper(bool is_virtual, bool is_optimized, TRAPS);\n+  static methodHandle resolve_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS);\n@@ -331,1 +332,1 @@\n-                                             bool& needs_ic_stub_refill, TRAPS);\n+                                             bool& needs_ic_stub_refill, bool& is_optimized, bool caller_is_c1, TRAPS);\n@@ -337,1 +338,1 @@\n-  static methodHandle reresolve_call_site(TRAPS);\n+  static methodHandle reresolve_call_site(bool& is_static_call, bool& is_optimized, bool& caller_is_c1, TRAPS);\n@@ -341,1 +342,1 @@\n-  static methodHandle handle_ic_miss_helper(TRAPS);\n+  static methodHandle handle_ic_miss_helper(bool& is_optimized, bool& caller_is_c1, TRAPS);\n@@ -350,0 +351,13 @@\n+  static address entry_for_handle_wrong_method(methodHandle callee_method, bool is_static_call, bool is_optimized, bool caller_is_c1) {\n+    assert(callee_method->verified_code_entry() != NULL, \"Jump to zero!\");\n+    assert(callee_method->verified_inline_code_entry() != NULL, \"Jump to zero!\");\n+    assert(callee_method->verified_inline_ro_code_entry() != NULL, \"Jump to zero!\");\n+    if (caller_is_c1) {\n+      return callee_method->verified_inline_code_entry();\n+    } else if (is_static_call || is_optimized) {\n+      return callee_method->verified_code_entry();\n+    } else {\n+      return callee_method->verified_inline_ro_code_entry();\n+    }\n+  }\n+\n@@ -372,0 +386,8 @@\n+  static int java_calling_convention(const GrowableArray<SigEntry>* sig, VMRegPair* regs) {\n+    BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig->length());\n+    int total_args_passed = SigEntry::fill_sig_bt(sig, sig_bt);\n+    return java_calling_convention(sig_bt, regs, total_args_passed);\n+  }\n+  static int java_return_convention(const BasicType* sig_bt, VMRegPair* regs, int total_args_passed);\n+  static const uint java_return_convention_max_int;\n+  static const uint java_return_convention_max_float;\n@@ -419,6 +441,11 @@\n-  static AdapterHandlerEntry* generate_i2c2i_adapters(MacroAssembler *_masm,\n-                                                      int total_args_passed,\n-                                                      int max_arg,\n-                                                      const BasicType *sig_bt,\n-                                                      const VMRegPair *regs,\n-                                                      AdapterFingerPrint* fingerprint);\n+  static AdapterHandlerEntry* generate_i2c2i_adapters(MacroAssembler *masm,\n+                                                      int comp_args_on_stack,\n+                                                      const GrowableArray<SigEntry>* sig,\n+                                                      const VMRegPair* regs,\n+                                                      const GrowableArray<SigEntry>* sig_cc,\n+                                                      const VMRegPair* regs_cc,\n+                                                      const GrowableArray<SigEntry>* sig_cc_ro,\n+                                                      const VMRegPair* regs_cc_ro,\n+                                                      AdapterFingerPrint* fingerprint,\n+                                                      AdapterBlob*& new_adapter,\n+                                                      bool allocate_code_blob);\n@@ -427,2 +454,1 @@\n-                              int total_args_passed,\n-                              const BasicType *sig_bt,\n+                              const GrowableArray<SigEntry>* sig,\n@@ -502,0 +528,3 @@\n+  static void load_inline_type_fields_in_regs(JavaThread* current, oopDesc* res);\n+  static void store_inline_type_fields_to_buf(JavaThread* current, intptr_t res);\n+\n@@ -512,0 +541,2 @@\n+  static void allocate_inline_types(JavaThread* current, Method* callee, bool allocate_receiver);\n+  static oop allocate_inline_types_impl(JavaThread* current, methodHandle callee, bool allocate_receiver, TRAPS);\n@@ -515,0 +546,1 @@\n+  static BufferedInlineTypeBlob* generate_buffered_inline_type_adapter(const InlineKlass* vk);\n@@ -626,0 +658,2 @@\n+  address _c2i_inline_entry;\n+  address _c2i_inline_ro_entry;\n@@ -627,0 +661,1 @@\n+  address _c2i_unverified_inline_entry;\n@@ -629,0 +664,3 @@\n+  \/\/ Support for scalarized inline type calling convention\n+  const GrowableArray<SigEntry>* _sig_cc;\n+\n@@ -637,1 +675,2 @@\n-                      address c2i_unverified_entry,\n+                      address c2i_inline_entry, address c2i_inline_ro_entry,\n+                      address c2i_unverified_entry, address c2i_unverified_inline_entry,\n@@ -642,0 +681,2 @@\n+    _c2i_inline_entry(c2i_inline_entry),\n+    _c2i_inline_ro_entry(c2i_inline_ro_entry),\n@@ -643,1 +684,3 @@\n-    _c2i_no_clinit_check_entry(c2i_no_clinit_check_entry)\n+    _c2i_unverified_inline_entry(c2i_unverified_inline_entry),\n+    _c2i_no_clinit_check_entry(c2i_no_clinit_check_entry),\n+    _sig_cc(NULL)\n@@ -652,4 +695,7 @@\n-  address get_i2c_entry()                  const { return _i2c_entry; }\n-  address get_c2i_entry()                  const { return _c2i_entry; }\n-  address get_c2i_unverified_entry()       const { return _c2i_unverified_entry; }\n-  address get_c2i_no_clinit_check_entry()  const { return _c2i_no_clinit_check_entry; }\n+  address get_i2c_entry()                   const { return _i2c_entry; }\n+  address get_c2i_entry()                   const { return _c2i_entry; }\n+  address get_c2i_inline_entry()            const { return _c2i_inline_entry; }\n+  address get_c2i_inline_ro_entry()         const { return _c2i_inline_ro_entry; }\n+  address get_c2i_unverified_entry()        const { return _c2i_unverified_entry; }\n+  address get_c2i_unverified_inline_entry() const { return _c2i_unverified_inline_entry; }\n+  address get_c2i_no_clinit_check_entry()   const { return _c2i_no_clinit_check_entry; }\n@@ -660,0 +706,4 @@\n+  \/\/ Support for scalarized inline type calling convention\n+  void set_sig_cc(const GrowableArray<SigEntry>* sig)  { _sig_cc = sig; }\n+  const GrowableArray<SigEntry>* get_sig_cc()    const { return _sig_cc; }\n+\n@@ -672,0 +722,2 @@\n+class CompiledEntrySignature;\n+\n@@ -686,2 +738,1 @@\n-                                             int total_args_passed,\n-                                             BasicType* sig_bt,\n+                                             CompiledEntrySignature& ces,\n@@ -693,4 +744,2 @@\n-                                        address i2c_entry,\n-                                        address c2i_entry,\n-                                        address c2i_unverified_entry,\n-                                        address c2i_no_clinit_check_entry = NULL);\n+                                        address i2c_entry, address c2i_entry, address c2i_inline_entry, address c2i_inline_ro_entry,\n+                                        address c2i_unverified_entry, address c2i_unverified_inline_entry, address c2i_no_clinit_check_entry = NULL);\n@@ -709,0 +758,55 @@\n+\/\/ Utility class for computing the calling convention of the 3 types\n+\/\/ of compiled method entries:\n+\/\/     Method::_from_compiled_entry               - sig_cc\n+\/\/     Method::_from_compiled_inline_ro_entry     - sig_cc_ro\n+\/\/     Method::_from_compiled_inline_entry        - sig\n+class CompiledEntrySignature : public StackObj {\n+  Method* _method;\n+  int  _num_inline_args;\n+  bool _has_inline_recv;\n+  GrowableArray<SigEntry> *_sig;\n+  GrowableArray<SigEntry> *_sig_cc;\n+  GrowableArray<SigEntry> *_sig_cc_ro;\n+  VMRegPair* _regs;\n+  VMRegPair* _regs_cc;\n+  VMRegPair* _regs_cc_ro;\n+\n+  int _args_on_stack;\n+  int _args_on_stack_cc;\n+  int _args_on_stack_cc_ro;\n+\n+  bool _c1_needs_stack_repair;\n+  bool _c2_needs_stack_repair;\n+\n+public:\n+  Method* method()                     const { return _method; }\n+\n+  \/\/ Used by Method::_from_compiled_inline_entry\n+  GrowableArray<SigEntry>& sig()       const { return *_sig; }\n+\n+  \/\/ Used by Method::_from_compiled_entry\n+  GrowableArray<SigEntry>& sig_cc()    const { return *_sig_cc; }\n+\n+  \/\/ Used by Method::_from_compiled_inline_ro_entry\n+  GrowableArray<SigEntry>& sig_cc_ro() const { return *_sig_cc_ro; }\n+\n+  VMRegPair* regs()                    const { return _regs; }\n+  VMRegPair* regs_cc()                 const { return _regs_cc; }\n+  VMRegPair* regs_cc_ro()              const { return _regs_cc_ro; }\n+\n+  int args_on_stack()                  const { return _args_on_stack; }\n+  int args_on_stack_cc()               const { return _args_on_stack_cc; }\n+  int args_on_stack_cc_ro()            const { return _args_on_stack_cc_ro; }\n+\n+  int  num_inline_args()               const { return _num_inline_args; }\n+  bool has_inline_recv()               const { return _has_inline_recv; }\n+\n+  bool has_scalarized_args()           const { return _sig != _sig_cc; }\n+  bool c1_needs_stack_repair()         const { return _c1_needs_stack_repair; }\n+  bool c2_needs_stack_repair()         const { return _c2_needs_stack_repair; }\n+  CodeOffsets::Entries c1_inline_ro_entry_type() const;\n+\n+  CompiledEntrySignature(Method* method = NULL);\n+  void compute_calling_conventions(bool init = true);\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":131,"deletions":27,"binary":false,"changes":158,"status":"modified"},{"patch":"@@ -173,0 +173,3 @@\n+address StubRoutines::_load_inline_type_fields_in_regs = NULL;\n+address StubRoutines::_store_inline_type_fields_to_buf = NULL;\n+\n@@ -506,0 +509,1 @@\n+  case T_PRIMITIVE_OBJECT:\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -261,0 +261,3 @@\n+  static address _load_inline_type_fields_in_regs;\n+  static address _store_inline_type_fields_to_buf;\n+\n@@ -456,0 +459,3 @@\n+\n+  static address load_inline_type_fields_in_regs() { return _load_inline_type_fields_in_regs; }\n+  static address store_inline_type_fields_to_buf() { return _store_inline_type_fields_to_buf; }\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -111,0 +111,1 @@\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<PrintClassLayoutDCmd>(full_export, true, false));\n@@ -145,1 +146,0 @@\n-\n@@ -934,1 +934,25 @@\n-#endif\n+\n+PrintClassLayoutDCmd::PrintClassLayoutDCmd(outputStream* output, bool heap) :\n+                                       DCmdWithParser(output, heap),\n+  _classname(\"classname\", \"Name of class whose layout should be printed. \",\n+             \"STRING\", true) {\n+  _dcmdparser.add_dcmd_argument(&_classname);\n+}\n+\n+void PrintClassLayoutDCmd::execute(DCmdSource source, TRAPS) {\n+  VM_PrintClassLayout printClassLayoutOp(output(), _classname.value());\n+  VMThread::execute(&printClassLayoutOp);\n+}\n+\n+int PrintClassLayoutDCmd::num_arguments() {\n+  ResourceMark rm;\n+  PrintClassLayoutDCmd* dcmd = new PrintClassLayoutDCmd(NULL, false);\n+  if (dcmd != NULL) {\n+    DCmdMark mark(dcmd);\n+    return dcmd->_dcmdparser.num_arguments();\n+  } else {\n+    return 0;\n+  }\n+}\n+\n+#endif \/\/ INCLUDE_SERVICES\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":26,"deletions":2,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -629,0 +629,9 @@\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ Prototyping\n+\/\/ \"Code Missing Here\" macro, un-define when integrating back from prototyping stage and break\n+\/\/ compilation on purpose (i.e. \"forget me not\")\n+#define PROTOTYPE\n+#ifdef PROTOTYPE\n+#define CMH(m)\n+#endif\n+\n@@ -714,6 +723,7 @@\n-  T_VOID        = 14,\n-  T_ADDRESS     = 15,\n-  T_NARROWOOP   = 16,\n-  T_METADATA    = 17,\n-  T_NARROWKLASS = 18,\n-  T_CONFLICT    = 19, \/\/ for stack value type with conflicting contents\n+  T_PRIMITIVE_OBJECT = 14,\n+  T_VOID        = 15,\n+  T_ADDRESS     = 16,\n+  T_NARROWOOP   = 17,\n+  T_METADATA    = 18,\n+  T_NARROWKLASS = 19,\n+  T_CONFLICT    = 20, \/\/ for stack value type with conflicting contents\n@@ -734,0 +744,1 @@\n+    F(JVM_SIGNATURE_PRIMITIVE_OBJECT, T_PRIMITIVE_OBJECT, N) \\\n@@ -763,1 +774,1 @@\n-  return (t == T_OBJECT || t == T_ARRAY || (include_narrow_oop && t == T_NARROWOOP));\n+  return (t == T_OBJECT || t == T_ARRAY || t == T_PRIMITIVE_OBJECT || (include_narrow_oop && t == T_NARROWOOP));\n@@ -824,1 +835,2 @@\n-  T_VOID_size        = 0\n+  T_VOID_size        = 0,\n+  T_PRIMITIVE_OBJECT_size = 1\n@@ -854,0 +866,1 @@\n+  T_PRIMITIVE_OBJECT_aelem_bytes = 8,\n@@ -857,0 +870,1 @@\n+  T_PRIMITIVE_OBJECT_aelem_bytes = 4,\n@@ -949,1 +963,1 @@\n-  vtos = 9,             \/\/ tos not cached\n+  vtos = 9,             \/\/ tos not cached,\n@@ -966,1 +980,2 @@\n-    case T_ARRAY  : \/\/ fall through\n+    case T_PRIMITIVE_OBJECT: \/\/ fall through\n+    case T_ARRAY  :   \/\/ fall through\n@@ -1278,0 +1293,6 @@\n+\/\/ TEMP!!!!\n+\/\/ This should be removed after LW2 arrays are implemented (JDK-8220790).\n+\/\/ It's an alias to (EnableValhalla && (FlatArrayElementMaxSize != 0)),\n+\/\/ which is actually not 100% correct, but works for the current set of C1\/C2\n+\/\/ implementation and test cases.\n+#define UseFlatArray (EnableValhalla && (FlatArrayElementMaxSize != 0))\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":31,"deletions":10,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -239,0 +239,2 @@\n+        PRIMITIVE_CLASSES(JDK19, Fragments.FeaturePrimitiveClasses, DiagKind.PLURAL),\n+        VALUE_CLASSES(JDK19, Fragments.FeatureValueClasses, DiagKind.PLURAL),\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Source.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+import com.sun.tools.javac.code.Type.ClassType.Flavor;\n@@ -239,0 +240,69 @@\n+    public boolean isPrimitiveClass() {\n+        return false;\n+    }\n+\n+    public boolean isValueClass() {\n+        return false;\n+    }\n+\n+    public boolean isValueInterface() {\n+        return false;\n+    }\n+\n+    public boolean isIdentityClass() {\n+        return false;\n+    }\n+\n+    public boolean isIdentityInterface() {\n+        return false;\n+    }\n+\n+    \/\/ Does this type need to be preloaded in the context of the referring class ??\n+    public boolean requiresPreload(Symbol referringClass) {\n+        if (this.tsym == referringClass)\n+            return false; \/\/ pointless\n+        if (this.isReferenceProjection())\n+            return true;\n+        return this.isValueClass() && !this.isPrimitiveClass();\n+    }\n+\n+    \/**\n+     * Return the `flavor' associated with a ClassType.\n+     * @see ClassType.Flavor\n+     *\/\n+    public Flavor getFlavor() {\n+        throw new AssertionError(\"Unexpected call to getFlavor() on a Type that is not a ClassType: \" + this);\n+    }\n+\n+    \/**\n+     * @return true IFF the receiver is a reference projection of a primitive class type and false\n+     * for primitives or plain references\n+     *\/\n+    public boolean isReferenceProjection() {\n+        return false;\n+    }\n+\n+    \/**\n+     * @return the value projection type IFF the receiver is a reference projection of a primitive class type\n+     * and null otherwise\n+     *\/\n+    public Type valueProjection() {\n+        return null;\n+    }\n+\n+    \/**\n+     * @return the reference projection type IFF the receiver is a primitive class type\n+     * and null otherwise\n+     *\/\n+    public Type referenceProjection() {\n+        return null;\n+    }\n+\n+    \/**\n+     * @return the reference projection type IFF the receiver is a primitive class type or self otherwise.\n+     *\/\n+    public Type referenceProjectionOrSelf() {\n+        Type projection = referenceProjection();\n+        return projection != null ? projection : this;\n+    }\n+\n@@ -253,1 +323,1 @@\n-            else return new ClassType(outer1, typarams1, t.tsym, t.metadata) {\n+            else return new ClassType(outer1, typarams1, t.tsym, t.metadata, t.getFlavor()) {\n@@ -949,0 +1019,34 @@\n+    public static class ConstantPoolQType implements PoolConstant {\n+\n+        public final Type type;\n+        final Types types;\n+\n+        public ConstantPoolQType(Type type, Types types) {\n+            this.type = type;\n+            this.types = types;\n+        }\n+\n+        @Override\n+        public Object poolKey(Types types) {\n+            return this;\n+        }\n+\n+        @Override\n+        public int poolTag() {\n+            return ClassFile.CONSTANT_Class;\n+        }\n+\n+        public int hashCode() {\n+            return types.hashCode(type);\n+        }\n+\n+        public boolean equals(Object obj) {\n+            return (obj instanceof ConstantPoolQType) &&\n+                    types.isSameType(type, ((ConstantPoolQType)obj).type);\n+        }\n+\n+        public String toString() {\n+            return type.toString();\n+        }\n+    }\n+\n@@ -952,0 +1056,78 @@\n+        \/**\n+         * The 'flavor' of a ClassType indicates its reference\/primitive projectionness\n+         * viewed against the default nature of the associated class.\n+         *\/\n+        public enum Flavor {\n+\n+            \/**\n+             * Classic reference type. Also reference projection type of a reference-favoring aka\n+             * reference-default primitive class type\n+             *\/\n+            L_TypeOf_L,\n+\n+            \/**\n+             * Reference projection type of a primitive-favoring aka primitive-default\n+             * plain vanilla primitive class type,\n+             *\/\n+            L_TypeOf_Q,\n+\n+            \/**\n+             * Value projection type of a primitive-favoring aka primitive-default\n+             * plain vanilla primitive class type,\n+             *\/\n+            Q_TypeOf_Q,\n+\n+            \/**\n+             * Value projection type of a reference-favoring aka\n+             * reference-default primitive class type\n+             *\/\n+            Q_TypeOf_L,\n+\n+            \/**\n+             * Reference projection type of a class type of an as yet unknown default provenance, 'X' will be\n+             * discovered to be 'L' or 'Q' in \"due course\" and mutated suitably.\n+             *\/\n+            L_TypeOf_X,\n+\n+            \/**\n+             * Value projection type of a class type of an as yet unknown default provenance, 'X' will be\n+             * discovered to be 'L' or 'Q' in \"due course\" and mutated suitably.\n+             *\/\n+            Q_TypeOf_X,\n+\n+            \/**\n+             *  As yet unknown projection type of an as yet unknown default provenance class.\n+             *\/\n+            X_Typeof_X,\n+\n+            \/**\n+             *  An error type - we don't care to discriminate them any further.\n+             *\/\n+             E_Typeof_X;\n+\n+            \/\/ We don't seem to need X_Typeof_L or X_Typeof_Q so far.\n+\n+            \/\/ Transform a larval form into a more evolved form\n+            public Flavor metamorphose(boolean isPrimtiveClass) {\n+\n+                switch (this) {\n+\n+                    case E_Typeof_X:  \/\/ stunted form\n+                    case L_TypeOf_L:\n+                    case L_TypeOf_Q:\n+                    case Q_TypeOf_L:\n+                    case Q_TypeOf_Q:\n+                            \/\/ These are fully evolved sealed forms or stunted - no futher transformation\n+                            return this;\n+                    case L_TypeOf_X:\n+                            return isPrimtiveClass ? L_TypeOf_Q : L_TypeOf_L;\n+                    case Q_TypeOf_X:\n+                            return isPrimtiveClass ? Q_TypeOf_Q : Q_TypeOf_L;\n+                    case X_Typeof_X:\n+                            return isPrimtiveClass ? Q_TypeOf_Q : L_TypeOf_L;\n+                    default:\n+                            throw new AssertionError(\"Unexpected class type flavor\");\n+                }\n+            }\n+        }\n+\n@@ -980,0 +1162,13 @@\n+        \/** The 'other' projection: If 'this' is type of a primitive class, then 'projection' is the\n+         *  reference projection type and vice versa. Lazily initialized, not to be accessed directly.\n+        *\/\n+        public ClassType projection;\n+\n+        \/** Is this L of default {L, Q, X} or Q of default {L, Q, X} ?\n+         *\/\n+        public Flavor flavor;\n+\n+        \/*\n+         * Use of this constructor is kinda sorta deprecated, use the other constructor\n+         * that forces the call site to consider and include the class type flavor.\n+         *\/\n@@ -981,1 +1176,1 @@\n-            this(outer, typarams, tsym, TypeMetadata.EMPTY);\n+            this(outer, typarams, tsym, TypeMetadata.EMPTY, Flavor.L_TypeOf_L);\n@@ -985,1 +1180,1 @@\n-                         TypeMetadata metadata) {\n+                         TypeMetadata metadata, Flavor flavor) {\n@@ -992,0 +1187,1 @@\n+            this.flavor = flavor;\n@@ -1000,1 +1196,1 @@\n-            return new ClassType(outer_field, typarams_field, tsym, md) {\n+            return new ClassType(outer_field, typarams_field, tsym, md, flavor) {\n@@ -1018,1 +1214,1 @@\n-            return new ClassType(getEnclosingType(), typarams_field, tsym, metadata) {\n+            return new ClassType(getEnclosingType(), typarams_field, tsym, metadata, flavor) {\n@@ -1061,0 +1257,11 @@\n+            boolean isReferenceProjection;\n+            try {\n+                isReferenceProjection = isReferenceProjection();\n+            } catch (CompletionFailure cf) {\n+                isReferenceProjection = false; \/\/ handle missing types gracefully.\n+            }\n+            if (isReferenceProjection) {\n+                buf.append('.');\n+                buf.append(tsym.name.table.names.ref);\n+            }\n+\n@@ -1092,2 +1299,4 @@\n-                } else if (longform) {\n-                    return sym.getQualifiedName().toString();\n+                }\n+                String s;\n+                if (longform) {\n+                    s =  sym.getQualifiedName().toString();\n@@ -1095,1 +1304,1 @@\n-                    return sym.name.toString();\n+                    s = sym.name.toString();\n@@ -1097,0 +1306,1 @@\n+                return s;\n@@ -1099,0 +1309,4 @@\n+        public Flavor getFlavor() {\n+            return flavor;\n+        }\n+\n@@ -1115,0 +1329,3 @@\n+            if (outer_field != null && outer_field.isReferenceProjection()) {\n+                outer_field = outer_field.valueProjection();\n+            }\n@@ -1146,0 +1363,74 @@\n+        @Override\n+        public boolean isPrimitiveClass() {\n+            return !isReferenceProjection() && tsym != null && tsym.isPrimitiveClass();\n+        }\n+\n+        @Override\n+        public boolean isValueClass() {\n+            return !isReferenceProjection() && tsym != null && tsym.isValueClass();\n+        }\n+\n+        @Override\n+        public boolean isValueInterface() {\n+            return tsym != null && tsym.isValueInterface();\n+        }\n+\n+        @Override\n+        public boolean isIdentityClass() {\n+            return !isReferenceProjection() && tsym != null && tsym.isIdentityClass();\n+        }\n+\n+        @Override\n+        public boolean isIdentityInterface() {\n+            return isInterface() && tsym.isIdentityInterface();\n+        }\n+\n+        @Override\n+        public boolean isReferenceProjection() {\n+            \/\/ gaurd against over-eager and\/or inopportune completion\n+            if (tsym != null) {\n+                if (flavor == Flavor.L_TypeOf_X || tsym.isCompleted()) {\n+                    flavor = flavor.metamorphose(tsym.isPrimitiveClass());\n+                }\n+            }\n+            return flavor == Flavor.L_TypeOf_Q;\n+        }\n+\n+        @Override\n+        public Type valueProjection() {\n+            if (!isReferenceProjection())\n+                return null;\n+\n+            if (projection !=  null)\n+                return projection;\n+\n+            projection = new ClassType(outer_field, typarams_field, tsym, getMetadata(), Flavor.Q_TypeOf_Q);\n+            projection.allparams_field = allparams_field;\n+            projection.supertype_field = supertype_field;\n+\n+            projection.interfaces_field = interfaces_field;\n+            projection.all_interfaces_field = all_interfaces_field;\n+            projection.projection = this;\n+            return projection;\n+        }\n+\n+        \/\/ return the reference projection type preserving parameterizations\n+        @Override\n+        public ClassType referenceProjection() {\n+\n+            if (!isPrimitiveClass())\n+                return null;\n+\n+            if (projection != null)\n+                return projection;\n+\n+            projection = new ClassType(outer_field, typarams_field, tsym, getMetadata(), Flavor.L_TypeOf_Q);\n+            projection.allparams_field = allparams_field;\n+            projection.supertype_field = supertype_field;\n+\n+            projection.interfaces_field = interfaces_field;\n+            projection.all_interfaces_field = all_interfaces_field;\n+            projection.projection = this;\n+            return projection;\n+        }\n+\n@@ -1194,1 +1485,1 @@\n-            super(outer, List.nil(), tsym, metadata);\n+            super(outer, List.nil(), tsym, metadata, tsym.type.getFlavor());\n@@ -2346,2 +2637,1 @@\n-            super(noType, List.nil(), null);\n-            this.tsym = tsym;\n+            super(noType, List.nil(), tsym, TypeMetadata.EMPTY, Flavor.E_Typeof_X);\n@@ -2352,2 +2642,2 @@\n-                          TypeMetadata metadata) {\n-            super(noType, List.nil(), null, metadata);\n+                          TypeMetadata metadata, Flavor flavor) {\n+            super(noType, List.nil(), null, metadata, flavor);\n@@ -2360,1 +2650,1 @@\n-            return new ErrorType(originalType, tsym, md) {\n+            return new ErrorType(originalType, tsym, md, getFlavor()) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Type.java","additions":304,"deletions":14,"binary":false,"changes":318,"status":"modified"},{"patch":"@@ -52,1 +52,0 @@\n-import com.sun.tools.javac.comp.LambdaToMethod;\n@@ -95,0 +94,1 @@\n+    final boolean allowValueBasedClasses;\n@@ -122,0 +122,2 @@\n+        Options options = Options.instance(context);\n+        allowValueBasedClasses = options.isSet(\"allowValueBasedClasses\");\n@@ -270,1 +272,1 @@\n-                else return new ClassType(outer1, typarams1.toList(), t.tsym, t.getMetadata()) {\n+                else return new ClassType(outer1, typarams1.toList(), t.tsym, t.getMetadata(), t.getFlavor()) {\n@@ -601,0 +603,9 @@\n+\n+        boolean tValue = t.isPrimitiveClass();\n+        boolean sValue = s.isPrimitiveClass();\n+        if (tValue != sValue) {\n+            return tValue ?\n+                    isSubtype(t.referenceProjection(), s) :\n+                    !t.hasTag(BOT) && isSubtype(t, s.referenceProjection());\n+        }\n+\n@@ -763,2 +774,4 @@\n-            } else if (abstracts.size() == 1) {\n-                return new FunctionDescriptor(abstracts.first());\n+            }\n+            FunctionDescriptor descRes;\n+            if (abstracts.size() == 1) {\n+                descRes = new FunctionDescriptor(abstracts.first());\n@@ -766,1 +779,1 @@\n-                FunctionDescriptor descRes = mergeDescriptors(origin, abstracts.toList());\n+                descRes = mergeDescriptors(origin, abstracts.toList());\n@@ -785,1 +798,11 @@\n-                return descRes;\n+            \/\/ an interface must be neither an identity interface nor a value interface to be functional.\n+            List<Type> allInterfaces = closure(origin.type);\n+            for (Type iface : allInterfaces) {\n+                if (iface.isValueInterface()) {\n+                    throw failure(\"not.a.functional.intf.1\", origin, diags.fragment(Fragments.ValueInterfaceNonfunctional));\n+                }\n+                if (iface.isIdentityInterface()) {\n+                    throw failure(\"not.a.functional.intf.1\", origin, diags.fragment(Fragments.IdentityInterfaceNonfunctional));\n+                }\n+            }\n+            return descRes;\n@@ -1026,1 +1049,11 @@\n-                    return isSubtypeUncheckedInternal(elemtype(t), elemtype(s), false, warn);\n+                    \/\/ if T.ref <: S, then T[] <: S[]\n+                    Type es = elemtype(s);\n+                    Type et = elemtype(t);\n+                    if (et.isPrimitiveClass()) {\n+                        et = et.referenceProjection();\n+                        if (es.isPrimitiveClass())\n+                            es = es.referenceProjection();  \/\/ V <: V, surely\n+                    }\n+                    if (!isSubtypeUncheckedInternal(et, es, false, warn))\n+                        return false;\n+                    return true;\n@@ -1123,1 +1156,1 @@\n-                         s.hasTag(BOT) || s.hasTag(CLASS) ||\n+                         s.hasTag(BOT) || (s.hasTag(CLASS) && !s.isPrimitiveClass()) ||\n@@ -1190,0 +1223,1 @@\n+                    && (t.tsym != s.tsym || t.isReferenceProjection() == s.isReferenceProjection())\n@@ -1201,2 +1235,11 @@\n-                    else\n-                        return isSubtypeNoCapture(t.elemtype, elemtype(s));\n+                    else {\n+                        \/\/ if T.ref <: S, then T[] <: S[]\n+                        Type es = elemtype(s);\n+                        Type et = elemtype(t);\n+                        if (et.isPrimitiveClass()) {\n+                            et = et.referenceProjection();\n+                            if (es.isPrimitiveClass())\n+                                es = es.referenceProjection();  \/\/ V <: V, surely\n+                        }\n+                        return isSubtypeNoCapture(et, es);\n+                    }\n@@ -1425,1 +1468,2 @@\n-                    && visit(t.getEnclosingType(), s.getEnclosingType())\n+                    && t.isReferenceProjection() == s.isReferenceProjection()\n+                    && visit(getEnclosingType(t), getEnclosingType(s))\n@@ -1428,0 +1472,8 @@\n+                \/\/ where\n+                private Type getEnclosingType(Type t) {\n+                    Type et = t.getEnclosingType();\n+                    if (et.isReferenceProjection()) {\n+                        et = et.valueProjection();\n+                    }\n+                    return et;\n+                }\n@@ -1587,0 +1639,9 @@\n+\n+                    \/\/ -----------------------------------  Unspecified behavior ----------------\n+\n+                    \/* If a primitive class V implements an interface I, then does \"? extends I\" contain V?\n+                       It seems widening must be applied here to answer yes to compile some common code\n+                       patterns.\n+                    *\/\n+\n+                    \/\/ ---------------------------------------------------------------------------\n@@ -1676,1 +1737,1 @@\n-            if (isSubtype(erasure(ts.type), erasure(ss.type))) {\n+            if (isSubtype(erasure(ts.type.referenceProjectionOrSelf()), erasure(ss.type))) {\n@@ -1731,1 +1792,1 @@\n-                if (s.hasTag(ERROR) || s.hasTag(BOT))\n+                if (s.hasTag(ERROR) || (s.hasTag(BOT) && !t.isPrimitiveClass()))\n@@ -1750,0 +1811,8 @@\n+                    if (t.isPrimitiveClass()) {\n+                        \/\/ (s) Value ? == (s) Value.ref\n+                        t = t.referenceProjection();\n+                    }\n+                    if (s.isPrimitiveClass()) {\n+                        \/\/ (Value) t ? == (Value.ref) t\n+                        s = s.referenceProjection();\n+                    }\n@@ -1855,1 +1924,5 @@\n-                        return visit(elemtype(t), elemtype(s));\n+                        Type et = elemtype(t);\n+                        Type es = elemtype(s);\n+                        if (!visit(et, es))\n+                            return false;\n+                        return true;\n@@ -2143,0 +2216,29 @@\n+     * Further caveats in Valhalla: There are two \"hazards\" we need to watch out for when using\n+     * this method.\n+     *\n+     * 1. Since Foo.ref and Foo.val share the same symbol, that of Foo.class, a call to\n+     *    asSuper(Foo.ref.type, Foo.val.type.tsym) would return non-null. This MAY NOT BE correct\n+     *    depending on the call site. Foo.val is NOT a super type of Foo.ref either in the language\n+     *    model or in the VM's world view. An example of such an hazardous call used to exist in\n+     *    Gen.visitTypeCast. When we emit code for  (Foo) Foo.ref.instance a check for whether we\n+     *    really need the cast cannot\/shouldn't be gated on\n+     *\n+     *        asSuper(tree.expr.type, tree.clazz.type.tsym) == null)\n+     *\n+     *    but use !types.isSubtype(tree.expr.type, tree.clazz.type) which operates in terms of\n+     *    types. When we operate in terms of symbols, there is a loss of type information leading\n+     *    to a hazard. Whether a call to asSuper should be transformed into a isSubtype call is\n+     *    tricky. isSubtype returns just a boolean while asSuper returns richer information which\n+     *    may be required at the call site. Also where the concerned symbol corresponds to a\n+     *    generic class, an asSuper call cannot be conveniently rewritten as an isSubtype call\n+     *    (see that asSuper(ArrayList<String>.type, List<T>.tsym) != null while\n+     *    isSubType(ArrayList<String>.type, List<T>.type) is false;) So care needs to be exercised.\n+     *\n+     * 2. Given a primitive class Foo, a call to asSuper(Foo.type, SuperclassOfFoo.tsym) and\/or\n+     *    a call to asSuper(Foo.type, SuperinterfaceOfFoo.tsym) would answer null. In many places\n+     *    that is NOT what we want. An example of such a hazardous call used to occur in\n+     *    Attr.visitForeachLoop when checking to make sure the for loop's control variable of a type\n+     *    that implements Iterable: viz: types.asSuper(exprType, syms.iterableType.tsym);\n+     *    These hazardous calls should be rewritten as\n+     *    types.asSuper(exprType.referenceProjectionOrSelf(), syms.iterableType.tsym); instead.\n+     *\n@@ -2155,0 +2257,6 @@\n+\n+        if (t.isPrimitiveClass()) {\n+            \/\/ No man may be an island, but the bell tolls for a value.\n+            return t.tsym == sym ? t : null;\n+        }\n+\n@@ -2285,3 +2393,12 @@\n-        return (sym.flags() & STATIC) != 0\n-            ? sym.type\n-            : memberType.visit(t, sym);\n+\n+        if ((sym.flags() & STATIC) != 0)\n+            return sym.type;\n+\n+        \/* If any primitive class types are involved, switch over to the reference universe,\n+           where the hierarchy is navigable. V and V.ref have identical membership\n+           with no bridging needs.\n+        *\/\n+        if (t.isPrimitiveClass())\n+            t = t.referenceProjection();\n+\n+        return memberType.visit(t, sym);\n@@ -2440,7 +2557,19 @@\n-                Type erased = t.tsym.erasure(Types.this);\n-                if (recurse) {\n-                    erased = new ErasedClassType(erased.getEnclosingType(),erased.tsym,\n-                            t.getMetadata().without(Kind.ANNOTATIONS));\n-                    return erased;\n-                } else {\n-                    return combineMetadata(erased, t);\n+                \/\/ erasure(projection(primitive)) = projection(erasure(primitive))\n+                Type erased = eraseClassType(t, recurse);\n+                if (erased.hasTag(CLASS) && t.flavor != erased.getFlavor()) {\n+                    erased = new ClassType(erased.getEnclosingType(),\n+                            List.nil(), erased.tsym,\n+                            erased.getMetadata(), t.flavor);\n+                }\n+                return erased;\n+            }\n+                \/\/ where\n+                private Type eraseClassType(ClassType t, Boolean recurse) {\n+                    Type erased = t.tsym.erasure(Types.this);\n+                    if (recurse) {\n+                        erased = new ErasedClassType(erased.getEnclosingType(), erased.tsym,\n+                                t.getMetadata().without(Kind.ANNOTATIONS));\n+                        return erased;\n+                    } else {\n+                        return combineMetadata(erased, t);\n+                    }\n@@ -2448,1 +2577,0 @@\n-            }\n@@ -2497,0 +2625,1 @@\n+        long flags = ABSTRACT | PUBLIC | SYNTHETIC | COMPOUND | ACYCLIC;\n@@ -2498,1 +2627,1 @@\n-            new ClassSymbol(ABSTRACT|PUBLIC|SYNTHETIC|COMPOUND|ACYCLIC,\n+            new ClassSymbol(flags,\n@@ -2768,1 +2897,1 @@\n-                                         t.getMetadata());\n+                                         t.getMetadata(), t.getFlavor());\n@@ -3893,1 +4022,1 @@\n-                                 class1.tsym);\n+                                 class1.tsym, TypeMetadata.EMPTY, class1.getFlavor());\n@@ -3965,1 +4094,0 @@\n-\n@@ -4453,1 +4581,1 @@\n-                                 cls.getMetadata());\n+                                 cls.getMetadata(), cls.getFlavor());\n@@ -4864,0 +4992,1 @@\n+        private boolean encodeTypeSig;\n@@ -4865,1 +4994,1 @@\n-        public UniqueType(Type type, Types types) {\n+        public UniqueType(Type type, Types types, boolean encodeTypeSig) {\n@@ -4868,0 +4997,5 @@\n+            this.encodeTypeSig = encodeTypeSig;\n+        }\n+\n+        public UniqueType(Type type, Types types) {\n+            this(type, types, true);\n@@ -4879,0 +5013,4 @@\n+        public boolean encodeTypeSig() {\n+            return encodeTypeSig;\n+        }\n+\n@@ -5117,1 +5255,4 @@\n-                    append('L');\n+                    if (type.isPrimitiveClass())\n+                        append('Q');\n+                    else\n+                        append('L');\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Types.java","additions":173,"deletions":32,"binary":false,"changes":205,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+import com.sun.tools.javac.code.Type.ClassType.Flavor;\n@@ -170,0 +171,1 @@\n+        allowPrimitiveClasses = Feature.PRIMITIVE_CLASSES.allowedInSource(source);\n@@ -197,0 +199,4 @@\n+    \/** Switch: allow primitive classes ?\n+     *\/\n+    boolean allowPrimitiveClasses;\n+\n@@ -812,1 +818,1 @@\n-                List<Type> bounds = List.of(attribType(tvar.bounds.head, env));\n+                List<Type> bounds = List.of(chk.checkRefType(tvar.bounds.head, attribType(tvar.bounds.head, env), false));\n@@ -814,1 +820,1 @@\n-                    bounds = bounds.prepend(attribType(bound, env));\n+                    bounds = bounds.prepend(chk.checkRefType(bound, attribType(bound, env), false));\n@@ -1201,1 +1207,1 @@\n-                            TreeInfo.getConstructorInvocationName(body.stats, names) == names.empty) {\n+                            TreeInfo.getConstructorInvocationName(body.stats, names, true) == names.empty) {\n@@ -1214,0 +1220,6 @@\n+                    } else if ((env.enclClass.sym.flags() & VALUE_CLASS) != 0 &&\n+                        (tree.mods.flags & GENERATEDCONSTR) == 0 &&\n+                        TreeInfo.isSuperCall(body.stats.head)) {\n+                        \/\/ value constructors are not allowed to call super directly,\n+                        \/\/ but tolerate compiler generated ones, these are ignored during code generation\n+                        log.error(tree.body.stats.head.pos(), Errors.CallToSuperNotAllowedInValueCtor);\n@@ -1301,0 +1313,3 @@\n+            \/* Don't want constant propagation\/folding for instance fields of primitive classes,\n+               as these can undergo updates via copy on write.\n+            *\/\n@@ -1302,1 +1317,1 @@\n-                if ((v.flags_field & FINAL) == 0 ||\n+                if ((v.flags_field & FINAL) == 0 || ((v.flags_field & STATIC) == 0 && v.owner.isValueClass()) ||\n@@ -1342,1 +1357,2 @@\n-        return false;\n+        \/\/ isValueObject is not included in Object yet so we need a work around\n+        return name == names.isValueObject;\n@@ -1534,1 +1550,1 @@\n-                Type base = types.asSuper(exprType, syms.iterableType.tsym);\n+                Type base = types.asSuper(exprType.referenceProjectionOrSelf(), syms.iterableType.tsym);\n@@ -1550,1 +1566,1 @@\n-                    if (types.asSuper(iterSymbol.type.getReturnType(), syms.iteratorType.tsym) == null) {\n+                    if (types.asSuper(iterSymbol.type.getReturnType().referenceProjectionOrSelf(), syms.iteratorType.tsym) == null) {\n@@ -1869,1 +1885,1 @@\n-        chk.checkRefType(tree.pos(), attribExpr(tree.lock, env));\n+        chk.checkIdentityType(tree.pos(), attribExpr(tree.lock, env));\n@@ -1958,1 +1974,1 @@\n-            types.asSuper(resource, syms.autoCloseableType.tsym) != null &&\n+            types.asSuper(resource.referenceProjectionOrSelf(), syms.autoCloseableType.tsym) != null &&\n@@ -2148,1 +2164,2 @@\n-            \/\/ Those were all the cases that could result in a primitive\n+            \/\/ Those were all the cases that could result in a primitive. See if primitive boxing and primitive\n+            \/\/ value conversions bring about a convergence.\n@@ -2150,1 +2167,2 @@\n-                                 .map(t -> t.isPrimitive() ? types.boxedClass(t).type : t)\n+                                 .map(t -> t.isPrimitive() ? types.boxedClass(t).type\n+                                         : t.isReferenceProjection() ? t.valueProjection() : t)\n@@ -2161,1 +2179,1 @@\n-                                 .map(t -> chk.checkNonVoid(posIt.next(), t))\n+                                 .map(t -> chk.checkNonVoid(posIt.next(), t.isPrimitiveClass() ? t.referenceProjection() : t))\n@@ -2164,1 +2182,1 @@\n-            \/\/ both are known to be reference types.  The result is\n+            \/\/ both are known to be reference types (or projections).  The result is\n@@ -2605,0 +2623,4 @@\n+                \/\/ Special treatment for primitive classes: Given an expression v of type V where\n+                \/\/ V is a primitive class, v.getClass() is typed to be Class<? extends |V.ref|>\n+                Type wcb = types.erasure(qualifierType.isPrimitiveClass() ?\n+                                                qualifierType.referenceProjection() : qualifierType);\n@@ -2606,1 +2628,1 @@\n-                        List.of(new WildcardType(types.erasure(qualifierType),\n+                        List.of(new WildcardType(wcb,\n@@ -2610,1 +2632,2 @@\n-                        restype.getMetadata());\n+                        restype.getMetadata(),\n+                        restype.getFlavor());\n@@ -2779,0 +2802,8 @@\n+            \/\/ Check that it is an instantiation of a class and not a projection type\n+            if (clazz.hasTag(SELECT)) {\n+                JCFieldAccess fieldAccess = (JCFieldAccess) clazz;\n+                if (fieldAccess.selected.type.isPrimitiveClass() &&\n+                        (fieldAccess.name == names.ref || fieldAccess.name == names.val)) {\n+                    log.error(tree.pos(), Errors.ProjectionCantBeInstantiated);\n+                }\n+            }\n@@ -2803,1 +2834,2 @@\n-                                               clazztype.getMetadata());\n+                                               clazztype.getMetadata(),\n+                                               clazztype.getFlavor());\n@@ -2957,0 +2989,1 @@\n+                    chk.checkParameterizationByPrimitiveClass(tree, clazztype);\n@@ -3029,0 +3062,3 @@\n+        \/\/ Likewise arg can't be null if it is a primitive class instance.\n+        if (arg.type.isPrimitiveClass())\n+            return arg;\n@@ -4043,0 +4079,1 @@\n+                chk.checkForSuspectClassLiteralComparison(tree, left, right);\n@@ -4354,0 +4391,10 @@\n+        Assert.check(site == tree.selected.type);\n+        if (tree.name == names._class && site.isPrimitiveClass()) {\n+            \/* JDK-8269956: Where a reflective (class) literal is needed, the unqualified Point.class is\n+             * always the \"primary\" mirror - representing the primitive reference runtime type - thereby\n+             * always matching the behavior of Object::getClass\n+             *\/\n+             if (!tree.selected.hasTag(SELECT) || ((JCFieldAccess) tree.selected).name != names.val) {\n+                 tree.selected.setType(site = site.referenceProjection());\n+             }\n+        }\n@@ -4366,1 +4413,1 @@\n-                return ;\n+                return;\n@@ -4374,0 +4421,1 @@\n+\n@@ -4470,1 +4518,1 @@\n-                Type site1 = types.asSuper(env.enclClass.sym.type, site.tsym);\n+                Type site1 = types.asSuper(env.enclClass.sym.type.referenceProjectionOrSelf(), site.tsym);\n@@ -4513,0 +4561,2 @@\n+                } else if (site.isPrimitiveClass() && isType(location) && resultInfo.pkind.contains(KindSelector.TYP) && (name == names.ref || name == names.val)) {\n+                    return site.tsym;\n@@ -4616,1 +4666,1 @@\n-                \/\/ except for two situations:\n+                \/\/ except for three situations:\n@@ -4619,0 +4669,1 @@\n+                    Assert.check(owntype.getFlavor() != Flavor.X_Typeof_X);\n@@ -4622,1 +4673,8 @@\n-                    \/\/ (a) If the symbol's type is parameterized, erase it\n+                    \/\/ (a) If symbol is a primitive class and its reference projection\n+                    \/\/ is requested via the .ref notation, then adjust the computed type to\n+                    \/\/ reflect this.\n+                    if (owntype.isPrimitiveClass() && tree.hasTag(SELECT) && ((JCFieldAccess) tree).name == names.ref) {\n+                        owntype = new ClassType(owntype.getEnclosingType(), owntype.getTypeArguments(), (TypeSymbol)sym, owntype.getMetadata(), Flavor.L_TypeOf_Q);\n+                    }\n+\n+                    \/\/ (b) If the symbol's type is parameterized, erase it\n@@ -4629,1 +4687,1 @@\n-                    \/\/ (b) If the symbol's type is an inner class, then\n+                    \/\/ (c) If the symbol's type is an inner class, then\n@@ -4649,1 +4707,1 @@\n-                                owntype.getMetadata());\n+                                owntype.getMetadata(), owntype.getFlavor());\n@@ -4966,0 +5024,28 @@\n+    public void visitDefaultValue(JCDefaultValue tree) {\n+        if (!allowPrimitiveClasses) {\n+            log.error(DiagnosticFlag.SOURCE_LEVEL, tree.pos(),\n+                    Feature.PRIMITIVE_CLASSES.error(sourceName));\n+        }\n+\n+        \/\/ Attribute the qualifier expression, and determine its symbol (if any).\n+        Type site = attribTree(tree.clazz, env, new ResultInfo(KindSelector.TYP_PCK, Type.noType));\n+        if (!pkind().contains(KindSelector.TYP_PCK))\n+            site = capture(site); \/\/ Capture field access\n+\n+        Symbol sym = switch (site.getTag()) {\n+                case WILDCARD -> throw new AssertionError(tree);\n+                case PACKAGE -> {\n+                    log.error(tree.pos, Errors.CantResolveLocation(Kinds.KindName.CLASS, site.tsym.getQualifiedName(), null, null,\n+                            Fragments.Location(Kinds.typeKindName(env.enclClass.type), env.enclClass.type, null)));\n+                    yield syms.errSymbol;\n+                }\n+                case ERROR -> types.createErrorType(names._default, site.tsym, site).tsym;\n+                default -> new VarSymbol(STATIC, names._default, site, site.tsym);\n+        };\n+\n+        if (site.hasTag(TYPEVAR) && sym.kind != ERR) {\n+            site = types.skipTypeVars(site, true);\n+        }\n+        result = checkId(tree, site, sym, env, resultInfo);\n+    }\n+\n@@ -5032,1 +5118,1 @@\n-                                        clazztype.getMetadata());\n+                                        clazztype.getMetadata(), clazztype.getFlavor());\n@@ -5159,1 +5245,1 @@\n-                make.Modifiers(PUBLIC | ABSTRACT),\n+                make.Modifiers(PUBLIC | ABSTRACT | (extending != null && TreeInfo.symbol(extending).isPrimitiveClass() ? PRIMITIVE_CLASS : 0)),\n@@ -5182,1 +5268,1 @@\n-        result = check(tree, new WildcardType(chk.checkRefType(tree.pos(), type),\n+        result = check(tree, new WildcardType(chk.checkRefType(tree.pos(), type, false),\n@@ -5300,0 +5386,5 @@\n+            if (c.type.isPrimitiveClass()) {\n+                final Env<AttrContext> env = typeEnvs.get(c);\n+                if (env != null && env.tree != null && env.tree.hasTag(CLASSDEF))\n+                    chk.checkNonCyclicMembership((JCClassDecl)env.tree);\n+            }\n@@ -5420,1 +5511,1 @@\n-            } else {\n+            } else if ((c.flags_field & Flags.COMPOUND) == 0) {\n@@ -5475,0 +5566,5 @@\n+                if (c.isValueClass()) {\n+                    Assert.check(env.tree.hasTag(CLASSDEF));\n+                    chk.checkConstraintsOfValueClass(env.tree.pos(), c);\n+                }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":122,"deletions":26,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -146,1 +146,0 @@\n-\n@@ -511,1 +510,1 @@\n-\/* *************************************************************************\n+    \/* *************************************************************************\n@@ -617,0 +616,5 @@\n+        } else {\n+            if (found.hasTag(CLASS)) {\n+                if (inferenceContext != infer.emptyContext)\n+                    checkParameterizationByPrimitiveClass(pos, found);\n+            }\n@@ -747,0 +751,53 @@\n+    void checkConstraintsOfValueClass(DiagnosticPosition pos, ClassSymbol c) {\n+        for (Type st : types.closure(c.type)) {\n+            if (st == null || st.tsym == null || st.tsym.kind == ERR)\n+                continue;\n+            if  (st.tsym == syms.objectType.tsym || st.tsym == syms.recordType.tsym || st.isInterface())\n+                continue;\n+            if (!st.tsym.isAbstract()) {\n+                if (c != st.tsym) {\n+                    log.error(pos, Errors.ConcreteSupertypeForValueClass(c, st));\n+                }\n+                continue;\n+            }\n+            \/\/ dealing with an abstract value or value super class below.\n+            Fragment fragment = c.isAbstract() && c.isValueClass() && c == st.tsym ? Fragments.AbstractValueClass(c) : Fragments.SuperclassOfValueClass(c, st);\n+            if ((st.tsym.flags() & HASINITBLOCK) != 0) {\n+                log.error(pos, Errors.SuperClassDeclaresInitBlock(fragment));\n+            }\n+            \/\/ No instance fields and no arged constructors both mean inner classes\n+            \/\/ cannot be super classes for primitive classes.\n+            Type encl = st.getEnclosingType();\n+            if (encl != null && encl.hasTag(CLASS)) {\n+                log.error(pos, Errors.SuperClassCannotBeInner(fragment));\n+            }\n+            for (Symbol s : st.tsym.members().getSymbols(NON_RECURSIVE)) {\n+                switch (s.kind) {\n+                case VAR:\n+                    if ((s.flags() & STATIC) == 0) {\n+                        log.error(pos, Errors.SuperFieldNotAllowed(s, fragment));\n+                    }\n+                    break;\n+                case MTH:\n+                    if ((s.flags() & (SYNCHRONIZED | STATIC)) == SYNCHRONIZED) {\n+                        log.error(pos, Errors.SuperMethodCannotBeSynchronized(s, c, st));\n+                    } else if (s.isConstructor()) {\n+                        MethodSymbol m = (MethodSymbol)s;\n+                        if (m.getParameters().size() > 0) {\n+                            log.error(pos, Errors.SuperConstructorCannotTakeArguments(m, fragment));\n+                        } else if (m.getTypeParameters().size() > 0) {\n+                            log.error(pos, Errors.SuperConstructorCannotBeGeneric(m, fragment));\n+                        } else if (m.type.getThrownTypes().size() > 0) {\n+                            log.error(pos, Errors.SuperConstructorCannotThrow(m, fragment));\n+                        } else if (protection(m.flags()) > protection(m.owner.flags())) {\n+                            log.error(pos, Errors.SuperConstructorAccessRestricted(m, fragment));\n+                        } else if ((m.flags() & EMPTYNOARGCONSTR) == 0) {\n+                                log.error(pos, Errors.SuperNoArgConstructorMustBeEmpty(m, fragment));\n+                        }\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n@@ -749,2 +806,2 @@\n-    Type checkConstructorRefType(DiagnosticPosition pos, Type t) {\n-        t = checkClassOrArrayType(pos, t);\n+    Type checkConstructorRefType(JCExpression expr, Type t) {\n+        t = checkClassOrArrayType(expr, t);\n@@ -753,1 +810,1 @@\n-                log.error(pos, Errors.AbstractCantBeInstantiated(t.tsym));\n+                log.error(expr, Errors.AbstractCantBeInstantiated(t.tsym));\n@@ -756,1 +813,1 @@\n-                log.error(pos, Errors.EnumCantBeInstantiated);\n+                log.error(expr, Errors.EnumCantBeInstantiated);\n@@ -759,1 +816,10 @@\n-                t = checkClassType(pos, t, true);\n+                \/\/ Projection types may not be mentioned in constructor references\n+                if (expr.hasTag(SELECT)) {\n+                    JCFieldAccess fieldAccess = (JCFieldAccess) expr;\n+                    if (fieldAccess.selected.type.isPrimitiveClass() &&\n+                            (fieldAccess.name == names.ref || fieldAccess.name == names.val)) {\n+                        log.error(expr, Errors.ProjectionCantBeInstantiated);\n+                        t = types.createErrorType(t);\n+                    }\n+                }\n+                t = checkClassType(expr, t, true);\n@@ -763,1 +829,1 @@\n-                log.error(pos, Errors.GenericArrayCreation);\n+                log.error(expr, Errors.GenericArrayCreation);\n@@ -794,0 +860,1 @@\n+     *  @param primitiveClassOK       If false, a primitive class does not qualify\n@@ -795,2 +862,2 @@\n-    Type checkRefType(DiagnosticPosition pos, Type t) {\n-        if (t.isReference())\n+    Type checkRefType(DiagnosticPosition pos, Type t, boolean primitiveClassOK) {\n+        if (t.isReference() && (primitiveClassOK || !t.isPrimitiveClass()))\n@@ -804,0 +871,31 @@\n+    \/** Check that type is an identity type, i.e. not a primitive\/value type\n+     *  nor its reference projection. When not discernible statically,\n+     *  give it the benefit of doubt and defer to runtime.\n+     *\n+     *  @param pos           Position to be used for error reporting.\n+     *  @param t             The type to be checked.\n+     *\/\n+    void checkIdentityType(DiagnosticPosition pos, Type t) {\n+        if (t.hasTag(TYPEVAR)) {\n+            t = types.skipTypeVars(t, false);\n+        }\n+        if (t.isIntersection()) {\n+            IntersectionClassType ict = (IntersectionClassType)t;\n+            for (Type component : ict.getExplicitComponents()) {\n+                checkIdentityType(pos, component);\n+            }\n+            return;\n+        }\n+        if (t.isPrimitive() || t.isValueClass() || t.isValueInterface() || t.isReferenceProjection())\n+            typeTagError(pos, diags.fragment(Fragments.TypeReqIdentity), t);\n+    }\n+\n+    \/** Check that type is a reference type, i.e. a class, interface or array type\n+     *  or a type variable.\n+     *  @param pos           Position to be used for error reporting.\n+     *  @param t             The type to be checked.\n+     *\/\n+    Type checkRefType(DiagnosticPosition pos, Type t) {\n+        return checkRefType(pos, t, true);\n+    }\n+\n@@ -812,1 +910,1 @@\n-            l.head = checkRefType(tl.head.pos(), l.head);\n+            l.head = checkRefType(tl.head.pos(), l.head, false);\n@@ -848,0 +946,49 @@\n+    void checkParameterizationByPrimitiveClass(DiagnosticPosition pos, Type t) {\n+        parameterizationByPrimitiveClassChecker.visit(t, pos);\n+    }\n+\n+    \/** parameterizationByPrimitiveClassChecker: A type visitor that descends down the given type looking for instances of primitive classes\n+     *  being used as type arguments and issues error against those usages.\n+     *\/\n+    private final Types.SimpleVisitor<Void, DiagnosticPosition> parameterizationByPrimitiveClassChecker =\n+            new Types.SimpleVisitor<Void, DiagnosticPosition>() {\n+\n+        @Override\n+        public Void visitType(Type t, DiagnosticPosition pos) {\n+            return null;\n+        }\n+\n+        @Override\n+        public Void visitClassType(ClassType t, DiagnosticPosition pos) {\n+            for (Type targ : t.allparams()) {\n+                if (targ.isPrimitiveClass()) {\n+                    log.error(pos, Errors.GenericParameterizationWithPrimitiveClass(t));\n+                }\n+                visit(targ, pos);\n+            }\n+            return null;\n+        }\n+\n+        @Override\n+        public Void visitTypeVar(TypeVar t, DiagnosticPosition pos) {\n+             return null;\n+        }\n+\n+        @Override\n+        public Void visitCapturedType(CapturedType t, DiagnosticPosition pos) {\n+            return null;\n+        }\n+\n+        @Override\n+        public Void visitArrayType(ArrayType t, DiagnosticPosition pos) {\n+            return visit(t.elemtype, pos);\n+        }\n+\n+        @Override\n+        public Void visitWildcardType(WildcardType t, DiagnosticPosition pos) {\n+            return visit(t.type, pos);\n+        }\n+    };\n+\n+\n+\n@@ -996,1 +1143,38 @@\n-        return types.upward(t, types.captures(t));\n+        Type varType = types.upward(t, types.captures(t));\n+        if (varType.hasTag(CLASS)) {\n+            checkParameterizationByPrimitiveClass(pos, varType);\n+        }\n+        return varType;\n+    }\n+\n+    public void checkForSuspectClassLiteralComparison(\n+            final JCBinary tree,\n+            final Type leftType,\n+            final Type rightType) {\n+\n+        if (lint.isEnabled(LintCategory.MIGRATION)) {\n+            if (isInvocationOfGetClass(tree.lhs) && isClassOfSomeInterface(rightType) ||\n+                    isInvocationOfGetClass(tree.rhs) && isClassOfSomeInterface(leftType)) {\n+                log.warning(LintCategory.MIGRATION, tree.pos(), Warnings.GetClassComparedWithInterface);\n+            }\n+        }\n+    }\n+    \/\/where\n+    private boolean isClassOfSomeInterface(Type someClass) {\n+        if (someClass.tsym.flatName() == names.java_lang_Class) {\n+            List<Type> arguments = someClass.getTypeArguments();\n+            if (arguments.length() == 1) {\n+                return arguments.head.isInterface();\n+            }\n+        }\n+        return false;\n+    }\n+    \/\/where\n+    private boolean isInvocationOfGetClass(JCExpression tree) {\n+        tree = TreeInfo.skipParens(tree);\n+        if (tree.hasTag(APPLY)) {\n+            JCMethodInvocation apply = (JCMethodInvocation)tree;\n+            MethodSymbol msym = (MethodSymbol)TreeInfo.symbol(apply.meth);\n+            return msym.name == names.getClass && msym.implementedIn(syms.objectType.tsym, types) != null;\n+        }\n+        return false;\n@@ -1194,1 +1378,1 @@\n-            else\n+            else {\n@@ -1196,0 +1380,4 @@\n+                if (sym.owner.type.isValueClass() && (flags & STATIC) == 0) {\n+                    implicit |= FINAL;\n+                }\n+            }\n@@ -1221,1 +1409,2 @@\n-                mask = RecordMethodFlags;\n+                mask = ((sym.owner.flags_field & VALUE_CLASS) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        RecordMethodFlags & ~SYNCHRONIZED : RecordMethodFlags;\n@@ -1223,1 +1412,3 @@\n-                mask = MethodFlags;\n+                \/\/ value objects do not have an associated monitor\/lock\n+                mask = ((sym.owner.flags_field & VALUE_CLASS) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        MethodFlags & ~SYNCHRONIZED : MethodFlags;\n@@ -1240,1 +1431,1 @@\n-                mask = staticOrImplicitlyStatic && allowRecords && (flags & ANNOTATION) == 0 ? StaticLocalFlags : LocalClassFlags;\n+                mask = staticOrImplicitlyStatic && allowRecords && (flags & ANNOTATION) == 0 ? ExtendedStaticLocalClassFlags : ExtendedLocalClassFlags;\n@@ -1260,2 +1451,2 @@\n-                \/\/ enums can't be declared abstract, final, sealed or non-sealed\n-                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED);\n+                \/\/ enums can't be declared abstract, final, sealed or non-sealed or primitive\/value\n+                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED | PRIMITIVE_CLASS | VALUE_CLASS);\n@@ -1274,0 +1465,17 @@\n+\n+            \/\/ primitive classes are implicitly final value classes.\n+            if ((flags & PRIMITIVE_CLASS) != 0)\n+                implicit |= VALUE_CLASS | FINAL;\n+\n+            \/\/ concrete value classes are implicitly final\n+            if ((flags & (ABSTRACT | INTERFACE | VALUE_CLASS)) == VALUE_CLASS) {\n+                implicit |= FINAL;\n+                if ((flags & NON_SEALED) != 0) {\n+                    \/\/ cant declare a final value class non-sealed\n+                    log.error(pos,\n+                            Errors.ModNotAllowedHere(asFlagSet(NON_SEALED)));\n+                }\n+            }\n+\n+            \/\/ TYPs can't be declared synchronized\n+            mask &= ~SYNCHRONIZED;\n@@ -1302,1 +1510,5 @@\n-                               FINAL | NATIVE | SYNCHRONIZED)\n+                               FINAL | NATIVE | SYNCHRONIZED | PRIMITIVE_CLASS)\n+                 &&\n+                 checkDisjoint(pos, flags,\n+                        IDENTITY_TYPE,\n+                        PRIMITIVE_CLASS | VALUE_CLASS)\n@@ -1312,1 +1524,1 @@\n-                 checkDisjoint(pos, flags,\n+                 checkDisjoint(pos, (flags | implicit), \/\/ complain against volatile & implcitly final entities too.\n@@ -1328,1 +1540,7 @@\n-                                ANNOTATION)) {\n+                                ANNOTATION)\n+                 && checkDisjoint(pos, flags,\n+                                IDENTITY_TYPE,\n+                                ANNOTATION)\n+                && checkDisjoint(pos, flags,\n+                                VALUE_CLASS,\n+                                ANNOTATION) ) {\n@@ -1501,1 +1719,2 @@\n-                tree.selected.type.isParameterized()) {\n+                tree.selected.type.isParameterized() &&\n+                    (tree.name != names.ref || !tree.type.isReferenceProjection())) {\n@@ -1505,0 +1724,2 @@\n+                \/\/ Tolerate the pseudo-select V.ref: V<T>.ref will be static if V<T> is and\n+                \/\/ should not be confused as selecting a static member of a parameterized type.\n@@ -2290,0 +2511,38 @@\n+    \/\/ A primitive class cannot contain a field of its own type either or indirectly.\n+    void checkNonCyclicMembership(JCClassDecl tree) {\n+        Assert.check((tree.sym.flags_field & LOCKED) == 0);\n+        try {\n+            tree.sym.flags_field |= LOCKED;\n+            for (List<? extends JCTree> l = tree.defs; l.nonEmpty(); l = l.tail) {\n+                if (l.head.hasTag(VARDEF)) {\n+                    JCVariableDecl field = (JCVariableDecl) l.head;\n+                    if (cyclePossible(field.sym)) {\n+                        checkNonCyclicMembership((ClassSymbol) field.type.tsym, field.pos());\n+                    }\n+                }\n+            }\n+        } finally {\n+            tree.sym.flags_field &= ~LOCKED;\n+        }\n+\n+    }\n+    \/\/ where\n+    private void checkNonCyclicMembership(ClassSymbol c, DiagnosticPosition pos) {\n+        if ((c.flags_field & LOCKED) != 0) {\n+            log.error(pos, Errors.CyclicPrimitiveClassMembership(c));\n+            return;\n+        }\n+        try {\n+            c.flags_field |= LOCKED;\n+            for (Symbol fld : c.members().getSymbols(s -> s.kind == VAR && cyclePossible((VarSymbol) s), NON_RECURSIVE)) {\n+                checkNonCyclicMembership((ClassSymbol) fld.type.tsym, pos);\n+            }\n+        } finally {\n+            c.flags_field &= ~LOCKED;\n+        }\n+    }\n+        \/\/ where\n+        private boolean cyclePossible(VarSymbol symbol) {\n+            return (symbol.flags() & STATIC) == 0 && symbol.type.isPrimitiveClass();\n+        }\n+\n@@ -2538,0 +2797,22 @@\n+\n+        boolean cIsValue = (c.tsym.flags() & VALUE_CLASS) != 0;\n+        boolean cHasIdentity = (c.tsym.flags() & IDENTITY_TYPE) != 0;\n+        Type identitySuper = null, valueSuper = null;\n+        for (Type t : types.closure(c)) {\n+            if (t != c) {\n+                if ((t.tsym.flags() & IDENTITY_TYPE) != 0)\n+                    identitySuper = t;\n+                else if ((t.tsym.flags() & VALUE_CLASS) != 0)\n+                    valueSuper = t;\n+                if (cIsValue &&  identitySuper != null) {\n+                    log.error(pos, Errors.ValueTypeHasIdentitySuperType(c, identitySuper));\n+                    break;\n+                } else if (cHasIdentity &&  valueSuper != null) {\n+                    log.error(pos, Errors.IdentityTypeHasValueSuperType(c, valueSuper));\n+                    break;\n+                } else if (identitySuper != null && valueSuper != null) {\n+                    log.error(pos, Errors.MutuallyIncompatibleSupers(c, identitySuper, valueSuper));\n+                    break;\n+                }\n+            }\n+        }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":303,"deletions":22,"binary":false,"changes":325,"status":"modified"},{"patch":"@@ -60,0 +60,2 @@\n+import static com.sun.tools.javac.comp.Flow.ThisExposability.ALLOWED;\n+import static com.sun.tools.javac.comp.Flow.ThisExposability.BANNED;\n@@ -1428,1 +1430,1 @@\n-                    if (types.asSuper(sup, syms.autoCloseableType.tsym) != null) {\n+                    if (types.asSuper(sup.referenceProjectionOrSelf(), syms.autoCloseableType.tsym) != null) {\n@@ -1851,0 +1853,8 @@\n+    \/** Enum to model whether constructors allowed to \"leak\" this reference before\n+        all instance fields are DA.\n+     *\/\n+    enum ThisExposability {\n+        ALLOWED,     \/\/ identity Object classes - NOP\n+        BANNED,      \/\/ primitive\/value classes - Error\n+    }\n+\n@@ -1939,0 +1949,3 @@\n+        \/\/ Are constructors allowed to leak this reference ?\n+        ThisExposability thisExposability = ALLOWED;\n+\n@@ -2064,0 +2077,22 @@\n+        void checkEmbryonicThisExposure(JCTree node) {\n+            if (this.thisExposability == ALLOWED || classDef == null)\n+                return;\n+\n+            \/\/ Note: for non-initial constructors, firstadr is post all instance fields.\n+            for (int i = firstadr; i < nextadr; i++) {\n+                VarSymbol sym = vardecls[i].sym;\n+                if (sym.owner != classDef.sym)\n+                    continue;\n+                if ((sym.flags() & (FINAL | HASINIT | STATIC | PARAMETER)) != FINAL)\n+                    continue;\n+                if (sym.pos < startPos || sym.adr < firstadr)\n+                    continue;\n+                if (!inits.isMember(sym.adr)) {\n+                    if (this.thisExposability == BANNED) {\n+                        log.error(node, Errors.ThisExposedPrematurely);\n+                    }\n+                    return; \/\/ don't flog a dead horse.\n+                }\n+            }\n+        }\n+\n@@ -2268,0 +2303,1 @@\n+            ThisExposability priorThisExposability = this.thisExposability;\n@@ -2291,0 +2327,6 @@\n+                        this.thisExposability = ALLOWED;\n+                    } else {\n+                        if (tree.sym.owner.type.isValueClass())\n+                            this.thisExposability = BANNED;\n+                        else\n+                            this.thisExposability = ALLOWED;\n@@ -2353,0 +2395,1 @@\n+                this.thisExposability = priorThisExposability;\n@@ -2828,0 +2871,5 @@\n+            if (tree.meth.hasTag(IDENT)) {\n+                JCIdent ident = (JCIdent) tree.meth;\n+                if (ident.name != names._super && !ident.sym.isStatic())\n+                    checkEmbryonicThisExposure(tree);\n+            }\n@@ -2834,0 +2882,6 @@\n+            if (classDef != null && tree.encl == null && tree.clazz.hasTag(IDENT)) {\n+                JCIdent clazz = (JCIdent) tree.clazz;\n+                if (!clazz.sym.isStatic() && clazz.type.getEnclosingType().tsym == classDef.sym) {\n+                    checkEmbryonicThisExposure(tree);\n+                }\n+            }\n@@ -2896,1 +2950,8 @@\n-            super.visitSelect(tree);\n+            ThisExposability priorThisExposability = this.thisExposability;\n+            try {\n+                if (tree.name == names._this && classDef != null && tree.sym.owner == classDef.sym) {\n+                    checkEmbryonicThisExposure(tree);\n+                } else if (tree.sym.kind == VAR || tree.sym.isStatic()) {\n+                    this.thisExposability = ALLOWED;\n+                }\n+                super.visitSelect(tree);\n@@ -2899,1 +2960,4 @@\n-                checkInit(tree.pos(), (VarSymbol)tree.sym);\n+                    checkInit(tree.pos(), (VarSymbol)tree.sym);\n+                }\n+            } finally {\n+                 this.thisExposability = priorThisExposability;\n@@ -2963,0 +3027,3 @@\n+            if (tree.name == names._this) {\n+                checkEmbryonicThisExposure(tree);\n+            }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Flow.java","additions":70,"deletions":3,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -56,1 +56,0 @@\n-import com.sun.tools.javac.util.JCDiagnostic.Warning;\n@@ -68,1 +67,0 @@\n-import java.util.function.Consumer;\n@@ -419,37 +417,54 @@\n-        switch ((short)(sym.flags() & AccessFlags)) {\n-        case PRIVATE:\n-            return\n-                (env.enclClass.sym == sym.owner \/\/ fast special case\n-                 ||\n-                 env.enclClass.sym.outermostClass() ==\n-                 sym.owner.outermostClass())\n-                &&\n-                sym.isInheritedIn(site.tsym, types);\n-        case 0:\n-            return\n-                (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n-                 ||\n-                 env.toplevel.packge == sym.packge())\n-                &&\n-                isAccessible(env, site, checkInner)\n-                &&\n-                sym.isInheritedIn(site.tsym, types)\n-                &&\n-                notOverriddenIn(site, sym);\n-        case PROTECTED:\n-            return\n-                (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n-                 ||\n-                 env.toplevel.packge == sym.packge()\n-                 ||\n-                 isProtectedAccessible(sym, env.enclClass.sym, site)\n-                 ||\n-                 \/\/ OK to select instance method or field from 'super' or type name\n-                 \/\/ (but type names should be disallowed elsewhere!)\n-                 env.info.selectSuper && (sym.flags() & STATIC) == 0 && sym.kind != TYP)\n-                &&\n-                isAccessible(env, site, checkInner)\n-                &&\n-                notOverriddenIn(site, sym);\n-        default: \/\/ this case includes erroneous combinations as well\n-            return isAccessible(env, site, checkInner) && notOverriddenIn(site, sym);\n+        ClassSymbol enclosingCsym = env.enclClass.sym;\n+        if (sym.kind == MTH || sym.kind == VAR) {\n+            \/* If any primitive class types are involved, ask the same question in the reference universe,\n+               where the hierarchy is navigable\n+            *\/\n+            if (site.isPrimitiveClass())\n+                site = site.referenceProjection();\n+        } else if (sym.kind == TYP) {\n+            \/\/ A type is accessible in a reference projection if it was\n+            \/\/ accessible in the value projection.\n+            if (site.isReferenceProjection())\n+                site = site.valueProjection();\n+        }\n+        try {\n+            switch ((short)(sym.flags() & AccessFlags)) {\n+                case PRIVATE:\n+                    return\n+                            (env.enclClass.sym == sym.owner \/\/ fast special case\n+                                    ||\n+                                    env.enclClass.sym.outermostClass() ==\n+                                            sym.owner.outermostClass())\n+                                    &&\n+                                    sym.isInheritedIn(site.tsym, types);\n+                case 0:\n+                    return\n+                            (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n+                                    ||\n+                                    env.toplevel.packge == sym.packge())\n+                                    &&\n+                                    isAccessible(env, site, checkInner)\n+                                    &&\n+                                    sym.isInheritedIn(site.tsym, types)\n+                                    &&\n+                                    notOverriddenIn(site, sym);\n+                case PROTECTED:\n+                    return\n+                            (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n+                                    ||\n+                                    env.toplevel.packge == sym.packge()\n+                                    ||\n+                                    isProtectedAccessible(sym, env.enclClass.sym, site)\n+                                    ||\n+                                    \/\/ OK to select instance method or field from 'super' or type name\n+                                    \/\/ (but type names should be disallowed elsewhere!)\n+                                    env.info.selectSuper && (sym.flags() & STATIC) == 0 && sym.kind != TYP)\n+                                    &&\n+                                    isAccessible(env, site, checkInner)\n+                                    &&\n+                                    notOverriddenIn(site, sym);\n+                default: \/\/ this case includes erroneous combinations as well\n+                    return isAccessible(env, site, checkInner) && notOverriddenIn(site, sym);\n+            }\n+        } finally {\n+            env.enclClass.sym = enclosingCsym;\n@@ -468,5 +483,10 @@\n-        else {\n-            Symbol s2 = ((MethodSymbol)sym).implementation(site.tsym, types, true);\n-            return (s2 == null || s2 == sym || sym.owner == s2.owner || (sym.owner.isInterface() && s2.owner == syms.objectType.tsym) ||\n-                    !types.isSubSignature(types.memberType(site, s2), types.memberType(site, sym)));\n-        }\n+\n+        \/* If any primitive class types are involved, ask the same question in the reference universe,\n+           where the hierarchy is navigable\n+        *\/\n+        if (site.isPrimitiveClass())\n+            site = site.referenceProjection();\n+\n+        Symbol s2 = ((MethodSymbol)sym).implementation(site.tsym, types, true);\n+        return (s2 == null || s2 == sym || sym.owner == s2.owner || (sym.owner.isInterface() && s2.owner == syms.objectType.tsym) ||\n+                !types.isSubSignature(types.memberType(site, s2), types.memberType(site, sym)));\n@@ -1692,1 +1712,1 @@\n-                    if (types.asSuper(m1Owner.type, m2Owner) != null &&\n+                    if (types.asSuper(m1Owner.type.referenceProjectionOrSelf(), m2Owner) != null &&\n@@ -1697,1 +1717,1 @@\n-                    if (types.asSuper(m2Owner.type, m1Owner) != null &&\n+                    if (types.asSuper(m2Owner.type.referenceProjectionOrSelf(), m1Owner) != null &&\n@@ -2299,0 +2319,16 @@\n+        return findMemberTypeInternal(env,site, name, c);\n+    }\n+\n+    \/** Find qualified member type.\n+     *  @param env       The current environment.\n+     *  @param site      The original type from where the selection takes\n+     *                   place.\n+     *  @param name      The type's name.\n+     *  @param c         The class to search for the member type. This is\n+     *                   always a superclass or implemented interface of\n+     *                   site's class.\n+     *\/\n+    Symbol findMemberTypeInternal(Env<AttrContext> env,\n+                          Type site,\n+                          Name name,\n+                          TypeSymbol c) {\n@@ -2347,0 +2383,8 @@\n+        return findTypeInternal(env, name);\n+    }\n+\n+    \/** Find an unqualified type symbol.\n+     *  @param env       The current environment.\n+     *  @param name      The type's name.\n+     *\/\n+    Symbol findTypeInternal(Env<AttrContext> env, Name name) {\n@@ -3571,1 +3615,1 @@\n-                        types.isSubtypeUnchecked(inferenceContext.asUndetVar(argtypes.head), originalSite))) {\n+                        types.isSubtypeUnchecked(inferenceContext.asUndetVar(argtypes.head.referenceProjectionOrSelf()), originalSite))) {\n@@ -3624,1 +3668,1 @@\n-                Type asSuperSite = types.asSuper(argtypes.head, site.tsym);\n+                Type asSuperSite = types.asSuper(argtypes.head.referenceProjectionOrSelf(), site.tsym);\n@@ -3683,1 +3727,1 @@\n-                this.site = new ClassType(site.getEnclosingType(), site.tsym.type.getTypeArguments(), site.tsym, site.getMetadata());\n+                this.site = new ClassType(site.getEnclosingType(), site.tsym.type.getTypeArguments(), site.tsym, site.getMetadata(), site.getFlavor());\n@@ -3773,1 +3817,1 @@\n-                            types.asSuper(env.enclClass.type, c), env.enclClass.sym);\n+                            types.asSuper(env.enclClass.type.referenceProjectionOrSelf(), c), env.enclClass.sym);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Resolve.java","additions":94,"deletions":50,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -509,0 +509,7 @@\n+    public void visitWithField(JCWithField tree) {\n+        tree.field = translate(tree.field, null);\n+        tree.value = translate(tree.value, erasure(tree.field.type));\n+        tree.type = erasure(tree.type);\n+        result = retype(tree, tree.type, pt);\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TransTypes.java","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+import com.sun.tools.javac.jvm.Target;\n@@ -55,0 +56,1 @@\n+import static com.sun.tools.javac.code.Flags.SYNCHRONIZED;\n@@ -747,1 +749,0 @@\n-\n@@ -1124,0 +1125,11 @@\n+\n+            if (tree.sym != syms.objectType.tsym && tree.sym != syms.recordType.tsym) {\n+                if ((tree.sym.flags() & (ABSTRACT | INTERFACE | VALUE_CLASS)) == 0) {\n+                    tree.sym.flags_field |= IDENTITY_TYPE;\n+                }\n+                if ((tree.sym.flags() & (ABSTRACT | IDENTITY_TYPE | INTERFACE)) == ABSTRACT) {\n+                    if (abstractClassHasImplicitIdentity(tree)) {\n+                        tree.sym.flags_field |= IDENTITY_TYPE;\n+                    }\n+                }\n+            }\n@@ -1126,0 +1138,44 @@\n+            \/\/ where\n+            private boolean abstractClassHasImplicitIdentity(JCClassDecl tree) {\n+\n+                Type t = tree.sym.type;\n+\n+                if (t == null || t.tsym == null || t.tsym.kind == ERR)\n+                    return false;\n+\n+                if ((t.tsym.flags() & HASINITBLOCK) != 0) {\n+                    return true;\n+                }\n+\n+                \/\/ No instance fields and no arged constructors both mean inner classes cannot be value class supers.\n+                Type encl = t.getEnclosingType();\n+                if (encl != null && encl.hasTag(CLASS)) {\n+                    return true;\n+                }\n+                for (Symbol s : t.tsym.members().getSymbols(NON_RECURSIVE)) {\n+                    switch (s.kind) {\n+                        case VAR:\n+                            if ((s.flags() & STATIC) == 0) {\n+                                return true;\n+                            }\n+                            break;\n+                        case MTH:\n+                            if ((s.flags() & (SYNCHRONIZED | STATIC)) == SYNCHRONIZED) {\n+                                return true;\n+                            } else if (s.isConstructor()) {\n+                                MethodSymbol m = (MethodSymbol)s;\n+                                if (m.getParameters().size() > 0\n+                                        || m.getTypeParameters().size() > 0\n+                                        || m.type.getThrownTypes().nonEmpty()\n+                                        || (m.flags() & EMPTYNOARGCONSTR) == 0\n+                                        || (Check.protection(m.flags()) > Check.protection(m.owner.flags()))) {\n+                                    return true;\n+                                }\n+                            }\n+                            break;\n+                    }\n+                }\n+                return false;\n+            }\n+\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":57,"deletions":1,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+import com.sun.tools.javac.code.Flags.Flag;\n@@ -52,0 +53,1 @@\n+import static com.sun.tools.javac.code.Flags.asFlagSet;\n@@ -60,0 +62,1 @@\n+import static com.sun.tools.javac.parser.Tokens.TokenKind.SYNCHRONIZED;\n@@ -191,0 +194,4 @@\n+        this.allowPrimitiveClasses = (!preview.isPreview(Feature.PRIMITIVE_CLASSES) || preview.isEnabled()) &&\n+                Feature.PRIMITIVE_CLASSES.allowedInSource(source);\n+        this.allowValueClasses = (!preview.isPreview(Feature.VALUE_CLASSES) || preview.isEnabled()) &&\n+                Feature.VALUE_CLASSES.allowedInSource(source);\n@@ -228,0 +235,8 @@\n+    \/** Switch: are primitive classes allowed in this source level?\n+     *\/\n+     boolean allowPrimitiveClasses;\n+\n+    \/** Switch: are value classes allowed in this source level?\n+     *\/\n+    boolean allowValueClasses;\n+\n@@ -475,0 +490,16 @@\n+    \/** If next input token matches one of the two given tokens, skip it, otherwise report\n+     *  an error.\n+     *\n+     * @return The actual token kind.\n+     *\/\n+    public TokenKind accept2(TokenKind tk1, TokenKind tk2) {\n+        TokenKind returnValue = token.kind;\n+        if (token.kind == tk1 || token.kind == tk2) {\n+            nextToken();\n+        } else {\n+            setErrorEndPos(token.pos);\n+            reportSyntaxError(S.prevToken().endPos, Errors.Expected2(tk1, tk2));\n+        }\n+        return returnValue;\n+    }\n+\n@@ -1379,0 +1410,6 @@\n+                            case DEFAULT:\n+                                if (typeArgs != null) return illegal();\n+                                selectExprMode();\n+                                t = to(F.at(pos).DefaultValue(t));\n+                                nextToken();\n+                                break loop;\n@@ -1436,3 +1473,4 @@\n-                        if ((mode & TYPE) == 0 && isUnboundMemberRef()) {\n-                            \/\/this is an unbound method reference whose qualifier\n-                            \/\/is a generic type i.e. A<S>::m\n+                        if ((mode & TYPE) == 0 && isParameterizedTypePrefix()) {\n+                            \/\/this is either an unbound method reference whose qualifier\n+                            \/\/is a generic type i.e. A<S>::m or a default value creation of\n+                            \/\/the form ValueType<S>.default\n@@ -1451,0 +1489,6 @@\n+                                if (token.kind == DEFAULT) {\n+                                    t =  toP(F.at(token.pos).DefaultValue(t));\n+                                    nextToken();\n+                                    selectExprMode();\n+                                    return term3Rest(t, typeArgs);\n+                                }\n@@ -1617,1 +1661,1 @@\n-                } else if (token.kind == NEW && (mode & EXPR) != 0) {\n+                } else if ((token.kind == NEW) && (mode & EXPR) != 0) {\n@@ -1671,1 +1715,2 @@\n-     * method reference or a binary expression. To disambiguate, look for a\n+     * method reference or a default value creation that uses a parameterized type\n+     * or a binary expression. To disambiguate, look for a\n@@ -1675,1 +1720,1 @@\n-    boolean isUnboundMemberRef() {\n+    boolean isParameterizedTypePrefix() {\n@@ -2275,1 +2320,1 @@\n-            accept(CLASS);\n+            TokenKind selector = accept2(CLASS, DEFAULT);\n@@ -2293,1 +2338,5 @@\n-                t = toP(F.at(pos).Select(t, names._class));\n+                if (selector == CLASS) {\n+                    t = toP(F.at(pos).Select(t, names._class));\n+                } else {\n+                    t = toP(F.at(pos).DefaultValue(t));\n+                }\n@@ -2337,2 +2386,2 @@\n-        List<JCAnnotation> newAnnotations = typeAnnotationsOpt();\n-\n+        final JCModifiers mods = modifiersOpt();\n+        List<JCAnnotation> newAnnotations = mods.annotations;\n@@ -2342,0 +2391,3 @@\n+            if (mods.flags != 0) {\n+                log.error(token.pos, Errors.ModNotAllowedHere(asFlagSet(mods.flags)));\n+            }\n@@ -2410,0 +2462,3 @@\n+            long badModifiers = mods.flags & ~(Flags.PRIMITIVE_CLASS | Flags.VALUE_CLASS | Flags.FINAL);\n+            if (badModifiers != 0)\n+                log.error(token.pos, Errors.ModNotAllowedHere(asFlagSet(badModifiers)));\n@@ -2414,1 +2469,5 @@\n-            return classCreatorRest(newpos, null, typeArgs, t);\n+            JCNewClass newClass = classCreatorRest(newpos, null, typeArgs, t, mods.flags);\n+            if ((newClass.def == null) && (mods.flags != 0)) {\n+                log.error(newClass.pos, Errors.ModNotAllowedHere(asFlagSet(mods.flags)));\n+            }\n+            return newClass;\n@@ -2439,1 +2498,1 @@\n-        return classCreatorRest(newpos, encl, typeArgs, t);\n+        return classCreatorRest(newpos, encl, typeArgs, t, 0);\n@@ -2517,1 +2576,2 @@\n-                                  JCExpression t)\n+                                  JCExpression t,\n+                                  long flags)\n@@ -2524,1 +2584,1 @@\n-            JCModifiers mods = F.at(Position.NOPOS).Modifiers(0);\n+            JCModifiers mods = F.at(Position.NOPOS).Modifiers(flags);\n@@ -2527,1 +2587,2 @@\n-        return toP(F.at(newpos).NewClass(encl, typeArgs, t, args, body));\n+        JCNewClass newClass = toP(F.at(newpos).NewClass(encl, typeArgs, t, args, body));\n+        return newClass;\n@@ -2760,0 +2821,4 @@\n+        if ((isPrimitiveModifier() && allowPrimitiveClasses) || (isValueModifier() || isIdentityModifier()) && allowValueClasses) {\n+            dc = token.comment(CommentStyle.JAVADOC);\n+            return List.of(classOrRecordOrInterfaceOrEnumDeclaration(modifiersOpt(), dc));\n+        }\n@@ -3219,1 +3284,4 @@\n-                return variableDeclarators(modifiersOpt(), t, stats, true).toList();\n+                pos = token.pos;\n+                JCModifiers mods = F.at(Position.NOPOS).Modifiers(0);\n+                F.at(pos);\n+                return variableDeclarators(mods, t, stats, true).toList();\n@@ -3316,0 +3384,12 @@\n+                if (isPrimitiveModifier()) {\n+                    flag = Flags.PRIMITIVE_CLASS;\n+                    break;\n+                }\n+                if (isValueModifier()) {\n+                    flag = Flags.VALUE_CLASS;\n+                    break;\n+                }\n+                if (isIdentityModifier()) {\n+                    flag = Flags.IDENTITY_TYPE;\n+                    break;\n+                }\n@@ -3329,2 +3409,9 @@\n-                    annotations.append(ann);\n-                    flag = 0;\n+                    final Name name = TreeInfo.name(ann.annotationType);\n+                    if (name == names.__primitive__ || name == names.java_lang___primitive__) {\n+                        flag = Flags.PRIMITIVE_CLASS;\n+                    } else if (name == names.__value__ || name == names.java_lang___value__) {\n+                        flag = Flags.VALUE_CLASS;\n+                    } else {\n+                        annotations.append(ann);\n+                        flag = 0;\n+                    }\n@@ -3567,0 +3654,21 @@\n+        if (name == names.primitive) {\n+            if (allowPrimitiveClasses) {\n+                return Source.JDK18;\n+            } else if (shouldWarn) {\n+                log.warning(pos, Warnings.RestrictedTypeNotAllowedPreview(name, Source.JDK18));\n+            }\n+        }\n+        if (name == names.value) {\n+            if (allowValueClasses) {\n+                return Source.JDK18;\n+            } else if (shouldWarn) {\n+                log.warning(pos, Warnings.RestrictedTypeNotAllowedPreview(name, Source.JDK18));\n+            }\n+        }\n+        if (name == names.identity) {\n+            if (allowPrimitiveClasses) {\n+                return Source.JDK18;\n+            } else if (shouldWarn) {\n+                log.warning(pos, Warnings.RestrictedTypeNotAllowedPreview(name, Source.JDK18));\n+            }\n+        }\n@@ -4465,0 +4573,78 @@\n+    protected boolean isPrimitiveModifier() {\n+        if (token.kind == IDENTIFIER && token.name() == names.primitive) {\n+            boolean isPrimitiveModifier = false;\n+            Token next = S.token(1);\n+            switch (next.kind) {\n+                case PRIVATE: case PROTECTED: case PUBLIC: case STATIC: case TRANSIENT:\n+                case FINAL: case ABSTRACT: case NATIVE: case VOLATILE: case SYNCHRONIZED:\n+                case STRICTFP: case MONKEYS_AT: case DEFAULT: case BYTE: case SHORT:\n+                case CHAR: case INT: case LONG: case FLOAT: case DOUBLE: case BOOLEAN: case VOID:\n+                case CLASS: case INTERFACE: case ENUM:\n+                    isPrimitiveModifier = true;\n+                    break;\n+                case IDENTIFIER: \/\/ primitive record R || primitive primitive || primitive identity || primitive value || new primitive Comparable() {}\n+                    if (next.name() == names.record || next.name() == names.primitive || next.name() == names.identity\n+                            || next.name() == names.value || (mode & EXPR) != 0)\n+                        isPrimitiveModifier = true;\n+                    break;\n+            }\n+            if (isPrimitiveModifier) {\n+                checkSourceLevel(Feature.PRIMITIVE_CLASSES);\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    protected boolean isValueModifier() {\n+        if (token.kind == IDENTIFIER && token.name() == names.value) {\n+            boolean isValueModifier = false;\n+            Token next = S.token(1);\n+            switch (next.kind) {\n+                case PRIVATE: case PROTECTED: case PUBLIC: case STATIC: case TRANSIENT:\n+                case FINAL: case ABSTRACT: case NATIVE: case VOLATILE: case SYNCHRONIZED:\n+                case STRICTFP: case MONKEYS_AT: case DEFAULT: case BYTE: case SHORT:\n+                case CHAR: case INT: case LONG: case FLOAT: case DOUBLE: case BOOLEAN: case VOID:\n+                case CLASS: case INTERFACE: case ENUM:\n+                    isValueModifier = true;\n+                    break;\n+                case IDENTIFIER: \/\/ value record R || value value || value identity || value primitive || new value Comparable() {} ??\n+                    if (next.name() == names.record || next.name() == names.value || next.name() == names.identity\n+                            || next.name() == names.primitive || (mode & EXPR) != 0)\n+                        isValueModifier = true;\n+                    break;\n+            }\n+            if (isValueModifier) {\n+                checkSourceLevel(Feature.VALUE_CLASSES);\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    protected boolean isIdentityModifier() {\n+        if (token.kind == IDENTIFIER && token.name() == names.identity) {\n+            boolean isIdentityModifier = false;\n+            Token next = S.token(1);\n+            switch (next.kind) {\n+                case PRIVATE: case PROTECTED: case PUBLIC: case STATIC: case TRANSIENT:\n+                case FINAL: case ABSTRACT: case NATIVE: case VOLATILE: case SYNCHRONIZED:\n+                case STRICTFP: case MONKEYS_AT: case DEFAULT: case BYTE: case SHORT:\n+                case CHAR: case INT: case LONG: case FLOAT: case DOUBLE: case BOOLEAN: case VOID:\n+                case CLASS: case INTERFACE: case ENUM:\n+                    isIdentityModifier = true;\n+                    break;\n+                case IDENTIFIER: \/\/ identity record R || identity primitive || || identity identity || identity value || new identity Comparable() {}\n+                    if (next.name() == names.record || next.name() == names.primitive || next.name() == names.identity\n+                            || next.name() == names.value || (mode & EXPR) != 0)\n+                        isIdentityModifier = true;\n+                    break;\n+            }\n+            if (isIdentityModifier) {\n+                checkSourceLevel(Feature.PRIMITIVE_CLASSES);\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n@@ -4492,1 +4678,4 @@\n-                case IDENTIFIER -> isNonSealedIdentifier(next, currentIsNonSealed ? 3 : 1) || next.name() == names.sealed;\n+                case IDENTIFIER -> isNonSealedIdentifier(next, currentIsNonSealed ? 3 : 1) ||\n+                        next.name() == names.sealed ||\n+                        next.name() == names.value ||\n+                        next.name() == names.identity;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":208,"deletions":19,"binary":false,"changes":227,"status":"modified"},{"patch":"@@ -266,0 +266,6 @@\n+compiler.misc.value.interface.nonfunctional=\\\n+    since it is a value interface\n+\n+compiler.misc.identity.interface.nonfunctional=\\\n+    since it is an identity interface\n+\n@@ -699,1 +705,1 @@\n-    improperly formed type, some parameters are missing\n+    improperly formed type, some parameters are missing or misplaced\n@@ -2575,0 +2581,3 @@\n+compiler.misc.type.req.identity=\\\n+    a type with identity\n+\n@@ -3902,0 +3911,93 @@\n+compiler.misc.feature.primitive.classes=\\\n+    primitive classes\n+\n+compiler.misc.feature.value.classes=\\\n+    value classes\n+\n+# 0: symbol\n+compiler.err.cyclic.primitive.class.membership=\\\n+    cyclic primitive class membership involving {0}\n+\n+compiler.warn.get.class.compared.with.interface=\\\n+    return value of getClass() can never equal the class literal of an interface\n+\n+# 0: name (of method)\n+compiler.err.value.class.does.not.support=\\\n+    value classes do not support {0}\n+\n+compiler.err.value.class.may.not.extend=\\\n+    inappropriate super class declaration for a value class\n+\n+compiler.err.this.exposed.prematurely=\\\n+    value class instance should not be passed around before being fully initialized\n+\n+# 0: type\n+compiler.err.generic.parameterization.with.primitive.class=\\\n+    Inferred type {0} involves generic parameterization by a primitive class\n+\n+# 0: type, 1: type\n+compiler.err.value.type.has.identity.super.type=\\\n+    The identity type {1} cannot be a supertype of the value type {0}\n+\n+# 0: type, 1: type\n+compiler.err.identity.type.has.value.super.type=\\\n+    The value type {1} cannot be a supertype of the identity type {0}\n+\n+# 0: type, 1: type, 2: type\n+compiler.err.mutually.incompatible.supers=\\\n+    The type {0} has mutually incompatible supertypes: the identity type {1} and the value type {2}\n+\n+# 0: symbol, 1: type\n+compiler.err.concrete.supertype.for.value.class=\\\n+    The concrete class {1} is not allowed to be a super class of the value class {0} either directly or indirectly\n+\n+# 0: symbol, 1: symbol, 2: type\n+compiler.err.super.method.cannot.be.synchronized=\\\n+    The method {0} in the super class {2} of the value class {1} is synchronized. This is disallowed\n+\n+# 0: symbol, 1: message segment\n+compiler.err.super.constructor.cannot.take.arguments=\\\n+    {1} defines a constructor {0} that takes arguments. This is disallowed\n+\n+# 0: symbol, 1: message segment\n+compiler.err.super.constructor.cannot.be.generic=\\\n+    {1} defines a generic constructor {0}. This is disallowed\n+\n+# 0: symbol, 1: message segment\n+compiler.err.super.constructor.cannot.throw=\\\n+    {1} defines a constructor {0} that throws an exception. This is disallowed\n+\n+# 0: symbol, 1: message segment\n+compiler.err.super.constructor.access.restricted=\\\n+    {1} defines a constructor {0} with a weaker access privilege than the declaring class. This is disallowed\n+\n+# 0: symbol, 1: message segment\n+compiler.err.super.field.not.allowed=\\\n+    {1} defines an instance field {0}. This is disallowed\n+\n+# 0: symbol, 1: message segment\n+compiler.err.super.no.arg.constructor.must.be.empty=\\\n+    {1} defines a nonempty no-arg constructor {0}. This is disallowed\n+\n+# 0: message segment\n+compiler.err.super.class.declares.init.block=\\\n+    {0} declares one or more non-empty instance initializer blocks. This is disallowed.\n+\n+# 0: message segment\n+compiler.err.super.class.cannot.be.inner=\\\n+    {0} is an inner class. This is disallowed.\n+\n+# 0: symbol, 1: type\n+compiler.misc.superclass.of.value.class=\\\n+    The super class {1} of the value class {0}\n+\n+# 0: symbol\n+compiler.misc.abstract.value.class=\\\n+    The abstract value class {0}\n+\n+compiler.err.projection.cant.be.instantiated=\\\n+    Illegal attempt to instantiate a projection type\n+\n+compiler.err.call.to.super.not.allowed.in.value.ctor=\\\n+    call to super not allowed in value class constructor\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":103,"deletions":1,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -106,0 +106,4 @@\n+# Valhalla\n+\n+runtime\/valhalla\/inlinetypes\/ClassInitializationFailuresTest.java 8274131 linux-aarch64-debug,macosx-aarch64-debug\n+\n@@ -126,0 +130,27 @@\n+# Valhalla TODO:\n+serviceability\/sa\/ClhsdbCDSCore.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbFindPC.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbInspect.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbLongConstant.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJdis.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJstack.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAs.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintStatics.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSource.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSymbol.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbWhere.java 8190936 generic-all\n+serviceability\/sa\/JhsdbThreadInfoTest.java 8190936 generic-all\n+serviceability\/sa\/TestClassDump.java 8190936 generic-all\n+serviceability\/sa\/TestClhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestCpoolForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForLargeArray.java 8190936 generic-all\n+serviceability\/sa\/TestIntConstant.java 8190936 generic-all\n+serviceability\/sa\/TestJhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCore.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8190936 generic-all\n+serviceability\/sa\/TestPrintMdo.java 8190936 generic-all\n+serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 8190936 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":31,"deletions":0,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -445,0 +445,4 @@\n+\n+        public String toString() {\n+            return super.toString() + \", vh:\" + vh;\n+        }\n@@ -465,0 +469,4 @@\n+\n+        public String toString() {\n+            return super.toString() + \", vh:\" + vh + \", f: \" + f;\n+        }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleBaseTest.java","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = boolean.class;\n+\n@@ -71,0 +75,1 @@\n+    VarHandle vhValueTypeField;\n@@ -79,1 +84,1 @@\n-                    VarHandleTestAccessBoolean.class, \"final_v\" + postfix, boolean.class);\n+                    VarHandleTestAccessBoolean.class, \"final_v\" + postfix, type);\n@@ -83,1 +88,1 @@\n-                    VarHandleTestAccessBoolean.class, \"v\" + postfix, boolean.class);\n+                    VarHandleTestAccessBoolean.class, \"v\" + postfix, type);\n@@ -87,1 +92,1 @@\n-                VarHandleTestAccessBoolean.class, \"static_final_v\" + postfix, boolean.class);\n+                VarHandleTestAccessBoolean.class, \"static_final_v\" + postfix, type);\n@@ -91,1 +96,1 @@\n-                VarHandleTestAccessBoolean.class, \"static_v\" + postfix, boolean.class);\n+                VarHandleTestAccessBoolean.class, \"static_v\" + postfix, type);\n@@ -110,1 +115,1 @@\n-                VarHandleTestAccessBoolean.class, \"final_v\", boolean.class);\n+                VarHandleTestAccessBoolean.class, \"final_v\", type);\n@@ -113,1 +118,1 @@\n-                VarHandleTestAccessBoolean.class, \"v\", boolean.class);\n+                VarHandleTestAccessBoolean.class, \"v\", type);\n@@ -116,1 +121,1 @@\n-            VarHandleTestAccessBoolean.class, \"static_final_v\", boolean.class);\n+            VarHandleTestAccessBoolean.class, \"static_final_v\", type);\n@@ -119,1 +124,1 @@\n-            VarHandleTestAccessBoolean.class, \"static_v\", boolean.class);\n+            VarHandleTestAccessBoolean.class, \"static_v\", type);\n@@ -122,0 +127,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"boolean_v\", type);\n@@ -206,1 +214,1 @@\n-        assertEquals(vh.varType(), boolean.class);\n+        assertEquals(vh.varType(), type);\n@@ -218,1 +226,1 @@\n-                    VarHandleTestAccessBoolean.class, \"final_v\", boolean.class);\n+                    VarHandleTestAccessBoolean.class, \"final_v\", type);\n@@ -223,1 +231,1 @@\n-                    VarHandleTestAccessBoolean.class, \"v\", boolean.class);\n+                    VarHandleTestAccessBoolean.class, \"v\", type);\n@@ -231,1 +239,1 @@\n-                VarHandleTestAccessBoolean.class, \"static_final_v\", boolean.class);\n+                VarHandleTestAccessBoolean.class, \"static_final_v\", type);\n@@ -236,1 +244,1 @@\n-                VarHandleTestAccessBoolean.class, \"static_v\", boolean.class);\n+                VarHandleTestAccessBoolean.class, \"static_v\", type);\n@@ -277,0 +285,5 @@\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n@@ -354,0 +367,13 @@\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            boolean x = (boolean) vh.get(recv);\n+            assertEquals(x, true, \"get boolean value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, false);\n+        });\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessBoolean.java","additions":39,"deletions":13,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = byte.class;\n+\n@@ -71,0 +75,1 @@\n+    VarHandle vhValueTypeField;\n@@ -79,1 +84,1 @@\n-                    VarHandleTestAccessByte.class, \"final_v\" + postfix, byte.class);\n+                    VarHandleTestAccessByte.class, \"final_v\" + postfix, type);\n@@ -83,1 +88,1 @@\n-                    VarHandleTestAccessByte.class, \"v\" + postfix, byte.class);\n+                    VarHandleTestAccessByte.class, \"v\" + postfix, type);\n@@ -87,1 +92,1 @@\n-                VarHandleTestAccessByte.class, \"static_final_v\" + postfix, byte.class);\n+                VarHandleTestAccessByte.class, \"static_final_v\" + postfix, type);\n@@ -91,1 +96,1 @@\n-                VarHandleTestAccessByte.class, \"static_v\" + postfix, byte.class);\n+                VarHandleTestAccessByte.class, \"static_v\" + postfix, type);\n@@ -110,1 +115,1 @@\n-                VarHandleTestAccessByte.class, \"final_v\", byte.class);\n+                VarHandleTestAccessByte.class, \"final_v\", type);\n@@ -113,1 +118,1 @@\n-                VarHandleTestAccessByte.class, \"v\", byte.class);\n+                VarHandleTestAccessByte.class, \"v\", type);\n@@ -116,1 +121,1 @@\n-            VarHandleTestAccessByte.class, \"static_final_v\", byte.class);\n+            VarHandleTestAccessByte.class, \"static_final_v\", type);\n@@ -119,1 +124,1 @@\n-            VarHandleTestAccessByte.class, \"static_v\", byte.class);\n+            VarHandleTestAccessByte.class, \"static_v\", type);\n@@ -122,0 +127,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"byte_v\", type);\n@@ -206,1 +214,1 @@\n-        assertEquals(vh.varType(), byte.class);\n+        assertEquals(vh.varType(), type);\n@@ -218,1 +226,1 @@\n-                    VarHandleTestAccessByte.class, \"final_v\", byte.class);\n+                    VarHandleTestAccessByte.class, \"final_v\", type);\n@@ -223,1 +231,1 @@\n-                    VarHandleTestAccessByte.class, \"v\", byte.class);\n+                    VarHandleTestAccessByte.class, \"v\", type);\n@@ -231,1 +239,1 @@\n-                VarHandleTestAccessByte.class, \"static_final_v\", byte.class);\n+                VarHandleTestAccessByte.class, \"static_final_v\", type);\n@@ -236,1 +244,1 @@\n-                VarHandleTestAccessByte.class, \"static_v\", byte.class);\n+                VarHandleTestAccessByte.class, \"static_v\", type);\n@@ -277,0 +285,5 @@\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n@@ -343,0 +356,13 @@\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            byte x = (byte) vh.get(recv);\n+            assertEquals(x, (byte)0x01, \"get byte value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, (byte)0x23);\n+        });\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessByte.java","additions":39,"deletions":13,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = char.class;\n+\n@@ -71,0 +75,1 @@\n+    VarHandle vhValueTypeField;\n@@ -79,1 +84,1 @@\n-                    VarHandleTestAccessChar.class, \"final_v\" + postfix, char.class);\n+                    VarHandleTestAccessChar.class, \"final_v\" + postfix, type);\n@@ -83,1 +88,1 @@\n-                    VarHandleTestAccessChar.class, \"v\" + postfix, char.class);\n+                    VarHandleTestAccessChar.class, \"v\" + postfix, type);\n@@ -87,1 +92,1 @@\n-                VarHandleTestAccessChar.class, \"static_final_v\" + postfix, char.class);\n+                VarHandleTestAccessChar.class, \"static_final_v\" + postfix, type);\n@@ -91,1 +96,1 @@\n-                VarHandleTestAccessChar.class, \"static_v\" + postfix, char.class);\n+                VarHandleTestAccessChar.class, \"static_v\" + postfix, type);\n@@ -110,1 +115,1 @@\n-                VarHandleTestAccessChar.class, \"final_v\", char.class);\n+                VarHandleTestAccessChar.class, \"final_v\", type);\n@@ -113,1 +118,1 @@\n-                VarHandleTestAccessChar.class, \"v\", char.class);\n+                VarHandleTestAccessChar.class, \"v\", type);\n@@ -116,1 +121,1 @@\n-            VarHandleTestAccessChar.class, \"static_final_v\", char.class);\n+            VarHandleTestAccessChar.class, \"static_final_v\", type);\n@@ -119,1 +124,1 @@\n-            VarHandleTestAccessChar.class, \"static_v\", char.class);\n+            VarHandleTestAccessChar.class, \"static_v\", type);\n@@ -122,0 +127,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"char_v\", type);\n@@ -206,1 +214,1 @@\n-        assertEquals(vh.varType(), char.class);\n+        assertEquals(vh.varType(), type);\n@@ -218,1 +226,1 @@\n-                    VarHandleTestAccessChar.class, \"final_v\", char.class);\n+                    VarHandleTestAccessChar.class, \"final_v\", type);\n@@ -223,1 +231,1 @@\n-                    VarHandleTestAccessChar.class, \"v\", char.class);\n+                    VarHandleTestAccessChar.class, \"v\", type);\n@@ -231,1 +239,1 @@\n-                VarHandleTestAccessChar.class, \"static_final_v\", char.class);\n+                VarHandleTestAccessChar.class, \"static_final_v\", type);\n@@ -236,1 +244,1 @@\n-                VarHandleTestAccessChar.class, \"static_v\", char.class);\n+                VarHandleTestAccessChar.class, \"static_v\", type);\n@@ -277,0 +285,5 @@\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n@@ -343,0 +356,13 @@\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            char x = (char) vh.get(recv);\n+            assertEquals(x, '\\u0123', \"get char value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, '\\u4567');\n+        });\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessChar.java","additions":39,"deletions":13,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = double.class;\n+\n@@ -71,0 +75,1 @@\n+    VarHandle vhValueTypeField;\n@@ -79,1 +84,1 @@\n-                    VarHandleTestAccessDouble.class, \"final_v\" + postfix, double.class);\n+                    VarHandleTestAccessDouble.class, \"final_v\" + postfix, type);\n@@ -83,1 +88,1 @@\n-                    VarHandleTestAccessDouble.class, \"v\" + postfix, double.class);\n+                    VarHandleTestAccessDouble.class, \"v\" + postfix, type);\n@@ -87,1 +92,1 @@\n-                VarHandleTestAccessDouble.class, \"static_final_v\" + postfix, double.class);\n+                VarHandleTestAccessDouble.class, \"static_final_v\" + postfix, type);\n@@ -91,1 +96,1 @@\n-                VarHandleTestAccessDouble.class, \"static_v\" + postfix, double.class);\n+                VarHandleTestAccessDouble.class, \"static_v\" + postfix, type);\n@@ -110,1 +115,1 @@\n-                VarHandleTestAccessDouble.class, \"final_v\", double.class);\n+                VarHandleTestAccessDouble.class, \"final_v\", type);\n@@ -113,1 +118,1 @@\n-                VarHandleTestAccessDouble.class, \"v\", double.class);\n+                VarHandleTestAccessDouble.class, \"v\", type);\n@@ -116,1 +121,1 @@\n-            VarHandleTestAccessDouble.class, \"static_final_v\", double.class);\n+            VarHandleTestAccessDouble.class, \"static_final_v\", type);\n@@ -119,1 +124,1 @@\n-            VarHandleTestAccessDouble.class, \"static_v\", double.class);\n+            VarHandleTestAccessDouble.class, \"static_v\", type);\n@@ -122,0 +127,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"double_v\", type);\n@@ -206,1 +214,1 @@\n-        assertEquals(vh.varType(), double.class);\n+        assertEquals(vh.varType(), type);\n@@ -218,1 +226,1 @@\n-                    VarHandleTestAccessDouble.class, \"final_v\", double.class);\n+                    VarHandleTestAccessDouble.class, \"final_v\", type);\n@@ -223,1 +231,1 @@\n-                    VarHandleTestAccessDouble.class, \"v\", double.class);\n+                    VarHandleTestAccessDouble.class, \"v\", type);\n@@ -231,1 +239,1 @@\n-                VarHandleTestAccessDouble.class, \"static_final_v\", double.class);\n+                VarHandleTestAccessDouble.class, \"static_final_v\", type);\n@@ -236,1 +244,1 @@\n-                VarHandleTestAccessDouble.class, \"static_v\", double.class);\n+                VarHandleTestAccessDouble.class, \"static_v\", type);\n@@ -277,0 +285,5 @@\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n@@ -378,0 +391,13 @@\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            double x = (double) vh.get(recv);\n+            assertEquals(x, 1.0d, \"get double value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, 2.0d);\n+        });\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessDouble.java","additions":39,"deletions":13,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = float.class;\n+\n@@ -71,0 +75,1 @@\n+    VarHandle vhValueTypeField;\n@@ -79,1 +84,1 @@\n-                    VarHandleTestAccessFloat.class, \"final_v\" + postfix, float.class);\n+                    VarHandleTestAccessFloat.class, \"final_v\" + postfix, type);\n@@ -83,1 +88,1 @@\n-                    VarHandleTestAccessFloat.class, \"v\" + postfix, float.class);\n+                    VarHandleTestAccessFloat.class, \"v\" + postfix, type);\n@@ -87,1 +92,1 @@\n-                VarHandleTestAccessFloat.class, \"static_final_v\" + postfix, float.class);\n+                VarHandleTestAccessFloat.class, \"static_final_v\" + postfix, type);\n@@ -91,1 +96,1 @@\n-                VarHandleTestAccessFloat.class, \"static_v\" + postfix, float.class);\n+                VarHandleTestAccessFloat.class, \"static_v\" + postfix, type);\n@@ -110,1 +115,1 @@\n-                VarHandleTestAccessFloat.class, \"final_v\", float.class);\n+                VarHandleTestAccessFloat.class, \"final_v\", type);\n@@ -113,1 +118,1 @@\n-                VarHandleTestAccessFloat.class, \"v\", float.class);\n+                VarHandleTestAccessFloat.class, \"v\", type);\n@@ -116,1 +121,1 @@\n-            VarHandleTestAccessFloat.class, \"static_final_v\", float.class);\n+            VarHandleTestAccessFloat.class, \"static_final_v\", type);\n@@ -119,1 +124,1 @@\n-            VarHandleTestAccessFloat.class, \"static_v\", float.class);\n+            VarHandleTestAccessFloat.class, \"static_v\", type);\n@@ -122,0 +127,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"float_v\", type);\n@@ -206,1 +214,1 @@\n-        assertEquals(vh.varType(), float.class);\n+        assertEquals(vh.varType(), type);\n@@ -218,1 +226,1 @@\n-                    VarHandleTestAccessFloat.class, \"final_v\", float.class);\n+                    VarHandleTestAccessFloat.class, \"final_v\", type);\n@@ -223,1 +231,1 @@\n-                    VarHandleTestAccessFloat.class, \"v\", float.class);\n+                    VarHandleTestAccessFloat.class, \"v\", type);\n@@ -231,1 +239,1 @@\n-                VarHandleTestAccessFloat.class, \"static_final_v\", float.class);\n+                VarHandleTestAccessFloat.class, \"static_final_v\", type);\n@@ -236,1 +244,1 @@\n-                VarHandleTestAccessFloat.class, \"static_v\", float.class);\n+                VarHandleTestAccessFloat.class, \"static_v\", type);\n@@ -277,0 +285,5 @@\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n@@ -378,0 +391,13 @@\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            float x = (float) vh.get(recv);\n+            assertEquals(x, 1.0f, \"get float value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, 2.0f);\n+        });\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessFloat.java","additions":39,"deletions":13,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = int.class;\n+\n@@ -71,0 +75,1 @@\n+    VarHandle vhValueTypeField;\n@@ -79,1 +84,1 @@\n-                    VarHandleTestAccessInt.class, \"final_v\" + postfix, int.class);\n+                    VarHandleTestAccessInt.class, \"final_v\" + postfix, type);\n@@ -83,1 +88,1 @@\n-                    VarHandleTestAccessInt.class, \"v\" + postfix, int.class);\n+                    VarHandleTestAccessInt.class, \"v\" + postfix, type);\n@@ -87,1 +92,1 @@\n-                VarHandleTestAccessInt.class, \"static_final_v\" + postfix, int.class);\n+                VarHandleTestAccessInt.class, \"static_final_v\" + postfix, type);\n@@ -91,1 +96,1 @@\n-                VarHandleTestAccessInt.class, \"static_v\" + postfix, int.class);\n+                VarHandleTestAccessInt.class, \"static_v\" + postfix, type);\n@@ -110,1 +115,1 @@\n-                VarHandleTestAccessInt.class, \"final_v\", int.class);\n+                VarHandleTestAccessInt.class, \"final_v\", type);\n@@ -113,1 +118,1 @@\n-                VarHandleTestAccessInt.class, \"v\", int.class);\n+                VarHandleTestAccessInt.class, \"v\", type);\n@@ -116,1 +121,1 @@\n-            VarHandleTestAccessInt.class, \"static_final_v\", int.class);\n+            VarHandleTestAccessInt.class, \"static_final_v\", type);\n@@ -119,1 +124,1 @@\n-            VarHandleTestAccessInt.class, \"static_v\", int.class);\n+            VarHandleTestAccessInt.class, \"static_v\", type);\n@@ -122,0 +127,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"int_v\", type);\n@@ -206,1 +214,1 @@\n-        assertEquals(vh.varType(), int.class);\n+        assertEquals(vh.varType(), type);\n@@ -218,1 +226,1 @@\n-                    VarHandleTestAccessInt.class, \"final_v\", int.class);\n+                    VarHandleTestAccessInt.class, \"final_v\", type);\n@@ -223,1 +231,1 @@\n-                    VarHandleTestAccessInt.class, \"v\", int.class);\n+                    VarHandleTestAccessInt.class, \"v\", type);\n@@ -231,1 +239,1 @@\n-                VarHandleTestAccessInt.class, \"static_final_v\", int.class);\n+                VarHandleTestAccessInt.class, \"static_final_v\", type);\n@@ -236,1 +244,1 @@\n-                VarHandleTestAccessInt.class, \"static_v\", int.class);\n+                VarHandleTestAccessInt.class, \"static_v\", type);\n@@ -277,0 +285,5 @@\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n@@ -343,0 +356,13 @@\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            int x = (int) vh.get(recv);\n+            assertEquals(x, 0x01234567, \"get int value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, 0x89ABCDEF);\n+        });\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessInt.java","additions":39,"deletions":13,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = long.class;\n+\n@@ -71,0 +75,1 @@\n+    VarHandle vhValueTypeField;\n@@ -79,1 +84,1 @@\n-                    VarHandleTestAccessLong.class, \"final_v\" + postfix, long.class);\n+                    VarHandleTestAccessLong.class, \"final_v\" + postfix, type);\n@@ -83,1 +88,1 @@\n-                    VarHandleTestAccessLong.class, \"v\" + postfix, long.class);\n+                    VarHandleTestAccessLong.class, \"v\" + postfix, type);\n@@ -87,1 +92,1 @@\n-                VarHandleTestAccessLong.class, \"static_final_v\" + postfix, long.class);\n+                VarHandleTestAccessLong.class, \"static_final_v\" + postfix, type);\n@@ -91,1 +96,1 @@\n-                VarHandleTestAccessLong.class, \"static_v\" + postfix, long.class);\n+                VarHandleTestAccessLong.class, \"static_v\" + postfix, type);\n@@ -110,1 +115,1 @@\n-                VarHandleTestAccessLong.class, \"final_v\", long.class);\n+                VarHandleTestAccessLong.class, \"final_v\", type);\n@@ -113,1 +118,1 @@\n-                VarHandleTestAccessLong.class, \"v\", long.class);\n+                VarHandleTestAccessLong.class, \"v\", type);\n@@ -116,1 +121,1 @@\n-            VarHandleTestAccessLong.class, \"static_final_v\", long.class);\n+            VarHandleTestAccessLong.class, \"static_final_v\", type);\n@@ -119,1 +124,1 @@\n-            VarHandleTestAccessLong.class, \"static_v\", long.class);\n+            VarHandleTestAccessLong.class, \"static_v\", type);\n@@ -122,0 +127,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"long_v\", type);\n@@ -206,1 +214,1 @@\n-        assertEquals(vh.varType(), long.class);\n+        assertEquals(vh.varType(), type);\n@@ -218,1 +226,1 @@\n-                    VarHandleTestAccessLong.class, \"final_v\", long.class);\n+                    VarHandleTestAccessLong.class, \"final_v\", type);\n@@ -223,1 +231,1 @@\n-                    VarHandleTestAccessLong.class, \"v\", long.class);\n+                    VarHandleTestAccessLong.class, \"v\", type);\n@@ -231,1 +239,1 @@\n-                VarHandleTestAccessLong.class, \"static_final_v\", long.class);\n+                VarHandleTestAccessLong.class, \"static_final_v\", type);\n@@ -236,1 +244,1 @@\n-                VarHandleTestAccessLong.class, \"static_v\", long.class);\n+                VarHandleTestAccessLong.class, \"static_v\", type);\n@@ -277,0 +285,5 @@\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n@@ -343,0 +356,13 @@\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            long x = (long) vh.get(recv);\n+            assertEquals(x, 0x0123456789ABCDEFL, \"get long value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, 0xCAFEBABECAFEBABEL);\n+        });\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessLong.java","additions":39,"deletions":13,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = short.class;\n+\n@@ -71,0 +75,1 @@\n+    VarHandle vhValueTypeField;\n@@ -79,1 +84,1 @@\n-                    VarHandleTestAccessShort.class, \"final_v\" + postfix, short.class);\n+                    VarHandleTestAccessShort.class, \"final_v\" + postfix, type);\n@@ -83,1 +88,1 @@\n-                    VarHandleTestAccessShort.class, \"v\" + postfix, short.class);\n+                    VarHandleTestAccessShort.class, \"v\" + postfix, type);\n@@ -87,1 +92,1 @@\n-                VarHandleTestAccessShort.class, \"static_final_v\" + postfix, short.class);\n+                VarHandleTestAccessShort.class, \"static_final_v\" + postfix, type);\n@@ -91,1 +96,1 @@\n-                VarHandleTestAccessShort.class, \"static_v\" + postfix, short.class);\n+                VarHandleTestAccessShort.class, \"static_v\" + postfix, type);\n@@ -110,1 +115,1 @@\n-                VarHandleTestAccessShort.class, \"final_v\", short.class);\n+                VarHandleTestAccessShort.class, \"final_v\", type);\n@@ -113,1 +118,1 @@\n-                VarHandleTestAccessShort.class, \"v\", short.class);\n+                VarHandleTestAccessShort.class, \"v\", type);\n@@ -116,1 +121,1 @@\n-            VarHandleTestAccessShort.class, \"static_final_v\", short.class);\n+            VarHandleTestAccessShort.class, \"static_final_v\", type);\n@@ -119,1 +124,1 @@\n-            VarHandleTestAccessShort.class, \"static_v\", short.class);\n+            VarHandleTestAccessShort.class, \"static_v\", type);\n@@ -122,0 +127,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"short_v\", type);\n@@ -206,1 +214,1 @@\n-        assertEquals(vh.varType(), short.class);\n+        assertEquals(vh.varType(), type);\n@@ -218,1 +226,1 @@\n-                    VarHandleTestAccessShort.class, \"final_v\", short.class);\n+                    VarHandleTestAccessShort.class, \"final_v\", type);\n@@ -223,1 +231,1 @@\n-                    VarHandleTestAccessShort.class, \"v\", short.class);\n+                    VarHandleTestAccessShort.class, \"v\", type);\n@@ -231,1 +239,1 @@\n-                VarHandleTestAccessShort.class, \"static_final_v\", short.class);\n+                VarHandleTestAccessShort.class, \"static_final_v\", type);\n@@ -236,1 +244,1 @@\n-                VarHandleTestAccessShort.class, \"static_v\", short.class);\n+                VarHandleTestAccessShort.class, \"static_v\", type);\n@@ -277,0 +285,5 @@\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n@@ -343,0 +356,13 @@\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            short x = (short) vh.get(recv);\n+            assertEquals(x, (short)0x0123, \"get short value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, (short)0x4567);\n+        });\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessShort.java","additions":39,"deletions":13,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -45,0 +47,2 @@\n+    static final Class<?> type = String.class;\n+\n@@ -80,1 +84,1 @@\n-                    VarHandleTestAccessString.class, \"final_v\" + postfix, String.class);\n+                    VarHandleTestAccessString.class, \"final_v\" + postfix, type);\n@@ -84,1 +88,1 @@\n-                    VarHandleTestAccessString.class, \"v\" + postfix, String.class);\n+                    VarHandleTestAccessString.class, \"v\" + postfix, type);\n@@ -88,1 +92,1 @@\n-                VarHandleTestAccessString.class, \"static_final_v\" + postfix, String.class);\n+                VarHandleTestAccessString.class, \"static_final_v\" + postfix, type);\n@@ -92,1 +96,1 @@\n-                VarHandleTestAccessString.class, \"static_v\" + postfix, String.class);\n+                VarHandleTestAccessString.class, \"static_v\" + postfix, type);\n@@ -111,1 +115,1 @@\n-                VarHandleTestAccessString.class, \"final_v\", String.class);\n+                VarHandleTestAccessString.class, \"final_v\", type);\n@@ -114,1 +118,1 @@\n-                VarHandleTestAccessString.class, \"v\", String.class);\n+                VarHandleTestAccessString.class, \"v\", type);\n@@ -117,1 +121,1 @@\n-            VarHandleTestAccessString.class, \"static_final_v\", String.class);\n+            VarHandleTestAccessString.class, \"static_final_v\", type);\n@@ -120,1 +124,1 @@\n-            VarHandleTestAccessString.class, \"static_v\", String.class);\n+            VarHandleTestAccessString.class, \"static_v\", type);\n@@ -124,0 +128,1 @@\n+\n@@ -208,1 +213,1 @@\n-        assertEquals(vh.varType(), String.class);\n+        assertEquals(vh.varType(), type);\n@@ -220,1 +225,1 @@\n-                    VarHandleTestAccessString.class, \"final_v\", String.class);\n+                    VarHandleTestAccessString.class, \"final_v\", type);\n@@ -225,1 +230,1 @@\n-                    VarHandleTestAccessString.class, \"v\", String.class);\n+                    VarHandleTestAccessString.class, \"v\", type);\n@@ -233,1 +238,1 @@\n-                VarHandleTestAccessString.class, \"static_final_v\", String.class);\n+                VarHandleTestAccessString.class, \"static_final_v\", type);\n@@ -238,1 +243,1 @@\n-                VarHandleTestAccessString.class, \"static_v\", String.class);\n+                VarHandleTestAccessString.class, \"static_v\", type);\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestAccessString.java","additions":18,"deletions":13,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = boolean.class;\n+\n@@ -61,0 +65,2 @@\n+    VarHandle vhValueTypeField;\n+\n@@ -64,1 +70,1 @@\n-                VarHandleTestMethodHandleAccessBoolean.class, \"final_v\", boolean.class);\n+                VarHandleTestMethodHandleAccessBoolean.class, \"final_v\", type);\n@@ -67,1 +73,1 @@\n-                VarHandleTestMethodHandleAccessBoolean.class, \"v\", boolean.class);\n+                VarHandleTestMethodHandleAccessBoolean.class, \"v\", type);\n@@ -70,1 +76,1 @@\n-            VarHandleTestMethodHandleAccessBoolean.class, \"static_final_v\", boolean.class);\n+            VarHandleTestMethodHandleAccessBoolean.class, \"static_final_v\", type);\n@@ -73,1 +79,1 @@\n-            VarHandleTestMethodHandleAccessBoolean.class, \"static_v\", boolean.class);\n+            VarHandleTestMethodHandleAccessBoolean.class, \"static_v\", type);\n@@ -76,0 +82,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"boolean_v\", type);\n@@ -104,0 +113,5 @@\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n@@ -391,0 +405,23 @@\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            boolean x = (boolean) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, true, \"get boolean value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, true);\n+            });\n+        }\n+\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_ADD)) {\n+            checkUOE(am, () -> {\n+                boolean r = (boolean) hs.get(am).invokeExact(recv, true);\n+            });\n+        }\n+\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessBoolean.java","additions":41,"deletions":4,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = byte.class;\n+\n@@ -61,0 +65,2 @@\n+    VarHandle vhValueTypeField;\n+\n@@ -64,1 +70,1 @@\n-                VarHandleTestMethodHandleAccessByte.class, \"final_v\", byte.class);\n+                VarHandleTestMethodHandleAccessByte.class, \"final_v\", type);\n@@ -67,1 +73,1 @@\n-                VarHandleTestMethodHandleAccessByte.class, \"v\", byte.class);\n+                VarHandleTestMethodHandleAccessByte.class, \"v\", type);\n@@ -70,1 +76,1 @@\n-            VarHandleTestMethodHandleAccessByte.class, \"static_final_v\", byte.class);\n+            VarHandleTestMethodHandleAccessByte.class, \"static_final_v\", type);\n@@ -73,1 +79,1 @@\n-            VarHandleTestMethodHandleAccessByte.class, \"static_v\", byte.class);\n+            VarHandleTestMethodHandleAccessByte.class, \"static_v\", type);\n@@ -76,0 +82,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"byte_v\", type);\n@@ -104,0 +113,5 @@\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n@@ -413,0 +427,18 @@\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            byte x = (byte) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, (byte)0x01, \"get byte value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, (byte)0x01);\n+            });\n+        }\n+\n+\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessByte.java","additions":36,"deletions":4,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = char.class;\n+\n@@ -61,0 +65,2 @@\n+    VarHandle vhValueTypeField;\n+\n@@ -64,1 +70,1 @@\n-                VarHandleTestMethodHandleAccessChar.class, \"final_v\", char.class);\n+                VarHandleTestMethodHandleAccessChar.class, \"final_v\", type);\n@@ -67,1 +73,1 @@\n-                VarHandleTestMethodHandleAccessChar.class, \"v\", char.class);\n+                VarHandleTestMethodHandleAccessChar.class, \"v\", type);\n@@ -70,1 +76,1 @@\n-            VarHandleTestMethodHandleAccessChar.class, \"static_final_v\", char.class);\n+            VarHandleTestMethodHandleAccessChar.class, \"static_final_v\", type);\n@@ -73,1 +79,1 @@\n-            VarHandleTestMethodHandleAccessChar.class, \"static_v\", char.class);\n+            VarHandleTestMethodHandleAccessChar.class, \"static_v\", type);\n@@ -76,0 +82,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"char_v\", type);\n@@ -104,0 +113,5 @@\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n@@ -413,0 +427,18 @@\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            char x = (char) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, '\\u0123', \"get char value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, '\\u0123');\n+            });\n+        }\n+\n+\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessChar.java","additions":36,"deletions":4,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = double.class;\n+\n@@ -61,0 +65,2 @@\n+    VarHandle vhValueTypeField;\n+\n@@ -64,1 +70,1 @@\n-                VarHandleTestMethodHandleAccessDouble.class, \"final_v\", double.class);\n+                VarHandleTestMethodHandleAccessDouble.class, \"final_v\", type);\n@@ -67,1 +73,1 @@\n-                VarHandleTestMethodHandleAccessDouble.class, \"v\", double.class);\n+                VarHandleTestMethodHandleAccessDouble.class, \"v\", type);\n@@ -70,1 +76,1 @@\n-            VarHandleTestMethodHandleAccessDouble.class, \"static_final_v\", double.class);\n+            VarHandleTestMethodHandleAccessDouble.class, \"static_final_v\", type);\n@@ -73,1 +79,1 @@\n-            VarHandleTestMethodHandleAccessDouble.class, \"static_v\", double.class);\n+            VarHandleTestMethodHandleAccessDouble.class, \"static_v\", type);\n@@ -76,0 +82,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"double_v\", type);\n@@ -104,0 +113,5 @@\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n@@ -335,0 +349,23 @@\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            double x = (double) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, 1.0d, \"get double value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, 1.0d);\n+            });\n+        }\n+\n+\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_BITWISE)) {\n+            checkUOE(am, () -> {\n+                double r = (double) hs.get(am).invokeExact(recv, 1.0d);\n+            });\n+        }\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessDouble.java","additions":41,"deletions":4,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = float.class;\n+\n@@ -61,0 +65,2 @@\n+    VarHandle vhValueTypeField;\n+\n@@ -64,1 +70,1 @@\n-                VarHandleTestMethodHandleAccessFloat.class, \"final_v\", float.class);\n+                VarHandleTestMethodHandleAccessFloat.class, \"final_v\", type);\n@@ -67,1 +73,1 @@\n-                VarHandleTestMethodHandleAccessFloat.class, \"v\", float.class);\n+                VarHandleTestMethodHandleAccessFloat.class, \"v\", type);\n@@ -70,1 +76,1 @@\n-            VarHandleTestMethodHandleAccessFloat.class, \"static_final_v\", float.class);\n+            VarHandleTestMethodHandleAccessFloat.class, \"static_final_v\", type);\n@@ -73,1 +79,1 @@\n-            VarHandleTestMethodHandleAccessFloat.class, \"static_v\", float.class);\n+            VarHandleTestMethodHandleAccessFloat.class, \"static_v\", type);\n@@ -76,0 +82,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"float_v\", type);\n@@ -104,0 +113,5 @@\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n@@ -335,0 +349,23 @@\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            float x = (float) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, 1.0f, \"get float value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, 1.0f);\n+            });\n+        }\n+\n+\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_BITWISE)) {\n+            checkUOE(am, () -> {\n+                float r = (float) hs.get(am).invokeExact(recv, 1.0f);\n+            });\n+        }\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessFloat.java","additions":41,"deletions":4,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = int.class;\n+\n@@ -61,0 +65,2 @@\n+    VarHandle vhValueTypeField;\n+\n@@ -64,1 +70,1 @@\n-                VarHandleTestMethodHandleAccessInt.class, \"final_v\", int.class);\n+                VarHandleTestMethodHandleAccessInt.class, \"final_v\", type);\n@@ -67,1 +73,1 @@\n-                VarHandleTestMethodHandleAccessInt.class, \"v\", int.class);\n+                VarHandleTestMethodHandleAccessInt.class, \"v\", type);\n@@ -70,1 +76,1 @@\n-            VarHandleTestMethodHandleAccessInt.class, \"static_final_v\", int.class);\n+            VarHandleTestMethodHandleAccessInt.class, \"static_final_v\", type);\n@@ -73,1 +79,1 @@\n-            VarHandleTestMethodHandleAccessInt.class, \"static_v\", int.class);\n+            VarHandleTestMethodHandleAccessInt.class, \"static_v\", type);\n@@ -76,0 +82,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"int_v\", type);\n@@ -104,0 +113,5 @@\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n@@ -413,0 +427,18 @@\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            int x = (int) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, 0x01234567, \"get int value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, 0x01234567);\n+            });\n+        }\n+\n+\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessInt.java","additions":36,"deletions":4,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = long.class;\n+\n@@ -61,0 +65,2 @@\n+    VarHandle vhValueTypeField;\n+\n@@ -64,1 +70,1 @@\n-                VarHandleTestMethodHandleAccessLong.class, \"final_v\", long.class);\n+                VarHandleTestMethodHandleAccessLong.class, \"final_v\", type);\n@@ -67,1 +73,1 @@\n-                VarHandleTestMethodHandleAccessLong.class, \"v\", long.class);\n+                VarHandleTestMethodHandleAccessLong.class, \"v\", type);\n@@ -70,1 +76,1 @@\n-            VarHandleTestMethodHandleAccessLong.class, \"static_final_v\", long.class);\n+            VarHandleTestMethodHandleAccessLong.class, \"static_final_v\", type);\n@@ -73,1 +79,1 @@\n-            VarHandleTestMethodHandleAccessLong.class, \"static_v\", long.class);\n+            VarHandleTestMethodHandleAccessLong.class, \"static_v\", type);\n@@ -76,0 +82,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"long_v\", type);\n@@ -104,0 +113,5 @@\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n@@ -413,0 +427,18 @@\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            long x = (long) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, 0x0123456789ABCDEFL, \"get long value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, 0x0123456789ABCDEFL);\n+            });\n+        }\n+\n+\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessLong.java","additions":36,"deletions":4,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = short.class;\n+\n@@ -61,0 +65,2 @@\n+    VarHandle vhValueTypeField;\n+\n@@ -64,1 +70,1 @@\n-                VarHandleTestMethodHandleAccessShort.class, \"final_v\", short.class);\n+                VarHandleTestMethodHandleAccessShort.class, \"final_v\", type);\n@@ -67,1 +73,1 @@\n-                VarHandleTestMethodHandleAccessShort.class, \"v\", short.class);\n+                VarHandleTestMethodHandleAccessShort.class, \"v\", type);\n@@ -70,1 +76,1 @@\n-            VarHandleTestMethodHandleAccessShort.class, \"static_final_v\", short.class);\n+            VarHandleTestMethodHandleAccessShort.class, \"static_final_v\", type);\n@@ -73,1 +79,1 @@\n-            VarHandleTestMethodHandleAccessShort.class, \"static_v\", short.class);\n+            VarHandleTestMethodHandleAccessShort.class, \"static_v\", type);\n@@ -76,0 +82,3 @@\n+\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"short_v\", type);\n@@ -104,0 +113,5 @@\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n@@ -413,0 +427,18 @@\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            short x = (short) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, (short)0x0123, \"get short value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, (short)0x0123);\n+            });\n+        }\n+\n+\n+    }\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessShort.java","additions":36,"deletions":4,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+\/\/ -- This file was mechanically generated: Do not edit! -- \/\/\n+\n@@ -43,0 +45,2 @@\n+    static final Class<?> type = String.class;\n+\n@@ -61,0 +65,1 @@\n+\n@@ -64,1 +69,1 @@\n-                VarHandleTestMethodHandleAccessString.class, \"final_v\", String.class);\n+                VarHandleTestMethodHandleAccessString.class, \"final_v\", type);\n@@ -67,1 +72,1 @@\n-                VarHandleTestMethodHandleAccessString.class, \"v\", String.class);\n+                VarHandleTestMethodHandleAccessString.class, \"v\", type);\n@@ -70,1 +75,1 @@\n-            VarHandleTestMethodHandleAccessString.class, \"static_final_v\", String.class);\n+            VarHandleTestMethodHandleAccessString.class, \"static_final_v\", type);\n@@ -73,1 +78,1 @@\n-            VarHandleTestMethodHandleAccessString.class, \"static_v\", String.class);\n+            VarHandleTestMethodHandleAccessString.class, \"static_v\", type);\n@@ -76,0 +81,1 @@\n+\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/VarHandleTestMethodHandleAccessString.java","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+#warn\n+\n@@ -45,0 +47,6 @@\n+#if[Point]\n+    static final Class<?> type = $type$.class.asValueType();\n+#else[Point]\n+    static final Class<?> type = $type$.class;\n+#end[Point]\n+\n@@ -71,1 +79,1 @@\n-#if[String]\n+#if[Object]\n@@ -73,1 +81,4 @@\n-#end[String]\n+#end[Object]\n+#if[Value]\n+    VarHandle vhValueTypeField;\n+#end[Value]\n@@ -82,1 +93,1 @@\n-                    VarHandleTestAccess$Type$.class, \"final_v\" + postfix, $type$.class);\n+                    VarHandleTestAccess$Type$.class, \"final_v\" + postfix, type);\n@@ -86,1 +97,1 @@\n-                    VarHandleTestAccess$Type$.class, \"v\" + postfix, $type$.class);\n+                    VarHandleTestAccess$Type$.class, \"v\" + postfix, type);\n@@ -90,1 +101,1 @@\n-                VarHandleTestAccess$Type$.class, \"static_final_v\" + postfix, $type$.class);\n+                VarHandleTestAccess$Type$.class, \"static_final_v\" + postfix, type);\n@@ -94,1 +105,1 @@\n-                VarHandleTestAccess$Type$.class, \"static_v\" + postfix, $type$.class);\n+                VarHandleTestAccess$Type$.class, \"static_v\" + postfix, type);\n@@ -117,1 +128,1 @@\n-                VarHandleTestAccess$Type$.class, \"final_v\", $type$.class);\n+                VarHandleTestAccess$Type$.class, \"final_v\", type);\n@@ -120,1 +131,1 @@\n-                VarHandleTestAccess$Type$.class, \"v\", $type$.class);\n+                VarHandleTestAccess$Type$.class, \"v\", type);\n@@ -123,1 +134,1 @@\n-            VarHandleTestAccess$Type$.class, \"static_final_v\", $type$.class);\n+            VarHandleTestAccess$Type$.class, \"static_final_v\", type);\n@@ -126,1 +137,1 @@\n-            VarHandleTestAccess$Type$.class, \"static_v\", $type$.class);\n+            VarHandleTestAccess$Type$.class, \"static_v\", type);\n@@ -129,1 +140,1 @@\n-#if[String]\n+#if[Object]\n@@ -131,1 +142,6 @@\n-#end[String]\n+#end[Object]\n+\n+#if[Value]\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"$varType$_v\", type);\n+#end[Value]\n@@ -248,1 +264,1 @@\n-        assertEquals(vh.varType(), $type$.class);\n+        assertEquals(vh.varType(), type);\n@@ -260,1 +276,1 @@\n-                    VarHandleTestAccess$Type$.class, \"final_v\", $type$.class);\n+                    VarHandleTestAccess$Type$.class, \"final_v\", type);\n@@ -265,1 +281,1 @@\n-                    VarHandleTestAccess$Type$.class, \"v\", $type$.class);\n+                    VarHandleTestAccess$Type$.class, \"v\", type);\n@@ -273,1 +289,1 @@\n-                VarHandleTestAccess$Type$.class, \"static_final_v\", $type$.class);\n+                VarHandleTestAccess$Type$.class, \"static_final_v\", type);\n@@ -278,1 +294,1 @@\n-                VarHandleTestAccess$Type$.class, \"static_v\", $type$.class);\n+                VarHandleTestAccess$Type$.class, \"static_v\", type);\n@@ -313,1 +329,1 @@\n-#if[String]\n+#if[Object]\n@@ -316,1 +332,1 @@\n-#end[String]\n+#end[Object]\n@@ -323,1 +339,1 @@\n-#if[String]\n+#if[Object]\n@@ -327,1 +343,8 @@\n-#end[String]\n+#end[Object]\n+#if[Value]\n+        cases.add(new VarHandleAccessTestCase(\"Value type field\",\n+                                              vhValueTypeField, vh -> testValueTypeField(Value.getInstance(), vh)));\n+        cases.add(new VarHandleAccessTestCase(\"Value type field unsupported\",\n+                                              vhValueTypeField, vh -> testValueTypeFieldUnsupported(Value.getInstance(), vh),\n+                                              false));\n+#end[Value]\n@@ -489,0 +512,15 @@\n+#if[Value]\n+    static void testValueTypeField(Value recv, VarHandle vh) {\n+        \/\/ Plain\n+        {\n+            $type$ x = ($type$) vh.get(recv);\n+            assertEquals(x, $value1$, \"get $type$ value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, VarHandle vh) {\n+        checkUOE(() -> {\n+            vh.set(recv, $value2$);\n+        });\n+    }\n+#end[Value]\n@@ -2005,1 +2043,1 @@\n-#if[String]\n+#if[Object]\n@@ -2086,1 +2124,1 @@\n-#end[String]\n+#end[Object]\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/X-VarHandleTestAccess.java.template","additions":61,"deletions":23,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -24,0 +24,2 @@\n+#warn\n+\n@@ -43,0 +45,6 @@\n+#if[Point]\n+    static final Class<?> type = $type$.class.asValueType();\n+#else[Point]\n+    static final Class<?> type = $type$.class;\n+#end[Point]\n+\n@@ -61,0 +69,4 @@\n+#if[Value]\n+    VarHandle vhValueTypeField;\n+#end[Value]\n+\n@@ -64,1 +76,1 @@\n-                VarHandleTestMethodHandleAccess$Type$.class, \"final_v\", $type$.class);\n+                VarHandleTestMethodHandleAccess$Type$.class, \"final_v\", type);\n@@ -67,1 +79,1 @@\n-                VarHandleTestMethodHandleAccess$Type$.class, \"v\", $type$.class);\n+                VarHandleTestMethodHandleAccess$Type$.class, \"v\", type);\n@@ -70,1 +82,1 @@\n-            VarHandleTestMethodHandleAccess$Type$.class, \"static_final_v\", $type$.class);\n+            VarHandleTestMethodHandleAccess$Type$.class, \"static_final_v\", type);\n@@ -73,1 +85,1 @@\n-            VarHandleTestMethodHandleAccess$Type$.class, \"static_v\", $type$.class);\n+            VarHandleTestMethodHandleAccess$Type$.class, \"static_v\", type);\n@@ -76,0 +88,5 @@\n+\n+#if[Value]\n+        vhValueTypeField = MethodHandles.lookup().findVarHandle(\n+                    Value.class, \"$varType$_v\", type);\n+#end[Value]\n@@ -104,0 +121,7 @@\n+#if[Value]\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeField(Value.getInstance(), hs)));\n+        cases.add(new MethodHandleAccessTestCase(\"Value type field unsupported\",\n+                                                 vhValueTypeField, f, hs -> testValueTypeFieldUnsupported(Value.getInstance(), hs),\n+                                                 false));\n+#end[Value]\n@@ -452,0 +476,53 @@\n+#if[Value]\n+    static void testValueTypeField(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        {\n+            $type$ x = ($type$) hs.get(TestAccessMode.GET).invokeExact(recv);\n+            assertEquals(x, $value1$, \"get $type$ value\");\n+        }\n+    }\n+\n+    static void testValueTypeFieldUnsupported(Value recv, Handles hs) throws Throwable {\n+        \/\/ Plain\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {\n+            checkUOE(am, () -> {\n+                hs.get(am).invokeExact(recv, $value1$);\n+            });\n+        }\n+#if[!CAS]\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.COMPARE_AND_SET)) {\n+            checkUOE(am, () -> {\n+                boolean r = (boolean) hs.get(am).invokeExact(recv, $value1$, $value2$);\n+            });\n+        }\n+\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.COMPARE_AND_EXCHANGE)) {\n+            checkUOE(am, () -> {\n+                $type$ r = ($type$) hs.get(am).invokeExact(recv, $value1$, $value2$);\n+            });\n+        }\n+\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_SET)) {\n+            checkUOE(am, () -> {\n+                $type$ r = ($type$) hs.get(am).invokeExact(recv, $value1$);\n+            });\n+        }\n+#end[CAS]\n+\n+#if[!AtomicAdd]\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_ADD)) {\n+            checkUOE(am, () -> {\n+                $type$ r = ($type$) hs.get(am).invokeExact(recv, $value1$);\n+            });\n+        }\n+#end[AtomicAdd]\n+\n+#if[!Bitwise]\n+        for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_BITWISE)) {\n+            checkUOE(am, () -> {\n+                $type$ r = ($type$) hs.get(am).invokeExact(recv, $value1$);\n+            });\n+        }\n+#end[Bitwise]\n+    }\n+#end[Value]\n","filename":"test\/jdk\/java\/lang\/invoke\/VarHandles\/X-VarHandleTestMethodHandleAccess.java.template","additions":81,"deletions":4,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -209,0 +209,1 @@\n+\n@@ -210,0 +211,21 @@\n+\n+# Value types\n+compiler.err.cyclic.primitive.class.membership\n+compiler.err.value.class.does.not.support\n+compiler.err.value.class.may.not.extend\n+compiler.err.this.exposed.prematurely\n+compiler.err.concrete.supertype.for.value.class\n+compiler.err.super.class.cannot.be.inner\n+compiler.err.super.class.declares.init.block\n+compiler.err.super.constructor.cannot.take.arguments\n+compiler.err.super.constructor.access.restricted\n+compiler.err.super.constructor.cannot.be.generic\n+compiler.err.super.constructor.cannot.throw\n+compiler.err.super.field.not.allowed\n+compiler.err.super.method.cannot.be.synchronized\n+compiler.err.super.no.arg.constructor.must.be.empty\n+compiler.err.generic.parameterization.with.primitive.class\n+compiler.misc.feature.primitive.classes\n+compiler.misc.feature.value.classes\n+compiler.misc.abstract.value.class\n+compiler.misc.superclass.of.value.class\n","filename":"test\/langtools\/tools\/javac\/diags\/examples.not-yet.txt","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"}]}