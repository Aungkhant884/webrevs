{"files":[{"patch":"@@ -277,1 +277,1 @@\n-  $1_FLAGS += $$($1_JAVAC_FLAGS)\n+  $1_FLAGS += $$($1_JAVAC_FLAGS) -XDenablePrimitiveClasses\n","filename":"make\/common\/JavaCompilation.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -7314,0 +7314,8 @@\n+void Assembler::evaddsh(XMMRegister dst, XMMRegister nds, XMMRegister src) {\n+  assert(VM_Version::supports_avx512_fp16(), \"requires AVX512-FP16\");\n+  InstructionAttr attributes(AVX_128bit, false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_F3, VEX_OPCODE_MAP5, &attributes);\n+  emit_int16(0x58, (0xC0 | encode));\n+}\n+\n@@ -11483,1 +11491,1 @@\n-  \/\/ of form {0F, 0F_38, 0F_3A}\n+  \/\/ of form {0F, 0F_38, 0F_3A, MAP5}\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -550,0 +550,1 @@\n+    VEX_OPCODE_MAP5  = 0x5,\n@@ -2397,0 +2398,1 @@\n+  void evaddsh(XMMRegister dst, XMMRegister nds, XMMRegister src);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3020,0 +3020,3 @@\n+\n+    if (_cpuid_info.sef_cpuid7_edx.bits.avx512_fp16 != 0)\n+      result |= CPU_AVX512_FP16;\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -278,1 +278,3 @@\n-                           : 11;\n+                           : 2,\n+              avx512_fp16  : 1,\n+                           : 8;\n@@ -393,1 +395,2 @@\n-    decl(AVX512_IFMA,       \"avx512_ifma\",       58) \/* Integer Vector FMA instructions*\/\n+    decl(AVX512_IFMA,       \"avx512_ifma\",       58) \/* Integer Vector FMA instructions*\/ \\\n+    decl(AVX512_FP16,       \"avx512_fp16\",       59) \/* AVX512 FP16 ISA support*\/\n@@ -699,0 +702,1 @@\n+  static bool supports_avx512_fp16()  { return (_features & CPU_AVX512_FP16) != 0; }\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1454,0 +1454,5 @@\n+    case Op_AddHF:\n+      if (!VM_Version::supports_avx512_fp16()) {\n+        return false;\n+      }\n+      break;\n@@ -10152,0 +10157,23 @@\n+instruct reinterpretS2H (regF dst, rRegI src, rRegI tmp)\n+%{\n+  match(Set dst (ReinterpretS2HF src));\n+  effect(TEMP tmp);\n+  format %{ \"movdl $dst, $src\\t! using $tmp as TEMP\" %}\n+  ins_encode %{\n+    __ movl($tmp$$Register, $src$$Register);\n+    __ andl($tmp$$Register, 0xFFFF);\n+    __ movdl($dst$$XMMRegister, $tmp$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reinterpretH2S (rRegI dst, regF src)\n+%{\n+  match(Set dst (ReinterpretHF2S src));\n+  format %{ \"movdl $dst, $src\" %}\n+  ins_encode %{\n+    __ movdl($dst$$Register, $src$$XMMRegister);\n+    __ movswl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -10153,0 +10181,9 @@\n+instruct addFP16_scalar (regF dst, regF src1, regF src2)\n+%{\n+  match(Set dst (AddHF src1 src2));\n+  format %{ \"vaddsh $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ evaddsh($dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":37,"deletions":0,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -4698,0 +4698,9 @@\n+\/\/ utility function to skip over internal jdk primitive classes used to override the need for passing\n+\/\/ an explict JVM flag EnablePrimitiveClasses.\n+bool ClassFileParser::is_jdk_internal_class(const Symbol* class_name) const {\n+  if (vmSymbols::java_lang_Float16() == class_name) {\n+    return true;\n+  }\n+  return false;\n+}\n+\n@@ -4728,1 +4737,1 @@\n-  if (is_primitive_class && !EnablePrimitiveClasses) {\n+  if (is_primitive_class && !is_jdk_internal_class(_class_name) && !EnablePrimitiveClasses) {\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -220,0 +220,2 @@\n+  bool is_jdk_internal_class(const Symbol* class_name) const;\n+\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -174,0 +174,1 @@\n+  do_klass(Float16_klass,                               java_lang_Float16                                     ) \\\n","filename":"src\/hotspot\/share\/classfile\/vmClassMacros.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -198,0 +198,6 @@\n+                                                                                                                        \\\n+  \/* Float16 intrinsics, similar to what we have in Math. *\/                                                            \\\n+  do_intrinsic(_add_float16,              java_lang_Float16,      add_name,           floa16_float16_signature,  F_R)   \\\n+   do_name(add_name,    \"add\")                                                                                          \\\n+   do_signature(floa16_float16_signature, \"(Qjava\/lang\/Float16;)Qjava\/lang\/Float16;\")                                   \\\n+                                                                                                                        \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -84,0 +84,1 @@\n+  template(java_lang_Float16,                         \"java\/lang\/Float16\")                        \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -134,0 +134,8 @@\n+\/\/------------------------------AddHFNode---------------------------------------\n+\/\/ Add 2 floats\n+class AddHFNode : public AddFNode {\n+public:\n+  AddHFNode( Node *in1, Node *in2 ) : AddFNode(in1,in2) {}\n+  virtual int Opcode() const;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/addnode.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -752,1 +752,3 @@\n-\n+  case vmIntrinsics::_add_float16:\n+    if (!Matcher::match_rule_supported(Op_AddHF)) return false;\n+    break;\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+macro(AddHF)\n@@ -489,0 +490,2 @@\n+macro(ReinterpretS2HF)\n+macro(ReinterpretHF2S)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -856,0 +856,24 @@\n+\n+const Type* ReinterpretS2HFNode::Value(PhaseGVN* phase) const {\n+  const Type* type = phase->type( in(1) );\n+  \/\/ Convert FP16 constant value to Float constant value, this will allow\n+  \/\/ further constant folding to be done at float granularity by value routines\n+  \/\/ of FP16 IR nodes.\n+  if (type->isa_int() && type->is_int()->is_con()) {\n+     jshort hfval = type->is_int()->get_con();\n+     jfloat fval = StubRoutines::hf2f(hfval);\n+     return TypeF::make(fval);\n+  }\n+  return Type::FLOAT;\n+}\n+\n+const Type* ReinterpretHF2SNode::Value(PhaseGVN* phase) const {\n+  const Type* type = phase->type( in(1) );\n+  \/\/ Convert Float constant value to FP16 constant value.\n+  if (type->isa_float_constant()) {\n+     jfloat fval = type->is_float_constant()->_f;\n+     jshort hfval = StubRoutines::f2hf(fval);\n+     return TypeInt::make(hfval);\n+  }\n+  return TypeInt::SHORT;\n+}\n","filename":"src\/hotspot\/share\/opto\/convertnode.cpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -176,0 +176,18 @@\n+class ReinterpretS2HFNode : public Node {\n+  public:\n+  ReinterpretS2HFNode( Node *in1 ) : Node(0,in1) {}\n+  virtual int Opcode() const;\n+  virtual const Type *bottom_type() const { return Type::FLOAT; }\n+  virtual const Type* Value(PhaseGVN* phase) const;\n+  virtual uint  ideal_reg() const { return Op_RegF; }\n+};\n+\n+class ReinterpretHF2SNode : public Node {\n+  public:\n+  ReinterpretHF2SNode( Node *in1 ) : Node(0,in1) {}\n+  virtual int Opcode() const;\n+  virtual const Type* Value(PhaseGVN* phase) const;\n+  virtual const Type *bottom_type() const { return TypeInt::SHORT; }\n+  virtual uint  ideal_reg() const { return Op_RegI; }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/convertnode.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -53,3 +53,0 @@\n-  \/\/ Get the klass defining the field layout of the inline type\n-  ciInlineKlass* inline_klass() const { return type()->inline_klass(); }\n-\n@@ -80,0 +77,3 @@\n+  \/\/ Get the klass defining the field layout of the inline type\n+  ciInlineKlass* inline_klass() const { return type()->inline_klass(); }\n+\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -547,0 +547,2 @@\n+  case vmIntrinsics::_add_float16:              return inline_fp16_operations(intrinsic_id());\n+\n@@ -4897,0 +4899,23 @@\n+bool LibraryCallKit::inline_fp16_operations(vmIntrinsics::ID id) {\n+  Node* result = NULL;\n+  Node* val1 = argument(0);  \/\/ receiver\n+  Node* val2 = argument(1);  \/\/ argument\n+  assert(val1->is_InlineType() && val2->is_InlineType(), \"\");\n+\n+  Node* fld1 = _gvn.transform(new ReinterpretS2HFNode(val1->as_InlineType()->field_value(0)));\n+  Node* fld2 = _gvn.transform(new ReinterpretS2HFNode(val2->as_InlineType()->field_value(0)));\n+\n+  switch (id) {\n+  case vmIntrinsics::_add_float16:   result = _gvn.transform(new AddHFNode(fld1, fld2)); break;\n+\n+  default:\n+    fatal_unexpected_iid(id);\n+    break;\n+  }\n+  InlineTypeNode* box = InlineTypeNode::make_uninitialized(_gvn, val1->as_InlineType()->inline_klass(), true);\n+  Node* short_result  = _gvn.transform(new ReinterpretHF2SNode(result));\n+  box->set_field_value(0, short_result);\n+  set_result(_gvn.transform(box));\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -306,0 +306,1 @@\n+  bool inline_fp16_operations(vmIntrinsics::ID id);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,102 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package java.lang;\n+\n+import java.lang.invoke.MethodHandles;\n+import java.lang.constant.Constable;\n+import java.lang.constant.ConstantDesc;\n+import java.util.Optional;\n+\n+import jdk.internal.math.FloatConsts;\n+import jdk.internal.math.FloatingDecimal;\n+import jdk.internal.math.FloatToDecimal;\n+import jdk.internal.vm.annotation.IntrinsicCandidate;\n+\n+\/**\n+ * The {@code Float16} is a primitive value class holding 16-bit data in IEEE 754 binary16 format\n+ * {@code Float16} contains a single field whose type is {@code short}.\n+ *\n+ * Binary16 Format:\n+ *   S EEEEE  MMMMMMMMMM\n+ *   Sign        - 1 bit\n+ *   Exponent    - 5 bits\n+ *   Significand - 10 bits\n+ *\n+ * <p>This is a <a href=\"https:\/\/openjdk.org\/jeps\/401\">primitive value class<\/a> and its objects are\n+ * identity-less non-nullable value objects.\n+ *\n+ * @author Jatin Bhateja\n+ * @since 20.00\n+ *\/\n+\n+public primitive class Float16 {\n+   private final short value;\n+\n+  \/**\n+   * Returns a {@code Float16} instance wrapping IEEE 754 binary16\n+   * encoded {@code short} value.\n+   *\n+   * @param  value a short value.\n+   * @since  20\n+   *\/\n+   public Float16 (short value ) {\n+       this.value = value;\n+   }\n+\n+  \/**\n+   * Returns a {@code Float16} instance wrapping IEEE 754 binary16\n+   * encoded {@code short} value.\n+   *\n+   * @param  value a short value.\n+   * @return a {@code Float16} instance representing {@code value}.\n+   * @since  20\n+   *\/\n+   public static Float16 valueOf(short value) {\n+      return new Float16(value);\n+   }\n+\n+   \/**\n+    * Adds two {@code Float16} values together as per the + operator semantics.\n+    *\n+    * @apiNote This method corresponds to the addition operation\n+    * defined in IEEE 754.\n+    *\n+    * @param value the first operand\n+    * @return sum of receiver and {@code value)}.\n+    * @since 20\n+    *\/\n+   @IntrinsicCandidate\n+   public Float16 add(Float16 value) {\n+      return Float16.valueOf(Float.floatToFloat16(Float.float16ToFloat(this.value) + Float.float16ToFloat(value.value)));\n+   }\n+\n+   \/**\n+    * Return raw short value.\n+    * @return raw short value {@code value)}.\n+    * @since 20\n+    *\/\n+   public short float16ToRawShortBits() { return value; }\n+}\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Float16.java","additions":102,"deletions":0,"binary":false,"changes":102,"status":"added"},{"patch":"@@ -235,0 +235,1 @@\n+        AVX512_FP16,\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/amd64\/AMD64.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,92 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test\n+ * @bug     8308363\n+ * @summary Initial compiler support for Float16.add operation.\n+ * @compile -XDenablePrimitiveClasses FP16ScalarOperations.java\n+ * @run main\/othervm -XX:+EnablePrimitiveClasses -XX:-TieredCompilation -Xbatch FP16ScalarOperations\n+ *\/\n+\n+import java.util.Random;\n+\n+public class FP16ScalarOperations {\n+\n+   public static Random r = new Random(1024);\n+\n+    public static short actual_value(char oper, short val1, short val2) {\n+        Float16 obj1 = new Float16((short)val1);\n+        Float16 obj2 = new Float16((short)val2);\n+        switch ((int)oper) {\n+            case '+' : return obj1.add(obj2).float16ToRawShortBits();\n+            default  : throw new AssertionError(\"Unsupported Operation!\");\n+        }\n+    }\n+\n+    public static void test_add(short [] arr1, short arr2[]) {\n+        for (int i = 0; i < arr1.length; i++) {\n+            validate('+', arr1[i], arr2[i]);\n+        }\n+    }\n+\n+    public static short expected_value(char oper, short input1, short input2) {\n+        switch((int)oper) {\n+            case '+' : return Float.floatToFloat16(Float.float16ToFloat(input1) + Float.float16ToFloat(input2));\n+            default  : throw new AssertionError(\"Unsupported Operation!\");\n+        }\n+    }\n+    public static void validate(char oper, short input1, short input2) {\n+        short actual = actual_value(oper, input1, input2);\n+        short expected = expected_value(oper, input1, input2);\n+        if (actual != expected) {\n+            throw new AssertionError(\"Test Failed: \" + input1 + \" + \" + input2 + \" : \" + actual + \" != \" + expected);\n+        }\n+    }\n+\n+    public static short [] get_fp16_array(int size) {\n+        short [] arr = new short[size];\n+        for (int i = 0; i < arr.length; i++) {\n+            arr[i] = Float.floatToFloat16(r.nextFloat());\n+        }\n+        return arr;\n+    }\n+\n+    public static void main(String [] args) {\n+        int res = 0;\n+        short [] input1 = get_fp16_array(1024);\n+        short [] input2 = get_fp16_array(1024);\n+        short [] special_values = {\n+              32256,          \/\/ NAN\n+              31744,          \/\/ +Inf\n+              (short)-1024,   \/\/ -Inf\n+              0,              \/\/ +0.0\n+              (short)-32768,  \/\/ -0.0\n+        };\n+        for (int i = 0;  i < 1000; i++) {\n+            test_add(input1, input2);\n+            test_add(special_values, special_values);\n+        }\n+        System.out.println(\"PASS\");\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Float16\/FP16ScalarOperations.java","additions":92,"deletions":0,"binary":false,"changes":92,"status":"added"}]}