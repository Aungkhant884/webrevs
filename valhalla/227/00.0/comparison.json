{"files":[{"patch":"@@ -1965,3 +1965,4 @@\n-    st->print(\"# touch polling page\\n\\t\");\n-    st->print(\"ldr rscratch1, [rthread],#polling_page_offset\\n\\t\");\n-    st->print(\"ldr zr, [rscratch1]\");\n+    st->print(\"# test polling word\\n\\t\");\n+    st->print(\"ldr  rscratch1, [rthread],#%d\\n\\t\", in_bytes(JavaThread::polling_word_offset()));\n+    st->print(\"cmp  sp, rscratch1\\n\\t\");\n+    st->print(\"bhi #slow_path\");\n@@ -1984,1 +1985,7 @@\n-    __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);\n+    Label dummy_label;\n+    Label* code_stub = &dummy_label;\n+    if (!C->output()->in_scratch_emit_size()) {\n+      code_stub = &C->output()->safepoint_poll_table()->add_safepoint(__ offset());\n+    }\n+    __ relocate(relocInfo::poll_return_type);\n+    __ safepoint_poll(*code_stub, true \/* at_return *\/, false \/* acquire *\/, true \/* in_nmethod *\/);\n@@ -16438,1 +16445,1 @@\n-instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n+instruct string_indexof_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n@@ -16443,0 +16450,1 @@\n+  predicate(((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::U);\n@@ -16446,1 +16454,1 @@\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$ch -> $result\" %}\n+  format %{ \"StringUTF16 IndexOf char[] $str1,$cnt1,$ch -> $result\" %}\n@@ -16456,0 +16464,19 @@\n+instruct stringL_indexof_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n+                              iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,\n+                              iRegINoSp tmp3, rFlagsReg cr)\n+%{\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  predicate(((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::L);\n+  effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,\n+         TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);\n+\n+  format %{ \"StringLatin1 IndexOf char[] $str1,$cnt1,$ch -> $result\" %}\n+\n+  ins_encode %{\n+    __ stringL_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,\n+                           $result$$Register, $tmp1$$Register, $tmp2$$Register,\n+                           $tmp3$$Register);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":33,"deletions":6,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -41,0 +41,13 @@\n+void C1SafepointPollStub::emit_code(LIR_Assembler* ce) {\n+  __ bind(_entry);\n+  InternalAddress safepoint_pc(ce->masm()->pc() - ce->masm()->offset() + safepoint_offset());\n+  __ adr(rscratch1, safepoint_pc);\n+  __ str(rscratch1, Address(rthread, JavaThread::saved_exception_pc_offset()));\n+\n+  assert(SharedRuntime::polling_page_return_handler_blob() != NULL,\n+         \"polling page return stub not created yet\");\n+  address stub = SharedRuntime::polling_page_return_handler_blob()->entry_point();\n+\n+  __ far_jump(RuntimeAddress(stub));\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_CodeStubs_aarch64.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -509,1 +509,1 @@\n-void LIR_Assembler::return_op(LIR_Opr result) {\n+void LIR_Assembler::return_op(LIR_Opr result, C1SafepointPollStub* code_stub) {\n@@ -534,1 +534,3 @@\n-  __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);\n+  code_stub->set_safepoint_offset(__ offset());\n+  __ relocate(relocInfo::poll_return_type);\n+  __ safepoint_poll(*code_stub->entry(), true \/* at_return *\/, false \/* acquire *\/, true \/* in_nmethod *\/);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -479,2 +480,2 @@\n-\/\/ frame::sender\n-frame frame::sender(RegisterMap* map) const {\n+\/\/ frame::sender_raw\n+frame frame::sender_raw(RegisterMap* map) const {\n@@ -502,0 +503,10 @@\n+frame frame::sender(RegisterMap* map) const {\n+  frame result = sender_raw(map);\n+\n+  if (map->process_frames()) {\n+    StackWatermarkSet::on_iteration(map->thread(), result);\n+  }\n+\n+  return result;\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -477,1 +477,1 @@\n-    ldr(rscratch2, Address(rthread, Thread::polling_page_offset()));\n+    ldr(rscratch2, Address(rthread, Thread::polling_word_offset()));\n@@ -525,0 +525,1 @@\n+\/\/ Apply stack watermark barrier.\n@@ -545,0 +546,13 @@\n+  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n+  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n+  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n+  Label slow_path;\n+  Label fast_path;\n+  safepoint_poll(slow_path, true \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n+  br(Assembler::AL, fast_path);\n+  bind(slow_path);\n+  push(state);\n+  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind));\n+  pop(state);\n+  bind(fast_path);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -292,21 +292,15 @@\n-void MacroAssembler::safepoint_poll(Label& slow_path) {\n-  ldr(rscratch1, Address(rthread, Thread::polling_page_offset()));\n-  tbnz(rscratch1, exact_log2(SafepointMechanism::poll_bit()), slow_path);\n-}\n-\n-\/\/ Just like safepoint_poll, but use an acquiring load for thread-\n-\/\/ local polling.\n-\/\/\n-\/\/ We need an acquire here to ensure that any subsequent load of the\n-\/\/ global SafepointSynchronize::_state flag is ordered after this load\n-\/\/ of the local Thread::_polling page.  We don't want this poll to\n-\/\/ return false (i.e. not safepointing) and a later poll of the global\n-\/\/ SafepointSynchronize::_state spuriously to return true.\n-\/\/\n-\/\/ This is to avoid a race when we're in a native->Java transition\n-\/\/ racing the code which wakes up from a safepoint.\n-\/\/\n-void MacroAssembler::safepoint_poll_acquire(Label& slow_path) {\n-  lea(rscratch1, Address(rthread, Thread::polling_page_offset()));\n-  ldar(rscratch1, rscratch1);\n-  tbnz(rscratch1, exact_log2(SafepointMechanism::poll_bit()), slow_path);\n+void MacroAssembler::safepoint_poll(Label& slow_path, bool at_return, bool acquire, bool in_nmethod) {\n+  if (acquire) {\n+    lea(rscratch1, Address(rthread, Thread::polling_word_offset()));\n+    ldar(rscratch1, rscratch1);\n+  } else {\n+    ldr(rscratch1, Address(rthread, Thread::polling_word_offset()));\n+  }\n+  if (at_return) {\n+    \/\/ Note that when in_nmethod is set, the stack pointer is incremented before the poll. Therefore,\n+    \/\/ we may safely use the sp instead to perform the stack watermark check.\n+    cmp(in_nmethod ? sp : rfp, rscratch1);\n+    br(Assembler::HI, slow_path);\n+  } else {\n+    tbnz(rscratch1, exact_log2(SafepointMechanism::poll_bit()), slow_path);\n+  }\n@@ -4460,1 +4454,1 @@\n-  for (int i = 0; i < (int)(JavaThread::stack_shadow_zone_size() \/ os::vm_page_size()) - 1; i++) {\n+  for (int i = 0; i < (int)(StackOverflow::stack_shadow_zone_size() \/ os::vm_page_size()) - 1; i++) {\n@@ -4473,7 +4467,0 @@\n-\/\/ Move the address of the polling page into r, then read the polling\n-\/\/ page.\n-address MacroAssembler::fetch_and_read_polling_page(Register r, relocInfo::relocType rtype) {\n-  get_polling_page(r, rtype);\n-  return read_polling_page(r, rtype);\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":16,"deletions":29,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -110,2 +110,1 @@\n-  void safepoint_poll(Label& slow_path);\n-  void safepoint_poll_acquire(Label& slow_path);\n+  void safepoint_poll(Label& slow_path, bool at_return, bool acquire, bool in_nmethod);\n@@ -1266,1 +1265,0 @@\n-  address fetch_and_read_polling_page(Register r, relocInfo::relocType rtype);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -1794,1 +1795,1 @@\n-    __ bang_stack_with_offset(JavaThread::stack_shadow_zone_size());\n+    __ bang_stack_with_offset(StackOverflow::stack_shadow_zone_size());\n@@ -2149,1 +2150,10 @@\n-    __ safepoint_poll_acquire(safepoint_in_progress);\n+    \/\/ We need an acquire here to ensure that any subsequent load of the\n+    \/\/ global SafepointSynchronize::_state flag is ordered after this load\n+    \/\/ of the thread-local polling word.  We don't want this poll to\n+    \/\/ return false (i.e. not safepointing) and a later poll of the global\n+    \/\/ SafepointSynchronize::_state spuriously to return true.\n+    \/\/\n+    \/\/ This is to avoid a race when we're in a native->Java transition\n+    \/\/ racing the code which wakes up from a safepoint.\n+\n+    __ safepoint_poll(safepoint_in_progress, true \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -2165,1 +2175,1 @@\n-  __ cmpw(rscratch1, JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpw(rscratch1, StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -990,1 +990,1 @@\n-    __ safepoint_poll(slow_path);\n+    __ safepoint_poll(slow_path, false \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -1039,1 +1039,1 @@\n-    __ safepoint_poll(slow_path);\n+    __ safepoint_poll(slow_path, false \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -1130,1 +1130,1 @@\n-    const int n_shadow_pages = JavaThread::stack_shadow_zone_size() \/ os::vm_page_size();\n+    const int n_shadow_pages = StackOverflow::stack_shadow_zone_size() \/ os::vm_page_size();\n@@ -1398,1 +1398,10 @@\n-    __ safepoint_poll_acquire(L);\n+\n+    \/\/ We need an acquire here to ensure that any subsequent load of the\n+    \/\/ global SafepointSynchronize::_state flag is ordered after this load\n+    \/\/ of the thread-local polling word.  We don't want this poll to\n+    \/\/ return false (i.e. not safepointing) and a later poll of the global\n+    \/\/ SafepointSynchronize::_state spuriously to return true.\n+    \/\/\n+    \/\/ This is to avoid a race when we're in a native->Java transition\n+    \/\/ racing the code which wakes up from a safepoint.\n+    __ safepoint_poll(L, true \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -1455,1 +1464,1 @@\n-    __ cmp(rscratch1, (u1)JavaThread::stack_guard_yellow_reserved_disabled);\n+    __ cmp(rscratch1, (u1)StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":14,"deletions":5,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -1983,1 +1983,1 @@\n-    if (ProfileInterpreter) {\n+    if (ProfileInterpreter && !TieredCompilation) {\n@@ -3456,5 +3456,0 @@\n-void TemplateTable::count_calls(Register method, Register temp)\n-{\n-  __ call_Unimplemented();\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -286,1 +286,1 @@\n-void LIR_Assembler::return_op(LIR_Opr result) {\n+void LIR_Assembler::return_op(LIR_Opr result, C1SafepointPollStub* code_stub) {\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1327,1 +1327,1 @@\n-void LIR_Assembler::return_op(LIR_Opr result) {\n+void LIR_Assembler::return_op(LIR_Opr result, C1SafepointPollStub* code_stub) {\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -226,1 +226,1 @@\n-      ld(R0, in_bytes(Thread::polling_page_offset()), R16_thread);\n+      ld(R0, in_bytes(Thread::polling_word_offset()), R16_thread);\n@@ -881,2 +881,1 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            monitor, \/*check_for_exceptions=*\/true);\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n@@ -983,2 +982,1 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            monitor, \/*check_for_exceptions=*\/true);\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n@@ -998,1 +996,1 @@\n-void InterpreterMacroAssembler::unlock_object(Register monitor, bool check_for_exceptions) {\n+void InterpreterMacroAssembler::unlock_object(Register monitor) {\n@@ -2404,2 +2402,1 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_method_entry),\n-            \/*check_exceptions=*\/true);\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_method_entry));\n@@ -2440,2 +2437,1 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_method_exit),\n-            \/*check_exceptions=*\/check_exceptions);\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_method_exit), check_exceptions);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":6,"deletions":10,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1210,1 +1210,1 @@\n-void LIR_Assembler::return_op(LIR_Opr result) {\n+void LIR_Assembler::return_op(LIR_Opr result, C1SafepointPollStub* code_stub) {\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRAssembler_s390.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -124,1 +124,1 @@\n-      const Address poll_byte_addr(Z_thread, in_bytes(Thread::polling_page_offset()) + 7 \/* Big Endian *\/);\n+      const Address poll_byte_addr(Z_thread, in_bytes(Thread::polling_word_offset()) + 7 \/* Big Endian *\/);\n@@ -972,2 +972,1 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            monitor, \/*check_for_exceptions=*\/false);\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n@@ -1064,3 +1063,1 @@\n-\n-  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-          monitor, \/*check_for_exceptions=*\/false);\n+  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n","filename":"src\/hotspot\/cpu\/s390\/interp_masm_s390.cpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -83,0 +83,16 @@\n+void C1SafepointPollStub::emit_code(LIR_Assembler* ce) {\n+#ifdef _LP64\n+  __ bind(_entry);\n+  InternalAddress safepoint_pc(ce->masm()->pc() - ce->masm()->offset() + safepoint_offset());\n+  __ lea(rscratch1, safepoint_pc);\n+  __ movptr(Address(r15_thread, JavaThread::saved_exception_pc_offset()), rscratch1);\n+\n+  assert(SharedRuntime::polling_page_return_handler_blob() != NULL,\n+         \"polling page return stub not created yet\");\n+  address stub = SharedRuntime::polling_page_return_handler_blob()->entry_point();\n+  __ jump(RuntimeAddress(stub));\n+#else\n+  ShouldNotReachHere();\n+#endif \/* _LP64 *\/\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c1_CodeStubs_x86.cpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"c1\/c1_CodeStubs.hpp\"\n@@ -523,2 +524,1 @@\n-\n-void LIR_Assembler::return_op(LIR_Opr result) {\n+void LIR_Assembler::return_op(LIR_Opr result, C1SafepointPollStub* code_stub) {\n@@ -555,2 +555,0 @@\n-  bool result_is_oop = result->is_valid() ? result->is_oop() : false;\n-\n@@ -561,2 +559,3 @@\n-  const Register poll_addr = rscratch1;\n-  __ movptr(poll_addr, Address(r15_thread, Thread::polling_page_offset()));\n+  code_stub->set_safepoint_offset(__ offset());\n+  __ relocate(relocInfo::poll_return_type);\n+  __ safepoint_poll(*code_stub->entry(), r15_thread, true \/* at_return *\/, true \/* in_nmethod *\/);\n@@ -568,1 +567,0 @@\n-#endif\n@@ -571,0 +569,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":6,"deletions":7,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -1866,0 +1866,93 @@\n+void C2_MacroAssembler::stringL_indexof_char(Register str1, Register cnt1, Register ch, Register result,\n+                                            XMMRegister vec1, XMMRegister vec2, XMMRegister vec3, Register tmp) {\n+  ShortBranchVerifier sbv(this);\n+  assert(UseSSE42Intrinsics, \"SSE4.2 intrinsics are required\");\n+\n+  int stride = 16;\n+\n+  Label FOUND_CHAR, SCAN_TO_CHAR_INIT, SCAN_TO_CHAR_LOOP,\n+        SCAN_TO_16_CHAR, SCAN_TO_16_CHAR_LOOP, SCAN_TO_32_CHAR_LOOP,\n+        RET_NOT_FOUND, SCAN_TO_16_CHAR_INIT,\n+        FOUND_SEQ_CHAR, DONE_LABEL;\n+\n+  movptr(result, str1);\n+  if (UseAVX >= 2) {\n+    cmpl(cnt1, stride);\n+    jcc(Assembler::less, SCAN_TO_CHAR_INIT);\n+    cmpl(cnt1, stride*2);\n+    jcc(Assembler::less, SCAN_TO_16_CHAR_INIT);\n+    movdl(vec1, ch);\n+    vpbroadcastb(vec1, vec1, Assembler::AVX_256bit);\n+    vpxor(vec2, vec2);\n+    movl(tmp, cnt1);\n+    andl(tmp, 0xFFFFFFE0);  \/\/vector count (in chars)\n+    andl(cnt1,0x0000001F);  \/\/tail count (in chars)\n+\n+    bind(SCAN_TO_32_CHAR_LOOP);\n+    vmovdqu(vec3, Address(result, 0));\n+    vpcmpeqb(vec3, vec3, vec1, Assembler::AVX_256bit);\n+    vptest(vec2, vec3);\n+    jcc(Assembler::carryClear, FOUND_CHAR);\n+    addptr(result, 32);\n+    subl(tmp, stride*2);\n+    jcc(Assembler::notZero, SCAN_TO_32_CHAR_LOOP);\n+    jmp(SCAN_TO_16_CHAR);\n+\n+    bind(SCAN_TO_16_CHAR_INIT);\n+    movdl(vec1, ch);\n+    pxor(vec2, vec2);\n+    pshufb(vec1, vec2);\n+  }\n+\n+  bind(SCAN_TO_16_CHAR);\n+  cmpl(cnt1, stride);\n+  jcc(Assembler::less, SCAN_TO_CHAR_INIT);\/\/less than 16 entires left\n+  if (UseAVX < 2) {\n+    movdl(vec1, ch);\n+    pxor(vec2, vec2);\n+    pshufb(vec1, vec2);\n+  }\n+  movl(tmp, cnt1);\n+  andl(tmp, 0xFFFFFFF0);  \/\/vector count (in bytes)\n+  andl(cnt1,0x0000000F);  \/\/tail count (in bytes)\n+\n+  bind(SCAN_TO_16_CHAR_LOOP);\n+  movdqu(vec3, Address(result, 0));\n+  pcmpeqb(vec3, vec1);\n+  ptest(vec2, vec3);\n+  jcc(Assembler::carryClear, FOUND_CHAR);\n+  addptr(result, 16);\n+  subl(tmp, stride);\n+  jcc(Assembler::notZero, SCAN_TO_16_CHAR_LOOP);\/\/last 16 items...\n+\n+  bind(SCAN_TO_CHAR_INIT);\n+  testl(cnt1, cnt1);\n+  jcc(Assembler::zero, RET_NOT_FOUND);\n+  bind(SCAN_TO_CHAR_LOOP);\n+  load_unsigned_byte(tmp, Address(result, 0));\n+  cmpl(ch, tmp);\n+  jccb(Assembler::equal, FOUND_SEQ_CHAR);\n+  addptr(result, 1);\n+  subl(cnt1, 1);\n+  jccb(Assembler::zero, RET_NOT_FOUND);\n+  jmp(SCAN_TO_CHAR_LOOP);\n+\n+  bind(RET_NOT_FOUND);\n+  movl(result, -1);\n+  jmpb(DONE_LABEL);\n+\n+  bind(FOUND_CHAR);\n+  if (UseAVX >= 2) {\n+    vpmovmskb(tmp, vec3);\n+  } else {\n+    pmovmskb(tmp, vec3);\n+  }\n+  bsfl(ch, tmp);\n+  addl(result, ch);\n+\n+  bind(FOUND_SEQ_CHAR);\n+  subptr(result, str1);\n+\n+  bind(DONE_LABEL);\n+} \/\/ stringL_indexof_char\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":93,"deletions":0,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -510,2 +511,2 @@\n-\/\/ frame::sender\n-frame frame::sender(RegisterMap* map) const {\n+\/\/ frame::sender_raw\n+frame frame::sender_raw(RegisterMap* map) const {\n@@ -528,0 +529,10 @@\n+frame frame::sender(RegisterMap* map) const {\n+  frame result = sender_raw(map);\n+\n+  if (map->process_frames()) {\n+    StackWatermarkSet::on_iteration(map->thread(), result);\n+  }\n+\n+  return result;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.cpp","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -162,0 +162,3 @@\n+  \/\/ returns the sending frame, without applying any barriers\n+  frame sender_raw(RegisterMap* map) const;\n+\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -369,1 +369,1 @@\n-  __ testb(gc_state, ShenandoahHeap::EVACUATION);\n+  __ testb(gc_state, ShenandoahHeap::HAS_FORWARDED);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shenandoah\/shenandoahBarrierSetAssembler_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -862,1 +862,1 @@\n-    testb(Address(r15_thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+    testb(Address(r15_thread, Thread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -881,1 +881,1 @@\n-    testb(Address(thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+    testb(Address(thread, Thread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -970,0 +970,1 @@\n+\/\/ Apply stack watermark barrier.\n@@ -996,1 +997,15 @@\n-  NOT_LP64(get_thread(rcx);)\n+  NOT_LP64(get_thread(rthread);)\n+\n+  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n+  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n+  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n+  Label slow_path;\n+  Label fast_path;\n+  safepoint_poll(slow_path, rthread, true \/* at_return *\/, false \/* in_nmethod *\/);\n+  jmp(fast_path);\n+  bind(slow_path);\n+  push(state);\n+  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind));\n+  pop(state);\n+  NOT_LP64(get_thread(rthread);) \/\/ call_VM clobbered it, restore\n+  bind(fast_path);\n@@ -1137,1 +1152,1 @@\n-    cmpl(Address(rthread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_enabled);\n+    cmpl(Address(rthread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_enabled);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":19,"deletions":4,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -1066,1 +1066,1 @@\n-  for (int i = 1; i < ((int)JavaThread::stack_shadow_zone_size() \/ os::vm_page_size()); i++) {\n+  for (int i = 1; i < ((int)StackOverflow::stack_shadow_zone_size() \/ os::vm_page_size()); i++) {\n@@ -2815,1 +2815,1 @@\n-void MacroAssembler::safepoint_poll(Label& slow_path, Register thread_reg, Register temp_reg) {\n+void MacroAssembler::safepoint_poll(Label& slow_path, Register thread_reg, bool at_return, bool in_nmethod) {\n@@ -2817,5 +2817,6 @@\n-  assert(thread_reg == r15_thread, \"should be\");\n-#else\n-  if (thread_reg == noreg) {\n-    thread_reg = temp_reg;\n-    get_thread(thread_reg);\n+  if (at_return) {\n+    \/\/ Note that when in_nmethod is set, the stack pointer is incremented before the poll. Therefore,\n+    \/\/ we may safely use rsp instead to perform the stack watermark check.\n+    cmpq(Address(thread_reg, Thread::polling_word_offset()), in_nmethod ? rsp : rbp);\n+    jcc(Assembler::above, slow_path);\n+    return;\n@@ -2824,1 +2825,1 @@\n-  testb(Address(thread_reg, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+  testb(Address(thread_reg, Thread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -8612,0 +8613,1 @@\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":10,"deletions":8,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -703,3 +703,1 @@\n-  \/\/ If thread_reg is != noreg the code assumes the register passed contains\n-  \/\/ the thread (required on 64 bit).\n-  void safepoint_poll(Label& slow_path, Register thread_reg, Register temp_reg);\n+  void safepoint_poll(Label& slow_path, Register thread_reg, bool at_return, bool in_nmethod);\n@@ -1798,0 +1796,29 @@\n+\n+#if COMPILER2_OR_JVMCI\n+  void arraycopy_avx3_special_cases(XMMRegister xmm, KRegister mask, Register from,\n+                                    Register to, Register count, int shift,\n+                                    Register index, Register temp,\n+                                    bool use64byteVector, Label& L_entry, Label& L_exit);\n+\n+  void arraycopy_avx3_special_cases_conjoint(XMMRegister xmm, KRegister mask, Register from,\n+                                             Register to, Register start_index, Register end_index,\n+                                             Register count, int shift, Register temp,\n+                                             bool use64byteVector, Label& L_entry, Label& L_exit);\n+\n+  void copy64_masked_avx(Register dst, Register src, XMMRegister xmm,\n+                         KRegister mask, Register length, Register index,\n+                         Register temp, int shift = Address::times_1, int offset = 0,\n+                         bool use64byteVector = false);\n+\n+  void copy32_masked_avx(Register dst, Register src, XMMRegister xmm,\n+                         KRegister mask, Register length, Register index,\n+                         Register temp, int shift = Address::times_1, int offset = 0);\n+\n+  void copy32_avx(Register dst, Register src, Register index, XMMRegister xmm,\n+                  int shift = Address::times_1, int offset = 0);\n+\n+  void copy64_avx(Register dst, Register src, Register index, XMMRegister xmm,\n+                  bool conjoint, int shift = Address::times_1, int offset = 0,\n+                  bool use64byteVector = false);\n+#endif \/\/ COMPILER2_OR_JVMCI\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":30,"deletions":3,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -1889,1 +1890,1 @@\n-    __ bang_stack_with_offset((int)JavaThread::stack_shadow_zone_size());\n+    __ bang_stack_with_offset((int)StackOverflow::stack_shadow_zone_size());\n@@ -2260,1 +2261,1 @@\n-    __ safepoint_poll(slow_path, thread, noreg);\n+    __ safepoint_poll(slow_path, thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -2302,1 +2303,1 @@\n-  __ cmpl(Address(thread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpl(Address(thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -2433,1 +2434,1 @@\n-    __ bang_stack_with_offset((int)JavaThread::stack_shadow_zone_size());\n+    __ bang_stack_with_offset((int)StackOverflow::stack_shadow_zone_size());\n@@ -2860,1 +2861,1 @@\n-    __ safepoint_poll(slow_path, r15_thread, rscratch1);\n+    __ safepoint_poll(slow_path, r15_thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -2903,1 +2904,1 @@\n-  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1142,18 +1142,2 @@\n-      \/\/ Copy 64-bytes per iteration\n-      if (UseAVX > 2) {\n-        Label L_loop_avx512, L_loop_avx2, L_32_byte_head, L_above_threshold, L_below_threshold;\n-\n-        __ BIND(L_copy_bytes);\n-        __ cmpptr(qword_count, (-1 * AVX3Threshold \/ 8));\n-        __ jccb(Assembler::less, L_above_threshold);\n-        __ jmpb(L_below_threshold);\n-\n-        __ bind(L_loop_avx512);\n-        __ evmovdqul(xmm0, Address(end_from, qword_count, Address::times_8, -56), Assembler::AVX_512bit);\n-        __ evmovdqul(Address(end_to, qword_count, Address::times_8, -56), xmm0, Assembler::AVX_512bit);\n-        __ bind(L_above_threshold);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop_avx512);\n-        __ jmpb(L_32_byte_head);\n-\n-        __ bind(L_loop_avx2);\n+      __ BIND(L_loop);\n+      if (UseAVX >= 2) {\n@@ -1164,29 +1148,8 @@\n-        __ bind(L_below_threshold);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop_avx2);\n-\n-        __ bind(L_32_byte_head);\n-        __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n-        __ jccb(Assembler::greater, L_end);\n-        __ BIND(L_loop);\n-        if (UseAVX == 2) {\n-          __ vmovdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n-          __ vmovdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n-          __ vmovdqu(xmm1, Address(end_from, qword_count, Address::times_8, -24));\n-          __ vmovdqu(Address(end_to, qword_count, Address::times_8, -24), xmm1);\n-        } else {\n-          __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n-          __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, -40));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -40), xmm1);\n-          __ movdqu(xmm2, Address(end_from, qword_count, Address::times_8, -24));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm2);\n-          __ movdqu(xmm3, Address(end_from, qword_count, Address::times_8, - 8));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm3);\n-        }\n-\n-        __ BIND(L_copy_bytes);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop);\n-        __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n-        __ jccb(Assembler::greater, L_end);\n+        __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n+        __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, -40));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -40), xmm1);\n+        __ movdqu(xmm2, Address(end_from, qword_count, Address::times_8, -24));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm2);\n+        __ movdqu(xmm3, Address(end_from, qword_count, Address::times_8, - 8));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm3);\n@@ -1195,0 +1158,6 @@\n+\n+      __ BIND(L_copy_bytes);\n+      __ addptr(qword_count, 8);\n+      __ jcc(Assembler::lessEqual, L_loop);\n+      __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n+      __ jccb(Assembler::greater, L_end);\n@@ -1250,18 +1219,2 @@\n-      \/\/ Copy 64-bytes per iteration\n-      if (UseAVX > 2) {\n-        Label L_loop_avx512, L_loop_avx2, L_32_byte_head, L_above_threshold, L_below_threshold;\n-\n-        __ BIND(L_copy_bytes);\n-        __ cmpptr(qword_count, (AVX3Threshold \/ 8));\n-        __ jccb(Assembler::greater, L_above_threshold);\n-        __ jmpb(L_below_threshold);\n-\n-        __ BIND(L_loop_avx512);\n-        __ evmovdqul(xmm0, Address(from, qword_count, Address::times_8, 0), Assembler::AVX_512bit);\n-        __ evmovdqul(Address(dest, qword_count, Address::times_8, 0), xmm0, Assembler::AVX_512bit);\n-        __ bind(L_above_threshold);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop_avx512);\n-        __ jmpb(L_32_byte_head);\n-\n-        __ bind(L_loop_avx2);\n+      __ BIND(L_loop);\n+      if (UseAVX >= 2) {\n@@ -1270,9 +1223,2 @@\n-        __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8, 0));\n-        __ vmovdqu(Address(dest, qword_count, Address::times_8, 0), xmm1);\n-        __ bind(L_below_threshold);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop_avx2);\n-\n-        __ bind(L_32_byte_head);\n-        __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n-        __ jccb(Assembler::less, L_end);\n+        __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8,  0));\n+        __ vmovdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);\n@@ -1280,16 +1226,9 @@\n-        __ BIND(L_loop);\n-        if (UseAVX == 2) {\n-          __ vmovdqu(xmm0, Address(from, qword_count, Address::times_8, 32));\n-          __ vmovdqu(Address(dest, qword_count, Address::times_8, 32), xmm0);\n-          __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8,  0));\n-          __ vmovdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);\n-        } else {\n-          __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 48));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 48), xmm0);\n-          __ movdqu(xmm1, Address(from, qword_count, Address::times_8, 32));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 32), xmm1);\n-          __ movdqu(xmm2, Address(from, qword_count, Address::times_8, 16));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm2);\n-          __ movdqu(xmm3, Address(from, qword_count, Address::times_8,  0));\n-          __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm3);\n-        }\n+        __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 48));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 48), xmm0);\n+        __ movdqu(xmm1, Address(from, qword_count, Address::times_8, 32));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 32), xmm1);\n+        __ movdqu(xmm2, Address(from, qword_count, Address::times_8, 16));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm2);\n+        __ movdqu(xmm3, Address(from, qword_count, Address::times_8,  0));\n+        __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm3);\n+      }\n@@ -1297,3 +1236,3 @@\n-        __ BIND(L_copy_bytes);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop);\n+      __ BIND(L_copy_bytes);\n+      __ subptr(qword_count, 8);\n+      __ jcc(Assembler::greaterEqual, L_loop);\n@@ -1301,3 +1240,2 @@\n-        __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n-        __ jccb(Assembler::less, L_end);\n-      }\n+      __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n+      __ jccb(Assembler::less, L_end);\n@@ -1341,0 +1279,438 @@\n+#ifndef PRODUCT\n+    int& get_profile_ctr(int shift) {\n+      if ( 0 == shift)\n+        return SharedRuntime::_jbyte_array_copy_ctr;\n+      else if(1 == shift)\n+        return SharedRuntime::_jshort_array_copy_ctr;\n+      else if(2 == shift)\n+        return SharedRuntime::_jint_array_copy_ctr;\n+      else\n+        return SharedRuntime::_jlong_array_copy_ctr;\n+    }\n+#endif\n+\n+  void setup_argument_regs(BasicType type) {\n+    if (type == T_BYTE || type == T_SHORT) {\n+      setup_arg_regs(); \/\/ from => rdi, to => rsi, count => rdx\n+                        \/\/ r9 and r10 may be used to save non-volatile registers\n+    } else {\n+      setup_arg_regs_using_thread(); \/\/ from => rdi, to => rsi, count => rdx\n+                                     \/\/ r9 is used to save r15_thread\n+    }\n+  }\n+\n+  void restore_argument_regs(BasicType type) {\n+    if (type == T_BYTE || type == T_SHORT) {\n+      restore_arg_regs();\n+    } else {\n+      restore_arg_regs_using_thread();\n+    }\n+  }\n+\n+#if COMPILER2_OR_JVMCI\n+  \/\/ Note: Following rules apply to AVX3 optimized arraycopy stubs:-\n+  \/\/ - If target supports AVX3 features (BW+VL+F) then implementation uses 32 byte vectors (YMMs)\n+  \/\/   for both special cases (various small block sizes) and aligned copy loop. This is the\n+  \/\/   default configuration.\n+  \/\/ - If copy length is above AVX3Threshold, then implementation use 64 byte vectors (ZMMs)\n+  \/\/   for main copy loop (and subsequent tail) since bulk of the cycles will be consumed in it.\n+  \/\/ - If user forces MaxVectorSize=32 then above 4096 bytes its seen that REP MOVs shows a\n+  \/\/   better performance for disjoint copies. For conjoint\/backward copy vector based\n+  \/\/   copy performs better.\n+  \/\/ - If user sets AVX3Threshold=0, then special cases for small blocks sizes operate over\n+  \/\/   64 byte vector registers (ZMMs).\n+\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - source array address\n+  \/\/   c_rarg1   - destination array address\n+  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n+  \/\/\n+  \/\/\n+  \/\/ Side Effects:\n+  \/\/   disjoint_copy_avx3_masked is set to the no-overlap entry point\n+  \/\/   used by generate_conjoint_[byte\/int\/short\/long]_copy().\n+  \/\/\n+\n+  address generate_disjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n+                                             bool aligned, bool is_oop, bool dest_uninitialized) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", name);\n+    address start = __ pc();\n+\n+    bool use64byteVector = MaxVectorSize > 32 && AVX3Threshold == 0;\n+    Label L_main_loop, L_main_loop_64bytes, L_tail, L_tail64, L_exit, L_entry;\n+    Label L_repmovs, L_main_pre_loop, L_main_pre_loop_64bytes, L_pre_main_post_64;\n+    const Register from        = rdi;  \/\/ source array address\n+    const Register to          = rsi;  \/\/ destination array address\n+    const Register count       = rdx;  \/\/ elements count\n+    const Register temp1       = r8;\n+    const Register temp2       = r11;\n+    const Register temp3       = rax;\n+    const Register temp4       = rcx;\n+    \/\/ End pointers are inclusive, and if count is not zero they point\n+    \/\/ to the last unit copied:  end_to[0] := end_from[0]\n+\n+    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    assert_clean_int(c_rarg2, rax);    \/\/ Make sure 'count' is clean int.\n+\n+    if (entry != NULL) {\n+      *entry = __ pc();\n+       \/\/ caller can pass a 64-bit byte count here (from Unsafe.copyMemory)\n+      BLOCK_COMMENT(\"Entry:\");\n+    }\n+\n+    BasicType type_vec[] = { T_BYTE,  T_SHORT,  T_INT,   T_LONG};\n+    BasicType type = is_oop ? T_OBJECT : type_vec[shift];\n+\n+    setup_argument_regs(type);\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;\n+    if (dest_uninitialized) {\n+      decorators |= IS_DEST_UNINITIALIZED;\n+    }\n+    if (aligned) {\n+      decorators |= ARRAYCOPY_ALIGNED;\n+    }\n+    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+    bs->arraycopy_prologue(_masm, decorators, type, from, to, count);\n+\n+    {\n+      \/\/ Type(shift)           byte(0), short(1), int(2),   long(3)\n+      int loop_size[]        = { 192,     96,       48,      24};\n+      int threshold[]        = { 4096,    2048,     1024,    512};\n+\n+      \/\/ UnsafeCopyMemory page error: continue after ucm\n+      UnsafeCopyMemoryMark ucmm(this, !is_oop && !aligned, true);\n+      \/\/ 'from', 'to' and 'count' are now valid\n+\n+      \/\/ temp1 holds remaining count and temp4 holds running count used to compute\n+      \/\/ next address offset for start of to\/from addresses (temp4 * scale).\n+      __ mov64(temp4, 0);\n+      __ movq(temp1, count);\n+\n+      \/\/ Zero length check.\n+      __ BIND(L_tail);\n+      __ cmpq(temp1, 0);\n+      __ jcc(Assembler::lessEqual, L_exit);\n+\n+      \/\/ Special cases using 32 byte [masked] vector copy operations.\n+      __ arraycopy_avx3_special_cases(xmm1, k2, from, to, temp1, shift,\n+                                      temp4, temp3, use64byteVector, L_entry, L_exit);\n+\n+      \/\/ PRE-MAIN-POST loop for aligned copy.\n+      __ BIND(L_entry);\n+\n+      if (AVX3Threshold != 0) {\n+        __ cmpq(count, threshold[shift]);\n+        if (MaxVectorSize == 64) {\n+          \/\/ Copy using 64 byte vectors.\n+          __ jcc(Assembler::greaterEqual, L_pre_main_post_64);\n+        } else {\n+          assert(MaxVectorSize < 64, \"vector size should be < 64 bytes\");\n+          \/\/ REP MOVS offer a faster copy path.\n+          __ jcc(Assembler::greaterEqual, L_repmovs);\n+        }\n+      }\n+\n+      if (MaxVectorSize < 64  || AVX3Threshold != 0) {\n+        \/\/ Partial copy to make dst address 32 byte aligned.\n+        __ movq(temp2, to);\n+        __ andq(temp2, 31);\n+        __ jcc(Assembler::equal, L_main_pre_loop);\n+\n+        __ negptr(temp2);\n+        __ addq(temp2, 32);\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ movq(temp3, temp2);\n+        __ copy32_masked_avx(to, from, xmm1, k2, temp3, temp4, temp1, shift);\n+        __ movq(temp4, temp2);\n+        __ movq(temp1, count);\n+        __ subq(temp1, temp2);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail);\n+\n+        __ BIND(L_main_pre_loop);\n+        __ subq(temp1, loop_size[shift]);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at 32 byte granularity.\n+        __ BIND(L_main_loop);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 0);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 64);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 128);\n+           __ addptr(temp4, loop_size[shift]);\n+           __ subq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop);\n+\n+        __ addq(temp1, loop_size[shift]);\n+\n+        \/\/ Tail loop.\n+        __ jmp(L_tail);\n+\n+        __ BIND(L_repmovs);\n+          __ movq(temp2, temp1);\n+          \/\/ Swap to(RSI) and from(RDI) addresses to comply with REP MOVs semantics.\n+          __ movq(temp3, to);\n+          __ movq(to,  from);\n+          __ movq(from, temp3);\n+          \/\/ Save to\/from for restoration post rep_mov.\n+          __ movq(temp1, to);\n+          __ movq(temp3, from);\n+          if(shift < 3) {\n+            __ shrq(temp2, 3-shift);     \/\/ quad word count\n+          }\n+          __ movq(temp4 , temp2);        \/\/ move quad ward count into temp4(RCX).\n+          __ rep_mov();\n+          __ shlq(temp2, 3);             \/\/ convert quad words into byte count.\n+          if(shift) {\n+            __ shrq(temp2, shift);       \/\/ type specific count.\n+          }\n+          \/\/ Restore original addresses in to\/from.\n+          __ movq(to, temp3);\n+          __ movq(from, temp1);\n+          __ movq(temp4, temp2);\n+          __ movq(temp1, count);\n+          __ subq(temp1, temp2);         \/\/ tailing part (less than a quad ward size).\n+          __ jmp(L_tail);\n+      }\n+\n+      if (MaxVectorSize > 32) {\n+        __ BIND(L_pre_main_post_64);\n+        \/\/ Partial copy to make dst address 64 byte aligned.\n+        __ movq(temp2, to);\n+        __ andq(temp2, 63);\n+        __ jcc(Assembler::equal, L_main_pre_loop_64bytes);\n+\n+        __ negptr(temp2);\n+        __ addq(temp2, 64);\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ movq(temp3, temp2);\n+        __ copy64_masked_avx(to, from, xmm1, k2, temp3, temp4, temp1, shift, 0 , true);\n+        __ movq(temp4, temp2);\n+        __ movq(temp1, count);\n+        __ subq(temp1, temp2);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail64);\n+\n+        __ BIND(L_main_pre_loop_64bytes);\n+        __ subq(temp1, loop_size[shift]);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at\n+        \/\/ 64 byte copy granularity.\n+        __ BIND(L_main_loop_64bytes);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 0 , true);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 64, true);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 128, true);\n+           __ addptr(temp4, loop_size[shift]);\n+           __ subq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop_64bytes);\n+\n+        __ addq(temp1, loop_size[shift]);\n+        \/\/ Zero length check.\n+        __ jcc(Assembler::lessEqual, L_exit);\n+\n+        __ BIND(L_tail64);\n+\n+        \/\/ Tail handling using 64 byte [masked] vector copy operations.\n+        use64byteVector = true;\n+        __ arraycopy_avx3_special_cases(xmm1, k2, from, to, temp1, shift,\n+                                        temp4, temp3, use64byteVector, L_entry, L_exit);\n+      }\n+      __ BIND(L_exit);\n+    }\n+\n+    address ucme_exit_pc = __ pc();\n+    \/\/ When called from generic_arraycopy r11 contains specific values\n+    \/\/ used during arraycopy epilogue, re-initializing r11.\n+    if (is_oop) {\n+      __ movq(r11, shift == 3 ? count : to);\n+    }\n+    bs->arraycopy_epilogue(_masm, decorators, type, from, to, count);\n+    restore_argument_regs(type);\n+    inc_counter_np(get_profile_ctr(shift)); \/\/ Update counter after rscratch1 is free\n+    __ xorptr(rax, rax); \/\/ return 0\n+    __ vzeroupper();\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(0);\n+    return start;\n+  }\n+\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - source array address\n+  \/\/   c_rarg1   - destination array address\n+  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n+  \/\/\n+  \/\/\n+  address generate_conjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n+                                             address nooverlap_target, bool aligned, bool is_oop,\n+                                             bool dest_uninitialized) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", name);\n+    address start = __ pc();\n+\n+    bool use64byteVector = MaxVectorSize > 32 && AVX3Threshold == 0;\n+\n+    Label L_main_pre_loop, L_main_pre_loop_64bytes, L_pre_main_post_64;\n+    Label L_main_loop, L_main_loop_64bytes, L_tail, L_tail64, L_exit, L_entry;\n+    const Register from        = rdi;  \/\/ source array address\n+    const Register to          = rsi;  \/\/ destination array address\n+    const Register count       = rdx;  \/\/ elements count\n+    const Register temp1       = r8;\n+    const Register temp2       = rcx;\n+    const Register temp3       = r11;\n+    const Register temp4       = rax;\n+    \/\/ End pointers are inclusive, and if count is not zero they point\n+    \/\/ to the last unit copied:  end_to[0] := end_from[0]\n+\n+    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    assert_clean_int(c_rarg2, rax);    \/\/ Make sure 'count' is clean int.\n+\n+    if (entry != NULL) {\n+      *entry = __ pc();\n+       \/\/ caller can pass a 64-bit byte count here (from Unsafe.copyMemory)\n+      BLOCK_COMMENT(\"Entry:\");\n+    }\n+\n+    array_overlap_test(nooverlap_target, (Address::ScaleFactor)(shift));\n+\n+    BasicType type_vec[] = { T_BYTE,  T_SHORT,  T_INT,   T_LONG};\n+    BasicType type = is_oop ? T_OBJECT : type_vec[shift];\n+\n+    setup_argument_regs(type);\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    if (dest_uninitialized) {\n+      decorators |= IS_DEST_UNINITIALIZED;\n+    }\n+    if (aligned) {\n+      decorators |= ARRAYCOPY_ALIGNED;\n+    }\n+    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+    bs->arraycopy_prologue(_masm, decorators, type, from, to, count);\n+    {\n+      \/\/ Type(shift)       byte(0), short(1), int(2),   long(3)\n+      int loop_size[]   = { 192,     96,       48,      24};\n+      int threshold[]   = { 4096,    2048,     1024,    512};\n+\n+      \/\/ UnsafeCopyMemory page error: continue after ucm\n+      UnsafeCopyMemoryMark ucmm(this, !is_oop && !aligned, true);\n+      \/\/ 'from', 'to' and 'count' are now valid\n+\n+      \/\/ temp1 holds remaining count.\n+      __ movq(temp1, count);\n+\n+      \/\/ Zero length check.\n+      __ BIND(L_tail);\n+      __ cmpq(temp1, 0);\n+      __ jcc(Assembler::lessEqual, L_exit);\n+\n+      __ mov64(temp2, 0);\n+      __ movq(temp3, temp1);\n+      \/\/ Special cases using 32 byte [masked] vector copy operations.\n+      __ arraycopy_avx3_special_cases_conjoint(xmm1, k2, from, to, temp2, temp3, temp1, shift,\n+                                               temp4, use64byteVector, L_entry, L_exit);\n+\n+      \/\/ PRE-MAIN-POST loop for aligned copy.\n+      __ BIND(L_entry);\n+\n+      if (MaxVectorSize > 32 && AVX3Threshold != 0) {\n+        __ cmpq(temp1, threshold[shift]);\n+        __ jcc(Assembler::greaterEqual, L_pre_main_post_64);\n+      }\n+\n+      if (MaxVectorSize < 64  || AVX3Threshold != 0) {\n+        \/\/ Partial copy to make dst address 32 byte aligned.\n+        __ leaq(temp2, Address(to, temp1, (Address::ScaleFactor)(shift), 0));\n+        __ andq(temp2, 31);\n+        __ jcc(Assembler::equal, L_main_pre_loop);\n+\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ subq(temp1, temp2);\n+        __ copy32_masked_avx(to, from, xmm1, k2, temp2, temp1, temp3, shift);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail);\n+\n+        __ BIND(L_main_pre_loop);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at 32 byte granularity.\n+        __ BIND(L_main_loop);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -64);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -128);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -192);\n+           __ subptr(temp1, loop_size[shift]);\n+           __ cmpq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop);\n+\n+        \/\/ Tail loop.\n+        __ jmp(L_tail);\n+      }\n+\n+      if (MaxVectorSize > 32) {\n+        __ BIND(L_pre_main_post_64);\n+        \/\/ Partial copy to make dst address 64 byte aligned.\n+        __ leaq(temp2, Address(to, temp1, (Address::ScaleFactor)(shift), 0));\n+        __ andq(temp2, 63);\n+        __ jcc(Assembler::equal, L_main_pre_loop_64bytes);\n+\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ subq(temp1, temp2);\n+        __ copy64_masked_avx(to, from, xmm1, k2, temp2, temp1, temp3, shift, 0 , true);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail64);\n+\n+        __ BIND(L_main_pre_loop_64bytes);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at\n+        \/\/ 64 byte copy granularity.\n+        __ BIND(L_main_loop_64bytes);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -64 , true);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -128, true);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -192, true);\n+           __ subq(temp1, loop_size[shift]);\n+           __ cmpq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop_64bytes);\n+\n+        \/\/ Zero length check.\n+        __ cmpq(temp1, 0);\n+        __ jcc(Assembler::lessEqual, L_exit);\n+\n+        __ BIND(L_tail64);\n+\n+        \/\/ Tail handling using 64 byte [masked] vector copy operations.\n+        use64byteVector = true;\n+        __ mov64(temp2, 0);\n+        __ movq(temp3, temp1);\n+        __ arraycopy_avx3_special_cases_conjoint(xmm1, k2, from, to, temp2, temp3, temp1, shift,\n+                                                 temp4, use64byteVector, L_entry, L_exit);\n+      }\n+      __ BIND(L_exit);\n+    }\n+    address ucme_exit_pc = __ pc();\n+    \/\/ When called from generic_arraycopy r11 contains specific values\n+    \/\/ used during arraycopy epilogue, re-initializing r11.\n+    if(is_oop) {\n+      __ movq(r11, count);\n+    }\n+    bs->arraycopy_epilogue(_masm, decorators, type, from, to, count);\n+    restore_argument_regs(type);\n+    inc_counter_np(get_profile_ctr(shift)); \/\/ Update counter after rscratch1 is free\n+    __ xorptr(rax, rax); \/\/ return 0\n+    __ vzeroupper();\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(0);\n+    return start;\n+  }\n+#endif \/\/ COMPILER2_OR_JVMCI\n+\n+\n@@ -1361,0 +1737,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jbyte_disjoint_arraycopy_avx3\", 0,\n+                                                 aligned, false, false);\n+    }\n+#endif\n@@ -1471,0 +1853,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jbyte_conjoint_arraycopy_avx3\", 0,\n+                                                 nooverlap_target, aligned, false, false);\n+    }\n+#endif\n@@ -1576,0 +1964,7 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jshort_disjoint_arraycopy_avx3\", 1,\n+                                                 aligned, false, false);\n+    }\n+#endif\n+\n@@ -1700,0 +2095,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jshort_conjoint_arraycopy_avx3\", 1,\n+                                                 nooverlap_target, aligned, false, false);\n+    }\n+#endif\n@@ -1798,0 +2199,7 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jint_disjoint_arraycopy_avx3\", 2,\n+                                                 aligned, is_oop, dest_uninitialized);\n+    }\n+#endif\n+\n@@ -1902,0 +2310,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jint_conjoint_arraycopy_avx3\", 2,\n+                                                 nooverlap_target, aligned, is_oop, dest_uninitialized);\n+    }\n+#endif\n@@ -2009,0 +2423,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jlong_disjoint_arraycopy_avx3\", 3,\n+                                                 aligned, is_oop, dest_uninitialized);\n+    }\n+#endif\n@@ -2113,0 +2533,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jlong_conjoint_arraycopy_avx3\", 3,\n+                                                 nooverlap_target, aligned, is_oop, dest_uninitialized);\n+    }\n+#endif\n@@ -2531,1 +2957,1 @@\n-    Label L_copy_bytes, L_copy_shorts, L_copy_ints, L_copy_longs;\n+    Label L_copy_shorts, L_copy_ints, L_copy_longs;\n@@ -2542,1 +2968,1 @@\n-    const Address  length(rsp, 6 * wordSize);  \/\/ elements count is on stack on Win64\n+    const Address  length(rsp, 7 * wordSize);  \/\/ elements count is on stack on Win64\n@@ -2564,0 +2990,4 @@\n+#ifdef _WIN64\n+    __ push(rklass_tmp); \/\/ rdi is callee-save on Windows\n+#endif\n+\n@@ -2704,0 +3134,4 @@\n+#ifdef _WIN64\n+    __ pop(rklass_tmp); \/\/ Restore callee-save rdi\n+#endif\n+\n@@ -2712,1 +3146,0 @@\n-  __ BIND(L_copy_bytes);\n@@ -2773,0 +3206,3 @@\n+#ifdef _WIN64\n+    __ pop(rklass_tmp); \/\/ Restore callee-save rdi\n+#endif\n@@ -2826,0 +3262,4 @@\n+#ifdef _WIN64\n+      __ pop(rklass_tmp); \/\/ Restore callee-save rdi\n+#endif\n+\n@@ -2835,0 +3275,3 @@\n+#ifdef _WIN64\n+    __ pop(rklass_tmp); \/\/ Restore callee-save rdi\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":542,"deletions":99,"binary":false,"changes":641,"status":"modified"},{"patch":"@@ -780,1 +780,1 @@\n-    const int n_shadow_pages = ((int)JavaThread::stack_shadow_zone_size()) \/ page_size;\n+    const int n_shadow_pages = ((int)StackOverflow::stack_shadow_zone_size()) \/ page_size;\n@@ -1115,5 +1115,1 @@\n-#ifndef _LP64\n-    __ safepoint_poll(slow_path, thread, noreg);\n-#else\n-    __ safepoint_poll(slow_path, r15_thread, rscratch1);\n-#endif\n+    __ safepoint_poll(slow_path, thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -1189,1 +1185,1 @@\n-            JavaThread::stack_guard_yellow_reserved_disabled);\n+            StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":3,"deletions":7,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2375,1 +2375,1 @@\n-    if (ProfileInterpreter) {\n+    if (ProfileInterpreter && !TieredCompilation) {\n@@ -2781,1 +2781,1 @@\n-    __ testb(Address(r15_thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+    __ testb(Address(r15_thread, Thread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -2785,1 +2785,1 @@\n-    __ testb(Address(thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());\n+    __ testb(Address(thread, Thread::polling_word_offset()), SafepointMechanism::poll_bit());\n@@ -2790,1 +2790,1 @@\n-                                    InterpreterRuntime::at_safepoint));\n+                                       InterpreterRuntime::at_safepoint));\n@@ -3957,5 +3957,0 @@\n-void TemplateTable::count_calls(Register method, Register temp) {\n-  \/\/ implemented elsewhere\n-  ShouldNotReachHere();\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":4,"deletions":9,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -766,0 +766,2 @@\n+      _features &= ~CPU_AVX512BW;\n+      _features &= ~CPU_AVX512VL;\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -11824,1 +11824,1 @@\n-instruct string_indexofU_char(eDIRegP str1, eDXRegI cnt1, eAXRegI ch,\n+instruct string_indexof_char(eDIRegP str1, eDXRegI cnt1, eAXRegI ch,\n@@ -11826,1 +11826,1 @@\n-  predicate(UseSSE42Intrinsics);\n+  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::U));\n@@ -11829,1 +11829,1 @@\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n+  format %{ \"StringUTF16 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n@@ -11837,0 +11837,14 @@\n+instruct stringL_indexof_char(eDIRegP str1, eDXRegI cnt1, eAXRegI ch,\n+                              eBXRegI result, regD vec1, regD vec2, regD vec3, eCXRegI tmp, eFlagsReg cr) %{\n+  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::L));\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  effect(TEMP vec1, TEMP vec2, TEMP vec3, USE_KILL str1, USE_KILL cnt1, USE_KILL ch, TEMP tmp, KILL cr);\n+  format %{ \"StringLatin1 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n+  ins_encode %{\n+    __ stringL_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register, $result$$Register,\n+                           $vec1$$XMMRegister, $vec2$$XMMRegister, $vec3$$XMMRegister, $tmp$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":17,"deletions":3,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -932,2 +932,2 @@\n-    st->print_cr(\"movq    rscratch1, poll_offset[r15_thread] #polling_page_address\\n\\t\"\n-                 \"testl   rax, [rscratch1]\\t\"\n+    st->print_cr(\"cmpq    poll_offset[r15_thread], rsp\\n\\t\"\n+                 \"ja      #safepoint_stub\\t\"\n@@ -960,1 +960,5 @@\n-    __ movq(rscratch1, Address(r15_thread, Thread::polling_page_offset()));\n+    Label dummy_label;\n+    Label* code_stub = &dummy_label;\n+    if (!C->output()->in_scratch_emit_size()) {\n+      code_stub = &C->output()->safepoint_poll_table()->add_safepoint(__ offset());\n+    }\n@@ -962,1 +966,1 @@\n-    __ testl(rax, Address(rscratch1, 0));\n+    __ safepoint_poll(*code_stub, r15_thread, true \/* at_return *\/, true \/* in_nmethod *\/);\n@@ -2906,0 +2910,10 @@\n+operand immU7()\n+%{\n+  predicate((0 <= n->get_int()) && (n->get_int() <= 0x7F));\n+  match(ConI);\n+\n+  op_cost(5);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -11157,1 +11171,1 @@\n-instruct string_indexofU_char(rdi_RegP str1, rdx_RegI cnt1, rax_RegI ch,\n+instruct string_indexof_char(rdi_RegP str1, rdx_RegI cnt1, rax_RegI ch,\n@@ -11160,1 +11174,1 @@\n-  predicate(UseSSE42Intrinsics);\n+  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::U));\n@@ -11163,1 +11177,1 @@\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n+  format %{ \"StringUTF16 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n@@ -11171,0 +11185,14 @@\n+instruct stringL_indexof_char(rdi_RegP str1, rdx_RegI cnt1, rax_RegI ch,\n+                              rbx_RegI result, legRegD tmp_vec1, legRegD tmp_vec2, legRegD tmp_vec3, rcx_RegI tmp, rFlagsReg cr)\n+%{\n+  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::L));\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  effect(TEMP tmp_vec1, TEMP tmp_vec2, TEMP tmp_vec3, USE_KILL str1, USE_KILL cnt1, USE_KILL ch, TEMP tmp, KILL cr);\n+  format %{ \"StringLatin1 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n+  ins_encode %{\n+    __ stringL_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register, $result$$Register,\n+                           $tmp_vec1$$XMMRegister, $tmp_vec2$$XMMRegister, $tmp_vec3$$XMMRegister, $tmp$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -11919,1 +11947,1 @@\n-instruct testUB_mem_imm(rFlagsReg cr, memory mem, immU8 imm, immI0 zero)\n+instruct testUB_mem_imm(rFlagsReg cr, memory mem, immU7 imm, immI0 zero)\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":36,"deletions":8,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -92,0 +92,22 @@\n+class C1SafepointPollStub: public CodeStub {\n+ private:\n+  uintptr_t _safepoint_offset;\n+\n+ public:\n+  C1SafepointPollStub() :\n+      _safepoint_offset(0) {\n+  }\n+\n+  uintptr_t safepoint_offset() { return _safepoint_offset; }\n+  void set_safepoint_offset(uintptr_t safepoint_offset) { _safepoint_offset = safepoint_offset; }\n+\n+  virtual void emit_code(LIR_Assembler* e);\n+  virtual void visit(LIR_OpVisitState* visitor) {\n+    \/\/ don't pass in the code emit info since it's processed in the fast path\n+    visitor->do_slow_case();\n+  }\n+#ifndef PRODUCT\n+  virtual void print_name(outputStream* out) const { out->print(\"C1SafepointPollStub\"); }\n+#endif \/\/ PRODUCT\n+};\n+\n","filename":"src\/hotspot\/share\/c1\/c1_CodeStubs.hpp","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"c1\/c1_CodeStubs.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"runtime\/safepointMechanism.inline.hpp\"\n@@ -487,1 +489,0 @@\n-    case lir_return:         \/\/ input always valid, result and info always invalid\n@@ -503,0 +504,13 @@\n+    case lir_return:\n+    {\n+      assert(op->as_OpReturn() != NULL, \"must be\");\n+      LIR_OpReturn* op_ret = (LIR_OpReturn*)op;\n+\n+      if (op_ret->_info)               do_info(op_ret->_info);\n+      if (op_ret->_opr->is_valid())    do_input(op_ret->_opr);\n+      if (op_ret->_result->is_valid()) do_output(op_ret->_result);\n+      if (op_ret->stub() != NULL)      do_stub(op_ret->stub());\n+\n+      break;\n+    }\n+\n@@ -1045,0 +1059,9 @@\n+\/\/ LIR_OpReturn\n+LIR_OpReturn::LIR_OpReturn(LIR_Opr opr) :\n+    LIR_Op1(lir_return, opr, (CodeEmitInfo*)NULL \/* info *\/),\n+    _stub(NULL) {\n+  if (VM_Version::supports_stack_watermark_barrier()) {\n+    _stub = new C1SafepointPollStub();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":24,"deletions":1,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+class C1SafepointPollStub;\n@@ -863,0 +864,1 @@\n+class      LIR_OpReturn;\n@@ -1138,0 +1140,1 @@\n+  virtual LIR_OpReturn* as_OpReturn() { return NULL; }\n@@ -1470,0 +1473,12 @@\n+class LIR_OpReturn: public LIR_Op1 {\n+ friend class LIR_OpVisitState;\n+\n+ private:\n+  C1SafepointPollStub* _stub;\n+\n+ public:\n+  LIR_OpReturn(LIR_Opr opr);\n+\n+  C1SafepointPollStub* stub() const { return _stub; }\n+  virtual LIR_OpReturn* as_OpReturn() { return this; }\n+};\n@@ -2237,2 +2252,1 @@\n-  void return_op(LIR_Opr result)                 { append(new LIR_Op1(lir_return, result)); }\n-\n+  void return_op(LIR_Opr result)                   { append(new LIR_OpReturn(result)); }\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":16,"deletions":2,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -534,2 +534,7 @@\n-    case lir_return:\n-      return_op(op->in_opr());\n+    case lir_return: {\n+      assert(op->as_OpReturn() != NULL, \"sanity\");\n+      LIR_OpReturn *ret_op = (LIR_OpReturn*)op;\n+      return_op(ret_op->in_opr(), ret_op->stub());\n+      if (ret_op->stub() != NULL) {\n+        append_code_stub(ret_op->stub());\n+      }\n@@ -537,0 +542,1 @@\n+    }\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -166,1 +166,1 @@\n-  void return_op(LIR_Opr result);\n+  void return_op(LIR_Opr result, C1SafepointPollStub* code_stub);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5439,1 +5439,1 @@\n-    if (allocator()->is_precolored_cpu_interval(register_hint)) {\n+    if (_num_phys_regs == 2 && allocator()->is_precolored_cpu_interval(register_hint)) {\n@@ -6413,1 +6413,1 @@\n-            pred_instructions->at_put(pred_instructions->length() - 1, new LIR_Op1(lir_return, return_opr));\n+            pred_instructions->at_put(pred_instructions->length() - 1, new LIR_OpReturn(return_opr));\n","filename":"src\/hotspot\/share\/c1\/c1_LinearScan.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -68,0 +68,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -627,0 +628,11 @@\n+\n+  \/\/ This function is called when we are about to throw an exception. Therefore,\n+  \/\/ we have to poll the stack watermark barrier to make sure that not yet safe\n+  \/\/ stack frames are made safe before returning into them.\n+  if (thread->last_frame().cb() == Runtime1::blob_for(Runtime1::handle_exception_from_callee_id)) {\n+    \/\/ The Runtime1::handle_exception_from_callee_id handler is invoked after the\n+    \/\/ frame has been unwound. It instead builds its own stub frame, to call the\n+    \/\/ runtime. But the throwing frame has already been unwound here.\n+    StackWatermarkSet::after_unwind(thread);\n+  }\n+\n@@ -649,2 +661,1 @@\n-  bool guard_pages_enabled = thread->stack_guards_enabled();\n-  if (!guard_pages_enabled) guard_pages_enabled = thread->reguard_stack();\n+  bool guard_pages_enabled = thread->stack_overflow_state()->reguard_stack_if_needed();\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -1001,0 +1002,12 @@\n+    methodHandle method(THREAD, target->get_Method());\n+\n+    \/\/ We require method counters to store some method state (max compilation levels) required by the compilation policy.\n+    if (method->get_method_counters(THREAD) == NULL) {\n+      record_failure(\"can't create method counters\");\n+      \/\/ All buffers in the CodeBuffer are allocated in the CodeCache.\n+      \/\/ If the code buffer is created on each compile attempt\n+      \/\/ as in C2, then it must be freed.\n+      code_buffer->free_blob();\n+      return;\n+    }\n+\n@@ -1040,3 +1053,0 @@\n-\n-    methodHandle method(THREAD, target->get_Method());\n-\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"prims\/methodHandles.hpp\"\n","filename":"src\/hotspot\/share\/ci\/ciMethod.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#include \"prims\/methodHandles.hpp\"\n+#include \"runtime\/handles.hpp\"\n","filename":"src\/hotspot\/share\/ci\/ciMethod.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"prims\/methodHandles.hpp\"\n","filename":"src\/hotspot\/share\/ci\/ciSymbol.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -220,1 +220,2 @@\n-            tag, CHECK);\n+            tag, THREAD);\n+          return;\n@@ -242,1 +243,2 @@\n-              tag, CHECK);\n+              tag, THREAD);\n+          return;\n@@ -257,1 +259,2 @@\n-              tag, CHECK);\n+              tag, THREAD);\n+          return;\n@@ -376,2 +379,2 @@\n-                              CHECK);\n-        break;\n+                              THREAD);\n+        return;\n@@ -577,1 +580,2 @@\n-              index, CHECK);\n+              index, THREAD);\n+            return;\n@@ -755,1 +759,2 @@\n-              name_ref_index, CHECK);\n+              name_ref_index, THREAD);\n+            return;\n@@ -777,1 +782,2 @@\n-                    name_ref_index, CHECK);\n+                    name_ref_index, THREAD);\n+                return;\n@@ -794,1 +800,2 @@\n-                  name_ref_index, CHECK);\n+                  name_ref_index, THREAD);\n+                return;\n@@ -1059,1 +1066,1 @@\n-                             name->as_C_string(), CHECK);\n+                             name->as_C_string(), THREAD);\n@@ -1115,1 +1122,1 @@\n-                             CHECK);\n+                             THREAD);\n@@ -1402,1 +1409,2 @@\n-        classfile_parse_error(\"Duplicate ConstantValue attribute in class file %s\", CHECK);\n+        classfile_parse_error(\"Duplicate ConstantValue attribute in class file %s\", THREAD);\n+        return;\n@@ -1417,1 +1425,2 @@\n-          attribute_length, CHECK);\n+          attribute_length, THREAD);\n+        return;\n@@ -1424,1 +1433,2 @@\n-          attribute_length, CHECK);\n+          attribute_length, THREAD);\n+        return;\n@@ -1430,1 +1440,2 @@\n-            \"Multiple Signature attributes for field in class file %s\", CHECK);\n+            \"Multiple Signature attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1435,1 +1446,2 @@\n-            attribute_length, CHECK);\n+            attribute_length, THREAD);\n+          return;\n@@ -1441,1 +1453,2 @@\n-            \"Multiple RuntimeVisibleAnnotations attributes for field in class file %s\", CHECK);\n+            \"Multiple RuntimeVisibleAnnotations attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1458,1 +1471,2 @@\n-            \"Multiple RuntimeInvisibleAnnotations attributes for field in class file %s\", CHECK);\n+            \"Multiple RuntimeInvisibleAnnotations attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1470,1 +1484,2 @@\n-            \"Multiple RuntimeVisibleTypeAnnotations attributes for field in class file %s\", CHECK);\n+            \"Multiple RuntimeVisibleTypeAnnotations attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1479,1 +1494,2 @@\n-            \"Multiple RuntimeInvisibleTypeAnnotations attributes for field in class file %s\", CHECK);\n+            \"Multiple RuntimeInvisibleTypeAnnotations attributes for field in class file %s\", THREAD);\n+          return;\n@@ -1882,1 +1898,1 @@\n-                             name->as_C_string(), sig->as_klass_external_name(), CHECK);\n+                             name->as_C_string(), sig->as_klass_external_name(), THREAD);\n@@ -2050,1 +2066,2 @@\n-          start_pc, tbl_name, CHECK_NULL);\n+          start_pc, tbl_name, THREAD);\n+        return NULL;\n@@ -2055,1 +2072,2 @@\n-          length, tbl_name, CHECK_NULL);\n+          length, tbl_name, THREAD);\n+        return NULL;\n@@ -2320,1 +2338,2 @@\n-                               CHECK);\n+                               THREAD);\n+        return;\n@@ -2339,1 +2358,2 @@\n-                                 CHECK);\n+                                 THREAD);\n+          return;\n@@ -2345,1 +2365,2 @@\n-                               CHECK);\n+                               THREAD);\n+        return;\n@@ -2464,1 +2485,2 @@\n-      classfile_parse_error(\"Method <clinit> is not static in class file %s\", CHECK_NULL);\n+      classfile_parse_error(\"Method <clinit> is not static in class file %s\", THREAD);\n+      return NULL;\n@@ -2472,1 +2494,2 @@\n-      classfile_parse_error(\"Interface cannot have a method named <init>, class file %s\", CHECK_NULL);\n+      classfile_parse_error(\"Interface cannot have a method named <init>, class file %s\", THREAD);\n+      return NULL;\n@@ -2524,1 +2547,2 @@\n-      classfile_parse_error(\"Too many arguments in method signature in class file %s\", CHECK_NULL);\n+      classfile_parse_error(\"Too many arguments in method signature in class file %s\", THREAD);\n+      return NULL;\n@@ -2603,1 +2627,2 @@\n-                              CHECK_NULL);\n+                              THREAD);\n+        return NULL;\n@@ -2735,1 +2760,2 @@\n-            classfile_parse_error(\"Multiple StackMapTable attributes in class file %s\", CHECK_NULL);\n+            classfile_parse_error(\"Multiple StackMapTable attributes in class file %s\", THREAD);\n+            return NULL;\n@@ -2755,1 +2781,2 @@\n-                              CHECK_NULL);\n+                              THREAD);\n+        return NULL;\n@@ -2767,1 +2794,2 @@\n-                              CHECK_NULL);\n+                              THREAD);\n+        return NULL;\n@@ -2775,1 +2803,2 @@\n-          method_attribute_length, CHECK_NULL);\n+          method_attribute_length, THREAD);\n+        return NULL;\n@@ -2787,1 +2816,2 @@\n-          method_attribute_length, CHECK_NULL);\n+          method_attribute_length, THREAD);\n+        return NULL;\n@@ -2795,1 +2825,2 @@\n-          method_attribute_length, CHECK_NULL);\n+          method_attribute_length, THREAD);\n+        return NULL;\n@@ -2802,1 +2833,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2807,1 +2839,2 @@\n-            method_attribute_length, CHECK_NULL);\n+            method_attribute_length, THREAD);\n+          return NULL;\n@@ -2814,1 +2847,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2832,1 +2866,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2845,1 +2880,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2855,1 +2891,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2869,1 +2906,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2879,1 +2917,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -2890,1 +2929,2 @@\n-            CHECK_NULL);\n+            THREAD);\n+          return NULL;\n@@ -3133,1 +3173,1 @@\n-                               name->as_C_string(), sig->as_klass_external_name(), CHECK);\n+                               name->as_C_string(), sig->as_klass_external_name(), THREAD);\n@@ -3382,1 +3422,2 @@\n-    classfile_parse_error(\"PermittedSubclasses attribute is empty in class file %s\", CHECK_0);\n+    classfile_parse_error(\"PermittedSubclasses attribute is empty in class file %s\", THREAD);\n+    return 0;\n@@ -3484,1 +3525,2 @@\n-            CHECK_0);\n+            THREAD);\n+          return 0;\n@@ -3489,1 +3531,2 @@\n-            attribute_length, CHECK_0);\n+            attribute_length, THREAD);\n+          return 0;\n@@ -3496,1 +3539,2 @@\n-            \"Multiple RuntimeVisibleAnnotations attributes for Record component in class file %s\", CHECK_0);\n+            \"Multiple RuntimeVisibleAnnotations attributes for Record component in class file %s\", THREAD);\n+          return 0;\n@@ -3508,1 +3552,2 @@\n-            \"Multiple RuntimeInvisibleAnnotations attributes for Record component in class file %s\", CHECK_0);\n+            \"Multiple RuntimeInvisibleAnnotations attributes for Record component in class file %s\", THREAD);\n+          return 0;\n@@ -3521,1 +3566,2 @@\n-            \"Multiple RuntimeVisibleTypeAnnotations attributes for Record component in class file %s\", CHECK_0);\n+            \"Multiple RuntimeVisibleTypeAnnotations attributes for Record component in class file %s\", THREAD);\n+          return 0;\n@@ -3533,1 +3579,2 @@\n-            \"Multiple RuntimeInvisibleTypeAnnotations attributes for Record component in class file %s\", CHECK_0);\n+            \"Multiple RuntimeInvisibleTypeAnnotations attributes for Record component in class file %s\", THREAD);\n+          return 0;\n@@ -3743,1 +3790,2 @@\n-        classfile_parse_error(\"Multiple SourceFile attributes in class file %s\", CHECK);\n+        classfile_parse_error(\"Multiple SourceFile attributes in class file %s\", THREAD);\n+        return;\n@@ -3751,2 +3799,3 @@\n-          classfile_parse_error(\n-            \"Multiple SourceDebugExtension attributes in class file %s\", CHECK);\n+        classfile_parse_error(\n+          \"Multiple SourceDebugExtension attributes in class file %s\", THREAD);\n+        return;\n@@ -3759,1 +3808,2 @@\n-        classfile_parse_error(\"Multiple InnerClasses attributes in class file %s\", CHECK);\n+        classfile_parse_error(\"Multiple InnerClasses attributes in class file %s\", THREAD);\n+        return;\n@@ -3772,1 +3822,2 @@\n-          attribute_length, CHECK);\n+          attribute_length, THREAD);\n+        return;\n@@ -3780,1 +3831,2 @@\n-          attribute_length, CHECK);\n+          attribute_length, THREAD);\n+        return;\n@@ -3786,1 +3838,2 @@\n-            \"Multiple Signature attributes in class file %s\", CHECK);\n+            \"Multiple Signature attributes in class file %s\", THREAD);\n+          return;\n@@ -3791,1 +3844,2 @@\n-            attribute_length, CHECK);\n+            attribute_length, THREAD);\n+          return;\n@@ -3797,1 +3851,2 @@\n-            \"Multiple RuntimeVisibleAnnotations attributes in class file %s\", CHECK);\n+            \"Multiple RuntimeVisibleAnnotations attributes in class file %s\", THREAD);\n+          return;\n@@ -3814,1 +3869,2 @@\n-            \"Multiple RuntimeInvisibleAnnotations attributes in class file %s\", CHECK);\n+            \"Multiple RuntimeInvisibleAnnotations attributes in class file %s\", THREAD);\n+          return;\n@@ -3825,1 +3881,2 @@\n-          classfile_parse_error(\"Multiple EnclosingMethod attributes in class file %s\", CHECK);\n+          classfile_parse_error(\"Multiple EnclosingMethod attributes in class file %s\", THREAD);\n+          return;\n@@ -3836,1 +3893,2 @@\n-          classfile_parse_error(\"Invalid class index in EnclosingMethod attribute in class file %s\", CHECK);\n+          classfile_parse_error(\"Invalid class index in EnclosingMethod attribute in class file %s\", THREAD);\n+          return;\n@@ -3844,1 +3902,2 @@\n-          classfile_parse_error(\"Invalid or out-of-bounds method index in EnclosingMethod attribute in class file %s\", CHECK);\n+          classfile_parse_error(\"Invalid or out-of-bounds method index in EnclosingMethod attribute in class file %s\", THREAD);\n+          return;\n@@ -3849,1 +3908,2 @@\n-          classfile_parse_error(\"Multiple BootstrapMethods attributes in class file %s\", CHECK);\n+          classfile_parse_error(\"Multiple BootstrapMethods attributes in class file %s\", THREAD);\n+          return;\n@@ -3856,1 +3916,2 @@\n-            \"Multiple RuntimeVisibleTypeAnnotations attributes in class file %s\", CHECK);\n+            \"Multiple RuntimeVisibleTypeAnnotations attributes in class file %s\", THREAD);\n+          return;\n@@ -3866,1 +3927,2 @@\n-            \"Multiple RuntimeInvisibleTypeAnnotations attributes in class file %s\", CHECK);\n+            \"Multiple RuntimeInvisibleTypeAnnotations attributes in class file %s\", THREAD);\n+          return;\n@@ -3880,1 +3942,2 @@\n-            classfile_parse_error(\"Multiple NestMembers attributes in class file %s\", CHECK);\n+            classfile_parse_error(\"Multiple NestMembers attributes in class file %s\", THREAD);\n+            return;\n@@ -3885,1 +3948,2 @@\n-            classfile_parse_error(\"Conflicting NestHost and NestMembers attributes in class file %s\", CHECK);\n+            classfile_parse_error(\"Conflicting NestHost and NestMembers attributes in class file %s\", THREAD);\n+            return;\n@@ -3892,1 +3956,2 @@\n-            classfile_parse_error(\"Multiple NestHost attributes in class file %s\", CHECK);\n+            classfile_parse_error(\"Multiple NestHost attributes in class file %s\", THREAD);\n+            return;\n@@ -3897,1 +3962,2 @@\n-            classfile_parse_error(\"Conflicting NestMembers and NestHost attributes in class file %s\", CHECK);\n+            classfile_parse_error(\"Conflicting NestMembers and NestHost attributes in class file %s\", THREAD);\n+            return;\n@@ -3916,1 +3982,2 @@\n-                classfile_parse_error(\"Multiple Record attributes in class file %s\", CHECK);\n+                classfile_parse_error(\"Multiple Record attributes in class file %s\", THREAD);\n+                return;\n@@ -3920,1 +3987,2 @@\n-                classfile_parse_error(\"Record attribute in non-final or abstract class file %s\", CHECK);\n+                classfile_parse_error(\"Record attribute in non-final or abstract class file %s\", THREAD);\n+                return;\n@@ -3947,1 +4015,2 @@\n-                  classfile_parse_error(\"Multiple PermittedSubclasses attributes in class file %s\", CHECK);\n+                  classfile_parse_error(\"Multiple PermittedSubclasses attributes in class file %s\", THREAD);\n+                  return;\n@@ -3951,1 +4020,2 @@\n-                  classfile_parse_error(\"PermittedSubclasses attribute in final class file %s\", CHECK);\n+                  classfile_parse_error(\"PermittedSubclasses attribute in final class file %s\", THREAD);\n+                  return;\n@@ -4486,1 +4556,1 @@\n-static void check_super_class_access(const InstanceKlass* this_klass, TRAPS) {\n+void ClassFileParser::check_super_class_access(const InstanceKlass* this_klass, TRAPS) {\n@@ -4505,7 +4575,1 @@\n-      ResourceMark rm(THREAD);\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_IncompatibleClassChangeError(),\n-        \"class %s cannot inherit from sealed class %s\",\n-        this_klass->external_name(),\n-        super_ik->external_name());\n+      classfile_icce_error(\"class %s cannot inherit from sealed class %s\", super_ik, THREAD);\n@@ -4567,1 +4631,1 @@\n-static void check_super_interface_access(const InstanceKlass* this_klass, TRAPS) {\n+void ClassFileParser::check_super_interface_access(const InstanceKlass* this_klass, TRAPS) {\n@@ -4576,8 +4640,4 @@\n-      ResourceMark rm(THREAD);\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_IncompatibleClassChangeError(),\n-        \"class %s cannot %s sealed interface %s\",\n-        this_klass->external_name(),\n-        this_klass->is_interface() ? \"extend\" : \"implement\",\n-        k->external_name());\n+      classfile_icce_error(this_klass->is_interface() ?\n+                             \"class %s cannot extend sealed interface %s\" :\n+                             \"class %s cannot implement sealed interface %s\",\n+                           k, THREAD);\n@@ -4776,1 +4836,1 @@\n-static void verify_class_version(u2 major, u2 minor, Symbol* class_name, TRAPS){\n+void ClassFileParser::verify_class_version(u2 major, u2 minor, Symbol* class_name, TRAPS){\n@@ -4780,5 +4840,2 @@\n-    Exceptions::fthrow(\n-      THREAD_AND_LOCATION,\n-      vmSymbols::java_lang_UnsupportedClassVersionError(),\n-      \"%s (class file version %u.%u) was compiled with an invalid major version\",\n-      class_name->as_C_string(), major, minor);\n+    classfile_ucve_error(\"%s (class file version %u.%u) was compiled with an invalid major version\",\n+                         class_name, major, minor, THREAD);\n@@ -4814,5 +4871,2 @@\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_UnsupportedClassVersionError(),\n-        \"Preview features are not enabled for %s (class file version %u.%u). Try running with '--enable-preview'\",\n-        class_name->as_C_string(), major, minor);\n+      classfile_ucve_error(\"Preview features are not enabled for %s (class file version %u.%u). Try running with '--enable-preview'\",\n+                           class_name, major, minor, THREAD);\n@@ -4823,5 +4877,2 @@\n-    Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_UnsupportedClassVersionError(),\n-        \"%s (class file version %u.%u) was compiled with an invalid non-zero minor version\",\n-        class_name->as_C_string(), major, minor);\n+    classfile_ucve_error(\"%s (class file version %u.%u) was compiled with an invalid non-zero minor version\",\n+                         class_name, major, minor, THREAD);\n@@ -4979,1 +5030,1 @@\n-    classfile_parse_error(\"Illegal UTF8 string in constant pool in class file %s\", CHECK);\n+    classfile_parse_error(\"Illegal UTF8 string in constant pool in class file %s\", THREAD);\n@@ -5157,1 +5208,1 @@\n-                                  CHECK_NULL);\n+                                  THREAD);\n@@ -5169,1 +5220,2 @@\n-        classfile_parse_error(\"Array type descriptor has more than 255 dimensions in class file %s\", CHECK_NULL);\n+        classfile_parse_error(\"Array type descriptor has more than 255 dimensions in class file %s\", THREAD);\n+        return NULL;\n@@ -6257,1 +6309,2 @@\n-    classfile_parse_error(\"Unknown constant tag %u in class file %s\", bad_constant, CHECK);\n+    classfile_parse_error(\"Unknown constant tag %u in class file %s\", bad_constant, THREAD);\n+    return;\n@@ -6429,1 +6482,12 @@\n-  jio_snprintf(addr_buf, 20, INTPTR_FORMAT, p2i(ik));\n+  if (DumpSharedSpaces) {\n+    \/\/ We want stable names for the archived hidden classes (only for static\n+    \/\/ archive for now). Spaces under default_SharedBaseAddress() will be\n+    \/\/ occupied by the archive at run time, so we know that no dynamically\n+    \/\/ loaded InstanceKlass will be placed under there.\n+    static volatile size_t counter = 0;\n+    Atomic::cmpxchg(&counter, (size_t)0, Arguments::default_SharedBaseAddress()); \/\/ initialize it\n+    size_t new_id = Atomic::add(&counter, (size_t)1);\n+    jio_snprintf(addr_buf, 20, SIZE_FORMAT_HEX, new_id);\n+  } else {\n+    jio_snprintf(addr_buf, 20, INTPTR_FORMAT, p2i(ik));\n+  }\n@@ -6493,8 +6557,1 @@\n-      ResourceMark rm(THREAD);\n-      Exceptions::fthrow(\n-        THREAD_AND_LOCATION,\n-        vmSymbols::java_lang_IncompatibleClassChangeError(),\n-        \"class %s has interface %s as super class\",\n-        _class_name->as_klass_external_name(),\n-        _super_klass->external_name()\n-      );\n+      classfile_icce_error(\"class %s has interface %s as super class\", _super_klass, THREAD);\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":180,"deletions":123,"binary":false,"changes":303,"status":"modified"},{"patch":"@@ -399,0 +399,10 @@\n+  void classfile_icce_error(const char* msg,\n+                            const Klass* k,\n+                            TRAPS) const;\n+\n+  void classfile_ucve_error(const char* msg,\n+                            const Symbol* class_name,\n+                            u2 major,\n+                            u2 minor,\n+                            TRAPS) const;\n+\n@@ -400,1 +410,1 @@\n-    if (!b) { classfile_parse_error(msg, CHECK); }\n+    if (!b) { classfile_parse_error(msg, THREAD); return; }\n@@ -445,1 +455,1 @@\n-    if (!b) { classfile_parse_error(msg, index, CHECK); }\n+    if (!b) { classfile_parse_error(msg, index, THREAD); return; }\n@@ -452,1 +462,1 @@\n-    if (!b) { classfile_parse_error(msg, name, CHECK); }\n+    if (!b) { classfile_parse_error(msg, name, THREAD); return; }\n@@ -460,1 +470,1 @@\n-    if (!b) { classfile_parse_error(msg, index, name, CHECK); }\n+    if (!b) { classfile_parse_error(msg, index, name, THREAD); return; }\n@@ -490,0 +500,2 @@\n+  void verify_class_version(u2 major, u2 minor, Symbol* class_name, TRAPS);\n+\n@@ -501,0 +513,6 @@\n+  void check_super_class_access(const InstanceKlass* this_klass,\n+                                TRAPS);\n+\n+  void check_super_interface_access(const InstanceKlass* this_klass,\n+                                    TRAPS);\n+\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":22,"deletions":4,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"classfile\/lambdaFormInvokers.hpp\"\n@@ -90,0 +91,6 @@\n+    \/\/ The line is output TRACE_RESOLVE\n+    if (strncmp(_line, LambdaFormInvokers::lambda_form_invoker_tag(),\n+                strlen(LambdaFormInvokers::lambda_form_invoker_tag())) == 0) {\n+      LambdaFormInvokers::append(os::strdup((const char*)_line, mtInternal));\n+      continue;\n+    }\n","filename":"src\/hotspot\/share\/classfile\/classListParser.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -137,1 +137,1 @@\n-  _modified_oops(true), _accumulated_modified_oops(false),\n+  _modified_oops(true),\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -126,2 +126,1 @@\n-  bool _modified_oops;             \/\/ Card Table Equivalent (YC\/CMS support)\n-  bool _accumulated_modified_oops; \/\/ Mod Union Equivalent (CMS support)\n+  bool _modified_oops;     \/\/ Card Table Equivalent\n@@ -179,3 +178,0 @@\n-  void accumulate_modified_oops()        { if (has_modified_oops()) _accumulated_modified_oops = true; }\n-  void clear_accumulated_modified_oops() { _accumulated_modified_oops = false; }\n-  bool has_accumulated_modified_oops()   { return _accumulated_modified_oops; }\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -1261,0 +1262,2 @@\n+    set_signers(archived_mirror, NULL);\n+    set_source_file(archived_mirror, NULL);\n@@ -2461,1 +2464,1 @@\n-  vframeStream st(thread);\n+  vframeStream st(thread, false \/* stop_at_java_call_stub *\/, false \/* process_frames *\/);\n@@ -2464,1 +2467,1 @@\n-  RegisterMap map(thread, false);\n+  RegisterMap map(thread, false \/* update *\/, false \/* process_frames *\/);\n@@ -2606,1 +2609,1 @@\n-  vframeStream st(THREAD);\n+  vframeStream st(THREAD, false \/* stop_at_java_call_stub *\/, false \/* process_frames *\/);\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -638,1 +638,0 @@\n-protected:\n@@ -641,0 +640,1 @@\n+protected:\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -249,0 +249,1 @@\n+    case vmIntrinsics::_indexOfL_char:\n@@ -538,0 +539,1 @@\n+  case vmIntrinsics::_indexOfL_char:\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -312,0 +312,1 @@\n+  do_intrinsic(_indexOfL_char,            java_lang_StringLatin1,indexOfChar_name, indexOfChar_signature,        F_S)   \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -287,0 +287,4 @@\n+  \/* used by CDS *\/                                                                               \\\n+  template(jdk_internal_misc_CDS, \"jdk\/internal\/misc\/CDS\")                                        \\\n+  template(generateLambdaFormHolderClasses, \"generateLambdaFormHolderClasses\")                    \\\n+  template(generateLambdaFormHolderClasses_signature, \"([Ljava\/lang\/String;)[Ljava\/lang\/Object;\") \\\n@@ -294,1 +298,0 @@\n-                                                                                                  \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -58,3 +58,2 @@\n-  return\n-    ((offset + (int)CodeHeap::header_size() + (CodeEntryAlignment-1)) & ~(CodeEntryAlignment-1))\n-    - (int)CodeHeap::header_size();\n+  int header_size = (int)CodeHeap::header_size();\n+  return align_up(offset + header_size, CodeEntryAlignment) - header_size;\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -53,0 +53,1 @@\n+#include \"prims\/methodHandles.hpp\"\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"runtime\/stackWatermarkSet.inline.hpp\"\n@@ -193,4 +194,1 @@\n-static void add_derived_oop(oop* base, oop* derived) {\n-#if !defined(TIERED) && !INCLUDE_JVMCI\n-  COMPILER1_PRESENT(ShouldNotReachHere();)\n-#endif \/\/ !defined(TIERED) && !INCLUDE_JVMCI\n+static void add_derived_oop(oop* base, oop* derived, OopClosure* oop_fn) {\n@@ -202,0 +200,13 @@\n+static void ignore_derived_oop(oop* base, oop* derived, OopClosure* oop_fn) {\n+}\n+\n+static void process_derived_oop(oop* base, oop* derived, OopClosure* oop_fn) {\n+  \/\/ All derived pointers must be processed before the base pointer of any derived pointer is processed.\n+  \/\/ Otherwise, if two derived pointers use the same base, the second derived pointer will get an obscured\n+  \/\/ offset, if the base pointer is processed in the first derived pointer.\n+  uintptr_t offset = cast_from_oop<uintptr_t>(*derived) - cast_from_oop<uintptr_t>(*base);\n+  *derived = *base;\n+  oop_fn->do_oop(derived);\n+  *derived = cast_to_oop(cast_from_oop<uintptr_t>(*derived) + offset);\n+}\n+\n@@ -231,3 +242,12 @@\n-void OopMapSet::oops_do(const frame *fr, const RegisterMap* reg_map, OopClosure* f) {\n-  \/\/ add derived oops to a table\n-  all_do(fr, reg_map, f, add_derived_oop, &do_nothing_cl);\n+void OopMapSet::oops_do(const frame *fr, const RegisterMap* reg_map, OopClosure* f, DerivedPointerIterationMode mode) {\n+  switch (mode) {\n+  case DerivedPointerIterationMode::_directly:\n+    all_do(fr, reg_map, f, process_derived_oop, &do_nothing_cl);\n+    break;\n+  case DerivedPointerIterationMode::_with_table:\n+    all_do(fr, reg_map, f, add_derived_oop, &do_nothing_cl);\n+    break;\n+  case DerivedPointerIterationMode::_ignore:\n+    all_do(fr, reg_map, f, ignore_derived_oop, &do_nothing_cl);\n+    break;\n+  }\n@@ -238,1 +258,1 @@\n-                       OopClosure* oop_fn, void derived_oop_fn(oop*, oop*),\n+                       OopClosure* oop_fn, void derived_oop_fn(oop*, oop*, OopClosure*),\n@@ -275,1 +295,1 @@\n-        derived_oop_fn(base_loc, derived_loc);\n+        derived_oop_fn(base_loc, derived_loc, oop_fn);\n@@ -300,14 +320,0 @@\n-#ifdef ASSERT\n-        if ((((uintptr_t)loc & (sizeof(*loc)-1)) != 0) ||\n-            !Universe::heap()->is_in_or_null(*loc)) {\n-          tty->print_cr(\"# Found non oop pointer.  Dumping state at failure\");\n-          \/\/ try to dump out some helpful debugging information\n-          trace_codeblob_maps(fr, reg_map);\n-          omv.print();\n-          tty->print_cr(\"register r\");\n-          omv.reg()->print();\n-          tty->print_cr(\"loc = %p *loc = %p\\n\", loc, cast_from_oop<address>(*loc));\n-          \/\/ do the real assert.\n-          assert(Universe::heap()->is_in_or_null(*loc), \"found non oop pointer\");\n-        }\n-#endif \/\/ ASSERT\n@@ -698,20 +704,15 @@\n-  if (_active) {\n-    assert(*derived_loc != (void*)base_loc, \"location already added\");\n-    assert(Entry::_list != NULL, \"list must exist\");\n-    intptr_t offset = value_of_loc(derived_loc) - value_of_loc(base_loc);\n-    \/\/ This assert is invalid because derived pointers can be\n-    \/\/ arbitrarily far away from their base.\n-    \/\/ assert(offset >= -1000000, \"wrong derived pointer info\");\n-\n-    if (TraceDerivedPointers) {\n-      tty->print_cr(\n-        \"Add derived pointer@\" INTPTR_FORMAT\n-        \" - Derived: \" INTPTR_FORMAT\n-        \" Base: \" INTPTR_FORMAT \" (@\" INTPTR_FORMAT \") (Offset: \" INTX_FORMAT \")\",\n-        p2i(derived_loc), p2i(*derived_loc), p2i(*base_loc), p2i(base_loc), offset\n-      );\n-    }\n-    \/\/ Set derived oop location to point to base.\n-    *derived_loc = (oop)base_loc;\n-    Entry* entry = new Entry(derived_loc, offset);\n-    Entry::_list->push(*entry);\n+  assert(*derived_loc != (void*)base_loc, \"location already added\");\n+  assert(Entry::_list != NULL, \"list must exist\");\n+  assert(is_active(), \"table must be active here\");\n+  intptr_t offset = value_of_loc(derived_loc) - value_of_loc(base_loc);\n+  \/\/ This assert is invalid because derived pointers can be\n+  \/\/ arbitrarily far away from their base.\n+  \/\/ assert(offset >= -1000000, \"wrong derived pointer info\");\n+\n+  if (TraceDerivedPointers) {\n+    tty->print_cr(\n+      \"Add derived pointer@\" INTPTR_FORMAT\n+      \" - Derived: \" INTPTR_FORMAT\n+      \" Base: \" INTPTR_FORMAT \" (@\" INTPTR_FORMAT \") (Offset: \" INTX_FORMAT \")\",\n+      p2i(derived_loc), p2i(*derived_loc), p2i(*base_loc), p2i(base_loc), offset\n+    );\n@@ -719,0 +720,4 @@\n+  \/\/ Set derived oop location to point to base.\n+  *derived_loc = (oop)base_loc;\n+  Entry* entry = new Entry(derived_loc, offset);\n+  Entry::_list->push(*entry);\n","filename":"src\/hotspot\/share\/compiler\/oopMap.cpp","additions":48,"deletions":43,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -528,1 +528,1 @@\n-    obj->oop_iterate_backwards(&_scanner);\n+    obj->oop_iterate_backwards(&_scanner, klass);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -374,0 +374,5 @@\n+  \/\/ If a GC uses a stack watermark barrier, the stack processing is lazy, concurrent,\n+  \/\/ incremental and cooperative. In order for that to work well, mechanisms that stop\n+  \/\/ another thread might want to ensure its roots are in a sane state.\n+  virtual bool uses_stack_watermark_barrier() const { return false; }\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1061,1 +1061,2 @@\n-    if (in1->bottom_type() == TypePtr::NULL_PTR) {\n+    if (in1->bottom_type() == TypePtr::NULL_PTR &&\n+        (in1->Opcode() != Op_ShenandoahLoadReferenceBarrier || !((ShenandoahLoadReferenceBarrierNode*)in1)->is_native())) {\n@@ -1064,1 +1065,2 @@\n-    if (in2->bottom_type() == TypePtr::NULL_PTR) {\n+    if (in2->bottom_type() == TypePtr::NULL_PTR &&\n+        (in2->Opcode() != Op_ShenandoahLoadReferenceBarrier || !((ShenandoahLoadReferenceBarrierNode*)in2)->is_native())) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahBarrierSetC2.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1325,1 +1325,1 @@\n-    enum { _heap_stable = 1, _not_cset, _evac_path, PATH_LIMIT };\n+    enum { _heap_stable = 1, _evac_path, _not_cset, PATH_LIMIT };\n@@ -1339,1 +1339,2 @@\n-    \/\/ Test for in-cset.\n+    \/\/ Test for in-cset, unless it's a native-LRB. Native LRBs need to return NULL\n+    \/\/ even for non-cset objects to prevent ressurrection of such objects.\n@@ -1342,1 +1343,3 @@\n-    test_in_cset(ctrl, not_cset_ctrl, val, raw_mem, phase);\n+    if (!lrb->is_native()) {\n+      test_in_cset(ctrl, not_cset_ctrl, val, raw_mem, phase);\n+    }\n@@ -1347,0 +1350,4 @@\n+    } else {\n+      region->del_req(_not_cset);\n+      val_phi->del_req(_not_cset);\n+      raw_mem_phi->del_req(_not_cset);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahSupport.cpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -96,2 +96,2 @@\n-  oop load_reference_barrier_native(oop obj, oop* load_addr);\n-  oop load_reference_barrier_native(oop obj, narrowOop* load_addr);\n+  template <class T>\n+  inline oop load_reference_barrier_native(oop obj, T* load_addr);\n@@ -116,3 +116,0 @@\n-  template <class T>\n-  oop load_reference_barrier_native_impl(oop obj, T* load_addr);\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSet.hpp","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -79,0 +79,25 @@\n+template <class T>\n+inline oop ShenandoahBarrierSet::load_reference_barrier_native(oop obj, T* load_addr) {\n+  if (CompressedOops::is_null(obj)) {\n+    return NULL;\n+  }\n+\n+  ShenandoahMarkingContext* const marking_context = _heap->marking_context();\n+  if (_heap->is_concurrent_weak_root_in_progress() && !marking_context->is_marked(obj)) {\n+    Thread* thr = Thread::current();\n+    if (thr->is_Java_thread()) {\n+      return NULL;\n+    } else {\n+      return obj;\n+    }\n+  }\n+\n+  oop fwd = load_reference_barrier_not_null(obj);\n+  if (ShenandoahSelfFixing && load_addr != NULL && fwd != obj) {\n+    \/\/ Since we are here and we know the load address, update the reference.\n+    ShenandoahHeap::cas_oop(fwd, load_addr, obj);\n+  }\n+\n+  return fwd;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSet.inline.hpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -62,0 +62,1 @@\n+  static uintptr_t relocate_or_mark_no_follow(uintptr_t addr);\n@@ -65,0 +66,1 @@\n+  static uintptr_t load_barrier_on_invisible_root_oop_slow_path(uintptr_t addr);\n@@ -76,1 +78,0 @@\n-  static uintptr_t mark_barrier_on_invisible_root_oop_slow_path(uintptr_t addr);\n@@ -90,0 +91,1 @@\n+  static void load_barrier_on_invisible_root_oop_field(oop* p);\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrier.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -70,0 +71,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -682,0 +684,4 @@\n+  \/\/ We get here after we have unwound from a callee throwing an exception\n+  \/\/ into the interpreter. Any deferred stack processing is notified of\n+  \/\/ the event via the StackWatermarkSet.\n+  StackWatermarkSet::after_unwind(thread);\n@@ -783,1 +789,1 @@\n-  if (handler_bci < 0 || !thread->reguard_stack((address) &continuation)) {\n+  if (handler_bci < 0 || !thread->stack_overflow_state()->reguard_stack((address) &continuation)) {\n@@ -1402,0 +1408,5 @@\n+    \/\/ This function is called by the interpreter when single stepping. Such single\n+    \/\/ stepping could unwind a frame. Then, it is important that we process any frames\n+    \/\/ that we might return into.\n+    StackWatermarkSet::before_unwind(thread);\n+\n@@ -1410,0 +1421,14 @@\n+JRT_ENTRY(void, InterpreterRuntime::at_unwind(JavaThread* thread))\n+  \/\/ JRT_END does an implicit safepoint check, hence we are guaranteed to block\n+  \/\/ if this is called during a safepoint\n+\n+  \/\/ This function is called by the interpreter when the return poll found a reason\n+  \/\/ to call the VM. The reason could be that we are returning into a not yet safe\n+  \/\/ to access frame. We handle that below.\n+  \/\/ Note that this path does not check for single stepping, because we do not want\n+  \/\/ to single step when unwinding frames for an exception being thrown. Instead,\n+  \/\/ such single stepping code will use the safepoint table, which will use the\n+  \/\/ InterpreterRuntime::at_safepoint callback.\n+  StackWatermarkSet::before_unwind(thread);\n+JRT_END\n+\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":26,"deletions":1,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -127,0 +127,1 @@\n+  static void    at_unwind(JavaThread* thread);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -238,1 +238,0 @@\n-  static void count_calls(Register method, Register temp);\n","filename":"src\/hotspot\/share\/interpreter\/templateTable.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"prims\/methodHandles.hpp\"\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCodeInstaller.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -1226,1 +1227,1 @@\n-  StackFrameStream fst(thread);\n+  StackFrameStream fst(thread, true \/* update *\/, true \/* process_frames *\/);\n@@ -1333,1 +1334,1 @@\n-          fst = StackFrameStream(thread);\n+          fst = StackFrameStream(thread, true \/* update *\/, true \/* process_frames *\/);\n@@ -1465,1 +1466,1 @@\n-  StackFrameStream fst(thread, false);\n+  StackFrameStream fst(thread, false \/* update *\/, true \/* process_frames *\/);\n@@ -1483,1 +1484,1 @@\n-  StackFrameStream fstAfterDeopt(thread);\n+  StackFrameStream fstAfterDeopt(thread, true \/* update *\/, true \/* process_frames *\/);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -183,1 +183,1 @@\n-  nonstatic_field(JavaThread,                  _reserved_stack_activation,                    address)                               \\\n+  nonstatic_field(JavaThread,                  _stack_overflow_state._reserved_stack_activation, address)                            \\\n@@ -232,0 +232,1 @@\n+  AOT_ONLY(nonstatic_field(MethodCounters,     _method,                                       Method*))                              \\\n@@ -331,1 +332,1 @@\n-  nonstatic_field(Thread,                   _polling_page,                                    volatile void*)                        \\\n+  nonstatic_field(Thread,                   _poll_data,                                       SafepointMechanism::ThreadData)        \\\n@@ -343,0 +344,3 @@\n+  nonstatic_field(SafepointMechanism::ThreadData, _polling_word,                              volatile uintptr_t)                    \\\n+  nonstatic_field(SafepointMechanism::ThreadData, _polling_page,                              volatile uintptr_t)                    \\\n+                                                                                                                                     \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -101,0 +101,1 @@\n+  LOG_TAG(map) \\\n@@ -156,0 +157,1 @@\n+  LOG_TAG(stackbarrier) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,1 +29,2 @@\n-#include \"logging\/logMessage.hpp\"\n+#include \"logging\/logStream.hpp\"\n+#include \"memory\/allStatic.hpp\"\n@@ -34,0 +35,1 @@\n+#include \"memory\/memRegion.hpp\"\n@@ -137,1 +139,1 @@\n-ArchiveBuilder::ArchiveBuilder(DumpRegion* rw_region, DumpRegion* ro_region)\n+ArchiveBuilder::ArchiveBuilder(DumpRegion* mc_region, DumpRegion* rw_region, DumpRegion* ro_region)\n@@ -151,0 +153,1 @@\n+  _mc_region = mc_region;\n@@ -297,1 +300,1 @@\n-      it->push(&_symbols->at(i));\n+      it->push(_symbols->adr_at(i));\n@@ -303,1 +306,1 @@\n-    it->push(&_klasses->at(i));\n+    it->push(_klasses->adr_at(i));\n@@ -606,0 +609,194 @@\n+\/\/ Write detailed info to a mapfile to analyze contents of the archive.\n+\/\/ static dump:\n+\/\/   java -Xshare:dump -Xlog:cds+map=trace:file=cds.map:none:filesize=0\n+\/\/ dynamic dump:\n+\/\/   java -cp MyApp.jar -XX:ArchiveClassesAtExit=MyApp.jsa \\\n+\/\/        -Xlog:cds+map=trace:file=cds.map:none:filesize=0 MyApp\n+\/\/\n+\/\/ We need to do some address translation because the buffers used at dump time may be mapped to\n+\/\/ a different location at runtime. At dump time, the buffers may be at arbitrary locations\n+\/\/ picked by the OS. At runtime, we try to map at a fixed location (SharedBaseAddress). For\n+\/\/ consistency, we log everything using runtime addresses.\n+class ArchiveBuilder::CDSMapLogger : AllStatic {\n+  static intx buffer_to_runtime_delta() {\n+    \/\/ Translate the buffers used by the MC\/RW\/RO regions to their eventual locations\n+    \/\/ at runtime.\n+    return _buffer_to_target_delta + MetaspaceShared::final_delta();\n+  }\n+\n+  \/\/ mc\/rw\/ro regions only\n+  static void write_dump_region(const char* name, DumpRegion* region) {\n+    address region_base = address(region->base());\n+    address region_top  = address(region->top());\n+    write_region(name, region_base, region_top, region_base + buffer_to_runtime_delta());\n+  }\n+\n+#define _LOG_PREFIX PTR_FORMAT \": @@ %-17s %d\"\n+\n+  static void write_klass(Klass* k, address runtime_dest, const char* type_name, int bytes, Thread* THREAD) {\n+    ResourceMark rm(THREAD);\n+    log_debug(cds, map)(_LOG_PREFIX \" %s\",\n+                        p2i(runtime_dest), type_name, bytes, k->external_name());\n+  }\n+  static void write_method(Method* m, address runtime_dest, const char* type_name, int bytes, Thread* THREAD) {\n+    ResourceMark rm(THREAD);\n+    log_debug(cds, map)(_LOG_PREFIX \" %s\",\n+                        p2i(runtime_dest), type_name, bytes,  m->external_name());\n+  }\n+\n+  \/\/ rw\/ro regions only\n+  static void write_objects(DumpRegion* region, const ArchiveBuilder::SourceObjList* src_objs) {\n+    address last_obj_base = address(region->base());\n+    address last_obj_end  = address(region->base());\n+    address region_end    = address(region->end());\n+    Thread* THREAD = Thread::current();\n+    for (int i = 0; i < src_objs->objs()->length(); i++) {\n+      SourceObjInfo* src_info = src_objs->at(i);\n+      address src = src_info->orig_obj();\n+      address dest = src_info->dumped_addr();\n+      write_data(last_obj_base, dest, last_obj_base + buffer_to_runtime_delta());\n+      address runtime_dest = dest + buffer_to_runtime_delta();\n+      int bytes = src_info->size_in_bytes();\n+\n+      MetaspaceObj::Type type = src_info->msotype();\n+      const char* type_name = MetaspaceObj::type_name(type);\n+\n+      switch (type) {\n+      case MetaspaceObj::ClassType:\n+        write_klass((Klass*)src, runtime_dest, type_name, bytes, THREAD);\n+        break;\n+      case MetaspaceObj::ConstantPoolType:\n+        write_klass(((ConstantPool*)src)->pool_holder(),\n+                    runtime_dest, type_name, bytes, THREAD);\n+        break;\n+      case MetaspaceObj::ConstantPoolCacheType:\n+        write_klass(((ConstantPoolCache*)src)->constant_pool()->pool_holder(),\n+                    runtime_dest, type_name, bytes, THREAD);\n+        break;\n+      case MetaspaceObj::MethodType:\n+        write_method((Method*)src, runtime_dest, type_name, bytes, THREAD);\n+        break;\n+      case MetaspaceObj::ConstMethodType:\n+        write_method(((ConstMethod*)src)->method(), runtime_dest, type_name, bytes, THREAD);\n+        break;\n+      case MetaspaceObj::SymbolType:\n+        {\n+          ResourceMark rm(THREAD);\n+          Symbol* s = (Symbol*)src;\n+          log_debug(cds, map)(_LOG_PREFIX \" %s\", p2i(runtime_dest), type_name, bytes,\n+                              s->as_quoted_ascii());\n+        }\n+        break;\n+      default:\n+        log_debug(cds, map)(_LOG_PREFIX, p2i(runtime_dest), type_name, bytes);\n+        break;\n+      }\n+\n+      last_obj_base = dest;\n+      last_obj_end  = dest + bytes;\n+    }\n+\n+    write_data(last_obj_base, last_obj_end, last_obj_base + buffer_to_runtime_delta());\n+    if (last_obj_end < region_end) {\n+      log_debug(cds, map)(PTR_FORMAT \": @@ Misc data \" SIZE_FORMAT \" bytes\",\n+                          p2i(last_obj_end + buffer_to_runtime_delta()),\n+                          size_t(region_end - last_obj_end));\n+      write_data(last_obj_end, region_end, last_obj_end + buffer_to_runtime_delta());\n+    }\n+  }\n+\n+#undef _LOG_PREFIX\n+\n+  \/\/ Write information about a region, whose address at dump time is [base .. top). At\n+  \/\/ runtime, this region will be mapped to runtime_base.  runtime_base is 0 if this\n+  \/\/ region will be mapped at os-selected addresses (such as the bitmap region), or will\n+  \/\/ be accessed with os::read (the header).\n+  static void write_region(const char* name, address base, address top, address runtime_base) {\n+    size_t size = top - base;\n+    base = runtime_base;\n+    top = runtime_base + size;\n+    log_info(cds, map)(\"[%-18s \" PTR_FORMAT \" - \" PTR_FORMAT \" \" SIZE_FORMAT_W(9) \" bytes]\",\n+                       name, p2i(base), p2i(top), size);\n+  }\n+\n+  \/\/ open and closed archive regions\n+  static void write_heap_region(const char* which, GrowableArray<MemRegion> *regions) {\n+    for (int i = 0; i < regions->length(); i++) {\n+      address start = address(regions->at(i).start());\n+      address end = address(regions->at(i).end());\n+      write_region(which, start, end, start);\n+      write_data(start, end, start);\n+    }\n+  }\n+\n+  \/\/ Dump all the data [base...top). Pretend that the base address\n+  \/\/ will be mapped to runtime_base at run-time.\n+  static void write_data(address base, address top, address runtime_base) {\n+    assert(top >= base, \"must be\");\n+\n+    LogStreamHandle(Trace, cds, map) lsh;\n+    if (lsh.is_enabled()) {\n+      os::print_hex_dump(&lsh, base, top, sizeof(address), 32, runtime_base);\n+    }\n+  }\n+\n+  static void write_header(FileMapInfo* mapinfo) {\n+    LogStreamHandle(Info, cds, map) lsh;\n+    if (lsh.is_enabled()) {\n+      mapinfo->print(&lsh);\n+    }\n+  }\n+\n+public:\n+  static void write(ArchiveBuilder* builder, FileMapInfo* mapinfo,\n+             GrowableArray<MemRegion> *closed_heap_regions,\n+             GrowableArray<MemRegion> *open_heap_regions,\n+             char* bitmap, size_t bitmap_size_in_bytes) {\n+    log_info(cds, map)(\"%s CDS archive map for %s\", DumpSharedSpaces ? \"Static\" : \"Dynamic\", mapinfo->full_path());\n+\n+    address header = address(mapinfo->header());\n+    address header_end = header + mapinfo->header()->header_size();\n+    write_region(\"header\", header, header_end, 0);\n+    write_header(mapinfo);\n+    write_data(header, header_end, 0);\n+\n+    DumpRegion* mc_region = builder->_mc_region;\n+    DumpRegion* rw_region = builder->_rw_region;\n+    DumpRegion* ro_region = builder->_ro_region;\n+\n+    address mc = address(mc_region->base());\n+    address mc_end = address(mc_region->end());\n+    write_dump_region(\"mc region\", mc_region);\n+    write_data(mc, mc_end, mc + buffer_to_runtime_delta());\n+\n+    write_dump_region(\"rw region\", rw_region);\n+    write_objects(rw_region, &builder->_rw_src_objs);\n+\n+    write_dump_region(\"ro region\", ro_region);\n+    write_objects(ro_region, &builder->_ro_src_objs);\n+\n+    address bitmap_end = address(bitmap + bitmap_size_in_bytes);\n+    write_region(\"bitmap\", address(bitmap), bitmap_end, 0);\n+    write_data(header, header_end, 0);\n+\n+    if (closed_heap_regions != NULL) {\n+      write_heap_region(\"closed heap region\", closed_heap_regions);\n+    }\n+    if (open_heap_regions != NULL) {\n+      write_heap_region(\"open heap region\", open_heap_regions);\n+    }\n+\n+    log_info(cds, map)(\"[End of CDS archive map]\");\n+  }\n+};\n+\n+void ArchiveBuilder::write_cds_map_to_log(FileMapInfo* mapinfo,\n+                                          GrowableArray<MemRegion> *closed_heap_regions,\n+                                          GrowableArray<MemRegion> *open_heap_regions,\n+                                          char* bitmap, size_t bitmap_size_in_bytes) {\n+  if (log_is_enabled(Info, cds, map)) {\n+    CDSMapLogger::write(this, mapinfo, closed_heap_regions, open_heap_regions,\n+                        bitmap, bitmap_size_in_bytes);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.cpp","additions":201,"deletions":4,"binary":false,"changes":205,"status":"modified"},{"patch":"@@ -37,0 +37,2 @@\n+class DumpAllocStats;\n+class FileMapInfo;\n@@ -38,0 +40,1 @@\n+class MemRegion;\n@@ -39,1 +42,0 @@\n-class DumpAllocStats;\n@@ -76,0 +78,2 @@\n+    int _size_in_bytes;\n+    MetaspaceObj::Type _msotype;\n@@ -77,0 +81,3 @@\n+    address _orig_obj;       \/\/ The value of the original object (_ref->obj()) when this\n+                             \/\/ SourceObjInfo was created. Note that _ref->obj() may change\n+                             \/\/ later if _ref is relocated.\n@@ -80,1 +87,3 @@\n-      _ref(ref), _ptrmap_start(0), _ptrmap_end(0), _read_only(read_only), _follow_mode(follow_mode) {\n+      _ref(ref), _ptrmap_start(0), _ptrmap_end(0), _read_only(read_only), _follow_mode(follow_mode),\n+      _size_in_bytes(ref->size() * BytesPerWord), _msotype(ref->msotype()),\n+      _orig_obj(ref->obj()) {\n@@ -101,1 +110,2 @@\n-    int size_in_bytes()   const    { return _ref->size() * BytesPerWord; }\n+    int size_in_bytes()   const    { return _size_in_bytes; }\n+    address orig_obj()    const    { return _orig_obj; }\n@@ -103,0 +113,1 @@\n+    MetaspaceObj::Type msotype() const { return _msotype; }\n@@ -135,0 +146,2 @@\n+  class CDSMapLogger;\n+\n@@ -138,0 +151,1 @@\n+  DumpRegion* _mc_region;\n@@ -188,1 +202,0 @@\n-\n@@ -195,6 +208,0 @@\n-  void set_dump_regions(DumpRegion* rw_region, DumpRegion* ro_region) {\n-    assert(_rw_region == NULL && _ro_region == NULL, \"do not change\");\n-    _rw_region = rw_region;\n-    _ro_region = ro_region;\n-  }\n-\n@@ -233,1 +240,1 @@\n-  ArchiveBuilder(DumpRegion* rw_region, DumpRegion* ro_region);\n+  ArchiveBuilder(DumpRegion* mc_region, DumpRegion* rw_region, DumpRegion* ro_region);\n@@ -250,0 +257,5 @@\n+  void write_cds_map_to_log(FileMapInfo* mapinfo,\n+                            GrowableArray<MemRegion> *closed_heap_regions,\n+                            GrowableArray<MemRegion> *open_heap_regions,\n+                            char* bitmap, size_t bitmap_size_in_bytes);\n+\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.hpp","additions":23,"deletions":11,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -126,1 +126,3 @@\n-  DynamicArchiveBuilder() : ArchiveBuilder(NULL, NULL) {\n+  DynamicArchiveBuilder() : ArchiveBuilder(MetaspaceShared::misc_code_dump_space(),\n+                                           MetaspaceShared::read_write_dump_space(),\n+                                           MetaspaceShared::read_only_dump_space()) {\n@@ -180,1 +182,0 @@\n-    set_dump_regions(MetaspaceShared::read_write_dump_space(), MetaspaceShared::read_only_dump_space());\n@@ -581,1 +582,2 @@\n-  MetaspaceShared::write_core_archive_regions(dynamic_info, NULL, NULL);\n+  size_t bitmap_size_in_bytes;\n+  char* bitmap = MetaspaceShared::write_core_archive_regions(dynamic_info, NULL, NULL, bitmap_size_in_bytes);\n@@ -587,0 +589,4 @@\n+  write_cds_map_to_log(dynamic_info, NULL, NULL,\n+                       bitmap, bitmap_size_in_bytes);\n+  FREE_C_HEAP_ARRAY(char, bitmap);\n+\n","filename":"src\/hotspot\/share\/memory\/dynamicArchive.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -30,1 +30,2 @@\n-#include \"classfile\/loaderConstraints.hpp\"\n+#include \"classfile\/lambdaFormInvokers.hpp\"\n+#include \"classfile\/loaderConstraints.hpp\"\n@@ -613,2 +614,2 @@\n-  StaticArchiveBuilder(DumpRegion* rw_region, DumpRegion* ro_region)\n-    : ArchiveBuilder(rw_region, ro_region) {\n+  StaticArchiveBuilder(DumpRegion* mc_region, DumpRegion* rw_region, DumpRegion* ro_region)\n+    : ArchiveBuilder(mc_region, rw_region, ro_region) {\n@@ -729,1 +730,1 @@\n-  StaticArchiveBuilder builder(&_rw_region, &_ro_region);\n+  StaticArchiveBuilder builder(&_mc_region, &_rw_region, &_ro_region);\n@@ -801,1 +802,4 @@\n-  MetaspaceShared::write_core_archive_regions(mapinfo, _closed_archive_heap_oopmaps, _open_archive_heap_oopmaps);\n+  size_t bitmap_size_in_bytes;\n+  char* bitmap = MetaspaceShared::write_core_archive_regions(mapinfo, _closed_archive_heap_oopmaps,\n+                                                             _open_archive_heap_oopmaps,\n+                                                             bitmap_size_in_bytes);\n@@ -819,0 +823,4 @@\n+  builder.write_cds_map_to_log(mapinfo, _closed_archive_heap_regions, _open_archive_heap_regions,\n+                               bitmap, bitmap_size_in_bytes);\n+  FREE_C_HEAP_ARRAY(char, bitmap);\n+\n@@ -883,3 +891,4 @@\n-void MetaspaceShared::write_core_archive_regions(FileMapInfo* mapinfo,\n-                                                 GrowableArray<ArchiveHeapOopmapInfo>* closed_oopmaps,\n-                                                 GrowableArray<ArchiveHeapOopmapInfo>* open_oopmaps) {\n+char* MetaspaceShared::write_core_archive_regions(FileMapInfo* mapinfo,\n+                                                  GrowableArray<ArchiveHeapOopmapInfo>* closed_oopmaps,\n+                                                  GrowableArray<ArchiveHeapOopmapInfo>* open_oopmaps,\n+                                                  size_t& bitmap_size_in_bytes) {\n@@ -895,1 +904,3 @@\n-  mapinfo->write_bitmap_region(ArchivePtrMarker::ptrmap(), closed_oopmaps, open_oopmaps);\n+\n+  return mapinfo->write_bitmap_region(ArchivePtrMarker::ptrmap(), closed_oopmaps, open_oopmaps,\n+                                      bitmap_size_in_bytes);\n@@ -1045,0 +1056,7 @@\n+      log_info(cds)(\"Reading extra data: done.\");\n+    }\n+\n+    if (LambdaFormInvokers::lambdaform_lines() != NULL) {\n+      log_info(cds)(\"Regenerate MethodHandle Holder classes...\");\n+      LambdaFormInvokers::regenerate_holder_classes(THREAD);\n+      log_info(cds)(\"Regenerate MethodHandle Holder classes done.\");\n@@ -1046,1 +1064,0 @@\n-    log_info(cds)(\"Reading extra data: done.\");\n","filename":"src\/hotspot\/share\/memory\/metaspaceShared.cpp","additions":27,"deletions":10,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"memory\/resourceArea.hpp\"\n","filename":"src\/hotspot\/share\/oops\/generateOopMap.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -680,1 +680,1 @@\n-    switch( bc ) {\n+    switch (bc) {\n@@ -699,1 +699,1 @@\n-        if( bcs.dest() < bcs.next_bci() ) _access_flags.set_has_loops();\n+        if (bcs.dest() < bcs.next_bci()) _access_flags.set_has_loops();\n@@ -704,1 +704,1 @@\n-        if( bcs.dest_w() < bcs.next_bci() ) _access_flags.set_has_loops();\n+        if (bcs.dest_w() < bcs.next_bci()) _access_flags.set_has_loops();\n@@ -707,0 +707,28 @@\n+      case Bytecodes::_lookupswitch: {\n+        Bytecode_lookupswitch lookupswitch(this, bcs.bcp());\n+        if (lookupswitch.default_offset() < 0) {\n+          _access_flags.set_has_loops();\n+        } else {\n+          for (int i = 0; i < lookupswitch.number_of_pairs(); ++i) {\n+            LookupswitchPair pair = lookupswitch.pair_at(i);\n+            if (pair.offset() < 0) {\n+              _access_flags.set_has_loops();\n+              break;\n+            }\n+          }\n+        }\n+        break;\n+      }\n+      case Bytecodes::_tableswitch: {\n+        Bytecode_tableswitch tableswitch(this, bcs.bcp());\n+        if (tableswitch.default_offset() < 0) {\n+          _access_flags.set_has_loops();\n+        } else {\n+          for (int i = 0; i < tableswitch.length(); ++i) {\n+            if (tableswitch.dest_offset_at(i) < 0) {\n+              _access_flags.set_has_loops();\n+            }\n+          }\n+        }\n+        break;\n+      }\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":31,"deletions":3,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -294,0 +294,3 @@\n+  template <typename OopClosureType>\n+  inline void oop_iterate_backwards(OopClosureType* cl, Klass* klass);\n+\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -362,1 +362,7 @@\n-  OopIteratorClosureDispatch::oop_oop_iterate_backwards(cl, this, klass());\n+  oop_iterate_backwards(cl, klass());\n+}\n+\n+template <typename OopClosureType>\n+void oopDesc::oop_iterate_backwards(OopClosureType* cl, Klass* k) {\n+  assert(k == klass(), \"wrong klass\");\n+  OopIteratorClosureDispatch::oop_oop_iterate_backwards(cl, this, k);\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -56,2 +56,2 @@\n-          \"Seed for IGVN stress testing (if unset, a random one is \"        \\\n-          \"generated\")                                                      \\\n+          \"Seed for randomized stress testing (if unset, a random one is \"  \\\n+          \"generated)\")                                                     \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -499,0 +499,1 @@\n+  case vmIntrinsics::_indexOfL_char:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -475,1 +475,1 @@\n-      map->disconnect_inputs(NULL, C);\n+      map->disconnect_inputs(C);\n@@ -517,1 +517,0 @@\n-    C->set_has_loops(C->has_loops() || _inline_cg->method()->has_loops());\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -319,2 +319,8 @@\n-bool RegionNode::is_unreachable_region(PhaseGVN *phase) const {\n-  assert(req() == 2, \"\");\n+bool RegionNode::is_unreachable_region(const PhaseGVN* phase) {\n+  Node* top = phase->C->top();\n+  assert(req() == 2 || (req() == 3 && in(1) != NULL && in(2) == top), \"sanity check arguments\");\n+  if (_is_unreachable_region) {\n+    \/\/ Return cached result from previous evaluation which should still be valid\n+    assert(is_unreachable_from_root(phase), \"walk the graph again and check if its indeed unreachable\");\n+    return true;\n+  }\n@@ -324,0 +330,11 @@\n+  if (is_possible_unsafe_loop(phase)) {\n+    \/\/ If we have a possible unsafe loop, check if the region node is actually unreachable from root.\n+    if (is_unreachable_from_root(phase)) {\n+      _is_unreachable_region = true;\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+bool RegionNode::is_possible_unsafe_loop(const PhaseGVN* phase) const {\n@@ -327,4 +344,5 @@\n-    Node* phi = raw_out(i);\n-    if (phi != NULL && phi->is_Phi()) {\n-      assert(phase->eqv(phi->in(0), this) && phi->req() == 2, \"\");\n-      if (phi->outcnt() == 0)\n+    Node* n = raw_out(i);\n+    if (n != NULL && n->is_Phi()) {\n+      PhiNode* phi = n->as_Phi();\n+      assert(phase->eqv(phi->in(0), this), \"sanity check phi\");\n+      if (phi->outcnt() == 0) {\n@@ -332,0 +350,1 @@\n+      }\n@@ -336,1 +355,1 @@\n-        if (u != NULL && (u->is_Phi() || u->is_CFG()))\n+        if (u != NULL && (u->is_Phi() || u->is_CFG())) {\n@@ -338,0 +357,1 @@\n+        }\n@@ -340,1 +360,1 @@\n-      if (phi->as_Phi()->simple_data_loop_check(phi->in(1)) >= PhiNode::Unsafe)\n+      if (phi->as_Phi()->simple_data_loop_check(phi->in(1)) >= PhiNode::Unsafe) {\n@@ -342,0 +362,1 @@\n+      }\n@@ -344,1 +365,1 @@\n-  if (i >= max)\n+  if (i >= max) {\n@@ -346,0 +367,3 @@\n+  }\n+  return true;\n+}\n@@ -347,1 +371,1 @@\n-  \/\/ Unsafe case - check if the Region node is reachable from root.\n+bool RegionNode::is_unreachable_from_root(const PhaseGVN* phase) const {\n@@ -349,1 +373,0 @@\n-\n@@ -371,1 +394,0 @@\n-\n@@ -828,1 +850,2 @@\n-             cmp2->Opcode() == Op_CmpP || cmp2->Opcode() == Op_CmpN) {\n+             cmp2->Opcode() == Op_CmpP || cmp2->Opcode() == Op_CmpN ||\n+             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck()) {\n@@ -830,0 +853,1 @@\n+    \/\/ SubTypeCheck is not commutative\n@@ -1958,10 +1982,1 @@\n-      \/\/ First, take the short cut when we know it is a loop and\n-      \/\/ the EntryControl data path is dead.\n-      \/\/ Loop node may have only one input because entry path\n-      \/\/ is removed in PhaseIdealLoop::Dominators().\n-      assert(!r->is_Loop() || r->req() <= 3, \"Loop node should have 3 or less inputs\");\n-      bool is_loop = (r->is_Loop() && r->req() == 3);\n-      \/\/ Then, check if there is a data loop when phi references itself directly\n-      \/\/ or through other data nodes.\n-      if ((is_loop && !uin->eqv_uncast(in(LoopNode::EntryControl))) ||\n-          (!is_loop && is_unsafe_data_reference(uin))) {\n+      if (is_data_loop(r->as_Region(), uin, phase)) {\n@@ -2410,0 +2425,16 @@\n+bool PhiNode::is_data_loop(RegionNode* r, Node* uin, const PhaseGVN* phase) {\n+  \/\/ First, take the short cut when we know it is a loop and the EntryControl data path is dead.\n+  \/\/ The loop node may only have one input because the entry path was removed in PhaseIdealLoop::Dominators().\n+  \/\/ Then, check if there is a data loop when the phi references itself directly or through other data nodes.\n+  assert(!r->is_Loop() || r->req() <= 3, \"Loop node should have 3 or less inputs\");\n+  const bool is_loop = (r->is_Loop() && r->req() == 3);\n+  const Node* top = phase->C->top();\n+  if (is_loop) {\n+    return !uin->eqv_uncast(in(LoopNode::EntryControl));\n+  } else {\n+    \/\/ We have a data loop either with an unsafe data reference or if a region is unreachable.\n+    return is_unsafe_data_reference(uin)\n+           || (r->req() == 3 && (r->in(1) != top && r->in(2) == top && r->is_unreachable_region(phase)));\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":54,"deletions":23,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -67,0 +67,5 @@\n+private:\n+  bool _is_unreachable_region;\n+\n+  bool is_possible_unsafe_loop(const PhaseGVN* phase) const;\n+  bool is_unreachable_from_root(const PhaseGVN* phase) const;\n@@ -73,1 +78,1 @@\n-  RegionNode( uint required ) : Node(required) {\n+  RegionNode(uint required) : Node(required), _is_unreachable_region(false) {\n@@ -75,1 +80,1 @@\n-    init_req(0,this);\n+    init_req(0, this);\n@@ -87,1 +92,1 @@\n-  bool is_unreachable_region(PhaseGVN *phase) const;\n+  bool is_unreachable_region(const PhaseGVN* phase);\n@@ -89,3 +94,4 @@\n-  virtual bool pinned() const { return (const Node *)in(0) == this; }\n-  virtual bool  is_CFG   () const { return true; }\n-  virtual uint hash() const { return NO_HASH; }  \/\/ CFG nodes do not hash\n+  virtual uint size_of() const { return sizeof(*this); }\n+  virtual bool pinned() const { return (const Node*)in(0) == this; }\n+  virtual bool is_CFG() const { return true; }\n+  virtual uint hash() const { return NO_HASH; } \/\/ CFG nodes do not hash\n@@ -93,1 +99,1 @@\n-  virtual const Type *bottom_type() const { return Type::CONTROL; }\n+  virtual const Type* bottom_type() const { return Type::CONTROL; }\n@@ -96,1 +102,1 @@\n-  virtual Node *Ideal(PhaseGVN *phase, bool can_reshape);\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -137,0 +143,1 @@\n+  bool is_data_loop(RegionNode* r, Node* uin, const PhaseGVN* phase);\n","filename":"src\/hotspot\/share\/opto\/cfgnode.hpp","additions":15,"deletions":8,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -738,3 +738,3 @@\n-  \/\/ If IGVN is randomized for stress testing, seed random number\n-  \/\/ generation and log the seed for repeatability.\n-  if (StressIGVN) {\n+  \/\/ If LCM, GCM, or IGVN are randomized for stress testing, seed\n+  \/\/ random number generation and log the seed for repeatability.\n+  if (StressLCM || StressGCM || StressIGVN) {\n@@ -935,1 +935,1 @@\n-  set_has_loops(has_method() && method()->has_loops()); \/\/ first approximation\n+  set_has_loops(false); \/\/ first approximation\n@@ -1039,0 +1039,1 @@\n+  _exception_backedge = false;\n@@ -3192,1 +3193,1 @@\n-        mem->disconnect_inputs(NULL, this);\n+        mem->disconnect_inputs(this);\n@@ -3475,1 +3476,1 @@\n-            addp->disconnect_inputs(NULL, this);\n+            addp->disconnect_inputs(this);\n@@ -3548,1 +3549,1 @@\n-        in1->disconnect_inputs(NULL, this);\n+        in1->disconnect_inputs(this);\n@@ -3553,1 +3554,1 @@\n-        n->disconnect_inputs(NULL, this);\n+        n->disconnect_inputs(this);\n@@ -3631,1 +3632,1 @@\n-          in1->disconnect_inputs(NULL, this);\n+          in1->disconnect_inputs(this);\n@@ -3634,1 +3635,1 @@\n-          in2->disconnect_inputs(NULL, this);\n+          in2->disconnect_inputs(this);\n@@ -3665,1 +3666,1 @@\n-      in1->disconnect_inputs(NULL, this);\n+      in1->disconnect_inputs(this);\n@@ -3831,1 +3832,1 @@\n-        in2->disconnect_inputs(NULL, this);\n+        in2->disconnect_inputs(this);\n@@ -3863,1 +3864,1 @@\n-          m->disconnect_inputs(NULL, this);\n+          m->disconnect_inputs(this);\n@@ -4014,1 +4015,1 @@\n-          in->disconnect_inputs(NULL, this);\n+          in->disconnect_inputs(this);\n@@ -4941,1 +4942,1 @@\n-  return (os::random() & RANDOMIZED_DOMAIN_MASK) < (RANDOMIZED_DOMAIN \/ count);\n+  return (random() & RANDOMIZED_DOMAIN_MASK) < (RANDOMIZED_DOMAIN \/ count);\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":16,"deletions":15,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -437,0 +437,1 @@\n+  DEBUG_ONLY(bool _exception_backedge;)\n@@ -1163,1 +1164,1 @@\n-  static bool randomized_select(int count);\n+  bool randomized_select(int count);\n@@ -1190,0 +1191,2 @@\n+  void set_exception_backedge() { _exception_backedge = true; }\n+  bool has_exception_backedge() const { return _exception_backedge; }\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,0 +42,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -666,1 +667,0 @@\n-    C->set_has_loops(C->has_loops() || cg->method()->has_loops());\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -178,1 +178,1 @@\n-    dead_map->disconnect_inputs(NULL, C); \/\/ Mark the map as killed.\n+    dead_map->disconnect_inputs(C); \/\/ Mark the map as killed.\n@@ -2064,1 +2064,1 @@\n-  call->disconnect_inputs(NULL, C);\n+  call->disconnect_inputs(C);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -477,1 +477,1 @@\n-      in->disconnect_inputs(NULL, C);\n+      in->disconnect_inputs(C);\n@@ -660,1 +660,1 @@\n-         ((StressLCM && Compile::randomized_select(cand_cnt)) ||\n+         ((StressLCM && C->randomized_select(cand_cnt)) ||\n@@ -1397,1 +1397,1 @@\n-    block->get_node(beg)->disconnect_inputs(NULL, C);\n+    block->get_node(beg)->disconnect_inputs(C);\n@@ -1410,1 +1410,1 @@\n-        n->disconnect_inputs(NULL, C);\n+        n->disconnect_inputs(C);\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -254,1 +254,1 @@\n-  bool inline_string_indexOfChar();\n+  bool inline_string_indexOfChar(StrIntrinsicNode::ArgEnc ae);\n@@ -628,1 +628,2 @@\n-  case vmIntrinsics::_indexOfU_char:            return inline_string_indexOfChar();\n+  case vmIntrinsics::_indexOfU_char:            return inline_string_indexOfChar(StrIntrinsicNode::U);\n+  case vmIntrinsics::_indexOfL_char:            return inline_string_indexOfChar(StrIntrinsicNode::L);\n@@ -1472,1 +1473,1 @@\n-bool LibraryCallKit::inline_string_indexOfChar() {\n+bool LibraryCallKit::inline_string_indexOfChar(StrIntrinsicNode::ArgEnc ae) {\n@@ -1487,1 +1488,1 @@\n-  Node* src_offset = _gvn.transform(new LShiftINode(from_index, intcon(1)));\n+  Node* src_offset = ae == StrIntrinsicNode::L ? from_index : _gvn.transform(new LShiftINode(from_index, intcon(1)));\n@@ -1492,1 +1493,1 @@\n-  generate_string_range_check(src, src_offset, src_count, true);\n+  generate_string_range_check(src, src_offset, src_count, ae == StrIntrinsicNode::U);\n@@ -1500,1 +1501,1 @@\n-  Node* result = new StrIndexOfCharNode(control(), memory(TypeAryPtr::BYTES), src_start, src_count, tgt, StrIntrinsicNode::none);\n+  Node* result = new StrIndexOfCharNode(control(), memory(TypeAryPtr::BYTES), src_start, src_count, tgt, ae);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -475,0 +475,2 @@\n+\n+  bool is_expanded(PhaseGVN *phase) const;\n@@ -809,0 +811,3 @@\n+#ifdef ASSERT\n+  bool only_has_infinite_loops();\n+#endif\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2582,1 +2582,1 @@\n-  _fallthroughproj->disconnect_inputs(NULL, C);\n+  _fallthroughproj->disconnect_inputs(C);\n@@ -2650,1 +2650,1 @@\n-  _fallthroughproj->disconnect_inputs(NULL, C);\n+  _fallthroughproj->disconnect_inputs(C);\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -589,1 +589,2 @@\n-  \/\/ Eagerly reclaim unique Node numberings\n+  \/\/ If this is the most recently created node, reclaim its index. Otherwise,\n+  \/\/ record the node as dead to keep liveness information accurate.\n@@ -593,0 +594,2 @@\n+  } else {\n+    compile->record_dead_node(_idx);\n@@ -900,9 +903,5 @@\n-\/\/ Return the number of edges between 'n' and 'this'\n-int Node::disconnect_inputs(Node *n, Compile* C) {\n-  int edges_to_n = 0;\n-\n-  uint cnt = req();\n-  for( uint i = 0; i < cnt; ++i ) {\n-    if( in(i) == 0 ) continue;\n-    if( in(i) == n ) ++edges_to_n;\n-    set_req(i, NULL);\n+void Node::disconnect_inputs(Compile* C) {\n+  for (uint i = 0; i < req(); ++i) {\n+    if (in(i) != nullptr) {\n+      set_req(i, nullptr);\n+    }\n@@ -910,0 +909,1 @@\n+\n@@ -912,7 +912,2 @@\n-  if( (req() != len()) && (in(req()) != NULL) ) {\n-    uint max = len();\n-    for( uint i = 0; i < max; ++i ) {\n-      if( in(i) == 0 ) continue;\n-      if( in(i) == n ) ++edges_to_n;\n-      set_prec(i, NULL);\n-    }\n+  for (uint i = req(); i < len(); ++i) {\n+    set_prec(i, nullptr);\n@@ -923,4 +918,1 @@\n-  if (edges_to_n == 0) {\n-    C->record_dead_node(_idx);\n-  }\n-  return edges_to_n;\n+  C->record_dead_node(_idx);\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":13,"deletions":21,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -454,2 +454,1 @@\n-  \/\/ Return the number of edges between 'n' and 'this'\n-  int  disconnect_inputs(Node *n, Compile *c);\n+  void disconnect_inputs(Compile* C);\n@@ -525,1 +524,1 @@\n-    disconnect_inputs(NULL, c);\n+    disconnect_inputs(c);\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -227,0 +227,66 @@\n+volatile int C2SafepointPollStubTable::_stub_size = 0;\n+\n+Label& C2SafepointPollStubTable::add_safepoint(uintptr_t safepoint_offset) {\n+  C2SafepointPollStub* entry = new (Compile::current()->comp_arena()) C2SafepointPollStub(safepoint_offset);\n+  _safepoints.append(entry);\n+  return entry->_stub_label;\n+}\n+\n+void C2SafepointPollStubTable::emit(CodeBuffer& cb) {\n+  MacroAssembler masm(&cb);\n+  for (int i = _safepoints.length() - 1; i >= 0; i--) {\n+    \/\/ Make sure there is enough space in the code buffer\n+    if (cb.insts()->maybe_expand_to_ensure_remaining(PhaseOutput::MAX_inst_size) && cb.blob() == NULL) {\n+      ciEnv::current()->record_failure(\"CodeCache is full\");\n+      return;\n+    }\n+\n+    C2SafepointPollStub* entry = _safepoints.at(i);\n+    emit_stub(masm, entry);\n+  }\n+}\n+\n+int C2SafepointPollStubTable::stub_size_lazy() const {\n+  int size = Atomic::load(&_stub_size);\n+\n+  if (size != 0) {\n+    return size;\n+  }\n+\n+  Compile* const C = Compile::current();\n+  BufferBlob* const blob = C->output()->scratch_buffer_blob();\n+  CodeBuffer cb(blob->content_begin(), C->output()->scratch_buffer_code_size());\n+  MacroAssembler masm(&cb);\n+  C2SafepointPollStub* entry = _safepoints.at(0);\n+  emit_stub(masm, entry);\n+  size += cb.insts_size();\n+\n+  Atomic::store(&_stub_size, size);\n+\n+  return size;\n+}\n+\n+int C2SafepointPollStubTable::estimate_stub_size() const {\n+  if (_safepoints.length() == 0) {\n+    return 0;\n+  }\n+\n+  int result = stub_size_lazy() * _safepoints.length();\n+\n+#ifdef ASSERT\n+  Compile* const C = Compile::current();\n+  BufferBlob* const blob = C->output()->scratch_buffer_blob();\n+  int size = 0;\n+\n+  for (int i = _safepoints.length() - 1; i >= 0; i--) {\n+    CodeBuffer cb(blob->content_begin(), C->output()->scratch_buffer_code_size());\n+    MacroAssembler masm(&cb);\n+    C2SafepointPollStub* entry = _safepoints.at(i);\n+    emit_stub(masm, entry);\n+    size += cb.insts_size();\n+  }\n+  assert(size == result, \"stubs should not have variable size\");\n+#endif\n+\n+  return result;\n+}\n@@ -1290,0 +1356,1 @@\n+  stub_req += safepoint_poll_table()->estimate_stub_size();\n@@ -1794,0 +1861,4 @@\n+  \/\/ Fill in stubs for calling the runtime from safepoint polls.\n+  safepoint_poll_table()->emit(*cb);\n+  if (C->failing())  return;\n+\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":71,"deletions":0,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -28,0 +28,3 @@\n+#include \"code\/debugInfo.hpp\"\n+#include \"code\/exceptionHandlerTable.hpp\"\n+#include \"metaprogramming\/enableIf.hpp\"\n@@ -31,2 +34,1 @@\n-#include \"code\/debugInfo.hpp\"\n-#include \"code\/exceptionHandlerTable.hpp\"\n+#include \"runtime\/vm_version.hpp\"\n@@ -73,0 +75,41 @@\n+class C2SafepointPollStubTable {\n+private:\n+  struct C2SafepointPollStub: public ResourceObj {\n+    uintptr_t _safepoint_offset;\n+    Label     _stub_label;\n+    Label     _trampoline_label;\n+    C2SafepointPollStub(uintptr_t safepoint_offset) :\n+      _safepoint_offset(safepoint_offset),\n+      _stub_label(),\n+      _trampoline_label() {}\n+  };\n+\n+  GrowableArray<C2SafepointPollStub*> _safepoints;\n+\n+  static volatile int _stub_size;\n+\n+  void emit_stub_impl(MacroAssembler& masm, C2SafepointPollStub* entry) const;\n+\n+  \/\/ The selection logic below relieves the need to add dummy files to unsupported platforms.\n+  template <bool enabled>\n+  typename EnableIf<enabled>::type\n+  select_emit_stub(MacroAssembler& masm, C2SafepointPollStub* entry) const {\n+    emit_stub_impl(masm, entry);\n+  }\n+\n+  template <bool enabled>\n+  typename EnableIf<!enabled>::type\n+  select_emit_stub(MacroAssembler& masm, C2SafepointPollStub* entry) const {}\n+\n+  void emit_stub(MacroAssembler& masm, C2SafepointPollStub* entry) const {\n+    select_emit_stub<VM_Version::supports_stack_watermark_barrier()>(masm, entry);\n+  }\n+\n+  int stub_size_lazy() const;\n+\n+public:\n+  Label& add_safepoint(uintptr_t safepoint_offset);\n+  int estimate_stub_size() const;\n+  void emit(CodeBuffer& cb);\n+};\n+\n@@ -81,0 +124,1 @@\n+  C2SafepointPollStubTable _safepoint_poll_table;\/\/ Table for safepoint polls\n@@ -132,0 +176,3 @@\n+  \/\/ Safepoint poll table\n+  C2SafepointPollStubTable* safepoint_poll_table() { return &_safepoint_poll_table; }\n+\n@@ -179,0 +226,1 @@\n+  int               scratch_buffer_code_size()  { return (address)scratch_locs_memory() - _scratch_buffer_blob->content_begin(); }\n","filename":"src\/hotspot\/share\/opto\/output.hpp","additions":50,"deletions":2,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -444,0 +444,1 @@\n+  C->set_has_loops(C->has_loops() || method()->has_loops());\n@@ -1671,0 +1672,5 @@\n+#ifdef ASSERT\n+  if (target_bci < bci()) {\n+    C->set_exception_backedge();\n+  }\n+#endif\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -1295,1 +1296,0 @@\n-\n@@ -1353,1 +1353,1 @@\n-    bool force_unwind = !thread->reguard_stack();\n+    bool force_unwind = !thread->stack_overflow_state()->reguard_stack();\n@@ -1473,0 +1473,5 @@\n+  \/\/ The frame we rethrow the exception to might not have been processed by the GC yet.\n+  \/\/ The stack watermark barrier takes care of detecting that and ensuring the frame\n+  \/\/ has updated oops.\n+  StackWatermarkSet::after_unwind(thread);\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -252,1 +252,1 @@\n-      uct->disconnect_inputs(NULL, C);\n+      uct->disconnect_inputs(C);\n@@ -258,1 +258,1 @@\n-    _arguments->disconnect_inputs(NULL, _stringopts->C);\n+    _arguments->disconnect_inputs(_stringopts->C);\n@@ -376,1 +376,1 @@\n-  init->disconnect_inputs(NULL, C);\n+  init->disconnect_inputs(C);\n@@ -1213,0 +1213,1 @@\n+    C->set_has_loops(true);\n@@ -1290,0 +1291,1 @@\n+  C->set_has_loops(true);\n@@ -1984,1 +1986,1 @@\n-  string_sizes->disconnect_inputs(NULL, C);\n+  string_sizes->disconnect_inputs(C);\n","filename":"src\/hotspot\/share\/opto\/stringopts.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -4384,1 +4384,1 @@\n-  thread->create_stack_guard_pages();\n+  thread->stack_overflow_state()->create_stack_guard_pages();\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"classfile\/lambdaFormInvokers.hpp\"\n@@ -3757,1 +3758,1 @@\n-  if (thread->stack_available((address) &method_handle) >= JVMInvokeMethodSlack) {\n+  if (thread->stack_overflow_state()->stack_available((address) &method_handle) >= JVMInvokeMethodSlack) {\n@@ -3940,0 +3941,22 @@\n+JVM_ENTRY(jboolean, JVM_IsDumpingClassList(JNIEnv *env))\n+  JVMWrapper(\"JVM_IsDumpingClassList\");\n+#if INCLUDE_CDS\n+  return DumpLoadedClassList != NULL && classlist_file != NULL && classlist_file->is_open();\n+#else\n+  return false;\n+#endif \/\/ INCLUDE_CDS\n+JVM_END\n+\n+JVM_ENTRY(void, JVM_LogLambdaFormInvoker(JNIEnv *env, jstring line))\n+  JVMWrapper(\"JVM_LogLambdaFormInvoker\");\n+#if INCLUDE_CDS\n+  assert(DumpLoadedClassList != NULL && classlist_file->is_open(), \"Should be set and open\");\n+  if (line != NULL) {\n+    ResourceMark rm(THREAD);\n+    Handle h_line (THREAD, JNIHandles::resolve_non_null(line));\n+    char* c_line = java_lang_String::as_utf8_string(h_line());\n+    classlist_file->print_cr(\"%s %s\", LambdaFormInvokers::lambda_form_invoker_tag(), c_line);\n+  }\n+#endif \/\/ INCLUDE_CDS\n+JVM_END\n+\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":24,"deletions":1,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -1677,1 +1677,1 @@\n-    for (vframeStream vfs(java_thread, true); !vfs.at_end(); vfs.next()) {\n+    for (vframeStream vfs(java_thread, true, false \/* process_frames *\/); !vfs.at_end(); vfs.next()) {\n@@ -1689,1 +1689,1 @@\n-      if(vframeFor(java_thread, 1) == NULL) {\n+      if(vframeForNoProcess(java_thread, 1) == NULL) {\n@@ -1788,1 +1788,1 @@\n-  vframe *vf = vframeFor(java_thread, depth);\n+  vframe *vf = vframeForNoProcess(java_thread, depth);\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -559,0 +559,1 @@\n+\/\/ The thread and the oops in the returned vframe might not have been process.\n@@ -560,1 +561,1 @@\n-JvmtiEnvBase::vframeFor(JavaThread* java_thread, jint depth) {\n+JvmtiEnvBase::vframeForNoProcess(JavaThread* java_thread, jint depth) {\n@@ -564,1 +565,1 @@\n-  RegisterMap reg_map(java_thread);\n+  RegisterMap reg_map(java_thread, true \/* update_map *\/, false \/* process_frames *\/);\n@@ -912,1 +913,1 @@\n-  vframe *vf = vframeFor(java_thread, depth);\n+  vframe *vf = vframeForNoProcess(java_thread, depth);\n@@ -1317,1 +1318,1 @@\n-  vframe *vf = vframeFor(java_thread, 0);\n+  vframe *vf = vframeForNoProcess(java_thread, 0);\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnvBase.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -862,1 +862,1 @@\n-        for (StackFrameStream fst(t, false); !fst.is_done(); fst.next()) {\n+        for (StackFrameStream fst(t, false \/* update *\/, true \/* process_frames *\/); !fst.is_done(); fst.next()) {\n@@ -1690,1 +1690,2 @@\n-  return (jlong) thread->stack_available(os::current_stack_pointer()) - (jlong)JavaThread::stack_shadow_zone_size();\n+  return (jlong) thread->stack_overflow_state()->stack_available(\n+                   os::current_stack_pointer()) - (jlong)StackOverflow::stack_shadow_zone_size();\n@@ -1908,1 +1909,1 @@\n-  StackFrameStream sfs(thread);\n+  StackFrameStream sfs(thread, false \/* update *\/, true \/* process_frames *\/);\n@@ -2390,0 +2391,7 @@\n+WB_ENTRY(jstring, WB_GetLibcName(JNIEnv* env, jobject o))\n+  ThreadToNativeFromVM ttn(thread);\n+  jstring info_string = env->NewStringUTF(XSTR(LIBC));\n+  CHECK_JNI_EXCEPTION_(env, NULL);\n+  return info_string;\n+WB_END\n+\n@@ -2648,0 +2656,1 @@\n+  {CC\"getLibcName\",     CC\"()Ljava\/lang\/String;\",     (void*)&WB_GetLibcName},\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -3263,1 +3263,0 @@\n-  NOT_PRODUCT(UNSUPPORTED_OPTION(TraceProfileInterpreter));\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -67,0 +68,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -166,0 +168,7 @@\n+  if (exec_mode == Unpack_exception) {\n+    \/\/ When we get here, a callee has thrown an exception into a deoptimized\n+    \/\/ frame. That throw might have deferred stack watermark checking until\n+    \/\/ after unwinding. So we deal with such deferred requests here.\n+    StackWatermarkSet::after_unwind(thread);\n+  }\n+\n@@ -282,0 +291,4 @@\n+  \/\/ When we get here we are about to unwind the deoptee frame. In order to\n+  \/\/ catch not yet safe to use frames, the following stack watermark barrier\n+  \/\/ poll will make such frames safe to use.\n+  StackWatermarkSet::before_unwind(thread);\n@@ -1600,1 +1613,1 @@\n-    StackFrameStream sfs(thread, true);\n+    StackFrameStream sfs(thread, true \/* update *\/, true \/* process_frames *\/);\n@@ -1779,2 +1792,1 @@\n-      bool guard_pages_enabled = jt->stack_guards_enabled();\n-      if (!guard_pages_enabled) guard_pages_enabled = jt->reguard_stack();\n+      bool guard_pages_enabled = jt->stack_overflow_state()->reguard_stack_if_needed();\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":15,"deletions":3,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-RegisterMap::RegisterMap(JavaThread *thread, bool update_map) {\n+RegisterMap::RegisterMap(JavaThread *thread, bool update_map, bool process_frames) {\n@@ -63,0 +63,1 @@\n+  _process_frames = process_frames;\n@@ -75,0 +76,1 @@\n+  _process_frames        = map->process_frames();\n@@ -943,1 +945,2 @@\n-void frame::oops_code_blob_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* reg_map) const {\n+void frame::oops_code_blob_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* reg_map,\n+                              DerivedPointerIterationMode derived_mode) const {\n@@ -946,1 +949,1 @@\n-    OopMapSet::oops_do(this, reg_map, f);\n+    OopMapSet::oops_do(this, reg_map, f, derived_mode);\n@@ -1079,0 +1082,14 @@\n+void frame::oops_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map,\n+                    DerivedPointerIterationMode derived_mode) const {\n+  oops_do_internal(f, cf, map, true, derived_mode);\n+}\n+\n+void frame::oops_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map) const {\n+#if COMPILER2_OR_JVMCI\n+  oops_do_internal(f, cf, map, true, DerivedPointerTable::is_active() ?\n+                                     DerivedPointerIterationMode::_with_table :\n+                                     DerivedPointerIterationMode::_ignore);\n+#else\n+  oops_do_internal(f, cf, map, true, DerivedPointerIterationMode::_ignore);\n+#endif\n+}\n@@ -1080,1 +1097,2 @@\n-void frame::oops_do_internal(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map, bool use_interpreter_oop_map_cache) const {\n+void frame::oops_do_internal(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map,\n+                             bool use_interpreter_oop_map_cache, DerivedPointerIterationMode derived_mode) const {\n@@ -1093,1 +1111,1 @@\n-    oops_code_blob_do(f, cf, map);\n+    oops_code_blob_do(f, cf, map, derived_mode);\n@@ -1130,1 +1148,1 @@\n-  oops_do_internal(&VerifyOopClosure::verify_oop, NULL, map, false);\n+  oops_do_internal(&VerifyOopClosure::verify_oop, NULL, map, false, DerivedPointerIterationMode::_ignore);\n@@ -1263,1 +1281,1 @@\n-StackFrameStream::StackFrameStream(JavaThread *thread, bool update) : _reg_map(thread, update) {\n+StackFrameStream::StackFrameStream(JavaThread *thread, bool update, bool process_frames) : _reg_map(thread, update, process_frames) {\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":25,"deletions":7,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -44,0 +44,5 @@\n+enum class DerivedPointerIterationMode {\n+  _with_table,\n+  _directly,\n+  _ignore\n+};\n@@ -370,1 +375,2 @@\n-  void oops_do_internal(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map, bool use_interpreter_oop_map_cache) const;\n+  void oops_do_internal(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map,\n+                        bool use_interpreter_oop_map_cache, DerivedPointerIterationMode derived_mode) const;\n@@ -372,1 +378,2 @@\n-  void oops_code_blob_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map) const;\n+  void oops_code_blob_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map,\n+                         DerivedPointerIterationMode derived_mode) const;\n@@ -376,1 +383,3 @@\n-  void oops_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map) const { oops_do_internal(f, cf, map, true); }\n+  void oops_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map,\n+               DerivedPointerIterationMode derived_mode) const;\n+  void oops_do(OopClosure* f, CodeBlobClosure* cf, const RegisterMap* map) const;\n@@ -443,2 +452,7 @@\n-\/\/ all (callee-saved) registers. Notice: If a thread is stopped at\n-\/\/ a safepoint, all registers are saved, not only the callee-saved ones.\n+\/\/ all (callee-saved) registers iff the update flag is set. It also\n+\/\/ automatically takes care of lazily applying deferred GC processing\n+\/\/ onto exposed frames, such that all oops are valid iff the process_frames\n+\/\/ flag is set.\n+\/\/\n+\/\/ Notice: If a thread is stopped at a safepoint, all registers are saved,\n+\/\/ not only the callee-saved ones.\n@@ -448,1 +462,3 @@\n-\/\/   for(StackFrameStream fst(thread); !fst.is_done(); fst.next()) {\n+\/\/   for(StackFrameStream fst(thread, true \/* update *\/, true \/* process_frames *\/);\n+\/\/       !fst.is_done();\n+\/\/       fst.next()) {\n@@ -458,1 +474,1 @@\n-   StackFrameStream(JavaThread *thread, bool update = true);\n+  StackFrameStream(JavaThread *thread, bool update, bool process_frames);\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":23,"deletions":7,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -289,4 +289,0 @@\n-  notproduct(bool, StressDerivedPointers, false,                            \\\n-          \"Force scavenge when a derived pointer is detected on stack \"     \\\n-          \"after rtm call\")                                                 \\\n-                                                                            \\\n@@ -480,3 +476,0 @@\n-  develop(bool, PrintVMMessages, true,                                      \\\n-          \"Print VM messages on console\")                                   \\\n-                                                                            \\\n@@ -1349,5 +1342,0 @@\n-  develop(bool, TraceProfileInterpreter, false,                             \\\n-          \"Trace profiling at the bytecode level during interpretation. \"   \\\n-          \"This outputs the profiling information collected to improve \"    \\\n-          \"jit compilation.\")                                               \\\n-                                                                            \\\n@@ -1368,4 +1356,0 @@\n-  develop(bool, VerifyCompiledCode, false,                                  \\\n-          \"Include miscellaneous runtime verifications in nmethod code; \"   \\\n-          \"default off because it disturbs nmethod size heuristics\")        \\\n-                                                                            \\\n@@ -1579,4 +1563,0 @@\n-  develop(intx, ProfilerNodeSize,  1024,                                    \\\n-          \"Size in K to allocate for the Profile Nodes of each thread\")     \\\n-          range(0, 1024)                                                    \\\n-                                                                            \\\n@@ -1824,1 +1804,1 @@\n-   product(ccstr, InlineDataFile, NULL,                                     \\\n+  product(ccstr, InlineDataFile, NULL,                                      \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":1,"deletions":21,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -140,0 +140,8 @@\n+\n+  if (_thread->has_pending_exception() && _thread->has_last_Java_frame()) {\n+    \/\/ If we get here, the Java code threw an exception that unwound a frame.\n+    \/\/ It could be that the new frame anchor has not passed through the required\n+    \/\/ StackWatermark barriers. Therefore, we process any such deferred unwind\n+    \/\/ requests here.\n+    StackWatermarkSet::after_unwind(_thread);\n+  }\n@@ -397,3 +405,1 @@\n-  if (!thread->stack_guards_enabled()) {\n-    thread->reguard_stack();\n-  }\n+  thread->stack_overflow_state()->reguard_stack_if_needed();\n","filename":"src\/hotspot\/share\/runtime\/javaCalls.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -62,0 +62,1 @@\n+#include \"runtime\/stackWatermarkSet.inline.hpp\"\n@@ -501,0 +502,9 @@\n+class ParallelSPCleanupThreadClosure : public ThreadClosure {\n+public:\n+  void do_thread(Thread* thread) {\n+    if (thread->is_Java_thread()) {\n+      StackWatermarkSet::start_processing(thread->as_Java_thread(), StackWatermarkKind::gc);\n+    }\n+  }\n+};\n+\n@@ -505,0 +515,1 @@\n+  bool _do_lazy_roots;\n@@ -526,1 +537,3 @@\n-    _num_workers(num_workers) {}\n+    _num_workers(num_workers),\n+    _do_lazy_roots(!VMThread::vm_operation()->skip_thread_oop_barriers() &&\n+                   Universe::heap()->uses_stack_watermark_barrier()) {}\n@@ -529,0 +542,6 @@\n+    if (_do_lazy_roots && _subtasks.try_claim_task(SafepointSynchronize::SAFEPOINT_CLEANUP_LAZY_ROOT_PROCESSING)) {\n+      Tracer t(\"lazy partial thread root processing\");\n+      ParallelSPCleanupThreadClosure cl;\n+      Threads::threads_do(&cl);\n+    }\n+\n@@ -777,1 +796,1 @@\n-  \/\/ cross_modify_fence is done by SafepointMechanism::process_operation_if_requested_slow\n+  \/\/ cross_modify_fence is done by SafepointMechanism::process_if_requested\n@@ -940,1 +959,1 @@\n-  RegisterMap map(thread(), true);\n+  RegisterMap map(thread(), true, false);\n@@ -989,0 +1008,5 @@\n+    \/\/ We get here if compiled return polls found a reason to call into the VM.\n+    \/\/ One condition for that is that the top frame is not yet safe to use.\n+    \/\/ The following stack watermark barrier poll will catch such situations.\n+    StackWatermarkSet::after_unwind(thread());\n+\n@@ -1023,1 +1047,1 @@\n-      RegisterMap map(thread(), true);\n+      RegisterMap map(thread(), true, false);\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":28,"deletions":4,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -72,0 +72,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -460,0 +461,6 @@\n+  \/\/ Note: This is called when we have unwound the frame of the callee that did\n+  \/\/ throw an exception. So far, no check has been performed by the StackWatermarkSet.\n+  \/\/ Notably, the stack is not walkable at this point, and hence the check must\n+  \/\/ be deferred until later. Specifically, any of the handlers returned here in\n+  \/\/ this function, will get dispatched to, and call deferred checks to\n+  \/\/ StackWatermarkSet::after_unwind at a point where the stack is walkable.\n@@ -486,4 +493,4 @@\n-      bool guard_pages_enabled = thread->stack_guards_enabled();\n-      if (!guard_pages_enabled) guard_pages_enabled = thread->reguard_stack();\n-      if (thread->reserved_stack_activation() != thread->stack_base()) {\n-        thread->set_reserved_stack_activation(thread->stack_base());\n+      StackOverflow* overflow_state = thread->stack_overflow_state();\n+      bool guard_pages_enabled = overflow_state->reguard_stack_if_needed();\n+      if (overflow_state->reserved_stack_activation() != thread->stack_base()) {\n+        overflow_state->set_reserved_stack_activation(thread->stack_base());\n@@ -492,0 +499,2 @@\n+      \/\/ The deferred StackWatermarkSet::after_unwind check will be performed in\n+      \/\/ Deoptimization::fetch_unroll_info (with exec_mode == Unpack_exception)\n@@ -494,0 +503,3 @@\n+      \/\/ The deferred StackWatermarkSet::after_unwind check will be performed in\n+      \/\/ * OptoRuntime::rethrow_C for C2 code\n+      \/\/ * exception_handler_for_pc_helper via Runtime1::handle_exception_from_callee_id for C1 code\n@@ -500,0 +512,2 @@\n+    \/\/ The deferred StackWatermarkSet::after_unwind check will be performed in\n+    \/\/ JavaCallWrapper::~JavaCallWrapper\n@@ -504,0 +518,2 @@\n+    \/\/ The deferred StackWatermarkSet::after_unwind check will be performed in\n+    \/\/ InterpreterRuntime::exception_handler_for_exception\n@@ -2138,1 +2154,1 @@\n-  (void) JavaThread::current()->reguard_stack();\n+  (void) JavaThread::current()->stack_overflow_state()->reguard_stack();\n@@ -3336,0 +3352,6 @@\n+  \/\/ During OSR migration, we unwind the interpreted frame and replace it with a compiled\n+  \/\/ frame. The stack watermark code below ensures that the interpreted frame is processed\n+  \/\/ before it gets unwound. This is helpful as the size of the compiled frame could be\n+  \/\/ larger than the interpreted frame, which could result in the new frame not being\n+  \/\/ processed correctly.\n+  StackWatermarkSet::before_unwind(thread);\n@@ -3472,4 +3494,3 @@\n-  if (thread->stack_reserved_zone_disabled()) {\n-    thread->enable_stack_reserved_zone();\n-  }\n-  thread->set_reserved_stack_activation(thread->stack_base());\n+  StackOverflow* overflow_state = thread->stack_overflow_state();\n+  overflow_state->enable_stack_reserved_zone(\/*check_if_disabled*\/true);\n+  overflow_state->set_reserved_stack_activation(thread->stack_base());\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":30,"deletions":9,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -94,0 +94,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -356,2 +357,1 @@\n-    as_Java_thread()->set_stack_overflow_limit();\n-    as_Java_thread()->set_reserved_stack_activation(stack_base());\n+    as_Java_thread()->stack_overflow_state()->initialize(stack_base(), stack_end());\n@@ -873,1 +873,1 @@\n-void Thread::oops_do(OopClosure* f, CodeBlobClosure* cf) {\n+void Thread::oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf) {\n@@ -882,0 +882,31 @@\n+\/\/ If the caller is a NamedThread, then remember, in the current scope,\n+\/\/ the given JavaThread in its _processed_thread field.\n+class RememberProcessedThread: public StackObj {\n+  NamedThread* _cur_thr;\n+public:\n+  RememberProcessedThread(Thread* thread) {\n+    Thread* self = Thread::current();\n+    if (self->is_Named_thread()) {\n+      _cur_thr = (NamedThread *)self;\n+      assert(_cur_thr->processed_thread() == NULL, \"nesting not supported\");\n+      _cur_thr->set_processed_thread(thread);\n+    } else {\n+      _cur_thr = NULL;\n+    }\n+  }\n+\n+  ~RememberProcessedThread() {\n+    if (_cur_thr) {\n+      assert(_cur_thr->processed_thread() != NULL, \"nesting not supported\");\n+      _cur_thr->set_processed_thread(NULL);\n+    }\n+  }\n+};\n+\n+void Thread::oops_do(OopClosure* f, CodeBlobClosure* cf) {\n+  \/\/ Record JavaThread to GC thread\n+  RememberProcessedThread rpt(this);\n+  oops_do_no_frames(f, cf);\n+  oops_do_frames(f, cf);\n+}\n+\n@@ -1666,1 +1697,1 @@\n-void JavaThread::initialize() {\n+JavaThread::JavaThread() :\n@@ -1669,3 +1700,67 @@\n-  set_saved_exception_pc(NULL);\n-  _anchor.clear();\n-  set_entry_point(NULL);\n+  _on_thread_list(false),\n+  DEBUG_ONLY(_java_call_counter(0) COMMA)\n+  _entry_point(nullptr),\n+  _deopt_mark(nullptr),\n+  _deopt_nmethod(nullptr),\n+  _vframe_array_head(nullptr),\n+  _vframe_array_last(nullptr),\n+  _deferred_locals_updates(nullptr),\n+  _callee_target(nullptr),\n+  _vm_result(nullptr),\n+  _vm_result_2(nullptr),\n+  _return_buffered_value(nullptr),\n+\n+  _monitor_chunks(nullptr),\n+  _special_runtime_exit_condition(_no_async_condition),\n+  _pending_async_exception(nullptr),\n+\n+  _thread_state(_thread_new),\n+  _saved_exception_pc(nullptr),\n+\n+  _terminated(_not_terminated),\n+  _suspend_equivalent(false),\n+  _in_deopt_handler(0),\n+  _doing_unsafe_access(false),\n+  _do_not_unlock_if_synchronized(false),\n+  _jni_attach_state(_not_attaching_via_jni),\n+#if INCLUDE_JVMCI\n+  _pending_deoptimization(-1),\n+  _pending_monitorenter(false),\n+  _pending_transfer_to_interpreter(false),\n+  _in_retryable_allocation(false),\n+  _pending_failed_speculation(0),\n+  _jvmci{nullptr},\n+  _jvmci_counters(nullptr),\n+#endif \/\/ INCLUDE_JVMCI\n+\n+  _exception_oop(oop()),\n+  _exception_pc(0),\n+  _exception_handler_pc(0),\n+  _is_method_handle_return(0),\n+\n+  _jni_active_critical(0),\n+  _pending_jni_exception_check_fn(nullptr),\n+  _depth_first_number(0),\n+\n+  \/\/ JVMTI PopFrame support\n+  _popframe_condition(popframe_inactive),\n+  _frames_to_pop_failed_realloc(0),\n+\n+  _handshake(this),\n+\n+  _popframe_preserved_args(nullptr),\n+  _popframe_preserved_args_size(0),\n+\n+  _jvmti_thread_state(nullptr),\n+  _interp_only_mode(0),\n+  _should_post_on_exceptions_flag(JNI_FALSE),\n+  _thread_stat(new ThreadStatistics()),\n+\n+  _parker(Parker::Allocate(this)),\n+  _cached_monitor_info(nullptr),\n+\n+  _class_to_be_initialized(nullptr),\n+\n+  _SleepEvent(ParkEvent::Allocate(this))\n+{\n+\n@@ -1673,25 +1768,1 @@\n-  set_callee_target(NULL);\n-  set_vm_result(NULL);\n-  set_vm_result_2(NULL);\n-  set_return_buffered_value(NULL);\n-  set_vframe_array_head(NULL);\n-  set_vframe_array_last(NULL);\n-  set_deferred_locals(NULL);\n-  set_deopt_mark(NULL);\n-  set_deopt_compiled_method(NULL);\n-  set_monitor_chunks(NULL);\n-  _on_thread_list = false;\n-  _thread_state = _thread_new;\n-  _terminated = _not_terminated;\n-  _suspend_equivalent = false;\n-  _in_deopt_handler = 0;\n-  _doing_unsafe_access = false;\n-  _stack_guard_state = stack_guard_unused;\n-  _pending_monitorenter = false;\n-  _pending_deoptimization = -1;\n-  _pending_failed_speculation = 0;\n-  _pending_transfer_to_interpreter = false;\n-  _in_retryable_allocation = false;\n-  _jvmci._alternate_call_target = NULL;\n-  assert(_jvmci._implicit_exception_pc == NULL, \"must be\");\n-  _jvmci_counters = NULL;\n+  assert(_jvmci._implicit_exception_pc == nullptr, \"must be\");\n@@ -1703,18 +1774,1 @@\n-  _reserved_stack_activation = NULL;  \/\/ stack base not known yet\n-  set_exception_oop(oop());\n-  _exception_pc  = 0;\n-  _exception_handler_pc = 0;\n-  _is_method_handle_return = 0;\n-  _jvmti_thread_state= NULL;\n-  _should_post_on_exceptions_flag = JNI_FALSE;\n-  _interp_only_mode    = 0;\n-  _special_runtime_exit_condition = _no_async_condition;\n-  _pending_async_exception = NULL;\n-  _thread_stat = NULL;\n-  _thread_stat = new ThreadStatistics();\n-  _jni_active_critical = 0;\n-  _pending_jni_exception_check_fn = NULL;\n-  _do_not_unlock_if_synchronized = false;\n-  _cached_monitor_info = NULL;\n-  _parker = Parker::Allocate(this);\n-  _SleepEvent = ParkEvent::Allocate(this);\n+\n@@ -1724,11 +1778,1 @@\n-  debug_only(_java_call_counter = 0);\n-\n-  \/\/ JVMTI PopFrame support\n-  _popframe_condition = popframe_inactive;\n-  _popframe_preserved_args = NULL;\n-  _popframe_preserved_args_size = 0;\n-  _frames_to_pop_failed_realloc = 0;\n-\n-\n-  _class_to_be_initialized = NULL;\n-\n+  assert(deferred_card_mark().is_empty(), \"Default MemRegion ctor\");\n@@ -1739,3 +1783,1 @@\n-JavaThread::JavaThread(bool is_attaching_via_jni) :\n-                       Thread(), _handshake(this) {\n-  initialize();\n+JavaThread::JavaThread(bool is_attaching_via_jni) : JavaThread() {\n@@ -1744,3 +1786,0 @@\n-  } else {\n-    _jni_attach_state = _not_attaching_via_jni;\n-  assert(deferred_card_mark().is_empty(), \"Default MemRegion ctor\");\n@@ -1808,29 +1847,0 @@\n-bool JavaThread::reguard_stack(address cur_sp) {\n-  if (_stack_guard_state != stack_guard_yellow_reserved_disabled\n-      && _stack_guard_state != stack_guard_reserved_disabled) {\n-    return true; \/\/ Stack already guarded or guard pages not needed.\n-  }\n-\n-  \/\/ Java code never executes within the yellow zone: the latter is only\n-  \/\/ there to provoke an exception during stack banging.  If java code\n-  \/\/ is executing there, either StackShadowPages should be larger, or\n-  \/\/ some exception code in c1, c2 or the interpreter isn't unwinding\n-  \/\/ when it should.\n-  guarantee(cur_sp > stack_reserved_zone_base(),\n-            \"not enough space to reguard - increase StackShadowPages\");\n-  if (_stack_guard_state == stack_guard_yellow_reserved_disabled) {\n-    enable_stack_yellow_reserved_zone();\n-    if (reserved_stack_activation() != stack_base()) {\n-      set_reserved_stack_activation(stack_base());\n-    }\n-  } else if (_stack_guard_state == stack_guard_reserved_disabled) {\n-    set_reserved_stack_activation(stack_base());\n-    enable_stack_reserved_zone();\n-  }\n-  return true;\n-}\n-\n-bool JavaThread::reguard_stack(void) {\n-  return reguard_stack(os::current_stack_pointer());\n-}\n-\n@@ -1854,3 +1864,1 @@\n-JavaThread::JavaThread(ThreadFunction entry_point, size_t stack_sz) :\n-                       Thread(), _handshake(this) {\n-  initialize();\n+JavaThread::JavaThread(ThreadFunction entry_point, size_t stack_sz) : JavaThread() {\n@@ -1940,1 +1948,1 @@\n-  this->initialize_tlab();\n+  initialize_tlab();\n@@ -1942,1 +1950,1 @@\n-  this->create_stack_guard_pages();\n+  _stack_overflow_state.create_stack_guard_pages();\n@@ -1944,1 +1952,1 @@\n-  this->cache_global_variables();\n+  cache_global_variables();\n@@ -1961,1 +1969,1 @@\n-  this->set_active_handles(JNIHandleBlock::allocate_block());\n+  set_active_handles(JNIHandleBlock::allocate_block());\n@@ -2180,1 +2188,1 @@\n-  remove_stack_guard_pages();\n+  _stack_overflow_state.remove_stack_guard_pages();\n@@ -2239,1 +2247,1 @@\n-  remove_stack_guard_pages();\n+  _stack_overflow_state.remove_stack_guard_pages();\n@@ -2652,0 +2660,5 @@\n+  \/\/ After returning from native, it could be that the stack frames are not\n+  \/\/ yet safe to use. We catch such situations in the subsequent stack watermark\n+  \/\/ barrier, which will trap unsafe stack frames.\n+  StackWatermarkSet::before_unwind(thread);\n+\n@@ -2702,181 +2715,0 @@\n-size_t JavaThread::_stack_red_zone_size = 0;\n-size_t JavaThread::_stack_yellow_zone_size = 0;\n-size_t JavaThread::_stack_reserved_zone_size = 0;\n-size_t JavaThread::_stack_shadow_zone_size = 0;\n-\n-void JavaThread::create_stack_guard_pages() {\n-  if (!os::uses_stack_guard_pages() ||\n-      _stack_guard_state != stack_guard_unused ||\n-      (DisablePrimordialThreadGuardPages && os::is_primordial_thread())) {\n-      log_info(os, thread)(\"Stack guard page creation for thread \"\n-                           UINTX_FORMAT \" disabled\", os::current_thread_id());\n-    return;\n-  }\n-  address low_addr = stack_end();\n-  size_t len = stack_guard_zone_size();\n-\n-  assert(is_aligned(low_addr, os::vm_page_size()), \"Stack base should be the start of a page\");\n-  assert(is_aligned(len, os::vm_page_size()), \"Stack size should be a multiple of page size\");\n-\n-  int must_commit = os::must_commit_stack_guard_pages();\n-  \/\/ warning(\"Guarding at \" PTR_FORMAT \" for len \" SIZE_FORMAT \"\\n\", low_addr, len);\n-\n-  if (must_commit && !os::create_stack_guard_pages((char *) low_addr, len)) {\n-    log_warning(os, thread)(\"Attempt to allocate stack guard pages failed.\");\n-    return;\n-  }\n-\n-  if (os::guard_memory((char *) low_addr, len)) {\n-    _stack_guard_state = stack_guard_enabled;\n-  } else {\n-    log_warning(os, thread)(\"Attempt to protect stack guard pages failed (\"\n-      PTR_FORMAT \"-\" PTR_FORMAT \").\", p2i(low_addr), p2i(low_addr + len));\n-    if (os::uncommit_memory((char *) low_addr, len)) {\n-      log_warning(os, thread)(\"Attempt to deallocate stack guard pages failed.\");\n-    }\n-    return;\n-  }\n-\n-  log_debug(os, thread)(\"Thread \" UINTX_FORMAT \" stack guard pages activated: \"\n-    PTR_FORMAT \"-\" PTR_FORMAT \".\",\n-    os::current_thread_id(), p2i(low_addr), p2i(low_addr + len));\n-}\n-\n-void JavaThread::remove_stack_guard_pages() {\n-  assert(Thread::current() == this, \"from different thread\");\n-  if (_stack_guard_state == stack_guard_unused) return;\n-  address low_addr = stack_end();\n-  size_t len = stack_guard_zone_size();\n-\n-  if (os::must_commit_stack_guard_pages()) {\n-    if (os::remove_stack_guard_pages((char *) low_addr, len)) {\n-      _stack_guard_state = stack_guard_unused;\n-    } else {\n-      log_warning(os, thread)(\"Attempt to deallocate stack guard pages failed (\"\n-        PTR_FORMAT \"-\" PTR_FORMAT \").\", p2i(low_addr), p2i(low_addr + len));\n-      return;\n-    }\n-  } else {\n-    if (_stack_guard_state == stack_guard_unused) return;\n-    if (os::unguard_memory((char *) low_addr, len)) {\n-      _stack_guard_state = stack_guard_unused;\n-    } else {\n-      log_warning(os, thread)(\"Attempt to unprotect stack guard pages failed (\"\n-        PTR_FORMAT \"-\" PTR_FORMAT \").\", p2i(low_addr), p2i(low_addr + len));\n-      return;\n-    }\n-  }\n-\n-  log_debug(os, thread)(\"Thread \" UINTX_FORMAT \" stack guard pages removed: \"\n-    PTR_FORMAT \"-\" PTR_FORMAT \".\",\n-    os::current_thread_id(), p2i(low_addr), p2i(low_addr + len));\n-}\n-\n-void JavaThread::enable_stack_reserved_zone() {\n-  assert(_stack_guard_state == stack_guard_reserved_disabled, \"inconsistent state\");\n-\n-  \/\/ The base notation is from the stack's point of view, growing downward.\n-  \/\/ We need to adjust it to work correctly with guard_memory()\n-  address base = stack_reserved_zone_base() - stack_reserved_zone_size();\n-\n-  guarantee(base < stack_base(),\"Error calculating stack reserved zone\");\n-  guarantee(base < os::current_stack_pointer(),\"Error calculating stack reserved zone\");\n-\n-  if (os::guard_memory((char *) base, stack_reserved_zone_size())) {\n-    _stack_guard_state = stack_guard_enabled;\n-  } else {\n-    warning(\"Attempt to guard stack reserved zone failed.\");\n-  }\n-}\n-\n-void JavaThread::disable_stack_reserved_zone() {\n-  assert(_stack_guard_state == stack_guard_enabled, \"inconsistent state\");\n-\n-  \/\/ Simply return if called for a thread that does not use guard pages.\n-  if (_stack_guard_state != stack_guard_enabled) return;\n-\n-  \/\/ The base notation is from the stack's point of view, growing downward.\n-  \/\/ We need to adjust it to work correctly with guard_memory()\n-  address base = stack_reserved_zone_base() - stack_reserved_zone_size();\n-\n-  if (os::unguard_memory((char *)base, stack_reserved_zone_size())) {\n-    _stack_guard_state = stack_guard_reserved_disabled;\n-  } else {\n-    warning(\"Attempt to unguard stack reserved zone failed.\");\n-  }\n-}\n-\n-void JavaThread::enable_stack_yellow_reserved_zone() {\n-  assert(_stack_guard_state != stack_guard_unused, \"must be using guard pages.\");\n-  assert(_stack_guard_state != stack_guard_enabled, \"already enabled\");\n-\n-  \/\/ The base notation is from the stacks point of view, growing downward.\n-  \/\/ We need to adjust it to work correctly with guard_memory()\n-  address base = stack_red_zone_base();\n-\n-  guarantee(base < stack_base(), \"Error calculating stack yellow zone\");\n-  guarantee(base < os::current_stack_pointer(), \"Error calculating stack yellow zone\");\n-\n-  if (os::guard_memory((char *) base, stack_yellow_reserved_zone_size())) {\n-    _stack_guard_state = stack_guard_enabled;\n-  } else {\n-    warning(\"Attempt to guard stack yellow zone failed.\");\n-  }\n-}\n-\n-void JavaThread::disable_stack_yellow_reserved_zone() {\n-  assert(_stack_guard_state != stack_guard_unused, \"must be using guard pages.\");\n-  assert(_stack_guard_state != stack_guard_yellow_reserved_disabled, \"already disabled\");\n-\n-  \/\/ Simply return if called for a thread that does not use guard pages.\n-  if (_stack_guard_state == stack_guard_unused) return;\n-\n-  \/\/ The base notation is from the stacks point of view, growing downward.\n-  \/\/ We need to adjust it to work correctly with guard_memory()\n-  address base = stack_red_zone_base();\n-\n-  if (os::unguard_memory((char *)base, stack_yellow_reserved_zone_size())) {\n-    _stack_guard_state = stack_guard_yellow_reserved_disabled;\n-  } else {\n-    warning(\"Attempt to unguard stack yellow zone failed.\");\n-  }\n-}\n-\n-void JavaThread::enable_stack_red_zone() {\n-  \/\/ The base notation is from the stacks point of view, growing downward.\n-  \/\/ We need to adjust it to work correctly with guard_memory()\n-  assert(_stack_guard_state != stack_guard_unused, \"must be using guard pages.\");\n-  address base = stack_red_zone_base() - stack_red_zone_size();\n-\n-  guarantee(base < stack_base(), \"Error calculating stack red zone\");\n-  guarantee(base < os::current_stack_pointer(), \"Error calculating stack red zone\");\n-\n-  if (!os::guard_memory((char *) base, stack_red_zone_size())) {\n-    warning(\"Attempt to guard stack red zone failed.\");\n-  }\n-}\n-\n-void JavaThread::disable_stack_red_zone() {\n-  \/\/ The base notation is from the stacks point of view, growing downward.\n-  \/\/ We need to adjust it to work correctly with guard_memory()\n-  assert(_stack_guard_state != stack_guard_unused, \"must be using guard pages.\");\n-  address base = stack_red_zone_base() - stack_red_zone_size();\n-  if (!os::unguard_memory((char *)base, stack_red_zone_size())) {\n-    warning(\"Attempt to unguard stack red zone failed.\");\n-  }\n-}\n-\n-void JavaThread::frames_do(void f(frame*, const RegisterMap* map)) {\n-  \/\/ ignore is there is no stack\n-  if (!has_last_Java_frame()) return;\n-  \/\/ Because this method is used to verify oops, it must support\n-  \/\/ oops in buffered values\n-\n-  \/\/ traverse the stack frames. Starts from top frame.\n-  for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {\n-    frame* fr = fst.current();\n-    f(fr, fst.register_map());\n-  }\n-}\n-\n-\n@@ -2887,1 +2719,1 @@\n-  StackFrameStream fst(this, false);\n+  StackFrameStream fst(this, false \/* update *\/, true \/* process_frames *\/);\n@@ -2937,1 +2769,1 @@\n-  for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {\n+  for (StackFrameStream fst(this, true \/* update *\/, true \/* process_frames *\/); !fst.is_done(); fst.next()) {\n@@ -2950,1 +2782,1 @@\n-  StackFrameStream fst(this, false);\n+  StackFrameStream fst(this, false \/* update *\/, true \/* process_frames *\/);\n@@ -2958,23 +2790,1 @@\n-\/\/ If the caller is a NamedThread, then remember, in the current scope,\n-\/\/ the given JavaThread in its _processed_thread field.\n-class RememberProcessedThread: public StackObj {\n-  NamedThread* _cur_thr;\n- public:\n-  RememberProcessedThread(JavaThread* jthr) {\n-    Thread* thread = Thread::current();\n-    if (thread->is_Named_thread()) {\n-      _cur_thr = (NamedThread *)thread;\n-      _cur_thr->set_processed_thread(jthr);\n-    } else {\n-      _cur_thr = NULL;\n-    }\n-  }\n-\n-  ~RememberProcessedThread() {\n-    if (_cur_thr) {\n-      _cur_thr->set_processed_thread(NULL);\n-    }\n-  }\n-};\n-\n-void JavaThread::oops_do(OopClosure* f, CodeBlobClosure* cf) {\n+void JavaThread::oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf) {\n@@ -2985,1 +2795,1 @@\n-  Thread::oops_do(f, cf);\n+  Thread::oops_do_no_frames(f, cf);\n@@ -2991,3 +2801,0 @@\n-    \/\/ Record JavaThread to GC thread\n-    RememberProcessedThread rpt(this);\n-\n@@ -2998,5 +2805,0 @@\n-\n-    \/\/ Traverse the execution stack\n-    for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {\n-      fst.current()->oops_do(f, cf, fst.register_map());\n-    }\n@@ -3026,0 +2828,12 @@\n+void JavaThread::oops_do_frames(OopClosure* f, CodeBlobClosure* cf) {\n+  if (!has_last_Java_frame()) {\n+    return;\n+  }\n+  \/\/ Finish any pending lazy GC activity for the frames\n+  StackWatermarkSet::finish_processing(this, NULL \/* context *\/, StackWatermarkKind::gc);\n+  \/\/ Traverse the execution stack\n+  for (StackFrameStream fst(this, true \/* update *\/, false \/* process_frames *\/); !fst.is_done(); fst.next()) {\n+    fst.current()->oops_do(f, cf, fst.register_map());\n+  }\n+}\n+\n@@ -3044,1 +2858,1 @@\n-    for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {\n+    for (StackFrameStream fst(this, true \/* update *\/, true \/* process_frames *\/); !fst.is_done(); fst.next()) {\n@@ -3057,1 +2871,1 @@\n-    for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {\n+    for (StackFrameStream fst(this, true \/* update *\/, true \/* process_frames *\/); !fst.is_done(); fst.next()) {\n@@ -3156,0 +2970,1 @@\n+\n@@ -3158,0 +2973,10 @@\n+void JavaThread::frames_do(void f(frame*, const RegisterMap* map)) {\n+  \/\/ ignore if there is no stack\n+  if (!has_last_Java_frame()) return;\n+  \/\/ traverse the stack frames. Starts from top frame.\n+  for (StackFrameStream fst(this, true \/* update *\/, true \/* process_frames *\/); !fst.is_done(); fst.next()) {\n+    frame* fr = fst.current();\n+    f(fr, fst.register_map());\n+  }\n+}\n+\n@@ -3330,1 +3155,1 @@\n-  for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {\n+  for (StackFrameStream fst(this, true \/* update *\/, true \/* process_frames *\/); !fst.is_done(); fst.next()) {\n@@ -3366,1 +3191,1 @@\n-  for (StackFrameStream fst(this, false); !fst.is_done(); fst.next()) {\n+  for (StackFrameStream fst(this, false \/* update *\/, true \/* process_frames *\/); !fst.is_done(); fst.next()) {\n@@ -3528,2 +3353,2 @@\n-void CodeCacheSweeperThread::oops_do(OopClosure* f, CodeBlobClosure* cf) {\n-  JavaThread::oops_do(f, cf);\n+void CodeCacheSweeperThread::oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf) {\n+  JavaThread::oops_do_no_frames(f, cf);\n@@ -3902,1 +3727,1 @@\n-  main_thread->create_stack_guard_pages();\n+  main_thread->stack_overflow_state()->create_stack_guard_pages();\n@@ -4574,7 +4399,0 @@\n-  \/\/ We must flush any deferred card marks and other various GC barrier\n-  \/\/ related buffers (e.g. G1 SATB buffer and G1 dirty card queue buffer)\n-  \/\/ before removing a thread from the list of active threads.\n-  \/\/ This must be done after ObjectSynchronizer::om_flush(), as GC barriers\n-  \/\/ are used in om_flush().\n-  BarrierSet::barrier_set()->on_thread_detach(p);\n-\n@@ -4585,0 +4403,7 @@\n+    \/\/ We must flush any deferred card marks and other various GC barrier\n+    \/\/ related buffers (e.g. G1 SATB buffer and G1 dirty card queue buffer)\n+    \/\/ before removing a thread from the list of active threads.\n+    \/\/ This must be done after ObjectSynchronizer::om_flush(), as GC barriers\n+    \/\/ are used in om_flush().\n+    BarrierSet::barrier_set()->on_thread_detach(p);\n+\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":160,"deletions":335,"binary":false,"changes":495,"status":"modified"},{"patch":"@@ -43,0 +43,2 @@\n+#include \"runtime\/safepointMechanism.hpp\"\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -44,0 +46,1 @@\n+#include \"runtime\/stackOverflow.hpp\"\n@@ -286,0 +289,6 @@\n+  \/\/ Stack watermark barriers.\n+  StackWatermarks _stack_watermarks;\n+\n+ public:\n+  inline StackWatermarks* stack_watermarks() { return &_stack_watermarks; }\n+\n@@ -393,1 +402,2 @@\n-  volatile void* _polling_page;                 \/\/ Thread local polling page\n+ protected:\n+  SafepointMechanism::ThreadData _poll_data;\n@@ -395,0 +405,1 @@\n+ private:\n@@ -657,1 +668,3 @@\n-  virtual void oops_do(OopClosure* f, CodeBlobClosure* cf);\n+  virtual void oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf);\n+  virtual void oops_do_frames(OopClosure* f, CodeBlobClosure* cf) {}\n+  void oops_do(OopClosure* f, CodeBlobClosure* cf);\n@@ -752,2 +765,0 @@\n-  volatile void** polling_page_addr() { return &_polling_page; }\n-\n@@ -817,1 +828,2 @@\n-  static ByteSize polling_page_offset()          { return byte_offset_of(Thread, _polling_page); }\n+  static ByteSize polling_word_offset()          { return byte_offset_of(Thread, _poll_data) + byte_offset_of(SafepointMechanism::ThreadData, _polling_word);}\n+  static ByteSize polling_page_offset()          { return byte_offset_of(Thread, _poll_data) + byte_offset_of(SafepointMechanism::ThreadData, _polling_page);}\n@@ -927,2 +939,2 @@\n-  \/\/ log JavaThread being processed by oops_do\n-  JavaThread* _processed_thread;\n+  \/\/ log Thread being processed by oops_do\n+  Thread* _processed_thread;\n@@ -938,2 +950,2 @@\n-  JavaThread *processed_thread() { return _processed_thread; }\n-  void set_processed_thread(JavaThread *thread) { _processed_thread = thread; }\n+  Thread *processed_thread() { return _processed_thread; }\n+  void set_processed_thread(Thread *thread) { _processed_thread = thread; }\n@@ -1140,10 +1152,0 @@\n- public:\n-  \/\/ State of the stack guard pages for this thread.\n-  enum StackGuardState {\n-    stack_guard_unused,         \/\/ not needed\n-    stack_guard_reserved_disabled,\n-    stack_guard_yellow_reserved_disabled,\/\/ disabled (temporarily) after stack overflow\n-    stack_guard_enabled         \/\/ enabled\n-  };\n-\n- private:\n@@ -1197,6 +1199,1 @@\n-  StackGuardState  _stack_guard_state;\n-\n-  \/\/ Precompute the limit of the stack as used in stack overflow checks.\n-  \/\/ We load it from here to simplify the stack overflow check in assembly.\n-  address          _stack_overflow_limit;\n-  address          _reserved_stack_activation;\n+  StackOverflow    _stack_overflow_state;\n@@ -1236,1 +1233,0 @@\n-  void initialize();                             \/\/ Initialized the instance variables\n@@ -1240,1 +1236,2 @@\n-  JavaThread(bool is_attaching_via_jni = false); \/\/ for main thread and JNI attached threads\n+  JavaThread();                            \/\/ delegating constructor\n+  JavaThread(bool is_attaching_via_jni);   \/\/ for main thread and JNI attached threads\n@@ -1249,0 +1246,2 @@\n+  StackOverflow* stack_overflow_state() { return &_stack_overflow_state; }\n+\n@@ -1294,1 +1293,0 @@\n-\n@@ -1345,3 +1343,1 @@\n-  inline void set_polling_page_release(void* poll_value);\n-  inline void set_polling_page(void* poll_value);\n-  inline volatile void* get_polling_page();\n+  SafepointMechanism::ThreadData* poll_data() { return &_poll_data; }\n@@ -1583,175 +1579,0 @@\n-  \/\/ Stack overflow support\n-  \/\/\n-  \/\/  (small addresses)\n-  \/\/\n-  \/\/  --  <-- stack_end()                   ---\n-  \/\/  |                                      |\n-  \/\/  |  red pages                           |\n-  \/\/  |                                      |\n-  \/\/  --  <-- stack_red_zone_base()          |\n-  \/\/  |                                      |\n-  \/\/  |                                     guard\n-  \/\/  |  yellow pages                       zone\n-  \/\/  |                                      |\n-  \/\/  |                                      |\n-  \/\/  --  <-- stack_yellow_zone_base()       |\n-  \/\/  |                                      |\n-  \/\/  |                                      |\n-  \/\/  |  reserved pages                      |\n-  \/\/  |                                      |\n-  \/\/  --  <-- stack_reserved_zone_base()    ---      ---\n-  \/\/                                                 \/|\\  shadow     <--  stack_overflow_limit() (somewhere in here)\n-  \/\/                                                  |   zone\n-  \/\/                                                 \\|\/  size\n-  \/\/  some untouched memory                          ---\n-  \/\/\n-  \/\/\n-  \/\/  --\n-  \/\/  |\n-  \/\/  |  shadow zone\n-  \/\/  |\n-  \/\/  --\n-  \/\/  x    frame n\n-  \/\/  --\n-  \/\/  x    frame n-1\n-  \/\/  x\n-  \/\/  --\n-  \/\/  ...\n-  \/\/\n-  \/\/  --\n-  \/\/  x    frame 0\n-  \/\/  --  <-- stack_base()\n-  \/\/\n-  \/\/  (large addresses)\n-  \/\/\n-\n- private:\n-  \/\/ These values are derived from flags StackRedPages, StackYellowPages,\n-  \/\/ StackReservedPages and StackShadowPages. The zone size is determined\n-  \/\/ ergonomically if page_size > 4K.\n-  static size_t _stack_red_zone_size;\n-  static size_t _stack_yellow_zone_size;\n-  static size_t _stack_reserved_zone_size;\n-  static size_t _stack_shadow_zone_size;\n- public:\n-  inline size_t stack_available(address cur_sp);\n-\n-  static size_t stack_red_zone_size() {\n-    assert(_stack_red_zone_size > 0, \"Don't call this before the field is initialized.\");\n-    return _stack_red_zone_size;\n-  }\n-  static void set_stack_red_zone_size(size_t s) {\n-    assert(is_aligned(s, os::vm_page_size()),\n-           \"We can not protect if the red zone size is not page aligned.\");\n-    assert(_stack_red_zone_size == 0, \"This should be called only once.\");\n-    _stack_red_zone_size = s;\n-  }\n-  address stack_red_zone_base() {\n-    return (address)(stack_end() + stack_red_zone_size());\n-  }\n-  bool in_stack_red_zone(address a) {\n-    return a <= stack_red_zone_base() && a >= stack_end();\n-  }\n-\n-  static size_t stack_yellow_zone_size() {\n-    assert(_stack_yellow_zone_size > 0, \"Don't call this before the field is initialized.\");\n-    return _stack_yellow_zone_size;\n-  }\n-  static void set_stack_yellow_zone_size(size_t s) {\n-    assert(is_aligned(s, os::vm_page_size()),\n-           \"We can not protect if the yellow zone size is not page aligned.\");\n-    assert(_stack_yellow_zone_size == 0, \"This should be called only once.\");\n-    _stack_yellow_zone_size = s;\n-  }\n-\n-  static size_t stack_reserved_zone_size() {\n-    \/\/ _stack_reserved_zone_size may be 0. This indicates the feature is off.\n-    return _stack_reserved_zone_size;\n-  }\n-  static void set_stack_reserved_zone_size(size_t s) {\n-    assert(is_aligned(s, os::vm_page_size()),\n-           \"We can not protect if the reserved zone size is not page aligned.\");\n-    assert(_stack_reserved_zone_size == 0, \"This should be called only once.\");\n-    _stack_reserved_zone_size = s;\n-  }\n-  address stack_reserved_zone_base() const {\n-    return (address)(stack_end() +\n-                     (stack_red_zone_size() + stack_yellow_zone_size() + stack_reserved_zone_size()));\n-  }\n-  bool in_stack_reserved_zone(address a) {\n-    return (a <= stack_reserved_zone_base()) &&\n-           (a >= (address)((intptr_t)stack_reserved_zone_base() - stack_reserved_zone_size()));\n-  }\n-\n-  static size_t stack_yellow_reserved_zone_size() {\n-    return _stack_yellow_zone_size + _stack_reserved_zone_size;\n-  }\n-  bool in_stack_yellow_reserved_zone(address a) {\n-    return (a <= stack_reserved_zone_base()) && (a >= stack_red_zone_base());\n-  }\n-\n-  \/\/ Size of red + yellow + reserved zones.\n-  static size_t stack_guard_zone_size() {\n-    return stack_red_zone_size() + stack_yellow_reserved_zone_size();\n-  }\n-\n-  static size_t stack_shadow_zone_size() {\n-    assert(_stack_shadow_zone_size > 0, \"Don't call this before the field is initialized.\");\n-    return _stack_shadow_zone_size;\n-  }\n-  static void set_stack_shadow_zone_size(size_t s) {\n-    \/\/ The shadow area is not allocated or protected, so\n-    \/\/ it needs not be page aligned.\n-    \/\/ But the stack bang currently assumes that it is a\n-    \/\/ multiple of page size. This guarantees that the bang\n-    \/\/ loop touches all pages in the shadow zone.\n-    \/\/ This can be guaranteed differently, as well.  E.g., if\n-    \/\/ the page size is a multiple of 4K, banging in 4K steps\n-    \/\/ suffices to touch all pages. (Some pages are banged\n-    \/\/ several times, though.)\n-    assert(is_aligned(s, os::vm_page_size()),\n-           \"Stack bang assumes multiple of page size.\");\n-    assert(_stack_shadow_zone_size == 0, \"This should be called only once.\");\n-    _stack_shadow_zone_size = s;\n-  }\n-\n-  void create_stack_guard_pages();\n-  void remove_stack_guard_pages();\n-\n-  void enable_stack_reserved_zone();\n-  void disable_stack_reserved_zone();\n-  void enable_stack_yellow_reserved_zone();\n-  void disable_stack_yellow_reserved_zone();\n-  void enable_stack_red_zone();\n-  void disable_stack_red_zone();\n-\n-  inline bool stack_guard_zone_unused();\n-  inline bool stack_yellow_reserved_zone_disabled();\n-  inline bool stack_reserved_zone_disabled();\n-  inline bool stack_guards_enabled();\n-\n-  address reserved_stack_activation() const { return _reserved_stack_activation; }\n-  void set_reserved_stack_activation(address addr) {\n-    assert(_reserved_stack_activation == stack_base()\n-            || _reserved_stack_activation == NULL\n-            || addr == stack_base(), \"Must not be set twice\");\n-    _reserved_stack_activation = addr;\n-  }\n-\n-  \/\/ Attempt to reguard the stack after a stack overflow may have occurred.\n-  \/\/ Returns true if (a) guard pages are not needed on this thread, (b) the\n-  \/\/ pages are already guarded, or (c) the pages were successfully reguarded.\n-  \/\/ Returns false if there is not enough stack space to reguard the pages, in\n-  \/\/ which case the caller should unwind a frame and try again.  The argument\n-  \/\/ should be the caller's (approximate) sp.\n-  bool reguard_stack(address cur_sp);\n-  \/\/ Similar to above but see if current stackpoint is out of the guard area\n-  \/\/ and reguard if possible.\n-  bool reguard_stack(void);\n-\n-  address stack_overflow_limit() { return _stack_overflow_limit; }\n-  void set_stack_overflow_limit() {\n-    _stack_overflow_limit =\n-      stack_end() + MAX2(JavaThread::stack_guard_zone_size(), JavaThread::stack_shadow_zone_size());\n-  }\n-\n@@ -1762,1 +1583,1 @@\n-    return is_in_stack_range_incl(adr, stack_reserved_zone_base());\n+    return is_in_stack_range_incl(adr, _stack_overflow_state.stack_reserved_zone_base());\n@@ -1803,3 +1624,12 @@\n-  static ByteSize stack_overflow_limit_offset()  { return byte_offset_of(JavaThread, _stack_overflow_limit); }\n-  static ByteSize stack_guard_state_offset()     { return byte_offset_of(JavaThread, _stack_guard_state); }\n-  static ByteSize reserved_stack_activation_offset() { return byte_offset_of(JavaThread, _reserved_stack_activation); }\n+\n+  \/\/ StackOverflow offsets\n+  static ByteSize stack_overflow_limit_offset()  {\n+    return byte_offset_of(JavaThread, _stack_overflow_state._stack_overflow_limit);\n+  }\n+  static ByteSize stack_guard_state_offset()     {\n+    return byte_offset_of(JavaThread, _stack_overflow_state._stack_guard_state);\n+  }\n+  static ByteSize reserved_stack_activation_offset() {\n+    return byte_offset_of(JavaThread, _stack_overflow_state._reserved_stack_activation);\n+  }\n+\n@@ -1879,1 +1709,2 @@\n-  void oops_do(OopClosure* f, CodeBlobClosure* cf);\n+  void oops_do_frames(OopClosure* f, CodeBlobClosure* cf);\n+  void oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf);\n@@ -2131,1 +1962,1 @@\n-  void oops_do(OopClosure* f, CodeBlobClosure* cf);\n+  void oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf);\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":43,"deletions":212,"binary":false,"changes":255,"status":"modified"},{"patch":"@@ -137,1 +137,1 @@\n-          for(StackFrameStream fst(thread, false); !fst.is_done(); fst.next()) {\n+          for(StackFrameStream fst(thread, false \/* update *\/, true \/* process_frames *\/); !fst.is_done(); fst.next()) {\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -154,0 +154,4 @@\n+  \/\/ You may override skip_thread_oop_barriers to return true if the operation\n+  \/\/ does not access thread-private oops (including frames).\n+  virtual bool skip_thread_oop_barriers() const { return false; }\n+\n@@ -217,0 +221,1 @@\n+  virtual bool skip_thread_oop_barriers() const { return true; }\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -299,0 +299,1 @@\n+  AOT_ONLY(nonstatic_field(MethodCounters,     _method,                                       Method*))                              \\\n@@ -742,1 +743,1 @@\n-  nonstatic_field(NamedThread,                 _processed_thread,                             JavaThread*)                           \\\n+  nonstatic_field(NamedThread,                 _processed_thread,                             Thread*)                               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+import jdk.internal.misc.CDS;\n@@ -35,0 +36,1 @@\n+import java.util.Objects;\n@@ -61,0 +63,3 @@\n+        if (CDS.isDumpingClassList()) {\n+            CDS.traceLambdaFormInvoker(LF_RESOLVE, holder.getName(), name, shortenSignature(basicTypeSignature(type)));\n+        }\n@@ -67,0 +72,3 @@\n+        if (CDS.isDumpingClassList()) {\n+            CDS.traceSpeciesType(SPECIES_RESOLVE, cn);\n+        }\n@@ -313,0 +321,1 @@\n+        Objects.requireNonNull(traces);\n@@ -319,1 +328,1 @@\n-                            assert parts.length == 3;\n+                            assert parts.length >= 2;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/GenerateJLIClassesHelper.java","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1390,3 +1390,0 @@\n-compiler.err.unsupported.cross.fp.lit=\\\n-    hexadecimal floating-point literals are not supported on this VM\n-\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1340,1 +1340,1 @@\n-     * Given a TypeElement, return the name of its type (Class, Interface, etc.).\n+     * Returns the name of the kind of a type element (Class, Interface, etc.).\n@@ -1342,4 +1342,4 @@\n-     * @param te the TypeElement to check.\n-     * @param lowerCaseOnly true if you want the name returned in lower case.\n-     *                      If false, the first letter of the name is capitalized.\n-     * @return\n+     * @param te the type element\n+     * @param lowerCaseOnly true if you want the name returned in lower case;\n+     *                      if false, the first letter of the name is capitalized\n+     * @return the name\n@@ -1347,20 +1347,22 @@\n-    public String getTypeElementName(TypeElement te, boolean lowerCaseOnly) {\n-        String typeName = \"\";\n-        if (isInterface(te)) {\n-            typeName = \"doclet.Interface\";\n-        } else if (isException(te)) {\n-            typeName = \"doclet.Exception\";\n-        } else if (isError(te)) {\n-            typeName = \"doclet.Error\";\n-        } else if (isAnnotationType(te)) {\n-            typeName = \"doclet.AnnotationType\";\n-        } else if (isEnum(te)) {\n-            typeName = \"doclet.Enum\";\n-        } else if (isOrdinaryClass(te)) {\n-            typeName = \"doclet.Class\";\n-        }\n-        typeName = lowerCaseOnly ? toLowerCase(typeName) : typeName;\n-        return typeNameMap.computeIfAbsent(typeName, resources::getText);\n-    }\n-\n-    private final Map<String, String> typeNameMap = new HashMap<>();\n+    public String getTypeElementKindName(TypeElement te, boolean lowerCaseOnly) {\n+        String kindName = switch (te.getKind()) {\n+            case ANNOTATION_TYPE ->\n+                    \"doclet.AnnotationType\";\n+            case ENUM ->\n+                    \"doclet.Enum\";\n+            case INTERFACE ->\n+                    \"doclet.Interface\";\n+            case RECORD ->\n+                    \"doclet.Record\";\n+            case CLASS ->\n+                    isException(te) ? \"doclet.Exception\"\n+                    : isError(te) ? \"doclet.Error\"\n+                    : \"doclet.Class\";\n+            default ->\n+                    throw new IllegalArgumentException(te.getKind().toString());\n+        };\n+        kindName = lowerCaseOnly ? toLowerCase(kindName) : kindName;\n+        return kindNameMap.computeIfAbsent(kindName, resources::getText);\n+    }\n+\n+    private final Map<String, String> kindNameMap = new HashMap<>();\n","filename":"src\/jdk.javadoc\/share\/classes\/jdk\/javadoc\/internal\/doclets\/toolkit\/util\/Utils.java","additions":27,"deletions":25,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -194,2 +194,0 @@\n-serviceability\/sa\/TestInstanceKlassSize.java 8230664 linux-ppc64le,linux-ppc64\n-serviceability\/sa\/TestInstanceKlassSizeForInterface.java 8230664 linux-ppc64le,linux-ppc64\n@@ -260,0 +258,1 @@\n+vmTestbase\/nsk\/jvmti\/ResourceExhausted\/resexhausted001\/TestDescription.java 8253916 linux-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -352,0 +352,1 @@\n+ -runtime\/cds\/appcds\/DumpClassListWithLF.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -118,0 +118,1 @@\n+        map.put(\"vm.musl\", this::isMusl);\n@@ -521,0 +522,9 @@\n+    \/**\n+     * Checks musl libc.\n+     *\n+     * @return true if musl libc is used.\n+     *\/\n+    protected String isMusl() {\n+        return Boolean.toString(WB.getLibcName().contains(\"musl\"));\n+    }\n+\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -47,1 +47,0 @@\n-compiler.err.unsupported.cross.fp.lit                   # Scanner: host system dependent\n","filename":"test\/langtools\/tools\/javac\/diags\/examples.not-yet.txt","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -633,0 +633,3 @@\n+  \/\/ libc name\n+  public native String getLibcName();\n+\n","filename":"test\/lib\/sun\/hotspot\/WhiteBox.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"}]}