{"files":[{"patch":"@@ -83,1 +83,1 @@\n-                                   Address dst, Register val, Register tmp1, Register tmp2) {\n+                                   Address dst, Register val, Register tmp1, Register tmp2, Register tmp3) {\n@@ -86,0 +86,2 @@\n+  bool is_not_null = (decorators & IS_NOT_NULL) != 0;\n+\n@@ -89,6 +91,7 @@\n-    val = val == noreg ? zr : val;\n-    if (in_heap) {\n-      if (UseCompressedOops) {\n-        assert(!dst.uses(val), \"not enough registers\");\n-        if (val != zr) {\n-          __ encode_heap_oop(val);\n+   if (in_heap) {\n+      if (val == noreg) {\n+        assert(!is_not_null, \"inconsistent access\");\n+        if (UseCompressedOops) {\n+          __ strw(zr, dst);\n+        } else {\n+          __ str(zr, dst);\n@@ -96,2 +99,11 @@\n-        __ strw(val, dst);\n-        __ str(val, dst);\n+        if (UseCompressedOops) {\n+          assert(!dst.uses(val), \"not enough registers\");\n+          if (is_not_null) {\n+            __ encode_heap_oop_not_null(val);\n+          } else {\n+            __ encode_heap_oop(val);\n+          }\n+          __ strw(val, dst);\n+        } else {\n+          __ str(val, dst);\n+        }\n@@ -102,0 +114,1 @@\n+      assert(val != noreg, \"not supported\");\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":22,"deletions":9,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -82,1 +82,1 @@\n-                                                Address dst, Register val, Register tmp1, Register tmp2) {\n+                                                Address dst, Register val, Register tmp1, Register tmp2, Register tmp3) {\n@@ -89,1 +89,1 @@\n-  BarrierSetAssembler::store_at(masm, decorators, type, dst, val, noreg, noreg);\n+  BarrierSetAssembler::store_at(masm, decorators, type, dst, val, noreg, noreg, noreg);\n@@ -93,1 +93,9 @@\n-      store_check(masm, dst.base(), dst);\n+      if (tmp3 != noreg) {\n+        \/\/ Called by MacroAssembler::pack_inline_helper. We cannot corrupt the dst.base() register\n+        __ mov(tmp3, dst.base());\n+        store_check(masm, tmp3, dst);\n+      } else {\n+        \/\/ It's OK to corrupt the dst.base() register.\n+        store_check(masm, dst.base(), dst);\n+      }\n+\n@@ -99,0 +107,1 @@\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/cardTableBarrierSetAssembler_aarch64.cpp","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -146,0 +146,4 @@\n+void InterpreterRuntime::SignatureHandlerGenerator::pass_valuetype() {\n+   pass_object();\n+}\n+\n@@ -213,0 +217,5 @@\n+  virtual void pass_valuetype() {\n+    \/\/ values are handled with oops, like objects\n+    pass_object();\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interpreterRT_aarch64.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+  void pass_valuetype();\n","filename":"src\/hotspot\/cpu\/aarch64\/interpreterRT_aarch64.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+#include \"runtime\/signature_cc.hpp\"\n@@ -1292,1 +1293,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -1322,1 +1327,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -1414,0 +1423,4 @@\n+void MacroAssembler::super_call_VM_leaf(address entry_point) {\n+  MacroAssembler::call_VM_leaf_base(entry_point, 1);\n+}\n+\n@@ -1463,0 +1476,33 @@\n+void MacroAssembler::test_klass_is_value(Register klass, Register temp_reg, Label& is_value) {\n+  ldrw(temp_reg, Address(klass, Klass::access_flags_offset()));\n+  andr(temp_reg, temp_reg, JVM_ACC_INLINE);\n+  cbnz(temp_reg, is_value);\n+}\n+\n+void MacroAssembler::test_field_is_inline_type(Register flags, Register temp_reg, Label& is_inline) {\n+  (void) temp_reg; \/\/ keep signature uniform with x86\n+  tbnz(flags, ConstantPoolCacheEntry::is_inline_field_shift, is_inline);\n+}\n+\n+void MacroAssembler::test_field_is_not_inline_type(Register flags, Register temp_reg, Label& not_inline) {\n+  (void) temp_reg; \/\/ keep signature uniform with x86\n+  tbz(flags, ConstantPoolCacheEntry::is_inline_field_shift, not_inline);\n+}\n+\n+void MacroAssembler::test_field_is_inlined(Register flags, Register temp_reg, Label& is_flattened) {\n+  (void) temp_reg; \/\/ keep signature uniform with x86\n+  tbnz(flags, ConstantPoolCacheEntry::is_flattened_field_shift, is_flattened);\n+}\n+\n+void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg, Label& is_flattened_array) {\n+  load_storage_props(temp_reg, oop);\n+  andr(temp_reg, temp_reg, ArrayStorageProperties::flattened_value);\n+  cbnz(temp_reg, is_flattened_array);\n+}\n+\n+void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label& is_null_free_array) {\n+  load_storage_props(temp_reg, oop);\n+  andr(temp_reg, temp_reg, ArrayStorageProperties::null_free_value);\n+  cbnz(temp_reg, is_null_free_array);\n+}\n+\n@@ -3776,1 +3822,1 @@\n-void MacroAssembler::load_klass(Register dst, Register src) {\n+void MacroAssembler::load_metadata(Register dst, Register src) {\n@@ -3779,1 +3825,0 @@\n-    decode_klass_not_null(dst);\n@@ -3785,0 +3830,10 @@\n+void MacroAssembler::load_klass(Register dst, Register src) {\n+  load_metadata(dst, src);\n+  if (UseCompressedClassPointers) {\n+    andr(dst, dst, oopDesc::compressed_klass_mask());\n+    decode_klass_not_null(dst);\n+  } else {\n+    ubfm(dst, dst, 0, 63 - oopDesc::storage_props_nof_bits);\n+  }\n+}\n+\n@@ -3816,0 +3871,9 @@\n+void MacroAssembler::load_storage_props(Register dst, Register src) {\n+  load_metadata(dst, src);\n+  if (UseCompressedClassPointers) {\n+    asrw(dst, dst, oopDesc::narrow_storage_props_shift);\n+  } else {\n+    asr(dst, dst, oopDesc::wide_storage_props_shift);\n+  }\n+}\n+\n@@ -4153,1 +4217,2 @@\n-                                     Register tmp1, Register thread_tmp) {\n+                                     Register tmp1, Register thread_tmp, Register tmp3) {\n+\n@@ -4158,1 +4223,1 @@\n-    bs->BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, thread_tmp);\n+    bs->BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, thread_tmp, tmp3);\n@@ -4160,1 +4225,1 @@\n-    bs->store_at(this, decorators, type, dst, src, tmp1, thread_tmp);\n+    bs->store_at(this, decorators, type, dst, src, tmp1, thread_tmp, tmp3);\n@@ -4184,2 +4249,2 @@\n-                                    Register thread_tmp, DecoratorSet decorators) {\n-  access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);\n+                                    Register thread_tmp, Register tmp3, DecoratorSet decorators) {\n+  access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp, tmp3);\n@@ -4190,1 +4255,1 @@\n-  access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);\n+  access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);\n@@ -5290,0 +5355,339 @@\n+\/\/ C2 compiled method's prolog code\n+\/\/ Moved here from aarch64.ad to support Valhalla code belows\n+void MacroAssembler::verified_entry(Compile* C, int sp_inc) {\n+\n+\/\/ n.b. frame size includes space for return pc and rfp\n+  const long framesize = C->frame_size_in_bytes();\n+  assert(framesize % (2 * wordSize) == 0, \"must preserve 2 * wordSize alignment\");\n+\n+  \/\/ insert a nop at the start of the prolog so we can patch in a\n+  \/\/ branch if we need to invalidate the method later\n+  nop();\n+\n+  int bangsize = C->bang_size_in_bytes();\n+  if (C->need_stack_bang(bangsize) && UseStackBanging)\n+     generate_stack_overflow_check(bangsize);\n+\n+  build_frame(framesize);\n+\n+  if (VerifyStackAtCalls) {\n+    Unimplemented();\n+  }\n+}\n+\n+int MacroAssembler::store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter) {\n+  \/\/ An inline type might be returned. If fields are in registers we\n+  \/\/ need to allocate an inline type instance and initialize it with\n+  \/\/ the value of the fields.\n+  Label skip;\n+  \/\/ We only need a new buffered inline type if a new one is not returned\n+  cmp(r0, (u1) 1);\n+  br(Assembler::EQ, skip);\n+  int call_offset = -1;\n+\n+  Label slow_case;\n+\n+  \/\/ Try to allocate a new buffered inline type (from the heap)\n+  if (UseTLAB) {\n+\n+    if (vk != NULL) {\n+      \/\/ Called from C1, where the return type is statically known.\n+      mov(r1, (intptr_t)vk->get_InlineKlass());\n+      jint lh = vk->layout_helper();\n+      assert(lh != Klass::_lh_neutral_value, \"inline class in return type must have been resolved\");\n+      mov(r14, lh);\n+    } else {\n+       \/\/ Call from interpreter. R0 contains ((the InlineKlass* of the return type) | 0x01)\n+       andr(r1, r0, -2);\n+       \/\/ get obj size\n+       ldrw(r14, Address(rscratch1 \/*klass*\/, Klass::layout_helper_offset()));\n+    }\n+\n+     ldr(r13, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));\n+\n+     \/\/ check whether we have space in TLAB,\n+     \/\/ rscratch1 contains pointer to just allocated obj\n+      lea(r14, Address(r13, r14));\n+      ldr(rscratch1, Address(rthread, in_bytes(JavaThread::tlab_end_offset())));\n+\n+      cmp(r14, rscratch1);\n+      br(Assembler::GT, slow_case);\n+\n+      \/\/ OK we have room in TLAB,\n+      \/\/ Set new TLAB top\n+      str(r14, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));\n+\n+      \/\/ Set new class always locked\n+      mov(rscratch1, (uint64_t) markWord::always_locked_prototype().value());\n+      str(rscratch1, Address(r13, oopDesc::mark_offset_in_bytes()));\n+\n+      store_klass_gap(r13, zr);  \/\/ zero klass gap for compressed oops\n+      if (vk == NULL) {\n+        \/\/ store_klass corrupts rbx, so save it in rax for later use (interpreter case only).\n+         mov(r0, r1);\n+      }\n+\n+      store_klass(r13, r1);  \/\/ klass\n+\n+      if (vk != NULL) {\n+        \/\/ FIXME -- do the packing in-line to avoid the runtime call\n+        mov(r0, r13);\n+        far_call(RuntimeAddress(vk->pack_handler())); \/\/ no need for call info as this will not safepoint.\n+      } else {\n+\n+        \/\/ We have our new buffered inline type, initialize its fields with an inline class specific handler\n+        ldr(r1, Address(r0, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+        ldr(r1, Address(r1, InlineKlass::pack_handler_offset()));\n+\n+        \/\/ Mov new class to r0 and call pack_handler\n+        mov(r0, r13);\n+        blr(r1);\n+      }\n+      b(skip);\n+  }\n+\n+  bind(slow_case);\n+  \/\/ We failed to allocate a new inline type, fall back to a runtime\n+  \/\/ call. Some oop field may be live in some registers but we can't\n+  \/\/ tell. That runtime call will take care of preserving them\n+  \/\/ across a GC if there's one.\n+\n+\n+  if (from_interpreter) {\n+    super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());\n+  } else {\n+    ldr(rscratch1, RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));\n+    blr(rscratch1);\n+    call_offset = offset();\n+  }\n+\n+  bind(skip);\n+  return call_offset;\n+}\n+\n+\/\/ Move a value between registers\/stack slots and update the reg_state\n+bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]) {\n+  if (reg_state[to->value()] == reg_written) {\n+    return true; \/\/ Already written\n+  }\n+\n+  if (from != to && bt != T_VOID) {\n+    if (reg_state[to->value()] == reg_readonly) {\n+      return false; \/\/ Not yet writable\n+    }\n+    if (from->is_reg()) {\n+      if (to->is_reg()) {\n+        mov(to->as_Register(), from->as_Register());\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        Address to_addr = Address(sp, st_off);\n+        if (from->is_FloatRegister()) {\n+          if (bt == T_DOUBLE) {\n+             strd(from->as_FloatRegister(), to_addr);\n+          } else {\n+             assert(bt == T_FLOAT, \"must be float\");\n+             strs(from->as_FloatRegister(), to_addr);\n+          }\n+        } else {\n+          str(from->as_Register(), to_addr);\n+        }\n+      }\n+    } else {\n+      Address from_addr = Address(sp, from->reg2stack() * VMRegImpl::stack_slot_size + wordSize);\n+      if (to->is_reg()) {\n+        if (to->is_FloatRegister()) {\n+          if (bt == T_DOUBLE) {\n+             ldrd(to->as_FloatRegister(), from_addr);\n+          } else {\n+            assert(bt == T_FLOAT, \"must be float\");\n+            ldrs(to->as_FloatRegister(), from_addr);\n+          }\n+        } else {\n+          ldr(to->as_Register(), from_addr);\n+        }\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        ldr(rscratch1, from_addr);\n+        str(rscratch1, Address(sp, st_off));\n+      }\n+    }\n+  }\n+\n+  \/\/ Update register states\n+  reg_state[from->value()] = reg_writable;\n+  reg_state[to->value()] = reg_written;\n+  return true;\n+}\n+\n+\/\/ Read all fields from an inline type oop and store the values in registers\/stack slots\n+bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, VMRegPair* regs_to,\n+                                          int& to_index, RegState reg_state[]) {\n+  Register fromReg = from->is_reg() ? from->as_Register() : noreg;\n+  assert(sig->at(sig_index)._bt == T_VOID, \"should be at end delimiter\");\n+\n+\n+  int vt = 1;\n+  bool done = true;\n+  bool mark_done = true;\n+  do {\n+    sig_index--;\n+    BasicType bt = sig->at(sig_index)._bt;\n+    if (bt == T_INLINE_TYPE) {\n+      vt--;\n+    } else if (bt == T_VOID &&\n+               sig->at(sig_index-1)._bt != T_LONG &&\n+               sig->at(sig_index-1)._bt != T_DOUBLE) {\n+      vt++;\n+    } else {\n+      assert(to_index >= 0, \"invalid to_index\");\n+      VMRegPair pair_to = regs_to[to_index--];\n+      VMReg to = pair_to.first();\n+\n+      if (bt == T_VOID) continue;\n+\n+      int idx = (int) to->value();\n+      if (reg_state[idx] == reg_readonly) {\n+         if (idx != from->value()) {\n+           mark_done = false;\n+         }\n+         done = false;\n+         continue;\n+      } else if (reg_state[idx] == reg_written) {\n+        continue;\n+      } else {\n+        assert(reg_state[idx] == reg_writable, \"must be writable\");\n+        reg_state[idx] = reg_written;\n+      }\n+\n+      if (fromReg == noreg) {\n+        int st_off = from->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        ldr(rscratch2, Address(sp, st_off));\n+        fromReg = rscratch2;\n+      }\n+\n+      int off = sig->at(sig_index)._offset;\n+      assert(off > 0, \"offset in object should be positive\");\n+      bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);\n+\n+      Address fromAddr = Address(fromReg, off);\n+      bool is_signed = (bt != T_CHAR) && (bt != T_BOOLEAN);\n+\n+      if (!to->is_FloatRegister()) {\n+\n+        Register dst = to->is_stack() ? rscratch1 : to->as_Register();\n+\n+        if (is_oop) {\n+          load_heap_oop(dst, fromAddr);\n+        } else {\n+          load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);\n+        }\n+        if (to->is_stack()) {\n+          int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+          str(dst, Address(sp, st_off));\n+        }\n+      } else {\n+        if (bt == T_DOUBLE) {\n+          ldrd(to->as_FloatRegister(), fromAddr);\n+        } else {\n+          assert(bt == T_FLOAT, \"must be float\");\n+          ldrs(to->as_FloatRegister(), fromAddr);\n+        }\n+     }\n+\n+    }\n+\n+  } while (vt != 0);\n+\n+  if (mark_done && reg_state[from->value()] != reg_written) {\n+    \/\/ This is okay because no one else will write to that slot\n+    reg_state[from->value()] = reg_writable;\n+  }\n+  return done;\n+}\n+\n+\/\/ Pack fields back into an inline type oop\n+bool MacroAssembler::pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[]) {\n+  assert(sig->at(sig_index)._bt == T_INLINE_TYPE, \"should be at end delimiter\");\n+  assert(to->is_valid(), \"must be\");\n+\n+  if (reg_state[to->value()] == reg_written) {\n+    skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);\n+    return true; \/\/ Already written\n+  }\n+\n+  Register val_array = r0;\n+  Register val_obj_tmp = r11;\n+  Register from_reg_tmp = r10;\n+  Register tmp1 = r14;\n+  Register tmp2 = r13;\n+  Register tmp3 = r1;\n+  Register val_obj = to->is_stack() ? val_obj_tmp : to->as_Register();\n+\n+  if (reg_state[to->value()] == reg_readonly) {\n+    if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {\n+      skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);\n+      return false; \/\/ Not yet writable\n+    }\n+    val_obj = val_obj_tmp;\n+  }\n+\n+  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_INLINE_TYPE);\n+  load_heap_oop(val_obj, Address(val_array, index));\n+\n+  ScalarizedInlineArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n+  VMRegPair from_pair;\n+  BasicType bt;\n+\n+  while (stream.next(from_pair, bt)) {\n+    int off = sig->at(stream.sig_index())._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);\n+    size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;\n+\n+    VMReg from_r1 = from_pair.first();\n+    VMReg from_r2 = from_pair.second();\n+\n+    \/\/ Pack the scalarized field into the value object.\n+    Address dst(val_obj, off);\n+\n+    if (!from_r1->is_FloatRegister()) {\n+      Register from_reg;\n+      if (from_r1->is_stack()) {\n+        from_reg = from_reg_tmp;\n+        int ld_off = from_r1->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        load_sized_value(from_reg, Address(sp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+      } else {\n+        from_reg = from_r1->as_Register();\n+      }\n+\n+      if (is_oop) {\n+        DecoratorSet decorators = IN_HEAP | ACCESS_WRITE;\n+        store_heap_oop(dst, from_reg, tmp1, tmp2, tmp3, decorators);\n+      } else {\n+        store_sized_value(dst, from_reg, size_in_bytes);\n+      }\n+    } else {\n+      if (from_r2->is_valid()) {\n+        strd(from_r1->as_FloatRegister(), dst);\n+      } else {\n+        strs(from_r1->as_FloatRegister(), dst);\n+      }\n+    }\n+\n+    reg_state[from_r1->value()] = reg_writable;\n+  }\n+  sig_index = stream.sig_index();\n+  from_index = stream.regs_index();\n+\n+  assert(reg_state[to->value()] == reg_writable, \"must have already been read\");\n+  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state);\n+  assert(success, \"to register must be writeable\");\n+\n+  return true;\n+}\n+\n+VMReg MacroAssembler::spill_reg_for(VMReg reg) {\n+  return (reg->is_FloatRegister()) ? v0->as_VMReg() : r14->as_VMReg();\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":414,"deletions":10,"binary":false,"changes":424,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"utilities\/macros.hpp\"\n@@ -32,0 +33,4 @@\n+#include \"runtime\/signature.hpp\"\n+\n+\n+class ciInlineKlass;\n@@ -614,0 +619,10 @@\n+  void test_klass_is_value(Register klass, Register temp_reg, Label& is_value);\n+\n+  void test_field_is_inline_type(Register flags, Register temp_reg, Label& is_inline);\n+  void test_field_is_not_inline_type(Register flags, Register temp_reg, Label& not_inline);\n+  void test_field_is_inlined(Register flags, Register temp_reg, Label& is_flattened);\n+\n+  \/\/ Check klass\/oops is flat inline type array (oop->_klass->_layout_helper & vt_bit)\n+  void test_flattened_array_oop(Register klass, Register temp_reg, Label& is_flattened_array);\n+  void test_null_free_array_oop(Register oop, Register temp_reg, Label& is_null_free_array);\n+\n@@ -821,0 +836,3 @@\n+  void load_metadata(Register dst, Register src);\n+  void load_storage_props(Register dst, Register src);\n+\n@@ -833,1 +851,1 @@\n-                       Register tmp1, Register tmp_thread);\n+                       Register tmp1, Register tmp_thread, Register tmp3 = noreg);\n@@ -845,1 +863,1 @@\n-                      Register tmp_thread = noreg, DecoratorSet decorators = 0);\n+                      Register tmp_thread = noreg, Register tmp3 = noreg, DecoratorSet decorators = 0);\n@@ -1199,0 +1217,14 @@\n+  void verified_entry(Compile* C, int sp_inc);\n+\n+  \/\/ Inline type specific methods\n+  #include \"asm\/macroAssembler_common.hpp\"\n+\n+  int store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter = true);\n+  bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]);\n+  bool unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, VMRegPair* regs_to, int& to_index,\n+                            RegState reg_state[]);\n+  bool pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                          VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[]);\n+  void restore_stack(Compile* C);\n+  VMReg spill_reg_for(VMReg reg);\n+\n@@ -1263,0 +1295,2 @@\n+  void fill_words(Register base, uint64_t cnt, Register value);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":36,"deletions":2,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -311,1 +311,1 @@\n-    \/\/ T_OBJECT, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n+    \/\/ T_OBJECT, T_INLINE_TYPE, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n@@ -315,1 +315,1 @@\n-    Label is_long, is_float, is_double, exit;\n+    Label is_long, is_float, is_double, is_value, exit;\n@@ -319,0 +319,2 @@\n+    __ cmp(j_rarg1, (u1)T_INLINE_TYPE);\n+    __ br(Assembler::EQ, is_value);\n@@ -373,0 +375,13 @@\n+    __ BIND(is_value);\n+    if (InlineTypeReturnedAsFields) {\n+      \/\/ Check for flattened return value\n+      __ cbz(r0, is_long);\n+      \/\/ Initialize pre-allocated buffer\n+      __ mov(r1, r0);\n+      __ andr(r1, r1, -2);\n+      __ ldr(r1, Address(r1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      __ ldr(r1, Address(r1, InlineKlass::pack_handler_offset()));\n+      __ ldr(r0, Address(j_rarg2, 0));\n+      __ blr(r1);\n+      __ b(exit);\n+    }\n@@ -1845,1 +1860,1 @@\n-    __ store_heap_oop(__ post(to, UseCompressedOops ? 4 : 8), copied_oop, noreg, noreg, AS_RAW);  \/\/ store the oop\n+    __ store_heap_oop(__ post(to, UseCompressedOops ? 4 : 8), copied_oop, noreg, noreg, noreg, AS_RAW);  \/\/ store the oop\n@@ -6594,0 +6609,178 @@\n+  \/\/ Call here from the interpreter or compiled code to either load\n+  \/\/ multiple returned values from the inline type instance being\n+  \/\/ returned to registers or to store returned values to a newly\n+  \/\/ allocated inline type instance.\n+  address generate_return_value_stub(address destination, const char* name, bool has_res) {\n+\n+    \/\/ Information about frame layout at time of blocking runtime call.\n+    \/\/ Note that we only have to preserve callee-saved registers since\n+    \/\/ the compilers are responsible for supplying a continuation point\n+    \/\/ if they expect all registers to be preserved.\n+    \/\/ n.b. aarch64 asserts that frame::arg_reg_save_area_bytes == 0\n+    enum layout {\n+      rfp_off = 0, rfp_off2,\n+\n+      j_rarg7_off, j_rarg7_2,\n+      j_rarg6_off, j_rarg6_2,\n+      j_rarg5_off, j_rarg5_2,\n+      j_rarg4_off, j_rarg4_2,\n+      j_rarg3_off, j_rarg3_2,\n+      j_rarg2_off, j_rarg2_2,\n+      j_rarg1_off, j_rarg1_2,\n+      j_rarg0_off, j_rarg0_2,\n+\n+      j_farg0_off, j_farg0_2,\n+      j_farg1_off, j_farg1_2,\n+      j_farg2_off, j_farg2_2,\n+      j_farg3_off, j_farg3_2,\n+      j_farg4_off, j_farg4_2,\n+      j_farg5_off, j_farg5_2,\n+      j_farg6_off, j_farg6_2,\n+      j_farg7_off, j_farg7_2,\n+\n+      return_off, return_off2,\n+      framesize \/\/ inclusive of return address\n+    };\n+\n+    int insts_size = 512;\n+    int locs_size  = 64;\n+\n+    CodeBuffer code(name, insts_size, locs_size);\n+    OopMapSet* oop_maps  = new OopMapSet();\n+    MacroAssembler* masm = new MacroAssembler(&code);\n+\n+    address start = __ pc();\n+\n+    const Address f7_save       (rfp, j_farg7_off * wordSize);\n+    const Address f6_save       (rfp, j_farg6_off * wordSize);\n+    const Address f5_save       (rfp, j_farg5_off * wordSize);\n+    const Address f4_save       (rfp, j_farg4_off * wordSize);\n+    const Address f3_save       (rfp, j_farg3_off * wordSize);\n+    const Address f2_save       (rfp, j_farg2_off * wordSize);\n+    const Address f1_save       (rfp, j_farg1_off * wordSize);\n+    const Address f0_save       (rfp, j_farg0_off * wordSize);\n+\n+    const Address r0_save      (rfp, j_rarg0_off * wordSize);\n+    const Address r1_save      (rfp, j_rarg1_off * wordSize);\n+    const Address r2_save      (rfp, j_rarg2_off * wordSize);\n+    const Address r3_save      (rfp, j_rarg3_off * wordSize);\n+    const Address r4_save      (rfp, j_rarg4_off * wordSize);\n+    const Address r5_save      (rfp, j_rarg5_off * wordSize);\n+    const Address r6_save      (rfp, j_rarg6_off * wordSize);\n+    const Address r7_save      (rfp, j_rarg7_off * wordSize);\n+\n+    \/\/ Generate oop map\n+    OopMap* map = new OopMap(framesize, 0);\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(rfp_off), rfp->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg7_off), j_rarg7->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg6_off), j_rarg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+    \/\/ This is an inlined and slightly modified version of call_VM\n+    \/\/ which has the ability to fetch the return PC out of\n+    \/\/ thread-local storage and also sets up last_Java_sp slightly\n+    \/\/ differently than the real call_VM\n+\n+    __ enter(); \/\/ Save FP and LR before call\n+\n+    assert(is_even(framesize\/2), \"sp not 16-byte aligned\");\n+\n+    \/\/ lr and fp are already in place\n+    __ sub(sp, rfp, ((unsigned)framesize - 4) << LogBytesPerInt); \/\/ prolog\n+\n+    __ strd(j_farg7, f7_save);\n+    __ strd(j_farg6, f6_save);\n+    __ strd(j_farg5, f5_save);\n+    __ strd(j_farg4, f4_save);\n+    __ strd(j_farg3, f3_save);\n+    __ strd(j_farg2, f2_save);\n+    __ strd(j_farg1, f1_save);\n+    __ strd(j_farg0, f0_save);\n+\n+    __ str(j_rarg0, r0_save);\n+    __ str(j_rarg1, r1_save);\n+    __ str(j_rarg2, r2_save);\n+    __ str(j_rarg3, r3_save);\n+    __ str(j_rarg4, r4_save);\n+    __ str(j_rarg5, r5_save);\n+    __ str(j_rarg6, r6_save);\n+    __ str(j_rarg7, r7_save);\n+\n+    int frame_complete = __ pc() - start;\n+\n+    \/\/ Set up last_Java_sp and last_Java_fp\n+    address the_pc = __ pc();\n+    __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n+\n+    \/\/ Call runtime\n+    __ mov(c_rarg0, rthread);\n+    __ mov(c_rarg1, r0);\n+\n+    BLOCK_COMMENT(\"call runtime_entry\");\n+    __ mov(rscratch1, destination);\n+    __ blr(rscratch1);\n+\n+    oop_maps->add_gc_map(the_pc - start, map);\n+\n+    __ reset_last_Java_frame(false);\n+    __ maybe_isb();\n+\n+    __ ldrd(j_farg7, f7_save);\n+    __ ldrd(j_farg6, f6_save);\n+    __ ldrd(j_farg5, f5_save);\n+    __ ldrd(j_farg4, f4_save);\n+    __ ldrd(j_farg3, f3_save);\n+    __ ldrd(j_farg3, f2_save);\n+    __ ldrd(j_farg1, f1_save);\n+    __ ldrd(j_farg0, f0_save);\n+\n+    __ ldr(j_rarg0, r0_save);\n+    __ ldr(j_rarg1, r1_save);\n+    __ ldr(j_rarg2, r2_save);\n+    __ ldr(j_rarg3, r3_save);\n+    __ ldr(j_rarg4, r4_save);\n+    __ ldr(j_rarg5, r5_save);\n+    __ ldr(j_rarg6, r6_save);\n+    __ ldr(j_rarg7, r7_save);\n+\n+    __ leave();\n+\n+    \/\/ check for pending exceptions\n+    Label pending;\n+    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    __ cmp(rscratch1, (u1)NULL_WORD);\n+    __ br(Assembler::NE, pending);\n+\n+    if (has_res) {\n+      __ get_vm_result(r0, rthread);\n+    }\n+    __ ret(lr);\n+\n+    __ bind(pending);\n+    __ ldr(r0, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+\n+    \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n+    int frame_size_in_words = (framesize >> (LogBytesPerWord - LogBytesPerInt));\n+    RuntimeStub* stub =\n+      RuntimeStub::new_runtime_stub(name, &code, frame_complete, frame_size_in_words, oop_maps, false);\n+\n+    return stub->entry_point();\n+  }\n+\n@@ -6644,0 +6837,5 @@\n+    StubRoutines::_load_inline_type_fields_in_regs =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), \"load_inline_type_fields_in_regs\", false);\n+    StubRoutines::_store_inline_type_fields_to_buf =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), \"store_inline_type_fields_to_buf\", true);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":201,"deletions":3,"binary":false,"changes":204,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"asm\/macroAssembler.inline.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"gc\/shared\/barrierSetRuntime.hpp\"\n@@ -47,0 +49,1 @@\n+  assert(type != T_INLINE_TYPE, \"Not supported yet\");\n@@ -106,1 +109,1 @@\n-                                   Address dst, Register val, Register tmp1, Register tmp2) {\n+                                   Address dst, Register val, Register tmp1, Register tmp2, Register tmp3) {\n@@ -112,0 +115,1 @@\n+  assert(type != T_INLINE_TYPE, \"Not supported yet\");\n@@ -198,0 +202,14 @@\n+void BarrierSetAssembler::value_copy(MacroAssembler* masm, DecoratorSet decorators,\n+                                     Register src, Register dst, Register value_klass) {\n+  \/\/ value_copy implementation is fairly complex, and there are not any\n+  \/\/ \"short-cuts\" to be made from asm. What there is, appears to have the same\n+  \/\/ cost in C++, so just \"call_VM_leaf\" for now rather than maintain hundreds\n+  \/\/ of hand-rolled instructions...\n+  if (decorators & IS_DEST_UNINITIALIZED) {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy_is_dest_uninitialized), src, dst, value_klass);\n+  } else {\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, BarrierSetRuntime::value_copy), src, dst, value_klass);\n+  }\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":19,"deletions":1,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -131,1 +131,1 @@\n-                                                Address dst, Register val, Register tmp1, Register tmp2) {\n+                                                Address dst, Register val, Register tmp1, Register tmp2, Register tmp3) {\n@@ -140,1 +140,1 @@\n-  BarrierSetAssembler::store_at(masm, decorators, type, dst, val, noreg, noreg);\n+  BarrierSetAssembler::store_at(masm, decorators, type, dst, val, noreg, noreg, noreg);\n@@ -144,1 +144,8 @@\n-      store_check(masm, dst.base(), dst);\n+      if (tmp3 != noreg) {\n+        \/\/ Called by MacroAssembler::pack_inline_helper. We cannot corrupt the dst.base() register\n+        __ movptr(tmp3, dst.base());\n+        store_check(masm, tmp3, dst);\n+      } else {\n+        \/\/ It's OK to corrupt the dst.base() register.\n+        store_check(masm, dst.base(), dst);\n+      }\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/cardTableBarrierSetAssembler_x86.cpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -300,1 +300,1 @@\n-void ciReturnTypeEntry::translate_type_data_from(const ReturnTypeEntry* ret) {\n+void ciSingleTypeEntry::translate_type_data_from(const SingleTypeEntry* ret) {\n@@ -305,1 +305,1 @@\n-    set_type(ReturnTypeEntry::with_status((Klass*)NULL, k));\n+    set_type(SingleTypeEntry::with_status((Klass*)NULL, k));\n@@ -356,0 +356,4 @@\n+  case DataLayout::array_load_store_data_tag:\n+    return new ciArrayLoadStoreData(data_layout);\n+  case DataLayout::acmp_data_tag:\n+    return new ciACmpData(data_layout);\n@@ -750,0 +754,13 @@\n+      } else if (pdata->is_ArrayLoadStoreData()) {\n+        ciArrayLoadStoreData* array_load_store_data = (ciArrayLoadStoreData*)pdata;\n+        dump_replay_data_type_helper(out, round, count, array_load_store_data, ciArrayLoadStoreData::array_offset(),\n+                                     array_load_store_data->array()->valid_type());\n+        dump_replay_data_type_helper(out, round, count, array_load_store_data, ciArrayLoadStoreData::element_offset(),\n+                                     array_load_store_data->element()->valid_type());\n+      } else if (pdata->is_ACmpData()) {\n+        ciACmpData* acmp_data = (ciACmpData*)pdata;\n+        dump_replay_data_type_helper(out, round, count, acmp_data, ciACmpData::left_offset(),\n+                                     acmp_data->left()->valid_type());\n+        dump_replay_data_type_helper(out, round, count, acmp_data, ciACmpData::right_offset(),\n+                                     acmp_data->right()->valid_type());\n+\n@@ -832,1 +849,1 @@\n-void ciReturnTypeEntry::print_data_on(outputStream* st) const {\n+void ciSingleTypeEntry::print_data_on(outputStream* st) const {\n@@ -905,0 +922,21 @@\n+\n+void ciArrayLoadStoreData::print_data_on(outputStream* st, const char* extra) const {\n+  print_shared(st, \"ciArrayLoadStoreData\", extra);\n+  tab(st, true);\n+  st->print(\"array\");\n+  array()->print_data_on(st);\n+  tab(st, true);\n+  st->print(\"element\");\n+  element()->print_data_on(st);\n+}\n+\n+void ciACmpData::print_data_on(outputStream* st, const char* extra) const {\n+  BranchData::print_data_on(st, extra);\n+  st->cr();\n+  tab(st, true);\n+  st->print(\"left\");\n+  left()->print_data_on(st);\n+  tab(st, true);\n+  st->print(\"right\");\n+  right()->print_data_on(st);\n+}\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.cpp","additions":41,"deletions":3,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -205,1 +205,1 @@\n-    if (*start == JVM_SIGNATURE_CLASS) {\n+    if (*start == JVM_SIGNATURE_CLASS || *start == JVM_SIGNATURE_INLINE_TYPE) {\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -44,0 +44,2 @@\n+\/\/ For INLINE_FIELD, set when loading inline type fields for\n+\/\/ class circularity checking.\n@@ -84,0 +86,3 @@\n+    case PlaceholderTable::INLINE_TYPE_FIELD:\n+       queuehead = _inlineTypeFieldQ;\n+       break;\n@@ -100,0 +105,3 @@\n+    case PlaceholderTable::INLINE_TYPE_FIELD:\n+       _inlineTypeFieldQ = seenthread;\n+       break;\n@@ -187,0 +195,1 @@\n+  entry->set_inlineTypeFieldQ(NULL);\n@@ -267,0 +276,1 @@\n+  case PlaceholderTable::INLINE_TYPE_FIELD: return \"INLINE_TYPE_FIELD\";\n@@ -332,1 +342,2 @@\n-          && (probe->defineThreadQ() == NULL) && (probe->definer() == NULL)) {\n+          && (probe->defineThreadQ() == NULL) && (probe->definer() == NULL)\n+          && (probe->inlineTypeFieldQ() == NULL)) {\n@@ -387,0 +398,3 @@\n+  st->print(\"inlineTypeFieldQ threads:\");\n+  inlineTypeFieldQ()->print_action_queue(st);\n+  st->cr();\n","filename":"src\/hotspot\/share\/classfile\/placeholders.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -76,0 +76,1 @@\n+\/\/ INLINE_TYPE_FIELD: needed to check for inline type fields circularity\n@@ -79,1 +80,2 @@\n-    DEFINE_CLASS = 3               \/\/ find_or_define class\n+    DEFINE_CLASS = 3,              \/\/ find_or_define class\n+    INLINE_TYPE_FIELD = 4          \/\/ inline type fields\n@@ -130,0 +132,1 @@\n+  SeenThread*       _inlineTypeFieldQ;  \/\/ queue of inline types for circularity checking\n@@ -164,0 +167,3 @@\n+  SeenThread*        inlineTypeFieldQ()    const { return _inlineTypeFieldQ; }\n+  void               set_inlineTypeFieldQ(SeenThread* SeenThread) { _inlineTypeFieldQ = SeenThread; }\n+\n@@ -190,0 +196,4 @@\n+  bool inline_type_field_in_progress() {\n+    return (_inlineTypeFieldQ != NULL);\n+  }\n+\n","filename":"src\/hotspot\/share\/classfile\/placeholders.hpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -69,0 +70,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -77,0 +79,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -288,1 +291,1 @@\n-    \/\/ Ignore wrapping L and ;.\n+    \/\/ Ignore wrapping L and ;. (and Q and ; for value types);\n@@ -316,0 +319,4 @@\n+      if ((class_name->is_Q_array_signature() && !k->is_inline_klass()) ||\n+          (!class_name->is_Q_array_signature() && k->is_inline_klass())) {\n+            THROW_MSG_NULL(vmSymbols::java_lang_IncompatibleClassChangeError(), \"L\/Q mismatch on bottom type\");\n+          }\n@@ -325,1 +332,0 @@\n-\n@@ -458,0 +464,44 @@\n+Klass* SystemDictionary::resolve_inline_type_field_or_fail(AllFieldStream* fs,\n+                                                           Handle class_loader,\n+                                                           Handle protection_domain,\n+                                                           bool throw_error,\n+                                                           TRAPS) {\n+  Symbol* class_name = fs->signature()->fundamental_name(THREAD);\n+  class_loader = Handle(THREAD, java_lang_ClassLoader::non_reflection_class_loader(class_loader()));\n+  ClassLoaderData* loader_data = class_loader_data(class_loader);\n+  unsigned int p_hash = placeholders()->compute_hash(class_name);\n+  bool throw_circularity_error = false;\n+  PlaceholderEntry* oldprobe;\n+\n+  {\n+    MutexLocker mu(THREAD, SystemDictionary_lock);\n+    oldprobe = placeholders()->get_entry(p_hash, class_name, loader_data);\n+    if (oldprobe != NULL &&\n+      oldprobe->check_seen_thread(THREAD, PlaceholderTable::INLINE_TYPE_FIELD)) {\n+      throw_circularity_error = true;\n+\n+    } else {\n+      placeholders()->find_and_add(p_hash, class_name, loader_data,\n+                                   PlaceholderTable::INLINE_TYPE_FIELD, NULL, THREAD);\n+    }\n+  }\n+\n+  Klass* klass = NULL;\n+  if (!throw_circularity_error) {\n+    klass = SystemDictionary::resolve_or_fail(class_name, class_loader,\n+                                               protection_domain, true, THREAD);\n+  } else {\n+    ResourceMark rm(THREAD);\n+    THROW_MSG_NULL(vmSymbols::java_lang_ClassCircularityError(), class_name->as_C_string());\n+  }\n+\n+  {\n+    MutexLocker mu(THREAD, SystemDictionary_lock);\n+    placeholders()->find_and_remove(p_hash, class_name, loader_data,\n+                                    PlaceholderTable::INLINE_TYPE_FIELD, THREAD);\n+  }\n+\n+  class_name->decrement_refcount();\n+  return klass;\n+}\n+\n@@ -941,1 +991,1 @@\n-    if (t != T_OBJECT) {\n+    if (t != T_OBJECT && t != T_INLINE_TYPE) {\n@@ -1318,0 +1368,18 @@\n+\n+  if (ik->has_inline_type_fields()) {\n+    for (AllFieldStream fs(ik->fields(), ik->constants()); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {\n+        if (!fs.access_flags().is_static()) {\n+          \/\/ Pre-load inline class\n+          Klass* real_k = SystemDictionary::resolve_inline_type_field_or_fail(&fs,\n+            class_loader, protection_domain, true, CHECK_NULL);\n+          Klass* k = ik->get_inline_type_field_klass_or_null(fs.index());\n+          if (real_k != k) {\n+            \/\/ oops, the app has substituted a different version of k!\n+            return NULL;\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1353,0 +1421,7 @@\n+\n+  if (ik->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(ik);\n+    oop val = ik->allocate_instance(CHECK_NULL);\n+    vk->set_default_value(val);\n+  }\n+\n@@ -1913,1 +1988,1 @@\n-    if (t != T_OBJECT) {\n+    if (t != T_OBJECT && t != T_INLINE_TYPE) {\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":79,"deletions":4,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -76,0 +76,1 @@\n+class AllFieldStream;\n@@ -125,0 +126,6 @@\n+  static Klass* resolve_inline_type_field_or_fail(AllFieldStream* fs,\n+                                                  Handle class_loader,\n+                                                  Handle protection_domain,\n+                                                  bool throw_error,\n+                                                  TRAPS);\n+\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -247,1 +247,1 @@\n-                                    bool& needs_ic_stub_refill, TRAPS) {\n+                                    bool& needs_ic_stub_refill, bool caller_is_c1, TRAPS) {\n@@ -256,1 +256,1 @@\n-    entry = VtableStubs::find_itable_stub(itable_index);\n+    entry = VtableStubs::find_itable_stub(itable_index, caller_is_c1);\n@@ -279,1 +279,1 @@\n-    entry = VtableStubs::find_vtable_stub(vtable_index);\n+    entry = VtableStubs::find_vtable_stub(vtable_index, caller_is_c1);\n@@ -514,0 +514,1 @@\n+                                           bool caller_is_c1,\n@@ -539,1 +540,1 @@\n-      entry      = method_code->verified_entry_point();\n+      entry      = caller_is_c1 ? method_code->verified_inline_entry_point() : method_code->verified_entry_point();\n@@ -541,1 +542,1 @@\n-      entry      = method_code->entry_point();\n+      entry      = caller_is_c1 ? method_code->inline_entry_point() : method_code->entry_point();\n@@ -555,1 +556,2 @@\n-        info.set_interpreter_entry(method()->get_c2i_entry(), method());\n+        address entry = caller_is_c1 ? method()->get_c2i_inline_entry() : method()->get_c2i_entry();\n+        info.set_interpreter_entry(entry, method());\n@@ -561,1 +563,2 @@\n-      info.set_icholder_entry(method()->get_c2i_unverified_entry(), holder);\n+      entry = (caller_is_c1)? method()->get_c2i_unverified_inline_entry() : method()->get_c2i_unverified_entry();\n+      info.set_icholder_entry(entry, holder);\n@@ -660,1 +663,2 @@\n-void CompiledStaticCall::compute_entry(const methodHandle& m, bool caller_is_nmethod, StaticCallInfo& info) {\n+void CompiledStaticCall::compute_entry(const methodHandle& m, CompiledMethod* caller_nm, StaticCallInfo& info) {\n+  bool caller_is_nmethod = caller_nm->is_nmethod();\n@@ -671,1 +675,5 @@\n-    info._entry  = m_code->verified_entry_point();\n+    if (caller_nm->is_compiled_by_c1()) {\n+      info._entry = m_code->verified_inline_entry_point();\n+    } else {\n+      info._entry = m_code->verified_entry_point();\n+    }\n@@ -677,1 +685,8 @@\n-    info._entry      = m()->get_c2i_entry();\n+\n+    if (caller_nm->is_compiled_by_c1()) {\n+      \/\/ C1 -> interp: values passed as oops\n+      info._entry = m()->get_c2i_inline_entry();\n+    } else {\n+      \/\/ C2 -> interp: values passed fields\n+      info._entry = m()->get_c2i_entry();\n+    }\n","filename":"src\/hotspot\/share\/code\/compiledIC.cpp","additions":25,"deletions":10,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -363,7 +363,0 @@\n-    SimpleScopeDesc ssd(this, pc);\n-    if (ssd.is_optimized_linkToNative()) return; \/\/ call was replaced\n-    Bytecode_invoke call(methodHandle(Thread::current(), ssd.method()), ssd.bci());\n-    bool has_receiver = call.has_receiver();\n-    bool has_appendix = call.has_appendix();\n-    Symbol* signature = call.signature();\n-\n@@ -373,0 +366,3 @@\n+    bool has_receiver = false;\n+    bool has_appendix = false;\n+    Symbol* signature = NULL;\n@@ -377,0 +373,18 @@\n+\n+      \/\/ If inline types are passed as fields, use the extended signature\n+      \/\/ which contains the types of all (oop) fields of the inline type.\n+      if (this->is_compiled_by_c2() && callee->has_scalarized_args()) {\n+        const GrowableArray<SigEntry>* sig = callee->adapter()->get_sig_cc();\n+        assert(sig != NULL, \"sig should never be null\");\n+        TempNewSymbol tmp_sig = SigEntry::create_symbol(sig);\n+        has_receiver = false; \/\/ The extended signature contains the receiver type\n+        fr.oops_compiled_arguments_do(tmp_sig, has_receiver, has_appendix, reg_map, f);\n+        return;\n+      }\n+    } else {\n+      SimpleScopeDesc ssd(this, pc);\n+      if (ssd.is_optimized_linkToNative()) return; \/\/ call was replaced\n+      Bytecode_invoke call(methodHandle(Thread::current(), ssd.method()), ssd.bci());\n+      has_receiver = call.has_receiver();\n+      has_appendix = call.has_appendix();\n+      signature = call.signature();\n","filename":"src\/hotspot\/share\/code\/compiledMethod.cpp","additions":21,"deletions":7,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -646,0 +646,6 @@\n+\n+    assert(!method->has_scalarized_args(), \"scalarized native wrappers not supported yet\"); \/\/ for the next 3 fields\n+    _inline_entry_point       = _entry_point;\n+    _verified_inline_entry_point = _verified_entry_point;\n+    _verified_inline_ro_entry_point = _verified_entry_point;\n+\n@@ -819,0 +825,3 @@\n+    _inline_entry_point       = code_begin()         + offsets->value(CodeOffsets::Inline_Entry);\n+    _verified_inline_entry_point = code_begin()      + offsets->value(CodeOffsets::Verified_Inline_Entry);\n+    _verified_inline_ro_entry_point = code_begin()   + offsets->value(CodeOffsets::Verified_Inline_Entry_RO);\n@@ -938,0 +947,3 @@\n+static nmethod* _nmethod_to_print = NULL;\n+static const CompiledEntrySignature* _nmethod_to_print_ces = NULL;\n+\n@@ -939,0 +951,6 @@\n+  ResourceMark rm;\n+  CompiledEntrySignature ces(method());\n+  ces.compute_calling_conventions();\n+  \/\/ ces.compute_calling_conventions() needs to grab the ProtectionDomainSet_lock, so we\n+  \/\/ can't do that (inside nmethod::print_entry_parameters) while holding the ttyLocker.\n+  \/\/ Hence we have do compute it here and pass via a global. Yuck.\n@@ -940,0 +958,3 @@\n+  assert(_nmethod_to_print == NULL && _nmethod_to_print_ces == NULL, \"no nesting\");\n+  _nmethod_to_print = this;\n+  _nmethod_to_print_ces = &ces;\n@@ -1019,0 +1040,3 @@\n+\n+  _nmethod_to_print = NULL;\n+  _nmethod_to_print_ces = NULL;\n@@ -3098,0 +3122,1 @@\n+  if (pos == inline_entry_point())                                      label = \"[Inline Entry Point]\";\n@@ -3099,0 +3124,2 @@\n+  if (pos == verified_inline_entry_point())                             label = \"[Verified Inline Entry Point]\";\n+  if (pos == verified_inline_ro_entry_point())                          label = \"[Verified Inline Entry Point (RO)]\";\n@@ -3108,0 +3135,10 @@\n+static int maybe_print_entry_label(outputStream* stream, address pos, address entry, const char* label) {\n+  if (pos == entry) {\n+    stream->bol();\n+    stream->print_cr(\"%s\", label);\n+    return 1;\n+  } else {\n+    return 0;\n+  }\n+}\n+\n@@ -3110,33 +3147,12 @@\n-    const char* label = nmethod_section_label(block_begin);\n-    if (label != NULL) {\n-      stream->bol();\n-      stream->print_cr(\"%s\", label);\n-    }\n-  }\n-\n-  if (block_begin == entry_point()) {\n-    Method* m = method();\n-    if (m != NULL) {\n-      stream->print(\"  # \");\n-      m->print_value_on(stream);\n-      stream->cr();\n-    }\n-    if (m != NULL && !is_osr_method()) {\n-      ResourceMark rm;\n-      int sizeargs = m->size_of_parameters();\n-      BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sizeargs);\n-      VMRegPair* regs   = NEW_RESOURCE_ARRAY(VMRegPair, sizeargs);\n-      {\n-        int sig_index = 0;\n-        if (!m->is_static())\n-          sig_bt[sig_index++] = T_OBJECT; \/\/ 'this'\n-        for (SignatureStream ss(m->signature()); !ss.at_return_type(); ss.next()) {\n-          BasicType t = ss.type();\n-          sig_bt[sig_index++] = t;\n-          if (type2size[t] == 2) {\n-            sig_bt[sig_index++] = T_VOID;\n-          } else {\n-            assert(type2size[t] == 1, \"size is 1 or 2\");\n-          }\n-        }\n-        assert(sig_index == sizeargs, \"\");\n+    int n = 0;\n+    \/\/ Multiple entry points may be at the same position. Print them all.\n+    n += maybe_print_entry_label(stream, block_begin, entry_point(),                    \"[Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, inline_entry_point(),             \"[Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_entry_point(),           \"[Verified Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_entry_point(),    \"[Verified Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_ro_entry_point(), \"[Verified Inline Entry Point (RO)]\");\n+    if (n == 0) {\n+      const char* label = nmethod_section_label(block_begin);\n+      if (label != NULL) {\n+        stream->bol();\n+        stream->print_cr(\"%s\", label);\n@@ -3144,54 +3160,65 @@\n-      const char* spname = \"sp\"; \/\/ make arch-specific?\n-      intptr_t out_preserve = SharedRuntime::java_calling_convention(sig_bt, regs, sizeargs);\n-      int stack_slot_offset = this->frame_size() * wordSize;\n-      int tab1 = 14, tab2 = 24;\n-      int sig_index = 0;\n-      int arg_index = (m->is_static() ? 0 : -1);\n-      bool did_old_sp = false;\n-      for (SignatureStream ss(m->signature()); !ss.at_return_type(); ) {\n-        bool at_this = (arg_index == -1);\n-        bool at_old_sp = false;\n-        BasicType t = (at_this ? T_OBJECT : ss.type());\n-        assert(t == sig_bt[sig_index], \"sigs in sync\");\n-        if (at_this)\n-          stream->print(\"  # this: \");\n-        else\n-          stream->print(\"  # parm%d: \", arg_index);\n-        stream->move_to(tab1);\n-        VMReg fst = regs[sig_index].first();\n-        VMReg snd = regs[sig_index].second();\n-        if (fst->is_reg()) {\n-          stream->print(\"%s\", fst->name());\n-          if (snd->is_valid())  {\n-            stream->print(\":%s\", snd->name());\n-          }\n-        } else if (fst->is_stack()) {\n-          int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n-          if (offset == stack_slot_offset)  at_old_sp = true;\n-          stream->print(\"[%s+0x%x]\", spname, offset);\n-        } else {\n-          stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n-        }\n-        stream->print(\" \");\n-        stream->move_to(tab2);\n-        stream->print(\"= \");\n-        if (at_this) {\n-          m->method_holder()->print_value_on(stream);\n-        } else {\n-          bool did_name = false;\n-          if (!at_this && ss.is_reference()) {\n-            Symbol* name = ss.as_symbol();\n-            name->print_value_on(stream);\n-            did_name = true;\n-          }\n-          if (!did_name)\n-            stream->print(\"%s\", type2name(t));\n-        }\n-        if (at_old_sp) {\n-          stream->print(\"  (%s of caller)\", spname);\n-          did_old_sp = true;\n-        }\n-        stream->cr();\n-        sig_index += type2size[t];\n-        arg_index += 1;\n-        if (!at_this)  ss.next();\n+    }\n+  }\n+\n+  if (_nmethod_to_print != this) {\n+    return;\n+  }\n+  Method* m = method();\n+  if (m == NULL || is_osr_method()) {\n+    return;\n+  }\n+\n+  \/\/ Print the name of the method (only once)\n+  address low = MIN4(entry_point(), verified_entry_point(), verified_inline_entry_point(), verified_inline_ro_entry_point());\n+  low = MIN2(low, inline_entry_point());\n+  assert(low != 0, \"sanity\");\n+  if (block_begin == low) {\n+    stream->print(\"  # \");\n+    m->print_value_on(stream);\n+    stream->cr();\n+  }\n+\n+  \/\/ Print the arguments for the 3 types of verified entry points\n+  const CompiledEntrySignature* ces = _nmethod_to_print_ces;\n+  const GrowableArray<SigEntry>* sig_cc;\n+  const VMRegPair* regs;\n+  if (block_begin == verified_entry_point()) {\n+    sig_cc = &ces->sig_cc();\n+    regs = ces->regs_cc();\n+  } else if (block_begin == verified_inline_entry_point()) {\n+    sig_cc = &ces->sig();\n+    regs = ces->regs();\n+  } else if (block_begin == verified_inline_ro_entry_point()) {\n+    sig_cc = &ces->sig_cc_ro();\n+    regs = ces->regs_cc_ro();\n+  } else {\n+    return;\n+  }\n+\n+  bool has_this = !m->is_static();\n+  if (ces->has_inline_recv() && block_begin == verified_entry_point()) {\n+    \/\/ <this> argument is scalarized for verified_entry_point()\n+    has_this = false;\n+  }\n+  const char* spname = \"sp\"; \/\/ make arch-specific?\n+  int stack_slot_offset = this->frame_size() * wordSize;\n+  int tab1 = 14, tab2 = 24;\n+  int sig_index = 0;\n+  int arg_index = has_this ? -1 : 0;\n+  bool did_old_sp = false;\n+  for (ExtendedSignature sig = ExtendedSignature(sig_cc, SigEntryFilter()); !sig.at_end(); ++sig) {\n+    bool at_this = (arg_index == -1);\n+    bool at_old_sp = false;\n+    BasicType t = (*sig)._bt;\n+    if (at_this) {\n+      stream->print(\"  # this: \");\n+    } else {\n+      stream->print(\"  # parm%d: \", arg_index);\n+    }\n+    stream->move_to(tab1);\n+    VMReg fst = regs[sig_index].first();\n+    VMReg snd = regs[sig_index].second();\n+    if (fst->is_reg()) {\n+      stream->print(\"%s\", fst->name());\n+      if (snd->is_valid())  {\n+        stream->print(\":%s\", snd->name());\n@@ -3199,6 +3226,18 @@\n-      if (!did_old_sp) {\n-        stream->print(\"  # \");\n-        stream->move_to(tab1);\n-        stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n-        stream->print(\"  (%s of caller)\", spname);\n-        stream->cr();\n+    } else if (fst->is_stack()) {\n+      int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n+      if (offset == stack_slot_offset)  at_old_sp = true;\n+      stream->print(\"[%s+0x%x]\", spname, offset);\n+    } else {\n+      stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n+    }\n+    stream->print(\" \");\n+    stream->move_to(tab2);\n+    stream->print(\"= \");\n+    if (at_this) {\n+      m->method_holder()->print_value_on(stream);\n+    } else {\n+      bool did_name = false;\n+      if (is_reference_type(t)) {\n+        Symbol* name = (*sig)._symbol;\n+        name->print_value_on(stream);\n+        did_name = true;\n@@ -3206,0 +3245,2 @@\n+      if (!did_name)\n+        stream->print(\"%s\", type2name(t));\n@@ -3207,0 +3248,14 @@\n+    if (at_old_sp) {\n+      stream->print(\"  (%s of caller)\", spname);\n+      did_old_sp = true;\n+    }\n+    stream->cr();\n+    sig_index += type2size[t];\n+    arg_index += 1;\n+  }\n+  if (!did_old_sp) {\n+    stream->print(\"  # \");\n+    stream->move_to(tab1);\n+    stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n+    stream->print(\"  (%s of caller)\", spname);\n+    stream->cr();\n@@ -3330,1 +3385,1 @@\n-      st->print(\" {reexecute=%d rethrow=%d return_oop=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop());\n+      st->print(\" {reexecute=%d rethrow=%d return_oop=%d return_vt=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop(), sd->return_vt());\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":149,"deletions":94,"binary":false,"changes":243,"status":"modified"},{"patch":"@@ -128,2 +128,2 @@\n-void CardTableBarrierSetC2::clone(GraphKit* kit, Node* src, Node* dst, Node* size, bool is_array) const {\n-  BarrierSetC2::clone(kit, src, dst, size, is_array);\n+void CardTableBarrierSetC2::clone(GraphKit* kit, Node* src_base, Node* dst_base, Node* countx, bool is_array) const {\n+  BarrierSetC2::clone(kit, src_base, dst_base, countx, is_array);\n@@ -144,1 +144,1 @@\n-                 dst,\n+                 dst_base,\n@@ -161,1 +161,1 @@\n-void CardTableBarrierSetC2::eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const {\n+void CardTableBarrierSetC2::eliminate_gc_barrier(PhaseIterGVN* igvn, Node* node) const {\n@@ -163,10 +163,16 @@\n-  Node *shift = node->unique_out();\n-  Node *addp = shift->unique_out();\n-  for (DUIterator_Last jmin, j = addp->last_outs(jmin); j >= jmin; --j) {\n-    Node *mem = addp->last_out(j);\n-    if (UseCondCardMark && mem->is_Load()) {\n-      assert(mem->Opcode() == Op_LoadB, \"unexpected code shape\");\n-      \/\/ The load is checking if the card has been written so\n-      \/\/ replace it with zero to fold the test.\n-      macro->replace_node(mem, macro->intcon(0));\n-      continue;\n+  for (DUIterator_Last imin, i = node->last_outs(imin); i >= imin; --i) {\n+    Node* shift = node->last_out(i);\n+    for (DUIterator_Last jmin, j = shift->last_outs(jmin); j >= jmin; --j) {\n+      Node* addp = shift->last_out(j);\n+      for (DUIterator_Last kmin, k = addp->last_outs(kmin); k >= kmin; --k) {\n+        Node* mem = addp->last_out(k);\n+        if (UseCondCardMark && mem->is_Load()) {\n+          assert(mem->Opcode() == Op_LoadB, \"unexpected code shape\");\n+          \/\/ The load is checking if the card has been written so\n+          \/\/ replace it with zero to fold the test.\n+          igvn->replace_node(mem, igvn->intcon(0));\n+          continue;\n+        }\n+        assert(mem->is_Store(), \"store required\");\n+        igvn->replace_node(mem, mem->in(MemNode::Memory));\n+      }\n@@ -174,2 +180,0 @@\n-    assert(mem->is_Store(), \"store required\");\n-    macro->replace_node(mem, mem->in(MemNode::Memory));\n@@ -180,1 +184,1 @@\n-  bool is_oop = is_reference_type(type);\n+  bool is_oop = type == T_OBJECT || type == T_ARRAY;\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/cardTableBarrierSetC2.cpp","additions":21,"deletions":17,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -56,0 +56,2 @@\n+  address _c2i_inline_ro_entry_trampoline;\n+  address _c2i_inline_entry_trampoline;\n@@ -59,0 +61,2 @@\n+  address c2i_inline_ro_entry_trampoline() { return _c2i_inline_ro_entry_trampoline; }\n+  address c2i_inline_entry_trampoline() { return _c2i_inline_entry_trampoline; }\n@@ -61,0 +65,2 @@\n+  void set_c2i_inline_ro_entry_trampoline(address addr) { _c2i_inline_ro_entry_trampoline = addr; }\n+  void set_c2i_inline_entry_trampoline(address addr) { _c2i_inline_entry_trampoline = addr; }\n@@ -458,1 +464,0 @@\n-    assert(type == _method_entry_ref, \"only special type allowed for now\");\n@@ -461,1 +466,1 @@\n-    _builder->add_special_ref(type, src_obj, field_offset);\n+    _builder->add_special_ref(type, src_obj, field_offset, ref->size() * BytesPerWord);\n@@ -505,4 +510,0 @@\n-void ArchiveBuilder::add_special_ref(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset) {\n-  _special_refs->append(SpecialRefInfo(type, src_obj, field_offset));\n-}\n-\n@@ -700,2 +701,18 @@\n-    assert(s.type() == MetaspaceClosure::_method_entry_ref, \"only special type allowed for now\");\n-    assert(*src_p == *dst_p, \"must be a copy\");\n+\n+    MetaspaceClosure::assert_valid(s.type());\n+    switch (s.type()) {\n+    case MetaspaceClosure::_method_entry_ref:\n+      assert(*src_p == *dst_p, \"must be a copy\");\n+      break;\n+    case MetaspaceClosure::_internal_pointer_ref:\n+      {\n+        \/\/ *src_p points to a location inside src_obj. Let's make *dst_p point to\n+        \/\/ the same location inside dst_obj.\n+        size_t off = pointer_delta(*((address*)src_p), src_obj, sizeof(u1));\n+        assert(off < s.src_obj_size_in_bytes(), \"must point to internal address\");\n+        *((address*)dst_p) = dst_obj + off;\n+      }\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n@@ -1112,0 +1129,4 @@\n+        info->set_c2i_inline_ro_entry_trampoline(\n+         (address)mc_region()->allocate(SharedRuntime::trampoline_size()));\n+        info->set_c2i_inline_entry_trampoline(\n+         (address)mc_region()->allocate(SharedRuntime::trampoline_size()));\n@@ -1135,1 +1156,1 @@\n-    align_up(SharedRuntime::trampoline_size(), BytesPerWord) +\n+    align_up(SharedRuntime::trampoline_size(), BytesPerWord) * 3 +\n@@ -1181,0 +1202,2 @@\n+        m->set_from_compiled_inline_ro_entry(info->c2i_inline_ro_entry_trampoline());\n+        m->set_from_compiled_inline_entry(info->c2i_inline_entry_trampoline());\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.cpp","additions":32,"deletions":9,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -105,0 +105,1 @@\n+    DEBUG_ONLY(size_t _src_obj_size_in_bytes;)\n@@ -108,2 +109,4 @@\n-    SpecialRefInfo(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset)\n-      : _type(type), _src_obj(src_obj), _field_offset(field_offset) {}\n+    SpecialRefInfo(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset, size_t src_obj_size_in_bytes)\n+      : _type(type), _src_obj(src_obj), _field_offset(field_offset) {\n+      DEBUG_ONLY(_src_obj_size_in_bytes = src_obj_size_in_bytes);\n+    }\n@@ -114,0 +117,2 @@\n+\n+    DEBUG_ONLY(size_t src_obj_size_in_bytes() const { return _src_obj_size_in_bytes; })\n@@ -348,1 +353,3 @@\n-  void add_special_ref(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset);\n+  void add_special_ref(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset, size_t src_obj_size_in_bytes) {\n+    _special_refs->append(SpecialRefInfo(type, src_obj, field_offset, src_obj_size_in_bytes));\n+  }\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.hpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n@@ -62,1 +64,3 @@\n-  f(TypeArrayKlass)\n+  f(TypeArrayKlass) \\\n+  f(FlatArrayKlass) \\\n+  f(InlineKlass)\n","filename":"src\/hotspot\/share\/memory\/cppVtables.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -138,1 +138,1 @@\n-  assert(!p->mark().has_bias_pattern(),\n+  assert(!UseBiasedLocking || !p->mark().has_bias_pattern(),\n@@ -276,1 +276,1 @@\n-    archived_oop->set_mark(markWord::prototype().copy_set_hash(hash_original));\n+    archived_oop->set_mark(markWord::prototype_for_klass(archived_oop->klass()).copy_set_hash(hash_original));\n","filename":"src\/hotspot\/share\/memory\/heapShared.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -58,0 +58,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n","filename":"src\/hotspot\/share\/memory\/metaspaceShared.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -232,1 +233,1 @@\n-      \/\/ All of these should have been reverted back to ClassIndex before calling\n+      \/\/ All of these should have been reverted back to Unresolved before calling\n@@ -256,0 +257,1 @@\n+  jbyte qdesc_bit = (name->is_Q_signature()) ? (jbyte) JVM_CONSTANT_QDescBit : 0;\n@@ -257,1 +259,1 @@\n-    release_tag_at_put(class_index, JVM_CONSTANT_Class);\n+    release_tag_at_put(class_index, JVM_CONSTANT_Class | qdesc_bit);\n@@ -259,1 +261,1 @@\n-    release_tag_at_put(class_index, JVM_CONSTANT_UnresolvedClass);\n+    release_tag_at_put(class_index, JVM_CONSTANT_UnresolvedClass | qdesc_bit);\n@@ -273,0 +275,1 @@\n+  assert(!k->name()->is_Q_signature(), \"Q-type without JVM_CONSTANT_QDescBit\");\n@@ -409,0 +412,1 @@\n+    jbyte qdesc_bit = tag_at(index).is_Qdescriptor_klass() ? (jbyte) JVM_CONSTANT_QDescBit : 0;\n@@ -410,1 +414,1 @@\n-      tag_at_put(index, JVM_CONSTANT_UnresolvedClass);\n+      tag_at_put(index, JVM_CONSTANT_UnresolvedClass | qdesc_bit);\n@@ -435,1 +439,1 @@\n-        tag_at_put(index, JVM_CONSTANT_UnresolvedClass);\n+        tag_at_put(index, JVM_CONSTANT_UnresolvedClass | qdesc_bit);\n@@ -485,0 +489,6 @@\n+void check_is_inline_type(Klass* k, TRAPS) {\n+  if (!k->is_inline_klass()) {\n+    THROW(vmSymbols::java_lang_IncompatibleClassChangeError());\n+  }\n+}\n+\n@@ -518,0 +528,5 @@\n+  bool inline_type_signature = false;\n+  if (name->is_Q_signature()) {\n+    name = name->fundamental_name(THREAD);\n+    inline_type_signature = true;\n+  }\n@@ -527,0 +542,3 @@\n+  if (inline_type_signature) {\n+    name->decrement_refcount();\n+  }\n@@ -535,0 +553,16 @@\n+  if (!HAS_PENDING_EXCEPTION && inline_type_signature) {\n+    check_is_inline_type(k, THREAD);\n+  }\n+\n+  if (!HAS_PENDING_EXCEPTION) {\n+    Klass* bottom_klass = NULL;\n+    if (k->is_objArray_klass()) {\n+      bottom_klass = ObjArrayKlass::cast(k)->bottom_klass();\n+      assert(bottom_klass != NULL, \"Should be set\");\n+      assert(bottom_klass->is_instance_klass() || bottom_klass->is_typeArray_klass(), \"Sanity check\");\n+    } else if (k->is_flatArray_klass()) {\n+      bottom_klass = FlatArrayKlass::cast(k)->element_klass();\n+      assert(bottom_klass != NULL, \"Should be set\");\n+    }\n+  }\n+\n@@ -539,1 +573,5 @@\n-      save_and_throw_exception(this_cp, which, constantTag(JVM_CONSTANT_UnresolvedClass), CHECK_NULL);\n+      jbyte tag = JVM_CONSTANT_UnresolvedClass;\n+      if (this_cp->tag_at(which).is_Qdescriptor_klass()) {\n+        tag |= JVM_CONSTANT_QDescBit;\n+      }\n+      save_and_throw_exception(this_cp, which, constantTag(tag), CHECK_NULL);\n@@ -560,1 +598,5 @@\n-  this_cp->release_tag_at_put(which, JVM_CONSTANT_Class);\n+  jbyte tag = JVM_CONSTANT_Class;\n+  if (this_cp->tag_at(which).is_Qdescriptor_klass()) {\n+    tag |= JVM_CONSTANT_QDescBit;\n+  }\n+  this_cp->release_tag_at_put(which, tag);\n@@ -1884,0 +1926,6 @@\n+      case (JVM_CONSTANT_Class | JVM_CONSTANT_QDescBit): {\n+        idx1 = Bytes::get_Java_u2(bytes);\n+        printf(\"qclass        #%03d\", idx1);\n+        ent_size = 2;\n+        break;\n+      }\n@@ -1926,0 +1974,4 @@\n+      case (JVM_CONSTANT_UnresolvedClass | JVM_CONSTANT_QDescBit): {\n+        printf(\"UnresolvedQClass: %s\", WARN_MSG);\n+        break;\n+      }\n@@ -2097,0 +2149,1 @@\n+        assert(!tag_at(idx).is_Qdescriptor_klass(), \"Failed to encode QDesc\");\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":60,"deletions":7,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -139,0 +139,2 @@\n+                                       bool is_inlined,\n+                                       bool is_inline_type,\n@@ -144,0 +146,1 @@\n+  assert(!is_inlined || is_inline_type, \"Sanity check\");\n@@ -146,1 +149,3 @@\n-                  ((is_final    ? 1 : 0) << is_final_shift),\n+                  ((is_final    ? 1 : 0) << is_final_shift) |\n+                  ((is_inlined  ? 1 : 0) << is_inlined_shift) |\n+                  ((is_inline_type ? 1 : 0) << is_inline_type_shift),\n@@ -304,0 +309,1 @@\n+      invoke_code = Bytecodes::_invokevirtual;\n@@ -319,1 +325,1 @@\n-    set_bytecode_2(Bytecodes::_invokevirtual);\n+    set_bytecode_2(invoke_code);\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -0,0 +1,62 @@\n+\/*\n+ * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_VM_OOPS_FLATARRAYOOP_HPP\n+#define SHARE_VM_OOPS_FLATARRAYOOP_HPP\n+\n+#include \"oops\/arrayOop.hpp\"\n+#include \"oops\/klass.hpp\"\n+#include \"runtime\/handles.hpp\"\n+\n+\/\/ A flatArrayOop is an array containing inline types (may include flatten embedded oop elements).\n+\n+class flatArrayOopDesc : public arrayOopDesc {\n+\n+ public:\n+  void*  base() const;\n+  void* value_at_addr(int index, jint lh) const;\n+\n+  \/\/ Return a buffered element from index\n+  static oop value_alloc_copy_from_index(flatArrayHandle vah, int index, TRAPS);\n+  void value_copy_from_index(int index, oop dst) const;\n+  void value_copy_to_index(oop src, int index) const;\n+\n+  \/\/ Sizing\n+  static size_t element_size(int lh, int nof_elements) {\n+    size_t sz = (size_t) nof_elements;\n+    return sz << Klass::layout_helper_log2_element_size(lh);\n+  }\n+\n+  static int object_size(int lh, int length) {\n+    julong size_in_bytes = header_size_in_bytes() + element_size(lh, length);\n+    julong size_in_words = ((size_in_bytes + (HeapWordSize-1)) >> LogHeapWordSize);\n+    assert(size_in_words <= (julong)max_jint, \"no overflow\");\n+    return align_object_size((intptr_t)size_in_words);\n+  }\n+\n+  int object_size() const;\n+\n+};\n+\n+#endif \/\/ SHARE_VM_OOPS_FLATARRAYOOP_HPP\n","filename":"src\/hotspot\/share\/oops\/flatArrayOop.hpp","additions":62,"deletions":0,"binary":false,"changes":62,"status":"added"},{"patch":"@@ -72,0 +72,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -164,0 +165,2 @@\n+bool InstanceKlass::field_is_inline_type(int index) const { return Signature::basic_type(field(index)->signature(constants())) == T_INLINE_TYPE; }\n+\n@@ -471,1 +474,3 @@\n-                                       should_store_fingerprint(is_hidden_or_anonymous));\n+                                       should_store_fingerprint(is_hidden_or_anonymous),\n+                                       parser.has_inline_fields() ? parser.java_fields_count() : 0,\n+                                       parser.is_inline_type());\n@@ -485,2 +490,1 @@\n-    }\n-    else if (is_class_loader(class_name, parser)) {\n+    } else if (is_class_loader(class_name, parser)) {\n@@ -489,0 +493,3 @@\n+    } else if (parser.is_inline_type()) {\n+      \/\/ inline type\n+      ik = new (loader_data, size, THREAD) InlineKlass(parser);\n@@ -504,0 +511,7 @@\n+#ifdef ASSERT\n+  assert(ik->size() == size, \"\");\n+  ik->bounds_check((address) ik->start_of_vtable(), false, size);\n+  ik->bounds_check((address) ik->start_of_itable(), false, size);\n+  ik->bounds_check((address) ik->end_of_itable(), true, size);\n+  ik->bounds_check((address) ik->end_of_nonstatic_oop_maps(), true, size);\n+#endif \/\/ASSERT\n@@ -507,0 +521,23 @@\n+#ifndef PRODUCT\n+bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {\n+  const char* bad = NULL;\n+  address end = NULL;\n+  if (addr < (address)this) {\n+    bad = \"before\";\n+  } else if (addr == (address)this) {\n+    if (edge_ok)  return true;\n+    bad = \"just before\";\n+  } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes < 0 ? size() : size_in_bytes))) {\n+    if (edge_ok)  return true;\n+    bad = \"just after\";\n+  } else if (addr > end) {\n+    bad = \"after\";\n+  } else {\n+    return true;\n+  }\n+  tty->print_cr(\"%s object bounds: \" INTPTR_FORMAT \" [\" INTPTR_FORMAT \"..\" INTPTR_FORMAT \"]\",\n+      bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);\n+  Verbose = WizardMode = true; this->print(); \/\/@@\n+  return false;\n+}\n+#endif \/\/PRODUCT\n@@ -541,1 +578,3 @@\n-  _init_thread(NULL)\n+  _init_thread(NULL),\n+  _inline_type_field_klasses(NULL),\n+  _adr_inlineklass_fixed_block(NULL)\n@@ -550,0 +589,4 @@\n+    if (parser.has_inline_fields()) {\n+      set_has_inline_type_fields();\n+    }\n+    _java_fields_count = parser.java_fields_count();\n@@ -551,3 +594,3 @@\n-  assert(NULL == _methods, \"underlying memory not zeroed?\");\n-  assert(is_instance_klass(), \"is layout incorrect?\");\n-  assert(size_helper() == parser.layout_size(), \"incorrect size_helper?\");\n+    assert(NULL == _methods, \"underlying memory not zeroed?\");\n+    assert(is_instance_klass(), \"is layout incorrect?\");\n+    assert(size_helper() == parser.layout_size(), \"incorrect size_helper?\");\n@@ -560,0 +603,3 @@\n+  if (has_inline_type_fields()) {\n+    _inline_type_field_klasses = (const Klass**) adr_inline_type_field_klasses();\n+  }\n@@ -589,1 +635,2 @@\n-    if (ti != sti && ti != NULL && !ti->is_shared()) {\n+    if (ti != sti && ti != NULL && !ti->is_shared() &&\n+        ti != Universe::the_single_IdentityObject_klass_array()) {\n@@ -596,1 +643,2 @@\n-      local_interfaces != NULL && !local_interfaces->is_shared()) {\n+      local_interfaces != NULL && !local_interfaces->is_shared() &&\n+      local_interfaces != Universe::the_single_IdentityObject_klass_array()) {\n@@ -928,0 +976,56 @@\n+\n+  \/\/ If a class declares a method that uses an inline class as an argument\n+  \/\/ type or return inline type, this inline class must be loaded during the\n+  \/\/ linking of this class because size and properties of the inline class\n+  \/\/ must be known in order to be able to perform inline type optimizations.\n+  \/\/ The implementation below is an approximation of this rule, the code\n+  \/\/ iterates over all methods of the current class (including overridden\n+  \/\/ methods), not only the methods declared by this class. This\n+  \/\/ approximation makes the code simpler, and doesn't change the semantic\n+  \/\/ because classes declaring methods overridden by the current class are\n+  \/\/ linked (and have performed their own pre-loading) before the linking\n+  \/\/ of the current class.\n+\n+\n+  \/\/ Note:\n+  \/\/ Inline class types are loaded during\n+  \/\/ the loading phase (see ClassFileParser::post_process_parsed_stream()).\n+  \/\/ Inline class types used as element types for array creation\n+  \/\/ are not pre-loaded. Their loading is triggered by either anewarray\n+  \/\/ or multianewarray bytecodes.\n+\n+  \/\/ Could it be possible to do the following processing only if the\n+  \/\/ class uses inline types?\n+  {\n+    ResourceMark rm(THREAD);\n+    for (int i = 0; i < methods()->length(); i++) {\n+      Method* m = methods()->at(i);\n+      for (SignatureStream ss(m->signature()); !ss.is_done(); ss.next()) {\n+        if (ss.is_reference()) {\n+          if (ss.is_array()) {\n+            ss.skip_array_prefix();\n+          }\n+          if (ss.type() == T_INLINE_TYPE) {\n+            Symbol* symb = ss.as_symbol();\n+\n+            oop loader = class_loader();\n+            oop protection_domain = this->protection_domain();\n+            Klass* klass = SystemDictionary::resolve_or_fail(symb,\n+                                                             Handle(THREAD, loader), Handle(THREAD, protection_domain), true,\n+                                                             CHECK_false);\n+            if (klass == NULL) {\n+              THROW_(vmSymbols::java_lang_LinkageError(), false);\n+            }\n+            if (!klass->is_inline_klass()) {\n+              Exceptions::fthrow(\n+                THREAD_AND_LOCATION,\n+                vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                \"class %s is not an inline type\",\n+                klass->external_name());\n+            }\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n@@ -999,0 +1103,1 @@\n+\n@@ -1149,0 +1254,29 @@\n+  \/\/ Step 8\n+  \/\/ Initialize classes of inline fields\n+  {\n+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {\n+        Klass* klass = get_inline_type_field_klass_or_null(fs.index());\n+        if (fs.access_flags().is_static() && klass == NULL) {\n+          klass = SystemDictionary::resolve_or_fail(field_signature(fs.index())->fundamental_name(THREAD),\n+              Handle(THREAD, class_loader()),\n+              Handle(THREAD, protection_domain()),\n+              true, CHECK);\n+          if (klass == NULL) {\n+            THROW(vmSymbols::java_lang_NoClassDefFoundError());\n+          }\n+          if (!klass->is_inline_klass()) {\n+            THROW(vmSymbols::java_lang_IncompatibleClassChangeError());\n+          }\n+          set_inline_type_field_klass(fs.index(), klass);\n+        }\n+        InstanceKlass::cast(klass)->initialize(CHECK);\n+        if (fs.access_flags().is_static()) {\n+          if (java_mirror()->obj_field(fs.offset()) == NULL) {\n+            java_mirror()->obj_field_put(fs.offset(), InlineKlass::cast(klass)->default_value());\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1153,1 +1287,1 @@\n-  \/\/ Step 8\n+  \/\/ Step 9\n@@ -1175,1 +1309,1 @@\n-  \/\/ Step 9\n+  \/\/ Step 10\n@@ -1183,1 +1317,1 @@\n-    \/\/ Step 10 and 11\n+    \/\/ Step 11 and 12\n@@ -1455,1 +1589,1 @@\n-  ObjArrayKlass* oak = array_klasses();\n+  ArrayKlass* oak = array_klasses();\n@@ -1471,1 +1605,1 @@\n-  if (clinit != NULL && clinit->has_valid_initializer_flags()) {\n+  if (clinit != NULL && clinit->is_class_initializer()) {\n@@ -1509,1 +1643,1 @@\n-    MutexLocker x(OopMapCacheAlloc_lock);\n+    MutexLocker x(OopMapCacheAlloc_lock,  Mutex::_no_safepoint_check_flag);\n@@ -1521,5 +1655,0 @@\n-bool InstanceKlass::contains_field_offset(int offset) {\n-  fieldDescriptor fd;\n-  return find_field_from_offset(offset, false, &fd);\n-}\n-\n@@ -1596,0 +1725,9 @@\n+bool InstanceKlass::contains_field_offset(int offset) {\n+  if (this->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(this);\n+    return offset >= vk->first_field_offset() && offset < (vk->first_field_offset() + vk->get_exact_size_in_bytes());\n+  } else {\n+    fieldDescriptor fd;\n+    return find_field_from_offset(offset, false, &fd);\n+  }\n+}\n@@ -1983,0 +2121,3 @@\n+    if (name == vmSymbols::object_initializer_name()) {\n+      break;  \/\/ <init> is never inherited, not even as a static factory\n+    }\n@@ -2491,0 +2632,6 @@\n+\n+  if (has_inline_type_fields()) {\n+    for (int i = 0; i < java_fields_count(); i++) {\n+      it->push(&((Klass**)adr_inline_type_field_klasses())[i]);\n+    }\n+  }\n@@ -2526,0 +2673,8 @@\n+  if (has_inline_type_fields()) {\n+    for (AllFieldStream fs(fields(), constants()); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {\n+        reset_inline_type_field_klass(fs.index());\n+      }\n+    }\n+  }\n+\n@@ -2586,0 +2741,4 @@\n+  if (is_inline_klass()) {\n+    InlineKlass::cast(this)->initialize_calling_convention(CHECK);\n+  }\n+\n@@ -2617,1 +2776,1 @@\n-  if (UseBiasedLocking && BiasedLocking::enabled()) {\n+  if (UseBiasedLocking && BiasedLocking::enabled() && !is_inline_klass()) {\n@@ -2788,1 +2947,1 @@\n-  \/\/ Add L as type indicator\n+  \/\/ Add L or Q as type indicator\n@@ -2790,1 +2949,1 @@\n-  dest[dest_index++] = JVM_SIGNATURE_CLASS;\n+  dest[dest_index++] = is_inline_klass() ? JVM_SIGNATURE_INLINE_TYPE : JVM_SIGNATURE_CLASS;\n@@ -3357,1 +3516,4 @@\n-static void print_vtable(intptr_t* start, int len, outputStream* st) {\n+static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {\n+  ResourceMark rm;\n+  int* forward_refs = NEW_RESOURCE_ARRAY(int, len);\n+  for (int i = 0; i < len; i++)  forward_refs[i] = 0;\n@@ -3361,0 +3523,5 @@\n+    if (forward_refs[i] != 0) {\n+      int from = forward_refs[i];\n+      int off = (int) start[from];\n+      st->print(\" (offset %d <= [%d])\", off, from);\n+    }\n@@ -3364,0 +3531,6 @@\n+    } else if (self != NULL && e > 0 && e < 0x10000) {\n+      address location = self + e;\n+      int index = (int)((intptr_t*)location - start);\n+      st->print(\" (offset %d => [%d])\", (int)e, index);\n+      if (index >= 0 && index < len)\n+        forward_refs[index] = i;\n@@ -3370,1 +3543,22 @@\n-  return print_vtable(reinterpret_cast<intptr_t*>(start), len, st);\n+  return print_vtable(NULL, reinterpret_cast<intptr_t*>(start), len, st);\n+}\n+\n+template<typename T>\n+ static void print_array_on(outputStream* st, Array<T>* array) {\n+   if (array == NULL) { st->print_cr(\"NULL\"); return; }\n+   array->print_value_on(st); st->cr();\n+   if (Verbose || WizardMode) {\n+     for (int i = 0; i < array->length(); i++) {\n+       st->print(\"%d : \", i); array->at(i)->print_value_on(st); st->cr();\n+     }\n+   }\n+ }\n+\n+static void print_array_on(outputStream* st, Array<int>* array) {\n+  if (array == NULL) { st->print_cr(\"NULL\"); return; }\n+  array->print_value_on(st); st->cr();\n+  if (Verbose || WizardMode) {\n+    for (int i = 0; i < array->length(); i++) {\n+      st->print(\"%d : %d\", i, array->at(i)); st->cr();\n+    }\n+  }\n@@ -3380,0 +3574,1 @@\n+  st->print(BULLET\"misc flags:        0x%x\", _misc_flags);                        st->cr();\n@@ -3406,15 +3601,3 @@\n-  st->print(BULLET\"methods:           \"); methods()->print_value_on(st);                  st->cr();\n-  if (Verbose || WizardMode) {\n-    Array<Method*>* method_array = methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n-  st->print(BULLET\"method ordering:   \"); method_ordering()->print_value_on(st);      st->cr();\n-  st->print(BULLET\"default_methods:   \"); default_methods()->print_value_on(st);      st->cr();\n-  if (Verbose && default_methods() != NULL) {\n-    Array<Method*>* method_array = default_methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n+  st->print(BULLET\"methods:           \"); print_array_on(st, methods());\n+  st->print(BULLET\"method ordering:   \"); print_array_on(st, method_ordering());\n+  st->print(BULLET\"default_methods:   \"); print_array_on(st, default_methods());\n@@ -3422,1 +3605,1 @@\n-    st->print(BULLET\"default vtable indices:   \"); default_vtable_indices()->print_value_on(st);       st->cr();\n+    st->print(BULLET\"default vtable indices:   \"); print_array_on(st, default_vtable_indices());\n@@ -3424,2 +3607,2 @@\n-  st->print(BULLET\"local interfaces:  \"); local_interfaces()->print_value_on(st);      st->cr();\n-  st->print(BULLET\"trans. interfaces: \"); transitive_interfaces()->print_value_on(st); st->cr();\n+  st->print(BULLET\"local interfaces:  \"); print_array_on(st, local_interfaces());\n+  st->print(BULLET\"trans. interfaces: \"); print_array_on(st, transitive_interfaces());\n@@ -3482,1 +3665,1 @@\n-  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(start_of_itable(), itable_length(), st);\n+  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(NULL, start_of_itable(), itable_length(), st);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":227,"deletions":44,"binary":false,"changes":271,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"code\/vmreg.hpp\"\n@@ -56,0 +57,2 @@\n+\/\/    [EMBEDDED inline_type_field_klasses] only if has_inline_fields() == true\n+\/\/    [EMBEDDED InlineKlassFixedBlock] only if is an InlineKlass instance\n@@ -72,0 +75,1 @@\n+class BufferedInlineTypeBlob;\n@@ -134,0 +138,16 @@\n+class SigEntry;\n+\n+class InlineKlassFixedBlock {\n+  Array<SigEntry>** _extended_sig;\n+  Array<VMRegPair>** _return_regs;\n+  address* _pack_handler;\n+  address* _pack_handler_jobject;\n+  address* _unpack_handler;\n+  int* _default_value_offset;\n+  int _alignment;\n+  int _first_field_offset;\n+  int _exact_size_in_bytes;\n+\n+  friend class InlineKlass;\n+};\n+\n@@ -139,0 +159,1 @@\n+  friend class TemplateTable;\n@@ -156,1 +177,1 @@\n-    fully_initialized,                  \/\/ initialized (successfull final state)\n+    fully_initialized,                  \/\/ initialized (successful final state)\n@@ -172,1 +193,1 @@\n-  ObjArrayKlass* volatile _array_klasses;\n+  ArrayKlass* volatile _array_klasses;\n@@ -239,1 +260,1 @@\n-  \/\/ This can be used to quickly discriminate among the four kinds of\n+  \/\/ This can be used to quickly discriminate among the five kinds of\n@@ -245,0 +266,1 @@\n+  static const unsigned _kind_inline_type  = 4; \/\/ InlineKlass\n@@ -266,1 +288,8 @@\n-    _misc_has_contended_annotations           = 1 << 15  \/\/ has @Contended annotation\n+    _misc_has_contended_annotations           = 1 << 15,  \/\/ has @Contended annotation\n+    _misc_has_inline_type_fields              = 1 << 16, \/\/ has inline fields and related embedded section is not empty\n+    _misc_is_empty_inline_type                = 1 << 17, \/\/ empty inline type (*)\n+    _misc_is_naturally_atomic                 = 1 << 18, \/\/ loaded\/stored in one instruction\n+    _misc_is_declared_atomic                  = 1 << 19, \/\/ implements jl.NonTearable\n+    _misc_invalid_inline_super                = 1 << 20, \/\/ invalid super type for an inline type\n+    _misc_invalid_identity_super              = 1 << 21, \/\/ invalid super type for an identity type\n+    _misc_has_injected_identityObject         = 1 << 22  \/\/ IdentityObject has been injected by the JVM\n@@ -268,0 +297,6 @@\n+\n+  \/\/ (*) An inline type is considered empty if it contains no non-static fields or\n+  \/\/ if it contains only empty inline fields. Note that JITs have a slightly different\n+  \/\/ definition: empty inline fields must be flattened otherwise the container won't\n+  \/\/ be considered empty\n+\n@@ -271,1 +306,1 @@\n-  u2              _misc_flags;           \/\/ There is more space in access_flags for more flags.\n+  u4              _misc_flags;           \/\/ There is more space in access_flags for more flags.\n@@ -323,0 +358,3 @@\n+  const Klass**   _inline_type_field_klasses; \/\/ For \"inline class\" fields, NULL if none present\n+\n+  const InlineKlassFixedBlock* _adr_inlineklass_fixed_block;\n@@ -383,0 +421,65 @@\n+  bool has_inline_type_fields() const          {\n+    return (_misc_flags & _misc_has_inline_type_fields) != 0;\n+  }\n+  void set_has_inline_type_fields()  {\n+    _misc_flags |= _misc_has_inline_type_fields;\n+  }\n+\n+  bool is_empty_inline_type() const {\n+    return (_misc_flags & _misc_is_empty_inline_type) != 0;\n+  }\n+  void set_is_empty_inline_type() {\n+    _misc_flags |= _misc_is_empty_inline_type;\n+  }\n+\n+  \/\/ Note:  The naturally_atomic property only applies to\n+  \/\/ inline classes; it is never true on identity classes.\n+  \/\/ The bit is placed on instanceKlass for convenience.\n+\n+  \/\/ Query if h\/w provides atomic load\/store for instances.\n+  bool is_naturally_atomic() const {\n+    return (_misc_flags & _misc_is_naturally_atomic) != 0;\n+  }\n+  \/\/ Initialized in the class file parser, not changed later.\n+  void set_is_naturally_atomic() {\n+    _misc_flags |= _misc_is_naturally_atomic;\n+  }\n+\n+  \/\/ Query if this class implements jl.NonTearable or was\n+  \/\/ mentioned in the JVM option ForceNonTearable.\n+  \/\/ This bit can occur anywhere, but is only significant\n+  \/\/ for inline classes *and* their super types.\n+  \/\/ It inherits from supers along with NonTearable.\n+  bool is_declared_atomic() const {\n+    return (_misc_flags & _misc_is_declared_atomic) != 0;\n+  }\n+  \/\/ Initialized in the class file parser, not changed later.\n+  void set_is_declared_atomic() {\n+    _misc_flags |= _misc_is_declared_atomic;\n+  }\n+\n+  \/\/ Query if class is an invalid super class for an inline type.\n+  bool invalid_inline_super() const {\n+    return (_misc_flags & _misc_invalid_inline_super) != 0;\n+  }\n+  \/\/ Initialized in the class file parser, not changed later.\n+  void set_invalid_inline_super() {\n+    _misc_flags |= _misc_invalid_inline_super;\n+  }\n+  \/\/ Query if class is an invalid super class for an identity type.\n+  bool invalid_identity_super() const {\n+    return (_misc_flags & _misc_invalid_identity_super) != 0;\n+  }\n+  \/\/ Initialized in the class file parser, not changed later.\n+  void set_invalid_identity_super() {\n+    _misc_flags |= _misc_invalid_identity_super;\n+  }\n+\n+  bool has_injected_identityObject() const {\n+    return (_misc_flags & _misc_has_injected_identityObject);\n+  }\n+\n+  void set_has_injected_identityObject() {\n+    _misc_flags |= _misc_has_injected_identityObject;\n+  }\n+\n@@ -398,4 +501,4 @@\n-  ObjArrayKlass* array_klasses() const     { return _array_klasses; }\n-  inline ObjArrayKlass* array_klasses_acquire() const; \/\/ load with acquire semantics\n-  void set_array_klasses(ObjArrayKlass* k) { _array_klasses = k; }\n-  inline void release_set_array_klasses(ObjArrayKlass* k); \/\/ store with release semantics\n+  ArrayKlass* array_klasses() const     { return _array_klasses; }\n+  inline ArrayKlass* array_klasses_acquire() const; \/\/ load with acquire semantics\n+  void set_array_klasses(ArrayKlass* k) { _array_klasses = k; }\n+  inline void release_set_array_klasses(ArrayKlass* k); \/\/ store with release semantics\n@@ -445,0 +548,2 @@\n+  bool    field_is_inlined(int index) const { return field(index)->is_inlined(); }\n+  bool    field_is_inline_type(int index) const;\n@@ -572,0 +677,4 @@\n+  static ByteSize kind_offset() { return in_ByteSize(offset_of(InstanceKlass, _kind)); }\n+  static ByteSize misc_flags_offset() { return in_ByteSize(offset_of(InstanceKlass, _misc_flags)); }\n+  static u4 misc_flags_is_empty_inline_type() { return _misc_is_empty_inline_type; }\n+\n@@ -754,0 +863,1 @@\n+\n@@ -755,1 +865,1 @@\n-    return ((_misc_flags & _misc_is_being_redefined) != 0);\n+    return (_misc_flags & _misc_is_being_redefined);\n@@ -840,0 +950,1 @@\n+  bool is_inline_type_klass()           const { return is_kind(_kind_inline_type); }\n@@ -1009,0 +1120,3 @@\n+  static ByteSize inline_type_field_klasses_offset() { return in_ByteSize(offset_of(InstanceKlass, _inline_type_field_klasses)); }\n+  static ByteSize adr_inlineklass_fixed_block_offset() { return in_ByteSize(offset_of(InstanceKlass, _adr_inlineklass_fixed_block)); }\n+\n@@ -1043,2 +1157,2 @@\n-  void array_klasses_do(void f(Klass* k));\n-  void array_klasses_do(void f(Klass* k, TRAPS), TRAPS);\n+  virtual void array_klasses_do(void f(Klass* k));\n+  virtual void array_klasses_do(void f(Klass* k, TRAPS), TRAPS);\n@@ -1065,1 +1179,2 @@\n-                  bool is_interface, bool is_unsafe_anonymous, bool has_stored_fingerprint) {\n+                  bool is_interface, bool is_unsafe_anonymous, bool has_stored_fingerprint,\n+                  int java_fields, bool is_inline_type) {\n@@ -1072,1 +1187,3 @@\n-           (has_stored_fingerprint ? (int)sizeof(uint64_t*)\/wordSize : 0));\n+           (has_stored_fingerprint ? (int)sizeof(uint64_t*)\/wordSize : 0) +\n+           (java_fields * (int)sizeof(Klass*)\/wordSize) +\n+           (is_inline_type ? (int)sizeof(InlineKlassFixedBlock) : 0));\n@@ -1079,1 +1196,3 @@\n-                                               has_stored_fingerprint());\n+                                               has_stored_fingerprint(),\n+                                               has_inline_type_fields() ? java_fields_count() : 0,\n+                                               is_inline_klass());\n@@ -1086,0 +1205,1 @@\n+  bool bounds_check(address addr, bool edge_ok = false, intptr_t size_in_bytes = -1) const PRODUCT_RETURN0;\n@@ -1094,0 +1214,6 @@\n+  inline address adr_inline_type_field_klasses() const;\n+  inline Klass* get_inline_type_field_klass(int idx) const;\n+  inline Klass* get_inline_type_field_klass_or_null(int idx) const;\n+  inline void set_inline_type_field_klass(int idx, Klass* k);\n+  inline void reset_inline_type_field_klass(int idx);\n+\n@@ -1095,1 +1221,1 @@\n-  int size_helper() const {\n+  virtual int size_helper() const {\n@@ -1232,1 +1358,1 @@\n-\n+protected:\n@@ -1234,1 +1360,1 @@\n-  Klass* array_klass_impl(bool or_null, int n, TRAPS);\n+  virtual Klass* array_klass_impl(bool or_null, int n, TRAPS);\n@@ -1237,1 +1363,3 @@\n-  Klass* array_klass_impl(bool or_null, TRAPS);\n+  virtual Klass* array_klass_impl(bool or_null, TRAPS);\n+\n+private:\n@@ -1267,1 +1395,1 @@\n-  void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS);\n+  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":148,"deletions":20,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -221,1 +221,1 @@\n-  int lh = array_layout_helper(tag, hsize, etype, exact_log2(esize));\n+  int lh = array_layout_helper(tag, false, hsize, etype, exact_log2(esize));\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+  FlatArrayKlassID,\n@@ -50,1 +51,1 @@\n-const uint KLASS_ID_COUNT = 6;\n+const uint KLASS_ID_COUNT = 7;\n@@ -101,1 +102,1 @@\n-  \/\/    tag is 0x80 if the elements are oops, 0xC0 if non-oops\n+  \/\/    tag is 0x80 if the elements are oops, 0xC0 if non-oops, 0xA0 if value types\n@@ -368,1 +369,1 @@\n-  static const int _lh_array_tag_bits          = 2;\n+  static const int _lh_array_tag_bits          = 3;\n@@ -370,2 +371,10 @@\n-  static const int _lh_array_tag_obj_value     = ~0x01;   \/\/ 0x80000000 >> 30\n-  static const unsigned int _lh_array_tag_type_value = 0Xffffffff; \/\/ ~0x00,  \/\/ 0xC0000000 >> 30\n+  static const unsigned int _lh_array_tag_type_value = 0Xfffffffc;\n+  static const unsigned int _lh_array_tag_vt_value   = 0Xfffffffd;\n+  static const unsigned int _lh_array_tag_obj_value  = 0Xfffffffe;\n+\n+  \/\/ null-free array flag bit under the array tag bits, shift one more to get array tag value\n+  static const int _lh_null_free_shift = _lh_array_tag_shift - 1;\n+  static const int _lh_null_free_mask  = 1;\n+\n+  static const jint _lh_array_tag_vt_value_bit_inplace = (jint) (1 << _lh_array_tag_shift);\n+  static const jint _lh_null_free_bit_inplace = (jint) (_lh_null_free_mask << _lh_null_free_shift);\n@@ -389,2 +398,1 @@\n-    \/\/ _lh_array_tag_type_value == (lh >> _lh_array_tag_shift);\n-    return (juint)lh >= (juint)(_lh_array_tag_type_value << _lh_array_tag_shift);\n+    return (juint) _lh_array_tag_type_value == (juint)(lh >> _lh_array_tag_shift);\n@@ -393,2 +401,13 @@\n-    \/\/ _lh_array_tag_obj_value == (lh >> _lh_array_tag_shift);\n-    return (jint)lh < (jint)(_lh_array_tag_type_value << _lh_array_tag_shift);\n+    return (juint)_lh_array_tag_obj_value == (juint)(lh >> _lh_array_tag_shift);\n+  }\n+  static bool layout_helper_is_flatArray(jint lh) {\n+    return (juint)_lh_array_tag_vt_value == (juint)(lh >> _lh_array_tag_shift);\n+  }\n+  static bool layout_helper_is_null_free(jint lh) {\n+    assert(layout_helper_is_flatArray(lh) || layout_helper_is_objArray(lh), \"must be array of inline types\");\n+    return ((lh >> _lh_null_free_shift) & _lh_null_free_mask);\n+  }\n+  static jint layout_helper_set_null_free(jint lh) {\n+    lh |= (_lh_null_free_mask << _lh_null_free_shift);\n+    assert(layout_helper_is_null_free(lh), \"Bad encoding\");\n+    return lh;\n@@ -405,1 +424,1 @@\n-    assert(btvalue >= T_BOOLEAN && btvalue <= T_OBJECT, \"sanity\");\n+    assert((btvalue >= T_BOOLEAN && btvalue <= T_OBJECT) || btvalue == T_INLINE_TYPE, \"sanity\");\n@@ -426,1 +445,1 @@\n-    assert(l2esz <= LogBytesPerLong,\n+    assert(layout_helper_element_type(lh) == T_INLINE_TYPE || l2esz <= LogBytesPerLong,\n@@ -430,1 +449,1 @@\n-  static jint array_layout_helper(jint tag, int hsize, BasicType etype, int log2_esize) {\n+  static jint array_layout_helper(jint tag, bool null_free, int hsize, BasicType etype, int log2_esize) {\n@@ -432,0 +451,1 @@\n+      |    ((null_free ? 1 : 0) <<  _lh_null_free_shift)\n@@ -568,0 +588,2 @@\n+  \/\/ For value classes, this returns the name with a leading 'Q' and a trailing ';'\n+  \/\/     and the package separators as '\/'.\n@@ -583,0 +605,1 @@\n+  virtual bool is_flatArray_klass_slow()    const { return false; }\n@@ -584,0 +607,2 @@\n+  \/\/ current implementation uses this method even in non debug builds\n+  virtual bool is_inline_klass_slow()       const { return false; }\n@@ -609,0 +634,5 @@\n+  inline  bool is_inline_klass()              const { return is_inline_klass_slow(); } \/\/temporary hack\n+  inline  bool is_flatArray_klass()           const { return assert_same_query(\n+                                                    layout_helper_is_flatArray(layout_helper()),\n+                                                    is_flatArray_klass_slow()); }\n+\n@@ -611,0 +641,2 @@\n+  inline bool is_null_free_array_klass()      const { return layout_helper_is_null_free(layout_helper()); }\n+\n@@ -646,1 +678,4 @@\n-  markWord prototype_header() const      { return _prototype_header; }\n+  markWord prototype_header() const     { return _prototype_header; }\n+  static inline markWord default_prototype_header(Klass* k) {\n+    return (k == NULL) ? markWord::prototype() : k->prototype_header();\n+  }\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":48,"deletions":13,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -53,1 +53,2 @@\n-  assert(!header.has_bias_pattern() || is_instance_klass(), \"biased locking currently only supported for Java instances\");\n+  assert(!is_inline_klass() || header.is_inline_type(), \"Unexpected prototype\");\n+  assert(!UseBiasedLocking || !header.has_bias_pattern() || is_instance_klass(), \"biased locking currently only supported for Java instances\");\n","filename":"src\/hotspot\/share\/oops\/klass.inline.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -143,1 +143,1 @@\n-    st->print(\"flags(%d) \", flags);\n+    st->print(\"flags(%d) %p\/%d\", flags, data(), in_bytes(DataLayout::flags_offset()));\n@@ -213,1 +213,1 @@\n-  assert(TypeStackSlotEntries::per_arg_count() > ReturnTypeEntry::static_cell_count(), \"code to test for arguments\/results broken\");\n+  assert(TypeStackSlotEntries::per_arg_count() > SingleTypeEntry::static_cell_count(), \"code to test for arguments\/results broken\");\n@@ -223,1 +223,1 @@\n-    ret_cell = ReturnTypeEntry::static_cell_count();\n+    ret_cell = SingleTypeEntry::static_cell_count();\n@@ -326,1 +326,1 @@\n-void ReturnTypeEntry::clean_weak_klass_links(bool always_clean) {\n+void SingleTypeEntry::clean_weak_klass_links(bool always_clean) {\n@@ -364,1 +364,1 @@\n-void ReturnTypeEntry::print_data_on(outputStream* st) const {\n+void SingleTypeEntry::print_data_on(outputStream* st) const {\n@@ -529,0 +529,4 @@\n+  if (data()->flags()) {\n+    tty->cr();\n+    tab(st);\n+  }\n@@ -652,0 +656,21 @@\n+void ArrayLoadStoreData::print_data_on(outputStream* st, const char* extra) const {\n+  print_shared(st, \"ArrayLoadStore\", extra);\n+  st->cr();\n+  tab(st, true);\n+  st->print(\"array\");\n+  _array.print_data_on(st);\n+  tab(st, true);\n+  st->print(\"element\");\n+  _element.print_data_on(st);\n+}\n+\n+void ACmpData::print_data_on(outputStream* st, const char* extra) const {\n+  BranchData::print_data_on(st, extra);\n+  tab(st, true);\n+  st->print(\"left\");\n+  _left.print_data_on(st);\n+  tab(st, true);\n+  st->print(\"right\");\n+  _right.print_data_on(st);\n+}\n+\n@@ -672,1 +697,0 @@\n-  case Bytecodes::_aastore:\n@@ -678,0 +702,3 @@\n+  case Bytecodes::_aaload:\n+  case Bytecodes::_aastore:\n+    return ArrayLoadStoreData::static_cell_count();\n@@ -717,2 +744,0 @@\n-  case Bytecodes::_if_acmpeq:\n-  case Bytecodes::_if_acmpne:\n@@ -722,0 +747,3 @@\n+  case Bytecodes::_if_acmpne:\n+  case Bytecodes::_if_acmpeq:\n+    return ACmpData::static_cell_count();\n@@ -780,0 +808,1 @@\n+  case Bytecodes::_aaload:\n@@ -983,1 +1012,0 @@\n-  case Bytecodes::_aastore:\n@@ -992,0 +1020,5 @@\n+  case Bytecodes::_aaload:\n+  case Bytecodes::_aastore:\n+    cell_count = ArrayLoadStoreData::static_cell_count();\n+    tag = DataLayout::array_load_store_data_tag;\n+    break;\n@@ -1063,2 +1096,0 @@\n-  case Bytecodes::_if_acmpeq:\n-  case Bytecodes::_if_acmpne:\n@@ -1070,0 +1101,5 @@\n+  case Bytecodes::_if_acmpeq:\n+  case Bytecodes::_if_acmpne:\n+    cell_count = ACmpData::static_cell_count();\n+    tag = DataLayout::acmp_data_tag;\n+    break;\n@@ -1137,0 +1173,4 @@\n+  case DataLayout::array_load_store_data_tag:\n+    return ((new ArrayLoadStoreData(this))->cell_count());\n+  case DataLayout::acmp_data_tag:\n+    return ((new ACmpData(this))->cell_count());\n@@ -1171,0 +1211,4 @@\n+  case DataLayout::array_load_store_data_tag:\n+    return new ArrayLoadStoreData(this);\n+  case DataLayout::acmp_data_tag:\n+    return new ACmpData(this);\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":55,"deletions":11,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -128,1 +128,3 @@\n-    speculative_trap_data_tag\n+    speculative_trap_data_tag,\n+    array_load_store_data_tag,\n+    acmp_data_tag\n@@ -264,0 +266,1 @@\n+class       ACmpData;\n@@ -269,0 +272,1 @@\n+class   ArrayLoadStoreData;\n@@ -276,1 +280,1 @@\n-  friend class ReturnTypeEntry;\n+  friend class SingleTypeEntry;\n@@ -397,0 +401,2 @@\n+  virtual bool is_ArrayLoadStoreData() const { return false; }\n+  virtual bool is_ACmpData()           const { return false; }\n@@ -455,0 +461,8 @@\n+  ArrayLoadStoreData* as_ArrayLoadStoreData() const {\n+    assert(is_ArrayLoadStoreData(), \"wrong type\");\n+    return is_ArrayLoadStoreData() ? (ArrayLoadStoreData*)this : NULL;\n+  }\n+  ACmpData* as_ACmpData() const {\n+    assert(is_ACmpData(), \"wrong type\");\n+    return is_ACmpData() ? (ACmpData*)this : NULL;\n+  }\n@@ -609,1 +623,2 @@\n-      layout->tag() == DataLayout::branch_data_tag, \"wrong type\");\n+      layout->tag() == DataLayout::branch_data_tag ||\n+      layout->tag() == DataLayout::acmp_data_tag, \"wrong type\");\n@@ -845,1 +860,1 @@\n-class ReturnTypeEntry : public TypeEntries {\n+class SingleTypeEntry : public TypeEntries {\n@@ -853,1 +868,1 @@\n-  ReturnTypeEntry(int base_off)\n+  SingleTypeEntry(int base_off)\n@@ -887,1 +902,1 @@\n-\/\/ (TypeStackSlotEntries), a return type (ReturnTypeEntry) and a\n+\/\/ (TypeStackSlotEntries), a return type (SingleTypeEntry) and a\n@@ -941,1 +956,1 @@\n-    return ReturnTypeEntry::size() + in_ByteSize(header_cell_count() * DataLayout::cell_size);\n+    return SingleTypeEntry::size() + in_ByteSize(header_cell_count() * DataLayout::cell_size);\n@@ -956,1 +971,1 @@\n-  ReturnTypeEntry _ret;\n+  SingleTypeEntry _ret;\n@@ -975,1 +990,1 @@\n-    _ret(cell_count() - ReturnTypeEntry::static_cell_count())\n+    _ret(cell_count() - SingleTypeEntry::static_cell_count())\n@@ -988,1 +1003,1 @@\n-  const ReturnTypeEntry* ret() const {\n+  const SingleTypeEntry* ret() const {\n@@ -1259,1 +1274,1 @@\n-  ReturnTypeEntry _ret;\n+  SingleTypeEntry _ret;\n@@ -1278,1 +1293,1 @@\n-    _ret(cell_count() - ReturnTypeEntry::static_cell_count())\n+    _ret(cell_count() - SingleTypeEntry::static_cell_count())\n@@ -1291,1 +1306,1 @@\n-  const ReturnTypeEntry* ret() const {\n+  const SingleTypeEntry* ret() const {\n@@ -1493,1 +1508,1 @@\n-    assert(layout->tag() == DataLayout::branch_data_tag, \"wrong type\");\n+    assert(layout->tag() == DataLayout::branch_data_tag || layout->tag() == DataLayout::acmp_data_tag, \"wrong type\");\n@@ -1850,0 +1865,146 @@\n+class ArrayLoadStoreData : public ProfileData {\n+private:\n+  enum {\n+    flat_array_flag = DataLayout::first_flag,\n+    null_free_array_flag = flat_array_flag + 1,\n+  };\n+\n+  SingleTypeEntry _array;\n+  SingleTypeEntry _element;\n+\n+public:\n+  ArrayLoadStoreData(DataLayout* layout) :\n+    ProfileData(layout),\n+    _array(0),\n+    _element(SingleTypeEntry::static_cell_count()) {\n+    assert(layout->tag() == DataLayout::array_load_store_data_tag, \"wrong type\");\n+    _array.set_profile_data(this);\n+    _element.set_profile_data(this);\n+  }\n+\n+  const SingleTypeEntry* array() const {\n+    return &_array;\n+  }\n+\n+  const SingleTypeEntry* element() const {\n+    return &_element;\n+  }\n+\n+  virtual bool is_ArrayLoadStoreData() const { return true; }\n+\n+  static int static_cell_count() {\n+    return SingleTypeEntry::static_cell_count() * 2;\n+  }\n+\n+  virtual int cell_count() const {\n+    return static_cell_count();\n+  }\n+\n+  void set_flat_array() { set_flag_at(flat_array_flag); }\n+  bool flat_array() const { return flag_at(flat_array_flag); }\n+\n+  void set_null_free_array() { set_flag_at(null_free_array_flag); }\n+  bool null_free_array() const { return flag_at(null_free_array_flag); }\n+\n+  \/\/ Code generation support\n+  static int flat_array_byte_constant() {\n+    return flag_number_to_constant(flat_array_flag);\n+  }\n+\n+  static int null_free_array_byte_constant() {\n+    return flag_number_to_constant(null_free_array_flag);\n+  }\n+\n+  static ByteSize array_offset() {\n+    return cell_offset(0);\n+  }\n+\n+  static ByteSize element_offset() {\n+    return cell_offset(SingleTypeEntry::static_cell_count());\n+  }\n+\n+  virtual void clean_weak_klass_links(bool always_clean) {\n+    _array.clean_weak_klass_links(always_clean);\n+    _element.clean_weak_klass_links(always_clean);\n+  }\n+\n+  static ByteSize array_load_store_data_size() {\n+    return cell_offset(static_cell_count());\n+  }\n+\n+  virtual void print_data_on(outputStream* st, const char* extra = NULL) const;\n+};\n+\n+class ACmpData : public BranchData {\n+private:\n+  enum {\n+    left_inline_type_flag = DataLayout::first_flag,\n+    right_inline_type_flag\n+  };\n+\n+  SingleTypeEntry _left;\n+  SingleTypeEntry _right;\n+\n+public:\n+  ACmpData(DataLayout* layout) :\n+    BranchData(layout),\n+    _left(BranchData::static_cell_count()),\n+    _right(BranchData::static_cell_count() + SingleTypeEntry::static_cell_count()) {\n+    assert(layout->tag() == DataLayout::acmp_data_tag, \"wrong type\");\n+    _left.set_profile_data(this);\n+    _right.set_profile_data(this);\n+  }\n+\n+  const SingleTypeEntry* left() const {\n+    return &_left;\n+  }\n+\n+  const SingleTypeEntry* right() const {\n+    return &_right;\n+  }\n+\n+  virtual bool is_ACmpData() const { return true; }\n+\n+  static int static_cell_count() {\n+    return BranchData::static_cell_count() + SingleTypeEntry::static_cell_count() * 2;\n+  }\n+\n+  virtual int cell_count() const {\n+    return static_cell_count();\n+  }\n+\n+  void set_left_inline_type() { set_flag_at(left_inline_type_flag); }\n+  bool left_inline_type() const { return flag_at(left_inline_type_flag); }\n+\n+  void set_right_inline_type() { set_flag_at(right_inline_type_flag); }\n+  bool right_inline_type() const { return flag_at(right_inline_type_flag); }\n+\n+  \/\/ Code generation support\n+  static int left_inline_type_byte_constant() {\n+    return flag_number_to_constant(left_inline_type_flag);\n+  }\n+\n+  static int right_inline_type_byte_constant() {\n+    return flag_number_to_constant(right_inline_type_flag);\n+  }\n+\n+  static ByteSize left_offset() {\n+    return cell_offset(BranchData::static_cell_count());\n+  }\n+\n+  static ByteSize right_offset() {\n+    return cell_offset(BranchData::static_cell_count() + SingleTypeEntry::static_cell_count());\n+  }\n+\n+  virtual void clean_weak_klass_links(bool always_clean) {\n+    _left.clean_weak_klass_links(always_clean);\n+    _right.clean_weak_klass_links(always_clean);\n+  }\n+\n+  static ByteSize acmp_data_size() {\n+    return cell_offset(static_cell_count());\n+  }\n+\n+  virtual void print_data_on(outputStream* st, const char* extra = NULL) const;\n+};\n+\n","filename":"src\/hotspot\/share\/oops\/methodData.hpp","additions":175,"deletions":14,"binary":false,"changes":189,"status":"modified"},{"patch":"@@ -45,1 +45,0 @@\n-  Klass* _element_klass;            \/\/ The klass of the elements of this array type\n@@ -55,5 +54,0 @@\n-  \/\/ Instance variables\n-  Klass* element_klass() const      { return _element_klass; }\n-  void set_element_klass(Klass* k)  { _element_klass = k; }\n-  Klass** element_klass_addr()      { return &_element_klass; }\n-\n@@ -67,3 +61,0 @@\n-  \/\/ Compiler\/Interpreter offset\n-  static ByteSize element_klass_offset() { return in_ByteSize(offset_of(ObjArrayKlass, _element_klass)); }\n-\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.hpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -49,0 +49,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n@@ -199,1 +201,1 @@\n-JRT_BLOCK_ENTRY(void, OptoRuntime::new_instance_C(Klass* klass, JavaThread* thread))\n+JRT_BLOCK_ENTRY(void, OptoRuntime::new_instance_C(Klass* klass, bool is_larval, JavaThread* thread))\n@@ -219,1 +221,5 @@\n-    oop result = InstanceKlass::cast(klass)->allocate_instance(THREAD);\n+    instanceOop result = InstanceKlass::cast(klass)->allocate_instance(THREAD);\n+    if (is_larval) {\n+      \/\/ Check if this is a larval buffer allocation\n+      result->set_mark(result->mark().enter_larval_state());\n+    }\n@@ -247,1 +253,4 @@\n-  if (array_type->is_typeArray_klass()) {\n+  if (array_type->is_flatArray_klass()) {\n+    Klass* elem_type = FlatArrayKlass::cast(array_type)->element_klass();\n+    result = oopFactory::new_flatArray(elem_type, len, THREAD);\n+  } else if (array_type->is_typeArray_klass()) {\n@@ -253,5 +262,1 @@\n-    \/\/ Although the oopFactory likes to work with the elem_type,\n-    \/\/ the compiler prefers the array_type, since it must already have\n-    \/\/ that latter value in hand for the fast path.\n-    Klass* elem_type = ObjArrayKlass::cast(array_type)->element_klass();\n-    result = oopFactory::new_objArray(elem_type, len, THREAD);\n+    result = ObjArrayKlass::cast(array_type)->allocate(len, THREAD);\n@@ -452,1 +457,1 @@\n-  const Type **fields = TypeTuple::fields(1);\n+  const Type **fields = TypeTuple::fields(2);\n@@ -454,1 +459,2 @@\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+1, fields);\n+  fields[TypeFunc::Parms+1] = TypeInt::BOOL;        \/\/ is_larval\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n@@ -572,1 +578,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1494,1 +1500,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1512,1 +1518,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1528,1 +1534,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1660,0 +1666,106 @@\n+\n+const TypeFunc *OptoRuntime::store_inline_type_fields_Type() {\n+  \/\/ create input type (domain)\n+  uint total = SharedRuntime::java_return_convention_max_int + SharedRuntime::java_return_convention_max_float*2;\n+  const Type **fields = TypeTuple::fields(total);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypePtr::BOTTOM;\n+  uint i = 1;\n+  for (; i < SharedRuntime::java_return_convention_max_int; i++) {\n+    fields[TypeFunc::Parms+i] = TypeInt::INT;\n+  }\n+  for (; i < total; i+=2) {\n+    fields[TypeFunc::Parms+i] = Type::DOUBLE;\n+    fields[TypeFunc::Parms+i+1] = Type::HALF;\n+  }\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + total, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1,fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+const TypeFunc *OptoRuntime::pack_inline_type_Type() {\n+  \/\/ create input type (domain)\n+  uint total = 1 + SharedRuntime::java_return_convention_max_int + SharedRuntime::java_return_convention_max_float*2;\n+  const Type **fields = TypeTuple::fields(total);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypeRawPtr::BOTTOM;\n+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;\n+  uint i = 2;\n+  for (; i < SharedRuntime::java_return_convention_max_int+1; i++) {\n+    fields[TypeFunc::Parms+i] = TypeInt::INT;\n+  }\n+  for (; i < total; i+=2) {\n+    fields[TypeFunc::Parms+i] = Type::DOUBLE;\n+    fields[TypeFunc::Parms+i+1] = Type::HALF;\n+  }\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + total, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1,fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+JRT_LEAF(void, OptoRuntime::load_unknown_inline(flatArrayOopDesc* array, int index, instanceOopDesc* buffer))\n+{\n+  array->value_copy_from_index(index, buffer);\n+}\n+JRT_END\n+\n+const TypeFunc* OptoRuntime::load_unknown_inline_type() {\n+  \/\/ create input type (domain)\n+  const Type** fields = TypeTuple::fields(3);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypeOopPtr::NOTNULL;\n+  fields[TypeFunc::Parms+1] = TypeInt::POS;\n+  fields[TypeFunc::Parms+2] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(0);\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms+0, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+JRT_LEAF(void, OptoRuntime::store_unknown_inline(instanceOopDesc* buffer, flatArrayOopDesc* array, int index))\n+{\n+  assert(buffer != NULL, \"can't store null into flat array\");\n+  array->value_copy_to_index(buffer, index);\n+}\n+JRT_END\n+\n+const TypeFunc* OptoRuntime::store_unknown_inline_type() {\n+  \/\/ create input type (domain)\n+  const Type** fields = TypeTuple::fields(3);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypeInstPtr::NOTNULL;\n+  fields[TypeFunc::Parms+1] = TypeOopPtr::NOTNULL;\n+  fields[TypeFunc::Parms+2] = TypeInt::POS;\n+\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(0);\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms+0, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":126,"deletions":14,"binary":false,"changes":140,"status":"modified"},{"patch":"@@ -26,0 +26,3 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciField.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -50,0 +53,46 @@\n+const Type::Offset Type::Offset::top(Type::OffsetTop);\n+const Type::Offset Type::Offset::bottom(Type::OffsetBot);\n+\n+const Type::Offset Type::Offset::meet(const Type::Offset other) const {\n+  \/\/ Either is 'TOP' offset?  Return the other offset!\n+  int offset = other._offset;\n+  if (_offset == OffsetTop) return Offset(offset);\n+  if (offset == OffsetTop) return Offset(_offset);\n+  \/\/ If either is different, return 'BOTTOM' offset\n+  if (_offset != offset) return bottom;\n+  return Offset(_offset);\n+}\n+\n+const Type::Offset Type::Offset::dual() const {\n+  if (_offset == OffsetTop) return bottom;\/\/ Map 'TOP' into 'BOTTOM'\n+  if (_offset == OffsetBot) return top;\/\/ Map 'BOTTOM' into 'TOP'\n+  return Offset(_offset);               \/\/ Map everything else into self\n+}\n+\n+const Type::Offset Type::Offset::add(intptr_t offset) const {\n+  \/\/ Adding to 'TOP' offset?  Return 'TOP'!\n+  if (_offset == OffsetTop || offset == OffsetTop) return top;\n+  \/\/ Adding to 'BOTTOM' offset?  Return 'BOTTOM'!\n+  if (_offset == OffsetBot || offset == OffsetBot) return bottom;\n+  \/\/ Addition overflows or \"accidentally\" equals to OffsetTop? Return 'BOTTOM'!\n+  offset += (intptr_t)_offset;\n+  if (offset != (int)offset || offset == OffsetTop) return bottom;\n+\n+  \/\/ assert( _offset >= 0 && _offset+offset >= 0, \"\" );\n+  \/\/ It is possible to construct a negative offset during PhaseCCP\n+\n+  return Offset((int)offset);        \/\/ Sum valid offsets\n+}\n+\n+void Type::Offset::dump2(outputStream *st) const {\n+  if (_offset == 0) {\n+    return;\n+  } else if (_offset == OffsetTop) {\n+    st->print(\"+top\");\n+  }\n+  else if (_offset == OffsetBot) {\n+    st->print(\"+bot\");\n+  } else if (_offset) {\n+    st->print(\"+%d\", _offset);\n+  }\n+}\n@@ -86,0 +135,1 @@\n+  { Bad,             T_INLINE_TYPE, \"inline:\",      false, Node::NotAMachineReg, relocInfo::none          },  \/\/ InlineType\n@@ -216,0 +266,9 @@\n+  case T_INLINE_TYPE: {\n+    ciInlineKlass* vk = type->as_inline_klass();\n+    if (vk->is_scalarizable()) {\n+      return TypeInlineType::make(vk);\n+    } else {\n+      return TypeOopPtr::make_from_klass(vk)->join_speculative(TypePtr::NOTNULL);\n+    }\n+  }\n+\n@@ -244,0 +303,1 @@\n+    case T_INLINE_TYPE:\n@@ -281,0 +341,1 @@\n+    case T_INLINE_TYPE: conbt = T_OBJECT; break;\n@@ -287,0 +348,1 @@\n+    case T_INLINE_TYPE: loadbt = T_OBJECT; break;\n@@ -522,3 +584,3 @@\n-  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, 0);\n-  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, OffsetBot);\n-  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, OffsetBot);\n+  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, Offset(0));\n+  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, Offset::bottom);\n+  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, Offset::bottom);\n@@ -541,1 +603,1 @@\n-                                           false, 0, oopDesc::mark_offset_in_bytes());\n+                                           false, 0, Offset(oopDesc::mark_offset_in_bytes()));\n@@ -543,2 +605,2 @@\n-                                           false, 0, oopDesc::klass_offset_in_bytes());\n-  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, OffsetBot, TypeOopPtr::InstanceBot);\n+                                           false, 0, Offset(oopDesc::klass_offset_in_bytes()));\n+  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, Offset::bottom, TypeOopPtr::InstanceBot);\n@@ -546,1 +608,3 @@\n-  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, NULL, OffsetBot);\n+  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, NULL, Offset::bottom);\n+\n+  TypeInlineType::BOTTOM = TypeInlineType::make(NULL);\n@@ -563,1 +627,1 @@\n-  TypeAryPtr::RANGE   = TypeAryPtr::make( TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), NULL \/* current->env()->Object_klass() *\/, false, arrayOopDesc::length_offset_in_bytes());\n+  TypeAryPtr::RANGE   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), NULL \/* current->env()->Object_klass() *\/, false, Offset(arrayOopDesc::length_offset_in_bytes()));\n@@ -565,1 +629,1 @@\n-  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Type::OffsetBot);\n+  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Offset::bottom);\n@@ -575,1 +639,1 @@\n-    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Type::OffsetBot);\n+    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Offset::bottom);\n@@ -577,7 +641,8 @@\n-  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Type::OffsetBot);\n-  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Type::OffsetBot);\n-  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Type::OffsetBot);\n-  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Type::OffsetBot);\n-  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Type::OffsetBot);\n-  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Type::OffsetBot);\n-  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Type::OffsetBot);\n+  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Offset::bottom);\n+  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Offset::bottom);\n+  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Offset::bottom);\n+  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Offset::bottom);\n+  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Offset::bottom);\n+  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Offset::bottom);\n+  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Offset::bottom);\n+  TypeAryPtr::INLINES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInlineType::BOTTOM,TypeInt::POS), NULL, false,  Offset::bottom);\n@@ -588,0 +653,1 @@\n+  TypeAryPtr::_array_body_type[T_INLINE_TYPE] = TypeAryPtr::OOPS;\n@@ -598,2 +664,2 @@\n-  TypeKlassPtr::OBJECT = TypeKlassPtr::make( TypePtr::NotNull, current->env()->Object_klass(), 0 );\n-  TypeKlassPtr::OBJECT_OR_NULL = TypeKlassPtr::make( TypePtr::BotPTR, current->env()->Object_klass(), 0 );\n+  TypeKlassPtr::OBJECT = TypeKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), Offset(0));\n+  TypeKlassPtr::OBJECT_OR_NULL = TypeKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), Offset(0));\n@@ -638,0 +704,1 @@\n+  _const_basic_type[T_INLINE_TYPE] = TypeInstPtr::BOTTOM;\n@@ -654,0 +721,1 @@\n+  _zero_type[T_INLINE_TYPE] = TypePtr::NULL_PTR;\n@@ -940,0 +1008,3 @@\n+  case InlineType:\n+    return t->xmeet(this);\n+\n@@ -1008,0 +1079,1 @@\n+  Bad,          \/\/ InlineType - handled in v-call\n@@ -2002,0 +2074,12 @@\n+static void collect_inline_fields(ciInlineKlass* vk, const Type** field_array, uint& pos) {\n+  for (int j = 0; j < vk->nof_nonstatic_fields(); j++) {\n+    ciField* field = vk->nonstatic_field_at(j);\n+    BasicType bt = field->type()->basic_type();\n+    const Type* ft = Type::get_const_type(field->type());\n+    field_array[pos++] = ft;\n+    if (type2size[bt] == 2) {\n+      field_array[pos++] = Type::HALF;\n+    }\n+  }\n+}\n+\n@@ -2004,1 +2088,1 @@\n-const TypeTuple *TypeTuple::make_range(ciSignature* sig) {\n+const TypeTuple *TypeTuple::make_range(ciSignature* sig, bool ret_vt_fields) {\n@@ -2007,0 +2091,4 @@\n+  if (ret_vt_fields) {\n+    arg_cnt = return_type->as_inline_klass()->inline_arg_slots() + 1;\n+  }\n+\n@@ -2027,0 +2115,10 @@\n+  case T_INLINE_TYPE:\n+    if (ret_vt_fields) {\n+      uint pos = TypeFunc::Parms;\n+      field_array[pos] = TypePtr::BOTTOM;\n+      pos++;\n+      collect_inline_fields(return_type->as_inline_klass(), field_array, pos);\n+    } else {\n+      field_array[TypeFunc::Parms] = get_const_type(return_type)->join_speculative(TypePtr::NOTNULL);\n+    }\n+    break;\n@@ -2036,2 +2134,9 @@\n-const TypeTuple *TypeTuple::make_domain(ciInstanceKlass* recv, ciSignature* sig) {\n-  uint arg_cnt = sig->size();\n+const TypeTuple *TypeTuple::make_domain(ciMethod* method, bool vt_fields_as_args) {\n+  ciSignature* sig = method->signature();\n+  uint arg_cnt = sig->size() + (method->is_static() ? 0 : 1);\n+  if (vt_fields_as_args) {\n+    arg_cnt = 0;\n+    for (ExtendedSignature sig_cc = ExtendedSignature(method->get_sig_cc(), SigEntryFilter()); !sig_cc.at_end(); ++sig_cc) {\n+      arg_cnt += type2size[(*sig_cc)._bt];\n+    }\n+  }\n@@ -2040,8 +2145,8 @@\n-  const Type **field_array;\n-  if (recv != NULL) {\n-    arg_cnt++;\n-    field_array = fields(arg_cnt);\n-    \/\/ Use get_const_type here because it respects UseUniqueSubclasses:\n-    field_array[pos++] = get_const_type(recv)->join_speculative(TypePtr::NOTNULL);\n-  } else {\n-    field_array = fields(arg_cnt);\n+  const Type** field_array = fields(arg_cnt);\n+  if (!method->is_static()) {\n+    ciInstanceKlass* recv = method->holder();\n+    if (vt_fields_as_args && recv->is_inlinetype() && recv->as_inline_klass()->can_be_passed_as_fields()) {\n+      collect_inline_fields(recv->as_inline_klass(), field_array, pos);\n+    } else {\n+      field_array[pos++] = get_const_type(recv)->join_speculative(TypePtr::NOTNULL);\n+    }\n@@ -2053,0 +2158,1 @@\n+    BasicType bt = type->basic_type();\n@@ -2054,1 +2160,1 @@\n-    switch (type->basic_type()) {\n+    switch (bt) {\n@@ -2075,0 +2181,8 @@\n+    case T_INLINE_TYPE: {\n+      if (vt_fields_as_args && type->as_inline_klass()->can_be_passed_as_fields()) {\n+        collect_inline_fields(type->as_inline_klass(), field_array, pos);\n+      } else {\n+        field_array[pos++] = get_const_type(type)->join_speculative(TypePtr::NOTNULL);\n+      }\n+      break;\n+    }\n@@ -2080,0 +2194,1 @@\n+  assert(pos == TypeFunc::Parms + arg_cnt, \"wrong number of arguments\");\n@@ -2214,1 +2329,2 @@\n-const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable) {\n+const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable,\n+                             bool not_flat, bool not_null_free) {\n@@ -2219,1 +2335,1 @@\n-  return (TypeAry*)(new TypeAry(elem,size,stable))->hashcons();\n+  return (TypeAry*)(new TypeAry(elem, size, stable, not_flat, not_null_free))->hashcons();\n@@ -2241,1 +2357,3 @@\n-                         _stable && a->_stable);\n+                         _stable && a->_stable,\n+                         _not_flat && a->_not_flat,\n+                         _not_null_free && a->_not_null_free);\n@@ -2254,1 +2372,1 @@\n-  return new TypeAry(_elem->dual(), size_dual, !_stable);\n+  return new TypeAry(_elem->dual(), size_dual, !_stable, !_not_flat, !_not_null_free);\n@@ -2263,1 +2381,4 @@\n-    _size == a->_size;\n+    _size == a->_size &&\n+    _not_flat == a->_not_flat &&\n+    _not_null_free == a->_not_null_free;\n+\n@@ -2276,1 +2397,1 @@\n-  return make(_elem->remove_speculative(), _size, _stable);\n+  return make(_elem->remove_speculative(), _size, _stable, _not_flat, _not_null_free);\n@@ -2283,1 +2404,1 @@\n-  return make(_elem->cleanup_speculative(), _size, _stable);\n+  return make(_elem->cleanup_speculative(), _size, _stable, _not_flat, _not_null_free);\n@@ -2317,0 +2438,4 @@\n+  if (Verbose) {\n+    if (_not_flat) st->print(\"not flat:\");\n+    if (_not_null_free) st->print(\"not null free:\");\n+  }\n@@ -2370,0 +2495,124 @@\n+\/\/==============================TypeInlineType=======================================\n+\n+const TypeInlineType* TypeInlineType::BOTTOM;\n+\n+\/\/------------------------------make-------------------------------------------\n+const TypeInlineType* TypeInlineType::make(ciInlineKlass* vk, bool larval) {\n+  return (TypeInlineType*)(new TypeInlineType(vk, larval))->hashcons();\n+}\n+\n+\/\/------------------------------meet-------------------------------------------\n+\/\/ Compute the MEET of two types.  It returns a new Type object.\n+const Type* TypeInlineType::xmeet(const Type* t) const {\n+  \/\/ Perform a fast test for common case; meeting the same types together.\n+  if(this == t) return this;  \/\/ Meeting same type-rep?\n+\n+  \/\/ Current \"this->_base\" is InlineType\n+  switch (t->base()) {          \/\/ switch on original type\n+\n+  case Int:\n+  case Long:\n+  case FloatTop:\n+  case FloatCon:\n+  case FloatBot:\n+  case DoubleTop:\n+  case DoubleCon:\n+  case DoubleBot:\n+  case NarrowKlass:\n+  case Bottom:\n+    return Type::BOTTOM;\n+\n+  case OopPtr:\n+  case MetadataPtr:\n+  case KlassPtr:\n+  case RawPtr:\n+    return TypePtr::BOTTOM;\n+\n+  case Top:\n+    return this;\n+\n+  case NarrowOop: {\n+    const Type* res = t->make_ptr()->xmeet(this);\n+    if (res->isa_ptr()) {\n+      return res->make_narrowoop();\n+    }\n+    return res;\n+  }\n+\n+  case AryPtr:\n+  case InstPtr: {\n+    return t->xmeet(this);\n+  }\n+\n+  case InlineType: {\n+    \/\/ All inline types inherit from Object\n+    const TypeInlineType* other = t->is_inlinetype();\n+    if (_vk == NULL) {\n+      return this;\n+    } else if (other->_vk == NULL) {\n+      return other;\n+    } else if (_vk == other->_vk) {\n+      if (_larval == other->_larval ||\n+          !_larval) {\n+        return this;\n+      } else {\n+        return t;\n+      }\n+    }\n+    return TypeInstPtr::NOTNULL;\n+  }\n+\n+  default:                      \/\/ All else is a mistake\n+    typerr(t);\n+\n+  }\n+  return this;\n+}\n+\n+\/\/------------------------------xdual------------------------------------------\n+const Type* TypeInlineType::xdual() const {\n+  return this;\n+}\n+\n+\/\/------------------------------eq---------------------------------------------\n+\/\/ Structural equality check for Type representations\n+bool TypeInlineType::eq(const Type* t) const {\n+  const TypeInlineType* vt = t->is_inlinetype();\n+  return (_vk == vt->inline_klass() && _larval == vt->larval());\n+}\n+\n+\/\/------------------------------hash-------------------------------------------\n+\/\/ Type-specific hashing function.\n+int TypeInlineType::hash(void) const {\n+  return (intptr_t)_vk;\n+}\n+\n+\/\/------------------------------singleton--------------------------------------\n+\/\/ TRUE if Type is a singleton type, FALSE otherwise. Singletons are simple constants.\n+bool TypeInlineType::singleton(void) const {\n+  return false;\n+}\n+\n+\/\/------------------------------empty------------------------------------------\n+\/\/ TRUE if Type is a type with no values, FALSE otherwise.\n+bool TypeInlineType::empty(void) const {\n+  return false;\n+}\n+\n+\/\/------------------------------dump2------------------------------------------\n+#ifndef PRODUCT\n+void TypeInlineType::dump2(Dict &d, uint depth, outputStream* st) const {\n+  if (_vk == NULL) {\n+    st->print(\"BOTTOM inlinetype\");\n+    return;\n+  }\n+  int count = _vk->nof_declared_nonstatic_fields();\n+  st->print(\"inlinetype[%d]:{\", count);\n+  st->print(\"%s\", count != 0 ? _vk->declared_nonstatic_field_at(0)->type()->name() : \"empty\");\n+  for (int i = 1; i < count; ++i) {\n+    st->print(\", %s\", _vk->declared_nonstatic_field_at(i)->type()->name());\n+  }\n+  st->print(\"}%s\", _larval?\" : larval\":\"\");\n+}\n+#endif\n+\n@@ -2515,1 +2764,1 @@\n-const TypePtr *TypePtr::make(TYPES t, enum PTR ptr, int offset, const TypePtr* speculative, int inline_depth) {\n+const TypePtr* TypePtr::make(TYPES t, enum PTR ptr, Offset offset, const TypePtr* speculative, int inline_depth) {\n@@ -2529,1 +2778,1 @@\n-  return _offset;\n+  return offset();\n@@ -2598,7 +2847,2 @@\n-int TypePtr::meet_offset( int offset ) const {\n-  \/\/ Either is 'TOP' offset?  Return the other offset!\n-  if( _offset == OffsetTop ) return offset;\n-  if( offset == OffsetTop ) return _offset;\n-  \/\/ If either is different, return 'BOTTOM' offset\n-  if( _offset != offset ) return OffsetBot;\n-  return _offset;\n+Type::Offset TypePtr::meet_offset(int offset) const {\n+  return _offset.meet(Offset(offset));\n@@ -2608,4 +2852,2 @@\n-int TypePtr::dual_offset( ) const {\n-  if( _offset == OffsetTop ) return OffsetBot;\/\/ Map 'TOP' into 'BOTTOM'\n-  if( _offset == OffsetBot ) return OffsetTop;\/\/ Map 'BOTTOM' into 'TOP'\n-  return _offset;               \/\/ Map everything else into self\n+Type::Offset TypePtr::dual_offset() const {\n+  return _offset.dual();\n@@ -2624,13 +2866,2 @@\n-int TypePtr::xadd_offset( intptr_t offset ) const {\n-  \/\/ Adding to 'TOP' offset?  Return 'TOP'!\n-  if( _offset == OffsetTop || offset == OffsetTop ) return OffsetTop;\n-  \/\/ Adding to 'BOTTOM' offset?  Return 'BOTTOM'!\n-  if( _offset == OffsetBot || offset == OffsetBot ) return OffsetBot;\n-  \/\/ Addition overflows or \"accidentally\" equals to OffsetTop? Return 'BOTTOM'!\n-  offset += (intptr_t)_offset;\n-  if (offset != (int)offset || offset == OffsetTop) return OffsetBot;\n-\n-  \/\/ assert( _offset >= 0 && _offset+offset >= 0, \"\" );\n-  \/\/ It is possible to construct a negative offset during PhaseCCP\n-\n-  return (int)offset;        \/\/ Sum valid offsets\n+Type::Offset TypePtr::xadd_offset(intptr_t offset) const {\n+  return _offset.add(offset);\n@@ -2648,1 +2879,1 @@\n-  return _ptr == a->ptr() && _offset == a->offset() && eq_speculative(a) && _inline_depth == a->_inline_depth;\n+  return _ptr == a->ptr() && _offset == a->_offset && eq_speculative(a) && _inline_depth == a->_inline_depth;\n@@ -2654,1 +2885,1 @@\n-  return java_add(java_add((jint)_ptr, (jint)_offset), java_add((jint)hash_speculative(), (jint)_inline_depth));\n+  return java_add(java_add((jint)_ptr, (jint)offset()), java_add((jint)hash_speculative(), (jint)_inline_depth));\n@@ -2914,3 +3145,1 @@\n-  if( _offset == OffsetTop ) st->print(\"+top\");\n-  else if( _offset == OffsetBot ) st->print(\"+bot\");\n-  else if( _offset ) st->print(\"+%d\", _offset);\n+  _offset.dump2(st);\n@@ -2951,1 +3180,1 @@\n-  return (_offset != OffsetBot) && !below_centerline(_ptr);\n+  return (_offset != Offset::bottom) && !below_centerline(_ptr);\n@@ -2955,1 +3184,1 @@\n-  return (_offset == OffsetTop) || above_centerline(_ptr);\n+  return (_offset == Offset::top) || above_centerline(_ptr);\n@@ -3097,1 +3326,1 @@\n-TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset,\n+TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset, Offset field_offset,\n@@ -3107,2 +3336,2 @@\n-      (offset > 0) && xk && (k != 0) && k->is_instance_klass()) {\n-    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset);\n+      (offset.get() > 0) && xk && (k != 0) && k->is_instance_klass()) {\n+    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset.get());\n@@ -3111,2 +3340,2 @@\n-  if (_offset > 0 || _offset == Type::OffsetTop || _offset == Type::OffsetBot) {\n-    if (_offset == oopDesc::klass_offset_in_bytes()) {\n+  if (this->offset() > 0 || this->offset() == Type::OffsetTop || this->offset() == Type::OffsetBot) {\n+    if (this->offset() == oopDesc::klass_offset_in_bytes()) {\n@@ -3118,3 +3347,12 @@\n-    } else if (this->isa_aryptr()) {\n-      _is_ptr_to_narrowoop = (UseCompressedOops && klass()->is_obj_array_klass() &&\n-                             _offset != arrayOopDesc::length_offset_in_bytes());\n+    } else if (UseCompressedOops && this->isa_aryptr() && this->offset() != arrayOopDesc::length_offset_in_bytes()) {\n+      if (klass()->is_obj_array_klass()) {\n+        _is_ptr_to_narrowoop = true;\n+      } else if (klass()->is_flat_array_klass() && field_offset != Offset::top && field_offset != Offset::bottom) {\n+        \/\/ Check if the field of the inline type array element contains oops\n+        ciInlineKlass* vk = klass()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+        int foffset = field_offset.get() + vk->first_field_offset();\n+        ciField* field = vk->get_field_by_offset(foffset, false);\n+        assert(field != NULL, \"missing field\");\n+        BasicType bt = field->layout_type();\n+        _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(bt);\n+      }\n@@ -3122,2 +3360,0 @@\n-      ciInstanceKlass* ik = klass()->as_instance_klass();\n-      ciField* field = NULL;\n@@ -3126,1 +3362,1 @@\n-      } else if (_offset == OffsetBot || _offset == OffsetTop) {\n+      } else if (_offset == Offset::bottom || _offset == Offset::top) {\n@@ -3131,3 +3367,2 @@\n-\n-            (_offset == java_lang_Class::klass_offset() ||\n-             _offset == java_lang_Class::array_klass_offset())) {\n+            (this->offset() == java_lang_Class::klass_offset() ||\n+             this->offset() == java_lang_Class::array_klass_offset())) {\n@@ -3139,1 +3374,1 @@\n-                   _offset >= InstanceMirrorKlass::offset_of_static_fields()) {\n+                   this->offset() >= InstanceMirrorKlass::offset_of_static_fields()) {\n@@ -3144,8 +3379,14 @@\n-            field = k->get_field_by_offset(_offset, true);\n-          }\n-          if (field != NULL) {\n-            BasicType basic_elem_type = field->layout_type();\n-            _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(basic_elem_type);\n-          } else {\n-            \/\/ unsafe access\n-            _is_ptr_to_narrowoop = UseCompressedOops;\n+            if (k->is_inlinetype() && this->offset() == k->as_inline_klass()->default_value_offset()) {\n+              \/\/ Special hidden field that contains the oop of the default inline type\n+              \/\/ basic_elem_type = T_INLINE_TYPE;\n+             _is_ptr_to_narrowoop = UseCompressedOops;\n+            } else {\n+              field = k->get_field_by_offset(this->offset(), true);\n+              if (field != NULL) {\n+                BasicType basic_elem_type = field->layout_type();\n+                _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(basic_elem_type);\n+              } else {\n+                \/\/ unsafe access\n+                _is_ptr_to_narrowoop = UseCompressedOops;\n+              }\n+            }\n@@ -3155,1 +3396,2 @@\n-          field = ik->get_field_by_offset(_offset, false);\n+          ciInstanceKlass* ik = klass()->as_instance_klass();\n+          ciField* field = ik->get_field_by_offset(this->offset(), false);\n@@ -3175,2 +3417,2 @@\n-const TypeOopPtr *TypeOopPtr::make(PTR ptr, int offset, int instance_id,\n-                                     const TypePtr* speculative, int inline_depth) {\n+const TypeOopPtr *TypeOopPtr::make(PTR ptr, Offset offset, int instance_id,\n+                                   const TypePtr* speculative, int inline_depth) {\n@@ -3181,1 +3423,1 @@\n-  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, xk, o, offset, instance_id, speculative, inline_depth))->hashcons();\n+  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, xk, o, offset, Offset::bottom, instance_id, speculative, inline_depth))->hashcons();\n@@ -3206,1 +3448,0 @@\n-\n@@ -3216,1 +3457,1 @@\n-    return TypeKlassPtr::make(xk? Constant: NotNull, k, 0);\n+    return TypeKlassPtr::make(xk? Constant: NotNull, k, Offset(0));\n@@ -3254,1 +3495,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3296,1 +3537,1 @@\n-  return new TypeOopPtr(_base, dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n+  return new TypeOopPtr(_base, dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), Offset::bottom, dual_instance_id(), dual_speculative(), dual_inline_depth());\n@@ -3302,1 +3543,1 @@\n-  if (klass->is_instance_klass()) {\n+  if (klass->is_instance_klass() || klass->is_inlinetype()) {\n@@ -3328,1 +3569,1 @@\n-    return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, 0);\n+    return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, Offset(0));\n@@ -3330,2 +3571,14 @@\n-    \/\/ Element is an object array. Recursively call ourself.\n-    const TypeOopPtr *etype = TypeOopPtr::make_from_klass_common(klass->as_obj_array_klass()->element_klass(), false, try_for_exact);\n+    \/\/ Element is an object or inline type array. Recursively call ourself.\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), \/* klass_change= *\/ false, try_for_exact);\n+    if (etype->is_inlinetypeptr()) {\n+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n+    \/\/ Determine null-free\/flattened properties\n+    const TypeOopPtr* exact_etype = etype;\n+    if (etype->can_be_inline_type()) {\n+      \/\/ Use exact type if element can be an inline type\n+      exact_etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), \/* klass_change= *\/ true, \/* try_for_exact= *\/ true);\n+    }\n+    bool not_null_free = !exact_etype->can_be_inline_type();\n+    bool not_flat = !UseFlatArray || not_null_free || (exact_etype->is_inlinetypeptr() && !exact_etype->inline_klass()->flatten_array());\n+\n@@ -3333,1 +3586,1 @@\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, false, not_flat, not_null_free);\n@@ -3337,1 +3590,1 @@\n-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, 0);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, Offset(0));\n@@ -3342,1 +3595,2 @@\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS,\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3345,1 +3599,6 @@\n-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, 0);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));\n+    return arr;\n+  } else if (klass->is_flat_array_klass()) {\n+    ciInlineKlass* vk = klass->as_array_klass()->element_klass()->as_inline_klass();\n+    const TypeAry* arr0 = TypeAry::make(TypeInlineType::make(vk), TypeInt::POS);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));\n@@ -3361,2 +3620,2 @@\n-  if (klass->is_instance_klass()) {\n-    \/\/ Element is an instance\n+  if (klass->is_instance_klass() || klass->is_inlinetype()) {\n+    \/\/ Element is an instance or inline type\n@@ -3366,1 +3625,1 @@\n-      return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, 0);\n+      return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, Offset(0));\n@@ -3370,3 +3629,8 @@\n-    const TypeOopPtr *etype =\n-      TypeOopPtr::make_from_klass_raw(klass->as_obj_array_klass()->element_klass());\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_raw(klass->as_array_klass()->element_klass());\n+    bool null_free = false;\n+    if (etype->is_inlinetypeptr()) {\n+      null_free = true;\n+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ !null_free);\n@@ -3377,1 +3641,1 @@\n-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n@@ -3379,1 +3643,1 @@\n-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n@@ -3383,3 +3647,3 @@\n-    const Type* etype =\n-      (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));\n+    const Type* etype = (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3389,1 +3653,12 @@\n-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n+    } else {\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n+    }\n+  } else if (klass->is_flat_array_klass()) {\n+    ciInlineKlass* vk = klass->as_array_klass()->element_klass()->as_inline_klass();\n+    const TypeAry* arr0 = TypeAry::make(TypeInlineType::make(vk), TypeInt::make(o->as_array()->length()));\n+    \/\/ We used to pass NotNull in here, asserting that the sub-arrays\n+    \/\/ are all not-null.  This is not true in generally, as code can\n+    \/\/ slam NULLs down in the subarrays.\n+    if (make_constant) {\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n@@ -3391,1 +3666,1 @@\n-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n@@ -3402,1 +3677,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -3404,1 +3679,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -3497,6 +3772,1 @@\n-  switch( _offset ) {\n-  case OffsetTop: st->print(\"+top\"); break;\n-  case OffsetBot: st->print(\"+any\"); break;\n-  case         0: break;\n-  default:        st->print(\"+%d\",_offset); break;\n-  }\n+  _offset.dump2(st);\n@@ -3519,1 +3789,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -3611,7 +3881,10 @@\n-TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, int off,\n-                         int instance_id, const TypePtr* speculative, int inline_depth)\n-  : TypeOopPtr(InstPtr, ptr, k, xk, o, off, instance_id, speculative, inline_depth),\n-    _name(k->name()) {\n-   assert(k != NULL &&\n-          (k->is_loaded() || o == NULL),\n-          \"cannot have constants with non-loaded klass\");\n+TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset off,\n+                         bool flatten_array, int instance_id, const TypePtr* speculative,\n+                         int inline_depth)\n+  : TypeOopPtr(InstPtr, ptr, k, xk, o, off, Offset::bottom, instance_id, speculative, inline_depth),\n+    _name(k->name()), _flatten_array(flatten_array) {\n+  assert(k != NULL &&\n+         (k->is_loaded() || o == NULL),\n+         \"cannot have constants with non-loaded klass\");\n+  assert(!klass()->flatten_array() || flatten_array, \"Should be flat in array\");\n+  assert(!flatten_array || can_be_inline_type(), \"Only inline types can be flat in array\");\n@@ -3625,1 +3898,2 @@\n-                                     int offset,\n+                                     Offset offset,\n+                                     bool flatten_array,\n@@ -3646,0 +3920,3 @@\n+  \/\/ Check if this type is known to be flat in arrays\n+  flatten_array = flatten_array || k->flatten_array();\n+\n@@ -3648,1 +3925,1 @@\n-    (TypeInstPtr*)(new TypeInstPtr(ptr, k, xk, o ,offset, instance_id, speculative, inline_depth))->hashcons();\n+    (TypeInstPtr*)(new TypeInstPtr(ptr, k, xk, o, offset, flatten_array, instance_id, speculative, inline_depth))->hashcons();\n@@ -3681,1 +3958,1 @@\n-  return make(ptr, klass(), klass_is_exact(), const_oop(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr, klass(), klass_is_exact(), const_oop(), _offset, _flatten_array, _instance_id, _speculative, _inline_depth);\n@@ -3692,1 +3969,1 @@\n-  return make(ptr(), klass(), klass_is_exact, const_oop(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), klass(), klass_is_exact, const_oop(), _offset, _flatten_array, _instance_id, _speculative, _inline_depth);\n@@ -3698,1 +3975,1 @@\n-  return make(_ptr, klass(), _klass_is_exact, const_oop(), _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, klass(), _klass_is_exact, const_oop(), _offset, _flatten_array, instance_id, _speculative, _inline_depth);\n@@ -3705,1 +3982,1 @@\n-    int off = meet_offset(tinst->offset());\n+    Offset off = meet_offset(tinst->offset());\n@@ -3730,1 +4007,1 @@\n-      else if (loaded->ptr() == TypePtr::AnyNull) { return TypeInstPtr::make(ptr, unloaded->klass(), false, NULL, off, instance_id, speculative, depth); }\n+      else if (loaded->ptr() == TypePtr::AnyNull) { return TypeInstPtr::make(ptr, unloaded->klass(), false, NULL, off, false, instance_id, speculative, depth); }\n@@ -3783,1 +4060,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3794,2 +4071,2 @@\n-      if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact()) {\n-        return TypeAryPtr::make(ptr, tp->ary(), tp->klass(), tp->klass_is_exact(), offset, instance_id, speculative, depth);\n+      if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact() && !flatten_array()) {\n+        return TypeAryPtr::make(ptr, tp->ary(), tp->klass(), tp->klass_is_exact(), offset, tp->field_offset(), instance_id, speculative, depth);\n@@ -3800,1 +4077,1 @@\n-        return TypeInstPtr::make( ptr, ciEnv::current()->Object_klass(), false, NULL, offset, instance_id, speculative, depth);\n+        return TypeInstPtr::make( ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);\n@@ -3812,1 +4089,1 @@\n-        if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact()) {\n+        if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact() && !flatten_array()) {\n@@ -3815,1 +4092,1 @@\n-                                  tp->ary(), tp->klass(), tp->klass_is_exact(), offset, instance_id, speculative, depth);\n+                                  tp->ary(), tp->klass(), tp->klass_is_exact(), offset, tp->field_offset(), instance_id, speculative, depth);\n@@ -3823,1 +4100,1 @@\n-      return make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, instance_id, speculative, depth);\n+      return make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);\n@@ -3831,1 +4108,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3840,1 +4117,1 @@\n-                  (ptr == Constant ? const_oop() : NULL), offset, instance_id, speculative, depth);\n+                  (ptr == Constant ? const_oop() : NULL), offset, flatten_array(), instance_id, speculative, depth);\n@@ -3856,1 +4133,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3868,1 +4145,1 @@\n-                  (ptr == Constant ? const_oop() : NULL), offset, instance_id, speculative, depth);\n+                  (ptr == Constant ? const_oop() : NULL), offset, flatten_array(), instance_id, speculative, depth);\n@@ -3896,1 +4173,1 @@\n-    int off = meet_offset( tinst->offset() );\n+    Offset off = meet_offset( tinst->offset() );\n@@ -3906,2 +4183,3 @@\n-    if (ptr != Constant && klass()->equals(tinst->klass()) && klass_is_exact() == tinst->klass_is_exact()) {\n-      return make(ptr, klass(), klass_is_exact(), NULL, off, instance_id, speculative, depth);\n+    if (ptr != Constant && klass()->equals(tinst->klass()) && klass_is_exact() == tinst->klass_is_exact() &&\n+        flatten_array() == tinst->flatten_array()) {\n+      return make(ptr, klass(), klass_is_exact(), NULL, off, flatten_array(), instance_id, speculative, depth);\n@@ -3915,0 +4193,2 @@\n+    bool tinst_flatten_array = tinst->flatten_array();\n+    bool this_flatten_array  = this->flatten_array();\n@@ -3937,0 +4217,3 @@\n+      tmp2 = tinst_flatten_array;\n+      tinst_flatten_array = this_flatten_array;\n+      this_flatten_array = tmp2;\n@@ -3948,0 +4231,1 @@\n+      bool flat_array;\n@@ -3956,0 +4240,1 @@\n+        flat_array = below_centerline(ptr) ? tinst_flatten_array    : this_flatten_array;\n@@ -3962,0 +4247,1 @@\n+        flat_array = above_centerline(ptr) ? tinst_flatten_array : false;\n@@ -3971,1 +4257,1 @@\n-      return make(ptr, k, xk, o, off, instance_id, speculative, depth);\n+      return make(ptr, k, xk, o, off, flat_array, instance_id, speculative, depth);\n@@ -4003,1 +4289,2 @@\n-    if( tinst_klass->equals(this_klass) ) {\n+    bool flat_array = false;\n+    if (tinst_klass->equals(this_klass)) {\n@@ -4006,1 +4293,2 @@\n-    } else if( !tinst_xk && this_klass->is_subtype_of( tinst_klass ) ) {\n+      flat_array = below_centerline(ptr) ? (this_flatten_array && tinst_flatten_array) : (this_flatten_array || tinst_flatten_array);\n+    } else if(!tinst_xk && this_klass->is_subtype_of(tinst_klass) && (!tinst_flatten_array || this_flatten_array)) {\n@@ -4009,1 +4297,2 @@\n-    } else if( !this_xk && tinst_klass->is_subtype_of( this_klass ) ) {\n+      flat_array = this_flatten_array;\n+    } else if(!this_xk && tinst_klass->is_subtype_of(this_klass) && (!this_flatten_array || tinst_flatten_array)) {\n@@ -4012,0 +4301,1 @@\n+      flat_array = tinst_flatten_array;\n@@ -4014,2 +4304,2 @@\n-    if( subtype ) {\n-      if( above_centerline(ptr) ) { \/\/ both are up?\n+    if (subtype) {\n+      if (above_centerline(ptr)) { \/\/ both are up?\n@@ -4018,1 +4308,2 @@\n-      } else if( above_centerline(this ->_ptr) && !above_centerline(tinst->_ptr) ) {\n+        this_flatten_array = tinst_flatten_array = flat_array;\n+      } else if (above_centerline(this ->_ptr) && !above_centerline(tinst->_ptr)) {\n@@ -4021,1 +4312,2 @@\n-      } else if( above_centerline(tinst->_ptr) && !above_centerline(this ->_ptr) ) {\n+        this_flatten_array = tinst_flatten_array;\n+      } else if (above_centerline(tinst->_ptr) && !above_centerline(this ->_ptr)) {\n@@ -4024,0 +4316,1 @@\n+        tinst_flatten_array = this_flatten_array;\n@@ -4026,0 +4319,1 @@\n+        this_flatten_array = flat_array;\n@@ -4048,1 +4342,1 @@\n-      return make(ptr, this_klass, this_xk, o, off, instance_id, speculative, depth);\n+      return make(ptr, this_klass, this_xk, o, off, this_flatten_array, instance_id, speculative, depth);\n@@ -4060,1 +4354,1 @@\n-    return make(ptr, k, false, NULL, off, instance_id, speculative, depth);\n+    return make(ptr, k, false, NULL, off, false, instance_id, speculative, depth);\n@@ -4063,0 +4357,21 @@\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return t;\n+      } else {\n+        return TypeInstPtr::NOTNULL;\n+      }\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return TypeInstPtr::make(ptr, _klass);\n+      } else {\n+        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass());\n+      }\n+    }\n+  }\n+\n@@ -4075,1 +4390,0 @@\n-\n@@ -4084,1 +4398,1 @@\n-  return new TypeInstPtr(dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n+  return new TypeInstPtr(dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), flatten_array(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n@@ -4093,0 +4407,1 @@\n+    flatten_array() == p->flatten_array() &&\n@@ -4099,1 +4414,1 @@\n-  int hash = java_add((jint)klass()->hash(), (jint)TypeOopPtr::hash());\n+  int hash = java_add(java_add((jint)klass()->hash(), (jint)TypeOopPtr::hash()), (jint)flatten_array());\n@@ -4131,5 +4446,1 @@\n-  if( _offset ) {               \/\/ Dump offset, if any\n-    if( _offset == OffsetBot )      st->print(\"+any\");\n-    else if( _offset == OffsetTop ) st->print(\"+unknown\");\n-    else st->print(\"+%d\", _offset);\n-  }\n+  _offset.dump2(st);\n@@ -4138,0 +4449,5 @@\n+\n+  if (flatten_array() && !klass()->is_inlinetype()) {\n+    st->print(\" (flatten array)\");\n+  }\n+\n@@ -4150,1 +4466,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), xadd_offset(offset),\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), xadd_offset(offset), flatten_array(),\n@@ -4159,1 +4475,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset,\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(),\n@@ -4167,1 +4483,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, _instance_id, _speculative, depth);\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(), _instance_id, _speculative, depth);\n@@ -4172,1 +4488,5 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(), instance_id, _speculative, _inline_depth);\n+}\n+\n+const TypeInstPtr *TypeInstPtr::cast_to_flatten_array() const {\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, true, _instance_id, _speculative, _inline_depth);\n@@ -4175,0 +4495,1 @@\n+\n@@ -4187,0 +4508,1 @@\n+const TypeAryPtr *TypeAryPtr::INLINES;\n@@ -4189,1 +4511,1 @@\n-const TypeAryPtr *TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+const TypeAryPtr* TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,\n@@ -4195,1 +4517,1 @@\n-  return (TypeAryPtr*)(new TypeAryPtr(ptr, NULL, ary, k, xk, offset, instance_id, false, speculative, inline_depth))->hashcons();\n+  return (TypeAryPtr*)(new TypeAryPtr(ptr, NULL, ary, k, xk, offset, field_offset, instance_id, false, speculative, inline_depth))->hashcons();\n@@ -4199,1 +4521,1 @@\n-const TypeAryPtr *TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+const TypeAryPtr* TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,\n@@ -4207,1 +4529,1 @@\n-  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();\n+  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, field_offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();\n@@ -4213,1 +4535,1 @@\n-  return make(ptr, const_oop(), _ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr, const_oop(), _ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4221,1 +4543,7 @@\n-  return make(ptr(), const_oop(), _ary, klass(), klass_is_exact, _offset, _instance_id, _speculative, _inline_depth);\n+\n+  const TypeAry* new_ary = _ary;\n+  if (klass() != NULL && klass()->is_obj_array_klass() && klass_is_exact) {\n+    \/\/ An object array can't be flat or null-free if the klass is exact\n+    new_ary = TypeAry::make(elem(), size(), is_stable(), \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n+  }\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact, _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4227,1 +4555,1 @@\n-  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4283,2 +4611,36 @@\n-  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable());\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable(), is_not_flat(), is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/-------------------------------cast_to_not_flat------------------------------\n+const TypeAryPtr* TypeAryPtr::cast_to_not_flat(bool not_flat) const {\n+  if (not_flat == is_not_flat()) {\n+    return this;\n+  }\n+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), not_flat, is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/-------------------------------cast_to_not_null_free-------------------------\n+const TypeAryPtr* TypeAryPtr::cast_to_not_null_free(bool not_null_free) const {\n+  if (not_null_free == is_not_null_free()) {\n+    return this;\n+  }\n+  \/\/ Not null free implies not flat\n+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), not_null_free ? true : is_not_flat(), not_null_free);\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/---------------------------------update_properties---------------------------\n+const TypeAryPtr* TypeAryPtr::update_properties(const TypeAryPtr* from) const {\n+  if ((from->is_flat()          && is_not_flat()) ||\n+      (from->is_not_flat()      && is_flat()) ||\n+      (from->is_null_free()     && is_not_null_free()) ||\n+      (from->is_not_null_free() && is_null_free())) {\n+    return NULL; \/\/ Inconsistent properties\n+  } else if (from->is_not_null_free()) {\n+    return cast_to_not_null_free(); \/\/ Implies not flat\n+  } else if (from->is_not_flat()) {\n+    return cast_to_not_flat();\n+  }\n+  return this;\n@@ -4300,1 +4662,1 @@\n-  const TypeAry* new_ary = TypeAry::make(elem, size(), stable);\n+  const TypeAry* new_ary = TypeAry::make(elem, size(), stable, is_not_flat(), is_not_null_free());\n@@ -4302,1 +4664,1 @@\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4322,2 +4684,2 @@\n-  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable());\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth, \/*is_autobox_cache=*\/true);\n+  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable(), is_not_flat(), is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, \/*is_autobox_cache=*\/true);\n@@ -4332,1 +4694,2 @@\n-    TypeOopPtr::eq(p);  \/\/ Check sub-parts\n+    TypeOopPtr::eq(p) &&\/\/ Check sub-parts\n+    _field_offset == p->_field_offset;\n@@ -4338,1 +4701,1 @@\n-  return (intptr_t)_ary + TypeOopPtr::hash();\n+  return (intptr_t)_ary + TypeOopPtr::hash() + _field_offset.get();\n@@ -4371,1 +4734,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4380,1 +4743,1 @@\n-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4394,1 +4757,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4410,1 +4773,1 @@\n-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4422,1 +4785,2 @@\n-    int off = meet_offset(tap->offset());\n+    Offset off = meet_offset(tap->offset());\n+    Offset field_off = meet_field_offset(tap->field_offset());\n@@ -4440,1 +4804,1 @@\n-        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable);\n+        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);\n@@ -4447,1 +4811,1 @@\n-          tap->_klass != NULL  && this->_klass != NULL   &&\n+          tap->_klass != NULL && this->_klass != NULL &&\n@@ -4450,1 +4814,1 @@\n-           \/\/ 'tap'  is exact and super or unrelated:\n+           \/\/ 'tap' is exact and super or unrelated:\n@@ -4454,2 +4818,15 @@\n-      if (above_centerline(ptr) || (tary->_elem->make_ptr() && above_centerline(tary->_elem->make_ptr()->_ptr))) {\n-        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable);\n+      if (above_centerline(ptr) || (tary->_elem->make_ptr() && above_centerline(tary->_elem->make_ptr()->_ptr)) ||\n+          tary->_elem->isa_inlinetype()) {\n+        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);\n+      }\n+      return make(NotNull, NULL, tary, lazy_klass, false, off, field_off, InstanceBot, speculative, depth);\n+    } else if (klass() != NULL && tap->klass() != NULL && klass()->is_flat_array_klass() != tap->klass()->is_flat_array_klass()) {\n+      \/\/ Meeting flattened inline type array with non-flattened array. Adjust (field) offset accordingly.\n+      if (tary->_elem->isa_inlinetype()) {\n+        \/\/ Result is flattened\n+        off = Offset(is_flat() ? offset() : tap->offset());\n+        field_off = is_flat() ? field_offset() : tap->field_offset();\n+      } else if (tary->_elem->make_oopptr() != NULL && tary->_elem->make_oopptr()->isa_instptr() && below_centerline(ptr)) {\n+        \/\/ Result is non-flattened\n+        off = Offset(flattened_offset()).meet(Offset(tap->flattened_offset()));\n+        field_off = Offset::bottom;\n@@ -4457,1 +4834,0 @@\n-      return make(NotNull, NULL, tary, lazy_klass, false, off, InstanceBot, speculative, depth);\n@@ -4470,1 +4846,1 @@\n-      return make(ptr, const_oop(), tary, lazy_klass, xk, off, instance_id, speculative, depth);\n+      return make(ptr, const_oop(), tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n@@ -4489,1 +4865,1 @@\n-      return TypeAryPtr::make(ptr, o, tary, lazy_klass, xk, off, instance_id, speculative, depth);\n+      return TypeAryPtr::make(ptr, o, tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n@@ -4498,1 +4874,1 @@\n-      return TypeAryPtr::make(ptr, NULL, tary, lazy_klass, xk, off, instance_id, speculative, depth);\n+      return TypeAryPtr::make(ptr, NULL, tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n@@ -4506,1 +4882,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4517,2 +4893,2 @@\n-      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {\n-        return TypeAryPtr::make(ptr, _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flatten_array()) {\n+        return TypeAryPtr::make(ptr, _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4523,1 +4899,1 @@\n-        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL,offset, instance_id, speculative, depth);\n+        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);\n@@ -4535,1 +4911,1 @@\n-        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {\n+        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flatten_array()) {\n@@ -4538,1 +4914,1 @@\n-                      _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                      _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4546,1 +4922,1 @@\n-      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL,offset, instance_id, speculative, depth);\n+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);\n@@ -4550,0 +4926,13 @@\n+\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      return TypeInstPtr::NOTNULL;\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass());\n+    }\n+  }\n@@ -4557,1 +4946,10 @@\n-  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(),_klass, _klass_is_exact, dual_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());\n+  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(), _klass, _klass_is_exact, dual_offset(), dual_field_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());\n+}\n+\n+Type::Offset TypeAryPtr::meet_field_offset(const Type::Offset offset) const {\n+  return _field_offset.meet(offset);\n+}\n+\n+\/\/------------------------------dual_offset------------------------------------\n+Type::Offset TypeAryPtr::dual_field_offset() const {\n+  return _field_offset.dual();\n@@ -4594,1 +4992,6 @@\n-  if( _offset != 0 ) {\n+  if (is_flat()) {\n+    st->print(\"(\");\n+    _field_offset.dump2(st);\n+    st->print(\")\");\n+  }\n+  if (offset() != 0) {\n@@ -4596,3 +4999,3 @@\n-    if( _offset == OffsetTop )       st->print(\"+undefined\");\n-    else if( _offset == OffsetBot )  st->print(\"+any\");\n-    else if( _offset < header_size ) st->print(\"+%d\", _offset);\n+    if( _offset == Offset::top )       st->print(\"+undefined\");\n+    else if( _offset == Offset::bottom )  st->print(\"+any\");\n+    else if( offset() < header_size ) st->print(\"+%d\", offset());\n@@ -4603,1 +5006,1 @@\n-      st->print(\"[%d]\", (_offset - array_base)\/elem_size);\n+      st->print(\"[%d]\", (offset() - array_base)\/elem_size);\n@@ -4624,1 +5027,1 @@\n-  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _instance_id, add_offset_speculative(offset), _inline_depth);\n+  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _field_offset, _instance_id, add_offset_speculative(offset), _inline_depth, _is_autobox_cache);\n@@ -4632,1 +5035,13 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, NULL, _inline_depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, NULL, _inline_depth, _is_autobox_cache);\n+}\n+\n+const Type* TypeAryPtr::cleanup_speculative() const {\n+  if (speculative() == NULL) {\n+    return this;\n+  }\n+  \/\/ Keep speculative part if it contains information about flat-\/nullability\n+  const TypeAryPtr* spec_aryptr = speculative()->isa_aryptr();\n+  if (spec_aryptr != NULL && (spec_aryptr->is_not_flat() || spec_aryptr->is_not_null_free())) {\n+    return this;\n+  }\n+  return TypeOopPtr::cleanup_speculative();\n@@ -4639,1 +5054,52 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, _speculative, depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, _speculative, depth, _is_autobox_cache);\n+}\n+\n+const TypeAryPtr* TypeAryPtr::with_field_offset(int offset) const {\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, Offset(offset), _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+const TypePtr* TypeAryPtr::add_field_offset_and_offset(intptr_t offset) const {\n+  int adj = 0;\n+  if (offset != Type::OffsetBot && offset != Type::OffsetTop) {\n+    const Type* elemtype = elem();\n+    if (elemtype->isa_inlinetype()) {\n+      if (_offset.get() != OffsetBot && _offset.get() != OffsetTop) {\n+        adj = _offset.get();\n+        offset += _offset.get();\n+      }\n+      uint header = arrayOopDesc::base_offset_in_bytes(T_OBJECT);\n+      if (_field_offset.get() != OffsetBot && _field_offset.get() != OffsetTop) {\n+        offset += _field_offset.get();\n+        if (_offset.get() == OffsetBot || _offset.get() == OffsetTop) {\n+          offset += header;\n+        }\n+      }\n+      if (offset >= (intptr_t)header || offset < 0) {\n+        \/\/ Try to get the field of the inline type array element we are pointing to\n+        ciKlass* arytype_klass = klass();\n+        ciFlatArrayKlass* vak = arytype_klass->as_flat_array_klass();\n+        ciInlineKlass* vk = vak->element_klass()->as_inline_klass();\n+        int shift = vak->log2_element_size();\n+        int mask = (1 << shift) - 1;\n+        intptr_t field_offset = ((offset - header) & mask);\n+        ciField* field = vk->get_field_by_offset(field_offset + vk->first_field_offset(), false);\n+        if (field == NULL) {\n+          \/\/ This may happen with nested AddP(base, AddP(base, base, offset), longcon(16))\n+          return add_offset(offset);\n+        } else {\n+          return with_field_offset(field_offset)->add_offset(offset - field_offset - adj);\n+        }\n+      }\n+    }\n+  }\n+  return add_offset(offset - adj);\n+}\n+\n+\/\/ Return offset incremented by field_offset for flattened inline type arrays\n+const int TypeAryPtr::flattened_offset() const {\n+  int offset = _offset.get();\n+  if (offset != Type::OffsetBot && offset != Type::OffsetTop &&\n+      _field_offset != Offset::bottom && _field_offset != Offset::top) {\n+    offset += _field_offset.get();\n+  }\n+  return offset;\n@@ -4644,1 +5110,1 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth);\n@@ -4649,0 +5115,1 @@\n+\n@@ -4737,1 +5204,0 @@\n-\n@@ -4743,0 +5209,3 @@\n+  case InlineType:\n+    return t->xmeet(this);\n+\n@@ -4821,1 +5290,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -4841,1 +5310,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -4843,1 +5312,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -4894,1 +5363,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4920,1 +5389,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4953,1 +5422,1 @@\n-  switch( _offset ) {\n+  switch (offset()) {\n@@ -4957,1 +5426,1 @@\n-  default:        st->print(\"+%d\",_offset); break;\n+  default:        st->print(\"+%d\",offset()); break;\n@@ -4967,1 +5436,1 @@\n-TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset):\n+TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset):\n@@ -4972,1 +5441,1 @@\n-  return make(Constant, m, 0);\n+  return make(Constant, m, Offset(0));\n@@ -4975,1 +5444,1 @@\n-  return make(Constant, m, 0);\n+  return make(Constant, m, Offset(0));\n@@ -4980,1 +5449,1 @@\n-const TypeMetadataPtr *TypeMetadataPtr::make(PTR ptr, ciMetadata* m, int offset) {\n+const TypeMetadataPtr* TypeMetadataPtr::make(PTR ptr, ciMetadata* m, Offset offset) {\n@@ -4994,2 +5463,5 @@\n-TypeKlassPtr::TypeKlassPtr( PTR ptr, ciKlass* klass, int offset )\n-  : TypePtr(KlassPtr, ptr, offset), _klass(klass), _klass_is_exact(ptr == Constant) {\n+TypeKlassPtr::TypeKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flatten_array, bool not_flat, bool not_null_free)\n+  : TypePtr(KlassPtr, ptr, offset), _klass(klass), _klass_is_exact(ptr == Constant),\n+    _flatten_array(flatten_array), _not_flat(not_flat), _not_null_free(not_null_free) {\n+  assert(!klass->flatten_array() || flatten_array, \"Should be flat in array\");\n+  assert(!flatten_array || can_be_inline_type(), \"Only inline types can be flat in array\");\n@@ -5000,7 +5472,5 @@\n-const TypeKlassPtr *TypeKlassPtr::make( PTR ptr, ciKlass* k, int offset ) {\n-  assert( k != NULL, \"Expect a non-NULL klass\");\n-  assert(k->is_instance_klass() || k->is_array_klass(), \"Incorrect type of klass oop\");\n-  TypeKlassPtr *r =\n-    (TypeKlassPtr*)(new TypeKlassPtr(ptr, k, offset))->hashcons();\n-\n-  return r;\n+const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array, bool not_flat, bool not_null_free) {\n+  assert(k == NULL || k->is_instance_klass() || k->is_array_klass(), \"Incorrect type of klass oop\");\n+  \/\/ Check if this type is known to be flat in arrays\n+  flatten_array = flatten_array || k->flatten_array();\n+  return (TypeKlassPtr*)(new TypeKlassPtr(ptr, k, offset, flatten_array, not_flat, not_null_free))->hashcons();\n@@ -5013,3 +5483,2 @@\n-  return\n-    klass()->equals(p->klass()) &&\n-    TypePtr::eq(p);\n+  return klass() == p->klass() && TypePtr::eq(p) && flatten_array() == p->flatten_array() &&\n+      is_not_flat() == p->is_not_flat() && is_not_null_free() == p->is_not_null_free();\n@@ -5021,1 +5490,2 @@\n-  return java_add((jint)klass()->hash(), (jint)TypePtr::hash());\n+  return java_add(java_add(java_add(java_add(klass() != NULL ? klass()->hash() : (jint)0, (jint)TypePtr::hash()),\n+      (jint)flatten_array()), (jint)is_not_flat()), (jint)is_not_null_free());\n@@ -5030,1 +5500,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -5042,1 +5512,1 @@\n-    if (!empty() && ktkp != NULL && ktkp->klass()->is_loaded() && ktkp->klass()->is_interface())\n+    if (!empty() && ktkp != NULL && ktkp->is_loaded() && ktkp->klass()->is_interface())\n@@ -5065,1 +5535,0 @@\n-  const TypeInstPtr *tinst;\n@@ -5073,3 +5542,8 @@\n-  if ((tinst = el->isa_instptr()) != NULL) {\n-    \/\/ Compute array klass from element klass\n-    k_ary = ciObjArrayKlass::make(tinst->klass());\n+  if (el->isa_instptr()) {\n+    \/\/ Compute object array klass from element klass\n+    k_ary = ciArrayKlass::make(el->is_oopptr()->klass());\n+  } else if (el->isa_inlinetype()) {\n+    \/\/ If element type is TypeInlineType::BOTTOM, inline_klass() will be null.\n+    if (el->inline_klass() != NULL) {\n+      k_ary = ciArrayKlass::make(el->inline_klass());\n+    }\n@@ -5140,1 +5614,1 @@\n-        _offset != 0 && _offset != arrayOopDesc::length_offset_in_bytes()) {\n+        offset() != 0 && offset() != arrayOopDesc::length_offset_in_bytes()) {\n@@ -5151,1 +5625,1 @@\n-  return make( _ptr, klass(), xadd_offset(offset) );\n+  return make(_ptr, klass(), xadd_offset(offset), flatten_array(), is_not_flat(), is_not_null_free());\n@@ -5158,1 +5632,1 @@\n-  return make(ptr, _klass, _offset);\n+  return make(ptr, _klass, _offset, _flatten_array, _not_flat, _not_null_free);\n@@ -5165,1 +5639,1 @@\n-  return make(klass_is_exact ? Constant : NotNull, _klass, _offset);\n+  return make(klass_is_exact ? Constant : NotNull, _klass, _offset, _flatten_array, _not_flat, _not_null_free);\n@@ -5174,0 +5648,1 @@\n+  assert(k != NULL, \"klass should not be NULL\");\n@@ -5175,1 +5650,0 @@\n-  \/\/return TypeInstPtr::make(TypePtr::NotNull, k, xk, NULL, 0);\n@@ -5179,0 +5653,7 @@\n+  if (flatten_array() && !klass()->is_inlinetype()) {\n+    toop = toop->is_instptr()->cast_to_flatten_array();\n+  } else if (is_not_null_free()) {\n+    toop = toop->is_aryptr()->cast_to_not_null_free();\n+  } else if (is_not_flat()) {\n+    toop = toop->is_aryptr()->cast_to_not_flat();\n+  }\n@@ -5213,1 +5694,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5221,1 +5702,1 @@\n-      return make( ptr, klass(), offset );\n+      return make(ptr, klass(), offset, flatten_array(), is_not_flat(), is_not_null_free());\n@@ -5254,1 +5735,1 @@\n-    int  off     = meet_offset(tkls->offset());\n+    Offset  off  = meet_offset(tkls->offset());\n@@ -5257,0 +5738,8 @@\n+    if (klass() == NULL || tkls->klass() == NULL) {\n+      ciKlass* k = NULL;\n+      if (ptr == Constant) {\n+        k = (klass() == NULL) ? tkls->klass() : klass();\n+      }\n+      return make(ptr, k, off);\n+    }\n+\n@@ -5261,2 +5750,2 @@\n-    if( ptr != Constant && tkls->klass()->equals(klass()) ) {\n-      return make( ptr, klass(), off );\n+    if (ptr != Constant && tkls->klass()->equals(klass()) && flatten_array() == tkls->flatten_array() && is_not_flat() == tkls->is_not_flat() && is_not_null_free() && tkls->is_not_null_free()) {\n+      return make(ptr, klass(), off, flatten_array(), is_not_flat(), is_not_null_free());\n@@ -5270,0 +5759,3 @@\n+    bool flatten_array = below_centerline(ptr) ? (this->flatten_array() && tkls->flatten_array()) : (this->flatten_array() || tkls->flatten_array());\n+    bool is_not_flat = this->is_not_flat() && tkls->is_not_flat();\n+    bool is_not_null_free = this->is_not_null_free() && tkls->is_not_null_free();\n@@ -5297,1 +5789,1 @@\n-      return make( ptr, this_klass, off );\n+      return make(ptr, this_klass, off, flatten_array, is_not_flat, is_not_null_free);\n@@ -5306,1 +5798,1 @@\n-    return   make( ptr, k, off );\n+    return make(ptr, k, off, false, is_not_flat, is_not_null_free);\n@@ -5316,1 +5808,1 @@\n-  return new TypeKlassPtr( dual_ptr(), klass(), dual_offset() );\n+  return new TypeKlassPtr(dual_ptr(), klass(), dual_offset(), flatten_array(), !is_not_flat(), !is_not_null_free());\n@@ -5322,1 +5814,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -5324,1 +5816,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -5347,2 +5839,2 @@\n-      const char *name = klass()->name()->as_utf8();\n-      if( name ) {\n+      if (klass() != NULL) {\n+        const char* name = klass()->name()->as_utf8();\n@@ -5351,1 +5843,1 @@\n-        ShouldNotReachHere();\n+        st->print(\"klass BOTTOM\");\n@@ -5364,5 +5856,4 @@\n-\n-  if( _offset ) {               \/\/ Dump offset, if any\n-    if( _offset == OffsetBot )      { st->print(\"+any\"); }\n-    else if( _offset == OffsetTop ) { st->print(\"+unknown\"); }\n-    else                            { st->print(\"+%d\", _offset); }\n+  if (Verbose) {\n+    if (_flatten_array) st->print(\":flatten array\");\n+    if (_not_flat) st->print(\":not flat\");\n+    if (_not_null_free) st->print(\":not null free\");\n@@ -5371,0 +5862,2 @@\n+  _offset.dump2(st);\n+\n@@ -5381,2 +5874,14 @@\n-const TypeFunc *TypeFunc::make( const TypeTuple *domain, const TypeTuple *range ) {\n-  return (TypeFunc*)(new TypeFunc(domain,range))->hashcons();\n+const TypeFunc *TypeFunc::make(const TypeTuple *domain_sig, const TypeTuple* domain_cc,\n+                               const TypeTuple *range_sig, const TypeTuple *range_cc) {\n+  return (TypeFunc*)(new TypeFunc(domain_sig, domain_cc, range_sig, range_cc))->hashcons();\n+}\n+\n+const TypeFunc *TypeFunc::make(const TypeTuple *domain, const TypeTuple *range) {\n+  return make(domain, domain, range, range);\n+}\n+\n+\/\/------------------------------osr_domain-----------------------------\n+const TypeTuple* osr_domain() {\n+  const Type **fields = TypeTuple::fields(2);\n+  fields[TypeFunc::Parms+0] = TypeRawPtr::BOTTOM;  \/\/ address of osr buffer\n+  return TypeTuple::make(TypeFunc::Parms+1, fields);\n@@ -5386,1 +5891,1 @@\n-const TypeFunc *TypeFunc::make(ciMethod* method) {\n+const TypeFunc* TypeFunc::make(ciMethod* method, bool is_osr_compilation) {\n@@ -5388,7 +5893,20 @@\n-  const TypeFunc* tf = C->last_tf(method); \/\/ check cache\n-  if (tf != NULL)  return tf;  \/\/ The hit rate here is almost 50%.\n-  const TypeTuple *domain;\n-  if (method->is_static()) {\n-    domain = TypeTuple::make_domain(NULL, method->signature());\n-  } else {\n-    domain = TypeTuple::make_domain(method->holder(), method->signature());\n+  const TypeFunc* tf = NULL;\n+  if (!is_osr_compilation) {\n+    tf = C->last_tf(method); \/\/ check cache\n+    if (tf != NULL)  return tf;  \/\/ The hit rate here is almost 50%.\n+  }\n+  \/\/ Inline types are not passed\/returned by reference, instead each field of\n+  \/\/ the inline type is passed\/returned as an argument. We maintain two views of\n+  \/\/ the argument\/return list here: one based on the signature (with an inline\n+  \/\/ type argument\/return as a single slot), one based on the actual calling\n+  \/\/ convention (with an inline type argument\/return as a list of its fields).\n+  bool has_scalar_args = method->has_scalarized_args() && !is_osr_compilation;\n+  const TypeTuple* domain_sig = is_osr_compilation ? osr_domain() : TypeTuple::make_domain(method, false);\n+  const TypeTuple* domain_cc = has_scalar_args ? TypeTuple::make_domain(method, true) : domain_sig;\n+  ciSignature* sig = method->signature();\n+  bool has_scalar_ret = sig->return_type()->is_inlinetype() && sig->return_type()->as_inline_klass()->can_be_returned_as_fields();\n+  const TypeTuple* range_sig = TypeTuple::make_range(sig, false);\n+  const TypeTuple* range_cc = has_scalar_ret ? TypeTuple::make_range(sig, true) : range_sig;\n+  tf = TypeFunc::make(domain_sig, domain_cc, range_sig, range_cc);\n+  if (!is_osr_compilation) {\n+    C->set_last_tf(method, tf);  \/\/ fill cache\n@@ -5396,3 +5914,0 @@\n-  const TypeTuple *range  = TypeTuple::make_range(method->signature());\n-  tf = TypeFunc::make(domain, range);\n-  C->set_last_tf(method, tf);  \/\/ fill cache\n@@ -5433,2 +5948,4 @@\n-  return _domain == a->_domain &&\n-    _range == a->_range;\n+  return _domain_sig == a->_domain_sig &&\n+    _domain_cc == a->_domain_cc &&\n+    _range_sig == a->_range_sig &&\n+    _range_cc == a->_range_cc;\n@@ -5440,1 +5957,1 @@\n-  return (intptr_t)_domain + (intptr_t)_range;\n+  return (intptr_t)_domain_sig + (intptr_t)_domain_cc + (intptr_t)_range_sig + (intptr_t)_range_cc;\n@@ -5447,1 +5964,1 @@\n-  if( _range->cnt() <= Parms )\n+  if( _range_sig->cnt() <= Parms )\n@@ -5451,2 +5968,2 @@\n-    for (i = Parms; i < _range->cnt()-1; i++) {\n-      _range->field_at(i)->dump2(d,depth,st);\n+    for (i = Parms; i < _range_sig->cnt()-1; i++) {\n+      _range_sig->field_at(i)->dump2(d,depth,st);\n@@ -5455,1 +5972,1 @@\n-    _range->field_at(i)->dump2(d,depth,st);\n+    _range_sig->field_at(i)->dump2(d,depth,st);\n@@ -5464,3 +5981,3 @@\n-  if (Parms < _domain->cnt())\n-    _domain->field_at(Parms)->dump2(d,depth-1,st);\n-  for (uint i = Parms+1; i < _domain->cnt(); i++) {\n+  if (Parms < _domain_sig->cnt())\n+    _domain_sig->field_at(Parms)->dump2(d,depth-1,st);\n+  for (uint i = Parms+1; i < _domain_sig->cnt(); i++) {\n@@ -5468,1 +5985,1 @@\n-    _domain->field_at(i)->dump2(d,depth-1,st);\n+    _domain_sig->field_at(i)->dump2(d,depth-1,st);\n@@ -5488,1 +6005,1 @@\n-  if (range()->cnt() == TypeFunc::Parms) {\n+  if (range_sig()->cnt() == TypeFunc::Parms) {\n@@ -5491,1 +6008,1 @@\n-  return range()->field_at(TypeFunc::Parms)->basic_type();\n+  return range_sig()->field_at(TypeFunc::Parms)->basic_type();\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":825,"deletions":308,"binary":false,"changes":1133,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n@@ -56,0 +58,1 @@\n+class   TypeInlineType;\n@@ -98,0 +101,1 @@\n+    InlineType,                 \/\/ Inline type\n@@ -129,0 +133,24 @@\n+  class Offset {\n+  private:\n+    int _offset;\n+\n+  public:\n+    explicit Offset(int offset) : _offset(offset) {}\n+\n+    const Offset meet(const Offset other) const;\n+    const Offset dual() const;\n+    const Offset add(intptr_t offset) const;\n+    bool operator==(const Offset& other) const {\n+      return _offset == other._offset;\n+    }\n+    bool operator!=(const Offset& other) const {\n+      return _offset != other._offset;\n+    }\n+    int get() const { return _offset; }\n+\n+    void dump2(outputStream *st) const;\n+\n+    static const Offset top;\n+    static const Offset bottom;\n+  };\n+\n@@ -278,3 +306,0 @@\n-  bool is_ptr_to_boxing_obj() const;\n-\n-\n@@ -316,0 +341,2 @@\n+  const TypeInlineType* isa_inlinetype() const;  \/\/ Returns NULL if not Inline Type\n+  const TypeInlineType* is_inlinetype() const;   \/\/ Inline Type\n@@ -325,0 +352,3 @@\n+  bool is_inlinetypeptr() const;\n+  virtual ciInlineKlass* inline_klass() const;\n+\n@@ -712,2 +742,2 @@\n-  static const TypeTuple *make_range(ciSignature *sig);\n-  static const TypeTuple *make_domain(ciInstanceKlass* recv, ciSignature *sig);\n+  static const TypeTuple *make_range(ciSignature* sig, bool ret_vt_fields = false);\n+  static const TypeTuple *make_domain(ciMethod* method, bool vt_fields_as_args = false);\n@@ -742,2 +772,2 @@\n-  TypeAry(const Type* elem, const TypeInt* size, bool stable) : Type(Array),\n-      _elem(elem), _size(size), _stable(stable) {}\n+  TypeAry(const Type* elem, const TypeInt* size, bool stable, bool not_flat, bool not_null_free) : Type(Array),\n+      _elem(elem), _size(size), _stable(stable), _not_flat(not_flat), _not_null_free(not_null_free) {}\n@@ -754,0 +784,5 @@\n+\n+  \/\/ Inline type array properties\n+  const bool _not_flat;         \/\/ Array is never flattened\n+  const bool _not_null_free;    \/\/ Array is never null-free\n+\n@@ -757,1 +792,2 @@\n-  static const TypeAry* make(const Type* elem, const TypeInt* size, bool stable = false);\n+  static const TypeAry* make(const Type* elem, const TypeInt* size, bool stable = false,\n+                             bool not_flat = false, bool not_null_free = false);\n@@ -764,0 +800,1 @@\n+\n@@ -773,0 +810,37 @@\n+\n+\/\/------------------------------TypeValue---------------------------------------\n+\/\/ Class of Inline Type Types\n+class TypeInlineType : public Type {\n+private:\n+  ciInlineKlass* _vk;\n+  bool _larval;\n+\n+protected:\n+  TypeInlineType(ciInlineKlass* vk, bool larval)\n+    : Type(InlineType),\n+      _vk(vk), _larval(larval) {\n+  }\n+\n+public:\n+  static const TypeInlineType* make(ciInlineKlass* vk, bool larval = false);\n+  virtual ciInlineKlass* inline_klass() const { return _vk; }\n+  bool larval() const { return _larval; }\n+\n+  virtual bool eq(const Type* t) const;\n+  virtual int  hash() const;             \/\/ Type specific hashing\n+  virtual bool singleton(void) const;    \/\/ TRUE if type is a singleton\n+  virtual bool empty(void) const;        \/\/ TRUE if type is vacuous\n+\n+  virtual const Type* xmeet(const Type* t) const;\n+  virtual const Type* xdual() const;     \/\/ Compute dual right now.\n+\n+  virtual bool would_improve_type(ciKlass* exact_kls, int inline_depth) const { return false; }\n+  virtual bool would_improve_ptr(ProfilePtrKind ptr_kind) const { return false; }\n+\n+  static const TypeInlineType* BOTTOM;\n+\n+#ifndef PRODUCT\n+  virtual void dump2(Dict &d, uint, outputStream* st) const; \/\/ Specialized per-Type dumping\n+#endif\n+};\n+\n@@ -858,1 +932,1 @@\n-  TypePtr(TYPES t, PTR ptr, int offset,\n+  TypePtr(TYPES t, PTR ptr, Offset offset,\n@@ -901,1 +975,1 @@\n-  const int _offset;            \/\/ Offset into oop, with TOP & BOT\n+  const Offset _offset;         \/\/ Offset into oop, with TOP & BOT\n@@ -904,1 +978,1 @@\n-  const int offset() const { return _offset; }\n+  const int offset() const { return _offset.get(); }\n@@ -907,1 +981,1 @@\n-  static const TypePtr *make(TYPES t, PTR ptr, int offset,\n+  static const TypePtr* make(TYPES t, PTR ptr, Offset offset,\n@@ -916,1 +990,1 @@\n-  int xadd_offset( intptr_t offset ) const;\n+  Offset xadd_offset(intptr_t offset) const;\n@@ -918,0 +992,2 @@\n+  virtual const int flattened_offset() const { return offset(); }\n+\n@@ -925,2 +1001,2 @@\n-  int meet_offset( int offset ) const;\n-  int dual_offset( ) const;\n+  Offset meet_offset(int offset) const;\n+  Offset dual_offset() const;\n@@ -954,0 +1030,5 @@\n+  virtual bool can_be_inline_type() const { return false; }\n+  virtual bool flatten_array() const { return false; }\n+  virtual bool is_not_flat() const { return false; }\n+  virtual bool is_not_null_free() const { return false; }\n+\n@@ -971,1 +1052,1 @@\n-  TypeRawPtr( PTR ptr, address bits ) : TypePtr(RawPtr,ptr,0), _bits(bits){}\n+  TypeRawPtr(PTR ptr, address bits) : TypePtr(RawPtr,ptr,Offset(0)), _bits(bits){}\n@@ -1002,2 +1083,2 @@\n-  TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset, int instance_id,\n-             const TypePtr* speculative, int inline_depth);\n+  TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset, Offset field_offset,\n+             int instance_id, const TypePtr* speculative, int inline_depth);\n@@ -1062,1 +1143,1 @@\n-  static const TypeOopPtr* make(PTR ptr, int offset, int instance_id,\n+  static const TypeOopPtr* make(PTR ptr, Offset offset, int instance_id,\n@@ -1077,1 +1158,3 @@\n-  bool is_known_instance_field() const { return is_known_instance() && _offset >= 0; }\n+  bool is_known_instance_field() const { return is_known_instance() && _offset.get() >= 0; }\n+\n+  virtual bool can_be_inline_type() const { return EnableValhalla && (_klass == NULL || _klass->can_be_inline_klass(_klass_is_exact)); }\n@@ -1115,2 +1198,3 @@\n-  TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset, int instance_id,\n-              const TypePtr* speculative, int inline_depth);\n+  TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset,\n+              bool flatten_array, int instance_id, const TypePtr* speculative,\n+              int inline_depth);\n@@ -1121,0 +1205,1 @@\n+  bool _flatten_array;     \/\/ Type is flat in arrays\n@@ -1129,1 +1214,1 @@\n-    return make(TypePtr::Constant, o->klass(), true, o, 0, InstanceBot);\n+    return make(TypePtr::Constant, o->klass(), true, o, Offset(0));\n@@ -1132,2 +1217,2 @@\n-  static const TypeInstPtr *make(ciObject* o, int offset) {\n-    return make(TypePtr::Constant, o->klass(), true, o, offset, InstanceBot);\n+  static const TypeInstPtr* make(ciObject* o, Offset offset) {\n+    return make(TypePtr::Constant, o->klass(), true, o, offset);\n@@ -1138,1 +1223,1 @@\n-    return make(ptr, klass, false, NULL, 0, InstanceBot);\n+    return make(ptr, klass, false, NULL, Offset(0));\n@@ -1143,1 +1228,1 @@\n-    return make(ptr, klass, true, NULL, 0, InstanceBot);\n+    return make(ptr, klass, true, NULL, Offset(0));\n@@ -1147,2 +1232,2 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* klass, int offset) {\n-    return make(ptr, klass, false, NULL, offset, InstanceBot);\n+  static const TypeInstPtr *make(PTR ptr, ciKlass* klass, Offset offset) {\n+    return make(ptr, klass, false, NULL, offset);\n@@ -1152,1 +1237,2 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset,\n+  static const TypeInstPtr* make(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset,\n+                                 bool flatten_array = false,\n@@ -1178,0 +1264,3 @@\n+  virtual const TypeInstPtr* cast_to_flatten_array() const;\n+  virtual bool flatten_array() const { return _flatten_array; }\n+\n@@ -1197,4 +1286,4 @@\n-  TypeAryPtr( PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk,\n-              int offset, int instance_id, bool is_autobox_cache,\n-              const TypePtr* speculative, int inline_depth)\n-    : TypeOopPtr(AryPtr,ptr,k,xk,o,offset, instance_id, speculative, inline_depth),\n+  TypeAryPtr(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk,\n+             Offset offset, Offset field_offset, int instance_id, bool is_autobox_cache,\n+             const TypePtr* speculative, int inline_depth)\n+    : TypeOopPtr(AryPtr, ptr, k, xk, o, offset, field_offset, instance_id, speculative, inline_depth),\n@@ -1202,1 +1291,2 @@\n-    _is_autobox_cache(is_autobox_cache)\n+    _is_autobox_cache(is_autobox_cache),\n+    _field_offset(field_offset)\n@@ -1225,0 +1315,6 @@\n+  \/\/ For flattened inline type arrays, each field of the inline type in\n+  \/\/ the array has its own memory slice so we need to keep track of\n+  \/\/ which field is accessed\n+  const Offset _field_offset;\n+  Offset meet_field_offset(const Type::Offset offset) const;\n+  Offset dual_field_offset() const;\n@@ -1236,0 +1332,6 @@\n+  \/\/ Inline type array properties\n+  bool is_flat()          const { return _ary->_elem->isa_inlinetype() != NULL; }\n+  bool is_not_flat()      const { return _ary->_not_flat; }\n+  bool is_null_free()     const { return is_flat() || (_ary->_elem->make_ptr() != NULL && _ary->_elem->make_ptr()->is_inlinetypeptr()); }\n+  bool is_not_null_free() const { return _ary->_not_null_free; }\n+\n@@ -1238,1 +1340,2 @@\n-  static const TypeAryPtr *make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+  static const TypeAryPtr* make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset,\n+                                Offset field_offset = Offset::bottom,\n@@ -1243,1 +1346,2 @@\n-  static const TypeAryPtr *make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+  static const TypeAryPtr* make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset,\n+                                Offset field_offset = Offset::bottom,\n@@ -1246,1 +1350,2 @@\n-                                int inline_depth = InlineDepthBottom, bool is_autobox_cache = false);\n+                                int inline_depth = InlineDepthBottom,\n+                                bool is_autobox_cache = false);\n@@ -1263,0 +1368,1 @@\n+  virtual const Type* cleanup_speculative() const;\n@@ -1270,0 +1376,5 @@\n+  \/\/ Inline type array properties\n+  const TypeAryPtr* cast_to_not_flat(bool not_flat = true) const;\n+  const TypeAryPtr* cast_to_not_null_free(bool not_null_free = true) const;\n+  const TypeAryPtr* update_properties(const TypeAryPtr* new_type) const;\n+\n@@ -1275,1 +1386,8 @@\n-  static jint max_array_length(BasicType etype) ;\n+  static jint max_array_length(BasicType etype);\n+\n+  const int flattened_offset() const;\n+  const Offset field_offset() const { return _field_offset; }\n+  const TypeAryPtr* with_field_offset(int offset) const;\n+  const TypePtr* add_field_offset_and_offset(intptr_t offset) const;\n+\n+  virtual bool can_be_inline_type() const { return false; }\n@@ -1288,0 +1406,1 @@\n+  static const TypeAryPtr *INLINES;\n@@ -1308,1 +1427,1 @@\n-  TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset);\n+  TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset);\n@@ -1320,1 +1439,1 @@\n-  static const TypeMetadataPtr* make(PTR ptr, ciMetadata* m, int offset);\n+  static const TypeMetadataPtr* make(PTR ptr, ciMetadata* m, Offset offset);\n@@ -1347,1 +1466,1 @@\n-  TypeKlassPtr( PTR ptr, ciKlass* klass, int offset );\n+  TypeKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flatten_array, bool not_flat, bool not_null_free);\n@@ -1357,2 +1476,0 @@\n-  static const TypeKlassPtr* make_from_klass_common(ciKlass* klass, bool klass_change, bool try_for_exact);\n-\n@@ -1362,1 +1479,4 @@\n-  bool          _klass_is_exact;\n+  bool _klass_is_exact;\n+  const bool _flatten_array; \/\/ Type is flat in arrays\n+  const bool _not_flat;      \/\/ Array is never flattened\n+  const bool _not_null_free; \/\/ Array is never null-free\n@@ -1365,2 +1485,0 @@\n-  ciSymbol* name()  const { return klass()->name(); }\n-\n@@ -1370,18 +1488,4 @@\n-  bool  is_loaded() const { return klass()->is_loaded(); }\n-\n-  \/\/ Creates a type given a klass. Correctly handles multi-dimensional arrays\n-  \/\/ Respects UseUniqueSubclasses.\n-  \/\/ If the klass is final, the resulting type will be exact.\n-  static const TypeKlassPtr* make_from_klass(ciKlass* klass) {\n-    return make_from_klass_common(klass, true, false);\n-  }\n-  \/\/ Same as before, but will produce an exact type, even if\n-  \/\/ the klass is not final, as long as it has exactly one implementation.\n-  static const TypeKlassPtr* make_from_klass_unique(ciKlass* klass) {\n-    return make_from_klass_common(klass, true, true);\n-  }\n-  \/\/ Same as before, but does not respects UseUniqueSubclasses.\n-  \/\/ Use this only for creating array element types.\n-  static const TypeKlassPtr* make_from_klass_raw(ciKlass* klass) {\n-    return make_from_klass_common(klass, false, false);\n-  }\n+  virtual bool can_be_inline_type() const { return EnableValhalla && (_klass == NULL || _klass->can_be_inline_klass(_klass_is_exact)); }\n+  virtual bool flatten_array() const { return _flatten_array; }\n+  virtual bool is_not_flat() const { return _not_flat; }\n+  virtual bool is_not_null_free() const { return _not_null_free; }\n@@ -1389,2 +1493,1 @@\n-  \/\/ Make a generic (unclassed) pointer to metadata.\n-  static const TypeKlassPtr* make(PTR ptr, int offset);\n+  bool  is_loaded() const { return klass() != NULL && klass()->is_loaded(); }\n@@ -1393,3 +1496,6 @@\n-  static const TypeKlassPtr *make( ciKlass* k ) { return make( TypePtr::Constant, k, 0); }\n-  \/\/ ptr to klass 'k' with offset\n-  static const TypeKlassPtr *make( ciKlass* k, int offset ) { return make( TypePtr::Constant, k, offset); }\n+  static const TypeKlassPtr* make(ciKlass* k) {\n+    bool not_null_free = k->is_array_klass() && ( k->as_array_klass()->element_klass() == NULL ||\n+                                                 !k->as_array_klass()->element_klass()->can_be_inline_klass(true));\n+    bool not_flat = k->is_array_klass() && !k->is_flat_array_klass();\n+    return make(TypePtr::Constant, k, Offset(0), false, not_flat, not_null_free);\n+  }\n@@ -1397,1 +1503,1 @@\n-  static const TypeKlassPtr *make( PTR ptr, ciKlass* k, int offset);\n+  static const TypeKlassPtr* make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array = false, bool not_flat = false, bool not_null_free = false);\n@@ -1548,1 +1654,2 @@\n-  TypeFunc( const TypeTuple *domain, const TypeTuple *range ) : Type(Function),  _domain(domain), _range(range) {}\n+  TypeFunc(const TypeTuple *domain_sig, const TypeTuple *domain_cc, const TypeTuple *range_sig, const TypeTuple *range_cc)\n+    : Type(Function), _domain_sig(domain_sig), _domain_cc(domain_cc), _range_sig(range_sig), _range_cc(range_cc) {}\n@@ -1554,2 +1661,13 @@\n-  const TypeTuple* const _domain;     \/\/ Domain of inputs\n-  const TypeTuple* const _range;      \/\/ Range of results\n+  \/\/ Domains of inputs: inline type arguments are not passed by\n+  \/\/ reference, instead each field of the inline type is passed as an\n+  \/\/ argument. We maintain 2 views of the argument list here: one\n+  \/\/ based on the signature (with an inline type argument as a single\n+  \/\/ slot), one based on the actual calling convention (with a value\n+  \/\/ type argument as a list of its fields).\n+  const TypeTuple* const _domain_sig;\n+  const TypeTuple* const _domain_cc;\n+  \/\/ Range of results. Similar to domains: an inline type result can be\n+  \/\/ returned in registers in which case range_cc lists all fields and\n+  \/\/ is the actual calling convention.\n+  const TypeTuple* const _range_sig;\n+  const TypeTuple* const _range_cc;\n@@ -1569,5 +1687,8 @@\n-  const TypeTuple* domain() const { return _domain; }\n-  const TypeTuple* range()  const { return _range; }\n-\n-  static const TypeFunc *make(ciMethod* method);\n-  static const TypeFunc *make(ciSignature signature, const Type* extra);\n+  const TypeTuple* domain_sig() const { return _domain_sig; }\n+  const TypeTuple* domain_cc()  const { return _domain_cc; }\n+  const TypeTuple* range_sig()  const { return _range_sig; }\n+  const TypeTuple* range_cc()   const { return _range_cc; }\n+\n+  static const TypeFunc* make(ciMethod* method, bool is_osr_compilation = false);\n+  static const TypeFunc *make(const TypeTuple* domain_sig, const TypeTuple* domain_cc,\n+                              const TypeTuple* range_sig, const TypeTuple* range_cc);\n@@ -1581,0 +1702,2 @@\n+  bool returns_inline_type_as_fields() const { return range_sig() != range_cc(); }\n+\n@@ -1743,0 +1866,9 @@\n+inline const TypeInlineType* Type::isa_inlinetype() const {\n+  return (_base == InlineType) ? (TypeInlineType*)this : NULL;\n+}\n+\n+inline const TypeInlineType* Type::is_inlinetype() const {\n+  assert(_base == InlineType, \"Not an inline type\");\n+  return (TypeInlineType*)this;\n+}\n+\n@@ -1809,5 +1941,8 @@\n-inline bool Type::is_ptr_to_boxing_obj() const {\n-  const TypeInstPtr* tp = isa_instptr();\n-  return (tp != NULL) && (tp->offset() == 0) &&\n-         tp->klass()->is_instance_klass()  &&\n-         tp->klass()->as_instance_klass()->is_box_klass();\n+inline bool Type::is_inlinetypeptr() const {\n+  return isa_instptr() != NULL && is_instptr()->klass()->is_inlinetype();\n+}\n+\n+\n+inline ciInlineKlass* Type::inline_klass() const {\n+  assert(is_inlinetypeptr(), \"must be an inline type ptr\");\n+  return is_instptr()->klass()->as_inline_klass();\n@@ -1842,0 +1977,1 @@\n+#define CmpUXNode    CmpULNode\n@@ -1862,0 +1998,1 @@\n+#define Op_StoreX    Op_StoreL\n@@ -1890,0 +2027,1 @@\n+#define CmpUXNode    CmpUNode\n@@ -1910,0 +2048,1 @@\n+#define Op_StoreX    Op_StoreI\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":223,"deletions":84,"binary":false,"changes":307,"status":"modified"},{"patch":"@@ -55,0 +55,2 @@\n+#include \"oops\/flatArrayOop.inline.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -420,0 +422,1 @@\n+  bool is_inlined = InstanceKlass::cast(k1)->field_is_inlined(slot);\n@@ -421,1 +424,1 @@\n-  ret = jfieldIDWorkaround::to_instance_jfieldID(k1, offset);\n+  ret = jfieldIDWorkaround::to_instance_jfieldID(k1, offset, is_inlined);\n@@ -438,1 +441,1 @@\n-  if (m->is_initializer()) {\n+  if (m->is_object_constructor() || m->is_static_init_factory()) {\n@@ -496,1 +499,0 @@\n-\n@@ -801,1 +803,2 @@\n-    case T_OBJECT:      push_object(va_arg(_ap, jobject)); break;\n+    case T_OBJECT:\n+    case T_INLINE_TYPE: push_object(va_arg(_ap, jobject)); break;\n@@ -841,1 +844,2 @@\n-    case T_OBJECT:      push_object((_ap++)->l); break;\n+    case T_OBJECT:\n+    case T_INLINE_TYPE: push_object((_ap++)->l); break;\n@@ -977,5 +981,19 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n-  obj = JNIHandles::make_local(THREAD, i);\n-  JavaValue jvalue(T_VOID);\n-  JNI_ArgumentPusherArray ap(methodID, args);\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == NULL) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);\n+  }\n+\n+  if (!k->is_inline_klass()) {\n+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n+    obj = JNIHandles::make_local(THREAD, i);\n+    JavaValue jvalue(T_VOID);\n+    JNI_ArgumentPusherArray ap(methodID, args);\n+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+  } else {\n+    JavaValue jvalue(T_INLINE_TYPE);\n+    JNI_ArgumentPusherArray ap(methodID, args);\n+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);\n+    obj = jvalue.get_jobject();\n+  }\n@@ -983,1 +1001,1 @@\n-JNI_END\n+  JNI_END\n@@ -995,5 +1013,19 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n-  obj = JNIHandles::make_local(THREAD, i);\n-  JavaValue jvalue(T_VOID);\n-  JNI_ArgumentPusherVaArg ap(methodID, args);\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == NULL) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);\n+  }\n+\n+  if (!k->is_inline_klass()) {\n+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n+    obj = JNIHandles::make_local(THREAD, i);\n+    JavaValue jvalue(T_VOID);\n+    JNI_ArgumentPusherVaArg ap(methodID, args);\n+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+  } else {\n+    JavaValue jvalue(T_INLINE_TYPE);\n+    JNI_ArgumentPusherVaArg ap(methodID, args);\n+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);\n+    obj = jvalue.get_jobject();\n+  }\n@@ -1013,8 +1045,25 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n-  obj = JNIHandles::make_local(THREAD, i);\n-  va_list args;\n-  va_start(args, methodID);\n-  JavaValue jvalue(T_VOID);\n-  JNI_ArgumentPusherVaArg ap(methodID, args);\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n-  va_end(args);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == NULL) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);\n+  }\n+\n+  if (!k->is_inline_klass()) {\n+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n+    obj = JNIHandles::make_local(THREAD, i);\n+    va_list args;\n+    va_start(args, methodID);\n+    JavaValue jvalue(T_VOID);\n+    JNI_ArgumentPusherVaArg ap(methodID, args);\n+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+    va_end(args);\n+  } else {\n+    va_list args;\n+    va_start(args, methodID);\n+    JavaValue jvalue(T_INLINE_TYPE);\n+    JNI_ArgumentPusherVaArg ap(methodID, args);\n+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);\n+    va_end(args);\n+    obj = jvalue.get_jobject();\n+  }\n@@ -1771,1 +1820,1 @@\n-  ret = jfieldIDWorkaround::to_instance_jfieldID(k, fd.offset());\n+  ret = jfieldIDWorkaround::to_instance_jfieldID(k, fd.offset(), fd.is_inlined());\n@@ -1781,0 +1830,1 @@\n+  oop res = NULL;\n@@ -1786,2 +1836,12 @@\n-  oop loaded_obj = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(o, offset);\n-  jobject ret = JNIHandles::make_local(THREAD, loaded_obj);\n+  if (!jfieldIDWorkaround::is_inlined_jfieldID(fieldID)) {\n+    res = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(o, offset);\n+  } else {\n+    assert(k->is_instance_klass(), \"Only instance can have inlined fields\");\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    fieldDescriptor fd;\n+    ik->find_field_from_offset(offset, false, &fd);  \/\/ performance bottleneck\n+    InstanceKlass* holder = fd.field_holder();\n+    InlineKlass* field_vklass = InlineKlass::cast(holder->get_inline_type_field_klass(fd.index()));\n+    res = field_vklass->read_inlined_field(o, ik->field_offset(fd.index()), CHECK_NULL);\n+  }\n+  jobject ret = JNIHandles::make_local(THREAD, res);\n@@ -1879,1 +1939,12 @@\n-  HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(o, offset, JNIHandles::resolve(value));\n+  if (!jfieldIDWorkaround::is_inlined_jfieldID(fieldID)) {\n+    HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(o, offset, JNIHandles::resolve(value));\n+  } else {\n+    assert(k->is_instance_klass(), \"Only instances can have inlined fields\");\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    fieldDescriptor fd;\n+    ik->find_field_from_offset(offset, false, &fd);\n+    InstanceKlass* holder = fd.field_holder();\n+    InlineKlass* vklass = InlineKlass::cast(holder->get_inline_type_field_klass(fd.index()));\n+    oop v = JNIHandles::resolve_non_null(value);\n+    vklass->write_inlined_field(o, offset, v, CHECK);\n+  }\n@@ -2296,4 +2367,13 @@\n-  objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n-  if (a->is_within_bounds(index)) {\n-    ret = JNIHandles::make_local(THREAD, a->obj_at(index));\n-    return ret;\n+  oop res = NULL;\n+  arrayOop arr((arrayOop)JNIHandles::resolve_non_null(array));\n+  if (arr->is_within_bounds(index)) {\n+    if (arr->is_flatArray()) {\n+      flatArrayOop a = flatArrayOop(JNIHandles::resolve_non_null(array));\n+      flatArrayHandle vah(thread, a);\n+      res = flatArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK_NULL);\n+      assert(res != NULL, \"Must be set in one of two paths above\");\n+    } else {\n+      assert(arr->is_objArray(), \"If not a valueArray. must be an objArray\");\n+      objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n+      res = a->obj_at(index);\n+    }\n@@ -2303,1 +2383,1 @@\n-    ss.print(\"Index %d out of bounds for length %d\", index, a->length());\n+    ss.print(\"Index %d out of bounds for length %d\", index,arr->length());\n@@ -2306,0 +2386,2 @@\n+  ret = JNIHandles::make_local(THREAD, res);\n+  return ret;\n@@ -2315,24 +2397,51 @@\n-  objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n-  oop v = JNIHandles::resolve(value);\n-  if (a->is_within_bounds(index)) {\n-    if (v == NULL || v->is_a(ObjArrayKlass::cast(a->klass())->element_klass())) {\n-      a->obj_at_put(index, v);\n-    } else {\n-      ResourceMark rm(THREAD);\n-      stringStream ss;\n-      Klass *bottom_kl = ObjArrayKlass::cast(a->klass())->bottom_klass();\n-      ss.print(\"type mismatch: can not store %s to %s[%d]\",\n-               v->klass()->external_name(),\n-               bottom_kl->is_typeArray_klass() ? type2name_tab[ArrayKlass::cast(bottom_kl)->element_type()] : bottom_kl->external_name(),\n-               index);\n-      for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n-        ss.print(\"[]\");\n-      }\n-      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n-    }\n-  } else {\n-    ResourceMark rm(THREAD);\n-    stringStream ss;\n-    ss.print(\"Index %d out of bounds for length %d\", index, a->length());\n-    THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());\n-  }\n+   bool oob = false;\n+   int length = -1;\n+   oop res = NULL;\n+   arrayOop arr((arrayOop)JNIHandles::resolve_non_null(array));\n+   if (arr->is_within_bounds(index)) {\n+     if (arr->is_flatArray()) {\n+       flatArrayOop a = flatArrayOop(JNIHandles::resolve_non_null(array));\n+       oop v = JNIHandles::resolve(value);\n+       FlatArrayKlass* vaklass = FlatArrayKlass::cast(a->klass());\n+       InlineKlass* element_vklass = vaklass->element_klass();\n+       if (v != NULL && v->is_a(element_vklass)) {\n+         a->value_copy_to_index(v, index);\n+       } else {\n+         ResourceMark rm(THREAD);\n+         stringStream ss;\n+         Klass *kl = FlatArrayKlass::cast(a->klass());\n+         ss.print(\"type mismatch: can not store %s to %s[%d]\",\n+             v->klass()->external_name(),\n+             kl->external_name(),\n+             index);\n+         for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n+           ss.print(\"[]\");\n+         }\n+         THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n+       }\n+     } else {\n+       assert(arr->is_objArray(), \"If not a valueArray. must be an objArray\");\n+       objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n+       oop v = JNIHandles::resolve(value);\n+       if (v == NULL || v->is_a(ObjArrayKlass::cast(a->klass())->element_klass())) {\n+         a->obj_at_put(index, v);\n+       } else {\n+         ResourceMark rm(THREAD);\n+         stringStream ss;\n+         Klass *bottom_kl = ObjArrayKlass::cast(a->klass())->bottom_klass();\n+         ss.print(\"type mismatch: can not store %s to %s[%d]\",\n+             v->klass()->external_name(),\n+             bottom_kl->is_typeArray_klass() ? type2name_tab[ArrayKlass::cast(bottom_kl)->element_type()] : bottom_kl->external_name(),\n+                 index);\n+         for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n+           ss.print(\"[]\");\n+         }\n+         THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n+       }\n+     }\n+   } else {\n+     ResourceMark rm(THREAD);\n+     stringStream ss;\n+     ss.print(\"Index %d out of bounds for length %d\", index, arr->length());\n+     THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());\n+   }\n@@ -3112,0 +3221,261 @@\n+JNI_ENTRY(void*, jni_GetFlattenedArrayElements(JNIEnv* env, jarray array, jboolean* isCopy))\n+  if (isCopy != NULL) {\n+    *isCopy = JNI_FALSE;\n+  }\n+  arrayOop ar = arrayOop(JNIHandles::resolve_non_null(array));\n+  if (!ar->is_array()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not an array\");\n+  }\n+  if (!ar->is_flatArray()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not a flattened array\");\n+  }\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass());\n+  if (vak->contains_oops()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Flattened array contains oops\");\n+  }\n+  oop a = lock_gc_or_pin_object(thread, array);\n+  flatArrayOop vap = flatArrayOop(a);\n+  void* ret = vap->value_at_addr(0, vak->layout_helper());\n+  return ret;\n+JNI_END\n+\n+JNI_ENTRY(void, jni_ReleaseFlattenedArrayElements(JNIEnv* env, jarray array, void* elem, jint mode))\n+  unlock_gc_or_unpin_object(thread, array);\n+JNI_END\n+\n+JNI_ENTRY(jsize, jni_GetFlattenedArrayElementSize(JNIEnv* env, jarray array)) {\n+  arrayOop a = arrayOop(JNIHandles::resolve_non_null(array));\n+  if (!a->is_array()) {\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Not an array\");\n+  }\n+  if (!a->is_flatArray()) {\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Not a flattened array\");\n+  }\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(a->klass());\n+  jsize ret = vak->element_byte_size();\n+  return ret;\n+}\n+JNI_END\n+\n+JNI_ENTRY(jclass, jni_GetFlattenedArrayElementClass(JNIEnv* env, jarray array))\n+  arrayOop a = arrayOop(JNIHandles::resolve_non_null(array));\n+  if (!a->is_array()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not an array\");\n+  }\n+  if (!a->is_flatArray()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not a flattened array\");\n+  }\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(a->klass());\n+  InlineKlass* vk = vak->element_klass();\n+  return (jclass) JNIHandles::make_local(vk->java_mirror());\n+JNI_END\n+\n+JNI_ENTRY(jsize, jni_GetFieldOffsetInFlattenedLayout(JNIEnv* env, jclass clazz, const char *name, const char *signature, jboolean* is_inlined))\n+  oop mirror = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(mirror);\n+  if (!k->is_inline_klass()) {\n+    ResourceMark rm;\n+        THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), err_msg(\"%s has not flattened layout\", k->external_name()));\n+  }\n+  InlineKlass* vk = InlineKlass::cast(k);\n+\n+  TempNewSymbol fieldname = SymbolTable::probe(name, (int)strlen(name));\n+  TempNewSymbol signame = SymbolTable::probe(signature, (int)strlen(signature));\n+  if (fieldname == NULL || signame == NULL) {\n+    ResourceMark rm;\n+    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg(\"%s.%s %s\", vk->external_name(), name, signature));\n+  }\n+\n+  assert(vk->is_initialized(), \"If a flattened array has been created, the element klass must have been initialized\");\n+\n+  fieldDescriptor fd;\n+  if (!vk->is_instance_klass() ||\n+      !InstanceKlass::cast(vk)->find_field(fieldname, signame, false, &fd)) {\n+    ResourceMark rm;\n+    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg(\"%s.%s %s\", vk->external_name(), name, signature));\n+  }\n+\n+  int offset = fd.offset() - vk->first_field_offset();\n+  if (is_inlined != NULL) {\n+    *is_inlined = fd.is_inlined();\n+  }\n+  return (jsize)offset;\n+JNI_END\n+\n+JNI_ENTRY(jobject, jni_CreateSubElementSelector(JNIEnv* env, jarray array))\n+  oop ar = JNIHandles::resolve_non_null(array);\n+  if (!ar->is_array()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not an array\");\n+  }\n+  if (!ar->is_flatArray()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not a flattened array\");\n+  }\n+  flatArrayHandle ar_h(THREAD, flatArrayOop(ar));\n+  Klass* ses_k = SystemDictionary::resolve_or_null(vmSymbols::jdk_internal_vm_jni_SubElementSelector(),\n+        Handle(THREAD, SystemDictionary::java_system_loader()), Handle(), CHECK_NULL);\n+  InstanceKlass* ses_ik = InstanceKlass::cast(ses_k);\n+  ses_ik->initialize(CHECK_NULL);\n+  Klass* elementKlass = ArrayKlass::cast(ar_h()->klass())->element_klass();\n+  oop ses = ses_ik->allocate_instance(CHECK_NULL);\n+  Handle ses_h(THREAD, ses);\n+  jdk_internal_vm_jni_SubElementSelector::setArrayElementType(ses_h(), elementKlass->java_mirror());\n+  jdk_internal_vm_jni_SubElementSelector::setSubElementType(ses_h(), elementKlass->java_mirror());\n+  jdk_internal_vm_jni_SubElementSelector::setOffset(ses_h(), 0);\n+  jdk_internal_vm_jni_SubElementSelector::setIsInlined(ses_h(), true);   \/\/ by definition, top element of a flattened array is inlined\n+  jdk_internal_vm_jni_SubElementSelector::setIsInlineType(ses_h(), true); \/\/ by definition, top element of a flattened array is an inline type\n+  return JNIHandles::make_local(ses_h());\n+JNI_END\n+\n+JNI_ENTRY(jobject, jni_GetSubElementSelector(JNIEnv* env, jobject selector, jfieldID fieldID))\n+  oop slct = JNIHandles::resolve_non_null(selector);\n+  if (slct->klass()->name() != vmSymbols::jdk_internal_vm_jni_SubElementSelector()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not a SubElementSelector\");\n+  }\n+  jboolean is_inlined = jdk_internal_vm_jni_SubElementSelector::getIsInlined(slct);\n+  if (!is_inlined) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"SubElement is not inlined\");\n+  }\n+  oop semirror = jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct);\n+  Klass* k = java_lang_Class::as_Klass(semirror);\n+  if (!k->is_inline_klass()) {\n+    ResourceMark rm;\n+        THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), err_msg(\"%s is not an inline type\", k->external_name()));\n+  }\n+  InlineKlass* vk = InlineKlass::cast(k);\n+  assert(vk->is_initialized(), \"If a flattened array has been created, the element klass must have been initialized\");\n+  int field_offset = jfieldIDWorkaround::from_instance_jfieldID(vk, fieldID);\n+  fieldDescriptor fd;\n+  if (!vk->find_field_from_offset(field_offset, false, &fd)) {\n+    THROW_NULL(vmSymbols::java_lang_NoSuchFieldError());\n+  }\n+  Handle arrayElementMirror(THREAD, jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct));\n+  \/\/ offset of the SubElement is offset of the original SubElement plus the offset of the field inside the element\n+  int offset = fd.offset() - vk->first_field_offset() + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);\n+  InstanceKlass* sesklass = InstanceKlass::cast(JNIHandles::resolve_non_null(selector)->klass());\n+  oop res = sesklass->allocate_instance(CHECK_NULL);\n+  Handle res_h(THREAD, res);\n+  jdk_internal_vm_jni_SubElementSelector::setArrayElementType(res_h(), arrayElementMirror());\n+  InstanceKlass* holder = fd.field_holder();\n+  BasicType bt = Signature::basic_type(fd.signature());\n+  if (is_java_primitive(bt)) {\n+    jdk_internal_vm_jni_SubElementSelector::setSubElementType(res_h(), java_lang_Class::primitive_mirror(bt));\n+  } else {\n+    Klass* fieldKlass = SystemDictionary::resolve_or_fail(fd.signature(), Handle(THREAD, holder->class_loader()),\n+        Handle(THREAD, holder->protection_domain()), true, CHECK_NULL);\n+    jdk_internal_vm_jni_SubElementSelector::setSubElementType(res_h(),fieldKlass->java_mirror());\n+  }\n+  jdk_internal_vm_jni_SubElementSelector::setOffset(res_h(), offset);\n+  jdk_internal_vm_jni_SubElementSelector::setIsInlined(res_h(), fd.is_inlined());\n+  jdk_internal_vm_jni_SubElementSelector::setIsInlineType(res_h(), fd.is_inline_type());\n+  return JNIHandles::make_local(res_h());\n+JNI_END\n+\n+JNI_ENTRY(jobject, jni_GetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+  flatArrayOop ar =  (flatArrayOop)JNIHandles::resolve_non_null(array);\n+  oop slct = JNIHandles::resolve_non_null(selector);\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass());\n+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Array\/Selector mismatch\");\n+  }\n+  oop res = NULL;\n+  if (!jdk_internal_vm_jni_SubElementSelector::getIsInlined(slct)) {\n+    int offset = (address)ar->base() - cast_from_oop<address>(ar) + index * vak->element_byte_size()\n+                      + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);\n+    res = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(ar, offset);\n+  } else {\n+    Handle slct_h(THREAD, slct);\n+    InlineKlass* fieldKlass = InlineKlass::cast(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)));\n+    res = fieldKlass->allocate_instance_buffer(CHECK_NULL);\n+    \/\/ The array might have been moved by the GC, refreshing the arrayOop\n+    ar =  (flatArrayOop)JNIHandles::resolve_non_null(array);\n+    address addr = (address)ar->value_at_addr(index, vak->layout_helper())\n+              + jdk_internal_vm_jni_SubElementSelector::getOffset(slct_h());\n+    fieldKlass->inline_copy_payload_to_new_oop(addr, res);\n+  }\n+  return JNIHandles::make_local(res);\n+JNI_END\n+\n+JNI_ENTRY(void, jni_SetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index, jobject value))\n+  flatArrayOop ar =  (flatArrayOop)JNIHandles::resolve_non_null(array);\n+  oop slct = JNIHandles::resolve_non_null(selector);\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass());\n+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Array\/Selector mismatch\");\n+  }\n+  oop val = JNIHandles::resolve(value);\n+  if (val == NULL) {\n+    if (jdk_internal_vm_jni_SubElementSelector::getIsInlineType(slct)) {\n+      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), \"null cannot be stored in a flattened array\");\n+    }\n+  } else {\n+    if (!val->is_a(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)))) {\n+      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), \"type mismatch\");\n+    }\n+  }\n+  if (!jdk_internal_vm_jni_SubElementSelector::getIsInlined(slct)) {\n+    int offset = (address)ar->base() - cast_from_oop<address>(ar) + index * vak->element_byte_size()\n+                  + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);\n+    HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(ar, offset, JNIHandles::resolve(value));\n+  } else {\n+    InlineKlass* fieldKlass = InlineKlass::cast(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)));\n+    address addr = (address)ar->value_at_addr(index, vak->layout_helper())\n+                  + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);\n+    fieldKlass->inline_copy_oop_to_payload(JNIHandles::resolve_non_null(value), addr);\n+  }\n+JNI_END\n+\n+#define DEFINE_GETSUBELEMENT(ElementType,Result,ElementBasicType) \\\n+\\\n+JNI_ENTRY(ElementType, \\\n+          jni_Get##Result##SubElement(JNIEnv *env, jarray array, jobject selector, int index)) \\\n+  flatArrayOop ar = (flatArrayOop)JNIHandles::resolve_non_null(array); \\\n+  oop slct = JNIHandles::resolve_non_null(selector); \\\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass()); \\\n+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) { \\\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Array\/Selector mismatch\"); \\\n+  } \\\n+  if (jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct) != java_lang_Class::primitive_mirror(ElementBasicType)) { \\\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong SubElement type\"); \\\n+  } \\\n+  address addr = (address)ar->value_at_addr(index, vak->layout_helper()) \\\n+               + jdk_internal_vm_jni_SubElementSelector::getOffset(slct); \\\n+  ElementType result = *(ElementType*)addr; \\\n+  return result; \\\n+JNI_END\n+\n+DEFINE_GETSUBELEMENT(jboolean, Boolean,T_BOOLEAN)\n+DEFINE_GETSUBELEMENT(jbyte, Byte, T_BYTE)\n+DEFINE_GETSUBELEMENT(jshort, Short,T_SHORT)\n+DEFINE_GETSUBELEMENT(jchar, Char,T_CHAR)\n+DEFINE_GETSUBELEMENT(jint, Int,T_INT)\n+DEFINE_GETSUBELEMENT(jlong, Long,T_LONG)\n+DEFINE_GETSUBELEMENT(jfloat, Float,T_FLOAT)\n+DEFINE_GETSUBELEMENT(jdouble, Double,T_DOUBLE)\n+\n+#define DEFINE_SETSUBELEMENT(ElementType,Result,ElementBasicType) \\\n+\\\n+JNI_ENTRY(void, \\\n+          jni_Set##Result##SubElement(JNIEnv *env, jarray array, jobject selector, int index, ElementType value)) \\\n+  flatArrayOop ar = (flatArrayOop)JNIHandles::resolve_non_null(array); \\\n+  oop slct = JNIHandles::resolve_non_null(selector); \\\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass()); \\\n+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) { \\\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Array\/Selector mismatch\"); \\\n+  } \\\n+  if (jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct) != java_lang_Class::primitive_mirror(ElementBasicType)) { \\\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong SubElement type\"); \\\n+  } \\\n+  address addr = (address)ar->value_at_addr(index, vak->layout_helper()) \\\n+               + jdk_internal_vm_jni_SubElementSelector::getOffset(slct); \\\n+  *(ElementType*)addr = value; \\\n+JNI_END\n+\n+DEFINE_SETSUBELEMENT(jboolean, Boolean,T_BOOLEAN)\n+DEFINE_SETSUBELEMENT(jbyte, Byte, T_BYTE)\n+DEFINE_SETSUBELEMENT(jshort, Short,T_SHORT)\n+DEFINE_SETSUBELEMENT(jchar, Char,T_CHAR)\n+DEFINE_SETSUBELEMENT(jint, Int,T_INT)\n+DEFINE_SETSUBELEMENT(jlong, Long,T_LONG)\n+DEFINE_SETSUBELEMENT(jfloat, Float,T_FLOAT)\n+DEFINE_SETSUBELEMENT(jdouble, Double,T_DOUBLE)\n+\n@@ -3395,1 +3765,32 @@\n-    jni_GetModule\n+    jni_GetModule,\n+\n+    \/\/ Flattened arrays features\n+\n+    jni_GetFlattenedArrayElements,\n+    jni_ReleaseFlattenedArrayElements,\n+    jni_GetFlattenedArrayElementClass,\n+    jni_GetFlattenedArrayElementSize,\n+    jni_GetFieldOffsetInFlattenedLayout,\n+\n+    jni_CreateSubElementSelector,\n+    jni_GetSubElementSelector,\n+    jni_GetObjectSubElement,\n+    jni_SetObjectSubElement,\n+\n+    jni_GetBooleanSubElement,\n+    jni_GetByteSubElement,\n+    jni_GetShortSubElement,\n+    jni_GetCharSubElement,\n+    jni_GetIntSubElement,\n+    jni_GetLongSubElement,\n+    jni_GetFloatSubElement,\n+    jni_GetDoubleSubElement,\n+\n+    jni_SetBooleanSubElement,\n+    jni_SetByteSubElement,\n+    jni_SetShortSubElement,\n+    jni_SetCharSubElement,\n+    jni_SetIntSubElement,\n+    jni_SetLongSubElement,\n+    jni_SetFloatSubElement,\n+    jni_SetDoubleSubElement\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":459,"deletions":58,"binary":false,"changes":517,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -595,1 +596,22 @@\n-  return handle == NULL ? 0 : ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)) ;\n+  if (handle == NULL) {\n+    return 0;\n+  }\n+  oop obj = JNIHandles::resolve_non_null(handle);\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+      JavaValue result(T_INT);\n+      JavaCallArguments args;\n+      Handle ho(THREAD, obj);\n+      args.push_oop(ho);\n+      methodHandle method(THREAD, Universe::inline_type_hash_code_method());\n+      JavaCalls::call(&result, method, &args, THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in hashCode\", e, false);\n+        }\n+      }\n+      return result.get_jint();\n+  } else {\n+    return ObjectSynchronizer::FastHashCode(THREAD, obj);\n+  }\n@@ -647,0 +669,1 @@\n+       klass->is_inline_klass() ||\n@@ -1145,1 +1168,2 @@\n-    size = InstanceKlass::cast(klass)->local_interfaces()->length();\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    size = ik->local_interfaces()->length();\n@@ -1148,1 +1172,1 @@\n-    size = 2;\n+    size = 3;\n@@ -1158,1 +1182,2 @@\n-      Klass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);\n+      InstanceKlass* ik = InstanceKlass::cast(klass);\n+      Klass* k = ik->local_interfaces()->at(index);\n@@ -1162,1 +1187,1 @@\n-    \/\/ All arrays implement java.lang.Cloneable and java.io.Serializable\n+    \/\/ All arrays implement java.lang.Cloneable, java.io.Serializable and java.lang.IdentityObject\n@@ -1165,0 +1190,1 @@\n+    result->obj_at_put(2, vmClasses::IdentityObject_klass()->java_mirror());\n@@ -1760,0 +1786,2 @@\n+  bool is_ctor = (method->is_object_constructor() ||\n+                  method->is_static_init_factory());\n@@ -1761,1 +1789,1 @@\n-    return (method->is_initializer() && !method->is_static());\n+    return is_ctor;\n@@ -1763,1 +1791,3 @@\n-    return  (!method->is_initializer() && !method->is_overpass());\n+    return (!is_ctor &&\n+            !method->is_class_initializer() &&\n+            !method->is_overpass());\n@@ -1826,0 +1856,2 @@\n+        assert(method->is_object_constructor() ||\n+               method->is_static_init_factory(), \"must be\");\n@@ -2108,3 +2140,1 @@\n-  if (!m->is_initializer() || m->is_static()) {\n-    method = Reflection::new_method(m, true, CHECK_NULL);\n-  } else {\n+  if (m->is_object_constructor() || m->is_static_init_factory()) {\n@@ -2112,0 +2142,2 @@\n+  } else {\n+    method = Reflection::new_method(m, true, CHECK_NULL);\n@@ -2382,0 +2414,37 @@\n+\/\/ Arrays support \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(jboolean, JVM_ArrayIsAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == NULL) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  return ArrayKlass::cast(k)->element_access_is_atomic();\n+JVM_END\n+\n+JVM_ENTRY(jobject, JVM_ArrayEnsureAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == NULL) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  if (k->is_flatArray_klass()) {\n+    FlatArrayKlass* vk = FlatArrayKlass::cast(k);\n+    if (!vk->element_access_is_atomic()) {\n+      \/**\n+       * Need to decide how to implement:\n+       *\n+       * 1) Change to objArrayOop layout, therefore oop->klass() differs so\n+       * then \"<atomic>[Qfoo;\" klass needs to subclass \"[Qfoo;\" to pass through\n+       * \"checkcast\" & \"instanceof\"\n+       *\n+       * 2) Use extra header in the flatArrayOop to flag atomicity required and\n+       * possibly per instance lock structure. Said info, could be placed in\n+       * \"trailer\" rather than disturb the current arrayOop\n+       *\/\n+      Unimplemented();\n+    }\n+  }\n+  return array;\n+JVM_END\n+\n@@ -2544,1 +2613,1 @@\n-  return method->name() == vmSymbols::object_initializer_name();\n+  return method->is_object_constructor();\n@@ -3518,1 +3587,1 @@\n-    objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n+    objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3538,0 +3607,1 @@\n+  objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3539,1 +3609,0 @@\n-  objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":82,"deletions":13,"binary":false,"changes":95,"status":"modified"},{"patch":"@@ -506,1 +506,2 @@\n-  if (ty_sign[0] == JVM_SIGNATURE_CLASS &&\n+  if ((ty_sign[0] == JVM_SIGNATURE_CLASS ||\n+       ty_sign[0] == JVM_SIGNATURE_INLINE_TYPE) &&\n@@ -574,0 +575,1 @@\n+  case T_INLINE_TYPE:\n@@ -699,1 +701,1 @@\n-      if (_type == T_OBJECT) {\n+      if (_type == T_OBJECT || _type == T_INLINE_TYPE) {\n@@ -717,1 +719,2 @@\n-      case T_OBJECT: {\n+      case T_OBJECT:\n+      case T_INLINE_TYPE: {\n@@ -738,1 +741,2 @@\n-        case T_OBJECT: {\n+        case T_OBJECT:\n+        case T_INLINE_TYPE: {\n","filename":"src\/hotspot\/share\/prims\/jvmtiImpl.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -46,0 +46,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.hpp\"\n@@ -51,0 +53,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -201,2 +204,13 @@\n-  bool save_oop_result = chunk->at(0)->scope()->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n-  Handle return_value;\n+  ScopeDesc* scope = chunk->at(0)->scope();\n+  bool save_oop_result = scope->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n+  \/\/ In case of the return of multiple values, we must take care\n+  \/\/ of all oop return values.\n+  GrowableArray<Handle> return_oops;\n+  InlineKlass* vk = NULL;\n+  if (save_oop_result && scope->return_vt()) {\n+    vk = InlineKlass::returned_inline_klass(map);\n+    if (vk != NULL) {\n+      vk->save_oop_fields(map, return_oops);\n+      save_oop_result = false;\n+    }\n+  }\n@@ -208,1 +222,1 @@\n-    return_value = Handle(thread, result);\n+    return_oops.push(Handle(thread, result));\n@@ -215,1 +229,1 @@\n-  if (objects != NULL) {\n+  if (objects != NULL || vk != NULL) {\n@@ -220,1 +234,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+      if (vk != NULL) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, CHECK_AND_CLEAR_(true));\n+      }\n+      if (objects != NULL) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+        bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, CHECK_AND_CLEAR_(true));\n+      }\n@@ -224,1 +245,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+      if (vk != NULL) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, THREAD);\n+      }\n+      if (objects != NULL) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+        bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, THREAD);\n+      }\n@@ -227,2 +255,0 @@\n-    bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n-    Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal);\n@@ -237,1 +263,1 @@\n-  if (save_oop_result) {\n+  if (save_oop_result || vk != NULL) {\n@@ -239,1 +265,2 @@\n-    deoptee.set_saved_oop_result(&map, return_value());\n+    assert(return_oops.length() == 1, \"no inline type\");\n+    deoptee.set_saved_oop_result(&map, return_oops.pop()());\n@@ -570,1 +597,1 @@\n-  \/\/ If the sender is deoptimized the we must retrieve the address of the handler\n+  \/\/ If the sender is deoptimized we must retrieve the address of the handler\n@@ -1072,0 +1099,4 @@\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* ak = FlatArrayKlass::cast(k);\n+      \/\/ Inline type array must be zeroed because not all memory is reassigned\n+      obj = ak->allocate(sv->field_size(), THREAD);\n@@ -1101,0 +1132,15 @@\n+\/\/ We're deoptimizing at the return of a call, inline type fields are\n+\/\/ in registers. When we go back to the interpreter, it will expect a\n+\/\/ reference to an inline type instance. Allocate and initialize it from\n+\/\/ the register values here.\n+bool Deoptimization::realloc_inline_type_result(InlineKlass* vk, const RegisterMap& map, GrowableArray<Handle>& return_oops, TRAPS) {\n+  oop new_vt = vk->realloc_result(map, return_oops, THREAD);\n+  if (new_vt == NULL) {\n+    CLEAR_PENDING_EXCEPTION;\n+    THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), true);\n+  }\n+  return_oops.clear();\n+  return_oops.push(Handle(THREAD, new_vt));\n+  return false;\n+}\n+\n@@ -1273,0 +1319,1 @@\n+  InstanceKlass* _klass;\n@@ -1277,0 +1324,1 @@\n+    _klass = NULL;\n@@ -1286,1 +1334,1 @@\n-static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal) {\n+static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {\n@@ -1295,0 +1343,8 @@\n+        if (field._type == T_INLINE_TYPE) {\n+          if (fs.is_inlined()) {\n+            \/\/ Resolve klass of flattened inline type field\n+            field._klass = InlineKlass::cast(klass->get_inline_type_field_klass(fs.index()));\n+          } else {\n+            field._type = T_OBJECT;\n+          }\n+        }\n@@ -1302,0 +1358,11 @@\n+    BasicType type = fields->at(i)._type;\n+    int offset = base_offset + fields->at(i)._offset;\n+    \/\/ Check for flattened inline type field before accessing the ScopeValue because it might not have any fields\n+    if (type == T_INLINE_TYPE) {\n+      \/\/ Recursively re-assign flattened inline type fields\n+      InstanceKlass* vk = fields->at(i)._klass;\n+      assert(vk != NULL, \"must be resolved\");\n+      offset -= InlineKlass::cast(vk)->first_field_offset(); \/\/ Adjust offset to omit oop header\n+      svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);\n+      continue; \/\/ Continue because we don't need to increment svIndex\n+    }\n@@ -1305,3 +1372,2 @@\n-    int offset = fields->at(i)._offset;\n-    BasicType type = fields->at(i)._type;\n-      case T_OBJECT: case T_ARRAY:\n+      case T_OBJECT:\n+      case T_ARRAY:\n@@ -1388,0 +1454,14 @@\n+\/\/ restore fields of an eliminated inline type array\n+void Deoptimization::reassign_flat_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, flatArrayOop obj, FlatArrayKlass* vak, bool skip_internal, TRAPS) {\n+  InlineKlass* vk = vak->element_klass();\n+  assert(vk->flatten_array(), \"should only be used for flattened inline type arrays\");\n+  \/\/ Adjust offset to omit oop header\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE) - InlineKlass::cast(vk)->first_field_offset();\n+  \/\/ Initialize all elements of the flattened inline type array\n+  for (int i = 0; i < sv->field_size(); i++) {\n+    ScopeValue* val = sv->field_at(i);\n+    int offset = base_offset + (i << Klass::layout_helper_log2_element_size(vak->layout_helper()));\n+    reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, skip_internal, offset, CHECK);\n+  }\n+}\n+\n@@ -1389,1 +1469,1 @@\n-void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal) {\n+void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal, TRAPS) {\n@@ -1414,1 +1494,4 @@\n-      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal);\n+      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, CHECK);\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* vak = FlatArrayKlass::cast(k);\n+      reassign_flat_array_elements(fr, reg_map, sv, (flatArrayOop) obj(), vak, skip_internal, CHECK);\n@@ -1480,1 +1563,0 @@\n-\n@@ -1484,1 +1566,3 @@\n-    Handle obj = sv->value();\n+    print_object(k, sv->value(), realloc_failures);\n+  }\n+}\n@@ -1486,9 +1570,10 @@\n-    tty->print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(sv->value()()));\n-    k->print_value();\n-    assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n-    if (obj.is_null()) {\n-      tty->print(\" allocation failed\");\n-    } else {\n-      tty->print(\" allocated (%d bytes)\", obj->size() * HeapWordSize);\n-    }\n-    tty->cr();\n+void Deoptimization::print_object(Klass* k, Handle obj, bool realloc_failures) {\n+  tty->print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(obj()));\n+  k->print_value();\n+  assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n+  if (obj.is_null()) {\n+    tty->print(\" allocation failed\");\n+  } else {\n+    tty->print(\" allocated (%d bytes)\", obj->size() * HeapWordSize);\n+  }\n+  tty->cr();\n@@ -1496,3 +1581,2 @@\n-    if (Verbose && !obj.is_null()) {\n-      k->oop_print_on(obj(), tty);\n-    }\n+  if (Verbose && !obj.is_null()) {\n+    k->oop_print_on(obj(), tty);\n@@ -1710,1 +1794,1 @@\n-  \/\/ Deoptimize only if the frame comes from compile code.\n+  \/\/ Deoptimize only if the frame comes from compiled code.\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":116,"deletions":32,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -925,0 +926,1 @@\n+    ResourceMark rm;\n@@ -926,2 +928,25 @@\n-    bool return_oop = nm->method()->is_returning_oop();\n-    Handle return_value;\n+    Method* method = nm->method();\n+    bool return_oop = method->is_returning_oop();\n+\n+    GrowableArray<Handle> return_values;\n+    InlineKlass* vk = NULL;\n+\n+    if (return_oop && InlineTypeReturnedAsFields) {\n+      SignatureStream ss(method->signature());\n+      while (!ss.at_return_type()) {\n+        ss.next();\n+      }\n+      if (ss.type() == T_INLINE_TYPE) {\n+        \/\/ Check if inline type is returned as fields\n+        vk = InlineKlass::returned_inline_klass(map);\n+        if (vk != NULL) {\n+          \/\/ We're at a safepoint at the return of a method that returns\n+          \/\/ multiple values. We must make sure we preserve the oop values\n+          \/\/ across the safepoint.\n+          assert(vk == method->returned_inline_type(thread()), \"bad inline klass\");\n+          vk->save_oop_fields(map, return_values);\n+          return_oop = false;\n+        }\n+      }\n+    }\n+\n@@ -934,1 +959,1 @@\n-      return_value = Handle(self, result);\n+      return_values.push(Handle(self, result));\n@@ -948,1 +973,4 @@\n-      caller_fr.set_saved_oop_result(&map, return_value());\n+      assert(return_values.length() == 1, \"only one return value\");\n+      caller_fr.set_saved_oop_result(&map, return_values.pop()());\n+    } else if (vk != NULL) {\n+      vk->restore_oop_results(map, return_values);\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":32,"deletions":4,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+#include \"memory\/oopFactory.hpp\"\n@@ -50,0 +51,2 @@\n+#include \"oops\/access.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -54,0 +57,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -55,0 +59,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -92,1 +97,0 @@\n-address             SharedRuntime::_resolve_static_call_entry;\n@@ -112,1 +116,0 @@\n-  _resolve_static_call_entry           = _resolve_static_call_blob->entry_point();\n@@ -1090,0 +1093,15 @@\n+  \/\/ Substitutability test implementation piggy backs on static call resolution\n+  Bytecodes::Code code = caller->java_code_at(bci);\n+  if (code == Bytecodes::_if_acmpeq || code == Bytecodes::_if_acmpne) {\n+    bc = Bytecodes::_invokestatic;\n+    methodHandle attached_method(THREAD, extract_attached_method(vfst));\n+    assert(attached_method.not_null(), \"must have attached method\");\n+    vmClasses::ValueBootstrapMethods_klass()->initialize(CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, false, CHECK_NH);\n+#ifdef ASSERT\n+    Method* is_subst = vmClasses::ValueBootstrapMethods_klass()->find_method(vmSymbols::isSubstitutable_name(), vmSymbols::object_object_boolean_signature());\n+    assert(callinfo.selected_method() == is_subst, \"must be isSubstitutable method\");\n+#endif\n+    return receiver;\n+  }\n+\n@@ -1125,0 +1143,6 @@\n+    } else {\n+      assert(attached_method->has_scalarized_args(), \"invalid use of attached method\");\n+      if (!attached_method->method_holder()->is_inline_klass()) {\n+        \/\/ Ignore the attached method in this case to not confuse below code\n+        attached_method = methodHandle(thread, NULL);\n+      }\n@@ -1133,0 +1157,1 @@\n+  bool check_null_and_abstract = true;\n@@ -1142,0 +1167,1 @@\n+    bool caller_is_c1 = false;\n@@ -1143,2 +1169,7 @@\n-    if (attached_method.is_null()) {\n-      Method* callee = bytecode.static_target(CHECK_NH);\n+    if (callerFrame.is_compiled_frame() && !callerFrame.is_deoptimized_frame()) {\n+      caller_is_c1 = callerFrame.cb()->is_compiled_by_c1();\n+    }\n+\n+    Method* callee = attached_method();\n+    if (callee == NULL) {\n+      callee = bytecode.static_target(CHECK_NH);\n@@ -1149,6 +1180,15 @@\n-\n-    \/\/ Retrieve from a compiled argument list\n-    receiver = Handle(THREAD, callerFrame.retrieve_receiver(&reg_map2));\n-\n-    if (receiver.is_null()) {\n-      THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+    if (!caller_is_c1 && callee->has_scalarized_args() && callee->method_holder()->is_inline_klass() &&\n+        InlineKlass::cast(callee->method_holder())->can_be_passed_as_fields()) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      \/\/ Resolve the call without receiver null checking.\n+      assert(attached_method.not_null() && !attached_method->is_abstract(), \"must have non-abstract attached method\");\n+      if (bc == Bytecodes::_invokeinterface) {\n+        bc = Bytecodes::_invokevirtual; \/\/ C2 optimistically replaces interface calls by virtual calls\n+      }\n+      check_null_and_abstract = false;\n+    } else {\n+      \/\/ Retrieve from a compiled argument list\n+      receiver = Handle(THREAD, callerFrame.retrieve_receiver(&reg_map2));\n+      if (receiver.is_null()) {\n+        THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+      }\n@@ -1161,1 +1201,1 @@\n-    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, check_null_and_abstract, CHECK_NH);\n@@ -1170,1 +1210,1 @@\n-  if (has_receiver) {\n+  if (has_receiver && check_null_and_abstract) {\n@@ -1229,1 +1269,2 @@\n-                                           bool is_optimized, TRAPS) {\n+                                           bool is_optimized,\n+                                           bool* caller_is_c1, TRAPS) {\n@@ -1231,1 +1272,1 @@\n-  callee_method = resolve_sub_helper(thread, is_virtual, is_optimized, THREAD);\n+  callee_method = resolve_sub_helper(thread, is_virtual, is_optimized, caller_is_c1, THREAD);\n@@ -1248,1 +1289,1 @@\n-      callee_method = resolve_sub_helper(thread, is_virtual, is_optimized, THREAD);\n+      callee_method = resolve_sub_helper(thread, is_virtual, is_optimized, caller_is_c1, THREAD);\n@@ -1279,0 +1320,1 @@\n+  bool caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1281,1 +1323,9 @@\n-    assert(receiver.not_null() || invoke_code == Bytecodes::_invokehandle, \"sanity check\");\n+    Klass* receiver_klass = NULL;\n+    if (!caller_is_c1 && callee_method->has_scalarized_args() && callee_method->method_holder()->is_inline_klass() &&\n+        InlineKlass::cast(callee_method->method_holder())->can_be_passed_as_fields()) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      receiver_klass = callee_method->method_holder();\n+    } else {\n+      assert(receiver.not_null() || invoke_code == Bytecodes::_invokehandle, \"sanity check\");\n+      receiver_klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver->klass();\n+    }\n@@ -1283,3 +1333,2 @@\n-    Klass* klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver->klass();\n-    CompiledIC::compute_monomorphic_entry(callee_method, klass,\n-                     is_optimized, static_bound, is_nmethod, virtual_call_info,\n+    CompiledIC::compute_monomorphic_entry(callee_method, receiver_klass,\n+                     is_optimized, static_bound, is_nmethod, caller_is_c1, virtual_call_info,\n@@ -1289,1 +1338,1 @@\n-    CompiledStaticCall::compute_entry(callee_method, is_nmethod, static_call_info);\n+    CompiledStaticCall::compute_entry(callee_method, caller_nm, static_call_info);\n@@ -1341,1 +1390,2 @@\n-                                               bool is_optimized, TRAPS) {\n+                                               bool is_optimized,\n+                                               bool* caller_is_c1, TRAPS) {\n@@ -1350,0 +1400,1 @@\n+  *caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1451,0 +1502,2 @@\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1452,1 +1505,1 @@\n-    callee_method = SharedRuntime::handle_ic_miss_helper(thread, CHECK_NULL);\n+    callee_method = SharedRuntime::handle_ic_miss_helper(thread, is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1457,2 +1510,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  return entry_for_handle_wrong_method(callee_method, false, is_optimized, caller_is_c1);\n@@ -1501,0 +1553,3 @@\n+  bool is_static_call = false;\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1503,1 +1558,1 @@\n-    callee_method = SharedRuntime::reresolve_call_site(thread, CHECK_NULL);\n+    callee_method = SharedRuntime::reresolve_call_site(thread, is_static_call, is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1507,2 +1562,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  return entry_for_handle_wrong_method(callee_method, is_static_call, is_optimized, caller_is_c1);\n@@ -1546,0 +1600,1 @@\n+  bool caller_is_c1;\n@@ -1547,1 +1602,1 @@\n-    callee_method = SharedRuntime::resolve_helper(thread, false, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(thread, false, false, &caller_is_c1, CHECK_NULL);\n@@ -1551,2 +1606,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1559,0 +1616,1 @@\n+  bool caller_is_c1;\n@@ -1560,1 +1618,1 @@\n-    callee_method = SharedRuntime::resolve_helper(thread, true, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(thread, true, false, &caller_is_c1, CHECK_NULL);\n@@ -1564,2 +1622,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_inline_ro_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1573,0 +1633,1 @@\n+  bool caller_is_c1;\n@@ -1574,1 +1635,1 @@\n-    callee_method = SharedRuntime::resolve_helper(thread, true, true, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(thread, true, true, &caller_is_c1, CHECK_NULL);\n@@ -1578,2 +1639,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1590,1 +1653,1 @@\n-                                                   bool& needs_ic_stub_refill, TRAPS) {\n+                                                   bool& needs_ic_stub_refill, bool& is_optimized, bool caller_is_c1, TRAPS) {\n@@ -1601,0 +1664,1 @@\n+    is_optimized = true;\n@@ -1638,0 +1702,1 @@\n+                                            caller_nm->is_compiled_by_c1(),\n@@ -1646,1 +1711,1 @@\n-    bool successful = inline_cache->set_to_megamorphic(&call_info, bc, needs_ic_stub_refill, CHECK_false);\n+    bool successful = inline_cache->set_to_megamorphic(&call_info, bc, needs_ic_stub_refill, caller_is_c1, CHECK_false);\n@@ -1662,1 +1727,1 @@\n-methodHandle SharedRuntime::handle_ic_miss_helper(JavaThread *thread, TRAPS) {\n+methodHandle SharedRuntime::handle_ic_miss_helper(JavaThread *thread, bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1682,1 +1747,3 @@\n-    methodHandle callee_method = SharedRuntime::reresolve_call_site(thread, CHECK_(methodHandle()));\n+    bool is_static_call = false;\n+    methodHandle callee_method = SharedRuntime::reresolve_call_site(thread, is_static_call, is_optimized, caller_is_c1, CHECK_(methodHandle()));\n+    assert(!is_static_call, \"IC miss at static call?\");\n@@ -1732,0 +1799,1 @@\n+  caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1737,1 +1805,1 @@\n-                                                     bc, call_info, needs_ic_stub_refill, CHECK_(methodHandle()));\n+                                                     bc, call_info, needs_ic_stub_refill, is_optimized, caller_is_c1, CHECK_(methodHandle()));\n@@ -1769,1 +1837,1 @@\n-methodHandle SharedRuntime::reresolve_call_site(JavaThread *thread, TRAPS) {\n+methodHandle SharedRuntime::reresolve_call_site(JavaThread *thread, bool& is_static_call, bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1785,1 +1853,1 @@\n-    bool is_static_call = false;\n+    caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1830,0 +1898,1 @@\n+          is_optimized = (iter.type() == relocInfo::opt_virtual_call_type);\n@@ -1855,1 +1924,0 @@\n-\n@@ -1949,2 +2017,0 @@\n-  address entry_point = moop->from_compiled_entry_no_trampoline();\n-\n@@ -1962,1 +2028,5 @@\n-  if (cb == NULL || !cb->is_compiled() || entry_point == moop->get_c2i_entry()) {\n+  if (cb == NULL || !cb->is_compiled()) {\n+    return;\n+  }\n+  address entry_point = moop->from_compiled_entry_no_trampoline(cb->is_compiled_by_c1());\n+  if (entry_point == moop->get_c2i_entry()) {\n@@ -2327,1 +2397,1 @@\n-  static int adapter_encoding(BasicType in) {\n+  static BasicType adapter_encoding(BasicType in) {\n@@ -2333,1 +2403,1 @@\n-        \/\/ There are all promoted to T_INT in the calling convention\n+        \/\/ They are all promoted to T_INT in the calling convention\n@@ -2360,1 +2430,1 @@\n-  AdapterFingerPrint(int total_args_passed, BasicType* sig_bt) {\n+  AdapterFingerPrint(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2363,0 +2433,1 @@\n+    int total_args_passed = (sig != NULL) ? sig->length() : 0;\n@@ -2380,0 +2451,2 @@\n+    BasicType prev_bt = T_ILLEGAL;\n+    int vt_count = 0;\n@@ -2383,5 +2456,26 @@\n-        int bt = ((sig_index < total_args_passed)\n-                  ? adapter_encoding(sig_bt[sig_index++])\n-                  : 0);\n-        assert((bt & _basic_type_mask) == bt, \"must fit in 4 bits\");\n-        value = (value << _basic_type_bits) | bt;\n+        BasicType bt = T_ILLEGAL;\n+        if (sig_index < total_args_passed) {\n+          bt = sig->at(sig_index++)._bt;\n+          if (bt == T_INLINE_TYPE) {\n+            \/\/ Found start of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected start of inline type\");\n+            if (sig_index == 1 && has_ro_adapter) {\n+              \/\/ With a ro_adapter, replace receiver inline type delimiter by T_VOID to prevent matching\n+              \/\/ with other adapters that have the same inline type as first argument and no receiver.\n+              bt = T_VOID;\n+            }\n+            vt_count++;\n+          } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+            \/\/ Found end of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected end of inline type\");\n+            vt_count--;\n+            assert(vt_count >= 0, \"invalid vt_count\");\n+          } else if (vt_count == 0) {\n+            \/\/ Widen fields that are not part of a scalarized inline type argument\n+            bt = adapter_encoding(bt);\n+          }\n+          prev_bt = bt;\n+        }\n+        int bt_val = (bt == T_ILLEGAL) ? 0 : bt;\n+        assert((bt_val & _basic_type_mask) == bt_val, \"must fit in 4 bits\");\n+        value = (value << _basic_type_bits) | bt_val;\n@@ -2391,0 +2485,1 @@\n+    assert(vt_count == 0, \"invalid vt_count\");\n@@ -2476,1 +2571,3 @@\n-  AdapterHandlerEntry* new_entry(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry, address c2i_unverified_entry, address c2i_no_clinit_check_entry) {\n+  AdapterHandlerEntry* new_entry(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry,\n+                                 address c2i_inline_entry, address c2i_inline_ro_entry,\n+                                 address c2i_unverified_entry, address c2i_unverified_inline_entry, address c2i_no_clinit_check_entry) {\n@@ -2478,1 +2575,2 @@\n-    entry->init(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+    entry->init(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry,\n+                c2i_unverified_entry, c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -2494,1 +2592,1 @@\n-  AdapterHandlerEntry* lookup(int total_args_passed, BasicType* sig_bt) {\n+  AdapterHandlerEntry* lookup(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2496,1 +2594,1 @@\n-    AdapterFingerPrint fp(total_args_passed, sig_bt);\n+    AdapterFingerPrint fp(sig, has_ro_adapter);\n@@ -2592,1 +2690,1 @@\n-const int AdapterHandlerLibrary_size = 16*K;\n+const int AdapterHandlerLibrary_size = 32*K;\n@@ -2616,1 +2714,1 @@\n-  _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, NULL),\n+  _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),\n@@ -2618,0 +2716,1 @@\n+                                                              wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n@@ -2624,0 +2723,2 @@\n+                                                      address c2i_inline_entry,\n+                                                      address c2i_inline_ro_entry,\n@@ -2625,0 +2726,1 @@\n+                                                      address c2i_unverified_inline_entry,\n@@ -2626,1 +2728,16 @@\n-  return _adapters->new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+  return _adapters->new_entry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry,\n+                              c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n+}\n+\n+static void generate_trampoline(address trampoline, address destination) {\n+  if (*(int*)trampoline == 0) {\n+    CodeBuffer buffer(trampoline, (int)SharedRuntime::trampoline_size());\n+    MacroAssembler _masm(&buffer);\n+    SharedRuntime::generate_trampoline(&_masm, destination);\n+    assert(*(int*)trampoline != 0, \"Instruction(s) for trampoline must not be encoded as zeros.\");\n+      _masm.flush();\n+\n+    if (PrintInterpreter) {\n+      Disassembler::decode(buffer.insts_begin(), buffer.insts_end());\n+    }\n+  }\n@@ -2637,7 +2754,15 @@\n-    address trampoline = method->from_compiled_entry();\n-    if (*(int*)trampoline == 0) {\n-      CodeBuffer buffer(trampoline, (int)SharedRuntime::trampoline_size());\n-      MacroAssembler _masm(&buffer);\n-      SharedRuntime::generate_trampoline(&_masm, entry->get_c2i_entry());\n-      assert(*(int*)trampoline != 0, \"Instruction(s) for trampoline must not be encoded as zeros.\");\n-      _masm.flush();\n+    generate_trampoline(method->from_compiled_entry(),           entry->get_c2i_entry());\n+    generate_trampoline(method->from_compiled_inline_ro_entry(), entry->get_c2i_inline_ro_entry());\n+    generate_trampoline(method->from_compiled_inline_entry(),    entry->get_c2i_inline_entry());\n+  }\n+\n+  return entry;\n+}\n+\n+\n+CompiledEntrySignature::CompiledEntrySignature(Method* method) :\n+  _method(method), _num_inline_args(0), _has_inline_recv(false),\n+  _sig_cc(NULL), _sig_cc_ro(NULL), _regs(NULL), _regs_cc(NULL), _regs_cc_ro(NULL),\n+  _args_on_stack(0), _args_on_stack_cc(0), _args_on_stack_cc_ro(0),\n+  _c1_needs_stack_repair(false), _c2_needs_stack_repair(false), _has_scalarized_args(false) {\n+  _sig = new GrowableArray<SigEntry>(method->size_of_parameters());\n@@ -2645,2 +2770,19 @@\n-      if (PrintInterpreter) {\n-        Disassembler::decode(buffer.insts_begin(), buffer.insts_end());\n+}\n+\n+int CompiledEntrySignature::compute_scalarized_cc(GrowableArray<SigEntry>*& sig_cc, VMRegPair*& regs_cc, bool scalar_receiver) {\n+  InstanceKlass* holder = _method->method_holder();\n+  sig_cc = new GrowableArray<SigEntry>(_method->size_of_parameters());\n+  if (!_method->is_static()) {\n+    if (holder->is_inline_klass() && scalar_receiver && InlineKlass::cast(holder)->can_be_passed_as_fields()) {\n+      sig_cc->appendAll(InlineKlass::cast(holder)->extended_sig());\n+    } else {\n+      SigEntry::add_entry(sig_cc, T_OBJECT, holder->name());\n+    }\n+  }\n+  for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {\n+    if (ss.type() == T_INLINE_TYPE) {\n+      InlineKlass* vk = ss.as_inline_klass(holder);\n+      if (vk->can_be_passed_as_fields()) {\n+        sig_cc->appendAll(vk->extended_sig());\n+      } else {\n+        SigEntry::add_entry(sig_cc, T_OBJECT, ss.as_symbol());\n@@ -2648,0 +2790,2 @@\n+    } else {\n+      SigEntry::add_entry(sig_cc, ss.type(), ss.as_symbol());\n@@ -2650,0 +2794,3 @@\n+  regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, sig_cc->length() + 2);\n+  return SharedRuntime::java_calling_convention(sig_cc, regs_cc);\n+}\n@@ -2651,1 +2798,103 @@\n-  return entry;\n+\/\/ See if we can save space by sharing the same entry for VIEP and VIEP(RO),\n+\/\/ or the same entry for VEP and VIEP(RO).\n+CodeOffsets::Entries CompiledEntrySignature::c1_inline_ro_entry_type() const {\n+  if (!has_scalarized_args()) {\n+    \/\/ VEP\/VIEP\/VIEP(RO) all share the same entry. There's no packing.\n+    return CodeOffsets::Verified_Entry;\n+  }\n+  if (_method->is_static()) {\n+    \/\/ Static methods don't need VIEP(RO)\n+    return CodeOffsets::Verified_Entry;\n+  }\n+\n+  if (has_inline_recv()) {\n+    if (num_inline_args() == 1) {\n+      \/\/ Share same entry for VIEP and VIEP(RO).\n+      \/\/ This is quite common: we have an instance method in an InlineKlass that has\n+      \/\/ no inline type args other than <this>.\n+      return CodeOffsets::Verified_Inline_Entry;\n+    } else {\n+      assert(num_inline_args() > 1, \"must be\");\n+      \/\/ No sharing:\n+      \/\/   VIEP(RO) -- <this> is passed as object\n+      \/\/   VEP      -- <this> is passed as fields\n+      return CodeOffsets::Verified_Inline_Entry_RO;\n+    }\n+  }\n+\n+  \/\/ Either a static method, or <this> is not an inline type\n+  if (args_on_stack_cc() != args_on_stack_cc_ro()) {\n+    \/\/ No sharing:\n+    \/\/ Some arguments are passed on the stack, and we have inserted reserved entries\n+    \/\/ into the VEP, but we never insert reserved entries into the VIEP(RO).\n+    return CodeOffsets::Verified_Inline_Entry_RO;\n+  } else {\n+    \/\/ Share same entry for VEP and VIEP(RO).\n+    return CodeOffsets::Verified_Entry;\n+  }\n+}\n+\n+\n+void CompiledEntrySignature::compute_calling_conventions() {\n+  \/\/ Get the (non-scalarized) signature and check for inline type arguments\n+  if (!_method->is_static()) {\n+    if (_method->method_holder()->is_inline_klass() && InlineKlass::cast(_method->method_holder())->can_be_passed_as_fields()) {\n+      _has_inline_recv = true;\n+      _num_inline_args++;\n+    }\n+    SigEntry::add_entry(_sig, T_OBJECT, _method->name());\n+  }\n+  for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if (bt == T_INLINE_TYPE) {\n+      if (ss.as_inline_klass(_method->method_holder())->can_be_passed_as_fields()) {\n+        _num_inline_args++;\n+      }\n+      bt = T_OBJECT;\n+    }\n+    SigEntry::add_entry(_sig, bt, ss.as_symbol());\n+  }\n+  if (_method->is_abstract() && !has_inline_arg()) {\n+    return;\n+  }\n+\n+  \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n+  _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig->length());\n+  _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);\n+\n+  \/\/ Now compute the scalarized calling convention if there are inline types in the signature\n+  _sig_cc = _sig;\n+  _sig_cc_ro = _sig;\n+  _regs_cc = _regs;\n+  _regs_cc_ro = _regs;\n+  _args_on_stack_cc = _args_on_stack;\n+  _args_on_stack_cc_ro = _args_on_stack;\n+\n+  if (has_inline_arg() && !_method->is_native()) {\n+    _args_on_stack_cc = compute_scalarized_cc(_sig_cc, _regs_cc, \/* scalar_receiver = *\/ true);\n+\n+    _sig_cc_ro = _sig_cc;\n+    _regs_cc_ro = _regs_cc;\n+    _args_on_stack_cc_ro = _args_on_stack_cc;\n+    if (_has_inline_recv) {\n+      \/\/ For interface calls, we need another entry point \/ adapter to unpack the receiver\n+      _args_on_stack_cc_ro = compute_scalarized_cc(_sig_cc_ro, _regs_cc_ro, \/* scalar_receiver = *\/ false);\n+    }\n+\n+    \/\/ Upper bound on stack arguments to avoid hitting the argument limit and\n+    \/\/ bailing out of compilation (\"unsupported incoming calling sequence\").\n+    \/\/ TODO we need a reasonable limit (flag?) here\n+    if (_args_on_stack_cc > 50) {\n+      \/\/ Don't scalarize inline type arguments\n+      _sig_cc = _sig;\n+      _sig_cc_ro = _sig;\n+      _regs_cc = _regs;\n+      _regs_cc_ro = _regs;\n+      _args_on_stack_cc = _args_on_stack;\n+      _args_on_stack_cc_ro = _args_on_stack;\n+    } else {\n+      _c1_needs_stack_repair = (_args_on_stack_cc < _args_on_stack) || (_args_on_stack_cc_ro < _args_on_stack);\n+      _c2_needs_stack_repair = (_args_on_stack_cc > _args_on_stack) || (_args_on_stack_cc > _args_on_stack_cc_ro);\n+      _has_scalarized_args = true;\n+    }\n+  }\n@@ -2662,1 +2911,1 @@\n-  NOT_PRODUCT(int insts_size);\n+  NOT_PRODUCT(int insts_size = 0);\n@@ -2666,0 +2915,1 @@\n+\n@@ -2671,2 +2921,4 @@\n-    if (method->is_abstract()) {\n-      return _abstract_method_handler;\n+    CompiledEntrySignature ces(method());\n+    {\n+       MutexUnlocker mul(AdapterHandlerLibrary_lock);\n+       ces.compute_calling_conventions();\n@@ -2674,0 +2926,6 @@\n+    GrowableArray<SigEntry>& sig       = ces.sig();\n+    GrowableArray<SigEntry>& sig_cc    = ces.sig_cc();\n+    GrowableArray<SigEntry>& sig_cc_ro = ces.sig_cc_ro();\n+    VMRegPair* regs         = ces.regs();\n+    VMRegPair* regs_cc      = ces.regs_cc();\n+    VMRegPair* regs_cc_ro   = ces.regs_cc_ro();\n@@ -2675,2 +2933,5 @@\n-    \/\/ Fill in the signature array, for the calling-convention call.\n-    int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n+    if (ces.has_scalarized_args()) {\n+      method->set_has_scalarized_args(true);\n+      method->set_c1_needs_stack_repair(ces.c1_needs_stack_repair());\n+      method->set_c2_needs_stack_repair(ces.c2_needs_stack_repair());\n+    }\n@@ -2678,9 +2939,15 @@\n-    BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n-    VMRegPair* regs   = NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n-    int i = 0;\n-    if (!method->is_static())  \/\/ Pass in receiver first\n-      sig_bt[i++] = T_OBJECT;\n-    for (SignatureStream ss(method->signature()); !ss.at_return_type(); ss.next()) {\n-      sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n-      if (ss.type() == T_LONG || ss.type() == T_DOUBLE)\n-        sig_bt[i++] = T_VOID;   \/\/ Longs & doubles take 2 Java slots\n+    if (method->is_abstract()) {\n+      if (ces.has_scalarized_args()) {\n+        \/\/ Save a C heap allocated version of the signature for abstract methods with scalarized inline type arguments\n+        address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n+        entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),\n+                                                 StubRoutines::throw_AbstractMethodError_entry(),\n+                                                 wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n+                                                 wrong_method_abstract, wrong_method_abstract);\n+        GrowableArray<SigEntry>* heap_sig = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<SigEntry>(sig_cc_ro.length(), mtInternal);\n+        heap_sig->appendAll(&sig_cc_ro);\n+        entry->set_sig_cc(heap_sig);\n+        return entry;\n+      } else {\n+        return _abstract_method_handler;\n+      }\n@@ -2688,1 +2955,0 @@\n-    assert(i == total_args_passed, \"\");\n@@ -2691,1 +2957,1 @@\n-    entry = _adapters->lookup(total_args_passed, sig_bt);\n+    entry = _adapters->lookup(&sig_cc, regs_cc != regs_cc_ro);\n@@ -2706,4 +2972,1 @@\n-    \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n-    int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n-\n-    fingerprint = new AdapterFingerPrint(total_args_passed, sig_bt);\n+    fingerprint = new AdapterFingerPrint(&sig_cc, regs_cc != regs_cc_ro);\n@@ -2728,3 +2991,2 @@\n-                                                     total_args_passed,\n-                                                     comp_args_on_stack,\n-                                                     sig_bt,\n+                                                     ces.args_on_stack(),\n+                                                     &sig,\n@@ -2732,1 +2994,14 @@\n-                                                     fingerprint);\n+                                                     &sig_cc,\n+                                                     regs_cc,\n+                                                     &sig_cc_ro,\n+                                                     regs_cc_ro,\n+                                                     fingerprint,\n+                                                     new_adapter);\n+\n+      if (ces.has_scalarized_args()) {\n+        \/\/ Save a C heap allocated version of the scalarized signature and store it in the adapter\n+        GrowableArray<SigEntry>* heap_sig = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<SigEntry>(sig_cc.length(), mtInternal);\n+        heap_sig->appendAll(&sig_cc);\n+        entry->set_sig_cc(heap_sig);\n+      }\n+\n@@ -2736,0 +3011,3 @@\n+          if (!shared_entry->compare_code(buf->code_begin(), buffer.insts_size())) {\n+            method->print();\n+          }\n@@ -2746,1 +3024,0 @@\n-      new_adapter = AdapterBlob::create(&buffer);\n@@ -2802,0 +3079,2 @@\n+  assert(base <= _c2i_inline_entry || _c2i_inline_entry == NULL, \"\");\n+  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == NULL, \"\");\n@@ -2803,0 +3082,1 @@\n+  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == NULL, \"\");\n@@ -2815,0 +3095,4 @@\n+  if (_c2i_inline_entry != NULL)\n+    _c2i_inline_entry += delta;\n+  if (_c2i_inline_ro_entry != NULL)\n+    _c2i_inline_ro_entry += delta;\n@@ -2817,0 +3101,2 @@\n+  if (_c2i_unverified_inline_entry != NULL)\n+    _c2i_unverified_inline_entry += delta;\n@@ -2825,0 +3111,3 @@\n+  if (_sig_cc != NULL) {\n+    delete _sig_cc;\n+  }\n@@ -2908,1 +3197,2 @@\n-        sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n+        BasicType bt = ss.type();\n+        sig_bt[i++] = bt;  \/\/ Collect remaining bits of signature\n@@ -3134,0 +3424,6 @@\n+  if (get_c2i_entry() != NULL) {\n+    st->print(\" c2iVE: \" INTPTR_FORMAT, p2i(get_c2i_inline_entry()));\n+  }\n+  if (get_c2i_entry() != NULL) {\n+    st->print(\" c2iVROE: \" INTPTR_FORMAT, p2i(get_c2i_inline_ro_entry()));\n+  }\n@@ -3135,1 +3431,4 @@\n-    st->print(\" c2iUV: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+    st->print(\" c2iUE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+  }\n+  if (get_c2i_unverified_entry() != NULL) {\n+    st->print(\" c2iUVE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_inline_entry()));\n@@ -3220,0 +3519,206 @@\n+\n+\/\/ We are at a compiled code to interpreter call. We need backing\n+\/\/ buffers for all inline type arguments. Allocate an object array to\n+\/\/ hold them (convenient because once we're done with it we don't have\n+\/\/ to worry about freeing it).\n+oop SharedRuntime::allocate_inline_types_impl(JavaThread* thread, methodHandle callee, bool allocate_receiver, TRAPS) {\n+  assert(InlineTypePassFieldsAsArgs, \"no reason to call this\");\n+  ResourceMark rm;\n+\n+  int nb_slots = 0;\n+  InstanceKlass* holder = callee->method_holder();\n+  allocate_receiver &= !callee->is_static() && holder->is_inline_klass();\n+  if (allocate_receiver) {\n+    nb_slots++;\n+  }\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    if (ss.type() == T_INLINE_TYPE) {\n+      nb_slots++;\n+    }\n+  }\n+  objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);\n+  objArrayHandle array(THREAD, array_oop);\n+  int i = 0;\n+  if (allocate_receiver) {\n+    InlineKlass* vk = InlineKlass::cast(holder);\n+    oop res = vk->allocate_instance(CHECK_NULL);\n+    array->obj_at_put(i, res);\n+    i++;\n+  }\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    if (ss.type() == T_INLINE_TYPE) {\n+      InlineKlass* vk = ss.as_inline_klass(holder);\n+      oop res = vk->allocate_instance(CHECK_NULL);\n+      array->obj_at_put(i, res);\n+      i++;\n+    }\n+  }\n+  return array();\n+}\n+\n+JRT_ENTRY(void, SharedRuntime::allocate_inline_types(JavaThread* thread, Method* callee_method, bool allocate_receiver))\n+  methodHandle callee(thread, callee_method);\n+  oop array = SharedRuntime::allocate_inline_types_impl(thread, callee, allocate_receiver, CHECK);\n+  thread->set_vm_result(array);\n+  thread->set_vm_result_2(callee()); \/\/ TODO: required to keep callee live?\n+JRT_END\n+\n+\/\/ TODO remove this once the AARCH64 dependency is gone\n+\/\/ Iterate over the array of heap allocated inline types and apply the GC post barrier to all reference fields.\n+\/\/ This is called from the C2I adapter after inline type arguments are heap allocated and initialized.\n+JRT_LEAF(void, SharedRuntime::apply_post_barriers(JavaThread* thread, objArrayOopDesc* array))\n+{\n+  assert(InlineTypePassFieldsAsArgs, \"no reason to call this\");\n+  assert(oopDesc::is_oop(array), \"should be oop\");\n+  for (int i = 0; i < array->length(); ++i) {\n+    instanceOop valueOop = (instanceOop)array->obj_at(i);\n+    InlineKlass* vk = InlineKlass::cast(valueOop->klass());\n+    if (vk->contains_oops()) {\n+      const address dst_oop_addr = ((address) (void*) valueOop);\n+      OopMapBlock* map = vk->start_of_nonstatic_oop_maps();\n+      OopMapBlock* const end = map + vk->nonstatic_oop_map_count();\n+      while (map != end) {\n+        address doop_address = dst_oop_addr + map->offset();\n+        barrier_set_cast<ModRefBarrierSet>(BarrierSet::barrier_set())->\n+          write_ref_array((HeapWord*) doop_address, map->count());\n+        map++;\n+      }\n+    }\n+  }\n+}\n+JRT_END\n+\n+\/\/ We're returning from an interpreted method: load each field into a\n+\/\/ register following the calling convention\n+JRT_LEAF(void, SharedRuntime::load_inline_type_fields_in_regs(JavaThread* thread, oopDesc* res))\n+{\n+  assert(res->klass()->is_inline_klass(), \"only inline types here\");\n+  ResourceMark rm;\n+  RegisterMap reg_map(thread);\n+  frame stubFrame = thread->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+  assert(callerFrame.is_interpreted_frame(), \"should be coming from interpreter\");\n+\n+  InlineKlass* vk = InlineKlass::cast(res->klass());\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  if (regs == NULL) {\n+    \/\/ The fields of the inline klass don't fit in registers, bail out\n+    return;\n+  }\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    address loc = reg_map.location(pair.first());\n+    switch(bt) {\n+    case T_BOOLEAN:\n+      *(jboolean*)loc = res->bool_field(off);\n+      break;\n+    case T_CHAR:\n+      *(jchar*)loc = res->char_field(off);\n+      break;\n+    case T_BYTE:\n+      *(jbyte*)loc = res->byte_field(off);\n+      break;\n+    case T_SHORT:\n+      *(jshort*)loc = res->short_field(off);\n+      break;\n+    case T_INT: {\n+      *(jint*)loc = res->int_field(off);\n+      break;\n+    }\n+    case T_LONG:\n+#ifdef _LP64\n+      *(intptr_t*)loc = res->long_field(off);\n+#else\n+      Unimplemented();\n+#endif\n+      break;\n+    case T_OBJECT:\n+    case T_ARRAY: {\n+      *(oop*)loc = res->obj_field(off);\n+      break;\n+    }\n+    case T_FLOAT:\n+      *(jfloat*)loc = res->float_field(off);\n+      break;\n+    case T_DOUBLE:\n+      *(jdouble*)loc = res->double_field(off);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+#ifdef ASSERT\n+  VMRegPair pair = regs->at(0);\n+  address loc = reg_map.location(pair.first());\n+  assert(*(oopDesc**)loc == res, \"overwritten object\");\n+#endif\n+\n+  thread->set_vm_result(res);\n+}\n+JRT_END\n+\n+\/\/ We've returned to an interpreted method, the interpreter needs a\n+\/\/ reference to an inline type instance. Allocate it and initialize it\n+\/\/ from field's values in registers.\n+JRT_BLOCK_ENTRY(void, SharedRuntime::store_inline_type_fields_to_buf(JavaThread* thread, intptr_t res))\n+{\n+  ResourceMark rm;\n+  RegisterMap reg_map(thread);\n+  frame stubFrame = thread->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+\n+#ifdef ASSERT\n+  InlineKlass* verif_vk = InlineKlass::returned_inline_klass(reg_map);\n+#endif\n+\n+  if (!is_set_nth_bit(res, 0)) {\n+    \/\/ We're not returning with inline type fields in registers (the\n+    \/\/ calling convention didn't allow it for this inline klass)\n+    assert(!Metaspace::contains((void*)res), \"should be oop or pointer in buffer area\");\n+    thread->set_vm_result((oopDesc*)res);\n+    assert(verif_vk == NULL, \"broken calling convention\");\n+    return;\n+  }\n+\n+  clear_nth_bit(res, 0);\n+  InlineKlass* vk = (InlineKlass*)res;\n+  assert(verif_vk == vk, \"broken calling convention\");\n+  assert(Metaspace::contains((void*)res), \"should be klass\");\n+\n+  \/\/ Allocate handles for every oop field so they are safe in case of\n+  \/\/ a safepoint when allocating\n+  GrowableArray<Handle> handles;\n+  vk->save_oop_fields(reg_map, handles);\n+\n+  \/\/ It's unsafe to safepoint until we are here\n+  JRT_BLOCK;\n+  {\n+    Thread* THREAD = thread;\n+    oop vt = vk->realloc_result(reg_map, handles, CHECK);\n+    thread->set_vm_result(vt);\n+  }\n+  JRT_BLOCK_END;\n+}\n+JRT_END\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":604,"deletions":99,"binary":false,"changes":703,"status":"modified"},{"patch":"@@ -244,0 +244,12 @@\n+#define CHECK_THROW_NOSYNC_IMSE(obj)  \\\n+  if (EnableValhalla && (obj)->mark().is_inline_type()) {  \\\n+    ResourceMark rm(THREAD);                \\\n+    THROW_MSG(vmSymbols::java_lang_IllegalMonitorStateException(), obj->klass()->external_name()); \\\n+  }\n+\n+#define CHECK_THROW_NOSYNC_IMSE_0(obj)  \\\n+    if (EnableValhalla && (obj)->mark().is_inline_type()) {  \\\n+    ResourceMark rm(THREAD);                  \\\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalMonitorStateException(), obj->klass()->external_name()); \\\n+  }\n+\n@@ -271,0 +283,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -320,0 +333,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -433,0 +447,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -446,1 +461,1 @@\n-  assert(!mark.has_bias_pattern(), \"should not see bias pattern here\");\n+  assert(!UseBiasedLocking || !mark.has_bias_pattern(), \"should not see bias pattern here\");\n@@ -482,0 +497,4 @@\n+  if (EnableValhalla && mark.is_inline_type()) {\n+    return;\n+  }\n+  assert(!EnableValhalla || !object->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -484,0 +503,1 @@\n+         !UseBiasedLocking ||\n@@ -545,0 +565,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -559,0 +580,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -585,0 +607,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -604,0 +627,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -608,0 +632,1 @@\n+    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n@@ -609,1 +634,0 @@\n-  assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n@@ -646,0 +670,1 @@\n+  CHECK_THROW_NOSYNC_IMSE_0(obj);\n@@ -670,0 +695,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -685,0 +711,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -702,0 +729,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -851,0 +879,4 @@\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+    \/\/ VM should be calling bootstrap method\n+    ShouldNotReachHere();\n+  }\n@@ -878,1 +910,1 @@\n-    assert(!mark.has_bias_pattern(), \"invariant\");\n+    assert(!UseBiasedLocking || !mark.has_bias_pattern(), \"invariant\");\n@@ -981,6 +1013,0 @@\n-\/\/ Deprecated -- use FastHashCode() instead.\n-\n-intptr_t ObjectSynchronizer::identity_hash_value_for(Handle obj) {\n-  return FastHashCode(Thread::current(), obj());\n-}\n-\n@@ -990,0 +1016,3 @@\n+  if (EnableValhalla && h_obj->mark().is_inline_type()) {\n+    return false;\n+  }\n@@ -1205,0 +1234,4 @@\n+  if (EnableValhalla) {\n+    guarantee(!object->klass()->is_inline_klass(), \"Attempt to inflate inline type\");\n+  }\n+\n@@ -1209,1 +1242,1 @@\n-    assert(!mark.has_bias_pattern(), \"invariant\");\n+    assert(!UseBiasedLocking || !mark.has_bias_pattern(), \"invariant\");\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":43,"deletions":10,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -69,0 +69,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -1220,0 +1221,1 @@\n+  _return_buffered_value(nullptr),\n@@ -1276,1 +1278,0 @@\n-\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -425,0 +425,1 @@\n+ public:\n@@ -856,0 +857,1 @@\n+  friend class VTBuffer;\n@@ -913,0 +915,1 @@\n+  oop           _return_buffered_value; \/\/ buffered value being returned\n@@ -1354,0 +1357,3 @@\n+  oop return_buffered_value() const              { return _return_buffered_value; }\n+  void set_return_buffered_value(oop val)        { _return_buffered_value = val; }\n+\n@@ -1418,0 +1424,1 @@\n+  static ByteSize return_buffered_value_offset() { return byte_offset_of(JavaThread, _return_buffered_value); }\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+import com.sun.tools.javac.code.Source.Feature;\n@@ -873,0 +874,3 @@\n+        else if (enclOp.hasTag(WITHFIELD) &&\n+                tree == TreeInfo.skipParens(((JCWithField) enclOp).field))\n+            return AccessCode.WITHFIELD.code;\n@@ -983,1 +987,1 @@\n-            } else if (acode == AccessCode.ASSIGN.code)\n+            } else if (acode == AccessCode.ASSIGN.code || acode == AccessCode.WITHFIELD.code)\n@@ -987,1 +991,1 @@\n-            restype = vsym.erasure(types);\n+            restype = acode == AccessCode.WITHFIELD.code ? vsym.owner.erasure(types) : vsym.erasure(types);\n@@ -1356,0 +1360,3 @@\n+            case WITHFIELD:\n+                expr = make.WithField(ref, args.head);\n+                break;\n@@ -1361,1 +1368,1 @@\n-            stat = make.Return(expr.setType(sym.type));\n+            stat = make.Return(expr.setType(aCode == AccessCode.WITHFIELD ? sym.owner.type : sym.type));\n@@ -1455,0 +1462,1 @@\n+            final Type type = v.erasure(types);\n@@ -1456,1 +1464,1 @@\n-                flags, proxyName, v.erasure(types), owner);\n+                flags, proxyName, type, owner);\n@@ -1519,1 +1527,3 @@\n-        VarSymbol outerThis = makeOuterThisVarSymbol(owner, FINAL | SYNTHETIC);\n+        Type target = types.erasure(owner.enclClass().type.getEnclosingType());\n+        long flags = FINAL | SYNTHETIC;\n+        VarSymbol outerThis = makeOuterThisVarSymbol(owner, flags);\n@@ -1703,1 +1713,1 @@\n-        if (types.asSuper(resource.type, syms.autoCloseableType.tsym) == null) {\n+        if (types.asSuper(resource.type, syms.autoCloseableType.tsym, true) == null) {\n@@ -2084,1 +2094,2 @@\n-        return (tree == null) ? null : boxIfNeeded(translate(tree), type);\n+        return (tree == null) ? null :\n+                applyPrimitiveConversionsAsNeeded(boxIfNeeded(translate(tree), type), type);\n@@ -3081,0 +3092,17 @@\n+    \/** Apply primitive value\/reference conversions as needed *\/\n+    @SuppressWarnings(\"unchecked\")\n+    <T extends JCExpression> T applyPrimitiveConversionsAsNeeded(T tree, Type type) {\n+        boolean haveValue = tree.type.isPrimitiveClass();\n+        if (haveValue == type.isPrimitiveClass())\n+            return tree;\n+        if (haveValue) {\n+            \/\/ widening coversion is a NOP for the VM due to subtyping relationship at class file\n+            return tree;\n+        } else {\n+            \/\/ For narrowing conversion, insert a cast which should trigger a null check\n+            return (T) make.TypeCast(type, tree);\n+        }\n+    }\n+\n+\n+\n@@ -3480,1 +3508,1 @@\n-                                              syms.iterableType.tsym);\n+                                              syms.iterableType.tsym, true);\n@@ -3569,0 +3597,17 @@\n+    public void visitWithField(JCWithField tree) {\n+        Type fieldType = tree.field.type;\n+        tree.field = translate(tree.field, tree);\n+        tree.value = translate(tree.value, fieldType); \/\/ important to use pre-translation type.\n+\n+        \/\/ If translated field is an Apply, we are\n+        \/\/ seeing an access method invocation. In this case, append\n+        \/\/ right hand side as last argument of the access method.\n+        if (tree.field.hasTag(APPLY)) {\n+            JCMethodInvocation app = (JCMethodInvocation) tree.field;\n+            app.args = List.of(tree.value).prependList(app.args);\n+            result = app;\n+        } else {\n+            result = tree;\n+        }\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Lower.java","additions":53,"deletions":8,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2577,1 +2577,1 @@\n-        return isKind(doctree, VALUE);\n+        return isKind(doctree, Kind.VALUE);\n","filename":"src\/jdk.javadoc\/share\/classes\/jdk\/javadoc\/internal\/doclets\/toolkit\/util\/Utils.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -65,0 +65,77 @@\n+# Valhalla\n+compiler\/arguments\/CheckCICompilerCount.java                        8205030 generic-all\n+compiler\/arguments\/CheckCompileThresholdScaling.java                8205030 generic-all\n+compiler\/codecache\/CheckSegmentedCodeCache.java                     8205030 generic-all\n+compiler\/codecache\/cli\/TestSegmentedCodeCacheOption.java            8205030 generic-all\n+compiler\/codecache\/cli\/codeheapsize\/TestCodeHeapSizeOptions.java    8205030 generic-all\n+compiler\/codecache\/cli\/printcodecache\/TestPrintCodeCacheOption.java 8205030 generic-all\n+compiler\/whitebox\/OSRFailureLevel4Test.java                         8205030 generic-all\n+\n+compiler\/aot\/cli\/DisabledAOTWithLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/SingleAOTOptionTest.java 8226295 generic-all\n+compiler\/aot\/cli\/MultipleAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileClassWithDebugTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileModuleTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/AtFileTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionWrongFileTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ClasspathOptionUnknownClassTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileDirectoryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionNotExistingTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileClassTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileJarTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/IgnoreErrorsTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileAbsoluteDirectoryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/NonExistingAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/SingleAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/IncorrectAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/RecompilationTest.java 8226295 generic-all\n+compiler\/aot\/SharedUsageTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/ClassSearchTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/SearchPathTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/module\/ModuleSourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/ClassSourceTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/directory\/DirectorySourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/jar\/JarSourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/NativeOrderOutputStreamTest.java 8226295 generic-all\n+compiler\/aot\/verification\/vmflags\/TrackedFlagTest.java 8226295 generic-all\n+compiler\/aot\/verification\/vmflags\/NotTrackedFlagTest.java 8226295 generic-all\n+compiler\/aot\/verification\/ClassAndLibraryNotMatchTest.java 8226295 generic-all\n+compiler\/aot\/DeoptimizationTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SelfChanged.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SelfChangedCDS.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SuperChanged.java 8226295 generic-all\n+\n@@ -92,0 +169,22 @@\n+# Valhalla TODO:\n+runtime\/CompressedOops\/CompressedClassPointers.java 8210258 generic-all\n+runtime\/RedefineTests\/RedefineLeak.java 8205032 generic-all\n+runtime\/SharedArchiveFile\/BootAppendTests.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/CdsDifferentCompactStrings.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/CdsDifferentObjectAlignment.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/NonBootLoaderClasses.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/PrintSharedArchiveAndExit.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedArchiveFile.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedStringsDedup.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedStringsRunAuto.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedSymbolTableBucketSize.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SpaceUtilizationCheck.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/TestInterpreterMethodEntries.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformInterfaceAndImplementor.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformSuperAndSubClasses.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformSuperSubTwoPckgs.java 8210258 generic-all\n+runtime\/appcds\/ClassLoaderTest.java 8210258 generic-all\n+runtime\/appcds\/HelloTest.java 8210258 generic-all\n+runtime\/appcds\/sharedStrings\/SharedStringsBasic.java 8210258 generic-all\n+\n+\n@@ -102,0 +201,28 @@\n+# Valhalla TODO:\n+serviceability\/sa\/ClhsdbCDSCore.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbFindPC.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbInspect.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbLongConstant.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJdis.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJstack.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAs.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintStatics.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSource.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSymbol.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbWhere.java 8190936 generic-all\n+serviceability\/sa\/JhsdbThreadInfoTest.java 8190936 generic-all\n+serviceability\/sa\/TestClassDump.java 8190936 generic-all\n+serviceability\/sa\/TestClhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestCpoolForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForLargeArray.java 8190936 generic-all\n+serviceability\/sa\/TestIntConstant.java 8190936 generic-all\n+serviceability\/sa\/TestJhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCore.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8190936 generic-all\n+serviceability\/sa\/TestPrintMdo.java 8190936 generic-all\n+serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 8190936 generic-all\n+\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":127,"deletions":0,"binary":false,"changes":127,"status":"modified"}]}