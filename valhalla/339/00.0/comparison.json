{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,0 +26,1 @@\n+#include \"classfile\/classLoaderData.hpp\"\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -41,3 +41,0 @@\n-  CardTableBarrierSet* ctbs = barrier_set_cast<CardTableBarrierSet>(bs);\n-  CardTable* ct = ctbs->card_table();\n-\n@@ -58,3 +55,0 @@\n-    if (ct->scanned_concurrently()) {\n-      __ membar(Assembler::StoreStore);\n-    }\n@@ -67,4 +61,0 @@\n-  BarrierSet* bs = BarrierSet::barrier_set();\n-  CardTableBarrierSet* ctbs = barrier_set_cast<CardTableBarrierSet>(bs);\n-  CardTable* ct = ctbs->card_table();\n-\n@@ -84,3 +74,0 @@\n-  if (ct->scanned_concurrently()) {\n-    __ membar(__ StoreStore);\n-  }\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/cardTableBarrierSetAssembler_aarch64.cpp","additions":0,"deletions":13,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -46,0 +46,20 @@\n+Register InterpreterRuntime::SignatureHandlerGenerator::next_gpr() {\n+  if (_num_reg_int_args < Argument::n_int_register_parameters_c-1) {\n+    return as_Register(_num_reg_int_args++ + c_rarg1->encoding());\n+  }\n+  return noreg;\n+}\n+\n+FloatRegister InterpreterRuntime::SignatureHandlerGenerator::next_fpr() {\n+  if (_num_reg_fp_args < Argument::n_float_register_parameters_c) {\n+    return as_FloatRegister(_num_reg_fp_args++);\n+  }\n+  return fnoreg;\n+}\n+\n+int InterpreterRuntime::SignatureHandlerGenerator::next_stack_offset() {\n+  int ret = _stack_offset;\n+  _stack_offset += wordSize;\n+  return ret;\n+}\n+\n@@ -49,2 +69,2 @@\n-  _num_int_args = (method->is_static() ? 1 : 0);\n-  _num_fp_args = 0;\n+  _num_reg_int_args = (method->is_static() ? 1 : 0);\n+  _num_reg_fp_args = 0;\n@@ -57,35 +77,6 @@\n-  switch (_num_int_args) {\n-  case 0:\n-    __ ldr(c_rarg1, src);\n-    _num_int_args++;\n-    break;\n-  case 1:\n-    __ ldr(c_rarg2, src);\n-    _num_int_args++;\n-    break;\n-  case 2:\n-    __ ldr(c_rarg3, src);\n-    _num_int_args++;\n-    break;\n-  case 3:\n-    __ ldr(c_rarg4, src);\n-    _num_int_args++;\n-    break;\n-  case 4:\n-    __ ldr(c_rarg5, src);\n-    _num_int_args++;\n-    break;\n-  case 5:\n-    __ ldr(c_rarg6, src);\n-    _num_int_args++;\n-    break;\n-  case 6:\n-    __ ldr(c_rarg7, src);\n-    _num_int_args++;\n-    break;\n-  default:\n-    __ ldr(r0, src);\n-    __ str(r0, Address(to(), _stack_offset));\n-    _stack_offset += wordSize;\n-    _num_int_args++;\n-    break;\n+  Register reg = next_gpr();\n+  if (reg != noreg) {\n+    __ ldr(reg, src);\n+  } else {\n+    __ ldrw(r0, src);\n+    __ strw(r0, Address(to(), next_stack_offset()));\n@@ -98,30 +89,4 @@\n-  switch (_num_int_args) {\n-  case 0:\n-    __ ldr(c_rarg1, src);\n-    _num_int_args++;\n-    break;\n-  case 1:\n-    __ ldr(c_rarg2, src);\n-    _num_int_args++;\n-    break;\n-  case 2:\n-    __ ldr(c_rarg3, src);\n-    _num_int_args++;\n-    break;\n-  case 3:\n-    __ ldr(c_rarg4, src);\n-    _num_int_args++;\n-    break;\n-  case 4:\n-    __ ldr(c_rarg5, src);\n-    _num_int_args++;\n-    break;\n-  case 5:\n-    __ ldr(c_rarg6, src);\n-    _num_int_args++;\n-    break;\n-  case 6:\n-    __ ldr(c_rarg7, src);\n-    _num_int_args++;\n-    break;\n-  default:\n+  Register reg = next_gpr();\n+  if (reg != noreg) {\n+    __ ldr(reg, src);\n+  } else {\n@@ -129,4 +94,1 @@\n-    __ str(r0, Address(to(), _stack_offset));\n-    _stack_offset += wordSize;\n-    _num_int_args++;\n-    break;\n+    __ str(r0, Address(to(), next_stack_offset()));\n@@ -139,2 +101,3 @@\n-  if (_num_fp_args < Argument::n_float_register_parameters_c) {\n-    __ ldrs(as_FloatRegister(_num_fp_args++), src);\n+  FloatRegister reg = next_fpr();\n+  if (reg != fnoreg) {\n+    __ ldrs(reg, src);\n@@ -143,3 +106,1 @@\n-    __ strw(r0, Address(to(), _stack_offset));\n-    _stack_offset += wordSize;\n-    _num_fp_args++;\n+    __ strw(r0, Address(to(), next_stack_offset()));\n@@ -152,2 +113,3 @@\n-  if (_num_fp_args < Argument::n_float_register_parameters_c) {\n-    __ ldrd(as_FloatRegister(_num_fp_args++), src);\n+  FloatRegister reg = next_fpr();\n+  if (reg != fnoreg) {\n+    __ ldrd(reg, src);\n@@ -156,3 +118,1 @@\n-    __ str(r0, Address(to(), _stack_offset));\n-    _stack_offset += wordSize;\n-    _num_fp_args++;\n+    __ str(r0, Address(to(), next_stack_offset()));\n@@ -163,3 +123,2 @@\n-\n-  switch (_num_int_args) {\n-  case 0:\n+  Register reg = next_gpr();\n+  if (reg == c_rarg1) {\n@@ -168,87 +127,16 @@\n-    _num_int_args++;\n-    break;\n-  case 1:\n-    {\n-      __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n-      __ mov(c_rarg2, 0);\n-      __ ldr(temp(), r0);\n-      Label L;\n-      __ cbz(temp(), L);\n-      __ mov(c_rarg2, r0);\n-      __ bind(L);\n-      _num_int_args++;\n-      break;\n-    }\n-  case 2:\n-    {\n-      __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n-      __ mov(c_rarg3, 0);\n-      __ ldr(temp(), r0);\n-      Label L;\n-      __ cbz(temp(), L);\n-      __ mov(c_rarg3, r0);\n-      __ bind(L);\n-      _num_int_args++;\n-      break;\n-    }\n-  case 3:\n-    {\n-      __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n-      __ mov(c_rarg4, 0);\n-      __ ldr(temp(), r0);\n-      Label L;\n-      __ cbz(temp(), L);\n-      __ mov(c_rarg4, r0);\n-      __ bind(L);\n-      _num_int_args++;\n-      break;\n-    }\n-  case 4:\n-    {\n-      __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n-      __ mov(c_rarg5, 0);\n-      __ ldr(temp(), r0);\n-      Label L;\n-      __ cbz(temp(), L);\n-      __ mov(c_rarg5, r0);\n-      __ bind(L);\n-      _num_int_args++;\n-      break;\n-    }\n-  case 5:\n-    {\n-      __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n-      __ mov(c_rarg6, 0);\n-      __ ldr(temp(), r0);\n-      Label L;\n-      __ cbz(temp(), L);\n-      __ mov(c_rarg6, r0);\n-      __ bind(L);\n-      _num_int_args++;\n-      break;\n-    }\n-  case 6:\n-    {\n-      __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n-      __ mov(c_rarg7, 0);\n-      __ ldr(temp(), r0);\n-      Label L;\n-      __ cbz(temp(), L);\n-      __ mov(c_rarg7, r0);\n-      __ bind(L);\n-      _num_int_args++;\n-      break;\n-    }\n- default:\n-   {\n-      __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n-      __ ldr(temp(), r0);\n-      Label L;\n-      __ cbnz(temp(), L);\n-      __ mov(r0, zr);\n-      __ bind(L);\n-      __ str(r0, Address(to(), _stack_offset));\n-      _stack_offset += wordSize;\n-      _num_int_args++;\n-      break;\n-   }\n+  } else if (reg != noreg) {\n+    __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n+    __ mov(reg, 0);\n+    __ ldr(temp(), r0);\n+    Label L;\n+    __ cbz(temp(), L);\n+    __ mov(reg, r0);\n+    __ bind(L);\n+  } else {\n+    __ add(r0, from(), Interpreter::local_offset_in_bytes(offset()));\n+    __ ldr(temp(), r0);\n+    Label L;\n+    __ cbnz(temp(), L);\n+    __ mov(r0, zr);\n+    __ bind(L);\n+    __ str(r0, Address(to(), next_stack_offset()));\n@@ -287,2 +175,2 @@\n-  unsigned int _num_int_args;\n-  unsigned int _num_fp_args;\n+  unsigned int _num_reg_int_args;\n+  unsigned int _num_reg_fp_args;\n@@ -290,3 +178,2 @@\n-  virtual void pass_int()\n-  {\n-    jint from_obj = *(jint *)(_from+Interpreter::local_offset_in_bytes(0));\n+  intptr_t* single_slot_addr() {\n+    intptr_t* from_addr = (intptr_t*)(_from+Interpreter::local_offset_in_bytes(0));\n@@ -294,8 +181,1 @@\n-\n-    if (_num_int_args < Argument::n_int_register_parameters_c-1) {\n-      *_int_args++ = from_obj;\n-      _num_int_args++;\n-    } else {\n-      *_to++ = from_obj;\n-      _num_int_args++;\n-    }\n+    return from_addr;\n@@ -304,3 +184,2 @@\n-  virtual void pass_long()\n-  {\n-    intptr_t from_obj = *(intptr_t*)(_from+Interpreter::local_offset_in_bytes(1));\n+  intptr_t* double_slot_addr() {\n+    intptr_t* from_addr = (intptr_t*)(_from+Interpreter::local_offset_in_bytes(1));\n@@ -308,0 +187,2 @@\n+    return from_addr;\n+  }\n@@ -309,6 +190,4 @@\n-    if (_num_int_args < Argument::n_int_register_parameters_c-1) {\n-      *_int_args++ = from_obj;\n-      _num_int_args++;\n-    } else {\n-      *_to++ = from_obj;\n-      _num_int_args++;\n+  int pass_gpr(intptr_t value) {\n+    if (_num_reg_int_args < Argument::n_int_register_parameters_c-1) {\n+      *_int_args++ = value;\n+      return _num_reg_int_args++;\n@@ -316,0 +195,1 @@\n+    return -1;\n@@ -318,4 +198,7 @@\n-  virtual void pass_object()\n-  {\n-    intptr_t *from_addr = (intptr_t*)(_from + Interpreter::local_offset_in_bytes(0));\n-    _from -= Interpreter::stackElementSize;\n+  int pass_fpr(intptr_t value) {\n+    if (_num_reg_fp_args < Argument::n_float_register_parameters_c) {\n+      *_fp_args++ = value;\n+      return _num_reg_fp_args++;\n+    }\n+    return -1;\n+  }\n@@ -323,6 +206,8 @@\n-    if (_num_int_args < Argument::n_int_register_parameters_c-1) {\n-      *_int_args++ = (*from_addr == 0) ? NULL : (intptr_t)from_addr;\n-      _num_int_args++;\n-    } else {\n-      *_to++ = (*from_addr == 0) ? NULL : (intptr_t) from_addr;\n-      _num_int_args++;\n+  void pass_stack(intptr_t value) {\n+    *_to++ = value;\n+  }\n+\n+  virtual void pass_int() {\n+    jint value = *(jint*)single_slot_addr();\n+    if (pass_gpr(value) < 0) {\n+      pass_stack(value);\n@@ -337,4 +222,6 @@\n-  virtual void pass_float()\n-  {\n-    jint from_obj = *(jint*)(_from+Interpreter::local_offset_in_bytes(0));\n-    _from -= Interpreter::stackElementSize;\n+  virtual void pass_long() {\n+    intptr_t value = *double_slot_addr();\n+    if (pass_gpr(value) < 0) {\n+      pass_stack(value);\n+    }\n+  }\n@@ -342,6 +229,5 @@\n-    if (_num_fp_args < Argument::n_float_register_parameters_c) {\n-      *_fp_args++ = from_obj;\n-      _num_fp_args++;\n-    } else {\n-      *_to++ = from_obj;\n-      _num_fp_args++;\n+  virtual void pass_object() {\n+    intptr_t* addr = single_slot_addr();\n+    intptr_t value = *addr == 0 ? NULL : (intptr_t)addr;\n+    if (pass_gpr(value) < 0) {\n+      pass_stack(value);\n@@ -351,4 +237,6 @@\n-  virtual void pass_double()\n-  {\n-    intptr_t from_obj = *(intptr_t*)(_from+Interpreter::local_offset_in_bytes(1));\n-    _from -= 2*Interpreter::stackElementSize;\n+  virtual void pass_float() {\n+    jint value = *(jint*)single_slot_addr();\n+    if (pass_fpr(value) < 0) {\n+      pass_stack(value);\n+    }\n+  }\n@@ -356,4 +244,5 @@\n-    if (_num_fp_args < Argument::n_float_register_parameters_c) {\n-      *_fp_args++ = from_obj;\n-      *_fp_identifiers |= (1ull << _num_fp_args); \/\/ mark as double\n-      _num_fp_args++;\n+  virtual void pass_double() {\n+    intptr_t value = *double_slot_addr();\n+    int arg = pass_fpr(value);\n+    if (0 <= arg) {\n+      *_fp_identifiers |= (1ull << arg); \/\/ mark as double\n@@ -361,2 +250,1 @@\n-      *_to++ = from_obj;\n-      _num_fp_args++;\n+      pass_stack(value);\n@@ -377,2 +265,2 @@\n-    _num_int_args = (method->is_static() ? 1 : 0);\n-    _num_fp_args = 0;\n+    _num_reg_int_args = (method->is_static() ? 1 : 0);\n+    _num_reg_fp_args = 0;\n","filename":"src\/hotspot\/cpu\/aarch64\/interpreterRT_aarch64.cpp","additions":113,"deletions":225,"binary":false,"changes":338,"status":"modified"},{"patch":"@@ -37,2 +37,2 @@\n-  unsigned int _num_fp_args;\n-  unsigned int _num_int_args;\n+  unsigned int _num_reg_fp_args;\n+  unsigned int _num_reg_int_args;\n@@ -48,0 +48,4 @@\n+  Register next_gpr();\n+  FloatRegister next_fpr();\n+  int next_stack_offset();\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interpreterRT_aarch64.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2616,0 +2616,2 @@\n+ATOMIC_XCHG(xchgl, swpl, ldxr, stlxr, Assembler::xword)\n+ATOMIC_XCHG(xchglw, swpl, ldxrw, stlxrw, Assembler::word)\n@@ -5334,1 +5336,2 @@\n-\/\/ aarch64_get_thread_helper() clobbers only r0, r1, and flags.\n+\/\/ On Linux, aarch64_get_thread_helper() clobbers only r0, r1, and flags.\n+\/\/ On other systems, the helper is a usual C function.\n@@ -5337,1 +5340,4 @@\n-  RegSet saved_regs = RegSet::range(r0, r1) + lr - dst;\n+  RegSet saved_regs =\n+    LINUX_ONLY(RegSet::range(r0, r1)  + lr - dst)\n+    NOT_LINUX (RegSet::range(r0, r17) + lr - dst);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1060,0 +1060,2 @@\n+  void atomic_xchgl(Register prev, Register newv, Register addr);\n+  void atomic_xchglw(Register prev, Register newv, Register addr);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"atomic_aarch64.hpp\"\n@@ -41,0 +42,1 @@\n+#include \"runtime\/atomic.hpp\"\n@@ -1379,1 +1381,1 @@\n-  \/\/ cache line boundaries will still be loaded and stored atomicly.\n+  \/\/ cache line boundaries will still be loaded and stored atomically.\n@@ -1449,1 +1451,1 @@\n-  \/\/ cache line boundaries will still be loaded and stored atomicly.\n+  \/\/ cache line boundaries will still be loaded and stored atomically.\n@@ -1614,1 +1616,1 @@\n-  \/\/ cache line boundaries will still be loaded and stored atomicly.\n+  \/\/ cache line boundaries will still be loaded and stored atomically.\n@@ -1638,1 +1640,1 @@\n-  \/\/ cache line boundaries will still be loaded and stored atomicly.\n+  \/\/ cache line boundaries will still be loaded and stored atomically.\n@@ -5589,0 +5591,85 @@\n+#ifdef LINUX\n+  \/\/ ARMv8.1 LSE versions of the atomic stubs used by Atomic::PlatformXX.\n+  \/\/\n+  \/\/ If LSE is in use, generate LSE versions of all the stubs. The\n+  \/\/ non-LSE versions are in atomic_aarch64.S.\n+  void generate_atomic_entry_points() {\n+\n+    if (! UseLSE) {\n+      return;\n+    }\n+\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"atomic entry points\");\n+\n+    __ align(32);\n+    aarch64_atomic_fetch_add_8_impl = (aarch64_atomic_stub_t)__ pc();\n+    {\n+      Register prev = r2, addr = c_rarg0, incr = c_rarg1;\n+      __ atomic_addal(prev, incr, addr);\n+      __ mov(r0, prev);\n+      __ ret(lr);\n+    }\n+    __ align(32);\n+    aarch64_atomic_fetch_add_4_impl = (aarch64_atomic_stub_t)__ pc();\n+    {\n+      Register prev = r2, addr = c_rarg0, incr = c_rarg1;\n+      __ atomic_addalw(prev, incr, addr);\n+      __ movw(r0, prev);\n+      __ ret(lr);\n+    }\n+    __ align(32);\n+    aarch64_atomic_xchg_4_impl = (aarch64_atomic_stub_t)__ pc();\n+    {\n+      Register prev = r2, addr = c_rarg0, newv = c_rarg1;\n+      __ atomic_xchglw(prev, newv, addr);\n+      __ movw(r0, prev);\n+      __ ret(lr);\n+    }\n+    __ align(32);\n+    aarch64_atomic_xchg_8_impl = (aarch64_atomic_stub_t)__ pc();\n+    {\n+      Register prev = r2, addr = c_rarg0, newv = c_rarg1;\n+      __ atomic_xchgl(prev, newv, addr);\n+      __ mov(r0, prev);\n+      __ ret(lr);\n+    }\n+    __ align(32);\n+    aarch64_atomic_cmpxchg_1_impl = (aarch64_atomic_stub_t)__ pc();\n+    {\n+      Register prev = r3, ptr = c_rarg0, compare_val = c_rarg1,\n+        exchange_val = c_rarg2;\n+      __ cmpxchg(ptr, compare_val, exchange_val,\n+                 MacroAssembler::byte,\n+                 \/*acquire*\/false, \/*release*\/false, \/*weak*\/false,\n+                 prev);\n+      __ movw(r0, prev);\n+      __ ret(lr);\n+    }\n+    __ align(32);\n+    aarch64_atomic_cmpxchg_4_impl = (aarch64_atomic_stub_t)__ pc();\n+    {\n+      Register prev = r3, ptr = c_rarg0, compare_val = c_rarg1,\n+        exchange_val = c_rarg2;\n+      __ cmpxchg(ptr, compare_val, exchange_val,\n+                 MacroAssembler::word,\n+                 \/*acquire*\/false, \/*release*\/false, \/*weak*\/false,\n+                 prev);\n+      __ movw(r0, prev);\n+      __ ret(lr);\n+    }\n+    __ align(32);\n+    aarch64_atomic_cmpxchg_8_impl = (aarch64_atomic_stub_t)__ pc();\n+    {\n+      Register prev = r3, ptr = c_rarg0, compare_val = c_rarg1,\n+        exchange_val = c_rarg2;\n+      __ cmpxchg(ptr, compare_val, exchange_val,\n+                 MacroAssembler::xword,\n+                 \/*acquire*\/false, \/*release*\/false, \/*weak*\/false,\n+                 prev);\n+      __ mov(r0, prev);\n+      __ ret(lr);\n+    }\n+  }\n+#endif \/\/ LINUX\n+\n@@ -6884,0 +6971,8 @@\n+#ifdef LINUX\n+\n+#if 0  \/\/ JDK-8261660: disabled for now.\n+    generate_atomic_entry_points();\n+#endif\n+\n+#endif \/\/ LINUX\n+\n@@ -6904,0 +6999,24 @@\n+\n+\n+#ifdef LINUX\n+\n+\/\/ Define pointers to atomic stubs and initialize them to point to the\n+\/\/ code in atomic_aarch64.S.\n+\n+#define DEFAULT_ATOMIC_OP(OPNAME, SIZE)                                 \\\n+  extern \"C\" uint64_t aarch64_atomic_ ## OPNAME ## _ ## SIZE ## _default_impl \\\n+    (volatile void *ptr, uint64_t arg1, uint64_t arg2);                 \\\n+  aarch64_atomic_stub_t aarch64_atomic_ ## OPNAME ## _ ## SIZE ## _impl \\\n+    = aarch64_atomic_ ## OPNAME ## _ ## SIZE ## _default_impl;\n+\n+DEFAULT_ATOMIC_OP(fetch_add, 4)\n+DEFAULT_ATOMIC_OP(fetch_add, 8)\n+DEFAULT_ATOMIC_OP(xchg, 4)\n+DEFAULT_ATOMIC_OP(xchg, 8)\n+DEFAULT_ATOMIC_OP(cmpxchg, 1)\n+DEFAULT_ATOMIC_OP(cmpxchg, 4)\n+DEFAULT_ATOMIC_OP(cmpxchg, 8)\n+\n+#undef DEFAULT_ATOMIC_OP\n+\n+#endif \/\/ LINUX\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":123,"deletions":4,"binary":false,"changes":127,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+#include \"classfile\/classLoaderData.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -121,3 +121,0 @@\n-    if (ct->scanned_concurrently()) {\n-      __ membar(Assembler::StoreLoad);\n-    }\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/cardTableBarrierSetAssembler_x86.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,0 +33,1 @@\n+#include \"oops\/klass.inline.hpp\"\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -290,1 +290,1 @@\n-  JavaThread* thread = JavaThread::current();\n+  JavaThread* thread = THREAD->as_Java_thread();\n@@ -504,1 +504,1 @@\n-void ClassLoader::setup_bootstrap_search_path() {\n+void ClassLoader::setup_bootstrap_search_path(TRAPS) {\n@@ -513,1 +513,1 @@\n-  setup_boot_search_path(sys_class_path);\n+  setup_bootstrap_search_path_impl(sys_class_path, CHECK);\n@@ -517,1 +517,1 @@\n-void ClassLoader::setup_app_search_path(const char *class_path) {\n+void ClassLoader::setup_app_search_path(const char *class_path, TRAPS) {\n@@ -525,1 +525,1 @@\n-    update_class_path_entry_list(path, false, false, false);\n+    update_class_path_entry_list(path, false, false, false, CHECK);\n@@ -545,1 +545,1 @@\n-void ClassLoader::update_module_path_entry_list(const char *path, TRAPS) {\n+void ClassLoader::setup_module_search_path(const char* path, TRAPS) {\n@@ -565,4 +565,0 @@\n-void ClassLoader::setup_module_search_path(const char* path, TRAPS) {\n-  update_module_path_entry_list(path, THREAD);\n-}\n-\n@@ -635,2 +631,1 @@\n-void ClassLoader::setup_boot_search_path(const char *class_path) {\n-  EXCEPTION_MARK;\n+void ClassLoader::setup_bootstrap_search_path_impl(const char *class_path, TRAPS) {\n@@ -678,1 +673,1 @@\n-      update_class_path_entry_list(path, false, true, false);\n+      update_class_path_entry_list(path, false, true, false, CHECK);\n@@ -725,1 +720,1 @@\n-  JavaThread* thread = JavaThread::current();\n+  JavaThread* thread = THREAD->as_Java_thread();\n@@ -850,1 +845,2 @@\n-                                               bool check_for_duplicates) {\n+                                               bool check_for_duplicates,\n+                                               TRAPS) {\n@@ -874,1 +870,1 @@\n-    ClassLoaderExt::process_jar_manifest(entry, check_for_duplicates);\n+    ClassLoaderExt::process_jar_manifest(entry, check_for_duplicates, CHECK);\n@@ -884,1 +880,1 @@\n-                                               bool throw_exception) {\n+                                               TRAPS) {\n@@ -889,2 +885,1 @@\n-    Thread* THREAD = Thread::current();\n-    new_entry = create_class_path_entry(path, &st, throw_exception, is_boot_append, from_class_path_attr, CHECK_(false));\n+    new_entry = create_class_path_entry(path, &st, \/*throw_exception=*\/true, is_boot_append, from_class_path_attr, CHECK_false);\n@@ -900,1 +895,1 @@\n-      add_to_app_classpath_entries(path, new_entry, check_for_duplicates);\n+      add_to_app_classpath_entries(path, new_entry, check_for_duplicates, CHECK_false);\n@@ -1289,1 +1284,1 @@\n-  result->set_classpath_index(classpath_index, THREAD);\n+  result->set_classpath_index(classpath_index);\n@@ -1424,1 +1419,1 @@\n-  ClassLoaderExt::record_result(classpath_index, ik, THREAD);\n+  ClassLoaderExt::record_result(classpath_index, ik, CHECK);\n@@ -1433,3 +1428,1 @@\n-void ClassLoader::initialize() {\n-  EXCEPTION_MARK;\n-\n+void ClassLoader::initialize(TRAPS) {\n@@ -1467,1 +1460,1 @@\n-  setup_bootstrap_search_path();\n+  setup_bootstrap_search_path(CHECK);\n@@ -1504,1 +1497,1 @@\n-void ClassLoader::initialize_shared_path() {\n+void ClassLoader::initialize_shared_path(TRAPS) {\n@@ -1506,1 +1499,1 @@\n-    ClassLoaderExt::setup_search_paths();\n+    ClassLoaderExt::setup_search_paths(CHECK);\n@@ -1512,2 +1505,2 @@\n-    ClassLoaderExt::setup_module_paths(THREAD);\n-    FileMapInfo::allocate_shared_path_table();\n+    ClassLoaderExt::setup_module_paths(CHECK);\n+    FileMapInfo::allocate_shared_path_table(CHECK);\n@@ -1569,1 +1562,5 @@\n-  ClassLoader::initialize();\n+  EXCEPTION_MARK;\n+  ClassLoader::initialize(THREAD);\n+  if (HAS_PENDING_EXCEPTION) {\n+    vm_exit_during_initialization(\"ClassLoader::initialize() failed unexpectedly\");\n+  }\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":28,"deletions":31,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -115,1 +115,1 @@\n-\/\/ bootstrapsearchpath support: links in a thread before load_instance_class\n+\/\/ bootstrap loader support:  links in a thread before load_instance_class\n@@ -123,0 +123,3 @@\n+  assert(action != PlaceholderTable::LOAD_INSTANCE || seen == NULL,\n+         \"Only one LOAD_INSTANCE allowed at a time\");\n+\n","filename":"src\/hotspot\/share\/classfile\/placeholders.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -125,2 +125,2 @@\n-                                    \/\/ can be multiple threads if classloader object lock broken by application\n-                                    \/\/ or if classloader supports parallel classloading\n+                                    \/\/ This can't be multiple threads since class loading waits for\n+                                    \/\/ this token to be removed.\n","filename":"src\/hotspot\/share\/classfile\/placeholders.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -191,1 +191,1 @@\n-Handle SystemDictionary::compute_loader_lock_object(Handle class_loader) {\n+Handle SystemDictionary::get_loader_lock_or_null(Handle class_loader) {\n@@ -623,5 +623,2 @@\n-\/\/ Note: must call resolve_super_or_fail even if null super -\n-\/\/ to force placeholder entry creation for this class for circularity detection\n-\/\/ Caller must check for pending exception\n-\/\/ and we are done,\n-\/\/ If return null Klass* and no pending exception, the caller must load the class\n+\/\/ and we are done.  If this returns a null Klass* and no pending exception,\n+\/\/ the caller must load the class.\n@@ -637,8 +634,1 @@\n-  \/\/ superk is not used, resolve_super called for circularity check only\n-  \/\/ This code is reached in two situations. One if this thread\n-  \/\/ is loading the same class twice (e.g. ClassCircularity, or\n-  \/\/ java.lang.instrument).\n-  \/\/ The second is if another thread started the resolve_super first\n-  \/\/ and has not yet finished.\n-  \/\/ In both cases the original caller will clean up the placeholder\n-  \/\/ entry on error.\n+  \/\/ superk is not used; resolve_super_or_fail is called for circularity check only.\n@@ -656,1 +646,0 @@\n-    \/\/ Check if classloading completed while we were loading superclass or waiting\n@@ -756,1 +745,1 @@\n-  Handle lockObject = compute_loader_lock_object(class_loader);\n+  Handle lockObject = get_loader_lock_or_null(class_loader);\n@@ -812,4 +801,2 @@\n-    \/\/    These class loaders don't lock the object until load_instance_class is\n-    \/\/    called after this placeholder is added.\n-    \/\/    Allow parallel classloading of a class\/classloader pair where mutual\n-    \/\/    exclusion is provided by this lock in the class loader Java code.\n+    \/\/    These class loaders lock a per-class object lock when ClassLoader.loadClass()\n+    \/\/    is called. A LOAD_INSTANCE placeholder isn't used for mutual exclusion.\n@@ -824,1 +811,1 @@\n-    {\n+    if (class_loader.is_null() || !is_parallelCapable(class_loader)) {\n@@ -826,16 +813,15 @@\n-      if (class_loader.is_null() || !is_parallelCapable(class_loader)) {\n-        PlaceholderEntry* oldprobe = placeholders()->get_entry(name_hash, name, loader_data);\n-        if (oldprobe != NULL) {\n-          \/\/ only need check_seen_thread once, not on each loop\n-          \/\/ 6341374 java\/lang\/Instrument with -Xcomp\n-          if (oldprobe->check_seen_thread(THREAD, PlaceholderTable::LOAD_INSTANCE)) {\n-            throw_circularity_error = true;\n-          } else {\n-            \/\/ case 3: traditional: should never see load_in_progress.\n-            while (!class_has_been_loaded && oldprobe != NULL && oldprobe->instance_load_in_progress()) {\n-\n-              \/\/ case 1: bootstrap classloader: prevent futile classloading,\n-              \/\/ wait on first requestor\n-              if (class_loader.is_null()) {\n-                SystemDictionary_lock->wait();\n-              } else {\n+      PlaceholderEntry* oldprobe = placeholders()->get_entry(name_hash, name, loader_data);\n+      if (oldprobe != NULL) {\n+        \/\/ only need check_seen_thread once, not on each loop\n+        \/\/ 6341374 java\/lang\/Instrument with -Xcomp\n+        if (oldprobe->check_seen_thread(THREAD, PlaceholderTable::LOAD_INSTANCE)) {\n+          throw_circularity_error = true;\n+        } else {\n+          \/\/ case 3: traditional: should never see load_in_progress.\n+          while (!class_has_been_loaded && oldprobe != NULL && oldprobe->instance_load_in_progress()) {\n+\n+            \/\/ case 1: bootstrap classloader: prevent futile classloading,\n+            \/\/ wait on first requestor\n+            if (class_loader.is_null()) {\n+              SystemDictionary_lock->wait();\n+            } else {\n@@ -844,11 +830,8 @@\n-                double_lock_wait(THREAD, lockObject);\n-              }\n-              \/\/ Check if classloading completed while we were waiting\n-              InstanceKlass* check = dictionary->find_class(name_hash, name);\n-              if (check != NULL) {\n-                \/\/ Klass is already loaded, so just return it\n-                loaded_class = check;\n-                class_has_been_loaded = true;\n-              }\n-              \/\/ check if other thread failed to load and cleaned up\n-              oldprobe = placeholders()->get_entry(name_hash, name, loader_data);\n+              double_lock_wait(THREAD, lockObject);\n+            }\n+            \/\/ Check if classloading completed while we were waiting\n+            InstanceKlass* check = dictionary->find_class(name_hash, name);\n+            if (check != NULL) {\n+              \/\/ Klass is already loaded, so just return it\n+              loaded_class = check;\n+              class_has_been_loaded = true;\n@@ -856,0 +839,2 @@\n+            \/\/ check if other thread failed to load and cleaned up\n+            oldprobe = placeholders()->get_entry(name_hash, name, loader_data);\n@@ -860,1 +845,1 @@\n-      \/\/ All cases: add LOAD_INSTANCE while holding the SystemDictionary_lock\n+      \/\/ Add LOAD_INSTANCE while holding the SystemDictionary_lock\n@@ -862,9 +847,3 @@\n-        PlaceholderEntry* newprobe = placeholders()->find_and_add(name_hash, name, loader_data,\n-                                                                  PlaceholderTable::LOAD_INSTANCE, NULL, THREAD);\n-        load_instance_added = true;\n-        \/\/ For class loaders that do not acquire the classloader object lock,\n-        \/\/ if they did not catch another thread holding LOAD_INSTANCE,\n-        \/\/ need a check analogous to the acquire ObjectLocker\/find_class\n-        \/\/ i.e. now that we hold the LOAD_INSTANCE token on loading this class\/CL\n-        \/\/ one final check if the load has already completed\n-        \/\/ class loaders holding the ObjectLock shouldn't find the class here\n+        \/\/ For the bootclass loader, if the thread did not catch another thread holding\n+        \/\/ the LOAD_INSTANCE token, we need to check whether it completed loading\n+        \/\/ while holding the SD_lock.\n@@ -876,0 +855,7 @@\n+        } else {\n+          \/\/ Now we've got the LOAD_INSTANCE token. Threads will wait on loading to complete for this thread.\n+          PlaceholderEntry* newprobe = placeholders()->find_and_add(name_hash, name, loader_data,\n+                                                                    PlaceholderTable::LOAD_INSTANCE,\n+                                                                    NULL,\n+                                                                    THREAD);\n+          load_instance_added = true;\n@@ -882,1 +868,1 @@\n-      assert(!HAS_PENDING_EXCEPTION && load_instance_added == false,\"circularity error cleanup\");\n+      assert(!HAS_PENDING_EXCEPTION && !load_instance_added, \"circularity error cleanup\");\n@@ -1118,1 +1104,1 @@\n-  Handle lockObject = compute_loader_lock_object(class_loader);\n+  Handle lockObject = get_loader_lock_or_null(class_loader);\n@@ -1427,1 +1413,1 @@\n-    Handle lockObject = compute_loader_lock_object(class_loader);\n+    Handle lockObject = get_loader_lock_or_null(class_loader);\n@@ -1452,1 +1438,1 @@\n-    ik->set_classpath_index(path_index, THREAD);\n+    ik->set_classpath_index(path_index);\n@@ -1636,1 +1622,1 @@\n-           compute_loader_lock_object(class_loader)),\n+           get_loader_lock_or_null(class_loader)),\n@@ -1890,11 +1876,0 @@\n-#ifdef ASSERT\n-\/\/ Verify that this placeholder exists since this class is in the middle of loading.\n-void verify_placeholder(Symbol* class_name, ClassLoaderData* loader_data) {\n-  \/\/ Only parallel capable class loaders use placeholder table for define class.\n-  assert_locked_or_safepoint(SystemDictionary_lock);\n-  unsigned int name_hash = placeholders()->compute_hash(class_name);\n-  Symbol* ph_check =  placeholders()->find_entry(name_hash, class_name, loader_data);\n-  assert(ph_check != NULL, \"This placeholder should exist\");\n-}\n-#endif \/\/ ASSERT\n-\n@@ -1940,2 +1915,0 @@\n-    DEBUG_ONLY(if (is_parallelCapable(class_loader)) verify_placeholder(name, loader_data));\n-\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":49,"deletions":76,"binary":false,"changes":125,"status":"modified"},{"patch":"@@ -397,1 +397,1 @@\n-  static Handle compute_loader_lock_object(Handle class_loader);\n+  static Handle get_loader_lock_or_null(Handle class_loader);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"oops\/klass.inline.hpp\"\n","filename":"src\/hotspot\/share\/code\/compiledIC.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -39,0 +39,2 @@\n+#include \"oops\/compiledICHolder.inline.hpp\"\n+#include \"oops\/klass.inline.hpp\"\n","filename":"src\/hotspot\/share\/code\/compiledMethod.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"oops\/klass.inline.hpp\"\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -61,2 +61,0 @@\n-  CardTableBarrierSet* ctbs = barrier_set_cast<CardTableBarrierSet>(BarrierSet::barrier_set());\n-  CardTable* ct = ctbs->card_table();\n@@ -108,4 +106,0 @@\n-    if (ct->scanned_concurrently()) {\n-      kit->insert_mem_bar(Op_MemBarVolatile, oop_store);\n-      __ sync_kit(kit);\n-    }\n@@ -124,6 +118,1 @@\n-  if (!ct->scanned_concurrently()) {\n-    __ store(__ ctrl(), card_adr, zero, T_BYTE, adr_type, MemNode::unordered);\n-  } else {\n-    \/\/ Specialized path for CM store barrier\n-    __ storeCM(__ ctrl(), card_adr, zero, oop_store, adr_idx, T_BYTE, adr_type);\n-  }\n+  __ store(__ ctrl(), card_adr, zero, T_BYTE, adr_type, MemNode::unordered);\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/cardTableBarrierSetC2.cpp","additions":1,"deletions":12,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"interpreter\/abstractInterpreter.hpp\"\n@@ -47,0 +48,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n@@ -78,1 +80,1 @@\n-  char* newtop = ArchiveBuilder::current()->_ro_region->top();\n+  char* newtop = ArchiveBuilder::current()->_ro_region.top();\n@@ -168,5 +170,28 @@\n-ArchiveBuilder::ArchiveBuilder(DumpRegion* mc_region, DumpRegion* rw_region, DumpRegion* ro_region)\n-  : _rw_src_objs(), _ro_src_objs(), _src_obj_table(INITIAL_TABLE_SIZE) {\n-  assert(_current == NULL, \"must be\");\n-  _current = this;\n-\n+ArchiveBuilder::ArchiveBuilder() :\n+  _current_dump_space(NULL),\n+  _buffer_bottom(NULL),\n+  _last_verified_top(NULL),\n+  _num_dump_regions_used(0),\n+  _other_region_used_bytes(0),\n+  _requested_static_archive_bottom(NULL),\n+  _requested_static_archive_top(NULL),\n+  _requested_dynamic_archive_bottom(NULL),\n+  _requested_dynamic_archive_top(NULL),\n+  _mapped_static_archive_bottom(NULL),\n+  _mapped_static_archive_top(NULL),\n+  _buffer_to_requested_delta(0),\n+  _mc_region(\"mc\", MAX_SHARED_DELTA),\n+  _rw_region(\"rw\", MAX_SHARED_DELTA),\n+  _ro_region(\"ro\", MAX_SHARED_DELTA),\n+  _rw_src_objs(),\n+  _ro_src_objs(),\n+  _src_obj_table(INITIAL_TABLE_SIZE),\n+  _num_instance_klasses(0),\n+  _num_obj_array_klasses(0),\n+  _num_type_array_klasses(0),\n+  _total_closed_heap_region_size(0),\n+  _total_open_heap_region_size(0),\n+  _estimated_metaspaceobj_bytes(0),\n+  _estimated_hashtable_bytes(0),\n+  _estimated_trampoline_bytes(0)\n+{\n@@ -177,22 +202,2 @@\n-  _num_instance_klasses = 0;\n-  _num_obj_array_klasses = 0;\n-  _num_type_array_klasses = 0;\n-  _alloc_stats = new (ResourceObj::C_HEAP, mtClassShared) DumpAllocStats;\n-\n-  _mc_region = mc_region;\n-  _rw_region = rw_region;\n-  _ro_region = ro_region;\n-\n-  _num_dump_regions_used = 0;\n-\n-  _estimated_metaspaceobj_bytes = 0;\n-  _estimated_hashtable_bytes = 0;\n-  _estimated_trampoline_bytes = 0;\n-\n-  _requested_static_archive_bottom = NULL;\n-  _requested_static_archive_top = NULL;\n-  _mapped_static_archive_bottom = NULL;\n-  _mapped_static_archive_top = NULL;\n-  _requested_dynamic_archive_bottom = NULL;\n-  _requested_dynamic_archive_top = NULL;\n-  _buffer_to_requested_delta = 0;\n+  assert(_current == NULL, \"must be\");\n+  _current = this;\n@@ -214,1 +219,4 @@\n-  delete _alloc_stats;\n+}\n+\n+bool ArchiveBuilder::is_dumping_full_module_graph() {\n+  return DumpSharedSpaces && MetaspaceShared::use_full_module_graph();\n@@ -270,1 +278,1 @@\n-  if (DumpSharedSpaces && MetaspaceShared::use_full_module_graph()) {\n+  if (is_dumping_full_module_graph()) {\n@@ -344,1 +352,1 @@\n-  _estimated_trampoline_bytes = allocate_method_trampoline_info();\n+  _estimated_trampoline_bytes = collect_method_trampolines();\n@@ -375,1 +383,1 @@\n-  log_info(cds)(\"Reserved output buffer space at    : \" PTR_FORMAT \" [\" SIZE_FORMAT \" bytes]\",\n+  log_info(cds)(\"Reserved output buffer space at \" PTR_FORMAT \" [\" SIZE_FORMAT \" bytes]\",\n@@ -377,1 +385,1 @@\n-  MetaspaceShared::set_shared_rs(rs);\n+  _shared_rs = rs;\n@@ -379,1 +387,0 @@\n-  MetaspaceShared::init_shared_dump_space(_mc_region);\n@@ -382,1 +389,1 @@\n-  _current_dump_space = _mc_region;\n+  _current_dump_space = &_mc_region;\n@@ -385,0 +392,1 @@\n+  _current_dump_space->init(&_shared_rs, &_shared_vs);\n@@ -386,1 +394,1 @@\n-  ArchivePtrMarker::initialize(&_ptrmap, (address*)_mc_region->base(), (address*)_mc_region->top());\n+  ArchivePtrMarker::initialize(&_ptrmap, &_shared_vs);\n@@ -524,0 +532,1 @@\n+  gather_klasses_and_symbols();\n@@ -569,0 +578,25 @@\n+void ArchiveBuilder::start_dump_space(DumpRegion* next) {\n+  address bottom = _last_verified_top;\n+  address top = (address)(current_dump_space()->top());\n+  _other_region_used_bytes += size_t(top - bottom);\n+\n+  current_dump_space()->pack(next);\n+  _current_dump_space = next;\n+  _num_dump_regions_used ++;\n+\n+  _last_verified_top = (address)(current_dump_space()->top());\n+}\n+\n+void ArchiveBuilder::verify_estimate_size(size_t estimate, const char* which) {\n+  address bottom = _last_verified_top;\n+  address top = (address)(current_dump_space()->top());\n+  size_t used = size_t(top - bottom) + _other_region_used_bytes;\n+  int diff = int(estimate) - int(used);\n+\n+  log_info(cds)(\"%s estimate = \" SIZE_FORMAT \" used = \" SIZE_FORMAT \"; diff = %d bytes\", which, estimate, used, diff);\n+  assert(diff >= 0, \"Estimate is too small\");\n+\n+  _last_verified_top = top;\n+  _other_region_used_bytes = 0;\n+}\n+\n@@ -572,1 +606,11 @@\n-  make_shallow_copies(_rw_region, &_rw_src_objs);\n+  start_dump_space(&_rw_region);\n+  make_shallow_copies(&_rw_region, &_rw_src_objs);\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+  if (is_dumping_full_module_graph()) {\n+    \/\/ Archive the ModuleEntry's and PackageEntry's of the 3 built-in loaders\n+    char* start = rw_region()->top();\n+    ClassLoaderDataShared::allocate_archived_tables();\n+    alloc_stats()->record_modules(rw_region()->top() - start, \/*read_only*\/false);\n+  }\n+#endif\n@@ -578,1 +622,11 @@\n-  make_shallow_copies(_ro_region, &_ro_src_objs);\n+\n+  start_dump_space(&_ro_region);\n+  make_shallow_copies(&_ro_region, &_ro_src_objs);\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+  if (is_dumping_full_module_graph()) {\n+    char* start = ro_region()->top();\n+    ClassLoaderDataShared::init_archived_tables();\n+    alloc_stats()->record_modules(ro_region()->top() - start, \/*read_only*\/true);\n+  }\n+#endif\n@@ -623,1 +677,1 @@\n-  _alloc_stats->record(ref->msotype(), int(newtop - oldtop), src_info->read_only());\n+  _alloc_stats.record(ref->msotype(), int(newtop - oldtop), src_info->read_only());\n@@ -841,0 +895,2 @@\n+  ro_region()->pack();\n+\n@@ -1009,3 +1065,3 @@\n-    DumpRegion* mc_region = builder->_mc_region;\n-    DumpRegion* rw_region = builder->_rw_region;\n-    DumpRegion* ro_region = builder->_ro_region;\n+    DumpRegion* mc_region = &builder->_mc_region;\n+    DumpRegion* rw_region = &builder->_rw_region;\n+    DumpRegion* ro_region = &builder->_ro_region;\n@@ -1039,12 +1095,2 @@\n-void ArchiveBuilder::write_cds_map_to_log(FileMapInfo* mapinfo,\n-                                          GrowableArray<MemRegion> *closed_heap_regions,\n-                                          GrowableArray<MemRegion> *open_heap_regions,\n-                                          char* bitmap, size_t bitmap_size_in_bytes) {\n-  if (log_is_enabled(Info, cds, map)) {\n-    CDSMapLogger::write(this, mapinfo, closed_heap_regions, open_heap_regions,\n-                        bitmap, bitmap_size_in_bytes);\n-  }\n-}\n-\n-void ArchiveBuilder::print_stats(int ro_all, int rw_all, int mc_all) {\n-  _alloc_stats->print_stats(ro_all, rw_all, mc_all);\n+void ArchiveBuilder::print_stats() {\n+  _alloc_stats.print_stats(int(_ro_region.used()), int(_rw_region.used()), int(_mc_region.used()));\n@@ -1058,0 +1104,14 @@\n+void ArchiveBuilder::init_mc_region() {\n+  if (DumpSharedSpaces) { \/\/ these are needed only for static archive\n+    \/\/ We don't want any valid object to be at the very bottom of the archive.\n+    \/\/ See ArchivePtrMarker::mark_pointer().\n+    mc_region()->allocate(16);\n+\n+    size_t trampoline_size = SharedRuntime::trampoline_size();\n+    size_t buf_size = (size_t)AbstractInterpreter::number_of_method_entries * trampoline_size;\n+    MetaspaceShared::set_i2i_entry_code_buffers((address)mc_region()->allocate(buf_size));\n+  }\n+\n+  allocate_method_trampolines();\n+}\n+\n@@ -1068,1 +1128,1 @@\n-          (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size()));\n+          (address)mc_region()->allocate(SharedRuntime::trampoline_size()));\n@@ -1070,1 +1130,1 @@\n-         (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size()));\n+         (address)mc_region()->allocate(SharedRuntime::trampoline_size()));\n@@ -1072,1 +1132,1 @@\n-         (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size()));\n+         (address)mc_region()->allocate(SharedRuntime::trampoline_size()));\n@@ -1074,1 +1134,1 @@\n-          (AdapterHandlerEntry**)MetaspaceShared::misc_code_space_alloc(sizeof(AdapterHandlerEntry*)));\n+          (AdapterHandlerEntry**)mc_region()->allocate(sizeof(AdapterHandlerEntry*)));\n@@ -1093,1 +1153,1 @@\n-size_t ArchiveBuilder::allocate_method_trampoline_info() {\n+size_t ArchiveBuilder::collect_method_trampolines() {\n@@ -1150,0 +1210,117 @@\n+void ArchiveBuilder::write_archive(FileMapInfo* mapinfo,\n+                                   GrowableArray<MemRegion>* closed_heap_regions,\n+                                   GrowableArray<MemRegion>* open_heap_regions,\n+                                   GrowableArray<ArchiveHeapOopmapInfo>* closed_heap_oopmaps,\n+                                   GrowableArray<ArchiveHeapOopmapInfo>* open_heap_oopmaps) {\n+  \/\/ Make sure NUM_CDS_REGIONS (exported in cds.h) agrees with\n+  \/\/ MetaspaceShared::n_regions (internal to hotspot).\n+  assert(NUM_CDS_REGIONS == MetaspaceShared::n_regions, \"sanity\");\n+\n+  \/\/ mc contains the trampoline code for method entries, which are patched at run time,\n+  \/\/ so it needs to be read\/write.\n+  write_region(mapinfo, MetaspaceShared::mc, &_mc_region, \/*read_only=*\/false,\/*allow_exec=*\/true);\n+  write_region(mapinfo, MetaspaceShared::rw, &_rw_region, \/*read_only=*\/false,\/*allow_exec=*\/false);\n+  write_region(mapinfo, MetaspaceShared::ro, &_ro_region, \/*read_only=*\/true, \/*allow_exec=*\/false);\n+\n+  size_t bitmap_size_in_bytes;\n+  char* bitmap = mapinfo->write_bitmap_region(ArchivePtrMarker::ptrmap(), closed_heap_oopmaps, open_heap_oopmaps,\n+                                              bitmap_size_in_bytes);\n+\n+  if (closed_heap_regions != NULL) {\n+    _total_closed_heap_region_size = mapinfo->write_archive_heap_regions(\n+                                        closed_heap_regions,\n+                                        closed_heap_oopmaps,\n+                                        MetaspaceShared::first_closed_archive_heap_region,\n+                                        MetaspaceShared::max_closed_archive_heap_region);\n+    _total_open_heap_region_size = mapinfo->write_archive_heap_regions(\n+                                        open_heap_regions,\n+                                        open_heap_oopmaps,\n+                                        MetaspaceShared::first_open_archive_heap_region,\n+                                        MetaspaceShared::max_open_archive_heap_region);\n+  }\n+\n+  print_region_stats(mapinfo, closed_heap_regions, open_heap_regions);\n+\n+  mapinfo->set_requested_base((char*)MetaspaceShared::requested_base_address());\n+  mapinfo->set_header_crc(mapinfo->compute_header_crc());\n+  mapinfo->write_header();\n+  mapinfo->close();\n+\n+  if (log_is_enabled(Info, cds)) {\n+    print_stats();\n+  }\n+\n+  if (log_is_enabled(Info, cds, map)) {\n+    CDSMapLogger::write(this, mapinfo, closed_heap_regions, open_heap_regions,\n+                        bitmap, bitmap_size_in_bytes);\n+  }\n+  FREE_C_HEAP_ARRAY(char, bitmap);\n+}\n+\n+void ArchiveBuilder::write_region(FileMapInfo* mapinfo, int region_idx, DumpRegion* dump_region, bool read_only,  bool allow_exec) {\n+  mapinfo->write_region(region_idx, dump_region->base(), dump_region->used(), read_only, allow_exec);\n+}\n+\n+void ArchiveBuilder::print_region_stats(FileMapInfo *mapinfo,\n+                                        GrowableArray<MemRegion>* closed_heap_regions,\n+                                        GrowableArray<MemRegion>* open_heap_regions) {\n+  \/\/ Print statistics of all the regions\n+  const size_t bitmap_used = mapinfo->space_at(MetaspaceShared::bm)->used();\n+  const size_t bitmap_reserved = mapinfo->space_at(MetaspaceShared::bm)->used_aligned();\n+  const size_t total_reserved = _ro_region.reserved()  + _rw_region.reserved() +\n+                                _mc_region.reserved()  +\n+                                bitmap_reserved +\n+                                _total_closed_heap_region_size +\n+                                _total_open_heap_region_size;\n+  const size_t total_bytes = _ro_region.used()  + _rw_region.used() +\n+                             _mc_region.used()  +\n+                             bitmap_used +\n+                             _total_closed_heap_region_size +\n+                             _total_open_heap_region_size;\n+  const double total_u_perc = percent_of(total_bytes, total_reserved);\n+\n+  _mc_region.print(total_reserved);\n+  _rw_region.print(total_reserved);\n+  _ro_region.print(total_reserved);\n+\n+  print_bitmap_region_stats(bitmap_used, total_reserved);\n+\n+  if (closed_heap_regions != NULL) {\n+    print_heap_region_stats(closed_heap_regions, \"ca\", total_reserved);\n+    print_heap_region_stats(open_heap_regions, \"oa\", total_reserved);\n+  }\n+\n+  log_debug(cds)(\"total    : \" SIZE_FORMAT_W(9) \" [100.0%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [%5.1f%% used]\",\n+                 total_bytes, total_reserved, total_u_perc);\n+}\n+\n+void ArchiveBuilder::print_bitmap_region_stats(size_t size, size_t total_size) {\n+  log_debug(cds)(\"bm  space: \" SIZE_FORMAT_W(9) \" [ %4.1f%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [100.0%% used]\",\n+                 size, size\/double(total_size)*100.0, size);\n+}\n+\n+void ArchiveBuilder::print_heap_region_stats(GrowableArray<MemRegion> *heap_mem,\n+                                             const char *name, size_t total_size) {\n+  int arr_len = heap_mem == NULL ? 0 : heap_mem->length();\n+  for (int i = 0; i < arr_len; i++) {\n+      char* start = (char*)heap_mem->at(i).start();\n+      size_t size = heap_mem->at(i).byte_size();\n+      char* top = start + size;\n+      log_debug(cds)(\"%s%d space: \" SIZE_FORMAT_W(9) \" [ %4.1f%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [100.0%% used] at \" INTPTR_FORMAT,\n+                     name, i, size, size\/double(total_size)*100.0, size, p2i(start));\n+  }\n+}\n+\n+void ArchiveBuilder::report_out_of_space(const char* name, size_t needed_bytes) {\n+  \/\/ This is highly unlikely to happen on 64-bits because we have reserved a 4GB space.\n+  \/\/ On 32-bit we reserve only 256MB so you could run out of space with 100,000 classes\n+  \/\/ or so.\n+  _mc_region.print_out_of_space_msg(name, needed_bytes);\n+  _rw_region.print_out_of_space_msg(name, needed_bytes);\n+  _ro_region.print_out_of_space_msg(name, needed_bytes);\n+\n+  vm_exit_during_initialization(err_msg(\"Unable to allocate from '%s' region\", name),\n+                                \"Please reduce the number of shared classes.\");\n+}\n+\n+\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.cpp","additions":236,"deletions":59,"binary":false,"changes":295,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"memory\/dumpAllocStats.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"oops\/array.hpp\"\n@@ -37,0 +39,1 @@\n+struct ArchiveHeapOopmapInfo;\n@@ -38,1 +41,0 @@\n-class DumpAllocStats;\n@@ -44,0 +46,4 @@\n+\/\/ Metaspace::allocate() requires that all blocks must be aligned with KlassAlignmentInBytes.\n+\/\/ We enforce the same alignment rule in blocks allocated from the shared space.\n+const int SharedSpaceObjectAlignment = KlassAlignmentInBytes;\n+\n@@ -194,3 +200,6 @@\n-  DumpRegion* _mc_region;\n-  DumpRegion* _rw_region;\n-  DumpRegion* _ro_region;\n+  ReservedSpace _shared_rs;\n+  VirtualSpace _shared_vs;\n+\n+  DumpRegion _mc_region;\n+  DumpRegion _rw_region;\n+  DumpRegion _ro_region;\n@@ -210,1 +219,10 @@\n-  DumpAllocStats* _alloc_stats;\n+  DumpAllocStats _alloc_stats;\n+  size_t _total_closed_heap_region_size;\n+  size_t _total_open_heap_region_size;\n+\n+  void print_region_stats(FileMapInfo *map_info,\n+                          GrowableArray<MemRegion>* closed_heap_regions,\n+                          GrowableArray<MemRegion>* open_heap_regions);\n+  void print_bitmap_region_stats(size_t size, size_t total_size);\n+  void print_heap_region_stats(GrowableArray<MemRegion> *heap_mem,\n+                               const char *name, size_t total_size);\n@@ -223,1 +241,1 @@\n-      _oldtop = _current->_ro_region->top();\n+      _oldtop = _current->_ro_region.top();\n@@ -229,0 +247,1 @@\n+  bool is_dumping_full_module_graph();\n@@ -262,0 +281,3 @@\n+  void start_dump_space(DumpRegion* next);\n+  void verify_estimate_size(size_t estimate, const char* which);\n+\n@@ -263,1 +285,0 @@\n-  void set_current_dump_space(DumpRegion* r) { _current_dump_space = r; }\n@@ -325,1 +346,1 @@\n-  ArchiveBuilder(DumpRegion* mc_region, DumpRegion* rw_region, DumpRegion* ro_region);\n+  ArchiveBuilder();\n@@ -337,0 +358,37 @@\n+  DumpRegion* mc_region() { return &_mc_region; }\n+  DumpRegion* rw_region() { return &_rw_region; }\n+  DumpRegion* ro_region() { return &_ro_region; }\n+\n+  static char* mc_region_alloc(size_t num_bytes) {\n+    return current()->mc_region()->allocate(num_bytes);\n+  }\n+  static char* rw_region_alloc(size_t num_bytes) {\n+    return current()->rw_region()->allocate(num_bytes);\n+  }\n+  static char* ro_region_alloc(size_t num_bytes) {\n+    return current()->ro_region()->allocate(num_bytes);\n+  }\n+\n+  template <typename T>\n+  static Array<T>* new_ro_array(int length) {\n+    size_t byte_size = Array<T>::byte_sizeof(length, sizeof(T));\n+    Array<T>* array = (Array<T>*)ro_region_alloc(byte_size);\n+    array->initialize(length);\n+    return array;\n+  }\n+\n+  template <typename T>\n+  static Array<T>* new_rw_array(int length) {\n+    size_t byte_size = Array<T>::byte_sizeof(length, sizeof(T));\n+    Array<T>* array = (Array<T>*)rw_region_alloc(byte_size);\n+    array->initialize(length);\n+    return array;\n+  }\n+\n+  template <typename T>\n+  static size_t ro_array_bytesize(int length) {\n+    size_t byte_size = Array<T>::byte_sizeof(length, sizeof(T));\n+    return align_up(byte_size, SharedSpaceObjectAlignment);\n+  }\n+\n+  void init_mc_region();\n@@ -344,4 +402,7 @@\n-  void write_cds_map_to_log(FileMapInfo* mapinfo,\n-                            GrowableArray<MemRegion> *closed_heap_regions,\n-                            GrowableArray<MemRegion> *open_heap_regions,\n-                            char* bitmap, size_t bitmap_size_in_bytes);\n+  void write_archive(FileMapInfo* mapinfo,\n+                     GrowableArray<MemRegion>* closed_heap_regions,\n+                     GrowableArray<MemRegion>* open_heap_regions,\n+                     GrowableArray<ArchiveHeapOopmapInfo>* closed_heap_oopmaps,\n+                     GrowableArray<ArchiveHeapOopmapInfo>* open_heap_oopmaps);\n+  void write_region(FileMapInfo* mapinfo, int region_idx, DumpRegion* dump_region,\n+                    bool read_only,  bool allow_exec);\n@@ -366,1 +427,9 @@\n-    return current()->_alloc_stats;\n+    return &(current()->_alloc_stats);\n+  }\n+\n+  static CompactHashtableStats* symbol_stats() {\n+    return alloc_stats()->symbol_stats();\n+  }\n+\n+  static CompactHashtableStats* string_stats() {\n+    return alloc_stats()->string_stats();\n@@ -381,1 +450,2 @@\n-  void print_stats(int ro_all, int rw_all, int mc_all);\n+  void print_stats();\n+  void report_out_of_space(const char* name, size_t needed_bytes);\n@@ -384,0 +454,1 @@\n+  size_t collect_method_trampolines();\n@@ -386,1 +457,0 @@\n-  size_t allocate_method_trampoline_info();\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.hpp","additions":85,"deletions":15,"binary":false,"changes":100,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"memory\/archiveBuilder.hpp\"\n@@ -107,1 +108,1 @@\n-      (CppVtableInfo*)MetaspaceShared::misc_code_dump_space()->allocate(CppVtableInfo::byte_size(n));\n+      (CppVtableInfo*)ArchiveBuilder::current()->mc_region()->allocate(CppVtableInfo::byte_size(n));\n@@ -221,1 +222,1 @@\n-  _index = (CppVtableInfo**)MetaspaceShared::misc_code_dump_space()->allocate(vtptrs_bytes);\n+  _index = (CppVtableInfo**)ArchiveBuilder::current()->mc_region()->allocate(vtptrs_bytes);\n","filename":"src\/hotspot\/share\/memory\/cppVtables.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -301,1 +301,1 @@\n-  GrowableArray<Klass*>* klasses = MetaspaceShared::collected_klasses();\n+  GrowableArray<Klass*>* klasses = ArchiveBuilder::current()->klasses();\n@@ -576,1 +576,1 @@\n-      MetaspaceShared::new_ro_array<int>(num_entry_fields);\n+      ArchiveBuilder::new_ro_array<int>(num_entry_fields);\n@@ -587,1 +587,1 @@\n-      MetaspaceShared::new_ro_array<Klass*>(num_subgraphs_klasses);\n+      ArchiveBuilder::new_ro_array<Klass*>(num_subgraphs_klasses);\n@@ -613,1 +613,1 @@\n-        (ArchivedKlassSubGraphInfoRecord*)MetaspaceShared::read_only_space_alloc(sizeof(ArchivedKlassSubGraphInfoRecord));\n+        (ArchivedKlassSubGraphInfoRecord*)ArchiveBuilder::ro_region_alloc(sizeof(ArchivedKlassSubGraphInfoRecord));\n","filename":"src\/hotspot\/share\/memory\/heapShared.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -43,1 +43,0 @@\n-#include \"interpreter\/abstractInterpreter.hpp\"\n@@ -49,1 +48,0 @@\n-#include \"memory\/archiveUtils.inline.hpp\"\n@@ -52,2 +50,1 @@\n-#include \"memory\/dynamicArchive.hpp\"\n-#include \"memory\/heapShared.inline.hpp\"\n+#include \"memory\/heapShared.hpp\"\n@@ -80,1 +77,0 @@\n-#include \"utilities\/hashtable.inline.hpp\"\n@@ -85,2 +81,0 @@\n-ReservedSpace MetaspaceShared::_shared_rs;\n-VirtualSpace MetaspaceShared::_shared_vs;\n@@ -89,1 +83,0 @@\n-MetaspaceSharedStats MetaspaceShared::_stats;\n@@ -110,3 +103,4 @@\n-\/\/ The mc, rw, and ro regions are linearly allocated, starting from\n-\/\/ SharedBaseAddress, in the order of mc->rw->ro. The size of these 3 regions\n-\/\/ are page-aligned, and there's no gap between any consecutive regions.\n+\/\/     bm  - bitmap for relocating the above 7 regions.\n+\/\/\n+\/\/ The mc, rw, and ro regions are linearly allocated, in the order of mc->rw->ro.\n+\/\/ These regions are aligned with MetaspaceShared::reserved_space_alignment().\n@@ -115,4 +109,4 @@\n-\/\/ [1] All classes are loaded in MetaspaceShared::preload_classes(). All metadata are\n-\/\/     temporarily allocated outside of the shared regions. Only the method entry\n-\/\/     trampolines are written into the mc region.\n-\/\/ [2] C++ vtables are copied into the mc region.\n+\/\/ [0] All classes are loaded in MetaspaceShared::preload_classes(). All metadata are\n+\/\/     temporarily allocated outside of the shared regions.\n+\/\/ [1] We enter a safepoint and allocate a buffer for the mc\/rw\/ro regions.\n+\/\/ [2] C++ vtables and method trampolines are copied into the mc region.\n@@ -124,21 +118,2 @@\n-\/\/ The s0\/s1 and oa0\/oa1 regions are populated inside HeapShared::archive_java_heap_objects.\n-\/\/ Their layout is independent of the other 4 regions.\n-\n-static DumpRegion _mc_region(\"mc\"), _ro_region(\"ro\"), _rw_region(\"rw\"), _symbol_region(\"symbols\");\n-static size_t _total_closed_archive_region_size = 0, _total_open_archive_region_size = 0;\n-\n-void MetaspaceShared::init_shared_dump_space(DumpRegion* first_space) {\n-  first_space->init(&_shared_rs, &_shared_vs);\n-}\n-\n-DumpRegion* MetaspaceShared::misc_code_dump_space() {\n-  return &_mc_region;\n-}\n-\n-DumpRegion* MetaspaceShared::read_write_dump_space() {\n-  return &_rw_region;\n-}\n-\n-DumpRegion* MetaspaceShared::read_only_dump_space() {\n-  return &_ro_region;\n-}\n+\/\/ The ca0\/ca1 and oa0\/oa1 regions are populated inside HeapShared::archive_java_heap_objects.\n+\/\/ Their layout is independent of the mc\/rw\/ro regions.\n@@ -146,4 +121,1 @@\n-void MetaspaceShared::pack_dump_space(DumpRegion* current, DumpRegion* next,\n-                                      ReservedSpace* rs) {\n-  current->pack(next);\n-}\n+static DumpRegion _symbol_region(\"symbols\");\n@@ -155,12 +127,0 @@\n-char* MetaspaceShared::misc_code_space_alloc(size_t num_bytes) {\n-  return _mc_region.allocate(num_bytes);\n-}\n-\n-char* MetaspaceShared::read_only_space_alloc(size_t num_bytes) {\n-  return _ro_region.allocate(num_bytes);\n-}\n-\n-char* MetaspaceShared::read_write_space_alloc(size_t num_bytes) {\n-  return _rw_region.allocate(num_bytes);\n-}\n-\n@@ -321,33 +281,0 @@\n-void MetaspaceShared::commit_to(ReservedSpace* rs, VirtualSpace* vs, char* newtop) {\n-  Arguments::assert_is_dumping_archive();\n-  char* base = rs->base();\n-  size_t need_committed_size = newtop - base;\n-  size_t has_committed_size = vs->committed_size();\n-  if (need_committed_size < has_committed_size) {\n-    return;\n-  }\n-\n-  size_t min_bytes = need_committed_size - has_committed_size;\n-  size_t preferred_bytes = 1 * M;\n-  size_t uncommitted = vs->reserved_size() - has_committed_size;\n-\n-  size_t commit =MAX2(min_bytes, preferred_bytes);\n-  commit = MIN2(commit, uncommitted);\n-  assert(commit <= uncommitted, \"sanity\");\n-\n-  bool result = vs->expand_by(commit, false);\n-  if (rs == &_shared_rs) {\n-    ArchivePtrMarker::expand_ptr_end((address*)vs->high());\n-  }\n-\n-  if (!result) {\n-    vm_exit_during_initialization(err_msg(\"Failed to expand shared space to \" SIZE_FORMAT \" bytes\",\n-                                          need_committed_size));\n-  }\n-\n-  assert(rs == &_shared_rs || rs == &_symbol_rs, \"must be\");\n-  const char* which = (rs == &_shared_rs) ? \"shared\" : \"symbol\";\n-  log_debug(cds)(\"Expanding %s spaces by \" SIZE_FORMAT_W(7) \" bytes [total \" SIZE_FORMAT_W(9)  \" bytes ending at %p]\",\n-                 which, commit, vs->actual_committed_size(), vs->high());\n-}\n-\n@@ -400,8 +327,4 @@\n-void MetaspaceShared::init_misc_code_space() {\n-  \/\/ We don't want any valid object to be at the very bottom of the archive.\n-  \/\/ See ArchivePtrMarker::mark_pointer().\n-  MetaspaceShared::misc_code_space_alloc(16);\n-\n-  size_t trampoline_size = SharedRuntime::trampoline_size();\n-  size_t buf_size = (size_t)AbstractInterpreter::number_of_method_entries * trampoline_size;\n-  _i2i_entry_code_buffers = (address)misc_code_space_alloc(buf_size);\n+void MetaspaceShared::set_i2i_entry_code_buffers(address b) {\n+  assert(DumpSharedSpaces, \"must be\");\n+  assert(_i2i_entry_code_buffers == NULL, \"initialize only once\");\n+  _i2i_entry_code_buffers = b;\n@@ -416,8 +339,0 @@\n-\/\/ Global object for holding classes that have been loaded.  Since this\n-\/\/ is run at a safepoint just before exit, this is the entire set of classes.\n-static GrowableArray<Klass*>* _global_klass_objects;\n-\n-GrowableArray<Klass*>* MetaspaceShared::collected_klasses() {\n-  return _global_klass_objects;\n-}\n-\n@@ -464,1 +379,1 @@\n-  void dump_java_heap_objects() NOT_CDS_JAVA_HEAP_RETURN;\n+  void dump_java_heap_objects(GrowableArray<Klass*>* klasses) NOT_CDS_JAVA_HEAP_RETURN;\n@@ -473,4 +388,0 @@\n-  void print_region_stats(FileMapInfo* map_info);\n-  void print_bitmap_region_stats(size_t size, size_t total_size);\n-  void print_heap_region_stats(GrowableArray<MemRegion> *heap_mem,\n-                               const char *name, size_t total_size);\n@@ -493,2 +404,1 @@\n-  StaticArchiveBuilder(DumpRegion* mc_region, DumpRegion* rw_region, DumpRegion* ro_region)\n-    : ArchiveBuilder(mc_region, rw_region, ro_region) {}\n+  StaticArchiveBuilder() : ArchiveBuilder() {}\n@@ -521,2 +431,3 @@\n-  char* start = _ro_region.top();\n-  WriteClosure wc(&_ro_region);\n+  DumpRegion* ro_region = ArchiveBuilder::current()->ro_region();\n+  char* start = ro_region->top();\n+  WriteClosure wc(ro_region);\n@@ -562,5 +473,1 @@\n-  StaticArchiveBuilder builder(&_mc_region, &_rw_region, &_ro_region);\n-  builder.gather_klasses_and_symbols();\n-  builder.reserve_buffer();\n-  _global_klass_objects = builder.klasses();\n-\n+  StaticArchiveBuilder builder;\n@@ -568,0 +475,1 @@\n+  builder.reserve_buffer();\n@@ -569,4 +477,1 @@\n-  MetaspaceShared::init_misc_code_space();\n-  builder.allocate_method_trampoline_info();\n-  builder.allocate_method_trampolines();\n-\n+  builder.init_mc_region();\n@@ -575,25 +480,2 @@\n-  {\n-    _mc_region.pack(&_rw_region);\n-    builder.set_current_dump_space(&_rw_region);\n-    builder.dump_rw_region();\n-#if INCLUDE_CDS_JAVA_HEAP\n-    if (MetaspaceShared::use_full_module_graph()) {\n-      \/\/ Archive the ModuleEntry's and PackageEntry's of the 3 built-in loaders\n-      char* start = _rw_region.top();\n-      ClassLoaderDataShared::allocate_archived_tables();\n-      ArchiveBuilder::alloc_stats()->record_modules(_rw_region.top() - start, \/*read_only*\/false);\n-    }\n-#endif\n-  }\n-  {\n-    _rw_region.pack(&_ro_region);\n-    builder.set_current_dump_space(&_ro_region);\n-    builder.dump_ro_region();\n-#if INCLUDE_CDS_JAVA_HEAP\n-    if (MetaspaceShared::use_full_module_graph()) {\n-      char* start = _ro_region.top();\n-      ClassLoaderDataShared::init_archived_tables();\n-      ArchiveBuilder::alloc_stats()->record_modules(_ro_region.top() - start, \/*read_only*\/true);\n-    }\n-#endif\n-  }\n+  builder.dump_rw_region();\n+  builder.dump_ro_region();\n@@ -605,1 +487,1 @@\n-  dump_java_heap_objects();\n+  dump_java_heap_objects(builder.klasses());\n@@ -619,1 +501,0 @@\n-  _ro_region.pack();\n@@ -631,2 +512,1 @@\n-  \/\/ Create and write the archive file that maps the shared spaces.\n-\n+  \/\/ Write the archive file\n@@ -639,28 +519,5 @@\n-  size_t bitmap_size_in_bytes;\n-  char* bitmap = MetaspaceShared::write_core_archive_regions(mapinfo, _closed_archive_heap_oopmaps,\n-                                                             _open_archive_heap_oopmaps,\n-                                                             bitmap_size_in_bytes);\n-  _total_closed_archive_region_size = mapinfo->write_archive_heap_regions(\n-                                        _closed_archive_heap_regions,\n-                                        _closed_archive_heap_oopmaps,\n-                                        MetaspaceShared::first_closed_archive_heap_region,\n-                                        MetaspaceShared::max_closed_archive_heap_region);\n-  _total_open_archive_region_size = mapinfo->write_archive_heap_regions(\n-                                        _open_archive_heap_regions,\n-                                        _open_archive_heap_oopmaps,\n-                                        MetaspaceShared::first_open_archive_heap_region,\n-                                        MetaspaceShared::max_open_archive_heap_region);\n-\n-  mapinfo->set_requested_base((char*)MetaspaceShared::requested_base_address());\n-  mapinfo->set_header_crc(mapinfo->compute_header_crc());\n-  mapinfo->write_header();\n-  print_region_stats(mapinfo);\n-  mapinfo->close();\n-\n-  builder.write_cds_map_to_log(mapinfo, _closed_archive_heap_regions, _open_archive_heap_regions,\n-                               bitmap, bitmap_size_in_bytes);\n-  FREE_C_HEAP_ARRAY(char, bitmap);\n-\n-  if (log_is_enabled(Info, cds)) {\n-    builder.print_stats(int(_ro_region.used()), int(_rw_region.used()), int(_mc_region.used()));\n-  }\n+  builder.write_archive(mapinfo,\n+                        _closed_archive_heap_regions,\n+                        _open_archive_heap_regions,\n+                        _closed_archive_heap_oopmaps,\n+                        _open_archive_heap_oopmaps);\n@@ -683,67 +540,0 @@\n-void VM_PopulateDumpSharedSpace::print_region_stats(FileMapInfo *map_info) {\n-  \/\/ Print statistics of all the regions\n-  const size_t bitmap_used = map_info->space_at(MetaspaceShared::bm)->used();\n-  const size_t bitmap_reserved = map_info->space_at(MetaspaceShared::bm)->used_aligned();\n-  const size_t total_reserved = _ro_region.reserved()  + _rw_region.reserved() +\n-                                _mc_region.reserved()  +\n-                                bitmap_reserved +\n-                                _total_closed_archive_region_size +\n-                                _total_open_archive_region_size;\n-  const size_t total_bytes = _ro_region.used()  + _rw_region.used() +\n-                             _mc_region.used()  +\n-                             bitmap_used +\n-                             _total_closed_archive_region_size +\n-                             _total_open_archive_region_size;\n-  const double total_u_perc = percent_of(total_bytes, total_reserved);\n-\n-  _mc_region.print(total_reserved);\n-  _rw_region.print(total_reserved);\n-  _ro_region.print(total_reserved);\n-  print_bitmap_region_stats(bitmap_used, total_reserved);\n-  print_heap_region_stats(_closed_archive_heap_regions, \"ca\", total_reserved);\n-  print_heap_region_stats(_open_archive_heap_regions, \"oa\", total_reserved);\n-\n-  log_debug(cds)(\"total    : \" SIZE_FORMAT_W(9) \" [100.0%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [%5.1f%% used]\",\n-                 total_bytes, total_reserved, total_u_perc);\n-}\n-\n-void VM_PopulateDumpSharedSpace::print_bitmap_region_stats(size_t size, size_t total_size) {\n-  log_debug(cds)(\"bm  space: \" SIZE_FORMAT_W(9) \" [ %4.1f%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [100.0%% used]\",\n-                 size, size\/double(total_size)*100.0, size);\n-}\n-\n-void VM_PopulateDumpSharedSpace::print_heap_region_stats(GrowableArray<MemRegion> *heap_mem,\n-                                                         const char *name, size_t total_size) {\n-  int arr_len = heap_mem == NULL ? 0 : heap_mem->length();\n-  for (int i = 0; i < arr_len; i++) {\n-      char* start = (char*)heap_mem->at(i).start();\n-      size_t size = heap_mem->at(i).byte_size();\n-      char* top = start + size;\n-      log_debug(cds)(\"%s%d space: \" SIZE_FORMAT_W(9) \" [ %4.1f%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [100.0%% used] at \" INTPTR_FORMAT,\n-                     name, i, size, size\/double(total_size)*100.0, size, p2i(start));\n-\n-  }\n-}\n-\n-char* MetaspaceShared::write_core_archive_regions(FileMapInfo* mapinfo,\n-                                                  GrowableArray<ArchiveHeapOopmapInfo>* closed_oopmaps,\n-                                                  GrowableArray<ArchiveHeapOopmapInfo>* open_oopmaps,\n-                                                  size_t& bitmap_size_in_bytes) {\n-  \/\/ Make sure NUM_CDS_REGIONS (exported in cds.h) agrees with\n-  \/\/ MetaspaceShared::n_regions (internal to hotspot).\n-  assert(NUM_CDS_REGIONS == MetaspaceShared::n_regions, \"sanity\");\n-\n-  \/\/ mc contains the trampoline code for method entries, which are patched at run time,\n-  \/\/ so it needs to be read\/write.\n-  write_region(mapinfo, mc, &_mc_region, \/*read_only=*\/false,\/*allow_exec=*\/true);\n-  write_region(mapinfo, rw, &_rw_region, \/*read_only=*\/false,\/*allow_exec=*\/false);\n-  write_region(mapinfo, ro, &_ro_region, \/*read_only=*\/true, \/*allow_exec=*\/false);\n-\n-  return mapinfo->write_bitmap_region(ArchivePtrMarker::ptrmap(), closed_oopmaps, open_oopmaps,\n-                                      bitmap_size_in_bytes);\n-}\n-\n-void MetaspaceShared::write_region(FileMapInfo* mapinfo, int region_idx, DumpRegion* dump_region, bool read_only,  bool allow_exec) {\n-  mapinfo->write_region(region_idx, dump_region->base(), dump_region->used(), read_only, allow_exec);\n-}\n-\n@@ -821,0 +611,1 @@\n+  Arguments::assert_is_dumping_archive();\n@@ -822,1 +613,7 @@\n-  ClassLoader::initialize_shared_path();\n+\n+  EXCEPTION_MARK;\n+  ClassLoader::initialize_shared_path(THREAD);\n+  if (HAS_PENDING_EXCEPTION) {\n+    java_lang_Throwable::print(PENDING_EXCEPTION, tty);\n+    vm_exit_during_initialization(\"ClassLoader::initialize_shared_path() failed unexpectedly\");\n+  }\n@@ -985,1 +782,1 @@\n-void VM_PopulateDumpSharedSpace::dump_java_heap_objects() {\n+void VM_PopulateDumpSharedSpace::dump_java_heap_objects(GrowableArray<Klass*>* klasses) {\n@@ -997,2 +794,2 @@\n-  for (i = 0; i < _global_klass_objects->length(); i++) {\n-    Klass* k = _global_klass_objects->at(i);\n+  for (i = 0; i < klasses->length(); i++) {\n+    Klass* k = klasses->at(i);\n@@ -1638,12 +1435,0 @@\n-void MetaspaceShared::report_out_of_space(const char* name, size_t needed_bytes) {\n-  \/\/ This is highly unlikely to happen on 64-bits because we have reserved a 4GB space.\n-  \/\/ On 32-bit we reserve only 256MB so you could run out of space with 100,000 classes\n-  \/\/ or so.\n-  _mc_region.print_out_of_space_msg(name, needed_bytes);\n-  _rw_region.print_out_of_space_msg(name, needed_bytes);\n-  _ro_region.print_out_of_space_msg(name, needed_bytes);\n-\n-  vm_exit_during_initialization(err_msg(\"Unable to allocate from '%s' region\", name),\n-                                \"Please reduce the number of shared classes.\");\n-}\n-\n@@ -1667,1 +1452,1 @@\n-  if (UseSharedSpaces || DumpSharedSpaces) {\n+  if (UseSharedSpaces) {\n@@ -1669,12 +1454,4 @@\n-    address base;\n-    address top;\n-    if (UseSharedSpaces) { \/\/ Runtime\n-      base = (address)MetaspaceObj::shared_metaspace_base();\n-      address static_top = (address)_shared_metaspace_static_top;\n-      top = (address)MetaspaceObj::shared_metaspace_top();\n-      st->print(\"[\" PTR_FORMAT \"-\" PTR_FORMAT \"-\" PTR_FORMAT \"), \", p2i(base), p2i(static_top), p2i(top));\n-    } else if (DumpSharedSpaces) { \/\/ Dump Time\n-      base = (address)_shared_rs.base();\n-      top = (address)_shared_rs.end();\n-      st->print(\"[\" PTR_FORMAT \"-\" PTR_FORMAT \"), \", p2i(base), p2i(top));\n-    }\n+    address base = (address)MetaspaceObj::shared_metaspace_base();\n+    address static_top = (address)_shared_metaspace_static_top;\n+    address top = (address)MetaspaceObj::shared_metaspace_top();\n+    st->print(\"[\" PTR_FORMAT \"-\" PTR_FORMAT \"-\" PTR_FORMAT \"), \", p2i(base), p2i(static_top), p2i(top));\n@@ -1684,1 +1461,1 @@\n-    st->print(\"CDS disabled.\");\n+    st->print(\"CDS archive(s) not mapped\");\n","filename":"src\/hotspot\/share\/memory\/metaspaceShared.cpp","additions":50,"deletions":273,"binary":false,"changes":323,"status":"modified"},{"patch":"@@ -42,1 +42,0 @@\n-#include \"memory\/metaspaceShared.hpp\"\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -39,1 +39,0 @@\n-#include \"memory\/metaspaceShared.hpp\"\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"runtime\/handles.hpp\"\n","filename":"src\/hotspot\/share\/oops\/flatArrayOop.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3096,1 +3096,1 @@\n-void InstanceKlass::set_classpath_index(s2 path_index, TRAPS) {\n+void InstanceKlass::set_classpath_index(s2 path_index) {\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-#include \"classfile\/classLoaderData.hpp\"\n@@ -632,1 +631,1 @@\n-  void set_classpath_index(s2 path_index, TRAPS);\n+  void set_classpath_index(s2 path_index);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-#include \"memory\/metaspaceShared.hpp\"\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-#include \"classfile\/classLoaderData.hpp\"\n@@ -71,0 +70,1 @@\n+class ClassLoaderData;\n@@ -531,5 +531,1 @@\n-  \/\/ This loads the klass's holder as a phantom. This is useful when a weak Klass\n-  \/\/ pointer has been \"peeked\" and then must be kept alive before it may\n-  \/\/ be used safely.  All uses of klass_holder need to apply the appropriate barriers,\n-  \/\/ except during GC.\n-  oop klass_holder() const { return class_loader_data()->holder_phantom(); }\n+  inline oop klass_holder() const;\n@@ -670,2 +666,0 @@\n-  bool is_non_strong_hidden() const     { return access_flags().is_hidden_class() &&\n-                                          class_loader_data()->has_class_mirror_holder(); }\n@@ -675,0 +669,2 @@\n+  inline bool is_non_strong_hidden() const;\n+\n@@ -710,4 +706,1 @@\n-  \/\/ Iff the class loader (or mirror for unsafe anonymous classes) is alive the\n-  \/\/ Klass is considered alive. This is safe to call before the CLD is marked as\n-  \/\/ unloading, and hence during concurrent class unloading.\n-  bool is_loader_alive() const { return class_loader_data()->is_alive(); }\n+  inline bool is_loader_alive() const;\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":6,"deletions":13,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,20 @@\n+\/\/ This loads the klass's holder as a phantom. This is useful when a weak Klass\n+\/\/ pointer has been \"peeked\" and then must be kept alive before it may\n+\/\/ be used safely.  All uses of klass_holder need to apply the appropriate barriers,\n+\/\/ except during GC.\n+inline oop Klass::klass_holder() const {\n+  return class_loader_data()->holder_phantom();\n+}\n+\n+inline bool Klass::is_non_strong_hidden() const {\n+  return access_flags().is_hidden_class() &&\n+         class_loader_data()->has_class_mirror_holder();\n+}\n+\n+\/\/ Iff the class loader (or mirror for unsafe anonymous classes) is alive the\n+\/\/ Klass is considered alive. This is safe to call before the CLD is marked as\n+\/\/ unloading, and hence during concurrent class unloading.\n+inline bool Klass::is_loader_alive() const {\n+  return class_loader_data()->is_alive();\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/klass.inline.hpp","additions":21,"deletions":1,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"oops\/klass.inline.hpp\"\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,0 +33,1 @@\n+#include \"runtime\/mutex.hpp\"\n","filename":"src\/hotspot\/share\/oops\/methodData.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-#include \"classfile\/classLoaderData.hpp\"\n@@ -32,0 +31,2 @@\n+class ClassLoaderData;\n+\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -52,0 +52,1 @@\n+#include \"oops\/klass.inline.hpp\"\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -1188,0 +1188,67 @@\n+\/\/------------------------------category---------------------------------------\n+#ifndef PRODUCT\n+Type::Category Type::category() const {\n+  const TypeTuple* tuple;\n+  switch (base()) {\n+    case Type::Int:\n+    case Type::Long:\n+    case Type::Half:\n+    case Type::NarrowOop:\n+    case Type::NarrowKlass:\n+    case Type::Array:\n+    case Type::VectorA:\n+    case Type::VectorS:\n+    case Type::VectorD:\n+    case Type::VectorX:\n+    case Type::VectorY:\n+    case Type::VectorZ:\n+    case Type::AnyPtr:\n+    case Type::RawPtr:\n+    case Type::OopPtr:\n+    case Type::InstPtr:\n+    case Type::AryPtr:\n+    case Type::MetadataPtr:\n+    case Type::KlassPtr:\n+    case Type::Function:\n+    case Type::Return_Address:\n+    case Type::FloatTop:\n+    case Type::FloatCon:\n+    case Type::FloatBot:\n+    case Type::DoubleTop:\n+    case Type::DoubleCon:\n+    case Type::DoubleBot:\n+      return Category::Data;\n+    case Type::Memory:\n+      return Category::Memory;\n+    case Type::Control:\n+      return Category::Control;\n+    case Type::Top:\n+    case Type::Abio:\n+    case Type::Bottom:\n+      return Category::Other;\n+    case Type::Bad:\n+    case Type::lastype:\n+      return Category::Undef;\n+    case Type::Tuple:\n+      \/\/ Recursive case. Return CatMixed if the tuple contains types of\n+      \/\/ different categories (e.g. CallStaticJavaNode's type), or the specific\n+      \/\/ category if all types are of the same category (e.g. IfNode's type).\n+      tuple = is_tuple();\n+      if (tuple->cnt() == 0) {\n+        return Category::Undef;\n+      } else {\n+        Category first = tuple->field_at(0)->category();\n+        for (uint i = 1; i < tuple->cnt(); i++) {\n+          if (tuple->field_at(i)->category() != first) {\n+            return Category::Mixed;\n+          }\n+        }\n+        return first;\n+      }\n+    default:\n+      assert(false, \"unmatched base type: all base types must be categorized\");\n+  }\n+  return Category::Undef;\n+}\n+#endif\n+\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":68,"deletions":1,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -397,0 +397,11 @@\n+  \/\/ Groups of types, for debugging and visualization only.\n+  enum class Category {\n+    Data,\n+    Memory,\n+    Mixed,   \/\/ Tuples with types of different categories.\n+    Control,\n+    Other,   \/\/ {Type::Top, Type::Abio, Type::Bottom}.\n+    Undef    \/\/ {Type::Bad, Type::lastype}, for completeness.\n+  };\n+  \/\/ Return the category of this type.\n+  Category category() const;\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"classfile\/classLoader.hpp\"\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3359,2 +3359,2 @@\n-    vfst.skip_reflection_related_frames(); \/\/ Only needed for 1.4 reflection\n-    oop loader = vfst.method()->method_holder()->class_loader();\n+    InstanceKlass* ik = vfst.method()->method_holder();\n+    oop loader = ik->class_loader();\n@@ -3362,1 +3362,5 @@\n-      return JNIHandles::make_local(THREAD, loader);\n+      \/\/ Skip reflection related frames\n+      if (!ik->is_subclass_of(vmClasses::reflect_MethodAccessorImpl_klass()) &&\n+          !ik->is_subclass_of(vmClasses::reflect_ConstructorAccessorImpl_klass())) {\n+        return JNIHandles::make_local(THREAD, loader);\n+      }\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"oops\/klass.inline.hpp\"\n","filename":"src\/hotspot\/share\/prims\/jvmtiImpl.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2552,0 +2552,1 @@\n+  HandleMark hm(thread);\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -594,1 +594,1 @@\n-    _subtasks.all_tasks_completed(_num_workers);\n+    _subtasks.all_tasks_claimed();\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -48,1 +48,0 @@\n-#include \"memory\/metaspaceShared.hpp\"\n@@ -54,0 +53,1 @@\n+#include \"oops\/compiledICHolder.inline.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"memory\/metaspaceShared.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3365,0 +3365,4 @@\n+  if (HAS_PENDING_EXCEPTION) {\n+    java_lang_Throwable::print(PENDING_EXCEPTION, tty);\n+    vm_exit_during_initialization(\"ClassLoader::initialize_module_path() failed unexpectedly\");\n+  }\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -277,6 +277,0 @@\n-  \/\/ Stack watermark barriers.\n-  StackWatermarks _stack_watermarks;\n-\n- public:\n-  inline StackWatermarks* stack_watermarks() { return &_stack_watermarks; }\n-\n@@ -1067,0 +1061,5 @@\n+  \/\/ Stack watermark barriers.\n+  StackWatermarks _stack_watermarks;\n+\n+ public:\n+  inline StackWatermarks* stack_watermarks() { return &_stack_watermarks; }\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":5,"deletions":6,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -96,1 +96,0 @@\n-    private final Source source;\n@@ -99,2 +98,0 @@\n-    private final Name classDollar;\n-    private final Name dollarCloseResource;\n@@ -118,1 +115,0 @@\n-        source = Source.instance(context);\n@@ -122,4 +118,0 @@\n-        classDollar = names.\n-            fromString(\"class\" + target.syntheticNameChar());\n-        dollarCloseResource = names.\n-            fromString(target.syntheticNameChar() + \"closeResource\");\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Lower.java","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -612,1 +612,2 @@\n-        return (isPackagePrivate(enclosingTypeElement) || isPrivate(enclosingTypeElement))\n+        return (isPackagePrivate(enclosingTypeElement) || isPrivate(enclosingTypeElement)\n+                    || hasHiddenTag(enclosingTypeElement))\n@@ -1160,2 +1161,3 @@\n-            (typeElem != null &&\n-                (isIncluded(typeElem) && configuration.isGeneratedDoc(typeElem))) ||\n+            typeElem != null &&\n+            ((isIncluded(typeElem) && configuration.isGeneratedDoc(typeElem) &&\n+                    !hasHiddenTag(typeElem)) ||\n@@ -1163,1 +1165,1 @@\n-                (isPublic(typeElem) || isProtected(typeElem)));\n+                    (isPublic(typeElem) || isProtected(typeElem))));\n@@ -1186,1 +1188,1 @@\n-        if (isIncluded(elem)) {\n+        if (isIncluded(elem) && !hasHiddenTag(elem)) {\n@@ -1556,1 +1558,1 @@\n-     * Returns true if the element is included, contains &#64;hidden tag,\n+     * Returns true if the element is included or selected, contains &#64;hidden tag,\n@@ -1563,1 +1565,2 @@\n-        \/\/ prevent needless tests on elements which are not included\n+        \/\/ Non-included elements may still be visible via \"transclusion\" from undocumented enclosures,\n+        \/\/ but we don't want to run doclint on them, possibly causing warnings or errors.\n@@ -1565,1 +1568,1 @@\n-            return false;\n+            return hasBlockTagUnchecked(e, HIDDEN);\n@@ -2268,1 +2271,1 @@\n-        if (e.getKind() == ElementKind.PACKAGE)\n+        if (isPackage(e) || isModule(e)) {\n@@ -2270,0 +2273,1 @@\n+        }\n@@ -2271,2 +2275,1 @@\n-        ElementKind kind = encl.getKind();\n-        if (kind == ElementKind.PACKAGE)\n+        if (isPackage(encl)) {\n@@ -2274,0 +2277,2 @@\n+        }\n+        ElementKind kind = encl.getKind();\n@@ -2594,1 +2599,4 @@\n-        DocCommentTree dcTree = getDocCommentTree(element);\n+        return getBlockTags(getDocCommentTree(element));\n+    }\n+\n+    public List<? extends DocTree> getBlockTags(DocCommentTree dcTree) {\n@@ -2644,4 +2652,18 @@\n-            String tname = tagName != null && tagName.startsWith(\"@\")\n-                    ? tagName.substring(1)\n-                    : tagName;\n-            for (DocTree dt : getBlockTags(element, kind)) {\n+            for (DocTree dt : getBlockTags(ch.dcTree)) {\n+                if (dt.getKind() == kind && (tagName == null || ch.getTagName(dt).equals(tagName))) {\n+                    return true;\n+                }\n+            }\n+        }\n+        return false;\n+    }\n+\n+    \/*\n+     * Tests whether an element's doc comment contains a block tag without caching it or\n+     * running doclint on it. This is done by using getDocCommentInfo(Element) to retrieve\n+     * the doc comment info.\n+     *\/\n+    boolean hasBlockTagUnchecked(Element element, DocTree.Kind kind) {\n+        DocCommentInfo dcInfo = getDocCommentInfo(element);\n+        if (dcInfo != null && dcInfo.dcTree != null) {\n+            for (DocTree dt : getBlockTags(dcInfo.dcTree)) {\n@@ -2649,3 +2671,1 @@\n-                    if (tname == null || ch.getTagName(dt).equals(tname)) {\n-                        return true;\n-                    }\n+                    return true;\n@@ -2704,1 +2724,1 @@\n-     * @param element\n+     * @param element the element\n@@ -2762,1 +2782,1 @@\n-        if (element.getKind() != ElementKind.OTHER) {\n+        if (!isOverviewElement(element)) {\n","filename":"src\/jdk.javadoc\/share\/classes\/jdk\/javadoc\/internal\/doclets\/toolkit\/util\/Utils.java","additions":41,"deletions":21,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -165,0 +165,1 @@\n+runtime\/NMT\/CheckForProperDetailStackTrace.java 8261520 generic-all\n@@ -200,1 +201,0 @@\n-serviceability\/attach\/RemovingUnixDomainSocketTest.java 8248162 linux-x64\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}