{"files":[{"patch":"@@ -1931,6 +1931,0 @@\n-uint MachPrologNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n@@ -1986,5 +1980,0 @@\n-uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {\n-  \/\/ Variable size. Determine dynamically.\n-  return MachNode::size(ra_);\n-}\n-\n@@ -2300,1 +2289,3 @@\n-    __ unpack_inline_args(ra_->C, _receiver_only);\n+    int sp_inc = __ unpack_inline_args(ra_->C, _receiver_only);\n+    \/\/ Emit code for verified entry and save increment for stack repair on return\n+    __ verified_entry(ra_->C, sp_inc);\n@@ -2305,7 +2296,0 @@\n-\n-uint MachVEPNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it the hard way\n-}\n-\n-\n@@ -2346,5 +2330,0 @@\n-uint MachUEPNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_);\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":3,"deletions":24,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -421,2 +421,0 @@\n-  int extra_stack_offset = wordSize; \/\/ tos is return address.\n-\n@@ -454,3 +452,3 @@\n-  int n = shuffle_inline_args(true, is_inline_ro_entry, extra_stack_offset, sig_bt, sig_cc,\n-                              args_passed_cc, args_on_stack_cc, regs_cc, \/\/ from\n-                              args_passed, args_on_stack, regs);         \/\/ to\n+  int n = shuffle_inline_args(true, is_inline_ro_entry, sig_cc,\n+                              args_passed_cc, regs_cc,            \/\/ from\n+                              args_passed, args_on_stack, regs);  \/\/ to\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -5442,1 +5442,1 @@\n-bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {\n+bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]) {\n@@ -5455,1 +5455,1 @@\n-        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n@@ -5469,1 +5469,1 @@\n-      Address from_addr = Address(sp, from->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset);\n+      Address from_addr = Address(sp, from->reg2stack() * VMRegImpl::stack_slot_size + wordSize);\n@@ -5482,1 +5482,1 @@\n-        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n@@ -5497,1 +5497,1 @@\n-                                          int& to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {\n+                                          int& to_index, RegState reg_state[]) {\n@@ -5514,2 +5514,0 @@\n-    } else if (SigEntry::is_reserved_entry(sig, sig_index)) {\n-      to_index--; \/\/ Ignore this\n@@ -5538,1 +5536,1 @@\n-        int st_off = from->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n+        int st_off = from->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n@@ -5560,1 +5558,1 @@\n-          int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n+          int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n@@ -5585,2 +5583,1 @@\n-                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],\n-                                        int ret_off, int extra_stack_offset) {\n+                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[]) {\n@@ -5614,1 +5611,1 @@\n-  ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n+  ScalarizedInlineArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n@@ -5619,1 +5616,1 @@\n-    int off = sig->at(stream.sig_cc_index())._offset;\n+    int off = sig->at(stream.sig_index())._offset;\n@@ -5634,1 +5631,1 @@\n-        int ld_off = from_r1->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n+        int ld_off = from_r1->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n@@ -5656,2 +5653,2 @@\n-  sig_index = stream.sig_cc_index();\n-  from_index = stream.regs_cc_index();\n+  sig_index = stream.sig_index();\n+  from_index = stream.regs_index();\n@@ -5660,1 +5657,1 @@\n-  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);\n+  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state);\n@@ -5666,47 +5663,0 @@\n-\/\/ Unpack all inline type arguments passed as oops\n-void MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {\n-  int sp_inc = unpack_inline_args_common(C, receiver_only);\n-  \/\/ Emit code for verified entry and save increment for stack repair on return\n-  verified_entry(C, sp_inc);\n-}\n-\n-int MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,\n-                                        BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,\n-                                        int args_passed, int args_on_stack, VMRegPair* regs,            \/\/ from\n-                                        int args_passed_to, int args_on_stack_to, VMRegPair* regs_to) { \/\/ to\n-  \/\/ Check if we need to extend the stack for packing\/unpacking\n-  int sp_inc = (args_on_stack_to - args_on_stack) * VMRegImpl::stack_slot_size;\n-  if (sp_inc > 0) {\n-    sp_inc = align_up(sp_inc, StackAlignmentInBytes);\n-    if (!is_packing) {\n-      \/\/ Save the return address, adjust the stack (make sure it is properly\n-      \/\/ 16-byte aligned) and copy the return address to the new top of the stack.\n-      \/\/ (Note: C1 does this in C1_MacroAssembler::scalarized_entry).\n-      \/\/ FIXME: We need not to preserve return address on aarch64\n-      pop(rscratch1);\n-      sub(sp, sp, sp_inc);\n-      push(rscratch1);\n-    }\n-  } else {\n-    \/\/ The scalarized calling convention needs less stack space than the unscalarized one.\n-    \/\/ No need to extend the stack, the caller will take care of these adjustments.\n-    sp_inc = 0;\n-  }\n-\n-  int ret_off; \/\/ make sure we don't overwrite the return address\n-  if (is_packing) {\n-    \/\/ For C1 code, the VIEP doesn't have reserved slots, so we store the returned address at\n-    \/\/ rsp[0] during shuffling.\n-    ret_off = 0;\n-  } else {\n-    \/\/ C2 code ensures that sp_inc is a reserved slot.\n-    ret_off = sp_inc;\n-  }\n-\n-  return shuffle_inline_args_common(is_packing, receiver_only, extra_stack_offset,\n-                                    sig_bt, sig_cc,\n-                                    args_passed, args_on_stack, regs,\n-                                    args_passed_to, args_on_stack_to, regs_to,\n-                                    sp_inc, ret_off);\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":14,"deletions":64,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -1194,7 +1194,0 @@\n-\n-  enum RegState {\n-     reg_readonly,\n-     reg_writable,\n-     reg_written\n-  };\n-\n@@ -1203,1 +1196,2 @@\n-  int store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter = true);\n+  \/\/ Inline type specific methods\n+  #include \"asm\/macroAssembler_common.hpp\"\n@@ -1205,3 +1199,2 @@\n-\/\/ Unpack all inline type arguments passed as oops\n-  void unpack_inline_args(Compile* C, bool receiver_only);\n-  bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset);\n+  int store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter = true);\n+  bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]);\n@@ -1209,1 +1202,1 @@\n-                            RegState reg_state[], int ret_off, int extra_stack_offset);\n+                            RegState reg_state[]);\n@@ -1211,2 +1204,1 @@\n-                          VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],\n-                          int ret_off, int extra_stack_offset);\n+                          VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[]);\n@@ -1214,8 +1206,0 @@\n-\n-  int shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,\n-                          BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,\n-                          int args_passed, int args_on_stack, VMRegPair* regs,\n-                          int args_passed_to, int args_on_stack_to, VMRegPair* regs_to);\n-  bool shuffle_inline_args_spill(bool is_packing,  const GrowableArray<SigEntry>* sig_cc, int sig_cc_index,\n-                                 VMRegPair* regs_from, int from_index, int regs_from_count,\n-                                 RegState* reg_state, int sp_inc, int extra_stack_offset);\n@@ -1224,1 +1208,0 @@\n-\n@@ -1428,3 +1411,0 @@\n-\n-  #include \"asm\/macroAssembler_common.hpp\"\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":6,"deletions":26,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -479,3 +479,1 @@\n-       if (SigEntry::is_reserved_entry(sig_extended, i)) {\n-         \/\/ Ignore reserved entry\n-       } else if (bt == T_INLINE_TYPE) {\n+       if (bt == T_INLINE_TYPE) {\n@@ -663,0 +661,5 @@\n+      if (bt == T_VOID) {\n+         assert(next_arg_comp > 0 && (sig_extended->at(next_arg_comp - 1)._bt == T_LONG || sig_extended->at(next_arg_comp - 1)._bt == T_DOUBLE), \"missing half\");\n+         next_arg_int ++;\n+         continue;\n+       }\n@@ -664,12 +667,2 @@\n-            if (SigEntry::is_reserved_entry(sig_extended, next_arg_comp)) {\n-               continue; \/\/ Ignore reserved entry\n-            }\n-\n-            if (bt == T_VOID) {\n-               assert(next_arg_comp > 0 && (sig_extended->at(next_arg_comp - 1)._bt == T_LONG || sig_extended->at(next_arg_comp - 1)._bt == T_DOUBLE), \"missing half\");\n-               next_arg_int ++;\n-               continue;\n-             }\n-\n-             int next_off = st_off - Interpreter::stackElementSize;\n-             int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : st_off;\n+       int next_off = st_off - Interpreter::stackElementSize;\n+       int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : st_off;\n@@ -677,2 +670,2 @@\n-             gen_c2i_adapter_helper(masm, bt, regs[next_arg_comp], extraspace, Address(sp, offset));\n-             next_arg_int ++;\n+       gen_c2i_adapter_helper(masm, bt, regs[next_arg_comp], extraspace, Address(sp, offset));\n+       next_arg_int ++;\n@@ -703,2 +696,0 @@\n-        } else if (SigEntry::is_reserved_entry(sig_extended, next_arg_comp)) {\n-          \/\/ Ignore reserved entry\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":10,"deletions":19,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -412,1 +412,0 @@\n-  int extra_stack_offset = wordSize; \/\/ tos is return address.\n@@ -420,1 +419,4 @@\n-    pop(r13); \/\/ Copy return address\n+    \/\/ Save the return address, adjust the stack (make sure it is properly\n+    \/\/ 16-byte aligned) and copy the return address to the new top of the stack.\n+    \/\/ The stack will be repaired on return (see MacroAssembler::remove_frame).\n+    pop(r13);\n@@ -448,1 +450,1 @@\n-  shuffle_inline_args(true, is_inline_ro_entry, extra_stack_offset, sig_bt, sig_cc,\n+  shuffle_inline_args(true, is_inline_ro_entry, sig_cc,\n@@ -450,1 +452,2 @@\n-                      args_passed, args_on_stack, regs, sp_inc); \/\/ to\n+                      args_passed, args_on_stack, regs,          \/\/ to\n+                      sp_inc);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":7,"deletions":4,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -5279,1 +5279,0 @@\n-\n@@ -5281,1 +5280,1 @@\n-bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {\n+bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]) {\n@@ -5302,2 +5301,1 @@\n-        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n-        assert(st_off != ret_off, \"overwriting return address at %d\", st_off);\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n@@ -5317,1 +5315,1 @@\n-      Address from_addr = Address(rsp, from->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset);\n+      Address from_addr = Address(rsp, from->reg2stack() * VMRegImpl::stack_slot_size + wordSize);\n@@ -5330,2 +5328,1 @@\n-        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n-        assert(st_off != ret_off, \"overwriting return address at %d\", st_off);\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n@@ -5343,4 +5340,4 @@\n-\/\/ Read all fields from an inline type oop and store the values in registers\/stack slots\n-bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, int& from_index, VMRegPair* regs_to,\n-                                          int& to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {\n-  Register fromReg = from->is_reg() ? from->as_Register() : noreg;\n+\/\/ Read all fields from an inline type buffer and store the field values in registers\/stack slots.\n+bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                                          VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                                          RegState reg_state[]) {\n@@ -5348,0 +5345,9 @@\n+  assert(from->is_valid(), \"source must bevalid\");\n+  Register fromReg;\n+  if (from->is_reg()) {\n+    fromReg = from->as_Register();\n+  } else {\n+    int st_off = from->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+    movq(r10, Address(rsp, st_off));\n+    fromReg = r10;\n+  }\n@@ -5349,1 +5355,1 @@\n-  int vt = 1;\n+  ScalarizedInlineArgsStream stream(sig, sig_index, to, to_count, to_index, -1);\n@@ -5352,11 +5358,16 @@\n-  do {\n-    sig_index--;\n-    BasicType bt = sig->at(sig_index)._bt;\n-    if (bt == T_INLINE_TYPE) {\n-      vt--;\n-    } else if (bt == T_VOID &&\n-               sig->at(sig_index-1)._bt != T_LONG &&\n-               sig->at(sig_index-1)._bt != T_DOUBLE) {\n-      vt++;\n-    } else if (SigEntry::is_reserved_entry(sig, sig_index)) {\n-      to_index--; \/\/ Ignore this\n+  VMReg toReg;\n+  BasicType bt;\n+  while (stream.next(toReg, bt)) {\n+    int off = sig->at(stream.sig_index())._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    Address fromAddr = Address(fromReg, off);\n+\n+    int idx = (int)toReg->value();\n+    if (reg_state[idx] == reg_readonly) {\n+     if (idx != from->value()) {\n+       mark_done = false;\n+     }\n+     done = false;\n+     continue;\n+    } else if (reg_state[idx] == reg_written) {\n+      continue;\n@@ -5364,29 +5375,3 @@\n-      assert(to_index >= 0, \"invalid to_index\");\n-      VMRegPair pair_to = regs_to[to_index--];\n-      VMReg to = pair_to.first();\n-\n-      if (bt == T_VOID) continue;\n-\n-      int idx = (int)to->value();\n-      if (reg_state[idx] == reg_readonly) {\n-         if (idx != from->value()) {\n-           mark_done = false;\n-         }\n-         done = false;\n-         continue;\n-      } else if (reg_state[idx] == reg_written) {\n-        continue;\n-      } else {\n-        assert(reg_state[idx] == reg_writable, \"must be writable\");\n-        reg_state[idx] = reg_written;\n-       }\n-\n-      if (fromReg == noreg) {\n-        int st_off = from->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n-        movq(r10, Address(rsp, st_off));\n-        fromReg = r10;\n-      }\n-\n-      int off = sig->at(sig_index)._offset;\n-      assert(off > 0, \"offset in object should be positive\");\n-      bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);\n+      assert(reg_state[idx] == reg_writable, \"must be writable\");\n+      reg_state[idx] = reg_written;\n+    }\n@@ -5394,14 +5379,4 @@\n-      Address fromAddr = Address(fromReg, off);\n-      bool is_signed = (bt != T_CHAR) && (bt != T_BOOLEAN);\n-      if (!to->is_XMMRegister()) {\n-        Register dst = to->is_stack() ? r13 : to->as_Register();\n-        if (is_oop) {\n-          load_heap_oop(dst, fromAddr);\n-        } else {\n-          load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);\n-        }\n-        if (to->is_stack()) {\n-          int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n-          assert(st_off != ret_off, \"overwriting return address at %d\", st_off);\n-          movq(Address(rsp, st_off), dst);\n-        }\n+    if (!toReg->is_XMMRegister()) {\n+      Register dst = toReg->is_stack() ? r13 : toReg->as_Register();\n+      if (is_reference_type(bt)) {\n+        load_heap_oop(dst, fromAddr);\n@@ -5409,6 +5384,2 @@\n-        if (bt == T_DOUBLE) {\n-          movdbl(to->as_XMMRegister(), fromAddr);\n-        } else {\n-          assert(bt == T_FLOAT, \"must be float\");\n-          movflt(to->as_XMMRegister(), fromAddr);\n-        }\n+        bool is_signed = (bt != T_CHAR) && (bt != T_BOOLEAN);\n+        load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);\n@@ -5416,0 +5387,9 @@\n+      if (toReg->is_stack()) {\n+        int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        movq(Address(rsp, st_off), dst);\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      movdbl(toReg->as_XMMRegister(), fromAddr);\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      movflt(toReg->as_XMMRegister(), fromAddr);\n@@ -5417,1 +5397,4 @@\n-  } while (vt != 0);\n+  }\n+  sig_index = stream.sig_index();\n+  to_index = stream.regs_index();\n+\n@@ -5426,1 +5409,0 @@\n-\/\/ Pack fields back into an inline type oop\n@@ -5428,2 +5410,2 @@\n-                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],\n-                                        int ret_off, int extra_stack_offset) {\n+                                        VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                                        RegState reg_state[]) {\n@@ -5431,1 +5413,1 @@\n-  assert(to->is_valid(), \"must be\");\n+  assert(to->is_valid(), \"destination must be valid\");\n@@ -5434,1 +5416,1 @@\n-    skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);\n+    skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n@@ -5447,2 +5429,2 @@\n-    if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {\n-      skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);\n+    if (!is_reg_in_unpacked_fields(sig, sig_index, to, from, from_count, from_index)) {\n+      skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n@@ -5457,2 +5439,2 @@\n-  ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n-  VMRegPair from_pair;\n+  ScalarizedInlineArgsStream stream(sig, sig_index, from, from_count, from_index);\n+  VMReg fromReg;\n@@ -5460,2 +5442,2 @@\n-  while (stream.next(from_pair, bt)) {\n-    int off = sig->at(stream.sig_cc_index())._offset;\n+  while (stream.next(fromReg, bt)) {\n+    int off = sig->at(stream.sig_index())._offset;\n@@ -5463,1 +5445,0 @@\n-    bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);\n@@ -5466,4 +5447,0 @@\n-    VMReg from_r1 = from_pair.first();\n-    VMReg from_r2 = from_pair.second();\n-\n-    \/\/ Pack the scalarized field into the value object.\n@@ -5471,6 +5448,6 @@\n-    if (!from_r1->is_XMMRegister()) {\n-      Register from_reg;\n-      if (from_r1->is_stack()) {\n-        from_reg = from_reg_tmp;\n-        int ld_off = from_r1->reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;\n-        load_sized_value(from_reg, Address(rsp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+    if (!fromReg->is_XMMRegister()) {\n+      Register src;\n+      if (fromReg->is_stack()) {\n+        src = from_reg_tmp;\n+        int ld_off = fromReg->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        load_sized_value(src, Address(rsp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n@@ -5478,1 +5455,1 @@\n-        from_reg = from_r1->as_Register();\n+        src = fromReg->as_Register();\n@@ -5480,3 +5457,3 @@\n-      assert_different_registers(dst.base(), from_reg, tmp1, tmp2, tmp3, val_array);\n-      if (is_oop) {\n-        store_heap_oop(dst, from_reg, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      assert_different_registers(dst.base(), src, tmp1, tmp2, tmp3, val_array);\n+      if (is_reference_type(bt)) {\n+        store_heap_oop(dst, src, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n@@ -5484,1 +5461,1 @@\n-        store_sized_value(dst, from_reg, size_in_bytes);\n+        store_sized_value(dst, src, size_in_bytes);\n@@ -5486,0 +5463,2 @@\n+    } else if (bt == T_DOUBLE) {\n+      movdbl(dst, fromReg->as_XMMRegister());\n@@ -5487,5 +5466,2 @@\n-      if (from_r2->is_valid()) {\n-        movdbl(dst, from_r1->as_XMMRegister());\n-      } else {\n-        movflt(dst, from_r1->as_XMMRegister());\n-      }\n+      assert(bt == T_FLOAT, \"must be float\");\n+      movflt(dst, fromReg->as_XMMRegister());\n@@ -5493,1 +5469,1 @@\n-    reg_state[from_r1->value()] = reg_writable;\n+    reg_state[fromReg->value()] = reg_writable;\n@@ -5495,2 +5471,2 @@\n-  sig_index = stream.sig_cc_index();\n-  from_index = stream.regs_cc_index();\n+  sig_index = stream.sig_index();\n+  from_index = stream.regs_index();\n@@ -5499,1 +5475,1 @@\n-  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);\n+  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state);\n@@ -5501,1 +5477,0 @@\n-\n@@ -5505,38 +5480,0 @@\n-\/\/ Unpack all inline type arguments passed as oops\n-void MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {\n-  int sp_inc = unpack_inline_args_common(C, receiver_only);\n-  \/\/ Emit code for verified entry and save increment for stack repair on return\n-  verified_entry(C, sp_inc);\n-}\n-\n-void MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,\n-                                         BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,\n-                                         int args_passed, int args_on_stack, VMRegPair* regs,\n-                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {\n-  \/\/ Check if we need to extend the stack for packing\/unpacking\n-  if (sp_inc > 0 && !is_packing) {\n-    \/\/ Save the return address, adjust the stack (make sure it is properly\n-    \/\/ 16-byte aligned) and copy the return address to the new top of the stack.\n-    \/\/ (Note: C1 does this in C1_MacroAssembler::scalarized_entry).\n-    pop(r13);\n-    subptr(rsp, sp_inc);\n-    push(r13);\n-  }\n-\n-  int ret_off; \/\/ make sure we don't overwrite the return address\n-  if (is_packing) {\n-    \/\/ For C1 code, the VIEP doesn't have reserved slots, so we store the returned address at\n-    \/\/ rsp[0] during shuffling.\n-    ret_off = 0;\n-  } else {\n-    \/\/ C2 code ensures that sp_inc is a reserved slot.\n-    ret_off = sp_inc;\n-  }\n-\n-  shuffle_inline_args_common(is_packing, receiver_only, extra_stack_offset,\n-                             sig_bt, sig_cc,\n-                             args_passed, args_on_stack, regs,\n-                             args_passed_to, args_on_stack_to, regs_to,\n-                             sp_inc, ret_off);\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":85,"deletions":148,"binary":false,"changes":233,"status":"modified"},{"patch":"@@ -1651,5 +1651,2 @@\n-  enum RegState {\n-    reg_readonly,\n-    reg_writable,\n-    reg_written\n-  };\n+  \/\/ Inline type specific methods\n+  #include \"asm\/macroAssembler_common.hpp\"\n@@ -1658,6 +1655,4 @@\n-\n-  \/\/ Unpack all inline type arguments passed as oops\n-  void unpack_inline_args(Compile* C, bool receiver_only);\n-  bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset);\n-  bool unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, int& from_index, VMRegPair* regs_to, int& to_index,\n-                            RegState reg_state[], int ret_off, int extra_stack_offset);\n+  bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]);\n+  bool unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                            VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                            RegState reg_state[]);\n@@ -1665,2 +1660,2 @@\n-                          VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],\n-                          int ret_off, int extra_stack_offset);\n+                          VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                          RegState reg_state[]);\n@@ -1668,8 +1663,0 @@\n-\n-  void shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,\n-                           BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,\n-                           int args_passed, int args_on_stack, VMRegPair* regs,\n-                           int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc);\n-  bool shuffle_inline_args_spill(bool is_packing,  const GrowableArray<SigEntry>* sig_cc, int sig_cc_index,\n-                                 VMRegPair* regs_from, int from_index, int regs_from_count,\n-                                 RegState* reg_state, int sp_inc, int extra_stack_offset);\n@@ -1813,2 +1800,0 @@\n-\n-  #include \"asm\/macroAssembler_common.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":8,"deletions":23,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -664,3 +664,1 @@\n-      if (SigEntry::is_reserved_entry(sig_extended, i)) {\n-        \/\/ Ignore reserved entry\n-      } else if (bt == T_INLINE_TYPE) {\n+      if (bt == T_INLINE_TYPE) {\n@@ -864,3 +862,0 @@\n-      if (SigEntry::is_reserved_entry(sig_extended, next_arg_comp)) {\n-        continue; \/\/ Ignore reserved entry\n-      }\n@@ -906,2 +901,0 @@\n-        } else if (SigEntry::is_reserved_entry(sig_extended, next_arg_comp)) {\n-          \/\/ Ignore reserved entry\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1511,1 +1511,1 @@\n-  MacroAssembler masm(&cbuf);\n+  MacroAssembler _masm(&cbuf);\n@@ -1515,2 +1515,2 @@\n-      masm.load_klass(rscratch1, j_rarg0, rscratch2);\n-      masm.cmpptr(rax, rscratch1);\n+      __ load_klass(rscratch1, j_rarg0, rscratch2);\n+      __ cmpptr(rax, rscratch1);\n@@ -1518,1 +1518,1 @@\n-      masm.cmpptr(rax, Address(j_rarg0, oopDesc::klass_offset_in_bytes()));\n+      __ cmpptr(rax, Address(j_rarg0, oopDesc::klass_offset_in_bytes()));\n@@ -1520,1 +1520,1 @@\n-    masm.jump_cc(Assembler::notEqual, RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+    __ jump_cc(Assembler::notEqual, RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n@@ -1524,2 +1524,4 @@\n-    masm.unpack_inline_args(ra_->C, _receiver_only);\n-    masm.jmp(*_verified_entry);\n+    int sp_inc = __ unpack_inline_args(ra_->C, _receiver_only);\n+    \/\/ Emit code for verified entry and save increment for stack repair on return\n+    __ verified_entry(ra_->C, sp_inc);\n+    __ jmp(*_verified_entry);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":9,"deletions":7,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -39,2 +39,2 @@\n-  ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n-  VMRegPair from_pair;\n+  ScalarizedInlineArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n+  VMReg reg;\n@@ -42,3 +42,3 @@\n-  while (stream.next(from_pair, bt)) {}\n-  sig_index = stream.sig_cc_index();\n-  from_index = stream.regs_cc_index();\n+  while (stream.next(reg, bt)) {}\n+  sig_index = stream.sig_index();\n+  from_index = stream.regs_index();\n@@ -48,2 +48,2 @@\n-  ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n-  VMRegPair from_pair;\n+  ScalarizedInlineArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n+  VMReg reg;\n@@ -51,2 +51,2 @@\n-  while (stream.next(from_pair, bt)) {\n-    if (from_pair.first() == to) {\n+  while (stream.next(reg, bt)) {\n+    if (reg == to) {\n@@ -56,1 +56,0 @@\n-\n@@ -69,32 +68,1 @@\n-void MacroAssembler::mark_reserved_entries_writable(const GrowableArray<SigEntry>* sig_cc, const VMRegPair* regs, int num_regs, MacroAssembler::RegState* reg_state) {\n-  int reg_index = 0;\n-  for (int sig_index = 0; sig_index <sig_cc->length(); sig_index ++) {\n-    if (SigEntry::is_reserved_entry(sig_cc, sig_index)) {\n-      mark_reg_writable(regs, num_regs, reg_index, reg_state);\n-      reg_index ++;\n-    } else if (SigEntry::skip_value_delimiters(sig_cc, sig_index)) {\n-      reg_index ++;\n-    } else {\n-      int vt = 1;\n-      do {\n-        sig_index++;\n-        BasicType bt = sig_cc->at(sig_index)._bt;\n-        if (bt == T_INLINE_TYPE) {\n-          vt++;\n-        } else if (bt == T_VOID &&\n-                   sig_cc->at(sig_index-1)._bt != T_LONG &&\n-                   sig_cc->at(sig_index-1)._bt != T_DOUBLE) {\n-          vt--;\n-        } else if (SigEntry::is_reserved_entry(sig_cc, sig_index)) {\n-          mark_reg_writable(regs, num_regs, reg_index, reg_state);\n-          reg_index++;\n-        } else {\n-          reg_index++;\n-        }\n-      } while (vt != 0);\n-    }\n-  }\n-}\n-\n-MacroAssembler::RegState* MacroAssembler::init_reg_state(bool is_packing, const GrowableArray<SigEntry>* sig_cc,\n-                                                         VMRegPair* regs, int num_regs, int sp_inc, int max_stack) {\n+MacroAssembler::RegState* MacroAssembler::init_reg_state(VMRegPair* regs, int num_regs, int sp_inc, int max_stack) {\n@@ -120,5 +88,0 @@\n-  if (is_packing) {\n-    \/\/ The reserved entries are not used by the packed args, so make them writable\n-    mark_reserved_entries_writable(sig_cc, regs, num_regs, reg_state);\n-  }\n-\n@@ -128,1 +91,1 @@\n-int MacroAssembler::unpack_inline_args_common(Compile* C, bool receiver_only) {\n+int MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {\n@@ -131,2 +94,2 @@\n-  const GrowableArray<SigEntry>* sig_cc = method->adapter()->get_sig_cc();\n-  assert(sig_cc != NULL, \"must have scalarized signature\");\n+  const GrowableArray<SigEntry>* sig = method->adapter()->get_sig_cc();\n+  assert(sig != NULL, \"must have scalarized signature\");\n@@ -135,1 +98,1 @@\n-  BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig_cc->length()); \/\/ FIXME - may underflow if we support values with no fields!\n+  BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, 256);\n@@ -152,7 +115,4 @@\n-    \/\/ Copy scalarized signature but skip receiver, inline type delimiters and reserved entries\n-    for (int i = 0; i < sig_cc->length(); i++) {\n-      if (!SigEntry::is_reserved_entry(sig_cc, i)) {\n-        if (SigEntry::skip_value_delimiters(sig_cc, i) && rec_len <= 0) {\n-          sig_bt[args_passed++] = sig_cc->at(i)._bt;\n-        }\n-        rec_len--;\n+    \/\/ Copy scalarized signature but skip receiver and inline type delimiters\n+    for (int i = 0; i < sig->length(); i++) {\n+      if (SigEntry::skip_value_delimiters(sig, i) && rec_len <= 0) {\n+        sig_bt[args_passed++] = sig->at(i)._bt;\n@@ -160,0 +120,1 @@\n+      rec_len--;\n@@ -166,2 +127,2 @@\n-  int args_passed_cc = SigEntry::fill_sig_bt(sig_cc, sig_bt);\n-  VMRegPair* regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, sig_cc->length());\n+  int args_passed_cc = SigEntry::fill_sig_bt(sig, sig_bt);\n+  VMRegPair* regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, sig->length());\n@@ -169,2 +130,2 @@\n-  int extra_stack_offset = wordSize; \/\/ stack has the returned address\n-  \/\/ Compute stack increment\n+\n+  \/\/ Check if we need to extend the stack for unpacking\n@@ -173,1 +134,2 @@\n-    sp_inc = (args_on_stack_cc - args_on_stack) * VMRegImpl::stack_slot_size;\n+    \/\/ Two additional slots to account for return address\n+    sp_inc = (args_on_stack_cc + 2) * VMRegImpl::stack_slot_size;\n@@ -175,0 +137,7 @@\n+    \/\/ Save the return address, adjust the stack (make sure it is properly\n+    \/\/ 16-byte aligned) and copy the return address to the new top of the stack.\n+    \/\/ The stack will be repaired on return (see MacroAssembler::remove_frame).\n+    assert(sp_inc > 0, \"sanity\");\n+    pop(r13);\n+    subptr(rsp, sp_inc);\n+    push(r13);\n@@ -176,3 +145,4 @@\n-  shuffle_inline_args(false, receiver_only, extra_stack_offset, sig_bt, sig_cc,\n-                      args_passed, args_on_stack, regs,\n-                      args_passed_cc, args_on_stack_cc, regs_cc, sp_inc);\n+  shuffle_inline_args(false, receiver_only, sig,\n+                      args_passed, args_on_stack, regs,           \/\/ from\n+                      args_passed_cc, args_on_stack_cc, regs_cc,  \/\/ to\n+                      sp_inc);\n@@ -182,5 +152,5 @@\n-void MacroAssembler::shuffle_inline_args_common(bool is_packing, bool receiver_only, int extra_stack_offset,\n-                                                BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,\n-                                                int args_passed, int args_on_stack, VMRegPair* regs,\n-                                                int args_passed_to, int args_on_stack_to, VMRegPair* regs_to,\n-                                                int sp_inc, int ret_off) {\n+void MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only,\n+                                         const GrowableArray<SigEntry>* sig,\n+                                         int args_passed, int args_on_stack, VMRegPair* regs,\n+                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to,\n+                                         int sp_inc) {\n@@ -188,1 +158,1 @@\n-  RegState* reg_state = init_reg_state(is_packing, sig_cc, regs, args_passed, sp_inc, max_stack);\n+  RegState* reg_state = init_reg_state(regs, args_passed, sp_inc, max_stack);\n@@ -200,2 +170,2 @@\n-    int sig_index     = is_packing ? 0 : sig_cc->length() - 1;\n-    int sig_index_end = is_packing ? sig_cc->length() : -1;\n+    int sig_index     = is_packing ? 0 : sig->length()    - 1;\n+    int sig_index_end = is_packing ? sig->length() : -1;\n@@ -204,34 +174,29 @@\n-      assert(0 <= sig_index && sig_index < sig_cc->length(), \"index out of bounds\");\n-      if (SigEntry::is_reserved_entry(sig_cc, sig_index)) {\n-        if (is_packing) {\n-          from_index += step;\n-        } else {\n-          to_index += step;\n-        }\n-      } else {\n-        if (spill) {\n-          \/\/ This call returns true IFF we should keep trying to spill in this round.\n-          spill = shuffle_inline_args_spill(is_packing, sig_cc, sig_index, regs, from_index, args_passed,\n-                                            reg_state, ret_off, extra_stack_offset);\n-        }\n-        BasicType bt = sig_cc->at(sig_index)._bt;\n-        if (SigEntry::skip_value_delimiters(sig_cc, sig_index)) {\n-          VMReg from_reg = regs[from_index].first();\n-          done &= move_helper(from_reg, regs_to[to_index].first(), bt, reg_state, ret_off, extra_stack_offset);\n-          to_index += step;\n-          from_index += step;\n-        } else if (is_packing) {\n-          VMReg reg_to = regs_to[to_index].first();\n-          done &= pack_inline_helper(sig_cc, sig_index, vtarg_index, reg_to, regs, args_passed, from_index,\n-                                     reg_state, ret_off, extra_stack_offset);\n-          vtarg_index++;\n-          to_index++;\n-        } else if (!receiver_only || (from_index == 0 && bt == T_VOID)) {\n-          VMReg from_reg = regs[from_index].first();\n-          done &= unpack_inline_helper(sig_cc, sig_index, from_reg, from_index, regs_to, to_index, reg_state, ret_off, extra_stack_offset);\n-          if (from_index == -1 && sig_index != 0) {\n-            \/\/ This can happen when we are confusing an empty inline type argument which is\n-            \/\/ not counted in the scalarized signature for the receiver. Just ignore it.\n-            assert(receiver_only, \"sanity\");\n-            from_index = 0;\n-          }\n+      assert(0 <= sig_index && sig_index < sig->length(), \"index out of bounds\");\n+      if (spill) {\n+        \/\/ This call returns true IFF we should keep trying to spill in this round.\n+        spill = shuffle_inline_args_spill(is_packing, sig, sig_index, regs, from_index, args_passed,\n+                                          reg_state);\n+      }\n+      BasicType bt = sig->at(sig_index)._bt;\n+      if (SigEntry::skip_value_delimiters(sig, sig_index)) {\n+        VMReg from_reg = regs[from_index].first();\n+        done &= move_helper(from_reg, regs_to[to_index].first(), bt, reg_state);\n+        to_index += step;\n+        from_index += step;\n+      } else if (is_packing) {\n+        VMReg reg_to = regs_to[to_index].first();\n+        done &= pack_inline_helper(sig, sig_index, vtarg_index,\n+                                   regs, args_passed, from_index, reg_to,\n+                                   reg_state);\n+        vtarg_index++;\n+        to_index++;\n+      } else if (!receiver_only || (from_index == 0 && bt == T_VOID)) {\n+        VMReg from_reg = regs[from_index].first();\n+        done &= unpack_inline_helper(sig, sig_index,\n+                                     from_reg, from_index, regs_to, args_passed_to, to_index,\n+                                     reg_state);\n+        if (from_index == -1 && sig_index != 0) {\n+          \/\/ This can happen when we are confusing an empty inline type argument which is\n+          \/\/ not counted in the scalarized signature for the receiver. Just ignore it.\n+          assert(receiver_only, \"sanity\");\n+          from_index = 0;\n@@ -245,3 +210,2 @@\n-bool MacroAssembler::shuffle_inline_args_spill(bool is_packing, const GrowableArray<SigEntry>* sig_cc, int sig_cc_index,\n-                                               VMRegPair* regs_from, int from_index, int regs_from_count,\n-                                               RegState* reg_state, int ret_off, int extra_stack_offset) {\n+bool MacroAssembler::shuffle_inline_args_spill(bool is_packing, const GrowableArray<SigEntry>* sig, int sig_index,\n+                                               VMRegPair* regs_from, int from_index, int regs_from_count, RegState* reg_state) {\n@@ -249,2 +213,1 @@\n-\n-  if (!is_packing || SigEntry::skip_value_delimiters(sig_cc, sig_cc_index)) {\n+  if (!is_packing || SigEntry::skip_value_delimiters(sig, sig_index)) {\n@@ -257,2 +220,2 @@\n-    ScalarizedValueArgsStream stream(sig_cc, sig_cc_index, regs_from, regs_from_count, from_index);\n-    VMRegPair from_pair;\n+    ScalarizedInlineArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);\n+    VMReg from_reg;\n@@ -261,4 +224,4 @@\n-    while (stream.next(from_pair, bt)) {\n-      reg = from_pair.first();\n-      assert(reg->is_valid(), \"must be\");\n-      if (reg_state[reg->value()] == reg_readonly) {\n+    while (stream.next(from_reg, bt)) {\n+      reg = from_reg;\n+      assert(from_reg->is_valid(), \"must be\");\n+      if (reg_state[from_reg->value()] == reg_readonly) {\n@@ -280,1 +243,1 @@\n-    bool res = move_helper(reg, spill_reg, T_DOUBLE, reg_state, ret_off, extra_stack_offset);\n+    bool res = move_helper(reg, spill_reg, T_DOUBLE, reg_state);\n","filename":"src\/hotspot\/share\/asm\/macroAssembler_common.cpp","additions":83,"deletions":120,"binary":false,"changes":203,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,2 +28,1 @@\n-\/\/ These are part of the MacroAssembler class that are common for\n-\/\/ all CPUs\n+\/\/ These are part of the MacroAssembler class that are common for all CPUs\n@@ -32,1 +31,7 @@\n-private:\n+\n+  enum RegState {\n+    reg_readonly,\n+    reg_writable,\n+    reg_written\n+  };\n+\n@@ -38,11 +43,9 @@\n-  void mark_reserved_entries_writable(const GrowableArray<SigEntry>* sig_cc, const VMRegPair* regs, int num_regs, RegState* reg_state);\n-  RegState* init_reg_state(bool is_packing, const GrowableArray<SigEntry>* sig_cc,\n-                           VMRegPair* regs, int num_regs, int sp_inc, int max_stack);\n-\n-  int unpack_inline_args_common(Compile* C, bool receiver_only);\n-  void shuffle_inline_args_common(bool is_packing, bool receiver_only, int extra_stack_offset,\n-                                  BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,\n-                                  int args_passed, int args_on_stack, VMRegPair* regs,\n-                                  int args_passed_to, int args_on_stack_to, VMRegPair* regs_to,\n-                                  int sp_inc, int ret_off);\n-\n+  RegState* init_reg_state(VMRegPair* regs, int num_regs, int sp_inc, int max_stack);\n+  int unpack_inline_args(Compile* C, bool receiver_only);\n+  void shuffle_inline_args(bool is_packing, bool receiver_only,\n+                           const GrowableArray<SigEntry>* sig,\n+                           int args_passed, int args_on_stack, VMRegPair* regs,\n+                           int args_passed_to, int args_on_stack_to, VMRegPair* regs_to,\n+                           int sp_inc);\n+  bool shuffle_inline_args_spill(bool is_packing, const GrowableArray<SigEntry>* sig, int sig_index,\n+                                 VMRegPair* regs_from, int from_index, int regs_from_count, RegState* reg_state);\n","filename":"src\/hotspot\/share\/asm\/macroAssembler_common.hpp","additions":18,"deletions":15,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -3173,1 +3173,0 @@\n-    bool has_scalarized_args = ces->has_scalarized_args();\n@@ -3193,1 +3192,0 @@\n-    int sig_index_cc = 0;\n@@ -3236,9 +3234,0 @@\n-      if (has_scalarized_args) {\n-        while (!SigEntry::skip_value_delimiters(sig_cc, sig_index_cc)) {\n-          sig_index_cc++;\n-        }\n-        if (SigEntry::is_reserved_entry(sig_cc, sig_index_cc)) {\n-          stream->print(\" [RESERVED]\");\n-        }\n-        sig_index_cc += type2size[t];\n-      }\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -372,1 +372,0 @@\n-  const GrowableArray<SigEntry>* sig_cc = method()->get_sig_cc();\n@@ -374,11 +373,1 @@\n-  for (uint i1 = TypeFunc::Parms, i2 = 0; i1 < r->cnt(); i1++) {\n-    if (sig_cc != NULL) {\n-      \/\/ Skip reserved entries\n-      while (!SigEntry::skip_value_delimiters(sig_cc, i2)) {\n-        i2++;\n-      }\n-      if (SigEntry::is_reserved_entry(sig_cc, i2++)) {\n-        assert(call->in(i1)->is_top(), \"should be top\");\n-        continue;\n-      }\n-    }\n+  for (uint i1 = TypeFunc::Parms; i1 < r->cnt(); i1++) {\n@@ -474,4 +463,0 @@\n-        BasicType bt = t->basic_type();\n-        while (SigEntry::next_is_reserved(sig_cc, bt, true)) {\n-          j += type2size[bt]; \/\/ Skip reserved arguments\n-        }\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":1,"deletions":16,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -2237,5 +2237,0 @@\n-        if (!C->FIRST_STACK_mask().Member(reg)) {\n-          \/\/ Reserved entry in the argument stack area that is not used because\n-          \/\/ it may hold the return address (see Matcher::init_first_stack_mask()).\n-          tty->print(\" [RESERVED] \");\n-        }\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1832,8 +1832,0 @@\n-    \/\/ Skip reserved arguments\n-    BasicType bt = t->basic_type();\n-    while (SigEntry::next_is_reserved(sig_cc, bt, true)) {\n-      call->init_req(idx++, top());\n-      if (type2size[bt] == 2) {\n-        call->init_req(idx++, top());\n-      }\n-    }\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -739,7 +739,0 @@\n-      \/\/ Skip reserved arguments\n-      while (SigEntry::next_is_reserved(sig, bt)) {\n-        n->init_req(base_input++, kit->top());\n-        if (type2size[bt] == 2) {\n-          n->init_req(base_input++, kit->top());\n-        }\n-      }\n@@ -779,4 +772,0 @@\n-      \/\/ Skip reserved arguments\n-      while (SigEntry::next_is_reserved(sig, bt)) {\n-        base_input += type2size[bt];\n-      }\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.cpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -522,18 +522,0 @@\n-  \/\/ Check if the method has a reserved entry in the argument stack area that\n-  \/\/ should not be used for spilling because it may hold the return address.\n-  if (!C->is_osr_compilation() && C->method() != NULL && C->method()->has_scalarized_args()) {\n-    ExtendedSignature sig_cc = ExtendedSignature(C->method()->get_sig_cc(), SigEntryFilter());\n-    for (int off = 0; !sig_cc.at_end(); ) {\n-      BasicType bt = (*sig_cc)._bt;\n-      off += type2size[bt];\n-      while (SigEntry::next_is_reserved(sig_cc, bt)) {\n-        \/\/ Remove reserved stack slot from mask to avoid spilling\n-        OptoRegPair reg = _parm_regs[off];\n-        assert(OptoReg::is_valid(reg.first()), \"invalid reserved register\");\n-        C->FIRST_STACK_mask().Remove(reg.first());\n-        C->FIRST_STACK_mask().Remove(reg.first()+1); \/\/ Always occupies two stack slots\n-        off += type2size[bt];\n-      }\n-    }\n-  }\n-\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":0,"deletions":18,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -884,4 +884,0 @@\n-      BasicType bt = t->basic_type();\n-      while (i >= TypeFunc::Parms && !is_osr_compilation() && SigEntry::next_is_reserved(sig_cc, bt, true)) {\n-        j += type2size[bt]; \/\/ Skip reserved arguments\n-      }\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1966,1 +1966,1 @@\n-static void collect_inline_fields(ciInlineKlass* vk, const Type** field_array, uint& pos, ExtendedSignature& sig_cc) {\n+static void collect_inline_fields(ciInlineKlass* vk, const Type** field_array, uint& pos) {\n@@ -1975,7 +1975,0 @@\n-    \/\/ Skip reserved arguments\n-    while (SigEntry::next_is_reserved(sig_cc, bt)) {\n-      field_array[pos++] = Type::get_const_basic_type(bt);\n-      if (type2size[bt] == 2) {\n-        field_array[pos++] = Type::HALF;\n-      }\n-    }\n@@ -2020,1 +2013,1 @@\n-      collect_inline_fields(return_type->as_inline_klass(), field_array, pos, sig);\n+      collect_inline_fields(return_type->as_inline_klass(), field_array, pos);\n@@ -2051,1 +2044,1 @@\n-      collect_inline_fields(recv->as_inline_klass(), field_array, pos, sig_cc);\n+      collect_inline_fields(recv->as_inline_klass(), field_array, pos);\n@@ -2090,1 +2083,1 @@\n-        collect_inline_fields(type->as_inline_klass(), field_array, pos, sig_cc);\n+        collect_inline_fields(type->as_inline_klass(), field_array, pos);\n@@ -2099,7 +2092,0 @@\n-    \/\/ Skip reserved arguments\n-    while (!is_flattened && SigEntry::next_is_reserved(sig_cc, bt)) {\n-      field_array[pos++] = Type::get_const_basic_type(bt);\n-      if (type2size[bt] == 2) {\n-        field_array[pos++] = Type::HALF;\n-      }\n-    }\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":4,"deletions":18,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -2748,1 +2748,0 @@\n-  _has_reserved_entries = false;\n@@ -2780,21 +2779,0 @@\n-int CompiledEntrySignature::insert_reserved_entry(int ret_off) {\n-  \/\/ Find index in signature that belongs to return address slot\n-  BasicType bt = T_ILLEGAL;\n-  int i = 0;\n-  for (uint off = 0; i < _sig_cc->length(); ++i) {\n-    if (SigEntry::skip_value_delimiters(_sig_cc, i)) {\n-      VMReg first = _regs_cc[off++].first();\n-      if (first->is_valid() && first->is_stack()) {\n-        \/\/ Select a type for the reserved entry that will end up on the stack\n-        bt = _sig_cc->at(i)._bt;\n-        if (((int)first->reg2stack() + VMRegImpl::slots_per_word) == ret_off) {\n-          break; \/\/ Index of the return address found\n-        }\n-      }\n-    }\n-  }\n-  \/\/ Insert reserved entry and re-compute calling convention\n-  SigEntry::insert_reserved_entry(_sig_cc, i, bt);\n-  return SharedRuntime::java_calling_convention(_sig_cc, _regs_cc);\n-}\n-\n@@ -2829,1 +2807,1 @@\n-  if (args_on_stack_cc() != args_on_stack_cc_ro() || _has_reserved_entries) {\n+  if (args_on_stack_cc() != args_on_stack_cc_ro()) {\n@@ -2887,32 +2865,0 @@\n-    \/\/ Compute the stack extension that is required to convert between the calling conventions.\n-    \/\/ The stack slots at these offsets are occupied by the return address with the unscalarized\n-    \/\/ calling convention. Don't use them for arguments with the scalarized calling convention.\n-    int ret_off    = _args_on_stack_cc - _args_on_stack;\n-    int ret_off_ro = _args_on_stack_cc - _args_on_stack_cc_ro;\n-    assert(ret_off_ro <= 0 || ret_off > 0, \"receiver unpacking requires more stack space than expected\");\n-\n-    if (ret_off > 0) {\n-      \/\/ Make sure the stack of the scalarized calling convention with the reserved\n-      \/\/ entries (2 slots each) remains 16-byte (4 slots) aligned after stack extension.\n-      int alignment = StackAlignmentInBytes \/ VMRegImpl::stack_slot_size;\n-      if (ret_off_ro != ret_off && ret_off_ro >= 0) {\n-        ret_off    += 4; \/\/ Account for two reserved entries (4 slots)\n-        ret_off_ro += 4;\n-        ret_off     = align_up(ret_off, alignment);\n-        ret_off_ro  = align_up(ret_off_ro, alignment);\n-        \/\/ TODO can we avoid wasting a stack slot here?\n-        \/\/assert(ret_off != ret_off_ro, \"fail\");\n-        if (ret_off > ret_off_ro) {\n-          swap(ret_off, ret_off_ro); \/\/ Sort by offset\n-        }\n-        _args_on_stack_cc = insert_reserved_entry(ret_off);\n-        _args_on_stack_cc = insert_reserved_entry(ret_off_ro);\n-      } else {\n-        ret_off += 2; \/\/ Account for one reserved entry (2 slots)\n-        ret_off = align_up(ret_off, alignment);\n-        _args_on_stack_cc = insert_reserved_entry(ret_off);\n-      }\n-\n-      _has_reserved_entries = true;\n-    }\n-\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":1,"deletions":55,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -808,1 +808,0 @@\n-  bool _has_reserved_entries;\n@@ -844,1 +843,0 @@\n-  int insert_reserved_entry(int ret_off);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -585,17 +585,0 @@\n-\/\/ Inserts a reserved argument at position 'i'\n-void SigEntry::insert_reserved_entry(GrowableArray<SigEntry>* sig, int i, BasicType bt) {\n-  if (bt == T_OBJECT || bt == T_ARRAY || bt == T_INLINE_TYPE) {\n-    \/\/ Treat this as INT to not confuse the GC\n-    bt = T_INT;\n-  } else if (bt == T_LONG || bt == T_DOUBLE) {\n-    \/\/ Longs and doubles take two stack slots\n-    sig->insert_before(i, SigEntry(T_VOID, SigEntry::ReservedOffset));\n-  }\n-  sig->insert_before(i, SigEntry(bt, SigEntry::ReservedOffset));\n-}\n-\n-\/\/ Returns true if the argument at index 'i' is a reserved argument\n-bool SigEntry::is_reserved_entry(const GrowableArray<SigEntry>* sig, int i) {\n-  return sig->at(i)._offset == SigEntry::ReservedOffset;\n-}\n-\n@@ -646,16 +629,0 @@\n-\n-\/\/ Increment signature iterator (skips inline type delimiters and T_VOID) and check if next entry is reserved\n-bool SigEntry::next_is_reserved(ExtendedSignature& sig, BasicType& bt, bool can_be_void) {\n-  assert(can_be_void || bt != T_VOID, \"should never see void\");\n-  if (sig.at_end() || (can_be_void && type2size[bt] == 2 && (*sig)._offset != SigEntry::ReservedOffset)) {\n-    \/\/ Don't increment at the end or at a T_LONG\/T_DOUBLE which will be followed by a (skipped) T_VOID\n-    return false;\n-  }\n-  assert(bt == T_VOID || type2wfield[bt] == type2wfield[(*sig)._bt], \"inconsistent signature\");\n-  ++sig;\n-  if (!sig.at_end() && (*sig)._offset == SigEntry::ReservedOffset) {\n-    bt = (*sig)._bt;\n-    return true;\n-  }\n-  return false;\n-}\n","filename":"src\/hotspot\/share\/runtime\/signature.cpp","additions":0,"deletions":33,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -578,2 +578,0 @@\n-  enum { ReservedOffset = -2 }; \/\/ Special offset to mark the reserved entry\n-\n@@ -612,2 +610,0 @@\n-  static void insert_reserved_entry(GrowableArray<SigEntry>* sig, int i, BasicType bt);\n-  static bool is_reserved_entry(const GrowableArray<SigEntry>* sig, int i);\n@@ -617,2 +613,0 @@\n-\n-  static bool next_is_reserved(ExtendedSignature& sig, BasicType& bt, bool can_be_void = false);\n","filename":"src\/hotspot\/share\/runtime\/signature.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-\/\/ Handling of scalarized Calling Convention\n@@ -31,7 +30,9 @@\n-class ScalarizedValueArgsStream : public StackObj {\n-  const GrowableArray<SigEntry>* _sig_cc;\n-  int _sig_cc_index;\n-  const VMRegPair* _regs_cc;\n-  int _regs_cc_count;\n-  int _regs_cc_index;\n-  int _vt;\n+\/\/ Stream that iterates over a scalarized signature\n+class ScalarizedInlineArgsStream : public StackObj {\n+  const GrowableArray<SigEntry>* _sig;\n+  int _sig_idx;\n+  const VMRegPair* _regs;\n+  int _regs_count;\n+  int _regs_idx;\n+  int _depth;\n+  int _step;\n@@ -39,0 +40,1 @@\n+\n@@ -40,4 +42,4 @@\n-  ScalarizedValueArgsStream(const GrowableArray<SigEntry>* sig_cc, int sig_cc_index, VMRegPair* regs_cc, int regs_cc_count, int regs_cc_index) :\n-    _sig_cc(sig_cc), _sig_cc_index(sig_cc_index), _regs_cc(regs_cc), _regs_cc_count(regs_cc_count), _regs_cc_index(regs_cc_index) {\n-    assert(_sig_cc->at(_sig_cc_index)._bt == T_INLINE_TYPE, \"should be at end delimiter\");\n-    _vt = 1;\n+  ScalarizedInlineArgsStream(const GrowableArray<SigEntry>* sig, int sig_idx, VMRegPair* regs, int regs_count, int regs_idx, int step = 1)\n+    : _sig(sig), _sig_idx(sig_idx), _regs(regs), _regs_count(regs_count), _regs_idx(regs_idx), _step(step) {\n+    assert(_sig->at(_sig_idx)._bt == (step > 0) ? T_INLINE_TYPE : T_VOID, \"should be at inline type delimiter\");\n+    _depth = 1;\n@@ -47,1 +49,1 @@\n-  bool next(VMRegPair& pair, BasicType& bt) {\n+  bool next(VMReg& reg, BasicType& bt) {\n@@ -50,2 +52,2 @@\n-      _sig_cc_index++;\n-      bt = _sig_cc->at(_sig_cc_index)._bt;\n+      _sig_idx += _step;\n+      bt = _sig->at(_sig_idx)._bt;\n@@ -53,1 +55,1 @@\n-        _vt++;\n+        _depth += _step;\n@@ -55,5 +57,3 @@\n-                 _sig_cc->at(_sig_cc_index-1)._bt != T_LONG &&\n-                 _sig_cc->at(_sig_cc_index-1)._bt != T_DOUBLE) {\n-        _vt--;\n-      } else if (SigEntry::is_reserved_entry(_sig_cc, _sig_cc_index)) {\n-        _regs_cc_index++;\n+                 _sig->at(_sig_idx-1)._bt != T_LONG &&\n+                 _sig->at(_sig_idx-1)._bt != T_DOUBLE) {\n+        _depth -= _step;\n@@ -61,7 +61,6 @@\n-        assert(_regs_cc_index < _regs_cc_count, \"must be\");\n-        pair = _regs_cc[_regs_cc_index++];\n-        VMReg r1 = pair.first();\n-        VMReg r2 = pair.second();\n-\n-        if (!r1->is_valid()) {\n-          assert(!r2->is_valid(), \"must be invalid\");\n+        assert(_regs_idx >= 0 && _regs_idx < _regs_count, \"out of bounds\");\n+        const VMRegPair pair = _regs[_regs_idx];\n+        _regs_idx += _step;\n+        reg = pair.first();\n+        if (!reg->is_valid()) {\n+          assert(!pair.second()->is_valid(), \"must be invalid\");\n@@ -72,1 +71,1 @@\n-    } while (_vt != 0);\n+    } while (_depth != 0);\n@@ -78,2 +77,2 @@\n-  int sig_cc_index() {return _sig_cc_index;}\n-  int regs_cc_index() {return _regs_cc_index;}\n+  int sig_index()  { return _sig_idx;  }\n+  int regs_index() { return _regs_idx; }\n","filename":"src\/hotspot\/share\/runtime\/signature_cc.hpp","additions":31,"deletions":32,"binary":false,"changes":63,"status":"modified"}]}