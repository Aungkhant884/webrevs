{"files":[{"patch":"@@ -1773,4 +1773,0 @@\n-  if (C->max_vector_size() > 0) {\n-    __ reinitialize_ptrue();\n-  }\n-\n@@ -1778,1 +1774,0 @@\n-  __ bind(*_verified_entry);\n@@ -1781,19 +1776,5 @@\n-    BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-    if (BarrierSet::barrier_set()->barrier_set_nmethod() != NULL) {\n-      \/\/ Dummy labels for just measuring the code size\n-      Label dummy_slow_path;\n-      Label dummy_continuation;\n-      Label dummy_guard;\n-      Label* slow_path = &dummy_slow_path;\n-      Label* continuation = &dummy_continuation;\n-      Label* guard = &dummy_guard;\n-      if (!Compile::current()->output()->in_scratch_emit_size()) {\n-        \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n-        C2EntryBarrierStub* stub = Compile::current()->output()->entry_barrier_table()->add_entry_barrier();\n-        slow_path = &stub->slow_path();\n-        continuation = &stub->continuation();\n-        guard = &stub->guard();\n-      }\n-      \/\/ In the C2 code, we move the non-hot part of nmethod entry barriers out-of-line to a stub.\n-      bs->nmethod_entry_barrier(&_masm, slow_path, continuation, guard);\n-    }\n+    __ entry_barrier();\n+  }\n+\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    __ bind(*_verified_entry);\n@@ -2196,1 +2177,1 @@\n-  MacroAssembler _masm(&cbuf);\n+  C2_MacroAssembler _masm(&cbuf);\n@@ -2206,0 +2187,11 @@\n+    \/\/ insert a nop at the start of the prolog so we can patch in a\n+    \/\/ branch if we need to invalidate the method later\n+    __ nop();\n+\n+    \/\/ TODO 8284443 Avoid creation of temporary frame\n+    if (ra_->C->stub_function() == NULL) {\n+      __ verified_entry(ra_->C, 0);\n+      __ entry_barrier();\n+      int framesize = ra_->C->output()->frame_slots() << LogBytesPerInt;\n+      __ remove_frame(framesize, false);\n+    }\n@@ -2211,1 +2203,6 @@\n-    __ b(*_verified_entry);\n+    if (Compile::current()->output()->in_scratch_emit_size()) {\n+      Label dummy_verified_entry;\n+      __ b(dummy_verified_entry);\n+    } else {\n+      __ b(*_verified_entry);\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":23,"deletions":26,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -306,1 +306,1 @@\n-void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_inc, bool needs_stack_repair) {\n+void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_offset_for_orig_pc, int sp_inc, bool has_scalarized_args, bool needs_stack_repair) {\n@@ -312,3 +312,0 @@\n-}\n-\n-void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_inline_entry_label) {\n@@ -317,4 +314,1 @@\n-    str(zr, Address(sp, sp_offset_for_orig_pc - frame_size_in_bytes));\n-  }\n-  if (!needs_stack_repair && verified_inline_entry_label != NULL) {\n-    bind(*verified_inline_entry_label);\n+    str(zr, Address(sp, sp_offset_for_orig_pc));\n@@ -322,0 +316,1 @@\n+}\n@@ -323,0 +318,1 @@\n+void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_inline_entry_label) {\n@@ -328,1 +324,1 @@\n-  build_frame_helper(frame_size_in_bytes, 0, needs_stack_repair);\n+  build_frame_helper(frame_size_in_bytes, sp_offset_for_orig_pc, 0, has_scalarized_args, needs_stack_repair);\n@@ -334,3 +330,2 @@\n-  if (needs_stack_repair && verified_inline_entry_label != NULL) {\n-    \/\/ Jump here from the scalarized entry points that require additional stack space\n-    \/\/ for packing scalarized arguments and therefore already created the frame.\n+  if (verified_inline_entry_label != NULL) {\n+    \/\/ Jump here from the scalarized entry points that already created the frame.\n@@ -368,6 +363,0 @@\n-  \/\/ Check if we need to extend the stack for packing\n-  int sp_inc = 0;\n-  if (args_on_stack > args_on_stack_cc) {\n-    sp_inc = extend_stack_for_inline_args(args_on_stack);\n-  }\n-\n@@ -375,4 +364,1 @@\n-  build_frame_helper(frame_size_in_bytes, sp_inc, ces->c1_needs_stack_repair());\n-\n-  \/\/ Initialize orig_pc to detect deoptimization during buffering in below runtime call\n-  str(zr, Address(sp, sp_offset_for_orig_pc));\n+  build_frame_helper(frame_size_in_bytes, sp_offset_for_orig_pc, 0, true, ces->c1_needs_stack_repair());\n@@ -382,0 +368,1 @@\n+  \/\/ C1 code is not hot enough to micro optimize the nmethod entry barrier with an out-of-line stub\n@@ -400,0 +387,6 @@\n+  \/\/ Check if we need to extend the stack for packing\n+  int sp_inc = 0;\n+  if (args_on_stack > args_on_stack_cc) {\n+    sp_inc = extend_stack_for_inline_args(args_on_stack);\n+  }\n+\n@@ -405,5 +398,3 @@\n-  if (ces->c1_needs_stack_repair()) {\n-    \/\/ Create the real frame. Below jump will then skip over the stack banging and frame\n-    \/\/ setup code in the verified_inline_entry (which has a different real_frame_size).\n-    build_frame_helper(frame_size_in_bytes, sp_inc, true);\n-  }\n+  \/\/ Create the real frame. Below jump will then skip over the stack banging and frame\n+  \/\/ setup code in the verified_inline_entry (which has a different real_frame_size).\n+  build_frame_helper(frame_size_in_bytes, sp_offset_for_orig_pc, sp_inc, true, ces->c1_needs_stack_repair());\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":18,"deletions":27,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -48,0 +48,22 @@\n+void C2_MacroAssembler::entry_barrier() {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  if (BarrierSet::barrier_set()->barrier_set_nmethod() != NULL) {\n+    \/\/ Dummy labels for just measuring the code size\n+    Label dummy_slow_path;\n+    Label dummy_continuation;\n+    Label dummy_guard;\n+    Label* slow_path = &dummy_slow_path;\n+    Label* continuation = &dummy_continuation;\n+    Label* guard = &dummy_guard;\n+    if (!Compile::current()->output()->in_scratch_emit_size()) {\n+      \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n+      C2EntryBarrierStub* stub = Compile::current()->output()->entry_barrier_table()->add_entry_barrier();\n+      slow_path = &stub->slow_path();\n+      continuation = &stub->continuation();\n+      guard = &stub->guard();\n+    }\n+    \/\/ In the C2 code, we move the non-hot part of nmethod entry barriers out-of-line to a stub.\n+    bs->nmethod_entry_barrier(this, slow_path, continuation, guard);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+  void entry_barrier();\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -166,0 +166,25 @@\n+static void set_value(nmethod* nm, jint val) {\n+  NativeNMethodBarrier* cmp1 = native_nmethod_barrier(nm);\n+  cmp1->set_value(nm, val);\n+\n+  if (!nm->is_osr_method() && nm->method()->has_scalarized_args()) {\n+    \/\/ nmethods with scalarized arguments have multiple entry points that each have an own nmethod entry barrier\n+    assert(nm->verified_entry_point() != nm->verified_inline_entry_point(), \"scalarized entry point not found\");\n+    address method_body = nm->is_compiled_by_c1() ? nm->verified_inline_entry_point() : nm->verified_entry_point();\n+    address entry_point2 = nm->is_compiled_by_c1() ? nm->verified_entry_point() : nm->verified_inline_entry_point();\n+\n+    int barrier_offset = reinterpret_cast<address>(cmp1) - method_body;\n+    NativeNMethodBarrier* cmp2 = reinterpret_cast<NativeNMethodBarrier*>(entry_point2 + barrier_offset);\n+    assert(cmp1 != cmp2, \"sanity\");\n+    debug_only(cmp2->verify());\n+    cmp2->set_value(nm, val);\n+\n+    if (method_body != nm->verified_inline_ro_entry_point() && entry_point2 != nm->verified_inline_ro_entry_point()) {\n+      NativeNMethodBarrier* cmp3 = reinterpret_cast<NativeNMethodBarrier*>(nm->verified_inline_ro_entry_point() + barrier_offset);\n+      assert(cmp1 != cmp3 && cmp2 != cmp3, \"sanity\");\n+      debug_only(cmp3->verify());\n+      cmp3->set_value(nm, val);\n+    }\n+  }\n+}\n+\n@@ -182,2 +207,1 @@\n-  NativeNMethodBarrier* barrier = native_nmethod_barrier(nm);\n-  barrier->set_value(nm, disarmed_value());\n+  set_value(nm, disarmed_value());\n@@ -202,2 +226,1 @@\n-  NativeNMethodBarrier* barrier = native_nmethod_barrier(nm);\n-  barrier->set_value(nm, arm_value);\n+  set_value(nm, arm_value);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetNMethod_aarch64.cpp","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -5954,7 +5954,3 @@\n-\n-  \/\/ n.b. frame size includes space for return pc and rfp\n-  const long framesize = C->output()->frame_size_in_bytes();\n-\n-  \/\/ insert a nop at the start of the prolog so we can patch in a\n-  \/\/ branch if we need to invalidate the method later\n-  nop();\n+  if (C->max_vector_size() > 0) {\n+    reinitialize_ptrue();\n+  }\n@@ -5966,0 +5962,2 @@\n+  \/\/ n.b. frame size includes space for return pc and rfp\n+  const long framesize = C->output()->frame_size_in_bytes();\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -618,0 +618,2 @@\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->c2i_entry_barrier(masm);\n@@ -1066,3 +1068,0 @@\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->c2i_entry_barrier(masm);\n-\n@@ -1081,0 +1080,2 @@\n+    \/\/ TODO 8294013 Fix this and add tests\n+    c2i_no_clinit_check_entry = __ pc();\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -315,1 +315,1 @@\n-void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_inc, bool needs_stack_repair) {\n+void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_offset_for_orig_pc, int sp_inc, bool has_scalarized_args, bool needs_stack_repair) {\n@@ -334,3 +334,0 @@\n-}\n-\n-void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_inline_entry_label) {\n@@ -339,4 +336,1 @@\n-    movptr(Address(rsp, sp_offset_for_orig_pc - frame_size_in_bytes - wordSize), 0);\n-  }\n-  if (!needs_stack_repair && verified_inline_entry_label != NULL) {\n-    bind(*verified_inline_entry_label);\n+    movptr(Address(rsp, sp_offset_for_orig_pc), 0);\n@@ -344,0 +338,3 @@\n+}\n+\n+void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_inline_entry_label) {\n@@ -352,1 +349,1 @@\n-  build_frame_helper(frame_size_in_bytes, 0, needs_stack_repair);\n+  build_frame_helper(frame_size_in_bytes, sp_offset_for_orig_pc, 0, has_scalarized_args, needs_stack_repair);\n@@ -358,3 +355,2 @@\n-  if (needs_stack_repair && verified_inline_entry_label != NULL) {\n-    \/\/ Jump here from the scalarized entry points that require additional stack space\n-    \/\/ for packing scalarized arguments and therefore already created the frame.\n+  if (verified_inline_entry_label != NULL) {\n+    \/\/ Jump here from the scalarized entry points that already created the frame.\n@@ -399,6 +395,0 @@\n-  \/\/ Check if we need to extend the stack for packing\n-  int sp_inc = 0;\n-  if (args_on_stack > args_on_stack_cc) {\n-    sp_inc = extend_stack_for_inline_args(args_on_stack);\n-  }\n-\n@@ -406,4 +396,1 @@\n-  build_frame_helper(frame_size_in_bytes, sp_inc, ces->c1_needs_stack_repair());\n-\n-  \/\/ Initialize orig_pc to detect deoptimization during buffering in below runtime call\n-  movptr(Address(rsp, sp_offset_for_orig_pc), 0);\n+  build_frame_helper(frame_size_in_bytes, sp_offset_for_orig_pc, 0, true, ces->c1_needs_stack_repair());\n@@ -413,0 +400,1 @@\n+  \/\/ C1 code is not hot enough to micro optimize the nmethod entry barrier with an out-of-line stub\n@@ -428,0 +416,6 @@\n+  \/\/ Check if we need to extend the stack for packing\n+  int sp_inc = 0;\n+  if (args_on_stack > args_on_stack_cc) {\n+    sp_inc = extend_stack_for_inline_args(args_on_stack);\n+  }\n+\n@@ -433,5 +427,3 @@\n-  if (ces->c1_needs_stack_repair()) {\n-    \/\/ Create the real frame. Below jump will then skip over the stack banging and frame\n-    \/\/ setup code in the verified_inline_entry (which has a different real_frame_size).\n-    build_frame_helper(frame_size_in_bytes, sp_inc, true);\n-  }\n+  \/\/ Create the real frame. Below jump will then skip over the stack banging and frame\n+  \/\/ setup code in the verified_inline_entry (which has a different real_frame_size).\n+  build_frame_helper(frame_size_in_bytes, sp_offset_for_orig_pc, sp_inc, true, ces->c1_needs_stack_repair());\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":19,"deletions":27,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -141,0 +141,23 @@\n+void C2_MacroAssembler::entry_barrier() {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+#ifdef _LP64\n+  if (BarrierSet::barrier_set()->barrier_set_nmethod() != NULL) {\n+    \/\/ We put the non-hot code of the nmethod entry barrier out-of-line in a stub.\n+    Label dummy_slow_path;\n+    Label dummy_continuation;\n+    Label* slow_path = &dummy_slow_path;\n+    Label* continuation = &dummy_continuation;\n+    if (!Compile::current()->output()->in_scratch_emit_size()) {\n+      \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n+      C2EntryBarrierStub* stub = Compile::current()->output()->entry_barrier_table()->add_entry_barrier();\n+      slow_path = &stub->slow_path();\n+      continuation = &stub->continuation();\n+    }\n+    bs->nmethod_entry_barrier(this, slow_path, continuation);\n+  }\n+#else\n+  \/\/ Don't bother with out-of-line nmethod entry barrier stub for x86_32.\n+  bs->nmethod_entry_barrier(this, NULL \/* slow_path *\/, NULL \/* continuation *\/);\n+#endif\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+  void entry_barrier();\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -179,0 +179,25 @@\n+static void set_immediate(nmethod* nm, jint val) {\n+  NativeNMethodCmpBarrier* cmp1 = native_nmethod_barrier(nm);\n+  cmp1->set_immediate(val);\n+\n+  if (!nm->is_osr_method() && nm->method()->has_scalarized_args()) {\n+    \/\/ nmethods with scalarized arguments have multiple entry points that each have an own nmethod entry barrier\n+    assert(nm->verified_entry_point() != nm->verified_inline_entry_point(), \"scalarized entry point not found\");\n+    address method_body = nm->is_compiled_by_c1() ? nm->verified_inline_entry_point() : nm->verified_entry_point();\n+    address entry_point2 = nm->is_compiled_by_c1() ? nm->verified_entry_point() : nm->verified_inline_entry_point();\n+\n+    int barrier_offset = reinterpret_cast<address>(cmp1) - method_body;\n+    NativeNMethodCmpBarrier* cmp2 = reinterpret_cast<NativeNMethodCmpBarrier*>(entry_point2 + barrier_offset);\n+    assert(cmp1 != cmp2, \"sanity\");\n+    debug_only(cmp2->verify());\n+    cmp2->set_immediate(val);\n+\n+    if (method_body != nm->verified_inline_ro_entry_point() && entry_point2 != nm->verified_inline_ro_entry_point()) {\n+      NativeNMethodCmpBarrier* cmp3 = reinterpret_cast<NativeNMethodCmpBarrier*>(nm->verified_inline_ro_entry_point() + barrier_offset);\n+      assert(cmp1 != cmp3 && cmp2 != cmp3, \"sanity\");\n+      debug_only(cmp3->verify());\n+      cmp3->set_immediate(val);\n+    }\n+  }\n+}\n+\n@@ -184,2 +209,1 @@\n-  NativeNMethodCmpBarrier* cmp = native_nmethod_barrier(nm);\n-  cmp->set_immediate(disarmed_value());\n+  set_immediate(nm, disarmed_value());\n@@ -193,2 +217,1 @@\n-  NativeNMethodCmpBarrier* cmp = native_nmethod_barrier(nm);\n-  cmp->set_immediate(arm_value);\n+  set_immediate(nm, arm_value);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetNMethod_x86.cpp","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -802,0 +802,3 @@\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->c2i_entry_barrier(masm);\n+\n@@ -1293,3 +1296,0 @@\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->c2i_entry_barrier(masm);\n-\n@@ -1308,0 +1308,2 @@\n+    \/\/ TODO 8294013 Fix this and add tests\n+    c2i_no_clinit_check_entry = __ pc();\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -920,23 +920,7 @@\n-  __ bind(*_verified_entry);\n-\n-  if (C->stub_function() == NULL) {\n-    BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n- #ifdef _LP64\n-    if (BarrierSet::barrier_set()->barrier_set_nmethod() != NULL) {\n-      \/\/ We put the non-hot code of the nmethod entry barrier out-of-line in a stub.\n-      Label dummy_slow_path;\n-      Label dummy_continuation;\n-      Label* slow_path = &dummy_slow_path;\n-      Label* continuation = &dummy_continuation;\n-      if (!Compile::current()->output()->in_scratch_emit_size()) {\n-        \/\/ Use real labels from actual stub when not emitting code for the purpose of measuring its size\n-        C2EntryBarrierStub* stub = Compile::current()->output()->entry_barrier_table()->add_entry_barrier();\n-        slow_path = &stub->slow_path();\n-        continuation = &stub->continuation();\n-      }\n-      bs->nmethod_entry_barrier(&_masm, slow_path, continuation);\n-    }\n-#else\n-    \/\/ Don't bother with out-of-line nmethod entry barrier stub for x86_32.\n-    bs->nmethod_entry_barrier(&_masm, NULL \/* slow_path *\/, NULL \/* continuation *\/);\n-#endif\n+\n+  if (ra_->C->stub_function() == NULL) {\n+    __ entry_barrier();\n+  }\n+\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    __ bind(*_verified_entry);\n@@ -1665,0 +1649,1 @@\n+  uint insts_size = cbuf.insts_size();\n@@ -1666,1 +1651,0 @@\n-    uint insts_size = cbuf.insts_size();\n@@ -1675,0 +1659,7 @@\n+    \/\/ TODO 8284443 Avoid creation of temporary frame\n+    if (ra_->C->stub_function() == NULL) {\n+      __ verified_entry(ra_->C, 0);\n+      __ entry_barrier();\n+      int initial_framesize = ra_->C->output()->frame_size_in_bytes() - 2*wordSize;\n+      __ remove_frame(initial_framesize, false);\n+    }\n@@ -1680,1 +1671,13 @@\n-    __ jmp(*_verified_entry);\n+    if (Compile::current()->output()->in_scratch_emit_size()) {\n+      Label dummy_verified_entry;\n+      __ jmp(dummy_verified_entry);\n+    } else {\n+      __ jmp(*_verified_entry);\n+    }\n+  }\n+  \/* WARNING these NOPs are critical so that verified entry point is properly\n+     4 bytes aligned for patching by NativeJump::patch_verified_entry() *\/\n+  int nops_cnt = 4 - ((cbuf.insts_size() - insts_size) & 0x3);\n+  nops_cnt &= 0x3; \/\/ Do not add nops if code is aligned.\n+  if (nops_cnt > 0) {\n+    __ nop(nops_cnt);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":28,"deletions":25,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  void build_frame_helper(int frame_size_in_bytes, int sp_inc, bool needs_stack_repair);\n+  void build_frame_helper(int frame_size_in_bytes, int sp_offset_for_orig_pc, int sp_inc, bool has_scalarized_args, bool needs_stack_repair);\n","filename":"src\/hotspot\/share\/c1\/c1_MacroAssembler.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -657,1 +657,1 @@\n-      \/\/ C2 -> interp: values passed fields\n+      \/\/ C2 -> interp: values passed as fields\n","filename":"src\/hotspot\/share\/code\/compiledIC.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-    \/\/ will re-resovle the call and update the compiled IC.\n+    \/\/ will re-resolve the call and update the compiled IC.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSetNMethod.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -54,1 +54,1 @@\n-    \/\/ will re-resovle the call and update the compiled IC.\n+    \/\/ will re-resolve the call and update the compiled IC.\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSetNMethod.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -291,3 +291,3 @@\n-  assert(_stub == NULL, \"There can only be one entry barrier stub\");\n-  _stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n-  return _stub;\n+  C2EntryBarrierStub* stub = new (Compile::current()->comp_arena()) C2EntryBarrierStub();\n+  _stubs.append(stub);\n+  return stub;\n@@ -297,1 +297,1 @@\n-  if (_stub == NULL) {\n+  if (_stubs.is_empty()) {\n@@ -303,5 +303,6 @@\n-  \/\/ Make sure there is enough space in the code buffer\n-  if (cb.insts()->maybe_expand_to_ensure_remaining(PhaseOutput::MAX_inst_size) && cb.blob() == NULL) {\n-    ciEnv::current()->record_failure(\"CodeCache is full\");\n-    return;\n-  }\n+  for (C2EntryBarrierStub* stub : _stubs) {\n+    \/\/ Make sure there is enough space in the code buffer\n+    if (cb.insts()->maybe_expand_to_ensure_remaining(PhaseOutput::MAX_inst_size) && cb.blob() == NULL) {\n+      ciEnv::current()->record_failure(\"CodeCache is full\");\n+      return;\n+    }\n@@ -309,6 +310,7 @@\n-  intptr_t before = masm.offset();\n-  masm.emit_entry_barrier_stub(_stub);\n-  intptr_t after = masm.offset();\n-  int actual_size = (int)(after - before);\n-  int expected_size = masm.entry_barrier_stub_size();\n-  assert(actual_size == expected_size, \"Estimated size is wrong, expected %d, was %d\", expected_size, actual_size);\n+    intptr_t before = masm.offset();\n+    masm.emit_entry_barrier_stub(stub);\n+    intptr_t after = masm.offset();\n+    int actual_size = (int)(after - before);\n+    int expected_size = masm.entry_barrier_stub_size();\n+    assert(actual_size == expected_size, \"Estimated size is wrong, expected %d, was %d\", expected_size, actual_size);\n+  }\n@@ -3448,6 +3450,0 @@\n-  } else if (n->is_MachProlog()) {\n-    saveL = ((MachPrologNode*)n)->_verified_entry;\n-    ((MachPrologNode*)n)->_verified_entry = &fakeL;\n-  } else if (n->is_MachVEP()) {\n-    saveL = ((MachVEPNode*)n)->_verified_entry;\n-    ((MachVEPNode*)n)->_verified_entry = &fakeL;\n@@ -3463,4 +3459,0 @@\n-  } else if (n->is_MachProlog()) {\n-    ((MachPrologNode*)n)->_verified_entry = saveL;\n-  } else if (n->is_MachVEP()) {\n-    ((MachVEPNode*)n)->_verified_entry = saveL;\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":17,"deletions":25,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -136,1 +136,1 @@\n-  C2EntryBarrierStub* _stub;\n+  GrowableArray<C2EntryBarrierStub*> _stubs;\n@@ -139,1 +139,1 @@\n-  C2EntryBarrierStubTable() : _stub(NULL) {}\n+  C2EntryBarrierStubTable() {}\n","filename":"src\/hotspot\/share\/opto\/output.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -362,1 +362,1 @@\n-    \/\/ addedin LIRGenerator::do_Base will detect the pending deoptimization by checking the original_pc).\n+    \/\/ added in LIRGenerator::do_Base will detect the pending deoptimization by checking the original_pc).\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1572,1 +1572,5 @@\n-      return callee->get_c2i_entry();\n+      if (caller_frame.is_interpreted_frame()) {\n+        return callee->get_c2i_inline_entry();\n+      } else {\n+        return callee->get_c2i_entry();\n+      }\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -104,0 +104,1 @@\n+    protected static final boolean DEOPT_BARRIERS_ALOT = (Boolean)WHITE_BOX.getVMFlag(\"DeoptimizeNMethodBarriersALot\");\n@@ -898,2 +899,1 @@\n-            TestRun.check(compiledByC1(m) != TriState.Yes || PER_METHOD_TRAP_LIMIT == 0 || !PROFILE_INTERPRETER,\n-                          m + \" should have been deoptimized by C1\");\n+            TestRun.check(compiledByC1(m) != TriState.Yes, m + \" should have been deoptimized by C1\");\n@@ -905,2 +905,1 @@\n-            TestRun.check(compiledByC2(m) != TriState.Yes || PER_METHOD_TRAP_LIMIT == 0 || !PROFILE_INTERPRETER,\n-                          m + \" should have been deoptimized by C2\");\n+            TestRun.check(compiledByC2(m) != TriState.Yes, m + \" should have been deoptimized by C2\");\n@@ -915,0 +914,1 @@\n+                PER_METHOD_TRAP_LIMIT != 0 && PROFILE_INTERPRETER && !DEOPT_BARRIERS_ALOT &&\n@@ -970,1 +970,1 @@\n-        if (!USE_COMPILER || XCOMP || TEST_C1 || IGNORE_COMPILER_CONTROLS || FLIP_C1_C2 ||\n+        if (!USE_COMPILER || XCOMP || TEST_C1 || IGNORE_COMPILER_CONTROLS || FLIP_C1_C2 || DEOPT_BARRIERS_ALOT ||\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/test\/TestVM.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"}]}