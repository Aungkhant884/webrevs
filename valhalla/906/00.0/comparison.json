{"files":[{"patch":"@@ -50,1 +50,1 @@\n-GrowableArrayCHeap<u1, mtClassShared>* ArchiveHeapWriter::_buffer;\n+GrowableArrayCHeap<u1, mtClassShared>* ArchiveHeapWriter::_buffer = nullptr;\n@@ -54,1 +54,1 @@\n-size_t ArchiveHeapWriter::_heap_roots_bottom_offset;\n+size_t ArchiveHeapWriter::_heap_roots_offset;\n@@ -156,1 +156,1 @@\n-  return cast_to_oop(_requested_bottom + _heap_roots_bottom_offset);\n+  return cast_to_oop(_requested_bottom + _heap_roots_offset);\n@@ -216,1 +216,1 @@\n-  _heap_roots_bottom_offset = _buffer_used;\n+  _heap_roots_offset = _buffer_used;\n@@ -342,1 +342,12 @@\n-  _requested_bottom = align_down(heap_end - heap_region_byte_size, HeapRegion::GrainBytes);\n+\n+  if (UseCompressedOops) {\n+    _requested_bottom = align_down(heap_end - heap_region_byte_size, HeapRegion::GrainBytes);\n+  } else {\n+    \/\/ We always write the objects as if the heap started at this address. This\n+    \/\/ makes the contents of the archive heap deterministic.\n+    \/\/\n+    \/\/ Note that at runtime, the heap address is selected by the OS, so the archive\n+    \/\/ heap will not be mapped at 0x10000000, and the contents need to be patched.\n+    _requested_bottom = (address)NOCOOPS_REQUESTED_BASE;\n+  }\n+\n@@ -347,2 +358,3 @@\n-  info->set_memregion(MemRegion(offset_to_buffered_address<HeapWord*>(0),\n-                                offset_to_buffered_address<HeapWord*>(_buffer_used)));\n+  info->set_buffer_region(MemRegion(offset_to_buffered_address<HeapWord*>(0),\n+                                    offset_to_buffered_address<HeapWord*>(_buffer_used)));\n+  info->set_heap_roots_offset(_heap_roots_offset);\n@@ -374,3 +386,2 @@\n-void ArchiveHeapWriter::store_oop_in_buffer(oop* buffered_addr, oop requested_obj) {\n-  \/\/ Make heap content deterministic. See comments inside HeapShared::to_requested_address.\n-  *buffered_addr = HeapShared::to_requested_address(requested_obj);\n+inline void ArchiveHeapWriter::store_oop_in_buffer(oop* buffered_addr, oop requested_obj) {\n+  *buffered_addr = requested_obj;\n@@ -379,3 +390,1 @@\n-void ArchiveHeapWriter::store_oop_in_buffer(narrowOop* buffered_addr, oop requested_obj) {\n-  \/\/ Note: HeapShared::to_requested_address() is not necessary because\n-  \/\/ the heap always starts at a deterministic address with UseCompressedOops==true.\n+inline void ArchiveHeapWriter::store_oop_in_buffer(narrowOop* buffered_addr, oop requested_obj) {\n@@ -484,1 +493,1 @@\n-  oop requested_roots = requested_obj_from_buffer_offset(_heap_roots_bottom_offset);\n+  oop requested_roots = requested_obj_from_buffer_offset(_heap_roots_offset);\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":23,"deletions":14,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -275,11 +275,0 @@\n-    if (UseCompressedOops) {\n-      _heap_begin = CompressedOops::begin();\n-      _heap_end = CompressedOops::end();\n-    } else {\n-#if INCLUDE_G1GC\n-      address start = (address)G1CollectedHeap::heap()->reserved().start();\n-      address end = (address)G1CollectedHeap::heap()->reserved().end();\n-      _heap_begin = HeapShared::to_requested_address(start);\n-      _heap_end = HeapShared::to_requested_address(end);\n-#endif\n-    }\n@@ -355,2 +344,0 @@\n-  st->print_cr(\"- heap_begin:                     \" INTPTR_FORMAT, p2i(_heap_begin));\n-  st->print_cr(\"- heap_end:                       \" INTPTR_FORMAT, p2i(_heap_end));\n@@ -369,0 +356,1 @@\n+  st->print_cr(\"- heap_roots_offset:              \" SIZE_FORMAT, _heap_roots_offset);\n@@ -1641,3 +1629,1 @@\n-#if INCLUDE_G1GC\n-      mapping_offset = requested_base - (char*)G1CollectedHeap::heap()->reserved().start();\n-#endif\n+      mapping_offset = 0; \/\/ not used with !UseCompressedOops\n@@ -1708,4 +1694,5 @@\n-  char* start = heap_info->start();\n-  size_t size = heap_info->byte_size();\n-  write_region(MetaspaceShared::hp, start, size, false, false);\n-  return size;\n+  char* buffer_start = heap_info->buffer_start();\n+  size_t buffer_size = heap_info->buffer_byte_size();\n+  write_region(MetaspaceShared::hp, buffer_start, buffer_size, false, false);\n+  header()->set_heap_roots_offset(heap_info->heap_roots_offset());\n+  return buffer_size;\n@@ -2101,3 +2088,0 @@\n-  log_info(cds)(\"    heap range = [\" PTR_FORMAT \" - \"  PTR_FORMAT \"]\",\n-                p2i(header()->heap_begin()), p2i(header()->heap_end()));\n-\n@@ -2158,3 +2142,4 @@\n-    \/\/ We can avoid relocation if each region is mapped into the exact same address\n-    \/\/ where it was at dump time.\n-    return \/*dumptime*\/header()->heap_begin() + r->mapping_offset();\n+    \/\/ This was the hard-coded requested base address used at dump time. With uncompressed oops,\n+    \/\/ the heap range is assigned by the OS so we will most likely have to relocate anyway, no matter\n+    \/\/ what base address was picked at duump time.\n+    return (address)ArchiveHeapWriter::NOCOOPS_REQUESTED_BASE;\n@@ -2246,1 +2231,1 @@\n-  ArchiveHeapLoader::init_mapped_heap_relocation(delta, narrow_oop_shift());\n+  ArchiveHeapLoader::init_mapped_heap_info(mapped_start, delta, narrow_oop_shift());\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":12,"deletions":27,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -230,2 +230,0 @@\n-  address _heap_begin;                            \/\/ heap begin at dump time.\n-  address _heap_end;                              \/\/ heap end at dump time.\n@@ -265,0 +263,2 @@\n+  size_t _heap_roots_offset;            \/\/ Offset of the HeapShared::roots() object, from the bottom\n+                                        \/\/ of the archived heap objects, in bytes.\n@@ -296,2 +296,0 @@\n-  address heap_begin()                     const { return _heap_begin; }\n-  address heap_end()                       const { return _heap_end; }\n@@ -306,0 +304,1 @@\n+  size_t heap_roots_offset()               const { return _heap_roots_offset; }\n@@ -317,0 +316,1 @@\n+  void set_heap_roots_offset(size_t n)           { _heap_roots_offset = n; }\n@@ -416,0 +416,1 @@\n+  size_t  heap_roots_offset()  const { return header()->heap_roots_offset(); }\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -371,1 +371,0 @@\n-  HeapShared::serialize_root(soc);\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+class SerializeClosure;\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -35,0 +35,2 @@\n+class SerializeClosure;\n+\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+  LOG_TAG(cause) \\\n@@ -127,0 +128,1 @@\n+  LOG_TAG(native) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -338,39 +338,0 @@\n-\/\/ Abstract closure for serializing data (read or write).\n-\n-class SerializeClosure : public Closure {\n-public:\n-  \/\/ Return bool indicating whether closure implements read or write.\n-  virtual bool reading() const = 0;\n-\n-  \/\/ Read\/write the void pointer pointed to by p.\n-  virtual void do_ptr(void** p) = 0;\n-\n-  \/\/ Read\/write the 32-bit unsigned integer pointed to by p.\n-  virtual void do_u4(u4* p) = 0;\n-\n-  \/\/ Read\/write the int pointed to by p.\n-  virtual void do_int(int* p) = 0;\n-\n-  \/\/ Read\/write the bool pointed to by p.\n-  virtual void do_bool(bool* p) = 0;\n-\n-  \/\/ Read\/write the region specified.\n-  virtual void do_region(u_char* start, size_t size) = 0;\n-\n-  \/\/ Check\/write the tag.  If reading, then compare the tag against\n-  \/\/ the passed in value and fail is they don't match.  This allows\n-  \/\/ for verification that sections of the serialized data are of the\n-  \/\/ correct length.\n-  virtual void do_tag(int tag) = 0;\n-\n-  \/\/ Read\/write the oop\n-  virtual void do_oop(oop* o) = 0;\n-\n-  bool writing() {\n-    return !reading();\n-  }\n-\n-  \/\/ Useful alias\n-  template <typename T> void do_ptr(T** p) { do_ptr((void**)p); }\n-};\n-\n","filename":"src\/hotspot\/share\/memory\/iterator.hpp","additions":0,"deletions":39,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -87,0 +87,1 @@\n+#include \"runtime\/os.inline.hpp\"\n@@ -4036,0 +4037,1 @@\n+\n@@ -4040,0 +4042,8 @@\n+  print_class_load_helper(loader_data, module_entry, cfs);\n+  print_class_load_cause_logging();\n+}\n+\n+void InstanceKlass::print_class_load_helper(ClassLoaderData* loader_data,\n+                                             const ModuleEntry* module_entry,\n+                                             const ClassFileStream* cfs) const {\n+\n@@ -4097,1 +4107,1 @@\n-                       p2i(this),  p2i(superklass()));\n+                      p2i(this),  p2i(superklass()));\n@@ -4105,1 +4115,1 @@\n-                           p2i(InstanceKlass::cast(local_interfaces()->at(i))));\n+                          p2i(InstanceKlass::cast(local_interfaces()->at(i))));\n@@ -4117,3 +4127,3 @@\n-                         cfs->length(),\n-                         ClassLoader::crc32(0, (const char*)cfs->buffer(),\n-                         cfs->length()));\n+                        cfs->length(),\n+                        ClassLoader::crc32(0, (const char*)cfs->buffer(),\n+                        cfs->length()));\n@@ -4126,0 +4136,60 @@\n+void InstanceKlass::print_class_load_cause_logging() const {\n+  bool log_cause_native = log_is_enabled(Info, class, load, cause, native);\n+  if (log_cause_native || log_is_enabled(Info, class, load, cause)) {\n+    JavaThread* current = JavaThread::current();\n+    ResourceMark rm(current);\n+    const char* name = external_name();\n+\n+    if (LogClassLoadingCauseFor == nullptr ||\n+        (strcmp(\"*\", LogClassLoadingCauseFor) != 0 &&\n+         strstr(name, LogClassLoadingCauseFor) == nullptr)) {\n+        return;\n+    }\n+\n+    \/\/ Log Java stack first\n+    {\n+      LogMessage(class, load, cause) msg;\n+      NonInterleavingLogStream info_stream{LogLevelType::Info, msg};\n+\n+      info_stream.print_cr(\"Java stack when loading %s:\", name);\n+      current->print_stack_on(&info_stream);\n+    }\n+\n+    \/\/ Log native stack second\n+    if (log_cause_native) {\n+      \/\/ Log to string first so that lines can be indented\n+      stringStream stack_stream;\n+      char buf[O_BUFLEN];\n+      address lastpc = nullptr;\n+      if (os::platform_print_native_stack(&stack_stream, nullptr, buf, O_BUFLEN, lastpc)) {\n+        \/\/ We have printed the native stack in platform-specific code,\n+        \/\/ so nothing else to do in this case.\n+      } else {\n+        frame f = os::current_frame();\n+        VMError::print_native_stack(&stack_stream, f, current, true \/*print_source_info *\/,\n+                                    -1 \/* max stack_stream *\/, buf, O_BUFLEN);\n+      }\n+\n+      LogMessage(class, load, cause, native) msg;\n+      NonInterleavingLogStream info_stream{LogLevelType::Info, msg};\n+      info_stream.print_cr(\"Native stack when loading %s:\", name);\n+\n+      \/\/ Print each native stack line to the log\n+      int size = (int) stack_stream.size();\n+      char* stack = stack_stream.as_string();\n+      char* stack_end = stack + size;\n+      char* line_start = stack;\n+      for (char* p = stack; p < stack_end; p++) {\n+        if (*p == '\\n') {\n+          *p = '\\0';\n+          info_stream.print_cr(\"\\t%s\", line_start);\n+          line_start = p + 1;\n+        }\n+      }\n+      if (line_start < stack_end) {\n+        info_stream.print_cr(\"\\t%s\", line_start);\n+      }\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":75,"deletions":5,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -1245,0 +1245,5 @@\n+ private:\n+  void print_class_load_cause_logging() const;\n+  void print_class_load_helper(ClassLoaderData* loader_data,\n+                               const ModuleEntry* module_entry,\n+                               const ClassFileStream* cfs) const;\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -784,0 +784,4 @@\n+    if (call->is_CallStaticJava() && call->as_CallStaticJava()->is_boxing_method()) {\n+      result = kit.must_be_not_null(result, false);\n+    }\n+\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1967,20 +1967,23 @@\n-    if (rc != nullptr &&\n-        rc->is_Proj()) {\n-      if (worklist.member(rc)) {\n-        delay = true;\n-      } else if (rc->in(0) != nullptr &&\n-                 rc->in(0)->is_If()) {\n-        if (worklist.member(rc->in(0))) {\n-          delay = true;\n-        } else if (rc->in(0)->in(1) != nullptr &&\n-                   rc->in(0)->in(1)->is_Bool()) {\n-          if (worklist.member(rc->in(0)->in(1))) {\n-            delay = true;\n-          } else if (rc->in(0)->in(1)->in(1) != nullptr &&\n-                     rc->in(0)->in(1)->in(1)->is_Cmp()) {\n-            if (worklist.member(rc->in(0)->in(1)->in(1))) {\n-              delay = true;\n-            }\n-          }\n-        }\n-      }\n+\n+    if (rc == nullptr || !rc->is_Proj()) { continue; }\n+    if (worklist.member(rc)) {\n+      delay = true;\n+      break;\n+    }\n+\n+    if (rc->in(0) == nullptr || !rc->in(0)->is_If()) { continue; }\n+    if (worklist.member(rc->in(0))) {\n+      delay = true;\n+      break;\n+    }\n+\n+    if (rc->in(0)->in(1) == nullptr || !rc->in(0)->in(1)->is_Bool()) { continue; }\n+    if (worklist.member(rc->in(0)->in(1))) {\n+      delay = true;\n+      break;\n+    }\n+\n+    if (rc->in(0)->in(1)->in(1) == nullptr || !rc->in(0)->in(1)->in(1)->is_Cmp()) { continue; }\n+    if (worklist.member(rc->in(0)->in(1)->in(1))) {\n+      delay = true;\n+      break;\n@@ -1989,0 +1992,1 @@\n+\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":24,"deletions":20,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -852,1 +852,1 @@\n-    if (FLAG_IS_DEFAULT(StressSeed) || (FLAG_IS_ERGO(StressSeed) && RepeatCompilation)) {\n+    if (FLAG_IS_DEFAULT(StressSeed) || (FLAG_IS_ERGO(StressSeed) && directive->RepeatCompilationOption)) {\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -836,1 +836,3 @@\n-    extypes->append(TypeOopPtr::make_from_klass(env()->Throwable_klass())->is_instptr());\n+    const Type* extype = TypeOopPtr::make_from_klass(env()->Throwable_klass())->is_instptr();\n+    extype = extype->join(TypeInstPtr::NOTNULL);\n+    extypes->append(extype);\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -94,1 +94,2 @@\n-  for( i4 = 1; i4 < phi->req(); i4++ ) {\n+  RegionNode* phi_region = phi->region();\n+  for (i4 = 1; i4 < phi->req(); i4++ ) {\n@@ -96,1 +97,5 @@\n-    if( !con1 ) return nullptr;    \/\/ Do not optimize partially collapsed merges\n+    \/\/ Do not optimize partially collapsed merges\n+    if (con1 == nullptr || phi_region->in(i4) == nullptr || igvn->type(phi_region->in(i4)) == Type::TOP) {\n+      igvn->_worklist.push(iff);\n+      return nullptr;\n+    }\n@@ -118,1 +123,1 @@\n-  if (!r->is_Region() || r->is_Loop() || phi->region() != r || r->as_Region()->is_copy()) {\n+  if (!r->is_Region() || r->is_Loop() || phi_region != r || r->as_Region()->is_copy()) {\n","filename":"src\/hotspot\/share\/opto\/ifnode.cpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -4312,1 +4312,1 @@\n-      slow_call = generate_method_call(vmIntrinsics::_allocateUninitializedArray, false, false);\n+      slow_call = generate_method_call(vmIntrinsics::_allocateUninitializedArray, false, false, true);\n@@ -4314,1 +4314,1 @@\n-      slow_call = generate_method_call_static(vmIntrinsics::_newArray);\n+      slow_call = generate_method_call_static(vmIntrinsics::_newArray, true);\n@@ -4603,1 +4603,1 @@\n-LibraryCallKit::generate_method_call(vmIntrinsics::ID method_id, bool is_virtual, bool is_static) {\n+LibraryCallKit::generate_method_call(vmIntrinsicID method_id, bool is_virtual, bool is_static, bool res_not_null) {\n@@ -4612,0 +4612,8 @@\n+  if (res_not_null) {\n+    assert(tf->return_type() == T_OBJECT, \"\");\n+    const TypeTuple* range = tf->range_cc();\n+    const Type** fields = TypeTuple::fields(range->cnt());\n+    fields[TypeFunc::Parms] = range->field_at(TypeFunc::Parms)->filter_speculative(TypePtr::NOTNULL);\n+    const TypeTuple* new_range = TypeTuple::make(range->cnt(), fields);\n+    tf = TypeFunc::make(tf->domain_cc(), new_range);\n+  }\n@@ -4766,1 +4774,1 @@\n-    CallJavaNode* slow_call = generate_method_call(hashCode_id, is_virtual, is_static);\n+    CallJavaNode* slow_call = generate_method_call(hashCode_id, is_virtual, is_static, false);\n@@ -5317,1 +5325,1 @@\n-      CallJavaNode* slow_call = generate_method_call(vmIntrinsics::_clone, is_virtual);\n+      CallJavaNode* slow_call = generate_method_call(vmIntrinsics::_clone, is_virtual, false, true);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":13,"deletions":5,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -199,7 +199,3 @@\n-  CallJavaNode* generate_method_call(vmIntrinsics::ID method_id,\n-                                     bool is_virtual = false, bool is_static = false);\n-  CallJavaNode* generate_method_call_static(vmIntrinsics::ID method_id) {\n-    return generate_method_call(method_id, false, true);\n-  }\n-  CallJavaNode* generate_method_call_virtual(vmIntrinsics::ID method_id) {\n-    return generate_method_call(method_id, true, false);\n+  CallJavaNode* generate_method_call(vmIntrinsicID method_id, bool is_virtual, bool is_static, bool res_not_null);\n+  CallJavaNode* generate_method_call_static(vmIntrinsicID method_id, bool res_not_null) {\n+    return generate_method_call(method_id, false, true, res_not_null);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":3,"deletions":7,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+  assert(sub_t != Type::TOP && !TypePtr::NULL_PTR->higher_equal(sub_t), \"should be not null\");\n","filename":"src\/hotspot\/share\/opto\/subtypenode.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1152,1 +1152,1 @@\n-                  \"Did you mean '%s%s%s'? \",\n+                  \"Did you mean '%s%s%s'?\\n\",\n@@ -1926,1 +1926,1 @@\n-                  \"Conflicting -XX:+UseHeavyMonitors and -XX:LockingMode=%d flags\", LockingMode);\n+                  \"Conflicting -XX:+UseHeavyMonitors and -XX:LockingMode=%d flags\\n\", LockingMode);\n@@ -1935,1 +1935,1 @@\n-                \"LockingMode == 0 (LM_MONITOR) is not fully implemented on this architecture\");\n+                \"LockingMode == 0 (LM_MONITOR) is not fully implemented on this architecture\\n\");\n@@ -1942,1 +1942,1 @@\n-                \"LockingMode == 0 (LM_MONITOR) and -XX:+UseRTMForStackLocks are mutually exclusive\");\n+                \"LockingMode == 0 (LM_MONITOR) and -XX:+UseRTMForStackLocks are mutually exclusive\\n\");\n@@ -1949,1 +1949,1 @@\n-                \"-XX:+VerifyHeavyMonitors requires LockingMode == 0 (LM_MONITOR)\");\n+                \"-XX:+VerifyHeavyMonitors requires LockingMode == 0 (LM_MONITOR)\\n\");\n@@ -2910,1 +2910,1 @@\n-              \"Value of jvmci.Compiler incompatible with +UseGraalJIT: %s\", jvmci_compiler);\n+              \"Value of jvmci.Compiler incompatible with +UseGraalJIT: %s\\n\", jvmci_compiler);\n@@ -2927,1 +2927,1 @@\n-            \"Unable to enable JVMCI in product mode\");\n+            \"Unable to enable JVMCI in product mode\\n\");\n@@ -4042,1 +4042,1 @@\n-                \"Syntax error, expecting -XX:NativeMemoryTracking=[off|summary|detail]\", nullptr);\n+                \"Syntax error, expecting -XX:NativeMemoryTracking=[off|summary|detail]\\n\");\n@@ -4055,0 +4055,6 @@\n+  bool log_class_load_cause = log_is_enabled(Info, class, load, cause, native) ||\n+                              log_is_enabled(Info, class, load, cause);\n+  if (log_class_load_cause && LogClassLoadingCauseFor == nullptr) {\n+    warning(\"class load cause logging will not produce output without LogClassLoadingCauseFor\");\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":14,"deletions":8,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -954,0 +954,5 @@\n+  product(ccstr, LogClassLoadingCauseFor, nullptr,                          \\\n+          \"Apply -Xlog:class+load+cause* to classes whose fully \"           \\\n+          \"qualified name contains this string (\\\"*\\\" matches \"             \\\n+          \"any class).\")                                                    \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2156,3 +2156,0 @@\n-  assert(!JavaThread::current()->is_interp_only_mode() || !nm->method()->is_continuation_enter_intrinsic()\n-    || ContinuationEntry::is_interpreted_call(return_pc), \"interp_only_mode but not in enterSpecial interpreted entry\");\n-\n@@ -2196,2 +2193,0 @@\n-        assert(ContinuationEntry::is_interpreted_call(call->instruction_address()) == JavaThread::current()->is_interp_only_mode(),\n-          \"mode: %d\", JavaThread::current()->is_interp_only_mode());\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"}]}