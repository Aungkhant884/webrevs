{"files":[{"patch":"@@ -1365,1 +1365,1 @@\n-var getVersion = function (feature, interim, update, patch) {\n+var getVersion = function (feature, interim, update, patch, extra1, extra2, extra3) {\n@@ -1371,3 +1371,3 @@\n-        + \".\" + version_numbers.get(\"DEFAULT_VERSION_EXTRA1\")\n-        + \".\" + version_numbers.get(\"DEFAULT_VERSION_EXTRA2\")\n-        + \".\" + version_numbers.get(\"DEFAULT_VERSION_EXTRA3\");\n+        + \".\" + (extra1 != null ? extra1 : version_numbers.get(\"DEFAULT_VERSION_EXTRA1\"))\n+        + \".\" + (extra2 != null ? extra2 : version_numbers.get(\"DEFAULT_VERSION_EXTRA2\"))\n+        + \".\" + (extra3 != null ? extra3 : version_numbers.get(\"DEFAULT_VERSION_EXTRA3\"));\n","filename":"make\/conf\/jib-profiles.js","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -16635,2440 +16635,0 @@\n-\/\/ ====================VECTOR INSTRUCTIONS=====================================\n-\n-\/\/ Load vector (32 bits)\n-instruct loadV4(vecD dst, vmem4 mem)\n-%{\n-  predicate(n->as_LoadVector()->memory_size() == 4);\n-  match(Set dst (LoadVector mem));\n-  ins_cost(4 * INSN_COST);\n-  format %{ \"ldrs   $dst,$mem\\t# vector (32 bits)\" %}\n-  ins_encode( aarch64_enc_ldrvS(dst, mem) );\n-  ins_pipe(vload_reg_mem64);\n-%}\n-\n-\/\/ Load vector (64 bits)\n-instruct loadV8(vecD dst, vmem8 mem)\n-%{\n-  predicate(n->as_LoadVector()->memory_size() == 8);\n-  match(Set dst (LoadVector mem));\n-  ins_cost(4 * INSN_COST);\n-  format %{ \"ldrd   $dst,$mem\\t# vector (64 bits)\" %}\n-  ins_encode( aarch64_enc_ldrvD(dst, mem) );\n-  ins_pipe(vload_reg_mem64);\n-%}\n-\n-\/\/ Load Vector (128 bits)\n-instruct loadV16(vecX dst, vmem16 mem)\n-%{\n-  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 16);\n-  match(Set dst (LoadVector mem));\n-  ins_cost(4 * INSN_COST);\n-  format %{ \"ldrq   $dst,$mem\\t# vector (128 bits)\" %}\n-  ins_encode( aarch64_enc_ldrvQ(dst, mem) );\n-  ins_pipe(vload_reg_mem128);\n-%}\n-\n-\/\/ Store Vector (32 bits)\n-instruct storeV4(vecD src, vmem4 mem)\n-%{\n-  predicate(n->as_StoreVector()->memory_size() == 4);\n-  match(Set mem (StoreVector mem src));\n-  ins_cost(4 * INSN_COST);\n-  format %{ \"strs   $mem,$src\\t# vector (32 bits)\" %}\n-  ins_encode( aarch64_enc_strvS(src, mem) );\n-  ins_pipe(vstore_reg_mem64);\n-%}\n-\n-\/\/ Store Vector (64 bits)\n-instruct storeV8(vecD src, vmem8 mem)\n-%{\n-  predicate(n->as_StoreVector()->memory_size() == 8);\n-  match(Set mem (StoreVector mem src));\n-  ins_cost(4 * INSN_COST);\n-  format %{ \"strd   $mem,$src\\t# vector (64 bits)\" %}\n-  ins_encode( aarch64_enc_strvD(src, mem) );\n-  ins_pipe(vstore_reg_mem64);\n-%}\n-\n-\/\/ Store Vector (128 bits)\n-instruct storeV16(vecX src, vmem16 mem)\n-%{\n-  predicate(n->as_StoreVector()->memory_size() == 16);\n-  match(Set mem (StoreVector mem src));\n-  ins_cost(4 * INSN_COST);\n-  format %{ \"strq   $mem,$src\\t# vector (128 bits)\" %}\n-  ins_encode( aarch64_enc_strvQ(src, mem) );\n-  ins_pipe(vstore_reg_mem128);\n-%}\n-\n-instruct replicate8B(vecD dst, iRegIorL2I src)\n-%{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (ReplicateB src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg64);\n-%}\n-\n-instruct replicate16B(vecX dst, iRegIorL2I src)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 16);\n-  match(Set dst (ReplicateB src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg128);\n-%}\n-\n-instruct replicate8B_imm(vecD dst, immI con)\n-%{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (ReplicateB con));\n-  ins_cost(INSN_COST);\n-  format %{ \"movi  $dst, $con\\t# vector(8B)\" %}\n-  ins_encode %{\n-    __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant & 0xff);\n-  %}\n-  ins_pipe(vmovi_reg_imm64);\n-%}\n-\n-instruct replicate16B_imm(vecX dst, immI con)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 16);\n-  match(Set dst (ReplicateB con));\n-  ins_cost(INSN_COST);\n-  format %{ \"movi  $dst, $con\\t# vector(16B)\" %}\n-  ins_encode %{\n-    __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant & 0xff);\n-  %}\n-  ins_pipe(vmovi_reg_imm128);\n-%}\n-\n-instruct replicate4S(vecD dst, iRegIorL2I src)\n-%{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (ReplicateS src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg64);\n-%}\n-\n-instruct replicate8S(vecX dst, iRegIorL2I src)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 8);\n-  match(Set dst (ReplicateS src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (8S)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg128);\n-%}\n-\n-instruct replicate4S_imm(vecD dst, immI con)\n-%{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (ReplicateS con));\n-  ins_cost(INSN_COST);\n-  format %{ \"movi  $dst, $con\\t# vector(4H)\" %}\n-  ins_encode %{\n-    __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant & 0xffff);\n-  %}\n-  ins_pipe(vmovi_reg_imm64);\n-%}\n-\n-instruct replicate8S_imm(vecX dst, immI con)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 8);\n-  match(Set dst (ReplicateS con));\n-  ins_cost(INSN_COST);\n-  format %{ \"movi  $dst, $con\\t# vector(8H)\" %}\n-  ins_encode %{\n-    __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant & 0xffff);\n-  %}\n-  ins_pipe(vmovi_reg_imm128);\n-%}\n-\n-instruct replicate2I(vecD dst, iRegIorL2I src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (ReplicateI src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (2I)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg64);\n-%}\n-\n-instruct replicate4I(vecX dst, iRegIorL2I src)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 4);\n-  match(Set dst (ReplicateI src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (4I)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg128);\n-%}\n-\n-instruct replicate2I_imm(vecD dst, immI con)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (ReplicateI con));\n-  ins_cost(INSN_COST);\n-  format %{ \"movi  $dst, $con\\t# vector(2I)\" %}\n-  ins_encode %{\n-    __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);\n-  %}\n-  ins_pipe(vmovi_reg_imm64);\n-%}\n-\n-instruct replicate4I_imm(vecX dst, immI con)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 4);\n-  match(Set dst (ReplicateI con));\n-  ins_cost(INSN_COST);\n-  format %{ \"movi  $dst, $con\\t# vector(4I)\" %}\n-  ins_encode %{\n-    __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);\n-  %}\n-  ins_pipe(vmovi_reg_imm128);\n-%}\n-\n-instruct replicate2L(vecX dst, iRegL src)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n-  match(Set dst (ReplicateL src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (2L)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg128);\n-%}\n-\n-instruct replicate2L_zero(vecX dst, immI0 zero)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n-  match(Set dst (ReplicateI zero));\n-  ins_cost(INSN_COST);\n-  format %{ \"movi  $dst, $zero\\t# vector(4I)\" %}\n-  ins_encode %{\n-    __ eor(as_FloatRegister($dst$$reg), __ T16B,\n-           as_FloatRegister($dst$$reg),\n-           as_FloatRegister($dst$$reg));\n-  %}\n-  ins_pipe(vmovi_reg_imm128);\n-%}\n-\n-instruct replicate2F(vecD dst, vRegF src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (ReplicateF src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (2F)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T2S,\n-           as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_freg64);\n-%}\n-\n-instruct replicate4F(vecX dst, vRegF src)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 4);\n-  match(Set dst (ReplicateF src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (4F)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T4S,\n-           as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_freg128);\n-%}\n-\n-instruct replicate2D(vecX dst, vRegD src)\n-%{\n-  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n-  match(Set dst (ReplicateD src));\n-  ins_cost(INSN_COST);\n-  format %{ \"dup  $dst, $src\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T2D,\n-           as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vdup_reg_dreg128);\n-%}\n-\n-\/\/ ====================REDUCTION ARITHMETIC====================================\n-\n-instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)\n-%{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n-  match(Set dst (AddReductionVI isrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp, TEMP tmp2);\n-  format %{ \"umov  $tmp, $vsrc, S, 0\\n\\t\"\n-            \"umov  $tmp2, $vsrc, S, 1\\n\\t\"\n-            \"addw  $tmp, $isrc, $tmp\\n\\t\"\n-            \"addw  $dst, $tmp, $tmp2\\t# add reduction2I\"\n-  %}\n-  ins_encode %{\n-    __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);\n-    __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);\n-    __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);\n-    __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)\n-%{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n-  match(Set dst (AddReductionVI isrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP vtmp, TEMP itmp);\n-  format %{ \"addv  $vtmp, T4S, $vsrc\\n\\t\"\n-            \"umov  $itmp, $vtmp, S, 0\\n\\t\"\n-            \"addw  $dst, $itmp, $isrc\\t# add reduction4I\"\n-  %}\n-  ins_encode %{\n-    __ addv(as_FloatRegister($vtmp$$reg), __ T4S,\n-            as_FloatRegister($vsrc$$reg));\n-    __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);\n-    __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)\n-%{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n-  match(Set dst (MulReductionVI isrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp, TEMP dst);\n-  format %{ \"umov  $tmp, $vsrc, S, 0\\n\\t\"\n-            \"mul   $dst, $tmp, $isrc\\n\\t\"\n-            \"umov  $tmp, $vsrc, S, 1\\n\\t\"\n-            \"mul   $dst, $tmp, $dst\\t# mul reduction2I\"\n-  %}\n-  ins_encode %{\n-    __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);\n-    __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);\n-    __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);\n-    __ mul($dst$$Register, $tmp$$Register, $dst$$Register);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)\n-%{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n-  match(Set dst (MulReductionVI isrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP vtmp, TEMP itmp, TEMP dst);\n-  format %{ \"ins   $vtmp, D, $vsrc, 0, 1\\n\\t\"\n-            \"mulv  $vtmp, T2S, $vtmp, $vsrc\\n\\t\"\n-            \"umov  $itmp, $vtmp, S, 0\\n\\t\"\n-            \"mul   $dst, $itmp, $isrc\\n\\t\"\n-            \"umov  $itmp, $vtmp, S, 1\\n\\t\"\n-            \"mul   $dst, $itmp, $dst\\t# mul reduction4I\"\n-  %}\n-  ins_encode %{\n-    __ ins(as_FloatRegister($vtmp$$reg), __ D,\n-           as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,\n-            as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));\n-    __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);\n-    __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);\n-    __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);\n-    __ mul($dst$$Register, $itmp$$Register, $dst$$Register);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)\n-%{\n-  match(Set dst (AddReductionVF fsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp, TEMP dst);\n-  format %{ \"fadds $dst, $fsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 1\\n\\t\"\n-            \"fadds $dst, $dst, $tmp\\t# add reduction2F\"\n-  %}\n-  ins_encode %{\n-    __ fadds(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S,\n-           as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fadds(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)\n-%{\n-  match(Set dst (AddReductionVF fsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp, TEMP dst);\n-  format %{ \"fadds $dst, $fsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 1\\n\\t\"\n-            \"fadds $dst, $dst, $tmp\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 2\\n\\t\"\n-            \"fadds $dst, $dst, $tmp\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 3\\n\\t\"\n-            \"fadds $dst, $dst, $tmp\\t# add reduction4F\"\n-  %}\n-  ins_encode %{\n-    __ fadds(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S,\n-           as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fadds(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S,\n-           as_FloatRegister($vsrc$$reg), 0, 2);\n-    __ fadds(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S,\n-           as_FloatRegister($vsrc$$reg), 0, 3);\n-    __ fadds(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)\n-%{\n-  match(Set dst (MulReductionVF fsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp, TEMP dst);\n-  format %{ \"fmuls $dst, $fsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 1\\n\\t\"\n-            \"fmuls $dst, $dst, $tmp\\t# mul reduction2F\"\n-  %}\n-  ins_encode %{\n-    __ fmuls(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S,\n-           as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fmuls(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)\n-%{\n-  match(Set dst (MulReductionVF fsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp, TEMP dst);\n-  format %{ \"fmuls $dst, $fsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 1\\n\\t\"\n-            \"fmuls $dst, $dst, $tmp\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 2\\n\\t\"\n-            \"fmuls $dst, $dst, $tmp\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 3\\n\\t\"\n-            \"fmuls $dst, $dst, $tmp\\t# mul reduction4F\"\n-  %}\n-  ins_encode %{\n-    __ fmuls(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S,\n-           as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fmuls(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S,\n-           as_FloatRegister($vsrc$$reg), 0, 2);\n-    __ fmuls(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S,\n-           as_FloatRegister($vsrc$$reg), 0, 3);\n-    __ fmuls(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)\n-%{\n-  match(Set dst (AddReductionVD dsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp, TEMP dst);\n-  format %{ \"faddd $dst, $dsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, D, $vsrc, 0, 1\\n\\t\"\n-            \"faddd $dst, $dst, $tmp\\t# add reduction2D\"\n-  %}\n-  ins_encode %{\n-    __ faddd(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ D,\n-           as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ faddd(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)\n-%{\n-  match(Set dst (MulReductionVD dsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp, TEMP dst);\n-  format %{ \"fmuld $dst, $dsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, D, $vsrc, 0, 1\\n\\t\"\n-            \"fmuld $dst, $dst, $tmp\\t# mul reduction2D\"\n-  %}\n-  ins_encode %{\n-    __ fmuld(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ D,\n-           as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fmuld(as_FloatRegister($dst$$reg),\n-             as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-\/\/ ====================VECTOR ARITHMETIC=======================================\n-\n-\/\/ --------------------------------- ADD --------------------------------------\n-\n-instruct vadd8B(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (AddVB src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"addv  $dst,$src1,$src2\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ addv(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop64);\n-%}\n-\n-instruct vadd16B(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (AddVB src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"addv  $dst,$src1,$src2\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ addv(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop128);\n-%}\n-\n-instruct vadd4S(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (AddVS src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"addv  $dst,$src1,$src2\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ addv(as_FloatRegister($dst$$reg), __ T4H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop64);\n-%}\n-\n-instruct vadd8S(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (AddVS src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"addv  $dst,$src1,$src2\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ addv(as_FloatRegister($dst$$reg), __ T8H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop128);\n-%}\n-\n-instruct vadd2I(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AddVI src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"addv  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ addv(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop64);\n-%}\n-\n-instruct vadd4I(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AddVI src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"addv  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ addv(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop128);\n-%}\n-\n-instruct vadd2L(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AddVL src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"addv  $dst,$src1,$src2\\t# vector (2L)\" %}\n-  ins_encode %{\n-    __ addv(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop128);\n-%}\n-\n-instruct vadd2F(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AddVF src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fadd  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ fadd(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp64);\n-%}\n-\n-instruct vadd4F(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AddVF src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fadd  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ fadd(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-instruct vadd2D(vecX dst, vecX src1, vecX src2)\n-%{\n-  match(Set dst (AddVD src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fadd  $dst,$src1,$src2\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fadd(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-\/\/ --------------------------------- SUB --------------------------------------\n-\n-instruct vsub8B(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (SubVB src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"subv  $dst,$src1,$src2\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ subv(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop64);\n-%}\n-\n-instruct vsub16B(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (SubVB src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"subv  $dst,$src1,$src2\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ subv(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop128);\n-%}\n-\n-instruct vsub4S(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (SubVS src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"subv  $dst,$src1,$src2\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ subv(as_FloatRegister($dst$$reg), __ T4H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop64);\n-%}\n-\n-instruct vsub8S(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (SubVS src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"subv  $dst,$src1,$src2\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ subv(as_FloatRegister($dst$$reg), __ T8H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop128);\n-%}\n-\n-instruct vsub2I(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (SubVI src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"subv  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ subv(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop64);\n-%}\n-\n-instruct vsub4I(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (SubVI src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"subv  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ subv(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop128);\n-%}\n-\n-instruct vsub2L(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (SubVL src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"subv  $dst,$src1,$src2\\t# vector (2L)\" %}\n-  ins_encode %{\n-    __ subv(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop128);\n-%}\n-\n-instruct vsub2F(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (SubVF src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fsub  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ fsub(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp64);\n-%}\n-\n-instruct vsub4F(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (SubVF src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fsub  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ fsub(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-instruct vsub2D(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (SubVD src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fsub  $dst,$src1,$src2\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fsub(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-\/\/ --------------------------------- MUL --------------------------------------\n-\n-instruct vmul8B(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (MulVB src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"mulv  $dst,$src1,$src2\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ mulv(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmul64);\n-%}\n-\n-instruct vmul16B(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (MulVB src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"mulv  $dst,$src1,$src2\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ mulv(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmul128);\n-%}\n-\n-instruct vmul4S(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (MulVS src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"mulv  $dst,$src1,$src2\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ mulv(as_FloatRegister($dst$$reg), __ T4H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmul64);\n-%}\n-\n-instruct vmul8S(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (MulVS src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"mulv  $dst,$src1,$src2\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ mulv(as_FloatRegister($dst$$reg), __ T8H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmul128);\n-%}\n-\n-instruct vmul2I(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (MulVI src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"mulv  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ mulv(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmul64);\n-%}\n-\n-instruct vmul4I(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (MulVI src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"mulv  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ mulv(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmul128);\n-%}\n-\n-instruct vmul2F(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (MulVF src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmul  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ fmul(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp64);\n-%}\n-\n-instruct vmul4F(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (MulVF src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmul  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ fmul(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-instruct vmul2D(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (MulVD src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmul  $dst,$src1,$src2\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fmul(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-\/\/ --------------------------------- MLA --------------------------------------\n-\n-instruct vmla4S(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (AddVS dst (MulVS src1 src2)));\n-  ins_cost(INSN_COST);\n-  format %{ \"mlav  $dst,$src1,$src2\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ mlav(as_FloatRegister($dst$$reg), __ T4H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmla64);\n-%}\n-\n-instruct vmla8S(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (AddVS dst (MulVS src1 src2)));\n-  ins_cost(INSN_COST);\n-  format %{ \"mlav  $dst,$src1,$src2\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ mlav(as_FloatRegister($dst$$reg), __ T8H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmla128);\n-%}\n-\n-instruct vmla2I(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AddVI dst (MulVI src1 src2)));\n-  ins_cost(INSN_COST);\n-  format %{ \"mlav  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ mlav(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmla64);\n-%}\n-\n-instruct vmla4I(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AddVI dst (MulVI src1 src2)));\n-  ins_cost(INSN_COST);\n-  format %{ \"mlav  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ mlav(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmla128);\n-%}\n-\n-\/\/ dst + src1 * src2\n-instruct vmla2F(vecD dst, vecD src1, vecD src2) %{\n-  predicate(UseFMA && n->as_Vector()->length() == 2);\n-  match(Set dst (FmaVF  dst (Binary src1 src2)));\n-  format %{ \"fmla  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_cost(INSN_COST);\n-  ins_encode %{\n-    __ fmla(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp64);\n-%}\n-\n-\/\/ dst + src1 * src2\n-instruct vmla4F(vecX dst, vecX src1, vecX src2) %{\n-  predicate(UseFMA && n->as_Vector()->length() == 4);\n-  match(Set dst (FmaVF  dst (Binary src1 src2)));\n-  format %{ \"fmla  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_cost(INSN_COST);\n-  ins_encode %{\n-    __ fmla(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-\/\/ dst + src1 * src2\n-instruct vmla2D(vecX dst, vecX src1, vecX src2) %{\n-  predicate(UseFMA && n->as_Vector()->length() == 2);\n-  match(Set dst (FmaVD  dst (Binary src1 src2)));\n-  format %{ \"fmla  $dst,$src1,$src2\\t# vector (2D)\" %}\n-  ins_cost(INSN_COST);\n-  ins_encode %{\n-    __ fmla(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-\/\/ --------------------------------- MLS --------------------------------------\n-\n-instruct vmls4S(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (SubVS dst (MulVS src1 src2)));\n-  ins_cost(INSN_COST);\n-  format %{ \"mlsv  $dst,$src1,$src2\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ mlsv(as_FloatRegister($dst$$reg), __ T4H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmla64);\n-%}\n-\n-instruct vmls8S(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (SubVS dst (MulVS src1 src2)));\n-  ins_cost(INSN_COST);\n-  format %{ \"mlsv  $dst,$src1,$src2\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ mlsv(as_FloatRegister($dst$$reg), __ T8H,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmla128);\n-%}\n-\n-instruct vmls2I(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (SubVI dst (MulVI src1 src2)));\n-  ins_cost(INSN_COST);\n-  format %{ \"mlsv  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ mlsv(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmla64);\n-%}\n-\n-instruct vmls4I(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (SubVI dst (MulVI src1 src2)));\n-  ins_cost(INSN_COST);\n-  format %{ \"mlsv  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ mlsv(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmla128);\n-%}\n-\n-\/\/ dst - src1 * src2\n-instruct vmls2F(vecD dst, vecD src1, vecD src2) %{\n-  predicate(UseFMA && n->as_Vector()->length() == 2);\n-  match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));\n-  match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));\n-  format %{ \"fmls  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_cost(INSN_COST);\n-  ins_encode %{\n-    __ fmls(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp64);\n-%}\n-\n-\/\/ dst - src1 * src2\n-instruct vmls4F(vecX dst, vecX src1, vecX src2) %{\n-  predicate(UseFMA && n->as_Vector()->length() == 4);\n-  match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));\n-  match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));\n-  format %{ \"fmls  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_cost(INSN_COST);\n-  ins_encode %{\n-    __ fmls(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-\/\/ dst - src1 * src2\n-instruct vmls2D(vecX dst, vecX src1, vecX src2) %{\n-  predicate(UseFMA && n->as_Vector()->length() == 2);\n-  match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));\n-  match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));\n-  format %{ \"fmls  $dst,$src1,$src2\\t# vector (2D)\" %}\n-  ins_cost(INSN_COST);\n-  ins_encode %{\n-    __ fmls(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-\/\/ --------------- Vector Multiply-Add Shorts into Integer --------------------\n-\n-instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{\n-  predicate(n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n-  match(Set dst (MulAddVS2VI src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"smullv  $tmp, $src1, $src2\\t# vector (4H)\\n\\t\"\n-            \"smullv  $dst, $src1, $src2\\t# vector (8H)\\n\\t\"\n-            \"addpv   $dst, $tmp, $dst\\t# vector (4S)\\n\\t\" %}\n-  ins_encode %{\n-    __ smullv(as_FloatRegister($tmp$$reg), __ T4H,\n-              as_FloatRegister($src1$$reg),\n-              as_FloatRegister($src2$$reg));\n-    __ smullv(as_FloatRegister($dst$$reg), __ T8H,\n-              as_FloatRegister($src1$$reg),\n-              as_FloatRegister($src2$$reg));\n-    __ addpv(as_FloatRegister($dst$$reg), __ T4S,\n-             as_FloatRegister($tmp$$reg),\n-             as_FloatRegister($dst$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-\/\/ --------------------------------- DIV --------------------------------------\n-\n-instruct vdiv2F(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (DivVF src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fdiv  $dst,$src1,$src2\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ fdiv(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp64);\n-%}\n-\n-instruct vdiv4F(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (DivVF src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fdiv  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ fdiv(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-instruct vdiv2D(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (DivVD src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fdiv  $dst,$src1,$src2\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fdiv(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vmuldiv_fp128);\n-%}\n-\n-\/\/ --------------------------------- SQRT -------------------------------------\n-\n-instruct vsqrt2F(vecD dst, vecD src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (SqrtVF src));\n-  format %{ \"fsqrt  $dst, $src\\t# vector (2F)\" %}\n-  ins_encode %{\n-    __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vunop_fp64);\n-%}\n-\n-instruct vsqrt4F(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (SqrtVF src));\n-  format %{ \"fsqrt  $dst, $src\\t# vector (4F)\" %}\n-  ins_encode %{\n-    __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vsqrt_fp128);\n-%}\n-\n-instruct vsqrt2D(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (SqrtVD src));\n-  format %{ \"fsqrt  $dst, $src\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,\n-             as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vsqrt_fp128);\n-%}\n-\n-\/\/ --------------------------------- NEG --------------------------------------\n-\n-instruct vneg2F(vecD dst, vecD src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (NegVF src));\n-  ins_cost(INSN_COST * 3);\n-  format %{ \"fneg  $dst,$src\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ fneg(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vunop_fp64);\n-%}\n-\n-instruct vneg4F(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (NegVF src));\n-  ins_cost(INSN_COST * 3);\n-  format %{ \"fneg  $dst,$src\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ fneg(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vunop_fp128);\n-%}\n-\n-instruct vneg2D(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (NegVD src));\n-  ins_cost(INSN_COST * 3);\n-  format %{ \"fneg  $dst,$src\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fneg(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vunop_fp128);\n-%}\n-\n-\/\/ --------------------------------- AND --------------------------------------\n-\n-instruct vand8B(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length_in_bytes() == 4 ||\n-            n->as_Vector()->length_in_bytes() == 8);\n-  match(Set dst (AndV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"and  $dst,$src1,$src2\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ andr(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vlogical64);\n-%}\n-\n-instruct vand16B(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length_in_bytes() == 16);\n-  match(Set dst (AndV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"and  $dst,$src1,$src2\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ andr(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vlogical128);\n-%}\n-\n-\/\/ --------------------------------- OR ---------------------------------------\n-\n-instruct vor8B(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length_in_bytes() == 4 ||\n-            n->as_Vector()->length_in_bytes() == 8);\n-  match(Set dst (OrV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"and  $dst,$src1,$src2\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ orr(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vlogical64);\n-%}\n-\n-instruct vor16B(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length_in_bytes() == 16);\n-  match(Set dst (OrV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"orr  $dst,$src1,$src2\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ orr(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vlogical128);\n-%}\n-\n-\/\/ --------------------------------- XOR --------------------------------------\n-\n-instruct vxor8B(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length_in_bytes() == 4 ||\n-            n->as_Vector()->length_in_bytes() == 8);\n-  match(Set dst (XorV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"xor  $dst,$src1,$src2\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ eor(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vlogical64);\n-%}\n-\n-instruct vxor16B(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length_in_bytes() == 16);\n-  match(Set dst (XorV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"xor  $dst,$src1,$src2\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ eor(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vlogical128);\n-%}\n-\n-\/\/ ------------------------------ Shift ---------------------------------------\n-instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{\n-  predicate(n->as_Vector()->length_in_bytes() == 4 ||\n-            n->as_Vector()->length_in_bytes() == 8);\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"dup  $dst, $cnt\\t# shift count vector (8B)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg64);\n-%}\n-\n-instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{\n-  predicate(n->as_Vector()->length_in_bytes() == 16);\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"dup  $dst, $cnt\\t# shift count vector (16B)\" %}\n-  ins_encode %{\n-    __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));\n-  %}\n-  ins_pipe(vdup_reg_reg128);\n-%}\n-\n-instruct vsll8B(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (LShiftVB src shift));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshl  $dst,$src,$shift\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ sshl(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($shift$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsll16B(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (LShiftVB src shift));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshl  $dst,$src,$shift\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ sshl(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($shift$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-\/\/ Right shifts with vector shift count on aarch64 SIMD are implemented\n-\/\/ as left shift by negative shift count.\n-\/\/ There are two cases for vector shift count.\n-\/\/\n-\/\/ Case 1: The vector shift count is from replication.\n-\/\/        |            |\n-\/\/    LoadVector  RShiftCntV\n-\/\/        |       \/\n-\/\/     RShiftVI\n-\/\/ Note: In inner loop, multiple neg instructions are used, which can be\n-\/\/ moved to outer loop and merge into one neg instruction.\n-\/\/\n-\/\/ Case 2: The vector shift count is from loading.\n-\/\/ This case isn't supported by middle-end now. But it's supported by\n-\/\/ panama\/vectorIntrinsics(JEP 338: Vector API).\n-\/\/        |            |\n-\/\/    LoadVector  LoadVector\n-\/\/        |       \/\n-\/\/     RShiftVI\n-\/\/\n-\n-instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (RShiftVB src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n-    __ sshl(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (RShiftVB src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n-    __ sshl(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (URShiftVB src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n-    __ ushl(as_FloatRegister($dst$$reg), __ T8B,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (URShiftVB src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n-    __ ushl(as_FloatRegister($dst$$reg), __ T16B,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (LShiftVB src (LShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"shl    $dst, $src, $shift\\t# vector (8B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) {\n-      __ eor(as_FloatRegister($dst$$reg), __ T8B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ shl(as_FloatRegister($dst$$reg), __ T8B,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (LShiftVB src (LShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"shl    $dst, $src, $shift\\t# vector (16B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) {\n-      __ eor(as_FloatRegister($dst$$reg), __ T16B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ shl(as_FloatRegister($dst$$reg), __ T16B,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (RShiftVB src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshr    $dst, $src, $shift\\t# vector (8B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) sh = 7;\n-    __ sshr(as_FloatRegister($dst$$reg), __ T8B,\n-           as_FloatRegister($src$$reg), sh);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (RShiftVB src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshr    $dst, $src, $shift\\t# vector (16B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) sh = 7;\n-    __ sshr(as_FloatRegister($dst$$reg), __ T16B,\n-           as_FloatRegister($src$$reg), sh);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (URShiftVB src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"ushr    $dst, $src, $shift\\t# vector (8B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) {\n-      __ eor(as_FloatRegister($dst$$reg), __ T8B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ ushr(as_FloatRegister($dst$$reg), __ T8B,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (URShiftVB src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"ushr    $dst, $src, $shift\\t# vector (16B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) {\n-      __ eor(as_FloatRegister($dst$$reg), __ T16B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ ushr(as_FloatRegister($dst$$reg), __ T16B,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsll4S(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (LShiftVS src shift));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshl  $dst,$src,$shift\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ sshl(as_FloatRegister($dst$$reg), __ T4H,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($shift$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsll8S(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (LShiftVS src shift));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshl  $dst,$src,$shift\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ sshl(as_FloatRegister($dst$$reg), __ T8H,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($shift$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (RShiftVS src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n-    __ sshl(as_FloatRegister($dst$$reg), __ T4H,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (RShiftVS src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n-    __ sshl(as_FloatRegister($dst$$reg), __ T8H,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (URShiftVS src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n-    __ ushl(as_FloatRegister($dst$$reg), __ T4H,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (URShiftVS src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n-    __ ushl(as_FloatRegister($dst$$reg), __ T8H,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (LShiftVS src (LShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"shl    $dst, $src, $shift\\t# vector (4H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) {\n-      __ eor(as_FloatRegister($dst$$reg), __ T8B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ shl(as_FloatRegister($dst$$reg), __ T4H,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (LShiftVS src (LShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"shl    $dst, $src, $shift\\t# vector (8H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) {\n-      __ eor(as_FloatRegister($dst$$reg), __ T16B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ shl(as_FloatRegister($dst$$reg), __ T8H,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (RShiftVS src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshr    $dst, $src, $shift\\t# vector (4H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) sh = 15;\n-    __ sshr(as_FloatRegister($dst$$reg), __ T4H,\n-           as_FloatRegister($src$$reg), sh);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (RShiftVS src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshr    $dst, $src, $shift\\t# vector (8H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) sh = 15;\n-    __ sshr(as_FloatRegister($dst$$reg), __ T8H,\n-           as_FloatRegister($src$$reg), sh);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n-  match(Set dst (URShiftVS src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"ushr    $dst, $src, $shift\\t# vector (4H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) {\n-      __ eor(as_FloatRegister($dst$$reg), __ T8B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ ushr(as_FloatRegister($dst$$reg), __ T4H,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (URShiftVS src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"ushr    $dst, $src, $shift\\t# vector (8H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) {\n-      __ eor(as_FloatRegister($dst$$reg), __ T16B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ ushr(as_FloatRegister($dst$$reg), __ T8H,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsll2I(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (LShiftVI src shift));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshl  $dst,$src,$shift\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ sshl(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($shift$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsll4I(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (LShiftVI src shift));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshl  $dst,$src,$shift\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ sshl(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($shift$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (RShiftVI src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n-    __ sshl(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (RShiftVI src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n-    __ sshl(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (URShiftVI src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n-    __ ushl(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift64);\n-%}\n-\n-instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (URShiftVI src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n-    __ ushl(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (LShiftVI src (LShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"shl    $dst, $src, $shift\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ shl(as_FloatRegister($dst$$reg), __ T2S,\n-           as_FloatRegister($src$$reg),\n-           (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (LShiftVI src (LShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"shl    $dst, $src, $shift\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ shl(as_FloatRegister($dst$$reg), __ T4S,\n-           as_FloatRegister($src$$reg),\n-           (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (RShiftVI src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshr    $dst, $src, $shift\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ sshr(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (RShiftVI src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshr    $dst, $src, $shift\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ sshr(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (URShiftVI src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"ushr    $dst, $src, $shift\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ ushr(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (URShiftVI src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"ushr    $dst, $src, $shift\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ ushr(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsll2L(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (LShiftVL src shift));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshl  $dst,$src,$shift\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ sshl(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($shift$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (RShiftVL src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n-    __ sshl(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (URShiftVL src shift));\n-  ins_cost(INSN_COST);\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n-    __ ushl(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src$$reg),\n-            as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(vshift128);\n-%}\n-\n-instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (LShiftVL src (LShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"shl    $dst, $src, $shift\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ shl(as_FloatRegister($dst$$reg), __ T2D,\n-           as_FloatRegister($src$$reg),\n-           (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (RShiftVL src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"sshr    $dst, $src, $shift\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ sshr(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (URShiftVL src (RShiftCntV shift)));\n-  ins_cost(INSN_COST);\n-  format %{ \"ushr    $dst, $src, $shift\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ ushr(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsraa8B_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (AddVB dst (RShiftVB src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"ssra    $dst, $src, $shift\\t# vector (8B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) sh = 7;\n-    __ ssra(as_FloatRegister($dst$$reg), __ T8B,\n-           as_FloatRegister($src$$reg), sh);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsraa16B_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (AddVB dst (RShiftVB src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"ssra    $dst, $src, $shift\\t# vector (16B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) sh = 7;\n-    __ ssra(as_FloatRegister($dst$$reg), __ T16B,\n-           as_FloatRegister($src$$reg), sh);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsraa4S_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AddVS dst (RShiftVS src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"ssra    $dst, $src, $shift\\t# vector (4H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) sh = 15;\n-    __ ssra(as_FloatRegister($dst$$reg), __ T4H,\n-           as_FloatRegister($src$$reg), sh);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsraa8S_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (AddVS dst (RShiftVS src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"ssra    $dst, $src, $shift\\t# vector (8H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) sh = 15;\n-    __ ssra(as_FloatRegister($dst$$reg), __ T8H,\n-           as_FloatRegister($src$$reg), sh);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsraa2I_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AddVI dst (RShiftVI src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"ssra    $dst, $src, $shift\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ ssra(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsraa4I_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AddVI dst (RShiftVI src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"ssra    $dst, $src, $shift\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ ssra(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsraa2L_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AddVL dst (RShiftVL src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"ssra    $dst, $src, $shift\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ ssra(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsrla8B_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (AddVB dst (URShiftVB src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"usra    $dst, $src, $shift\\t# vector (8B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) {\n-      __ eor(as_FloatRegister($src$$reg), __ T8B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ usra(as_FloatRegister($dst$$reg), __ T8B,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsrla16B_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (AddVB dst (URShiftVB src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"usra    $dst, $src, $shift\\t# vector (16B)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 8) {\n-      __ eor(as_FloatRegister($src$$reg), __ T16B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ usra(as_FloatRegister($dst$$reg), __ T16B,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsrla4S_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AddVS dst (URShiftVS src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"usra    $dst, $src, $shift\\t# vector (4H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) {\n-      __ eor(as_FloatRegister($src$$reg), __ T8B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ ushr(as_FloatRegister($dst$$reg), __ T4H,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsrla8S_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (AddVS dst (URShiftVS src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"usra    $dst, $src, $shift\\t# vector (8H)\" %}\n-  ins_encode %{\n-    int sh = (int)$shift$$constant;\n-    if (sh >= 16) {\n-      __ eor(as_FloatRegister($src$$reg), __ T16B,\n-             as_FloatRegister($src$$reg),\n-             as_FloatRegister($src$$reg));\n-    } else {\n-      __ usra(as_FloatRegister($dst$$reg), __ T8H,\n-             as_FloatRegister($src$$reg), sh);\n-    }\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsrla2I_imm(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AddVI dst (URShiftVI src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"usra    $dst, $src, $shift\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ usra(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift64_imm);\n-%}\n-\n-instruct vsrla4I_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AddVI dst (URShiftVI src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"usra    $dst, $src, $shift\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ usra(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vsrla2L_imm(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AddVL dst (URShiftVL src (RShiftCntV shift))));\n-  ins_cost(INSN_COST);\n-  format %{ \"usra    $dst, $src, $shift\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ usra(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src$$reg),\n-            (int)$shift$$constant);\n-  %}\n-  ins_pipe(vshift128_imm);\n-%}\n-\n-instruct vmax2F(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 && n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n-  match(Set dst (MaxV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmax  $dst,$src1,$src2\\t# vector (2F)\" %}\n-  ins_encode %{\n-    __ fmax(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp64);\n-%}\n-\n-instruct vmax4F(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4 && n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n-  match(Set dst (MaxV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmax  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ fmax(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-instruct vmax2D(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 && n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (MaxV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmax  $dst,$src1,$src2\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fmax(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-instruct vmin2F(vecD dst, vecD src1, vecD src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 && n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n-  match(Set dst (MinV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmin  $dst,$src1,$src2\\t# vector (2F)\" %}\n-  ins_encode %{\n-    __ fmin(as_FloatRegister($dst$$reg), __ T2S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp64);\n-%}\n-\n-instruct vmin4F(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 4 && n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n-  match(Set dst (MinV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmin  $dst,$src1,$src2\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ fmin(as_FloatRegister($dst$$reg), __ T4S,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-instruct vmin2D(vecX dst, vecX src1, vecX src2)\n-%{\n-  predicate(n->as_Vector()->length() == 2 && n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (MinV src1 src2));\n-  ins_cost(INSN_COST);\n-  format %{ \"fmin  $dst,$src1,$src2\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fmin(as_FloatRegister($dst$$reg), __ T2D,\n-            as_FloatRegister($src1$$reg),\n-            as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{\n-  predicate(n->as_Vector()->length() == 2 && n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (RoundDoubleModeV src rmode));\n-  format %{ \"frint  $dst, $src, $rmode\" %}\n-  ins_encode %{\n-    switch ($rmode$$constant) {\n-      case RoundDoubleModeNode::rmode_rint:\n-        __ frintn(as_FloatRegister($dst$$reg), __ T2D,\n-                  as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_floor:\n-        __ frintm(as_FloatRegister($dst$$reg), __ T2D,\n-                  as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_ceil:\n-        __ frintp(as_FloatRegister($dst$$reg), __ T2D,\n-                  as_FloatRegister($src$$reg));\n-        break;\n-    }\n-  %}\n-  ins_pipe(vdop_fp128);\n-%}\n-\n-instruct vpopcount4I(vecX dst, vecX src) %{\n-  predicate(UsePopCountInstruction && n->as_Vector()->length() == 4);\n-  match(Set dst (PopCountVI src));\n-  format %{\n-    \"cnt     $dst, $src\\t# vector (16B)\\n\\t\"\n-    \"uaddlp  $dst, $dst\\t# vector (16B)\\n\\t\"\n-    \"uaddlp  $dst, $dst\\t# vector (8H)\"\n-  %}\n-  ins_encode %{\n-    __ cnt(as_FloatRegister($dst$$reg), __ T16B,\n-           as_FloatRegister($src$$reg));\n-    __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,\n-              as_FloatRegister($dst$$reg));\n-    __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,\n-              as_FloatRegister($dst$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct vpopcount2I(vecD dst, vecD src) %{\n-  predicate(UsePopCountInstruction && n->as_Vector()->length() == 2);\n-  match(Set dst (PopCountVI src));\n-  format %{\n-    \"cnt     $dst, $src\\t# vector (8B)\\n\\t\"\n-    \"uaddlp  $dst, $dst\\t# vector (8B)\\n\\t\"\n-    \"uaddlp  $dst, $dst\\t# vector (4H)\"\n-  %}\n-  ins_encode %{\n-    __ cnt(as_FloatRegister($dst$$reg), __ T8B,\n-           as_FloatRegister($src$$reg));\n-    __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,\n-              as_FloatRegister($dst$$reg));\n-    __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,\n-              as_FloatRegister($dst$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":0,"deletions":2440,"binary":false,"changes":2440,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -603,1 +603,1 @@\n-      assert(obj == NULL || Universe::heap()->is_in(obj), \"sanity check\");\n+      assert(Universe::is_in_heap_or_null(obj), \"sanity check\");\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -33,1 +33,0 @@\n-#include \"gc\/shared\/cardTable.hpp\"\n@@ -36,0 +35,2 @@\n+#include \"gc\/shared\/cardTable.hpp\"\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n@@ -49,0 +50,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n@@ -87,0 +89,1 @@\n+  const bool _save_vectors;\n@@ -88,2 +91,4 @@\n-  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors = false);\n-  static void restore_live_registers(MacroAssembler* masm, bool restore_vectors = false);\n+  RegisterSaver(bool save_vectors) : _save_vectors(save_vectors) {}\n+\n+  OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words);\n+  void restore_live_registers(MacroAssembler* masm);\n@@ -95,10 +100,4 @@\n-  static int r0_offset_in_bytes(void)    { return (32 + r0->encoding()) * wordSize; }\n-  static int reg_offset_in_bytes(Register r)    { return r0_offset_in_bytes() + r->encoding() * wordSize; }\n-  static int rmethod_offset_in_bytes(void)    { return reg_offset_in_bytes(rmethod); }\n-  static int rscratch1_offset_in_bytes(void)    { return (32 + rscratch1->encoding()) * wordSize; }\n-  static int v0_offset_in_bytes(void)   { return 0; }\n-  static int return_offset_in_bytes(void) { return (32 \/* floats*\/ + 31 \/* gregs*\/) * wordSize; }\n-\n-  \/\/ During deoptimization only the result registers need to be restored,\n-  \/\/ all the other values have already been extracted.\n-  static void restore_result_registers(MacroAssembler* masm);\n+  int reg_offset_in_bytes(Register r);\n+  int r0_offset_in_bytes()    { return reg_offset_in_bytes(r0); }\n+  int rscratch1_offset_in_bytes()    { return reg_offset_in_bytes(rscratch1); }\n+  int v0_offset_in_bytes(void)   { return 0; }\n@@ -106,1 +105,2 @@\n-    \/\/ Capture info about frame layout\n+  \/\/ Capture info about frame layout\n+  \/\/ Note this is only correct when not saving full vectors.\n@@ -121,1 +121,25 @@\n-OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors) {\n+int RegisterSaver::reg_offset_in_bytes(Register r) {\n+  \/\/ The integer registers are located above the floating point\n+  \/\/ registers in the stack frame pushed by save_live_registers() so the\n+  \/\/ offset depends on whether we are saving full vectors, and whether\n+  \/\/ those vectors are NEON or SVE.\n+\n+  int slots_per_vect = FloatRegisterImpl::save_slots_per_register;\n+\n+#if COMPILER2_OR_JVMCI\n+  if (_save_vectors) {\n+    slots_per_vect = FloatRegisterImpl::slots_per_neon_register;\n+\n+#ifdef COMPILER2\n+    if (Matcher::supports_scalable_vector()) {\n+      slots_per_vect = Matcher::scalable_vector_reg_size(T_FLOAT);\n+    }\n+#endif\n+  }\n+#endif\n+\n+  int r0_offset = (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n+  return r0_offset + r->encoding() * wordSize;\n+}\n+\n+OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words) {\n@@ -133,1 +157,1 @@\n-  if (save_vectors) {\n+  if (_save_vectors) {\n@@ -147,1 +171,1 @@\n-  assert(!save_vectors, \"vectors are generated only by C2 and JVMCI\");\n+  assert(!_save_vectors, \"vectors are generated only by C2 and JVMCI\");\n@@ -162,1 +186,1 @@\n-  __ push_CPU_state(save_vectors, use_sve, sve_vector_size_in_bytes);\n+  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes);\n@@ -187,1 +211,1 @@\n-    if (save_vectors) {\n+    if (_save_vectors) {\n@@ -200,1 +224,1 @@\n-void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_vectors) {\n+void RegisterSaver::restore_live_registers(MacroAssembler* masm) {\n@@ -202,1 +226,1 @@\n-  __ pop_CPU_state(restore_vectors, Matcher::supports_scalable_vector(),\n+  __ pop_CPU_state(_save_vectors, Matcher::supports_scalable_vector(),\n@@ -206,1 +230,1 @@\n-  assert(!restore_vectors, \"vectors are generated only by C2 and JVMCI\");\n+  assert(!_save_vectors, \"vectors are generated only by C2 and JVMCI\");\n@@ -208,1 +232,1 @@\n-  __ pop_CPU_state(restore_vectors);\n+  __ pop_CPU_state(_save_vectors);\n@@ -214,17 +238,0 @@\n-void RegisterSaver::restore_result_registers(MacroAssembler* masm) {\n-\n-  \/\/ Just restore result register. Only used by deoptimization. By\n-  \/\/ now any callee save register that needs to be restored to a c2\n-  \/\/ caller of the deoptee has been extracted into the vframeArray\n-  \/\/ and will be stuffed into the c2i adapter we create for later\n-  \/\/ restoration so only result registers need to be restored here.\n-\n-  \/\/ Restore fp result register\n-  __ ldrd(v0, Address(sp, v0_offset_in_bytes()));\n-  \/\/ Restore integer result register\n-  __ ldr(r0, Address(sp, r0_offset_in_bytes()));\n-\n-  \/\/ Pop all of the register save are off the stack\n-  __ add(sp, sp, align_up(return_offset_in_bytes(), 16));\n-}\n-\n@@ -2434,0 +2441,1 @@\n+  RegisterSaver reg_save(COMPILER2_OR_JVMCI != 0);\n@@ -2471,1 +2479,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2489,1 +2497,1 @@\n-  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  (void) reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2508,1 +2516,1 @@\n-    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+    reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2565,1 +2573,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2646,1 +2654,1 @@\n-  __ str(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ str(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -2655,1 +2663,8 @@\n-  RegisterSaver::restore_result_registers(masm);\n+\n+  \/\/ Restore fp result register\n+  __ ldrd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  \/\/ Restore integer result register\n+  __ ldr(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n+\n+  \/\/ Pop all of the register save area off the stack\n+  __ add(sp, sp, frame_size_in_words * wordSize);\n@@ -2736,2 +2751,2 @@\n-  __ strd(v0, Address(sp, RegisterSaver::v0_offset_in_bytes()));\n-  __ str(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ strd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  __ str(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -2764,2 +2779,2 @@\n-  __ ldrd(v0, Address(sp, RegisterSaver::v0_offset_in_bytes()));\n-  __ ldr(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ ldrd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  __ ldr(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -3011,1 +3026,1 @@\n-  bool save_vectors = (poll_type == POLL_AT_VECTOR_LOOP);\n+  RegisterSaver reg_save(poll_type == POLL_AT_VECTOR_LOOP \/* save_vectors *\/);\n@@ -3014,1 +3029,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, save_vectors);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -3059,1 +3074,1 @@\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n+  reg_save.restore_live_registers(masm);\n@@ -3091,1 +3106,1 @@\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n+  reg_save.restore_live_registers(masm);\n@@ -3125,0 +3140,1 @@\n+  RegisterSaver reg_save(false \/* save_vectors *\/);\n@@ -3131,1 +3147,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -3163,1 +3179,1 @@\n-  __ str(rmethod, Address(sp, RegisterSaver::reg_offset_in_bytes(rmethod)));\n+  __ str(rmethod, Address(sp, reg_save.reg_offset_in_bytes(rmethod)));\n@@ -3166,2 +3182,2 @@\n-  __ str(r0, Address(sp, RegisterSaver::rscratch1_offset_in_bytes()));\n-  RegisterSaver::restore_live_registers(masm);\n+  __ str(r0, Address(sp, reg_save.rscratch1_offset_in_bytes()));\n+  reg_save.restore_live_registers(masm);\n@@ -3177,1 +3193,1 @@\n-  RegisterSaver::restore_live_registers(masm);\n+  reg_save.restore_live_registers(masm);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":74,"deletions":58,"binary":false,"changes":132,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -480,1 +480,2 @@\n-void InterpreterMacroAssembler::load_resolved_reference_at_index(Register result, Register index, Register tmp1,\n+void InterpreterMacroAssembler::load_resolved_reference_at_index(Register result, Register index,\n+                                                                 Register tmp1, Register tmp2,\n@@ -482,1 +483,2 @@\n-  assert_different_registers(result, index);\n+  assert_different_registers(result, index, tmp1, tmp2);\n+  assert(index->is_nonvolatile(), \"needs to survive C-call in resolve_oop_handle\");\n@@ -487,2 +489,1 @@\n-  Register tmp2 = index;  \/\/ reuse\n-  sldi(tmp1, index, LogBytesPerHeapOop);\n+  sldi(index, index, LogBytesPerHeapOop);\n@@ -492,1 +493,1 @@\n-  resolve_oop_handle(result);\n+  resolve_oop_handle(result, tmp1, tmp2, MacroAssembler::PRESERVATION_NONE);\n@@ -497,1 +498,1 @@\n-  cmpd(CCR0, tmp1, R0);\n+  cmpd(CCR0, index, R0);\n@@ -503,1 +504,1 @@\n-  add(result, tmp1, result);\n+  add(result, index, result);\n@@ -506,1 +507,1 @@\n-                MacroAssembler::PRESERVATION_FRAME_LR,\n+                MacroAssembler::PRESERVATION_NONE,\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":9,"deletions":8,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n@@ -632,1 +633,1 @@\n-      assert(obj == NULL || Universe::heap()->is_in(obj), \"sanity check\");\n+      assert(Universe::is_in_heap_or_null(obj), \"sanity check\");\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/methodHandles_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"compiler\/compilerThread.hpp\"\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,1 +31,0 @@\n-#include \"runtime\/jniHandles.hpp\"\n@@ -47,1 +46,1 @@\n-  virtual bool is_classless() const         { return false; }\n+  virtual bool is_classless() const;\n","filename":"src\/hotspot\/share\/ci\/ciMetadata.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -82,0 +82,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"memory\/archiveBuilder.hpp\"\n@@ -860,1 +861,3 @@\n-          assert(fd->signature() == vmSymbols::string_signature(),\n+          \/\/ Can't use vmSymbols::string_signature() as fd->signature() may have been relocated\n+          \/\/ during DumpSharedSpaces\n+          assert(fd->signature()->equals(\"Ljava\/lang\/String;\"),\n@@ -865,1 +868,1 @@\n-            oop archived_s = StringTable::create_archived_string(s, CHECK);\n+            oop archived_s = StringTable::create_archived_string(s);\n@@ -1133,1 +1136,16 @@\n-void java_lang_Class::archive_basic_type_mirrors(TRAPS) {\n+static void set_klass_field_in_archived_mirror(oop mirror_obj, int offset, Klass* k) {\n+  assert(java_lang_Class::is_instance(mirror_obj), \"must be\");\n+  \/\/ this is the copy of k in the output buffer\n+  Klass* copy = ArchiveBuilder::get_relocated_klass(k);\n+\n+  \/\/ This is the address of k, if the archive is loaded at the requested location\n+  Klass* def = ArchiveBuilder::current()->to_requested(copy);\n+\n+  log_debug(cds, heap, mirror)(\n+      \"Relocate mirror metadata field at %d from \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n+      offset, p2i(k), p2i(def));\n+\n+  mirror_obj->metadata_field_put(offset, def);\n+}\n+\n+void java_lang_Class::archive_basic_type_mirrors() {\n@@ -1142,1 +1160,1 @@\n-      oop archived_m = HeapShared::archive_heap_object(m, THREAD);\n+      oop archived_m = HeapShared::archive_heap_object(m);\n@@ -1147,2 +1165,1 @@\n-        Klass *reloc_ak = MetaspaceShared::get_relocated_klass(ak, true);\n-        archived_m->metadata_field_put(_array_klass_offset, reloc_ak);\n+        set_klass_field_in_archived_mirror(archived_m, _array_klass_offset, ak);\n@@ -1153,1 +1170,1 @@\n-      Handle archived_mirror_h(THREAD, archived_m);\n+      Handle archived_mirror_h(Thread::current(), archived_m);\n@@ -1173,1 +1190,1 @@\n-oop java_lang_Class::archive_mirror(Klass* k, TRAPS) {\n+oop java_lang_Class::archive_mirror(Klass* k) {\n@@ -1208,1 +1225,1 @@\n-  oop archived_mirror = HeapShared::archive_heap_object(mirror, THREAD);\n+  oop archived_mirror = HeapShared::archive_heap_object(mirror);\n@@ -1213,1 +1230,1 @@\n-  archived_mirror = process_archived_mirror(k, mirror, archived_mirror, THREAD);\n+  archived_mirror = process_archived_mirror(k, mirror, archived_mirror);\n@@ -1230,2 +1247,1 @@\n-                                             oop archived_mirror,\n-                                             Thread *THREAD) {\n+                                             oop archived_mirror) {\n@@ -1235,1 +1251,1 @@\n-  Handle archived_mirror_h(THREAD, archived_mirror);\n+  Handle archived_mirror_h(Thread::current(), archived_mirror);\n@@ -1250,1 +1266,1 @@\n-      archived_comp_mirror = archive_mirror(element_klass, THREAD);\n+      archived_comp_mirror = archive_mirror(element_klass);\n@@ -1276,5 +1292,1 @@\n-  Klass *reloc_k = MetaspaceShared::get_relocated_klass(as_Klass(mirror), true);\n-  log_debug(cds, heap, mirror)(\n-    \"Relocate mirror metadata field at _klass_offset from \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n-    p2i(as_Klass(mirror)), p2i(reloc_k));\n-  archived_mirror->metadata_field_put(_klass_offset, reloc_k);\n+  set_klass_field_in_archived_mirror(archived_mirror, _klass_offset, as_Klass(mirror));\n@@ -1286,5 +1298,1 @@\n-    Klass *reloc_arr = MetaspaceShared::get_relocated_klass(arr, true);\n-    log_debug(cds, heap, mirror)(\n-      \"Relocate mirror metadata field at _array_klass_offset from \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n-      p2i(arr), p2i(reloc_arr));\n-    archived_mirror->metadata_field_put(_array_klass_offset, reloc_arr);\n+    set_klass_field_in_archived_mirror(archived_mirror, _array_klass_offset, arr);\n@@ -4407,0 +4415,2 @@\n+int java_lang_System::_static_allow_security_offset;\n+int java_lang_System::_static_never_offset;\n@@ -4412,1 +4422,3 @@\n-  macro(_static_security_offset, k, \"security\", security_manager_signature, true)\n+  macro(_static_security_offset, k, \"security\", security_manager_signature, true); \\\n+  macro(_static_allow_security_offset, k, \"allowSecurityManager\", int_signature, true); \\\n+  macro(_static_never_offset, k, \"NEVER\", int_signature, true)\n@@ -4419,0 +4431,19 @@\n+\/\/ This field tells us that a security manager can never be installed so we\n+\/\/ can completely skip populating the ProtectionDomainCacheTable.\n+bool java_lang_System::allow_security_manager() {\n+  static int initialized = false;\n+  static bool allowed = true; \/\/ default\n+  if (!initialized) {\n+    oop base = vmClasses::System_klass()->static_field_base_raw();\n+    int never = base->int_field(_static_never_offset);\n+    allowed = (base->int_field(_static_allow_security_offset) != never);\n+  }\n+  return allowed;\n+}\n+\n+\/\/ This field tells us that a security manager is installed.\n+bool java_lang_System::has_security_manager() {\n+  oop base = vmClasses::System_klass()->static_field_base_raw();\n+  return base->obj_field(_static_security_offset) != NULL;\n+}\n+\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":56,"deletions":25,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -280,3 +280,3 @@\n-  static void archive_basic_type_mirrors(TRAPS) NOT_CDS_JAVA_HEAP_RETURN;\n-  static oop  archive_mirror(Klass* k, TRAPS) NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n-  static oop  process_archived_mirror(Klass* k, oop mirror, oop archived_mirror, Thread *THREAD)\n+  static void archive_basic_type_mirrors() NOT_CDS_JAVA_HEAP_RETURN;\n+  static oop  archive_mirror(Klass* k) NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n+  static oop  process_archived_mirror(Klass* k, oop mirror, oop archived_mirror)\n@@ -1375,0 +1375,2 @@\n+  static int _static_allow_security_offset;\n+  static int _static_never_offset;\n@@ -1380,0 +1382,2 @@\n+  static bool allow_security_manager();\n+  static bool has_security_manager();\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -157,1 +157,1 @@\n-bool SystemDictionary::is_parallelCapable(Handle class_loader) {\n+bool is_parallelCapable(Handle class_loader) {\n@@ -164,1 +164,1 @@\n-bool SystemDictionary::is_parallelDefine(Handle class_loader) {\n+bool is_parallelDefine(Handle class_loader) {\n@@ -191,1 +191,1 @@\n-Handle SystemDictionary::compute_loader_lock_object(Thread* thread, Handle class_loader) {\n+Handle SystemDictionary::compute_loader_lock_object(Handle class_loader) {\n@@ -513,8 +513,28 @@\n-  JavaValue result(T_VOID);\n-  LogTarget(Debug, protectiondomain) lt;\n-  if (lt.is_enabled()) {\n-    ResourceMark rm(THREAD);\n-    \/\/ Print out trace information\n-    LogStream ls(lt);\n-    ls.print_cr(\"Checking package access\");\n-    if (class_loader() != NULL) {\n+  assert(class_loader() != NULL, \"Should not call this\");\n+  assert(protection_domain() != NULL, \"Should not call this\");\n+\n+  \/\/ We only have to call checkPackageAccess if there's a security manager installed.\n+  if (java_lang_System::has_security_manager()) {\n+\n+    \/\/ This handle and the class_loader handle passed in keeps this class from\n+    \/\/ being unloaded through several GC points.\n+    \/\/ The class_loader handle passed in is the initiating loader.\n+    Handle mirror(THREAD, klass->java_mirror());\n+\n+    InstanceKlass* system_loader = vmClasses::ClassLoader_klass();\n+    JavaValue result(T_VOID);\n+    JavaCalls::call_special(&result,\n+                           class_loader,\n+                           system_loader,\n+                           vmSymbols::checkPackageAccess_name(),\n+                           vmSymbols::class_protectiondomain_signature(),\n+                           mirror,\n+                           protection_domain,\n+                           THREAD);\n+\n+    LogTarget(Debug, protectiondomain) lt;\n+    if (lt.is_enabled()) {\n+      ResourceMark rm(THREAD);\n+      \/\/ Print out trace information\n+      LogStream ls(lt);\n+      ls.print_cr(\"Checking package access\");\n@@ -523,4 +543,0 @@\n-    } else {\n-      ls.print_cr(\"class loader: NULL\");\n-    }\n-    if (protection_domain() != NULL) {\n@@ -529,2 +545,6 @@\n-    } else {\n-      ls.print_cr(\" protection domain: NULL\");\n+      ls.print(\" loading: \"); klass->print_value_on(&ls);\n+      if (HAS_PENDING_EXCEPTION) {\n+        ls.print_cr(\" DENIED !!!!!!!!!!!!!!!!!!!!!\");\n+      } else {\n+        ls.print_cr(\" granted\");\n+      }\n@@ -532,22 +552,1 @@\n-    ls.print(\" loading: \"); klass->print_value_on(&ls);\n-    ls.cr();\n-  }\n-\n-  \/\/ This handle and the class_loader handle passed in keeps this class from\n-  \/\/ being unloaded through several GC points.\n-  \/\/ The class_loader handle passed in is the initiating loader.\n-  Handle mirror(THREAD, klass->java_mirror());\n-  InstanceKlass* system_loader = vmClasses::ClassLoader_klass();\n-  JavaCalls::call_special(&result,\n-                         class_loader,\n-                         system_loader,\n-                         vmSymbols::checkPackageAccess_name(),\n-                         vmSymbols::class_protectiondomain_signature(),\n-                         mirror,\n-                         protection_domain,\n-                         THREAD);\n-\n-  if (HAS_PENDING_EXCEPTION) {\n-    log_debug(protectiondomain)(\"DENIED !!!!!!!!!!!!!!!!!!!!!\");\n-  } else {\n-   log_debug(protectiondomain)(\"granted\");\n+    if (HAS_PENDING_EXCEPTION) return;\n@@ -557,2 +556,0 @@\n-  if (HAS_PENDING_EXCEPTION) return;\n-\n@@ -561,0 +558,3 @@\n+  \/\/ We still have to add the protection_domain to the dictionary in case a new\n+  \/\/ security manager is installed later. Calls to load the same class with class loader\n+  \/\/ and protection domain are expected to succeed.\n@@ -756,1 +756,1 @@\n-  Handle lockObject = compute_loader_lock_object(THREAD, class_loader);\n+  Handle lockObject = compute_loader_lock_object(class_loader);\n@@ -942,5 +942,4 @@\n-  \/\/ return if the protection domain in NULL\n-  if (protection_domain() == NULL) return loaded_class;\n-\n-  \/\/ Check the protection domain has the right access\n-  if (dictionary->is_valid_protection_domain(name_hash, name,\n+  \/\/ Check if the protection domain is present it has the right access\n+  if (protection_domain() != NULL &&\n+     java_lang_System::allow_security_manager() &&\n+     !dictionary->is_valid_protection_domain(name_hash, name,\n@@ -948,1 +947,2 @@\n-    return loaded_class;\n+    \/\/ Verify protection domain. If it fails an exception is thrown\n+    validate_protection_domain(loaded_class, class_loader, protection_domain, CHECK_NULL);\n@@ -951,3 +951,0 @@\n-  \/\/ Verify protection domain. If it fails an exception is thrown\n-  validate_protection_domain(loaded_class, class_loader, protection_domain, CHECK_NULL);\n-\n@@ -992,1 +989,0 @@\n-\n@@ -1122,1 +1118,1 @@\n-  Handle lockObject = compute_loader_lock_object(THREAD, class_loader);\n+  Handle lockObject = compute_loader_lock_object(class_loader);\n@@ -1283,0 +1279,13 @@\n+  \/\/ Quick check if the super type has been already loaded.\n+  \/\/ + Don't do it for unregistered classes -- they can be unloaded so\n+  \/\/   super_type->class_loader_data() could be stale.\n+  \/\/ + Don't check if loader data is NULL, ie. the super_type isn't fully loaded.\n+  if (!super_type->is_shared_unregistered_class() && super_type->class_loader_data() != NULL) {\n+    \/\/ Check if the super class is loaded by the current class_loader\n+    Symbol* name = super_type->name();\n+    Klass* check = find(name, class_loader, protection_domain, CHECK_0);\n+    if (check == super_type) {\n+      return true;\n+    }\n+  }\n+\n@@ -1418,1 +1427,1 @@\n-    Handle lockObject = compute_loader_lock_object(THREAD, class_loader);\n+    Handle lockObject = compute_loader_lock_object(class_loader);\n@@ -1627,1 +1636,1 @@\n-           compute_loader_lock_object(THREAD, class_loader)),\n+           compute_loader_lock_object(class_loader)),\n@@ -1839,6 +1848,10 @@\n-    \/\/ Oops referenced by the protection domain cache table may get unreachable independently\n-    \/\/ of the class loader (eg. cached protection domain oops). So we need to\n-    \/\/ explicitly unlink them here.\n-    \/\/ All protection domain oops are linked to the caller class, so if nothing\n-    \/\/ unloads, this is not needed.\n-    _pd_cache_table->trigger_cleanup();\n+    if (java_lang_System::allow_security_manager()) {\n+      \/\/ Oops referenced by the protection domain cache table may get unreachable independently\n+      \/\/ of the class loader (eg. cached protection domain oops). So we need to\n+      \/\/ explicitly unlink them here.\n+      \/\/ All protection domain oops are linked to the caller class, so if nothing\n+      \/\/ unloads, this is not needed.\n+      _pd_cache_table->trigger_cleanup();\n+    } else {\n+      assert(_pd_cache_table->number_of_entries() == 0, \"should be empty\");\n+    }\n@@ -1873,1 +1886,1 @@\n-    HeapShared::resolve_classes(CHECK);\n+    HeapShared::resolve_classes(THREAD);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":75,"deletions":62,"binary":false,"changes":137,"status":"modified"},{"patch":"@@ -362,3 +362,0 @@\n-  static bool is_parallelDefine(Handle class_loader);\n-  static Handle compute_loader_lock_object(Thread* thread, Handle class_loader);\n-  static void check_loader_lock_contention(Thread* thread, Handle loader_lock);\n@@ -400,1 +397,1 @@\n-  static bool is_parallelCapable(Handle class_loader);\n+  static Handle compute_loader_lock_object(Handle class_loader);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"runtime\/safepoint.hpp\"\n","filename":"src\/hotspot\/share\/code\/compiledIC.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/thread.hpp\"\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSet.inline.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -124,1 +124,1 @@\n-  if(!ct->scanned_concurrently()) {\n+  if (!ct->scanned_concurrently()) {\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/cardTableBarrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"memory\/heapInspection.hpp\"\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -31,0 +30,1 @@\n+#include \"runtime\/thread.hpp\"\n@@ -32,0 +32,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2285,1 +2285,1 @@\n-  uint8_t max_depth = 0;\n+  uint16_t max_depth = 0;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahSupport.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+class BufferBlob;\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,1 @@\n+#include \"runtime\/safepoint.hpp\"\n","filename":"src\/hotspot\/share\/interpreter\/oopMapCache.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"classfile\/symbolTable.hpp\"\n@@ -43,0 +44,1 @@\n+#include \"runtime\/thread.hpp\"\n@@ -47,3 +49,1 @@\n-ArchiveBuilder* ArchiveBuilder::_singleton = NULL;\n-intx ArchiveBuilder::_buffer_to_target_delta = 0;\n-\n+ArchiveBuilder* ArchiveBuilder::_current = NULL;\n@@ -78,1 +78,1 @@\n-  char* newtop = ArchiveBuilder::singleton()->_ro_region->top();\n+  char* newtop = ArchiveBuilder::current()->_ro_region->top();\n@@ -170,2 +170,2 @@\n-  assert(_singleton == NULL, \"must be\");\n-  _singleton = this;\n+  assert(_current == NULL, \"must be\");\n+  _current = this;\n@@ -186,0 +186,2 @@\n+  _num_dump_regions_used = 0;\n+\n@@ -187,0 +189,10 @@\n+  _estimated_hashtable_bytes = 0;\n+  _estimated_trampoline_bytes = 0;\n+\n+  _requested_static_archive_bottom = NULL;\n+  _requested_static_archive_top = NULL;\n+  _mapped_static_archive_bottom = NULL;\n+  _mapped_static_archive_top = NULL;\n+  _requested_dynamic_archive_bottom = NULL;\n+  _requested_dynamic_archive_top = NULL;\n+  _buffer_to_requested_delta = 0;\n@@ -190,2 +202,2 @@\n-  assert(_singleton == this, \"must be\");\n-  _singleton = NULL;\n+  assert(_current == this, \"must be\");\n+  _current = NULL;\n@@ -291,0 +303,4 @@\n+\n+    \/\/ TODO -- we need a proper estimate for the archived modules, etc,\n+    \/\/ but this should be enough for now\n+    _estimated_metaspaceobj_bytes += 200 * 1024 * 1024;\n@@ -322,0 +338,87 @@\n+size_t ArchiveBuilder::estimate_archive_size() {\n+  \/\/ size of the symbol table and two dictionaries, plus the RunTimeSharedClassInfo's\n+  size_t symbol_table_est = SymbolTable::estimate_size_for_archive();\n+  size_t dictionary_est = SystemDictionaryShared::estimate_size_for_archive();\n+  _estimated_hashtable_bytes = symbol_table_est + dictionary_est;\n+\n+  _estimated_trampoline_bytes = allocate_method_trampoline_info();\n+\n+  size_t total = 0;\n+\n+  total += _estimated_metaspaceobj_bytes;\n+  total += _estimated_hashtable_bytes;\n+  total += _estimated_trampoline_bytes;\n+\n+  \/\/ allow fragmentation at the end of each dump region\n+  total += _total_dump_regions * reserve_alignment();\n+\n+  log_info(cds)(\"_estimated_hashtable_bytes = \" SIZE_FORMAT \" + \" SIZE_FORMAT \" = \" SIZE_FORMAT,\n+                symbol_table_est, dictionary_est, _estimated_hashtable_bytes);\n+  log_info(cds)(\"_estimated_metaspaceobj_bytes = \" SIZE_FORMAT, _estimated_metaspaceobj_bytes);\n+  log_info(cds)(\"_estimated_trampoline_bytes = \" SIZE_FORMAT, _estimated_trampoline_bytes);\n+  log_info(cds)(\"total estimate bytes = \" SIZE_FORMAT, total);\n+\n+  return align_up(total, reserve_alignment());\n+}\n+\n+address ArchiveBuilder::reserve_buffer() {\n+  size_t buffer_size = estimate_archive_size();\n+  ReservedSpace rs(buffer_size);\n+  if (!rs.is_reserved()) {\n+    log_error(cds)(\"Failed to reserve \" SIZE_FORMAT \" bytes of output buffer.\", buffer_size);\n+    vm_direct_exit(0);\n+  }\n+\n+  \/\/ buffer_bottom is the lowest address of the 3 core regions (mc, rw, ro) when\n+  \/\/ we are copying the class metadata into the buffer.\n+  address buffer_bottom = (address)rs.base();\n+  log_info(cds)(\"Reserved output buffer space at    : \" PTR_FORMAT \" [\" SIZE_FORMAT \" bytes]\",\n+                p2i(buffer_bottom), buffer_size);\n+  MetaspaceShared::set_shared_rs(rs);\n+\n+  MetaspaceShared::init_shared_dump_space(_mc_region);\n+  _buffer_bottom = buffer_bottom;\n+  _last_verified_top = buffer_bottom;\n+  _current_dump_space = _mc_region;\n+  _num_dump_regions_used = 1;\n+  _other_region_used_bytes = 0;\n+\n+  ArchivePtrMarker::initialize(&_ptrmap, (address*)_mc_region->base(), (address*)_mc_region->top());\n+\n+  \/\/ The bottom of the static archive should be mapped at this address by default.\n+  _requested_static_archive_bottom = (address)MetaspaceShared::requested_base_address();\n+\n+  \/\/ The bottom of the archive (that I am writing now) should be mapped at this address by default.\n+  address my_archive_requested_bottom;\n+\n+  if (DumpSharedSpaces) {\n+    my_archive_requested_bottom = _requested_static_archive_bottom;\n+  } else {\n+    _mapped_static_archive_bottom = (address)MetaspaceObj::shared_metaspace_base();\n+    _mapped_static_archive_top  = (address)MetaspaceObj::shared_metaspace_top();\n+    assert(_mapped_static_archive_top >= _mapped_static_archive_bottom, \"must be\");\n+    size_t static_archive_size = _mapped_static_archive_top - _mapped_static_archive_bottom;\n+\n+    \/\/ At run time, we will mmap the dynamic archive at my_archive_requested_bottom\n+    _requested_static_archive_top = _requested_static_archive_bottom + static_archive_size;\n+    my_archive_requested_bottom = align_up(_requested_static_archive_top, MetaspaceShared::reserved_space_alignment());\n+\n+    _requested_dynamic_archive_bottom = my_archive_requested_bottom;\n+  }\n+\n+  _buffer_to_requested_delta = my_archive_requested_bottom - _buffer_bottom;\n+\n+  address my_archive_requested_top = my_archive_requested_bottom + buffer_size;\n+  if (my_archive_requested_bottom <  _requested_static_archive_bottom ||\n+      my_archive_requested_top    <= _requested_static_archive_bottom) {\n+    \/\/ Size overflow.\n+    log_error(cds)(\"my_archive_requested_bottom = \" INTPTR_FORMAT, p2i(my_archive_requested_bottom));\n+    log_error(cds)(\"my_archive_requested_top    = \" INTPTR_FORMAT, p2i(my_archive_requested_top));\n+    log_error(cds)(\"SharedBaseAddress (\" INTPTR_FORMAT \") is too high. \"\n+                   \"Please rerun java -Xshare:dump with a lower value\", p2i(_requested_static_archive_bottom));\n+    vm_direct_exit(0);\n+  }\n+\n+  return buffer_bottom;\n+}\n+\n@@ -583,0 +686,1 @@\n+  log_info(cds)(\"Relocating external roots ... \");\n@@ -587,0 +691,1 @@\n+  log_info(cds)(\"done\");\n@@ -589,2 +694,2 @@\n-void ArchiveBuilder::relocate_pointers() {\n-  log_info(cds)(\"Relocating embedded pointers ... \");\n+void ArchiveBuilder::relocate_metaspaceobj_embedded_pointers() {\n+  log_info(cds)(\"Relocating embedded pointers in core regions ... \");\n@@ -594,5 +699,0 @@\n-\n-  log_info(cds)(\"Relocating external roots ... \");\n-  relocate_roots();\n-\n-  log_info(cds)(\"done\");\n@@ -633,1 +733,93 @@\n-        log_debug(cds, class)(\"klasses[%4d] = \" PTR_FORMAT \" %s\", i, p2i(to_target(ik)), ik->external_name());\n+        log_debug(cds, class)(\"klasses[%4d] = \" PTR_FORMAT \" %s\", i, p2i(to_requested(ik)), ik->external_name());\n+      }\n+    }\n+  }\n+}\n+\n+uintx ArchiveBuilder::buffer_to_offset(address p) const {\n+  address requested_p = to_requested(p);\n+  assert(requested_p >= _requested_static_archive_bottom, \"must be\");\n+  return requested_p - _requested_static_archive_bottom;\n+}\n+\n+uintx ArchiveBuilder::any_to_offset(address p) const {\n+  if (is_in_mapped_static_archive(p)) {\n+    assert(DynamicDumpSharedSpaces, \"must be\");\n+    return p - _mapped_static_archive_bottom;\n+  }\n+  return buffer_to_offset(p);\n+}\n+\n+\/\/ Update a Java object to point its Klass* to the new location after\n+\/\/ shared archive has been compacted.\n+void ArchiveBuilder::relocate_klass_ptr(oop o) {\n+  assert(DumpSharedSpaces, \"sanity\");\n+  Klass* k = get_relocated_klass(o->klass());\n+  Klass* requested_k = to_requested(k);\n+  narrowKlass nk = CompressedKlassPointers::encode_not_null(requested_k, _requested_static_archive_bottom);\n+  o->set_narrow_klass(nk);\n+}\n+\n+\/\/ RelocateBufferToRequested --- Relocate all the pointers in mc\/rw\/ro,\n+\/\/ so that the archive can be mapped to the \"requested\" location without runtime relocation.\n+\/\/\n+\/\/ - See ArchiveBuilder header for the definition of \"buffer\", \"mapped\" and \"requested\"\n+\/\/ - ArchivePtrMarker::ptrmap() marks all the pointers in the mc\/rw\/ro regions\n+\/\/ - Every pointer must have one of the following values:\n+\/\/   [a] NULL:\n+\/\/       No relocation is needed. Remove this pointer from ptrmap so we don't need to\n+\/\/       consider it at runtime.\n+\/\/   [b] Points into an object X which is inside the buffer:\n+\/\/       Adjust this pointer by _buffer_to_requested_delta, so it points to X\n+\/\/       when the archive is mapped at the requested location.\n+\/\/   [c] Points into an object Y which is inside mapped static archive:\n+\/\/       - This happens only during dynamic dump\n+\/\/       - Adjust this pointer by _mapped_to_requested_static_archive_delta,\n+\/\/         so it points to Y when the static archive is mapped at the requested location.\n+template <bool STATIC_DUMP>\n+class RelocateBufferToRequested : public BitMapClosure {\n+  ArchiveBuilder* _builder;\n+  address _buffer_bottom;\n+  intx _buffer_to_requested_delta;\n+  intx _mapped_to_requested_static_archive_delta;\n+  size_t _max_non_null_offset;\n+\n+ public:\n+  RelocateBufferToRequested(ArchiveBuilder* builder) {\n+    _builder = builder;\n+    _buffer_bottom = _builder->buffer_bottom();\n+    _buffer_to_requested_delta = builder->buffer_to_requested_delta();\n+    _mapped_to_requested_static_archive_delta = builder->requested_static_archive_bottom() - builder->mapped_static_archive_bottom();\n+    _max_non_null_offset = 0;\n+\n+    address bottom = _builder->buffer_bottom();\n+    address top = _builder->buffer_top();\n+    address new_bottom = bottom + _buffer_to_requested_delta;\n+    address new_top = top + _buffer_to_requested_delta;\n+    log_debug(cds)(\"Relocating archive from [\" INTPTR_FORMAT \" - \" INTPTR_FORMAT \" ] to \"\n+                   \"[\" INTPTR_FORMAT \" - \" INTPTR_FORMAT \" ]\",\n+                   p2i(bottom), p2i(top),\n+                   p2i(new_bottom), p2i(new_top));\n+  }\n+\n+  bool do_bit(size_t offset) {\n+    address* p = (address*)_buffer_bottom + offset;\n+    assert(_builder->is_in_buffer_space(p), \"pointer must live in buffer space\");\n+\n+    if (*p == NULL) {\n+      \/\/ todo -- clear bit, etc\n+      ArchivePtrMarker::ptrmap()->clear_bit(offset);\n+    } else {\n+      if (STATIC_DUMP) {\n+        assert(_builder->is_in_buffer_space(*p), \"old pointer must point inside buffer space\");\n+        *p += _buffer_to_requested_delta;\n+        assert(_builder->is_in_requested_static_archive(*p), \"new pointer must point inside requested archive\");\n+      } else {\n+        if (_builder->is_in_buffer_space(*p)) {\n+          *p += _buffer_to_requested_delta;\n+          \/\/ assert is in requested dynamic archive\n+        } else {\n+          assert(_builder->is_in_mapped_static_archive(*p), \"old pointer must point inside buffer space or mapped static archive\");\n+          *p += _mapped_to_requested_static_archive_delta;\n+          assert(_builder->is_in_requested_static_archive(*p), \"new pointer must point inside requested archive\");\n+        }\n@@ -635,0 +827,1 @@\n+      _max_non_null_offset = offset;\n@@ -636,0 +829,23 @@\n+\n+    return true; \/\/ keep iterating\n+  }\n+\n+  void doit() {\n+    ArchivePtrMarker::ptrmap()->iterate(this);\n+    ArchivePtrMarker::compact(_max_non_null_offset);\n+  }\n+};\n+\n+\n+void ArchiveBuilder::relocate_to_requested() {\n+  size_t my_archive_size = buffer_top() - buffer_bottom();\n+\n+  if (DumpSharedSpaces) {\n+    _requested_static_archive_top = _requested_static_archive_bottom + my_archive_size;\n+    RelocateBufferToRequested<true> patcher(this);\n+    patcher.doit();\n+  } else {\n+    assert(DynamicDumpSharedSpaces, \"must be\");\n+    _requested_dynamic_archive_top = _requested_dynamic_archive_bottom + my_archive_size;\n+    RelocateBufferToRequested<false> patcher(this);\n+    patcher.doit();\n@@ -652,1 +868,1 @@\n-    \/\/ Translate the buffers used by the MC\/RW\/RO regions to their eventual locations\n+    \/\/ Translate the buffers used by the MC\/RW\/RO regions to their eventual (requested) locations\n@@ -654,1 +870,1 @@\n-    return _buffer_to_target_delta + MetaspaceShared::final_delta();\n+    return ArchiveBuilder::current()->buffer_to_requested_delta();\n@@ -933,0 +1149,6 @@\n+\n+#ifndef PRODUCT\n+void ArchiveBuilder::assert_is_vm_thread() {\n+  assert(Thread::current()->is_VM_thread(), \"ArchiveBuilder should be used only inside the VMThread\");\n+}\n+#endif\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.cpp","additions":240,"deletions":18,"binary":false,"changes":258,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -43,0 +44,16 @@\n+\/\/ Overview of CDS archive creation (for both static and dynamic dump):\n+\/\/\n+\/\/ [1] Load all classes (static dump: from the classlist, dynamic dump: as part of app execution)\n+\/\/ [2] Allocate \"output buffer\"\n+\/\/ [3] Copy contents of the 3 \"core\" regions (mc\/rw\/ro) into the output buffer.\n+\/\/       - mc region:\n+\/\/         allocate_method_trampolines();\n+\/\/         allocate the cpp vtables (static dump only)\n+\/\/       - memcpy the MetaspaceObjs into rw\/ro:\n+\/\/         dump_rw_region();\n+\/\/         dump_ro_region();\n+\/\/       - fix all the pointers in the MetaspaceObjs to point to the copies\n+\/\/         relocate_metaspaceobj_embedded_pointers()\n+\/\/ [4] Copy symbol table, dictionary, etc, into the ro region\n+\/\/ [5] Relocate all the pointers in mc\/rw\/ro, so that the archive can be mapped to\n+\/\/     the \"requested\" location without runtime relocation. See relocate_to_requested()\n@@ -44,0 +61,26 @@\n+protected:\n+  DumpRegion* _current_dump_space;\n+  address _buffer_bottom;                      \/\/ for writing the contents of mc\/rw\/ro regions\n+  address _last_verified_top;\n+  int _num_dump_regions_used;\n+  size_t _other_region_used_bytes;\n+\n+  \/\/ These are the addresses where we will request the static and dynamic archives to be\n+  \/\/ mapped at run time. If the request fails (due to ASLR), we will map the archives at\n+  \/\/ os-selected addresses.\n+  address _requested_static_archive_bottom;     \/\/ This is determined solely by the value of\n+                                                \/\/ SharedBaseAddress during -Xshare:dump.\n+  address _requested_static_archive_top;\n+  address _requested_dynamic_archive_bottom;    \/\/ Used only during dynamic dump. It's placed\n+                                                \/\/ immediately above _requested_static_archive_top.\n+  address _requested_dynamic_archive_top;\n+\n+  \/\/ (Used only during dynamic dump) where the static archive is actually mapped. This\n+  \/\/ may be different than _requested_static_archive_{bottom,top} due to ASLR\n+  address _mapped_static_archive_bottom;\n+  address _mapped_static_archive_top;\n+\n+  intx _buffer_to_requested_delta;\n+\n+  DumpRegion* current_dump_space() const {  return _current_dump_space;  }\n+\n@@ -154,0 +197,1 @@\n+  CHeapBitMap _ptrmap;    \/\/ bitmap used by ArchivePtrMarker\n@@ -169,1 +213,1 @@\n-  static ArchiveBuilder* _singleton;\n+  static ArchiveBuilder* _current;\n@@ -179,1 +223,1 @@\n-      _oldtop = _singleton->_ro_region->top();\n+      _oldtop = _current->_ro_region->top();\n@@ -198,1 +242,0 @@\n-  void relocate_roots();\n@@ -202,0 +245,1 @@\n+\n@@ -207,0 +251,2 @@\n+  size_t _estimated_hashtable_bytes;     \/\/ symbol table and dictionaries\n+  size_t _estimated_trampoline_bytes;    \/\/ method entry trampolines\n@@ -208,3 +254,1 @@\n-protected:\n-  DumpRegion* _current_dump_space;\n-  address _alloc_bottom;\n+  static const int _total_dump_regions = 3;\n@@ -212,1 +256,5 @@\n-  DumpRegion* current_dump_space() const {  return _current_dump_space;  }\n+  size_t estimate_archive_size();\n+\n+  static size_t reserve_alignment() {\n+    return os::vm_allocation_granularity();\n+  }\n@@ -216,0 +264,7 @@\n+  address reserve_buffer();\n+\n+  address buffer_bottom()                    const { return _buffer_bottom;                       }\n+  address buffer_top()                       const { return (address)current_dump_space()->top(); }\n+  address requested_static_archive_bottom()  const { return  _requested_static_archive_bottom;    }\n+  address mapped_static_archive_bottom()     const { return  _mapped_static_archive_bottom;       }\n+  intx buffer_to_requested_delta()           const { return _buffer_to_requested_delta;           }\n@@ -218,1 +273,5 @@\n-    return (_alloc_bottom <= p && p < (address)current_dump_space()->top());\n+    return (buffer_bottom() <= p && p < buffer_top());\n+  }\n+\n+  template <typename T> bool is_in_requested_static_archive(T p) const {\n+    return _requested_static_archive_bottom <= (address)p && (address)p < _requested_static_archive_top;\n@@ -221,3 +280,2 @@\n-  template <typename T> bool is_in_target_space(T target_obj) const {\n-    address buff_obj = address(target_obj) - _buffer_to_target_delta;\n-    return is_in_buffer_space(buff_obj);\n+  template <typename T> bool is_in_mapped_static_archive(T p) const {\n+    return _mapped_static_archive_bottom <= (address)p && (address)p < _mapped_static_archive_top;\n@@ -230,2 +288,3 @@\n-  template <typename T> T to_target_no_check(T obj) const {\n-    return (T)(address(obj) + _buffer_to_target_delta);\n+  template <typename T> T to_requested(T obj) const {\n+    assert(is_in_buffer_space(obj), \"must be\");\n+    return (T)(address(obj) + _buffer_to_requested_delta);\n@@ -234,3 +293,2 @@\n-  template <typename T> T to_target(T obj) const {\n-    assert(is_in_buffer_space(obj), \"must be\");\n-    return (T)(address(obj) + _buffer_to_target_delta);\n+  static intx get_buffer_to_requested_delta() {\n+    return current()->buffer_to_requested_delta();\n@@ -239,0 +297,27 @@\n+public:\n+  static const uintx MAX_SHARED_DELTA = 0x7FFFFFFF;\n+\n+  \/\/ The address p points to an object inside the output buffer. When the archive is mapped\n+  \/\/ at the requested address, what's the offset of this object from _requested_static_archive_bottom?\n+  uintx buffer_to_offset(address p) const;\n+\n+  \/\/ Same as buffer_to_offset, except that the address p points to either (a) an object\n+  \/\/ inside the output buffer, or (b), an object in the currently mapped static archive.\n+  uintx any_to_offset(address p) const;\n+\n+  template <typename T>\n+  u4 buffer_to_offset_u4(T p) const {\n+    uintx offset = buffer_to_offset((address)p);\n+    guarantee(offset <= MAX_SHARED_DELTA, \"must be 32-bit offset\");\n+    return (u4)offset;\n+  }\n+\n+  template <typename T>\n+  u4 any_to_offset_u4(T p) const {\n+    uintx offset = any_to_offset((address)p);\n+    guarantee(offset <= MAX_SHARED_DELTA, \"must be 32-bit offset\");\n+    return (u4)offset;\n+  }\n+\n+  static void assert_is_vm_thread() PRODUCT_RETURN;\n+\n@@ -254,1 +339,2 @@\n-  void relocate_pointers();\n+  void relocate_metaspaceobj_embedded_pointers();\n+  void relocate_roots();\n@@ -257,0 +343,1 @@\n+  void relocate_to_requested();\n@@ -268,3 +355,8 @@\n-  static ArchiveBuilder* singleton() {\n-    assert(_singleton != NULL, \"ArchiveBuilder must be active\");\n-    return _singleton;\n+  static bool is_active() {\n+    return (_current != NULL);\n+  }\n+\n+  static ArchiveBuilder* current() {\n+    assert_is_vm_thread();\n+    assert(_current != NULL, \"ArchiveBuilder must be active\");\n+    return _current;\n@@ -274,1 +366,1 @@\n-    return singleton()->_alloc_stats;\n+    return current()->_alloc_stats;\n@@ -277,0 +369,2 @@\n+  void relocate_klass_ptr(oop o);\n+\n@@ -278,1 +372,1 @@\n-    Klass* klass = (Klass*)singleton()->get_dumped_addr((address)orig_klass);\n+    Klass* klass = (Klass*)current()->get_dumped_addr((address)orig_klass);\n@@ -284,1 +378,1 @@\n-    return (Symbol*)singleton()->get_dumped_addr((address)orig_symbol);\n+    return (Symbol*)current()->get_dumped_addr((address)orig_symbol);\n@@ -288,1 +382,0 @@\n-  static intx _buffer_to_target_delta;\n@@ -295,1 +388,0 @@\n-\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.hpp","additions":117,"deletions":25,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -169,1 +169,1 @@\n-  reset_states(SystemDictionary::java_platform_loader(), THREAD);\n+  reset_states(SystemDictionary::java_platform_loader(), CHECK);\n@@ -250,1 +250,1 @@\n-oop HeapShared::archive_heap_object(oop obj, Thread* THREAD) {\n+oop HeapShared::archive_heap_object(oop obj) {\n@@ -269,1 +269,0 @@\n-    MetaspaceShared::relocate_klass_ptr(archived_oop);\n@@ -301,1 +300,1 @@\n-void HeapShared::archive_klass_objects(Thread* THREAD) {\n+void HeapShared::archive_klass_objects() {\n@@ -305,1 +304,1 @@\n-    Klass* k = klasses->at(i);\n+    Klass* k = ArchiveBuilder::get_relocated_klass(klasses->at(i));\n@@ -308,1 +307,1 @@\n-    java_lang_Class::archive_mirror(k, CHECK);\n+    java_lang_Class::archive_mirror(k);\n@@ -313,1 +312,1 @@\n-      ik->constants()->archive_resolved_references(THREAD);\n+      ik->constants()->archive_resolved_references();\n@@ -373,2 +372,1 @@\n-                           false \/* is_full_module_graph *\/,\n-                           THREAD);\n+                           false \/* is_full_module_graph *\/);\n@@ -384,1 +382,0 @@\n-  Thread* THREAD = Thread::current();\n@@ -387,1 +384,1 @@\n-  java_lang_Class::archive_basic_type_mirrors(THREAD);\n+  java_lang_Class::archive_basic_type_mirrors();\n@@ -389,1 +386,1 @@\n-  archive_klass_objects(THREAD);\n+  archive_klass_objects();\n@@ -394,2 +391,1 @@\n-                           false \/* is_full_module_graph *\/,\n-                           THREAD);\n+                           false \/* is_full_module_graph *\/);\n@@ -400,2 +396,1 @@\n-                             true \/* is_full_module_graph *\/,\n-                             THREAD);\n+                             true \/* is_full_module_graph *\/);\n@@ -457,1 +452,1 @@\n-  Klass* relocated_k = MetaspaceShared::get_relocated_klass(k);\n+  Klass* relocated_k = ArchiveBuilder::get_relocated_klass(k);\n@@ -467,1 +462,1 @@\n-  Klass* relocated_k = MetaspaceShared::get_relocated_klass(k);\n+  Klass* relocated_k = ArchiveBuilder::get_relocated_klass(k);\n@@ -487,1 +482,1 @@\n-void KlassSubGraphInfo::add_subgraph_object_klass(Klass* orig_k, Klass* relocated_k) {\n+void KlassSubGraphInfo::add_subgraph_object_klass(Klass* orig_k) {\n@@ -489,2 +484,1 @@\n-  assert(relocated_k == MetaspaceShared::get_relocated_klass(orig_k),\n-         \"must be the relocated Klass in the shared space\");\n+  Klass* relocated_k = ArchiveBuilder::get_relocated_klass(orig_k);\n@@ -497,1 +491,1 @@\n-  assert(ArchiveBuilder::singleton()->is_in_buffer_space(relocated_k), \"must be a shared class\");\n+  assert(ArchiveBuilder::current()->is_in_buffer_space(relocated_k), \"must be a shared class\");\n@@ -622,2 +616,2 @@\n-      unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary(klass);\n-      u4 delta = MetaspaceShared::object_delta_u4(record);\n+      unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary((address)klass);\n+      u4 delta = ArchiveBuilder::current()->any_to_offset_u4(record);\n@@ -683,1 +677,1 @@\n-void HeapShared::resolve_classes(TRAPS) {\n+void HeapShared::resolve_classes(Thread* THREAD) {\n@@ -689,1 +683,1 @@\n-                                CHECK);\n+                                THREAD);\n@@ -692,1 +686,1 @@\n-                                CHECK);\n+                                THREAD);\n@@ -695,1 +689,1 @@\n-                                CHECK);\n+                                THREAD);\n@@ -699,1 +693,1 @@\n-                                               int num, TRAPS) {\n+                                               int num, Thread* THREAD) {\n@@ -705,1 +699,1 @@\n-    resolve_classes_for_subgraph_of(k, CHECK);\n+    resolve_classes_for_subgraph_of(k, THREAD);\n@@ -709,2 +703,3 @@\n-void HeapShared::resolve_classes_for_subgraph_of(Klass* k, TRAPS) {\n- const ArchivedKlassSubGraphInfoRecord* record = resolve_or_init_classes_for_subgraph_of(k, \/*do_init=*\/false, THREAD);\n+void HeapShared::resolve_classes_for_subgraph_of(Klass* k, Thread* THREAD) {\n+ const ArchivedKlassSubGraphInfoRecord* record =\n+   resolve_or_init_classes_for_subgraph_of(k, \/*do_init=*\/false, THREAD);\n@@ -719,1 +714,1 @@\n-void HeapShared::initialize_from_archived_subgraph(Klass* k, TRAPS) {\n+void HeapShared::initialize_from_archived_subgraph(Klass* k, Thread* THREAD) {\n@@ -736,1 +731,1 @@\n-    init_archived_fields_for(k, record, THREAD);\n+    init_archived_fields_for(k, record);\n@@ -744,1 +739,4 @@\n-  unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary(k);\n+  if (!k->is_shared()) {\n+    return NULL;\n+  }\n+  unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary_quick(k);\n@@ -775,1 +773,5 @@\n-        resolve_or_init(klasses->at(i), do_init, CHECK_NULL);\n+        Klass* klass = klasses->at(i);\n+        if (!klass->is_shared()) {\n+          return NULL;\n+        }\n+        resolve_or_init(klass, do_init, CHECK_NULL);\n@@ -801,1 +803,1 @@\n-void HeapShared::init_archived_fields_for(Klass* k, const ArchivedKlassSubGraphInfoRecord* record, TRAPS) {\n+void HeapShared::init_archived_fields_for(Klass* k, const ArchivedKlassSubGraphInfoRecord* record) {\n@@ -832,1 +834,1 @@\n-  unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary(k);\n+  unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary_quick(k);\n@@ -854,1 +856,0 @@\n-  Thread* _thread;\n@@ -860,1 +861,1 @@\n-                           oop orig, oop archived, TRAPS) :\n+                           oop orig, oop archived) :\n@@ -864,2 +865,1 @@\n-    _orig_referencing_obj(orig), _archived_referencing_obj(archived),\n-    _thread(THREAD) {}\n+    _orig_referencing_obj(orig), _archived_referencing_obj(archived) {}\n@@ -878,1 +878,0 @@\n-      Thread* THREAD = _thread;\n@@ -891,1 +890,1 @@\n-          _level + 1, _subgraph_info, obj, _is_closed_archive, THREAD);\n+          _level + 1, _subgraph_info, obj, _is_closed_archive);\n@@ -905,2 +904,1 @@\n-void HeapShared::check_closed_archive_heap_region_object(InstanceKlass* k,\n-                                                         Thread* THREAD) {\n+void HeapShared::check_closed_archive_heap_region_object(InstanceKlass* k) {\n@@ -912,1 +910,1 @@\n-        ResourceMark rm(THREAD);\n+        ResourceMark rm;\n@@ -948,2 +946,1 @@\n-                                               bool is_closed_archive,\n-                                               TRAPS) {\n+                                               bool is_closed_archive) {\n@@ -989,1 +986,1 @@\n-    archived_obj = archive_heap_object(orig_obj, THREAD);\n+    archived_obj = archive_heap_object(orig_obj);\n@@ -1024,2 +1021,1 @@\n-  Klass *relocated_k = archived_obj->klass();\n-  subgraph_info->add_subgraph_object_klass(orig_k, relocated_k);\n+  subgraph_info->add_subgraph_object_klass(orig_k);\n@@ -1028,1 +1024,1 @@\n-                                  subgraph_info, orig_obj, archived_obj, THREAD);\n+                                  subgraph_info, orig_obj, archived_obj);\n@@ -1031,1 +1027,1 @@\n-    check_closed_archive_heap_region_object(InstanceKlass::cast(orig_k), THREAD);\n+    check_closed_archive_heap_region_object(InstanceKlass::cast(orig_k));\n@@ -1074,2 +1070,1 @@\n-                                                             bool is_closed_archive,\n-                                                             TRAPS) {\n+                                                             bool is_closed_archive) {\n@@ -1093,2 +1088,1 @@\n-    oop af = archive_reachable_objects_from(1, subgraph_info, f,\n-                                            is_closed_archive, CHECK);\n+    oop af = archive_reachable_objects_from(1, subgraph_info, f, is_closed_archive);\n@@ -1307,2 +1301,1 @@\n-                                          bool is_full_module_graph,\n-                                          Thread* THREAD) {\n+                                          bool is_full_module_graph) {\n@@ -1339,1 +1332,1 @@\n-                                                  is_closed_archive, CHECK);\n+                                                  is_closed_archive);\n@@ -1408,0 +1401,1 @@\n+  ArchiveBuilder* builder = DumpSharedSpaces ? ArchiveBuilder::current() : NULL;\n@@ -1414,0 +1408,3 @@\n+    if (DumpSharedSpaces) {\n+      builder->relocate_klass_ptr(o);\n+    }\n","filename":"src\/hotspot\/share\/memory\/heapShared.cpp","additions":58,"deletions":61,"binary":false,"changes":119,"status":"modified"},{"patch":"@@ -177,2 +177,2 @@\n-static bool shared_base_too_high(char* shared_base, size_t cds_total) {\n-  if (SharedBaseAddress != 0 && shared_base < (char*)SharedBaseAddress) {\n+static bool shared_base_too_high(char* specified_base, char* aligned_base, size_t cds_max) {\n+  if (specified_base != NULL && aligned_base < specified_base) {\n@@ -183,1 +183,1 @@\n-  if (max_uintx - uintx(shared_base) < uintx(cds_total)) {\n+  if (max_uintx - uintx(aligned_base) < uintx(cds_max)) {\n@@ -191,2 +191,4 @@\n-static char* compute_shared_base(size_t cds_total) {\n-  char* shared_base = (char*)align_up((char*)SharedBaseAddress, MetaspaceShared::reserved_space_alignment());\n+static char* compute_shared_base(size_t cds_max) {\n+  char* specified_base = (char*)SharedBaseAddress;\n+  char* aligned_base = align_up(specified_base, MetaspaceShared::reserved_space_alignment());\n+\n@@ -194,1 +196,1 @@\n-  if (shared_base_too_high(shared_base, cds_total)) {\n+  if (shared_base_too_high(specified_base, aligned_base, cds_max)) {\n@@ -196,1 +198,1 @@\n-  } else if (!shared_base_valid(shared_base)) {\n+  } else if (!shared_base_valid(aligned_base)) {\n@@ -198,0 +200,2 @@\n+  } else {\n+    return aligned_base;\n@@ -199,9 +203,12 @@\n-  if (err) {\n-    log_warning(cds)(\"SharedBaseAddress (\" INTPTR_FORMAT \") is %s. Reverted to \" INTPTR_FORMAT,\n-                     p2i((void*)SharedBaseAddress), err,\n-                     p2i((void*)Arguments::default_SharedBaseAddress()));\n-    SharedBaseAddress = Arguments::default_SharedBaseAddress();\n-    shared_base = (char*)align_up((char*)SharedBaseAddress, MetaspaceShared::reserved_space_alignment());\n-  }\n-  assert(!shared_base_too_high(shared_base, cds_total) && shared_base_valid(shared_base), \"Sanity\");\n-  return shared_base;\n+\n+  log_warning(cds)(\"SharedBaseAddress (\" INTPTR_FORMAT \") is %s. Reverted to \" INTPTR_FORMAT,\n+                   p2i((void*)SharedBaseAddress), err,\n+                   p2i((void*)Arguments::default_SharedBaseAddress()));\n+\n+  specified_base = (char*)Arguments::default_SharedBaseAddress();\n+  aligned_base = align_up(specified_base, MetaspaceShared::reserved_space_alignment());\n+\n+  \/\/ Make sure the default value of SharedBaseAddress specified in globals.hpp is sane.\n+  assert(!shared_base_too_high(specified_base, aligned_base, cds_max), \"Sanity\");\n+  assert(shared_base_valid(aligned_base), \"Sanity\");\n+  return aligned_base;\n@@ -210,1 +217,1 @@\n-void MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() {\n+void MetaspaceShared::initialize_for_static_dump() {\n@@ -213,0 +220,3 @@\n+  \/\/ The max allowed size for CDS archive. We use this to limit SharedBaseAddress\n+  \/\/ to avoid address space wrap around.\n+  size_t cds_max;\n@@ -216,4 +226,1 @@\n-  \/\/ On 64-bit VM we reserve a 4G range and, if UseCompressedClassPointers=1,\n-  \/\/  will use that to house both the archives and the ccs. See below for\n-  \/\/  details.\n-  const size_t cds_total = align_down(UnscaledClassSpaceMax, reserve_alignment);\n+  cds_max = align_down(UnscaledClassSpaceMax, reserve_alignment);\n@@ -224,1 +231,1 @@\n-  size_t cds_total = align_down(256*M, reserve_alignment);\n+  cds_max = align_down(256*M, reserve_alignment);\n@@ -227,122 +234,2 @@\n-  char* shared_base = compute_shared_base(cds_total);\n-  _requested_base_address = shared_base;\n-\n-  \/\/ Whether to use SharedBaseAddress as attach address.\n-  bool use_requested_base = true;\n-\n-  if (shared_base == NULL) {\n-    use_requested_base = false;\n-  }\n-\n-  if (ArchiveRelocationMode == 1) {\n-    log_info(cds)(\"ArchiveRelocationMode == 1: always allocate class space at an alternative address\");\n-    use_requested_base = false;\n-  }\n-\n-  \/\/ First try to reserve the space at the specified SharedBaseAddress.\n-  assert(!_shared_rs.is_reserved(), \"must be\");\n-  if (use_requested_base) {\n-    _shared_rs = ReservedSpace(cds_total, reserve_alignment,\n-                               false \/* large *\/, (char*)shared_base);\n-    if (_shared_rs.is_reserved()) {\n-      assert(_shared_rs.base() == shared_base, \"should match\");\n-    } else {\n-      log_info(cds)(\"dumptime space reservation: failed to map at \"\n-                    \"SharedBaseAddress \" PTR_FORMAT, p2i(shared_base));\n-    }\n-  }\n-  if (!_shared_rs.is_reserved()) {\n-    \/\/ Get a reserved space anywhere if attaching at the SharedBaseAddress\n-    \/\/  fails:\n-    if (UseCompressedClassPointers) {\n-      \/\/ If we need to reserve class space as well, let the platform handle\n-      \/\/  the reservation.\n-      LP64_ONLY(_shared_rs =\n-                Metaspace::reserve_address_space_for_compressed_classes(cds_total);)\n-      NOT_LP64(ShouldNotReachHere();)\n-    } else {\n-      \/\/ anywhere is fine.\n-      _shared_rs = ReservedSpace(cds_total, reserve_alignment,\n-                                 false \/* large *\/, (char*)NULL);\n-    }\n-  }\n-\n-  if (!_shared_rs.is_reserved()) {\n-    vm_exit_during_initialization(\"Unable to reserve memory for shared space\",\n-                                  err_msg(SIZE_FORMAT \" bytes.\", cds_total));\n-  }\n-\n-#ifdef _LP64\n-\n-  if (UseCompressedClassPointers) {\n-\n-    assert(CompressedKlassPointers::is_valid_base((address)_shared_rs.base()), \"Sanity\");\n-\n-    \/\/ On 64-bit VM, if UseCompressedClassPointers=1, the compressed class space\n-    \/\/  must be allocated near the cds such as that the compressed Klass pointer\n-    \/\/  encoding can be used to en\/decode pointers from both cds and ccs. Since\n-    \/\/  Metaspace cannot do this (it knows nothing about cds), we do it for\n-    \/\/  Metaspace here and pass it the space to use for ccs.\n-    \/\/\n-    \/\/ We do this by reserving space for the ccs behind the archives. Note\n-    \/\/  however that ccs follows a different alignment\n-    \/\/  (Metaspace::reserve_alignment), so there may be a gap between ccs and\n-    \/\/  cds.\n-    \/\/ We use a similar layout at runtime, see reserve_address_space_for_archives().\n-    \/\/\n-    \/\/                              +-- SharedBaseAddress (default = 0x800000000)\n-    \/\/                              v\n-    \/\/ +-..---------+---------+ ... +----+----+----+--------+-----------------+\n-    \/\/ |    Heap    | Archive |     | MC | RW | RO | [gap]  |    class space  |\n-    \/\/ +-..---------+---------+ ... +----+----+----+--------+-----------------+\n-    \/\/ |<--   MaxHeapSize  -->|     |<-- UnscaledClassSpaceMax = 4GB -->|\n-    \/\/\n-    \/\/ Note: ccs must follow the archives, and the archives must start at the\n-    \/\/  encoding base. However, the exact placement of ccs does not matter as\n-    \/\/  long as it it resides in the encoding range of CompressedKlassPointers\n-    \/\/  and comes after the archive.\n-    \/\/\n-    \/\/ We do this by splitting up the allocated 4G into 3G of archive space,\n-    \/\/  followed by 1G for the ccs:\n-    \/\/ + The upper 1 GB is used as the \"temporary compressed class space\"\n-    \/\/   -- preload_classes() will store Klasses into this space.\n-    \/\/ + The lower 3 GB is used for the archive -- when preload_classes()\n-    \/\/   is done, ArchiveBuilder will copy the class metadata into this\n-    \/\/   space, first the RW parts, then the RO parts.\n-\n-    \/\/ Starting address of ccs must be aligned to Metaspace::reserve_alignment()...\n-    size_t class_space_size = align_down(_shared_rs.size() \/ 4, Metaspace::reserve_alignment());\n-    address class_space_start = (address)align_down(_shared_rs.end() - class_space_size, Metaspace::reserve_alignment());\n-    size_t archive_size = class_space_start - (address)_shared_rs.base();\n-\n-    ReservedSpace tmp_class_space = _shared_rs.last_part(archive_size);\n-    _shared_rs = _shared_rs.first_part(archive_size);\n-\n-    \/\/ ... as does the size of ccs.\n-    tmp_class_space = tmp_class_space.first_part(class_space_size);\n-    CompressedClassSpaceSize = class_space_size;\n-\n-    \/\/ Let Metaspace initialize ccs\n-    Metaspace::initialize_class_space(tmp_class_space);\n-\n-    \/\/ and set up CompressedKlassPointers encoding.\n-    CompressedKlassPointers::initialize((address)_shared_rs.base(), cds_total);\n-\n-    log_info(cds)(\"narrow_klass_base = \" PTR_FORMAT \", narrow_klass_shift = %d\",\n-                  p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());\n-\n-    log_info(cds)(\"Allocated temporary class space: \" SIZE_FORMAT \" bytes at \" PTR_FORMAT,\n-                  CompressedClassSpaceSize, p2i(tmp_class_space.base()));\n-\n-    assert(_shared_rs.end() == tmp_class_space.base() &&\n-           is_aligned(_shared_rs.base(), MetaspaceShared::reserved_space_alignment()) &&\n-           is_aligned(tmp_class_space.base(), Metaspace::reserve_alignment()) &&\n-           is_aligned(tmp_class_space.size(), Metaspace::reserve_alignment()), \"Sanity\");\n-  }\n-\n-#endif\n-\n-  init_shared_dump_space(&_mc_region);\n-  SharedBaseAddress = (size_t)_shared_rs.base();\n-  log_info(cds)(\"Allocated shared space: \" SIZE_FORMAT \" bytes at \" PTR_FORMAT,\n-                _shared_rs.size(), p2i(_shared_rs.base()));\n+  _requested_base_address = compute_shared_base(cds_max);\n+  SharedBaseAddress = (size_t)_requested_base_address;\n@@ -467,4 +354,0 @@\n-void MetaspaceShared::initialize_ptr_marker(CHeapBitMap* ptrmap) {\n-  ArchivePtrMarker::initialize(ptrmap, (address*)_shared_vs.low(), (address*)_shared_vs.high());\n-}\n-\n@@ -533,12 +416,0 @@\n-uintx MetaspaceShared::object_delta_uintx(void* obj) {\n-  Arguments::assert_is_dumping_archive();\n-  if (DumpSharedSpaces) {\n-    assert(shared_rs()->contains(obj), \"must be\");\n-  } else {\n-    assert(is_in_shared_metaspace(obj) || DynamicArchive::is_in_target_space(obj), \"must be\");\n-  }\n-  address base_address = address(SharedBaseAddress);\n-  uintx deltax = address(obj) - base_address;\n-  return deltax;\n-}\n-\n@@ -606,1 +477,0 @@\n-  void relocate_to_requested_base_address(CHeapBitMap* ptrmap);\n@@ -624,4 +494,1 @@\n-    : ArchiveBuilder(mc_region, rw_region, ro_region) {\n-    _alloc_bottom = address(SharedBaseAddress);\n-    _buffer_to_target_delta = 0;\n-  }\n+    : ArchiveBuilder(mc_region, rw_region, ro_region) {}\n@@ -666,40 +533,0 @@\n-void VM_PopulateDumpSharedSpace::relocate_to_requested_base_address(CHeapBitMap* ptrmap) {\n-  intx addr_delta = MetaspaceShared::final_delta();\n-  if (addr_delta == 0) {\n-    ArchivePtrMarker::compact((address)SharedBaseAddress, (address)_ro_region.top());\n-  } else {\n-    \/\/ We are not able to reserve space at MetaspaceShared::requested_base_address() (due to ASLR).\n-    \/\/ This means that the current content of the archive is based on a random\n-    \/\/ address. Let's relocate all the pointers, so that it can be mapped to\n-    \/\/ MetaspaceShared::requested_base_address() without runtime relocation.\n-    \/\/\n-    \/\/ Note: both the base and dynamic archive are written with\n-    \/\/ FileMapHeader::_requested_base_address == MetaspaceShared::requested_base_address()\n-\n-    \/\/ Patch all pointers that are marked by ptrmap within this region,\n-    \/\/ where we have just dumped all the metaspace data.\n-    address patch_base = (address)SharedBaseAddress;\n-    address patch_end  = (address)_ro_region.top();\n-    size_t size = patch_end - patch_base;\n-\n-    \/\/ the current value of the pointers to be patched must be within this\n-    \/\/ range (i.e., must point to valid metaspace objects)\n-    address valid_old_base = patch_base;\n-    address valid_old_end  = patch_end;\n-\n-    \/\/ after patching, the pointers must point inside this range\n-    \/\/ (the requested location of the archive, as mapped at runtime).\n-    address valid_new_base = (address)MetaspaceShared::requested_base_address();\n-    address valid_new_end  = valid_new_base + size;\n-\n-    log_debug(cds)(\"Relocating archive from [\" INTPTR_FORMAT \" - \" INTPTR_FORMAT \" ] to \"\n-                   \"[\" INTPTR_FORMAT \" - \" INTPTR_FORMAT \" ]\", p2i(patch_base), p2i(patch_end),\n-                   p2i(valid_new_base), p2i(valid_new_end));\n-\n-    SharedDataRelocator<true> patcher((address*)patch_base, (address*)patch_end, valid_old_base, valid_old_end,\n-                                      valid_new_base, valid_new_end, addr_delta, ptrmap);\n-    ptrmap->iterate(&patcher);\n-    ArchivePtrMarker::compact(patcher.max_non_null_offset());\n-  }\n-}\n-\n@@ -708,2 +535,0 @@\n-  CHeapBitMap ptrmap;\n-  MetaspaceShared::initialize_ptr_marker(&ptrmap);\n@@ -738,1 +563,1 @@\n-  builder.set_current_dump_space(&_mc_region);\n+  builder.reserve_buffer();\n@@ -775,3 +600,1 @@\n-  builder.relocate_pointers();\n-\n-  dump_shared_symbol_table(builder.symbols());\n+  builder.relocate_metaspaceobj_embedded_pointers();\n@@ -784,0 +607,3 @@\n+  builder.relocate_roots();\n+  dump_shared_symbol_table(builder.symbols());\n+\n@@ -803,1 +629,1 @@\n-  relocate_to_requested_base_address(&ptrmap);\n+  builder.relocate_to_requested();\n@@ -828,1 +654,1 @@\n-  mapinfo->set_final_requested_base((char*)MetaspaceShared::requested_base_address());\n+  mapinfo->set_requested_base((char*)MetaspaceShared::requested_base_address());\n@@ -924,17 +750,0 @@\n-\/\/ Update a Java object to point its Klass* to the new location after\n-\/\/ shared archive has been compacted.\n-void MetaspaceShared::relocate_klass_ptr(oop o) {\n-  assert(DumpSharedSpaces, \"sanity\");\n-  Klass* k = ArchiveBuilder::get_relocated_klass(o->klass());\n-  o->set_klass(k);\n-}\n-\n-Klass* MetaspaceShared::get_relocated_klass(Klass *k, bool is_final) {\n-  assert(DumpSharedSpaces, \"sanity\");\n-  k = ArchiveBuilder::get_relocated_klass(k);\n-  if (is_final) {\n-    k = (Klass*)(address(k) + final_delta());\n-  }\n-  return k;\n-}\n-\n@@ -1841,7 +1650,0 @@\n-\/\/ This is used to relocate the pointers so that the base archive can be mapped at\n-\/\/ MetaspaceShared::requested_base_address() without runtime relocation.\n-intx MetaspaceShared::final_delta() {\n-  return intx(MetaspaceShared::requested_base_address())  \/\/ We want the base archive to be mapped to here at runtime\n-       - intx(SharedBaseAddress);                         \/\/ .. but the base archive is mapped at here at dump time\n-}\n-\n","filename":"src\/hotspot\/share\/memory\/metaspaceShared.cpp","additions":39,"deletions":237,"binary":false,"changes":276,"status":"modified"},{"patch":"@@ -69,0 +69,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n@@ -1265,1 +1266,0 @@\n-\n@@ -1284,0 +1284,8 @@\n+bool Universe::is_gc_active() {\n+  return heap()->is_gc_active();\n+}\n+\n+bool Universe::is_in_heap(const void* p) {\n+  return heap()->is_in(p);\n+}\n+\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -318,0 +318,4 @@\n+  DEBUG_ONLY(static bool is_gc_active();)\n+  DEBUG_ONLY(static bool is_in_heap(const void* p);)\n+  DEBUG_ONLY(static bool is_in_heap_or_null(const void* p) { return p == NULL || is_in_heap(p); })\n+\n","filename":"src\/hotspot\/share\/memory\/universe.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"oops\/arrayOop.hpp\"\n","filename":"src\/hotspot\/share\/oops\/accessBackend.inline.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -282,1 +282,1 @@\n-void ConstantPool::archive_resolved_references(Thread* THREAD) {\n+void ConstantPool::archive_resolved_references() {\n@@ -317,1 +317,1 @@\n-    oop archived = HeapShared::archive_heap_object(rr, THREAD);\n+    oop archived = HeapShared::archive_heap_object(rr);\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -751,1 +751,1 @@\n-  void archive_resolved_references(Thread *THREAD) NOT_CDS_JAVA_HEAP_RETURN;\n+  void archive_resolved_references() NOT_CDS_JAVA_HEAP_RETURN;\n","filename":"src\/hotspot\/share\/oops\/constantPool.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1303,1 +1303,1 @@\n-  \/\/ If we are profiling parameters, we reserver an area near the end\n+  \/\/ If we are profiling parameters, we reserved an area near the end\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -149,0 +149,8 @@\n+#if INCLUDE_CDS_JAVA_HEAP\n+void oopDesc::set_narrow_klass(narrowKlass nk) {\n+  assert(DumpSharedSpaces, \"Used by CDS only. Do not abuse!\");\n+  assert(UseCompressedClassPointers, \"must be\");\n+  _metadata._compressed_klass = nk;\n+}\n+#endif\n+\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -89,0 +89,1 @@\n+  void set_narrow_klass(narrowKlass nk) NOT_CDS_JAVA_HEAP_RETURN;\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,1 +28,0 @@\n-#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -36,0 +35,1 @@\n+#include \"oops\/oopsHierarchy.hpp\"\n@@ -38,0 +38,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -39,0 +40,1 @@\n+#include \"utilities\/debug.hpp\"\n@@ -40,0 +42,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -188,1 +191,1 @@\n-             (Universe::heap()->is_gc_active() && is_objArray() && is_forwarded() && (get_UseParallelGC() || get_UseG1GC())),\n+             (Universe::is_gc_active() && is_objArray() && is_forwarded() && (get_UseParallelGC() || get_UseG1GC())),\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -617,1 +617,1 @@\n-  uint8_t _nest;                \/\/ Nesting depth\n+  uint16_t _nest;               \/\/ Nesting depth\n@@ -1616,0 +1616,2 @@\n+\n+  bool is_safe_load_ctrl(Node* ctrl);\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1595,1 +1595,1 @@\n-        if (!n->is_Load() || late_load_ctrl != n_ctrl) {\n+        if (!n->is_Load() || (late_load_ctrl != n_ctrl && is_safe_load_ctrl(late_load_ctrl))) {\n@@ -1705,0 +1705,7 @@\n+bool PhaseIdealLoop::is_safe_load_ctrl(Node* ctrl) {\n+  if (ctrl->is_Proj() && ctrl->in(0)->is_Call() && ctrl->has_out_with(Op_Catch)) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"gc\/shared\/barrierSet.hpp\"\n@@ -416,9 +417,11 @@\n-    Node* vec_field_ld = LoadNode::make(gvn,\n-                                        ctrl,\n-                                        mem,\n-                                        vec_adr,\n-                                        vec_adr->bottom_type()->is_ptr(),\n-                                        TypeOopPtr::make_from_klass(field->type()->as_klass()),\n-                                        T_OBJECT,\n-                                        MemNode::unordered);\n-    vec_field_ld = gvn.transform(vec_field_ld);\n+    Node* vec_field_ld;\n+    {\n+      DecoratorSet decorators = MO_UNORDERED | IN_HEAP;\n+      C2AccessValuePtr addr(vec_adr, vec_adr->bottom_type()->is_ptr());\n+      MergeMemNode* local_mem = MergeMemNode::make(mem);\n+      gvn.record_for_igvn(local_mem);\n+      BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+      C2OptAccess access(gvn, ctrl, local_mem, decorators, T_OBJECT, obj, addr);\n+      const Type* type = TypeOopPtr::make_from_klass(field->type()->as_klass());\n+      vec_field_ld = bs->load_at(access, type);\n+    }\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":12,"deletions":9,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n","filename":"src\/hotspot\/share\/prims\/jvmtiImpl.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -680,3 +680,0 @@\n-  develop(bool, ProtectionDomainVerification, true,                         \\\n-          \"Verify protection domain before resolution in system dictionary\")\\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/jniHandles.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/reflection.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -490,0 +490,1 @@\n+  case T_VOID:\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"classfile\/moduleEntry.hpp\"\n@@ -39,0 +38,1 @@\n+#include \"compiler\/compilerThread.hpp\"\n@@ -40,0 +40,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -46,1 +47,0 @@\n-#include \"gc\/shared\/workgroup.hpp\"\n@@ -93,0 +93,1 @@\n+#include \"runtime\/nonJavaThread.hpp\"\n@@ -104,2 +105,0 @@\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"runtime\/sweeper.hpp\"\n@@ -130,1 +129,0 @@\n-#include \"utilities\/singleWriterSynchronizer.hpp\"\n@@ -1109,300 +1107,0 @@\n-\/\/ List of all NonJavaThreads and safe iteration over that list.\n-\n-class NonJavaThread::List {\n-public:\n-  NonJavaThread* volatile _head;\n-  SingleWriterSynchronizer _protect;\n-\n-  List() : _head(NULL), _protect() {}\n-};\n-\n-NonJavaThread::List NonJavaThread::_the_list;\n-\n-NonJavaThread::Iterator::Iterator() :\n-  _protect_enter(_the_list._protect.enter()),\n-  _current(Atomic::load_acquire(&_the_list._head))\n-{}\n-\n-NonJavaThread::Iterator::~Iterator() {\n-  _the_list._protect.exit(_protect_enter);\n-}\n-\n-void NonJavaThread::Iterator::step() {\n-  assert(!end(), \"precondition\");\n-  _current = Atomic::load_acquire(&_current->_next);\n-}\n-\n-NonJavaThread::NonJavaThread() : Thread(), _next(NULL) {\n-  assert(BarrierSet::barrier_set() != NULL, \"NonJavaThread created too soon!\");\n-}\n-\n-NonJavaThread::~NonJavaThread() { }\n-\n-void NonJavaThread::add_to_the_list() {\n-  MutexLocker ml(NonJavaThreadsList_lock, Mutex::_no_safepoint_check_flag);\n-  \/\/ Initialize BarrierSet-related data before adding to list.\n-  BarrierSet::barrier_set()->on_thread_attach(this);\n-  Atomic::release_store(&_next, _the_list._head);\n-  Atomic::release_store(&_the_list._head, this);\n-}\n-\n-void NonJavaThread::remove_from_the_list() {\n-  {\n-    MutexLocker ml(NonJavaThreadsList_lock, Mutex::_no_safepoint_check_flag);\n-    \/\/ Cleanup BarrierSet-related data before removing from list.\n-    BarrierSet::barrier_set()->on_thread_detach(this);\n-    NonJavaThread* volatile* p = &_the_list._head;\n-    for (NonJavaThread* t = *p; t != NULL; p = &t->_next, t = *p) {\n-      if (t == this) {\n-        *p = _next;\n-        break;\n-      }\n-    }\n-  }\n-  \/\/ Wait for any in-progress iterators.  Concurrent synchronize is not\n-  \/\/ allowed, so do it while holding a dedicated lock.  Outside and distinct\n-  \/\/ from NJTList_lock in case an iteration attempts to lock it.\n-  MutexLocker ml(NonJavaThreadsListSync_lock, Mutex::_no_safepoint_check_flag);\n-  _the_list._protect.synchronize();\n-  _next = NULL;                 \/\/ Safe to drop the link now.\n-}\n-\n-void NonJavaThread::pre_run() {\n-  add_to_the_list();\n-\n-  \/\/ This is slightly odd in that NamedThread is a subclass, but\n-  \/\/ in fact name() is defined in Thread\n-  assert(this->name() != NULL, \"thread name was not set before it was started\");\n-  this->set_native_thread_name(this->name());\n-}\n-\n-void NonJavaThread::post_run() {\n-  JFR_ONLY(Jfr::on_thread_exit(this);)\n-  remove_from_the_list();\n-  unregister_thread_stack_with_NMT();\n-  \/\/ Ensure thread-local-storage is cleared before termination.\n-  Thread::clear_thread_current();\n-  osthread()->set_state(ZOMBIE);\n-}\n-\n-\/\/ NamedThread --  non-JavaThread subclasses with multiple\n-\/\/ uniquely named instances should derive from this.\n-NamedThread::NamedThread() :\n-  NonJavaThread(),\n-  _name(NULL),\n-  _processed_thread(NULL),\n-  _gc_id(GCId::undefined())\n-{}\n-\n-NamedThread::~NamedThread() {\n-  FREE_C_HEAP_ARRAY(char, _name);\n-}\n-\n-void NamedThread::set_name(const char* format, ...) {\n-  guarantee(_name == NULL, \"Only get to set name once.\");\n-  _name = NEW_C_HEAP_ARRAY(char, max_name_len, mtThread);\n-  va_list ap;\n-  va_start(ap, format);\n-  jio_vsnprintf(_name, max_name_len, format, ap);\n-  va_end(ap);\n-}\n-\n-void NamedThread::print_on(outputStream* st) const {\n-  st->print(\"\\\"%s\\\" \", name());\n-  Thread::print_on(st);\n-  st->cr();\n-}\n-\n-\n-\/\/ ======= WatcherThread ========\n-\n-\/\/ The watcher thread exists to simulate timer interrupts.  It should\n-\/\/ be replaced by an abstraction over whatever native support for\n-\/\/ timer interrupts exists on the platform.\n-\n-WatcherThread* WatcherThread::_watcher_thread   = NULL;\n-bool WatcherThread::_startable = false;\n-volatile bool  WatcherThread::_should_terminate = false;\n-\n-WatcherThread::WatcherThread() : NonJavaThread() {\n-  assert(watcher_thread() == NULL, \"we can only allocate one WatcherThread\");\n-  if (os::create_thread(this, os::watcher_thread)) {\n-    _watcher_thread = this;\n-\n-    \/\/ Set the watcher thread to the highest OS priority which should not be\n-    \/\/ used, unless a Java thread with priority java.lang.Thread.MAX_PRIORITY\n-    \/\/ is created. The only normal thread using this priority is the reference\n-    \/\/ handler thread, which runs for very short intervals only.\n-    \/\/ If the VMThread's priority is not lower than the WatcherThread profiling\n-    \/\/ will be inaccurate.\n-    os::set_priority(this, MaxPriority);\n-    os::start_thread(this);\n-  }\n-}\n-\n-int WatcherThread::sleep() const {\n-  \/\/ The WatcherThread does not participate in the safepoint protocol\n-  \/\/ for the PeriodicTask_lock because it is not a JavaThread.\n-  MonitorLocker ml(PeriodicTask_lock, Mutex::_no_safepoint_check_flag);\n-\n-  if (_should_terminate) {\n-    \/\/ check for termination before we do any housekeeping or wait\n-    return 0;  \/\/ we did not sleep.\n-  }\n-\n-  \/\/ remaining will be zero if there are no tasks,\n-  \/\/ causing the WatcherThread to sleep until a task is\n-  \/\/ enrolled\n-  int remaining = PeriodicTask::time_to_wait();\n-  int time_slept = 0;\n-\n-  \/\/ we expect this to timeout - we only ever get unparked when\n-  \/\/ we should terminate or when a new task has been enrolled\n-  OSThreadWaitState osts(this->osthread(), false \/* not Object.wait() *\/);\n-\n-  jlong time_before_loop = os::javaTimeNanos();\n-\n-  while (true) {\n-    bool timedout = ml.wait(remaining);\n-    jlong now = os::javaTimeNanos();\n-\n-    if (remaining == 0) {\n-      \/\/ if we didn't have any tasks we could have waited for a long time\n-      \/\/ consider the time_slept zero and reset time_before_loop\n-      time_slept = 0;\n-      time_before_loop = now;\n-    } else {\n-      \/\/ need to recalculate since we might have new tasks in _tasks\n-      time_slept = (int) ((now - time_before_loop) \/ 1000000);\n-    }\n-\n-    \/\/ Change to task list or spurious wakeup of some kind\n-    if (timedout || _should_terminate) {\n-      break;\n-    }\n-\n-    remaining = PeriodicTask::time_to_wait();\n-    if (remaining == 0) {\n-      \/\/ Last task was just disenrolled so loop around and wait until\n-      \/\/ another task gets enrolled\n-      continue;\n-    }\n-\n-    remaining -= time_slept;\n-    if (remaining <= 0) {\n-      break;\n-    }\n-  }\n-\n-  return time_slept;\n-}\n-\n-void WatcherThread::run() {\n-  assert(this == watcher_thread(), \"just checking\");\n-\n-  this->set_active_handles(JNIHandleBlock::allocate_block());\n-  while (true) {\n-    assert(watcher_thread() == Thread::current(), \"thread consistency check\");\n-    assert(watcher_thread() == this, \"thread consistency check\");\n-\n-    \/\/ Calculate how long it'll be until the next PeriodicTask work\n-    \/\/ should be done, and sleep that amount of time.\n-    int time_waited = sleep();\n-\n-    if (VMError::is_error_reported()) {\n-      \/\/ A fatal error has happened, the error handler(VMError::report_and_die)\n-      \/\/ should abort JVM after creating an error log file. However in some\n-      \/\/ rare cases, the error handler itself might deadlock. Here periodically\n-      \/\/ check for error reporting timeouts, and if it happens, just proceed to\n-      \/\/ abort the VM.\n-\n-      \/\/ This code is in WatcherThread because WatcherThread wakes up\n-      \/\/ periodically so the fatal error handler doesn't need to do anything;\n-      \/\/ also because the WatcherThread is less likely to crash than other\n-      \/\/ threads.\n-\n-      for (;;) {\n-        \/\/ Note: we use naked sleep in this loop because we want to avoid using\n-        \/\/ any kind of VM infrastructure which may be broken at this point.\n-        if (VMError::check_timeout()) {\n-          \/\/ We hit error reporting timeout. Error reporting was interrupted and\n-          \/\/ will be wrapping things up now (closing files etc). Give it some more\n-          \/\/ time, then quit the VM.\n-          os::naked_short_sleep(200);\n-          \/\/ Print a message to stderr.\n-          fdStream err(defaultStream::output_fd());\n-          err.print_raw_cr(\"# [ timer expired, abort... ]\");\n-          \/\/ skip atexit\/vm_exit\/vm_abort hooks\n-          os::die();\n-        }\n-\n-        \/\/ Wait a second, then recheck for timeout.\n-        os::naked_short_sleep(999);\n-      }\n-    }\n-\n-    if (_should_terminate) {\n-      \/\/ check for termination before posting the next tick\n-      break;\n-    }\n-\n-    PeriodicTask::real_time_tick(time_waited);\n-  }\n-\n-  \/\/ Signal that it is terminated\n-  {\n-    MutexLocker mu(Terminator_lock, Mutex::_no_safepoint_check_flag);\n-    _watcher_thread = NULL;\n-    Terminator_lock->notify_all();\n-  }\n-}\n-\n-void WatcherThread::start() {\n-  assert(PeriodicTask_lock->owned_by_self(), \"PeriodicTask_lock required\");\n-\n-  if (watcher_thread() == NULL && _startable) {\n-    _should_terminate = false;\n-    \/\/ Create the single instance of WatcherThread\n-    new WatcherThread();\n-  }\n-}\n-\n-void WatcherThread::make_startable() {\n-  assert(PeriodicTask_lock->owned_by_self(), \"PeriodicTask_lock required\");\n-  _startable = true;\n-}\n-\n-void WatcherThread::stop() {\n-  {\n-    \/\/ Follow normal safepoint aware lock enter protocol since the\n-    \/\/ WatcherThread is stopped by another JavaThread.\n-    MutexLocker ml(PeriodicTask_lock);\n-    _should_terminate = true;\n-\n-    WatcherThread* watcher = watcher_thread();\n-    if (watcher != NULL) {\n-      \/\/ unpark the WatcherThread so it can see that it should terminate\n-      watcher->unpark();\n-    }\n-  }\n-\n-  MonitorLocker mu(Terminator_lock);\n-\n-  while (watcher_thread() != NULL) {\n-    \/\/ This wait should make safepoint checks, wait without a timeout,\n-    \/\/ and wait as a suspend-equivalent condition.\n-    mu.wait(0, Mutex::_as_suspend_equivalent_flag);\n-  }\n-}\n-\n-void WatcherThread::unpark() {\n-  assert(PeriodicTask_lock->owned_by_self(), \"PeriodicTask_lock required\");\n-  PeriodicTask_lock->notify();\n-}\n-\n-void WatcherThread::print_on(outputStream* st) const {\n-  st->print(\"\\\"%s\\\" \", name());\n-  Thread::print_on(st);\n-  st->cr();\n-}\n-\n@@ -1677,5 +1375,0 @@\n-\n-\/\/ Remove this ifdef when C1 is ported to the compiler interface.\n-static void compiler_thread_entry(JavaThread* thread, TRAPS);\n-static void sweeper_thread_entry(JavaThread* thread, TRAPS);\n-\n@@ -1688,2 +1381,2 @@\n-  thr_type = entry_point == &compiler_thread_entry ? os::compiler_thread :\n-                                                     os::java_thread;\n+  thr_type = entry_point == &CompilerThread::thread_entry ? os::compiler_thread :\n+                                                            os::java_thread;\n@@ -3142,64 +2835,0 @@\n-static void compiler_thread_entry(JavaThread* thread, TRAPS) {\n-  assert(thread->is_Compiler_thread(), \"must be compiler thread\");\n-  CompileBroker::compiler_thread_loop();\n-}\n-\n-static void sweeper_thread_entry(JavaThread* thread, TRAPS) {\n-  NMethodSweeper::sweeper_loop();\n-}\n-\n-\/\/ Create a CompilerThread\n-CompilerThread::CompilerThread(CompileQueue* queue,\n-                               CompilerCounters* counters)\n-                               : JavaThread(&compiler_thread_entry) {\n-  _env   = NULL;\n-  _log   = NULL;\n-  _task  = NULL;\n-  _queue = queue;\n-  _counters = counters;\n-  _buffer_blob = NULL;\n-  _compiler = NULL;\n-\n-  \/\/ Compiler uses resource area for compilation, let's bias it to mtCompiler\n-  resource_area()->bias_to(mtCompiler);\n-\n-#ifndef PRODUCT\n-  _ideal_graph_printer = NULL;\n-#endif\n-}\n-\n-CompilerThread::~CompilerThread() {\n-  \/\/ Delete objects which were allocated on heap.\n-  delete _counters;\n-}\n-\n-bool CompilerThread::can_call_java() const {\n-  return _compiler != NULL && _compiler->is_jvmci();\n-}\n-\n-\/\/ Create sweeper thread\n-CodeCacheSweeperThread::CodeCacheSweeperThread()\n-: JavaThread(&sweeper_thread_entry) {\n-  _scanned_compiled_method = NULL;\n-}\n-\n-void CodeCacheSweeperThread::oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf) {\n-  JavaThread::oops_do_no_frames(f, cf);\n-  if (_scanned_compiled_method != NULL && cf != NULL) {\n-    \/\/ Safepoints can occur when the sweeper is scanning an nmethod so\n-    \/\/ process it here to make sure it isn't unloaded in the middle of\n-    \/\/ a scan.\n-    cf->do_code_blob(_scanned_compiled_method);\n-  }\n-}\n-\n-void CodeCacheSweeperThread::nmethods_do(CodeBlobClosure* cf) {\n-  JavaThread::nmethods_do(cf);\n-  if (_scanned_compiled_method != NULL && cf != NULL) {\n-    \/\/ Safepoints can occur when the sweeper is scanning an nmethod so\n-    \/\/ process it here to make sure it isn't unloaded in the middle of\n-    \/\/ a scan.\n-    cf->do_code_blob(_scanned_compiled_method);\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":5,"deletions":376,"binary":false,"changes":381,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-#include \"runtime\/jniHandles.hpp\"\n@@ -63,0 +62,1 @@\n+class JNIHandleBlock;\n@@ -72,9 +72,0 @@\n-class BufferBlob;\n-class AbstractCompiler;\n-class ciEnv;\n-class CompileThread;\n-class CompileLog;\n-class CompileTask;\n-class CompileQueue;\n-class CompilerCounters;\n-\n@@ -90,4 +81,0 @@\n-class IdealGraphPrinter;\n-\n-class JVMCIEnv;\n-class JVMCIPrimitiveArray;\n@@ -868,135 +855,0 @@\n-class NonJavaThread: public Thread {\n-  friend class VMStructs;\n-\n-  NonJavaThread* volatile _next;\n-\n-  class List;\n-  static List _the_list;\n-\n-  void add_to_the_list();\n-  void remove_from_the_list();\n-\n- protected:\n-  virtual void pre_run();\n-  virtual void post_run();\n-\n- public:\n-  NonJavaThread();\n-  ~NonJavaThread();\n-\n-  class Iterator;\n-};\n-\n-\/\/ Provides iteration over the list of NonJavaThreads.\n-\/\/ List addition occurs in pre_run(), and removal occurs in post_run(),\n-\/\/ so that only live fully-initialized threads can be found in the list.\n-\/\/ Threads created after an iterator is constructed will not be visited\n-\/\/ by the iterator. The scope of an iterator is a critical section; there\n-\/\/ must be no safepoint checks in that scope.\n-class NonJavaThread::Iterator : public StackObj {\n-  uint _protect_enter;\n-  NonJavaThread* _current;\n-\n-  NONCOPYABLE(Iterator);\n-\n-public:\n-  Iterator();\n-  ~Iterator();\n-\n-  bool end() const { return _current == NULL; }\n-  NonJavaThread* current() const { return _current; }\n-  void step();\n-};\n-\n-\/\/ Name support for threads.  non-JavaThread subclasses with multiple\n-\/\/ uniquely named instances should derive from this.\n-class NamedThread: public NonJavaThread {\n-  friend class VMStructs;\n-  enum {\n-    max_name_len = 64\n-  };\n- private:\n-  char* _name;\n-  \/\/ log Thread being processed by oops_do\n-  Thread* _processed_thread;\n-  uint _gc_id; \/\/ The current GC id when a thread takes part in GC\n-\n- public:\n-  NamedThread();\n-  ~NamedThread();\n-  \/\/ May only be called once per thread.\n-  void set_name(const char* format, ...)  ATTRIBUTE_PRINTF(2, 3);\n-  virtual bool is_Named_thread() const { return true; }\n-  virtual char* name() const { return _name == NULL ? (char*)\"Unknown Thread\" : _name; }\n-  Thread *processed_thread() { return _processed_thread; }\n-  void set_processed_thread(Thread *thread) { _processed_thread = thread; }\n-  virtual void print_on(outputStream* st) const;\n-\n-  void set_gc_id(uint gc_id) { _gc_id = gc_id; }\n-  uint gc_id() { return _gc_id; }\n-};\n-\n-\/\/ Worker threads are named and have an id of an assigned work.\n-class WorkerThread: public NamedThread {\n- private:\n-  uint _id;\n- public:\n-  WorkerThread() : _id(0)               { }\n-  virtual bool is_Worker_thread() const { return true; }\n-\n-  virtual WorkerThread* as_Worker_thread() const {\n-    assert(is_Worker_thread(), \"Dubious cast to WorkerThread*?\");\n-    return (WorkerThread*) this;\n-  }\n-\n-  void set_id(uint work_id)             { _id = work_id; }\n-  uint id() const                       { return _id; }\n-};\n-\n-\/\/ A single WatcherThread is used for simulating timer interrupts.\n-class WatcherThread: public NonJavaThread {\n-  friend class VMStructs;\n- protected:\n-  virtual void run();\n-\n- private:\n-  static WatcherThread* _watcher_thread;\n-\n-  static bool _startable;\n-  \/\/ volatile due to at least one lock-free read\n-  volatile static bool _should_terminate;\n- public:\n-  enum SomeConstants {\n-    delay_interval = 10                          \/\/ interrupt delay in milliseconds\n-  };\n-\n-  \/\/ Constructor\n-  WatcherThread();\n-\n-  \/\/ No destruction allowed\n-  ~WatcherThread() {\n-    guarantee(false, \"WatcherThread deletion must fix the race with VM termination\");\n-  }\n-\n-  \/\/ Tester\n-  bool is_Watcher_thread() const                 { return true; }\n-\n-  \/\/ Printing\n-  char* name() const { return (char*)\"VM Periodic Task Thread\"; }\n-  void print_on(outputStream* st) const;\n-  void unpark();\n-\n-  \/\/ Returns the single instance of WatcherThread\n-  static WatcherThread* watcher_thread()         { return _watcher_thread; }\n-\n-  \/\/ Create and start the single instance of WatcherThread, or stop it on shutdown\n-  static void start();\n-  static void stop();\n-  \/\/ Only allow start once the VM is sufficiently initialized\n-  \/\/ Otherwise the first task to enroll will trigger the start\n-  static void make_startable();\n- private:\n-  int sleep() const;\n-};\n-\n-\n@@ -1907,94 +1759,0 @@\n-inline CompilerThread* JavaThread::as_CompilerThread() {\n-  assert(is_Compiler_thread(), \"just checking\");\n-  return (CompilerThread*)this;\n-}\n-\n-\/\/ Dedicated thread to sweep the code cache\n-class CodeCacheSweeperThread : public JavaThread {\n-  CompiledMethod*       _scanned_compiled_method; \/\/ nmethod being scanned by the sweeper\n- public:\n-  CodeCacheSweeperThread();\n-  \/\/ Track the nmethod currently being scanned by the sweeper\n-  void set_scanned_compiled_method(CompiledMethod* cm) {\n-    assert(_scanned_compiled_method == NULL || cm == NULL, \"should reset to NULL before writing a new value\");\n-    _scanned_compiled_method = cm;\n-  }\n-\n-  \/\/ Hide sweeper thread from external view.\n-  bool is_hidden_from_external_view() const { return true; }\n-\n-  bool is_Code_cache_sweeper_thread() const { return true; }\n-\n-  \/\/ Prevent GC from unloading _scanned_compiled_method\n-  void oops_do_no_frames(OopClosure* f, CodeBlobClosure* cf);\n-  void nmethods_do(CodeBlobClosure* cf);\n-};\n-\n-\/\/ A thread used for Compilation.\n-class CompilerThread : public JavaThread {\n-  friend class VMStructs;\n- private:\n-  CompilerCounters* _counters;\n-\n-  ciEnv*                _env;\n-  CompileLog*           _log;\n-  CompileTask* volatile _task;  \/\/ print_threads_compiling can read this concurrently.\n-  CompileQueue*         _queue;\n-  BufferBlob*           _buffer_blob;\n-\n-  AbstractCompiler*     _compiler;\n-  TimeStamp             _idle_time;\n-\n- public:\n-\n-  static CompilerThread* current();\n-\n-  CompilerThread(CompileQueue* queue, CompilerCounters* counters);\n-  ~CompilerThread();\n-\n-  bool is_Compiler_thread() const                { return true; }\n-\n-  virtual bool can_call_java() const;\n-\n-  \/\/ Hide native compiler threads from external view.\n-  bool is_hidden_from_external_view() const      { return !can_call_java(); }\n-\n-  void set_compiler(AbstractCompiler* c)         { _compiler = c; }\n-  AbstractCompiler* compiler() const             { return _compiler; }\n-\n-  CompileQueue* queue()        const             { return _queue; }\n-  CompilerCounters* counters() const             { return _counters; }\n-\n-  \/\/ Get\/set the thread's compilation environment.\n-  ciEnv*        env()                            { return _env; }\n-  void          set_env(ciEnv* env)              { _env = env; }\n-\n-  BufferBlob*   get_buffer_blob() const          { return _buffer_blob; }\n-  void          set_buffer_blob(BufferBlob* b)   { _buffer_blob = b; }\n-\n-  \/\/ Get\/set the thread's logging information\n-  CompileLog*   log()                            { return _log; }\n-  void          init_log(CompileLog* log) {\n-    \/\/ Set once, for good.\n-    assert(_log == NULL, \"set only once\");\n-    _log = log;\n-  }\n-\n-  void start_idle_timer()                        { _idle_time.update(); }\n-  jlong idle_time_millis() {\n-    return TimeHelper::counter_to_millis(_idle_time.ticks_since_update());\n-  }\n-\n-#ifndef PRODUCT\n- private:\n-  IdealGraphPrinter *_ideal_graph_printer;\n- public:\n-  IdealGraphPrinter *ideal_graph_printer()           { return _ideal_graph_printer; }\n-  void set_ideal_graph_printer(IdealGraphPrinter *n) { _ideal_graph_printer = n; }\n-#endif\n-\n-  \/\/ Get\/set the thread's current task\n-  CompileTask* task()                      { return _task; }\n-  void         set_task(CompileTask* task) { _task = task; }\n-};\n-\n@@ -2011,4 +1769,0 @@\n-inline CompilerThread* CompilerThread::current() {\n-  return JavaThread::current()->as_CompilerThread();\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":1,"deletions":247,"binary":false,"changes":248,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -92,0 +92,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n@@ -263,1 +264,1 @@\n-  volatile_nonstatic_field(Klass,              _subklass,                                     Klass*)                                 \\\n+  volatile_nonstatic_field(Klass,              _subklass,                                     Klass*)                                \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"runtime\/jniHandles.hpp\"\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3224,1 +3224,1 @@\n-     * Add a package name prefix if the name is not absolute Remove leading \"\/\"\n+     * Add a package name prefix if the name is not absolute. Remove leading \"\/\"\n@@ -3229,2 +3229,1 @@\n-            Class<?> c = isArray() ? elementType() : this;\n-            String baseName = c.getPackageName();\n+            String baseName = getPackageName();\n@@ -3232,1 +3231,6 @@\n-                name = baseName.replace('.', '\/') + \"\/\" + name;\n+                int len = baseName.length() + 1 + name.length();\n+                StringBuilder sb = new StringBuilder(len);\n+                name = sb.append(baseName.replace('.', '\/'))\n+                    .append('\/')\n+                    .append(name)\n+                    .toString();\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-import jdk.internal.misc.CDS;\n@@ -42,3 +41,0 @@\n-import static java.lang.invoke.LambdaForm.basicTypeSignature;\n-import static java.lang.invoke.LambdaForm.shortenSignature;\n-import static java.lang.invoke.MethodHandleStatics.TRACE_RESOLVE;\n@@ -54,23 +50,0 @@\n-    private static final String LF_RESOLVE = \"[LF_RESOLVE]\";\n-    private static final String SPECIES_RESOLVE = \"[SPECIES_RESOLVE]\";\n-\n-    static void traceLambdaForm(String name, MethodType type, Class<?> holder, MemberName resolvedMember) {\n-        if (TRACE_RESOLVE) {\n-            System.out.println(LF_RESOLVE + \" \" + holder.getName() + \" \" + name + \" \" +\n-                    shortenSignature(basicTypeSignature(type)) +\n-                    (resolvedMember != null ? \" (success)\" : \" (fail)\"));\n-        }\n-        if (CDS.isDumpingClassList()) {\n-            CDS.traceLambdaFormInvoker(LF_RESOLVE, holder.getName(), name, shortenSignature(basicTypeSignature(type)));\n-        }\n-    }\n-\n-    static void traceSpeciesType(String cn, Class<?> salvage) {\n-        if (TRACE_RESOLVE) {\n-            System.out.println(SPECIES_RESOLVE + \" \" + cn + (salvage != null ? \" (salvaged)\" : \" (generated)\"));\n-        }\n-        if (CDS.isDumpingClassList()) {\n-            CDS.traceSpeciesType(SPECIES_RESOLVE, cn);\n-        }\n-    }\n-\n@@ -326,1 +299,1 @@\n-                        case SPECIES_RESOLVE:\n+                        case \"[SPECIES_RESOLVE]\":\n@@ -336,1 +309,1 @@\n-                        case LF_RESOLVE:\n+                        case \"[LF_RESOLVE]\":\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/GenerateJLIClassesHelper.java","additions":3,"deletions":30,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -49,1 +49,0 @@\n-import static java.lang.invoke.GenerateJLIClassesHelper.traceLambdaForm;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/InvokerBytecodeGenerator.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,3 +43,2 @@\n-            test(true,  false);\n-            test(false, true);\n-            test(true,  true);\n+            test(false);\n+            test(true);\n@@ -54,2 +53,2 @@\n-    \/\/ dump_reloc - force relocation of archive during dump time?\n-    static void test(boolean dump_reloc, boolean run_reloc) throws Exception {\n+    \/\/ Note: relocation always happens during dumping.\n+    static void test(boolean run_reloc) throws Exception {\n@@ -59,2 +58,1 @@\n-        System.out.println(\"case = \" + caseCount + \", dump = \" + dump_reloc\n-                           + \", run = \" + run_reloc);\n+        System.out.println(\"case = \" + caseCount + \", run_reloc = \" + run_reloc);\n@@ -63,1 +61,0 @@\n-\n@@ -67,1 +64,0 @@\n-        String dumpRelocArg = dump_reloc ? forceRelocation : \"-showversion\";\n@@ -78,4 +74,1 @@\n-        if (dump_reloc) {\n-            out.shouldContain(\"ArchiveRelocationMode == 1: always allocate class space at an alternative address\");\n-            out.shouldContain(\"Relocating archive from\");\n-        }\n+        out.shouldContain(\"Relocating archive from\");\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/ArchiveRelocationTest.java","additions":7,"deletions":14,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,2 +46,1 @@\n-            testOuter(false);\n-            testOuter(true);\n+            testOuter();\n@@ -54,4 +53,4 @@\n-    static void testOuter(boolean dump_base_reloc) throws Exception {\n-        testInner(dump_base_reloc, true,  false);\n-        testInner(dump_base_reloc, false, true);\n-        testInner(dump_base_reloc, true,  true);\n+    static void testOuter() throws Exception {\n+        testInner(true,  false);\n+        testInner(false, true);\n+        testInner(true,  true);\n@@ -60,1 +59,1 @@\n-    static boolean dump_base_reloc, dump_top_reloc, run_reloc;\n+    static boolean dump_top_reloc, run_reloc;\n@@ -62,1 +61,0 @@\n-    \/\/ dump_base_reloc - force relocation of archive when dumping base archive\n@@ -65,2 +63,1 @@\n-    static void testInner(boolean dump_base_reloc, boolean dump_top_reloc, boolean run_reloc) throws Exception {\n-        DynamicArchiveRelocationTest.dump_base_reloc = dump_base_reloc;\n+    static void testInner(boolean dump_top_reloc, boolean run_reloc) throws Exception {\n@@ -77,2 +74,2 @@\n-        System.out.println(\"case = \" + caseCount + \", base = \" + dump_base_reloc\n-                           + \", top = \" + dump_top_reloc\n+        System.out.println(\"case = \" + caseCount\n+                           + \", top_reloc = \" + dump_top_reloc\n@@ -85,1 +82,0 @@\n-        String dumpBaseRelocArg = dump_base_reloc ? forceRelocation : \"-showversion\";\n@@ -94,0 +90,1 @@\n+        String runtimeRelocMsg = \"runtime archive relocation start\";\n@@ -96,0 +93,3 @@\n+        String archiveRelocPattern = \".*ArchiveRelocationMode == 1.*\";\n+        String unmapRgn1Pattern = \".*Unmapping region #1 at base 0x.*\";\n+        String unmapRgn0Pattern = \".*Unmapping region #0 at base 0x.*(MiscCode)\";\n@@ -100,5 +100,2 @@\n-        OutputAnalyzer out = TestCommon.dumpBaseArchive(baseArchiveName, unlockArg, dumpBaseRelocArg, logArg);\n-        if (dump_base_reloc) {\n-            out.shouldContain(\"ArchiveRelocationMode == 1: always allocate class space at an alternative address\");\n-            out.shouldContain(\"Relocating archive from\");\n-        }\n+        OutputAnalyzer out = TestCommon.dumpBaseArchive(baseArchiveName, unlockArg, logArg);\n+        out.shouldContain(\"Relocating archive from\");\n@@ -126,6 +123,15 @@\n-                        output.shouldContain(runtimeMsg)\n-                              \/\/ Check that there are two of the following lines in\n-                              \/\/ the output. One for static archive and one for\n-                              \/\/ dynamic archive:\n-                              \/\/ Unmapping region #3 at base 0x<hex digits> (Bitmap)\n-                              .shouldMatchByLine(unmapPrefix, \"Hello World\", unmapPattern);\n+                        output.shouldContain(runtimeMsg);\n+                        try {\n+                            output.shouldContain(runtimeRelocMsg)\n+                                  \/\/ Check that there are two of the following lines in\n+                                  \/\/ the output. One for static archive and one for\n+                                  \/\/ dynamic archive:\n+                                  \/\/ Unmapping region #3 at base 0x<hex digits> (Bitmap)\n+                                  .shouldMatchByLine(unmapPrefix, \"Hello World\", unmapPattern);\n+                        } catch(java.lang.RuntimeException ex) {\n+                            \/\/ On Windows, sometimes the OS picks the same archive\n+                            \/\/ base address even with ArchiveRelcationMode=1. In\n+                            \/\/ this case, runtime relocation won't happen. Checking\n+                            \/\/ for \"Unmapping region #0\" messages instead.\n+                            output.shouldMatchByLine(archiveRelocPattern, unmapRgn1Pattern, unmapRgn0Pattern);\n+                        }\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/dynamicArchive\/DynamicArchiveRelocationTest.java","additions":31,"deletions":25,"binary":false,"changes":56,"status":"modified"}]}