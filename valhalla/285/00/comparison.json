{"files":[{"patch":"@@ -479,2 +479,1 @@\n-    \/\/ Allocate a buffer for the returned InlineTypeNode because the caller expects an oop return.\n-    \/\/ Do this before the method handle call in case the buffer allocation triggers deoptimization.\n+    \/\/ Check if we are late inlining a method handle call that returns an inline type as fields.\n@@ -482,1 +481,5 @@\n-    if (is_mh_late_inline() && _inline_cg->method()->return_type()->is_inlinetype()) {\n+    ciType* mh_rt = _inline_cg->method()->return_type();\n+    if (is_mh_late_inline() && mh_rt->is_inlinetype() && mh_rt->as_inline_klass()->can_be_returned_as_fields()) {\n+      \/\/ Allocate a buffer for the inline type returned as fields because the caller expects an oop return.\n+      \/\/ Do this before the method handle call in case the buffer allocation triggers deoptimization and\n+      \/\/ we need to \"re-execute\" the call in the interpreter (to make sure the call is only executed once).\n@@ -488,1 +491,1 @@\n-        Node* klass_node = arg_kit.makecon(TypeKlassPtr::make(_inline_cg->method()->return_type()->as_inline_klass()));\n+        Node* klass_node = arg_kit.makecon(TypeKlassPtr::make(mh_rt->as_inline_klass()));\n@@ -522,15 +525,22 @@\n-    bool returned_as_fields = call->tf()->returns_inline_type_as_fields();\n-    if (result->is_InlineType()) {\n-      \/\/ Only possible if is_mh_late_inline() when the callee does not \"know\" that the caller expects an oop\n-      assert(is_mh_late_inline() && !returned_as_fields, \"sanity\");\n-      assert(buffer_oop != NULL, \"should have allocated a buffer\");\n-      InlineTypeNode* vt = result->as_InlineType();\n-      vt->store(&kit, buffer_oop, buffer_oop, vt->type()->inline_klass(), 0);\n-      \/\/ Do not let stores that initialize this buffer be reordered with a subsequent\n-      \/\/ store that would make this buffer accessible by other threads.\n-      AllocateNode* alloc = AllocateNode::Ideal_allocation(buffer_oop, &kit.gvn());\n-      assert(alloc != NULL, \"must have an allocation node\");\n-      kit.insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out_or_null(AllocateNode::RawAddress));\n-      result = buffer_oop;\n-    } else if (result->is_InlineTypePtr() && returned_as_fields) {\n-      result->as_InlineTypePtr()->replace_call_results(&kit, call, C);\n+    InlineTypeNode* vt = result->isa_InlineType();\n+    if (vt != NULL) {\n+      if (call->tf()->returns_inline_type_as_fields()) {\n+        vt->replace_call_results(&kit, call, C);\n+      } else {\n+        \/\/ Only possible with is_mh_late_inline() when the callee does not \"know\" that the caller expects an oop\n+        assert(is_mh_late_inline(), \"sanity\");\n+        assert(!result->isa_InlineType()->is_allocated(&kit.gvn()), \"already allocated\");\n+        assert(buffer_oop != NULL, \"should have allocated a buffer\");\n+        vt->store(&kit, buffer_oop, buffer_oop, vt->type()->inline_klass());\n+        \/\/ Do not let stores that initialize this buffer be reordered with a subsequent\n+        \/\/ store that would make this buffer accessible by other threads.\n+        AllocateNode* alloc = AllocateNode::Ideal_allocation(buffer_oop, &kit.gvn());\n+        assert(alloc != NULL, \"must have an allocation node\");\n+        kit.insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out_or_null(AllocateNode::RawAddress));\n+        \/\/ Convert to InlineTypePtrNode to keep track of field values\n+        kit.gvn().hash_delete(vt);\n+        vt->set_oop(buffer_oop);\n+        DEBUG_ONLY(buffer_oop = NULL);\n+        vt = kit.gvn().transform(vt)->as_InlineType();\n+        result = vt->as_ptr(&kit.gvn());\n+      }\n@@ -538,0 +548,1 @@\n+    assert(buffer_oop == NULL, \"unused buffer allocation\");\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":30,"deletions":19,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -1803,1 +1803,2 @@\n-    \/\/ Make sure the call is re-executed, if buffering of inline type arguments triggers deoptimization\n+    \/\/ Make sure the call is \"re-executed\", if buffering of inline type arguments triggers deoptimization.\n+    \/\/ At this point, the call hasn't been executed yet, so we will only ever execute the call once.\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -396,1 +396,1 @@\n-    store(kit, alloc_oop, alloc_oop, vk, 0);\n+    store(kit, alloc_oop, alloc_oop, vk);\n@@ -448,1 +448,1 @@\n-\/\/ projections, one per field. Replacing the result of the call by a\n+\/\/ projections, one per field. Replacing the result of the call by an\n@@ -625,1 +625,1 @@\n-    store(kit, alloc_oop, alloc_oop, vk, 0);\n+    store(kit, alloc_oop, alloc_oop, vk);\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -826,1 +826,2 @@\n-    if ((_caller->has_method() || tf()->returns_inline_type_as_fields()) &&\n+    \/\/ Scalarize inline type when returning as fields or inlining non-incrementally\n+    if ((tf()->returns_inline_type_as_fields() || (_caller->has_method() && !Compile::current()->inlining_incrementally())) &&\n@@ -828,1 +829,0 @@\n-      \/\/ Scalarize inline type return when inlining or with multiple return values\n@@ -2342,1 +2342,2 @@\n-    if (return_type->isa_inlinetype() && !Compile::current()->inlining_incrementally()) {\n+    \/\/ The return_type is set in Parse::build_exits().\n+    if (return_type->isa_inlinetype()) {\n@@ -2347,2 +2348,2 @@\n-      if (!_caller->has_method()) {\n-        \/\/ Inline type is returned as fields from root method, make sure all non-flattened\n+      if (!_caller->has_method() || Compile::current()->inlining_incrementally()) {\n+        \/\/ Returning from root or an incrementally inlined method. Make sure all non-flattened\n@@ -2363,3 +2364,0 @@\n-      if (Compile::current()->inlining_incrementally()) {\n-        value = value->as_InlineTypeBase()->allocate_fields(this);\n-      }\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":6,"deletions":8,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1038,0 +1038,52 @@\n+\n+    \/\/ Test conditional inline type return with incremental inlining\n+    public MyValue3 test49_inlined1(boolean b) {\n+        if (b) {\n+            return MyValue3.create();\n+        } else {\n+            return MyValue3.create();\n+        }\n+    }\n+\n+    public MyValue3 test49_inlined2(boolean b) {\n+        return test49_inlined1(b);\n+    }\n+\n+    @Test\n+    public void test49(boolean b) {\n+        test49_inlined2(b);\n+    }\n+\n+    @DontCompile\n+    public void test49_verifier(boolean warmup) {\n+        test49(true);\n+        test49(false);\n+    }\n+\n+    \/\/ Variant of test49 with result verification (triggered different failure mode)\n+    final MyValue3 test50_vt = MyValue3.create();\n+    final MyValue3 test50_vt2 = test50_vt;\n+\n+    public MyValue3 test50_inlined1(boolean b) {\n+        if (b) {\n+            return test50_vt;\n+        } else {\n+            return test50_vt2;\n+        }\n+    }\n+\n+    public MyValue3 test50_inlined2(boolean b) {\n+        return test50_inlined1(b);\n+    }\n+\n+    @Test\n+    public void test50(boolean b) {\n+        MyValue3 vt = test50_inlined2(b);\n+        test50_vt.verify(vt);\n+    }\n+\n+    @DontCompile\n+    public void test50_verifier(boolean warmup) {\n+        test50(true);\n+        test50(false);\n+    }\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestCallingConvention.java","additions":52,"deletions":0,"binary":false,"changes":52,"status":"modified"}]}