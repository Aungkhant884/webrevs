{"files":[{"patch":"@@ -7,0 +7,3 @@\n+      - lworld\n+      - type-restrictions\n+      - jep390\n@@ -13,1 +16,2 @@\n-        default: \"Linux additional (hotspot only), Linux x64, Linux x86, Windows aarch64, Windows x64, macOS x64\"\n+        default: \"Linux x64, Windows x64, macOS x64\"\n+#        default: \"Linux additional (hotspot only), Linux x64, Linux x86, Windows aarch64, Windows x64, macOS x64\"\n","filename":".github\/workflows\/submit.yml","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -106,1 +106,1 @@\n-JAVADOC_OPTIONS := -use -keywords -notimestamp \\\n+JAVADOC_OPTIONS := -XDignore.symbol.file=true -use -keywords -notimestamp \\\n@@ -109,0 +109,1 @@\n+    -XDenableValueTypes \\\n","filename":"make\/Docs.gmk","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1445,0 +1445,1 @@\n+        args = concat(args, \"--with-version-pre=\" + version_numbers.get(\"DEFAULT_PROMOTED_VERSION_PRE\"));\n","filename":"make\/conf\/jib-profiles.js","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-DEFAULT_PROMOTED_VERSION_PRE=ea\n+DEFAULT_PROMOTED_VERSION_PRE=lworld3ea\n","filename":"make\/conf\/version-numbers.conf","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1887,4 +1887,0 @@\n-  \/\/ n.b. frame size includes space for return pc and rfp\n-  const int framesize = C->output()->frame_size_in_bytes();\n-  assert(framesize%(2*wordSize) == 0, \"must preserve 2*wordSize alignment\");\n-\n@@ -1910,5 +1906,2 @@\n-  int bangsize = C->output()->bang_size_in_bytes();\n-  if (C->output()->need_stack_bang(bangsize))\n-    __ generate_stack_overflow_check(bangsize);\n-\n-  __ build_frame(framesize);\n+  __ verified_entry(C, 0);\n+  __ bind(*_verified_entry);\n@@ -1935,6 +1928,0 @@\n-uint MachPrologNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n@@ -1997,5 +1984,0 @@\n-uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {\n-  \/\/ Variable size. Determine dynamically.\n-  return MachNode::size(ra_);\n-}\n-\n@@ -2284,1 +2266,12 @@\n-\/\/=============================================================================\n+\/\/\/=============================================================================\n+#ifndef PRODUCT\n+void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const\n+{\n+  st->print_cr(\"# MachVEPNode\");\n+  if (!_verified) {\n+    st->print_cr(\"\\t load_class\");\n+  } else {\n+    st->print_cr(\"\\t unpack_inline_arg\");\n+  }\n+}\n+#endif\n@@ -2286,0 +2279,22 @@\n+void MachVEPNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const\n+{\n+  MacroAssembler _masm(&cbuf);\n+\n+  if (!_verified) {\n+    Label skip;\n+    __ cmp_klass(j_rarg0, rscratch2, rscratch1);\n+    __ br(Assembler::EQ, skip);\n+      __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+    __ bind(skip);\n+\n+  } else {\n+    \/\/ Unpack inline type args passed as oop and then jump to\n+    \/\/ the verified entry point (skipping the unverified entry).\n+    int sp_inc = __ unpack_inline_args(ra_->C, _receiver_only);\n+    \/\/ Emit code for verified entry and save increment for stack repair on return\n+    __ verified_entry(ra_->C, sp_inc);\n+    __ b(*_verified_entry);\n+  }\n+}\n+\n+\/\/=============================================================================\n@@ -2307,0 +2322,1 @@\n+  Label skip;\n@@ -2308,0 +2324,1 @@\n+  \/\/ UseCompressedClassPointers logic are inside cmp_klass\n@@ -2309,1 +2326,1 @@\n-  Label skip;\n+\n@@ -2317,5 +2334,0 @@\n-uint MachUEPNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_);\n-}\n-\n@@ -2760,1 +2772,0 @@\n-\n@@ -3915,0 +3926,6 @@\n+    if (EnableValhalla) {\n+      assert(!UseBiasedLocking, \"Not compatible with biased-locking\");\n+      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+      __ andr(tmp, tmp, ~((int) markWord::inline_type_bit_in_place));\n+    }\n+\n@@ -8704,0 +8721,15 @@\n+instruct castN2X(iRegLNoSp dst, iRegN src) %{\n+  match(Set dst (CastP2X src));\n+\n+  ins_cost(INSN_COST);\n+  format %{ \"mov $dst, $src\\t# ptr -> long\" %}\n+\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ mov(as_Register($dst$$reg), as_Register($src$$reg));\n+    }\n+  %}\n+\n+  ins_pipe(ialu_reg);\n+%}\n+\n@@ -14997,1 +15029,1 @@\n-instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)\n+instruct clearArray_reg_reg_immL0(iRegL_R11 cnt, iRegP_R10 base, immL0 zero, Universe dummy, rFlagsReg cr)\n@@ -14999,1 +15031,1 @@\n-  match(Set dummy (ClearArray cnt base));\n+  match(Set dummy (ClearArray (Binary cnt base) zero));\n@@ -15016,0 +15048,16 @@\n+instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(((ClearArrayNode*)n)->word_copy_only());\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, KILL cr);\n+\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ClearArray $cnt, $base, $val\" %}\n+\n+  ins_encode %{\n+    __ fill_words($base$$Register, $cnt$$Register, $val$$Register);\n+  %}\n+\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n@@ -15019,1 +15067,2 @@\n-            < (uint64_t)(BlockZeroingLowLimit >> LogBytesPerWord));\n+            < (uint64_t)(BlockZeroingLowLimit >> LogBytesPerWord)\n+            && !((ClearArrayNode*)n)->word_copy_only());\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":80,"deletions":31,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -42,0 +43,1 @@\n+#include \"oops\/oop.inline.hpp\"\n@@ -461,1 +463,2 @@\n-  __ remove_frame(initial_frame_size_in_bytes());\n+  int initial_framesize = initial_frame_size_in_bytes();\n+  __ remove_frame(initial_framesize, needs_stack_repair(), initial_framesize - wordSize);\n@@ -512,0 +515,14 @@\n+  ciMethod* method = compilation()->method();\n+\n+  ciType* return_type = method->return_type();\n+  if (InlineTypeReturnedAsFields && return_type->is_inlinetype()) {\n+    ciInlineKlass* vk = return_type->as_inline_klass();\n+    if (vk->can_be_returned_as_fields()) {\n+      address unpack_handler = vk->unpack_handler();\n+      assert(unpack_handler != NULL, \"must be\");\n+      __ far_call(RuntimeAddress(unpack_handler));\n+      \/\/ At this point, rax points to the value object (for interpreter or C1 caller).\n+      \/\/ The fields of the object are copied into registers (for C2 caller).\n+    }\n+  }\n+\n@@ -513,1 +530,2 @@\n-  __ remove_frame(initial_frame_size_in_bytes());\n+  int initial_framesize = initial_frame_size_in_bytes();\n+  __ remove_frame(initial_framesize, needs_stack_repair(), initial_framesize - wordSize);\n@@ -525,0 +543,4 @@\n+int LIR_Assembler::store_inline_type_fields_to_buf(ciInlineKlass* vk) {\n+  return (__ store_inline_type_fields_to_buf(vk, false));\n+}\n+\n@@ -570,0 +592,1 @@\n+    case T_INLINE_TYPE:\n@@ -571,3 +594,1 @@\n-        if (patch_code == lir_patch_none) {\n-          jobject2reg(c->as_jobject(), dest->as_register());\n-        } else {\n+        if (patch_code != lir_patch_none) {\n@@ -575,0 +596,2 @@\n+        } else {\n+          jobject2reg(c->as_jobject(), dest->as_register());\n@@ -616,0 +639,1 @@\n+  case T_INLINE_TYPE:\n@@ -682,0 +706,1 @@\n+  case T_INLINE_TYPE:\n@@ -684,0 +709,2 @@\n+    \/\/ Non-null case is not handled on aarch64 but handled on x86\n+    \/\/ FIXME: do we need to add it here?\n@@ -722,1 +749,1 @@\n-    if (src->type() == T_OBJECT) {\n+    if (src->type() == T_OBJECT || src->type() == T_INLINE_TYPE) {\n@@ -822,0 +849,1 @@\n+    case T_INLINE_TYPE: \/\/ fall through\n@@ -951,1 +979,1 @@\n-  if (addr->base()->type() == T_OBJECT) {\n+  if (addr->base()->type() == T_OBJECT || addr->base()->type() == T_INLINE_TYPE) {\n@@ -975,0 +1003,1 @@\n+    case T_INLINE_TYPE: \/\/ fall through\n@@ -1045,0 +1074,14 @@\n+void LIR_Assembler::move(LIR_Opr src, LIR_Opr dst) {\n+  assert(dst->is_cpu_register(), \"must be\");\n+  assert(dst->type() == src->type(), \"must be\");\n+\n+  if (src->is_cpu_register()) {\n+    reg2reg(src, dst);\n+  } else if (src->is_stack()) {\n+    stack2reg(src, dst, dst->type());\n+  } else if (src->is_constant()) {\n+    const2reg(src, dst, lir_patch_none, NULL);\n+  } else {\n+    ShouldNotReachHere();\n+  }\n+}\n@@ -1236,1 +1279,1 @@\n-  if (UseSlowPath ||\n+  if (UseSlowPath || op->type() == T_INLINE_TYPE ||\n@@ -1342,0 +1385,1 @@\n+  if (op->need_null_check()) {\n@@ -1360,0 +1404,1 @@\n+  }\n@@ -1548,0 +1593,127 @@\n+void LIR_Assembler::emit_opFlattenedArrayCheck(LIR_OpFlattenedArrayCheck* op) {\n+  \/\/ We are loading\/storing from\/to an array that *may* be flattened (the\n+  \/\/ declared type is Object[], abstract[], interface[] or VT.ref[]).\n+  \/\/ If this array is flattened, take the slow path.\n+\n+  Register klass = op->tmp()->as_register();\n+  if (UseArrayMarkWordCheck) {\n+    __ test_flattened_array_oop(op->array()->as_register(), op->tmp()->as_register(), *op->stub()->entry());\n+  } else {\n+    __ load_klass(klass, op->array()->as_register());\n+    __ ldrw(klass, Address(klass, Klass::layout_helper_offset()));\n+    __ tst(klass, Klass::_lh_array_tag_vt_value_bit_inplace);\n+    __ br(Assembler::NE, *op->stub()->entry());\n+  }\n+  if (!op->value()->is_illegal()) {\n+    \/\/ The array is not flattened, but it might be null-free. If we are storing\n+    \/\/ a null into a null-free array, take the slow path (which will throw NPE).\n+    Label skip;\n+    __ cbnz(op->value()->as_register(), skip);\n+    if (UseArrayMarkWordCheck) {\n+      __ test_null_free_array_oop(op->array()->as_register(), op->tmp()->as_register(), *op->stub()->entry());\n+    } else {\n+      __ tst(klass, Klass::_lh_null_free_bit_inplace);\n+      __ br(Assembler::NE, *op->stub()->entry());\n+    }\n+    __ bind(skip);\n+  }\n+}\n+\n+void LIR_Assembler::emit_opNullFreeArrayCheck(LIR_OpNullFreeArrayCheck* op) {\n+  \/\/ We are storing into an array that *may* be null-free (the declared type is\n+  \/\/ Object[], abstract[], interface[] or VT.ref[]).\n+  if (UseArrayMarkWordCheck) {\n+    Label test_mark_word;\n+    Register tmp = op->tmp()->as_register();\n+    __ ldr(tmp, Address(op->array()->as_register(), oopDesc::mark_offset_in_bytes()));\n+    __ tst(tmp, markWord::unlocked_value);\n+    __ br(Assembler::NE, test_mark_word);\n+    __ load_prototype_header(tmp, op->array()->as_register());\n+    __ bind(test_mark_word);\n+    __ tst(tmp, markWord::nullfree_array_bit_in_place);\n+  } else {\n+    Register klass = op->tmp()->as_register();\n+    __ load_klass(klass, op->array()->as_register());\n+    __ ldr(klass, Address(klass, Klass::layout_helper_offset()));\n+    __ tst(klass, Klass::_lh_null_free_bit_inplace);\n+  }\n+}\n+\n+void LIR_Assembler::emit_opSubstitutabilityCheck(LIR_OpSubstitutabilityCheck* op) {\n+  Label L_oops_equal;\n+  Label L_oops_not_equal;\n+  Label L_end;\n+\n+  Register left  = op->left()->as_register();\n+  Register right = op->right()->as_register();\n+\n+  __ cmp(left, right);\n+  __ br(Assembler::EQ, L_oops_equal);\n+\n+  \/\/ (1) Null check -- if one of the operands is null, the other must not be null (because\n+  \/\/     the two references are not equal), so they are not substitutable,\n+  \/\/     FIXME: do null check only if the operand is nullable\n+  {\n+    __ cbz(left, L_oops_not_equal);\n+    __ cbz(right, L_oops_not_equal);\n+  }\n+\n+  ciKlass* left_klass = op->left_klass();\n+  ciKlass* right_klass = op->right_klass();\n+\n+  \/\/ (2) Inline type check -- if either of the operands is not a inline type,\n+  \/\/     they are not substitutable. We do this only if we are not sure that the\n+  \/\/     operands are inline type\n+  if ((left_klass == NULL || right_klass == NULL) ||\/\/ The klass is still unloaded, or came from a Phi node.\n+      !left_klass->is_inlinetype() || !right_klass->is_inlinetype()) {\n+    Register tmp1  = op->tmp1()->as_register();\n+    __ mov(tmp1, markWord::inline_type_pattern);\n+    __ ldr(rscratch1, Address(left, oopDesc::mark_offset_in_bytes()));\n+    __ andr(tmp1, tmp1, rscratch1);\n+    __ ldr(rscratch1, Address(right, oopDesc::mark_offset_in_bytes()));\n+    __ andr(tmp1, tmp1, rscratch1);\n+    __ cmp(tmp1, (u1)markWord::inline_type_pattern);\n+    __ br(Assembler::NE, L_oops_not_equal);\n+  }\n+\n+  \/\/ (3) Same klass check: if the operands are of different klasses, they are not substitutable.\n+  if (left_klass != NULL && left_klass->is_inlinetype() && left_klass == right_klass) {\n+    \/\/ No need to load klass -- the operands are statically known to be the same inline klass.\n+    __ b(*op->stub()->entry());\n+  } else {\n+    Register left_klass_op = op->left_klass_op()->as_register();\n+    Register right_klass_op = op->right_klass_op()->as_register();\n+\n+    if (UseCompressedClassPointers) {\n+      __ ldrw(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));\n+      __ ldrw(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));\n+      __ cmpw(left_klass_op, right_klass_op);\n+    } else {\n+      __ ldr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));\n+      __ ldr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));\n+      __ cmp(left_klass_op, right_klass_op);\n+    }\n+\n+    __ br(Assembler::EQ, *op->stub()->entry()); \/\/ same klass -> do slow check\n+    \/\/ fall through to L_oops_not_equal\n+  }\n+\n+  __ bind(L_oops_not_equal);\n+  move(op->not_equal_result(), op->result_opr());\n+  __ b(L_end);\n+\n+  __ bind(L_oops_equal);\n+  move(op->equal_result(), op->result_opr());\n+  __ b(L_end);\n+\n+  \/\/ We've returned from the stub. R0 contains 0x0 IFF the two\n+  \/\/ operands are not substitutable. (Don't compare against 0x1 in case the\n+  \/\/ C compiler is naughty)\n+  __ bind(*op->stub()->continuation());\n+  __ cbz(r0, L_oops_not_equal); \/\/ (call_stub() == 0x0) -> not_equal\n+  move(op->equal_result(), op->result_opr()); \/\/ (call_stub() != 0x0) -> equal\n+  \/\/ fall-through\n+  __ bind(L_end);\n+}\n+\n+\n@@ -1991,0 +2163,1 @@\n+      case T_INLINE_TYPE:\n@@ -2065,1 +2238,1 @@\n-  add_call_info(code_offset(), op->info());\n+  add_call_info(code_offset(), op->info(), op->maybe_return_as_fields());\n@@ -2075,1 +2248,1 @@\n-  add_call_info(code_offset(), op->info());\n+  add_call_info(code_offset(), op->info(), op->maybe_return_as_fields());\n@@ -2157,0 +2330,1 @@\n+    case T_INLINE_TYPE:\n@@ -2193,0 +2367,1 @@\n+    case T_INLINE_TYPE:\n@@ -2237,0 +2412,22 @@\n+void LIR_Assembler::arraycopy_inlinetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {\n+  if (null_check) {\n+    __ cbz(obj, *slow_path->entry());\n+  }\n+  if (UseArrayMarkWordCheck) {\n+    if (is_dest) {\n+      __ test_null_free_array_oop(obj, tmp, *slow_path->entry());\n+    } else {\n+      __ test_flattened_array_oop(obj, tmp, *slow_path->entry());\n+    }\n+  } else {\n+    __ load_klass(tmp, obj);\n+    __ ldr(tmp, Address(tmp, Klass::layout_helper_offset()));\n+    if (is_dest) {\n+      \/\/ Take the slow path if it's a null_free destination array, in case the source array contains NULLs.\n+      __ tst(tmp, Klass::_lh_null_free_bit_inplace);\n+    } else {\n+      __ tst(tmp, Klass::_lh_array_tag_vt_value_bit_inplace);\n+    }\n+    __ br(Assembler::NE, *slow_path->entry());\n+  }\n+}\n@@ -2258,0 +2455,6 @@\n+  if (flags & LIR_OpArrayCopy::always_slow_path) {\n+    __ b(*stub->entry());\n+    __ bind(*stub->continuation());\n+    return;\n+  }\n+\n@@ -2311,0 +2514,9 @@\n+  \/\/ Handle inline type arrays\n+  if (flags & LIR_OpArrayCopy::src_inlinetype_check) {\n+    arraycopy_inlinetype_check(src, tmp, stub, false, (flags & LIR_OpArrayCopy::src_null_check));\n+  }\n+\n+  if (flags & LIR_OpArrayCopy::dst_inlinetype_check) {\n+    arraycopy_inlinetype_check(dst, tmp, stub, true, (flags & LIR_OpArrayCopy::dst_null_check));\n+  }\n+\n@@ -2870,0 +3082,20 @@\n+void LIR_Assembler::emit_profile_inline_type(LIR_OpProfileInlineType* op) {\n+  Register obj = op->obj()->as_register();\n+  Register tmp = op->tmp()->as_pointer_register();\n+  Address mdo_addr = as_Address(op->mdp()->as_address_ptr());\n+  bool not_null = op->not_null();\n+  int flag = op->flag();\n+\n+  Label not_inline_type;\n+  if (!not_null) {\n+    __ cbz(obj, not_inline_type);\n+  }\n+\n+  __ test_oop_is_not_inline_type(obj, tmp, not_inline_type);\n+\n+  __ ldrb(rscratch1, mdo_addr);\n+  __ orr(rscratch1, rscratch1, flag);\n+  __ strb(rscratch1, mdo_addr);\n+\n+  __ bind(not_inline_type);\n+}\n@@ -3009,0 +3241,4 @@\n+void LIR_Assembler::check_orig_pc() {\n+  __ ldr(rscratch2, frame_map()->address_for_orig_pc_addr());\n+  __ cmp(rscratch2, (u1)NULL_WORD);\n+}\n@@ -3156,0 +3392,1 @@\n+  case T_INLINE_TYPE:\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":247,"deletions":10,"binary":false,"changes":257,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -105,0 +106,6 @@\n+void LIRGenerator::init_temps_for_substitutability_check(LIR_Opr& tmp1, LIR_Opr& tmp2) {\n+  tmp1 = new_register(T_INT);\n+  tmp2 = LIR_OprFact::illegalOpr;\n+}\n+\n+\n@@ -336,1 +343,1 @@\n-  if (UseBiasedLocking) {\n+  if (UseBiasedLocking || x->maybe_inlinetype()) {\n@@ -344,0 +351,6 @@\n+\n+  CodeStub* throw_imse_stub =\n+      x->maybe_inlinetype() ?\n+      new SimpleExceptionStub(Runtime1::throw_illegal_monitor_state_exception_id, LIR_OprFact::illegalOpr, state_for(x)) :\n+      NULL;\n+\n@@ -348,1 +361,1 @@\n-                        x->monitor_no(), info_for_exception, info);\n+                        x->monitor_no(), info_for_exception, info, throw_imse_stub);\n@@ -1147,5 +1160,6 @@\n-                       FrameMap::r2_oop_opr,\n-                       FrameMap::r5_oop_opr,\n-                       FrameMap::r4_oop_opr,\n-                       LIR_OprFact::illegalOpr,\n-                       FrameMap::r3_metadata_opr, info);\n+               \/* allow_inline *\/ false,\n+               FrameMap::r2_oop_opr,\n+               FrameMap::r5_oop_opr,\n+               FrameMap::r4_oop_opr,\n+               LIR_OprFact::illegalOpr,\n+               FrameMap::r3_metadata_opr, info);\n@@ -1156,0 +1170,17 @@\n+void LIRGenerator::do_NewInlineTypeInstance(NewInlineTypeInstance* x) {\n+  \/\/ Mapping to do_NewInstance (same code) but use state_before for reexecution.\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+  x->set_to_object_type();\n+  LIR_Opr reg = result_register_for(x->type());\n+  new_instance(reg, x->klass(), false,\n+               \/* allow_inline *\/ true,\n+               FrameMap::r2_oop_opr,\n+               FrameMap::r5_oop_opr,\n+               FrameMap::r4_oop_opr,\n+               LIR_OprFact::illegalOpr,\n+               FrameMap::r3_metadata_opr, info);\n+  LIR_Opr result = rlock_result(x);\n+  __ move(reg, result);\n+\n+}\n+\n@@ -1201,2 +1232,2 @@\n-  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info);\n-  ciKlass* obj = (ciKlass*) ciObjArrayKlass::make(x->klass());\n+  ciKlass* obj = (ciKlass*) x->exact_type();\n+  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, x->is_null_free());\n@@ -1206,0 +1237,1 @@\n+\n@@ -1207,1 +1239,5 @@\n-  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);\n+  if (x->is_null_free()) {\n+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_INLINE_TYPE, klass_reg, slow_path);\n+  } else {\n+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);\n+  }\n@@ -1283,0 +1319,3 @@\n+  if (x->is_null_free()) {\n+    __ null_check(obj.result(), new CodeEmitInfo(info_for_exception));\n+  }\n@@ -1301,0 +1340,2 @@\n+\n+\n@@ -1304,1 +1345,2 @@\n-               x->profiled_method(), x->profiled_bci());\n+               x->profiled_method(), x->profiled_bci(), x->is_null_free());\n+\n@@ -1382,1 +1424,6 @@\n-  __ cmp(lir_cond(cond), left, right);\n+  if (x->substitutability_check()) {\n+    substitutability_check(x, *xin, *yin);\n+  } else {\n+    __ cmp(lir_cond(cond), left, right);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":59,"deletions":12,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -635,0 +635,1 @@\n+    case new_instance_no_inline_id:\n@@ -643,0 +644,2 @@\n+        } else if (id == new_instance_no_inline_id) {\n+          __ set_info(\"new_instance_no_inline\", dont_gc_arguments);\n@@ -702,1 +705,6 @@\n-        int call_offset = __ call_RT(obj, noreg, CAST_FROM_FN_PTR(address, new_instance), klass);\n+        int call_offset;\n+        if (id == new_instance_no_inline_id) {\n+          call_offset = __ call_RT(obj, noreg, CAST_FROM_FN_PTR(address, new_instance_no_inline), klass);\n+        } else {\n+          call_offset = __ call_RT(obj, noreg, CAST_FROM_FN_PTR(address, new_instance), klass);\n+        }\n@@ -735,0 +743,1 @@\n+    case new_flat_array_id:\n@@ -742,1 +751,1 @@\n-        } else {\n+        } else if (id == new_object_array_id) {\n@@ -744,0 +753,2 @@\n+        } else {\n+          __ set_info(\"new_flat_array\", dont_gc_arguments);\n@@ -753,7 +764,23 @@\n-          int tag = ((id == new_type_array_id)\n-                     ? Klass::_lh_array_tag_type_value\n-                     : Klass::_lh_array_tag_obj_value);\n-          __ mov(rscratch1, tag);\n-          __ cmpw(t0, rscratch1);\n-          __ br(Assembler::EQ, ok);\n-          __ stop(\"assert(is an array klass)\");\n+          switch (id) {\n+          case new_type_array_id:\n+            __ cmpw(t0, Klass::_lh_array_tag_type_value);\n+            __ br(Assembler::EQ, ok);\n+            __ stop(\"assert(is a type array klass)\");\n+            break;\n+          case new_object_array_id:\n+            __ cmpw(t0, Klass::_lh_array_tag_obj_value); \/\/ new \"[Ljava\/lang\/Object;\"\n+            __ br(Assembler::EQ, ok);\n+            __ cmpw(t0, Klass::_lh_array_tag_vt_value);  \/\/ new \"[LVT;\"\n+            __ br(Assembler::EQ, ok);\n+            __ stop(\"assert(is an object or inline type array klass)\");\n+            break;\n+          case new_flat_array_id:\n+            \/\/ new \"[QVT;\"\n+            __ cmpw(t0, Klass::_lh_array_tag_vt_value);  \/\/ the array can be flattened.\n+            __ br(Assembler::EQ, ok);\n+            __ cmpw(t0, Klass::_lh_array_tag_obj_value); \/\/ the array cannot be flattened (due to InlineArrayElementMaxFlatSize, etc)\n+            __ br(Assembler::EQ, ok);\n+            __ stop(\"assert(is an object or inline type array klass)\");\n+            break;\n+          default:  ShouldNotReachHere();\n+          }\n@@ -815,1 +842,1 @@\n-        } else {\n+        } else if (id == new_object_array_id) {\n@@ -817,0 +844,3 @@\n+        } else {\n+          assert(id == new_flat_array_id, \"must be\");\n+          call_offset = __ call_RT(obj, noreg, CAST_FROM_FN_PTR(address, new_flat_array), klass, length);\n@@ -851,0 +881,76 @@\n+    case buffer_inline_args_id:\n+    case buffer_inline_args_no_receiver_id:\n+      {\n+        const char* name = (id == buffer_inline_args_id) ?\n+          \"buffer_inline_args\" : \"buffer_inline_args_no_receiver\";\n+        StubFrame f(sasm, name, dont_gc_arguments);\n+        OopMap* map = save_live_registers(sasm);\n+        Register method = r1;\n+        address entry = (id == buffer_inline_args_id) ?\n+          CAST_FROM_FN_PTR(address, buffer_inline_args) :\n+          CAST_FROM_FN_PTR(address, buffer_inline_args_no_receiver);\n+        int call_offset = __ call_RT(r0, noreg, entry, method);\n+        oop_maps = new OopMapSet();\n+        oop_maps->add_gc_map(call_offset, map);\n+        restore_live_registers_except_r0(sasm);\n+        __ verify_oop(r0);  \/\/ r0: an array of buffered value objects\n+     }\n+     break;\n+\n+    case load_flattened_array_id:\n+      {\n+        StubFrame f(sasm, \"load_flattened_array\", dont_gc_arguments);\n+        OopMap* map = save_live_registers(sasm);\n+\n+        \/\/ Called with store_parameter and not C abi\n+\n+        f.load_argument(1, r0); \/\/ r0,: array\n+        f.load_argument(0, r1); \/\/ r1,: index\n+        int call_offset = __ call_RT(r0, noreg, CAST_FROM_FN_PTR(address, load_flattened_array), r0, r1);\n+\n+        oop_maps = new OopMapSet();\n+        oop_maps->add_gc_map(call_offset, map);\n+        restore_live_registers_except_r0(sasm);\n+\n+        \/\/ r0: loaded element at array[index]\n+        __ verify_oop(r0);\n+      }\n+      break;\n+\n+    case store_flattened_array_id:\n+      {\n+        StubFrame f(sasm, \"store_flattened_array\", dont_gc_arguments);\n+        OopMap* map = save_live_registers(sasm, 4);\n+\n+        \/\/ Called with store_parameter and not C abi\n+\n+        f.load_argument(2, r0); \/\/ r0: array\n+        f.load_argument(1, r1); \/\/ r1: index\n+        f.load_argument(0, r2); \/\/ r2: value\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, store_flattened_array), r0, r1, r2);\n+\n+        oop_maps = new OopMapSet();\n+        oop_maps->add_gc_map(call_offset, map);\n+        restore_live_registers_except_r0(sasm);\n+      }\n+      break;\n+\n+    case substitutability_check_id:\n+      {\n+        StubFrame f(sasm, \"substitutability_check\", dont_gc_arguments);\n+        OopMap* map = save_live_registers(sasm);\n+\n+        \/\/ Called with store_parameter and not C abi\n+\n+        f.load_argument(1, r1); \/\/ r1,: left\n+        f.load_argument(0, r2); \/\/ r2,: right\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, substitutability_check), r1, r2);\n+\n+        oop_maps = new OopMapSet();\n+        oop_maps->add_gc_map(call_offset, map);\n+        restore_live_registers_except_r0(sasm);\n+\n+        \/\/ r0,: are the two operands substitutable\n+      }\n+      break;\n+\n@@ -890,1 +996,1 @@\n-      { StubFrame f(sasm, \"throw_incompatible_class_cast_exception\", dont_gc_arguments);\n+      { StubFrame f(sasm, \"throw_incompatible_class_change_error\", dont_gc_arguments);\n@@ -895,0 +1001,6 @@\n+    case throw_illegal_monitor_state_exception_id:\n+      { StubFrame f(sasm, \"throw_illegal_monitor_state_exception\", dont_gc_arguments);\n+        oop_maps = generate_exception_throw(sasm, CAST_FROM_FN_PTR(address, throw_illegal_monitor_state_exception), false);\n+      }\n+      break;\n+\n@@ -1098,0 +1210,2 @@\n+      \/\/ FIXME: For unhandled trap_id this code fails with assert during vm intialization\n+      \/\/ rather than insert a call to unimplemented_entry\n@@ -1106,0 +1220,2 @@\n+\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":127,"deletions":11,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -590,0 +590,1 @@\n+    case T_INLINE_TYPE :\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -177,0 +177,4 @@\n+void InterpreterRuntime::SignatureHandlerGenerator::pass_valuetype() {\n+   pass_object();\n+}\n+\n@@ -261,0 +265,5 @@\n+  virtual void pass_valuetype() {\n+    \/\/ values are handled with oops, like objects\n+    pass_object();\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interpreterRT_aarch64.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+  void pass_valuetype();\n","filename":"src\/hotspot\/cpu\/aarch64\/interpreterRT_aarch64.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2004, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2004, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2021, Red Hat Inc. All rights reserved.\n@@ -34,0 +34,1 @@\n+#include \"runtime\/jfieldIDWorkaround.hpp\"\n@@ -155,1 +156,1 @@\n-  __ lsr(roffset, c_rarg2, 2);                \/\/ offset\n+  __ lsr(roffset, c_rarg2, jfieldIDWorkaround::offset_shift);       \/\/ offset\n","filename":"src\/hotspot\/cpu\/aarch64\/jniFastGetField_aarch64.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -52,0 +53,1 @@\n+#include \"runtime\/signature_cc.hpp\"\n@@ -55,0 +57,1 @@\n+#include \"vmreg_aarch64.inline.hpp\"\n@@ -941,0 +944,35 @@\n+void MacroAssembler::get_default_value_oop(Register inline_klass, Register temp_reg, Register obj) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_inline_type(inline_klass, temp_reg, done_check);\n+    stop(\"get_default_value_oop from non inline type klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  Register offset = temp_reg;\n+  \/\/ Getting the offset of the pre-allocated default value\n+  ldr(offset, Address(inline_klass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())));\n+  ldr(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())));\n+\n+  \/\/ Getting the mirror\n+  ldr(obj, Address(inline_klass, in_bytes(Klass::java_mirror_offset())));\n+  resolve_oop_handle(obj, inline_klass);\n+\n+  \/\/ Getting the pre-allocated default value from the mirror\n+  Address field(obj, offset);\n+  load_heap_oop(obj, field);\n+}\n+\n+void MacroAssembler::get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_empty_inline_type(inline_klass, temp_reg, done_check);\n+    stop(\"get_empty_value from non-empty inline klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  get_default_value_oop(inline_klass, temp_reg, obj);\n+}\n+\n@@ -1291,1 +1329,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -1321,1 +1363,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -1400,0 +1446,1 @@\n+  assert_different_registers(arg_1, c_rarg0);\n@@ -1407,0 +1454,2 @@\n+  assert_different_registers(arg_1, c_rarg0);\n+  assert_different_registers(arg_2, c_rarg0, c_rarg1);\n@@ -1413,0 +1462,4 @@\n+void MacroAssembler::super_call_VM_leaf(address entry_point) {\n+  MacroAssembler::call_VM_leaf_base(entry_point, 1);\n+}\n+\n@@ -1462,0 +1515,109 @@\n+void MacroAssembler::test_markword_is_inline_type(Register markword, Label& is_inline_type) {\n+  assert_different_registers(markword, rscratch2);\n+  andr(markword, markword, markWord::inline_type_mask_in_place);\n+  mov(rscratch2, markWord::inline_type_pattern);\n+  cmp(markword, rscratch2);\n+  br(Assembler::EQ, is_inline_type);\n+}\n+\n+void MacroAssembler::test_klass_is_inline_type(Register klass, Register temp_reg, Label& is_inline_type) {\n+  ldrw(temp_reg, Address(klass, Klass::access_flags_offset()));\n+  andr(temp_reg, temp_reg, JVM_ACC_INLINE);\n+  cbnz(temp_reg, is_inline_type);\n+}\n+\n+void MacroAssembler::test_oop_is_not_inline_type(Register object, Register tmp, Label& not_inline_type) {\n+  cbz(object, not_inline_type);\n+  const int is_inline_type_mask = markWord::inline_type_pattern;\n+  ldr(tmp, Address(object, oopDesc::mark_offset_in_bytes()));\n+  mov(rscratch1, is_inline_type_mask);\n+  andr(tmp, tmp, rscratch1);\n+  cmp(tmp, rscratch1);\n+  br(Assembler::NE, not_inline_type);\n+}\n+\n+void MacroAssembler::test_klass_is_empty_inline_type(Register klass, Register temp_reg, Label& is_empty_inline_type) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_inline_type(klass, temp_reg, done_check);\n+    stop(\"test_klass_is_empty_inline_type with non inline type klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  ldrw(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));\n+  andr(temp_reg, temp_reg, InstanceKlass::misc_flags_is_empty_inline_type());\n+  cbnz(temp_reg, is_empty_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_inline_type(Register flags, Register temp_reg, Label& is_inline) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbnz(flags, ConstantPoolCacheEntry::is_inline_type_shift, is_inline);\n+}\n+\n+void MacroAssembler::test_field_is_not_inline_type(Register flags, Register temp_reg, Label& not_inline) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbz(flags, ConstantPoolCacheEntry::is_inline_type_shift, not_inline);\n+}\n+\n+void MacroAssembler::test_field_is_inlined(Register flags, Register temp_reg, Label& is_flattened) {\n+  assert(temp_reg == noreg, \"not needed\"); \/\/ keep signature uniform with x86\n+  tbnz(flags, ConstantPoolCacheEntry::is_inlined_shift, is_flattened);\n+}\n+\n+void MacroAssembler::test_oop_prototype_bit(Register oop, Register temp_reg, int32_t test_bit, bool jmp_set, Label& jmp_label) {\n+  Label test_mark_word;\n+  \/\/ load mark word\n+  ldr(temp_reg, Address(oop, oopDesc::mark_offset_in_bytes()));\n+  \/\/ check displaced\n+  tst(temp_reg, markWord::unlocked_value);\n+  br(Assembler::NE, test_mark_word);\n+  \/\/ slow path use klass prototype\n+  load_prototype_header(temp_reg, oop);\n+\n+  bind(test_mark_word);\n+  andr(temp_reg, temp_reg, test_bit);\n+  if (jmp_set) {\n+    cbnz(temp_reg, jmp_label);\n+  } else {\n+    cbz(temp_reg, jmp_label);\n+  }\n+}\n+\n+void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg, Label& is_flattened_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::flat_array_bit_in_place, true, is_flattened_array);\n+}\n+\n+void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,\n+                                                  Label&is_non_flattened_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::flat_array_bit_in_place, false, is_non_flattened_array);\n+}\n+\n+void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label& is_null_free_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::nullfree_array_bit_in_place, true, is_null_free_array);\n+}\n+\n+void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&is_non_null_free_array) {\n+  test_oop_prototype_bit(oop, temp_reg, markWord::nullfree_array_bit_in_place, false, is_non_null_free_array);\n+}\n+\n+void MacroAssembler::test_flattened_array_layout(Register lh, Label& is_flattened_array) {\n+  tst(lh, Klass::_lh_array_tag_vt_value_bit_inplace);\n+  br(Assembler::NE, is_flattened_array);\n+}\n+\n+void MacroAssembler::test_non_flattened_array_layout(Register lh, Label& is_non_flattened_array) {\n+  tst(lh, Klass::_lh_array_tag_vt_value_bit_inplace);\n+  br(Assembler::EQ, is_non_flattened_array);\n+}\n+\n+void MacroAssembler::test_null_free_array_layout(Register lh, Label& is_null_free_array) {\n+  tst(lh, Klass::_lh_null_free_bit_inplace);\n+  br(Assembler::NE, is_null_free_array);\n+}\n+\n+void MacroAssembler::test_non_null_free_array_layout(Register lh, Label& is_non_null_free_array) {\n+  tst(lh, Klass::_lh_null_free_bit_inplace);\n+  br(Assembler::EQ, is_non_null_free_array);\n+}\n+\n@@ -3775,0 +3937,8 @@\n+void MacroAssembler::load_metadata(Register dst, Register src) {\n+  if (UseCompressedClassPointers) {\n+    ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  } else {\n+    ldr(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n+\n@@ -4152,1 +4322,2 @@\n-                                     Register tmp1, Register thread_tmp) {\n+                                     Register tmp1, Register thread_tmp, Register tmp3) {\n+\n@@ -4157,1 +4328,1 @@\n-    bs->BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, thread_tmp);\n+    bs->BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, thread_tmp, tmp3);\n@@ -4159,1 +4330,1 @@\n-    bs->store_at(this, decorators, type, dst, src, tmp1, thread_tmp);\n+    bs->store_at(this, decorators, type, dst, src, tmp1, thread_tmp, tmp3);\n@@ -4163,0 +4334,40 @@\n+void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,\n+                                       Register inline_klass) {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->value_copy(this, decorators, src, dst, inline_klass);\n+}\n+\n+void MacroAssembler::first_field_offset(Register inline_klass, Register offset) {\n+  ldr(offset, Address(inline_klass, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+  ldrw(offset, Address(offset, InlineKlass::first_field_offset_offset()));\n+}\n+\n+void MacroAssembler::data_for_oop(Register oop, Register data, Register inline_klass) {\n+  \/\/ ((address) (void*) o) + vk->first_field_offset();\n+  Register offset = (data == oop) ? rscratch1 : data;\n+  first_field_offset(inline_klass, offset);\n+  if (data == oop) {\n+    add(data, data, offset);\n+  } else {\n+    lea(data, Address(oop, offset));\n+  }\n+}\n+\n+void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,\n+                                                Register index, Register data) {\n+  assert_different_registers(array, array_klass, index);\n+  assert_different_registers(rscratch1, array, index);\n+\n+  \/\/ array->base() + (index << Klass::layout_helper_log2_element_size(lh));\n+  ldrw(rscratch1, Address(array_klass, Klass::layout_helper_offset()));\n+\n+  \/\/ Klass::layout_helper_log2_element_size(lh)\n+  \/\/ (lh >> _lh_log2_element_size_shift) & _lh_log2_element_size_mask;\n+  lsr(rscratch1, rscratch1, Klass::_lh_log2_element_size_shift);\n+  andr(rscratch1, rscratch1, Klass::_lh_log2_element_size_mask);\n+  lslv(index, index, rscratch1);\n+\n+  add(data, array, index);\n+  add(data, data, arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE));\n+}\n+\n@@ -4183,2 +4394,2 @@\n-                                    Register thread_tmp, DecoratorSet decorators) {\n-  access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);\n+                                    Register thread_tmp, Register tmp3, DecoratorSet decorators) {\n+  access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp, tmp3);\n@@ -4189,1 +4400,1 @@\n-  access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);\n+  access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);\n@@ -4253,0 +4464,119 @@\n+\/\/ Object \/ value buffer allocation...\n+void MacroAssembler::allocate_instance(Register klass, Register new_obj,\n+                                       Register t1, Register t2,\n+                                       bool clear_fields, Label& alloc_failed)\n+{\n+  Label done, initialize_header, initialize_object, slow_case, slow_case_no_pop;\n+  Register layout_size = t1;\n+  assert(new_obj == r0, \"needs to be r0, according to barrier asm eden_allocate\");\n+  assert_different_registers(klass, new_obj, t1, t2);\n+\n+#ifdef ASSERT\n+  {\n+    Label L;\n+    ldrb(rscratch1, Address(klass, InstanceKlass::init_state_offset()));\n+    cmpw(rscratch1, InstanceKlass::fully_initialized);\n+    br(Assembler::EQ, L);\n+    stop(\"klass not initialized\");\n+    bind(L);\n+  }\n+#endif\n+\n+  \/\/ get instance_size in InstanceKlass (scaled to a count of bytes)\n+  ldrw(layout_size, Address(klass, Klass::layout_helper_offset()));\n+  \/\/ test to see if it has a finalizer or is malformed in some way\n+  tst(layout_size, Klass::_lh_instance_slow_path_bit);\n+  br(Assembler::NE, slow_case_no_pop);\n+\n+  \/\/ Allocate the instance:\n+  \/\/  If TLAB is enabled:\n+  \/\/    Try to allocate in the TLAB.\n+  \/\/    If fails, go to the slow path.\n+  \/\/  Else If inline contiguous allocations are enabled:\n+  \/\/    Try to allocate in eden.\n+  \/\/    If fails due to heap end, go to slow path.\n+  \/\/\n+  \/\/  If TLAB is enabled OR inline contiguous is enabled:\n+  \/\/    Initialize the allocation.\n+  \/\/    Exit.\n+  \/\/\n+  \/\/  Go to slow path.\n+  const bool allow_shared_alloc =\n+    Universe::heap()->supports_inline_contig_alloc();\n+\n+  push(klass);\n+\n+  if (UseTLAB) {\n+    tlab_allocate(new_obj, layout_size, 0, klass, t2, slow_case);\n+    if (ZeroTLAB || (!clear_fields)) {\n+      \/\/ the fields have been already cleared\n+      b(initialize_header);\n+    } else {\n+      \/\/ initialize both the header and fields\n+      b(initialize_object);\n+    }\n+  } else {\n+    \/\/ Allocation in the shared Eden, if allowed.\n+    \/\/\n+    eden_allocate(new_obj, layout_size, 0, t2, slow_case);\n+  }\n+\n+  \/\/ If UseTLAB or allow_shared_alloc are true, the object is created above and\n+  \/\/ there is an initialize need. Otherwise, skip and go to the slow path.\n+  if (UseTLAB || allow_shared_alloc) {\n+    if (clear_fields) {\n+      \/\/ The object is initialized before the header.  If the object size is\n+      \/\/ zero, go directly to the header initialization.\n+      bind(initialize_object);\n+      subs(layout_size, layout_size, sizeof(oopDesc));\n+      br(Assembler::EQ, initialize_header);\n+\n+      \/\/ Initialize topmost object field, divide size by 8, check if odd and\n+      \/\/ test if zero.\n+\n+  #ifdef ASSERT\n+      \/\/ make sure instance_size was multiple of 8\n+      Label L;\n+      tst(layout_size, 7);\n+      br(Assembler::EQ, L);\n+      stop(\"object size is not multiple of 8 - adjust this code\");\n+      bind(L);\n+      \/\/ must be > 0, no extra check needed here\n+  #endif\n+\n+      lsr(layout_size, layout_size, LogBytesPerLong);\n+\n+      \/\/ initialize remaining object fields: instance_size was a multiple of 8\n+      {\n+        Label loop;\n+        Register base = t2;\n+\n+        bind(loop);\n+        add(rscratch1, new_obj, layout_size, Assembler::LSL, LogBytesPerLong);\n+        str(zr, Address(rscratch1, sizeof(oopDesc) - 1*oopSize));\n+        subs(layout_size, layout_size, 1);\n+        br(Assembler::NE, loop);\n+      }\n+    } \/\/ clear_fields\n+\n+    \/\/ initialize object header only.\n+    bind(initialize_header);\n+    pop(klass);\n+    Register mark_word = t2;\n+    ldr(mark_word, Address(klass, Klass::prototype_header_offset()));\n+    str(mark_word, Address(new_obj, oopDesc::mark_offset_in_bytes ()));\n+    store_klass_gap(new_obj, zr);  \/\/ zero klass gap for compressed oops\n+    mov(t2, klass);         \/\/ preserve klass\n+    store_klass(new_obj, t2);  \/\/ src klass reg is potentially compressed\n+\n+    b(done);\n+  }\n+\n+  bind(slow_case);\n+  pop(klass);\n+  bind(slow_case_no_pop);\n+  b(alloc_failed);\n+\n+  bind(done);\n+}\n+\n@@ -4364,0 +4694,13 @@\n+void MacroAssembler::get_inline_type_field_klass(Register klass, Register index, Register inline_klass) {\n+  ldr(inline_klass, Address(klass, InstanceKlass::inline_type_field_klasses_offset()));\n+#ifdef ASSERT\n+  {\n+    Label done;\n+    cbnz(inline_klass, done);\n+    stop(\"get_inline_type_field_klass contains no inline klass\");\n+    bind(done);\n+  }\n+#endif\n+  ldr(inline_klass, Address(inline_klass, index, Address::lsl(3)));\n+}\n+\n@@ -5289,0 +5632,313 @@\n+#ifdef COMPILER2\n+\/\/ C2 compiled method's prolog code\n+\/\/ Moved here from aarch64.ad to support Valhalla code belows\n+void MacroAssembler::verified_entry(Compile* C, int sp_inc) {\n+\n+\/\/ n.b. frame size includes space for return pc and rfp\n+  const long framesize = C->output()->frame_size_in_bytes();\n+  assert(framesize % (2 * wordSize) == 0, \"must preserve 2 * wordSize alignment\");\n+\n+  \/\/ insert a nop at the start of the prolog so we can patch in a\n+  \/\/ branch if we need to invalidate the method later\n+  nop();\n+\n+  int bangsize = C->output()->bang_size_in_bytes();\n+  if (C->output()->need_stack_bang(bangsize))\n+     generate_stack_overflow_check(bangsize);\n+\n+  build_frame(framesize);\n+\n+  if (C->needs_stack_repair()) {\n+    Unimplemented();\n+  }\n+\n+  if (VerifyStackAtCalls) {\n+    Unimplemented();\n+  }\n+}\n+#endif \/\/ COMPILER2\n+\n+int MacroAssembler::store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter) {\n+  \/\/ An inline type might be returned. If fields are in registers we\n+  \/\/ need to allocate an inline type instance and initialize it with\n+  \/\/ the value of the fields.\n+  Label skip;\n+  \/\/ We only need a new buffered inline type if a new one is not returned\n+  cmp(r0, (u1) 1);\n+  br(Assembler::EQ, skip);\n+  int call_offset = -1;\n+\n+  Label slow_case;\n+\n+  \/\/ Try to allocate a new buffered inline type (from the heap)\n+  if (UseTLAB) {\n+\n+    if (vk != NULL) {\n+      \/\/ Called from C1, where the return type is statically known.\n+      mov(r1, (intptr_t)vk->get_InlineKlass());\n+      jint lh = vk->layout_helper();\n+      assert(lh != Klass::_lh_neutral_value, \"inline class in return type must have been resolved\");\n+      mov(r14, lh);\n+    } else {\n+       \/\/ Call from interpreter. R0 contains ((the InlineKlass* of the return type) | 0x01)\n+       andr(r1, r0, -2);\n+       \/\/ get obj size\n+       ldrw(r14, Address(rscratch1 \/*klass*\/, Klass::layout_helper_offset()));\n+    }\n+\n+    ldr(r13, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));\n+    lea(r14, Address(r13, r14));\n+    ldr(rscratch1, Address(rthread, in_bytes(JavaThread::tlab_end_offset())));\n+    cmp(r14, rscratch1);\n+    br(Assembler::GT, slow_case);\n+    str(r14, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));\n+    mov(rscratch1, (intptr_t)markWord::inline_type_prototype().value());\n+    str(rscratch1, Address(r13, oopDesc::mark_offset_in_bytes()));\n+\n+    store_klass_gap(r13, zr);  \/\/ zero klass gap for compressed oops\n+\n+    if (vk != NULL) {\n+      \/\/ FIXME -- do the packing in-line to avoid the runtime call\n+      mov(r0, r13);\n+      far_call(RuntimeAddress(vk->pack_handler())); \/\/ no need for call info as this will not safepoint.\n+    } else {\n+      \/\/ We have our new buffered inline type, initialize its fields with an inline class specific handler\n+      ldr(r1, Address(r0, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      ldr(r1, Address(r1, InlineKlass::pack_handler_offset()));\n+\n+      \/\/ Mov new class to r0 and call pack_handler\n+      mov(r0, r13);\n+      blr(r1);\n+    }\n+    b(skip);\n+  }\n+\n+  bind(slow_case);\n+  \/\/ We failed to allocate a new inline type, fall back to a runtime\n+  \/\/ call. Some oop field may be live in some registers but we can't\n+  \/\/ tell. That runtime call will take care of preserving them\n+  \/\/ across a GC if there's one.\n+\n+  if (from_interpreter) {\n+    super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());\n+  } else {\n+    ldr(rscratch1, RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));\n+    blr(rscratch1);\n+    call_offset = offset();\n+  }\n+\n+  bind(skip);\n+  return call_offset;\n+}\n+\n+\/\/ Move a value between registers\/stack slots and update the reg_state\n+bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]) {\n+  if (reg_state[to->value()] == reg_written) {\n+    return true; \/\/ Already written\n+  }\n+\n+  if (from != to && bt != T_VOID) {\n+    if (reg_state[to->value()] == reg_readonly) {\n+      return false; \/\/ Not yet writable\n+    }\n+    if (from->is_reg()) {\n+      if (to->is_reg()) {\n+        mov(to->as_Register(), from->as_Register());\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        Address to_addr = Address(sp, st_off);\n+        if (from->is_FloatRegister()) {\n+          if (bt == T_DOUBLE) {\n+             strd(from->as_FloatRegister(), to_addr);\n+          } else {\n+             assert(bt == T_FLOAT, \"must be float\");\n+             strs(from->as_FloatRegister(), to_addr);\n+          }\n+        } else {\n+          str(from->as_Register(), to_addr);\n+        }\n+      }\n+    } else {\n+      Address from_addr = Address(sp, from->reg2stack() * VMRegImpl::stack_slot_size + wordSize);\n+      if (to->is_reg()) {\n+        if (to->is_FloatRegister()) {\n+          if (bt == T_DOUBLE) {\n+             ldrd(to->as_FloatRegister(), from_addr);\n+          } else {\n+            assert(bt == T_FLOAT, \"must be float\");\n+            ldrs(to->as_FloatRegister(), from_addr);\n+          }\n+        } else {\n+          ldr(to->as_Register(), from_addr);\n+        }\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        ldr(rscratch1, from_addr);\n+        str(rscratch1, Address(sp, st_off));\n+      }\n+    }\n+  }\n+\n+  \/\/ Update register states\n+  reg_state[from->value()] = reg_writable;\n+  reg_state[to->value()] = reg_written;\n+  return true;\n+}\n+\n+\/\/ Read all fields from an inline type oop and store the values in registers\/stack slots\n+bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                                          VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                                          RegState reg_state[]) {\n+  assert(sig->at(sig_index)._bt == T_VOID, \"should be at end delimiter\");\n+  assert(from->is_valid(), \"source must bevalid\");\n+  Register fromReg;\n+  if (from->is_reg()) {\n+    fromReg = from->as_Register();\n+  } else {\n+    int st_off = from->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+    ldr(r10, Address(sp, st_off));\n+    fromReg = r10;\n+  }\n+\n+  ScalarizedInlineArgsStream stream(sig, sig_index, to, to_count, to_index, -1);\n+  bool done = true;\n+  bool mark_done = true;\n+  VMReg toReg;\n+  BasicType bt;\n+  while (stream.next(toReg, bt)) {\n+    int off = sig->at(stream.sig_index())._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    Address fromAddr = Address(fromReg, off);\n+\n+    int idx = (int)toReg->value();\n+    if (reg_state[idx] == reg_readonly) {\n+     if (idx != from->value()) {\n+       mark_done = false;\n+     }\n+     done = false;\n+     continue;\n+    } else if (reg_state[idx] == reg_written) {\n+      continue;\n+    } else {\n+      assert(reg_state[idx] == reg_writable, \"must be writable\");\n+      reg_state[idx] = reg_written;\n+    }\n+\n+    if (!toReg->is_FloatRegister()) {\n+      Register dst = toReg->is_stack() ? r13 : toReg->as_Register();\n+      if (is_reference_type(bt)) {\n+        load_heap_oop(dst, fromAddr);\n+      } else {\n+        bool is_signed = (bt != T_CHAR) && (bt != T_BOOLEAN);\n+        load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);\n+      }\n+      if (toReg->is_stack()) {\n+        int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        str(dst, Address(sp, st_off));\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      ldrd(toReg->as_FloatRegister(), fromAddr);\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      ldrs(toReg->as_FloatRegister(), fromAddr);\n+    }\n+  }\n+  sig_index = stream.sig_index();\n+  to_index = stream.regs_index();\n+\n+  if (mark_done && reg_state[from->value()] != reg_written) {\n+    \/\/ This is okay because no one else will write to that slot\n+    reg_state[from->value()] = reg_writable;\n+  }\n+  from_index--;\n+  return done;\n+}\n+\n+\/\/ Pack fields back into an inline type oop\n+bool MacroAssembler::pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                                        VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                                        RegState reg_state[]) {\n+  assert(sig->at(sig_index)._bt == T_INLINE_TYPE, \"should be at end delimiter\");\n+  assert(to->is_valid(), \"destination must be valid\");\n+\n+  if (reg_state[to->value()] == reg_written) {\n+    skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n+    return true; \/\/ Already written\n+  }\n+\n+  Register val_array = r0;\n+  Register val_obj_tmp = r11;\n+  Register from_reg_tmp = r10;\n+  Register tmp1 = r14;\n+  Register tmp2 = r13;\n+  Register tmp3 = r1;\n+  Register val_obj = to->is_stack() ? val_obj_tmp : to->as_Register();\n+\n+  if (reg_state[to->value()] == reg_readonly) {\n+    if (!is_reg_in_unpacked_fields(sig, sig_index, to, from, from_count, from_index)) {\n+      skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n+      return false; \/\/ Not yet writable\n+    }\n+    val_obj = val_obj_tmp;\n+  }\n+\n+  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_INLINE_TYPE);\n+  load_heap_oop(val_obj, Address(val_array, index));\n+\n+  ScalarizedInlineArgsStream stream(sig, sig_index, from, from_count, from_index);\n+  VMReg fromReg;\n+  BasicType bt;\n+  while (stream.next(fromReg, bt)) {\n+    int off = sig->at(stream.sig_index())._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;\n+\n+    \/\/ Pack the scalarized field into the value object.\n+    Address dst(val_obj, off);\n+\n+    if (!fromReg->is_FloatRegister()) {\n+      Register src;\n+      if (fromReg->is_stack()) {\n+        src = from_reg_tmp;\n+        int ld_off = fromReg->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        load_sized_value(src, Address(sp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+      } else {\n+        src = fromReg->as_Register();\n+      }\n+      assert_different_registers(dst.base(), src, tmp1, tmp2, tmp3, val_array);\n+      if (is_reference_type(bt)) {\n+        store_heap_oop(dst, src, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      } else {\n+        store_sized_value(dst, src, size_in_bytes);\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      strd(fromReg->as_FloatRegister(), dst);\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      strs(fromReg->as_FloatRegister(), dst);\n+    }\n+    reg_state[fromReg->value()] = reg_writable;\n+  }\n+  sig_index = stream.sig_index();\n+  from_index = stream.regs_index();\n+\n+  assert(reg_state[to->value()] == reg_writable, \"must have already been read\");\n+  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state);\n+  assert(success, \"to register must be writeable\");\n+\n+  return true;\n+}\n+\n+VMReg MacroAssembler::spill_reg_for(VMReg reg) {\n+  return (reg->is_FloatRegister()) ? v0->as_VMReg() : r14->as_VMReg();\n+}\n+\n+void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {\n+  assert((initial_framesize & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n+  if (needs_stack_repair) {\n+    Unimplemented();\n+  } else {\n+    remove_frame(initial_framesize);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":664,"deletions":8,"binary":false,"changes":672,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"utilities\/macros.hpp\"\n@@ -33,0 +34,4 @@\n+#include \"runtime\/signature.hpp\"\n+\n+\n+class ciInlineKlass;\n@@ -616,0 +621,31 @@\n+  \/\/ markWord tests, kills markWord reg\n+  void test_markword_is_inline_type(Register markword, Label& is_inline_type);\n+\n+  \/\/ inlineKlass queries, kills temp_reg\n+  void test_klass_is_inline_type(Register klass, Register temp_reg, Label& is_inline_type);\n+  void test_klass_is_empty_inline_type(Register klass, Register temp_reg, Label& is_empty_inline_type);\n+  void test_oop_is_not_inline_type(Register object, Register tmp, Label& not_inline_type);\n+\n+  \/\/ Get the default value oop for the given InlineKlass\n+  void get_default_value_oop(Register inline_klass, Register temp_reg, Register obj);\n+  \/\/ The empty value oop, for the given InlineKlass (\"empty\" as in no instance fields)\n+  \/\/ get_default_value_oop with extra assertion for empty inline klass\n+  void get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj);\n+\n+  void test_field_is_inline_type(Register flags, Register temp_reg, Label& is_inline);\n+  void test_field_is_not_inline_type(Register flags, Register temp_reg, Label& not_inline);\n+  void test_field_is_inlined(Register flags, Register temp_reg, Label& is_flattened);\n+\n+  \/\/ Check oops for special arrays, i.e. flattened and\/or null-free\n+  void test_oop_prototype_bit(Register oop, Register temp_reg, int32_t test_bit, bool jmp_set, Label& jmp_label);\n+  void test_flattened_array_oop(Register klass, Register temp_reg, Label& is_flattened_array);\n+  void test_non_flattened_array_oop(Register oop, Register temp_reg, Label&is_non_flattened_array);\n+  void test_null_free_array_oop(Register oop, Register temp_reg, Label& is_null_free_array);\n+  void test_non_null_free_array_oop(Register oop, Register temp_reg, Label&is_non_null_free_array);\n+\n+  \/\/ Check array klass layout helper for flatten or null-free arrays...\n+  void test_flattened_array_layout(Register lh, Label& is_flattened_array);\n+  void test_non_flattened_array_layout(Register lh, Label& is_non_flattened_array);\n+  void test_null_free_array_layout(Register lh, Label& is_null_free_array);\n+  void test_non_null_free_array_layout(Register lh, Label& is_non_null_free_array);\n+\n@@ -823,0 +859,2 @@\n+  void load_metadata(Register dst, Register src);\n+\n@@ -835,1 +873,10 @@\n-                       Register tmp1, Register tmp_thread);\n+                       Register tmp1, Register tmp_thread, Register tmp3 = noreg);\n+\n+  void access_value_copy(DecoratorSet decorators, Register src, Register dst, Register inline_klass);\n+\n+  \/\/ inline type data payload offsets...\n+  void first_field_offset(Register inline_klass, Register offset);\n+  void data_for_oop(Register oop, Register data, Register inline_klass);\n+  \/\/ get data payload ptr a flat value array at index, kills rcx and index\n+  void data_for_value_array_index(Register array, Register array_klass,\n+                                  Register index, Register data);\n@@ -847,1 +894,1 @@\n-                      Register tmp_thread = noreg, DecoratorSet decorators = 0);\n+                      Register tmp_thread = noreg, Register tmp3 = noreg, DecoratorSet decorators = 0);\n@@ -896,0 +943,9 @@\n+\n+  \/\/ Object \/ value buffer allocation...\n+  \/\/ Allocate instance of klass, assumes klass initialized by caller\n+  \/\/ new_obj prefers to be rax\n+  \/\/ Kills t1 and t2, perserves klass, return allocation in new_obj (rsi on LP64)\n+  void allocate_instance(Register klass, Register new_obj,\n+                         Register t1, Register t2,\n+                         bool clear_fields, Label& alloc_failed);\n+\n@@ -914,0 +970,3 @@\n+  \/\/ For field \"index\" within \"klass\", return inline_klass ...\n+  void get_inline_type_field_klass(Register klass, Register index, Register inline_klass);\n+\n@@ -1201,0 +1260,16 @@\n+  void verified_entry(Compile* C, int sp_inc);\n+\n+  \/\/ Inline type specific methods\n+  #include \"asm\/macroAssembler_common.hpp\"\n+\n+  int store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter = true);\n+  bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]);\n+  bool unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                            VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                            RegState reg_state[]);\n+  bool pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                          VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                          RegState reg_state[]);\n+  void remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset);\n+  VMReg spill_reg_for(VMReg reg);\n+\n@@ -1265,0 +1340,2 @@\n+  void fill_words(Register base, uint64_t cnt, Register value);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":79,"deletions":2,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"classfile\/symbolTable.hpp\"\n@@ -323,0 +324,1 @@\n+    case T_INLINE_TYPE:\n@@ -356,0 +358,84 @@\n+\n+\/\/ const uint SharedRuntime::java_return_convention_max_int = Argument::n_int_register_parameters_j+1;\n+const uint SharedRuntime::java_return_convention_max_int = 6;\n+const uint SharedRuntime::java_return_convention_max_float = Argument::n_float_register_parameters_j;\n+\n+int SharedRuntime::java_return_convention(const BasicType *sig_bt, VMRegPair *regs, int total_args_passed) {\n+\n+  \/\/ Create the mapping between argument positions and\n+  \/\/ registers.\n+  \/\/ r1, r2 used to address klasses and states, exclude it from return convention to avoid colision\n+\n+  static const Register INT_ArgReg[java_return_convention_max_int] = {\n+     r0 \/* j_rarg7 *\/, j_rarg6, j_rarg5, j_rarg4, j_rarg3, j_rarg2\n+  };\n+\n+  static const FloatRegister FP_ArgReg[java_return_convention_max_float] = {\n+    j_farg0, j_farg1, j_farg2, j_farg3, j_farg4, j_farg5, j_farg6, j_farg7\n+  };\n+\n+  uint int_args = 0;\n+  uint fp_args = 0;\n+\n+  for (int i = 0; i < total_args_passed; i++) {\n+    switch (sig_bt[i]) {\n+    case T_BOOLEAN:\n+    case T_CHAR:\n+    case T_BYTE:\n+    case T_SHORT:\n+    case T_INT:\n+      if (int_args < SharedRuntime::java_return_convention_max_int) {\n+        regs[i].set1(INT_ArgReg[int_args]->as_VMReg());\n+        int_args ++;\n+      } else {\n+        \/\/ Should we have gurantee here?\n+        return -1;\n+      }\n+      break;\n+    case T_VOID:\n+      \/\/ halves of T_LONG or T_DOUBLE\n+      assert(i != 0 && (sig_bt[i - 1] == T_LONG || sig_bt[i - 1] == T_DOUBLE), \"expecting half\");\n+      regs[i].set_bad();\n+      break;\n+    case T_LONG:\n+      assert((i + 1) < total_args_passed && sig_bt[i + 1] == T_VOID, \"expecting half\");\n+      \/\/ fall through\n+    case T_OBJECT:\n+    case T_ARRAY:\n+    case T_ADDRESS:\n+      \/\/ Should T_METADATA be added to java_calling_convention as well ?\n+    case T_METADATA:\n+    case T_INLINE_TYPE:\n+      if (int_args < SharedRuntime::java_return_convention_max_int) {\n+        regs[i].set2(INT_ArgReg[int_args]->as_VMReg());\n+        int_args ++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_FLOAT:\n+      if (fp_args < SharedRuntime::java_return_convention_max_float) {\n+        regs[i].set1(FP_ArgReg[fp_args]->as_VMReg());\n+        fp_args ++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_DOUBLE:\n+      assert((i + 1) < total_args_passed && sig_bt[i + 1] == T_VOID, \"expecting half\");\n+      if (fp_args < Argument::n_float_register_parameters_j) {\n+        regs[i].set2(FP_ArgReg[fp_args]->as_VMReg());\n+        fp_args ++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+      break;\n+    }\n+  }\n+\n+  return int_args + fp_args;\n+}\n+\n@@ -389,19 +475,40 @@\n-static void gen_c2i_adapter(MacroAssembler *masm,\n-                            int total_args_passed,\n-                            int comp_args_on_stack,\n-                            const BasicType *sig_bt,\n-                            const VMRegPair *regs,\n-                            Label& skip_fixup) {\n-  \/\/ Before we get into the guts of the C2I adapter, see if we should be here\n-  \/\/ at all.  We've come from compiled code and are attempting to jump to the\n-  \/\/ interpreter, which means the caller made a static call to get here\n-  \/\/ (vcalls always get a compiled target if there is one).  Check for a\n-  \/\/ compiled target.  If there is one, we need to patch the caller's call.\n-  patch_callers_callsite(masm);\n-\n-  __ bind(skip_fixup);\n-\n-  int words_pushed = 0;\n-\n-  \/\/ Since all args are passed on the stack, total_args_passed *\n-  \/\/ Interpreter::stackElementSize is the space we need.\n+\/\/ For each inline type argument, sig includes the list of fields of\n+\/\/ the inline type. This utility function computes the number of\n+\/\/ arguments for the call if inline types are passed by reference (the\n+\/\/ calling convention the interpreter expects).\n+static int compute_total_args_passed_int(const GrowableArray<SigEntry>* sig_extended) {\n+  int total_args_passed = 0;\n+  if (InlineTypePassFieldsAsArgs) {\n+     for (int i = 0; i < sig_extended->length(); i++) {\n+       BasicType bt = sig_extended->at(i)._bt;\n+       if (bt == T_INLINE_TYPE) {\n+         \/\/ In sig_extended, an inline type argument starts with:\n+         \/\/ T_INLINE_TYPE, followed by the types of the fields of the\n+         \/\/ inline type and T_VOID to mark the end of the value\n+         \/\/ type. Inline types are flattened so, for instance, in the\n+         \/\/ case of an inline type with an int field and an inline type\n+         \/\/ field that itself has 2 fields, an int and a long:\n+         \/\/ T_INLINE_TYPE T_INT T_INLINE_TYPE T_INT T_LONG T_VOID (second\n+         \/\/ slot for the T_LONG) T_VOID (inner T_INLINE_TYPE) T_VOID\n+         \/\/ (outer T_INLINE_TYPE)\n+         total_args_passed++;\n+         int vt = 1;\n+         do {\n+           i++;\n+           BasicType bt = sig_extended->at(i)._bt;\n+           BasicType prev_bt = sig_extended->at(i-1)._bt;\n+           if (bt == T_INLINE_TYPE) {\n+             vt++;\n+           } else if (bt == T_VOID &&\n+                      prev_bt != T_LONG &&\n+                      prev_bt != T_DOUBLE) {\n+             vt--;\n+           }\n+         } while (vt != 0);\n+       } else {\n+         total_args_passed++;\n+       }\n+     }\n+  } else {\n+    total_args_passed = sig_extended->length();\n+  }\n@@ -409,1 +516,2 @@\n-  int extraspace = total_args_passed * Interpreter::stackElementSize;\n+  return total_args_passed;\n+}\n@@ -411,3 +519,1 @@\n-  __ mov(r13, sp);\n-  \/\/ stack is aligned, keep it that way\n-  extraspace = align_up(extraspace, 2*wordSize);\n+static void gen_c2i_adapter_helper(MacroAssembler* masm, BasicType bt, const VMRegPair& reg_pair, int extraspace, const Address& to) {\n@@ -416,13 +522,1 @@\n-  if (extraspace)\n-    __ sub(sp, sp, extraspace);\n-\n-  \/\/ Now write the args into the outgoing interpreter space\n-  for (int i = 0; i < total_args_passed; i++) {\n-    if (sig_bt[i] == T_VOID) {\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n-      continue;\n-    }\n-\n-    \/\/ offset to start parameters\n-    int st_off   = (total_args_passed - i - 1) * Interpreter::stackElementSize;\n-    int next_off = st_off - Interpreter::stackElementSize;\n+    assert(bt != T_INLINE_TYPE || !InlineTypePassFieldsAsArgs, \"no inline type here\");\n@@ -443,2 +537,5 @@\n-    VMReg r_1 = regs[i].first();\n-    VMReg r_2 = regs[i].second();\n+    \/\/ int next_off = st_off - Interpreter::stackElementSize;\n+\n+    VMReg r_1 = reg_pair.first();\n+    VMReg r_2 = reg_pair.second();\n+\n@@ -447,1 +544,1 @@\n-      continue;\n+      return;\n@@ -449,0 +546,1 @@\n+\n@@ -451,3 +549,2 @@\n-      int ld_off = (r_1->reg2stack() * VMRegImpl::stack_slot_size\n-                    + extraspace\n-                    + words_pushed * wordSize);\n+      \/\/ words_pushed is always 0 so we don't use it.\n+      int ld_off = (r_1->reg2stack() * VMRegImpl::stack_slot_size + extraspace \/* + word_pushed * wordSize *\/);\n@@ -457,1 +554,1 @@\n-        __ str(rscratch1, Address(sp, st_off));\n+        __ str(rscratch1, to);\n@@ -460,16 +557,1 @@\n-\n-\n-        \/\/ Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG\n-        \/\/ T_DOUBLE and T_LONG use two slots in the interpreter\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n-          \/\/ ld_off == LSW, ld_off+wordSize == MSW\n-          \/\/ st_off == MSW, next_off == LSW\n-          __ str(rscratch1, Address(sp, next_off));\n-#ifdef ASSERT\n-          \/\/ Overwrite the unused slot with known junk\n-          __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaaaull);\n-          __ str(rscratch1, Address(sp, st_off));\n-#endif \/* ASSERT *\/\n-        } else {\n-          __ str(rscratch1, Address(sp, st_off));\n-        }\n+        __ str(rscratch1, to);\n@@ -480,19 +562,1 @@\n-      if (!r_2->is_valid()) {\n-        \/\/ must be only an int (or less ) so move only 32bits to slot\n-        \/\/ why not sign extend??\n-        __ str(r, Address(sp, st_off));\n-      } else {\n-        \/\/ Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG\n-        \/\/ T_DOUBLE and T_LONG use two slots in the interpreter\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n-          \/\/ jlong\/double in gpr\n-#ifdef ASSERT\n-          \/\/ Overwrite the unused slot with known junk\n-          __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaabull);\n-          __ str(rscratch1, Address(sp, st_off));\n-#endif \/* ASSERT *\/\n-          __ str(r, Address(sp, next_off));\n-        } else {\n-          __ str(r, Address(sp, st_off));\n-        }\n-      }\n+      __ str(r, to);\n@@ -503,1 +567,1 @@\n-        __ strs(r_1->as_FloatRegister(), Address(sp, st_off));\n+        __ strs(r_1->as_FloatRegister(), to);\n@@ -505,6 +569,1 @@\n-#ifdef ASSERT\n-        \/\/ Overwrite the unused slot with known junk\n-        __ mov(rscratch1, (uint64_t)0xdeadffffdeadaaacull);\n-        __ str(rscratch1, Address(sp, st_off));\n-#endif \/* ASSERT *\/\n-        __ strd(r_1->as_FloatRegister(), Address(sp, next_off));\n+        __ strd(r_1->as_FloatRegister(), to);\n@@ -512,0 +571,66 @@\n+   }\n+}\n+\n+static void gen_c2i_adapter(MacroAssembler *masm,\n+                            const GrowableArray<SigEntry>* sig_extended,\n+                            const VMRegPair *regs,\n+                            Label& skip_fixup,\n+                            address start,\n+                            OopMapSet* oop_maps,\n+                            int& frame_complete,\n+                            int& frame_size_in_words,\n+                            bool alloc_inline_receiver) {\n+\n+  \/\/ Before we get into the guts of the C2I adapter, see if we should be here\n+  \/\/ at all.  We've come from compiled code and are attempting to jump to the\n+  \/\/ interpreter, which means the caller made a static call to get here\n+  \/\/ (vcalls always get a compiled target if there is one).  Check for a\n+  \/\/ compiled target.  If there is one, we need to patch the caller's call.\n+  patch_callers_callsite(masm);\n+\n+  __ bind(skip_fixup);\n+\n+  bool has_inline_argument = false;\n+\n+  if (InlineTypePassFieldsAsArgs) {\n+      \/\/ Is there an inline type argument?\n+     for (int i = 0; i < sig_extended->length() && !has_inline_argument; i++) {\n+       has_inline_argument = (sig_extended->at(i)._bt == T_INLINE_TYPE);\n+     }\n+     if (has_inline_argument) {\n+      \/\/ There is at least an inline type argument: we're coming from\n+      \/\/ compiled code so we have no buffers to back the inline types\n+      \/\/ Allocate the buffers here with a runtime call.\n+      RegisterSaver reg_save(false \/* save_vectors *\/);\n+      OopMap* map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n+\n+      frame_complete = __ offset();\n+      address the_pc = __ pc();\n+\n+      __ set_last_Java_frame(noreg, noreg, the_pc, rscratch1);\n+\n+      __ mov(c_rarg0, rthread);\n+      __ mov(c_rarg1, r1);\n+      __ mov(c_rarg2, (int64_t)alloc_inline_receiver);\n+\n+      __ lea(rscratch1, RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::allocate_inline_types)));\n+      __ blr(rscratch1);\n+\n+      oop_maps->add_gc_map((int)(__ pc() - start), map);\n+      __ reset_last_Java_frame(false);\n+\n+      reg_save.restore_live_registers(masm);\n+\n+      Label no_exception;\n+      __ ldr(r0, Address(rthread, Thread::pending_exception_offset()));\n+      __ cbz(r0, no_exception);\n+\n+      __ str(zr, Address(rthread, JavaThread::vm_result_offset()));\n+      __ ldr(r0, Address(rthread, Thread::pending_exception_offset()));\n+      __ b(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+      __ bind(no_exception);\n+\n+      \/\/ We get an array of objects from the runtime call\n+      __ get_vm_result(r10, rthread);\n+      __ get_vm_result_2(r1, rthread); \/\/ TODO: required to keep the callee Method live?\n@@ -515,0 +640,95 @@\n+  int words_pushed = 0;\n+\n+  \/\/ Since all args are passed on the stack, total_args_passed *\n+  \/\/ Interpreter::stackElementSize is the space we need.\n+\n+  int total_args_passed = compute_total_args_passed_int(sig_extended);\n+  int extraspace = (total_args_passed * Interpreter::stackElementSize) + wordSize;\n+\n+  \/\/ stack is aligned, keep it that way\n+  extraspace = align_up(extraspace, 2 * wordSize);\n+\n+  __ mov(r13, sp);\n+\n+  if (extraspace)\n+    __ sub(sp, sp, extraspace);\n+\n+  \/\/ Now write the args into the outgoing interpreter space\n+\n+  int ignored = 0, next_vt_arg = 0, next_arg_int = 0;\n+  bool has_oop_field = false;\n+\n+  for (int next_arg_comp = 0; next_arg_comp < total_args_passed; next_arg_comp++) {\n+    BasicType bt = sig_extended->at(next_arg_comp)._bt;\n+    \/\/ offset to start parameters\n+    int st_off   = (total_args_passed - next_arg_int - 1) * Interpreter::stackElementSize;\n+\n+    if (!InlineTypePassFieldsAsArgs || bt != T_INLINE_TYPE) {\n+      if (bt == T_VOID) {\n+         assert(next_arg_comp > 0 && (sig_extended->at(next_arg_comp - 1)._bt == T_LONG || sig_extended->at(next_arg_comp - 1)._bt == T_DOUBLE), \"missing half\");\n+         next_arg_int ++;\n+         continue;\n+       }\n+\n+       int next_off = st_off - Interpreter::stackElementSize;\n+       int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : st_off;\n+\n+       gen_c2i_adapter_helper(masm, bt, regs[next_arg_comp], extraspace, Address(sp, offset));\n+       next_arg_int ++;\n+   } else {\n+       ignored++;\n+      \/\/ get the buffer from the just allocated pool of buffers\n+      int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_INLINE_TYPE);\n+      __ load_heap_oop(rscratch1, Address(r10, index));\n+      next_vt_arg++;\n+      next_arg_int++;\n+      int vt = 1;\n+      \/\/ write fields we get from compiled code in registers\/stack\n+      \/\/ slots to the buffer: we know we are done with that inline type\n+      \/\/ argument when we hit the T_VOID that acts as an end of value\n+      \/\/ type delimiter for this inline type. Inline types are flattened\n+      \/\/ so we might encounter embedded inline types. Each entry in\n+      \/\/ sig_extended contains a field offset in the buffer.\n+      do {\n+        next_arg_comp++;\n+        BasicType bt = sig_extended->at(next_arg_comp)._bt;\n+        BasicType prev_bt = sig_extended->at(next_arg_comp - 1)._bt;\n+        if (bt == T_INLINE_TYPE) {\n+          vt++;\n+          ignored++;\n+        } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+          vt--;\n+          ignored++;\n+        } else {\n+          int off = sig_extended->at(next_arg_comp)._offset;\n+          assert(off > 0, \"offset in object should be positive\");\n+\n+          bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);\n+          has_oop_field = has_oop_field || is_oop;\n+\n+          gen_c2i_adapter_helper(masm, bt, regs[next_arg_comp - ignored], extraspace, Address(r11, off));\n+        }\n+      } while (vt != 0);\n+      \/\/ pass the buffer to the interpreter\n+      __ str(rscratch1, Address(sp, st_off));\n+   }\n+\n+  }\n+\n+\/\/ If an inline type was allocated and initialized, apply post barrier to all oop fields\n+  if (has_inline_argument && has_oop_field) {\n+    __ push(r13); \/\/ save senderSP\n+    __ push(r1); \/\/ save callee\n+    \/\/ Allocate argument register save area\n+    if (frame::arg_reg_save_area_bytes != 0) {\n+      __ sub(sp, sp, frame::arg_reg_save_area_bytes);\n+    }\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::apply_post_barriers), rthread, r10);\n+    \/\/ De-allocate argument register save area\n+    if (frame::arg_reg_save_area_bytes != 0) {\n+      __ add(sp, sp, frame::arg_reg_save_area_bytes);\n+    }\n+    __ pop(r1); \/\/ restore callee\n+    __ pop(r13); \/\/ restore sender SP\n+  }\n+\n@@ -521,0 +741,1 @@\n+void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm, int comp_args_on_stack, const GrowableArray<SigEntry>* sig, const VMRegPair *regs) {\n@@ -522,5 +743,0 @@\n-void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm,\n-                                    int total_args_passed,\n-                                    int comp_args_on_stack,\n-                                    const BasicType *sig_bt,\n-                                    const VMRegPair *regs) {\n@@ -586,1 +802,1 @@\n-  int comp_words_on_stack = align_up(comp_args_on_stack*VMRegImpl::stack_slot_size, wordSize)>>LogBytesPerWord;\n+  int comp_words_on_stack = 0;\n@@ -588,2 +804,3 @@\n-    __ sub(rscratch1, sp, comp_words_on_stack * wordSize);\n-    __ andr(sp, rscratch1, -16);\n+     comp_words_on_stack = align_up(comp_args_on_stack * VMRegImpl::stack_slot_size, wordSize) >> LogBytesPerWord;\n+     __ sub(rscratch1, sp, comp_words_on_stack * wordSize);\n+     __ andr(sp, rscratch1, -16);\n@@ -608,0 +825,2 @@\n+  int total_args_passed = sig->length();\n+\n@@ -610,2 +829,5 @@\n-    if (sig_bt[i] == T_VOID) {\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n+    BasicType bt = sig->at(i)._bt;\n+\n+    assert(bt != T_INLINE_TYPE, \"i2c adapter doesn't unpack inline typ args\");\n+    if (bt == T_VOID) {\n+      assert(i > 0 && (sig->at(i - 1)._bt == T_LONG || sig->at(i - 1)._bt == T_DOUBLE), \"missing half\");\n@@ -616,0 +838,1 @@\n+    assert(!regs[i].second()->is_valid() || regs[i].first()->next() == regs[i].second(), \"scrambled load targets?\");\n@@ -617,3 +840,1 @@\n-    assert(!regs[i].second()->is_valid() || regs[i].first()->next() == regs[i].second(),\n-            \"scrambled load targets?\");\n-    int ld_off = (total_args_passed - i - 1)*Interpreter::stackElementSize;\n+    int ld_off = (total_args_passed - i - 1) * Interpreter::stackElementSize;\n@@ -634,1 +855,1 @@\n-      int st_off = regs[i].first()->reg2stack()*VMRegImpl::stack_slot_size;\n+      int st_off = regs[i].first()->reg2stack() * VMRegImpl::stack_slot_size;\n@@ -651,2 +872,1 @@\n-        const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n-                           next_off : ld_off;\n+        const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : ld_off;\n@@ -655,11 +875,28 @@\n-        __ str(rscratch2, Address(sp, st_off));\n-      }\n-    } else if (r_1->is_Register()) {  \/\/ Register argument\n-      Register r = r_1->as_Register();\n-      if (r_2->is_valid()) {\n-        \/\/\n-        \/\/ We are using two VMRegs. This can be either T_OBJECT,\n-        \/\/ T_ADDRESS, T_LONG, or T_DOUBLE the interpreter allocates\n-        \/\/ two slots but only uses one for thr T_LONG or T_DOUBLE case\n-        \/\/ So we must adjust where to pick up the data to match the\n-        \/\/ interpreter.\n+         __ str(rscratch2, Address(sp, st_off));\n+       }\n+     } else if (r_1->is_Register()) {  \/\/ Register argument\n+       Register r = r_1->as_Register();\n+       if (r_2->is_valid()) {\n+         \/\/\n+         \/\/ We are using two VMRegs. This can be either T_OBJECT,\n+         \/\/ T_ADDRESS, T_LONG, or T_DOUBLE the interpreter allocates\n+         \/\/ two slots but only uses one for thr T_LONG or T_DOUBLE case\n+         \/\/ So we must adjust where to pick up the data to match the\n+         \/\/ interpreter.\n+\n+        const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : ld_off;\n+\n+         \/\/ this can be a misaligned move\n+         __ ldr(r, Address(esp, offset));\n+       } else {\n+         \/\/ sign extend and use a full word?\n+         __ ldrw(r, Address(esp, ld_off));\n+       }\n+     } else {\n+       if (!r_2->is_valid()) {\n+         __ ldrs(r_1->as_FloatRegister(), Address(esp, ld_off));\n+       } else {\n+         __ ldrd(r_1->as_FloatRegister(), Address(esp, next_off));\n+       }\n+     }\n+   }\n@@ -667,17 +904,0 @@\n-        const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n-                           next_off : ld_off;\n-\n-        \/\/ this can be a misaligned move\n-        __ ldr(r, Address(esp, offset));\n-      } else {\n-        \/\/ sign extend and use a full word?\n-        __ ldrw(r, Address(esp, ld_off));\n-      }\n-    } else {\n-      if (!r_2->is_valid()) {\n-        __ ldrs(r_1->as_FloatRegister(), Address(esp, ld_off));\n-      } else {\n-        __ ldrd(r_1->as_FloatRegister(), Address(esp, next_off));\n-      }\n-    }\n-  }\n@@ -696,1 +916,0 @@\n-\n@@ -700,13 +919,1 @@\n-\/\/ ---------------------------------------------------------------\n-AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler *masm,\n-                                                            int total_args_passed,\n-                                                            int comp_args_on_stack,\n-                                                            const BasicType *sig_bt,\n-                                                            const VMRegPair *regs,\n-                                                            AdapterFingerPrint* fingerprint) {\n-  address i2c_entry = __ pc();\n-\n-  gen_i2c_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs);\n-\n-  address c2i_unverified_entry = __ pc();\n-  Label skip_fixup;\n+static void gen_inline_cache_check(MacroAssembler *masm, Label& skip_fixup) {\n@@ -747,0 +954,33 @@\n+}\n+\n+\n+\/\/ ---------------------------------------------------------------\n+AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler *masm,\n+                                                            int comp_args_on_stack,\n+                                                            const GrowableArray<SigEntry>* sig,\n+                                                            const VMRegPair* regs,\n+                                                            const GrowableArray<SigEntry>* sig_cc,\n+                                                            const VMRegPair* regs_cc,\n+                                                            const GrowableArray<SigEntry>* sig_cc_ro,\n+                                                            const VMRegPair* regs_cc_ro,\n+                                                            AdapterFingerPrint* fingerprint,\n+                                                            AdapterBlob*& new_adapter) {\n+\n+  address i2c_entry = __ pc();\n+  gen_i2c_adapter(masm, comp_args_on_stack, sig, regs);\n+\n+  address c2i_unverified_entry = __ pc();\n+  Label skip_fixup;\n+\n+  gen_inline_cache_check(masm, skip_fixup);\n+\n+  OopMapSet* oop_maps = new OopMapSet();\n+  int frame_complete = CodeOffsets::frame_never_safe;\n+  int frame_size_in_words = 0;\n+\n+  \/\/ Scalarized c2i adapter with non-scalarized receiver (i.e., don't pack receiver)\n+  address c2i_inline_ro_entry = __ pc();\n+  if (regs_cc != regs_cc_ro) {\n+    gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);\n+    skip_fixup.reset();\n+  }\n@@ -748,0 +988,1 @@\n+  \/\/ Scalarized c2i adapter\n@@ -772,1 +1013,14 @@\n-  gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);\n+  gen_c2i_adapter(masm, sig_cc, regs_cc, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, true);\n+\n+  address c2i_unverified_inline_entry = c2i_unverified_entry;\n+\n+  \/\/ Non-scalarized c2i adapter\n+  address c2i_inline_entry = c2i_entry;\n+  if (regs != regs_cc) {\n+    Label inline_entry_skip_fixup;\n+    c2i_unverified_inline_entry = __ pc();\n+    gen_inline_cache_check(masm, inline_entry_skip_fixup);\n+\n+    c2i_inline_entry = __ pc();\n+    gen_c2i_adapter(masm, sig, regs, inline_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);\n+  }\n@@ -775,1 +1029,8 @@\n-  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+\n+  \/\/ The c2i adapter might safepoint and trigger a GC. The caller must make sure that\n+  \/\/ the GC knows about the location of oop argument locations passed to the c2i adapter.\n+\n+  bool caller_must_gc_arguments = (regs != regs_cc);\n+  new_adapter = AdapterBlob::create(masm->code(), frame_complete, frame_size_in_words + 10, oop_maps, caller_must_gc_arguments);\n+\n+  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry, c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -823,0 +1084,1 @@\n+      case T_INLINE_TYPE:\n@@ -1656,0 +1918,1 @@\n+      case T_INLINE_TYPE:\n@@ -1778,0 +2041,5 @@\n+    if (EnableValhalla) {\n+      assert(!UseBiasedLocking, \"Not compatible with biased-locking\");\n+      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+      __ andr(swap_reg, swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+    }\n@@ -1843,0 +2111,1 @@\n+  case T_INLINE_TYPE:           \/\/ Really a handle\n@@ -3092,0 +3361,115 @@\n+#endif \/\/ COMPILER2\n+\n+BufferedInlineTypeBlob* SharedRuntime::generate_buffered_inline_type_adapter(const InlineKlass* vk) {\n+  BufferBlob* buf = BufferBlob::create(\"inline types pack\/unpack\", 16 * K);\n+  CodeBuffer buffer(buf);\n+  short buffer_locs[20];\n+  buffer.insts()->initialize_shared_locs((relocInfo*)buffer_locs,\n+                                         sizeof(buffer_locs)\/sizeof(relocInfo));\n+\n+  MacroAssembler _masm(&buffer);\n+  MacroAssembler* masm = &_masm;\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  int pack_fields_jobject_off = __ offset();\n+  \/\/ Resolve pre-allocated buffer from JNI handle.\n+  \/\/ We cannot do this in generate_call_stub() because it requires GC code to be initialized.\n+  __ ldr(r0, Address(r13, 0));\n+  __ resolve_jobject(r0 \/* value *\/,\n+                     rthread \/* thread *\/,\n+                     r12 \/* tmp *\/);\n+  __ str(r0, Address(r13, 0));\n+\n+  int pack_fields_off = __ offset();\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    VMRegPair pair = regs->at(j);\n+    VMReg r_1 = pair.first();\n+    VMReg r_2 = pair.second();\n+    Address to(r0, off);\n+    if (bt == T_FLOAT) {\n+      __ strs(r_1->as_FloatRegister(), to);\n+    } else if (bt == T_DOUBLE) {\n+      __ strd(r_1->as_FloatRegister(), to);\n+    } else if (bt == T_OBJECT || bt == T_ARRAY) {\n+      Register val = r_1->as_Register();\n+      assert_different_registers(r0, val);\n+      \/\/ We don't need barriers because the destination is a newly allocated object.\n+      \/\/ Also, we cannot use store_heap_oop(to, val) because it uses r8 as tmp.\n+      if (UseCompressedOops) {\n+        __ encode_heap_oop(val);\n+        __ str(val, to);\n+      } else {\n+        __ str(val, to);\n+      }\n+    } else {\n+      assert(is_java_primitive(bt), \"unexpected basic type\");\n+      assert_different_registers(r0, r_1->as_Register());\n+      size_t size_in_bytes = type2aelembytes(bt);\n+      __ store_sized_value(to, r_1->as_Register(), size_in_bytes);\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+  __ ret(lr);\n+\n+  int unpack_fields_off = __ offset();\n+\n+  j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    VMRegPair pair = regs->at(j);\n+    VMReg r_1 = pair.first();\n+    VMReg r_2 = pair.second();\n+    Address from(r0, off);\n+    if (bt == T_FLOAT) {\n+      __ ldrs(r_1->as_FloatRegister(), from);\n+    } else if (bt == T_DOUBLE) {\n+      __ ldrd(r_1->as_FloatRegister(), from);\n+    } else if (bt == T_OBJECT || bt == T_ARRAY) {\n+       assert_different_registers(r0, r_1->as_Register());\n+       __ load_heap_oop(r_1->as_Register(), from);\n+    } else {\n+      assert(is_java_primitive(bt), \"unexpected basic type\");\n+      assert_different_registers(r0, r_1->as_Register());\n+\n+      size_t size_in_bytes = type2aelembytes(bt);\n+      __ load_sized_value(r_1->as_Register(), from, size_in_bytes, bt != T_CHAR && bt != T_BOOLEAN);\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+  __ ret(lr);\n+\n+  __ flush();\n+\n+  return BufferedInlineTypeBlob::create(&buffer, pack_fields_off, pack_fields_jobject_off, unpack_fields_off);\n+}\n@@ -3344,1 +3728,0 @@\n-#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":529,"deletions":146,"binary":false,"changes":675,"status":"modified"},{"patch":"@@ -312,1 +312,1 @@\n-    \/\/ T_OBJECT, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n+    \/\/ T_OBJECT, T_INLINE_TYPE, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n@@ -316,1 +316,1 @@\n-    Label is_long, is_float, is_double, exit;\n+    Label is_long, is_float, is_double, is_value, exit;\n@@ -320,0 +320,2 @@\n+    __ cmp(j_rarg1, (u1)T_INLINE_TYPE);\n+    __ br(Assembler::EQ, is_value);\n@@ -374,0 +376,13 @@\n+    __ BIND(is_value);\n+    if (InlineTypeReturnedAsFields) {\n+      \/\/ Check for flattened return value\n+      __ cbz(r0, is_long);\n+      \/\/ Initialize pre-allocated buffer\n+      __ mov(r1, r0);\n+      __ andr(r1, r1, -2);\n+      __ ldr(r1, Address(r1, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      __ ldr(r1, Address(r1, InlineKlass::pack_handler_offset()));\n+      __ ldr(r0, Address(j_rarg2, 0));\n+      __ blr(r1);\n+      __ b(exit);\n+    }\n@@ -1846,1 +1861,1 @@\n-    __ store_heap_oop(__ post(to, UseCompressedOops ? 4 : 8), copied_oop, noreg, noreg, AS_RAW);  \/\/ store the oop\n+    __ store_heap_oop(__ post(to, UseCompressedOops ? 4 : 8), copied_oop, noreg, noreg, noreg, AS_RAW);  \/\/ store the oop\n@@ -2093,0 +2108,8 @@\n+    \/\/ Check for flat inline type array -> return -1\n+    __ tst(lh, Klass::_lh_array_tag_vt_value_bit_inplace);\n+    __ br(Assembler::NE, L_failed);\n+\n+    \/\/ Check for null-free (non-flat) inline type array -> handle as object array\n+    __ tst(lh, Klass::_lh_null_free_bit_inplace);\n+    __ br(Assembler::NE, L_failed);\n+\n@@ -6975,0 +6998,177 @@\n+  \/\/ Call here from the interpreter or compiled code to either load\n+  \/\/ multiple returned values from the inline type instance being\n+  \/\/ returned to registers or to store returned values to a newly\n+  \/\/ allocated inline type instance.\n+  address generate_return_value_stub(address destination, const char* name, bool has_res) {\n+\n+    \/\/ Information about frame layout at time of blocking runtime call.\n+    \/\/ Note that we only have to preserve callee-saved registers since\n+    \/\/ the compilers are responsible for supplying a continuation point\n+    \/\/ if they expect all registers to be preserved.\n+    \/\/ n.b. aarch64 asserts that frame::arg_reg_save_area_bytes == 0\n+    enum layout {\n+      rfp_off = 0, rfp_off2,\n+\n+      j_rarg7_off, j_rarg7_2,\n+      j_rarg6_off, j_rarg6_2,\n+      j_rarg5_off, j_rarg5_2,\n+      j_rarg4_off, j_rarg4_2,\n+      j_rarg3_off, j_rarg3_2,\n+      j_rarg2_off, j_rarg2_2,\n+      j_rarg1_off, j_rarg1_2,\n+      j_rarg0_off, j_rarg0_2,\n+\n+      j_farg0_off, j_farg0_2,\n+      j_farg1_off, j_farg1_2,\n+      j_farg2_off, j_farg2_2,\n+      j_farg3_off, j_farg3_2,\n+      j_farg4_off, j_farg4_2,\n+      j_farg5_off, j_farg5_2,\n+      j_farg6_off, j_farg6_2,\n+      j_farg7_off, j_farg7_2,\n+\n+      return_off, return_off2,\n+      framesize \/\/ inclusive of return address\n+    };\n+\n+    int insts_size = 512;\n+    int locs_size  = 64;\n+\n+    CodeBuffer code(name, insts_size, locs_size);\n+    OopMapSet* oop_maps  = new OopMapSet();\n+    MacroAssembler* masm = new MacroAssembler(&code);\n+\n+    address start = __ pc();\n+\n+    const Address f7_save       (rfp, j_farg7_off * wordSize);\n+    const Address f6_save       (rfp, j_farg6_off * wordSize);\n+    const Address f5_save       (rfp, j_farg5_off * wordSize);\n+    const Address f4_save       (rfp, j_farg4_off * wordSize);\n+    const Address f3_save       (rfp, j_farg3_off * wordSize);\n+    const Address f2_save       (rfp, j_farg2_off * wordSize);\n+    const Address f1_save       (rfp, j_farg1_off * wordSize);\n+    const Address f0_save       (rfp, j_farg0_off * wordSize);\n+\n+    const Address r0_save      (rfp, j_rarg0_off * wordSize);\n+    const Address r1_save      (rfp, j_rarg1_off * wordSize);\n+    const Address r2_save      (rfp, j_rarg2_off * wordSize);\n+    const Address r3_save      (rfp, j_rarg3_off * wordSize);\n+    const Address r4_save      (rfp, j_rarg4_off * wordSize);\n+    const Address r5_save      (rfp, j_rarg5_off * wordSize);\n+    const Address r6_save      (rfp, j_rarg6_off * wordSize);\n+    const Address r7_save      (rfp, j_rarg7_off * wordSize);\n+\n+    \/\/ Generate oop map\n+    OopMap* map = new OopMap(framesize, 0);\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(rfp_off), rfp->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg7_off), j_rarg7->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg6_off), j_rarg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+    \/\/ This is an inlined and slightly modified version of call_VM\n+    \/\/ which has the ability to fetch the return PC out of\n+    \/\/ thread-local storage and also sets up last_Java_sp slightly\n+    \/\/ differently than the real call_VM\n+\n+    __ enter(); \/\/ Save FP and LR before call\n+\n+    assert(is_even(framesize\/2), \"sp not 16-byte aligned\");\n+\n+    \/\/ lr and fp are already in place\n+    __ sub(sp, rfp, ((unsigned)framesize - 4) << LogBytesPerInt); \/\/ prolog\n+\n+    __ strd(j_farg7, f7_save);\n+    __ strd(j_farg6, f6_save);\n+    __ strd(j_farg5, f5_save);\n+    __ strd(j_farg4, f4_save);\n+    __ strd(j_farg3, f3_save);\n+    __ strd(j_farg2, f2_save);\n+    __ strd(j_farg1, f1_save);\n+    __ strd(j_farg0, f0_save);\n+\n+    __ str(j_rarg0, r0_save);\n+    __ str(j_rarg1, r1_save);\n+    __ str(j_rarg2, r2_save);\n+    __ str(j_rarg3, r3_save);\n+    __ str(j_rarg4, r4_save);\n+    __ str(j_rarg5, r5_save);\n+    __ str(j_rarg6, r6_save);\n+    __ str(j_rarg7, r7_save);\n+\n+    int frame_complete = __ pc() - start;\n+\n+    \/\/ Set up last_Java_sp and last_Java_fp\n+    address the_pc = __ pc();\n+    __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n+\n+    \/\/ Call runtime\n+    __ mov(c_rarg0, rthread);\n+    __ mov(c_rarg1, r0);\n+\n+    BLOCK_COMMENT(\"call runtime_entry\");\n+    __ mov(rscratch1, destination);\n+    __ blr(rscratch1);\n+\n+    oop_maps->add_gc_map(the_pc - start, map);\n+\n+    __ reset_last_Java_frame(false);\n+\n+    __ ldrd(j_farg7, f7_save);\n+    __ ldrd(j_farg6, f6_save);\n+    __ ldrd(j_farg5, f5_save);\n+    __ ldrd(j_farg4, f4_save);\n+    __ ldrd(j_farg3, f3_save);\n+    __ ldrd(j_farg3, f2_save);\n+    __ ldrd(j_farg1, f1_save);\n+    __ ldrd(j_farg0, f0_save);\n+\n+    __ ldr(j_rarg0, r0_save);\n+    __ ldr(j_rarg1, r1_save);\n+    __ ldr(j_rarg2, r2_save);\n+    __ ldr(j_rarg3, r3_save);\n+    __ ldr(j_rarg4, r4_save);\n+    __ ldr(j_rarg5, r5_save);\n+    __ ldr(j_rarg6, r6_save);\n+    __ ldr(j_rarg7, r7_save);\n+\n+    __ leave();\n+\n+    \/\/ check for pending exceptions\n+    Label pending;\n+    __ ldr(rscratch1, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    __ cmp(rscratch1, (u1)NULL_WORD);\n+    __ br(Assembler::NE, pending);\n+\n+    if (has_res) {\n+      __ get_vm_result(r0, rthread);\n+    }\n+    __ ret(lr);\n+\n+    __ bind(pending);\n+    __ ldr(r0, Address(rthread, in_bytes(Thread::pending_exception_offset())));\n+    __ far_jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+\n+    \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n+    int frame_size_in_words = (framesize >> (LogBytesPerWord - LogBytesPerInt));\n+    RuntimeStub* stub =\n+      RuntimeStub::new_runtime_stub(name, &code, frame_complete, frame_size_in_words, oop_maps, false);\n+\n+    return stub->entry_point();\n+  }\n+\n@@ -7025,0 +7225,7 @@\n+    if (InlineTypeReturnedAsFields) {\n+      StubRoutines::_load_inline_type_fields_in_regs =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), \"load_inline_type_fields_in_regs\", false);\n+      StubRoutines::_store_inline_type_fields_to_buf =\n+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), \"store_inline_type_fields_to_buf\", true);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":210,"deletions":3,"binary":false,"changes":213,"status":"modified"},{"patch":"@@ -148,1 +148,1 @@\n-  __ store_heap_oop(dst, val, r10, r1, decorators);\n+  __ store_heap_oop(dst, val, r10, r1, noreg, decorators);\n@@ -171,0 +171,1 @@\n+  case Bytecodes::_fast_qputfield:\n@@ -330,0 +331,1 @@\n+  __ andr(r3, r3, ~JVM_CONSTANT_QDescBit);\n@@ -747,4 +749,4 @@\n-    \/\/ ??? convention: move array into r3 for exception message\n-  __ mov(r3, array);\n-  __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);\n-  __ br(rscratch1);\n+  \/\/ ??? convention: move array into r3 for exception message\n+   __ mov(r3, array);\n+   __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);\n+   __ br(rscratch1);\n@@ -810,5 +812,17 @@\n-  __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);\n-  do_oop_load(_masm,\n-              Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)),\n-              r0,\n-              IS_ARRAY);\n+  __ profile_array(r2, r0, r4);\n+  if (UseFlatArray) {\n+    Label is_flat_array, done;\n+\n+    __ test_flattened_array_oop(r0, r8 \/*temp*\/, is_flat_array);\n+    __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);\n+    do_oop_load(_masm, Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)), r0, IS_ARRAY);\n+\n+    __ b(done);\n+    __ bind(is_flat_array);\n+    __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::value_array_load), r0, r1);\n+    __ bind(done);\n+  } else {\n+    __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);\n+    do_oop_load(_masm, Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)), r0, IS_ARRAY);\n+  }\n+  __ profile_element(r2, r0, r4);\n@@ -1101,1 +1115,1 @@\n-  Label is_null, ok_is_subtype, done;\n+  Label is_null, is_flat_array, ok_is_subtype, done;\n@@ -1108,2 +1122,4 @@\n-  Address element_address(r3, r4, Address::uxtw(LogBytesPerHeapOop));\n-\n+\n+  __ profile_array(r4, r3, r5);\n+  __ profile_element(r4, r0, r5);\n+\n@@ -1112,0 +1128,2 @@\n+  Address element_address(r3, r4, Address::uxtw(LogBytesPerHeapOop));\n+  \/\/ Be careful not to clobber r4 below\n@@ -1116,0 +1134,8 @@\n+  \/\/ Move array class to r5\n+  __ load_klass(r5, r3);\n+\n+  if (UseFlatArray) {\n+    __ ldrw(r6, Address(r5, Klass::layout_helper_offset()));\n+    __ test_flattened_array_layout(r6, is_flat_array);\n+  }\n+\n@@ -1118,4 +1144,3 @@\n-  \/\/ Move superklass into r0\n-  __ load_klass(r0, r3);\n-  __ ldr(r0, Address(r0,\n-                     ObjArrayKlass::element_klass_offset()));\n+\n+  \/\/ Move array element superklass into r0\n+  __ ldr(r0, Address(r5, ObjArrayKlass::element_klass_offset()));\n@@ -1126,1 +1151,3 @@\n-  __ gen_subtype_check(r1, ok_is_subtype);\n+\n+  \/\/ is \"r1 <: r0\" ? (value subclass <: array element superclass)\n+  __ gen_subtype_check(r1, ok_is_subtype, false);\n@@ -1143,1 +1170,12 @@\n-  __ profile_null_seen(r2);\n+  if (EnableValhalla) {\n+    Label is_null_into_value_array_npe, store_null;\n+\n+    \/\/ No way to store null in flat null-free array\n+    __ test_null_free_array_oop(r3, r8, is_null_into_value_array_npe);\n+    __ b(store_null);\n+\n+    __ bind(is_null_into_value_array_npe);\n+    __ b(ExternalAddress(Interpreter::_throw_NullPointerException_entry));\n+\n+    __ bind(store_null);\n+  }\n@@ -1147,0 +1185,41 @@\n+  __ b(done);\n+\n+  if (EnableValhalla) {\n+     Label is_type_ok;\n+    __ bind(is_flat_array); \/\/ Store non-null value to flat\n+\n+    \/\/ Simplistic type check...\n+    \/\/ r0 - value, r2 - index, r3 - array.\n+\n+    \/\/ Profile the not-null value's klass.\n+    \/\/ Load value class\n+     __ load_klass(r1, r0);\n+\n+    \/\/ Move element klass into r7\n+     __ ldr(r7, Address(r5, ArrayKlass::element_klass_offset()));\n+\n+    \/\/ flat value array needs exact type match\n+    \/\/ is \"r1 == r7\" (value subclass == array element superclass)\n+\n+     __ cmp(r7, r1);\n+     __ br(Assembler::EQ, is_type_ok);\n+\n+     __ b(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));\n+\n+     __ bind(is_type_ok);\n+    \/\/ r1: value's klass\n+    \/\/ r3: array\n+    \/\/ r5: array klass\n+    __ test_klass_is_empty_inline_type(r1, r7, done);\n+\n+    \/\/ calc dst for copy\n+    __ ldrw(r7, at_tos_p1()); \/\/ index\n+    __ data_for_value_array_index(r3, r5, r7, r7);\n+\n+    \/\/ ...and src for copy\n+    __ ldr(r6, at_tos());  \/\/ value\n+    __ data_for_oop(r6, r6, r1);\n+\n+    __ mov(r4, r1);  \/\/ Shuffle arguments to avoid conflict with c_rarg1\n+    __ access_value_copy(IN_HEAP, r6, r7, r4);\n+  }\n@@ -1957,2 +2036,1 @@\n-void TemplateTable::if_acmp(Condition cc)\n-{\n+void TemplateTable::if_acmp(Condition cc) {\n@@ -1961,1 +2039,1 @@\n-  Label not_taken;\n+  Label taken, not_taken;\n@@ -1963,0 +2041,38 @@\n+\n+  __ profile_acmp(r2, r1, r0, r4);\n+\n+  Register is_inline_type_mask = rscratch1;\n+  __ mov(is_inline_type_mask, markWord::inline_type_pattern);\n+\n+  if (EnableValhalla) {\n+    __ cmp(r1, r0);\n+    __ br(Assembler::EQ, (cc == equal) ? taken : not_taken);\n+\n+    \/\/ might be substitutable, test if either r0 or r1 is null\n+    __ andr(r2, r0, r1);\n+    __ cbz(r2, (cc == equal) ? not_taken : taken);\n+\n+    \/\/ and both are values ?\n+    __ ldr(r2, Address(r1, oopDesc::mark_offset_in_bytes()));\n+    __ andr(r2, r2, is_inline_type_mask);\n+    __ ldr(r4, Address(r0, oopDesc::mark_offset_in_bytes()));\n+    __ andr(r4, r4, is_inline_type_mask);\n+    __ andr(r2, r2, r4);\n+    __ cmp(r2,  is_inline_type_mask);\n+    __ br(Assembler::NE, (cc == equal) ? not_taken : taken);\n+\n+    \/\/ same value klass ?\n+    __ load_metadata(r2, r1);\n+    __ load_metadata(r4, r0);\n+    __ cmp(r2, r4);\n+    __ br(Assembler::NE, (cc == equal) ? not_taken : taken);\n+\n+    \/\/ Know both are the same type, let's test for substitutability...\n+    if (cc == equal) {\n+      invoke_is_substitutable(r0, r1, taken, not_taken);\n+    } else {\n+      invoke_is_substitutable(r0, r1, not_taken, taken);\n+    }\n+    __ stop(\"Not reachable\");\n+  }\n+\n@@ -1965,0 +2081,1 @@\n+  __ bind(taken);\n@@ -1967,1 +2084,1 @@\n-  __ profile_not_taken_branch(r0);\n+  __ profile_not_taken_branch(r0, true);\n@@ -1970,0 +2087,10 @@\n+void TemplateTable::invoke_is_substitutable(Register aobj, Register bobj,\n+                                            Label& is_subst, Label& not_subst) {\n+\n+  __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::is_substitutable), aobj, bobj);\n+  \/\/ Restored... r0 answer, jmp to outcome...\n+  __ cbz(r0, not_subst);\n+  __ b(is_subst);\n+}\n+\n+\n@@ -2307,1 +2434,1 @@\n-                                          ConstantPoolCacheEntry::f2_offset())));\n+                                      ConstantPoolCacheEntry::f2_offset())));\n@@ -2310,1 +2437,1 @@\n-                                           ConstantPoolCacheEntry::flags_offset())));\n+                                         ConstantPoolCacheEntry::flags_offset())));\n@@ -2408,0 +2535,2 @@\n+  const Register klass = r5;\n+  const Register inline_klass = r7;\n@@ -2440,0 +2569,5 @@\n+  if (!is_static) {\n+    __ ldr(klass, Address(cache, in_bytes(ConstantPoolCache::base_offset() +\n+                                          ConstantPoolCacheEntry::f1_offset())));\n+  }\n+\n@@ -2442,2 +2576,1 @@\n-  __ ubfxw(flags, raw_flags, ConstantPoolCacheEntry::tos_state_shift,\n-           ConstantPoolCacheEntry::tos_state_bits);\n+  __ ubfxw(flags, raw_flags, ConstantPoolCacheEntry::tos_state_shift, ConstantPoolCacheEntry::tos_state_bits);\n@@ -2478,4 +2611,70 @@\n-  do_oop_load(_masm, field, r0, IN_HEAP);\n-  __ push(atos);\n-  if (rc == may_rewrite) {\n-    patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);\n+  if (!EnableValhalla) {\n+    do_oop_load(_masm, field, r0, IN_HEAP);\n+    __ push(atos);\n+    if (rc == may_rewrite) {\n+      patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);\n+    }\n+    __ b(Done);\n+  } else { \/\/ Valhalla\n+    if (is_static) {\n+      __ load_heap_oop(r0, field);\n+      Label is_inline_type, uninitialized;\n+      \/\/ Issue below if the static field has not been initialized yet\n+      __ test_field_is_inline_type(raw_flags, noreg \/*temp*\/, is_inline_type);\n+        \/\/ field is not an inline type\n+        __ push(atos);\n+        __ b(Done);\n+      \/\/ field is an inline type, must not return null even if uninitialized\n+      __ bind(is_inline_type);\n+        __ cbz(r0, uninitialized);\n+          __ push(atos);\n+          __ b(Done);\n+        __ bind(uninitialized);\n+          __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);\n+          Label slow_case, finish;\n+          __ ldrb(rscratch1, Address(cache, InstanceKlass::init_state_offset()));\n+          __ cmp(rscratch1, (u1)InstanceKlass::fully_initialized);\n+          __ br(Assembler::NE, slow_case);\n+          __ get_default_value_oop(klass, off \/* temp *\/, r0);\n+        __ b(finish);\n+        __ bind(slow_case);\n+          __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_static_inline_type_field), obj, raw_flags);\n+          __ bind(finish);\n+          __ verify_oop(r0);\n+          __ push(atos);\n+          __ b(Done);\n+    } else {\n+      Label is_inlined, nonnull, is_inline_type, rewrite_inline;\n+      __ test_field_is_inline_type(raw_flags, noreg \/*temp*\/, is_inline_type);\n+        \/\/ Non-inline field case\n+        __ load_heap_oop(r0, field);\n+        __ push(atos);\n+        if (rc == may_rewrite) {\n+          patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);\n+        }\n+        __ b(Done);\n+      __ bind(is_inline_type);\n+        __ test_field_is_inlined(raw_flags, noreg \/* temp *\/, is_inlined);\n+         \/\/ field is not inlined\n+          __ load_heap_oop(r0, field);\n+          __ cbnz(r0, nonnull);\n+            __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);\n+            __ get_inline_type_field_klass(klass, raw_flags, inline_klass);\n+            __ get_default_value_oop(inline_klass, klass \/* temp *\/, r0);\n+          __ bind(nonnull);\n+          __ verify_oop(r0);\n+          __ push(atos);\n+          __ b(rewrite_inline);\n+        __ bind(is_inlined);\n+        \/\/ field is inlined\n+          __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);\n+          __ mov(r0, obj);\n+          __ read_inlined_field(klass, raw_flags, off, inline_klass \/* temp *\/, r0);\n+          __ verify_oop(r0);\n+          __ push(atos);\n+      __ bind(rewrite_inline);\n+      if (rc == may_rewrite) {\n+        patch_bytecode(Bytecodes::_fast_qgetfield, bc, r1);\n+      }\n+      __ b(Done);\n+    }\n@@ -2483,1 +2682,0 @@\n-  __ b(Done);\n@@ -2653,0 +2851,1 @@\n+  const Register flags2 = r6;\n@@ -2654,0 +2853,1 @@\n+  const Register inline_klass = r5;\n@@ -2675,0 +2875,2 @@\n+  __ mov(flags2, flags);\n+\n@@ -2717,8 +2919,54 @@\n-    __ pop(atos);\n-    if (!is_static) pop_and_check_object(obj);\n-    \/\/ Store into the field\n-    do_oop_store(_masm, field, r0, IN_HEAP);\n-    if (rc == may_rewrite) {\n-      patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);\n-    }\n-    __ b(Done);\n+     if (!EnableValhalla) {\n+      __ pop(atos);\n+      if (!is_static) pop_and_check_object(obj);\n+      \/\/ Store into the field\n+      do_oop_store(_masm, field, r0, IN_HEAP);\n+      if (rc == may_rewrite) {\n+        patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);\n+      }\n+      __ b(Done);\n+     } else { \/\/ Valhalla\n+      __ pop(atos);\n+      if (is_static) {\n+        Label is_inline_type;\n+         __ test_field_is_not_inline_type(flags2, noreg \/* temp *\/, is_inline_type);\n+         __ null_check(r0);\n+         __ bind(is_inline_type);\n+         do_oop_store(_masm, field, r0, IN_HEAP);\n+         __ b(Done);\n+      } else {\n+        Label is_inline_type, is_inlined, rewrite_not_inline, rewrite_inline;\n+        __ test_field_is_inline_type(flags2, noreg \/*temp*\/, is_inline_type);\n+        \/\/ Not an inline type\n+        pop_and_check_object(obj);\n+        \/\/ Store into the field\n+        do_oop_store(_masm, field, r0, IN_HEAP);\n+        __ bind(rewrite_not_inline);\n+        if (rc == may_rewrite) {\n+          patch_bytecode(Bytecodes::_fast_aputfield, bc, r19, true, byte_no);\n+        }\n+        __ b(Done);\n+        \/\/ Implementation of the inline type semantic\n+        __ bind(is_inline_type);\n+        __ null_check(r0);\n+        __ test_field_is_inlined(flags2, noreg \/*temp*\/, is_inlined);\n+        \/\/ field is not inlined\n+        pop_and_check_object(obj);\n+        \/\/ Store into the field\n+        do_oop_store(_masm, field, r0, IN_HEAP);\n+        __ b(rewrite_inline);\n+        __ bind(is_inlined);\n+        \/\/ field is inlined\n+        pop_and_check_object(obj);\n+        assert_different_registers(r0, inline_klass, obj, off);\n+        __ load_klass(inline_klass, r0);\n+        __ data_for_oop(r0, r0, inline_klass);\n+        __ add(obj, obj, off);\n+        __ access_value_copy(IN_HEAP, r0, obj, inline_klass);\n+        __ bind(rewrite_inline);\n+        if (rc == may_rewrite) {\n+          patch_bytecode(Bytecodes::_fast_qputfield, bc, r19, true, byte_no);\n+        }\n+        __ b(Done);\n+      }\n+     }  \/\/ Valhalla\n@@ -2864,0 +3112,1 @@\n+    case Bytecodes::_fast_qputfield: \/\/fall through\n@@ -2890,0 +3139,1 @@\n+    case Bytecodes::_fast_qputfield: \/\/fall through\n@@ -2943,0 +3193,17 @@\n+  case Bytecodes::_fast_qputfield: \/\/fall through\n+   {\n+      Label is_inlined, done;\n+      __ null_check(r0);\n+      __ test_field_is_inlined(r3, noreg \/* temp *\/, is_inlined);\n+      \/\/ field is not inlined\n+      do_oop_store(_masm, field, r0, IN_HEAP);\n+      __ b(done);\n+      __ bind(is_inlined);\n+      \/\/ field is inlined\n+      __ load_klass(r4, r0);\n+      __ data_for_oop(r0, r0, r4);\n+      __ lea(rscratch1, field);\n+      __ access_value_copy(IN_HEAP, r0, rscratch1, r4);\n+      __ bind(done);\n+    }\n+    break;\n@@ -3040,0 +3307,26 @@\n+  case Bytecodes::_fast_qgetfield:\n+    {\n+      Register index = r4, klass = r5, inline_klass = r6;\n+      Label is_inlined, nonnull, Done;\n+      __ test_field_is_inlined(r3, noreg \/* temp *\/, is_inlined);\n+        \/\/ field is not inlined\n+        __ load_heap_oop(r0, field);\n+        __ cbnz(r0, nonnull);\n+          __ andw(index, r3, ConstantPoolCacheEntry::field_index_mask);\n+          __ ldr(klass, Address(r2, in_bytes(ConstantPoolCache::base_offset() +\n+                                             ConstantPoolCacheEntry::f1_offset())));\n+          __ get_inline_type_field_klass(klass, index, inline_klass);\n+          __ get_default_value_oop(inline_klass, rscratch1 \/* temp *\/, r0);\n+        __ bind(nonnull);\n+        __ verify_oop(r0);\n+        __ b(Done);\n+      __ bind(is_inlined);\n+      \/\/ field is inlined\n+        __ andw(index, r3, ConstantPoolCacheEntry::field_index_mask);\n+        __ ldr(klass, Address(r2, in_bytes(ConstantPoolCache::base_offset() +\n+                                           ConstantPoolCacheEntry::f1_offset())));\n+        __ read_inlined_field(klass, index, r1, inline_klass \/* temp *\/, r0);\n+        __ verify_oop(r0);\n+      __ bind(Done);\n+    }\n+    break;\n@@ -3470,0 +3763,1 @@\n+  Label is_not_value;\n@@ -3487,0 +3781,8 @@\n+  __ ldrb(rscratch1, Address(r4, InstanceKlass::kind_offset()));\n+  __ cmp(rscratch1, (u1)InstanceKlass::_kind_inline_type);\n+  __ br(Assembler::NE, is_not_value);\n+\n+  __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::throw_InstantiationError));\n+\n+  __ bind(is_not_value);\n+\n@@ -3493,83 +3795,2 @@\n-  \/\/ get instance_size in InstanceKlass (scaled to a count of bytes)\n-  __ ldrw(r3,\n-          Address(r4,\n-                  Klass::layout_helper_offset()));\n-  \/\/ test to see if it has a finalizer or is malformed in some way\n-  __ tbnz(r3, exact_log2(Klass::_lh_instance_slow_path_bit), slow_case);\n-\n-  \/\/ Allocate the instance:\n-  \/\/  If TLAB is enabled:\n-  \/\/    Try to allocate in the TLAB.\n-  \/\/    If fails, go to the slow path.\n-  \/\/  Else If inline contiguous allocations are enabled:\n-  \/\/    Try to allocate in eden.\n-  \/\/    If fails due to heap end, go to slow path.\n-  \/\/\n-  \/\/  If TLAB is enabled OR inline contiguous is enabled:\n-  \/\/    Initialize the allocation.\n-  \/\/    Exit.\n-  \/\/\n-  \/\/  Go to slow path.\n-  const bool allow_shared_alloc =\n-    Universe::heap()->supports_inline_contig_alloc();\n-\n-  if (UseTLAB) {\n-    __ tlab_allocate(r0, r3, 0, noreg, r1, slow_case);\n-\n-    if (ZeroTLAB) {\n-      \/\/ the fields have been already cleared\n-      __ b(initialize_header);\n-    } else {\n-      \/\/ initialize both the header and fields\n-      __ b(initialize_object);\n-    }\n-  } else {\n-    \/\/ Allocation in the shared Eden, if allowed.\n-    \/\/\n-    \/\/ r3: instance size in bytes\n-    if (allow_shared_alloc) {\n-      __ eden_allocate(r0, r3, 0, r10, slow_case);\n-    }\n-  }\n-\n-  \/\/ If UseTLAB or allow_shared_alloc are true, the object is created above and\n-  \/\/ there is an initialize need. Otherwise, skip and go to the slow path.\n-  if (UseTLAB || allow_shared_alloc) {\n-    \/\/ The object is initialized before the header.  If the object size is\n-    \/\/ zero, go directly to the header initialization.\n-    __ bind(initialize_object);\n-    __ sub(r3, r3, sizeof(oopDesc));\n-    __ cbz(r3, initialize_header);\n-\n-    \/\/ Initialize object fields\n-    {\n-      __ add(r2, r0, sizeof(oopDesc));\n-      Label loop;\n-      __ bind(loop);\n-      __ str(zr, Address(__ post(r2, BytesPerLong)));\n-      __ sub(r3, r3, BytesPerLong);\n-      __ cbnz(r3, loop);\n-    }\n-\n-    \/\/ initialize object header only.\n-    __ bind(initialize_header);\n-    if (UseBiasedLocking) {\n-      __ ldr(rscratch1, Address(r4, Klass::prototype_header_offset()));\n-    } else {\n-      __ mov(rscratch1, (intptr_t)markWord::prototype().value());\n-    }\n-    __ str(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n-    __ store_klass_gap(r0, zr);  \/\/ zero klass gap for compressed oops\n-    __ store_klass(r0, r4);      \/\/ store klass last\n-\n-    {\n-      SkipIfEqual skip(_masm, &DTraceAllocProbes, false);\n-      \/\/ Trigger dtrace event for fastpath\n-      __ push(atos); \/\/ save the return value\n-      __ call_VM_leaf(\n-           CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), r0);\n-      __ pop(atos); \/\/ restore the return value\n-\n-    }\n-    __ b(done);\n-  }\n+  __ allocate_instance(r4, r0, r3, r1, true, slow_case);\n+  __ b(done);\n@@ -3590,0 +3811,24 @@\n+void TemplateTable::defaultvalue() {\n+  transition(vtos, atos);\n+  __ get_unsigned_2_byte_index_at_bcp(c_rarg2, 1);\n+  __ get_constant_pool(c_rarg1);\n+  call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::defaultvalue),\n+          c_rarg1, c_rarg2);\n+  __ verify_oop(r0);\n+  \/\/ Must prevent reordering of stores for object initialization with stores that publish the new object.\n+  __ membar(Assembler::StoreStore);\n+}\n+\n+void TemplateTable::withfield() {\n+  transition(vtos, atos);\n+  resolve_cache_and_index(f2_byte, c_rarg1 \/*cache*\/, c_rarg2 \/*index*\/, sizeof(u2));\n+\n+  \/\/ n.b. unlike x86 cache is now rcpool plus the indexed offset\n+  \/\/ so using rcpool to meet shared code expectations\n+\n+  call_VM(r1, CAST_FROM_FN_PTR(address, InterpreterRuntime::withfield), rcpool);\n+  __ verify_oop(r1);\n+  __ add(esp, esp, r0);\n+  __ mov(r0, r1);\n+}\n+\n@@ -3630,0 +3875,1 @@\n+  __ andr(r1, r1, ~JVM_CONSTANT_QDescBit);\n@@ -3661,0 +3907,3 @@\n+  __ b(done);\n+  __ bind(is_null);\n+\n@@ -3663,4 +3912,16 @@\n-    __ b(done);\n-    __ bind(is_null);\n-  } else {\n-    __ bind(is_null);   \/\/ same as 'done'\n+\n+  if (EnableValhalla) {\n+    \/\/ Get cpool & tags index\n+    __ get_cpool_and_tags(r2, r3); \/\/ r2=cpool, r3=tags array\n+    __ get_unsigned_2_byte_index_at_bcp(r19, 1); \/\/ r19=index\n+     \/\/ See if bytecode has already been quicked\n+    __ add(rscratch1, r3, Array<u1>::base_offset_in_bytes());\n+    __ lea(r1, Address(rscratch1, r19));\n+    __ ldarb(r1, r1);\n+    \/\/ See if CP entry is a Q-descriptor\n+    __ andr (r1, r1, JVM_CONSTANT_QDescBit);\n+    __ cmp(r1, (u1) JVM_CONSTANT_QDescBit);\n+    __ br(Assembler::NE, done);\n+    __ b(ExternalAddress(Interpreter::_throw_NullPointerException_entry));\n+  }\n+\n@@ -3684,0 +3945,1 @@\n+  __ andr(r1, r1, ~JVM_CONSTANT_QDescBit);\n@@ -3789,0 +4051,4 @@\n+  Label is_inline_type;\n+  __ ldr(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n+  __ test_markword_is_inline_type(rscratch1, is_inline_type);\n+\n@@ -3878,0 +4144,5 @@\n+\n+  __ bind(is_inline_type);\n+  __ call_VM(noreg, CAST_FROM_FN_PTR(address,\n+                    InterpreterRuntime::throw_illegal_monitor_state_exception));\n+  __ should_not_reach_here();\n@@ -3890,0 +4161,12 @@\n+  const int is_inline_type_mask = markWord::inline_type_pattern;\n+  Label has_identity;\n+  __ ldr(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n+  __ mov(rscratch2, is_inline_type_mask);\n+  __ andr(rscratch1, rscratch1, rscratch2);\n+  __ cmp(rscratch1, rscratch2);\n+  __ br(Assembler::NE, has_identity);\n+  __ call_VM(noreg, CAST_FROM_FN_PTR(address,\n+                     InterpreterRuntime::throw_illegal_monitor_state_exception));\n+  __ should_not_reach_here();\n+  __ bind(has_identity);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":410,"deletions":127,"binary":false,"changes":537,"status":"modified"},{"patch":"@@ -2561,0 +2561,4 @@\n+void LIR_Assembler::emit_profile_inline_type(LIR_OpProfileInlineType* op) {\n+  Unimplemented();\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3200,0 +3200,3 @@\n+void LIR_Assembler::emit_profile_inline_type(LIR_OpProfileInlineType* op) {\n+  Unimplemented();\n+}\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1823,1 +1823,1 @@\n-        assert(ReturnTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(),\n+        assert(SingleTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(),\n@@ -1864,1 +1864,1 @@\n-    profile_obj_type(ret, R28_mdx, -in_bytes(ReturnTypeEntry::size()), tmp1, tmp2);\n+    profile_obj_type(ret, R28_mdx, -in_bytes(SingleTypeEntry::size()), tmp1, tmp2);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3086,0 +3086,4 @@\n+void LIR_Assembler::emit_profile_inline_type(LIR_OpProfileInlineType* op) {\n+  Unimplemented();\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRAssembler_s390.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -40,0 +41,1 @@\n+#include \"oops\/oop.inline.hpp\"\n@@ -198,1 +200,1 @@\n-    if (const_opr->type() == T_OBJECT) {\n+    if (const_opr->type() == T_OBJECT || const_opr->type() == T_INLINE_TYPE) {\n@@ -485,1 +487,2 @@\n-  __ remove_frame(initial_frame_size_in_bytes());\n+  int initial_framesize = initial_frame_size_in_bytes();\n+  __ remove_frame(initial_framesize, needs_stack_repair(), initial_framesize - wordSize);\n@@ -530,0 +533,17 @@\n+  ciMethod* method = compilation()->method();\n+  ciType* return_type = method->return_type();\n+  if (InlineTypeReturnedAsFields && return_type->is_inlinetype()) {\n+    ciInlineKlass* vk = return_type->as_inline_klass();\n+    if (vk->can_be_returned_as_fields()) {\n+#ifndef _LP64\n+      Unimplemented();\n+#else\n+      address unpack_handler = vk->unpack_handler();\n+      assert(unpack_handler != NULL, \"must be\");\n+      __ call(RuntimeAddress(unpack_handler));\n+      \/\/ At this point, rax points to the value object (for interpreter or C1 caller).\n+      \/\/ The fields of the object are copied into registers (for C2 caller).\n+#endif\n+    }\n+  }\n+\n@@ -531,1 +551,2 @@\n-  __ remove_frame(initial_frame_size_in_bytes());\n+  int initial_framesize = initial_frame_size_in_bytes();\n+  __ remove_frame(initial_framesize, needs_stack_repair(), initial_framesize - wordSize);\n@@ -553,0 +574,4 @@\n+int LIR_Assembler::store_inline_type_fields_to_buf(ciInlineKlass* vk) {\n+  return (__ store_inline_type_fields_to_buf(vk, false));\n+}\n+\n@@ -613,0 +638,1 @@\n+    case T_INLINE_TYPE: \/\/ Fall through\n@@ -703,0 +729,1 @@\n+    case T_INLINE_TYPE: \/\/ Fall through\n@@ -742,0 +769,1 @@\n+    case T_INLINE_TYPE: \/\/ fall through\n@@ -830,1 +858,1 @@\n-    if (src->type() == T_OBJECT) {\n+    if (src->type() == T_OBJECT || src->type() == T_INLINE_TYPE) {\n@@ -1016,0 +1044,1 @@\n+    case T_INLINE_TYPE: \/\/ fall through\n@@ -1189,1 +1218,1 @@\n-  if (addr->base()->type() == T_OBJECT) {\n+  if (addr->base()->type() == T_OBJECT || addr->base()->type() == T_INLINE_TYPE) {\n@@ -1250,0 +1279,1 @@\n+    case T_INLINE_TYPE: \/\/ fall through\n@@ -1636,1 +1666,1 @@\n-  if (UseSlowPath ||\n+  if (UseSlowPath || op->type() == T_INLINE_TYPE ||\n@@ -1735,14 +1765,16 @@\n-  __ cmpptr(obj, (int32_t)NULL_WORD);\n-  if (op->should_profile()) {\n-    Label not_null;\n-    __ jccb(Assembler::notEqual, not_null);\n-    \/\/ Object is null; update MDO and exit\n-    Register mdo  = klass_RInfo;\n-    __ mov_metadata(mdo, md->constant_encoding());\n-    Address data_addr(mdo, md->byte_offset_of_slot(data, DataLayout::flags_offset()));\n-    int header_bits = BitData::null_seen_byte_constant();\n-    __ orb(data_addr, header_bits);\n-    __ jmp(*obj_is_null);\n-    __ bind(not_null);\n-  } else {\n-    __ jcc(Assembler::equal, *obj_is_null);\n+  if (op->need_null_check()) {\n+    __ cmpptr(obj, (int32_t)NULL_WORD);\n+    if (op->should_profile()) {\n+      Label not_null;\n+      __ jccb(Assembler::notEqual, not_null);\n+      \/\/ Object is null; update MDO and exit\n+      Register mdo  = klass_RInfo;\n+      __ mov_metadata(mdo, md->constant_encoding());\n+      Address data_addr(mdo, md->byte_offset_of_slot(data, DataLayout::flags_offset()));\n+      int header_bits = BitData::null_seen_byte_constant();\n+      __ orb(data_addr, header_bits);\n+      __ jmp(*obj_is_null);\n+      __ bind(not_null);\n+    } else {\n+      __ jcc(Assembler::equal, *obj_is_null);\n+    }\n@@ -1960,0 +1992,124 @@\n+void LIR_Assembler::emit_opFlattenedArrayCheck(LIR_OpFlattenedArrayCheck* op) {\n+  \/\/ We are loading\/storing from\/to an array that *may* be flattened (the\n+  \/\/ declared type is Object[], abstract[], interface[] or VT.ref[]).\n+  \/\/ If this array is flattened, take the slow path.\n+  Register klass = op->tmp()->as_register();\n+  if (UseArrayMarkWordCheck) {\n+    __ test_flattened_array_oop(op->array()->as_register(), op->tmp()->as_register(), *op->stub()->entry());\n+  } else {\n+    Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+    __ load_klass(klass, op->array()->as_register(), tmp_load_klass);\n+    __ movl(klass, Address(klass, Klass::layout_helper_offset()));\n+    __ testl(klass, Klass::_lh_array_tag_vt_value_bit_inplace);\n+    __ jcc(Assembler::notZero, *op->stub()->entry());\n+  }\n+  if (!op->value()->is_illegal()) {\n+    \/\/ The array is not flattened, but it might be null-free. If we are storing\n+    \/\/ a null into a null-free array, take the slow path (which will throw NPE).\n+    Label skip;\n+    __ cmpptr(op->value()->as_register(), (int32_t)NULL_WORD);\n+    __ jcc(Assembler::notEqual, skip);\n+    if (UseArrayMarkWordCheck) {\n+      __ test_null_free_array_oop(op->array()->as_register(), op->tmp()->as_register(), *op->stub()->entry());\n+    } else {\n+      __ testl(klass, Klass::_lh_null_free_bit_inplace);\n+      __ jcc(Assembler::notZero, *op->stub()->entry());\n+    }\n+    __ bind(skip);\n+  }\n+}\n+\n+void LIR_Assembler::emit_opNullFreeArrayCheck(LIR_OpNullFreeArrayCheck* op) {\n+  \/\/ We are storing into an array that *may* be null-free (the declared type is\n+  \/\/ Object[], abstract[], interface[] or VT.ref[]).\n+  if (UseArrayMarkWordCheck) {\n+    Label test_mark_word;\n+    Register tmp = op->tmp()->as_register();\n+    __ movptr(tmp, Address(op->array()->as_register(), oopDesc::mark_offset_in_bytes()));\n+    __ testl(tmp, markWord::unlocked_value);\n+    __ jccb(Assembler::notZero, test_mark_word);\n+    __ load_prototype_header(tmp, op->array()->as_register(), rscratch1);\n+    __ bind(test_mark_word);\n+    __ testl(tmp, markWord::nullfree_array_bit_in_place);\n+  } else {\n+    Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+    Register klass = op->tmp()->as_register();\n+    __ load_klass(klass, op->array()->as_register(), tmp_load_klass);\n+    __ movl(klass, Address(klass, Klass::layout_helper_offset()));\n+    __ testl(klass, Klass::_lh_null_free_bit_inplace);\n+  }\n+}\n+\n+void LIR_Assembler::emit_opSubstitutabilityCheck(LIR_OpSubstitutabilityCheck* op) {\n+  Label L_oops_equal;\n+  Label L_oops_not_equal;\n+  Label L_end;\n+\n+  Register left  = op->left()->as_register();\n+  Register right = op->right()->as_register();\n+\n+  __ cmpptr(left, right);\n+  __ jcc(Assembler::equal, L_oops_equal);\n+\n+  \/\/ (1) Null check -- if one of the operands is null, the other must not be null (because\n+  \/\/     the two references are not equal), so they are not substitutable,\n+  \/\/     FIXME: do null check only if the operand is nullable\n+  __ testptr(left, right);\n+  __ jcc(Assembler::zero, L_oops_not_equal);\n+\n+  ciKlass* left_klass = op->left_klass();\n+  ciKlass* right_klass = op->right_klass();\n+\n+  \/\/ (2) Inline type check -- if either of the operands is not a inline type,\n+  \/\/     they are not substitutable. We do this only if we are not sure that the\n+  \/\/     operands are inline type\n+  if ((left_klass == NULL || right_klass == NULL) ||\/\/ The klass is still unloaded, or came from a Phi node.\n+      !left_klass->is_inlinetype() || !right_klass->is_inlinetype()) {\n+    Register tmp1  = op->tmp1()->as_register();\n+    __ movptr(tmp1, (intptr_t)markWord::inline_type_pattern);\n+    __ andptr(tmp1, Address(left, oopDesc::mark_offset_in_bytes()));\n+    __ andptr(tmp1, Address(right, oopDesc::mark_offset_in_bytes()));\n+    __ cmpptr(tmp1, (intptr_t)markWord::inline_type_pattern);\n+    __ jcc(Assembler::notEqual, L_oops_not_equal);\n+  }\n+\n+  \/\/ (3) Same klass check: if the operands are of different klasses, they are not substitutable.\n+  if (left_klass != NULL && left_klass->is_inlinetype() && left_klass == right_klass) {\n+    \/\/ No need to load klass -- the operands are statically known to be the same inline klass.\n+    __ jmp(*op->stub()->entry());\n+  } else {\n+    Register left_klass_op = op->left_klass_op()->as_register();\n+    Register right_klass_op = op->right_klass_op()->as_register();\n+\n+    if (UseCompressedClassPointers) {\n+      __ movl(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));\n+      __ movl(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));\n+      __ cmpl(left_klass_op, right_klass_op);\n+    } else {\n+      __ movptr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));\n+      __ movptr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));\n+      __ cmpptr(left_klass_op, right_klass_op);\n+    }\n+\n+    __ jcc(Assembler::equal, *op->stub()->entry()); \/\/ same klass -> do slow check\n+    \/\/ fall through to L_oops_not_equal\n+  }\n+\n+  __ bind(L_oops_not_equal);\n+  move(op->not_equal_result(), op->result_opr());\n+  __ jmp(L_end);\n+\n+  __ bind(L_oops_equal);\n+  move(op->equal_result(), op->result_opr());\n+  __ jmp(L_end);\n+\n+  \/\/ We've returned from the stub. RAX contains 0x0 IFF the two\n+  \/\/ operands are not substitutable. (Don't compare against 0x1 in case the\n+  \/\/ C compiler is naughty)\n+  __ bind(*op->stub()->continuation());\n+  __ cmpl(rax, 0);\n+  __ jcc(Assembler::equal, L_oops_not_equal); \/\/ (call_stub() == 0x0) -> not_equal\n+  move(op->equal_result(), op->result_opr()); \/\/ (call_stub() != 0x0) -> equal\n+  \/\/ fall-through\n+  __ bind(L_end);\n+}\n@@ -2020,0 +2176,15 @@\n+void LIR_Assembler::move(LIR_Opr src, LIR_Opr dst) {\n+  assert(dst->is_cpu_register(), \"must be\");\n+  assert(dst->type() == src->type(), \"must be\");\n+\n+  if (src->is_cpu_register()) {\n+    reg2reg(src, dst);\n+  } else if (src->is_stack()) {\n+    stack2reg(src, dst, dst->type());\n+  } else if (src->is_constant()) {\n+    const2reg(src, dst, lir_patch_none, NULL);\n+  } else {\n+    ShouldNotReachHere();\n+  }\n+}\n+\n@@ -2898,1 +3069,1 @@\n-  add_call_info(code_offset(), op->info());\n+  add_call_info(code_offset(), op->info(), op->maybe_return_as_fields());\n@@ -2904,1 +3075,1 @@\n-  add_call_info(code_offset(), op->info());\n+  add_call_info(code_offset(), op->info(), op->maybe_return_as_fields());\n@@ -3094,0 +3265,26 @@\n+void LIR_Assembler::arraycopy_inlinetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {\n+  if (null_check) {\n+    __ testptr(obj, obj);\n+    __ jcc(Assembler::zero, *slow_path->entry());\n+  }\n+  if (UseArrayMarkWordCheck) {\n+    if (is_dest) {\n+      __ test_null_free_array_oop(obj, tmp, *slow_path->entry());\n+    } else {\n+      __ test_flattened_array_oop(obj, tmp, *slow_path->entry());\n+    }\n+  } else {\n+    Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+    __ load_klass(tmp, obj, tmp_load_klass);\n+    __ movl(tmp, Address(tmp, Klass::layout_helper_offset()));\n+    if (is_dest) {\n+      \/\/ Take the slow path if it's a null_free destination array, in case the source array contains NULLs.\n+      __ testl(tmp, Klass::_lh_null_free_bit_inplace);\n+    } else {\n+      __ testl(tmp, Klass::_lh_array_tag_vt_value_bit_inplace);\n+    }\n+    __ jcc(Assembler::notZero, *slow_path->entry());\n+  }\n+}\n+\n+\n@@ -3115,0 +3312,6 @@\n+  if (flags & LIR_OpArrayCopy::always_slow_path) {\n+    __ jmp(*stub->entry());\n+    __ bind(*stub->continuation());\n+    return;\n+  }\n+\n@@ -3208,0 +3411,8 @@\n+  \/\/ Handle inline type arrays\n+  if (flags & LIR_OpArrayCopy::src_inlinetype_check) {\n+    arraycopy_inlinetype_check(src, tmp, stub, false, (flags & LIR_OpArrayCopy::src_null_check));\n+  }\n+  if (flags & LIR_OpArrayCopy::dst_inlinetype_check) {\n+    arraycopy_inlinetype_check(dst, tmp, stub, true, (flags & LIR_OpArrayCopy::dst_null_check));\n+  }\n+\n@@ -3792,0 +4003,20 @@\n+void LIR_Assembler::emit_profile_inline_type(LIR_OpProfileInlineType* op) {\n+  Register obj = op->obj()->as_register();\n+  Register tmp = op->tmp()->as_pointer_register();\n+  Address mdo_addr = as_Address(op->mdp()->as_address_ptr());\n+  bool not_null = op->not_null();\n+  int flag = op->flag();\n+\n+  Label not_inline_type;\n+  if (!not_null) {\n+    __ testptr(obj, obj);\n+    __ jccb(Assembler::zero, not_inline_type);\n+  }\n+\n+  __ test_oop_is_not_inline_type(obj, tmp, not_inline_type);\n+\n+  __ orb(mdo_addr, flag);\n+\n+  __ bind(not_inline_type);\n+}\n+\n@@ -4052,0 +4283,3 @@\n+void LIR_Assembler::check_orig_pc() {\n+  __ cmpptr(frame_map()->address_for_orig_pc_addr(), (int32_t)NULL_WORD);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":256,"deletions":22,"binary":false,"changes":278,"status":"modified"},{"patch":"@@ -1025,0 +1025,1 @@\n+    case new_instance_no_inline_id:\n@@ -1033,0 +1034,2 @@\n+        } else if (id == new_instance_no_inline_id) {\n+          __ set_info(\"new_instance_no_inline\", dont_gc_arguments);\n@@ -1097,1 +1100,6 @@\n-        int call_offset = __ call_RT(obj, noreg, CAST_FROM_FN_PTR(address, new_instance), klass);\n+        int call_offset;\n+        if (id == new_instance_no_inline_id) {\n+          call_offset = __ call_RT(obj, noreg, CAST_FROM_FN_PTR(address, new_instance_no_inline), klass);\n+        } else {\n+          call_offset = __ call_RT(obj, noreg, CAST_FROM_FN_PTR(address, new_instance), klass);\n+        }\n@@ -1130,0 +1138,1 @@\n+    case new_flat_array_id:\n@@ -1137,1 +1146,1 @@\n-        } else {\n+        } else if (id == new_object_array_id) {\n@@ -1139,0 +1148,2 @@\n+        } else {\n+          __ set_info(\"new_flat_array\", dont_gc_arguments);\n@@ -1148,6 +1159,23 @@\n-          int tag = ((id == new_type_array_id)\n-                     ? Klass::_lh_array_tag_type_value\n-                     : Klass::_lh_array_tag_obj_value);\n-          __ cmpl(t0, tag);\n-          __ jcc(Assembler::equal, ok);\n-          __ stop(\"assert(is an array klass)\");\n+          switch (id) {\n+          case new_type_array_id:\n+            __ cmpl(t0, Klass::_lh_array_tag_type_value);\n+            __ jcc(Assembler::equal, ok);\n+            __ stop(\"assert(is a type array klass)\");\n+            break;\n+          case new_object_array_id:\n+            __ cmpl(t0, Klass::_lh_array_tag_obj_value); \/\/ new \"[Ljava\/lang\/Object;\"\n+            __ jcc(Assembler::equal, ok);\n+            __ cmpl(t0, Klass::_lh_array_tag_vt_value);  \/\/ new \"[LVT;\"\n+            __ jcc(Assembler::equal, ok);\n+            __ stop(\"assert(is an object or inline type array klass)\");\n+            break;\n+          case new_flat_array_id:\n+            \/\/ new \"[QVT;\"\n+            __ cmpl(t0, Klass::_lh_array_tag_vt_value);  \/\/ the array can be flattened.\n+            __ jcc(Assembler::equal, ok);\n+            __ cmpl(t0, Klass::_lh_array_tag_obj_value); \/\/ the array cannot be flattened (due to InlineArrayElementMaxFlatSize, etc)\n+            __ jcc(Assembler::equal, ok);\n+            __ stop(\"assert(is an object or inline type array klass)\");\n+            break;\n+          default:  ShouldNotReachHere();\n+          }\n@@ -1205,1 +1233,1 @@\n-        } else {\n+        } else if (id == new_object_array_id) {\n@@ -1207,0 +1235,3 @@\n+        } else {\n+          assert(id == new_flat_array_id, \"must be\");\n+          call_offset = __ call_RT(obj, noreg, CAST_FROM_FN_PTR(address, new_flat_array), klass, length);\n@@ -1238,0 +1269,77 @@\n+    case load_flattened_array_id:\n+      {\n+        StubFrame f(sasm, \"load_flattened_array\", dont_gc_arguments);\n+        OopMap* map = save_live_registers(sasm, 3);\n+\n+        \/\/ Called with store_parameter and not C abi\n+\n+        f.load_argument(1, rax); \/\/ rax,: array\n+        f.load_argument(0, rbx); \/\/ rbx,: index\n+        int call_offset = __ call_RT(rax, noreg, CAST_FROM_FN_PTR(address, load_flattened_array), rax, rbx);\n+\n+        oop_maps = new OopMapSet();\n+        oop_maps->add_gc_map(call_offset, map);\n+        restore_live_registers_except_rax(sasm);\n+\n+        \/\/ rax,: loaded element at array[index]\n+        __ verify_oop(rax);\n+      }\n+      break;\n+\n+    case store_flattened_array_id:\n+      {\n+        StubFrame f(sasm, \"store_flattened_array\", dont_gc_arguments);\n+        OopMap* map = save_live_registers(sasm, 4);\n+\n+        \/\/ Called with store_parameter and not C abi\n+\n+        f.load_argument(2, rax); \/\/ rax,: array\n+        f.load_argument(1, rbx); \/\/ rbx,: index\n+        f.load_argument(0, rcx); \/\/ rcx,: value\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, store_flattened_array), rax, rbx, rcx);\n+\n+        oop_maps = new OopMapSet();\n+        oop_maps->add_gc_map(call_offset, map);\n+        restore_live_registers_except_rax(sasm);\n+      }\n+      break;\n+\n+    case substitutability_check_id:\n+      {\n+        StubFrame f(sasm, \"substitutability_check\", dont_gc_arguments);\n+        OopMap* map = save_live_registers(sasm, 3);\n+\n+        \/\/ Called with store_parameter and not C abi\n+\n+        f.load_argument(1, rax); \/\/ rax,: left\n+        f.load_argument(0, rbx); \/\/ rbx,: right\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, substitutability_check), rax, rbx);\n+\n+        oop_maps = new OopMapSet();\n+        oop_maps->add_gc_map(call_offset, map);\n+        restore_live_registers_except_rax(sasm);\n+\n+        \/\/ rax,: are the two operands substitutable\n+      }\n+      break;\n+\n+\n+    case buffer_inline_args_id:\n+    case buffer_inline_args_no_receiver_id:\n+      {\n+        const char* name = (id == buffer_inline_args_id) ?\n+          \"buffer_inline_args\" : \"buffer_inline_args_no_receiver\";\n+        StubFrame f(sasm, name, dont_gc_arguments);\n+        OopMap* map = save_live_registers(sasm, 2);\n+        Register method = rbx;\n+        address entry = (id == buffer_inline_args_id) ?\n+          CAST_FROM_FN_PTR(address, buffer_inline_args) :\n+          CAST_FROM_FN_PTR(address, buffer_inline_args_no_receiver);\n+        int call_offset = __ call_RT(rax, noreg, entry, method);\n+        oop_maps = new OopMapSet();\n+        oop_maps->add_gc_map(call_offset, map);\n+        restore_live_registers_except_rax(sasm);\n+        __ verify_oop(rax);  \/\/ rax: an array of buffered value objects\n+      }\n+      break;\n+\n@@ -1340,1 +1448,1 @@\n-      { StubFrame f(sasm, \"throw_incompatible_class_cast_exception\", dont_gc_arguments);\n+      { StubFrame f(sasm, \"throw_incompatible_class_change_error\", dont_gc_arguments);\n@@ -1345,0 +1453,6 @@\n+    case throw_illegal_monitor_state_exception_id:\n+      { StubFrame f(sasm, \"throw_illegal_monitor_state_exception\", dont_gc_arguments);\n+        oop_maps = generate_exception_throw(sasm, CAST_FROM_FN_PTR(address, throw_illegal_monitor_state_exception), false);\n+      }\n+      break;\n+\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":124,"deletions":10,"binary":false,"changes":134,"status":"modified"},{"patch":"@@ -520,0 +520,5 @@\n+  if (EnableValhalla) {\n+    assert(!UseBiasedLocking, \"Not compatible with biased-locking\");\n+    \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+    andptr(tmpReg, ~((int) markWord::inline_type_bit_in_place));\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -141,1 +141,0 @@\n-      sender_unextended_sp = sender_sp;\n@@ -145,2 +144,2 @@\n-      saved_fp = (intptr_t*) *(sender_sp - frame::sender_sp_offset);\n-    }\n+      intptr_t** saved_fp_addr = (intptr_t**) (sender_sp - frame::sender_sp_offset);\n+      saved_fp = *saved_fp_addr;\n@@ -148,0 +147,4 @@\n+      \/\/ Repair the sender sp if this is a method with scalarized inline type args\n+      sender_sp = repair_sender_sp(sender_sp, saved_fp_addr);\n+      sender_unextended_sp = sender_sp;\n+    }\n@@ -446,3 +449,3 @@\n-  intptr_t* unextended_sp = sender_sp;\n-  \/\/ On Intel the return_address is always the word on the stack\n-  address sender_pc = (address) *(sender_sp-1);\n+#ifdef ASSERT\n+  address sender_pc_copy = (address) *(sender_sp-1);\n+#endif\n@@ -455,0 +458,16 @@\n+  \/\/ Repair the sender sp if the frame has been extended\n+  sender_sp = repair_sender_sp(sender_sp, saved_fp_addr);\n+\n+  \/\/ On Intel the return_address is always the word on the stack\n+  address sender_pc = (address) *(sender_sp-1);\n+\n+#ifdef ASSERT\n+  if (sender_pc != sender_pc_copy) {\n+    \/\/ When extending the stack in the callee method entry to make room for unpacking of value\n+    \/\/ type args, we keep a copy of the sender pc at the expected location in the callee frame.\n+    \/\/ If the sender pc is patched due to deoptimization, the copy is not consistent anymore.\n+    nmethod* nm = CodeCache::find_blob(sender_pc)->as_nmethod();\n+    assert(sender_pc == nm->deopt_mh_handler_begin() || sender_pc == nm->deopt_handler_begin(), \"unexpected sender pc\");\n+  }\n+#endif\n+\n@@ -459,1 +478,20 @@\n-    map->set_include_argument_oops(_cb->caller_must_gc_arguments(map->thread()));\n+    bool caller_args = _cb->caller_must_gc_arguments(map->thread());\n+#ifdef COMPILER1\n+    if (!caller_args) {\n+      nmethod* nm = _cb->as_nmethod_or_null();\n+      if (nm != NULL && nm->is_compiled_by_c1() && nm->method()->has_scalarized_args() &&\n+          pc() < nm->verified_inline_entry_point()) {\n+        \/\/ The VEP and VIEP(RO) of C1-compiled methods call buffer_inline_args_xxx\n+        \/\/ before doing any argument shuffling, so we need to scan the oops\n+        \/\/ as the caller passes them.\n+        caller_args = true;\n+#ifdef ASSERT\n+        NativeCall* call = nativeCall_before(pc());\n+        address dest = call->destination();\n+        assert(dest == Runtime1::entry_for(Runtime1::buffer_inline_args_no_receiver_id) ||\n+               dest == Runtime1::entry_for(Runtime1::buffer_inline_args_id), \"unexpected safepoint in entry point\");\n+#endif\n+      }\n+    }\n+#endif\n+    map->set_include_argument_oops(caller_args);\n@@ -471,1 +509,1 @@\n-  return frame(sender_sp, unextended_sp, *saved_fp_addr, sender_pc);\n+  return frame(sender_sp, sender_sp, *saved_fp_addr, sender_pc);\n@@ -478,1 +516,1 @@\n-  \/\/ Default is we done have to follow them. The sender_for_xxx will\n+  \/\/ Default is we don't have to follow them. The sender_for_xxx will\n@@ -583,0 +621,1 @@\n+    case T_INLINE_TYPE:\n@@ -684,0 +723,15 @@\n+\/\/ Check for a method with scalarized inline type arguments that needs\n+\/\/ a stack repair and return the repaired sender stack pointer.\n+intptr_t* frame::repair_sender_sp(intptr_t* sender_sp, intptr_t** saved_fp_addr) const {\n+  CompiledMethod* cm = _cb->as_compiled_method_or_null();\n+  if (cm != NULL && cm->needs_stack_repair()) {\n+    \/\/ The stack increment resides just below the saved rbp on the stack\n+    \/\/ and does not account for the return address.\n+    intptr_t* real_frame_size_addr = (intptr_t*) (saved_fp_addr - 1);\n+    int real_frame_size = ((*real_frame_size_addr) + wordSize) \/ wordSize;\n+    assert(real_frame_size >= _cb->frame_size() && real_frame_size <= 1000000, \"invalid frame size\");\n+    sender_sp = unextended_sp() + real_frame_size;\n+  }\n+  return sender_sp;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.cpp","additions":63,"deletions":9,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -594,1 +594,1 @@\n-              Address dst, Register val, Register tmp1, Register tmp2) {\n+              Address dst, Register val, Register tmp1, Register tmp2, Register tmp3) {\n@@ -632,1 +632,1 @@\n-      BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg);\n+      BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg, noreg);\n@@ -635,1 +635,1 @@\n-      BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg);\n+      BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg, noreg);\n@@ -639,1 +639,1 @@\n-    BarrierSetAssembler::store_at(masm, decorators, type, dst, val, tmp1, tmp2);\n+    BarrierSetAssembler::store_at(masm, decorators, type, dst, val, tmp1, tmp2, tmp3);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shenandoah\/shenandoahBarrierSetAssembler_x86.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -196,1 +196,2 @@\n-                                    Register tmp2) {\n+                                    Register tmp2,\n+                                    Register tmp3) {\n@@ -199,0 +200,1 @@\n+  assert(type != T_INLINE_TYPE, \"Not supported yet\");\n@@ -214,1 +216,1 @@\n-  BarrierSetAssembler::store_at(masm, decorators, type, dst, src, tmp1, tmp2);\n+  BarrierSetAssembler::store_at(masm, decorators, type, dst, src, tmp1, tmp2, tmp3);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/zBarrierSetAssembler_x86.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -74,0 +74,4 @@\n+void InterpreterRuntime::SignatureHandlerGenerator::pass_valuetype() {\n+  box (offset(), jni_offset() + 1);\n+}\n+\n@@ -141,0 +145,7 @@\n+  virtual void pass_valuetype() {\n+    \/\/ pass address of from\n+    intptr_t from_addr = (intptr_t)(_from + Interpreter::local_offset_in_bytes(0));\n+    *_to++ = (*(intptr_t*)from_addr == 0) ? NULL_WORD : from_addr;\n+    _from -= Interpreter::stackElementSize;\n+   }\n+\n","filename":"src\/hotspot\/cpu\/x86\/interpreterRT_x86_32.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -52,0 +53,1 @@\n+#include \"runtime\/signature_cc.hpp\"\n@@ -55,0 +57,1 @@\n+#include \"vmreg_x86.inline.hpp\"\n@@ -56,0 +59,3 @@\n+#ifdef COMPILER2\n+#include \"opto\/output.hpp\"\n+#endif\n@@ -1630,0 +1636,4 @@\n+void MacroAssembler::super_call_VM_leaf(address entry_point) {\n+  MacroAssembler::call_VM_leaf_base(entry_point, 1);\n+}\n+\n@@ -2709,0 +2719,140 @@\n+void MacroAssembler::test_markword_is_inline_type(Register markword, Label& is_inline_type) {\n+  andptr(markword, markWord::inline_type_mask_in_place);\n+  cmpptr(markword, markWord::inline_type_pattern);\n+  jcc(Assembler::equal, is_inline_type);\n+}\n+\n+void MacroAssembler::test_klass_is_inline_type(Register klass, Register temp_reg, Label& is_inline_type) {\n+  movl(temp_reg, Address(klass, Klass::access_flags_offset()));\n+  testl(temp_reg, JVM_ACC_INLINE);\n+  jcc(Assembler::notZero, is_inline_type);\n+}\n+\n+void MacroAssembler::test_oop_is_not_inline_type(Register object, Register tmp, Label& not_inline_type) {\n+  testptr(object, object);\n+  jcc(Assembler::equal, not_inline_type);\n+  const int is_inline_type_mask = markWord::inline_type_pattern;\n+  movptr(tmp, Address(object, oopDesc::mark_offset_in_bytes()));\n+  andptr(tmp, is_inline_type_mask);\n+  cmpptr(tmp, is_inline_type_mask);\n+  jcc(Assembler::notEqual, not_inline_type);\n+}\n+\n+void MacroAssembler::test_klass_is_empty_inline_type(Register klass, Register temp_reg, Label& is_empty_inline_type) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_inline_type(klass, temp_reg, done_check);\n+    stop(\"test_klass_is_empty_inline_type with non inline type klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  movl(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));\n+  testl(temp_reg, InstanceKlass::misc_flags_is_empty_inline_type());\n+  jcc(Assembler::notZero, is_empty_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_inline_type(Register flags, Register temp_reg, Label& is_inline_type) {\n+  movl(temp_reg, flags);\n+  shrl(temp_reg, ConstantPoolCacheEntry::is_inline_type_shift);\n+  andl(temp_reg, 0x1);\n+  testl(temp_reg, temp_reg);\n+  jcc(Assembler::notZero, is_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_not_inline_type(Register flags, Register temp_reg, Label& not_inline_type) {\n+  movl(temp_reg, flags);\n+  shrl(temp_reg, ConstantPoolCacheEntry::is_inline_type_shift);\n+  andl(temp_reg, 0x1);\n+  testl(temp_reg, temp_reg);\n+  jcc(Assembler::zero, not_inline_type);\n+}\n+\n+void MacroAssembler::test_field_is_inlined(Register flags, Register temp_reg, Label& is_inlined) {\n+  movl(temp_reg, flags);\n+  shrl(temp_reg, ConstantPoolCacheEntry::is_inlined_shift);\n+  andl(temp_reg, 0x1);\n+  testl(temp_reg, temp_reg);\n+  jcc(Assembler::notZero, is_inlined);\n+}\n+\n+void MacroAssembler::test_oop_prototype_bit(Register oop, Register temp_reg, int32_t test_bit, bool jmp_set, Label& jmp_label) {\n+  Label test_mark_word;\n+  \/\/ load mark word\n+  movptr(temp_reg, Address(oop, oopDesc::mark_offset_in_bytes()));\n+  \/\/ check displaced\n+  testl(temp_reg, markWord::unlocked_value);\n+  jccb(Assembler::notZero, test_mark_word);\n+  \/\/ slow path use klass prototype\n+  push(rscratch1);\n+  load_prototype_header(temp_reg, oop, rscratch1);\n+  pop(rscratch1);\n+\n+  bind(test_mark_word);\n+  testl(temp_reg, test_bit);\n+  jcc((jmp_set) ? Assembler::notZero : Assembler::zero, jmp_label);\n+}\n+\n+void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg,\n+                                              Label&is_flattened_array) {\n+#ifdef _LP64\n+  test_oop_prototype_bit(oop, temp_reg, markWord::flat_array_bit_in_place, true, is_flattened_array);\n+#else\n+  load_klass(temp_reg, oop, noreg);\n+  movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));\n+  test_flattened_array_layout(temp_reg, is_flattened_array);\n+#endif\n+}\n+\n+void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,\n+                                                  Label&is_non_flattened_array) {\n+#ifdef _LP64\n+  test_oop_prototype_bit(oop, temp_reg, markWord::flat_array_bit_in_place, false, is_non_flattened_array);\n+#else\n+  load_klass(temp_reg, oop, noreg);\n+  movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));\n+  test_non_flattened_array_layout(temp_reg, is_non_flattened_array);\n+#endif\n+}\n+\n+void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&is_null_free_array) {\n+#ifdef _LP64\n+  test_oop_prototype_bit(oop, temp_reg, markWord::nullfree_array_bit_in_place, true, is_null_free_array);\n+#else\n+  load_klass(temp_reg, oop, noreg);\n+  movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));\n+  test_null_free_array_layout(temp_reg, is_null_free_array);\n+#endif\n+}\n+\n+void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&is_non_null_free_array) {\n+#ifdef _LP64\n+  test_oop_prototype_bit(oop, temp_reg, markWord::nullfree_array_bit_in_place, false, is_non_null_free_array);\n+#else\n+  load_klass(temp_reg, oop, noreg);\n+  movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));\n+  test_non_null_free_array_layout(temp_reg, is_non_null_free_array);\n+#endif\n+}\n+\n+void MacroAssembler::test_flattened_array_layout(Register lh, Label& is_flattened_array) {\n+  testl(lh, Klass::_lh_array_tag_vt_value_bit_inplace);\n+  jcc(Assembler::notZero, is_flattened_array);\n+}\n+\n+void MacroAssembler::test_non_flattened_array_layout(Register lh, Label& is_non_flattened_array) {\n+  testl(lh, Klass::_lh_array_tag_vt_value_bit_inplace);\n+  jcc(Assembler::zero, is_non_flattened_array);\n+}\n+\n+void MacroAssembler::test_null_free_array_layout(Register lh, Label& is_null_free_array) {\n+  testl(lh, Klass::_lh_null_free_bit_inplace);\n+  jcc(Assembler::notZero, is_null_free_array);\n+}\n+\n+void MacroAssembler::test_non_null_free_array_layout(Register lh, Label& is_non_null_free_array) {\n+  testl(lh, Klass::_lh_null_free_bit_inplace);\n+  jcc(Assembler::zero, is_non_null_free_array);\n+}\n+\n+\n@@ -3525,0 +3675,129 @@\n+\/\/ Object \/ value buffer allocation...\n+\/\/\n+\/\/ Kills klass and rsi on LP64\n+void MacroAssembler::allocate_instance(Register klass, Register new_obj,\n+                                       Register t1, Register t2,\n+                                       bool clear_fields, Label& alloc_failed)\n+{\n+  Label done, initialize_header, initialize_object, slow_case, slow_case_no_pop;\n+  Register layout_size = t1;\n+  assert(new_obj == rax, \"needs to be rax, according to barrier asm eden_allocate\");\n+  assert_different_registers(klass, new_obj, t1, t2);\n+\n+#ifdef ASSERT\n+  {\n+    Label L;\n+    cmpb(Address(klass, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);\n+    jcc(Assembler::equal, L);\n+    stop(\"klass not initialized\");\n+    bind(L);\n+  }\n+#endif\n+\n+  \/\/ get instance_size in InstanceKlass (scaled to a count of bytes)\n+  movl(layout_size, Address(klass, Klass::layout_helper_offset()));\n+  \/\/ test to see if it has a finalizer or is malformed in some way\n+  testl(layout_size, Klass::_lh_instance_slow_path_bit);\n+  jcc(Assembler::notZero, slow_case_no_pop);\n+\n+  \/\/ Allocate the instance:\n+  \/\/  If TLAB is enabled:\n+  \/\/    Try to allocate in the TLAB.\n+  \/\/    If fails, go to the slow path.\n+  \/\/  Else If inline contiguous allocations are enabled:\n+  \/\/    Try to allocate in eden.\n+  \/\/    If fails due to heap end, go to slow path.\n+  \/\/\n+  \/\/  If TLAB is enabled OR inline contiguous is enabled:\n+  \/\/    Initialize the allocation.\n+  \/\/    Exit.\n+  \/\/\n+  \/\/  Go to slow path.\n+  const bool allow_shared_alloc =\n+    Universe::heap()->supports_inline_contig_alloc();\n+\n+  push(klass);\n+  const Register thread = LP64_ONLY(r15_thread) NOT_LP64(klass);\n+#ifndef _LP64\n+  if (UseTLAB || allow_shared_alloc) {\n+    get_thread(thread);\n+  }\n+#endif \/\/ _LP64\n+\n+  if (UseTLAB) {\n+    tlab_allocate(thread, new_obj, layout_size, 0, klass, t2, slow_case);\n+    if (ZeroTLAB || (!clear_fields)) {\n+      \/\/ the fields have been already cleared\n+      jmp(initialize_header);\n+    } else {\n+      \/\/ initialize both the header and fields\n+      jmp(initialize_object);\n+    }\n+  } else {\n+    \/\/ Allocation in the shared Eden, if allowed.\n+    \/\/\n+    eden_allocate(thread, new_obj, layout_size, 0, t2, slow_case);\n+  }\n+\n+  \/\/ If UseTLAB or allow_shared_alloc are true, the object is created above and\n+  \/\/ there is an initialize need. Otherwise, skip and go to the slow path.\n+  if (UseTLAB || allow_shared_alloc) {\n+    if (clear_fields) {\n+      \/\/ The object is initialized before the header.  If the object size is\n+      \/\/ zero, go directly to the header initialization.\n+      bind(initialize_object);\n+      decrement(layout_size, sizeof(oopDesc));\n+      jcc(Assembler::zero, initialize_header);\n+\n+      \/\/ Initialize topmost object field, divide size by 8, check if odd and\n+      \/\/ test if zero.\n+      Register zero = klass;\n+      xorl(zero, zero);    \/\/ use zero reg to clear memory (shorter code)\n+      shrl(layout_size, LogBytesPerLong); \/\/ divide by 2*oopSize and set carry flag if odd\n+\n+  #ifdef ASSERT\n+      \/\/ make sure instance_size was multiple of 8\n+      Label L;\n+      \/\/ Ignore partial flag stall after shrl() since it is debug VM\n+      jcc(Assembler::carryClear, L);\n+      stop(\"object size is not multiple of 2 - adjust this code\");\n+      bind(L);\n+      \/\/ must be > 0, no extra check needed here\n+  #endif\n+\n+      \/\/ initialize remaining object fields: instance_size was a multiple of 8\n+      {\n+        Label loop;\n+        bind(loop);\n+        movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 1*oopSize), zero);\n+        NOT_LP64(movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 2*oopSize), zero));\n+        decrement(layout_size);\n+        jcc(Assembler::notZero, loop);\n+      }\n+    } \/\/ clear_fields\n+\n+    \/\/ initialize object header only.\n+    bind(initialize_header);\n+    pop(klass);\n+    Register mark_word = t2;\n+    movptr(mark_word, Address(klass, Klass::prototype_header_offset()));\n+    movptr(Address(new_obj, oopDesc::mark_offset_in_bytes ()), mark_word);\n+#ifdef _LP64\n+    xorl(rsi, rsi);                 \/\/ use zero reg to clear memory (shorter code)\n+    store_klass_gap(new_obj, rsi);  \/\/ zero klass gap for compressed oops\n+#endif\n+    movptr(t2, klass);         \/\/ preserve klass\n+    Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+    store_klass(new_obj, t2, tmp_store_klass);  \/\/ src klass reg is potentially compressed\n+\n+    jmp(done);\n+  }\n+\n+  bind(slow_case);\n+  pop(klass);\n+  bind(slow_case_no_pop);\n+  jmp(alloc_failed);\n+\n+  bind(done);\n+}\n+\n@@ -3602,0 +3881,50 @@\n+void MacroAssembler::get_inline_type_field_klass(Register klass, Register index, Register inline_klass) {\n+  movptr(inline_klass, Address(klass, InstanceKlass::inline_type_field_klasses_offset()));\n+#ifdef ASSERT\n+  {\n+    Label done;\n+    cmpptr(inline_klass, 0);\n+    jcc(Assembler::notEqual, done);\n+    stop(\"get_inline_type_field_klass contains no inline klass\");\n+    bind(done);\n+  }\n+#endif\n+  movptr(inline_klass, Address(inline_klass, index, Address::times_ptr));\n+}\n+\n+void MacroAssembler::get_default_value_oop(Register inline_klass, Register temp_reg, Register obj) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_inline_type(inline_klass, temp_reg, done_check);\n+    stop(\"get_default_value_oop from non inline type klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  Register offset = temp_reg;\n+  \/\/ Getting the offset of the pre-allocated default value\n+  movptr(offset, Address(inline_klass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())));\n+  movl(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())));\n+\n+  \/\/ Getting the mirror\n+  movptr(obj, Address(inline_klass, in_bytes(Klass::java_mirror_offset())));\n+  resolve_oop_handle(obj, inline_klass);\n+\n+  \/\/ Getting the pre-allocated default value from the mirror\n+  Address field(obj, offset, Address::times_1);\n+  load_heap_oop(obj, field);\n+}\n+\n+void MacroAssembler::get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj) {\n+#ifdef ASSERT\n+  {\n+    Label done_check;\n+    test_klass_is_empty_inline_type(inline_klass, temp_reg, done_check);\n+    stop(\"get_empty_value from non-empty inline klass\");\n+    bind(done_check);\n+  }\n+#endif\n+  get_default_value_oop(inline_klass, temp_reg, obj);\n+}\n+\n+\n@@ -3950,1 +4279,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -4009,1 +4342,5 @@\n-  if (!VerifyOops) return;\n+  if (!VerifyOops || VerifyAdapterSharing) {\n+    \/\/ Below address of the code string confuses VerifyAdapterSharing\n+    \/\/ because it may differ between otherwise equivalent adapters.\n+    return;\n+  }\n@@ -4511,0 +4848,8 @@\n+void MacroAssembler::load_metadata(Register dst, Register src) {\n+  if (UseCompressedClassPointers) {\n+    movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  } else {\n+    movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n+\n@@ -4520,1 +4865,1 @@\n-    movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n+  movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n@@ -4553,1 +4898,1 @@\n-                                     Register tmp1, Register tmp2) {\n+                                     Register tmp1, Register tmp2, Register tmp3) {\n@@ -4558,1 +4903,23 @@\n-    bs->BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2);\n+    bs->BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);\n+  } else {\n+    bs->store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);\n+  }\n+}\n+\n+void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,\n+                                       Register inline_klass) {\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->value_copy(this, decorators, src, dst, inline_klass);\n+}\n+\n+void MacroAssembler::first_field_offset(Register inline_klass, Register offset) {\n+  movptr(offset, Address(inline_klass, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+  movl(offset, Address(offset, InlineKlass::first_field_offset_offset()));\n+}\n+\n+void MacroAssembler::data_for_oop(Register oop, Register data, Register inline_klass) {\n+  \/\/ ((address) (void*) o) + vk->first_field_offset();\n+  Register offset = (data == oop) ? rscratch1 : data;\n+  first_field_offset(inline_klass, offset);\n+  if (data == oop) {\n+    addptr(data, offset);\n@@ -4560,1 +4927,1 @@\n-    bs->store_at(this, decorators, type, dst, src, tmp1, tmp2);\n+    lea(data, Address(oop, offset));\n@@ -4564,0 +4931,18 @@\n+void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,\n+                                                Register index, Register data) {\n+  assert(index != rcx, \"index needs to shift by rcx\");\n+  assert_different_registers(array, array_klass, index);\n+  assert_different_registers(rcx, array, index);\n+\n+  \/\/ array->base() + (index << Klass::layout_helper_log2_element_size(lh));\n+  movl(rcx, Address(array_klass, Klass::layout_helper_offset()));\n+\n+  \/\/ Klass::layout_helper_log2_element_size(lh)\n+  \/\/ (lh >> _lh_log2_element_size_shift) & _lh_log2_element_size_mask;\n+  shrl(rcx, Klass::_lh_log2_element_size_shift);\n+  andl(rcx, Klass::_lh_log2_element_size_mask);\n+  shlptr(index); \/\/ index << rcx\n+\n+  lea(data, Address(array, index, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE)));\n+}\n+\n@@ -4585,2 +4970,2 @@\n-                                    Register tmp2, DecoratorSet decorators) {\n-  access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2);\n+                                    Register tmp2, Register tmp3, DecoratorSet decorators) {\n+  access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2, tmp3);\n@@ -4591,1 +4976,1 @@\n-  access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);\n+  access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);\n@@ -4905,0 +5290,1 @@\n+#ifdef COMPILER2\n@@ -4906,1 +5292,5 @@\n-void MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub) {\n+void MacroAssembler::verified_entry(Compile* C, int sp_inc) {\n+  int framesize = C->output()->frame_size_in_bytes();\n+  int bangsize = C->output()->bang_size_in_bytes();\n+  bool fp_mode_24b = false;\n+  int stack_bang_size = C->output()->need_stack_bang(bangsize) ? bangsize : 0;\n@@ -4959,0 +5349,6 @@\n+  if (C->needs_stack_repair()) {\n+    \/\/ Save stack increment (also account for fixed framesize and rbp)\n+    assert((sp_inc & (StackAlignmentInBytes-1)) == 0, \"stack increment not aligned\");\n+    movptr(Address(rsp, C->output()->sp_inc_offset()), sp_inc + framesize + wordSize);\n+  }\n+\n@@ -4987,5 +5383,1 @@\n-\n-  if (!is_stub) {\n-    BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-    bs->nmethod_entry_barrier(this);\n-  }\n+#endif \/\/ COMPILER2\n@@ -4997,1 +5389,1 @@\n-void MacroAssembler::xmm_clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp, KRegister mask) {\n+void MacroAssembler::xmm_clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, KRegister mask) {\n@@ -5003,1 +5395,1 @@\n-    vpxor(xtmp, xtmp, xtmp, AVX_512bit);\n+    evpbroadcastq(xtmp, val, AVX_512bit);\n@@ -5005,1 +5397,3 @@\n-    vpxor(xtmp, xtmp, xtmp, AVX_256bit);\n+    movdq(xtmp, val);\n+    punpcklqdq(xtmp, xtmp);\n+    vinserti128_high(xtmp, xtmp);\n@@ -5007,1 +5401,2 @@\n-    pxor(xtmp, xtmp);\n+    movdq(xtmp, val);\n+    punpcklqdq(xtmp, xtmp);\n@@ -5030,1 +5425,1 @@\n-    fill64_masked_avx(3, base, 0, xtmp, mask, cnt, rtmp, true);\n+    fill64_masked_avx(3, base, 0, xtmp, mask, cnt, val, true);\n@@ -5049,1 +5444,1 @@\n-    fill32_masked_avx(3, base, 0, xtmp, mask, cnt, rtmp);\n+    fill32_masked_avx(3, base, 0, xtmp, mask, cnt, val);\n@@ -5062,0 +5457,297 @@\n+int MacroAssembler::store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter) {\n+  \/\/ An inline type might be returned. If fields are in registers we\n+  \/\/ need to allocate an inline type instance and initialize it with\n+  \/\/ the value of the fields.\n+  Label skip;\n+  \/\/ We only need a new buffered inline type if a new one is not returned\n+  testptr(rax, 1);\n+  jcc(Assembler::zero, skip);\n+  int call_offset = -1;\n+\n+#ifdef _LP64\n+  \/\/ The following code is similar to allocate_instance but has some slight differences,\n+  \/\/ e.g. object size is always not zero, sometimes it's constant; storing klass ptr after\n+  \/\/ allocating is not necessary if vk != NULL, etc. allocate_instance is not aware of these.\n+  Label slow_case;\n+  \/\/ 1. Try to allocate a new buffered inline instance either from TLAB or eden space\n+  mov(rscratch1, rax); \/\/ save rax for slow_case since *_allocate may corrupt it when allocation failed\n+  if (vk != NULL) {\n+    \/\/ Called from C1, where the return type is statically known.\n+    movptr(rbx, (intptr_t)vk->get_InlineKlass());\n+    jint obj_size = vk->layout_helper();\n+    assert(obj_size != Klass::_lh_neutral_value, \"inline class in return type must have been resolved\");\n+    if (UseTLAB) {\n+      tlab_allocate(r15_thread, rax, noreg, obj_size, r13, r14, slow_case);\n+    } else {\n+      eden_allocate(r15_thread, rax, noreg, obj_size, r13, slow_case);\n+    }\n+  } else {\n+    \/\/ Call from interpreter. RAX contains ((the InlineKlass* of the return type) | 0x01)\n+    mov(rbx, rax);\n+    andptr(rbx, -2);\n+    movl(r14, Address(rbx, Klass::layout_helper_offset()));\n+    if (UseTLAB) {\n+      tlab_allocate(r15_thread, rax, r14, 0, r13, r14, slow_case);\n+    } else {\n+      eden_allocate(r15_thread, rax, r14, 0, r13, slow_case);\n+    }\n+  }\n+  if (UseTLAB || Universe::heap()->supports_inline_contig_alloc()) {\n+    \/\/ 2. Initialize buffered inline instance header\n+    Register buffer_obj = rax;\n+    movptr(Address(buffer_obj, oopDesc::mark_offset_in_bytes()), (intptr_t)markWord::inline_type_prototype().value());\n+    xorl(r13, r13);\n+    store_klass_gap(buffer_obj, r13);\n+    if (vk == NULL) {\n+      \/\/ store_klass corrupts rbx(klass), so save it in r13 for later use (interpreter case only).\n+      mov(r13, rbx);\n+    }\n+    Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+    store_klass(buffer_obj, rbx, tmp_store_klass);\n+    \/\/ 3. Initialize its fields with an inline class specific handler\n+    if (vk != NULL) {\n+      call(RuntimeAddress(vk->pack_handler())); \/\/ no need for call info as this will not safepoint.\n+    } else {\n+      movptr(rbx, Address(r13, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      movptr(rbx, Address(rbx, InlineKlass::pack_handler_offset()));\n+      call(rbx);\n+    }\n+    jmp(skip);\n+  }\n+  bind(slow_case);\n+  \/\/ We failed to allocate a new inline type, fall back to a runtime\n+  \/\/ call. Some oop field may be live in some registers but we can't\n+  \/\/ tell. That runtime call will take care of preserving them\n+  \/\/ across a GC if there's one.\n+  mov(rax, rscratch1);\n+#endif\n+\n+  if (from_interpreter) {\n+    super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());\n+  } else {\n+    call(RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));\n+    call_offset = offset();\n+  }\n+\n+  bind(skip);\n+  return call_offset;\n+}\n+\n+\/\/ Move a value between registers\/stack slots and update the reg_state\n+bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]) {\n+  if (reg_state[to->value()] == reg_written) {\n+    return true; \/\/ Already written\n+  }\n+  if (from != to && bt != T_VOID) {\n+    if (reg_state[to->value()] == reg_readonly) {\n+      return false; \/\/ Not yet writable\n+    }\n+    if (from->is_reg()) {\n+      if (to->is_reg()) {\n+        if (from->is_XMMRegister()) {\n+          if (bt == T_DOUBLE) {\n+            movdbl(to->as_XMMRegister(), from->as_XMMRegister());\n+          } else {\n+            assert(bt == T_FLOAT, \"must be float\");\n+            movflt(to->as_XMMRegister(), from->as_XMMRegister());\n+          }\n+        } else {\n+          movq(to->as_Register(), from->as_Register());\n+        }\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        Address to_addr = Address(rsp, st_off);\n+        if (from->is_XMMRegister()) {\n+          if (bt == T_DOUBLE) {\n+            movdbl(to_addr, from->as_XMMRegister());\n+          } else {\n+            assert(bt == T_FLOAT, \"must be float\");\n+            movflt(to_addr, from->as_XMMRegister());\n+          }\n+        } else {\n+          movq(to_addr, from->as_Register());\n+        }\n+      }\n+    } else {\n+      Address from_addr = Address(rsp, from->reg2stack() * VMRegImpl::stack_slot_size + wordSize);\n+      if (to->is_reg()) {\n+        if (to->is_XMMRegister()) {\n+          if (bt == T_DOUBLE) {\n+            movdbl(to->as_XMMRegister(), from_addr);\n+          } else {\n+            assert(bt == T_FLOAT, \"must be float\");\n+            movflt(to->as_XMMRegister(), from_addr);\n+          }\n+        } else {\n+          movq(to->as_Register(), from_addr);\n+        }\n+      } else {\n+        int st_off = to->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        movq(r13, from_addr);\n+        movq(Address(rsp, st_off), r13);\n+      }\n+    }\n+  }\n+  \/\/ Update register states\n+  reg_state[from->value()] = reg_writable;\n+  reg_state[to->value()] = reg_written;\n+  return true;\n+}\n+\n+\/\/ Read all fields from an inline type buffer and store the field values in registers\/stack slots.\n+bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                                          VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                                          RegState reg_state[]) {\n+  assert(sig->at(sig_index)._bt == T_VOID, \"should be at end delimiter\");\n+  assert(from->is_valid(), \"source must bevalid\");\n+  Register fromReg;\n+  if (from->is_reg()) {\n+    fromReg = from->as_Register();\n+  } else {\n+    int st_off = from->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+    movq(r10, Address(rsp, st_off));\n+    fromReg = r10;\n+  }\n+\n+  ScalarizedInlineArgsStream stream(sig, sig_index, to, to_count, to_index, -1);\n+  bool done = true;\n+  bool mark_done = true;\n+  VMReg toReg;\n+  BasicType bt;\n+  while (stream.next(toReg, bt)) {\n+    int off = sig->at(stream.sig_index())._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    Address fromAddr = Address(fromReg, off);\n+\n+    int idx = (int)toReg->value();\n+    if (reg_state[idx] == reg_readonly) {\n+     if (idx != from->value()) {\n+       mark_done = false;\n+     }\n+     done = false;\n+     continue;\n+    } else if (reg_state[idx] == reg_written) {\n+      continue;\n+    } else {\n+      assert(reg_state[idx] == reg_writable, \"must be writable\");\n+      reg_state[idx] = reg_written;\n+    }\n+\n+    if (!toReg->is_XMMRegister()) {\n+      Register dst = toReg->is_stack() ? r13 : toReg->as_Register();\n+      if (is_reference_type(bt)) {\n+        load_heap_oop(dst, fromAddr);\n+      } else {\n+        bool is_signed = (bt != T_CHAR) && (bt != T_BOOLEAN);\n+        load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);\n+      }\n+      if (toReg->is_stack()) {\n+        int st_off = toReg->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        movq(Address(rsp, st_off), dst);\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      movdbl(toReg->as_XMMRegister(), fromAddr);\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      movflt(toReg->as_XMMRegister(), fromAddr);\n+    }\n+  }\n+  sig_index = stream.sig_index();\n+  to_index = stream.regs_index();\n+\n+  if (mark_done && reg_state[from->value()] != reg_written) {\n+    \/\/ This is okay because no one else will write to that slot\n+    reg_state[from->value()] = reg_writable;\n+  }\n+  from_index--;\n+  return done;\n+}\n+\n+bool MacroAssembler::pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                                        VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                                        RegState reg_state[]) {\n+  assert(sig->at(sig_index)._bt == T_INLINE_TYPE, \"should be at end delimiter\");\n+  assert(to->is_valid(), \"destination must be valid\");\n+\n+  if (reg_state[to->value()] == reg_written) {\n+    skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n+    return true; \/\/ Already written\n+  }\n+\n+  Register val_array = rax;\n+  Register val_obj_tmp = r11;\n+  Register from_reg_tmp = r14; \/\/ Be careful with r14 because it's used for spilling\n+  Register tmp1 = r10;\n+  Register tmp2 = r13;\n+  Register tmp3 = rbx;\n+  Register val_obj = to->is_stack() ? val_obj_tmp : to->as_Register();\n+\n+  if (reg_state[to->value()] == reg_readonly) {\n+    if (!is_reg_in_unpacked_fields(sig, sig_index, to, from, from_count, from_index)) {\n+      skip_unpacked_fields(sig, sig_index, from, from_count, from_index);\n+      return false; \/\/ Not yet writable\n+    }\n+    val_obj = val_obj_tmp;\n+  }\n+\n+  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_INLINE_TYPE);\n+  load_heap_oop(val_obj, Address(val_array, index));\n+\n+  ScalarizedInlineArgsStream stream(sig, sig_index, from, from_count, from_index);\n+  VMReg fromReg;\n+  BasicType bt;\n+  while (stream.next(fromReg, bt)) {\n+    int off = sig->at(stream.sig_index())._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;\n+\n+    Address dst(val_obj, off);\n+    if (!fromReg->is_XMMRegister()) {\n+      Register src;\n+      if (fromReg->is_stack()) {\n+        src = from_reg_tmp;\n+        int ld_off = fromReg->reg2stack() * VMRegImpl::stack_slot_size + wordSize;\n+        load_sized_value(src, Address(rsp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+      } else {\n+        src = fromReg->as_Register();\n+      }\n+      assert_different_registers(dst.base(), src, tmp1, tmp2, tmp3, val_array);\n+      if (is_reference_type(bt)) {\n+        store_heap_oop(dst, src, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      } else {\n+        store_sized_value(dst, src, size_in_bytes);\n+      }\n+    } else if (bt == T_DOUBLE) {\n+      movdbl(dst, fromReg->as_XMMRegister());\n+    } else {\n+      assert(bt == T_FLOAT, \"must be float\");\n+      movflt(dst, fromReg->as_XMMRegister());\n+    }\n+    reg_state[fromReg->value()] = reg_writable;\n+  }\n+  sig_index = stream.sig_index();\n+  from_index = stream.regs_index();\n+\n+  assert(reg_state[to->value()] == reg_writable, \"must have already been read\");\n+  bool success = move_helper(val_obj->as_VMReg(), to, T_OBJECT, reg_state);\n+  assert(success, \"to register must be writeable\");\n+  return true;\n+}\n+\n+VMReg MacroAssembler::spill_reg_for(VMReg reg) {\n+  return reg->is_XMMRegister() ? xmm8->as_VMReg() : r14->as_VMReg();\n+}\n+\n+void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {\n+  assert((initial_framesize & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n+  if (needs_stack_repair) {\n+    movq(rbp, Address(rsp, initial_framesize));\n+    addq(rsp, Address(rsp, sp_inc_offset));\n+  } else {\n+    if (initial_framesize > 0) {\n+      addq(rsp, initial_framesize);\n+    }\n+    pop(rbp);\n+  }\n+}\n+\n@@ -5133,2 +5825,2 @@\n-void MacroAssembler::clear_mem(Register base, Register cnt, Register tmp, XMMRegister xtmp,\n-                               bool is_large, KRegister mask) {\n+void MacroAssembler::clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp,\n+                               bool is_large, bool word_copy_only, KRegister mask) {\n@@ -5139,1 +5831,1 @@\n-  assert(tmp==rax,   \"tmp register must be eax for rep stos\");\n+  assert(val==rax,   \"val register must be eax for rep stos\");\n@@ -5145,3 +5837,0 @@\n-  if (!is_large || !UseXMMForObjInit) {\n-    xorptr(tmp, tmp);\n-  }\n@@ -5161,1 +5850,1 @@\n-    movptr(Address(base, cnt, Address::times_ptr), tmp);\n+    movptr(Address(base, cnt, Address::times_ptr), val);\n@@ -5170,1 +5859,1 @@\n-  if (UseFastStosb) {\n+  if (UseFastStosb && !word_copy_only) {\n@@ -5174,1 +5863,1 @@\n-    xmm_clear_mem(base, cnt, tmp, xtmp, mask);\n+    xmm_clear_mem(base, cnt, val, xtmp, mask);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":719,"deletions":30,"binary":false,"changes":749,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/signature.hpp\"\n@@ -33,0 +34,2 @@\n+class ciInlineKlass;\n+\n@@ -102,0 +105,31 @@\n+  \/\/ markWord tests, kills markWord reg\n+  void test_markword_is_inline_type(Register markword, Label& is_inline_type);\n+\n+  \/\/ inlineKlass queries, kills temp_reg\n+  void test_klass_is_inline_type(Register klass, Register temp_reg, Label& is_inline_type);\n+  void test_klass_is_empty_inline_type(Register klass, Register temp_reg, Label& is_empty_inline_type);\n+  void test_oop_is_not_inline_type(Register object, Register tmp, Label& not_inline_type);\n+\n+  \/\/ Get the default value oop for the given InlineKlass\n+  void get_default_value_oop(Register inline_klass, Register temp_reg, Register obj);\n+  \/\/ The empty value oop, for the given InlineKlass (\"empty\" as in no instance fields)\n+  \/\/ get_default_value_oop with extra assertion for empty inline klass\n+  void get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj);\n+\n+  void test_field_is_inline_type(Register flags, Register temp_reg, Label& is_inline);\n+  void test_field_is_not_inline_type(Register flags, Register temp_reg, Label& not_inline);\n+  void test_field_is_inlined(Register flags, Register temp_reg, Label& is_inlined);\n+\n+  \/\/ Check oops for special arrays, i.e. flattened and\/or null-free\n+  void test_oop_prototype_bit(Register oop, Register temp_reg, int32_t test_bit, bool jmp_set, Label& jmp_label);\n+  void test_flattened_array_oop(Register oop, Register temp_reg, Label&is_flattened_array);\n+  void test_non_flattened_array_oop(Register oop, Register temp_reg, Label&is_non_flattened_array);\n+  void test_null_free_array_oop(Register oop, Register temp_reg, Label&is_null_free_array);\n+  void test_non_null_free_array_oop(Register oop, Register temp_reg, Label&is_non_null_free_array);\n+\n+  \/\/ Check array klass layout helper for flatten or null-free arrays...\n+  void test_flattened_array_layout(Register lh, Label& is_flattened_array);\n+  void test_non_flattened_array_layout(Register lh, Label& is_non_flattened_array);\n+  void test_null_free_array_layout(Register lh, Label& is_null_free_array);\n+  void test_non_null_free_array_layout(Register lh, Label& is_non_null_free_array);\n+\n@@ -322,0 +356,1 @@\n+  void load_metadata(Register dst, Register src);\n@@ -328,1 +363,11 @@\n-                       Register tmp1, Register tmp2);\n+                       Register tmp1, Register tmp2, Register tmp3 = noreg);\n+\n+  void access_value_copy(DecoratorSet decorators, Register src, Register dst, Register inline_klass);\n+\n+  \/\/ inline type data payload offsets...\n+  void first_field_offset(Register inline_klass, Register offset);\n+  void data_for_oop(Register oop, Register data, Register inline_klass);\n+  \/\/ get data payload ptr a flat value array at index, kills rcx and index\n+  void data_for_value_array_index(Register array, Register array_klass,\n+                                  Register index, Register data);\n+\n@@ -339,1 +384,1 @@\n-                      Register tmp2 = noreg, DecoratorSet decorators = 0);\n+                      Register tmp2 = noreg, Register tmp3 = noreg, DecoratorSet decorators = 0);\n@@ -515,0 +560,9 @@\n+\n+  \/\/ Object \/ value buffer allocation...\n+  \/\/ Allocate instance of klass, assumes klass initialized by caller\n+  \/\/ new_obj prefers to be rax\n+  \/\/ Kills t1 and t2, perserves klass, return allocation in new_obj (rsi on LP64)\n+  void allocate_instance(Register klass, Register new_obj,\n+                         Register t1, Register t2,\n+                         bool clear_fields, Label& alloc_failed);\n+\n@@ -534,0 +588,3 @@\n+  \/\/ For field \"index\" within \"klass\", return inline_klass ...\n+  void get_inline_type_field_klass(Register klass, Register index, Register inline_klass);\n+\n@@ -699,1 +756,2 @@\n-  void andptr(Register src1, Register src2) { LP64_ONLY(andq(src1, src2)) NOT_LP64(andl(src1, src2)) ; }\n+  void andptr(Register dst, Register src) { LP64_ONLY(andq(dst, src)) NOT_LP64(andl(dst, src)) ; }\n+  void andptr(Register dst, Address src) { LP64_ONLY(andq(dst, src)) NOT_LP64(andl(dst, src)) ; }\n@@ -1699,1 +1757,15 @@\n-  void verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub);\n+  void verified_entry(Compile* C, int sp_inc = 0);\n+\n+  \/\/ Inline type specific methods\n+  #include \"asm\/macroAssembler_common.hpp\"\n+\n+  int store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter = true);\n+  bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[]);\n+  bool unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,\n+                            VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,\n+                            RegState reg_state[]);\n+  bool pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,\n+                          VMRegPair* from, int from_count, int& from_index, VMReg to,\n+                          RegState reg_state[]);\n+  void remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset);\n+  VMReg spill_reg_for(VMReg reg);\n@@ -1703,1 +1775,1 @@\n-  void clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp, bool is_large, KRegister mask=knoreg);\n+  void clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only, KRegister mask=knoreg);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":77,"deletions":5,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -156,1 +156,5 @@\n-  const ByteSize entry_offset = for_compiler_entry ? Method::from_compiled_offset() :\n+  \/\/ The following jump might pass an inline type argument that was erased to Object as oop to a\n+  \/\/ callee that expects inline type arguments to be passed as fields. We need to call the compiled\n+  \/\/ value entry (_code->inline_entry_point() or _adapter->c2i_inline_entry()) which will take care\n+  \/\/ of translating between the calling conventions.\n+  const ByteSize entry_offset = for_compiler_entry ? Method::from_compiled_inline_offset() :\n","filename":"src\/hotspot\/cpu\/x86\/methodHandles_x86.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -485,0 +485,1 @@\n+    case T_INLINE_TYPE:\n@@ -535,0 +536,9 @@\n+const uint SharedRuntime::java_return_convention_max_int = 1;\n+const uint SharedRuntime::java_return_convention_max_float = 1;\n+int SharedRuntime::java_return_convention(const BasicType *sig_bt,\n+                                          VMRegPair *regs,\n+                                          int total_args_passed) {\n+  Unimplemented();\n+  return 0;\n+}\n+\n@@ -596,3 +606,1 @@\n-                            int total_args_passed,\n-                            int comp_args_on_stack,\n-                            const BasicType *sig_bt,\n+                            const GrowableArray<SigEntry>& sig_extended,\n@@ -600,1 +608,5 @@\n-                            Label& skip_fixup) {\n+                            Label& skip_fixup,\n+                            address start,\n+                            OopMapSet*& oop_maps,\n+                            int& frame_complete,\n+                            int& frame_size_in_words) {\n@@ -622,1 +634,1 @@\n-  int extraspace = total_args_passed * Interpreter::stackElementSize;\n+  int extraspace = sig_extended.length() * Interpreter::stackElementSize;\n@@ -633,3 +645,3 @@\n-  for (int i = 0; i < total_args_passed; i++) {\n-    if (sig_bt[i] == T_VOID) {\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n+  for (int i = 0; i < sig_extended.length(); i++) {\n+    if (sig_extended.at(i)._bt == T_VOID) {\n+      assert(i > 0 && (sig_extended.at(i-1)._bt == T_LONG || sig_extended.at(i-1)._bt == T_DOUBLE), \"missing half\");\n@@ -640,1 +652,1 @@\n-    int st_off = ((total_args_passed - 1) - i) * Interpreter::stackElementSize;\n+    int st_off = ((sig_extended.length() - 1) - i) * Interpreter::stackElementSize;\n@@ -690,1 +702,1 @@\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n+        if (sig_extended.at(i)._bt == T_LONG || sig_extended.at(i)._bt == T_DOUBLE) {\n@@ -707,1 +719,1 @@\n-        assert(sig_bt[i] == T_DOUBLE || sig_bt[i] == T_LONG, \"wrong type\");\n+        assert(sig_extended.at(i)._bt == T_DOUBLE || sig_extended.at(i)._bt == T_LONG, \"wrong type\");\n@@ -740,2 +752,1 @@\n-                                    int total_args_passed,\n-                                    const BasicType *sig_bt,\n+                                    const GrowableArray<SigEntry>& sig_extended,\n@@ -744,0 +755,1 @@\n+\n@@ -832,2 +844,2 @@\n-  for (int i = 0; i < total_args_passed; i++) {\n-    if (sig_bt[i] == T_VOID) {\n+  for (int i = 0; i < sig_extended.length(); i++) {\n+    if (sig_extended.at(i)._bt == T_VOID) {\n@@ -836,1 +848,1 @@\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n+      assert(i > 0 && (sig_extended.at(i-1)._bt == T_LONG || sig_extended.at(i-1)._bt == T_DOUBLE), \"missing half\");\n@@ -845,1 +857,1 @@\n-    int ld_off = (total_args_passed - i) * Interpreter::stackElementSize;\n+    int ld_off = (sig_extended.length() - i) * Interpreter::stackElementSize;\n@@ -886,1 +898,1 @@\n-        const int offset = (NOT_LP64(true ||) sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n+        const int offset = (NOT_LP64(true ||) sig_extended.at(i)._bt==T_LONG||sig_extended.at(i)._bt==T_DOUBLE)?\n@@ -904,1 +916,1 @@\n-        const int offset = (NOT_LP64(true ||) sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n+        const int offset = (NOT_LP64(true ||) sig_extended.at(i)._bt==T_LONG||sig_extended.at(i)._bt==T_DOUBLE)?\n@@ -952,2 +964,1 @@\n-                                                            int total_args_passed,\n-                                                            const BasicType *sig_bt,\n+                                                            const GrowableArray<SigEntry>& sig_extended,\n@@ -956,1 +967,2 @@\n-                                                            AdapterFingerPrint* fingerprint) {\n+                                                            AdapterFingerPrint* fingerprint,\n+                                                            AdapterBlob*& new_adapter) {\n@@ -959,1 +971,1 @@\n-  gen_i2c_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs);\n+  gen_i2c_adapter(masm, comp_args_on_stack, sig_extended, regs);\n@@ -999,1 +1011,4 @@\n-  gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);\n+  OopMapSet* oop_maps = NULL;\n+  int frame_complete = CodeOffsets::frame_never_safe;\n+  int frame_size_in_words = 0;\n+  gen_c2i_adapter(masm, sig_extended, regs, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words);\n@@ -1002,0 +1017,1 @@\n+  new_adapter = AdapterBlob::create(masm->code(), frame_complete, frame_size_in_words, oop_maps);\n@@ -1025,0 +1041,1 @@\n+    case T_INLINE_TYPE:\n@@ -1716,0 +1733,1 @@\n+      case T_INLINE_TYPE:\n@@ -1897,0 +1915,1 @@\n+  case T_INLINE_TYPE:           \/\/ Really a handle\n@@ -2995,0 +3014,5 @@\n+BufferedInlineTypeBlob* SharedRuntime::generate_buffered_inline_type_adapter(const InlineKlass* vk) {\n+  Unimplemented();\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":48,"deletions":24,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"classfile\/symbolTable.hpp\"\n@@ -540,0 +541,1 @@\n+    case T_INLINE_TYPE:\n@@ -573,0 +575,82 @@\n+\/\/ Same as java_calling_convention() but for multiple return\n+\/\/ values. There's no way to store them on the stack so if we don't\n+\/\/ have enough registers, multiple values can't be returned.\n+const uint SharedRuntime::java_return_convention_max_int = Argument::n_int_register_parameters_j+1;\n+const uint SharedRuntime::java_return_convention_max_float = Argument::n_float_register_parameters_j;\n+int SharedRuntime::java_return_convention(const BasicType *sig_bt,\n+                                          VMRegPair *regs,\n+                                          int total_args_passed) {\n+  \/\/ Create the mapping between argument positions and\n+  \/\/ registers.\n+  static const Register INT_ArgReg[java_return_convention_max_int] = {\n+    rax, j_rarg5, j_rarg4, j_rarg3, j_rarg2, j_rarg1, j_rarg0\n+  };\n+  static const XMMRegister FP_ArgReg[java_return_convention_max_float] = {\n+    j_farg0, j_farg1, j_farg2, j_farg3,\n+    j_farg4, j_farg5, j_farg6, j_farg7\n+  };\n+\n+\n+  uint int_args = 0;\n+  uint fp_args = 0;\n+\n+  for (int i = 0; i < total_args_passed; i++) {\n+    switch (sig_bt[i]) {\n+    case T_BOOLEAN:\n+    case T_CHAR:\n+    case T_BYTE:\n+    case T_SHORT:\n+    case T_INT:\n+      if (int_args < Argument::n_int_register_parameters_j+1) {\n+        regs[i].set1(INT_ArgReg[int_args]->as_VMReg());\n+        int_args++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_VOID:\n+      \/\/ halves of T_LONG or T_DOUBLE\n+      assert(i != 0 && (sig_bt[i - 1] == T_LONG || sig_bt[i - 1] == T_DOUBLE), \"expecting half\");\n+      regs[i].set_bad();\n+      break;\n+    case T_LONG:\n+      assert(sig_bt[i + 1] == T_VOID, \"expecting half\");\n+      \/\/ fall through\n+    case T_OBJECT:\n+    case T_INLINE_TYPE:\n+    case T_ARRAY:\n+    case T_ADDRESS:\n+    case T_METADATA:\n+      if (int_args < Argument::n_int_register_parameters_j+1) {\n+        regs[i].set2(INT_ArgReg[int_args]->as_VMReg());\n+        int_args++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_FLOAT:\n+      if (fp_args < Argument::n_float_register_parameters_j) {\n+        regs[i].set1(FP_ArgReg[fp_args]->as_VMReg());\n+        fp_args++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    case T_DOUBLE:\n+      assert(sig_bt[i + 1] == T_VOID, \"expecting half\");\n+      if (fp_args < Argument::n_float_register_parameters_j) {\n+        regs[i].set2(FP_ArgReg[fp_args]->as_VMReg());\n+        fp_args++;\n+      } else {\n+        return -1;\n+      }\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+      break;\n+    }\n+  }\n+\n+  return int_args + fp_args;\n+}\n+\n@@ -615,0 +699,106 @@\n+\/\/ For each inline type argument, sig includes the list of fields of\n+\/\/ the inline type. This utility function computes the number of\n+\/\/ arguments for the call if inline types are passed by reference (the\n+\/\/ calling convention the interpreter expects).\n+static int compute_total_args_passed_int(const GrowableArray<SigEntry>* sig_extended) {\n+  int total_args_passed = 0;\n+  if (InlineTypePassFieldsAsArgs) {\n+    for (int i = 0; i < sig_extended->length(); i++) {\n+      BasicType bt = sig_extended->at(i)._bt;\n+      if (bt == T_INLINE_TYPE) {\n+        \/\/ In sig_extended, an inline type argument starts with:\n+        \/\/ T_INLINE_TYPE, followed by the types of the fields of the\n+        \/\/ inline type and T_VOID to mark the end of the value\n+        \/\/ type. Inline types are flattened so, for instance, in the\n+        \/\/ case of an inline type with an int field and an inline type\n+        \/\/ field that itself has 2 fields, an int and a long:\n+        \/\/ T_INLINE_TYPE T_INT T_INLINE_TYPE T_INT T_LONG T_VOID (second\n+        \/\/ slot for the T_LONG) T_VOID (inner T_INLINE_TYPE) T_VOID\n+        \/\/ (outer T_INLINE_TYPE)\n+        total_args_passed++;\n+        int vt = 1;\n+        do {\n+          i++;\n+          BasicType bt = sig_extended->at(i)._bt;\n+          BasicType prev_bt = sig_extended->at(i-1)._bt;\n+          if (bt == T_INLINE_TYPE) {\n+            vt++;\n+          } else if (bt == T_VOID &&\n+                     prev_bt != T_LONG &&\n+                     prev_bt != T_DOUBLE) {\n+            vt--;\n+          }\n+        } while (vt != 0);\n+      } else {\n+        total_args_passed++;\n+      }\n+    }\n+  } else {\n+    total_args_passed = sig_extended->length();\n+  }\n+  return total_args_passed;\n+}\n+\n+\n+static void gen_c2i_adapter_helper(MacroAssembler* masm,\n+                                   BasicType bt,\n+                                   BasicType prev_bt,\n+                                   size_t size_in_bytes,\n+                                   const VMRegPair& reg_pair,\n+                                   const Address& to,\n+                                   int extraspace,\n+                                   bool is_oop) {\n+  assert(bt != T_INLINE_TYPE || !InlineTypePassFieldsAsArgs, \"no inline type here\");\n+  if (bt == T_VOID) {\n+    assert(prev_bt == T_LONG || prev_bt == T_DOUBLE, \"missing half\");\n+    return;\n+  }\n+\n+  \/\/ Say 4 args:\n+  \/\/ i   st_off\n+  \/\/ 0   32 T_LONG\n+  \/\/ 1   24 T_VOID\n+  \/\/ 2   16 T_OBJECT\n+  \/\/ 3    8 T_BOOL\n+  \/\/ -    0 return address\n+  \/\/\n+  \/\/ However to make thing extra confusing. Because we can fit a long\/double in\n+  \/\/ a single slot on a 64 bt vm and it would be silly to break them up, the interpreter\n+  \/\/ leaves one slot empty and only stores to a single slot. In this case the\n+  \/\/ slot that is occupied is the T_VOID slot. See I said it was confusing.\n+\n+  bool wide = (size_in_bytes == wordSize);\n+  VMReg r_1 = reg_pair.first();\n+  VMReg r_2 = reg_pair.second();\n+  assert(r_2->is_valid() == wide, \"invalid size\");\n+  if (!r_1->is_valid()) {\n+    assert(!r_2->is_valid(), \"must be invalid\");\n+    return;\n+  }\n+\n+  if (!r_1->is_XMMRegister()) {\n+    Register val = rax;\n+    if (r_1->is_stack()) {\n+      int ld_off = r_1->reg2stack() * VMRegImpl::stack_slot_size + extraspace;\n+      __ load_sized_value(val, Address(rsp, ld_off), size_in_bytes, \/* is_signed *\/ false);\n+    } else {\n+      val = r_1->as_Register();\n+    }\n+    assert_different_registers(to.base(), val, rscratch1);\n+    if (is_oop) {\n+      __ push(r13);\n+      __ push(rbx);\n+      __ store_heap_oop(to, val, rscratch1, r13, rbx, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      __ pop(rbx);\n+      __ pop(r13);\n+    } else {\n+      __ store_sized_value(to, val, size_in_bytes);\n+    }\n+  } else {\n+    if (wide) {\n+      __ movdbl(to, r_1->as_XMMRegister());\n+    } else {\n+      __ movflt(to, r_1->as_XMMRegister());\n+    }\n+  }\n+}\n@@ -617,3 +807,1 @@\n-                            int total_args_passed,\n-                            int comp_args_on_stack,\n-                            const BasicType *sig_bt,\n+                            const GrowableArray<SigEntry>* sig_extended,\n@@ -621,1 +809,6 @@\n-                            Label& skip_fixup) {\n+                            Label& skip_fixup,\n+                            address start,\n+                            OopMapSet* oop_maps,\n+                            int& frame_complete,\n+                            int& frame_size_in_words,\n+                            bool alloc_inline_receiver) {\n@@ -631,0 +824,42 @@\n+  if (InlineTypePassFieldsAsArgs) {\n+    \/\/ Is there an inline type argument?\n+    bool has_inline_argument = false;\n+    for (int i = 0; i < sig_extended->length() && !has_inline_argument; i++) {\n+      has_inline_argument = (sig_extended->at(i)._bt == T_INLINE_TYPE);\n+    }\n+    if (has_inline_argument) {\n+      \/\/ There is at least an inline type argument: we're coming from\n+      \/\/ compiled code so we have no buffers to back the inline types.\n+      \/\/ Allocate the buffers here with a runtime call.\n+      OopMap* map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ false);\n+\n+      frame_complete = __ offset();\n+\n+      __ set_last_Java_frame(noreg, noreg, NULL);\n+\n+      __ mov(c_rarg0, r15_thread);\n+      __ mov(c_rarg1, rbx);\n+      __ mov64(c_rarg2, (int64_t)alloc_inline_receiver);\n+      __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::allocate_inline_types)));\n+\n+      oop_maps->add_gc_map((int)(__ pc() - start), map);\n+      __ reset_last_Java_frame(false);\n+\n+      RegisterSaver::restore_live_registers(masm);\n+\n+      Label no_exception;\n+      __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), (int32_t)NULL_WORD);\n+      __ jcc(Assembler::equal, no_exception);\n+\n+      __ movptr(Address(r15_thread, JavaThread::vm_result_offset()), (int)NULL_WORD);\n+      __ movptr(rax, Address(r15_thread, Thread::pending_exception_offset()));\n+      __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+      __ bind(no_exception);\n+\n+      \/\/ We get an array of objects from the runtime call\n+      __ get_vm_result(rscratch2, r15_thread); \/\/ Use rscratch2 (r11) as temporary because rscratch1 (r10) is trashed by movptr()\n+      __ get_vm_result_2(rbx, r15_thread); \/\/ TODO: required to keep the callee Method live?\n+    }\n+  }\n+\n@@ -635,1 +870,1 @@\n-\n+  int total_args_passed = compute_total_args_passed_int(sig_extended);\n@@ -653,46 +888,24 @@\n-  for (int i = 0; i < total_args_passed; i++) {\n-    if (sig_bt[i] == T_VOID) {\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n-      continue;\n-    }\n-\n-    \/\/ offset to start parameters\n-    int st_off   = (total_args_passed - i) * Interpreter::stackElementSize;\n-    int next_off = st_off - Interpreter::stackElementSize;\n-\n-    \/\/ Say 4 args:\n-    \/\/ i   st_off\n-    \/\/ 0   32 T_LONG\n-    \/\/ 1   24 T_VOID\n-    \/\/ 2   16 T_OBJECT\n-    \/\/ 3    8 T_BOOL\n-    \/\/ -    0 return address\n-    \/\/\n-    \/\/ However to make thing extra confusing. Because we can fit a long\/double in\n-    \/\/ a single slot on a 64 bt vm and it would be silly to break them up, the interpreter\n-    \/\/ leaves one slot empty and only stores to a single slot. In this case the\n-    \/\/ slot that is occupied is the T_VOID slot. See I said it was confusing.\n-\n-    VMReg r_1 = regs[i].first();\n-    VMReg r_2 = regs[i].second();\n-    if (!r_1->is_valid()) {\n-      assert(!r_2->is_valid(), \"\");\n-      continue;\n-    }\n-    if (r_1->is_stack()) {\n-      \/\/ memory to memory use rax\n-      int ld_off = r_1->reg2stack() * VMRegImpl::stack_slot_size + extraspace;\n-      if (!r_2->is_valid()) {\n-        \/\/ sign extend??\n-        __ movl(rax, Address(rsp, ld_off));\n-        __ movptr(Address(rsp, st_off), rax);\n-\n-      } else {\n-\n-        __ movq(rax, Address(rsp, ld_off));\n-        \/\/ Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG\n-        \/\/ T_DOUBLE and T_LONG use two slots in the interpreter\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n-          \/\/ ld_off == LSW, ld_off+wordSize == MSW\n-          \/\/ st_off == MSW, next_off == LSW\n-          __ movq(Address(rsp, next_off), rax);\n+  \/\/ next_arg_comp is the next argument from the compiler point of\n+  \/\/ view (inline type fields are passed in registers\/on the stack). In\n+  \/\/ sig_extended, an inline type argument starts with: T_INLINE_TYPE,\n+  \/\/ followed by the types of the fields of the inline type and T_VOID\n+  \/\/ to mark the end of the inline type. ignored counts the number of\n+  \/\/ T_INLINE_TYPE\/T_VOID. next_vt_arg is the next inline type argument:\n+  \/\/ used to get the buffer for that argument from the pool of buffers\n+  \/\/ we allocated above and want to pass to the\n+  \/\/ interpreter. next_arg_int is the next argument from the\n+  \/\/ interpreter point of view (inline types are passed by reference).\n+  for (int next_arg_comp = 0, ignored = 0, next_vt_arg = 0, next_arg_int = 0;\n+       next_arg_comp < sig_extended->length(); next_arg_comp++) {\n+    assert(ignored <= next_arg_comp, \"shouldn't skip over more slots than there are arguments\");\n+    assert(next_arg_int <= total_args_passed, \"more arguments for the interpreter than expected?\");\n+    BasicType bt = sig_extended->at(next_arg_comp)._bt;\n+    int st_off = (total_args_passed - next_arg_int) * Interpreter::stackElementSize;\n+    if (!InlineTypePassFieldsAsArgs || bt != T_INLINE_TYPE) {\n+      int next_off = st_off - Interpreter::stackElementSize;\n+      const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : st_off;\n+      const VMRegPair reg_pair = regs[next_arg_comp-ignored];\n+      size_t size_in_bytes = reg_pair.second()->is_valid() ? 8 : 4;\n+      gen_c2i_adapter_helper(masm, bt, next_arg_comp > 0 ? sig_extended->at(next_arg_comp-1)._bt : T_ILLEGAL,\n+                             size_in_bytes, reg_pair, Address(rsp, offset), extraspace, false);\n+      next_arg_int++;\n@@ -701,7 +914,4 @@\n-          \/\/ Overwrite the unused slot with known junk\n-          __ mov64(rax, CONST64(0xdeadffffdeadaaaa));\n-          __ movptr(Address(rsp, st_off), rax);\n-#endif \/* ASSERT *\/\n-        } else {\n-          __ movq(Address(rsp, st_off), rax);\n-        }\n+      if (bt == T_LONG || bt == T_DOUBLE) {\n+        \/\/ Overwrite the unused slot with known junk\n+        __ mov64(rax, CONST64(0xdeadffffdeadaaaa));\n+        __ movptr(Address(rsp, st_off), rax);\n@@ -709,16 +919,25 @@\n-    } else if (r_1->is_Register()) {\n-      Register r = r_1->as_Register();\n-      if (!r_2->is_valid()) {\n-        \/\/ must be only an int (or less ) so move only 32bits to slot\n-        \/\/ why not sign extend??\n-        __ movl(Address(rsp, st_off), r);\n-      } else {\n-        \/\/ Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG\n-        \/\/ T_DOUBLE and T_LONG use two slots in the interpreter\n-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {\n-          \/\/ long\/double in gpr\n-#ifdef ASSERT\n-          \/\/ Overwrite the unused slot with known junk\n-          __ mov64(rax, CONST64(0xdeadffffdeadaaab));\n-          __ movptr(Address(rsp, st_off), rax);\n-          __ movq(Address(rsp, next_off), r);\n+    } else {\n+      ignored++;\n+      \/\/ get the buffer from the just allocated pool of buffers\n+      int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_INLINE_TYPE);\n+      __ load_heap_oop(r14, Address(rscratch2, index));\n+      next_vt_arg++; next_arg_int++;\n+      int vt = 1;\n+      \/\/ write fields we get from compiled code in registers\/stack\n+      \/\/ slots to the buffer: we know we are done with that inline type\n+      \/\/ argument when we hit the T_VOID that acts as an end of inline\n+      \/\/ type delimiter for this inline type. Inline types are flattened\n+      \/\/ so we might encounter embedded inline types. Each entry in\n+      \/\/ sig_extended contains a field offset in the buffer.\n+      do {\n+        next_arg_comp++;\n+        BasicType bt = sig_extended->at(next_arg_comp)._bt;\n+        BasicType prev_bt = sig_extended->at(next_arg_comp-1)._bt;\n+        if (bt == T_INLINE_TYPE) {\n+          vt++;\n+          ignored++;\n+        } else if (bt == T_VOID &&\n+                   prev_bt != T_LONG &&\n+                   prev_bt != T_DOUBLE) {\n+          vt--;\n+          ignored++;\n@@ -727,1 +946,6 @@\n-          __ movptr(Address(rsp, st_off), r);\n+          int off = sig_extended->at(next_arg_comp)._offset;\n+          assert(off > 0, \"offset in object should be positive\");\n+          size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;\n+          bool is_oop = is_reference_type(bt);\n+          gen_c2i_adapter_helper(masm, bt, next_arg_comp > 0 ? sig_extended->at(next_arg_comp-1)._bt : T_ILLEGAL,\n+                                 size_in_bytes, regs[next_arg_comp-ignored], Address(r14, off), extraspace, is_oop);\n@@ -729,14 +953,3 @@\n-      }\n-    } else {\n-      assert(r_1->is_XMMRegister(), \"\");\n-      if (!r_2->is_valid()) {\n-        \/\/ only a float use just part of the slot\n-        __ movflt(Address(rsp, st_off), r_1->as_XMMRegister());\n-      } else {\n-#ifdef ASSERT\n-        \/\/ Overwrite the unused slot with known junk\n-        __ mov64(rax, CONST64(0xdeadffffdeadaaac));\n-        __ movptr(Address(rsp, st_off), rax);\n-#endif \/* ASSERT *\/\n-        __ movdbl(Address(rsp, next_off), r_1->as_XMMRegister());\n-      }\n+      } while (vt != 0);\n+      \/\/ pass the buffer to the interpreter\n+      __ movptr(Address(rsp, st_off), r14);\n@@ -765,2 +978,1 @@\n-                                    int total_args_passed,\n-                                    const BasicType *sig_bt,\n+                                    const GrowableArray<SigEntry>* sig,\n@@ -859,1 +1071,1 @@\n-  __ movptr(r11, Address(rbx, in_bytes(Method::from_compiled_offset())));\n+  __ movptr(r11, Address(rbx, in_bytes(Method::from_compiled_inline_offset())));\n@@ -873,0 +1085,2 @@\n+  int total_args_passed = sig->length();\n+\n@@ -876,1 +1090,3 @@\n-    if (sig_bt[i] == T_VOID) {\n+    BasicType bt = sig->at(i)._bt;\n+    assert(bt != T_INLINE_TYPE, \"i2c adapter doesn't unpack inline type args\");\n+    if (bt == T_VOID) {\n@@ -879,1 +1095,2 @@\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n+      BasicType prev_bt = (i > 0) ? sig->at(i-1)._bt : T_ILLEGAL;\n+      assert(i > 0 && (prev_bt == T_LONG || prev_bt == T_DOUBLE), \"missing half\");\n@@ -921,1 +1138,1 @@\n-        const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n+        const int offset = (bt==T_LONG||bt==T_DOUBLE)?\n@@ -936,1 +1153,1 @@\n-        const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?\n+        const int offset = (bt==T_LONG||bt==T_DOUBLE)?\n@@ -967,1 +1184,1 @@\n-  \/\/ only needed becaus eof c2 resolve stubs return Method* as a result in\n+  \/\/ only needed because of c2 resolve stubs return Method* as a result in\n@@ -973,0 +1190,22 @@\n+static void gen_inline_cache_check(MacroAssembler *masm, Label& skip_fixup) {\n+  Label ok;\n+\n+  Register holder = rax;\n+  Register receiver = j_rarg0;\n+  Register temp = rbx;\n+\n+  __ load_klass(temp, receiver, rscratch1);\n+  __ cmpptr(temp, Address(holder, CompiledICHolder::holder_klass_offset()));\n+  __ movptr(rbx, Address(holder, CompiledICHolder::holder_metadata_offset()));\n+  __ jcc(Assembler::equal, ok);\n+  __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+\n+  __ bind(ok);\n+  \/\/ Method might have been compiled since the call site was patched to\n+  \/\/ interpreted if that is the case treat it as a miss so we can get\n+  \/\/ the call site corrected.\n+  __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);\n+  __ jcc(Assembler::equal, skip_fixup);\n+  __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+}\n+\n@@ -975,4 +1214,8 @@\n-                                                            int total_args_passed,\n-                                                            const BasicType *sig_bt,\n-                                                            const VMRegPair *regs,\n-                                                            AdapterFingerPrint* fingerprint) {\n+                                                            const GrowableArray<SigEntry>* sig,\n+                                                            const VMRegPair* regs,\n+                                                            const GrowableArray<SigEntry>* sig_cc,\n+                                                            const VMRegPair* regs_cc,\n+                                                            const GrowableArray<SigEntry>* sig_cc_ro,\n+                                                            const VMRegPair* regs_cc_ro,\n+                                                            AdapterFingerPrint* fingerprint,\n+                                                            AdapterBlob*& new_adapter) {\n@@ -981,2 +1224,1 @@\n-\n-  gen_i2c_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs);\n+  gen_i2c_adapter(masm, comp_args_on_stack, sig, regs);\n@@ -995,11 +1237,1 @@\n-  Label ok;\n-\n-  Register holder = rax;\n-  Register receiver = j_rarg0;\n-  Register temp = rbx;\n-  {\n-    __ load_klass(temp, receiver, rscratch1);\n-    __ cmpptr(temp, Address(holder, CompiledICHolder::holder_klass_offset()));\n-    __ movptr(rbx, Address(holder, CompiledICHolder::holder_metadata_offset()));\n-    __ jcc(Assembler::equal, ok);\n-    __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+  gen_inline_cache_check(masm, skip_fixup);\n@@ -1008,7 +1240,9 @@\n-    __ bind(ok);\n-    \/\/ Method might have been compiled since the call site was patched to\n-    \/\/ interpreted if that is the case treat it as a miss so we can get\n-    \/\/ the call site corrected.\n-    __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);\n-    __ jcc(Assembler::equal, skip_fixup);\n-    __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+  OopMapSet* oop_maps = new OopMapSet();\n+  int frame_complete = CodeOffsets::frame_never_safe;\n+  int frame_size_in_words = 0;\n+\n+  \/\/ Scalarized c2i adapter with non-scalarized receiver (i.e., don't pack receiver)\n+  address c2i_inline_ro_entry = __ pc();\n+  if (regs_cc != regs_cc_ro) {\n+    gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);\n+    skip_fixup.reset();\n@@ -1017,0 +1251,1 @@\n+  \/\/ Scalarized c2i adapter\n@@ -1045,1 +1280,14 @@\n-  gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);\n+  gen_c2i_adapter(masm, sig_cc, regs_cc, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, true);\n+\n+  address c2i_unverified_inline_entry = c2i_unverified_entry;\n+\n+  \/\/ Non-scalarized c2i adapter\n+  address c2i_inline_entry = c2i_entry;\n+  if (regs != regs_cc) {\n+    Label inline_entry_skip_fixup;\n+    c2i_unverified_inline_entry = __ pc();\n+    gen_inline_cache_check(masm, inline_entry_skip_fixup);\n+\n+    c2i_inline_entry = __ pc();\n+    gen_c2i_adapter(masm, sig, regs, inline_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);\n+  }\n@@ -1048,1 +1296,7 @@\n-  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+\n+  \/\/ The c2i adapters might safepoint and trigger a GC. The caller must make sure that\n+  \/\/ the GC knows about the location of oop argument locations passed to the c2i adapter.\n+  bool caller_must_gc_arguments = (regs != regs_cc);\n+  new_adapter = AdapterBlob::create(masm->code(), frame_complete, frame_size_in_words, oop_maps, caller_must_gc_arguments);\n+\n+  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry, c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -1106,0 +1360,1 @@\n+      case T_INLINE_TYPE:\n@@ -2139,0 +2394,1 @@\n+      case T_INLINE_TYPE:\n@@ -2274,0 +2530,6 @@\n+    if (EnableValhalla) {\n+      assert(!UseBiasedLocking, \"Not compatible with biased-locking\");\n+      \/\/ Mask inline_type bit such that we go to the slow path if object is an inline type\n+      __ andptr(swap_reg, ~((int) markWord::inline_type_bit_in_place));\n+    }\n+\n@@ -2333,0 +2595,1 @@\n+  case T_INLINE_TYPE:           \/\/ Really a handle\n@@ -4092,0 +4355,111 @@\n+\n+BufferedInlineTypeBlob* SharedRuntime::generate_buffered_inline_type_adapter(const InlineKlass* vk) {\n+  BufferBlob* buf = BufferBlob::create(\"inline types pack\/unpack\", 16 * K);\n+  CodeBuffer buffer(buf);\n+  short buffer_locs[20];\n+  buffer.insts()->initialize_shared_locs((relocInfo*)buffer_locs,\n+                                         sizeof(buffer_locs)\/sizeof(relocInfo));\n+\n+  MacroAssembler* masm = new MacroAssembler(&buffer);\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  int pack_fields_jobject_off = __ offset();\n+  \/\/ Resolve pre-allocated buffer from JNI handle.\n+  \/\/ We cannot do this in generate_call_stub() because it requires GC code to be initialized.\n+  __ movptr(rax, Address(r13, 0));\n+  __ resolve_jobject(rax \/* value *\/,\n+                     r15_thread \/* thread *\/,\n+                     r12 \/* tmp *\/);\n+  __ movptr(Address(r13, 0), rax);\n+\n+  int pack_fields_off = __ offset();\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    VMReg r_1 = pair.first();\n+    VMReg r_2 = pair.second();\n+    Address to(rax, off);\n+    if (bt == T_FLOAT) {\n+      __ movflt(to, r_1->as_XMMRegister());\n+    } else if (bt == T_DOUBLE) {\n+      __ movdbl(to, r_1->as_XMMRegister());\n+    } else {\n+      Register val = r_1->as_Register();\n+      assert_different_registers(to.base(), val, r14, r13, rbx, rscratch1);\n+      if (is_reference_type(bt)) {\n+        __ store_heap_oop(to, val, r14, r13, rbx, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);\n+      } else {\n+        __ store_sized_value(to, r_1->as_Register(), type2aelembytes(bt));\n+      }\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+  __ ret(0);\n+\n+  int unpack_fields_off = __ offset();\n+\n+  j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    VMReg r_1 = pair.first();\n+    VMReg r_2 = pair.second();\n+    Address from(rax, off);\n+    if (bt == T_FLOAT) {\n+      __ movflt(r_1->as_XMMRegister(), from);\n+    } else if (bt == T_DOUBLE) {\n+      __ movdbl(r_1->as_XMMRegister(), from);\n+    } else if (bt == T_OBJECT || bt == T_ARRAY) {\n+      assert_different_registers(rax, r_1->as_Register());\n+      __ load_heap_oop(r_1->as_Register(), from);\n+    } else {\n+      assert(is_java_primitive(bt), \"unexpected basic type\");\n+      assert_different_registers(rax, r_1->as_Register());\n+      size_t size_in_bytes = type2aelembytes(bt);\n+      __ load_sized_value(r_1->as_Register(), from, size_in_bytes, bt != T_CHAR && bt != T_BOOLEAN);\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+  if (StressInlineTypeReturnedAsFields) {\n+    __ load_klass(rax, rax, rscratch1);\n+    __ orptr(rax, 1);\n+  }\n+\n+  __ ret(0);\n+\n+  __ flush();\n+\n+  return BufferedInlineTypeBlob::create(&buffer, pack_fields_off, pack_fields_jobject_off, unpack_fields_off);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":497,"deletions":123,"binary":false,"changes":620,"status":"modified"},{"patch":"@@ -344,5 +344,5 @@\n-    \/\/ T_OBJECT, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n-    __ movptr(c_rarg0, result);\n-    Label is_long, is_float, is_double, exit;\n-    __ movl(c_rarg1, result_type);\n-    __ cmpl(c_rarg1, T_OBJECT);\n+    \/\/ T_OBJECT, T_INLINE_TYPE, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n+    __ movptr(r13, result);\n+    Label is_long, is_float, is_double, is_value, exit;\n+    __ movl(rbx, result_type);\n+    __ cmpl(rbx, T_OBJECT);\n@@ -350,1 +350,3 @@\n-    __ cmpl(c_rarg1, T_LONG);\n+    __ cmpl(rbx, T_INLINE_TYPE);\n+    __ jcc(Assembler::equal, is_value);\n+    __ cmpl(rbx, T_LONG);\n@@ -352,1 +354,1 @@\n-    __ cmpl(c_rarg1, T_FLOAT);\n+    __ cmpl(rbx, T_FLOAT);\n@@ -354,1 +356,1 @@\n-    __ cmpl(c_rarg1, T_DOUBLE);\n+    __ cmpl(rbx, T_DOUBLE);\n@@ -358,1 +360,1 @@\n-    __ movl(Address(c_rarg0, 0), rax);\n+    __ movl(Address(r13, 0), rax);\n@@ -420,0 +422,13 @@\n+    __ BIND(is_value);\n+    if (InlineTypeReturnedAsFields) {\n+      \/\/ Check for flattened return value\n+      __ testptr(rax, 1);\n+      __ jcc(Assembler::zero, is_long);\n+      \/\/ Load pack handler address\n+      __ andptr(rax, -2);\n+      __ movptr(rax, Address(rax, InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+      __ movptr(rbx, Address(rax, InlineKlass::pack_handler_jobject_offset()));\n+      \/\/ Call pack handler to initialize the buffer\n+      __ call(rbx);\n+      __ jmp(exit);\n+    }\n@@ -421,1 +436,1 @@\n-    __ movq(Address(c_rarg0, 0), rax);\n+    __ movq(Address(r13, 0), rax);\n@@ -425,1 +440,1 @@\n-    __ movflt(Address(c_rarg0, 0), xmm0);\n+    __ movflt(Address(r13, 0), xmm0);\n@@ -429,1 +444,1 @@\n-    __ movdbl(Address(c_rarg0, 0), xmm0);\n+    __ movdbl(Address(r13, 0), xmm0);\n@@ -2843,1 +2858,1 @@\n-    __ store_heap_oop(to_element_addr, rax_oop, noreg, noreg, AS_RAW);  \/\/ store the oop\n+    __ store_heap_oop(to_element_addr, rax_oop, noreg, noreg, noreg, AS_RAW);  \/\/ store the oop\n@@ -3138,0 +3153,8 @@\n+    \/\/ Check for flat inline type array -> return -1\n+    __ testl(rax_lh, Klass::_lh_array_tag_vt_value_bit_inplace);\n+    __ jcc(Assembler::notZero, L_failed);\n+\n+    \/\/ Check for null-free (non-flat) inline type array -> handle as object array\n+    __ testl(rax_lh, Klass::_lh_null_free_bit_inplace);\n+    __ jcc(Assembler::notZero, L_objArray);\n+\n@@ -3147,2 +3170,4 @@\n-      __ cmpl(rax_lh, (Klass::_lh_array_tag_type_value << Klass::_lh_array_tag_shift));\n-      __ jcc(Assembler::greaterEqual, L);\n+      __ movl(rklass_tmp, rax_lh);\n+      __ sarl(rklass_tmp, Klass::_lh_array_tag_shift);\n+      __ cmpl(rklass_tmp, Klass::_lh_array_tag_type_value);\n+      __ jcc(Assembler::equal, L);\n@@ -3256,0 +3281,1 @@\n+      \/\/ This check also fails for flat\/null-free arrays which are not supported.\n@@ -3259,0 +3285,13 @@\n+#ifdef ASSERT\n+      {\n+        BLOCK_COMMENT(\"assert not null-free array {\");\n+        Label L;\n+        __ movl(rklass_tmp, Address(rax, lh_offset));\n+        __ testl(rklass_tmp, Klass::_lh_null_free_bit_inplace);\n+        __ jcc(Assembler::zero, L);\n+        __ stop(\"unexpected null-free array\");\n+        __ bind(L);\n+        BLOCK_COMMENT(\"} assert not null-free array\");\n+      }\n+#endif\n+\n@@ -6695,0 +6734,140 @@\n+  \/\/ Call here from the interpreter or compiled code to either load\n+  \/\/ multiple returned values from the inline type instance being\n+  \/\/ returned to registers or to store returned values to a newly\n+  \/\/ allocated inline type instance.\n+  address generate_return_value_stub(address destination, const char* name, bool has_res) {\n+    \/\/ We need to save all registers the calling convention may use so\n+    \/\/ the runtime calls read or update those registers. This needs to\n+    \/\/ be in sync with SharedRuntime::java_return_convention().\n+    enum layout {\n+      pad_off = frame::arg_reg_save_area_bytes\/BytesPerInt, pad_off_2,\n+      rax_off, rax_off_2,\n+      j_rarg5_off, j_rarg5_2,\n+      j_rarg4_off, j_rarg4_2,\n+      j_rarg3_off, j_rarg3_2,\n+      j_rarg2_off, j_rarg2_2,\n+      j_rarg1_off, j_rarg1_2,\n+      j_rarg0_off, j_rarg0_2,\n+      j_farg0_off, j_farg0_2,\n+      j_farg1_off, j_farg1_2,\n+      j_farg2_off, j_farg2_2,\n+      j_farg3_off, j_farg3_2,\n+      j_farg4_off, j_farg4_2,\n+      j_farg5_off, j_farg5_2,\n+      j_farg6_off, j_farg6_2,\n+      j_farg7_off, j_farg7_2,\n+      rbp_off, rbp_off_2,\n+      return_off, return_off_2,\n+\n+      framesize\n+    };\n+\n+    CodeBuffer buffer(name, 1000, 512);\n+    MacroAssembler* masm = new MacroAssembler(&buffer);\n+\n+    int frame_size_in_bytes = align_up(framesize*BytesPerInt, 16);\n+    assert(frame_size_in_bytes == framesize*BytesPerInt, \"misaligned\");\n+    int frame_size_in_slots = frame_size_in_bytes \/ BytesPerInt;\n+    int frame_size_in_words = frame_size_in_bytes \/ wordSize;\n+\n+    OopMapSet *oop_maps = new OopMapSet();\n+    OopMap* map = new OopMap(frame_size_in_slots, 0);\n+\n+    map->set_callee_saved(VMRegImpl::stack2reg(rax_off), rax->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg5_off), j_rarg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg4_off), j_rarg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg3_off), j_rarg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg2_off), j_rarg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg1_off), j_rarg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_rarg0_off), j_rarg0->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg0_off), j_farg0->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg1_off), j_farg1->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg2_off), j_farg2->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg3_off), j_farg3->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg4_off), j_farg4->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg5_off), j_farg5->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg6_off), j_farg6->as_VMReg());\n+    map->set_callee_saved(VMRegImpl::stack2reg(j_farg7_off), j_farg7->as_VMReg());\n+\n+    int start = __ offset();\n+\n+    __ subptr(rsp, frame_size_in_bytes - 8 \/* return address*\/);\n+\n+    __ movptr(Address(rsp, rbp_off * BytesPerInt), rbp);\n+    __ movdbl(Address(rsp, j_farg7_off * BytesPerInt), j_farg7);\n+    __ movdbl(Address(rsp, j_farg6_off * BytesPerInt), j_farg6);\n+    __ movdbl(Address(rsp, j_farg5_off * BytesPerInt), j_farg5);\n+    __ movdbl(Address(rsp, j_farg4_off * BytesPerInt), j_farg4);\n+    __ movdbl(Address(rsp, j_farg3_off * BytesPerInt), j_farg3);\n+    __ movdbl(Address(rsp, j_farg2_off * BytesPerInt), j_farg2);\n+    __ movdbl(Address(rsp, j_farg1_off * BytesPerInt), j_farg1);\n+    __ movdbl(Address(rsp, j_farg0_off * BytesPerInt), j_farg0);\n+\n+    __ movptr(Address(rsp, j_rarg0_off * BytesPerInt), j_rarg0);\n+    __ movptr(Address(rsp, j_rarg1_off * BytesPerInt), j_rarg1);\n+    __ movptr(Address(rsp, j_rarg2_off * BytesPerInt), j_rarg2);\n+    __ movptr(Address(rsp, j_rarg3_off * BytesPerInt), j_rarg3);\n+    __ movptr(Address(rsp, j_rarg4_off * BytesPerInt), j_rarg4);\n+    __ movptr(Address(rsp, j_rarg5_off * BytesPerInt), j_rarg5);\n+    __ movptr(Address(rsp, rax_off * BytesPerInt), rax);\n+\n+    int frame_complete = __ offset();\n+\n+    __ set_last_Java_frame(noreg, noreg, NULL);\n+\n+    __ mov(c_rarg0, r15_thread);\n+    __ mov(c_rarg1, rax);\n+\n+    __ call(RuntimeAddress(destination));\n+\n+    \/\/ Set an oopmap for the call site.\n+\n+    oop_maps->add_gc_map( __ offset() - start, map);\n+\n+    \/\/ clear last_Java_sp\n+    __ reset_last_Java_frame(false);\n+\n+    __ movptr(rbp, Address(rsp, rbp_off * BytesPerInt));\n+    __ movdbl(j_farg7, Address(rsp, j_farg7_off * BytesPerInt));\n+    __ movdbl(j_farg6, Address(rsp, j_farg6_off * BytesPerInt));\n+    __ movdbl(j_farg5, Address(rsp, j_farg5_off * BytesPerInt));\n+    __ movdbl(j_farg4, Address(rsp, j_farg4_off * BytesPerInt));\n+    __ movdbl(j_farg3, Address(rsp, j_farg3_off * BytesPerInt));\n+    __ movdbl(j_farg2, Address(rsp, j_farg2_off * BytesPerInt));\n+    __ movdbl(j_farg1, Address(rsp, j_farg1_off * BytesPerInt));\n+    __ movdbl(j_farg0, Address(rsp, j_farg0_off * BytesPerInt));\n+\n+    __ movptr(j_rarg0, Address(rsp, j_rarg0_off * BytesPerInt));\n+    __ movptr(j_rarg1, Address(rsp, j_rarg1_off * BytesPerInt));\n+    __ movptr(j_rarg2, Address(rsp, j_rarg2_off * BytesPerInt));\n+    __ movptr(j_rarg3, Address(rsp, j_rarg3_off * BytesPerInt));\n+    __ movptr(j_rarg4, Address(rsp, j_rarg4_off * BytesPerInt));\n+    __ movptr(j_rarg5, Address(rsp, j_rarg5_off * BytesPerInt));\n+    __ movptr(rax, Address(rsp, rax_off * BytesPerInt));\n+\n+    __ addptr(rsp, frame_size_in_bytes-8);\n+\n+    \/\/ check for pending exceptions\n+    Label pending;\n+    __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), (int32_t)NULL_WORD);\n+    __ jcc(Assembler::notEqual, pending);\n+\n+    if (has_res) {\n+      __ get_vm_result(rax, r15_thread);\n+    }\n+\n+    __ ret(0);\n+\n+    __ bind(pending);\n+\n+    __ movptr(rax, Address(r15_thread, Thread::pending_exception_offset()));\n+    __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n+\n+    \/\/ -------------\n+    \/\/ make sure all code is generated\n+    masm->flush();\n+\n+    RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &buffer, frame_complete, frame_size_in_words, oop_maps, false);\n+    return stub->entry_point();\n+  }\n+\n@@ -6710,2 +6889,8 @@\n-    StubRoutines::_call_stub_entry =\n-      generate_call_stub(StubRoutines::_call_stub_return_address);\n+    \/\/ Generate these first because they are called from other stubs\n+    if (InlineTypeReturnedAsFields) {\n+      StubRoutines::_load_inline_type_fields_in_regs =\n+        generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), \"load_inline_type_fields_in_regs\", false);\n+      StubRoutines::_store_inline_type_fields_to_buf =\n+        generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), \"store_inline_type_fields_to_buf\", true);\n+    }\n+    StubRoutines::_call_stub_entry = generate_call_stub(StubRoutines::_call_stub_return_address);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":202,"deletions":17,"binary":false,"changes":219,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -62,1 +63,1 @@\n-int TemplateInterpreter::InterpreterCodeSize = JVMCI_ONLY(268) NOT_JVMCI(256) * 1024;\n+int TemplateInterpreter::InterpreterCodeSize = JVMCI_ONLY(280) NOT_JVMCI(268) * 1024;\n@@ -210,0 +211,4 @@\n+  if (state == atos && InlineTypeReturnedAsFields) {\n+    __ store_inline_type_fields_to_buf(NULL);\n+  }\n+\n@@ -352,0 +357,1 @@\n+  case T_INLINE_TYPE: \/\/ fall through (inline types are handled with oops)\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2436,0 +2436,12 @@\n+    if (tf()->returns_inline_type_as_fields() && !_method->is_method_handle_intrinsic()) {\n+      \/\/ An inline type is returned as fields in multiple registers.\n+      \/\/ Rax either contains an oop if the inline type is buffered or a pointer\n+      \/\/ to the corresponding InlineKlass with the lowest bit set to 1. Zero rax\n+      \/\/ if the lowest bit is set to allow C2 to use the oop after null checking.\n+      \/\/ rax &= (rax & 1) - 1\n+      C2_MacroAssembler _masm(&cbuf);\n+      __ movptr(rscratch1, rax);\n+      __ andptr(rscratch1, 0x1);\n+      __ subptr(rscratch1, 0x1);\n+      __ andptr(rax, rscratch1);\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -627,4 +627,1 @@\n-  int framesize = C->output()->frame_size_in_bytes();\n-  int bangsize = C->output()->bang_size_in_bytes();\n-\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, C->in_24_bit_fp_mode(), C->stub_function() != NULL);\n+  __ verified_entry(C);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -465,0 +465,4 @@\n+  if (_entry_point == NULL) {\n+    \/\/ CallLeafNoFPInDirect\n+    return 3; \/\/ callq (register)\n+  }\n@@ -475,0 +479,1 @@\n+\n@@ -883,3 +888,0 @@\n-  int framesize = C->output()->frame_size_in_bytes();\n-  int bangsize = C->output()->bang_size_in_bytes();\n-\n@@ -901,1 +903,7 @@\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, false, C->stub_function() != NULL);\n+  __ verified_entry(C);\n+  __ bind(*_verified_entry);\n+\n+  if (C->stub_function() == NULL) {\n+    BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+    bs->nmethod_entry_barrier(&_masm);\n+  }\n@@ -913,6 +921,0 @@\n-uint MachPrologNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n@@ -966,23 +968,3 @@\n-  int framesize = C->output()->frame_size_in_bytes();\n-  assert((framesize & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n-  \/\/ Remove word for return adr already pushed\n-  \/\/ and RBP\n-  framesize -= 2*wordSize;\n-\n-  \/\/ Note that VerifyStackAtCalls' Majik cookie does not change the frame size popped here\n-\n-  if (framesize) {\n-    emit_opcode(cbuf, Assembler::REX_W);\n-    if (framesize < 0x80) {\n-      emit_opcode(cbuf, 0x83); \/\/ addq rsp, #framesize\n-      emit_rm(cbuf, 0x3, 0x00, RSP_enc);\n-      emit_d8(cbuf, framesize);\n-    } else {\n-      emit_opcode(cbuf, 0x81); \/\/ addq rsp, #framesize\n-      emit_rm(cbuf, 0x3, 0x00, RSP_enc);\n-      emit_d32(cbuf, framesize);\n-    }\n-  }\n-\n-  \/\/ popq rbp\n-  emit_opcode(cbuf, 0x58 | RBP_enc);\n+  \/\/ Subtract two words to account for return address and rbp\n+  int initial_framesize = C->output()->frame_size_in_bytes() - 2*wordSize;\n+  __ remove_frame(initial_framesize, C->needs_stack_repair(), C->output()->sp_inc_offset());\n@@ -1006,6 +988,0 @@\n-uint MachEpilogNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n@@ -1644,0 +1620,30 @@\n+\/\/=============================================================================\n+#ifndef PRODUCT\n+void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const\n+{\n+  st->print_cr(\"MachVEPNode\");\n+}\n+#endif\n+\n+void MachVEPNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const\n+{\n+  MacroAssembler _masm(&cbuf);\n+  if (!_verified) {\n+    uint insts_size = cbuf.insts_size();\n+    if (UseCompressedClassPointers) {\n+      __ load_klass(rscratch1, j_rarg0, rscratch2);\n+      __ cmpptr(rax, rscratch1);\n+    } else {\n+      __ cmpptr(rax, Address(j_rarg0, oopDesc::klass_offset_in_bytes()));\n+    }\n+    __ jump_cc(Assembler::notEqual, RuntimeAddress(SharedRuntime::get_ic_miss_stub()));\n+  } else {\n+    \/\/ Unpack inline type args passed as oop and then jump to\n+    \/\/ the verified entry point (skipping the unverified entry).\n+    int sp_inc = __ unpack_inline_args(ra_->C, _receiver_only);\n+    \/\/ Emit code for verified entry and save increment for stack repair on return\n+    __ verified_entry(ra_->C, sp_inc);\n+    __ jmp(*_verified_entry);\n+  }\n+}\n+\n@@ -1686,7 +1692,0 @@\n-uint MachUEPNode::size(PhaseRegAlloc* ra_) const\n-{\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n-\n@@ -4032,0 +4031,16 @@\n+\/\/ Indirect Narrow Oop Operand\n+operand indCompressedOop(rRegN reg) %{\n+  predicate(UseCompressedOops && (CompressedOops::shift() == Address::times_8));\n+  constraint(ALLOC_IN_RC(ptr_reg));\n+  match(DecodeN reg);\n+\n+  op_cost(10);\n+  format %{\"[R12 + $reg << 3] (compressed oop addressing)\" %}\n+  interface(MEMORY_INTER) %{\n+    base(0xc); \/\/ R12\n+    index($reg);\n+    scale(0x3);\n+    disp(0x0);\n+  %}\n+%}\n+\n@@ -4374,1 +4389,1 @@\n-               indCompressedOopOffset,\n+               indCompressedOop, indCompressedOopOffset,\n@@ -6827,0 +6842,13 @@\n+instruct castN2X(rRegL dst, rRegN src)\n+%{\n+  match(Set dst (CastP2X src));\n+\n+  format %{ \"movq    $dst, $src\\t# ptr -> long\" %}\n+  ins_encode %{\n+    if ($dst$$reg != $src$$reg) {\n+      __ movptr($dst$$Register, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ XXX\n+%}\n+\n@@ -10943,0 +10971,1 @@\n+\n@@ -10945,1 +10974,1 @@\n-instruct rep_stos(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegI zero,\n+instruct rep_stos(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegL val,\n@@ -10948,4 +10977,3 @@\n-  predicate(!((ClearArrayNode*)n)->is_large() &&\n-              (UseAVX <= 2 || !VM_Version::supports_avx512vlbw()));\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n+  predicate(!((ClearArrayNode*)n)->is_large() && !((ClearArrayNode*)n)->word_copy_only() && (UseAVX <= 2 || !VM_Version::supports_avx512vlbw()));\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, USE_KILL val, KILL cr);\n@@ -10954,1 +10982,0 @@\n-    $$emit$$\"xorq    rax, rax\\t# ClearArray:\\n\\t\"\n@@ -10968,2 +10995,3 @@\n-       $$emit$$\"mov     rdi,rax\\n\\t\"\n-       $$emit$$\"vpxor   ymm0,ymm0,ymm0\\n\\t\"\n+       $$emit$$\"movdq   $tmp, $val\\n\\t\"\n+       $$emit$$\"punpcklqdq $tmp, $tmp\\n\\t\"\n+       $$emit$$\"vinserti128_high $tmp, $tmp\\n\\t\"\n@@ -10972,2 +11000,2 @@\n-       $$emit$$\"vmovdqu ymm0,(rax)\\n\\t\"\n-       $$emit$$\"vmovdqu ymm0,0x20(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,0x20(rax)\\n\\t\"\n@@ -10980,1 +11008,1 @@\n-       $$emit$$\"vmovdqu ymm0,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n@@ -10999,2 +11027,58 @@\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, false, knoreg);\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, false, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct rep_stos_word_copy(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegL val,\n+                  Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(!((ClearArrayNode*)n)->is_large() && ((ClearArrayNode*)n)->word_copy_only());\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, USE_KILL val, KILL cr);\n+\n+  format %{ $$template\n+    $$emit$$\"cmp     InitArrayShortSize,rcx\\n\\t\"\n+    $$emit$$\"jg      LARGE\\n\\t\"\n+    $$emit$$\"dec     rcx\\n\\t\"\n+    $$emit$$\"js      DONE\\t# Zero length\\n\\t\"\n+    $$emit$$\"mov     rax,(rdi,rcx,8)\\t# LOOP\\n\\t\"\n+    $$emit$$\"dec     rcx\\n\\t\"\n+    $$emit$$\"jge     LOOP\\n\\t\"\n+    $$emit$$\"jmp     DONE\\n\\t\"\n+    $$emit$$\"# LARGE:\\n\\t\"\n+    if (UseXMMForObjInit) {\n+       $$emit$$\"movdq   $tmp, $val\\n\\t\"\n+       $$emit$$\"punpcklqdq $tmp, $tmp\\n\\t\"\n+       $$emit$$\"vinserti128_high $tmp, $tmp\\n\\t\"\n+       $$emit$$\"jmpq    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,0x20(rax)\\n\\t\"\n+       $$emit$$\"add     0x40,rax\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"sub     0x8,rcx\\n\\t\"\n+       $$emit$$\"jge     L_loop\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jl      L_tail\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"add     0x20,rax\\n\\t\"\n+       $$emit$$\"sub     0x4,rcx\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jle     L_end\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"vmovq   xmm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x8,rax\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"jge     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"rep     stosq\\t# Store rax to *rdi++ while rcx--\\n\\t\"\n+    }\n+    $$emit$$\"# DONE\"\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, false, true, knoreg);\n@@ -11006,1 +11090,1 @@\n-instruct rep_stos_evex(rcx_RegL cnt, rdi_RegP base, regD tmp, kReg ktmp, rax_RegI zero,\n+instruct rep_stos_evex(rcx_RegL cnt, rdi_RegP base, regD tmp, kReg ktmp, rax_RegL val,\n@@ -11012,2 +11096,2 @@\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, USE_KILL val, KILL cr);\n@@ -11061,1 +11145,1 @@\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n@@ -11068,1 +11152,1 @@\n-instruct rep_stos_large(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegI zero,\n+instruct rep_stos_large(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegL val,\n@@ -11071,3 +11155,3 @@\n-  predicate(UseAVX <=2 && ((ClearArrayNode*)n)->is_large());\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n+  predicate(UseAVX <=2 && ((ClearArrayNode*)n)->is_large() && !((ClearArrayNode*)n)->word_copy_only());\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, USE_KILL val, KILL cr);\n@@ -11077,1 +11161,0 @@\n-       $$emit$$\"xorq    rax, rax\\t# ClearArray:\\n\\t\"\n@@ -11081,2 +11164,3 @@\n-       $$emit$$\"mov     rdi,rax\\t# ClearArray:\\n\\t\"\n-       $$emit$$\"vpxor   ymm0,ymm0,ymm0\\n\\t\"\n+       $$emit$$\"movdq   $tmp, $val\\n\\t\"\n+       $$emit$$\"punpcklqdq $tmp, $tmp\\n\\t\"\n+       $$emit$$\"vinserti128_high $tmp, $tmp\\n\\t\"\n@@ -11085,2 +11169,2 @@\n-       $$emit$$\"vmovdqu ymm0,(rax)\\n\\t\"\n-       $$emit$$\"vmovdqu ymm0,0x20(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,0x20(rax)\\n\\t\"\n@@ -11093,1 +11177,1 @@\n-       $$emit$$\"vmovdqu ymm0,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n@@ -11107,1 +11191,0 @@\n-       $$emit$$\"xorq    rax, rax\\t# ClearArray:\\n\\t\"\n@@ -11112,2 +11195,2 @@\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, true, knoreg);\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, true, false, knoreg);\n@@ -11119,1 +11202,1 @@\n-instruct rep_stos_large_evex(rcx_RegL cnt, rdi_RegP base, regD tmp, kReg ktmp, rax_RegI zero,\n+instruct rep_stos_large_evex(rcx_RegL cnt, rdi_RegP base, regD tmp, kReg ktmp, rax_RegL val,\n@@ -11123,2 +11206,2 @@\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, USE_KILL val, KILL cr);\n@@ -11163,1 +11246,1 @@\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n@@ -11169,0 +11252,46 @@\n+instruct rep_stos_large_word_copy(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegL val,\n+                        Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(((ClearArrayNode*)n)->is_large() && ((ClearArrayNode*)n)->word_copy_only());\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, USE_KILL val, KILL cr);\n+\n+  format %{ $$template\n+    if (UseXMMForObjInit) {\n+       $$emit$$\"movdq   $tmp, $val\\n\\t\"\n+       $$emit$$\"punpcklqdq $tmp, $tmp\\n\\t\"\n+       $$emit$$\"vinserti128_high $tmp, $tmp\\n\\t\"\n+       $$emit$$\"jmpq    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,0x20(rax)\\n\\t\"\n+       $$emit$$\"add     0x40,rax\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"sub     0x8,rcx\\n\\t\"\n+       $$emit$$\"jge     L_loop\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jl      L_tail\\n\\t\"\n+       $$emit$$\"vmovdqu $tmp,(rax)\\n\\t\"\n+       $$emit$$\"add     0x20,rax\\n\\t\"\n+       $$emit$$\"sub     0x4,rcx\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jle     L_end\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"vmovq   xmm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x8,rax\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"jge     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"rep     stosq\\t# Store rax to *rdi++ while rcx--\"\n+    }\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $val$$Register,\n+                 $tmp$$XMMRegister, true, true);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -11170,1 +11299,1 @@\n-instruct rep_stos_im(immL cnt, rRegP base, regD tmp, rRegI zero, kReg ktmp, Universe dummy, rFlagsReg cr)\n+instruct rep_stos_im(immL cnt, rRegP base, regD tmp, rax_RegL val, kReg ktmp, Universe dummy, rFlagsReg cr)\n@@ -11173,0 +11302,1 @@\n+            !((ClearArrayNode*)n)->word_copy_only() &&\n@@ -11175,2 +11305,2 @@\n-  match(Set dummy (ClearArray cnt base));\n-  effect(TEMP tmp, TEMP zero, TEMP ktmp, KILL cr);\n+  match(Set dummy (ClearArray (Binary cnt base) val));\n+  effect(TEMP tmp, USE_KILL val, TEMP ktmp, KILL cr);\n@@ -11179,1 +11309,1 @@\n-   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n+    __ clear_mem($base$$Register, $cnt$$constant, $val$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n@@ -12919,0 +13049,15 @@\n+\/\/ entry point is null, target holds the address to call\n+instruct CallLeafNoFPInDirect(rRegP target)\n+%{\n+  predicate(n->as_Call()->entry_point() == NULL);\n+  match(CallLeafNoFP target);\n+\n+  ins_cost(300);\n+  format %{ \"call_leaf_nofp,runtime indirect \" %}\n+  ins_encode %{\n+     __ call($target$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -12921,0 +13066,1 @@\n+  predicate(n->as_Call()->entry_point() != NULL);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":231,"deletions":85,"binary":false,"changes":316,"status":"modified"},{"patch":"@@ -796,1 +796,1 @@\n-  return  false;\n+  return false;\n@@ -886,1 +886,2 @@\n-      strcmp(_matrule->_opType,\"Halt\"      )==0 )\n+      strcmp(_matrule->_opType,\"Halt\"      )==0 ||\n+      strcmp(_matrule->_opType,\"CallLeafNoFP\")==0)\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -218,0 +218,1 @@\n+  AD.addInclude(AD._CPP_file, \"gc\/shared\/barrierSetAssembler.hpp\");\n","filename":"src\/hotspot\/share\/adlc\/main.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -284,1 +284,1 @@\n-  if (!x->mismatched() && array != NULL && index != NULL) {\n+  if (!x->should_profile() && !x->mismatched() && array != NULL && index != NULL) {\n@@ -648,0 +648,1 @@\n+void Canonicalizer::do_NewInlineTypeInstance(NewInlineTypeInstance* x) {}\n@@ -651,0 +652,1 @@\n+void Canonicalizer::do_Deoptimize     (Deoptimize*      x) {}\n@@ -664,0 +666,1 @@\n+        assert(!x->klass()->is_inlinetype() || x->klass() == klass, \"Inline klasses can't have subtypes\");\n@@ -668,2 +671,2 @@\n-    \/\/ checkcast of null returns null\n-    if (obj->as_Constant() && obj->type()->as_ObjectType()->constant_value()->is_null_object()) {\n+    \/\/ checkcast of null returns null for non-inline klasses\n+    if (!x->klass()->is_inlinetype() && obj->as_Constant() && obj->type()->as_ObjectType()->constant_value()->is_null_object()) {\n@@ -1059,0 +1062,1 @@\n+void Canonicalizer::do_ProfileACmpTypes(ProfileACmpTypes* x) {}\n","filename":"src\/hotspot\/share\/c1\/c1_Canonicalizer.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -33,0 +33,2 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -660,0 +662,11 @@\n+  \/\/ Record this newly allocated object\n+  void new_instance(NewInlineTypeInstance* object) {\n+    int index = _newobjects.length();\n+    _newobjects.append(object);\n+    if (_fields.at_grow(index, NULL) == NULL) {\n+      _fields.at_put(index, new FieldBuffer());\n+    } else {\n+      _fields.at(index)->kill();\n+    }\n+  }\n+\n@@ -942,0 +955,7 @@\n+  if (x->as_NewInlineTypeInstance() != NULL && x->as_NewInlineTypeInstance()->in_larval_state()) {\n+    if (x->as_NewInlineTypeInstance()->on_stack_count() == 1) {\n+      x->as_NewInlineTypeInstance()->set_not_larva_anymore();\n+    } else {\n+      x->as_NewInlineTypeInstance()->increment_on_stack_count();\n+    }\n+  }\n@@ -948,0 +968,3 @@\n+  if (x->as_NewInlineTypeInstance() != NULL) {\n+    x->as_NewInlineTypeInstance()->set_local_index(index);\n+  }\n@@ -976,0 +999,3 @@\n+  if (x->as_NewInlineTypeInstance() != NULL) {\n+    x->as_NewInlineTypeInstance()->set_local_index(index);\n+  }\n@@ -981,1 +1007,9 @@\n-  ValueStack* state_before = copy_state_indexed_access();\n+  ValueStack* state_before = NULL;\n+  int array_idx = state()->stack_size() - 2;\n+  if (type == T_OBJECT && state()->stack_at(array_idx)->maybe_flattened_array()) {\n+    \/\/ Save the entire state and re-execute on deopt when accessing flattened arrays\n+    state_before = copy_state_before();\n+    state_before->set_should_reexecute(true);\n+  } else {\n+    state_before = copy_state_indexed_access();\n+  }\n@@ -993,1 +1027,61 @@\n-  push(as_ValueType(type), append(new LoadIndexed(array, index, length, type, state_before)));\n+\n+  bool need_membar = false;\n+  LoadIndexed* load_indexed = NULL;\n+  Instruction* result = NULL;\n+  if (array->is_loaded_flattened_array()) {\n+    ciType* array_type = array->declared_type();\n+    ciInlineKlass* elem_klass = array_type->as_flat_array_klass()->element_klass()->as_inline_klass();\n+\n+    bool can_delay_access = false;\n+    ciBytecodeStream s(method());\n+    s.force_bci(bci());\n+    s.next();\n+    if (s.cur_bc() == Bytecodes::_getfield) {\n+      bool will_link;\n+      ciField* next_field = s.get_field(will_link);\n+      bool next_needs_patching = !next_field->holder()->is_loaded() ||\n+                                 !next_field->will_link(method(), Bytecodes::_getfield) ||\n+                                 PatchALot;\n+      can_delay_access = !next_needs_patching;\n+    }\n+    if (can_delay_access) {\n+      \/\/ potentially optimizable array access, storing information for delayed decision\n+      LoadIndexed* li = new LoadIndexed(array, index, length, type, state_before);\n+      DelayedLoadIndexed* dli = new DelayedLoadIndexed(li, state_before);\n+      li->set_delayed(dli);\n+      set_pending_load_indexed(dli);\n+      return; \/\/ Nothing else to do for now\n+    } else {\n+      if (elem_klass->is_empty()) {\n+        \/\/ No need to create a new instance, the default instance will be used instead\n+        load_indexed = new LoadIndexed(array, index, length, type, state_before);\n+        apush(append(load_indexed));\n+      } else {\n+        NewInlineTypeInstance* new_instance = new NewInlineTypeInstance(elem_klass, state_before);\n+        _memory->new_instance(new_instance);\n+        apush(append_split(new_instance));\n+        load_indexed = new LoadIndexed(array, index, length, type, state_before);\n+        load_indexed->set_vt(new_instance);\n+        \/\/ The LoadIndexed node will initialise this instance by copying from\n+        \/\/ the flattened field.  Ensure these stores are visible before any\n+        \/\/ subsequent store that publishes this reference.\n+        need_membar = true;\n+      }\n+    }\n+  } else {\n+    load_indexed = new LoadIndexed(array, index, length, type, state_before);\n+    if (profile_array_accesses() && is_reference_type(type)) {\n+      compilation()->set_would_profile(true);\n+      load_indexed->set_should_profile(true);\n+      load_indexed->set_profiled_method(method());\n+      load_indexed->set_profiled_bci(bci());\n+    }\n+  }\n+  result = append(load_indexed);\n+  if (need_membar) {\n+    append(new MemBar(lir_membar_storestore));\n+  }\n+  assert(!load_indexed->should_profile() || load_indexed == result, \"should not be optimized out\");\n+  if (!array->is_loaded_flattened_array()) {\n+    push(as_ValueType(type), result);\n+  }\n@@ -999,1 +1093,9 @@\n-  ValueStack* state_before = copy_state_indexed_access();\n+  ValueStack* state_before = NULL;\n+  int array_idx = state()->stack_size() - 3;\n+  if (type == T_OBJECT && state()->stack_at(array_idx)->maybe_flattened_array()) {\n+    \/\/ Save the entire state and re-execute on deopt when accessing flattened arrays\n+    state_before = copy_state_before();\n+    state_before->set_should_reexecute(true);\n+  } else {\n+    state_before = copy_state_indexed_access();\n+  }\n@@ -1024,5 +1126,2 @@\n-  StoreIndexed* result = new StoreIndexed(array, index, length, type, value, state_before, check_boolean);\n-  append(result);\n-  _memory->store_value(value);\n-  if (type == T_OBJECT && is_profiling()) {\n-    \/\/ Note that we'd collect profile data in this method if we wanted it.\n+  StoreIndexed* store_indexed = new StoreIndexed(array, index, length, type, value, state_before, check_boolean);\n+  if (profile_array_accesses() && is_reference_type(type) && !array->is_loaded_flattened_array()) {\n@@ -1031,6 +1130,3 @@\n-\n-    if (profile_checkcasts()) {\n-      result->set_profiled_method(method());\n-      result->set_profiled_bci(bci());\n-      result->set_should_profile(true);\n-    }\n+    store_indexed->set_should_profile(true);\n+    store_indexed->set_profiled_method(method());\n+    store_indexed->set_profiled_bci(bci());\n@@ -1038,0 +1134,3 @@\n+  Instruction* result = append(store_indexed);\n+  assert(!store_indexed->should_profile() || store_indexed == result, \"should not be optimized out\");\n+  _memory->store_value(value);\n@@ -1040,1 +1139,0 @@\n-\n@@ -1044,1 +1142,2 @@\n-      { state()->raw_pop();\n+      { Value w = state()->raw_pop();\n+        update_larva_stack_count(w);\n@@ -1048,2 +1147,4 @@\n-      { state()->raw_pop();\n-        state()->raw_pop();\n+      { Value w1 = state()->raw_pop();\n+        Value w2 = state()->raw_pop();\n+        update_larva_stack_count(w1);\n+        update_larva_stack_count(w2);\n@@ -1054,0 +1155,1 @@\n+        update_larval_state(w);\n@@ -1061,0 +1163,1 @@\n+        update_larval_state(w1);\n@@ -1070,0 +1173,11 @@\n+        \/\/ special handling for the dup_x2\/pop sequence (see JDK-8251046)\n+        if (w1 != NULL && w1->as_NewInlineTypeInstance() != NULL) {\n+          ciBytecodeStream s(method());\n+          s.force_bci(bci());\n+          s.next();\n+          if (s.cur_bc() != Bytecodes::_pop) {\n+            w1->as_NewInlineTypeInstance()->set_not_larva_anymore();\n+          }  else {\n+            w1->as_NewInlineTypeInstance()->increment_on_stack_count();\n+           }\n+        }\n@@ -1079,0 +1193,2 @@\n+        update_larval_state(w1);\n+        update_larval_state(w2);\n@@ -1089,0 +1205,2 @@\n+        update_larval_state(w1);\n+        update_larval_state(w2);\n@@ -1101,0 +1219,2 @@\n+        update_larval_state(w1);\n+        update_larval_state(w2);\n@@ -1232,0 +1352,27 @@\n+\n+  bool subst_check = false;\n+  if (EnableValhalla && (stream()->cur_bc() == Bytecodes::_if_acmpeq || stream()->cur_bc() == Bytecodes::_if_acmpne)) {\n+    ValueType* left_vt = x->type();\n+    ValueType* right_vt = y->type();\n+    if (left_vt->is_object()) {\n+      assert(right_vt->is_object(), \"must be\");\n+      ciKlass* left_klass = x->as_loaded_klass_or_null();\n+      ciKlass* right_klass = y->as_loaded_klass_or_null();\n+\n+      if (left_klass == NULL || right_klass == NULL) {\n+        \/\/ The klass is still unloaded, or came from a Phi node. Go slow case;\n+        subst_check = true;\n+      } else if (left_klass->can_be_inline_klass() || right_klass->can_be_inline_klass()) {\n+        \/\/ Either operand may be a value object, but we're not sure. Go slow case;\n+        subst_check = true;\n+      } else {\n+        \/\/ No need to do substitutability check\n+      }\n+    }\n+  }\n+  if ((stream()->cur_bc() == Bytecodes::_if_acmpeq || stream()->cur_bc() == Bytecodes::_if_acmpne) &&\n+      is_profiling() && profile_branches()) {\n+    compilation()->set_would_profile(true);\n+    append(new ProfileACmpTypes(method(), bci(), x, y));\n+  }\n+\n@@ -1234,1 +1381,1 @@\n-  Instruction *i = append(new If(x, cond, false, y, tsux, fsux, (is_bb || compilation()->is_optimistic()) ? state_before : NULL, is_bb));\n+  Instruction *i = append(new If(x, cond, false, y, tsux, fsux, (is_bb || compilation()->is_optimistic() || subst_check) ? state_before : NULL, is_bb, subst_check));\n@@ -1485,1 +1632,1 @@\n-  if (method()->name() == ciSymbols::object_initializer_name() &&\n+  if ((method()->is_object_constructor() || method()->is_static_init_factory()) &&\n@@ -1636,0 +1783,13 @@\n+void GraphBuilder::copy_inline_content(ciInlineKlass* vk, Value src, int src_off, Value dest, int dest_off, ValueStack* state_before) {\n+  assert(vk->nof_nonstatic_fields() > 0, \"Empty inline type access should be removed\");\n+  for (int i = 0; i < vk->nof_nonstatic_fields(); i++) {\n+    ciField* inner_field = vk->nonstatic_field_at(i);\n+    assert(!inner_field->is_flattened(), \"the iteration over nested fields is handled by the loop itself\");\n+    int off = inner_field->offset() - vk->first_field_offset();\n+    LoadField* load = new LoadField(src, src_off + off, inner_field, false, state_before, false);\n+    Value replacement = append(load);\n+    StoreField* store = new StoreField(dest, dest_off + off, inner_field, replacement, false, state_before, false);\n+    append(store);\n+  }\n+}\n+\n@@ -1642,0 +1802,1 @@\n+\n@@ -1645,1 +1806,1 @@\n-                              PatchALot;\n+                              (!field->is_flattened() && PatchALot);\n@@ -1664,1 +1825,1 @@\n-  if (field->is_final() && (code == Bytecodes::_putfield)) {\n+  if (field->is_final() && code == Bytecodes::_putfield) {\n@@ -1675,1 +1836,1 @@\n-  const int offset = !needs_patching ? field->offset() : -1;\n+  int offset = !needs_patching ? field->offset() : -1;\n@@ -1685,0 +1846,3 @@\n+      } else if (field_type == T_INLINE_TYPE && field->type()->as_inline_klass()->is_empty()) {\n+        \/\/ Loading from a field of an empty inline type. Just return the default instance.\n+        constant = new Constant(new InstanceConstant(field->type()->as_inline_klass()->default_instance()));\n@@ -1692,2 +1856,3 @@\n-        push(type, append(new LoadField(append(obj), offset, field, true,\n-                                        state_before, needs_patching)));\n+        LoadField* load_field = new LoadField(append(obj), offset, field, true,\n+                                        state_before, needs_patching);\n+        push(type, append(load_field));\n@@ -1702,1 +1867,1 @@\n-      if (field->type()->basic_type() == T_BOOLEAN) {\n+      if (field_type == T_BOOLEAN) {\n@@ -1706,0 +1871,4 @@\n+      if (field_type == T_INLINE_TYPE && field->type()->as_inline_klass()->is_empty()) {\n+        \/\/ Storing to a field of an empty inline type. Ignore.\n+        break;\n+      }\n@@ -1712,14 +1881,30 @@\n-      obj = apop();\n-      ObjectType* obj_type = obj->type()->as_ObjectType();\n-      if (field->is_constant() && obj_type->is_constant() && !PatchALot) {\n-        ciObject* const_oop = obj_type->constant_value();\n-        if (!const_oop->is_null_object() && const_oop->is_loaded()) {\n-          ciConstant field_value = field->constant_value_of(const_oop);\n-          if (field_value.is_valid()) {\n-            constant = make_constant(field_value, field);\n-            \/\/ For CallSite objects add a dependency for invalidation of the optimization.\n-            if (field->is_call_site_target()) {\n-              ciCallSite* call_site = const_oop->as_call_site();\n-              if (!call_site->is_fully_initialized_constant_call_site()) {\n-                ciMethodHandle* target = field_value.as_object()->as_method_handle();\n-                dependency_recorder()->assert_call_site_target_value(call_site, target);\n+      if (state_before == NULL && field->is_flattened()) {\n+        \/\/ Save the entire state and re-execute on deopt when accessing flattened fields\n+        assert(Interpreter::bytecode_should_reexecute(code), \"should reexecute\");\n+        state_before = copy_state_before();\n+      }\n+      if (!has_pending_field_access() && !has_pending_load_indexed()) {\n+        obj = apop();\n+        ObjectType* obj_type = obj->type()->as_ObjectType();\n+        if (field_type == T_INLINE_TYPE && field->type()->as_inline_klass()->is_empty()) {\n+          \/\/ Loading from a field of an empty inline type. Just return the default instance.\n+          null_check(obj);\n+          constant = new Constant(new InstanceConstant(field->type()->as_inline_klass()->default_instance()));\n+        } else if (field->is_constant() && !field->is_flattened() && obj_type->is_constant() && !PatchALot) {\n+          ciObject* const_oop = obj_type->constant_value();\n+          if (!const_oop->is_null_object() && const_oop->is_loaded()) {\n+            ciConstant field_value = field->constant_value_of(const_oop);\n+            if (field_value.is_valid()) {\n+              if (field->signature()->is_Q_signature() && field_value.is_null_or_zero()) {\n+                \/\/ Non-flattened inline type field. Replace null by the default value.\n+                constant = new Constant(new InstanceConstant(field->type()->as_inline_klass()->default_instance()));\n+              } else {\n+                constant = make_constant(field_value, field);\n+              }\n+              \/\/ For CallSite objects add a dependency for invalidation of the optimization.\n+              if (field->is_call_site_target()) {\n+                ciCallSite* call_site = const_oop->as_call_site();\n+                if (!call_site->is_fully_initialized_constant_call_site()) {\n+                  ciMethodHandle* target = field_value.as_object()->as_method_handle();\n+                  dependency_recorder()->assert_call_site_target_value(call_site, target);\n+                }\n@@ -1737,19 +1922,15 @@\n-        LoadField* load = new LoadField(obj, offset, field, false, state_before, needs_patching);\n-        Value replacement = !needs_patching ? _memory->load(load) : load;\n-        if (replacement != load) {\n-          assert(replacement->is_linked() || !replacement->can_be_linked(), \"should already by linked\");\n-          \/\/ Writing an (integer) value to a boolean, byte, char or short field includes an implicit narrowing\n-          \/\/ conversion. Emit an explicit conversion here to get the correct field value after the write.\n-          BasicType bt = field->type()->basic_type();\n-          switch (bt) {\n-          case T_BOOLEAN:\n-          case T_BYTE:\n-            replacement = append(new Convert(Bytecodes::_i2b, replacement, as_ValueType(bt)));\n-            break;\n-          case T_CHAR:\n-            replacement = append(new Convert(Bytecodes::_i2c, replacement, as_ValueType(bt)));\n-            break;\n-          case T_SHORT:\n-            replacement = append(new Convert(Bytecodes::_i2s, replacement, as_ValueType(bt)));\n-            break;\n-          default:\n+        if (!field->is_flattened()) {\n+          if (has_pending_field_access()) {\n+            assert(!needs_patching, \"Can't patch delayed field access\");\n+            obj = pending_field_access()->obj();\n+            offset += pending_field_access()->offset() - field->holder()->as_inline_klass()->first_field_offset();\n+            field = pending_field_access()->holder()->get_field_by_offset(offset, false);\n+            assert(field != NULL, \"field not found\");\n+            set_pending_field_access(NULL);\n+          } else if (has_pending_load_indexed()) {\n+            assert(!needs_patching, \"Can't patch delayed field access\");\n+            pending_load_indexed()->update(field, offset - field->holder()->as_inline_klass()->first_field_offset());\n+            LoadIndexed* li = pending_load_indexed()->load_instr();\n+            li->set_type(type);\n+            push(type, append(li));\n+            set_pending_load_indexed(NULL);\n@@ -1758,1 +1939,24 @@\n-          push(type, replacement);\n+          LoadField* load = new LoadField(obj, offset, field, false, state_before, needs_patching);\n+          Value replacement = !needs_patching ? _memory->load(load) : load;\n+          if (replacement != load) {\n+            assert(replacement->is_linked() || !replacement->can_be_linked(), \"should already by linked\");\n+            \/\/ Writing an (integer) value to a boolean, byte, char or short field includes an implicit narrowing\n+            \/\/ conversion. Emit an explicit conversion here to get the correct field value after the write.\n+            switch (field_type) {\n+            case T_BOOLEAN:\n+            case T_BYTE:\n+              replacement = append(new Convert(Bytecodes::_i2b, replacement, type));\n+              break;\n+            case T_CHAR:\n+              replacement = append(new Convert(Bytecodes::_i2c, replacement, type));\n+              break;\n+            case T_SHORT:\n+              replacement = append(new Convert(Bytecodes::_i2s, replacement, type));\n+              break;\n+            default:\n+              break;\n+            }\n+            push(type, replacement);\n+          } else {\n+            push(type, append(load));\n+          }\n@@ -1760,1 +1964,66 @@\n-          push(type, append(load));\n+          \/\/ Look at the next bytecode to check if we can delay the field access\n+          bool can_delay_access = false;\n+          ciBytecodeStream s(method());\n+          s.force_bci(bci());\n+          s.next();\n+          if (s.cur_bc() == Bytecodes::_getfield && !needs_patching) {\n+            ciField* next_field = s.get_field(will_link);\n+            bool next_needs_patching = !next_field->holder()->is_loaded() ||\n+                                       !next_field->will_link(method(), Bytecodes::_getfield) ||\n+                                       PatchALot;\n+            can_delay_access = !next_needs_patching;\n+          }\n+          if (can_delay_access) {\n+            if (has_pending_load_indexed()) {\n+              pending_load_indexed()->update(field, offset - field->holder()->as_inline_klass()->first_field_offset());\n+            } else if (has_pending_field_access()) {\n+              pending_field_access()->inc_offset(offset - field->holder()->as_inline_klass()->first_field_offset());\n+            } else {\n+              null_check(obj);\n+              DelayedFieldAccess* dfa = new DelayedFieldAccess(obj, field->holder(), field->offset());\n+              set_pending_field_access(dfa);\n+            }\n+          } else {\n+            ciInlineKlass* inline_klass = field->type()->as_inline_klass();\n+            scope()->set_wrote_final();\n+            scope()->set_wrote_fields();\n+            bool need_membar = false;\n+            if (inline_klass->is_empty()) {\n+              apush(append(new Constant(new InstanceConstant(inline_klass->default_instance()))));\n+              if (has_pending_field_access()) {\n+                set_pending_field_access(NULL);\n+              } else if (has_pending_load_indexed()) {\n+                set_pending_load_indexed(NULL);\n+              }\n+            } else if (has_pending_load_indexed()) {\n+              assert(!needs_patching, \"Can't patch delayed field access\");\n+              pending_load_indexed()->update(field, offset - field->holder()->as_inline_klass()->first_field_offset());\n+              NewInlineTypeInstance* vt = new NewInlineTypeInstance(inline_klass, pending_load_indexed()->state_before());\n+              _memory->new_instance(vt);\n+              pending_load_indexed()->load_instr()->set_vt(vt);\n+              apush(append_split(vt));\n+              append(pending_load_indexed()->load_instr());\n+              set_pending_load_indexed(NULL);\n+              need_membar = true;\n+            } else {\n+              NewInlineTypeInstance* new_instance = new NewInlineTypeInstance(inline_klass, state_before);\n+              _memory->new_instance(new_instance);\n+              apush(append_split(new_instance));\n+              assert(!needs_patching, \"Can't patch flattened inline type field access\");\n+              if (has_pending_field_access()) {\n+                copy_inline_content(inline_klass, pending_field_access()->obj(),\n+                                    pending_field_access()->offset() + field->offset() - field->holder()->as_inline_klass()->first_field_offset(),\n+                                    new_instance, inline_klass->first_field_offset(), state_before);\n+                set_pending_field_access(NULL);\n+              } else {\n+                copy_inline_content(inline_klass, obj, field->offset(), new_instance, inline_klass->first_field_offset(), state_before);\n+              }\n+              need_membar = true;\n+            }\n+            if (need_membar) {\n+              \/\/ If we allocated a new instance ensure the stores to copy the\n+              \/\/ field contents are visible before any subsequent store that\n+              \/\/ publishes this reference.\n+              append(new MemBar(lir_membar_storestore));\n+            }\n+          }\n@@ -1771,1 +2040,1 @@\n-      if (field->type()->basic_type() == T_BOOLEAN) {\n+      if (field_type == T_BOOLEAN) {\n@@ -1775,4 +2044,13 @@\n-      StoreField* store = new StoreField(obj, offset, field, val, false, state_before, needs_patching);\n-      if (!needs_patching) store = _memory->store(store);\n-      if (store != NULL) {\n-        append(store);\n+      if (field_type == T_INLINE_TYPE && field->type()->as_inline_klass()->is_empty()) {\n+        \/\/ Storing to a field of an empty inline type. Ignore.\n+        null_check(obj);\n+      } else if (!field->is_flattened()) {\n+        StoreField* store = new StoreField(obj, offset, field, val, false, state_before, needs_patching);\n+        if (!needs_patching) store = _memory->store(store);\n+        if (store != NULL) {\n+          append(store);\n+        }\n+      } else {\n+        assert(!needs_patching, \"Can't patch flattened inline type field access\");\n+        ciInlineKlass* inline_klass = field->type()->as_inline_klass();\n+        copy_inline_content(inline_klass, val, inline_klass->first_field_offset(), obj, offset, state_before);\n@@ -1788,0 +2066,74 @@\n+\/\/ Baseline version of withfield, allocate every time\n+void GraphBuilder::withfield(int field_index) {\n+  \/\/ Save the entire state and re-execute on deopt\n+  ValueStack* state_before = copy_state_before();\n+  state_before->set_should_reexecute(true);\n+\n+  bool will_link;\n+  ciField* field_modify = stream()->get_field(will_link);\n+  ciInstanceKlass* holder = field_modify->holder();\n+  BasicType field_type = field_modify->type()->basic_type();\n+  ValueType* type = as_ValueType(field_type);\n+  Value val = pop(type);\n+  Value obj = apop();\n+\n+  if (!holder->is_loaded()) {\n+    apush(append_split(new Deoptimize(holder, state_before)));\n+    return;\n+  }\n+\n+  \/\/ call will_link again to determine if the field is valid.\n+  const bool needs_patching = !field_modify->will_link(method(), Bytecodes::_withfield) ||\n+                              (!field_modify->is_flattened() && PatchALot);\n+  const int offset_modify = !needs_patching ? field_modify->offset() : -1;\n+  assert(holder->is_inlinetype(), \"must be an inline klass\");\n+\n+  scope()->set_wrote_final();\n+  scope()->set_wrote_fields();\n+\n+  NewInlineTypeInstance* new_instance;\n+  if (obj->as_NewInlineTypeInstance() != NULL && obj->as_NewInlineTypeInstance()->in_larval_state()) {\n+    new_instance = obj->as_NewInlineTypeInstance();\n+    apush(append_split(new_instance));\n+  } else {\n+    new_instance = new NewInlineTypeInstance(holder->as_inline_klass(), state_before);\n+    _memory->new_instance(new_instance);\n+    apush(append_split(new_instance));\n+\n+    \/\/ Initialize fields which are not modified\n+    for (int i = 0; i < holder->nof_nonstatic_fields(); i++) {\n+      ciField* field = holder->nonstatic_field_at(i);\n+      int offset = field->offset();\n+      \/\/ Don't use offset_modify here, it might be set to -1 if needs_patching\n+      if (offset != field_modify->offset()) {\n+        if (field->is_flattened()) {\n+          ciInlineKlass* vk = field->type()->as_inline_klass();\n+          if (!vk->is_empty()) {\n+            copy_inline_content(vk, obj, offset, new_instance, vk->first_field_offset(), state_before);\n+          }\n+        } else {\n+          LoadField* load = new LoadField(obj, offset, field, false, state_before, false);\n+          Value replacement = append(load);\n+          StoreField* store = new StoreField(new_instance, offset, field, replacement, false, state_before, false);\n+          append(store);\n+        }\n+      }\n+    }\n+  }\n+\n+  \/\/ Field to modify\n+  if (field_type == T_BOOLEAN) {\n+    Value mask = append(new Constant(new IntConstant(1)));\n+    val = append(new LogicOp(Bytecodes::_iand, val, mask));\n+  }\n+  if (field_modify->is_flattened()) {\n+    assert(!needs_patching, \"Can't patch flattened inline type field access\");\n+    ciInlineKlass* vk = field_modify->type()->as_inline_klass();\n+    if (!vk->is_empty()) {\n+      copy_inline_content(vk, val, vk->first_field_offset(), new_instance, offset_modify, state_before);\n+    }\n+  } else {\n+    StoreField* store = new StoreField(new_instance, offset_modify, field_modify, val, false, state_before, needs_patching);\n+    append(store);\n+  }\n+}\n@@ -1873,1 +2225,1 @@\n-  if (bc_raw == Bytecodes::_invokespecial && !target->is_object_initializer()) {\n+  if (bc_raw == Bytecodes::_invokespecial && !target->is_object_constructor()) {\n@@ -2127,1 +2479,2 @@\n-  Invoke* result = new Invoke(code, result_type, recv, args, target, state_before);\n+  Invoke* result = new Invoke(code, result_type, recv, args, target, state_before,\n+                              declared_signature->return_type()->is_inlinetype());\n@@ -2154,0 +2507,11 @@\n+void GraphBuilder::default_value(int klass_index) {\n+  bool will_link;\n+  ciKlass* klass = stream()->get_klass(will_link);\n+  if (!stream()->is_unresolved_klass() && klass->is_inlinetype() &&\n+      klass->as_inline_klass()->is_initialized()) {\n+    ciInlineKlass* vk = klass->as_inline_klass();\n+    apush(append(new Constant(new InstanceConstant(vk->default_instance()))));\n+  } else {\n+    apush(append_split(new Deoptimize(klass, copy_state_before())));\n+  }\n+}\n@@ -2164,0 +2528,1 @@\n+  bool null_free = stream()->is_inline_klass();\n@@ -2165,1 +2530,1 @@\n-  NewArray* n = new NewObjectArray(klass, ipop(), state_before);\n+  NewArray* n = new NewObjectArray(klass, ipop(), state_before, null_free);\n@@ -2190,0 +2555,1 @@\n+  bool null_free = stream()->is_inline_klass();\n@@ -2191,1 +2557,1 @@\n-  CheckCast* c = new CheckCast(klass, apop(), state_before);\n+  CheckCast* c = new CheckCast(klass, apop(), state_before, null_free);\n@@ -2230,0 +2596,19 @@\n+  bool maybe_inlinetype = false;\n+  if (bci == InvocationEntryBci) {\n+    \/\/ Called by GraphBuilder::inline_sync_entry.\n+#ifdef ASSERT\n+    ciType* obj_type = x->declared_type();\n+    assert(obj_type == NULL || !obj_type->is_inlinetype(), \"inline types cannot have synchronized methods\");\n+#endif\n+  } else {\n+    \/\/ We are compiling a monitorenter bytecode\n+    if (EnableValhalla) {\n+      ciType* obj_type = x->declared_type();\n+      if (obj_type == NULL || obj_type->as_klass()->can_be_inline_klass()) {\n+        \/\/ If we're (possibly) locking on an inline type, check for markWord::always_locked_pattern\n+        \/\/ and throw IMSE. (obj_type is null for Phi nodes, so let's just be conservative).\n+        maybe_inlinetype = true;\n+      }\n+    }\n+  }\n+\n@@ -2232,1 +2617,1 @@\n-  append_with_bci(new MonitorEnter(x, state()->lock(x), state_before), bci);\n+  append_with_bci(new MonitorEnter(x, state()->lock(x), state_before, maybe_inlinetype), bci);\n@@ -2406,1 +2791,3 @@\n-    assert(cur_bci == SynchronizationEntryBCI || cur_bci == cur_scope_data->stream()->cur_bci(), \"invalid bci\");\n+    assert(cur_bci == SynchronizationEntryBCI || cur_bci == cur_scope_data->stream()->cur_bci()\n+           || has_pending_field_access() || has_pending_load_indexed(), \"invalid bci\");\n+\n@@ -2894,0 +3281,2 @@\n+      case Bytecodes::_defaultvalue   : default_value(s.get_index_u2()); break;\n+      case Bytecodes::_withfield      : withfield(s.get_index_u2()); break;\n@@ -3179,1 +3568,2 @@\n-    state->store_local(idx, new Local(method()->holder(), objectType, idx, true));\n+    state->store_local(idx, new Local(method()->holder(), objectType, idx,\n+             \/*receiver*\/ true, \/*null_free*\/ method()->holder()->is_flat_array_klass()));\n@@ -3191,1 +3581,1 @@\n-    state->store_local(idx, new Local(type, vt, idx, false));\n+    state->store_local(idx, new Local(type, vt, idx, false, type->is_inlinetype()));\n@@ -3211,0 +3601,2 @@\n+  , _pending_field_access(NULL)\n+  , _pending_load_indexed(NULL)\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":466,"deletions":74,"binary":false,"changes":540,"status":"modified"},{"patch":"@@ -174,0 +174,3 @@\n+  if (_should_reexecute) {\n+    return true;\n+  }\n@@ -183,1 +186,0 @@\n-\n@@ -215,1 +217,1 @@\n-void CodeEmitInfo::record_debug_info(DebugInformationRecorder* recorder, int pc_offset) {\n+void CodeEmitInfo::record_debug_info(DebugInformationRecorder* recorder, int pc_offset, bool maybe_return_as_fields) {\n@@ -218,1 +220,1 @@\n-  _scope_debug_info->record_debug_info(recorder, pc_offset, true\/*topmost*\/, _is_method_handle_invoke);\n+  _scope_debug_info->record_debug_info(recorder, pc_offset, true\/*topmost*\/, _is_method_handle_invoke, maybe_return_as_fields);\n","filename":"src\/hotspot\/share\/c1\/c1_IR.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -30,0 +30,2 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -116,0 +118,63 @@\n+ciKlass* Instruction::as_loaded_klass_or_null() const {\n+  ciType* type = declared_type();\n+  if (type != NULL && type->is_klass()) {\n+    ciKlass* klass = type->as_klass();\n+    if (klass->is_loaded()) {\n+      return klass;\n+    }\n+  }\n+  return NULL;\n+}\n+\n+bool Instruction::is_loaded_flattened_array() const {\n+  if (UseFlatArray) {\n+    ciType* type = declared_type();\n+    return type != NULL && type->is_flat_array_klass();\n+  }\n+  return false;\n+}\n+\n+bool Instruction::maybe_flattened_array() {\n+  if (UseFlatArray) {\n+    ciType* type = declared_type();\n+    if (type != NULL) {\n+      if (type->is_obj_array_klass()) {\n+        \/\/ Due to array covariance, the runtime type might be a flattened array.\n+        ciKlass* element_klass = type->as_obj_array_klass()->element_klass();\n+        if (element_klass->can_be_inline_klass() && (!element_klass->is_inlinetype() || element_klass->as_inline_klass()->flatten_array())) {\n+          return true;\n+        }\n+      } else if (type->is_flat_array_klass()) {\n+        ciKlass* element_klass = type->as_flat_array_klass()->element_klass();\n+        assert(!element_klass->is_loaded() || element_klass->flatten_array(), \"must be flattened\");\n+        return true;\n+      } else if (type->is_klass() && type->as_klass()->is_java_lang_Object()) {\n+        \/\/ This can happen as a parameter to System.arraycopy()\n+        return true;\n+      }\n+    } else {\n+      \/\/ Type info gets lost during Phi merging (Phi, IfOp, etc), but we might be storing into a\n+      \/\/ flattened array, so we should do a runtime check.\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+bool Instruction::maybe_null_free_array() {\n+  ciType* type = declared_type();\n+  if (type != NULL) {\n+    if (type->is_obj_array_klass()) {\n+      \/\/ Due to array covariance, the runtime type might be a null-free array.\n+      ciKlass* element_klass = type->as_obj_array_klass()->element_klass();\n+      if (element_klass->can_be_inline_klass()) {\n+        return true;\n+      }\n+    }\n+  } else {\n+    \/\/ Type info gets lost during Phi merging (Phi, IfOp, etc), but we might be storing into a\n+    \/\/ null-free array, so we should do a runtime check.\n+    return true;\n+  }\n+  return false;\n+}\n@@ -176,1 +241,1 @@\n-  if (array_type != NULL) {\n+  if (delayed() == NULL && array_type != NULL) {\n@@ -190,1 +255,3 @@\n-\n+  if (delayed() != NULL) {\n+    return delayed()->field()->type();\n+  }\n@@ -201,0 +268,14 @@\n+bool StoreIndexed::is_exact_flattened_array_store() const {\n+  if (array()->is_loaded_flattened_array() && value()->as_Constant() == NULL && value()->declared_type() != NULL) {\n+    ciKlass* element_klass = array()->declared_type()->as_flat_array_klass()->element_klass();\n+    ciKlass* actual_klass = value()->declared_type()->as_klass();\n+\n+    \/\/ The following check can fail with inlining:\n+    \/\/     void test45_inline(Object[] oa, Object o, int index) { oa[index] = o; }\n+    \/\/     void test45(MyValue1[] va, int index, MyValue2 v) { test45_inline(va, v, index); }\n+    if (element_klass == actual_klass) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n@@ -212,1 +293,5 @@\n-  return ciObjArrayKlass::make(klass());\n+  return ciArrayKlass::make(klass());\n+}\n+\n+ciType* NewMultiArray::exact_type() const {\n+  return _klass;\n@@ -227,0 +312,8 @@\n+ciType* NewInlineTypeInstance::exact_type() const {\n+  return klass();\n+}\n+\n+ciType* NewInlineTypeInstance::declared_type() const {\n+  return exact_type();\n+}\n+\n@@ -322,0 +415,34 @@\n+StoreField::StoreField(Value obj, int offset, ciField* field, Value value, bool is_static,\n+                       ValueStack* state_before, bool needs_patching)\n+  : AccessField(obj, offset, field, is_static, state_before, needs_patching)\n+  , _value(value)\n+{\n+  set_flag(NeedsWriteBarrierFlag, as_ValueType(field_type())->is_object());\n+#ifdef ASSERT\n+  AssertValues assert_value;\n+  values_do(&assert_value);\n+#endif\n+  pin();\n+  if (value->as_NewInlineTypeInstance() != NULL) {\n+    value->as_NewInlineTypeInstance()->set_not_larva_anymore();\n+  }\n+}\n+\n+StoreIndexed::StoreIndexed(Value array, Value index, Value length, BasicType elt_type, Value value,\n+                           ValueStack* state_before, bool check_boolean, bool mismatched)\n+  : AccessIndexed(array, index, length, elt_type, state_before, mismatched)\n+  , _value(value), _check_boolean(check_boolean)\n+{\n+  set_flag(NeedsWriteBarrierFlag, (as_ValueType(elt_type)->is_object()));\n+  set_flag(NeedsStoreCheckFlag, (as_ValueType(elt_type)->is_object()));\n+#ifdef ASSERT\n+  AssertValues assert_value;\n+  values_do(&assert_value);\n+#endif\n+  pin();\n+  if (value->as_NewInlineTypeInstance() != NULL) {\n+    value->as_NewInlineTypeInstance()->set_not_larva_anymore();\n+  }\n+}\n+\n+\n@@ -326,1 +453,1 @@\n-               ciMethod* target, ValueStack* state_before)\n+               ciMethod* target, ValueStack* state_before, bool null_free)\n@@ -336,0 +463,1 @@\n+  set_null_free(null_free);\n@@ -347,0 +475,3 @@\n+    if (receiver()->as_NewInlineTypeInstance() != NULL) {\n+      receiver()->as_NewInlineTypeInstance()->set_not_larva_anymore();\n+    }\n@@ -349,1 +480,2 @@\n-    ValueType* t = argument_at(i)->type();\n+    Value v = argument_at(i);\n+    ValueType* t = v->type();\n@@ -352,0 +484,3 @@\n+    if (v->as_NewInlineTypeInstance() != NULL) {\n+      v->as_NewInlineTypeInstance()->set_not_larva_anymore();\n+    }\n@@ -864,0 +999,2 @@\n+          if (new_value->as_NewInlineTypeInstance() != NULL) {new_value->as_NewInlineTypeInstance()->set_not_larva_anymore(); }\n+          if (existing_value->as_NewInlineTypeInstance() != NULL) {existing_value->as_NewInlineTypeInstance()->set_not_larva_anymore(); }\n@@ -878,0 +1015,2 @@\n+          if (new_value->as_NewInlineTypeInstance() != NULL) {new_value->as_NewInlineTypeInstance()->set_not_larva_anymore(); }\n+          if (existing_value->as_NewInlineTypeInstance() != NULL) {existing_value->as_NewInlineTypeInstance()->set_not_larva_anymore(); }\n@@ -1044,0 +1183,1 @@\n+\n","filename":"src\/hotspot\/share\/c1\/c1_Instruction.cpp","additions":145,"deletions":5,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -75,0 +75,1 @@\n+class     NewInlineTypeInstance;\n@@ -79,0 +80,1 @@\n+class     Deoptimize;\n@@ -108,0 +110,1 @@\n+class   ProfileACmpTypes;\n@@ -180,0 +183,1 @@\n+  virtual void do_NewInlineTypeInstance(NewInlineTypeInstance* x) = 0;\n@@ -183,0 +187,1 @@\n+  virtual void do_Deoptimize     (Deoptimize*      x) = 0;\n@@ -207,0 +212,1 @@\n+  virtual void do_ProfileACmpTypes(ProfileACmpTypes*  x) = 0;\n@@ -223,3 +229,4 @@\n-#define HASH2(x1, x2        )                    ((HASH1(x1        ) << 7) ^ HASH1(x2))\n-#define HASH3(x1, x2, x3    )                    ((HASH2(x1, x2    ) << 7) ^ HASH1(x3))\n-#define HASH4(x1, x2, x3, x4)                    ((HASH3(x1, x2, x3) << 7) ^ HASH1(x4))\n+#define HASH2(x1, x2        )                    ((HASH1(x1            ) << 7) ^ HASH1(x2))\n+#define HASH3(x1, x2, x3    )                    ((HASH2(x1, x2        ) << 7) ^ HASH1(x3))\n+#define HASH4(x1, x2, x3, x4)                    ((HASH3(x1, x2, x3    ) << 7) ^ HASH1(x4))\n+#define HASH5(x1, x2, x3, x4, x5)                ((HASH4(x1, x2, x3, x4) << 7) ^ HASH1(x5))\n@@ -284,0 +291,15 @@\n+#define HASHING4(class_name, enabled, f1, f2, f3, f4) \\\n+  virtual intx hash() const {                         \\\n+    return (enabled) ? HASH5(name(), f1, f2, f3, f4) : 0; \\\n+  }                                                   \\\n+  virtual bool is_equal(Value v) const {              \\\n+    if (!(enabled)  ) return false;                   \\\n+    class_name* _v = v->as_##class_name();            \\\n+    if (_v == NULL  ) return false;                   \\\n+    if (f1 != _v->f1) return false;                   \\\n+    if (f2 != _v->f2) return false;                   \\\n+    if (f3 != _v->f3) return false;                   \\\n+    if (f4 != _v->f4) return false;                   \\\n+    return true;                                      \\\n+  }                                                   \\\n+\n@@ -306,0 +328,1 @@\n+  friend class GraphBuilder;\n@@ -358,0 +381,1 @@\n+    NeverNullFlag,          \/\/ For \"Q\" signatures\n@@ -452,0 +476,2 @@\n+  void set_null_free(bool f)                     { set_flag(NeverNullFlag, f); }\n+  bool is_null_free() const                      { return check_flag(NeverNullFlag); }\n@@ -462,0 +488,1 @@\n+  ciKlass* as_loaded_klass_or_null() const;\n@@ -506,0 +533,4 @@\n+  bool is_loaded_flattened_array() const;\n+  bool maybe_flattened_array();\n+  bool maybe_null_free_array();\n+\n@@ -553,0 +584,1 @@\n+  virtual NewInlineTypeInstance* as_NewInlineTypeInstance() { return NULL; }\n@@ -557,0 +589,1 @@\n+  virtual Deoptimize*       as_Deoptimize()      { return NULL; }\n@@ -706,1 +739,1 @@\n-  Local(ciType* declared, ValueType* type, int index, bool receiver)\n+  Local(ciType* declared, ValueType* type, int index, bool receiver, bool null_free)\n@@ -712,0 +745,1 @@\n+    set_null_free(null_free);\n@@ -831,1 +865,2 @@\n-            ValueStack* state_before, bool needs_patching)\n+            ValueStack* state_before, bool needs_patching,\n+            ciInlineKlass* inline_klass = NULL, Value default_value = NULL )\n@@ -833,1 +868,3 @@\n-  {}\n+  {\n+    set_null_free(field->signature()->is_Q_signature());\n+  }\n@@ -849,8 +886,1 @@\n-             ValueStack* state_before, bool needs_patching)\n-  : AccessField(obj, offset, field, is_static, state_before, needs_patching)\n-  , _value(value)\n-  {\n-    set_flag(NeedsWriteBarrierFlag, as_ValueType(field_type())->is_object());\n-    ASSERT_VALUES\n-    pin();\n-  }\n+             ValueStack* state_before, bool needs_patching);\n@@ -918,0 +948,2 @@\n+  ciMethod* _profiled_method;\n+  int       _profiled_bci;\n@@ -927,0 +959,1 @@\n+  , _profiled_method(NULL), _profiled_bci(0)\n@@ -942,1 +975,10 @@\n-  \/\/ generic\n+  \/\/ Helpers for MethodData* profiling\n+  void set_should_profile(bool value)                { set_flag(ProfileMDOFlag, value); }\n+  void set_profiled_method(ciMethod* method)         { _profiled_method = method;   }\n+  void set_profiled_bci(int bci)                     { _profiled_bci = bci;         }\n+  bool      should_profile() const                   { return check_flag(ProfileMDOFlag); }\n+  ciMethod* profiled_method() const                  { return _profiled_method;     }\n+  int       profiled_bci() const                     { return _profiled_bci;        }\n+\n+\n+\/\/ generic\n@@ -946,0 +988,1 @@\n+class DelayedLoadIndexed;\n@@ -950,0 +993,2 @@\n+  NewInlineTypeInstance* _vt;\n+  DelayedLoadIndexed* _delayed;\n@@ -955,1 +1000,1 @@\n-  , _explicit_null_check(NULL) {}\n+  , _explicit_null_check(NULL), _vt(NULL), _delayed(NULL) {}\n@@ -967,2 +1012,8 @@\n-  \/\/ generic;\n-  HASHING3(LoadIndexed, true, type()->tag(), array()->subst(), index()->subst())\n+  NewInlineTypeInstance* vt() const { return _vt; }\n+  void set_vt(NewInlineTypeInstance* vt) { _vt = vt; }\n+\n+  DelayedLoadIndexed* delayed() const { return _delayed; }\n+  void set_delayed(DelayedLoadIndexed* delayed) { _delayed = delayed; }\n+\n+  \/\/ generic\n+  HASHING4(LoadIndexed, delayed() == NULL && !should_profile(), type()->tag(), array()->subst(), index()->subst(), vt())\n@@ -971,0 +1022,23 @@\n+class DelayedLoadIndexed : public CompilationResourceObj {\n+private:\n+  LoadIndexed* _load_instr;\n+  ValueStack* _state_before;\n+  ciField* _field;\n+  int _offset;\n+ public:\n+  DelayedLoadIndexed(LoadIndexed* load, ValueStack* state_before)\n+  : _load_instr(load)\n+  , _state_before(state_before)\n+  , _field(NULL)\n+  , _offset(0) { }\n+\n+  void update(ciField* field, int offset) {\n+    _field = field;\n+    _offset += offset;\n+  }\n+\n+  LoadIndexed* load_instr() const { return _load_instr; }\n+  ValueStack* state_before() const { return _state_before; }\n+  ciField* field() const { return _field; }\n+  int offset() const { return _offset; }\n+};\n@@ -976,2 +1050,0 @@\n-  ciMethod* _profiled_method;\n-  int       _profiled_bci;\n@@ -983,9 +1055,1 @@\n-               bool check_boolean, bool mismatched = false)\n-  : AccessIndexed(array, index, length, elt_type, state_before, mismatched)\n-  , _value(value), _profiled_method(NULL), _profiled_bci(0), _check_boolean(check_boolean)\n-  {\n-    set_flag(NeedsWriteBarrierFlag, (as_ValueType(elt_type)->is_object()));\n-    set_flag(NeedsStoreCheckFlag, (as_ValueType(elt_type)->is_object()));\n-    ASSERT_VALUES\n-    pin();\n-  }\n+               bool check_boolean, bool mismatched = false);\n@@ -998,7 +1062,3 @@\n-  \/\/ Helpers for MethodData* profiling\n-  void set_should_profile(bool value)                { set_flag(ProfileMDOFlag, value); }\n-  void set_profiled_method(ciMethod* method)         { _profiled_method = method;   }\n-  void set_profiled_bci(int bci)                     { _profiled_bci = bci;         }\n-  bool      should_profile() const                   { return check_flag(ProfileMDOFlag); }\n-  ciMethod* profiled_method() const                  { return _profiled_method;     }\n-  int       profiled_bci() const                     { return _profiled_bci;        }\n+\n+  \/\/ Flattened array support\n+  bool is_exact_flattened_array_store() const;\n@@ -1119,0 +1179,1 @@\n+  bool _substitutability_check;\n@@ -1122,1 +1183,1 @@\n-  IfOp(Value x, Condition cond, Value y, Value tval, Value fval)\n+  IfOp(Value x, Condition cond, Value y, Value tval, Value fval, ValueStack* state_before, bool substitutability_check)\n@@ -1126,0 +1187,1 @@\n+  , _substitutability_check(substitutability_check)\n@@ -1129,0 +1191,1 @@\n+    set_state_before(state_before);\n@@ -1137,1 +1200,1 @@\n-\n+  bool substitutability_check() const             { return _substitutability_check; }\n@@ -1256,1 +1319,1 @@\n-         ciMethod* target, ValueStack* state_before);\n+         ciMethod* target, ValueStack* state_before, bool null_free);\n@@ -1316,0 +1379,48 @@\n+LEAF(NewInlineTypeInstance, StateSplit)\n+  ciInlineKlass* _klass;\n+  bool _in_larval_state;\n+  int _first_local_index;\n+  int _on_stack_count;\n+public:\n+\n+  \/\/ Default creation, always allocated for now\n+  NewInlineTypeInstance(ciInlineKlass* klass, ValueStack* state_before)\n+  : StateSplit(instanceType, state_before)\n+   , _klass(klass)\n+   , _in_larval_state(true)\n+   , _first_local_index(-1)\n+   , _on_stack_count(1)\n+  {\n+    set_null_free(true);\n+  }\n+\n+  \/\/ accessors\n+  ciInlineKlass* klass() const { return _klass; }\n+  virtual bool needs_exception_state() const     { return false; }\n+\n+  \/\/ generic\n+  virtual bool can_trap() const                  { return true; }\n+  ciType* exact_type() const;\n+  ciType* declared_type() const;\n+\n+  \/\/ Only done in LIR Generator -> map everything to object\n+  void set_to_object_type() { set_type(instanceType); }\n+\n+  void set_local_index(int index) {\n+    decrement_on_stack_count();\n+    if (_first_local_index != index) {\n+      if (_first_local_index == -1) {\n+        _first_local_index = index;\n+      } else {\n+        set_not_larva_anymore();\n+      }\n+    }\n+  }\n+\n+  bool in_larval_state() const { return _in_larval_state; }\n+  void set_not_larva_anymore() { _in_larval_state = false; }\n+\n+  int on_stack_count() const { return _on_stack_count; }\n+  void increment_on_stack_count() { _on_stack_count++; }\n+  void decrement_on_stack_count() { _on_stack_count--; }\n+};\n@@ -1367,1 +1478,4 @@\n-  NewObjectArray(ciKlass* klass, Value length, ValueStack* state_before) : NewArray(length, state_before), _klass(klass) {}\n+  NewObjectArray(ciKlass* klass, Value length, ValueStack* state_before, bool null_free)\n+  : NewArray(length, state_before), _klass(klass) {\n+    set_null_free(null_free);\n+  }\n@@ -1402,0 +1516,2 @@\n+\n+  ciType* exact_type() const;\n@@ -1404,0 +1520,11 @@\n+LEAF(Deoptimize, StateSplit)\n+private:\n+  ciKlass*    _klass;\n+\n+ public:\n+  Deoptimize(ciKlass* klass, ValueStack* state_before)\n+  : StateSplit(objectType, state_before), _klass(klass) {}\n+\n+  \/\/ accessors\n+  ciKlass* klass() const                         { return _klass; }\n+};\n@@ -1448,2 +1575,4 @@\n-  CheckCast(ciKlass* klass, Value obj, ValueStack* state_before)\n-  : TypeCheck(klass, obj, objectType, state_before) {}\n+  CheckCast(ciKlass* klass, Value obj, ValueStack* state_before, bool null_free = false)\n+  : TypeCheck(klass, obj, objectType, state_before) {\n+    set_null_free(null_free);\n+  }\n@@ -1507,0 +1636,1 @@\n+  bool _maybe_inlinetype;\n@@ -1509,1 +1639,1 @@\n-  MonitorEnter(Value obj, int monitor_no, ValueStack* state_before)\n+  MonitorEnter(Value obj, int monitor_no, ValueStack* state_before, bool maybe_inlinetype)\n@@ -1511,0 +1641,1 @@\n+  , _maybe_inlinetype(maybe_inlinetype)\n@@ -1515,0 +1646,3 @@\n+  \/\/ accessors\n+  bool maybe_inlinetype() const                   { return _maybe_inlinetype; }\n+\n@@ -1979,0 +2113,1 @@\n+  bool        _substitutability_check;\n@@ -1982,1 +2117,1 @@\n-  If(Value x, Condition cond, bool unordered_is_true, Value y, BlockBegin* tsux, BlockBegin* fsux, ValueStack* state_before, bool is_safepoint)\n+  If(Value x, Condition cond, bool unordered_is_true, Value y, BlockBegin* tsux, BlockBegin* fsux, ValueStack* state_before, bool is_safepoint, bool substitutability_check=false)\n@@ -1990,0 +2125,1 @@\n+  , _substitutability_check(substitutability_check)\n@@ -1998,0 +2134,4 @@\n+    if (!_substitutability_check) {\n+      assert(x->as_NewInlineTypeInstance() == NULL || y->type() == objectNull, \"Sanity check\");\n+      assert(y->as_NewInlineTypeInstance() == NULL || x->type() == objectNull, \"Sanity check\");\n+    }\n@@ -2032,0 +2172,1 @@\n+  bool substitutability_check() const              { return _substitutability_check; }\n@@ -2523,1 +2664,1 @@\n-    \/\/ The ProfileType has side-effects and must occur precisely where located\n+    \/\/ The ProfileReturnType has side-effects and must occur precisely where located\n@@ -2539,0 +2680,42 @@\n+LEAF(ProfileACmpTypes, Instruction)\n+ private:\n+  ciMethod*        _method;\n+  int              _bci;\n+  Value            _left;\n+  Value            _right;\n+  bool             _left_maybe_null;\n+  bool             _right_maybe_null;\n+\n+ public:\n+  ProfileACmpTypes(ciMethod* method, int bci, Value left, Value right)\n+    : Instruction(voidType)\n+    , _method(method)\n+    , _bci(bci)\n+    , _left(left)\n+    , _right(right)\n+  {\n+    \/\/ The ProfileACmp has side-effects and must occur precisely where located\n+    pin();\n+    _left_maybe_null = true;\n+    _right_maybe_null = true;\n+  }\n+\n+  ciMethod* method()             const { return _method; }\n+  int bci()                      const { return _bci; }\n+  Value left()                   const { return _left; }\n+  Value right()                  const { return _right; }\n+  bool left_maybe_null()         const { return _left_maybe_null; }\n+  bool right_maybe_null()        const { return _right_maybe_null; }\n+  void set_left_maybe_null(bool v)     { _left_maybe_null = v; }\n+  void set_right_maybe_null(bool v)    { _right_maybe_null = v; }\n+\n+  virtual void input_values_do(ValueVisitor* f)   {\n+    if (_left != NULL) {\n+      f->visit(&_left);\n+    }\n+    if (_right != NULL) {\n+      f->visit(&_right);\n+    }\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/c1\/c1_Instruction.hpp","additions":228,"deletions":45,"binary":false,"changes":273,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -98,0 +99,1 @@\n+    case T_INLINE_TYPE:\n@@ -156,0 +158,1 @@\n+    case T_INLINE_TYPE:\n@@ -299,1 +302,1 @@\n-                                 CodeStub* stub)\n+                                 CodeStub* stub, bool need_null_check)\n@@ -315,0 +318,1 @@\n+  , _need_null_check(need_null_check)\n@@ -342,0 +346,1 @@\n+  , _need_null_check(true)\n@@ -351,0 +356,31 @@\n+LIR_OpFlattenedArrayCheck::LIR_OpFlattenedArrayCheck(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub)\n+  : LIR_Op(lir_flattened_array_check, LIR_OprFact::illegalOpr, NULL)\n+  , _array(array)\n+  , _value(value)\n+  , _tmp(tmp)\n+  , _stub(stub) {}\n+\n+\n+LIR_OpNullFreeArrayCheck::LIR_OpNullFreeArrayCheck(LIR_Opr array, LIR_Opr tmp)\n+  : LIR_Op(lir_null_free_array_check, LIR_OprFact::illegalOpr, NULL)\n+  , _array(array)\n+  , _tmp(tmp) {}\n+\n+\n+LIR_OpSubstitutabilityCheck::LIR_OpSubstitutabilityCheck(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,\n+                                                         LIR_Opr tmp1, LIR_Opr tmp2,\n+                                                         ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,\n+                                                         CodeEmitInfo* info, CodeStub* stub)\n+  : LIR_Op(lir_substitutability_check, result, info)\n+  , _left(left)\n+  , _right(right)\n+  , _equal_result(equal_result)\n+  , _not_equal_result(not_equal_result)\n+  , _tmp1(tmp1)\n+  , _tmp2(tmp2)\n+  , _left_klass(left_klass)\n+  , _right_klass(right_klass)\n+  , _left_klass_op(left_klass_op)\n+  , _right_klass_op(right_klass_op)\n+  , _stub(stub) {}\n+\n@@ -418,0 +454,1 @@\n+    case lir_check_orig_pc:            \/\/ result and info always invalid\n@@ -809,0 +846,1 @@\n+      do_stub(opLock->_throw_imse_stub);\n@@ -845,0 +883,45 @@\n+\/\/ LIR_OpFlattenedArrayCheck\n+    case lir_flattened_array_check: {\n+      assert(op->as_OpFlattenedArrayCheck() != NULL, \"must be\");\n+      LIR_OpFlattenedArrayCheck* opFlattenedArrayCheck = (LIR_OpFlattenedArrayCheck*)op;\n+\n+      if (opFlattenedArrayCheck->_array->is_valid()) do_input(opFlattenedArrayCheck->_array);\n+      if (opFlattenedArrayCheck->_value->is_valid()) do_input(opFlattenedArrayCheck->_value);\n+      if (opFlattenedArrayCheck->_tmp->is_valid())   do_temp(opFlattenedArrayCheck->_tmp);\n+                                                     do_stub(opFlattenedArrayCheck->_stub);\n+\n+      break;\n+    }\n+\n+\/\/ LIR_OpNullFreeArrayCheck\n+    case lir_null_free_array_check: {\n+      assert(op->as_OpNullFreeArrayCheck() != NULL, \"must be\");\n+      LIR_OpNullFreeArrayCheck* opNullFreeArrayCheck = (LIR_OpNullFreeArrayCheck*)op;\n+\n+      if (opNullFreeArrayCheck->_array->is_valid()) do_input(opNullFreeArrayCheck->_array);\n+      if (opNullFreeArrayCheck->_tmp->is_valid())   do_temp(opNullFreeArrayCheck->_tmp);\n+      break;\n+    }\n+\n+\/\/ LIR_OpSubstitutabilityCheck\n+    case lir_substitutability_check: {\n+      assert(op->as_OpSubstitutabilityCheck() != NULL, \"must be\");\n+      LIR_OpSubstitutabilityCheck* opSubstitutabilityCheck = (LIR_OpSubstitutabilityCheck*)op;\n+                                                                do_input(opSubstitutabilityCheck->_left);\n+                                                                do_temp (opSubstitutabilityCheck->_left);\n+                                                                do_input(opSubstitutabilityCheck->_right);\n+                                                                do_temp (opSubstitutabilityCheck->_right);\n+                                                                do_input(opSubstitutabilityCheck->_equal_result);\n+                                                                do_temp (opSubstitutabilityCheck->_equal_result);\n+                                                                do_input(opSubstitutabilityCheck->_not_equal_result);\n+                                                                do_temp (opSubstitutabilityCheck->_not_equal_result);\n+      if (opSubstitutabilityCheck->_tmp1->is_valid())           do_temp(opSubstitutabilityCheck->_tmp1);\n+      if (opSubstitutabilityCheck->_tmp2->is_valid())           do_temp(opSubstitutabilityCheck->_tmp2);\n+      if (opSubstitutabilityCheck->_left_klass_op->is_valid())  do_temp(opSubstitutabilityCheck->_left_klass_op);\n+      if (opSubstitutabilityCheck->_right_klass_op->is_valid()) do_temp(opSubstitutabilityCheck->_right_klass_op);\n+      if (opSubstitutabilityCheck->_result->is_valid())         do_output(opSubstitutabilityCheck->_result);\n+                                                                do_info(opSubstitutabilityCheck->_info);\n+                                                                do_stub(opSubstitutabilityCheck->_stub);\n+      break;\n+    }\n+\n@@ -908,1 +991,12 @@\n-  default:\n+\n+    \/\/ LIR_OpProfileInlineType:\n+    case lir_profile_inline_type: {\n+      assert(op->as_OpProfileInlineType() != NULL, \"must be\");\n+      LIR_OpProfileInlineType* opProfileInlineType = (LIR_OpProfileInlineType*)op;\n+\n+      do_input(opProfileInlineType->_mdp); do_temp(opProfileInlineType->_mdp);\n+      do_input(opProfileInlineType->_obj);\n+      do_temp(opProfileInlineType->_tmp);\n+      break;\n+    }\n+default:\n@@ -981,0 +1075,28 @@\n+bool LIR_OpJavaCall::maybe_return_as_fields(ciInlineKlass** vk_ret) const {\n+  if (InlineTypeReturnedAsFields &&\n+      (method()->signature()->returns_inline_type() ||\n+       method()->is_method_handle_intrinsic())) {\n+    ciType* return_type = method()->return_type();\n+    if (return_type->is_inlinetype()) {\n+      ciInlineKlass* vk = return_type->as_inline_klass();\n+      if (vk->can_be_returned_as_fields()) {\n+        if (vk_ret != NULL) {\n+          *vk_ret = vk;\n+        }\n+        return true;\n+      }\n+    } else if (return_type->is_instance_klass()) {\n+      \/\/ An inline type might be returned from the call but we don't know its\n+      \/\/ type. Either we get a buffered inline type (and nothing needs to be done)\n+      \/\/ or one of the inlines being returned is the klass of the inline type\n+      \/\/ (RAX on x64, with LSB set to 1) and we need to allocate an inline\n+      \/\/ type instance of that type and initialize it with other values being\n+      \/\/ returned (in other registers).\n+      assert(!return_type->as_instance_klass()->is_loaded() ||\n+             method()->is_method_handle_intrinsic(), \"unexpected return type\");\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -1041,0 +1163,18 @@\n+void LIR_OpFlattenedArrayCheck::emit_code(LIR_Assembler* masm) {\n+  masm->emit_opFlattenedArrayCheck(this);\n+  if (stub() != NULL) {\n+    masm->append_code_stub(stub());\n+  }\n+}\n+\n+void LIR_OpNullFreeArrayCheck::emit_code(LIR_Assembler* masm) {\n+  masm->emit_opNullFreeArrayCheck(this);\n+}\n+\n+void LIR_OpSubstitutabilityCheck::emit_code(LIR_Assembler* masm) {\n+  masm->emit_opSubstitutabilityCheck(this);\n+  if (stub() != NULL) {\n+    masm->append_code_stub(stub());\n+  }\n+}\n+\n@@ -1054,0 +1194,3 @@\n+  if (throw_imse_stub()) {\n+    masm->append_code_stub(throw_imse_stub());\n+  }\n@@ -1074,0 +1217,4 @@\n+void LIR_OpProfileInlineType::emit_code(LIR_Assembler* masm) {\n+  masm->emit_profile_inline_type(this);\n+}\n+\n@@ -1355,1 +1502,1 @@\n-void LIR_List::lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info) {\n+void LIR_List::lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info, CodeStub* throw_imse_stub) {\n@@ -1363,1 +1510,2 @@\n-                    info));\n+                    info,\n+                    throw_imse_stub));\n@@ -1388,1 +1536,4 @@\n-                          ciMethod* profiled_method, int profiled_bci) {\n+                          ciMethod* profiled_method, int profiled_bci, bool is_null_free) {\n+  \/\/ If klass is non-nullable,  LIRGenerator::do_CheckCast has already performed null-check\n+  \/\/ on the object.\n+  bool need_null_check = !is_null_free;\n@@ -1390,1 +1541,2 @@\n-                                           tmp1, tmp2, tmp3, fast_check, info_for_exception, info_for_patch, stub);\n+                                           tmp1, tmp2, tmp3, fast_check, info_for_exception, info_for_patch, stub,\n+                                           need_null_check);\n@@ -1412,0 +1564,1 @@\n+  \/\/ FIXME -- if the types of the array and\/or the object are known statically, we can avoid loading the klass\n@@ -1433,0 +1586,21 @@\n+void LIR_List::check_flattened_array(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub) {\n+  LIR_OpFlattenedArrayCheck* c = new LIR_OpFlattenedArrayCheck(array, value, tmp, stub);\n+  append(c);\n+}\n+\n+void LIR_List::check_null_free_array(LIR_Opr array, LIR_Opr tmp) {\n+  LIR_OpNullFreeArrayCheck* c = new LIR_OpNullFreeArrayCheck(array, tmp);\n+  append(c);\n+}\n+\n+void LIR_List::substitutability_check(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,\n+                                      LIR_Opr tmp1, LIR_Opr tmp2,\n+                                      ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,\n+                                      CodeEmitInfo* info, CodeStub* stub) {\n+  LIR_OpSubstitutabilityCheck* c = new LIR_OpSubstitutabilityCheck(result, left, right, equal_result, not_equal_result,\n+                                                                   tmp1, tmp2,\n+                                                                   left_klass, right_klass, left_klass_op, right_klass_op,\n+                                                                   info, stub);\n+  append(c);\n+}\n+\n@@ -1650,0 +1824,1 @@\n+     case lir_check_orig_pc:         s = \"check_orig_pc\"; break;\n@@ -1717,0 +1892,6 @@\n+     \/\/ LIR_OpFlattenedArrayCheck\n+     case lir_flattened_array_check: s = \"flattened_array_check\"; break;\n+     \/\/ LIR_OpNullFreeArrayCheck\n+     case lir_null_free_array_check: s = \"null_free_array_check\"; break;\n+     \/\/ LIR_OpSubstitutabilityCheck\n+     case lir_substitutability_check: s = \"substitutability_check\"; break;\n@@ -1725,0 +1906,2 @@\n+     \/\/ LIR_OpProfileInlineType\n+     case lir_profile_inline_type:   s = \"profile_inline_type\"; break;\n@@ -1962,0 +2145,38 @@\n+void LIR_OpFlattenedArrayCheck::print_instr(outputStream* out) const {\n+  array()->print(out);                   out->print(\" \");\n+  value()->print(out);                   out->print(\" \");\n+  tmp()->print(out);                     out->print(\" \");\n+  if (stub() != NULL) {\n+    out->print(\"[label:\" INTPTR_FORMAT \"]\", p2i(stub()->entry()));\n+  }\n+}\n+\n+void LIR_OpNullFreeArrayCheck::print_instr(outputStream* out) const {\n+  array()->print(out);                   out->print(\" \");\n+  tmp()->print(out);                     out->print(\" \");\n+}\n+\n+void LIR_OpSubstitutabilityCheck::print_instr(outputStream* out) const {\n+  result_opr()->print(out);              out->print(\" \");\n+  left()->print(out);                    out->print(\" \");\n+  right()->print(out);                   out->print(\" \");\n+  equal_result()->print(out);            out->print(\" \");\n+  not_equal_result()->print(out);        out->print(\" \");\n+  tmp1()->print(out);                    out->print(\" \");\n+  tmp2()->print(out);                    out->print(\" \");\n+  if (left_klass() == NULL) {\n+    out->print(\"unknown \");\n+  } else {\n+    left_klass()->print(out);            out->print(\" \");\n+  }\n+  if (right_klass() == NULL) {\n+    out->print(\"unknown \");\n+  } else {\n+    right_klass()->print(out);           out->print(\" \");\n+  }\n+  left_klass_op()->print(out);           out->print(\" \");\n+  right_klass_op()->print(out);          out->print(\" \");\n+  if (stub() != NULL) {\n+    out->print(\"[label:\" INTPTR_FORMAT \"]\", p2i(stub()->entry()));\n+  }\n+}\n@@ -2023,0 +2244,8 @@\n+\/\/ LIR_OpProfileInlineType\n+void LIR_OpProfileInlineType::print_instr(outputStream* out) const {\n+  out->print(\" flag = %x \", flag());\n+  mdp()->print(out);          out->print(\" \");\n+  obj()->print(out);          out->print(\" \");\n+  tmp()->print(out);          out->print(\" \");\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":235,"deletions":6,"binary":false,"changes":241,"status":"modified"},{"patch":"@@ -320,0 +320,1 @@\n+      case T_INLINE_TYPE:\n@@ -470,0 +471,1 @@\n+  case T_INLINE_TYPE:\n@@ -660,0 +662,1 @@\n+      case T_INLINE_TYPE: \/\/ fall through\n@@ -765,0 +768,1 @@\n+      case T_INLINE_TYPE: \/\/ fall through\n@@ -878,0 +882,3 @@\n+class    LIR_OpFlattenedArrayCheck;\n+class    LIR_OpNullFreeArrayCheck;\n+class    LIR_OpSubstitutabilityCheck;\n@@ -881,0 +888,1 @@\n+class    LIR_OpProfileInlineType;\n@@ -906,0 +914,1 @@\n+      , lir_check_orig_pc\n@@ -984,0 +993,9 @@\n+  , begin_opFlattenedArrayCheck\n+    , lir_flattened_array_check\n+  , end_opFlattenedArrayCheck\n+  , begin_opNullFreeArrayCheck\n+    , lir_null_free_array_check\n+  , end_opNullFreeArrayCheck\n+  , begin_opSubstitutabilityCheck\n+    , lir_substitutability_check\n+  , end_opSubstitutabilityCheck\n@@ -992,0 +1010,1 @@\n+    , lir_profile_inline_type\n@@ -1135,0 +1154,3 @@\n+  virtual LIR_OpFlattenedArrayCheck* as_OpFlattenedArrayCheck() { return NULL; }\n+  virtual LIR_OpNullFreeArrayCheck* as_OpNullFreeArrayCheck() { return NULL; }\n+  virtual LIR_OpSubstitutabilityCheck* as_OpSubstitutabilityCheck() { return NULL; }\n@@ -1138,0 +1160,1 @@\n+  virtual LIR_OpProfileInlineType* as_OpProfileInlineType() { return NULL; }\n@@ -1210,0 +1233,2 @@\n+\n+  bool maybe_return_as_fields(ciInlineKlass** vk = NULL) const;\n@@ -1261,1 +1286,4 @@\n-    all_flags              = (1 << 12) - 1\n+    always_slow_path       = 1 << 12,\n+    src_inlinetype_check   = 1 << 13,\n+    dst_inlinetype_check   = 1 << 14,\n+    all_flags              = (1 << 15) - 1\n@@ -1563,0 +1591,1 @@\n+  bool          _need_null_check;\n@@ -1567,1 +1596,1 @@\n-                  CodeEmitInfo* info_for_exception, CodeEmitInfo* info_for_patch, CodeStub* stub);\n+                  CodeEmitInfo* info_for_exception, CodeEmitInfo* info_for_patch, CodeStub* stub, bool need_null_check = true);\n@@ -1589,1 +1618,1 @@\n-\n+  bool      need_null_check() const              { return _need_null_check;   }\n@@ -1596,0 +1625,76 @@\n+\/\/ LIR_OpFlattenedArrayCheck\n+class LIR_OpFlattenedArrayCheck: public LIR_Op {\n+ friend class LIR_OpVisitState;\n+\n+ private:\n+  LIR_Opr       _array;\n+  LIR_Opr       _value;\n+  LIR_Opr       _tmp;\n+  CodeStub*     _stub;\n+public:\n+  LIR_OpFlattenedArrayCheck(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub);\n+  LIR_Opr array() const                          { return _array;         }\n+  LIR_Opr value() const                          { return _value;         }\n+  LIR_Opr tmp() const                            { return _tmp;           }\n+  CodeStub* stub() const                         { return _stub;          }\n+\n+  virtual void emit_code(LIR_Assembler* masm);\n+  virtual LIR_OpFlattenedArrayCheck* as_OpFlattenedArrayCheck() { return this; }\n+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;\n+};\n+\n+\/\/ LIR_OpNullFreeArrayCheck\n+class LIR_OpNullFreeArrayCheck: public LIR_Op {\n+ friend class LIR_OpVisitState;\n+\n+ private:\n+  LIR_Opr       _array;\n+  LIR_Opr       _tmp;\n+public:\n+  LIR_OpNullFreeArrayCheck(LIR_Opr array, LIR_Opr tmp);\n+  LIR_Opr array() const                          { return _array;         }\n+  LIR_Opr tmp() const                            { return _tmp;           }\n+\n+  virtual void emit_code(LIR_Assembler* masm);\n+  virtual LIR_OpNullFreeArrayCheck* as_OpNullFreeArrayCheck() { return this; }\n+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;\n+};\n+\n+class LIR_OpSubstitutabilityCheck: public LIR_Op {\n+ friend class LIR_OpVisitState;\n+\n+ private:\n+  LIR_Opr       _left;\n+  LIR_Opr       _right;\n+  LIR_Opr       _equal_result;\n+  LIR_Opr       _not_equal_result;\n+  LIR_Opr       _tmp1;\n+  LIR_Opr       _tmp2;\n+  ciKlass*      _left_klass;\n+  ciKlass*      _right_klass;\n+  LIR_Opr       _left_klass_op;\n+  LIR_Opr       _right_klass_op;\n+  CodeStub*     _stub;\n+public:\n+  LIR_OpSubstitutabilityCheck(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,\n+                              LIR_Opr tmp1, LIR_Opr tmp2,\n+                              ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,\n+                              CodeEmitInfo* info, CodeStub* stub);\n+\n+  LIR_Opr left() const             { return _left; }\n+  LIR_Opr right() const            { return _right; }\n+  LIR_Opr equal_result() const     { return _equal_result; }\n+  LIR_Opr not_equal_result() const { return _not_equal_result; }\n+  LIR_Opr tmp1() const             { return _tmp1; }\n+  LIR_Opr tmp2() const             { return _tmp2; }\n+  ciKlass* left_klass() const      { return _left_klass; }\n+  ciKlass* right_klass() const     { return _right_klass; }\n+  LIR_Opr left_klass_op() const    { return _left_klass_op; }\n+  LIR_Opr right_klass_op() const   { return _right_klass_op; }\n+  CodeStub* stub() const           { return _stub; }\n+\n+  virtual void emit_code(LIR_Assembler* masm);\n+  virtual LIR_OpSubstitutabilityCheck* as_OpSubstitutabilityCheck() { return this; }\n+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;\n+};\n+\n@@ -1788,0 +1893,1 @@\n+  CodeStub* _throw_imse_stub;\n@@ -1789,1 +1895,1 @@\n-  LIR_OpLock(LIR_Code code, LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info)\n+  LIR_OpLock(LIR_Code code, LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info, CodeStub* throw_imse_stub=NULL)\n@@ -1795,1 +1901,2 @@\n-    , _stub(stub)                      {}\n+    , _stub(stub)\n+    , _throw_imse_stub(throw_imse_stub)                    {}\n@@ -1802,0 +1909,1 @@\n+  CodeStub* throw_imse_stub() const              { return _throw_imse_stub; }\n@@ -1968,0 +2076,32 @@\n+\/\/ LIR_OpProfileInlineType\n+class LIR_OpProfileInlineType : public LIR_Op {\n+ friend class LIR_OpVisitState;\n+\n+ private:\n+  LIR_Opr      _mdp;\n+  LIR_Opr      _obj;\n+  int          _flag;\n+  LIR_Opr      _tmp;\n+  bool         _not_null;      \/\/ true if we know statically that _obj cannot be null\n+\n+ public:\n+  \/\/ Destroys recv\n+  LIR_OpProfileInlineType(LIR_Opr mdp, LIR_Opr obj, int flag, LIR_Opr tmp, bool not_null)\n+    : LIR_Op(lir_profile_inline_type, LIR_OprFact::illegalOpr, NULL)  \/\/ no result, no info\n+    , _mdp(mdp)\n+    , _obj(obj)\n+    , _flag(flag)\n+    , _tmp(tmp)\n+    , _not_null(not_null) { }\n+\n+  LIR_Opr      mdp()              const             { return _mdp;              }\n+  LIR_Opr      obj()              const             { return _obj;              }\n+  int          flag()             const             { return _flag;             }\n+  LIR_Opr      tmp()              const             { return _tmp;              }\n+  bool         not_null()         const             { return _not_null;         }\n+\n+  virtual void emit_code(LIR_Assembler* masm);\n+  virtual LIR_OpProfileInlineType* as_OpProfileInlineType() { return this; }\n+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;\n+};\n+\n@@ -2228,1 +2368,1 @@\n-  void lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info);\n+  void lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info, CodeStub* throw_imse_stub=NULL);\n@@ -2238,0 +2378,6 @@\n+  void check_flattened_array(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub);\n+  void check_null_free_array(LIR_Opr array, LIR_Opr tmp);\n+  void substitutability_check(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,\n+                              LIR_Opr tmp1, LIR_Opr tmp2,\n+                              ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,\n+                              CodeEmitInfo* info, CodeStub* stub);\n@@ -2242,1 +2388,1 @@\n-                  ciMethod* profiled_method, int profiled_bci);\n+                  ciMethod* profiled_method, int profiled_bci, bool is_null_free);\n@@ -2250,0 +2396,3 @@\n+  void profile_inline_type(LIR_Address* mdp, LIR_Opr obj, int flag, LIR_Opr tmp, bool not_null) {\n+    append(new LIR_OpProfileInlineType(LIR_OprFact::address(mdp), obj, flag, tmp, not_null));\n+  }\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":156,"deletions":7,"binary":false,"changes":163,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -37,0 +38,1 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n@@ -57,0 +59,1 @@\n+      case Bytecodes::_withfield:\n@@ -64,0 +67,1 @@\n+      case Bytecodes::_defaultvalue:\n@@ -120,0 +124,1 @@\n+  _verified_inline_entry.reset();\n@@ -330,1 +335,0 @@\n-\n@@ -340,2 +344,1 @@\n-\n-void LIR_Assembler::add_call_info(int pc_offset, CodeEmitInfo* cinfo) {\n+void LIR_Assembler::add_call_info(int pc_offset, CodeEmitInfo* cinfo, bool maybe_return_as_fields) {\n@@ -343,1 +346,1 @@\n-  cinfo->record_debug_info(compilation()->debug_info_recorder(), pc_offset);\n+  cinfo->record_debug_info(compilation()->debug_info_recorder(), pc_offset, maybe_return_as_fields);\n@@ -483,0 +486,6 @@\n+  ciInlineKlass* vk = NULL;\n+  if (op->maybe_return_as_fields(&vk)) {\n+    int offset = store_inline_type_fields_to_buf(vk);\n+    add_call_info(offset, op->info(), true);\n+  }\n+\n@@ -590,0 +599,135 @@\n+void LIR_Assembler::add_scalarized_entry_info(int pc_offset) {\n+  flush_debug_info(pc_offset);\n+  DebugInformationRecorder* debug_info = compilation()->debug_info_recorder();\n+  \/\/ The VEP and VIEP(RO) of a C1-compiled method call buffer_inline_args_xxx()\n+  \/\/ before doing any argument shuffling. This call may cause GC. When GC happens,\n+  \/\/ all the parameters are still as passed by the caller, so we just use\n+  \/\/ map->set_include_argument_oops() inside frame::sender_for_compiled_frame(RegisterMap* map).\n+  \/\/ There's no need to build a GC map here.\n+  OopMap* oop_map = new OopMap(0, 0);\n+  debug_info->add_safepoint(pc_offset, oop_map);\n+  DebugToken* locvals = debug_info->create_scope_values(NULL); \/\/ FIXME is this needed (for Java debugging to work properly??)\n+  DebugToken* expvals = debug_info->create_scope_values(NULL); \/\/ FIXME is this needed (for Java debugging to work properly??)\n+  DebugToken* monvals = debug_info->create_monitor_values(NULL); \/\/ FIXME: need testing with synchronized method\n+  bool reexecute = false;\n+  bool return_oop = false; \/\/ This flag will be ignored since it used only for C2 with escape analysis.\n+  bool rethrow_exception = false;\n+  bool is_method_handle_invoke = false;\n+  debug_info->describe_scope(pc_offset, methodHandle(), method(), 0, reexecute, rethrow_exception, is_method_handle_invoke, return_oop, false, locvals, expvals, monvals);\n+  debug_info->end_safepoint(pc_offset);\n+}\n+\n+\/\/ The entries points of C1-compiled methods can have the following types:\n+\/\/ (1) Methods with no inline type args\n+\/\/ (2) Methods with inline type receiver but no inline type args\n+\/\/     VIEP_RO is the same as VIEP\n+\/\/ (3) Methods with non-inline type receiver and some inline type args\n+\/\/     VIEP_RO is the same as VEP\n+\/\/ (4) Methods with inline type receiver and other inline type args\n+\/\/     Separate VEP, VIEP and VIEP_RO\n+\/\/\n+\/\/ (1)               (2)                 (3)                    (4)\n+\/\/ UEP\/UIEP:         VEP:                UEP:                   UEP:\n+\/\/   check_icache      pack receiver       check_icache           check_icache\n+\/\/ VEP\/VIEP\/VIEP_RO    jump to VIEP      VEP\/VIEP_RO:           VIEP_RO:\n+\/\/   body            UEP\/UIEP:             pack inline args       pack inline args (except receiver)\n+\/\/                     check_icache        jump to VIEP           jump to VIEP\n+\/\/                   VIEP\/VIEP_RO        UIEP:                  VEP:\n+\/\/                     body                check_icache           pack all inline args\n+\/\/                                       VIEP:                    jump to VIEP\n+\/\/                                         body                 UIEP:\n+\/\/                                                                check_icache\n+\/\/                                                              VIEP:\n+\/\/                                                                body\n+void LIR_Assembler::emit_std_entries() {\n+  offsets()->set_value(CodeOffsets::OSR_Entry, _masm->offset());\n+\n+  _masm->align(CodeEntryAlignment);\n+  const CompiledEntrySignature* ces = compilation()->compiled_entry_signature();\n+  if (ces->has_scalarized_args()) {\n+    assert(InlineTypePassFieldsAsArgs && method()->get_Method()->has_scalarized_args(), \"must be\");\n+    CodeOffsets::Entries ro_entry_type = ces->c1_inline_ro_entry_type();\n+\n+    \/\/ UEP: check icache and fall-through\n+    if (ro_entry_type != CodeOffsets::Verified_Inline_Entry) {\n+      offsets()->set_value(CodeOffsets::Entry, _masm->offset());\n+      if (needs_icache(method())) {\n+        check_icache();\n+      }\n+    }\n+\n+    \/\/ VIEP_RO: pack all value parameters, except the receiver\n+    if (ro_entry_type == CodeOffsets::Verified_Inline_Entry_RO) {\n+      emit_std_entry(CodeOffsets::Verified_Inline_Entry_RO, ces);\n+    }\n+\n+    \/\/ VEP: pack all value parameters\n+    _masm->align(CodeEntryAlignment);\n+    emit_std_entry(CodeOffsets::Verified_Entry, ces);\n+\n+    \/\/ UIEP: check icache and fall-through\n+    _masm->align(CodeEntryAlignment);\n+    offsets()->set_value(CodeOffsets::Inline_Entry, _masm->offset());\n+    if (ro_entry_type == CodeOffsets::Verified_Inline_Entry) {\n+      \/\/ Special case if we have VIEP == VIEP(RO):\n+      \/\/ this means UIEP (called by C1) == UEP (called by C2).\n+      offsets()->set_value(CodeOffsets::Entry, _masm->offset());\n+    }\n+    if (needs_icache(method())) {\n+      check_icache();\n+    }\n+\n+    \/\/ VIEP: all value parameters are passed as refs - no packing.\n+    emit_std_entry(CodeOffsets::Verified_Inline_Entry, NULL);\n+\n+    if (ro_entry_type != CodeOffsets::Verified_Inline_Entry_RO) {\n+      \/\/ The VIEP(RO) is the same as VEP or VIEP\n+      assert(ro_entry_type == CodeOffsets::Verified_Entry ||\n+             ro_entry_type == CodeOffsets::Verified_Inline_Entry, \"must be\");\n+      offsets()->set_value(CodeOffsets::Verified_Inline_Entry_RO,\n+                           offsets()->value(ro_entry_type));\n+    }\n+  } else {\n+    \/\/ All 3 entries are the same (no inline type packing)\n+    offsets()->set_value(CodeOffsets::Entry, _masm->offset());\n+    offsets()->set_value(CodeOffsets::Inline_Entry, _masm->offset());\n+    if (needs_icache(method())) {\n+      check_icache();\n+    }\n+    emit_std_entry(CodeOffsets::Verified_Inline_Entry, NULL);\n+    offsets()->set_value(CodeOffsets::Verified_Entry, offsets()->value(CodeOffsets::Verified_Inline_Entry));\n+    offsets()->set_value(CodeOffsets::Verified_Inline_Entry_RO, offsets()->value(CodeOffsets::Verified_Inline_Entry));\n+  }\n+}\n+\n+void LIR_Assembler::emit_std_entry(CodeOffsets::Entries entry, const CompiledEntrySignature* ces) {\n+  offsets()->set_value(entry, _masm->offset());\n+  _masm->verified_entry();\n+  switch (entry) {\n+  case CodeOffsets::Verified_Entry: {\n+    if (needs_clinit_barrier_on_entry(method())) {\n+      clinit_barrier(method());\n+    }\n+    int rt_call_offset = _masm->verified_entry(ces, initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()->sp_offset_for_orig_pc()), _verified_inline_entry);\n+    add_scalarized_entry_info(rt_call_offset);\n+    break;\n+  }\n+  case CodeOffsets::Verified_Inline_Entry_RO: {\n+    assert(!needs_clinit_barrier_on_entry(method()), \"can't be static\");\n+    int rt_call_offset = _masm->verified_inline_ro_entry(ces, initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()->sp_offset_for_orig_pc()), _verified_inline_entry);\n+    add_scalarized_entry_info(rt_call_offset);\n+    break;\n+  }\n+  case CodeOffsets::Verified_Inline_Entry: {\n+    if (needs_clinit_barrier_on_entry(method())) {\n+      clinit_barrier(method());\n+    }\n+    build_frame();\n+    offsets()->set_value(CodeOffsets::Frame_Complete, _masm->offset());\n+    break;\n+  }\n+  default:\n+    ShouldNotReachHere();\n+    break;\n+  }\n+}\n@@ -603,13 +747,1 @@\n-      \/\/ init offsets\n-      offsets()->set_value(CodeOffsets::OSR_Entry, _masm->offset());\n-      _masm->align(CodeEntryAlignment);\n-      if (needs_icache(compilation()->method())) {\n-        check_icache();\n-      }\n-      offsets()->set_value(CodeOffsets::Verified_Entry, _masm->offset());\n-      _masm->verified_entry();\n-      if (needs_clinit_barrier_on_entry(compilation()->method())) {\n-        clinit_barrier(compilation()->method());\n-      }\n-      build_frame();\n-      offsets()->set_value(CodeOffsets::Frame_Complete, _masm->offset());\n+      emit_std_entries();\n@@ -669,0 +801,4 @@\n+    case lir_check_orig_pc:\n+      check_orig_pc();\n+      break;\n+\n@@ -762,1 +898,2 @@\n-  _masm->build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n+  _masm->build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()->sp_offset_for_orig_pc()),\n+                     needs_stack_repair(), method()->has_scalarized_args(), &_verified_inline_entry);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.cpp","additions":155,"deletions":18,"binary":false,"changes":173,"status":"modified"},{"patch":"@@ -34,0 +34,2 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -213,0 +215,2 @@\n+  assert(!_gen->in_conditional_code(), \"LIRItem cannot be loaded in conditional code\");\n+\n@@ -640,1 +644,2 @@\n-void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n+void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no,\n+                                 CodeEmitInfo* info_for_exception, CodeEmitInfo* info, CodeStub* throw_imse_stub) {\n@@ -643,1 +648,1 @@\n-  CodeStub* slow_path = new MonitorEnterStub(object, lock, info);\n+  CodeStub* slow_path = new MonitorEnterStub(object, lock, info, throw_imse_stub, scratch);\n@@ -646,1 +651,1 @@\n-  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception);\n+  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception, throw_imse_stub);\n@@ -670,4 +675,9 @@\n-void LIRGenerator::new_instance(LIR_Opr dst, ciInstanceKlass* klass, bool is_unresolved, LIR_Opr scratch1, LIR_Opr scratch2, LIR_Opr scratch3, LIR_Opr scratch4, LIR_Opr klass_reg, CodeEmitInfo* info) {\n-  klass2reg_with_patching(klass_reg, klass, info, is_unresolved);\n-  \/\/ If klass is not loaded we do not know if the klass has finalizers:\n-  if (UseFastNewInstance && klass->is_loaded()\n+void LIRGenerator::new_instance(LIR_Opr dst, ciInstanceKlass* klass, bool is_unresolved, bool allow_inline, LIR_Opr scratch1, LIR_Opr scratch2, LIR_Opr scratch3, LIR_Opr scratch4, LIR_Opr klass_reg, CodeEmitInfo* info) {\n+  if (allow_inline) {\n+    assert(!is_unresolved && klass->is_loaded(), \"inline type klass should be resolved\");\n+    __ metadata2reg(klass->constant_encoding(), klass_reg);\n+  } else {\n+    klass2reg_with_patching(klass_reg, klass, info, is_unresolved);\n+  }\n+  \/\/ If klass is not loaded we do not know if the klass has finalizers or is an unexpected inline klass\n+  if (UseFastNewInstance && klass->is_loaded() && (allow_inline || !klass->is_inlinetype())\n@@ -687,2 +697,2 @@\n-    CodeStub* slow_path = new NewInstanceStub(klass_reg, dst, klass, info, Runtime1::new_instance_id);\n-    __ branch(lir_cond_always, slow_path);\n+    CodeStub* slow_path = new NewInstanceStub(klass_reg, dst, klass, info, allow_inline ? Runtime1::new_instance_id : Runtime1::new_instance_no_inline_id);\n+    __ jump(slow_path);\n@@ -788,0 +798,10 @@\n+  if (!src->is_loaded_flattened_array() && !dst->is_loaded_flattened_array()) {\n+    flags &= ~LIR_OpArrayCopy::always_slow_path;\n+  }\n+  if (!src->maybe_flattened_array()) {\n+    flags &= ~LIR_OpArrayCopy::src_inlinetype_check;\n+  }\n+  if (!dst->maybe_flattened_array() && !dst->maybe_null_free_array()) {\n+    flags &= ~LIR_OpArrayCopy::dst_inlinetype_check;\n+  }\n+\n@@ -1537,2 +1557,4 @@\n-  _constants.append(c);\n-  _reg_for_constants.append(result);\n+  if (!in_conditional_code()) {\n+    _constants.append(c);\n+    _reg_for_constants.append(result);\n+  }\n@@ -1542,0 +1564,6 @@\n+void LIRGenerator::set_in_conditional_code(bool v) {\n+  assert(v != _in_conditional_code, \"must change state\");\n+  _in_conditional_code = v;\n+}\n+\n+\n@@ -1633,0 +1661,5 @@\n+  if (!inline_type_field_access_prolog(x, info)) {\n+    \/\/ Field store will always deopt due to unloaded field or holder klass\n+    return;\n+  }\n+\n@@ -1654,0 +1687,171 @@\n+\/\/ FIXME -- I can't find any other way to pass an address to access_load_at().\n+class TempResolvedAddress: public Instruction {\n+ public:\n+  TempResolvedAddress(ValueType* type, LIR_Opr addr) : Instruction(type) {\n+    set_operand(addr);\n+  }\n+  virtual void input_values_do(ValueVisitor*) {}\n+  virtual void visit(InstructionVisitor* v)   {}\n+  virtual const char* name() const  { return \"TempResolvedAddress\"; }\n+};\n+\n+LIR_Opr LIRGenerator::get_and_load_element_address(LIRItem& array, LIRItem& index) {\n+  ciType* array_type = array.value()->declared_type();\n+  ciFlatArrayKlass* flat_array_klass = array_type->as_flat_array_klass();\n+  assert(flat_array_klass->is_loaded(), \"must be\");\n+\n+  int array_header_size = flat_array_klass->array_header_in_bytes();\n+  int shift = flat_array_klass->log2_element_size();\n+\n+#ifndef _LP64\n+  LIR_Opr index_op = new_register(T_INT);\n+  \/\/ FIXME -- on 32-bit, the shift below can overflow, so we need to check that\n+  \/\/ the top (shift+1) bits of index_op must be zero, or\n+  \/\/ else throw ArrayIndexOutOfBoundsException\n+  if (index.result()->is_constant()) {\n+    jint const_index = index.result()->as_jint();\n+    __ move(LIR_OprFact::intConst(const_index << shift), index_op);\n+  } else {\n+    __ shift_left(index_op, shift, index.result());\n+  }\n+#else\n+  LIR_Opr index_op = new_register(T_LONG);\n+  if (index.result()->is_constant()) {\n+    jint const_index = index.result()->as_jint();\n+    __ move(LIR_OprFact::longConst(const_index << shift), index_op);\n+  } else {\n+    __ convert(Bytecodes::_i2l, index.result(), index_op);\n+    \/\/ Need to shift manually, as LIR_Address can scale only up to 3.\n+    __ shift_left(index_op, shift, index_op);\n+  }\n+#endif\n+\n+  LIR_Opr elm_op = new_pointer_register();\n+  LIR_Address* elm_address = generate_address(array.result(), index_op, 0, array_header_size, T_ADDRESS);\n+  __ leal(LIR_OprFact::address(elm_address), elm_op);\n+  return elm_op;\n+}\n+\n+void LIRGenerator::access_sub_element(LIRItem& array, LIRItem& index, LIR_Opr& result, ciField* field, int sub_offset) {\n+  assert(field != NULL, \"Need a subelement type specified\");\n+\n+  \/\/ Find the starting address of the source (inside the array)\n+  LIR_Opr elm_op = get_and_load_element_address(array, index);\n+\n+  BasicType subelt_type = field->type()->basic_type();\n+  TempResolvedAddress* elm_resolved_addr = new TempResolvedAddress(as_ValueType(subelt_type), elm_op);\n+  LIRItem elm_item(elm_resolved_addr, this);\n+\n+  DecoratorSet decorators = IN_HEAP;\n+  access_load_at(decorators, subelt_type,\n+                     elm_item, LIR_OprFact::intConst(sub_offset), result,\n+                     NULL, NULL);\n+\n+  if (field->signature()->is_Q_signature()) {\n+    assert(field->type()->as_inline_klass()->is_loaded(), \"Must be\");\n+    LabelObj* L_end = new LabelObj();\n+    __ cmp(lir_cond_notEqual, result, LIR_OprFact::oopConst(NULL));\n+    __ branch(lir_cond_notEqual, L_end->label());\n+    set_in_conditional_code(true);\n+    Constant* default_value = new Constant(new InstanceConstant(field->type()->as_inline_klass()->default_instance()));\n+    if (default_value->is_pinned()) {\n+      __ move(LIR_OprFact::value_type(default_value->type()), result);\n+    } else {\n+      __ move(load_constant(default_value), result);\n+    }\n+    __ branch_destination(L_end->label());\n+    set_in_conditional_code(false);\n+  }\n+}\n+\n+void LIRGenerator::access_flattened_array(bool is_load, LIRItem& array, LIRItem& index, LIRItem& obj_item,\n+                                          ciField* field, int sub_offset) {\n+  assert(sub_offset == 0 || field != NULL, \"Sanity check\");\n+\n+  \/\/ Find the starting address of the source (inside the array)\n+  LIR_Opr elm_op = get_and_load_element_address(array, index);\n+\n+  ciInlineKlass* elem_klass = NULL;\n+  if (field != NULL) {\n+    elem_klass = field->type()->as_inline_klass();\n+  } else {\n+    elem_klass = array.value()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+  }\n+  for (int i = 0; i < elem_klass->nof_nonstatic_fields(); i++) {\n+    ciField* inner_field = elem_klass->nonstatic_field_at(i);\n+    assert(!inner_field->is_flattened(), \"flattened fields must have been expanded\");\n+    int obj_offset = inner_field->offset();\n+    int elm_offset = obj_offset - elem_klass->first_field_offset() + sub_offset; \/\/ object header is not stored in array.\n+    BasicType field_type = inner_field->type()->basic_type();\n+\n+    \/\/ Types which are smaller than int are still passed in an int register.\n+    BasicType reg_type = field_type;\n+    switch (reg_type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+    case T_SHORT:\n+    case T_CHAR:\n+      reg_type = T_INT;\n+      break;\n+    default:\n+      break;\n+    }\n+\n+    LIR_Opr temp = new_register(reg_type);\n+    TempResolvedAddress* elm_resolved_addr = new TempResolvedAddress(as_ValueType(field_type), elm_op);\n+    LIRItem elm_item(elm_resolved_addr, this);\n+\n+    DecoratorSet decorators = IN_HEAP;\n+    if (is_load) {\n+      access_load_at(decorators, field_type,\n+                     elm_item, LIR_OprFact::intConst(elm_offset), temp,\n+                     NULL, NULL);\n+      access_store_at(decorators, field_type,\n+                      obj_item, LIR_OprFact::intConst(obj_offset), temp,\n+                      NULL, NULL);\n+    } else {\n+      access_load_at(decorators, field_type,\n+                     obj_item, LIR_OprFact::intConst(obj_offset), temp,\n+                     NULL, NULL);\n+      access_store_at(decorators, field_type,\n+                      elm_item, LIR_OprFact::intConst(elm_offset), temp,\n+                      NULL, NULL);\n+    }\n+  }\n+}\n+\n+void LIRGenerator::check_flattened_array(LIR_Opr array, LIR_Opr value, CodeStub* slow_path) {\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_flattened_array(array, value, tmp, slow_path);\n+}\n+\n+void LIRGenerator::check_null_free_array(LIRItem& array, LIRItem& value, CodeEmitInfo* info) {\n+  LabelObj* L_end = new LabelObj();\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_null_free_array(array.result(), tmp);\n+  __ branch(lir_cond_equal, L_end->label());\n+  __ null_check(value.result(), info);\n+  __ branch_destination(L_end->label());\n+}\n+\n+bool LIRGenerator::needs_flattened_array_store_check(StoreIndexed* x) {\n+  if (x->elt_type() == T_OBJECT && x->array()->maybe_flattened_array()) {\n+    ciType* type = x->value()->declared_type();\n+    if (type != NULL && type->is_klass()) {\n+      ciKlass* klass = type->as_klass();\n+      if (!klass->can_be_inline_klass() || (klass->is_inlinetype() && !klass->as_inline_klass()->flatten_array())) {\n+        \/\/ This is known to be a non-flattened object. If the array is flattened,\n+        \/\/ it will be caught by the code generated by array_store_check().\n+        return false;\n+      }\n+    }\n+    \/\/ We're not 100% sure, so let's do the flattened_array_store_check.\n+    return true;\n+  }\n+  return false;\n+}\n+\n+bool LIRGenerator::needs_null_free_array_store_check(StoreIndexed* x) {\n+  return x->elt_type() == T_OBJECT && x->array()->maybe_null_free_array();\n+}\n+\n@@ -1656,0 +1860,2 @@\n+  assert(x->elt_type() != T_ARRAY, \"never used\");\n+  bool is_loaded_flattened_array = x->array()->is_loaded_flattened_array();\n@@ -1659,3 +1865,3 @@\n-  bool needs_store_check = obj_store && (x->value()->as_Constant() == NULL ||\n-                                         !get_jobject_constant(x->value())->is_null_object() ||\n-                                         x->should_profile());\n+  bool needs_store_check = obj_store && !(is_loaded_flattened_array && x->is_exact_flattened_array_store()) &&\n+                                        (x->value()->as_Constant() == NULL ||\n+                                         !get_jobject_constant(x->value())->is_null_object());\n@@ -1674,2 +1880,3 @@\n-\n-  if (needs_store_check || x->check_boolean()) {\n+\n+  if (needs_store_check || x->check_boolean()\n+      || is_loaded_flattened_array || needs_flattened_array_store_check(x) || needs_null_free_array_store_check(x)) {\n@@ -1704,0 +1911,16 @@\n+  if (x->should_profile()) {\n+    if (x->array()->is_loaded_flattened_array()) {\n+      \/\/ No need to profile a store to a flattened array of known type. This can happen if\n+      \/\/ the type only became known after optimizations (for example, after the PhiSimplifier).\n+      x->set_should_profile(false);\n+    } else {\n+      ciMethodData* md = NULL;\n+      ciArrayLoadStoreData* load_store = NULL;\n+      profile_array_type(x, md, load_store);\n+      if (x->array()->maybe_null_free_array()) {\n+        profile_null_free_array(array, md, load_store);\n+      }\n+      profile_element_type(x->value(), md, load_store);\n+    }\n+  }\n+\n@@ -1706,1 +1929,1 @@\n-    array_store_check(value.result(), array.result(), store_check_info, x->profiled_method(), x->profiled_bci());\n+    array_store_check(value.result(), array.result(), store_check_info, NULL, -1);\n@@ -1709,4 +1932,10 @@\n-  DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n-  if (x->check_boolean()) {\n-    decorators |= C1_MASK_BOOLEAN;\n-  }\n+  if (is_loaded_flattened_array) {\n+    if (!x->value()->is_null_free()) {\n+      __ null_check(value.result(), new CodeEmitInfo(range_check_info));\n+    }\n+    \/\/ If array element is an empty inline type, no need to copy anything\n+    if (!x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass()->is_empty()) {\n+      access_flattened_array(false, array, index, value);\n+    }\n+  } else {\n+    StoreFlattenedArrayStub* slow_path = NULL;\n@@ -1714,2 +1943,23 @@\n-  access_store_at(decorators, x->elt_type(), array, index.result(), value.result(),\n-                  NULL, null_check_info);\n+    if (needs_flattened_array_store_check(x)) {\n+      \/\/ Check if we indeed have a flattened array\n+      index.load_item();\n+      slow_path = new StoreFlattenedArrayStub(array.result(), index.result(), value.result(), state_for(x, x->state_before()));\n+      check_flattened_array(array.result(), value.result(), slow_path);\n+      set_in_conditional_code(true);\n+    } else if (needs_null_free_array_store_check(x)) {\n+      CodeEmitInfo* info = new CodeEmitInfo(range_check_info);\n+      check_null_free_array(array, value, info);\n+    }\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    if (x->check_boolean()) {\n+      decorators |= C1_MASK_BOOLEAN;\n+    }\n+\n+    access_store_at(decorators, x->elt_type(), array, index.result(), value.result(),\n+                    NULL, null_check_info);\n+    if (slow_path != NULL) {\n+      __ branch_destination(slow_path->continuation());\n+      set_in_conditional_code(false);\n+    }\n+  }\n@@ -1805,0 +2055,25 @@\n+bool LIRGenerator::inline_type_field_access_prolog(AccessField* x, CodeEmitInfo* info) {\n+  ciField* field = x->field();\n+  assert(!field->is_flattened(), \"Flattened field access should have been expanded\");\n+  if (!field->signature()->is_Q_signature()) {\n+    return true; \/\/ Not an inline type field\n+  }\n+  \/\/ Deoptimize if the access is non-static and requires patching (holder not loaded\n+  \/\/ or not accessible) because then we only have partial field information and the\n+  \/\/ field could be flattened (see ciField constructor).\n+  bool could_be_flat = !x->is_static() && x->needs_patching();\n+  \/\/ Deoptimize if we load from a static field with an unloaded type because we need\n+  \/\/ the default value if the field is null.\n+  bool could_be_null = x->is_static() && x->as_LoadField() != NULL && !field->type()->is_loaded();\n+  assert(!could_be_null || !field->holder()->is_loaded(), \"inline type field should be loaded\");\n+  if (could_be_flat || could_be_null) {\n+    assert(x->needs_patching(), \"no deopt required\");\n+    CodeStub* stub = new DeoptimizeStub(new CodeEmitInfo(info),\n+                                        Deoptimization::Reason_unloaded,\n+                                        Deoptimization::Action_make_not_entrant);\n+    __ jump(stub);\n+    return false;\n+  }\n+  return true;\n+}\n+\n@@ -1834,0 +2109,7 @@\n+  if (!inline_type_field_access_prolog(x, info)) {\n+    \/\/ Field load will always deopt due to unloaded field or holder klass\n+    LIR_Opr result = rlock_result(x, field_type);\n+    __ move(LIR_OprFact::oopConst(NULL), result);\n+    return;\n+  }\n+\n@@ -1862,0 +2144,29 @@\n+\n+  ciField* field = x->field();\n+  if (field->signature()->is_Q_signature()) {\n+    \/\/ Load from non-flattened inline type field requires\n+    \/\/ a null check to replace null with the default value.\n+    ciInlineKlass* inline_klass = field->type()->as_inline_klass();\n+    assert(inline_klass->is_loaded(), \"field klass must be loaded\");\n+\n+    ciInstanceKlass* holder = field->holder();\n+    if (field->is_static() && holder->is_loaded()) {\n+      ciObject* val = holder->java_mirror()->field_value(field).as_object();\n+      if (!val->is_null_object()) {\n+        \/\/ Static field is initialized, we don need to perform a null check.\n+        return;\n+      }\n+    }\n+    LabelObj* L_end = new LabelObj();\n+    __ cmp(lir_cond_notEqual, result, LIR_OprFact::oopConst(NULL));\n+    __ branch(lir_cond_notEqual, L_end->label());\n+    set_in_conditional_code(true);\n+    Constant* default_value = new Constant(new InstanceConstant(inline_klass->default_instance()));\n+    if (default_value->is_pinned()) {\n+      __ move(LIR_OprFact::value_type(default_value->type()), result);\n+    } else {\n+      __ move(load_constant(default_value), result);\n+    }\n+    __ branch_destination(L_end->label());\n+    set_in_conditional_code(false);\n+  }\n@@ -1976,1 +2287,58 @@\n-  DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+  ciMethodData* md = NULL;\n+  ciArrayLoadStoreData* load_store = NULL;\n+  if (x->should_profile()) {\n+    if (x->array()->is_loaded_flattened_array()) {\n+      \/\/ No need to profile a load from a flattened array of known type. This can happen if\n+      \/\/ the type only became known after optimizations (for example, after the PhiSimplifier).\n+      x->set_should_profile(false);\n+    } else {\n+      profile_array_type(x, md, load_store);\n+    }\n+  }\n+\n+  Value element;\n+  if (x->vt() != NULL) {\n+    assert(x->array()->is_loaded_flattened_array(), \"must be\");\n+    \/\/ Find the destination address (of the NewInlineTypeInstance).\n+    LIRItem obj_item(x->vt(), this);\n+\n+    access_flattened_array(true, array, index, obj_item,\n+                           x->delayed() == NULL ? 0 : x->delayed()->field(),\n+                           x->delayed() == NULL ? 0 : x->delayed()->offset());\n+    set_no_result(x);\n+  } else if (x->delayed() != NULL) {\n+    assert(x->array()->is_loaded_flattened_array(), \"must be\");\n+    LIR_Opr result = rlock_result(x, x->delayed()->field()->type()->basic_type());\n+    access_sub_element(array, index, result, x->delayed()->field(), x->delayed()->offset());\n+  } else if (x->array() != NULL && x->array()->is_loaded_flattened_array() &&\n+             x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass()->is_empty()) {\n+    \/\/ Load the default instance instead of reading the element\n+    ciInlineKlass* elem_klass = x->array()->declared_type()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+    LIR_Opr result = rlock_result(x, x->elt_type());\n+    Constant* default_value = new Constant(new InstanceConstant(elem_klass->default_instance()));\n+    if (default_value->is_pinned()) {\n+      __ move(LIR_OprFact::value_type(default_value->type()), result);\n+    } else {\n+      __ move(load_constant(default_value), result);\n+    }\n+  } else {\n+    LIR_Opr result = rlock_result(x, x->elt_type());\n+    LoadFlattenedArrayStub* slow_path = NULL;\n+\n+    if (x->should_profile() && x->array()->maybe_null_free_array()) {\n+      profile_null_free_array(array, md, load_store);\n+    }\n+\n+    if (x->elt_type() == T_OBJECT && x->array()->maybe_flattened_array()) {\n+      assert(x->delayed() == NULL, \"Delayed LoadIndexed only apply to loaded_flattened_arrays\");\n+      index.load_item();\n+      \/\/ if we are loading from flattened array, load it using a runtime call\n+      slow_path = new LoadFlattenedArrayStub(array.result(), index.result(), result, state_for(x, x->state_before()));\n+      check_flattened_array(array.result(), LIR_OprFact::illegalOpr, slow_path);\n+      set_in_conditional_code(true);\n+    }\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    access_load_at(decorators, x->elt_type(),\n+                   array, index.result(), result,\n+                   NULL, null_check_info);\n@@ -1978,4 +2346,11 @@\n-  LIR_Opr result = rlock_result(x, x->elt_type());\n-  access_load_at(decorators, x->elt_type(),\n-                 array, index.result(), result,\n-                 NULL, null_check_info);\n+    if (slow_path != NULL) {\n+      __ branch_destination(slow_path->continuation());\n+      set_in_conditional_code(false);\n+    }\n+\n+    element = x;\n+  }\n+\n+  if (x->should_profile()) {\n+    profile_element_type(element, md, load_store);\n+  }\n@@ -1984,0 +2359,12 @@\n+void LIRGenerator::do_Deoptimize(Deoptimize* x) {\n+  \/\/ This happens only when a class X uses the withfield\/defaultvalue bytecode\n+  \/\/ to refer to an inline class V, where V has not yet been loaded\/resolved.\n+  \/\/ This is not a common case. Let's just deoptimize.\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+  CodeStub* stub = new DeoptimizeStub(new CodeEmitInfo(info),\n+                                      Deoptimization::Reason_unloaded,\n+                                      Deoptimization::Action_make_not_entrant);\n+  __ jump(stub);\n+  LIR_Opr reg = rlock_result(x, T_OBJECT);\n+  __ move(LIR_OprFact::oopConst(NULL), reg);\n+}\n@@ -2647,1 +3034,1 @@\n-  if (do_update) {\n+  if (do_update && signature_at_call_k != NULL) {\n@@ -2679,0 +3066,5 @@\n+  \/\/ Inline types can't be null\n+  if (exact_klass != NULL && exact_klass->is_inlinetype()) {\n+    do_null = false;\n+  }\n+\n@@ -2732,0 +3124,46 @@\n+void LIRGenerator::profile_flags(ciMethodData* md, ciProfileData* data, int flag, LIR_Condition condition) {\n+  assert(md != NULL && data != NULL, \"should have been initialized\");\n+  LIR_Opr mdp = new_register(T_METADATA);\n+  __ metadata2reg(md->constant_encoding(), mdp);\n+  LIR_Address* addr = new LIR_Address(mdp, md->byte_offset_of_slot(data, DataLayout::flags_offset()), T_BYTE);\n+  LIR_Opr flags = new_register(T_INT);\n+  __ move(addr, flags);\n+  if (condition != lir_cond_always) {\n+    LIR_Opr update = new_register(T_INT);\n+    __ cmove(condition, LIR_OprFact::intConst(0), LIR_OprFact::intConst(flag), update, T_INT);\n+  } else {\n+    __ logical_or(flags, LIR_OprFact::intConst(flag), flags);\n+  }\n+  __ store(flags, addr);\n+}\n+\n+void LIRGenerator::profile_null_free_array(LIRItem array, ciMethodData* md, ciArrayLoadStoreData* load_store) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  LabelObj* L_end = new LabelObj();\n+  LIR_Opr tmp = new_register(T_METADATA);\n+  __ check_null_free_array(array.result(), tmp);\n+\n+  profile_flags(md, load_store, ArrayLoadStoreData::null_free_array_byte_constant(), lir_cond_equal);\n+}\n+\n+void LIRGenerator::profile_array_type(AccessIndexed* x, ciMethodData*& md, ciArrayLoadStoreData*& load_store) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  int bci = x->profiled_bci();\n+  md = x->profiled_method()->method_data();\n+  assert(md != NULL, \"Sanity\");\n+  ciProfileData* data = md->bci_to_data(bci);\n+  assert(data != NULL && data->is_ArrayLoadStoreData(), \"incorrect profiling entry\");\n+  load_store = (ciArrayLoadStoreData*)data;\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(load_store, ArrayLoadStoreData::array_offset()), 0,\n+               load_store->array()->type(), x->array(), mdp, true, NULL, NULL);\n+}\n+\n+void LIRGenerator::profile_element_type(Value element, ciMethodData* md, ciArrayLoadStoreData* load_store) {\n+  assert(compilation()->profile_array_accesses(), \"array access profiling is disabled\");\n+  assert(md != NULL && load_store != NULL, \"should have been initialized\");\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(load_store, ArrayLoadStoreData::element_offset()), 0,\n+               load_store->element()->type(), element, mdp, false, NULL, NULL);\n+}\n+\n@@ -2816,0 +3254,8 @@\n+  if (method()->has_scalarized_args()) {\n+    \/\/ Check if deoptimization was triggered (i.e. orig_pc was set) while buffering scalarized inline type arguments\n+    \/\/ in the entry point (see comments in frame::deoptimize). If so, deoptimize only now that we have the right state.\n+    CodeEmitInfo* info = new CodeEmitInfo(scope()->start()->state()->copy(ValueStack::StateBefore, 0), NULL, false);\n+    CodeStub* deopt_stub = new DeoptimizeStub(info, Deoptimization::Reason_none, Deoptimization::Action_none);\n+    __ append(new LIR_Op0(lir_check_orig_pc));\n+    __ branch(lir_cond_notEqual, deopt_stub);\n+  }\n@@ -2831,0 +3277,18 @@\n+void LIRGenerator::invoke_load_one_argument(LIRItem* param, LIR_Opr loc) {\n+  if (loc->is_register()) {\n+    param->load_item_force(loc);\n+  } else {\n+    LIR_Address* addr = loc->as_address_ptr();\n+    param->load_for_store(addr->type());\n+    assert(addr->type() != T_INLINE_TYPE, \"not supported yet\");\n+    if (addr->type() == T_OBJECT) {\n+      __ move_wide(param->result(), addr);\n+    } else {\n+      if (addr->type() == T_LONG || addr->type() == T_DOUBLE) {\n+        __ unaligned_move(param->result(), addr);\n+      } else {\n+        __ move(param->result(), addr);\n+      }\n+    }\n+  }\n+}\n@@ -2838,14 +3302,1 @@\n-    if (loc->is_register()) {\n-      param->load_item_force(loc);\n-    } else {\n-      LIR_Address* addr = loc->as_address_ptr();\n-      param->load_for_store(addr->type());\n-      if (addr->type() == T_OBJECT) {\n-        __ move_wide(param->result(), addr);\n-      } else\n-        if (addr->type() == T_LONG || addr->type() == T_DOUBLE) {\n-          __ unaligned_move(param->result(), addr);\n-        } else {\n-          __ move(param->result(), addr);\n-        }\n-    }\n+    invoke_load_one_argument(param, loc);\n@@ -3028,1 +3479,1 @@\n-  if (can_inline_as_constant(right.value())) {\n+  if (can_inline_as_constant(right.value()) && !x->substitutability_check()) {\n@@ -3031,0 +3482,1 @@\n+    \/\/ substitutability_check() needs to use right as a base register.\n@@ -3038,3 +3490,60 @@\n-  LIR_Opr reg = rlock_result(x);\n-  __ cmp(lir_cond(x->cond()), left.result(), right.result());\n-  __ cmove(lir_cond(x->cond()), t_val.result(), f_val.result(), reg, as_BasicType(x->x()->type()));\n+  if (x->substitutability_check()) {\n+    substitutability_check(x, left, right, t_val, f_val);\n+  } else {\n+    LIR_Opr reg = rlock_result(x);\n+    __ cmp(lir_cond(x->cond()), left.result(), right.result());\n+    __ cmove(lir_cond(x->cond()), t_val.result(), f_val.result(), reg, as_BasicType(x->x()->type()));\n+  }\n+}\n+\n+void LIRGenerator::substitutability_check(IfOp* x, LIRItem& left, LIRItem& right, LIRItem& t_val, LIRItem& f_val) {\n+  assert(x->cond() == If::eql || x->cond() == If::neq, \"must be\");\n+  bool is_acmpeq = (x->cond() == If::eql);\n+  LIR_Opr equal_result     = is_acmpeq ? t_val.result() : f_val.result();\n+  LIR_Opr not_equal_result = is_acmpeq ? f_val.result() : t_val.result();\n+  LIR_Opr result = rlock_result(x);\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+\n+  substitutability_check_common(x->x(), x->y(), left, right, equal_result, not_equal_result, result, info);\n+}\n+\n+void LIRGenerator::substitutability_check(If* x, LIRItem& left, LIRItem& right) {\n+  LIR_Opr equal_result     = LIR_OprFact::intConst(1);\n+  LIR_Opr not_equal_result = LIR_OprFact::intConst(0);\n+  LIR_Opr result = new_register(T_INT);\n+  CodeEmitInfo* info = state_for(x, x->state_before());\n+\n+  substitutability_check_common(x->x(), x->y(), left, right, equal_result, not_equal_result, result, info);\n+\n+  assert(x->cond() == If::eql || x->cond() == If::neq, \"must be\");\n+  __ cmp(lir_cond(x->cond()), result, equal_result);\n+}\n+\n+void LIRGenerator::substitutability_check_common(Value left_val, Value right_val, LIRItem& left, LIRItem& right,\n+                                                 LIR_Opr equal_result, LIR_Opr not_equal_result, LIR_Opr result,\n+                                                 CodeEmitInfo* info) {\n+  LIR_Opr tmp1 = LIR_OprFact::illegalOpr;\n+  LIR_Opr tmp2 = LIR_OprFact::illegalOpr;\n+  LIR_Opr left_klass_op = LIR_OprFact::illegalOpr;\n+  LIR_Opr right_klass_op = LIR_OprFact::illegalOpr;\n+\n+  ciKlass* left_klass  = left_val ->as_loaded_klass_or_null();\n+  ciKlass* right_klass = right_val->as_loaded_klass_or_null();\n+\n+  if ((left_klass == NULL || right_klass == NULL) ||\/\/ The klass is still unloaded, or came from a Phi node.\n+      !left_klass->is_inlinetype() || !right_klass->is_inlinetype()) {\n+    init_temps_for_substitutability_check(tmp1, tmp2);\n+  }\n+\n+  if (left_klass != NULL && left_klass->is_inlinetype() && left_klass == right_klass) {\n+    \/\/ No need to load klass -- the operands are statically known to be the same inline klass.\n+  } else {\n+    BasicType t_klass = UseCompressedOops ? T_INT : T_METADATA;\n+    left_klass_op = new_register(t_klass);\n+    right_klass_op = new_register(t_klass);\n+  }\n+\n+  CodeStub* slow_path = new SubstitutabilityCheckStub(left.result(), right.result(), info);\n+  __ substitutability_check(result, left.result(), right.result(), equal_result, not_equal_result,\n+                            tmp1, tmp2,\n+                            left_klass, right_klass, left_klass_op, right_klass_op, info, slow_path);\n@@ -3354,1 +3863,1 @@\n-    ciReturnTypeEntry* ret = data->is_CallTypeData() ? ((ciCallTypeData*)data)->ret() : ((ciVirtualCallTypeData*)data)->ret();\n+    ciSingleTypeEntry* ret = data->is_CallTypeData() ? ((ciCallTypeData*)data)->ret() : ((ciVirtualCallTypeData*)data)->ret();\n@@ -3375,0 +3884,47 @@\n+bool LIRGenerator::profile_inline_klass(ciMethodData* md, ciProfileData* data, Value value, int flag) {\n+  ciKlass* klass = value->as_loaded_klass_or_null();\n+  if (klass != NULL) {\n+    if (klass->is_inlinetype()) {\n+      profile_flags(md, data, flag, lir_cond_always);\n+    } else if (klass->can_be_inline_klass()) {\n+      return false;\n+    }\n+  } else {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+\n+void LIRGenerator::do_ProfileACmpTypes(ProfileACmpTypes* x) {\n+  ciMethod* method = x->method();\n+  assert(method != NULL, \"method should be set if branch is profiled\");\n+  ciMethodData* md = method->method_data_or_null();\n+  assert(md != NULL, \"Sanity\");\n+  ciProfileData* data = md->bci_to_data(x->bci());\n+  assert(data != NULL, \"must have profiling data\");\n+  assert(data->is_ACmpData(), \"need BranchData for two-way branches\");\n+  ciACmpData* acmp = (ciACmpData*)data;\n+  LIR_Opr mdp = LIR_OprFact::illegalOpr;\n+  profile_type(md, md->byte_offset_of_slot(acmp, ACmpData::left_offset()), 0,\n+               acmp->left()->type(), x->left(), mdp, !x->left_maybe_null(), NULL, NULL);\n+  int flags_offset = md->byte_offset_of_slot(data, DataLayout::flags_offset());\n+  if (!profile_inline_klass(md, acmp, x->left(), ACmpData::left_inline_type_byte_constant())) {\n+    LIR_Opr mdp = new_register(T_METADATA);\n+    __ metadata2reg(md->constant_encoding(), mdp);\n+    LIRItem value(x->left(), this);\n+    value.load_item();\n+    __ profile_inline_type(new LIR_Address(mdp, flags_offset, T_INT), value.result(), ACmpData::left_inline_type_byte_constant(), new_register(T_INT), !x->left_maybe_null());\n+  }\n+  profile_type(md, md->byte_offset_of_slot(acmp, ACmpData::left_offset()),\n+               in_bytes(ACmpData::right_offset()) - in_bytes(ACmpData::left_offset()),\n+               acmp->right()->type(), x->right(), mdp, !x->right_maybe_null(), NULL, NULL);\n+  if (!profile_inline_klass(md, acmp, x->right(), ACmpData::right_inline_type_byte_constant())) {\n+    LIR_Opr mdp = new_register(T_METADATA);\n+    __ metadata2reg(md->constant_encoding(), mdp);\n+    LIRItem value(x->right(), this);\n+    value.load_item();\n+    __ profile_inline_type(new LIR_Address(mdp, flags_offset, T_INT), value.result(), ACmpData::right_inline_type_byte_constant(), new_register(T_INT), !x->left_maybe_null());\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":604,"deletions":48,"binary":false,"changes":652,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-static int type2spill_size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2,  1, 2, 1, -1};\n+static int type2spill_size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2,  1, 2, 1, 2, -1};\n@@ -68,1 +68,1 @@\n-static int type2spill_size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, -1, 1, 1, -1};\n+static int type2spill_size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, -1, 1, 1, 1, -1};\n@@ -263,1 +263,1 @@\n-  if (!frame_map()->finalize_frame(max_spills())) {\n+  if (!frame_map()->finalize_frame(max_spills(), compilation()->needs_stack_repair())) {\n@@ -2945,1 +2945,1 @@\n-  return new IRScopeDebugInfo(cur_scope, cur_state->bci(), locals, expressions, monitors, caller_debug_info);\n+  return new IRScopeDebugInfo(cur_scope, cur_state->bci(), locals, expressions, monitors, caller_debug_info, cur_state->should_reexecute());\n","filename":"src\/hotspot\/share\/c1\/c1_LinearScan.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -56,0 +56,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n@@ -126,0 +128,1 @@\n+int Runtime1::_new_flat_array_slowcase_cnt = 0;\n@@ -128,0 +131,5 @@\n+int Runtime1::_load_flattened_array_slowcase_cnt = 0;\n+int Runtime1::_store_flattened_array_slowcase_cnt = 0;\n+int Runtime1::_substitutability_check_slowcase_cnt = 0;\n+int Runtime1::_buffer_inline_args_slowcase_cnt = 0;\n+int Runtime1::_buffer_inline_args_no_receiver_slowcase_cnt = 0;\n@@ -137,0 +145,1 @@\n+int Runtime1::_throw_illegal_monitor_state_exception_count = 0;\n@@ -355,4 +364,1 @@\n-\n-JRT_ENTRY(void, Runtime1::new_instance(JavaThread* current, Klass* klass))\n-  NOT_PRODUCT(_new_instance_slowcase_cnt++;)\n-\n+static void allocate_instance(JavaThread* current, Klass* klass, TRAPS) {\n@@ -370,0 +376,14 @@\n+JRT_ENTRY(void, Runtime1::new_instance(JavaThread* current, Klass* klass))\n+  NOT_PRODUCT(_new_instance_slowcase_cnt++;)\n+  allocate_instance(current, klass, CHECK);\n+JRT_END\n+\n+\/\/ Same as new_instance but throws error for inline klasses\n+JRT_ENTRY(void, Runtime1::new_instance_no_inline(JavaThread* current, Klass* klass))\n+  NOT_PRODUCT(_new_instance_slowcase_cnt++;)\n+  if (klass->is_inline_klass()) {\n+    SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_InstantiationError());\n+  } else {\n+    allocate_instance(current, klass, CHECK);\n+  }\n+JRT_END\n@@ -397,1 +417,1 @@\n-  Klass* elem_klass = ObjArrayKlass::cast(array_klass)->element_klass();\n+  Klass* elem_klass = ArrayKlass::cast(array_klass)->element_klass();\n@@ -408,0 +428,22 @@\n+JRT_ENTRY(void, Runtime1::new_flat_array(JavaThread* current, Klass* array_klass, jint length))\n+  NOT_PRODUCT(_new_flat_array_slowcase_cnt++;)\n+\n+  \/\/ Note: no handle for klass needed since they are not used\n+  \/\/       anymore after new_objArray() and no GC can happen before.\n+  \/\/       (This may have to change if this code changes!)\n+  assert(array_klass->is_klass(), \"not a class\");\n+  Handle holder(THREAD, array_klass->klass_holder()); \/\/ keep the klass alive\n+  Klass* elem_klass = ArrayKlass::cast(array_klass)->element_klass();\n+  assert(elem_klass->is_inline_klass(), \"must be\");\n+  \/\/ Logically creates elements, ensure klass init\n+  elem_klass->initialize(CHECK);\n+  arrayOop obj = oopFactory::new_flatArray(elem_klass, length, CHECK);\n+  current->set_vm_result(obj);\n+  \/\/ This is pretty rare but this runtime patch is stressful to deoptimization\n+  \/\/ if we deoptimize here so force a deopt to stress the path.\n+  if (DeoptimizeALot) {\n+    deopt_caller(current);\n+  }\n+JRT_END\n+\n+\n@@ -419,0 +461,81 @@\n+static void profile_flat_array(JavaThread* current) {\n+  ResourceMark rm(current);\n+  vframeStream vfst(current, true);\n+  assert(!vfst.at_end(), \"Java frame must exist\");\n+  \/\/ Check if array access profiling is enabled\n+  if (vfst.nm()->comp_level() != CompLevel_full_profile || !C1UpdateMethodData) {\n+    return;\n+  }\n+  int bci = vfst.bci();\n+  Method* method = vfst.method();\n+  MethodData* md = method->method_data();\n+  if (md != NULL) {\n+    ProfileData* data = md->bci_to_data(bci);\n+    assert(data != NULL && data->is_ArrayLoadStoreData(), \"incorrect profiling entry\");\n+    ArrayLoadStoreData* load_store = (ArrayLoadStoreData*)data;\n+    load_store->set_flat_array();\n+  }\n+}\n+\n+JRT_ENTRY(void, Runtime1::load_flattened_array(JavaThread* current, flatArrayOopDesc* array, int index))\n+  assert(array->klass()->is_flatArray_klass(), \"should not be called\");\n+  profile_flat_array(current);\n+\n+  NOT_PRODUCT(_load_flattened_array_slowcase_cnt++;)\n+  assert(array->length() > 0 && index < array->length(), \"already checked\");\n+  flatArrayHandle vah(current, array);\n+  oop obj = flatArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK);\n+  current->set_vm_result(obj);\n+JRT_END\n+\n+\n+JRT_ENTRY(void, Runtime1::store_flattened_array(JavaThread* current, flatArrayOopDesc* array, int index, oopDesc* value))\n+  if (array->klass()->is_flatArray_klass()) {\n+    profile_flat_array(current);\n+  }\n+\n+  NOT_PRODUCT(_store_flattened_array_slowcase_cnt++;)\n+  if (value == NULL) {\n+    assert(array->klass()->is_flatArray_klass() || array->klass()->is_null_free_array_klass(), \"should not be called\");\n+    SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_NullPointerException());\n+  } else {\n+    assert(array->klass()->is_flatArray_klass(), \"should not be called\");\n+    array->value_copy_to_index(value, index);\n+  }\n+JRT_END\n+\n+\n+JRT_ENTRY(int, Runtime1::substitutability_check(JavaThread* current, oopDesc* left, oopDesc* right))\n+  NOT_PRODUCT(_substitutability_check_slowcase_cnt++;)\n+  JavaCallArguments args;\n+  args.push_oop(Handle(THREAD, left));\n+  args.push_oop(Handle(THREAD, right));\n+  JavaValue result(T_BOOLEAN);\n+  JavaCalls::call_static(&result,\n+                         vmClasses::ValueBootstrapMethods_klass(),\n+                         vmSymbols::isSubstitutable_name(),\n+                         vmSymbols::object_object_boolean_signature(),\n+                         &args, CHECK_0);\n+  return result.get_jboolean() ? 1 : 0;\n+JRT_END\n+\n+\n+extern \"C\" void ps();\n+\n+void Runtime1::buffer_inline_args_impl(JavaThread* current, Method* m, bool allocate_receiver) {\n+  Thread* THREAD = current;\n+  methodHandle method(current, m); \/\/ We are inside the verified_entry or verified_inline_ro_entry of this method.\n+  oop obj = SharedRuntime::allocate_inline_types_impl(current, method, allocate_receiver, CHECK);\n+  current->set_vm_result(obj);\n+}\n+\n+JRT_ENTRY(void, Runtime1::buffer_inline_args(JavaThread* current, Method* method))\n+  NOT_PRODUCT(_buffer_inline_args_slowcase_cnt++;)\n+  buffer_inline_args_impl(current, method, true);\n+JRT_END\n+\n+JRT_ENTRY(void, Runtime1::buffer_inline_args_no_receiver(JavaThread* current, Method* method))\n+  NOT_PRODUCT(_buffer_inline_args_no_receiver_slowcase_cnt++;)\n+  buffer_inline_args_impl(current, method, false);\n+JRT_END\n+\n@@ -706,0 +829,6 @@\n+JRT_ENTRY(void, Runtime1::throw_illegal_monitor_state_exception(JavaThread* current))\n+  NOT_PRODUCT(_throw_illegal_monitor_state_exception_count++;)\n+  ResourceMark rm(current);\n+  SharedRuntime::throw_and_post_jvmti_exception(current, vmSymbols::java_lang_IllegalMonitorStateException());\n+JRT_END\n+\n@@ -908,0 +1037,1 @@\n+    assert(!result.is_inlined(), \"Can not patch access to flattened field\");\n@@ -950,0 +1080,5 @@\n+      case Bytecodes::_defaultvalue:\n+        { Bytecode_defaultvalue bdefaultvalue(caller_method(), caller_method->bcp_from(bci));\n+          k = caller_method->constants()->klass_at(bdefaultvalue.index(), CHECK);\n+        }\n+        break;\n@@ -953,0 +1088,4 @@\n+          if (k->name()->is_Q_array_signature()) {\n+            \/\/ Logically creates elements, ensure klass init\n+            k->initialize(CHECK);\n+          }\n@@ -1462,0 +1601,1 @@\n+  tty->print_cr(\" _new_flat_array_slowcase_cnt:    %d\", _new_flat_array_slowcase_cnt);\n@@ -1464,0 +1604,6 @@\n+  tty->print_cr(\" _load_flattened_array_slowcase_cnt:   %d\", _load_flattened_array_slowcase_cnt);\n+  tty->print_cr(\" _store_flattened_array_slowcase_cnt:  %d\", _store_flattened_array_slowcase_cnt);\n+  tty->print_cr(\" _substitutability_check_slowcase_cnt: %d\", _substitutability_check_slowcase_cnt);\n+  tty->print_cr(\" _buffer_inline_args_slowcase_cnt:%d\", _buffer_inline_args_slowcase_cnt);\n+  tty->print_cr(\" _buffer_inline_args_no_receiver_slowcase_cnt:%d\", _buffer_inline_args_no_receiver_slowcase_cnt);\n+\n@@ -1474,0 +1620,1 @@\n+  tty->print_cr(\" _throw_illegal_monitor_state_exception_count:  %d:\", _throw_illegal_monitor_state_exception_count);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":152,"deletions":5,"binary":false,"changes":157,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+  stub(new_instance_no_inline)       \\\n@@ -54,0 +55,1 @@\n+  stub(new_flat_array)               \\\n@@ -55,0 +57,5 @@\n+  stub(load_flattened_array)         \\\n+  stub(store_flattened_array)        \\\n+  stub(substitutability_check)       \\\n+  stub(buffer_inline_args)           \\\n+  stub(buffer_inline_args_no_receiver)\\\n@@ -61,0 +68,1 @@\n+  stub(throw_illegal_monitor_state_exception)   \\\n@@ -103,0 +111,1 @@\n+  static int _new_flat_array_slowcase_cnt;\n@@ -105,0 +114,5 @@\n+  static int _load_flattened_array_slowcase_cnt;\n+  static int _store_flattened_array_slowcase_cnt;\n+  static int _substitutability_check_slowcase_cnt;\n+  static int _buffer_inline_args_slowcase_cnt;\n+  static int _buffer_inline_args_no_receiver_slowcase_cnt;\n@@ -114,0 +128,1 @@\n+  static int _throw_illegal_monitor_state_exception_count;\n@@ -120,0 +135,1 @@\n+  static void buffer_inline_args_impl(JavaThread* current, Method* m, bool allocate_receiver);\n@@ -137,0 +153,1 @@\n+  static void new_instance_no_inline(JavaThread* current, Klass* klass);\n@@ -139,0 +156,1 @@\n+  static void new_flat_array (JavaThread* current, Klass* klass, jint length);\n@@ -140,0 +158,5 @@\n+  static void load_flattened_array(JavaThread* current, flatArrayOopDesc* array, int index);\n+  static void store_flattened_array(JavaThread* current, flatArrayOopDesc* array, int index, oopDesc* value);\n+  static int  substitutability_check(JavaThread* current, oopDesc* left, oopDesc* right);\n+  static void buffer_inline_args(JavaThread* current, Method* method);\n+  static void buffer_inline_args_no_receiver(JavaThread* current, Method* method);\n@@ -153,0 +176,1 @@\n+  static void throw_illegal_monitor_state_exception(JavaThread* current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.hpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -586,0 +586,2 @@\n+    assert(instr->as_LoadIndexed() == NULL || !instr->as_LoadIndexed()->should_profile(), \"should not be optimized out\");\n+    assert(instr->as_StoreIndexed() == NULL, \"should not be optimized out\");\n","filename":"src\/hotspot\/share\/c1\/c1_ValueMap.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -560,0 +560,3 @@\n+        \/\/ If the array is flattened, a larger part of it is modified than\n+        \/\/ the size of a reference. However, if OFFSET_ANY is given as\n+        \/\/ parameter to set_modified(), size is not taken into account.\n@@ -944,0 +947,1 @@\n+      case Bytecodes::_defaultvalue:\n@@ -946,0 +950,15 @@\n+      case Bytecodes::_withfield: {\n+        bool will_link;\n+        ciField* field = s.get_field(will_link);\n+        BasicType field_type = field->type()->basic_type();\n+        if (field_type == T_OBJECT || field_type == T_ARRAY) {\n+          set_global_escape(state.apop());\n+        } else if (type2size[field_type] == 1) {\n+          state.spop();\n+        } else {\n+          state.lpop();\n+        }\n+        set_method_escape(state.apop());\n+        state.apush(allocated_obj);\n+        break;\n+      }\n","filename":"src\/hotspot\/share\/ci\/bcEscapeAnalyzer.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -462,1 +463,3 @@\n-      (sym->char_at(1) == JVM_SIGNATURE_ARRAY || sym->char_at(1) == JVM_SIGNATURE_CLASS)) {\n+      (sym->char_at(1) == JVM_SIGNATURE_ARRAY ||\n+       sym->char_at(1) == JVM_SIGNATURE_CLASS ||\n+       sym->char_at(1) == JVM_SIGNATURE_INLINE_TYPE )) {\n@@ -475,1 +478,1 @@\n-      return ciObjArrayKlass::make_impl(elem_klass);\n+      return ciArrayKlass::make(elem_klass);\n@@ -501,0 +504,15 @@\n+  int i = 0;\n+  while (sym->char_at(i) == JVM_SIGNATURE_ARRAY) {\n+    i++;\n+  }\n+  if (i > 0 && sym->char_at(i) == JVM_SIGNATURE_INLINE_TYPE) {\n+    \/\/ An unloaded array class of inline types is an ObjArrayKlass, an\n+    \/\/ unloaded inline type class is an InstanceKlass. For consistency,\n+    \/\/ make the signature of the unloaded array of inline type use L\n+    \/\/ rather than Q.\n+    char* new_name = name_buffer(sym->utf8_length()+1);\n+    strncpy(new_name, (char*)sym->base(), sym->utf8_length());\n+    new_name[i] = JVM_SIGNATURE_CLASS;\n+    new_name[sym->utf8_length()] = '\\0';\n+    return get_unloaded_klass(accessing_klass, ciSymbol::make(new_name));\n+  }\n@@ -531,1 +549,1 @@\n-    klass =  ConstantPool::klass_at_if_loaded(cpool, index);\n+    klass = ConstantPool::klass_at_if_loaded(cpool, index);\n@@ -583,0 +601,8 @@\n+\/\/ ------------------------------------------------------------------\n+\/\/ ciEnv::is_inline_klass\n+\/\/\n+\/\/ Check if the klass is an inline klass.\n+bool ciEnv::is_inline_klass(const constantPoolHandle& cpool, int index) {\n+  GUARDED_VM_ENTRY(return cpool->klass_name_at(index)->is_Q_signature();)\n+}\n+\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":29,"deletions":3,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -138,0 +138,2 @@\n+  bool       is_inline_klass(const constantPoolHandle& cpool,\n+                             int klass_index);\n@@ -202,0 +204,4 @@\n+  ciFlatArrayKlass* get_flat_array_klass(Klass* o) {\n+    if (o == NULL) return NULL;\n+    return get_metadata(o)->as_flat_array_klass();\n+  }\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -40,0 +41,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -122,2 +124,3 @@\n-                                 jobject loader, jobject protection_domain)\n-  : ciKlass(name, T_OBJECT)\n+                                 jobject loader, jobject protection_domain,\n+                                 BasicType bt)\n+  : ciKlass(name, bt)\n@@ -129,1 +132,1 @@\n-  _nonstatic_fields = NULL;\n+  _nonstatic_fields = NULL;            \/\/ initialized lazily by compute_nonstatic_fields\n@@ -364,1 +367,1 @@\n-    _flags.print_klass_flags();\n+    _flags.print_klass_flags(st);\n@@ -368,1 +371,1 @@\n-      _super->print_name();\n+      _super->print_name_on(st);\n@@ -464,0 +467,23 @@\n+ciField* ciInstanceKlass::get_non_flattened_field_by_offset(int field_offset) {\n+  if (super() != NULL && super()->has_nonstatic_fields()) {\n+    ciField* f = super()->get_non_flattened_field_by_offset(field_offset);\n+    if (f != NULL) {\n+      return f;\n+    }\n+  }\n+\n+  VM_ENTRY_MARK;\n+  InstanceKlass* k = get_instanceKlass();\n+  Arena* arena = CURRENT_ENV->arena();\n+  for (JavaFieldStream fs(k); !fs.done(); fs.next()) {\n+    if (fs.access_flags().is_static())  continue;\n+    fieldDescriptor& fd = fs.field_descriptor();\n+    if (fd.offset() == field_offset) {\n+      ciField* f = new (arena) ciField(&fd);\n+      return f;\n+    }\n+  }\n+\n+  return NULL;\n+}\n+\n@@ -525,6 +551,1 @@\n-  int flen = fields->length();\n-\n-  \/\/ Now sort them by offset, ascending.\n-  \/\/ (In principle, they could mix with superclass fields.)\n-  fields->sort(sort_field_by_offset);\n-  return flen;\n+  return fields->length();\n@@ -534,3 +555,1 @@\n-GrowableArray<ciField*>*\n-ciInstanceKlass::compute_nonstatic_fields_impl(GrowableArray<ciField*>*\n-                                               super_fields) {\n+GrowableArray<ciField*>* ciInstanceKlass::compute_nonstatic_fields_impl(GrowableArray<ciField*>* super_fields, bool flatten) {\n@@ -554,0 +573,1 @@\n+\n@@ -562,2 +582,22 @@\n-    ciField* field = new (arena) ciField(&fd);\n-    fields->append(field);\n+    if (fd.is_inlined() && flatten) {\n+      \/\/ Inline type fields are embedded\n+      int field_offset = fd.offset();\n+      \/\/ Get InlineKlass and adjust number of fields\n+      Klass* k = get_instanceKlass()->get_inline_type_field_klass(fd.index());\n+      ciInlineKlass* vk = CURRENT_ENV->get_klass(k)->as_inline_klass();\n+      flen += vk->nof_nonstatic_fields() - 1;\n+      \/\/ Iterate over fields of the flattened inline type and copy them to 'this'\n+      for (int i = 0; i < vk->nof_nonstatic_fields(); ++i) {\n+        ciField* flattened_field = vk->nonstatic_field_at(i);\n+        \/\/ Adjust offset to account for missing oop header\n+        int offset = field_offset + (flattened_field->offset() - vk->first_field_offset());\n+        \/\/ A flattened field can be treated as final if the non-flattened\n+        \/\/ field is declared final or the holder klass is an inline type itself.\n+        bool is_final = fd.is_final() || is_inlinetype();\n+        ciField* field = new (arena) ciField(flattened_field, this, offset, is_final);\n+        fields->append(field);\n+      }\n+    } else {\n+      ciField* field = new (arena) ciField(&fd);\n+      fields->append(field);\n+    }\n@@ -566,0 +606,3 @@\n+  \/\/ Now sort them by offset, ascending.\n+  \/\/ (In principle, they could mix with superclass fields.)\n+  fields->sort(sort_field_by_offset);\n@@ -663,0 +706,16 @@\n+bool ciInstanceKlass::can_be_inline_klass(bool is_exact) {\n+  if (!EnableValhalla) {\n+    return false;\n+  }\n+  if (!is_loaded() || is_inlinetype()) {\n+    \/\/ Not loaded or known to be an inline klass\n+    return true;\n+  }\n+  if (!is_exact) {\n+    \/\/ Not exact, check if this is a valid super for an inline klass\n+    VM_ENTRY_MARK;\n+    return !get_instanceKlass()->invalid_inline_super();\n+  }\n+  return false;\n+}\n+\n@@ -681,1 +740,2 @@\n-class StaticFinalFieldPrinter : public FieldClosure {\n+class StaticFieldPrinter : public FieldClosure {\n+protected:\n@@ -683,0 +743,8 @@\n+public:\n+  StaticFieldPrinter(outputStream* out) :\n+    _out(out) {\n+  }\n+  void do_field_helper(fieldDescriptor* fd, oop obj, bool flattened);\n+};\n+\n+class StaticFinalFieldPrinter : public StaticFieldPrinter {\n@@ -686,2 +754,1 @@\n-    _out(out),\n-    _holder(holder) {\n+    StaticFieldPrinter(out), _holder(holder) {\n@@ -692,46 +759,58 @@\n-      oop mirror = fd->field_holder()->java_mirror();\n-      _out->print(\"staticfield %s %s %s \", _holder, fd->name()->as_quoted_ascii(), fd->signature()->as_quoted_ascii());\n-      switch (fd->field_type()) {\n-        case T_BYTE:    _out->print_cr(\"%d\", mirror->byte_field(fd->offset()));   break;\n-        case T_BOOLEAN: _out->print_cr(\"%d\", mirror->bool_field(fd->offset()));   break;\n-        case T_SHORT:   _out->print_cr(\"%d\", mirror->short_field(fd->offset()));  break;\n-        case T_CHAR:    _out->print_cr(\"%d\", mirror->char_field(fd->offset()));   break;\n-        case T_INT:     _out->print_cr(\"%d\", mirror->int_field(fd->offset()));    break;\n-        case T_LONG:    _out->print_cr(INT64_FORMAT, (int64_t)(mirror->long_field(fd->offset())));   break;\n-        case T_FLOAT: {\n-          float f = mirror->float_field(fd->offset());\n-          _out->print_cr(\"%d\", *(int*)&f);\n-          break;\n-        }\n-        case T_DOUBLE: {\n-          double d = mirror->double_field(fd->offset());\n-          _out->print_cr(INT64_FORMAT, *(int64_t*)&d);\n-          break;\n-        }\n-        case T_ARRAY:  \/\/ fall-through\n-        case T_OBJECT: {\n-          oop value =  mirror->obj_field_acquire(fd->offset());\n-          if (value == NULL) {\n-            _out->print_cr(\"null\");\n-          } else if (value->is_instance()) {\n-            assert(fd->field_type() == T_OBJECT, \"\");\n-            if (value->is_a(vmClasses::String_klass())) {\n-              const char* ascii_value = java_lang_String::as_quoted_ascii(value);\n-              _out->print(\"\\\"%s\\\"\", (ascii_value != NULL) ? ascii_value : \"\");\n-            } else {\n-              const char* klass_name  = value->klass()->name()->as_quoted_ascii();\n-              _out->print_cr(\"%s\", klass_name);\n-            }\n-          } else if (value->is_array()) {\n-            typeArrayOop ta = (typeArrayOop)value;\n-            _out->print(\"%d\", ta->length());\n-            if (value->is_objArray()) {\n-              objArrayOop oa = (objArrayOop)value;\n-              const char* klass_name  = value->klass()->name()->as_quoted_ascii();\n-              _out->print(\" %s\", klass_name);\n-            }\n-            _out->cr();\n-          } else {\n-            ShouldNotReachHere();\n-          }\n-          break;\n+      InstanceKlass* holder = fd->field_holder();\n+      oop mirror = holder->java_mirror();\n+      _out->print(\"staticfield %s %s \", _holder, fd->name()->as_quoted_ascii());\n+      BasicType bt = fd->field_type();\n+      if (bt != T_OBJECT && bt != T_ARRAY) {\n+        _out->print(\"%s \", fd->signature()->as_quoted_ascii());\n+      }\n+      do_field_helper(fd, mirror, false);\n+      _out->cr();\n+    }\n+  }\n+};\n+\n+class InlineTypeFieldPrinter : public StaticFieldPrinter {\n+  oop _obj;\n+public:\n+  InlineTypeFieldPrinter(outputStream* out, oop obj) :\n+    StaticFieldPrinter(out), _obj(obj) {\n+  }\n+  void do_field(fieldDescriptor* fd) {\n+    do_field_helper(fd, _obj, true);\n+    _out->print(\" \");\n+  }\n+};\n+\n+void StaticFieldPrinter::do_field_helper(fieldDescriptor* fd, oop mirror, bool flattened) {\n+  BasicType bt = fd->field_type();\n+  switch (bt) {\n+    case T_BYTE:    _out->print(\"%d\", mirror->byte_field(fd->offset()));   break;\n+    case T_BOOLEAN: _out->print(\"%d\", mirror->bool_field(fd->offset()));   break;\n+    case T_SHORT:   _out->print(\"%d\", mirror->short_field(fd->offset()));  break;\n+    case T_CHAR:    _out->print(\"%d\", mirror->char_field(fd->offset()));   break;\n+    case T_INT:     _out->print(\"%d\", mirror->int_field(fd->offset()));    break;\n+    case T_LONG:    _out->print(INT64_FORMAT, (int64_t)(mirror->long_field(fd->offset())));   break;\n+    case T_FLOAT: {\n+      float f = mirror->float_field(fd->offset());\n+      _out->print(\"%d\", *(int*)&f);\n+      break;\n+    }\n+    case T_DOUBLE: {\n+      double d = mirror->double_field(fd->offset());\n+      _out->print(INT64_FORMAT, *(int64_t*)&d);\n+      break;\n+    }\n+    case T_ARRAY:  \/\/ fall-through\n+    case T_OBJECT: {\n+      _out->print(\"%s \", fd->signature()->as_quoted_ascii());\n+      oop value =  mirror->obj_field_acquire(fd->offset());\n+      if (value == NULL) {\n+        _out->print_cr(\"null\");\n+      } else if (value->is_instance()) {\n+        assert(fd->field_type() == T_OBJECT, \"\");\n+        if (value->is_a(vmClasses::String_klass())) {\n+          const char* ascii_value = java_lang_String::as_quoted_ascii(value);\n+          _out->print(\"\\\"%s\\\"\", (ascii_value != NULL) ? ascii_value : \"\");\n+         } else {\n+          const char* klass_name  = value->klass()->name()->as_quoted_ascii();\n+          _out->print(\"%s\", klass_name);\n@@ -739,2 +818,7 @@\n-        default:\n-          ShouldNotReachHere();\n+      } else if (value->is_array()) {\n+        typeArrayOop ta = (typeArrayOop)value;\n+        _out->print(\"%d\", ta->length());\n+        if (value->is_objArray() || value->is_flatArray()) {\n+          objArrayOop oa = (objArrayOop)value;\n+          const char* klass_name  = value->klass()->name()->as_quoted_ascii();\n+          _out->print(\" %s\", klass_name);\n@@ -742,0 +826,4 @@\n+      } else {\n+        ShouldNotReachHere();\n+      }\n+      break;\n@@ -743,0 +831,25 @@\n+    case T_INLINE_TYPE: {\n+      ResetNoHandleMark rnhm;\n+      Thread* THREAD = Thread::current();\n+      SignatureStream ss(fd->signature(), false);\n+      Symbol* name = ss.as_symbol();\n+      assert(!HAS_PENDING_EXCEPTION, \"can resolve klass?\");\n+      InstanceKlass* holder = fd->field_holder();\n+      InstanceKlass* k = SystemDictionary::find_instance_klass(name,\n+                                                               Handle(THREAD, holder->class_loader()),\n+                                                               Handle(THREAD, holder->protection_domain()));\n+      assert(k != NULL && !HAS_PENDING_EXCEPTION, \"can resolve klass?\");\n+      InlineKlass* vk = InlineKlass::cast(k);\n+      oop obj;\n+      if (flattened) {\n+        int field_offset = fd->offset() - vk->first_field_offset();\n+        obj = cast_to_oop(cast_from_oop<address>(mirror) + field_offset);\n+      } else {\n+        obj = mirror->obj_field_acquire(fd->offset());\n+      }\n+      InlineTypeFieldPrinter print_field(_out, obj);\n+      vk->do_nonstatic_fields(&print_field);\n+      break;\n+    }\n+    default:\n+      ShouldNotReachHere();\n@@ -744,1 +857,1 @@\n-};\n+}\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.cpp","additions":181,"deletions":68,"binary":false,"changes":249,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+\n@@ -86,1 +87,1 @@\n-  ciInstanceKlass(ciSymbol* name, jobject loader, jobject protection_domain);\n+  ciInstanceKlass(ciSymbol* name, jobject loader, jobject protection_domain, BasicType bt = T_OBJECT); \/\/ for unloaded klasses\n@@ -110,2 +111,2 @@\n-  int  compute_nonstatic_fields();\n-  GrowableArray<ciField*>* compute_nonstatic_fields_impl(GrowableArray<ciField*>* super_fields);\n+  virtual int compute_nonstatic_fields();\n+  GrowableArray<ciField*>* compute_nonstatic_fields_impl(GrowableArray<ciField*>* super_fields, bool flatten = true);\n@@ -212,0 +213,2 @@\n+  \/\/ get field descriptor at field_offset ignoring flattening\n+  ciField* get_non_flattened_field_by_offset(int field_offset);\n@@ -215,1 +218,1 @@\n-    if (_nonstatic_fields == NULL)\n+    if (_nonstatic_fields == NULL) {\n@@ -217,1 +220,1 @@\n-    else\n+    } else {\n@@ -219,0 +222,1 @@\n+    }\n@@ -266,0 +270,2 @@\n+  virtual bool can_be_inline_klass(bool is_exact = false);\n+\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.hpp","additions":11,"deletions":5,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n@@ -653,0 +654,33 @@\n+bool ciMethod::array_access_profiled_type(int bci, ciKlass*& array_type, ciKlass*& element_type, ProfilePtrKind& element_ptr, bool &flat_array, bool &null_free_array) {\n+  if (method_data() != NULL && method_data()->is_mature()) {\n+    ciProfileData* data = method_data()->bci_to_data(bci);\n+    if (data != NULL && data->is_ArrayLoadStoreData()) {\n+      ciArrayLoadStoreData* array_access = (ciArrayLoadStoreData*)data->as_ArrayLoadStoreData();\n+      array_type = array_access->array()->valid_type();\n+      element_type = array_access->element()->valid_type();\n+      element_ptr = array_access->element()->ptr_kind();\n+      flat_array = array_access->flat_array();\n+      null_free_array = array_access->null_free_array();\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+bool ciMethod::acmp_profiled_type(int bci, ciKlass*& left_type, ciKlass*& right_type, ProfilePtrKind& left_ptr, ProfilePtrKind& right_ptr, bool &left_inline_type, bool &right_inline_type) {\n+  if (method_data() != NULL && method_data()->is_mature()) {\n+    ciProfileData* data = method_data()->bci_to_data(bci);\n+    if (data != NULL && data->is_ACmpData()) {\n+      ciACmpData* acmp = (ciACmpData*)data->as_ACmpData();\n+      left_type = acmp->left()->valid_type();\n+      right_type = acmp->right()->valid_type();\n+      left_ptr = acmp->left()->ptr_kind();\n+      right_ptr = acmp->right()->ptr_kind();\n+      left_inline_type = acmp->left_inline_type();\n+      right_inline_type = acmp->right_inline_type();\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -932,1 +966,1 @@\n-\/\/ ciMethod::is_object_initializer\n+\/\/ ciMethod::is_object_constructor\n@@ -934,2 +968,15 @@\n-bool ciMethod::is_object_initializer() const {\n-   return name() == ciSymbols::object_initializer_name();\n+bool ciMethod::is_object_constructor() const {\n+   return (name() == ciSymbols::object_initializer_name()\n+           && signature()->return_type()->is_void());\n+   \/\/ Note:  We can't test is_static, because that would\n+   \/\/ require the method to be loaded.  Sometimes it isn't.\n+}\n+\n+\/\/ ------------------------------------------------------------------\n+\/\/ ciMethod::is_static_init_factory\n+\/\/\n+bool ciMethod::is_static_init_factory() const {\n+   return (name() == ciSymbols::object_initializer_name()\n+           && !signature()->return_type()->is_void());\n+   \/\/ Note:  We can't test is_static, because that would\n+   \/\/ require the method to be loaded.  Sometimes it isn't.\n@@ -1214,1 +1261,1 @@\n-bool ciMethod::is_initializer () const {         FETCH_FLAG_FROM_VM(is_initializer); }\n+bool ciMethod::is_object_constructor_or_class_initializer() const { FETCH_FLAG_FROM_VM(is_object_constructor_or_class_initializer); }\n@@ -1365,0 +1412,1 @@\n+  if (bt == T_INLINE_TYPE)   return T_OBJECT;\n@@ -1452,0 +1500,13 @@\n+\n+bool ciMethod::has_scalarized_args() const {\n+  VM_ENTRY_MARK;\n+  return get_Method()->has_scalarized_args();\n+}\n+\n+const GrowableArray<SigEntry>* ciMethod::get_sig_cc() {\n+  VM_ENTRY_MARK;\n+  if (get_Method()->adapter() == NULL) {\n+    return NULL;\n+  }\n+  return get_Method()->adapter()->get_sig_cc();\n+}\n","filename":"src\/hotspot\/share\/ci\/ciMethod.cpp","additions":65,"deletions":4,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -304,1 +304,1 @@\n-void ciReturnTypeEntry::translate_type_data_from(const ReturnTypeEntry* ret) {\n+void ciSingleTypeEntry::translate_type_data_from(const SingleTypeEntry* ret) {\n@@ -309,1 +309,1 @@\n-    set_type(ReturnTypeEntry::with_status((Klass*)NULL, k));\n+    set_type(SingleTypeEntry::with_status((Klass*)NULL, k));\n@@ -360,0 +360,4 @@\n+  case DataLayout::array_load_store_data_tag:\n+    return new ciArrayLoadStoreData(data_layout);\n+  case DataLayout::acmp_data_tag:\n+    return new ciACmpData(data_layout);\n@@ -754,0 +758,13 @@\n+      } else if (pdata->is_ArrayLoadStoreData()) {\n+        ciArrayLoadStoreData* array_load_store_data = (ciArrayLoadStoreData*)pdata;\n+        dump_replay_data_type_helper(out, round, count, array_load_store_data, ciArrayLoadStoreData::array_offset(),\n+                                     array_load_store_data->array()->valid_type());\n+        dump_replay_data_type_helper(out, round, count, array_load_store_data, ciArrayLoadStoreData::element_offset(),\n+                                     array_load_store_data->element()->valid_type());\n+      } else if (pdata->is_ACmpData()) {\n+        ciACmpData* acmp_data = (ciACmpData*)pdata;\n+        dump_replay_data_type_helper(out, round, count, acmp_data, ciACmpData::left_offset(),\n+                                     acmp_data->left()->valid_type());\n+        dump_replay_data_type_helper(out, round, count, acmp_data, ciACmpData::right_offset(),\n+                                     acmp_data->right()->valid_type());\n+\n@@ -836,1 +853,1 @@\n-void ciReturnTypeEntry::print_data_on(outputStream* st) const {\n+void ciSingleTypeEntry::print_data_on(outputStream* st) const {\n@@ -909,0 +926,21 @@\n+\n+void ciArrayLoadStoreData::print_data_on(outputStream* st, const char* extra) const {\n+  print_shared(st, \"ciArrayLoadStoreData\", extra);\n+  tab(st, true);\n+  st->print(\"array\");\n+  array()->print_data_on(st);\n+  tab(st, true);\n+  st->print(\"element\");\n+  element()->print_data_on(st);\n+}\n+\n+void ciACmpData::print_data_on(outputStream* st, const char* extra) const {\n+  BranchData::print_data_on(st, extra);\n+  st->cr();\n+  tab(st, true);\n+  st->print(\"left\");\n+  left()->print_data_on(st);\n+  tab(st, true);\n+  st->print(\"right\");\n+  right()->print_data_on(st);\n+}\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.cpp","additions":41,"deletions":3,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -127,1 +127,1 @@\n-class ciReturnTypeEntry : public ReturnTypeEntry, ciTypeEntries {\n+class ciSingleTypeEntry : public SingleTypeEntry, ciTypeEntries {\n@@ -129,1 +129,1 @@\n-  void translate_type_data_from(const ReturnTypeEntry* ret);\n+  void translate_type_data_from(const SingleTypeEntry* ret);\n@@ -149,1 +149,1 @@\n-  ciReturnTypeEntry* ret() const { return (ciReturnTypeEntry*)CallTypeData::ret(); }\n+  ciSingleTypeEntry* ret() const { return (ciSingleTypeEntry*)CallTypeData::ret(); }\n@@ -261,1 +261,1 @@\n-  ciReturnTypeEntry* ret() const { return (ciReturnTypeEntry*)VirtualCallTypeData::ret(); }\n+  ciSingleTypeEntry* ret() const { return (ciSingleTypeEntry*)VirtualCallTypeData::ret(); }\n@@ -365,0 +365,34 @@\n+class ciArrayLoadStoreData : public ArrayLoadStoreData {\n+public:\n+  ciArrayLoadStoreData(DataLayout* layout) : ArrayLoadStoreData(layout) {}\n+\n+  ciSingleTypeEntry* array() const { return (ciSingleTypeEntry*)ArrayLoadStoreData::array(); }\n+  ciSingleTypeEntry* element() const { return (ciSingleTypeEntry*)ArrayLoadStoreData::element(); }\n+\n+  virtual void translate_from(const ProfileData* data) {\n+    array()->translate_type_data_from(data->as_ArrayLoadStoreData()->array());\n+    element()->translate_type_data_from(data->as_ArrayLoadStoreData()->element());\n+  }\n+\n+#ifndef PRODUCT\n+  void print_data_on(outputStream* st, const char* extra = NULL) const;\n+#endif\n+};\n+\n+class ciACmpData : public ACmpData {\n+public:\n+  ciACmpData(DataLayout* layout) : ACmpData(layout) {}\n+\n+  ciSingleTypeEntry* left() const { return (ciSingleTypeEntry*)ACmpData::left(); }\n+  ciSingleTypeEntry* right() const { return (ciSingleTypeEntry*)ACmpData::right(); }\n+\n+  virtual void translate_from(const ProfileData* data) {\n+    left()->translate_type_data_from(data->as_ACmpData()->left());\n+    right()->translate_type_data_from(data->as_ACmpData()->right());\n+  }\n+\n+#ifndef PRODUCT\n+  void print_data_on(outputStream* st, const char* extra = NULL) const;\n+#endif\n+};\n+\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.hpp","additions":38,"deletions":4,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -739,0 +740,1 @@\n+\n@@ -785,26 +787,79 @@\n-  \/\/ staticfield <klass> <name> <signature> <value>\n-  \/\/\n-  \/\/ Initialize a class and fill in the value for a static field.\n-  \/\/ This is useful when the compile was dependent on the value of\n-  \/\/ static fields but it's impossible to properly rerun the static\n-  \/\/ initializer.\n-  void process_staticfield(TRAPS) {\n-    InstanceKlass* k = (InstanceKlass *)parse_klass(CHECK);\n-\n-    if (k == NULL || ReplaySuppressInitializers == 0 ||\n-        (ReplaySuppressInitializers == 2 && k->class_loader() == NULL)) {\n-      return;\n-    }\n-\n-    assert(k->is_initialized(), \"must be\");\n-\n-    const char* field_name = parse_escaped_string();\n-    const char* field_signature = parse_string();\n-    fieldDescriptor fd;\n-    Symbol* name = SymbolTable::new_symbol(field_name);\n-    Symbol* sig = SymbolTable::new_symbol(field_signature);\n-    if (!k->find_local_field(name, sig, &fd) ||\n-        !fd.is_static() ||\n-        fd.has_initial_value()) {\n-      report_error(field_name);\n-      return;\n+  class InlineTypeFieldInitializer : public FieldClosure {\n+    oop _vt;\n+    CompileReplay* _replay;\n+  public:\n+    InlineTypeFieldInitializer(oop vt, CompileReplay* replay)\n+  : _vt(vt), _replay(replay) {}\n+\n+    void do_field(fieldDescriptor* fd) {\n+      BasicType bt = fd->field_type();\n+      const char* string_value = bt != T_INLINE_TYPE ? _replay->parse_escaped_string() : NULL;\n+      switch (bt) {\n+      case T_BYTE: {\n+        int value = atoi(string_value);\n+        _vt->byte_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_BOOLEAN: {\n+        int value = atoi(string_value);\n+        _vt->bool_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_SHORT: {\n+        int value = atoi(string_value);\n+        _vt->short_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_CHAR: {\n+        int value = atoi(string_value);\n+        _vt->char_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_INT: {\n+        int value = atoi(string_value);\n+        _vt->int_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_LONG: {\n+        jlong value;\n+        if (sscanf(string_value, JLONG_FORMAT, &value) != 1) {\n+          fprintf(stderr, \"Error parsing long: %s\\n\", string_value);\n+          break;\n+        }\n+        _vt->long_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_FLOAT: {\n+        float value = atof(string_value);\n+        _vt->float_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_DOUBLE: {\n+        double value = atof(string_value);\n+        _vt->double_field_put(fd->offset(), value);\n+        break;\n+      }\n+      case T_ARRAY:\n+      case T_OBJECT: {\n+        Thread* THREAD = Thread::current();\n+        bool res = _replay->process_staticfield_reference(string_value, _vt, fd, THREAD);\n+        assert(res, \"should succeed for arrays & objects\");\n+        break;\n+      }\n+      case T_INLINE_TYPE: {\n+        InlineKlass* vk = InlineKlass::cast(fd->field_holder()->get_inline_type_field_klass(fd->index()));\n+        if (fd->is_inlined()) {\n+          int field_offset = fd->offset() - vk->first_field_offset();\n+          oop obj = cast_to_oop(cast_from_oop<address>(_vt) + field_offset);\n+          InlineTypeFieldInitializer init_fields(obj, _replay);\n+          vk->do_nonstatic_fields(&init_fields);\n+        } else {\n+          oop value = vk->allocate_instance(Thread::current());\n+          _vt->obj_field_put(fd->offset(), value);\n+        }\n+        break;\n+      }\n+      default: {\n+        fatal(\"Unhandled type: %s\", type2name(bt));\n+      }\n+      }\n@@ -812,0 +867,1 @@\n+  };\n@@ -813,1 +869,1 @@\n-    oop java_mirror = k->java_mirror();\n+  bool process_staticfield_reference(const char* field_signature, oop java_mirror, fieldDescriptor* fd, TRAPS) {\n@@ -820,4 +876,2 @@\n-        ArrayKlass* kelem = (ArrayKlass *)parse_klass(CHECK);\n-        if (kelem == NULL) {\n-          return;\n-        }\n+        Klass* k = resolve_klass(field_signature, CHECK_(true));\n+        ArrayKlass* kelem = (ArrayKlass *)k;\n@@ -833,1 +887,1 @@\n-        value = kelem->multi_allocate(rank, dims, CHECK);\n+        value = kelem->multi_allocate(rank, dims, CHECK_(true));\n@@ -836,1 +890,1 @@\n-          value = oopFactory::new_byteArray(length, CHECK);\n+          value = oopFactory::new_byteArray(length, CHECK_(true));\n@@ -838,1 +892,1 @@\n-          value = oopFactory::new_boolArray(length, CHECK);\n+          value = oopFactory::new_boolArray(length, CHECK_(true));\n@@ -840,1 +894,1 @@\n-          value = oopFactory::new_charArray(length, CHECK);\n+          value = oopFactory::new_charArray(length, CHECK_(true));\n@@ -842,1 +896,1 @@\n-          value = oopFactory::new_shortArray(length, CHECK);\n+          value = oopFactory::new_shortArray(length, CHECK_(true));\n@@ -844,1 +898,1 @@\n-          value = oopFactory::new_floatArray(length, CHECK);\n+          value = oopFactory::new_floatArray(length, CHECK_(true));\n@@ -846,1 +900,1 @@\n-          value = oopFactory::new_doubleArray(length, CHECK);\n+          value = oopFactory::new_doubleArray(length, CHECK_(true));\n@@ -848,1 +902,1 @@\n-          value = oopFactory::new_intArray(length, CHECK);\n+          value = oopFactory::new_intArray(length, CHECK_(true));\n@@ -850,1 +904,1 @@\n-          value = oopFactory::new_longArray(length, CHECK);\n+          value = oopFactory::new_longArray(length, CHECK_(true));\n@@ -853,2 +907,6 @@\n-          Klass* kelem = resolve_klass(field_signature + 1, CHECK);\n-          value = oopFactory::new_objArray(kelem, length, CHECK);\n+          Klass* kelem = resolve_klass(field_signature + 1, CHECK_(true));\n+          value = oopFactory::new_objArray(kelem, length, CHECK_(true));\n+        } else if (field_signature[0] == JVM_SIGNATURE_ARRAY &&\n+                   field_signature[1] == JVM_SIGNATURE_INLINE_TYPE) {\n+          Klass* kelem = resolve_klass(field_signature + 1, CHECK_(true));\n+          value = oopFactory::new_flatArray(kelem, length, CHECK_(true));\n@@ -859,0 +917,86 @@\n+      java_mirror->obj_field_put(fd->offset(), value);\n+      return true;\n+    } else if (strcmp(field_signature, \"Ljava\/lang\/String;\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      Handle value = java_lang_String::create_from_str(string_value, CHECK_(true));\n+      java_mirror->obj_field_put(fd->offset(), value());\n+      return true;\n+    } else if (field_signature[0] == 'L') {\n+      const char* instance = parse_escaped_string();\n+      Klass* k = resolve_klass(instance, CHECK_(true));\n+      oop value = InstanceKlass::cast(k)->allocate_instance(CHECK_(true));\n+      java_mirror->obj_field_put(fd->offset(), value);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  \/\/ Initialize a class and fill in the value for a static field.\n+  \/\/ This is useful when the compile was dependent on the value of\n+  \/\/ static fields but it's impossible to properly rerun the static\n+  \/\/ initializer.\n+  void process_staticfield(TRAPS) {\n+    InstanceKlass* k = (InstanceKlass *)parse_klass(CHECK);\n+\n+    if (k == NULL || ReplaySuppressInitializers == 0 ||\n+        (ReplaySuppressInitializers == 2 && k->class_loader() == NULL)) {\n+      return;\n+    }\n+\n+    assert(k->is_initialized(), \"must be\");\n+\n+    const char* field_name = parse_escaped_string();\n+    const char* field_signature = parse_string();\n+    fieldDescriptor fd;\n+    Symbol* name = SymbolTable::new_symbol(field_name);\n+    Symbol* sig = SymbolTable::new_symbol(field_signature);\n+    if (!k->find_local_field(name, sig, &fd) ||\n+        !fd.is_static() ||\n+        fd.has_initial_value()) {\n+      report_error(field_name);\n+      return;\n+    }\n+\n+    oop java_mirror = k->java_mirror();\n+    if (strcmp(field_signature, \"I\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->int_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"B\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->byte_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"C\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->char_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"S\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->short_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"Z\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      int value = atoi(string_value);\n+      java_mirror->bool_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"J\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      jlong value;\n+      if (sscanf(string_value, JLONG_FORMAT, &value) != 1) {\n+        fprintf(stderr, \"Error parsing long: %s\\n\", string_value);\n+        return;\n+      }\n+      java_mirror->long_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"F\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      float value = atof(string_value);\n+      java_mirror->float_field_put(fd.offset(), value);\n+    } else if (strcmp(field_signature, \"D\") == 0) {\n+      const char* string_value = parse_escaped_string();\n+      double value = atof(string_value);\n+      java_mirror->double_field_put(fd.offset(), value);\n+    } else if (field_signature[0] == JVM_SIGNATURE_INLINE_TYPE) {\n+      Klass* kelem = resolve_klass(field_signature, CHECK);\n+      InlineKlass* vk = InlineKlass::cast(kelem);\n+      oop value = vk->allocate_instance(CHECK);\n+      InlineTypeFieldInitializer init_fields(value, this);\n+      vk->do_nonstatic_fields(&init_fields);\n@@ -861,37 +1005,2 @@\n-      const char* string_value = parse_escaped_string();\n-      if (strcmp(field_signature, \"I\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->int_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"B\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->byte_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"C\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->char_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"S\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->short_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"Z\") == 0) {\n-        int value = atoi(string_value);\n-        java_mirror->bool_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"J\") == 0) {\n-        jlong value;\n-        if (sscanf(string_value, JLONG_FORMAT, &value) != 1) {\n-          fprintf(stderr, \"Error parsing long: %s\\n\", string_value);\n-          return;\n-        }\n-        java_mirror->long_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"F\") == 0) {\n-        float value = atof(string_value);\n-        java_mirror->float_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"D\") == 0) {\n-        double value = atof(string_value);\n-        java_mirror->double_field_put(fd.offset(), value);\n-      } else if (strcmp(field_signature, \"Ljava\/lang\/String;\") == 0) {\n-        Handle value = java_lang_String::create_from_str(string_value, CHECK);\n-        java_mirror->obj_field_put(fd.offset(), value());\n-      } else if (field_signature[0] == JVM_SIGNATURE_CLASS) {\n-        Klass* k = resolve_klass(string_value, CHECK);\n-        oop value = InstanceKlass::cast(k)->allocate_instance(CHECK);\n-        java_mirror->obj_field_put(fd.offset(), value);\n-      } else {\n+      bool res = process_staticfield_reference(field_signature, java_mirror, &fd, CHECK);\n+      if (!res)  {\n","filename":"src\/hotspot\/share\/ci\/ciReplay.cpp","additions":188,"deletions":79,"binary":false,"changes":267,"status":"modified"},{"patch":"@@ -222,0 +222,1 @@\n+  bool is_inline_klass() const;\n","filename":"src\/hotspot\/share\/ci\/ciStreams.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -279,1 +280,1 @@\n-    \/\/ is T.  null_type meet null_type is null_type.\n+    \/\/ is T (except for inline types).  null_type meet null_type is null_type.\n@@ -281,1 +282,4 @@\n-      if (!t2->is_primitive_type() || t2->equals(null_type())) {\n+      if (t2->is_inlinetype()) {\n+        \/\/ Inline types are null-free, return the super type\n+        return t2->as_inline_klass()->super();\n+      } else if (!t2->is_primitive_type() || t2->equals(null_type())) {\n@@ -285,1 +289,4 @@\n-      if (!t1->is_primitive_type()) {\n+      if (t1->is_inlinetype()) {\n+        \/\/ Inline types are null-free, return the super type\n+        return t1->as_inline_klass()->super();\n+      } else if (!t1->is_primitive_type()) {\n@@ -293,35 +300,36 @@\n-  } else {\n-    \/\/ Both types are non-top non-primitive types.  That is,\n-    \/\/ both types are either instanceKlasses or arrayKlasses.\n-    ciKlass* object_klass = analyzer->env()->Object_klass();\n-    ciKlass* k1 = t1->as_klass();\n-    ciKlass* k2 = t2->as_klass();\n-    if (k1->equals(object_klass) || k2->equals(object_klass)) {\n-      return object_klass;\n-    } else if (!k1->is_loaded() || !k2->is_loaded()) {\n-      \/\/ Unloaded classes fall to java.lang.Object at a merge.\n-      return object_klass;\n-    } else if (k1->is_interface() != k2->is_interface()) {\n-      \/\/ When an interface meets a non-interface, we get Object;\n-      \/\/ This is what the verifier does.\n-      return object_klass;\n-    } else if (k1->is_array_klass() || k2->is_array_klass()) {\n-      \/\/ When an array meets a non-array, we get Object.\n-      \/\/ When objArray meets typeArray, we also get Object.\n-      \/\/ And when typeArray meets different typeArray, we again get Object.\n-      \/\/ But when objArray meets objArray, we look carefully at element types.\n-      if (k1->is_obj_array_klass() && k2->is_obj_array_klass()) {\n-        \/\/ Meet the element types, then construct the corresponding array type.\n-        ciKlass* elem1 = k1->as_obj_array_klass()->element_klass();\n-        ciKlass* elem2 = k2->as_obj_array_klass()->element_klass();\n-        ciKlass* elem  = type_meet_internal(elem1, elem2, analyzer)->as_klass();\n-        \/\/ Do an easy shortcut if one type is a super of the other.\n-        if (elem == elem1) {\n-          assert(k1 == ciObjArrayKlass::make(elem), \"shortcut is OK\");\n-          return k1;\n-        } else if (elem == elem2) {\n-          assert(k2 == ciObjArrayKlass::make(elem), \"shortcut is OK\");\n-          return k2;\n-        } else {\n-          return ciObjArrayKlass::make(elem);\n-        }\n+  }\n+\n+  \/\/ Both types are non-top non-primitive types.  That is,\n+  \/\/ both types are either instanceKlasses or arrayKlasses.\n+  ciKlass* object_klass = analyzer->env()->Object_klass();\n+  ciKlass* k1 = t1->as_klass();\n+  ciKlass* k2 = t2->as_klass();\n+  if (k1->equals(object_klass) || k2->equals(object_klass)) {\n+    return object_klass;\n+  } else if (!k1->is_loaded() || !k2->is_loaded()) {\n+    \/\/ Unloaded classes fall to java.lang.Object at a merge.\n+    return object_klass;\n+  } else if (k1->is_interface() != k2->is_interface()) {\n+    \/\/ When an interface meets a non-interface, we get Object;\n+    \/\/ This is what the verifier does.\n+    return object_klass;\n+  } else if (k1->is_array_klass() || k2->is_array_klass()) {\n+    \/\/ When an array meets a non-array, we get Object.\n+    \/\/ When (obj\/flat)Array meets typeArray, we also get Object.\n+    \/\/ And when typeArray meets different typeArray, we again get Object.\n+    \/\/ But when (obj\/flat)Array meets (obj\/flat)Array, we look carefully at element types.\n+    if ((k1->is_obj_array_klass() || k1->is_flat_array_klass()) &&\n+        (k2->is_obj_array_klass() || k2->is_flat_array_klass())) {\n+      ciType* elem1 = k1->as_array_klass()->element_klass();\n+      ciType* elem2 = k2->as_array_klass()->element_klass();\n+      ciType* elem = elem1;\n+      if (elem1 != elem2) {\n+        elem = type_meet_internal(elem1, elem2, analyzer)->as_klass();\n+      }\n+      \/\/ Do an easy shortcut if one type is a super of the other.\n+      if (elem == elem1) {\n+        assert(k1 == ciArrayKlass::make(elem), \"shortcut is OK\");\n+        return k1;\n+      } else if (elem == elem2) {\n+        assert(k2 == ciArrayKlass::make(elem), \"shortcut is OK\");\n+        return k2;\n@@ -329,1 +337,1 @@\n-        return object_klass;\n+        return ciArrayKlass::make(elem);\n@@ -332,4 +340,1 @@\n-      \/\/ Must be two plain old instance klasses.\n-      assert(k1->is_instance_klass(), \"previous cases handle non-instances\");\n-      assert(k2->is_instance_klass(), \"previous cases handle non-instances\");\n-      return k1->least_common_ancestor(k2);\n+      return object_klass;\n@@ -337,0 +342,5 @@\n+  } else {\n+    \/\/ Must be two plain old instance klasses.\n+    assert(k1->is_instance_klass(), \"previous cases handle non-instances\");\n+    assert(k2->is_instance_klass(), \"previous cases handle non-instances\");\n+    return k1->least_common_ancestor(k2);\n@@ -550,2 +560,2 @@\n-\/\/ ciTypeFlow::StateVector::do_aaload\n-void ciTypeFlow::StateVector::do_aaload(ciBytecodeStream* str) {\n+\/\/ ciTypeFlow::StateVector::do_aload\n+void ciTypeFlow::StateVector::do_aload(ciBytecodeStream* str) {\n@@ -553,1 +563,1 @@\n-  ciObjArrayKlass* array_klass = pop_objArray();\n+  ciArrayKlass* array_klass = pop_objOrFlatArray();\n@@ -555,1 +565,1 @@\n-    \/\/ Did aaload on a null reference; push a null and ignore the exception.\n+    \/\/ Did aload on a null reference; push a null and ignore the exception.\n@@ -591,6 +601,13 @@\n-    \/\/ VM's interpreter will not load 'klass' if object is NULL.\n-    \/\/ Type flow after this block may still be needed in two situations:\n-    \/\/ 1) C2 uses do_null_assert() and continues compilation for later blocks\n-    \/\/ 2) C2 does an OSR compile in a later block (see bug 4778368).\n-    pop_object();\n-    do_null_assert(klass);\n+    if (str->is_inline_klass()) {\n+      trap(str, klass,\n+           Deoptimization::make_trap_request\n+           (Deoptimization::Reason_unloaded,\n+            Deoptimization::Action_reinterpret));\n+    } else {\n+      \/\/ VM's interpreter will not load 'klass' if object is NULL.\n+      \/\/ Type flow after this block may still be needed in two situations:\n+      \/\/ 1) C2 uses do_null_assert() and continues compilation for later blocks\n+      \/\/ 2) C2 does an OSR compile in a later block (see bug 4778368).\n+      pop_object();\n+      do_null_assert(klass);\n+    }\n@@ -770,1 +787,13 @@\n-  if (!will_link || str->is_unresolved_klass()) {\n+  if (!will_link || str->is_unresolved_klass() || klass->is_inlinetype()) {\n+    trap(str, klass, str->get_klass_index());\n+  } else {\n+    push_object(klass);\n+  }\n+}\n+\n+\/\/ ------------------------------------------------------------------\n+\/\/ ciTypeFlow::StateVector::do_defaultvalue\n+void ciTypeFlow::StateVector::do_defaultvalue(ciBytecodeStream* str) {\n+  bool will_link;\n+  ciKlass* klass = str->get_klass(will_link);\n+  if (!will_link || str->is_unresolved_klass() || !klass->is_inlinetype()) {\n@@ -777,0 +806,22 @@\n+\/\/ ------------------------------------------------------------------\n+\/\/ ciTypeFlow::StateVector::do_withfield\n+void ciTypeFlow::StateVector::do_withfield(ciBytecodeStream* str) {\n+  bool will_link;\n+  ciField* field = str->get_field(will_link);\n+  ciKlass* klass = field->holder();\n+  if (!will_link) {\n+    trap(str, klass, str->get_field_holder_index());\n+  } else {\n+    ciType* type = pop_value();\n+    ciType* field_type = field->type();\n+    if (field_type->is_two_word()) {\n+      ciType* type2 = pop_value();\n+      assert(type2->is_two_word(), \"must be 2nd half\");\n+      assert(type == half_type(type2), \"must be 2nd half\");\n+    }\n+    pop_object();\n+    assert(klass->is_inlinetype(), \"should be inline type\");\n+    push_object(klass);\n+  }\n+}\n+\n@@ -882,1 +933,1 @@\n-  case Bytecodes::_aaload: do_aaload(str);                       break;\n+  case Bytecodes::_aaload: do_aload(str);                           break;\n@@ -888,1 +939,1 @@\n-      pop_objArray();\n+      pop_objOrFlatArray();\n@@ -910,1 +961,1 @@\n-        push_object(ciObjArrayKlass::make(element_klass));\n+        push_object(ciArrayKlass::make(element_klass));\n@@ -1442,0 +1493,3 @@\n+  case Bytecodes::_defaultvalue: do_defaultvalue(str);              break;\n+  case Bytecodes::_withfield: do_withfield(str);                    break;\n+\n@@ -1469,0 +1523,1 @@\n+\n@@ -1751,3 +1806,6 @@\n-      case Bytecodes::_athrow:     case Bytecodes::_ireturn:\n-      case Bytecodes::_lreturn:    case Bytecodes::_freturn:\n-      case Bytecodes::_dreturn:    case Bytecodes::_areturn:\n+      case Bytecodes::_athrow:\n+      case Bytecodes::_ireturn:\n+      case Bytecodes::_lreturn:\n+      case Bytecodes::_freturn:\n+      case Bytecodes::_dreturn:\n+      case Bytecodes::_areturn:\n","filename":"src\/hotspot\/share\/ci\/ciTypeFlow.cpp","additions":118,"deletions":60,"binary":false,"changes":178,"status":"modified"},{"patch":"@@ -24,0 +24,1 @@\n+\n@@ -53,0 +54,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -86,0 +88,1 @@\n+#include \"utilities\/stringUtils.hpp\"\n@@ -141,0 +144,2 @@\n+#define CONSTANT_CLASS_DESCRIPTORS        61\n+\n@@ -180,1 +185,1 @@\n-      case JVM_CONSTANT_Class : {\n+      case JVM_CONSTANT_Class: {\n@@ -513,1 +518,8 @@\n-        cp->unresolved_klass_at_put(index, class_index, num_klasses++);\n+\n+        Symbol* const name = cp->symbol_at(class_index);\n+        const unsigned int name_len = name->utf8_length();\n+        if (name->is_Q_signature()) {\n+          cp->unresolved_qdescriptor_at_put(index, class_index, num_klasses++);\n+        } else {\n+          cp->unresolved_klass_at_put(index, class_index, num_klasses++);\n+        }\n@@ -769,2 +781,2 @@\n-            if (ref_kind == JVM_REF_newInvokeSpecial) {\n-              if (name != vmSymbols::object_initializer_name()) {\n+            if (name != vmSymbols::object_initializer_name()) {\n+              if (ref_kind == JVM_REF_newInvokeSpecial) {\n@@ -777,1 +789,12 @@\n-              if (name == vmSymbols::object_initializer_name()) {\n+              \/\/ The allowed invocation mode of <init> depends on its signature.\n+              \/\/ This test corresponds to verify_invoke_instructions in the verifier.\n+              const int signature_ref_index =\n+                cp->signature_ref_index_at(name_and_type_ref_index);\n+              const Symbol* const signature = cp->symbol_at(signature_ref_index);\n+              if (signature->is_void_method_signature()\n+                  && ref_kind == JVM_REF_newInvokeSpecial) {\n+                \/\/ OK, could be a constructor call\n+              } else if (!signature->is_void_method_signature()\n+                         && ref_kind == JVM_REF_invokeStatic) {\n+                \/\/ also OK, could be a static factory call\n+              } else {\n@@ -937,3 +960,3 @@\n-void ClassFileParser::parse_interfaces(const ClassFileStream* const stream,\n-                                       const int itfs_len,\n-                                       ConstantPool* const cp,\n+void ClassFileParser::parse_interfaces(const ClassFileStream* stream,\n+                                       int itfs_len,\n+                                       ConstantPool* cp,\n@@ -941,0 +964,7 @@\n+                                       \/\/ FIXME: lots of these functions\n+                                       \/\/ declare their parameters as const,\n+                                       \/\/ which adds only noise to the code.\n+                                       \/\/ Remove the spurious const modifiers.\n+                                       \/\/ Many are of the form \"const int x\"\n+                                       \/\/ or \"T* const x\".\n+                                       bool* const is_declared_atomic,\n@@ -947,1 +977,1 @@\n-    _local_interfaces = Universe::the_empty_instance_klass_array();\n+    _temp_local_interfaces = new GrowableArray<InstanceKlass*>(0);\n@@ -950,3 +980,2 @@\n-    _local_interfaces = MetadataFactory::new_array<InstanceKlass*>(_loader_data, itfs_len, NULL, CHECK);\n-\n-    int index;\n+    _temp_local_interfaces = new GrowableArray<InstanceKlass*>(itfs_len);\n+    int index = 0;\n@@ -988,1 +1017,14 @@\n-      if (InstanceKlass::cast(interf)->has_nonstatic_concrete_methods()) {\n+      InstanceKlass* ik = InstanceKlass::cast(interf);\n+      if (is_inline_type() && ik->invalid_inline_super()) {\n+        ResourceMark rm(THREAD);\n+        Exceptions::fthrow(\n+          THREAD_AND_LOCATION,\n+          vmSymbols::java_lang_IncompatibleClassChangeError(),\n+          \"Inline type %s attempts to implement interface java.lang.IdentityObject\",\n+          _class_name->as_klass_external_name());\n+        return;\n+      }\n+      if (ik->invalid_inline_super()) {\n+        set_invalid_inline_super();\n+      }\n+      if (ik->has_nonstatic_concrete_methods()) {\n@@ -991,1 +1033,12 @@\n-      _local_interfaces->at_put(index, InstanceKlass::cast(interf));\n+      if (ik->is_declared_atomic()) {\n+        *is_declared_atomic = true;\n+      }\n+      if (ik->name() == vmSymbols::java_lang_IdentityObject()) {\n+        _implements_identityObject = true;\n+      }\n+      if (ik->name() == vmSymbols::java_lang_PrimitiveObject()) {\n+        \/\/ further checks for \"is_invalid_super_for_inline_type()\" needed later\n+        \/\/ needs field parsing, delay unitl post_process_parse_stream()\n+        _implements_primitiveObject = true;\n+      }\n+      _temp_local_interfaces->append(ik);\n@@ -1009,1 +1062,1 @@\n-        const InstanceKlass* const k = _local_interfaces->at(index);\n+        const InstanceKlass* const k = _temp_local_interfaces->at(index);\n@@ -1494,0 +1547,1 @@\n+  STATIC_INLINE,        \/\/ inline type field\n@@ -1499,0 +1553,1 @@\n+  NONSTATIC_INLINE,\n@@ -1518,6 +1573,7 @@\n-  BAD_ALLOCATION_TYPE, \/\/ T_VOID        = 14,\n-  BAD_ALLOCATION_TYPE, \/\/ T_ADDRESS     = 15,\n-  BAD_ALLOCATION_TYPE, \/\/ T_NARROWOOP   = 16,\n-  BAD_ALLOCATION_TYPE, \/\/ T_METADATA    = 17,\n-  BAD_ALLOCATION_TYPE, \/\/ T_NARROWKLASS = 18,\n-  BAD_ALLOCATION_TYPE, \/\/ T_CONFLICT    = 19,\n+  NONSTATIC_OOP,       \/\/ T_INLINE_TYPE = 14,\n+  BAD_ALLOCATION_TYPE, \/\/ T_VOID        = 15,\n+  BAD_ALLOCATION_TYPE, \/\/ T_ADDRESS     = 16,\n+  BAD_ALLOCATION_TYPE, \/\/ T_NARROWOOP   = 17,\n+  BAD_ALLOCATION_TYPE, \/\/ T_METADATA    = 18,\n+  BAD_ALLOCATION_TYPE, \/\/ T_NARROWKLASS = 19,\n+  BAD_ALLOCATION_TYPE, \/\/ T_CONFLICT    = 20,\n@@ -1538,6 +1594,7 @@\n-  BAD_ALLOCATION_TYPE, \/\/ T_VOID        = 14,\n-  BAD_ALLOCATION_TYPE, \/\/ T_ADDRESS     = 15,\n-  BAD_ALLOCATION_TYPE, \/\/ T_NARROWOOP   = 16,\n-  BAD_ALLOCATION_TYPE, \/\/ T_METADATA    = 17,\n-  BAD_ALLOCATION_TYPE, \/\/ T_NARROWKLASS = 18,\n-  BAD_ALLOCATION_TYPE, \/\/ T_CONFLICT    = 19,\n+  STATIC_OOP,          \/\/ T_INLINE_TYPE = 14,\n+  BAD_ALLOCATION_TYPE, \/\/ T_VOID        = 15,\n+  BAD_ALLOCATION_TYPE, \/\/ T_ADDRESS     = 16,\n+  BAD_ALLOCATION_TYPE, \/\/ T_NARROWOOP   = 17,\n+  BAD_ALLOCATION_TYPE, \/\/ T_METADATA    = 18,\n+  BAD_ALLOCATION_TYPE, \/\/ T_NARROWKLASS = 19,\n+  BAD_ALLOCATION_TYPE, \/\/ T_CONFLICT    = 20\n@@ -1546,1 +1603,1 @@\n-static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type) {\n+static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_inline_type) {\n@@ -1550,0 +1607,3 @@\n+  if (is_inline_type) {\n+    result = is_static ? STATIC_INLINE : NONSTATIC_INLINE;\n+  }\n@@ -1563,2 +1623,2 @@\n-  void update(bool is_static, BasicType type) {\n-    FieldAllocationType atype = basic_type_to_atype(is_static, type);\n+  void update(bool is_static, BasicType type, bool is_inline_type) {\n+    FieldAllocationType atype = basic_type_to_atype(is_static, type, is_inline_type);\n@@ -1577,0 +1637,1 @@\n+                                   bool is_inline_type,\n@@ -1599,1 +1660,5 @@\n-  const int total_fields = length + num_injected;\n+\n+  \/\/ two more slots are required for inline classes:\n+  \/\/ one for the static field with a reference to the pre-allocated default value\n+  \/\/ one for the field the JVM injects when detecting an empty inline class\n+  const int total_fields = length + num_injected + (is_inline_type ? 2 : 0);\n@@ -1629,0 +1694,1 @@\n+  int instance_fields_count = 0;\n@@ -1633,0 +1699,4 @@\n+    jint recognized_modifiers = JVM_RECOGNIZED_FIELD_MODIFIERS;\n+\n+    const jint flags = cfs->get_u2_fast() & recognized_modifiers;\n+    verify_legal_field_modifiers(flags, is_interface, is_inline_type, CHECK);\n@@ -1634,2 +1704,0 @@\n-    const jint flags = cfs->get_u2_fast() & JVM_RECOGNIZED_FIELD_MODIFIERS;\n-    verify_legal_field_modifiers(flags, is_interface, CHECK);\n@@ -1651,0 +1719,1 @@\n+    if (!access_flags.is_static()) instance_fields_count++;\n@@ -1710,1 +1779,1 @@\n-    fac->update(is_static, type);\n+    fac->update(is_static, type, type == T_INLINE_TYPE);\n@@ -1754,1 +1823,1 @@\n-      fac->update(false, type);\n+      fac->update(false, type, false);\n@@ -1759,0 +1828,27 @@\n+  if (is_inline_type) {\n+    FieldInfo* const field = FieldInfo::from_field_array(fa, index);\n+    field->initialize(JVM_ACC_FIELD_INTERNAL | JVM_ACC_STATIC,\n+                      (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(default_value_name)),\n+                      (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(object_signature)),\n+                      0);\n+    const BasicType type = Signature::basic_type(vmSymbols::object_signature());\n+    fac->update(true, type, false);\n+    index++;\n+  }\n+\n+  if (is_inline_type && instance_fields_count == 0) {\n+    _is_empty_inline_type = true;\n+    FieldInfo* const field = FieldInfo::from_field_array(fa, index);\n+    field->initialize(JVM_ACC_FIELD_INTERNAL,\n+        (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(empty_marker_name)),\n+        (u2)vmSymbols::as_int(VM_SYMBOL_ENUM_NAME(byte_signature)),\n+        0);\n+    const BasicType type = Signature::basic_type(vmSymbols::byte_signature());\n+    fac->update(false, type, false);\n+    index++;\n+  }\n+\n+  if (instance_fields_count > 0) {\n+    _has_nonstatic_fields = true;\n+  }\n+\n@@ -2076,0 +2172,5 @@\n+  const char* class_note = \"\";\n+  if (is_inline_type() && name == vmSymbols::object_initializer_name()) {\n+    class_note = \" (an inline class)\";\n+  }\n+\n@@ -2079,2 +2180,2 @@\n-      \"%s \\\"%s\\\" in class %s has illegal signature \\\"%s\\\"\", type,\n-      name->as_C_string(), _class_name->as_C_string(), sig->as_C_string());\n+      \"%s \\\"%s\\\" in class %s%s has illegal signature \\\"%s\\\"\", type,\n+      name->as_C_string(), _class_name->as_C_string(), class_note, sig->as_C_string());\n@@ -2369,0 +2470,1 @@\n+                                      bool is_inline_type,\n@@ -2410,1 +2512,1 @@\n-    verify_legal_method_modifiers(flags, is_interface, name, CHECK_NULL);\n+    verify_legal_method_modifiers(flags, is_interface, is_inline_type, name, CHECK_NULL);\n@@ -2413,3 +2515,48 @@\n-  if (name == vmSymbols::object_initializer_name() && is_interface) {\n-    classfile_parse_error(\"Interface cannot have a method named <init>, class file %s\", THREAD);\n-    return NULL;\n+  if (name == vmSymbols::object_initializer_name()) {\n+    if (is_interface) {\n+      classfile_parse_error(\"Interface cannot have a method named <init>, class file %s\", THREAD);\n+      return NULL;\n+    } else if (!is_inline_type && signature->is_void_method_signature()) {\n+      \/\/ OK, a constructor\n+    } else if (is_inline_type && !signature->is_void_method_signature()) {\n+      \/\/ also OK, a static factory, as long as the return value is good\n+      bool ok = false;\n+      SignatureStream ss((Symbol*) signature, true);\n+      while (!ss.at_return_type())  ss.next();\n+      if (ss.is_reference()) {\n+        Symbol* ret = ss.as_symbol();\n+        const Symbol* required = class_name();\n+        if (is_hidden()) {\n+          \/\/ The original class name in hidden classes gets changed.  So using\n+          \/\/ the original name in the return type is no longer valid.\n+          \/\/ Note that expecting the return type for inline hidden class factory\n+          \/\/ methods to be java.lang.Object works around a JVM Spec issue for\n+          \/\/ hidden classes.\n+          required = vmSymbols::java_lang_Object();\n+        }\n+        ok = (ret == required);\n+      }\n+      if (!ok) {\n+        throwIllegalSignature(\"Method\", name, signature, CHECK_0);\n+      }\n+    } else {\n+      \/\/ not OK, so throw the same error as in verify_legal_method_signature.\n+      throwIllegalSignature(\"Method\", name, signature, CHECK_0);\n+    }\n+    \/\/ A declared <init> method must always be either a non-static\n+    \/\/ object constructor, with a void return, or else it must be a\n+    \/\/ static factory method, with a non-void return.  No other\n+    \/\/ definition of <init> is possible.\n+    \/\/\n+    \/\/ The verifier (in verify_invoke_instructions) will inspect the\n+    \/\/ signature of any attempt to invoke <init>, and ensures that it\n+    \/\/ returns non-void if and only if it is being invoked by\n+    \/\/ invokestatic, and void if and only if it is being invoked by\n+    \/\/ invokespecial.\n+    \/\/\n+    \/\/ When a symbolic reference to <init> is resolved for a\n+    \/\/ particular invocation mode (special or static), the mode is\n+    \/\/ matched to the JVM_ACC_STATIC modifier of the <init> method.\n+    \/\/ Thus, it is impossible to statically invoke a constructor, and\n+    \/\/ impossible to \"new + invokespecial\" a static factory, either\n+    \/\/ through bytecode or through reflection.\n@@ -2982,0 +3129,1 @@\n+                                    bool is_inline_type,\n@@ -3006,0 +3154,1 @@\n+                                    is_inline_type,\n@@ -3273,2 +3422,2 @@\n-    \/\/ Access flags\n-    jint flags;\n+\n+    jint recognized_modifiers = RECOGNIZED_INNER_CLASS_MODIFIERS;\n@@ -3277,3 +3426,1 @@\n-      flags = cfs->get_u2_fast() & (RECOGNIZED_INNER_CLASS_MODIFIERS | JVM_ACC_MODULE);\n-    } else {\n-      flags = cfs->get_u2_fast() & RECOGNIZED_INNER_CLASS_MODIFIERS;\n+      recognized_modifiers |= JVM_ACC_MODULE;\n@@ -3281,0 +3428,8 @@\n+    \/\/ JVM_ACC_INLINE is defined for class file version 55 and later\n+    if (supports_inline_types()) {\n+      recognized_modifiers |= JVM_ACC_INLINE;\n+    }\n+\n+    \/\/ Access flags\n+    jint flags = cfs->get_u2_fast() & recognized_modifiers;\n+\n@@ -3661,3 +3816,2 @@\n-  return _major_version == JVM_CLASSFILE_MAJOR_VERSION &&\n-         _minor_version == JAVA_PREVIEW_MINOR_VERSION &&\n-         Arguments::enable_preview();\n+  \/\/ temporarily disable the sealed type preview feature check\n+  return _major_version == JVM_CLASSFILE_MAJOR_VERSION;\n@@ -4131,1 +4285,2 @@\n-    check_property(_class_name == vmSymbols::java_lang_Object(),\n+    check_property(_class_name == vmSymbols::java_lang_Object()\n+                   || (_access_flags.get_flags() & JVM_ACC_INLINE),\n@@ -4274,0 +4429,19 @@\n+void ClassFileParser::throwInlineTypeLimitation(THREAD_AND_LOCATION_DECL,\n+                                                const char* msg,\n+                                                const Symbol* name,\n+                                                const Symbol* sig) const {\n+\n+  ResourceMark rm(THREAD);\n+  if (name == NULL || sig == NULL) {\n+    Exceptions::fthrow(THREAD_AND_LOCATION_ARGS,\n+        vmSymbols::java_lang_ClassFormatError(),\n+        \"class: %s - %s\", _class_name->as_C_string(), msg);\n+  }\n+  else {\n+    Exceptions::fthrow(THREAD_AND_LOCATION_ARGS,\n+        vmSymbols::java_lang_ClassFormatError(),\n+        \"\\\"%s\\\" sig: \\\"%s\\\" class: %s - %s\", name->as_C_string(), sig->as_C_string(),\n+        _class_name->as_C_string(), msg);\n+  }\n+}\n+\n@@ -4307,0 +4481,5 @@\n+      if (ik->is_inline_klass()) {\n+        Thread *THREAD = Thread::current();\n+        throwInlineTypeLimitation(THREAD_AND_LOCATION, \"Inline Types do not support Cloneable\");\n+        return;\n+      }\n@@ -4347,0 +4526,5 @@\n+bool ClassFileParser::supports_inline_types() const {\n+  \/\/ Inline types are only supported by class file version 55 and later\n+  return _major_version >= JAVA_11_VERSION;\n+}\n+\n@@ -4390,3 +4574,4 @@\n-  } else if (max_transitive_size == local_size) {\n-    \/\/ only local interfaces added, share local interface array\n-    return local_ifs;\n+    \/\/ The three lines below are commented to work around bug JDK-8245487\n+\/\/  } else if (max_transitive_size == local_size) {\n+\/\/    \/\/ only local interfaces added, share local interface array\n+\/\/    return local_ifs;\n@@ -4413,0 +4598,8 @@\n+\n+    if (length == 1 && result->at(0) == vmClasses::IdentityObject_klass()) {\n+      return Universe::the_single_IdentityObject_klass_array();\n+    }\n+    if (length == 1 && result->at(0) == vmClasses::PrimitiveObject_klass()) {\n+      return Universe::the_single_PrimitiveObject_klass_array();\n+    }\n+\n@@ -4626,0 +4819,1 @@\n+  const bool is_inline_type = (flags & JVM_ACC_INLINE) != 0;\n@@ -4627,0 +4821,1 @@\n+  assert(supports_inline_types() || !is_inline_type, \"JVM_ACC_INLINE should not be set\");\n@@ -4637,0 +4832,11 @@\n+  if (is_inline_type && !EnableValhalla) {\n+    ResourceMark rm(THREAD);\n+    Exceptions::fthrow(\n+      THREAD_AND_LOCATION,\n+      vmSymbols::java_lang_ClassFormatError(),\n+      \"Class modifier ACC_INLINE in class %s requires option -XX:+EnableValhalla\",\n+      _class_name->as_C_string()\n+    );\n+    return;\n+  }\n+\n@@ -4651,1 +4857,2 @@\n-      (!is_interface && major_gte_1_5 && is_annotation)) {\n+      (!is_interface && major_gte_1_5 && is_annotation) ||\n+      (is_inline_type && (is_interface || is_abstract || is_enum || !is_final))) {\n@@ -4653,0 +4860,2 @@\n+    const char* class_note = \"\";\n+    if (is_inline_type)  class_note = \" (an inline class)\";\n@@ -4656,2 +4865,2 @@\n-      \"Illegal class modifiers in class %s: 0x%X\",\n-      _class_name->as_C_string(), flags\n+      \"Illegal class modifiers in class %s%s: 0x%X\",\n+      _class_name->as_C_string(), class_note, flags\n@@ -4727,0 +4936,1 @@\n+                                                   bool is_inline_type,\n@@ -4751,0 +4961,4 @@\n+    } else {\n+      if (is_inline_type && !is_static && !is_final) {\n+        is_illegal = true;\n+      }\n@@ -4767,0 +4981,1 @@\n+                                                    bool is_inline_type,\n@@ -4787,0 +5002,1 @@\n+  const char* class_note = \"\";\n@@ -4821,1 +5037,1 @@\n-        if (is_static || is_final || is_synchronized || is_native ||\n+        if (is_final || is_synchronized || is_native ||\n@@ -4825,0 +5041,9 @@\n+        if (!is_static && !is_inline_type) {\n+          \/\/ OK, an object constructor in a regular class\n+        } else if (is_static && is_inline_type) {\n+          \/\/ OK, a static init factory in an inline class\n+        } else {\n+          \/\/ but no other combinations are allowed\n+          is_illegal = true;\n+          class_note = (is_inline_type ? \" (an inline class)\" : \" (not an inline class)\");\n+        }\n@@ -4826,4 +5051,9 @@\n-        if (is_abstract) {\n-          if ((is_final || is_native || is_private || is_static ||\n-              (major_gte_1_5 && (is_synchronized || is_strict)))) {\n-            is_illegal = true;\n+        if (is_inline_type && is_synchronized && !is_static) {\n+          is_illegal = true;\n+          class_note = \" (an inline class)\";\n+        } else {\n+          if (is_abstract) {\n+            if ((is_final || is_native || is_private || is_static ||\n+                (major_gte_1_5 && (is_synchronized || is_strict)))) {\n+              is_illegal = true;\n+            }\n@@ -4841,2 +5071,2 @@\n-      \"Method %s in class %s has illegal modifiers: 0x%X\",\n-      name->as_C_string(), _class_name->as_C_string(), flags);\n+      \"Method %s in class %s%s has illegal modifiers: 0x%X\",\n+      name->as_C_string(), _class_name->as_C_string(), class_note, flags);\n@@ -5000,1 +5230,10 @@\n-    case JVM_SIGNATURE_CLASS: {\n+    case JVM_SIGNATURE_INLINE_TYPE:\n+      \/\/ Can't enable this check until JDK upgrades the bytecode generators\n+      \/\/ if (_major_version < CONSTANT_CLASS_DESCRIPTORS ) {\n+      \/\/   classfile_parse_error(\"Class name contains illegal Q-signature \"\n+      \/\/                                    \"in descriptor in class file %s\",\n+      \/\/                                    CHECK_0);\n+      \/\/ }\n+      \/\/ fall through\n+    case JVM_SIGNATURE_CLASS:\n+    {\n@@ -5011,1 +5250,1 @@\n-        \/\/ Skip leading 'L' and ignore first appearance of ';'\n+        \/\/ Skip leading 'L' or 'Q' and ignore first appearance of ';'\n@@ -5067,0 +5306,3 @@\n+    } else if (_major_version >= CONSTANT_CLASS_DESCRIPTORS && bytes[length - 1] == ';' ) {\n+      \/\/ Support for L...; and Q...; descriptors\n+      legal = verify_unqualified_name(bytes + 1, length - 2, LegalClass);\n@@ -5164,0 +5406,3 @@\n+  if (!supports_inline_types() && (signature->is_Q_signature() || signature->is_Q_array_signature())) {\n+    throwIllegalSignature(\"Field\", name, signature, CHECK);\n+  }\n@@ -5216,1 +5461,1 @@\n-        \/\/ All internal methods must return void\n+        \/\/ All constructor methods must return void\n@@ -5220,0 +5465,16 @@\n+        \/\/ All static init methods must return the current class\n+        if ((length >= 3) && (p[length-1] == JVM_SIGNATURE_ENDCLASS)\n+            && name == vmSymbols::object_initializer_name()) {\n+          nextp = skip_over_field_signature(p, true, length, CHECK_0);\n+          if (nextp && ((int)length == (nextp - p))) {\n+            \/\/ The actual class will be checked against current class\n+            \/\/ when the method is defined (see parse_method).\n+            \/\/ A reference to a static init with a bad return type\n+            \/\/ will load and verify OK, but will fail to link.\n+            return args_size;\n+          }\n+        }\n+        \/\/ The distinction between static factory methods and\n+        \/\/ constructors depends on the JVM_ACC_STATIC modifier.\n+        \/\/ This distinction must be reflected in a void or non-void\n+        \/\/ return. For declared methods, the check is in parse_method.\n@@ -5376,0 +5637,6 @@\n+  if (ik->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(ik);\n+    oop val = ik->allocate_instance(CHECK_NULL);\n+    vk->set_default_value(val);\n+  }\n+\n@@ -5379,0 +5646,34 @@\n+\/\/ Return true if the specified class is not a valid super class for an inline type.\n+\/\/ A valid super class for an inline type is abstract, has no instance fields,\n+\/\/ does not implement interface java.lang.IdentityObject (checked elsewhere), has\n+\/\/ an empty body-less no-arg constructor, and no synchronized instance methods.\n+\/\/ This function doesn't check if the class's super types are invalid.  Those checks\n+\/\/ are done elsewhere.  The final determination of whether or not a class is an\n+\/\/ invalid super type for an inline class is done in fill_instance_klass().\n+bool ClassFileParser::is_invalid_super_for_inline_type() {\n+  if (class_name() == vmSymbols::java_lang_IdentityObject()) {\n+    return true;\n+  }\n+  if (is_interface() || class_name() == vmSymbols::java_lang_Object()) {\n+    return false;\n+  }\n+  if (!access_flags().is_abstract() || _has_nonstatic_fields) {\n+    return true;\n+  } else {\n+    \/\/ Look at each method\n+    for (int x = 0; x < _methods->length(); x++) {\n+      const Method* const method = _methods->at(x);\n+      if (method->is_synchronized() && !method->is_static()) {\n+        return true;\n+\n+      } else if (method->name() == vmSymbols::object_initializer_name()) {\n+        if (method->signature() != vmSymbols::void_method_signature() ||\n+            !method->is_vanilla_constructor()) {\n+          return true;\n+        }\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -5411,0 +5712,15 @@\n+  if (_field_info->_is_naturally_atomic && ik->is_inline_klass()) {\n+    ik->set_is_naturally_atomic();\n+  }\n+\n+  if (this->_invalid_inline_super) {\n+    ik->set_invalid_inline_super();\n+  }\n+\n+  if (_has_injected_identityObject) {\n+    ik->set_has_injected_identityObject();\n+  }\n+  if (_has_injected_primitiveObject) {\n+    ik->set_has_injected_primitiveObject();\n+  }\n+\n@@ -5412,1 +5728,1 @@\n-  ik->set_static_oop_field_count(_fac->count[STATIC_OOP]);\n+  ik->set_static_oop_field_count(_fac->count[STATIC_OOP] + _fac->count[STATIC_INLINE]);\n@@ -5462,0 +5778,3 @@\n+  if (_is_declared_atomic) {\n+    ik->set_is_declared_atomic();\n+  }\n@@ -5573,0 +5892,37 @@\n+  bool all_fields_empty = true;\n+  int nfields = ik->java_fields_count();\n+  if (ik->is_inline_klass()) nfields++;\n+  for (int i = 0; i < nfields; i++) {\n+    if (((ik->field_access_flags(i) & JVM_ACC_STATIC) == 0)) {\n+      if (ik->field_is_inline_type(i)) {\n+        Symbol* klass_name = ik->field_signature(i)->fundamental_name(CHECK);\n+        \/\/ Inline classes for instance fields must have been pre-loaded\n+        \/\/ Inline classes for static fields might not have been loaded yet\n+        InstanceKlass* klass = SystemDictionary::find_instance_klass(klass_name,\n+            Handle(THREAD, ik->class_loader()),\n+            Handle(THREAD, ik->protection_domain()));\n+        assert(klass != NULL, \"Just checking\");\n+        assert(klass->access_flags().is_inline_type(), \"Inline type expected\");\n+        ik->set_inline_type_field_klass(i, klass);\n+        klass_name->decrement_refcount();\n+        if (!InlineKlass::cast(klass)->is_empty_inline_type()) { all_fields_empty = false; }\n+      } else {\n+        all_fields_empty = false;\n+      }\n+    } else if (is_inline_type() && ((ik->field_access_flags(i) & JVM_ACC_FIELD_INTERNAL) != 0)) {\n+      InlineKlass::cast(ik)->set_default_value_offset(ik->field_offset(i));\n+    }\n+  }\n+\n+  if (_is_empty_inline_type || (is_inline_type() && all_fields_empty)) {\n+    ik->set_is_empty_inline_type();\n+  }\n+\n+  if (is_inline_type()) {\n+    InlineKlass* vk = InlineKlass::cast(ik);\n+    vk->set_alignment(_alignment);\n+    vk->set_first_field_offset(_first_field_offset);\n+    vk->set_exact_size_in_bytes(_exact_size_in_bytes);\n+    InlineKlass::cast(ik)->initialize_calling_convention(CHECK);\n+  }\n+\n@@ -5618,0 +5974,10 @@\n+  \/\/ the common single interface arrays need setup here to provide the\n+  \/\/ correct answer to \"compute_transitive_interfaces()\", during\n+  \/\/ \"SystemDictionary::initialize()\"\n+  if (ik->name() == vmSymbols::java_lang_IdentityObject()) {\n+    Universe::initialize_the_single_IdentityObject_klass_array(ik, CHECK);\n+  }\n+  if (ik->name() == vmSymbols::java_lang_PrimitiveObject()) {\n+    Universe::initialize_the_single_PrimitiveObject_klass_array(ik, CHECK);\n+  }\n+\n@@ -5720,0 +6086,1 @@\n+  _temp_local_interfaces(NULL),\n@@ -5759,0 +6126,11 @@\n+  _has_inline_type_fields(false),\n+  _has_nonstatic_fields(false),\n+  _is_empty_inline_type(false),\n+  _is_naturally_atomic(false),\n+  _is_declared_atomic(false),\n+  _invalid_inline_super(false),\n+  _invalid_identity_super(false),\n+  _implements_identityObject(false),\n+  _has_injected_identityObject(false),\n+  _implements_primitiveObject(false),\n+  _has_injected_primitiveObject(false),\n@@ -5969,2 +6347,1 @@\n-  \/\/ Access flags\n-  jint flags;\n+  jint recognized_modifiers = JVM_RECOGNIZED_CLASS_MODIFIERS;\n@@ -5973,3 +6350,5 @@\n-    flags = stream->get_u2_fast() & (JVM_RECOGNIZED_CLASS_MODIFIERS | JVM_ACC_MODULE);\n-  } else {\n-    flags = stream->get_u2_fast() & JVM_RECOGNIZED_CLASS_MODIFIERS;\n+    recognized_modifiers |= JVM_ACC_MODULE;\n+  }\n+  \/\/ JVM_ACC_INLINE is defined for class file version 55 and later\n+  if (supports_inline_types()) {\n+    recognized_modifiers |= JVM_ACC_INLINE;\n@@ -5978,0 +6357,3 @@\n+  \/\/ Access flags\n+  jint flags = stream->get_u2_fast() & recognized_modifiers;\n+\n@@ -6099,0 +6481,1 @@\n+                   &_is_declared_atomic,\n@@ -6101,1 +6484,1 @@\n-  assert(_local_interfaces != NULL, \"invariant\");\n+  assert(_temp_local_interfaces != NULL, \"invariant\");\n@@ -6106,1 +6489,2 @@\n-               _access_flags.is_interface(),\n+               is_interface(),\n+               is_inline_type(),\n@@ -6118,1 +6502,2 @@\n-                _access_flags.is_interface(),\n+                is_interface(),\n+                is_inline_type(),\n@@ -6200,3 +6585,3 @@\n-    check_property(_local_interfaces == Universe::the_empty_instance_klass_array(),\n-                   \"java.lang.Object cannot implement an interface in class file %s\",\n-                   CHECK);\n+    check_property(_temp_local_interfaces->length() == 0,\n+        \"java.lang.Object cannot implement an interface in class file %s\",\n+        CHECK);\n@@ -6207,1 +6592,1 @@\n-    if (_access_flags.is_interface()) {\n+    if (is_interface()) {\n@@ -6228,0 +6613,3 @@\n+    if (_super_klass->is_declared_atomic()) {\n+      _is_declared_atomic = true;\n+    }\n@@ -6233,0 +6621,22 @@\n+\n+    \/\/ For an inline class, only java\/lang\/Object or special abstract classes\n+    \/\/ are acceptable super classes.\n+    if (is_inline_type()) {\n+      const InstanceKlass* super_ik = _super_klass;\n+      if (super_ik->invalid_inline_super()) {\n+        classfile_icce_error(\"inline class %s has an invalid super class %s\", _super_klass, THREAD);\n+        return;\n+      }\n+    }\n+  }\n+\n+  if (_class_name == vmSymbols::java_lang_NonTearable() && _loader_data->class_loader() == NULL) {\n+    \/\/ This is the original source of this condition.\n+    \/\/ It propagates by inheritance, as if testing \"instanceof NonTearable\".\n+    _is_declared_atomic = true;\n+  } else if (*ForceNonTearable != '\\0') {\n+    \/\/ Allow a command line switch to force the same atomicity property:\n+    const char* class_name_str = _class_name->as_C_string();\n+    if (StringUtils::class_list_match(ForceNonTearable, class_name_str)) {\n+      _is_declared_atomic = true;\n+    }\n@@ -6235,0 +6645,42 @@\n+  \/\/ Set ik->invalid_inline_super field to TRUE if already marked as invalid,\n+  \/\/ if super is marked invalid, or if is_invalid_super_for_inline_type()\n+  \/\/ returns true\n+  if (invalid_inline_super() ||\n+      (_super_klass != NULL && _super_klass->invalid_inline_super()) ||\n+      is_invalid_super_for_inline_type()) {\n+    set_invalid_inline_super();\n+  }\n+\n+  if (!is_inline_type() && invalid_inline_super() && (_super_klass == NULL || !_super_klass->invalid_inline_super())\n+      && !_implements_identityObject && class_name() != vmSymbols::java_lang_IdentityObject()) {\n+    _temp_local_interfaces->append(vmClasses::IdentityObject_klass());\n+    _has_injected_identityObject = true;\n+  }\n+  \/\/ Check if declared as PrimitiveObject...else add if needed\n+  if (_implements_primitiveObject) {\n+    if (!is_inline_type() && invalid_inline_super()) {\n+      classfile_icce_error(\"class %s can not implement %s, neither valid inline classes or valid supertype\",\n+                            vmClasses::PrimitiveObject_klass(), THREAD);\n+      return;\n+    }\n+  } else if (is_inline_type()) {\n+    _temp_local_interfaces->append(vmClasses::PrimitiveObject_klass());\n+    _has_injected_primitiveObject = true;\n+  }\n+\n+  int itfs_len = _temp_local_interfaces->length();\n+  if (itfs_len == 0) {\n+    _local_interfaces = Universe::the_empty_instance_klass_array();\n+  } else if (itfs_len == 1 && _temp_local_interfaces->at(0) == vmClasses::IdentityObject_klass()) {\n+    _local_interfaces = Universe::the_single_IdentityObject_klass_array();\n+  } else if (itfs_len == 1 && _temp_local_interfaces->at(0) == vmClasses::PrimitiveObject_klass()) {\n+    _local_interfaces = Universe::the_single_PrimitiveObject_klass_array();\n+  } else {\n+    _local_interfaces = MetadataFactory::new_array<InstanceKlass*>(_loader_data, itfs_len, NULL, CHECK);\n+    for (int i = 0; i < itfs_len; i++) {\n+      _local_interfaces->at_put(i, _temp_local_interfaces->at(i));\n+    }\n+  }\n+  _temp_local_interfaces = NULL;\n+  assert(_local_interfaces != NULL, \"invariant\");\n+\n@@ -6262,1 +6714,1 @@\n-  _itable_size = _access_flags.is_interface() ? 0 :\n+  _itable_size = is_interface() ? 0 :\n@@ -6268,0 +6720,19 @@\n+\n+  for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {\n+    if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE && !fs.access_flags().is_static()) {\n+      \/\/ Pre-load inline class\n+      Klass* klass = SystemDictionary::resolve_inline_type_field_or_fail(&fs,\n+          Handle(THREAD, _loader_data->class_loader()),\n+          _protection_domain, true, CHECK);\n+      assert(klass != NULL, \"Sanity check\");\n+      if (!klass->access_flags().is_inline_type()) {\n+        assert(klass->is_instance_klass(), \"Sanity check\");\n+        ResourceMark rm(THREAD);\n+          THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                    err_msg(\"Class %s expects class %s to be an inline type, but it is not\",\n+                    _class_name->as_C_string(),\n+                    InstanceKlass::cast(klass)->external_name()));\n+      }\n+    }\n+  }\n+\n@@ -6270,2 +6741,9 @@\n-                        _parsed_annotations->is_contended(), _field_info);\n-  lb.build_layout();\n+      _parsed_annotations->is_contended(), is_inline_type(),\n+      loader_data(), _protection_domain, _field_info);\n+  lb.build_layout(CHECK);\n+  if (is_inline_type()) {\n+    _alignment = lb.get_alignment();\n+    _first_field_offset = lb.get_first_field_offset();\n+    _exact_size_in_bytes = lb.get_exact_size_in_byte();\n+  }\n+  _has_inline_type_fields = _field_info->_has_inline_fields;\n@@ -6273,1 +6751,1 @@\n-  \/\/ Compute reference typ\n+  \/\/ Compute reference type\n@@ -6275,1 +6753,0 @@\n-\n@@ -6307,0 +6784,1 @@\n+\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":562,"deletions":84,"binary":false,"changes":646,"status":"modified"},{"patch":"@@ -78,0 +78,2 @@\n+  bool  _is_naturally_atomic;\n+  bool _has_inline_fields;\n@@ -137,0 +139,1 @@\n+  GrowableArray<InstanceKlass*>* _temp_local_interfaces;\n@@ -162,0 +165,4 @@\n+  int _alignment;\n+  int _first_field_offset;\n+  int _exact_size_in_bytes;\n+\n@@ -200,0 +207,12 @@\n+  bool _has_inline_type_fields;\n+  bool _has_nonstatic_fields;\n+  bool _is_empty_inline_type;\n+  bool _is_naturally_atomic;\n+  bool _is_declared_atomic;\n+  bool _invalid_inline_super;   \/\/ if true, invalid super type for an inline type.\n+  bool _invalid_identity_super; \/\/ if true, invalid super type for an identity type.\n+  bool _implements_identityObject;\n+  bool _has_injected_identityObject;\n+  bool _implements_primitiveObject;\n+  bool _has_injected_primitiveObject;\n+\n@@ -250,0 +269,1 @@\n+                        bool* is_declared_atomic,\n@@ -270,0 +290,1 @@\n+                    bool is_inline_type,\n@@ -279,0 +300,1 @@\n+                       bool is_inline_type,\n@@ -285,0 +307,1 @@\n+                     bool is_inline_type,\n@@ -460,0 +483,5 @@\n+  void throwInlineTypeLimitation(THREAD_AND_LOCATION_DECL,\n+                                 const char* msg,\n+                                 const Symbol* name = NULL,\n+                                 const Symbol* sig  = NULL) const;\n+\n@@ -480,1 +508,4 @@\n-  void verify_legal_field_modifiers(jint flags, bool is_interface, TRAPS) const;\n+  void verify_legal_field_modifiers(jint flags,\n+                                    bool is_interface,\n+                                    bool is_inline_type,\n+                                    TRAPS) const;\n@@ -483,0 +514,1 @@\n+                                     bool is_inline_type,\n@@ -560,0 +592,3 @@\n+  \/\/ Check if the class file supports inline types\n+  bool supports_inline_types() const;\n+\n@@ -588,0 +623,10 @@\n+  bool is_inline_type() const { return _access_flags.is_inline_type(); }\n+  bool is_value_capable_class() const;\n+  bool has_inline_fields() const { return _has_inline_type_fields; }\n+  bool invalid_inline_super() const { return _invalid_inline_super; }\n+  void set_invalid_inline_super() { _invalid_inline_super = true; }\n+  bool invalid_identity_super() const { return _invalid_identity_super; }\n+  void set_invalid_identity_super() { _invalid_identity_super = true; }\n+  bool is_invalid_super_for_inline_type();\n+\n+  u2 java_fields_count() const { return _java_fields_count; }\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":46,"deletions":1,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -467,4 +467,53 @@\n-  bool added = SystemDictionaryShared::add_unregistered_class(THREAD, k);\n-  if (!added) {\n-    \/\/ We allow only a single unregistered class for each unique name.\n-    error(\"Duplicated class %s\", _class_name);\n+  if (k != NULL) {\n+    int actual_num_interfaces = k->local_interfaces()->length();\n+    int specified_num_interfaces = _interfaces->length();\n+    int expected_num_interfaces, i;\n+\n+    bool identity_object_implemented = false;\n+    bool identity_object_specified = false;\n+    bool primitive_object_implemented = false;\n+    bool primitive_object_specified = false;\n+    for (i = 0; i < actual_num_interfaces; i++) {\n+      if (k->local_interfaces()->at(i) == vmClasses::IdentityObject_klass()) {\n+        identity_object_implemented = true;\n+        break;\n+      }\n+      if (k->local_interfaces()->at(i) == vmClasses::PrimitiveObject_klass()) {\n+        primitive_object_implemented = true;\n+        break;\n+      }\n+    }\n+    for (i = 0; i < specified_num_interfaces; i++) {\n+      if (lookup_class_by_id(_interfaces->at(i)) == vmClasses::IdentityObject_klass()) {\n+        identity_object_specified = true;\n+        break;\n+      }\n+      if (lookup_class_by_id(_interfaces->at(i)) == vmClasses::PrimitiveObject_klass()) {\n+        primitive_object_specified = true;\n+        break;\n+      }\n+    }\n+\n+    expected_num_interfaces = actual_num_interfaces;\n+    if ( (identity_object_implemented  && !identity_object_specified) ||\n+         (primitive_object_implemented && !primitive_object_specified) ){\n+      \/\/ Backwards compatibility -- older classlists do not know about\n+      \/\/ java.lang.IdentityObject or java.lang.PrimitiveObject\n+      expected_num_interfaces--;\n+    }\n+    if (specified_num_interfaces != expected_num_interfaces) {\n+      print_specified_interfaces();\n+      print_actual_interfaces(k);\n+      error(\"The number of interfaces (%d) specified in class list does not match the class file (%d)\",\n+            specified_num_interfaces, expected_num_interfaces);\n+    }\n+\n+    bool added = SystemDictionaryShared::add_unregistered_class(THREAD, k);\n+    if (!added) {\n+      \/\/ We allow only a single unregistered class for each unique name.\n+      error(\"Duplicated class %s\", _class_name);\n+    }\n+\n+    \/\/ This tells JVM_FindLoadedClass to not find this class.\n+    k->set_shared_classpath_index(UNREGISTERED_INDEX);\n+    k->clear_shared_class_loader_type();\n@@ -688,0 +737,11 @@\n+  if (interface_name == vmSymbols::java_lang_IdentityObject()) {\n+    \/\/ Backwards compatibility -- older classlists do not know about\n+    \/\/ java.lang.IdentityObject.\n+    return vmClasses::IdentityObject_klass();\n+  }\n+  if (interface_name == vmSymbols::java_lang_PrimitiveObject()) {\n+    \/\/ Backwards compatibility -- older classlists do not know about\n+    \/\/ java.lang.PrimitiveObject.\n+    return vmClasses::PrimitiveObject_klass();\n+  }\n+\n","filename":"src\/hotspot\/share\/classfile\/classListParser.cpp","additions":64,"deletions":4,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -205,1 +205,1 @@\n-    if (*start == JVM_SIGNATURE_CLASS) {\n+    if (*start == JVM_SIGNATURE_CLASS || *start == JVM_SIGNATURE_INLINE_TYPE) {\n","filename":"src\/hotspot\/share\/classfile\/classLoader.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -71,0 +71,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -384,0 +385,10 @@\n+void ClassLoaderData::inline_classes_do(void f(InlineKlass*)) {\n+  \/\/ Lock-free access requires load_acquire\n+  for (Klass* k = Atomic::load_acquire(&_klasses); k != NULL; k = k->next_link()) {\n+    if (k->is_inline_klass()) {\n+      f(InlineKlass::cast(k));\n+    }\n+    assert(k != k->next_link(), \"no loops!\");\n+  }\n+}\n+\n@@ -550,0 +561,2 @@\n+  inline_classes_do(InlineKlass::cleanup);\n+\n@@ -844,1 +857,5 @@\n-        MetadataFactory::free_metadata(this, (InstanceKlass*)m);\n+        if (!((Klass*)m)->is_inline_klass()) {\n+          MetadataFactory::free_metadata(this, (InstanceKlass*)m);\n+        } else {\n+          MetadataFactory::free_metadata(this, (InlineKlass*)m);\n+        }\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.cpp","additions":18,"deletions":1,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -51,0 +51,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -52,1 +54,1 @@\n-#include \"oops\/instanceMirrorKlass.hpp\"\n+#include \"oops\/instanceMirrorKlass.inline.hpp\"\n@@ -1050,1 +1052,6 @@\n-      if (k->is_typeArray_klass()) {\n+      if (k->is_flatArray_klass()) {\n+        Klass* element_klass = (Klass*) FlatArrayKlass::cast(k)->element_klass();\n+        assert(element_klass->is_inline_klass(), \"Must be inline type component\");\n+        InlineKlass* vk = InlineKlass::cast(InstanceKlass::cast(element_klass));\n+        comp_mirror = Handle(THREAD, vk->java_mirror());\n+      } else if (k->is_typeArray_klass()) {\n@@ -1149,0 +1156,1 @@\n+      case T_INLINE_TYPE:\n@@ -1246,0 +1254,6 @@\n+  if (k->is_inline_klass()) {\n+    \/\/ Inline types have a val type mirror and a ref type mirror. Don't handle this for now. TODO:CDS\n+    k->clear_java_mirror_handle();\n+    return NULL;\n+  }\n+\n@@ -1564,0 +1578,1 @@\n+  bool is_value = false;\n@@ -1569,0 +1584,1 @@\n+    is_value = k->is_inline_klass();\n@@ -1575,1 +1591,7 @@\n-  if (is_instance)  st->print(\"L\");\n+  if (is_instance)  {\n+    if (is_value) {\n+      st->print(\"Q\");\n+    } else {\n+      st->print(\"L\");\n+    }\n+  }\n@@ -1597,1 +1619,1 @@\n-      int         siglen = (int) strlen(sigstr);\n+      int siglen = (int) strlen(sigstr);\n@@ -2567,2 +2589,2 @@\n-      \/\/ This is simlar to classic VM.\n-      if (method->name() == vmSymbols::object_initializer_name() &&\n+      \/\/ This is similar to classic VM (before HotSpot).\n+      if (method->is_object_constructor() &&\n@@ -4002,1 +4024,1 @@\n-  return (flags(mname) & (MN_IS_METHOD | MN_IS_CONSTRUCTOR)) > 0;\n+  return (flags(mname) & (MN_IS_METHOD | MN_IS_OBJECT_CONSTRUCTOR)) > 0;\n@@ -4850,0 +4872,71 @@\n+\/\/ jdk_internal_vm_jni_SubElementSelector\n+\n+int jdk_internal_vm_jni_SubElementSelector::_arrayElementType_offset;\n+int jdk_internal_vm_jni_SubElementSelector::_subElementType_offset;\n+int jdk_internal_vm_jni_SubElementSelector::_offset_offset;\n+int jdk_internal_vm_jni_SubElementSelector::_isInlined_offset;\n+int jdk_internal_vm_jni_SubElementSelector::_isInlineType_offset;\n+\n+#define SUBELEMENT_SELECTOR_FIELDS_DO(macro) \\\n+  macro(_arrayElementType_offset,  k, \"arrayElementType\", class_signature, false); \\\n+  macro(_subElementType_offset,    k, \"subElementType\",   class_signature, false); \\\n+  macro(_offset_offset,            k, \"offset\",           int_signature,   false); \\\n+  macro(_isInlined_offset,         k, \"isInlined\",        bool_signature,  false); \\\n+  macro(_isInlineType_offset,      k, \"isInlineType\",     bool_signature,  false);\n+\n+void jdk_internal_vm_jni_SubElementSelector::compute_offsets() {\n+  InstanceKlass* k = vmClasses::jdk_internal_vm_jni_SubElementSelector_klass();\n+  SUBELEMENT_SELECTOR_FIELDS_DO(FIELD_COMPUTE_OFFSET);\n+}\n+\n+#if INCLUDE_CDS\n+void jdk_internal_vm_jni_SubElementSelector::serialize_offsets(SerializeClosure* f) {\n+  SUBELEMENT_SELECTOR_FIELDS_DO(FIELD_SERIALIZE_OFFSET);\n+}\n+#endif\n+#undef SUBELEMENT_SELECTOR_FIELDS_DO\n+\n+Symbol* jdk_internal_vm_jni_SubElementSelector::symbol() {\n+  return vmSymbols::jdk_internal_vm_jni_SubElementSelector();\n+}\n+\n+oop jdk_internal_vm_jni_SubElementSelector::getArrayElementType(oop obj) {\n+  return obj->obj_field(_arrayElementType_offset);\n+}\n+\n+void jdk_internal_vm_jni_SubElementSelector::setArrayElementType(oop obj, oop type) {\n+  obj->obj_field_put(_arrayElementType_offset, type);\n+}\n+\n+oop jdk_internal_vm_jni_SubElementSelector::getSubElementType(oop obj) {\n+  return obj->obj_field(_subElementType_offset);\n+}\n+\n+void jdk_internal_vm_jni_SubElementSelector::setSubElementType(oop obj, oop type) {\n+  obj->obj_field_put(_subElementType_offset, type);\n+}\n+\n+int jdk_internal_vm_jni_SubElementSelector::getOffset(oop obj) {\n+  return obj->int_field(_offset_offset);\n+}\n+\n+void jdk_internal_vm_jni_SubElementSelector::setOffset(oop obj, int offset) {\n+  obj->int_field_put(_offset_offset, offset);\n+}\n+\n+bool jdk_internal_vm_jni_SubElementSelector::getIsInlined(oop obj) {\n+  return obj->bool_field(_isInlined_offset);\n+}\n+\n+void jdk_internal_vm_jni_SubElementSelector::setIsInlined(oop obj, bool b) {\n+  obj->bool_field_put(_isInlined_offset, b);\n+}\n+\n+bool jdk_internal_vm_jni_SubElementSelector::getIsInlineType(oop obj) {\n+  return obj->bool_field(_isInlineType_offset);\n+}\n+\n+void jdk_internal_vm_jni_SubElementSelector::setIsInlineType(oop obj, bool b) {\n+  obj->bool_field_put(_isInlineType_offset, b);\n+}\n+\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":100,"deletions":7,"binary":false,"changes":107,"status":"modified"},{"patch":"@@ -80,0 +80,1 @@\n+  f(jdk_internal_vm_jni_SubElementSelector) \\\n@@ -309,0 +310,1 @@\n+  static int component_mirror_offset()     { CHECK_INIT(_component_mirror_offset); }\n@@ -325,2 +327,0 @@\n-  static int component_mirror_offset() { return _component_mirror_offset; }\n-\n@@ -1148,1 +1148,1 @@\n-    MN_IS_CONSTRUCTOR        = 0x00020000, \/\/ constructor\n+    MN_IS_OBJECT_CONSTRUCTOR = 0x00020000, \/\/ constructor\n@@ -1699,1 +1699,0 @@\n-\n@@ -1715,0 +1714,25 @@\n+class jdk_internal_vm_jni_SubElementSelector : AllStatic {\n+ private:\n+  static int _arrayElementType_offset;\n+  static int _subElementType_offset;\n+  static int _offset_offset;\n+  static int _isInlined_offset;\n+  static int _isInlineType_offset;\n+ public:\n+  static Symbol* symbol();\n+  static void compute_offsets();\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  static oop getArrayElementType(oop obj);\n+  static void setArrayElementType(oop obj, oop type);\n+  static oop getSubElementType(oop obj);\n+  static void setSubElementType(oop obj, oop type);\n+  static int getOffset(oop obj);\n+  static void setOffset(oop obj, int offset);\n+  static bool getIsInlined(oop obj);\n+  static void setIsInlined(oop obj, bool b);\n+  static bool getIsInlineType(oop obj);\n+  static void setIsInlineType(oop obj, bool b);\n+};\n+\n+\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":28,"deletions":4,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -44,0 +44,2 @@\n+\/\/ For INLINE_FIELD, set when loading inline type fields for\n+\/\/ class circularity checking.\n@@ -84,0 +86,3 @@\n+    case PlaceholderTable::INLINE_TYPE_FIELD:\n+       queuehead = _inlineTypeFieldQ;\n+       break;\n@@ -100,0 +105,3 @@\n+    case PlaceholderTable::INLINE_TYPE_FIELD:\n+       _inlineTypeFieldQ = seenthread;\n+       break;\n@@ -187,0 +195,1 @@\n+  entry->set_inlineTypeFieldQ(NULL);\n@@ -267,0 +276,1 @@\n+  case PlaceholderTable::INLINE_TYPE_FIELD: return \"INLINE_TYPE_FIELD\";\n@@ -332,1 +342,2 @@\n-          && (probe->defineThreadQ() == NULL) && (probe->definer() == NULL)) {\n+          && (probe->defineThreadQ() == NULL) && (probe->definer() == NULL)\n+          && (probe->inlineTypeFieldQ() == NULL)) {\n@@ -387,0 +398,3 @@\n+  st->print(\"inlineTypeFieldQ threads:\");\n+  inlineTypeFieldQ()->print_action_queue(st);\n+  st->cr();\n","filename":"src\/hotspot\/share\/classfile\/placeholders.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -84,1 +84,1 @@\n-    if (m->name() == vmSymbols::object_initializer_name() &&\n+    if (m->is_object_constructor() &&\n@@ -104,0 +104,1 @@\n+    case T_INLINE_TYPE:\n@@ -114,0 +115,3 @@\n+      if (ss.type() == T_INLINE_TYPE) {\n+        return VerificationType::inline_type(sig);\n+      }\n","filename":"src\/hotspot\/share\/classfile\/stackMapFrame.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -69,0 +70,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -77,0 +79,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -288,1 +291,1 @@\n-    \/\/ Ignore wrapping L and ;.\n+    \/\/ Ignore wrapping L and ;. (and Q and ; for value types);\n@@ -316,0 +319,4 @@\n+      if ((class_name->is_Q_array_signature() && !k->is_inline_klass()) ||\n+          (!class_name->is_Q_array_signature() && k->is_inline_klass())) {\n+            THROW_MSG_NULL(vmSymbols::java_lang_IncompatibleClassChangeError(), \"L\/Q mismatch on bottom type\");\n+          }\n@@ -446,0 +453,44 @@\n+Klass* SystemDictionary::resolve_inline_type_field_or_fail(AllFieldStream* fs,\n+                                                           Handle class_loader,\n+                                                           Handle protection_domain,\n+                                                           bool throw_error,\n+                                                           TRAPS) {\n+  Symbol* class_name = fs->signature()->fundamental_name(THREAD);\n+  class_loader = Handle(THREAD, java_lang_ClassLoader::non_reflection_class_loader(class_loader()));\n+  ClassLoaderData* loader_data = class_loader_data(class_loader);\n+  unsigned int p_hash = placeholders()->compute_hash(class_name);\n+  bool throw_circularity_error = false;\n+  PlaceholderEntry* oldprobe;\n+\n+  {\n+    MutexLocker mu(THREAD, SystemDictionary_lock);\n+    oldprobe = placeholders()->get_entry(p_hash, class_name, loader_data);\n+    if (oldprobe != NULL &&\n+      oldprobe->check_seen_thread(THREAD, PlaceholderTable::INLINE_TYPE_FIELD)) {\n+      throw_circularity_error = true;\n+\n+    } else {\n+      placeholders()->find_and_add(p_hash, class_name, loader_data,\n+                                   PlaceholderTable::INLINE_TYPE_FIELD, NULL, THREAD);\n+    }\n+  }\n+\n+  Klass* klass = NULL;\n+  if (!throw_circularity_error) {\n+    klass = SystemDictionary::resolve_or_fail(class_name, class_loader,\n+                                               protection_domain, true, THREAD);\n+  } else {\n+    ResourceMark rm(THREAD);\n+    THROW_MSG_NULL(vmSymbols::java_lang_ClassCircularityError(), class_name->as_C_string());\n+  }\n+\n+  {\n+    MutexLocker mu(THREAD, SystemDictionary_lock);\n+    placeholders()->find_and_remove(p_hash, class_name, loader_data,\n+                                    PlaceholderTable::INLINE_TYPE_FIELD, THREAD);\n+  }\n+\n+  class_name->decrement_refcount();\n+  return klass;\n+}\n+\n@@ -803,1 +854,1 @@\n-    if (t != T_OBJECT) {\n+    if (t != T_OBJECT && t != T_INLINE_TYPE) {\n@@ -1183,0 +1234,18 @@\n+\n+  if (ik->has_inline_type_fields()) {\n+    for (AllFieldStream fs(ik->fields(), ik->constants()); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {\n+        if (!fs.access_flags().is_static()) {\n+          \/\/ Pre-load inline class\n+          Klass* real_k = SystemDictionary::resolve_inline_type_field_or_fail(&fs,\n+            class_loader, protection_domain, true, CHECK_NULL);\n+          Klass* k = ik->get_inline_type_field_klass_or_null(fs.index());\n+          if (real_k != k) {\n+            \/\/ oops, the app has substituted a different version of k!\n+            return NULL;\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1218,0 +1287,7 @@\n+\n+  if (ik->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(ik);\n+    oop val = ik->allocate_instance(CHECK_NULL);\n+    vk->set_default_value(val);\n+  }\n+\n@@ -1814,1 +1890,1 @@\n-    if (t != T_OBJECT) {\n+    if (t != T_OBJECT && t != T_INLINE_TYPE) {\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":79,"deletions":3,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+class AllFieldStream;\n@@ -139,0 +140,6 @@\n+  static Klass* resolve_inline_type_field_or_fail(AllFieldStream* fs,\n+                                                  Handle class_loader,\n+                                                  Handle protection_domain,\n+                                                  bool throw_error,\n+                                                  TRAPS);\n+\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -67,0 +67,1 @@\n+  if (this_class->access_flags().is_inline_type()) return false;\n@@ -71,1 +72,2 @@\n-    \/\/ to interfaces java.lang.Cloneable and java.io.Serializable.\n+    \/\/ to interfaces java.lang.Cloneable, java.io.Serializable,\n+    \/\/ and java.lang.IdentityObject.\n@@ -75,1 +77,2 @@\n-      this_class == vmClasses::Serializable_klass();\n+      this_class == vmClasses::Serializable_klass() ||\n+      this_class == vmClasses::IdentityObject_klass();\n@@ -127,0 +130,29 @@\n+\n+\/*\n+    \/\/ This code implements non-covariance between inline type arrays and both\n+    \/\/ arrays of objects and arrays of interface types.  If covariance is\n+    \/\/ supported for inline type arrays then this code should be removed.\n+    if (comp_from.is_inline_type() && !comp_this.is_null() && comp_this.is_reference()) {\n+      \/\/ An array of inline types is not assignable to an array of java.lang.Objects.\n+      if (comp_this.name() == vmSymbols::java_lang_Object()) {\n+        return false;\n+      }\n+\n+      \/\/ Need to load 'comp_this' to see if it is an interface.\n+      InstanceKlass* klass = context->current_class();\n+      {\n+        HandleMark hm(THREAD);\n+        Klass* comp_this_class = SystemDictionary::resolve_or_fail(\n+            comp_this.name(), Handle(THREAD, klass->class_loader()),\n+            Handle(THREAD, klass->protection_domain()), true, CHECK_false);\n+        klass->class_loader_data()->record_dependency(comp_this_class);\n+        if (log_is_enabled(Debug, class, resolve)) {\n+          Verifier::trace_class_resolution(comp_this_class, klass);\n+        }\n+        \/\/ An array of inline types is not assignable to an array of interface types.\n+        if (comp_this_class->is_interface()) {\n+          return false;\n+        }\n+      }\n+    }\n+*\/\n@@ -135,0 +167,39 @@\n+bool VerificationType::is_inline_type_assignable_from(const VerificationType& from) const {\n+  \/\/ Check that 'from' is not null, is an inline type, and is the same inline type.\n+  assert(is_inline_type(), \"called with a non-inline type\");\n+  assert(!is_null(), \"inline type is not null\");\n+  return (!from.is_null() && from.is_inline_type() && name() == from.name());\n+}\n+\n+bool VerificationType::is_ref_assignable_from_inline_type(const VerificationType& from, ClassVerifier* context, TRAPS) const {\n+  assert(!from.is_null(), \"Inline type should not be null\");\n+  if (!is_null() && (name()->is_same_fundamental_type(from.name()) ||\n+      name() == vmSymbols::java_lang_Object())) {\n+    return true;\n+  }\n+\n+  \/\/ Need to load 'this' to see if it is an interface or supertype.\n+  InstanceKlass* klass = context->current_class();\n+  {\n+    HandleMark hm(THREAD);\n+    Klass* this_class = SystemDictionary::resolve_or_fail(\n+        name(), Handle(THREAD, klass->class_loader()),\n+        Handle(THREAD, klass->protection_domain()), true, CHECK_false);\n+    klass->class_loader_data()->record_dependency(this_class);\n+    if (log_is_enabled(Debug, class, resolve)) {\n+      Verifier::trace_class_resolution(this_class, klass);\n+    }\n+    if (this_class->is_interface()) {\n+      return true;\n+    } else {\n+      Klass* from_class = SystemDictionary::resolve_or_fail(\n+        from.name(), Handle(THREAD, klass->class_loader()),\n+        Handle(THREAD, klass->protection_domain()), true, CHECK_false);\n+      if (log_is_enabled(Debug, class, resolve)) {\n+        Verifier::trace_class_resolution(from_class, klass);\n+      }\n+      return from_class->is_subclass_of(this_class);\n+    }\n+  }\n+}\n+\n@@ -149,1 +220,2 @@\n-    case T_OBJECT: {\n+    case T_OBJECT:\n+    case T_INLINE_TYPE: {\n@@ -155,1 +227,3 @@\n-      return VerificationType::reference_type(component_copy);\n+      return (ss.type() == T_INLINE_TYPE) ?\n+        VerificationType::inline_type(component_copy) :\n+        VerificationType::reference_type(component_copy);\n@@ -181,0 +255,2 @@\n+    case InlineTypeQuery:  st->print(\"inline type\"); break;\n+    case NonScalarQuery:   st->print(\"reference or inline type\"); break;\n@@ -189,0 +265,2 @@\n+      } else if (is_inline_type()) {\n+        name()->print_Qvalue_on(st);\n","filename":"src\/hotspot\/share\/classfile\/verificationType.cpp","additions":82,"deletions":4,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -71,3 +71,3 @@\n-      \/\/ Bottom two bits determine if the type is a reference, primitive,\n-      \/\/ uninitialized or a query-type.\n-      TypeMask           = 0x00000003,\n+      \/\/ Bottom three bits determine if the type is a reference, inline type,\n+      \/\/ primitive, uninitialized or a query-type.\n+      TypeMask           = 0x00000007,\n@@ -76,1 +76,1 @@\n-      Reference          = 0x0,        \/\/ _sym contains the name\n+      Reference          = 0x0,        \/\/ _sym contains the name of an object\n@@ -80,0 +80,1 @@\n+      InlineType         = 0x4,        \/\/ _sym contains the name of an inline type\n@@ -86,0 +87,2 @@\n+      InlineTypeFlag     = 0x08,       \/\/ For inline type query types\n+      NonScalarFlag      = 0x10,       \/\/ For either inline type or reference queries\n@@ -117,1 +120,3 @@\n-      Category2_2ndQuery = (Category2_2ndFlag << 1 * BitsPerByte) | TypeQuery\n+      Category2_2ndQuery = (Category2_2ndFlag << 1 * BitsPerByte) | TypeQuery,\n+      InlineTypeQuery    = (InlineTypeFlag    << 1 * BitsPerByte) | TypeQuery,\n+      NonScalarQuery     = (NonScalarFlag     << 1 * BitsPerByte) | TypeQuery\n@@ -150,0 +155,2 @@\n+  static VerificationType inline_type_check()\n+    { return VerificationType(InlineTypeQuery); }\n@@ -156,0 +163,2 @@\n+  static VerificationType nonscalar_check()\n+    { return VerificationType(NonScalarQuery); }\n@@ -159,1 +168,1 @@\n-      assert(((uintptr_t)sh & 0x3) == 0, \"Symbols must be aligned\");\n+      assert(((uintptr_t)sh & TypeMask) == 0, \"Symbols must be aligned\");\n@@ -162,1 +171,1 @@\n-      \/\/ to descriminate between oops and primitives.\n+      \/\/ to discriminate between oops and primitives.\n@@ -170,0 +179,11 @@\n+  \/\/ For inline types, store the actual Symbol* and set the 3rd bit.\n+  \/\/ Provides a way for an inline type to be distinguished from a reference type.\n+  static VerificationType inline_type(Symbol* sh) {\n+      assert(((uintptr_t)sh & TypeMask) == 0, \"Symbols must be aligned\");\n+      assert((uintptr_t)sh != 0, \"Null is not a valid inline type\");\n+      \/\/ If the above assert fails in the future because oop* isn't aligned,\n+      \/\/ then this type encoding system will have to change to have a tag value\n+      \/\/ to discriminate between oops and primitives.\n+      return VerificationType((uintptr_t)sh | InlineType);\n+  }\n+\n@@ -185,1 +205,2 @@\n-  bool is_reference() const { return ((_u._data & TypeMask) == Reference); }\n+  bool is_reference() const { return (((_u._data & TypeMask) == Reference) && !is_inline_type_check()); }\n+  bool is_inline_type() const { return ((_u._data & TypeMask) == InlineType); }\n@@ -188,2 +209,2 @@\n-    \/\/ primitives, and references (including uninitialized refs).  Though\n-    \/\/ the 'query' types should technically return 'false' here, if we\n+    \/\/ primitives, references (including uninitialized refs) and inline types.\n+    \/\/ Though the 'query' types should technically return 'false' here, if we\n@@ -203,0 +224,2 @@\n+  bool is_inline_type_check() const { return _u._data == InlineTypeQuery; }\n+  bool is_nonscalar_check() const { return _u._data == NonScalarQuery; }\n@@ -221,0 +244,1 @@\n+  bool is_inline_type_array() const { return is_x_array(JVM_SIGNATURE_INLINE_TYPE); }\n@@ -223,0 +247,2 @@\n+  bool is_nonscalar_array() const\n+    { return is_object_array() || is_array_array() || is_inline_type_array(); }\n@@ -239,0 +265,6 @@\n+  static VerificationType change_ref_to_inline_type(VerificationType ref) {\n+    assert(ref.is_reference(), \"Bad arg\");\n+    assert(!ref.is_null(), \"Unexpected NULL\");\n+    return inline_type(ref.name());\n+  }\n+\n@@ -245,2 +277,2 @@\n-    assert(is_reference() && !is_null(), \"Must be a non-null reference\");\n-    return _u._sym;\n+    assert(!is_null() && (is_reference() || is_inline_type()), \"Must be a non-null reference or an inline type\");\n+    return (is_reference() ? _u._sym : ((Symbol*)(_u._data & ~(uintptr_t)InlineType)));\n@@ -251,2 +283,4 @@\n-      (is_reference() && t.is_reference() && !is_null() && !t.is_null() &&\n-       name() == t.name()));\n+            (((is_reference() && t.is_reference()) ||\n+             (is_inline_type() && t.is_inline_type())) &&\n+              !is_null() && !t.is_null() && name() == t.name()));\n+\n@@ -281,0 +315,5 @@\n+        case NonScalarQuery:\n+          return from.is_reference() || from.is_uninitialized() ||\n+                 from.is_inline_type();\n+        case InlineTypeQuery:\n+          return from.is_inline_type();\n@@ -288,1 +327,5 @@\n-          if (is_reference() && from.is_reference()) {\n+          if (is_inline_type()) {\n+            return is_inline_type_assignable_from(from);\n+          } else if (is_reference() && from.is_inline_type()) {\n+            return is_ref_assignable_from_inline_type(from, context, THREAD);\n+          } else if (is_reference() && from.is_reference()) {\n@@ -336,0 +379,5 @@\n+  bool is_inline_type_assignable_from(const VerificationType& from) const;\n+\n+  bool is_ref_assignable_from_inline_type(const VerificationType& from, ClassVerifier* context, TRAPS) const;\n+\n+\n","filename":"src\/hotspot\/share\/classfile\/verificationType.hpp","additions":63,"deletions":15,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -66,0 +66,1 @@\n+#define INLINE_TYPE_MAJOR_VERSION                       56\n@@ -278,1 +279,1 @@\n-    \/\/ We need to skip the following four for bootstraping\n+    \/\/ We need to skip the following four for bootstrapping\n@@ -499,0 +500,7 @@\n+    case WRONG_INLINE_TYPE:\n+      ss->print(\"Type \");\n+      _type.details(ss);\n+      ss->print(\" and type \");\n+      _expected.details(ss);\n+      ss->print(\" must be identical inline types.\");\n+      break;\n@@ -593,0 +601,8 @@\n+VerificationType reference_or_inline_type(InstanceKlass* klass) {\n+  if (klass->is_inline_klass()) {\n+    return VerificationType::inline_type(klass->name());\n+  } else {\n+    return VerificationType::reference_type(klass->name());\n+  }\n+}\n+\n@@ -596,1 +612,1 @@\n-  _this_type = VerificationType::reference_type(klass->name());\n+  _this_type = reference_or_inline_type(klass);\n@@ -1040,1 +1056,1 @@\n-          if (!atype.is_reference_array()) {\n+          if (!atype.is_nonscalar_array()) {\n@@ -1213,1 +1229,1 @@\n-          if (!atype.is_reference_array()) {\n+          if (!atype.is_nonscalar_array()) {\n@@ -1613,1 +1629,1 @@\n-            VerificationType::reference_check(), CHECK_VERIFY(this));\n+            VerificationType::nonscalar_check(), CHECK_VERIFY(this));\n@@ -1618,1 +1634,1 @@\n-            VerificationType::reference_check(), CHECK_VERIFY(this));\n+            VerificationType::nonscalar_check(), CHECK_VERIFY(this));\n@@ -1669,1 +1685,1 @@\n-            VerificationType::reference_check(), CHECK_VERIFY(this));\n+            VerificationType::nonscalar_check(), CHECK_VERIFY(this));\n@@ -1681,1 +1697,1 @@\n-          if (_method->name() == vmSymbols::object_initializer_name() &&\n+          if (_method->is_object_constructor() &&\n@@ -1701,0 +1717,11 @@\n+        case Bytecodes::_withfield :\n+          if (_klass->major_version() < INLINE_TYPE_MAJOR_VERSION) {\n+            class_format_error(\n+              \"withfield not supported by this class file version (%d.%d), class %s\",\n+              _klass->major_version(), _klass->minor_version(), _klass->external_name());\n+            return;\n+          }\n+          \/\/ pass FALSE, operand can't be an array type for withfield.\n+          verify_field_instructions(\n+            &bcs, &current_frame, cp, false, CHECK_VERIFY(this));\n+          no_control_flow = false; break;\n@@ -1704,4 +1731,0 @@\n-          verify_invoke_instructions(\n-            &bcs, code_length, &current_frame, (bci >= ex_min && bci < ex_max),\n-            &this_uninit, return_type, cp, &stackmap_table, CHECK_VERIFY(this));\n-          no_control_flow = false; break;\n@@ -1712,1 +1735,1 @@\n-            &this_uninit, return_type, cp, &stackmap_table, CHECK_VERIFY(this));\n+            &this_uninit, cp, &stackmap_table, CHECK_VERIFY(this));\n@@ -1730,0 +1753,22 @@\n+        case Bytecodes::_defaultvalue :\n+        {\n+          if (_klass->major_version() < INLINE_TYPE_MAJOR_VERSION) {\n+            class_format_error(\n+              \"defaultvalue not supported by this class file version (%d.%d), class %s\",\n+              _klass->major_version(), _klass->minor_version(), _klass->external_name());\n+            return;\n+          }\n+          index = bcs.get_index_u2();\n+          verify_cp_class_type(bci, index, cp, CHECK_VERIFY(this));\n+          VerificationType ref_type = cp_index_to_type(index, cp, CHECK_VERIFY(this));\n+          if (!ref_type.is_object()) {\n+            verify_error(ErrorContext::bad_type(bci,\n+                TypeOrigin::cp(index, ref_type)),\n+                \"Illegal defaultvalue instruction\");\n+            return;\n+          }\n+          VerificationType inline_type =\n+            VerificationType::change_ref_to_inline_type(ref_type);\n+          current_frame.push_stack(inline_type, CHECK_VERIFY(this));\n+          no_control_flow = false; break;\n+        }\n@@ -1770,3 +1815,3 @@\n-        case Bytecodes::_monitorexit :\n-          current_frame.pop_stack(\n-            VerificationType::reference_check(), CHECK_VERIFY(this));\n+        case Bytecodes::_monitorexit : {\n+          VerificationType ref = current_frame.pop_stack(\n+            VerificationType::nonscalar_check(), CHECK_VERIFY(this));\n@@ -1774,0 +1819,1 @@\n+        }\n@@ -2032,0 +2078,1 @@\n+\n@@ -2146,1 +2193,1 @@\n-            | (1 << JVM_CONSTANT_String)  | (1 << JVM_CONSTANT_Class)\n+            | (1 << JVM_CONSTANT_String) | (1 << JVM_CONSTANT_Class)\n@@ -2322,1 +2369,1 @@\n-    (!allow_arrays || !ref_class_type.is_array())) {\n+      (!allow_arrays || !ref_class_type.is_array())) {\n@@ -2329,0 +2376,1 @@\n+\n@@ -2358,0 +2406,19 @@\n+    case Bytecodes::_withfield: {\n+      for (int i = n - 1; i >= 0; i--) {\n+        current_frame->pop_stack(field_type[i], CHECK_VERIFY(this));\n+      }\n+      \/\/ stack_object_type and target_class_type must be the same inline type.\n+      stack_object_type =\n+        current_frame->pop_stack(VerificationType::inline_type_check(), CHECK_VERIFY(this));\n+      VerificationType target_inline_type =\n+        VerificationType::change_ref_to_inline_type(target_class_type);\n+      if (!stack_object_type.equals(target_inline_type)) {\n+        verify_error(ErrorContext::bad_inline_type(bci,\n+            current_frame->stack_top_ctx(),\n+            TypeOrigin::cp(index, target_class_type)),\n+            \"Invalid type on operand stack in withfield instruction\");\n+        return;\n+      }\n+      current_frame->push_stack(target_inline_type, CHECK_VERIFY(this));\n+      break;\n+    }\n@@ -2766,1 +2833,1 @@\n-    bool in_try_block, bool *this_uninit, VerificationType return_type,\n+    bool in_try_block, bool *this_uninit,\n@@ -2798,1 +2865,1 @@\n-  \/\/ Get referenced class type\n+  \/\/ Get referenced class\n@@ -2864,2 +2931,4 @@\n-    \/\/ Make sure <init> can only be invoked by invokespecial\n-    if (opcode != Bytecodes::_invokespecial ||\n+    \/\/ Make sure <init> can only be invoked by invokespecial or invokestatic.\n+    \/\/ The allowed invocation mode of <init> depends on its signature.\n+    if ((opcode != Bytecodes::_invokespecial &&\n+         opcode != Bytecodes::_invokestatic) ||\n@@ -2874,1 +2943,1 @@\n-                  current_class()->super()->name()))) {\n+                  current_class()->super()->name()))) { \/\/ super() can never be an inline_type.\n@@ -2881,2 +2950,2 @@\n-      VerificationType unsafe_anonymous_host_type =\n-                        VerificationType::reference_type(current_class()->unsafe_anonymous_host()->name());\n+      InstanceKlass* unsafe_host = current_class()->unsafe_anonymous_host();\n+      VerificationType unsafe_anonymous_host_type = reference_or_inline_type(unsafe_host);\n@@ -2889,1 +2958,1 @@\n-                             current_class()->unsafe_anonymous_host(),\n+                             unsafe_host,\n@@ -2919,0 +2988,1 @@\n+      \/\/ (use of <init> as a static factory is handled under invokestatic)\n@@ -2933,3 +3003,4 @@\n-          VerificationType hosttype =\n-            VerificationType::reference_type(current_class()->unsafe_anonymous_host()->name());\n-          bool subtype = hosttype.is_assignable_from(top, this, false, CHECK_VERIFY(this));\n+\n+          InstanceKlass* unsafe_host = current_class()->unsafe_anonymous_host();\n+          VerificationType host_type = reference_or_inline_type(unsafe_host);\n+          bool subtype = host_type.is_assignable_from(top, this, false, CHECK_VERIFY(this));\n@@ -2988,4 +3059,3 @@\n-    if (method_name == vmSymbols::object_initializer_name()) {\n-      \/\/ <init> method must have a void return type\n-      \/* Unreachable?  Class file parser verifies that methods with '<' have\n-       * void return *\/\n+    if (method_name == vmSymbols::object_initializer_name() &&\n+        opcode != Bytecodes::_invokestatic) {\n+      \/\/ an <init> method must have a void return type, unless it's a static factory\n@@ -3004,0 +3074,8 @@\n+  } else {\n+    \/\/ an <init> method may not have a void return type, if it's a static factory\n+    if (method_name == vmSymbols::object_initializer_name() &&\n+        opcode != Bytecodes::_invokespecial) {\n+      verify_error(ErrorContext::bad_code(bci),\n+          \"Return type must be non-void in <init> static factory method\");\n+      return;\n+    }\n@@ -3051,1 +3129,2 @@\n-    \/\/ add one dimension to component with 'L' prepended and ';' postpended.\n+    char Q_or_L = component_type.is_inline_type() ? JVM_SIGNATURE_INLINE_TYPE : JVM_SIGNATURE_CLASS;\n+    \/\/ add one dimension to component with 'L' or 'Q' prepended and ';' appended.\n@@ -3055,1 +3134,1 @@\n-                         JVM_SIGNATURE_ARRAY, JVM_SIGNATURE_CLASS, component_name);\n+                         JVM_SIGNATURE_ARRAY, Q_or_L, component_name);\n@@ -3097,1 +3176,1 @@\n-    index, VerificationType::reference_check(), CHECK_VERIFY(this));\n+    index, VerificationType::nonscalar_check(), CHECK_VERIFY(this));\n@@ -3134,1 +3213,1 @@\n-    VerificationType::reference_check(), CHECK_VERIFY(this));\n+    VerificationType::nonscalar_check(), CHECK_VERIFY(this));\n","filename":"src\/hotspot\/share\/classfile\/verifier.cpp","additions":116,"deletions":37,"binary":false,"changes":153,"status":"modified"},{"patch":"@@ -43,1 +43,1 @@\n-    DYNAMICCONSTANT_MAJOR_VERSION       = 55\n+    DYNAMICCONSTANT_MAJOR_VERSION       = 55,\n@@ -158,0 +158,1 @@\n+    WRONG_INLINE_TYPE,    \/\/ Mismatched inline type\n@@ -221,0 +222,3 @@\n+  static ErrorContext bad_inline_type(u2 bci, TypeOrigin type, TypeOrigin exp) {\n+    return ErrorContext(bci, WRONG_INLINE_TYPE, type, exp);\n+  }\n@@ -352,1 +356,1 @@\n-    bool in_try_block, bool* this_uninit, VerificationType return_type,\n+    bool in_try_block, bool* this_uninit,\n@@ -453,1 +457,8 @@\n-    return VerificationType::reference_type(cp->klass_name_at(index));\n+    Symbol* name = cp->klass_name_at(index);\n+    if (name->is_Q_signature()) {\n+      \/\/ Remove the Q and ;\n+      \/\/ TBD need error msg if fundamental_name() returns NULL?\n+      Symbol* fund_name = name->fundamental_name(CHECK_(VerificationType::bogus_type()));\n+      return VerificationType::inline_type(fund_name);\n+    }\n+    return VerificationType::reference_type(name);\n@@ -491,2 +502,10 @@\n-        *inference_type =\n-          VerificationType::reference_type(name_copy);\n+        *inference_type = VerificationType::reference_type(name_copy);\n+        return 1;\n+      }\n+    case T_INLINE_TYPE:\n+      {\n+        Symbol* vname = sig_type->as_symbol();\n+        \/\/ Create another symbol to save as signature stream unreferences this symbol.\n+        Symbol* vname_copy = create_temporary_symbol(vname);\n+        assert(vname_copy == vname, \"symbols don't match\");\n+        *inference_type = VerificationType::inline_type(vname_copy);\n","filename":"src\/hotspot\/share\/classfile\/verifier.hpp","additions":24,"deletions":5,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -294,0 +294,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:\n+  case vmIntrinsics::_finishPrivateBuffer:\n@@ -303,0 +305,1 @@\n+  case vmIntrinsics::_getValue:\n@@ -312,0 +315,1 @@\n+  case vmIntrinsics::_putValue:\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -556,0 +556,2 @@\n+  do_signature(getValue_signature,        \"(Ljava\/lang\/Object;JLjava\/lang\/Class;)Ljava\/lang\/Object;\")                   \\\n+  do_signature(putValue_signature,        \"(Ljava\/lang\/Object;JLjava\/lang\/Class;Ljava\/lang\/Object;)V\")                  \\\n@@ -566,0 +568,3 @@\n+  do_name(getValue_name,\"getValue\")             do_name(putValue_name,\"putValue\")                                       \\\n+  do_name(makePrivateBuffer_name,\"makePrivateBuffer\")                                                                   \\\n+  do_name(finishPrivateBuffer_name,\"finishPrivateBuffer\")                                                               \\\n@@ -576,0 +581,1 @@\n+  do_intrinsic(_getValue,           jdk_internal_misc_Unsafe,     getValue_name, getValue_signature,             F_RN)  \\\n@@ -585,0 +591,4 @@\n+  do_intrinsic(_putValue,           jdk_internal_misc_Unsafe,     putValue_name, putValue_signature,             F_RN)  \\\n+                                                                                                                        \\\n+  do_intrinsic(_makePrivateBuffer,  jdk_internal_misc_Unsafe,     makePrivateBuffer_name, object_object_signature, F_RN)   \\\n+  do_intrinsic(_finishPrivateBuffer,  jdk_internal_misc_Unsafe,   finishPrivateBuffer_name, object_object_signature, F_RN) \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -58,0 +58,2 @@\n+  template(java_lang_IdentityObject,                  \"java\/lang\/IdentityObject\")                 \\\n+  template(java_lang_PrimitiveObject,                 \"java\/lang\/PrimitiveObject\")                \\\n@@ -67,0 +69,1 @@\n+  template(java_lang_NonTearable,                     \"java\/lang\/NonTearable\")                    \\\n@@ -484,0 +487,2 @@\n+  template(default_value_name,                        \".default\")                                 \\\n+  template(empty_marker_name,                         \".empty\")                                   \\\n@@ -557,0 +562,1 @@\n+  template(object_object_boolean_signature,           \"(Ljava\/lang\/Object;Ljava\/lang\/Object;)Z\") \\\n@@ -704,0 +710,5 @@\n+  template(java_lang_invoke_ValueBootstrapMethods, \"java\/lang\/invoke\/ValueBootstrapMethods\")                      \\\n+  template(isSubstitutable_name,                   \"isSubstitutable\")                                             \\\n+  template(inlineObjectHashCode_name,              \"inlineObjectHashCode\")                                        \\\n+                                                                                                                  \\\n+  template(jdk_internal_vm_jni_SubElementSelector, \"jdk\/internal\/vm\/jni\/SubElementSelector\")                      \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -250,2 +250,2 @@\n-BufferBlob::BufferBlob(const char* name, int size, CodeBuffer* cb)\n-  : RuntimeBlob(name, cb, sizeof(BufferBlob), size, CodeOffsets::frame_never_safe, 0, NULL)\n+BufferBlob::BufferBlob(const char* name, int header_size, int size, CodeBuffer* cb)\n+  : RuntimeBlob(name, cb, header_size, size, CodeOffsets::frame_never_safe, 0, NULL)\n@@ -262,1 +262,1 @@\n-    blob = new (size) BufferBlob(name, size, cb);\n+    blob = new (size) BufferBlob(name, sizeof(BufferBlob), size, cb);\n@@ -286,0 +286,4 @@\n+BufferBlob::BufferBlob(const char* name, int size, CodeBuffer* cb, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments)\n+  : RuntimeBlob(name, cb, sizeof(BufferBlob), size, frame_complete, frame_size, oop_maps, caller_must_gc_arguments)\n+{}\n+\n@@ -290,2 +294,2 @@\n-AdapterBlob::AdapterBlob(int size, CodeBuffer* cb) :\n-  BufferBlob(\"I2C\/C2I adapters\", size, cb) {\n+AdapterBlob::AdapterBlob(int size, CodeBuffer* cb, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments) :\n+  BufferBlob(\"I2C\/C2I adapters\", size, cb, frame_complete, frame_size, oop_maps, caller_must_gc_arguments) {\n@@ -295,1 +299,1 @@\n-AdapterBlob* AdapterBlob::create(CodeBuffer* cb) {\n+AdapterBlob* AdapterBlob::create(CodeBuffer* cb, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments) {\n@@ -302,1 +306,1 @@\n-    blob = new (size) AdapterBlob(size, cb);\n+    blob = new (size) AdapterBlob(size, cb, frame_complete, frame_size, oop_maps, caller_must_gc_arguments);\n@@ -374,0 +378,25 @@\n+  \/\/ Track memory usage statistic after releasing CodeCache_lock\n+  MemoryService::track_code_cache_memory_usage();\n+\n+  return blob;\n+}\n+\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ Implementation of BufferedInlineTypeBlob\n+BufferedInlineTypeBlob::BufferedInlineTypeBlob(int size, CodeBuffer* cb, int pack_fields_off, int pack_fields_jobject_off, int unpack_fields_off) :\n+  BufferBlob(\"buffered inline type\", sizeof(BufferedInlineTypeBlob), size, cb),\n+  _pack_fields_off(pack_fields_off),\n+  _pack_fields_jobject_off(pack_fields_jobject_off),\n+  _unpack_fields_off(unpack_fields_off) {\n+  CodeCache::commit(this);\n+}\n+\n+BufferedInlineTypeBlob* BufferedInlineTypeBlob::create(CodeBuffer* cb, int pack_fields_off, int pack_fields_jobject_off, int unpack_fields_off) {\n+  ThreadInVMfromUnknown __tiv;  \/\/ get to VM state in case we block on CodeCache_lock\n+\n+  BufferedInlineTypeBlob* blob = NULL;\n+  unsigned int size = CodeBlob::allocation_size(cb, sizeof(BufferedInlineTypeBlob));\n+  {\n+    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    blob = new (size) BufferedInlineTypeBlob(size, cb, pack_fields_off, pack_fields_jobject_off, unpack_fields_off);\n+  }\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":36,"deletions":7,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -150,0 +150,1 @@\n+  virtual bool is_buffered_inline_type_blob() const   { return false; }\n@@ -394,0 +395,1 @@\n+  friend class BufferedInlineTypeBlob;\n@@ -399,1 +401,2 @@\n-  BufferBlob(const char* name, int size, CodeBuffer* cb);\n+  BufferBlob(const char* name, int header_size, int size, CodeBuffer* cb);\n+  BufferBlob(const char* name, int size, CodeBuffer* cb, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments = false);\n@@ -432,1 +435,1 @@\n-  AdapterBlob(int size, CodeBuffer* cb);\n+  AdapterBlob(int size, CodeBuffer* cb, int frame_complete, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments = false);\n@@ -436,1 +439,5 @@\n-  static AdapterBlob* create(CodeBuffer* cb);\n+  static AdapterBlob* create(CodeBuffer* cb,\n+                             int frame_complete,\n+                             int frame_size,\n+                             OopMapSet* oop_maps,\n+                             bool caller_must_gc_arguments = false);\n@@ -440,0 +447,2 @@\n+\n+  bool caller_must_gc_arguments(JavaThread* thread) const { return true; }\n@@ -472,0 +481,22 @@\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ BufferedInlineTypeBlob : used for pack\/unpack handlers\n+\n+class BufferedInlineTypeBlob: public BufferBlob {\n+private:\n+  const int _pack_fields_off;\n+  const int _pack_fields_jobject_off;\n+  const int _unpack_fields_off;\n+\n+  BufferedInlineTypeBlob(int size, CodeBuffer* cb, int pack_fields_off, int pack_fields_jobject_off, int unpack_fields_off);\n+\n+public:\n+  \/\/ Creation\n+  static BufferedInlineTypeBlob* create(CodeBuffer* cb, int pack_fields_off, int pack_fields_jobject_off, int unpack_fields_off);\n+\n+  address pack_fields() const { return code_begin() + _pack_fields_off; }\n+  address pack_fields_jobject() const { return code_begin() + _pack_fields_jobject_off; }\n+  address unpack_fields() const { return code_begin() + _unpack_fields_off; }\n+\n+  \/\/ Typing\n+  virtual bool is_buffered_inline_type_blob() const { return true; }\n+};\n","filename":"src\/hotspot\/share\/code\/codeBlob.hpp","additions":34,"deletions":3,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -247,1 +247,1 @@\n-                                    bool& needs_ic_stub_refill, TRAPS) {\n+                                    bool& needs_ic_stub_refill, bool caller_is_c1, TRAPS) {\n@@ -256,1 +256,1 @@\n-    entry = VtableStubs::find_itable_stub(itable_index);\n+    entry = VtableStubs::find_itable_stub(itable_index, caller_is_c1);\n@@ -279,1 +279,1 @@\n-    entry = VtableStubs::find_vtable_stub(vtable_index);\n+    entry = VtableStubs::find_vtable_stub(vtable_index, caller_is_c1);\n@@ -514,0 +514,1 @@\n+                                           bool caller_is_c1,\n@@ -539,1 +540,1 @@\n-      entry      = method_code->verified_entry_point();\n+      entry      = caller_is_c1 ? method_code->verified_inline_entry_point() : method_code->verified_entry_point();\n@@ -541,1 +542,1 @@\n-      entry      = method_code->entry_point();\n+      entry      = caller_is_c1 ? method_code->inline_entry_point() : method_code->entry_point();\n@@ -555,1 +556,2 @@\n-        info.set_interpreter_entry(method()->get_c2i_entry(), method());\n+        address entry = caller_is_c1 ? method()->get_c2i_inline_entry() : method()->get_c2i_entry();\n+        info.set_interpreter_entry(entry, method());\n@@ -561,1 +563,2 @@\n-      info.set_icholder_entry(method()->get_c2i_unverified_entry(), holder);\n+      entry = (caller_is_c1)? method()->get_c2i_unverified_inline_entry() : method()->get_c2i_unverified_entry();\n+      info.set_icholder_entry(entry, holder);\n@@ -660,1 +663,2 @@\n-void CompiledStaticCall::compute_entry(const methodHandle& m, bool caller_is_nmethod, StaticCallInfo& info) {\n+void CompiledStaticCall::compute_entry(const methodHandle& m, CompiledMethod* caller_nm, StaticCallInfo& info) {\n+  bool caller_is_nmethod = caller_nm->is_nmethod();\n@@ -671,1 +675,5 @@\n-    info._entry  = m_code->verified_entry_point();\n+    if (caller_nm->is_compiled_by_c1()) {\n+      info._entry = m_code->verified_inline_entry_point();\n+    } else {\n+      info._entry = m_code->verified_entry_point();\n+    }\n@@ -677,1 +685,8 @@\n-    info._entry      = m()->get_c2i_entry();\n+\n+    if (caller_nm->is_compiled_by_c1()) {\n+      \/\/ C1 -> interp: values passed as oops\n+      info._entry = m()->get_c2i_inline_entry();\n+    } else {\n+      \/\/ C2 -> interp: values passed fields\n+      info._entry = m()->get_c2i_entry();\n+    }\n","filename":"src\/hotspot\/share\/code\/compiledIC.cpp","additions":25,"deletions":10,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -293,0 +293,1 @@\n+                                              bool        return_scalarized,\n@@ -312,0 +313,1 @@\n+  last_pd->set_return_scalarized(return_scalarized);\n","filename":"src\/hotspot\/share\/code\/debugInfoRec.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -111,0 +111,1 @@\n+                      bool        return_scalarized = false,\n","filename":"src\/hotspot\/share\/code\/debugInfoRec.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -647,0 +647,6 @@\n+\n+    assert(!method->has_scalarized_args(), \"scalarized native wrappers not supported yet\"); \/\/ for the next 3 fields\n+    _inline_entry_point       = _entry_point;\n+    _verified_inline_entry_point = _verified_entry_point;\n+    _verified_inline_ro_entry_point = _verified_entry_point;\n+\n@@ -820,0 +826,3 @@\n+    _inline_entry_point       = code_begin()         + offsets->value(CodeOffsets::Inline_Entry);\n+    _verified_inline_entry_point = code_begin()      + offsets->value(CodeOffsets::Verified_Inline_Entry);\n+    _verified_inline_ro_entry_point = code_begin()   + offsets->value(CodeOffsets::Verified_Inline_Entry_RO);\n@@ -939,0 +948,3 @@\n+static nmethod* _nmethod_to_print = NULL;\n+static const CompiledEntrySignature* _nmethod_to_print_ces = NULL;\n+\n@@ -942,0 +954,6 @@\n+  ResourceMark rm;\n+  CompiledEntrySignature ces(method());\n+  ces.compute_calling_conventions();\n+  \/\/ ces.compute_calling_conventions() needs to grab the ProtectionDomainSet_lock, so we\n+  \/\/ can't do that (inside nmethod::print_entry_parameters) while holding the ttyLocker.\n+  \/\/ Hence we have do compute it here and pass via a global. Yuck.\n@@ -943,0 +961,3 @@\n+  assert(_nmethod_to_print == NULL && _nmethod_to_print_ces == NULL, \"no nesting\");\n+  _nmethod_to_print = this;\n+  _nmethod_to_print_ces = &ces;\n@@ -1022,0 +1043,3 @@\n+\n+  _nmethod_to_print = NULL;\n+  _nmethod_to_print_ces = NULL;\n@@ -3122,0 +3146,1 @@\n+  if (pos == inline_entry_point())                                      label = \"[Inline Entry Point]\";\n@@ -3123,0 +3148,2 @@\n+  if (pos == verified_inline_entry_point())                             label = \"[Verified Inline Entry Point]\";\n+  if (pos == verified_inline_ro_entry_point())                          label = \"[Verified Inline Entry Point (RO)]\";\n@@ -3132,0 +3159,10 @@\n+static int maybe_print_entry_label(outputStream* stream, address pos, address entry, const char* label) {\n+  if (pos == entry) {\n+    stream->bol();\n+    stream->print_cr(\"%s\", label);\n+    return 1;\n+  } else {\n+    return 0;\n+  }\n+}\n+\n@@ -3134,33 +3171,12 @@\n-    const char* label = nmethod_section_label(block_begin);\n-    if (label != NULL) {\n-      stream->bol();\n-      stream->print_cr(\"%s\", label);\n-    }\n-  }\n-\n-  if (block_begin == entry_point()) {\n-    Method* m = method();\n-    if (m != NULL) {\n-      stream->print(\"  # \");\n-      m->print_value_on(stream);\n-      stream->cr();\n-    }\n-    if (m != NULL && !is_osr_method()) {\n-      ResourceMark rm;\n-      int sizeargs = m->size_of_parameters();\n-      BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sizeargs);\n-      VMRegPair* regs   = NEW_RESOURCE_ARRAY(VMRegPair, sizeargs);\n-      {\n-        int sig_index = 0;\n-        if (!m->is_static())\n-          sig_bt[sig_index++] = T_OBJECT; \/\/ 'this'\n-        for (SignatureStream ss(m->signature()); !ss.at_return_type(); ss.next()) {\n-          BasicType t = ss.type();\n-          sig_bt[sig_index++] = t;\n-          if (type2size[t] == 2) {\n-            sig_bt[sig_index++] = T_VOID;\n-          } else {\n-            assert(type2size[t] == 1, \"size is 1 or 2\");\n-          }\n-        }\n-        assert(sig_index == sizeargs, \"\");\n+    int n = 0;\n+    \/\/ Multiple entry points may be at the same position. Print them all.\n+    n += maybe_print_entry_label(stream, block_begin, entry_point(),                    \"[Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, inline_entry_point(),             \"[Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_entry_point(),           \"[Verified Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_entry_point(),    \"[Verified Inline Entry Point]\");\n+    n += maybe_print_entry_label(stream, block_begin, verified_inline_ro_entry_point(), \"[Verified Inline Entry Point (RO)]\");\n+    if (n == 0) {\n+      const char* label = nmethod_section_label(block_begin);\n+      if (label != NULL) {\n+        stream->bol();\n+        stream->print_cr(\"%s\", label);\n@@ -3168,54 +3184,65 @@\n-      const char* spname = \"sp\"; \/\/ make arch-specific?\n-      intptr_t out_preserve = SharedRuntime::java_calling_convention(sig_bt, regs, sizeargs);\n-      int stack_slot_offset = this->frame_size() * wordSize;\n-      int tab1 = 14, tab2 = 24;\n-      int sig_index = 0;\n-      int arg_index = (m->is_static() ? 0 : -1);\n-      bool did_old_sp = false;\n-      for (SignatureStream ss(m->signature()); !ss.at_return_type(); ) {\n-        bool at_this = (arg_index == -1);\n-        bool at_old_sp = false;\n-        BasicType t = (at_this ? T_OBJECT : ss.type());\n-        assert(t == sig_bt[sig_index], \"sigs in sync\");\n-        if (at_this)\n-          stream->print(\"  # this: \");\n-        else\n-          stream->print(\"  # parm%d: \", arg_index);\n-        stream->move_to(tab1);\n-        VMReg fst = regs[sig_index].first();\n-        VMReg snd = regs[sig_index].second();\n-        if (fst->is_reg()) {\n-          stream->print(\"%s\", fst->name());\n-          if (snd->is_valid())  {\n-            stream->print(\":%s\", snd->name());\n-          }\n-        } else if (fst->is_stack()) {\n-          int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n-          if (offset == stack_slot_offset)  at_old_sp = true;\n-          stream->print(\"[%s+0x%x]\", spname, offset);\n-        } else {\n-          stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n-        }\n-        stream->print(\" \");\n-        stream->move_to(tab2);\n-        stream->print(\"= \");\n-        if (at_this) {\n-          m->method_holder()->print_value_on(stream);\n-        } else {\n-          bool did_name = false;\n-          if (!at_this && ss.is_reference()) {\n-            Symbol* name = ss.as_symbol();\n-            name->print_value_on(stream);\n-            did_name = true;\n-          }\n-          if (!did_name)\n-            stream->print(\"%s\", type2name(t));\n-        }\n-        if (at_old_sp) {\n-          stream->print(\"  (%s of caller)\", spname);\n-          did_old_sp = true;\n-        }\n-        stream->cr();\n-        sig_index += type2size[t];\n-        arg_index += 1;\n-        if (!at_this)  ss.next();\n+    }\n+  }\n+\n+  if (_nmethod_to_print != this) {\n+    return;\n+  }\n+  Method* m = method();\n+  if (m == NULL || is_osr_method()) {\n+    return;\n+  }\n+\n+  \/\/ Print the name of the method (only once)\n+  address low = MIN4(entry_point(), verified_entry_point(), verified_inline_entry_point(), verified_inline_ro_entry_point());\n+  low = MIN2(low, inline_entry_point());\n+  assert(low != 0, \"sanity\");\n+  if (block_begin == low) {\n+    stream->print(\"  # \");\n+    m->print_value_on(stream);\n+    stream->cr();\n+  }\n+\n+  \/\/ Print the arguments for the 3 types of verified entry points\n+  const CompiledEntrySignature* ces = _nmethod_to_print_ces;\n+  const GrowableArray<SigEntry>* sig_cc;\n+  const VMRegPair* regs;\n+  if (block_begin == verified_entry_point()) {\n+    sig_cc = &ces->sig_cc();\n+    regs = ces->regs_cc();\n+  } else if (block_begin == verified_inline_entry_point()) {\n+    sig_cc = &ces->sig();\n+    regs = ces->regs();\n+  } else if (block_begin == verified_inline_ro_entry_point()) {\n+    sig_cc = &ces->sig_cc_ro();\n+    regs = ces->regs_cc_ro();\n+  } else {\n+    return;\n+  }\n+\n+  bool has_this = !m->is_static();\n+  if (ces->has_inline_recv() && block_begin == verified_entry_point()) {\n+    \/\/ <this> argument is scalarized for verified_entry_point()\n+    has_this = false;\n+  }\n+  const char* spname = \"sp\"; \/\/ make arch-specific?\n+  int stack_slot_offset = this->frame_size() * wordSize;\n+  int tab1 = 14, tab2 = 24;\n+  int sig_index = 0;\n+  int arg_index = has_this ? -1 : 0;\n+  bool did_old_sp = false;\n+  for (ExtendedSignature sig = ExtendedSignature(sig_cc, SigEntryFilter()); !sig.at_end(); ++sig) {\n+    bool at_this = (arg_index == -1);\n+    bool at_old_sp = false;\n+    BasicType t = (*sig)._bt;\n+    if (at_this) {\n+      stream->print(\"  # this: \");\n+    } else {\n+      stream->print(\"  # parm%d: \", arg_index);\n+    }\n+    stream->move_to(tab1);\n+    VMReg fst = regs[sig_index].first();\n+    VMReg snd = regs[sig_index].second();\n+    if (fst->is_reg()) {\n+      stream->print(\"%s\", fst->name());\n+      if (snd->is_valid())  {\n+        stream->print(\":%s\", snd->name());\n@@ -3223,6 +3250,18 @@\n-      if (!did_old_sp) {\n-        stream->print(\"  # \");\n-        stream->move_to(tab1);\n-        stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n-        stream->print(\"  (%s of caller)\", spname);\n-        stream->cr();\n+    } else if (fst->is_stack()) {\n+      int offset = fst->reg2stack() * VMRegImpl::stack_slot_size + stack_slot_offset;\n+      if (offset == stack_slot_offset)  at_old_sp = true;\n+      stream->print(\"[%s+0x%x]\", spname, offset);\n+    } else {\n+      stream->print(\"reg%d:%d??\", (int)(intptr_t)fst, (int)(intptr_t)snd);\n+    }\n+    stream->print(\" \");\n+    stream->move_to(tab2);\n+    stream->print(\"= \");\n+    if (at_this) {\n+      m->method_holder()->print_value_on(stream);\n+    } else {\n+      bool did_name = false;\n+      if (is_reference_type(t)) {\n+        Symbol* name = (*sig)._symbol;\n+        name->print_value_on(stream);\n+        did_name = true;\n@@ -3230,0 +3269,2 @@\n+      if (!did_name)\n+        stream->print(\"%s\", type2name(t));\n@@ -3231,0 +3272,14 @@\n+    if (at_old_sp) {\n+      stream->print(\"  (%s of caller)\", spname);\n+      did_old_sp = true;\n+    }\n+    stream->cr();\n+    sig_index += type2size[t];\n+    arg_index += 1;\n+  }\n+  if (!did_old_sp) {\n+    stream->print(\"  # \");\n+    stream->move_to(tab1);\n+    stream->print(\"[%s+0x%x]\", spname, stack_slot_offset);\n+    stream->print(\"  (%s of caller)\", spname);\n+    stream->cr();\n@@ -3354,1 +3409,1 @@\n-      st->print(\" {reexecute=%d rethrow=%d return_oop=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop());\n+      st->print(\" {reexecute=%d rethrow=%d return_oop=%d return_scalarized=%d}\", sd->should_reexecute(), sd->rethrow_exception(), sd->return_oop(), sd->return_scalarized());\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":149,"deletions":94,"binary":false,"changes":243,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"compiler\/compilerDefinitions.hpp\"\n@@ -196,0 +197,3 @@\n+  address _inline_entry_point;               \/\/ inline type entry point (unpack all inline type args) with class check\n+  address _verified_inline_entry_point;      \/\/ inline type entry point (unpack all inline type args) without class check\n+  address _verified_inline_ro_entry_point;   \/\/ inline type entry point (unpack receiver only) without class check\n@@ -456,2 +460,5 @@\n-  address entry_point() const                     { return _entry_point;             } \/\/ normal entry point\n-  address verified_entry_point() const            { return _verified_entry_point;    } \/\/ if klass is correct\n+  address entry_point() const                     { return _entry_point;             }        \/\/ normal entry point\n+  address verified_entry_point() const            { return _verified_entry_point;    }        \/\/ normal entry point without class check\n+  address inline_entry_point() const              { return _inline_entry_point; }             \/\/ inline type entry point (unpack all inline type args)\n+  address verified_inline_entry_point() const     { return _verified_inline_entry_point; }    \/\/ inline type entry point (unpack all inline type args) without class check\n+  address verified_inline_ro_entry_point() const  { return _verified_inline_ro_entry_point; } \/\/ inline type entry point (only unpack receiver) without class check\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1279,1 +1279,1 @@\n-          if (vfst.method()->is_static_initializer() ||\n+        if (vfst.method()->is_class_initializer() ||\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n","filename":"src\/hotspot\/share\/compiler\/oopMap.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -211,1 +211,1 @@\n-  assert(bt == T_OBJECT, \"or we shouldn't be here\");\n+  assert(bt == T_OBJECT || bt == T_INLINE_TYPE, \"or we shouldn't be here\");\n@@ -667,1 +667,1 @@\n-void G1BarrierSetC2::eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const {\n+void G1BarrierSetC2::eliminate_gc_barrier(PhaseIterGVN* igvn, Node* node) const {\n@@ -695,1 +695,1 @@\n-    macro->replace_node(cmpx, macro->makecon(TypeInt::CC_EQ));\n+    igvn->replace_node(cmpx, igvn->makecon(TypeInt::CC_EQ));\n@@ -703,18 +703,16 @@\n-      int ind = 1;\n-      if (!this_region->in(ind)->is_IfFalse()) {\n-        ind = 2;\n-      }\n-      if (this_region->in(ind)->is_IfFalse() &&\n-          this_region->in(ind)->in(0)->Opcode() == Op_If) {\n-        Node* bol = this_region->in(ind)->in(0)->in(1);\n-        assert(bol->is_Bool(), \"\");\n-        cmpx = bol->in(1);\n-        if (bol->as_Bool()->_test._test == BoolTest::ne &&\n-            cmpx->is_Cmp() && cmpx->in(2) == macro->intcon(0) &&\n-            cmpx->in(1)->is_Load()) {\n-          Node* adr = cmpx->in(1)->as_Load()->in(MemNode::Address);\n-          const int marking_offset = in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset());\n-          if (adr->is_AddP() && adr->in(AddPNode::Base) == macro->top() &&\n-              adr->in(AddPNode::Address)->Opcode() == Op_ThreadLocal &&\n-              adr->in(AddPNode::Offset) == macro->MakeConX(marking_offset)) {\n-            macro->replace_node(cmpx, macro->makecon(TypeInt::CC_EQ));\n+      for (int i = 1; i < 3; ++i) {\n+        if (this_region->in(i)->is_IfFalse() &&\n+            this_region->in(i)->in(0)->is_If() &&\n+            this_region->in(i)->in(0)->in(1)->is_Bool()) {\n+          Node* bol = this_region->in(i)->in(0)->in(1);\n+          cmpx = bol->in(1);\n+          if (bol->as_Bool()->_test._test == BoolTest::ne &&\n+              cmpx->is_Cmp() && cmpx->in(2) == igvn->intcon(0) &&\n+              cmpx->in(1)->is_Load()) {\n+            Node* adr = cmpx->in(1)->as_Load()->in(MemNode::Address);\n+            const int marking_offset = in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset());\n+            if (adr->is_AddP() && adr->in(AddPNode::Base) == igvn->C->top() &&\n+                adr->in(AddPNode::Address)->Opcode() == Op_ThreadLocal &&\n+                adr->in(AddPNode::Offset) == igvn->MakeConX(marking_offset)) {\n+              igvn->replace_node(cmpx, igvn->makecon(TypeInt::CC_EQ));\n+            }\n@@ -739,1 +737,1 @@\n-    macro->replace_node(cmpx, macro->makecon(TypeInt::CC_EQ));\n+    igvn->replace_node(cmpx, igvn->makecon(TypeInt::CC_EQ));\n@@ -745,1 +743,1 @@\n-  macro->replace_node(node, macro->top());\n+  igvn->replace_node(node, igvn->C->top());\n","filename":"src\/hotspot\/share\/gc\/g1\/c2\/g1BarrierSetC2.cpp","additions":21,"deletions":23,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -508,1 +508,2 @@\n-    if (klass->is_array_klass()) {\n+    \/\/ CMH: Valhalla flat arrays can split this work up, but for now, doesn't\n+    if (klass->is_array_klass() && !klass->is_flatArray_klass()) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -70,0 +70,1 @@\n+#include \"oops\/flatArrayKlass.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -84,2 +84,2 @@\n-    assert(new_obj != NULL ||                      \/\/ is forwarding ptr?\n-           obj->mark() == markWord::prototype() || \/\/ not gc marked?\n+    assert(new_obj != NULL ||                          \/\/ is forwarding ptr?\n+           obj->mark() == markWord::prototype_for_klass(obj->klass()) || \/\/ not gc marked?\n","filename":"src\/hotspot\/share\/gc\/serial\/markSweep.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -128,2 +128,2 @@\n-void CardTableBarrierSetC2::clone(GraphKit* kit, Node* src, Node* dst, Node* size, bool is_array) const {\n-  BarrierSetC2::clone(kit, src, dst, size, is_array);\n+void CardTableBarrierSetC2::clone(GraphKit* kit, Node* src_base, Node* dst_base, Node* countx, bool is_array) const {\n+  BarrierSetC2::clone(kit, src_base, dst_base, countx, is_array);\n@@ -144,1 +144,1 @@\n-                 dst,\n+                 dst_base,\n@@ -161,1 +161,1 @@\n-void CardTableBarrierSetC2::eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const {\n+void CardTableBarrierSetC2::eliminate_gc_barrier(PhaseIterGVN* igvn, Node* node) const {\n@@ -163,10 +163,16 @@\n-  Node *shift = node->unique_out();\n-  Node *addp = shift->unique_out();\n-  for (DUIterator_Last jmin, j = addp->last_outs(jmin); j >= jmin; --j) {\n-    Node *mem = addp->last_out(j);\n-    if (UseCondCardMark && mem->is_Load()) {\n-      assert(mem->Opcode() == Op_LoadB, \"unexpected code shape\");\n-      \/\/ The load is checking if the card has been written so\n-      \/\/ replace it with zero to fold the test.\n-      macro->replace_node(mem, macro->intcon(0));\n-      continue;\n+  for (DUIterator_Last imin, i = node->last_outs(imin); i >= imin; --i) {\n+    Node* shift = node->last_out(i);\n+    for (DUIterator_Last jmin, j = shift->last_outs(jmin); j >= jmin; --j) {\n+      Node* addp = shift->last_out(j);\n+      for (DUIterator_Last kmin, k = addp->last_outs(kmin); k >= kmin; --k) {\n+        Node* mem = addp->last_out(k);\n+        if (UseCondCardMark && mem->is_Load()) {\n+          assert(mem->Opcode() == Op_LoadB, \"unexpected code shape\");\n+          \/\/ The load is checking if the card has been written so\n+          \/\/ replace it with zero to fold the test.\n+          igvn->replace_node(mem, igvn->intcon(0));\n+          continue;\n+        }\n+        assert(mem->is_Store(), \"store required\");\n+        igvn->replace_node(mem, mem->in(MemNode::Memory));\n+      }\n@@ -174,2 +180,0 @@\n-    assert(mem->is_Store(), \"store required\");\n-    macro->replace_node(mem, mem->in(MemNode::Memory));\n@@ -180,1 +184,1 @@\n-  bool is_oop = is_reference_type(type);\n+  bool is_oop = type == T_OBJECT || type == T_ARRAY;\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/cardTableBarrierSetC2.cpp","additions":21,"deletions":17,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -387,6 +387,1 @@\n-  if (UseBiasedLocking) {\n-    oopDesc::set_mark(mem, _klass->prototype_header());\n-  } else {\n-    \/\/ May be bootstrapping\n-    oopDesc::set_mark(mem, markWord::prototype());\n-  }\n+  oopDesc::set_mark(mem, Klass::default_prototype_header(_klass));\n@@ -405,0 +400,6 @@\n+oop ObjBufferAllocator::initialize(HeapWord* mem) const {\n+  oopDesc::set_klass_gap(mem, 0);\n+  return finish(mem);\n+}\n+\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -466,1 +466,1 @@\n-        const TypeTuple* args = n->as_Call()->_tf->domain();\n+        const TypeTuple* args = n->as_Call()->_tf->domain_sig();\n@@ -585,1 +585,1 @@\n-      uint stop = n->is_Call() ? n->as_Call()->tf()->domain()->cnt() : n->req();\n+      uint stop = n->is_Call() ? n->as_Call()->tf()->domain_sig()->cnt() : n->req();\n@@ -805,6 +805,5 @@\n-        CallProjections projs;\n-        c->as_Call()->extract_projections(&projs, true, false);\n-        if (projs.fallthrough_memproj != NULL) {\n-          if (projs.fallthrough_memproj->adr_type() == TypePtr::BOTTOM) {\n-            if (projs.catchall_memproj == NULL) {\n-              mem = projs.fallthrough_memproj;\n+        CallProjections* projs = c->as_Call()->extract_projections(true, false);\n+        if (projs->fallthrough_memproj != NULL) {\n+          if (projs->fallthrough_memproj->adr_type() == TypePtr::BOTTOM) {\n+            if (projs->catchall_memproj == NULL) {\n+              mem = projs->fallthrough_memproj;\n@@ -812,2 +811,2 @@\n-              if (phase->is_dominator(projs.fallthrough_catchproj, ctrl)) {\n-                mem = projs.fallthrough_memproj;\n+              if (phase->is_dominator(projs->fallthrough_catchproj, ctrl)) {\n+                mem = projs->fallthrough_memproj;\n@@ -815,2 +814,2 @@\n-                assert(phase->is_dominator(projs.catchall_catchproj, ctrl), \"one proj must dominate barrier\");\n-                mem = projs.catchall_memproj;\n+                assert(phase->is_dominator(projs->catchall_catchproj, ctrl), \"one proj must dominate barrier\");\n+                mem = projs->catchall_memproj;\n@@ -1085,1 +1084,1 @@\n-static Node* create_phis_on_call_return(Node* ctrl, Node* c, Node* n, Node* n_clone, const CallProjections& projs, PhaseIdealLoop* phase) {\n+static Node* create_phis_on_call_return(Node* ctrl, Node* c, Node* n, Node* n_clone, const CallProjections* projs, PhaseIdealLoop* phase) {\n@@ -1097,1 +1096,1 @@\n-    if (phase->is_dominator(projs.fallthrough_catchproj, in)) {\n+    if (phase->is_dominator(projs->fallthrough_catchproj, in)) {\n@@ -1099,1 +1098,1 @@\n-    } else if (phase->is_dominator(projs.catchall_catchproj, in)) {\n+    } else if (phase->is_dominator(projs->catchall_catchproj, in)) {\n@@ -1215,3 +1214,1 @@\n-      CallProjections projs;\n-      call->extract_projections(&projs, false, false);\n-\n+      CallProjections* projs = call->extract_projections(false, false);\n@@ -1222,2 +1219,2 @@\n-      phase->register_new_node(lrb_clone, projs.catchall_catchproj);\n-      phase->set_ctrl(lrb, projs.fallthrough_catchproj);\n+      phase->register_new_node(lrb_clone, projs->catchall_catchproj);\n+      phase->set_ctrl(lrb, projs->fallthrough_catchproj);\n@@ -1245,1 +1242,1 @@\n-          if (phase->is_dominator(call, c) && phase->is_dominator(c, projs.fallthrough_proj)) {\n+          if (phase->is_dominator(call, c) && phase->is_dominator(c, projs->fallthrough_proj)) {\n@@ -1253,1 +1250,1 @@\n-            phase->register_new_node(u_clone, projs.catchall_catchproj);\n+            phase->register_new_node(u_clone, projs->catchall_catchproj);\n@@ -1255,1 +1252,1 @@\n-            phase->set_ctrl(u, projs.fallthrough_catchproj);\n+            phase->set_ctrl(u, projs->fallthrough_catchproj);\n@@ -1261,1 +1258,1 @@\n-                  if (phase->is_dominator(projs.catchall_catchproj, u->in(0)->in(k))) {\n+                  if (phase->is_dominator(projs->catchall_catchproj, u->in(0)->in(k))) {\n@@ -1264,1 +1261,1 @@\n-                  } else if (!phase->is_dominator(projs.fallthrough_catchproj, u->in(0)->in(k))) {\n+                  } else if (!phase->is_dominator(projs->fallthrough_catchproj, u->in(0)->in(k))) {\n@@ -1271,1 +1268,1 @@\n-              if (phase->is_dominator(projs.catchall_catchproj, c)) {\n+              if (phase->is_dominator(projs->catchall_catchproj, c)) {\n@@ -1276,1 +1273,1 @@\n-              } else if (!phase->is_dominator(projs.fallthrough_catchproj, c)) {\n+              } else if (!phase->is_dominator(projs->fallthrough_catchproj, c)) {\n@@ -2443,5 +2440,4 @@\n-    CallProjections projs;\n-    call->extract_projections(&projs, true, false);\n-    if (projs.catchall_memproj != NULL) {\n-      if (projs.fallthrough_memproj == n) {\n-        c = projs.fallthrough_catchproj;\n+    CallProjections* projs = call->extract_projections(true, false);\n+    if (projs->catchall_memproj != NULL) {\n+      if (projs->fallthrough_memproj == n) {\n+        c = projs->fallthrough_catchproj;\n@@ -2449,2 +2445,2 @@\n-        assert(projs.catchall_memproj == n, \"\");\n-        c = projs.catchall_catchproj;\n+        assert(projs->catchall_memproj == n, \"\");\n+        c = projs->catchall_catchproj;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahSupport.cpp","additions":30,"deletions":34,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -255,0 +255,1 @@\n+  bool is_withfield() const                      { return java_code() == Bytecodes::_withfield; }\n@@ -262,1 +263,2 @@\n-                                                          is_putstatic(); }\n+                                                          is_putstatic()  ||\n+                                                          is_withfield(); }\n@@ -295,0 +297,9 @@\n+class Bytecode_defaultvalue: public Bytecode {\n+ public:\n+  Bytecode_defaultvalue(Method* method, address bcp): Bytecode(method, bcp) { verify(); }\n+  void verify() const { assert(java_code() == Bytecodes::_defaultvalue, \"check defaultvalue\"); }\n+\n+  \/\/ Returns index\n+  long index() const   { return get_index_u2(Bytecodes::_defaultvalue); };\n+};\n+\n","filename":"src\/hotspot\/share\/interpreter\/bytecode.hpp","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -47,0 +48,3 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -77,0 +81,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -222,0 +227,4 @@\n+  if (klass->is_inline_klass()) {\n+    THROW(vmSymbols::java_lang_InstantiationError());\n+  }\n+\n@@ -246,0 +255,179 @@\n+void copy_primitive_argument(intptr_t* addr, Handle instance, int offset, BasicType type) {\n+  switch (type) {\n+  case T_BOOLEAN:\n+    instance()->bool_field_put(offset, (jboolean)*((int*)addr));\n+    break;\n+  case T_CHAR:\n+    instance()->char_field_put(offset, (jchar) *((int*)addr));\n+    break;\n+  case T_FLOAT:\n+    instance()->float_field_put(offset, (jfloat)*((float*)addr));\n+    break;\n+  case T_DOUBLE:\n+    instance()->double_field_put(offset, (jdouble)*((double*)addr));\n+    break;\n+  case T_BYTE:\n+    instance()->byte_field_put(offset, (jbyte)*((int*)addr));\n+    break;\n+  case T_SHORT:\n+    instance()->short_field_put(offset, (jshort)*((int*)addr));\n+    break;\n+  case T_INT:\n+    instance()->int_field_put(offset, (jint)*((int*)addr));\n+    break;\n+  case T_LONG:\n+    instance()->long_field_put(offset, (jlong)*((long long*)addr));\n+    break;\n+  case T_OBJECT:\n+  case T_ARRAY:\n+  case T_INLINE_TYPE:\n+    fatal(\"Should not be handled with this method\");\n+    break;\n+  default:\n+    fatal(\"Unsupported BasicType\");\n+  }\n+}\n+\n+JRT_ENTRY(void, InterpreterRuntime::defaultvalue(JavaThread* current, ConstantPool* pool, int index))\n+  \/\/ Getting the InlineKlass\n+  Klass* k = pool->klass_at(index, CHECK);\n+  if (!k->is_inline_klass()) {\n+    \/\/ inconsistency with 'new' which throws an InstantiationError\n+    \/\/ in the future, defaultvalue will just return null instead of throwing an exception\n+    THROW(vmSymbols::java_lang_IncompatibleClassChangeError());\n+  }\n+  assert(k->is_inline_klass(), \"defaultvalue argument must be the inline type class\");\n+  InlineKlass* vklass = InlineKlass::cast(k);\n+\n+  vklass->initialize(THREAD);\n+  oop res = vklass->default_value();\n+  current->set_vm_result(res);\n+JRT_END\n+\n+JRT_ENTRY(int, InterpreterRuntime::withfield(JavaThread* current, ConstantPoolCache* cp_cache))\n+  LastFrameAccessor last_frame(current);\n+  \/\/ Getting the InlineKlass\n+  int index = ConstantPool::decode_cpcache_index(last_frame.get_index_u2_cpcache(Bytecodes::_withfield));\n+  ConstantPoolCacheEntry* cp_entry = cp_cache->entry_at(index);\n+  assert(cp_entry->is_resolved(Bytecodes::_withfield), \"Should have been resolved\");\n+  Klass* klass = cp_entry->f1_as_klass();\n+  assert(klass->is_inline_klass(), \"withfield only applies to inline types\");\n+  InlineKlass* vklass = InlineKlass::cast(klass);\n+\n+  \/\/ Getting Field information\n+  int offset = cp_entry->f2_as_index();\n+  int field_index = cp_entry->field_index();\n+  int field_offset = cp_entry->f2_as_offset();\n+  Symbol* field_signature = vklass->field_signature(field_index);\n+  BasicType field_type = Signature::basic_type(field_signature);\n+  int return_offset = (type2size[field_type] + type2size[T_OBJECT]) * AbstractInterpreter::stackElementSize;\n+\n+  \/\/ Getting old value\n+  frame& f = last_frame.get_frame();\n+  jint tos_idx = f.interpreter_frame_expression_stack_size() - 1;\n+  int vt_offset = type2size[field_type];\n+  oop old_value = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx - vt_offset);\n+  assert(old_value != NULL && oopDesc::is_oop(old_value) && old_value->is_inline_type(),\"Verifying receiver\");\n+  Handle old_value_h(THREAD, old_value);\n+\n+  \/\/ Creating new value by copying the one passed in argument\n+  instanceOop new_value = vklass->allocate_instance_buffer(\n+      CHECK_((type2size[field_type]) * AbstractInterpreter::stackElementSize));\n+  Handle new_value_h = Handle(THREAD, new_value);\n+  vklass->inline_copy_oop_to_new_oop(old_value_h(), new_value_h());\n+\n+  \/\/ Updating the field specified in arguments\n+  if (field_type == T_ARRAY || field_type == T_OBJECT) {\n+    oop aoop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);\n+    assert(aoop == NULL || oopDesc::is_oop(aoop),\"argument must be a reference type\");\n+    new_value_h()->obj_field_put(field_offset, aoop);\n+  } else if (field_type == T_INLINE_TYPE) {\n+    if (cp_entry->is_inlined()) {\n+      oop vt_oop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);\n+      assert(vt_oop != NULL && oopDesc::is_oop(vt_oop) && vt_oop->is_inline_type(),\"argument must be an inline type\");\n+      InlineKlass* field_vk = InlineKlass::cast(vklass->get_inline_type_field_klass(field_index));\n+      assert(vt_oop != NULL && field_vk == vt_oop->klass(), \"Must match\");\n+      field_vk->write_inlined_field(new_value_h(), offset, vt_oop, CHECK_(return_offset));\n+    } else { \/\/ not inlined\n+      oop voop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);\n+      if (voop == NULL && cp_entry->is_inline_type()) {\n+        THROW_(vmSymbols::java_lang_NullPointerException(), return_offset);\n+      }\n+      assert(voop == NULL || oopDesc::is_oop(voop),\"checking argument\");\n+      new_value_h()->obj_field_put(field_offset, voop);\n+    }\n+  } else { \/\/ not T_OBJECT nor T_ARRAY nor T_INLINE_TYPE\n+    intptr_t* addr = f.interpreter_frame_expression_stack_at(tos_idx);\n+    copy_primitive_argument(addr, new_value_h, field_offset, field_type);\n+  }\n+\n+  \/\/ returning result\n+  current->set_vm_result(new_value_h());\n+  return return_offset;\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::uninitialized_static_inline_type_field(JavaThread* current, oopDesc* mirror, int index))\n+  \/\/ The interpreter tries to access an inline static field that has not been initialized.\n+  \/\/ This situation can happen in different scenarios:\n+  \/\/   1 - if the load or initialization of the field failed during step 8 of\n+  \/\/       the initialization of the holder of the field, in this case the access to the field\n+  \/\/       must fail\n+  \/\/   2 - it can also happen when the initialization of the holder class triggered the initialization of\n+  \/\/       another class which accesses this field in its static initializer, in this case the\n+  \/\/       access must succeed to allow circularity\n+  \/\/ The code below tries to load and initialize the field's class again before returning the default value.\n+  \/\/ If the field was not initialized because of an error, a exception should be thrown.\n+  \/\/ If the class is being initialized, the default value is returned.\n+  instanceHandle mirror_h(THREAD, (instanceOop)mirror);\n+  InstanceKlass* klass = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));\n+  if (klass->is_being_initialized() && klass->is_reentrant_initialization(THREAD)) {\n+    int offset = klass->field_offset(index);\n+    Klass* field_k = klass->get_inline_type_field_klass_or_null(index);\n+    if (field_k == NULL) {\n+      field_k = SystemDictionary::resolve_or_fail(klass->field_signature(index)->fundamental_name(THREAD),\n+          Handle(THREAD, klass->class_loader()),\n+          Handle(THREAD, klass->protection_domain()),\n+          true, CHECK);\n+      assert(field_k != NULL, \"Should have been loaded or an exception thrown above\");\n+      klass->set_inline_type_field_klass(index, field_k);\n+    }\n+    field_k->initialize(CHECK);\n+    oop defaultvalue = InlineKlass::cast(field_k)->default_value();\n+    \/\/ It is safe to initialized the static field because 1) the current thread is the initializing thread\n+    \/\/ and is the only one that can access it, and 2) the field is actually not initialized (i.e. null)\n+    \/\/ otherwise the JVM should not be executing this code.\n+    mirror->obj_field_put(offset, defaultvalue);\n+    current->set_vm_result(defaultvalue);\n+  } else {\n+    assert(klass->is_in_error_state(), \"If not initializing, initialization must have failed to get there\");\n+    ResourceMark rm(THREAD);\n+    const char* desc = \"Could not initialize class \";\n+    const char* className = klass->external_name();\n+    size_t msglen = strlen(desc) + strlen(className) + 1;\n+    char* message = NEW_RESOURCE_ARRAY(char, msglen);\n+    if (NULL == message) {\n+      \/\/ Out of memory: can't create detailed error message\n+      THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), className);\n+    } else {\n+      jio_snprintf(message, msglen, \"%s%s\", desc, className);\n+      THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), message);\n+    }\n+  }\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::read_inlined_field(JavaThread* current, oopDesc* obj, int index, Klass* field_holder))\n+  Handle obj_h(THREAD, obj);\n+\n+  assert(oopDesc::is_oop(obj), \"Sanity check\");\n+\n+  assert(field_holder->is_instance_klass(), \"Sanity check\");\n+  InstanceKlass* klass = InstanceKlass::cast(field_holder);\n+\n+  assert(klass->field_is_inlined(index), \"Sanity check\");\n+\n+  InlineKlass* field_vklass = InlineKlass::cast(klass->get_inline_type_field_klass(index));\n+  assert(field_vklass->is_initialized(), \"Must be initialized at this point\");\n+\n+  oop res = field_vklass->read_inlined_field(obj_h(), klass->field_offset(index), CHECK);\n+  current->set_vm_result(res);\n+JRT_END\n@@ -255,1 +443,8 @@\n-  objArrayOop obj = oopFactory::new_objArray(klass, size, CHECK);\n+  bool      is_qtype_desc = pool->tag_at(index).is_Qdescriptor_klass();\n+  arrayOop obj;\n+  if ((!klass->is_array_klass()) && is_qtype_desc) { \/\/ Logically creates elements, ensure klass init\n+    klass->initialize(CHECK);\n+    obj = oopFactory::new_flatArray(klass, size, CHECK);\n+  } else {\n+    obj = oopFactory::new_objArray(klass, size, CHECK);\n+  }\n@@ -259,0 +454,10 @@\n+JRT_ENTRY(void, InterpreterRuntime::value_array_load(JavaThread* current, arrayOopDesc* array, int index))\n+  flatArrayHandle vah(current, (flatArrayOop)array);\n+  oop value_holder = flatArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK);\n+  current->set_vm_result(value_holder);\n+JRT_END\n+\n+JRT_ENTRY(void, InterpreterRuntime::value_array_store(JavaThread* current, void* val, arrayOopDesc* array, int index))\n+  assert(val != NULL, \"can't store null into flat array\");\n+  ((flatArrayOop)array)->value_copy_to_index(cast_to_oop(val), index);\n+JRT_END\n@@ -264,2 +469,3 @@\n-  int          i = last_frame.get_index_u2(Bytecodes::_multianewarray);\n-  Klass* klass   = constants->klass_at(i, CHECK);\n+  int i = last_frame.get_index_u2(Bytecodes::_multianewarray);\n+  Klass* klass = constants->klass_at(i, CHECK);\n+  bool is_qtype = klass->name()->is_Q_array_signature();\n@@ -270,0 +476,4 @@\n+  if (is_qtype) { \/\/ Logically creates elements, ensure klass init\n+    klass->initialize(CHECK);\n+  }\n+\n@@ -294,0 +504,23 @@\n+JRT_ENTRY(jboolean, InterpreterRuntime::is_substitutable(JavaThread* current, oopDesc* aobj, oopDesc* bobj))\n+  assert(oopDesc::is_oop(aobj) && oopDesc::is_oop(bobj), \"must be valid oops\");\n+\n+  Handle ha(THREAD, aobj);\n+  Handle hb(THREAD, bobj);\n+  JavaValue result(T_BOOLEAN);\n+  JavaCallArguments args;\n+  args.push_oop(ha);\n+  args.push_oop(hb);\n+  methodHandle method(current, Universe::is_substitutable_method());\n+  JavaCalls::call(&result, method, &args, THREAD);\n+  if (HAS_PENDING_EXCEPTION) {\n+    \/\/ Something really bad happened because isSubstitutable() should not throw exceptions\n+    \/\/ If it is an error, just let it propagate\n+    \/\/ If it is an exception, wrap it into an InternalError\n+    if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+      Handle e(THREAD, PENDING_EXCEPTION);\n+      CLEAR_PENDING_EXCEPTION;\n+      THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in substitutability test\", e, false);\n+    }\n+  }\n+  return result.get_jboolean();\n+JRT_END\n@@ -620,0 +853,4 @@\n+JRT_ENTRY(void, InterpreterRuntime::throw_InstantiationError(JavaThread* current))\n+  THROW(vmSymbols::java_lang_InstantiationError());\n+JRT_END\n+\n@@ -653,1 +890,1 @@\n-                    bytecode == Bytecodes::_putstatic);\n+                    bytecode == Bytecodes::_putstatic || bytecode == Bytecodes::_withfield);\n@@ -655,0 +892,1 @@\n+  bool is_inline_type  = bytecode == Bytecodes::_withfield;\n@@ -699,3 +937,9 @@\n-    get_code = ((is_static) ? Bytecodes::_getstatic : Bytecodes::_getfield);\n-    if ((is_put && !has_initialized_final_update) || !info.access_flags().is_final()) {\n-      put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);\n+    if (is_static) {\n+      get_code = Bytecodes::_getstatic;\n+    } else {\n+      get_code = Bytecodes::_getfield;\n+    }\n+    if (is_put && is_inline_type) {\n+        put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_withfield);\n+    } else if ((is_put && !has_initialized_final_update) || !info.access_flags().is_final()) {\n+        put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);\n@@ -713,1 +957,3 @@\n-    info.access_flags().is_volatile()\n+    info.access_flags().is_volatile(),\n+    info.is_inlined(),\n+    info.is_inline_type()\n@@ -949,0 +1195,1 @@\n+  case Bytecodes::_withfield:\n@@ -1167,0 +1414,1 @@\n+  bool is_inlined = cp_entry->is_inlined();\n@@ -1175,1 +1423,1 @@\n-  jfieldID fid = jfieldIDWorkaround::to_jfieldID(cp_entry_f1, cp_entry->f2_as_index(), is_static);\n+  jfieldID fid = jfieldIDWorkaround::to_jfieldID(cp_entry_f1, cp_entry->f2_as_index(), is_static, is_inlined);\n@@ -1205,0 +1453,6 @@\n+\n+  \/\/ Both Q-signatures and L-signatures are mapped to atos\n+  if (cp_entry->flag_state() == atos && ik->field_signature(index)->is_Q_signature()) {\n+    sig_type = JVM_SIGNATURE_INLINE_TYPE;\n+  }\n+\n@@ -1206,0 +1460,1 @@\n+  bool is_inlined = cp_entry->is_inlined();\n@@ -1208,1 +1463,1 @@\n-  jfieldID fid = jfieldIDWorkaround::to_jfieldID(ik, cp_entry->f2_as_index(), is_static);\n+  jfieldID fid = jfieldIDWorkaround::to_jfieldID(ik, cp_entry->f2_as_index(), is_static, is_inlined);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":265,"deletions":10,"binary":false,"changes":275,"status":"modified"},{"patch":"@@ -64,1 +64,1 @@\n-  static void    anewarray     (JavaThread* current, ConstantPool* pool, int index, jint size);\n+  static void    anewarray     (JavaThread* threcurrentad, ConstantPool* pool, int index, jint size);\n@@ -67,0 +67,10 @@\n+  static void    defaultvalue  (JavaThread* current, ConstantPool* pool, int index);\n+  static int     withfield     (JavaThread* current, ConstantPoolCache* cp_cache);\n+  static void    uninitialized_static_inline_type_field(JavaThread* current, oopDesc* mirror, int offset);\n+  static void    write_heap_copy (JavaThread* current, oopDesc* value, int offset, oopDesc* rcv);\n+  static void    read_inlined_field(JavaThread* current, oopDesc* value, int index, Klass* field_holder);\n+\n+  static void value_array_load(JavaThread* current, arrayOopDesc* array, int index);\n+  static void value_array_store(JavaThread* current, void* val, arrayOopDesc* array, int index);\n+\n+  static jboolean is_substitutable(JavaThread* current, oopDesc* aobj, oopDesc* bobj);\n@@ -78,0 +88,1 @@\n+  static void    throw_InstantiationError(JavaThread* current);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.hpp","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -956,0 +956,1 @@\n+         byte == Bytecodes::_withfield ||\n@@ -960,1 +961,2 @@\n-  bool is_put    = (byte == Bytecodes::_putfield  || byte == Bytecodes::_putstatic || byte == Bytecodes::_nofast_putfield);\n+  bool is_put    = (byte == Bytecodes::_putfield  || byte == Bytecodes::_putstatic ||\n+                    byte == Bytecodes::_nofast_putfield || byte == Bytecodes::_withfield);\n@@ -998,0 +1000,2 @@\n+    \/\/ (3) by withfield when field is in a value type and the\n+    \/\/     selected class and current class are nest mates.\n@@ -1001,6 +1005,15 @@\n-        ResourceMark rm(THREAD);\n-        stringStream ss;\n-        ss.print(\"Update to %s final field %s.%s attempted from a different class (%s) than the field's declaring class\",\n-                 is_static ? \"static\" : \"non-static\", resolved_klass->external_name(), fd.name()->as_C_string(),\n-                current_klass->external_name());\n-        THROW_MSG(vmSymbols::java_lang_IllegalAccessError(), ss.as_string());\n+        \/\/ If byte code is a withfield check if they are nestmates.\n+        bool are_nestmates = false;\n+        if (sel_klass->is_instance_klass() &&\n+            InstanceKlass::cast(sel_klass)->is_inline_klass() &&\n+            current_klass->is_instance_klass()) {\n+          are_nestmates = InstanceKlass::cast(current_klass)->has_nestmate_access_to(InstanceKlass::cast(sel_klass), THREAD);\n+        }\n+        if (!are_nestmates) {\n+          ResourceMark rm(THREAD);\n+          stringStream ss;\n+          ss.print(\"Update to %s final field %s.%s attempted from a different class (%s) than the field's declaring class\",\n+                   is_static ? \"static\" : \"non-static\", resolved_klass->external_name(), fd.name()->as_C_string(),\n+                    current_klass->external_name());\n+          THROW_MSG(vmSymbols::java_lang_IllegalAccessError(), ss.as_string());\n+        }\n@@ -1014,1 +1027,1 @@\n-                                                   !m->is_static_initializer());\n+                                                   !m->is_class_initializer());\n@@ -1017,1 +1030,1 @@\n-                                                     !m->is_object_initializer());\n+                                                     !m->is_object_constructor());\n@@ -1137,0 +1150,2 @@\n+  \/\/ Since this method is never inherited from a super, any appearance here under\n+  \/\/ the wrong class would be an error.\n@@ -1210,1 +1225,1 @@\n-      \/\/ check if the method is not <init>\n+      \/\/ check if the method is not <init>, which is never inherited\n@@ -1630,2 +1645,2 @@\n-                             const methodHandle& attached_method,\n-                             Bytecodes::Code byte, TRAPS) {\n+                                  const methodHandle& attached_method,\n+                                  Bytecodes::Code byte, bool check_null_and_abstract, TRAPS) {\n@@ -1636,0 +1651,1 @@\n+  Klass* recv_klass = recv.is_null() ? defc : recv->klass();\n@@ -1638,2 +1654,2 @@\n-      resolve_virtual_call(result, recv, recv->klass(), link_info,\n-                           \/*check_null_and_abstract=*\/true, CHECK);\n+      resolve_virtual_call(result, recv, recv_klass, link_info,\n+                           check_null_and_abstract, CHECK);\n@@ -1642,2 +1658,2 @@\n-      resolve_interface_call(result, recv, recv->klass(), link_info,\n-                             \/*check_null_and_abstract=*\/true, CHECK);\n+      resolve_interface_call(result, recv, recv_klass, link_info,\n+                             check_null_and_abstract, CHECK);\n","filename":"src\/hotspot\/share\/interpreter\/linkResolver.cpp","additions":32,"deletions":16,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -338,1 +338,1 @@\n-                             Bytecodes::Code byte, TRAPS);\n+                             Bytecodes::Code byte, bool check_null_and_abstract, TRAPS);\n","filename":"src\/hotspot\/share\/interpreter\/linkResolver.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -281,1 +281,1 @@\n-    bool v2 = vars[i].is_reference()  ? true : false;\n+    bool v2 = vars[i].is_reference();\n@@ -290,1 +290,1 @@\n-    bool v2 = stack[j].is_reference() ? true : false;\n+    bool v2 = stack[j].is_reference();\n@@ -371,1 +371,1 @@\n-    if ( cell->is_reference()) {\n+    if (cell->is_reference()) {\n","filename":"src\/hotspot\/share\/interpreter\/oopMapCache.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1206,1 +1206,1 @@\n-  _debug_recorder->describe_scope(pc_offset, method, NULL, bci, reexecute, throw_exception, is_mh_invoke, is_opt_native, return_oop,\n+  _debug_recorder->describe_scope(pc_offset, method, NULL, bci, reexecute, throw_exception, is_mh_invoke, is_opt_native, return_oop, false,\n@@ -1373,0 +1373,2 @@\n+        _offsets.set_value(CodeOffsets::Verified_Inline_Entry, pc_offset);\n+        _offsets.set_value(CodeOffsets::Verified_Inline_Entry_RO, pc_offset);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCodeInstaller.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1278,1 +1278,1 @@\n-              Deoptimization::reassign_fields(fst.current(), fst.register_map(), objects, realloc_failures, false);\n+              Deoptimization::reassign_fields(fst.current(), fst.register_map(), objects, realloc_failures, false, CHECK_NULL);\n@@ -1538,1 +1538,1 @@\n-  Deoptimization::reassign_fields(fstAfterDeopt.current(), fstAfterDeopt.register_map(), objects, realloc_failures, false);\n+  Deoptimization::reassign_fields(fstAfterDeopt.current(), fstAfterDeopt.register_map(), objects, realloc_failures, false, THREAD);\n@@ -1868,1 +1868,1 @@\n-    if (m->is_initializer() && !m->is_static()) {\n+    if (m->is_object_constructor()) {\n@@ -1898,1 +1898,1 @@\n-    if (!m->is_initializer() && !m->is_overpass()) {\n+    if (!(m->is_object_constructor() || m->is_class_initializer()) && !m->is_overpass()) {\n@@ -2519,2 +2519,1 @@\n-  if (m->is_initializer()) {\n-    if (m->is_static_initializer()) {\n+  if (m->is_class_initializer()) {\n@@ -2523,1 +2522,2 @@\n-    }\n+  }\n+  else if (m->is_object_constructor() || m->is_static_init_factory()) {\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -162,1 +162,1 @@\n-  nonstatic_field(InstanceKlass,               _misc_flags,                                   u2)                                    \\\n+  nonstatic_field(InstanceKlass,               _misc_flags,                                   u4)                                    \\\n@@ -534,0 +534,2 @@\n+  declare_constant(DataLayout::array_load_store_data_tag)                 \\\n+  declare_constant(DataLayout::acmp_data_tag)                             \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -193,0 +193,1 @@\n+  LOG_TAG(valuetypes) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -157,0 +157,1 @@\n+  mtValueTypes,        \/\/ memory for buffered value types\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -440,1 +440,0 @@\n-    assert(type == _method_entry_ref, \"only special type allowed for now\");\n@@ -443,1 +442,1 @@\n-    _builder->add_special_ref(type, src_obj, field_offset);\n+    _builder->add_special_ref(type, src_obj, field_offset, ref->size() * BytesPerWord);\n@@ -487,4 +486,0 @@\n-void ArchiveBuilder::add_special_ref(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset) {\n-  _special_refs->append(SpecialRefInfo(type, src_obj, field_offset));\n-}\n-\n@@ -681,2 +676,18 @@\n-    assert(s.type() == MetaspaceClosure::_method_entry_ref, \"only special type allowed for now\");\n-    assert(*src_p == *dst_p, \"must be a copy\");\n+\n+    MetaspaceClosure::assert_valid(s.type());\n+    switch (s.type()) {\n+    case MetaspaceClosure::_method_entry_ref:\n+      assert(*src_p == *dst_p, \"must be a copy\");\n+      break;\n+    case MetaspaceClosure::_internal_pointer_ref:\n+      {\n+        \/\/ *src_p points to a location inside src_obj. Let's make *dst_p point to\n+        \/\/ the same location inside dst_obj.\n+        size_t off = pointer_delta(*((address*)src_p), src_obj, sizeof(u1));\n+        assert(off < s.src_obj_size_in_bytes(), \"must point to internal address\");\n+        *((address*)dst_p) = dst_obj + off;\n+      }\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.cpp","additions":19,"deletions":8,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -103,0 +103,1 @@\n+    DEBUG_ONLY(size_t _src_obj_size_in_bytes;)\n@@ -106,2 +107,4 @@\n-    SpecialRefInfo(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset)\n-      : _type(type), _src_obj(src_obj), _field_offset(field_offset) {}\n+    SpecialRefInfo(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset, size_t src_obj_size_in_bytes)\n+      : _type(type), _src_obj(src_obj), _field_offset(field_offset) {\n+      DEBUG_ONLY(_src_obj_size_in_bytes = src_obj_size_in_bytes);\n+    }\n@@ -112,0 +115,2 @@\n+\n+    DEBUG_ONLY(size_t src_obj_size_in_bytes() const { return _src_obj_size_in_bytes; })\n@@ -339,1 +344,3 @@\n-  void add_special_ref(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset);\n+  void add_special_ref(MetaspaceClosure::SpecialRef type, address src_obj, size_t field_offset, size_t src_obj_size_in_bytes) {\n+    _special_refs->append(SpecialRefInfo(type, src_obj, field_offset, src_obj_size_in_bytes));\n+  }\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.hpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -140,1 +140,1 @@\n-  assert(!p->mark().has_bias_pattern(),\n+  assert(!UseBiasedLocking || !p->mark().has_bias_pattern(),\n@@ -278,1 +278,1 @@\n-    archived_oop->set_mark(markWord::prototype().copy_set_hash(hash_original));\n+    archived_oop->set_mark(markWord::prototype_for_klass(archived_oop->klass()).copy_set_hash(hash_original));\n","filename":"src\/hotspot\/share\/memory\/heapShared.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -59,0 +59,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n","filename":"src\/hotspot\/share\/memory\/metaspaceShared.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -124,0 +124,2 @@\n+LatestMethodCache* Universe::_is_substitutable_cache  = NULL;\n+LatestMethodCache* Universe::_inline_type_hash_code_cache = NULL;\n@@ -132,0 +134,2 @@\n+Array<InstanceKlass*>* Universe::_the_single_IdentityObject_klass_array = NULL;\n+Array<InstanceKlass*>* Universe::_the_single_PrimitiveObject_klass_array = NULL;\n@@ -222,0 +226,2 @@\n+  it->push(&_the_single_IdentityObject_klass_array);\n+  it->push(&_the_single_PrimitiveObject_klass_array);\n@@ -228,0 +234,2 @@\n+  _is_substitutable_cache->metaspace_pointers_do(it);\n+  _inline_type_hash_code_cache->metaspace_pointers_do(it);\n@@ -270,0 +278,2 @@\n+  f->do_ptr((void**)&_the_single_IdentityObject_klass_array);\n+  f->do_ptr((void**)&_the_single_PrimitiveObject_klass_array);\n@@ -275,0 +285,2 @@\n+  _is_substitutable_cache->serialize(f);\n+  _inline_type_hash_code_cache->serialize(f);\n@@ -324,1 +336,1 @@\n-        _the_array_interfaces_array     = MetadataFactory::new_array<Klass*>(null_cld, 2, NULL, CHECK);\n+        _the_array_interfaces_array     = MetadataFactory::new_array<Klass*>(null_cld, 3, NULL, CHECK);\n@@ -351,0 +363,7 @@\n+      assert(_the_array_interfaces_array->at(2) ==\n+                   vmClasses::IdentityObject_klass(), \"u3\");\n+\n+      assert(_the_single_IdentityObject_klass_array->at(0) ==\n+          vmClasses::IdentityObject_klass(), \"u3\");\n+      assert(_the_single_PrimitiveObject_klass_array->at(0) ==\n+          vmClasses::PrimitiveObject_klass(), \"u3\");\n@@ -357,0 +376,1 @@\n+      _the_array_interfaces_array->at_put(2, vmClasses::IdentityObject_klass());\n@@ -461,0 +481,17 @@\n+void Universe::initialize_the_single_IdentityObject_klass_array(InstanceKlass* ik, TRAPS) {\n+    assert(_the_single_IdentityObject_klass_array == NULL, \"Must not be initialized twice\");\n+    assert(ik->name() == vmSymbols::java_lang_IdentityObject(), \"Must be\");\n+    Array<InstanceKlass*>* array = MetadataFactory::new_array<InstanceKlass*>(ik->class_loader_data(), 1, NULL, CHECK);\n+    array->at_put(0, ik);\n+    _the_single_IdentityObject_klass_array = array;\n+}\n+\n+void Universe::initialize_the_single_PrimitiveObject_klass_array(InstanceKlass* ik, TRAPS) {\n+    assert(_the_single_PrimitiveObject_klass_array == NULL, \"Must not be initialized twice\");\n+    assert(ik->name() == vmSymbols::java_lang_PrimitiveObject(), \"Must be\");\n+    Array<InstanceKlass*>* array = MetadataFactory::new_array<InstanceKlass*>(ik->class_loader_data(), 1, NULL, CHECK);\n+    array->at_put(0, ik);\n+    _the_single_PrimitiveObject_klass_array = array;\n+}\n+\n+\n@@ -752,1 +789,0 @@\n-\n@@ -775,0 +811,2 @@\n+  Universe::_is_substitutable_cache = new LatestMethodCache();\n+  Universe::_inline_type_hash_code_cache = new LatestMethodCache();\n@@ -933,0 +971,11 @@\n+\n+  \/\/ Set up substitutability testing\n+  ResourceMark rm;\n+  initialize_known_method(_is_substitutable_cache,\n+                          vmClasses::ValueBootstrapMethods_klass(),\n+                          vmSymbols::isSubstitutable_name()->as_C_string(),\n+                          vmSymbols::object_object_boolean_signature(), true, CHECK);\n+  initialize_known_method(_inline_type_hash_code_cache,\n+                          vmClasses::ValueBootstrapMethods_klass(),\n+                          vmSymbols::inlineObjectHashCode_name()->as_C_string(),\n+                          vmSymbols::object_int_signature(), true, CHECK);\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":51,"deletions":2,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -120,0 +120,2 @@\n+  static LatestMethodCache* _is_substitutable_cache;   \/\/ ValueBootstrapMethods.isSubstitutable() method\n+  static LatestMethodCache* _inline_type_hash_code_cache;  \/\/ ValueBootstrapMethods.inlineObjectHashCode() method\n@@ -125,0 +127,2 @@\n+  static Array<InstanceKlass*>* _the_single_IdentityObject_klass_array;  \/\/ Common single interface array for IdentityObjects\n+  static Array<InstanceKlass*>* _the_single_PrimitiveObject_klass_array; \/\/ Common single interface array for PrimitiveObjects\n@@ -147,0 +151,1 @@\n+\n@@ -260,0 +265,3 @@\n+  static Method*      is_substitutable_method()       { return _is_substitutable_cache->get_method(); }\n+  static Method*      inline_type_hash_code_method()  { return _inline_type_hash_code_cache->get_method(); }\n+\n@@ -284,0 +292,12 @@\n+  static Array<InstanceKlass*>*  the_single_IdentityObject_klass_array() {\n+    assert(_the_single_IdentityObject_klass_array != NULL, \"Must be initialized before use\");\n+    assert(_the_single_IdentityObject_klass_array->length() == 1, \"Sanity check\");\n+    return _the_single_IdentityObject_klass_array;\n+  }\n+  static void initialize_the_single_IdentityObject_klass_array(InstanceKlass* ik, TRAPS);\n+  static Array<InstanceKlass*>*  the_single_PrimitiveObject_klass_array() {\n+    assert(_the_single_PrimitiveObject_klass_array != NULL, \"Must be initialized before use\");\n+    assert(_the_single_PrimitiveObject_klass_array->length() == 1, \"Sanity check\");\n+    return _the_single_PrimitiveObject_klass_array;\n+  }\n+  static void initialize_the_single_PrimitiveObject_klass_array(InstanceKlass* ik, TRAPS);\n","filename":"src\/hotspot\/share\/memory\/universe.hpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"classfile\/symbolTable.hpp\"\n@@ -36,0 +37,1 @@\n+#include \"oops\/objArrayKlass.hpp\"\n@@ -101,0 +103,24 @@\n+Symbol* ArrayKlass::create_element_klass_array_name(Klass* element_klass, TRAPS) {\n+  ResourceMark rm(THREAD);\n+  Symbol* name = NULL;\n+  bool is_qtype = element_klass->is_inline_klass();\n+  char *name_str = element_klass->name()->as_C_string();\n+  int len = element_klass->name()->utf8_length();\n+  char *new_str = NEW_RESOURCE_ARRAY(char, len + 4);\n+  int idx = 0;\n+  new_str[idx++] = JVM_SIGNATURE_ARRAY;\n+  if (element_klass->is_instance_klass()) { \/\/ it could be an array or simple type\n+    if (is_qtype) {\n+      new_str[idx++] = JVM_SIGNATURE_INLINE_TYPE;\n+    } else {\n+      new_str[idx++] = JVM_SIGNATURE_CLASS;\n+    }\n+  }\n+  memcpy(&new_str[idx], name_str, len * sizeof(char));\n+  idx += len;\n+  if (element_klass->is_instance_klass()) {\n+    new_str[idx++] = JVM_SIGNATURE_ENDCLASS;\n+  }\n+  new_str[idx++] = '\\0';\n+  return SymbolTable::new_symbol(new_str);\n+}\n@@ -156,0 +182,4 @@\n+oop ArrayKlass::component_mirror() const {\n+  return java_lang_Class::component_mirror(java_mirror());\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":30,"deletions":0,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -45,0 +45,7 @@\n+  Klass* _element_klass;            \/\/ The klass of the elements of this array type\n+                                    \/\/ The element type must be registered for both object arrays\n+                                    \/\/ (incl. object arrays with value type elements) and value type\n+                                    \/\/ arrays containing flattened value types. However, the element\n+                                    \/\/ type must not be registered for arrays of primitive types.\n+                                    \/\/ TODO: Update the class hierarchy so that element klass appears\n+                                    \/\/ only in array that contain non-primitive types.\n@@ -51,0 +58,3 @@\n+  \/\/ Create array_name for element klass\n+  static Symbol* create_element_klass_array_name(Klass* element_klass, TRAPS);\n+\n@@ -52,0 +62,11 @@\n+  \/\/ Instance variables\n+  virtual Klass* element_klass() const      { return _element_klass; }\n+  virtual void set_element_klass(Klass* k)  { _element_klass = k; }\n+\n+  \/\/ Compiler\/Interpreter offset\n+  static ByteSize element_klass_offset() { return in_ByteSize(offset_of(ArrayKlass, _element_klass)); }\n+\n+  \/\/ Are loads and stores to this concrete array type atomic?\n+  \/\/ Note that Object[] is naturally atomic, but its subtypes may not be.\n+  virtual bool element_access_is_atomic() { return true; }\n+\n@@ -102,0 +123,2 @@\n+  oop component_mirror() const;\n+\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.hpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -232,1 +233,1 @@\n-      \/\/ All of these should have been reverted back to ClassIndex before calling\n+      \/\/ All of these should have been reverted back to Unresolved before calling\n@@ -256,0 +257,1 @@\n+  jbyte qdesc_bit = (name->is_Q_signature()) ? (jbyte) JVM_CONSTANT_QDescBit : 0;\n@@ -257,1 +259,1 @@\n-    release_tag_at_put(class_index, JVM_CONSTANT_Class);\n+    release_tag_at_put(class_index, JVM_CONSTANT_Class | qdesc_bit);\n@@ -259,1 +261,1 @@\n-    release_tag_at_put(class_index, JVM_CONSTANT_UnresolvedClass);\n+    release_tag_at_put(class_index, JVM_CONSTANT_UnresolvedClass | qdesc_bit);\n@@ -273,0 +275,1 @@\n+  assert(!k->name()->is_Q_signature(), \"Q-type without JVM_CONSTANT_QDescBit\");\n@@ -409,0 +412,1 @@\n+    jbyte qdesc_bit = tag_at(index).is_Qdescriptor_klass() ? (jbyte) JVM_CONSTANT_QDescBit : 0;\n@@ -410,1 +414,1 @@\n-      tag_at_put(index, JVM_CONSTANT_UnresolvedClass);\n+      tag_at_put(index, JVM_CONSTANT_UnresolvedClass | qdesc_bit);\n@@ -435,1 +439,1 @@\n-        tag_at_put(index, JVM_CONSTANT_UnresolvedClass);\n+        tag_at_put(index, JVM_CONSTANT_UnresolvedClass | qdesc_bit);\n@@ -485,0 +489,6 @@\n+void check_is_inline_type(Klass* k, TRAPS) {\n+  if (!k->is_inline_klass()) {\n+    THROW(vmSymbols::java_lang_IncompatibleClassChangeError());\n+  }\n+}\n+\n@@ -522,0 +532,5 @@\n+  bool inline_type_signature = false;\n+  if (name->is_Q_signature()) {\n+    name = name->fundamental_name(THREAD);\n+    inline_type_signature = true;\n+  }\n@@ -531,0 +546,3 @@\n+  if (inline_type_signature) {\n+    name->decrement_refcount();\n+  }\n@@ -539,0 +557,16 @@\n+  if (!HAS_PENDING_EXCEPTION && inline_type_signature) {\n+    check_is_inline_type(k, THREAD);\n+  }\n+\n+  if (!HAS_PENDING_EXCEPTION) {\n+    Klass* bottom_klass = NULL;\n+    if (k->is_objArray_klass()) {\n+      bottom_klass = ObjArrayKlass::cast(k)->bottom_klass();\n+      assert(bottom_klass != NULL, \"Should be set\");\n+      assert(bottom_klass->is_instance_klass() || bottom_klass->is_typeArray_klass(), \"Sanity check\");\n+    } else if (k->is_flatArray_klass()) {\n+      bottom_klass = FlatArrayKlass::cast(k)->element_klass();\n+      assert(bottom_klass != NULL, \"Should be set\");\n+    }\n+  }\n+\n@@ -542,1 +576,5 @@\n-    save_and_throw_exception(this_cp, which, constantTag(JVM_CONSTANT_UnresolvedClass), CHECK_NULL);\n+    jbyte tag = JVM_CONSTANT_UnresolvedClass;\n+    if (this_cp->tag_at(which).is_Qdescriptor_klass()) {\n+      tag |= JVM_CONSTANT_QDescBit;\n+    }\n+    save_and_throw_exception(this_cp, which, constantTag(tag), CHECK_NULL);\n@@ -561,0 +599,4 @@\n+  jbyte tag = JVM_CONSTANT_Class;\n+  if (this_cp->tag_at(which).is_Qdescriptor_klass()) {\n+    tag |= JVM_CONSTANT_QDescBit;\n+  }\n@@ -565,1 +607,1 @@\n-                                  (jbyte)JVM_CONSTANT_Class);\n+                                  tag);\n@@ -1923,0 +1965,6 @@\n+      case (JVM_CONSTANT_Class | JVM_CONSTANT_QDescBit): {\n+        idx1 = Bytes::get_Java_u2(bytes);\n+        printf(\"qclass        #%03d\", idx1);\n+        ent_size = 2;\n+        break;\n+      }\n@@ -1965,0 +2013,4 @@\n+      case (JVM_CONSTANT_UnresolvedClass | JVM_CONSTANT_QDescBit): {\n+        printf(\"UnresolvedQClass: %s\", WARN_MSG);\n+        break;\n+      }\n@@ -2136,0 +2188,1 @@\n+        assert(!tag_at(idx).is_Qdescriptor_klass(), \"Failed to encode QDesc\");\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":60,"deletions":7,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -307,1 +307,1 @@\n-  \/\/ For temporary use while constructing constant pool\n+  \/\/ For temporary use while constructing constant pool. Used during a retransform\/class redefinition as well.\n@@ -317,0 +317,9 @@\n+  void unresolved_qdescriptor_at_put(int which, int name_index, int resolved_klass_index) {\n+      release_tag_at_put(which, JVM_CONSTANT_UnresolvedClass | (jbyte) JVM_CONSTANT_QDescBit);\n+\n+      assert((name_index & 0xffff0000) == 0, \"must be\");\n+      assert((resolved_klass_index & 0xffff0000) == 0, \"must be\");\n+      *int_at_addr(which) =\n+        build_int_from_shorts((jushort)resolved_klass_index, (jushort)name_index);\n+    }\n+\n","filename":"src\/hotspot\/share\/oops\/constantPool.hpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -138,1 +138,3 @@\n-                                       bool is_volatile) {\n+                                       bool is_volatile,\n+                                       bool is_inlined,\n+                                       bool is_inline_type) {\n@@ -143,0 +145,1 @@\n+  assert(!is_inlined || is_inline_type, \"Sanity check\");\n@@ -145,1 +148,3 @@\n-                  ((is_final    ? 1 : 0) << is_final_shift),\n+                  ((is_final    ? 1 : 0) << is_final_shift) |\n+                  ((is_inlined  ? 1 : 0) << is_inlined_shift) |\n+                  ((is_inline_type ? 1 : 0) << is_inline_type_shift),\n@@ -303,0 +308,1 @@\n+      invoke_code = Bytecodes::_invokevirtual;\n@@ -318,1 +324,1 @@\n-    set_bytecode_2(Bytecodes::_invokevirtual);\n+    set_bytecode_2(invoke_code);\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -54,1 +54,1 @@\n-\/\/ _flags     [tos|0|F=1|0|0|0|f|v|0 |0000|field_index] (for field entries)\n+\/\/ _flags     [tos|0|F=1|0|I|i|f|v|0 |0000|field_index] (for field entries)\n@@ -80,0 +80,2 @@\n+\/\/ I  flag true if field is an inline type (must never be null)\n+\/\/ i  flag true if field is inlined\n@@ -187,0 +189,1 @@\n+    is_inline_type_shift       = 24,  \/\/ (I) is the type of the field an inline type (must never be null)\n@@ -188,0 +191,1 @@\n+    is_inlined_shift           = 23,  \/\/ (i) is the field inlined?\n@@ -226,1 +230,3 @@\n-    bool            is_volatile                  \/\/ the field is volatile\n+    bool            is_volatile,                 \/\/ the field is volatile\n+    bool            is_inlined,                  \/\/ the field is inlined\n+    bool            is_inline_type               \/\/ the field is an inline type (must never be null)\n@@ -315,0 +321,1 @@\n+      case Bytecodes::_withfield       :    \/\/ fall through\n@@ -342,0 +349,1 @@\n+  int       f2_as_offset() const                 { assert(is_field_entry(),  \"\"); return (int)_f2; }\n@@ -347,0 +355,1 @@\n+  bool is_inlined() const                        { return  (_flags & (1 << is_inlined_shift))       != 0; }\n@@ -356,0 +365,1 @@\n+  bool is_inline_type() const                    { return (_flags & (1 << is_inline_type_shift))       != 0; }\n","filename":"src\/hotspot\/share\/oops\/cpCache.hpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -0,0 +1,504 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"classfile\/moduleEntry.hpp\"\n+#include \"classfile\/packageEntry.hpp\"\n+#include \"classfile\/symbolTable.hpp\"\n+#include \"classfile\/systemDictionary.hpp\"\n+#include \"classfile\/vmSymbols.hpp\"\n+#include \"gc\/shared\/collectedHeap.inline.hpp\"\n+#include \"memory\/iterator.inline.hpp\"\n+#include \"memory\/metadataFactory.hpp\"\n+#include \"memory\/metaspaceClosure.hpp\"\n+#include \"memory\/oopFactory.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"memory\/universe.hpp\"\n+#include \"oops\/arrayKlass.inline.hpp\"\n+#include \"oops\/arrayOop.hpp\"\n+#include \"oops\/flatArrayOop.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n+#include \"oops\/instanceKlass.hpp\"\n+#include \"oops\/klass.inline.hpp\"\n+#include \"oops\/objArrayKlass.hpp\"\n+#include \"oops\/objArrayOop.inline.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"oops\/verifyOopClosure.hpp\"\n+#include \"runtime\/handles.inline.hpp\"\n+#include \"runtime\/mutexLocker.hpp\"\n+#include \"utilities\/copy.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+#include \"oops\/flatArrayKlass.hpp\"\n+\n+\/\/ Allocation...\n+\n+FlatArrayKlass::FlatArrayKlass(Klass* element_klass, Symbol* name) : ArrayKlass(name, ID) {\n+  assert(element_klass->is_inline_klass(), \"Expected Inline\");\n+\n+  set_element_klass(InlineKlass::cast(element_klass));\n+  set_class_loader_data(element_klass->class_loader_data());\n+\n+  set_layout_helper(array_layout_helper(InlineKlass::cast(element_klass)));\n+  assert(is_array_klass(), \"sanity\");\n+  assert(is_flatArray_klass(), \"sanity\");\n+  assert(is_null_free_array_klass(), \"sanity\");\n+\n+  set_prototype_header(markWord::flat_array_prototype());\n+  assert(prototype_header().is_flat_array(), \"sanity\");\n+\n+#ifndef PRODUCT\n+  if (PrintFlatArrayLayout) {\n+    print();\n+  }\n+#endif\n+}\n+\n+InlineKlass* FlatArrayKlass::element_klass() const {\n+  return InlineKlass::cast(_element_klass);\n+}\n+\n+void FlatArrayKlass::set_element_klass(Klass* k) {\n+  _element_klass = k;\n+}\n+\n+FlatArrayKlass* FlatArrayKlass::allocate_klass(Klass* element_klass, TRAPS) {\n+  guarantee((!Universe::is_bootstrapping() || vmClasses::Object_klass_loaded()), \"Really ?!\");\n+  assert(UseFlatArray, \"Flatten array required\");\n+  assert(InlineKlass::cast(element_klass)->is_naturally_atomic() || (!InlineArrayAtomicAccess), \"Atomic by-default\");\n+\n+  \/*\n+   *  MVT->LWorld, now need to allocate secondaries array types, just like objArrayKlass...\n+   *  ...so now we are trying out covariant array types, just copy objArrayKlass\n+   *  TODO refactor any remaining commonality\n+   *\n+   *\/\n+  \/\/ Eagerly allocate the direct array supertype.\n+  Klass* super_klass = NULL;\n+  Klass* element_super = element_klass->super();\n+  if (element_super != NULL) {\n+    \/\/ The element type has a direct super.  E.g., String[] has direct super of Object[].\n+    super_klass = element_super->array_klass_or_null();\n+    bool supers_exist = super_klass != NULL;\n+    \/\/ Also, see if the element has secondary supertypes.\n+    \/\/ We need an array type for each.\n+    const Array<Klass*>* element_supers = element_klass->secondary_supers();\n+    for( int i = element_supers->length()-1; i >= 0; i-- ) {\n+      Klass* elem_super = element_supers->at(i);\n+      if (elem_super->array_klass_or_null() == NULL) {\n+        supers_exist = false;\n+        break;\n+      }\n+    }\n+    if (!supers_exist) {\n+      \/\/ Oops.  Not allocated yet.  Back out, allocate it, and retry.\n+      Klass* ek = NULL;\n+      {\n+        MutexUnlocker mu(MultiArray_lock);\n+        super_klass = element_super->array_klass(CHECK_NULL);\n+        for( int i = element_supers->length()-1; i >= 0; i-- ) {\n+          Klass* elem_super = element_supers->at(i);\n+          elem_super->array_klass(CHECK_NULL);\n+        }\n+        \/\/ Now retry from the beginning\n+        ek = element_klass->array_klass(CHECK_NULL);\n+      }  \/\/ re-lock\n+      return FlatArrayKlass::cast(ek);\n+    }\n+  }\n+\n+  Symbol* name = ArrayKlass::create_element_klass_array_name(element_klass, CHECK_NULL);\n+  ClassLoaderData* loader_data = element_klass->class_loader_data();\n+  int size = ArrayKlass::static_size(FlatArrayKlass::header_size());\n+  FlatArrayKlass* vak = new (loader_data, size, THREAD) FlatArrayKlass(element_klass, name);\n+\n+  ModuleEntry* module = vak->module();\n+  assert(module != NULL, \"No module entry for array\");\n+  complete_create_array_klass(vak, super_klass, module, CHECK_NULL);\n+\n+  loader_data->add_class(vak);\n+\n+  return vak;\n+}\n+\n+void FlatArrayKlass::initialize(TRAPS) {\n+  element_klass()->initialize(THREAD);\n+}\n+\n+\/\/ Oops allocation...\n+flatArrayOop FlatArrayKlass::allocate(int length, TRAPS) {\n+  check_array_allocation_length(length, max_elements(), CHECK_NULL);\n+  int size = flatArrayOopDesc::object_size(layout_helper(), length);\n+  return (flatArrayOop) Universe::heap()->array_allocate(this, size, length, true, THREAD);\n+}\n+\n+\n+oop FlatArrayKlass::multi_allocate(int rank, jint* last_size, TRAPS) {\n+  \/\/ For flatArrays this is only called for the last dimension\n+  assert(rank == 1, \"just checking\");\n+  int length = *last_size;\n+  return allocate(length, THREAD);\n+}\n+\n+jint FlatArrayKlass::array_layout_helper(InlineKlass* vk) {\n+  BasicType etype = T_INLINE_TYPE;\n+  int esize = log2i_exact(round_up_power_of_2(vk->get_exact_size_in_bytes()));\n+  int hsize = arrayOopDesc::base_offset_in_bytes(etype);\n+\n+  int lh = Klass::array_layout_helper(_lh_array_tag_vt_value, true, hsize, etype, esize);\n+\n+  assert(lh < (int)_lh_neutral_value, \"must look like an array layout\");\n+  assert(layout_helper_is_array(lh), \"correct kind\");\n+  assert(layout_helper_is_flatArray(lh), \"correct kind\");\n+  assert(!layout_helper_is_typeArray(lh), \"correct kind\");\n+  assert(!layout_helper_is_objArray(lh), \"correct kind\");\n+  assert(layout_helper_is_null_free(lh), \"correct kind\");\n+  assert(layout_helper_header_size(lh) == hsize, \"correct decode\");\n+  assert(layout_helper_element_type(lh) == etype, \"correct decode\");\n+  assert(layout_helper_log2_element_size(lh) == esize, \"correct decode\");\n+  assert((1 << esize) < BytesPerLong || is_aligned(hsize, HeapWordsPerLong), \"unaligned base\");\n+\n+  return lh;\n+}\n+\n+int FlatArrayKlass::oop_size(oop obj) const {\n+  assert(obj->klass()->is_flatArray_klass(),\"must be an flat array\");\n+  flatArrayOop array = flatArrayOop(obj);\n+  return array->object_size();\n+}\n+\n+\/\/ For now return the maximum number of array elements that will not exceed:\n+\/\/ nof bytes = \"max_jint * HeapWord\" since the \"oopDesc::oop_iterate_size\"\n+\/\/ returns \"int\" HeapWords, need fix for JDK-4718400 and JDK-8233189\n+jint FlatArrayKlass::max_elements() const {\n+  \/\/ Check the max number of heap words limit first (because of int32_t in oopDesc_oop_size() etc)\n+  size_t max_size = max_jint;\n+  max_size -= arrayOopDesc::header_size(T_INLINE_TYPE);\n+  max_size = align_down(max_size, MinObjAlignment);\n+  max_size <<= LogHeapWordSize;                                  \/\/ convert to max payload size in bytes\n+  max_size >>= layout_helper_log2_element_size(_layout_helper);  \/\/ divide by element size (in bytes) = max elements\n+  \/\/ Within int32_t heap words, still can't exceed Java array element limit\n+  if (max_size > max_jint) {\n+    max_size = max_jint;\n+  }\n+  assert((max_size >> LogHeapWordSize) <= max_jint, \"Overflow\");\n+  return (jint) max_size;\n+}\n+\n+oop FlatArrayKlass::protection_domain() const {\n+  return element_klass()->protection_domain();\n+}\n+\n+\/\/ Temp hack having this here: need to move towards Access API\n+static bool needs_backwards_copy(arrayOop s, int src_pos,\n+                                 arrayOop d, int dst_pos, int length) {\n+  return (s == d) && (dst_pos > src_pos) && (dst_pos - src_pos) < length;\n+}\n+\n+void FlatArrayKlass::copy_array(arrayOop s, int src_pos,\n+                                arrayOop d, int dst_pos, int length, TRAPS) {\n+\n+  assert(s->is_objArray() || s->is_flatArray(), \"must be obj or flat array\");\n+\n+   \/\/ Check destination\n+   if ((!d->is_flatArray()) && (!d->is_objArray())) {\n+     THROW(vmSymbols::java_lang_ArrayStoreException());\n+   }\n+\n+   \/\/ Check if all offsets and lengths are non negative\n+   if (src_pos < 0 || dst_pos < 0 || length < 0) {\n+     THROW(vmSymbols::java_lang_ArrayIndexOutOfBoundsException());\n+   }\n+   \/\/ Check if the ranges are valid\n+   if  ( (((unsigned int) length + (unsigned int) src_pos) > (unsigned int) s->length())\n+      || (((unsigned int) length + (unsigned int) dst_pos) > (unsigned int) d->length()) ) {\n+     THROW(vmSymbols::java_lang_ArrayIndexOutOfBoundsException());\n+   }\n+   \/\/ Check zero copy\n+   if (length == 0)\n+     return;\n+\n+   ArrayKlass* sk = ArrayKlass::cast(s->klass());\n+   ArrayKlass* dk = ArrayKlass::cast(d->klass());\n+   Klass* d_elem_klass = dk->element_klass();\n+   Klass* s_elem_klass = sk->element_klass();\n+   \/**** CMH: compare and contrast impl, re-factor once we find edge cases... ****\/\n+\n+   if (sk->is_flatArray_klass()) {\n+     assert(sk == this, \"Unexpected call to copy_array\");\n+     \/\/ Check subtype, all src homogeneous, so just once\n+     if (!s_elem_klass->is_subtype_of(d_elem_klass)) {\n+       THROW(vmSymbols::java_lang_ArrayStoreException());\n+     }\n+\n+     flatArrayOop sa = flatArrayOop(s);\n+     InlineKlass* s_elem_vklass = element_klass();\n+\n+     \/\/ flatArray-to-flatArray\n+     if (dk->is_flatArray_klass()) {\n+       \/\/ element types MUST be exact, subtype check would be dangerous\n+       if (dk != this) {\n+         THROW(vmSymbols::java_lang_ArrayStoreException());\n+       }\n+\n+       flatArrayOop da = flatArrayOop(d);\n+       address dst = (address) da->value_at_addr(dst_pos, layout_helper());\n+       address src = (address) sa->value_at_addr(src_pos, layout_helper());\n+       if (contains_oops()) {\n+         int elem_incr = 1 << log2_element_size();\n+         address src_end = src + (length << log2_element_size());\n+         if (needs_backwards_copy(s, src_pos, d, dst_pos, length)) {\n+           swap(src, src_end);\n+           dst = dst + (length << log2_element_size());\n+           do {\n+             src -= elem_incr;\n+             dst -= elem_incr;\n+             HeapAccess<>::value_copy(src, dst, s_elem_vklass);\n+           } while (src > src_end);\n+         } else {\n+           address src_end = src + (length << log2_element_size());\n+           while (src < src_end) {\n+             HeapAccess<>::value_copy(src, dst, s_elem_vklass);\n+             src += elem_incr;\n+             dst += elem_incr;\n+           }\n+         }\n+       } else {\n+         \/\/ we are basically a type array...don't bother limiting element copy\n+         \/\/ it would have to be a lot wasted space to be worth value_store() calls, need a setting here ?\n+         Copy::conjoint_memory_atomic(src, dst, (size_t)length << log2_element_size());\n+       }\n+     }\n+     else { \/\/ flatArray-to-objArray\n+       assert(dk->is_objArray_klass(), \"Expected objArray here\");\n+       \/\/ Need to allocate each new src elem payload -> dst oop\n+       objArrayHandle dh(THREAD, (objArrayOop)d);\n+       flatArrayHandle sh(THREAD, sa);\n+       int dst_end = dst_pos + length;\n+       while (dst_pos < dst_end) {\n+         oop o = flatArrayOopDesc::value_alloc_copy_from_index(sh, src_pos, CHECK);\n+         dh->obj_at_put(dst_pos, o);\n+         dst_pos++;\n+         src_pos++;\n+       }\n+     }\n+   } else {\n+     assert(s->is_objArray(), \"Expected objArray\");\n+     objArrayOop sa = objArrayOop(s);\n+     assert(d->is_flatArray(), \"Excepted flatArray\");  \/\/ objArray-to-flatArray\n+     InlineKlass* d_elem_vklass = InlineKlass::cast(d_elem_klass);\n+     flatArrayOop da = flatArrayOop(d);\n+\n+     int src_end = src_pos + length;\n+     int delem_incr = 1 << dk->log2_element_size();\n+     address dst = (address) da->value_at_addr(dst_pos, layout_helper());\n+     while (src_pos < src_end) {\n+       oop se = sa->obj_at(src_pos);\n+       if (se == NULL) {\n+         THROW(vmSymbols::java_lang_NullPointerException());\n+       }\n+       \/\/ Check exact type per element\n+       if (se->klass() != d_elem_klass) {\n+         THROW(vmSymbols::java_lang_ArrayStoreException());\n+       }\n+       d_elem_vklass->inline_copy_oop_to_payload(se, dst);\n+       dst += delem_incr;\n+       src_pos++;\n+     }\n+   }\n+}\n+\n+\n+Klass* FlatArrayKlass::array_klass_impl(bool or_null, int n, TRAPS) {\n+  assert(dimension() <= n, \"check order of chain\");\n+  int dim = dimension();\n+  if (dim == n) return this;\n+\n+  if (higher_dimension_acquire() == NULL) {\n+    if (or_null)  return NULL;\n+\n+    ResourceMark rm;\n+    {\n+      \/\/ Ensure atomic creation of higher dimensions\n+      MutexLocker mu(THREAD, MultiArray_lock);\n+\n+      \/\/ Check if another thread beat us\n+      if (higher_dimension() == NULL) {\n+\n+        \/\/ Create multi-dim klass object and link them together\n+        Klass* k =\n+          ObjArrayKlass::allocate_objArray_klass(class_loader_data(), dim + 1, this, CHECK_NULL);\n+        ObjArrayKlass* ak = ObjArrayKlass::cast(k);\n+        ak->set_lower_dimension(this);\n+        OrderAccess::storestore();\n+        release_set_higher_dimension(ak);\n+        assert(ak->is_objArray_klass(), \"incorrect initialization of ObjArrayKlass\");\n+      }\n+    }\n+  } else {\n+    CHECK_UNHANDLED_OOPS_ONLY(Thread::current()->clear_unhandled_oops());\n+  }\n+\n+  ObjArrayKlass *ak = ObjArrayKlass::cast(higher_dimension());\n+  if (or_null) {\n+    return ak->array_klass_or_null(n);\n+  }\n+  return ak->array_klass(n, THREAD);\n+}\n+\n+Klass* FlatArrayKlass::array_klass_impl(bool or_null, TRAPS) {\n+  return array_klass_impl(or_null, dimension() +  1, THREAD);\n+}\n+\n+ModuleEntry* FlatArrayKlass::module() const {\n+  assert(element_klass() != NULL, \"FlatArrayKlass returned unexpected NULL bottom_klass\");\n+  \/\/ The array is defined in the module of its bottom class\n+  return element_klass()->module();\n+}\n+\n+PackageEntry* FlatArrayKlass::package() const {\n+  assert(element_klass() != NULL, \"FlatArrayKlass returned unexpected NULL bottom_klass\");\n+  return element_klass()->package();\n+}\n+\n+bool FlatArrayKlass::can_be_primary_super_slow() const {\n+    return true;\n+}\n+\n+GrowableArray<Klass*>* FlatArrayKlass::compute_secondary_supers(int num_extra_slots,\n+                                                                Array<InstanceKlass*>* transitive_interfaces) {\n+  assert(transitive_interfaces == NULL, \"sanity\");\n+  \/\/ interfaces = { cloneable_klass, serializable_klass, elemSuper[], ... };\n+  Array<Klass*>* elem_supers = element_klass()->secondary_supers();\n+  int num_elem_supers = elem_supers == NULL ? 0 : elem_supers->length();\n+  int num_secondaries = num_extra_slots + 2 + num_elem_supers;\n+  if (num_secondaries == 2) {\n+    \/\/ Must share this for correct bootstrapping!\n+    set_secondary_supers(Universe::the_array_interfaces_array());\n+    return NULL;\n+  } else {\n+    GrowableArray<Klass*>* secondaries = new GrowableArray<Klass*>(num_elem_supers+3);\n+    secondaries->push(vmClasses::Cloneable_klass());\n+    secondaries->push(vmClasses::Serializable_klass());\n+    secondaries->push(vmClasses::IdentityObject_klass());\n+    for (int i = 0; i < num_elem_supers; i++) {\n+      Klass* elem_super = (Klass*) elem_supers->at(i);\n+      Klass* array_super = elem_super->array_klass_or_null();\n+      assert(array_super != NULL, \"must already have been created\");\n+      secondaries->push(array_super);\n+    }\n+    return secondaries;\n+  }\n+}\n+\n+void FlatArrayKlass::print_on(outputStream* st) const {\n+#ifndef PRODUCT\n+  assert(!is_objArray_klass(), \"Unimplemented\");\n+\n+  st->print(\"Flat Type Array: \");\n+  Klass::print_on(st);\n+\n+  st->print(\" - element klass: \");\n+  element_klass()->print_value_on(st);\n+  st->cr();\n+\n+  int elem_size = element_byte_size();\n+  st->print(\" - element size %i \", elem_size);\n+  st->print(\"aligned layout size %i\", 1 << layout_helper_log2_element_size(layout_helper()));\n+  st->cr();\n+#endif \/\/PRODUCT\n+}\n+\n+void FlatArrayKlass::print_value_on(outputStream* st) const {\n+  assert(is_klass(), \"must be klass\");\n+\n+  element_klass()->print_value_on(st);\n+  st->print(\"[]\");\n+}\n+\n+\n+#ifndef PRODUCT\n+void FlatArrayKlass::oop_print_on(oop obj, outputStream* st) {\n+  ArrayKlass::oop_print_on(obj, st);\n+  flatArrayOop va = flatArrayOop(obj);\n+  InlineKlass* vk = element_klass();\n+  int print_len = MIN2((intx) va->length(), MaxElementPrintSize);\n+  for(int index = 0; index < print_len; index++) {\n+    int off = (address) va->value_at_addr(index, layout_helper()) - cast_from_oop<address>(obj);\n+    st->print_cr(\" - Index %3d offset %3d: \", index, off);\n+    oop obj = cast_to_oop((address)va->value_at_addr(index, layout_helper()) - vk->first_field_offset());\n+    FieldPrinter print_field(st, obj);\n+    vk->do_nonstatic_fields(&print_field);\n+    st->cr();\n+  }\n+  int remaining = va->length() - print_len;\n+  if (remaining > 0) {\n+    st->print_cr(\" - <%d more elements, increase MaxElementPrintSize to print>\", remaining);\n+  }\n+}\n+#endif \/\/PRODUCT\n+\n+void FlatArrayKlass::oop_print_value_on(oop obj, outputStream* st) {\n+  assert(obj->is_flatArray(), \"must be flatArray\");\n+  st->print(\"a \");\n+  element_klass()->print_value_on(st);\n+  int len = flatArrayOop(obj)->length();\n+  st->print(\"[%d] \", len);\n+  obj->print_address_on(st);\n+  if (PrintMiscellaneous && (WizardMode || Verbose)) {\n+    int lh = layout_helper();\n+    st->print(\"{\");\n+    for (int i = 0; i < len; i++) {\n+      if (i > 4) {\n+        st->print(\"...\"); break;\n+      }\n+      st->print(\" \" INTPTR_FORMAT, (intptr_t)(void*)flatArrayOop(obj)->value_at_addr(i , lh));\n+    }\n+    st->print(\" }\");\n+  }\n+}\n+\n+\/\/ Verification\n+class VerifyElementClosure: public BasicOopIterateClosure {\n+ public:\n+  virtual void do_oop(oop* p)       { VerifyOopClosure::verify_oop.do_oop(p); }\n+  virtual void do_oop(narrowOop* p) { VerifyOopClosure::verify_oop.do_oop(p); }\n+};\n+\n+void FlatArrayKlass::oop_verify_on(oop obj, outputStream* st) {\n+  ArrayKlass::oop_verify_on(obj, st);\n+  guarantee(obj->is_flatArray(), \"must be flatArray\");\n+\n+  if (contains_oops()) {\n+    flatArrayOop va = flatArrayOop(obj);\n+    VerifyElementClosure ec;\n+    va->oop_iterate(&ec);\n+  }\n+}\n+\n+void FlatArrayKlass::verify_on(outputStream* st) {\n+  ArrayKlass::verify_on(st);\n+  guarantee(element_klass()->is_inline_klass(), \"should be inline type klass\");\n+}\n","filename":"src\/hotspot\/share\/oops\/flatArrayKlass.cpp","additions":504,"deletions":0,"binary":false,"changes":504,"status":"added"},{"patch":"@@ -143,1 +143,1 @@\n-    if (!is_static)\n+    if (!is_static) {\n@@ -145,0 +145,1 @@\n+    }\n@@ -841,1 +842,1 @@\n-  assert(cts.is_reference() || cts.is_value() || cts.is_address(),\n+  assert(cts.is_reference() || cts.is_inline_type() || cts.is_address(),\n@@ -1388,0 +1389,3 @@\n+    case Bytecodes::_defaultvalue:      ppush1(CellTypeState::make_line_ref(itr->bci())); break;\n+    case Bytecodes::_withfield:         do_withfield(itr->get_index_u2_cpcache(), itr->bci()); break;\n+\n@@ -1601,2 +1605,2 @@\n-    case Bytecodes::_getstatic:         do_field(true,  true,  itr->get_index_u2_cpcache(), itr->bci()); break;\n-    case Bytecodes::_putstatic:         do_field(false, true,  itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_getstatic:         do_field(true,  true, itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_putstatic:         do_field(false, true, itr->get_index_u2_cpcache(), itr->bci()); break;\n@@ -1606,0 +1610,1 @@\n+    case Bytecodes::_invokeinterface:\n@@ -1607,4 +1612,3 @@\n-    case Bytecodes::_invokespecial:     do_method(false, false, itr->get_index_u2_cpcache(), itr->bci()); break;\n-    case Bytecodes::_invokestatic:      do_method(true,  false, itr->get_index_u2_cpcache(), itr->bci()); break;\n-    case Bytecodes::_invokedynamic:     do_method(true,  false, itr->get_index_u4(),         itr->bci()); break;\n-    case Bytecodes::_invokeinterface:   do_method(false, true,  itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_invokespecial:     do_method(false, itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_invokestatic:      do_method(true , itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_invokedynamic:     do_method(true , itr->get_index_u4(),         itr->bci()); break;\n@@ -1630,0 +1634,1 @@\n+\n@@ -1736,1 +1741,1 @@\n-  assert(in.is_reference() | in.is_value(), \"sanity check\");\n+  assert(in.is_reference() || in.is_inline_type(), \"sanity check\");\n@@ -1955,1 +1960,3 @@\n-  if (!is_static) in[i++] = CellTypeState::ref;\n+  if (!is_static) {\n+    in[i++] = CellTypeState::ref;\n+  }\n@@ -1961,1 +1968,1 @@\n-void GenerateOopMap::do_method(int is_static, int is_interface, int idx, int bci) {\n+void GenerateOopMap::do_method(int is_static, int idx, int bci) {\n@@ -1998,0 +2005,27 @@\n+void GenerateOopMap::do_withfield(int idx, int bci) {\n+  \/\/ Dig up signature for field in constant pool\n+  ConstantPool* cp = method()->constants();\n+  int nameAndTypeIdx = cp->name_and_type_ref_index_at(idx);\n+  int signatureIdx = cp->signature_ref_index_at(nameAndTypeIdx);\n+  Symbol* signature = cp->symbol_at(signatureIdx);\n+\n+  \/\/ Parse signature (especially simple for fields)\n+  assert(signature->utf8_length() > 0,\n+      \"field signatures cannot have zero length\");\n+  \/\/ The signature is UFT8 encoded, but the first char is always ASCII for signatures.\n+  CellTypeState temp[4];\n+  CellTypeState *eff = signature_to_effect(signature, bci, temp);\n+\n+  CellTypeState in[4];\n+  int i = copy_cts(in, eff);\n+  in[i++] = CellTypeState::ref;\n+  in[i] = CellTypeState::bottom;\n+  assert(i <= 3, \"sanity check\");\n+\n+  CellTypeState out[2];\n+  out[0] = CellTypeState::ref;\n+  out[1] = CellTypeState::bottom;\n+\n+  pp(in, out);\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/generateOopMap.cpp","additions":45,"deletions":11,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -94,1 +94,1 @@\n-  enum { info_mask            = right_n_bits(28),\n+  enum { info_mask            = right_n_bits(27),\n@@ -107,3 +107,3 @@\n-  enum { top_info_bit         = nth_bit(27),\n-         not_bottom_info_bit  = nth_bit(26),\n-         info_data_mask       = right_n_bits(26),\n+  enum { top_info_bit         = nth_bit(26),\n+         not_bottom_info_bit  = nth_bit(25),\n+         info_data_mask       = right_n_bits(25),\n@@ -114,2 +114,2 @@\n-  enum { ref_not_lock_bit     = nth_bit(25),  \/\/ 0 if this reference is locked as a monitor\n-         ref_slot_bit         = nth_bit(24),  \/\/ 1 if this reference is a \"slot\" reference,\n+  enum { ref_not_lock_bit     = nth_bit(24),  \/\/ 0 if this reference is locked as a monitor\n+         ref_slot_bit         = nth_bit(23),  \/\/ 1 if this reference is a \"slot\" reference,\n@@ -117,1 +117,1 @@\n-         ref_data_mask        = right_n_bits(24) };\n+         ref_data_mask        = right_n_bits(23) };\n@@ -119,0 +119,5 @@\n+  \/\/ Within the INFO data, these values are used to distinguish different\n+  \/\/ kinds of value types.\n+  enum { valuetype_slot_bit   = nth_bit(24),  \/\/ 1 if this reference is a \"slot\" value type,\n+    \/\/ 0 if it is a \"line\" value type.\n+    valuetype_data_mask  = right_n_bits(24) };\n@@ -199,1 +204,1 @@\n-  bool is_value() const                 { return ((_state & bits_mask) == val_bit); }\n+  bool is_inline_type() const           { return ((_state & bits_mask) == val_bit); }\n@@ -400,1 +405,2 @@\n-  void  do_method                           (int is_static, int is_interface, int idx, int bci);\n+  void  do_method                           (int is_static, int idx, int bci);\n+  void  do_withfield                       (int idx, int bci);\n","filename":"src\/hotspot\/share\/oops\/generateOopMap.hpp","additions":15,"deletions":9,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -0,0 +1,528 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"code\/codeCache.hpp\"\n+#include \"gc\/shared\/barrierSet.hpp\"\n+#include \"gc\/shared\/collectedHeap.inline.hpp\"\n+#include \"gc\/shared\/gcLocker.inline.hpp\"\n+#include \"interpreter\/interpreter.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"memory\/metaspaceClosure.hpp\"\n+#include \"memory\/metadataFactory.hpp\"\n+#include \"oops\/access.hpp\"\n+#include \"oops\/compressedOops.inline.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n+#include \"oops\/instanceKlass.inline.hpp\"\n+#include \"oops\/method.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"oops\/objArrayKlass.hpp\"\n+#include \"runtime\/fieldDescriptor.inline.hpp\"\n+#include \"runtime\/handles.inline.hpp\"\n+#include \"runtime\/safepointVerifiers.hpp\"\n+#include \"runtime\/sharedRuntime.hpp\"\n+#include \"runtime\/signature.hpp\"\n+#include \"runtime\/thread.inline.hpp\"\n+#include \"utilities\/copy.hpp\"\n+\n+  \/\/ Constructor\n+InlineKlass::InlineKlass(const ClassFileParser& parser)\n+    : InstanceKlass(parser, InstanceKlass::_kind_inline_type, InstanceKlass::ID) {\n+  _adr_inlineklass_fixed_block = inlineklass_static_block();\n+  \/\/ Addresses used for inline type calling convention\n+  *((Array<SigEntry>**)adr_extended_sig()) = NULL;\n+  *((Array<VMRegPair>**)adr_return_regs()) = NULL;\n+  *((address*)adr_pack_handler()) = NULL;\n+  *((address*)adr_pack_handler_jobject()) = NULL;\n+  *((address*)adr_unpack_handler()) = NULL;\n+  assert(pack_handler() == NULL, \"pack handler not null\");\n+  *((int*)adr_default_value_offset()) = 0;\n+  set_prototype_header(markWord::inline_type_prototype());\n+  assert(is_inline_type_klass(), \"sanity\");\n+  assert(prototype_header().is_inline_type(), \"sanity\");\n+}\n+\n+oop InlineKlass::default_value() {\n+  oop val = java_mirror()->obj_field_acquire(default_value_offset());\n+  assert(oopDesc::is_oop(val), \"Sanity check\");\n+  assert(val->is_inline_type(), \"Sanity check\");\n+  assert(val->klass() == this, \"sanity check\");\n+  return val;\n+}\n+\n+int InlineKlass::first_field_offset_old() {\n+#ifdef ASSERT\n+  int first_offset = INT_MAX;\n+  for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+    if (fs.offset() < first_offset) first_offset= fs.offset();\n+  }\n+#endif\n+  int base_offset = instanceOopDesc::base_offset_in_bytes();\n+  \/\/ The first field of line types is aligned on a long boundary\n+  base_offset = align_up(base_offset, BytesPerLong);\n+  assert(base_offset == first_offset, \"inconsistent offsets\");\n+  return base_offset;\n+}\n+\n+instanceOop InlineKlass::allocate_instance(TRAPS) {\n+  int size = size_helper();  \/\/ Query before forming handle.\n+\n+  instanceOop oop = (instanceOop)Universe::heap()->obj_allocate(this, size, CHECK_NULL);\n+  assert(oop->mark().is_inline_type(), \"Expected inline type\");\n+  return oop;\n+}\n+\n+instanceOop InlineKlass::allocate_instance_buffer(TRAPS) {\n+  int size = size_helper();  \/\/ Query before forming handle.\n+\n+  instanceOop oop = (instanceOop)Universe::heap()->obj_buffer_allocate(this, size, CHECK_NULL);\n+  assert(oop->mark().is_inline_type(), \"Expected inline type\");\n+  return oop;\n+}\n+\n+int InlineKlass::nonstatic_oop_count() {\n+  int oops = 0;\n+  int map_count = nonstatic_oop_map_count();\n+  OopMapBlock* block = start_of_nonstatic_oop_maps();\n+  OopMapBlock* end = block + map_count;\n+  while (block != end) {\n+    oops += block->count();\n+    block++;\n+  }\n+  return oops;\n+}\n+\n+oop InlineKlass::read_inlined_field(oop obj, int offset, TRAPS) {\n+  oop res = NULL;\n+  this->initialize(CHECK_NULL); \/\/ will throw an exception if in error state\n+  if (is_empty_inline_type()) {\n+    res = (instanceOop)default_value();\n+  } else {\n+    Handle obj_h(THREAD, obj);\n+    res = allocate_instance_buffer(CHECK_NULL);\n+    inline_copy_payload_to_new_oop(((char*)(oopDesc*)obj_h()) + offset, res);\n+  }\n+  assert(res != NULL, \"Must be set in one of two paths above\");\n+  return res;\n+}\n+\n+void InlineKlass::write_inlined_field(oop obj, int offset, oop value, TRAPS) {\n+  if (value == NULL) {\n+    THROW(vmSymbols::java_lang_NullPointerException());\n+  }\n+  if (!is_empty_inline_type()) {\n+    inline_copy_oop_to_payload(value, ((char*)(oopDesc*)obj) + offset);\n+  }\n+}\n+\n+\/\/ Arrays of...\n+\n+bool InlineKlass::flatten_array() {\n+  if (!UseFlatArray) {\n+    return false;\n+  }\n+  \/\/ Too big\n+  int elem_bytes = get_exact_size_in_bytes();\n+  if ((FlatArrayElementMaxSize >= 0) && (elem_bytes > FlatArrayElementMaxSize)) {\n+    return false;\n+  }\n+  \/\/ Too many embedded oops\n+  if ((FlatArrayElementMaxOops >= 0) && (nonstatic_oop_count() > FlatArrayElementMaxOops)) {\n+    return false;\n+  }\n+  \/\/ Declared atomic but not naturally atomic.\n+  if (is_declared_atomic() && !is_naturally_atomic()) {\n+    return false;\n+  }\n+  \/\/ VM enforcing InlineArrayAtomicAccess only...\n+  if (InlineArrayAtomicAccess && (!is_naturally_atomic())) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+void InlineKlass::remove_unshareable_info() {\n+  InstanceKlass::remove_unshareable_info();\n+\n+  *((Array<SigEntry>**)adr_extended_sig()) = NULL;\n+  *((Array<VMRegPair>**)adr_return_regs()) = NULL;\n+  *((address*)adr_pack_handler()) = NULL;\n+  *((address*)adr_pack_handler_jobject()) = NULL;\n+  *((address*)adr_unpack_handler()) = NULL;\n+  assert(pack_handler() == NULL, \"pack handler not null\");\n+}\n+\n+void InlineKlass::restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS) {\n+  InstanceKlass::restore_unshareable_info(loader_data, protection_domain, pkg_entry, CHECK);\n+}\n+\n+Klass* InlineKlass::array_klass_impl(bool or_null, int n, TRAPS) {\n+  \/\/ Need load-acquire for lock-free read\n+  if (array_klasses_acquire() == NULL) {\n+    if (or_null) return NULL;\n+\n+    ResourceMark rm(THREAD);\n+    JavaThread *jt = (JavaThread *)THREAD;\n+    {\n+      \/\/ Atomic creation of array_klasses\n+      MutexLocker ma(THREAD, MultiArray_lock);\n+\n+      ArrayKlass* k = NULL;\n+      \/\/ Check if update has already taken place\n+      if (array_klasses() == NULL) {\n+        if (flatten_array()) {\n+          k = FlatArrayKlass::allocate_klass(this, CHECK_NULL);\n+        } else {\n+          k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, CHECK_NULL);\n+        }\n+        \/\/ use 'release' to pair with lock-free load\n+        release_set_array_klasses(k);\n+      }\n+    }\n+  }\n+  \/\/ _this will always be set at this point\n+  ArrayKlass* ak = array_klasses();\n+  if (or_null) {\n+    return ak->array_klass_or_null(n);\n+  }\n+  return ak->array_klass(n, THREAD);\n+}\n+\n+Klass* InlineKlass::array_klass_impl(bool or_null, TRAPS) {\n+  return array_klass_impl(or_null, 1, THREAD);\n+}\n+\n+\/\/ Inline type arguments are not passed by reference, instead each\n+\/\/ field of the inline type is passed as an argument. This helper\n+\/\/ function collects the inlined field (recursively)\n+\/\/ in a list. Included with the field's type is\n+\/\/ the offset of each field in the inline type: i2c and c2i adapters\n+\/\/ need that to load or store fields. Finally, the list of fields is\n+\/\/ sorted in order of increasing offsets: the adapters and the\n+\/\/ compiled code need to agree upon the order of fields.\n+\/\/\n+\/\/ The list of basic types that is returned starts with a T_INLINE_TYPE\n+\/\/ and ends with an extra T_VOID. T_INLINE_TYPE\/T_VOID pairs are used as\n+\/\/ delimiters. Every entry between the two is a field of the inline\n+\/\/ type. If there's an embedded inline type in the list, it also starts\n+\/\/ with a T_INLINE_TYPE and ends with a T_VOID. This is so we can\n+\/\/ generate a unique fingerprint for the method's adapters and we can\n+\/\/ generate the list of basic types from the interpreter point of view\n+\/\/ (inline types passed as reference: iterate on the list until a\n+\/\/ T_INLINE_TYPE, drop everything until and including the closing\n+\/\/ T_VOID) or the compiler point of view (each field of the inline\n+\/\/ types is an argument: drop all T_INLINE_TYPE\/T_VOID from the list).\n+int InlineKlass::collect_fields(GrowableArray<SigEntry>* sig, int base_off) {\n+  int count = 0;\n+  SigEntry::add_entry(sig, T_INLINE_TYPE, name(), base_off);\n+  for (JavaFieldStream fs(this); !fs.done(); fs.next()) {\n+    if (fs.access_flags().is_static()) continue;\n+    int offset = base_off + fs.offset() - (base_off > 0 ? first_field_offset() : 0);\n+    if (fs.is_inlined()) {\n+      \/\/ Resolve klass of inlined field and recursively collect fields\n+      Klass* vk = get_inline_type_field_klass(fs.index());\n+      count += InlineKlass::cast(vk)->collect_fields(sig, offset);\n+    } else {\n+      BasicType bt = Signature::basic_type(fs.signature());\n+      if (bt == T_INLINE_TYPE) {\n+        bt = T_OBJECT;\n+      }\n+      SigEntry::add_entry(sig, bt, fs.signature(), offset);\n+      count += type2size[bt];\n+    }\n+  }\n+  int offset = base_off + size_helper()*HeapWordSize - (base_off > 0 ? first_field_offset() : 0);\n+  SigEntry::add_entry(sig, T_VOID, name(), offset);\n+  if (base_off == 0) {\n+    sig->sort(SigEntry::compare);\n+  }\n+  assert(sig->at(0)._bt == T_INLINE_TYPE && sig->at(sig->length()-1)._bt == T_VOID, \"broken structure\");\n+  return count;\n+}\n+\n+void InlineKlass::initialize_calling_convention(TRAPS) {\n+  \/\/ Because the pack and unpack handler addresses need to be loadable from generated code,\n+  \/\/ they are stored at a fixed offset in the klass metadata. Since inline type klasses do\n+  \/\/ not have a vtable, the vtable offset is used to store these addresses.\n+  if (InlineTypeReturnedAsFields || InlineTypePassFieldsAsArgs) {\n+    ResourceMark rm;\n+    GrowableArray<SigEntry> sig_vk;\n+    int nb_fields = collect_fields(&sig_vk);\n+    Array<SigEntry>* extended_sig = MetadataFactory::new_array<SigEntry>(class_loader_data(), sig_vk.length(), CHECK);\n+    *((Array<SigEntry>**)adr_extended_sig()) = extended_sig;\n+    for (int i = 0; i < sig_vk.length(); i++) {\n+      extended_sig->at_put(i, sig_vk.at(i));\n+    }\n+    if (can_be_returned_as_fields(\/* init= *\/ true)) {\n+      nb_fields++;\n+      BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, nb_fields);\n+      sig_bt[0] = T_METADATA;\n+      SigEntry::fill_sig_bt(&sig_vk, sig_bt+1);\n+      VMRegPair* regs = NEW_RESOURCE_ARRAY(VMRegPair, nb_fields);\n+      int total = SharedRuntime::java_return_convention(sig_bt, regs, nb_fields);\n+\n+      if (total > 0) {\n+        Array<VMRegPair>* return_regs = MetadataFactory::new_array<VMRegPair>(class_loader_data(), nb_fields, CHECK);\n+        *((Array<VMRegPair>**)adr_return_regs()) = return_regs;\n+        for (int i = 0; i < nb_fields; i++) {\n+          return_regs->at_put(i, regs[i]);\n+        }\n+\n+        BufferedInlineTypeBlob* buffered_blob = SharedRuntime::generate_buffered_inline_type_adapter(this);\n+        *((address*)adr_pack_handler()) = buffered_blob->pack_fields();\n+        *((address*)adr_pack_handler_jobject()) = buffered_blob->pack_fields_jobject();\n+        *((address*)adr_unpack_handler()) = buffered_blob->unpack_fields();\n+        assert(CodeCache::find_blob(pack_handler()) == buffered_blob, \"lost track of blob\");\n+        assert(can_be_returned_as_fields(), \"sanity\");\n+      }\n+    }\n+    if (!can_be_returned_as_fields() && !can_be_passed_as_fields()) {\n+      MetadataFactory::free_array<SigEntry>(class_loader_data(), extended_sig);\n+      assert(return_regs() == NULL, \"sanity\");\n+    }\n+  }\n+}\n+\n+void InlineKlass::deallocate_contents(ClassLoaderData* loader_data) {\n+  if (extended_sig() != NULL) {\n+    MetadataFactory::free_array<SigEntry>(loader_data, extended_sig());\n+  }\n+  if (return_regs() != NULL) {\n+    MetadataFactory::free_array<VMRegPair>(loader_data, return_regs());\n+  }\n+  cleanup_blobs();\n+  InstanceKlass::deallocate_contents(loader_data);\n+}\n+\n+void InlineKlass::cleanup(InlineKlass* ik) {\n+  ik->cleanup_blobs();\n+}\n+\n+void InlineKlass::cleanup_blobs() {\n+  if (pack_handler() != NULL) {\n+    CodeBlob* buffered_blob = CodeCache::find_blob(pack_handler());\n+    assert(buffered_blob->is_buffered_inline_type_blob(), \"bad blob type\");\n+    BufferBlob::free((BufferBlob*)buffered_blob);\n+    *((address*)adr_pack_handler()) = NULL;\n+    *((address*)adr_pack_handler_jobject()) = NULL;\n+    *((address*)adr_unpack_handler()) = NULL;\n+  }\n+}\n+\n+\/\/ Can this inline type be scalarized?\n+bool InlineKlass::is_scalarizable() const {\n+  return ScalarizeInlineTypes;\n+}\n+\n+\/\/ Can this inline type be passed as multiple values?\n+bool InlineKlass::can_be_passed_as_fields() const {\n+  return InlineTypePassFieldsAsArgs && is_scalarizable();\n+}\n+\n+\/\/ Can this inline type be returned as multiple values?\n+bool InlineKlass::can_be_returned_as_fields(bool init) const {\n+  return InlineTypeReturnedAsFields && is_scalarizable() && (init || return_regs() != NULL);\n+}\n+\n+\/\/ Create handles for all oop fields returned in registers that are going to be live across a safepoint\n+void InlineKlass::save_oop_fields(const RegisterMap& reg_map, GrowableArray<Handle>& handles) const {\n+  Thread* thread = Thread::current();\n+  const Array<SigEntry>* sig_vk = extended_sig();\n+  const Array<VMRegPair>* regs = return_regs();\n+  int j = 1;\n+\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_OBJECT || bt == T_ARRAY) {\n+      VMRegPair pair = regs->at(j);\n+      address loc = reg_map.location(pair.first());\n+      oop v = *(oop*)loc;\n+      assert(v == NULL || oopDesc::is_oop(v), \"not an oop?\");\n+      assert(Universe::heap()->is_in_or_null(v), \"must be heap pointer\");\n+      handles.push(Handle(thread, v));\n+    }\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID &&\n+        sig_vk->at(i-1)._bt != T_LONG &&\n+        sig_vk->at(i-1)._bt != T_DOUBLE) {\n+      continue;\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+}\n+\n+\/\/ Update oop fields in registers from handles after a safepoint\n+void InlineKlass::restore_oop_results(RegisterMap& reg_map, GrowableArray<Handle>& handles) const {\n+  assert(InlineTypeReturnedAsFields, \"inconsistent\");\n+  const Array<SigEntry>* sig_vk = extended_sig();\n+  const Array<VMRegPair>* regs = return_regs();\n+  assert(regs != NULL, \"inconsistent\");\n+\n+  int j = 1;\n+  for (int i = 0, k = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_OBJECT || bt == T_ARRAY) {\n+      VMRegPair pair = regs->at(j);\n+      address loc = reg_map.location(pair.first());\n+      *(oop*)loc = handles.at(k++)();\n+    }\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID &&\n+        sig_vk->at(i-1)._bt != T_LONG &&\n+        sig_vk->at(i-1)._bt != T_DOUBLE) {\n+      continue;\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+}\n+\n+\/\/ Fields are in registers. Create an instance of the inline type and\n+\/\/ initialize it with the values of the fields.\n+oop InlineKlass::realloc_result(const RegisterMap& reg_map, const GrowableArray<Handle>& handles, TRAPS) {\n+  oop new_vt = allocate_instance(CHECK_NULL);\n+  const Array<SigEntry>* sig_vk = extended_sig();\n+  const Array<VMRegPair>* regs = return_regs();\n+\n+  int j = 1;\n+  int k = 0;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    address loc = reg_map.location(pair.first());\n+    switch(bt) {\n+    case T_BOOLEAN: {\n+      new_vt->bool_field_put(off, *(jboolean*)loc);\n+      break;\n+    }\n+    case T_CHAR: {\n+      new_vt->char_field_put(off, *(jchar*)loc);\n+      break;\n+    }\n+    case T_BYTE: {\n+      new_vt->byte_field_put(off, *(jbyte*)loc);\n+      break;\n+    }\n+    case T_SHORT: {\n+      new_vt->short_field_put(off, *(jshort*)loc);\n+      break;\n+    }\n+    case T_INT: {\n+      new_vt->int_field_put(off, *(jint*)loc);\n+      break;\n+    }\n+    case T_LONG: {\n+#ifdef _LP64\n+      new_vt->double_field_put(off,  *(jdouble*)loc);\n+#else\n+      Unimplemented();\n+#endif\n+      break;\n+    }\n+    case T_OBJECT:\n+    case T_ARRAY: {\n+      Handle handle = handles.at(k++);\n+      new_vt->obj_field_put(off, handle());\n+      break;\n+    }\n+    case T_FLOAT: {\n+      new_vt->float_field_put(off,  *(jfloat*)loc);\n+      break;\n+    }\n+    case T_DOUBLE: {\n+      new_vt->double_field_put(off, *(jdouble*)loc);\n+      break;\n+    }\n+    default:\n+      ShouldNotReachHere();\n+    }\n+    *(intptr_t*)loc = 0xDEAD;\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+  assert(k == handles.length(), \"missed an oop?\");\n+  return new_vt;\n+}\n+\n+\/\/ Check the return register for an InlineKlass oop\n+InlineKlass* InlineKlass::returned_inline_klass(const RegisterMap& map) {\n+  BasicType bt = T_METADATA;\n+  VMRegPair pair;\n+  int nb = SharedRuntime::java_return_convention(&bt, &pair, 1);\n+  assert(nb == 1, \"broken\");\n+\n+  address loc = map.location(pair.first());\n+  intptr_t ptr = *(intptr_t*)loc;\n+  if (is_set_nth_bit(ptr, 0)) {\n+    \/\/ Oop is tagged, must be an InlineKlass oop\n+    clear_nth_bit(ptr, 0);\n+    assert(Metaspace::contains((void*)ptr), \"should be klass\");\n+    InlineKlass* vk = (InlineKlass*)ptr;\n+    assert(vk->can_be_returned_as_fields(), \"must be able to return as fields\");\n+    return vk;\n+  }\n+#ifdef ASSERT\n+  \/\/ Oop is not tagged, must be a valid oop\n+  if (VerifyOops) {\n+    oopDesc::verify(cast_to_oop(ptr));\n+  }\n+#endif\n+  return NULL;\n+}\n+\n+void InlineKlass::verify_on(outputStream* st) {\n+  InstanceKlass::verify_on(st);\n+  guarantee(prototype_header().is_inline_type(), \"Prototype header is not inline type\");\n+}\n+\n+void InlineKlass::oop_verify_on(oop obj, outputStream* st) {\n+  InstanceKlass::oop_verify_on(obj, st);\n+  guarantee(obj->mark().is_inline_type(), \"Header is not inline type\");\n+}\n+\n+void InlineKlass::metaspace_pointers_do(MetaspaceClosure* it) {\n+  InstanceKlass::metaspace_pointers_do(it);\n+\n+  InlineKlass* this_ptr = this;\n+  it->push_internal_pointer(&this_ptr, (intptr_t*)&_adr_inlineklass_fixed_block);\n+}\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.cpp","additions":528,"deletions":0,"binary":false,"changes":528,"status":"added"},{"patch":"@@ -0,0 +1,260 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_VM_OOPS_INLINEKLASS_HPP\n+#define SHARE_VM_OOPS_INLINEKLASS_HPP\n+\n+#include \"classfile\/javaClasses.hpp\"\n+#include \"oops\/instanceKlass.hpp\"\n+#include \"oops\/method.hpp\"\n+#include \"runtime\/registerMap.hpp\"\n+\/\/#include \"oops\/oop.inline.hpp\"\n+\n+\/\/ An InlineKlass is a specialized InstanceKlass for inline types.\n+\n+\n+class InlineKlass: public InstanceKlass {\n+  friend class VMStructs;\n+  friend class InstanceKlass;\n+\n+ public:\n+  InlineKlass() { assert(DumpSharedSpaces || UseSharedSpaces, \"only for CDS\"); }\n+\n+ private:\n+\n+  \/\/ Constructor\n+  InlineKlass(const ClassFileParser& parser);\n+\n+  inline InlineKlassFixedBlock* inlineklass_static_block() const;\n+  inline address adr_return_regs() const;\n+\n+  address adr_extended_sig() const {\n+    assert(_adr_inlineklass_fixed_block != NULL, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _extended_sig));\n+  }\n+\n+  \/\/ pack and unpack handlers for inline types return\n+  address adr_pack_handler() const {\n+    assert(_adr_inlineklass_fixed_block != NULL, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _pack_handler));\n+  }\n+\n+  address adr_pack_handler_jobject() const {\n+    assert(_adr_inlineklass_fixed_block != NULL, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _pack_handler_jobject));\n+  }\n+\n+  address adr_unpack_handler() const {\n+    assert(_adr_inlineklass_fixed_block != NULL, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _unpack_handler));\n+  }\n+\n+  address adr_default_value_offset() const {\n+    assert(_adr_inlineklass_fixed_block != NULL, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(default_value_offset_offset());\n+  }\n+\n+  address adr_alignment() const {\n+    assert(_adr_inlineklass_fixed_block != NULL, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _alignment));\n+  }\n+\n+  address adr_first_field_offset() const {\n+    assert(_adr_inlineklass_fixed_block != NULL, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _first_field_offset));\n+  }\n+\n+  address adr_exact_size_in_bytes() const {\n+    assert(_adr_inlineklass_fixed_block != NULL, \"Should have been initialized\");\n+    return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _exact_size_in_bytes));\n+  }\n+\n+ public:\n+  int get_alignment() const {\n+    return *(int*)adr_alignment();\n+  }\n+\n+  void set_alignment(int alignment) {\n+    *(int*)adr_alignment() = alignment;\n+  }\n+\n+  int first_field_offset() const {\n+    int offset = *(int*)adr_first_field_offset();\n+    assert(offset != 0, \"Must be initialized before use\");\n+    return *(int*)adr_first_field_offset();\n+  }\n+\n+  void set_first_field_offset(int offset) {\n+    *(int*)adr_first_field_offset() = offset;\n+  }\n+\n+  int get_exact_size_in_bytes() const {\n+    return *(int*)adr_exact_size_in_bytes();\n+  }\n+\n+  void set_exact_size_in_bytes(int exact_size) {\n+    *(int*)adr_exact_size_in_bytes() = exact_size;\n+  }\n+\n+  int first_field_offset_old();\n+\n+  virtual void remove_unshareable_info();\n+  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS);\n+  virtual void metaspace_pointers_do(MetaspaceClosure* it);\n+\n+ private:\n+  int collect_fields(GrowableArray<SigEntry>* sig, int base_off = 0);\n+\n+  void cleanup_blobs();\n+\n+\n+ protected:\n+  \/\/ Returns the array class for the n'th dimension\n+  Klass* array_klass_impl(bool or_null, int n, TRAPS);\n+\n+  \/\/ Returns the array class with this class as element type\n+  Klass* array_klass_impl(bool or_null, TRAPS);\n+\n+ public:\n+  \/\/ Type testing\n+  bool is_inline_klass_slow() const        { return true; }\n+\n+  \/\/ Casting from Klass*\n+  static InlineKlass* cast(Klass* k);\n+\n+  \/\/ Use this to return the size of an instance in heap words.\n+  \/\/ Note that this size only applies to heap allocated stand-alone instances.\n+  virtual int size_helper() const {\n+    return layout_helper_to_size_helper(layout_helper());\n+  }\n+\n+  \/\/ allocate_instance() allocates a stand alone value in the Java heap\n+  \/\/ initialized to default value (cleared memory)\n+  instanceOop allocate_instance(TRAPS);\n+  \/\/ allocates a stand alone inline buffer in the Java heap\n+  \/\/ DOES NOT have memory cleared, user MUST initialize payload before\n+  \/\/ returning to Java (i.e.: inline_copy)\n+  instanceOop allocate_instance_buffer(TRAPS);\n+\n+  address data_for_oop(oop o) const;\n+\n+  \/\/ Query if this class promises atomicity one way or another\n+  bool is_atomic() { return is_naturally_atomic() || is_declared_atomic(); }\n+\n+  bool flatten_array();\n+\n+  bool contains_oops() const { return nonstatic_oop_map_count() > 0; }\n+  int nonstatic_oop_count();\n+\n+  \/\/ General store methods\n+  \/\/\n+  \/\/ Normally loads and store methods would be found in *Oops classes, but since values can be\n+  \/\/ \"in-lined\" (flattened) into containing oops, these methods reside here in InlineKlass.\n+  \/\/\n+  \/\/ \"inline_copy_*_to_new_*\" assume new memory (i.e. IS_DEST_UNINITIALIZED for write barriers)\n+\n+  void inline_copy_payload_to_new_oop(void* src, oop dst);\n+  void inline_copy_oop_to_new_oop(oop src, oop dst);\n+  void inline_copy_oop_to_new_payload(oop src, void* dst);\n+  void inline_copy_oop_to_payload(oop src, void* dst);\n+\n+  oop read_inlined_field(oop obj, int offset, TRAPS);\n+  void write_inlined_field(oop obj, int offset, oop value, TRAPS);\n+\n+  \/\/ oop iterate raw inline type data pointer (where oop_addr may not be an oop, but backing\/array-element)\n+  template <typename T, class OopClosureType>\n+  inline void oop_iterate_specialized(const address oop_addr, OopClosureType* closure);\n+\n+  template <typename T, class OopClosureType>\n+  inline void oop_iterate_specialized_bounded(const address oop_addr, OopClosureType* closure, void* lo, void* hi);\n+\n+  \/\/ calling convention support\n+  void initialize_calling_convention(TRAPS);\n+  Array<SigEntry>* extended_sig() const {\n+    return *((Array<SigEntry>**)adr_extended_sig());\n+  }\n+  inline Array<VMRegPair>* return_regs() const;\n+  bool is_scalarizable() const;\n+  bool can_be_passed_as_fields() const;\n+  bool can_be_returned_as_fields(bool init = false) const;\n+  void save_oop_fields(const RegisterMap& map, GrowableArray<Handle>& handles) const;\n+  void restore_oop_results(RegisterMap& map, GrowableArray<Handle>& handles) const;\n+  oop realloc_result(const RegisterMap& reg_map, const GrowableArray<Handle>& handles, TRAPS);\n+  static InlineKlass* returned_inline_klass(const RegisterMap& reg_map);\n+\n+  address pack_handler() const {\n+    return *(address*)adr_pack_handler();\n+  }\n+\n+  address unpack_handler() const {\n+    return *(address*)adr_unpack_handler();\n+  }\n+\n+  \/\/ pack and unpack handlers. Need to be loadable from generated code\n+  \/\/ so at a fixed offset from the base of the klass pointer.\n+  static ByteSize pack_handler_offset() {\n+    return byte_offset_of(InlineKlassFixedBlock, _pack_handler);\n+  }\n+\n+  static ByteSize pack_handler_jobject_offset() {\n+    return byte_offset_of(InlineKlassFixedBlock, _pack_handler_jobject);\n+  }\n+\n+  static ByteSize unpack_handler_offset() {\n+    return byte_offset_of(InlineKlassFixedBlock, _unpack_handler);\n+  }\n+\n+  static ByteSize default_value_offset_offset() {\n+    return byte_offset_of(InlineKlassFixedBlock, _default_value_offset);\n+  }\n+\n+  static ByteSize first_field_offset_offset() {\n+    return byte_offset_of(InlineKlassFixedBlock, _first_field_offset);\n+  }\n+\n+  void set_default_value_offset(int offset) {\n+    *((int*)adr_default_value_offset()) = offset;\n+  }\n+\n+  int default_value_offset() {\n+    int offset = *((int*)adr_default_value_offset());\n+    assert(offset != 0, \"must not be called if not initialized\");\n+    return offset;\n+  }\n+\n+  void set_default_value(oop val) {\n+    java_mirror()->obj_field_put(default_value_offset(), val);\n+  }\n+\n+  oop default_value();\n+  void deallocate_contents(ClassLoaderData* loader_data);\n+  static void cleanup(InlineKlass* ik) ;\n+\n+  \/\/ Verification\n+  void verify_on(outputStream* st);\n+  void oop_verify_on(oop obj, outputStream* st);\n+\n+};\n+\n+#endif \/* SHARE_VM_OOPS_INLINEKLASS_HPP *\/\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.hpp","additions":260,"deletions":0,"binary":false,"changes":260,"status":"added"},{"patch":"@@ -0,0 +1,132 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+#ifndef SHARE_VM_OOPS_INLINEKLASS_INLINE_HPP\n+#define SHARE_VM_OOPS_INLINEKLASS_INLINE_HPP\n+\n+#include \"memory\/iterator.hpp\"\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n+#include \"oops\/instanceKlass.inline.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+inline InlineKlassFixedBlock* InlineKlass::inlineklass_static_block() const {\n+  address adr_jf = adr_inline_type_field_klasses();\n+  if (adr_jf != NULL) {\n+    return (InlineKlassFixedBlock*)(adr_jf + this->java_fields_count() * sizeof(Klass*));\n+  }\n+\n+  address adr_fing = adr_fingerprint();\n+  if (adr_fing != NULL) {\n+    return (InlineKlassFixedBlock*)(adr_fingerprint() + sizeof(u8));\n+  }\n+\n+  InstanceKlass** adr_host = adr_unsafe_anonymous_host();\n+  if (adr_host != NULL) {\n+    return (InlineKlassFixedBlock*)(adr_host + 1);\n+  }\n+\n+  InstanceKlass* volatile* adr_impl = adr_implementor();\n+  if (adr_impl != NULL) {\n+    return (InlineKlassFixedBlock*)(adr_impl + 1);\n+  }\n+\n+  return (InlineKlassFixedBlock*)end_of_nonstatic_oop_maps();\n+}\n+\n+inline address InlineKlass::adr_return_regs() const {\n+  InlineKlassFixedBlock* vkst = inlineklass_static_block();\n+  return ((address)_adr_inlineklass_fixed_block) + in_bytes(byte_offset_of(InlineKlassFixedBlock, _return_regs));\n+}\n+\n+inline Array<VMRegPair>* InlineKlass::return_regs() const {\n+  return *((Array<VMRegPair>**)adr_return_regs());\n+}\n+\n+\n+inline InlineKlass* InlineKlass::cast(Klass* k) {\n+  assert(k->is_inline_klass(), \"cast to InlineKlass\");\n+  return (InlineKlass*) k;\n+}\n+\n+inline address InlineKlass::data_for_oop(oop o) const {\n+  return ((address) (void*) o) + first_field_offset();\n+}\n+\n+inline void InlineKlass::inline_copy_payload_to_new_oop(void* src, oop dst) {\n+  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(src, data_for_oop(dst), this);\n+}\n+\n+inline void InlineKlass::inline_copy_oop_to_new_oop(oop src, oop dst) {\n+  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(data_for_oop(src), data_for_oop(dst), this);\n+}\n+\n+inline void InlineKlass::inline_copy_oop_to_new_payload(oop src, void* dst) {\n+  HeapAccess<IS_DEST_UNINITIALIZED>::value_copy(data_for_oop(src), dst, this);\n+}\n+\n+inline void InlineKlass::inline_copy_oop_to_payload(oop src, void* dst) {\n+  HeapAccess<>::value_copy(data_for_oop(src), dst, this);\n+}\n+\n+\n+template <typename T, class OopClosureType>\n+void InlineKlass::oop_iterate_specialized(const address oop_addr, OopClosureType* closure) {\n+  OopMapBlock* map = start_of_nonstatic_oop_maps();\n+  OopMapBlock* const end_map = map + nonstatic_oop_map_count();\n+\n+  for (; map < end_map; map++) {\n+    T* p = (T*) (oop_addr + map->offset());\n+    T* const end = p + map->count();\n+    for (; p < end; ++p) {\n+      Devirtualizer::do_oop(closure, p);\n+    }\n+  }\n+}\n+\n+template <typename T, class OopClosureType>\n+inline void InlineKlass::oop_iterate_specialized_bounded(const address oop_addr, OopClosureType* closure, void* lo, void* hi) {\n+  OopMapBlock* map = start_of_nonstatic_oop_maps();\n+  OopMapBlock* const end_map = map + nonstatic_oop_map_count();\n+\n+  T* const l   = (T*) lo;\n+  T* const h   = (T*) hi;\n+\n+  for (; map < end_map; map++) {\n+    T* p = (T*) (oop_addr + map->offset());\n+    T* end = p + map->count();\n+    if (p < l) {\n+      p = l;\n+    }\n+    if (end > h) {\n+      end = h;\n+    }\n+    for (; p < end; ++p) {\n+      Devirtualizer::do_oop(closure, p);\n+    }\n+  }\n+}\n+\n+\n+#endif \/\/ SHARE_VM_OOPS_INLINEKLASS_INLINE_HPP\n","filename":"src\/hotspot\/share\/oops\/inlineKlass.inline.hpp","additions":132,"deletions":0,"binary":false,"changes":132,"status":"added"},{"patch":"@@ -72,0 +72,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -164,0 +165,2 @@\n+bool InstanceKlass::field_is_inline_type(int index) const { return Signature::basic_type(field(index)->signature(constants())) == T_INLINE_TYPE; }\n+\n@@ -471,1 +474,3 @@\n-                                       should_store_fingerprint(is_hidden_or_anonymous));\n+                                       should_store_fingerprint(is_hidden_or_anonymous),\n+                                       parser.has_inline_fields() ? parser.java_fields_count() : 0,\n+                                       parser.is_inline_type());\n@@ -485,2 +490,1 @@\n-    }\n-    else if (is_class_loader(class_name, parser)) {\n+    } else if (is_class_loader(class_name, parser)) {\n@@ -489,0 +493,3 @@\n+    } else if (parser.is_inline_type()) {\n+      \/\/ inline type\n+      ik = new (loader_data, size, THREAD) InlineKlass(parser);\n@@ -504,0 +511,7 @@\n+#ifdef ASSERT\n+  assert(ik->size() == size, \"\");\n+  ik->bounds_check((address) ik->start_of_vtable(), false, size);\n+  ik->bounds_check((address) ik->start_of_itable(), false, size);\n+  ik->bounds_check((address) ik->end_of_itable(), true, size);\n+  ik->bounds_check((address) ik->end_of_nonstatic_oop_maps(), true, size);\n+#endif \/\/ASSERT\n@@ -507,0 +521,23 @@\n+#ifndef PRODUCT\n+bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {\n+  const char* bad = NULL;\n+  address end = NULL;\n+  if (addr < (address)this) {\n+    bad = \"before\";\n+  } else if (addr == (address)this) {\n+    if (edge_ok)  return true;\n+    bad = \"just before\";\n+  } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes < 0 ? size() : size_in_bytes))) {\n+    if (edge_ok)  return true;\n+    bad = \"just after\";\n+  } else if (addr > end) {\n+    bad = \"after\";\n+  } else {\n+    return true;\n+  }\n+  tty->print_cr(\"%s object bounds: \" INTPTR_FORMAT \" [\" INTPTR_FORMAT \"..\" INTPTR_FORMAT \"]\",\n+      bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);\n+  Verbose = WizardMode = true; this->print(); \/\/@@\n+  return false;\n+}\n+#endif \/\/PRODUCT\n@@ -541,1 +578,3 @@\n-  _init_thread(NULL)\n+  _init_thread(NULL),\n+  _inline_type_field_klasses(NULL),\n+  _adr_inlineklass_fixed_block(NULL)\n@@ -550,0 +589,4 @@\n+    if (parser.has_inline_fields()) {\n+      set_has_inline_type_fields();\n+    }\n+    _java_fields_count = parser.java_fields_count();\n@@ -551,3 +594,3 @@\n-  assert(NULL == _methods, \"underlying memory not zeroed?\");\n-  assert(is_instance_klass(), \"is layout incorrect?\");\n-  assert(size_helper() == parser.layout_size(), \"incorrect size_helper?\");\n+    assert(NULL == _methods, \"underlying memory not zeroed?\");\n+    assert(is_instance_klass(), \"is layout incorrect?\");\n+    assert(size_helper() == parser.layout_size(), \"incorrect size_helper?\");\n@@ -560,0 +603,3 @@\n+  if (has_inline_type_fields()) {\n+    _inline_type_field_klasses = (const Klass**) adr_inline_type_field_klasses();\n+  }\n@@ -589,1 +635,3 @@\n-    if (ti != sti && ti != NULL && !ti->is_shared()) {\n+    if (ti != sti && ti != NULL && !ti->is_shared() &&\n+        ti != Universe::the_single_IdentityObject_klass_array() &&\n+        ti != Universe::the_single_PrimitiveObject_klass_array()) {\n@@ -596,1 +644,3 @@\n-      local_interfaces != NULL && !local_interfaces->is_shared()) {\n+      local_interfaces != NULL && !local_interfaces->is_shared() &&\n+      local_interfaces != Universe::the_single_IdentityObject_klass_array() &&\n+      local_interfaces != Universe::the_single_PrimitiveObject_klass_array()) {\n@@ -928,0 +978,56 @@\n+\n+  \/\/ If a class declares a method that uses an inline class as an argument\n+  \/\/ type or return inline type, this inline class must be loaded during the\n+  \/\/ linking of this class because size and properties of the inline class\n+  \/\/ must be known in order to be able to perform inline type optimizations.\n+  \/\/ The implementation below is an approximation of this rule, the code\n+  \/\/ iterates over all methods of the current class (including overridden\n+  \/\/ methods), not only the methods declared by this class. This\n+  \/\/ approximation makes the code simpler, and doesn't change the semantic\n+  \/\/ because classes declaring methods overridden by the current class are\n+  \/\/ linked (and have performed their own pre-loading) before the linking\n+  \/\/ of the current class.\n+\n+\n+  \/\/ Note:\n+  \/\/ Inline class types are loaded during\n+  \/\/ the loading phase (see ClassFileParser::post_process_parsed_stream()).\n+  \/\/ Inline class types used as element types for array creation\n+  \/\/ are not pre-loaded. Their loading is triggered by either anewarray\n+  \/\/ or multianewarray bytecodes.\n+\n+  \/\/ Could it be possible to do the following processing only if the\n+  \/\/ class uses inline types?\n+  {\n+    ResourceMark rm(THREAD);\n+    for (int i = 0; i < methods()->length(); i++) {\n+      Method* m = methods()->at(i);\n+      for (SignatureStream ss(m->signature()); !ss.is_done(); ss.next()) {\n+        if (ss.is_reference()) {\n+          if (ss.is_array()) {\n+            ss.skip_array_prefix();\n+          }\n+          if (ss.type() == T_INLINE_TYPE) {\n+            Symbol* symb = ss.as_symbol();\n+\n+            oop loader = class_loader();\n+            oop protection_domain = this->protection_domain();\n+            Klass* klass = SystemDictionary::resolve_or_fail(symb,\n+                                                             Handle(THREAD, loader), Handle(THREAD, protection_domain), true,\n+                                                             CHECK_false);\n+            if (klass == NULL) {\n+              THROW_(vmSymbols::java_lang_LinkageError(), false);\n+            }\n+            if (!klass->is_inline_klass()) {\n+              Exceptions::fthrow(\n+                THREAD_AND_LOCATION,\n+                vmSymbols::java_lang_IncompatibleClassChangeError(),\n+                \"class %s is not an inline type\",\n+                klass->external_name());\n+            }\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n@@ -999,0 +1105,1 @@\n+\n@@ -1149,0 +1256,29 @@\n+  \/\/ Step 8\n+  \/\/ Initialize classes of inline fields\n+  {\n+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {\n+        Klass* klass = get_inline_type_field_klass_or_null(fs.index());\n+        if (fs.access_flags().is_static() && klass == NULL) {\n+          klass = SystemDictionary::resolve_or_fail(field_signature(fs.index())->fundamental_name(THREAD),\n+              Handle(THREAD, class_loader()),\n+              Handle(THREAD, protection_domain()),\n+              true, CHECK);\n+          if (klass == NULL) {\n+            THROW(vmSymbols::java_lang_NoClassDefFoundError());\n+          }\n+          if (!klass->is_inline_klass()) {\n+            THROW(vmSymbols::java_lang_IncompatibleClassChangeError());\n+          }\n+          set_inline_type_field_klass(fs.index(), klass);\n+        }\n+        InstanceKlass::cast(klass)->initialize(CHECK);\n+        if (fs.access_flags().is_static()) {\n+          if (java_mirror()->obj_field(fs.offset()) == NULL) {\n+            java_mirror()->obj_field_put(fs.offset(), InlineKlass::cast(klass)->default_value());\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1153,1 +1289,1 @@\n-  \/\/ Step 8\n+  \/\/ Step 9\n@@ -1175,1 +1311,1 @@\n-  \/\/ Step 9\n+  \/\/ Step 10\n@@ -1183,1 +1319,1 @@\n-    \/\/ Step 10 and 11\n+    \/\/ Step 11 and 12\n@@ -1455,1 +1591,1 @@\n-  ObjArrayKlass* oak = array_klasses();\n+  ArrayKlass* oak = array_klasses();\n@@ -1471,1 +1607,1 @@\n-  if (clinit != NULL && clinit->has_valid_initializer_flags()) {\n+  if (clinit != NULL && clinit->is_class_initializer()) {\n@@ -1509,1 +1645,1 @@\n-    MutexLocker x(OopMapCacheAlloc_lock);\n+    MutexLocker x(OopMapCacheAlloc_lock,  Mutex::_no_safepoint_check_flag);\n@@ -1521,5 +1657,0 @@\n-bool InstanceKlass::contains_field_offset(int offset) {\n-  fieldDescriptor fd;\n-  return find_field_from_offset(offset, false, &fd);\n-}\n-\n@@ -1596,0 +1727,9 @@\n+bool InstanceKlass::contains_field_offset(int offset) {\n+  if (this->is_inline_klass()) {\n+    InlineKlass* vk = InlineKlass::cast(this);\n+    return offset >= vk->first_field_offset() && offset < (vk->first_field_offset() + vk->get_exact_size_in_bytes());\n+  } else {\n+    fieldDescriptor fd;\n+    return find_field_from_offset(offset, false, &fd);\n+  }\n+}\n@@ -1983,0 +2123,3 @@\n+    if (name == vmSymbols::object_initializer_name()) {\n+      break;  \/\/ <init> is never inherited, not even as a static factory\n+    }\n@@ -2491,0 +2634,6 @@\n+\n+  if (has_inline_type_fields()) {\n+    for (int i = 0; i < java_fields_count(); i++) {\n+      it->push(&((Klass**)adr_inline_type_field_klasses())[i]);\n+    }\n+  }\n@@ -2526,0 +2675,8 @@\n+  if (has_inline_type_fields()) {\n+    for (AllFieldStream fs(fields(), constants()); !fs.done(); fs.next()) {\n+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {\n+        reset_inline_type_field_klass(fs.index());\n+      }\n+    }\n+  }\n+\n@@ -2586,0 +2743,4 @@\n+  if (is_inline_klass()) {\n+    InlineKlass::cast(this)->initialize_calling_convention(CHECK);\n+  }\n+\n@@ -2617,1 +2778,1 @@\n-  if (UseBiasedLocking && BiasedLocking::enabled()) {\n+  if (UseBiasedLocking && BiasedLocking::enabled() && !is_inline_klass()) {\n@@ -2788,1 +2949,1 @@\n-  \/\/ Add L as type indicator\n+  \/\/ Add L or Q as type indicator\n@@ -2790,1 +2951,1 @@\n-  dest[dest_index++] = JVM_SIGNATURE_CLASS;\n+  dest[dest_index++] = is_inline_klass() ? JVM_SIGNATURE_INLINE_TYPE : JVM_SIGNATURE_CLASS;\n@@ -3392,1 +3553,4 @@\n-static void print_vtable(intptr_t* start, int len, outputStream* st) {\n+static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {\n+  ResourceMark rm;\n+  int* forward_refs = NEW_RESOURCE_ARRAY(int, len);\n+  for (int i = 0; i < len; i++)  forward_refs[i] = 0;\n@@ -3396,0 +3560,5 @@\n+    if (forward_refs[i] != 0) {\n+      int from = forward_refs[i];\n+      int off = (int) start[from];\n+      st->print(\" (offset %d <= [%d])\", off, from);\n+    }\n@@ -3399,0 +3568,6 @@\n+    } else if (self != NULL && e > 0 && e < 0x10000) {\n+      address location = self + e;\n+      int index = (int)((intptr_t*)location - start);\n+      st->print(\" (offset %d => [%d])\", (int)e, index);\n+      if (index >= 0 && index < len)\n+        forward_refs[index] = i;\n@@ -3405,1 +3580,22 @@\n-  return print_vtable(reinterpret_cast<intptr_t*>(start), len, st);\n+  return print_vtable(NULL, reinterpret_cast<intptr_t*>(start), len, st);\n+}\n+\n+template<typename T>\n+ static void print_array_on(outputStream* st, Array<T>* array) {\n+   if (array == NULL) { st->print_cr(\"NULL\"); return; }\n+   array->print_value_on(st); st->cr();\n+   if (Verbose || WizardMode) {\n+     for (int i = 0; i < array->length(); i++) {\n+       st->print(\"%d : \", i); array->at(i)->print_value_on(st); st->cr();\n+     }\n+   }\n+ }\n+\n+static void print_array_on(outputStream* st, Array<int>* array) {\n+  if (array == NULL) { st->print_cr(\"NULL\"); return; }\n+  array->print_value_on(st); st->cr();\n+  if (Verbose || WizardMode) {\n+    for (int i = 0; i < array->length(); i++) {\n+      st->print(\"%d : %d\", i, array->at(i)); st->cr();\n+    }\n+  }\n@@ -3415,0 +3611,1 @@\n+  st->print(BULLET\"misc flags:        0x%x\", _misc_flags);                        st->cr();\n@@ -3441,15 +3638,3 @@\n-  st->print(BULLET\"methods:           \"); methods()->print_value_on(st);                  st->cr();\n-  if (Verbose || WizardMode) {\n-    Array<Method*>* method_array = methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n-  st->print(BULLET\"method ordering:   \"); method_ordering()->print_value_on(st);      st->cr();\n-  st->print(BULLET\"default_methods:   \"); default_methods()->print_value_on(st);      st->cr();\n-  if (Verbose && default_methods() != NULL) {\n-    Array<Method*>* method_array = default_methods();\n-    for (int i = 0; i < method_array->length(); i++) {\n-      st->print(\"%d : \", i); method_array->at(i)->print_value(); st->cr();\n-    }\n-  }\n+  st->print(BULLET\"methods:           \"); print_array_on(st, methods());\n+  st->print(BULLET\"method ordering:   \"); print_array_on(st, method_ordering());\n+  st->print(BULLET\"default_methods:   \"); print_array_on(st, default_methods());\n@@ -3457,1 +3642,1 @@\n-    st->print(BULLET\"default vtable indices:   \"); default_vtable_indices()->print_value_on(st);       st->cr();\n+    st->print(BULLET\"default vtable indices:   \"); print_array_on(st, default_vtable_indices());\n@@ -3459,2 +3644,2 @@\n-  st->print(BULLET\"local interfaces:  \"); local_interfaces()->print_value_on(st);      st->cr();\n-  st->print(BULLET\"trans. interfaces: \"); transitive_interfaces()->print_value_on(st); st->cr();\n+  st->print(BULLET\"local interfaces:  \"); print_array_on(st, local_interfaces());\n+  st->print(BULLET\"trans. interfaces: \"); print_array_on(st, transitive_interfaces());\n@@ -3517,1 +3702,1 @@\n-  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(start_of_itable(), itable_length(), st);\n+  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(NULL, start_of_itable(), itable_length(), st);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":229,"deletions":44,"binary":false,"changes":273,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"code\/vmreg.hpp\"\n@@ -56,0 +57,2 @@\n+\/\/    [EMBEDDED inline_type_field_klasses] only if has_inline_fields() == true\n+\/\/    [EMBEDDED InlineKlassFixedBlock] only if is an InlineKlass instance\n@@ -72,0 +75,1 @@\n+class BufferedInlineTypeBlob;\n@@ -134,0 +138,16 @@\n+class SigEntry;\n+\n+class InlineKlassFixedBlock {\n+  Array<SigEntry>** _extended_sig;\n+  Array<VMRegPair>** _return_regs;\n+  address* _pack_handler;\n+  address* _pack_handler_jobject;\n+  address* _unpack_handler;\n+  int* _default_value_offset;\n+  int _alignment;\n+  int _first_field_offset;\n+  int _exact_size_in_bytes;\n+\n+  friend class InlineKlass;\n+};\n+\n@@ -139,0 +159,1 @@\n+  friend class TemplateTable;\n@@ -156,1 +177,1 @@\n-    fully_initialized,                  \/\/ initialized (successfull final state)\n+    fully_initialized,                  \/\/ initialized (successful final state)\n@@ -172,1 +193,1 @@\n-  ObjArrayKlass* volatile _array_klasses;\n+  ArrayKlass* volatile _array_klasses;\n@@ -239,1 +260,1 @@\n-  \/\/ This can be used to quickly discriminate among the four kinds of\n+  \/\/ This can be used to quickly discriminate among the five kinds of\n@@ -245,0 +266,1 @@\n+  static const unsigned _kind_inline_type  = 4; \/\/ InlineKlass\n@@ -266,1 +288,9 @@\n-    _misc_has_contended_annotations           = 1 << 15  \/\/ has @Contended annotation\n+    _misc_has_contended_annotations           = 1 << 15,  \/\/ has @Contended annotation\n+    _misc_has_inline_type_fields              = 1 << 16, \/\/ has inline fields and related embedded section is not empty\n+    _misc_is_empty_inline_type                = 1 << 17, \/\/ empty inline type (*)\n+    _misc_is_naturally_atomic                 = 1 << 18, \/\/ loaded\/stored in one instruction\n+    _misc_is_declared_atomic                  = 1 << 19, \/\/ implements jl.NonTearable\n+    _misc_invalid_inline_super                = 1 << 20, \/\/ invalid super type for an inline type\n+    _misc_invalid_identity_super              = 1 << 21, \/\/ invalid super type for an identity type\n+    _misc_has_injected_identityObject         = 1 << 22, \/\/ IdentityObject has been injected by the JVM\n+    _misc_has_injected_primitiveObject        = 1 << 23  \/\/ PrimitiveObject has been injected by the JVM\n@@ -268,0 +298,6 @@\n+\n+  \/\/ (*) An inline type is considered empty if it contains no non-static fields or\n+  \/\/ if it contains only empty inline fields. Note that JITs have a slightly different\n+  \/\/ definition: empty inline fields must be flattened otherwise the container won't\n+  \/\/ be considered empty\n+\n@@ -271,1 +307,1 @@\n-  u2              _misc_flags;           \/\/ There is more space in access_flags for more flags.\n+  u4              _misc_flags;           \/\/ There is more space in access_flags for more flags.\n@@ -323,0 +359,3 @@\n+  const Klass**   _inline_type_field_klasses; \/\/ For \"inline class\" fields, NULL if none present\n+\n+  const InlineKlassFixedBlock* _adr_inlineklass_fixed_block;\n@@ -386,0 +425,73 @@\n+  bool has_inline_type_fields() const          {\n+    return (_misc_flags & _misc_has_inline_type_fields) != 0;\n+  }\n+  void set_has_inline_type_fields()  {\n+    _misc_flags |= _misc_has_inline_type_fields;\n+  }\n+\n+  bool is_empty_inline_type() const {\n+    return (_misc_flags & _misc_is_empty_inline_type) != 0;\n+  }\n+  void set_is_empty_inline_type() {\n+    _misc_flags |= _misc_is_empty_inline_type;\n+  }\n+\n+  \/\/ Note:  The naturally_atomic property only applies to\n+  \/\/ inline classes; it is never true on identity classes.\n+  \/\/ The bit is placed on instanceKlass for convenience.\n+\n+  \/\/ Query if h\/w provides atomic load\/store for instances.\n+  bool is_naturally_atomic() const {\n+    return (_misc_flags & _misc_is_naturally_atomic) != 0;\n+  }\n+  \/\/ Initialized in the class file parser, not changed later.\n+  void set_is_naturally_atomic() {\n+    _misc_flags |= _misc_is_naturally_atomic;\n+  }\n+\n+  \/\/ Query if this class implements jl.NonTearable or was\n+  \/\/ mentioned in the JVM option ForceNonTearable.\n+  \/\/ This bit can occur anywhere, but is only significant\n+  \/\/ for inline classes *and* their super types.\n+  \/\/ It inherits from supers along with NonTearable.\n+  bool is_declared_atomic() const {\n+    return (_misc_flags & _misc_is_declared_atomic) != 0;\n+  }\n+  \/\/ Initialized in the class file parser, not changed later.\n+  void set_is_declared_atomic() {\n+    _misc_flags |= _misc_is_declared_atomic;\n+  }\n+\n+  \/\/ Query if class is an invalid super class for an inline type.\n+  bool invalid_inline_super() const {\n+    return (_misc_flags & _misc_invalid_inline_super) != 0;\n+  }\n+  \/\/ Initialized in the class file parser, not changed later.\n+  void set_invalid_inline_super() {\n+    _misc_flags |= _misc_invalid_inline_super;\n+  }\n+  \/\/ Query if class is an invalid super class for an identity type.\n+  bool invalid_identity_super() const {\n+    return (_misc_flags & _misc_invalid_identity_super) != 0;\n+  }\n+  \/\/ Initialized in the class file parser, not changed later.\n+  void set_invalid_identity_super() {\n+    _misc_flags |= _misc_invalid_identity_super;\n+  }\n+\n+  bool has_injected_identityObject() const {\n+    return (_misc_flags & _misc_has_injected_identityObject);\n+  }\n+\n+  void set_has_injected_identityObject() {\n+    _misc_flags |= _misc_has_injected_identityObject;\n+  }\n+\n+  bool has_injected_primitiveObject() const {\n+    return (_misc_flags & _misc_has_injected_primitiveObject);\n+  }\n+\n+  void set_has_injected_primitiveObject() {\n+    _misc_flags |= _misc_has_injected_primitiveObject;\n+  }\n+\n@@ -401,4 +513,4 @@\n-  ObjArrayKlass* array_klasses() const     { return _array_klasses; }\n-  inline ObjArrayKlass* array_klasses_acquire() const; \/\/ load with acquire semantics\n-  void set_array_klasses(ObjArrayKlass* k) { _array_klasses = k; }\n-  inline void release_set_array_klasses(ObjArrayKlass* k); \/\/ store with release semantics\n+  ArrayKlass* array_klasses() const     { return _array_klasses; }\n+  inline ArrayKlass* array_klasses_acquire() const; \/\/ load with acquire semantics\n+  void set_array_klasses(ArrayKlass* k) { _array_klasses = k; }\n+  inline void release_set_array_klasses(ArrayKlass* k); \/\/ store with release semantics\n@@ -448,0 +560,2 @@\n+  bool    field_is_inlined(int index) const { return field(index)->is_inlined(); }\n+  bool    field_is_inline_type(int index) const;\n@@ -575,0 +689,4 @@\n+  static ByteSize kind_offset() { return in_ByteSize(offset_of(InstanceKlass, _kind)); }\n+  static ByteSize misc_flags_offset() { return in_ByteSize(offset_of(InstanceKlass, _misc_flags)); }\n+  static u4 misc_flags_is_empty_inline_type() { return _misc_is_empty_inline_type; }\n+\n@@ -757,0 +875,1 @@\n+\n@@ -758,1 +877,1 @@\n-    return ((_misc_flags & _misc_is_being_redefined) != 0);\n+    return (_misc_flags & _misc_is_being_redefined);\n@@ -843,0 +962,1 @@\n+  bool is_inline_type_klass()           const { return is_kind(_kind_inline_type); }\n@@ -1012,0 +1132,3 @@\n+  static ByteSize inline_type_field_klasses_offset() { return in_ByteSize(offset_of(InstanceKlass, _inline_type_field_klasses)); }\n+  static ByteSize adr_inlineklass_fixed_block_offset() { return in_ByteSize(offset_of(InstanceKlass, _adr_inlineklass_fixed_block)); }\n+\n@@ -1046,2 +1169,2 @@\n-  void array_klasses_do(void f(Klass* k));\n-  void array_klasses_do(void f(Klass* k, TRAPS), TRAPS);\n+  virtual void array_klasses_do(void f(Klass* k));\n+  virtual void array_klasses_do(void f(Klass* k, TRAPS), TRAPS);\n@@ -1068,1 +1191,2 @@\n-                  bool is_interface, bool is_unsafe_anonymous, bool has_stored_fingerprint) {\n+                  bool is_interface, bool is_unsafe_anonymous, bool has_stored_fingerprint,\n+                  int java_fields, bool is_inline_type) {\n@@ -1075,1 +1199,3 @@\n-           (has_stored_fingerprint ? (int)sizeof(uint64_t*)\/wordSize : 0));\n+           (has_stored_fingerprint ? (int)sizeof(uint64_t*)\/wordSize : 0) +\n+           (java_fields * (int)sizeof(Klass*)\/wordSize) +\n+           (is_inline_type ? (int)sizeof(InlineKlassFixedBlock) : 0));\n@@ -1082,1 +1208,3 @@\n-                                               has_stored_fingerprint());\n+                                               has_stored_fingerprint(),\n+                                               has_inline_type_fields() ? java_fields_count() : 0,\n+                                               is_inline_klass());\n@@ -1089,0 +1217,1 @@\n+  bool bounds_check(address addr, bool edge_ok = false, intptr_t size_in_bytes = -1) const PRODUCT_RETURN0;\n@@ -1097,0 +1226,6 @@\n+  inline address adr_inline_type_field_klasses() const;\n+  inline Klass* get_inline_type_field_klass(int idx) const;\n+  inline Klass* get_inline_type_field_klass_or_null(int idx) const;\n+  inline void set_inline_type_field_klass(int idx, Klass* k);\n+  inline void reset_inline_type_field_klass(int idx);\n+\n@@ -1098,1 +1233,1 @@\n-  int size_helper() const {\n+  virtual int size_helper() const {\n@@ -1237,1 +1372,1 @@\n-\n+protected:\n@@ -1239,1 +1374,1 @@\n-  Klass* array_klass_impl(bool or_null, int n, TRAPS);\n+  virtual Klass* array_klass_impl(bool or_null, int n, TRAPS);\n@@ -1242,1 +1377,3 @@\n-  Klass* array_klass_impl(bool or_null, TRAPS);\n+  virtual Klass* array_klass_impl(bool or_null, TRAPS);\n+\n+private:\n@@ -1272,1 +1409,1 @@\n-  void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS);\n+  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":157,"deletions":20,"binary":false,"changes":177,"status":"modified"},{"patch":"@@ -220,1 +220,1 @@\n-  int lh = array_layout_helper(tag, hsize, etype, exact_log2(esize));\n+  int lh = array_layout_helper(tag, false, hsize, etype, exact_log2(esize));\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+  FlatArrayKlassID,\n@@ -50,1 +51,1 @@\n-const uint KLASS_ID_COUNT = 6;\n+const uint KLASS_ID_COUNT = 7;\n@@ -101,1 +102,1 @@\n-  \/\/    tag is 0x80 if the elements are oops, 0xC0 if non-oops\n+  \/\/    tag is 0x80 if the elements are oops, 0xC0 if non-oops, 0xA0 if value types\n@@ -368,1 +369,1 @@\n-  static const int _lh_array_tag_bits          = 2;\n+  static const int _lh_array_tag_bits          = 3;\n@@ -370,2 +371,10 @@\n-  static const int _lh_array_tag_obj_value     = ~0x01;   \/\/ 0x80000000 >> 30\n-  static const unsigned int _lh_array_tag_type_value = 0Xffffffff; \/\/ ~0x00,  \/\/ 0xC0000000 >> 30\n+  static const unsigned int _lh_array_tag_type_value = 0Xfffffffc;\n+  static const unsigned int _lh_array_tag_vt_value   = 0Xfffffffd;\n+  static const unsigned int _lh_array_tag_obj_value  = 0Xfffffffe;\n+\n+  \/\/ null-free array flag bit under the array tag bits, shift one more to get array tag value\n+  static const int _lh_null_free_shift = _lh_array_tag_shift - 1;\n+  static const int _lh_null_free_mask  = 1;\n+\n+  static const jint _lh_array_tag_vt_value_bit_inplace = (jint) (1 << _lh_array_tag_shift);\n+  static const jint _lh_null_free_bit_inplace = (jint) (_lh_null_free_mask << _lh_null_free_shift);\n@@ -389,2 +398,1 @@\n-    \/\/ _lh_array_tag_type_value == (lh >> _lh_array_tag_shift);\n-    return (juint)lh >= (juint)(_lh_array_tag_type_value << _lh_array_tag_shift);\n+    return (juint) _lh_array_tag_type_value == (juint)(lh >> _lh_array_tag_shift);\n@@ -393,2 +401,13 @@\n-    \/\/ _lh_array_tag_obj_value == (lh >> _lh_array_tag_shift);\n-    return (jint)lh < (jint)(_lh_array_tag_type_value << _lh_array_tag_shift);\n+    return (juint)_lh_array_tag_obj_value == (juint)(lh >> _lh_array_tag_shift);\n+  }\n+  static bool layout_helper_is_flatArray(jint lh) {\n+    return (juint)_lh_array_tag_vt_value == (juint)(lh >> _lh_array_tag_shift);\n+  }\n+  static bool layout_helper_is_null_free(jint lh) {\n+    assert(layout_helper_is_flatArray(lh) || layout_helper_is_objArray(lh), \"must be array of inline types\");\n+    return ((lh >> _lh_null_free_shift) & _lh_null_free_mask);\n+  }\n+  static jint layout_helper_set_null_free(jint lh) {\n+    lh |= (_lh_null_free_mask << _lh_null_free_shift);\n+    assert(layout_helper_is_null_free(lh), \"Bad encoding\");\n+    return lh;\n@@ -405,1 +424,1 @@\n-    assert(btvalue >= T_BOOLEAN && btvalue <= T_OBJECT, \"sanity\");\n+    assert((btvalue >= T_BOOLEAN && btvalue <= T_OBJECT) || btvalue == T_INLINE_TYPE, \"sanity\");\n@@ -426,1 +445,1 @@\n-    assert(l2esz <= LogBytesPerLong,\n+    assert(layout_helper_element_type(lh) == T_INLINE_TYPE || l2esz <= LogBytesPerLong,\n@@ -430,1 +449,1 @@\n-  static jint array_layout_helper(jint tag, int hsize, BasicType etype, int log2_esize) {\n+  static jint array_layout_helper(jint tag, bool null_free, int hsize, BasicType etype, int log2_esize) {\n@@ -432,0 +451,1 @@\n+      |    ((null_free ? 1 : 0) <<  _lh_null_free_shift)\n@@ -568,0 +588,2 @@\n+  \/\/ For value classes, this returns the name with a leading 'Q' and a trailing ';'\n+  \/\/     and the package separators as '\/'.\n@@ -583,0 +605,1 @@\n+  virtual bool is_flatArray_klass_slow()    const { return false; }\n@@ -584,0 +607,2 @@\n+  \/\/ current implementation uses this method even in non debug builds\n+  virtual bool is_inline_klass_slow()       const { return false; }\n@@ -609,0 +634,5 @@\n+  inline  bool is_inline_klass()              const { return is_inline_klass_slow(); } \/\/temporary hack\n+  inline  bool is_flatArray_klass()           const { return assert_same_query(\n+                                                    layout_helper_is_flatArray(layout_helper()),\n+                                                    is_flatArray_klass_slow()); }\n+\n@@ -611,0 +641,2 @@\n+  inline bool is_null_free_array_klass()      const { return layout_helper_is_null_free(layout_helper()); }\n+\n@@ -646,1 +678,4 @@\n-  markWord prototype_header() const      { return _prototype_header; }\n+  markWord prototype_header() const     { return _prototype_header; }\n+  static inline markWord default_prototype_header(Klass* k) {\n+    return (k == NULL) ? markWord::prototype() : k->prototype_header();\n+  }\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":48,"deletions":13,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -54,1 +54,2 @@\n-  assert(!header.has_bias_pattern() || is_instance_klass(), \"biased locking currently only supported for Java instances\");\n+  assert(!is_inline_klass() || header.is_inline_type(), \"Unexpected prototype\");\n+  assert(!UseBiasedLocking || !header.has_bias_pattern() || is_instance_klass(), \"biased locking currently only supported for Java instances\");\n","filename":"src\/hotspot\/share\/oops\/klass.inline.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1228,3 +1228,4 @@\n-  if (m->is_static())           return false;   \/\/ e.g., Stream.empty\n-  if (m->is_initializer())      return false;   \/\/ <init> or <clinit>\n-  if (m->is_private())          return false;   \/\/ uses direct call\n+  if (m->is_static())             return false;   \/\/ e.g., Stream.empty\n+  if (m->is_private())            return false;   \/\/ uses direct call\n+  if (m->is_object_constructor()) return false;   \/\/ <init>(...)V\n+  if (m->is_class_initializer())  return false;   \/\/ <clinit>()V\n@@ -1439,0 +1440,12 @@\n+int count_interface_methods_needing_itable_index(Array<Method*>* methods) {\n+  int method_count = 0;\n+  if (methods->length() > 0) {\n+    for (int i = methods->length(); --i >= 0; ) {\n+      if (interface_method_needs_itable_index(methods->at(i))) {\n+        method_count++;\n+      }\n+    }\n+  }\n+  return method_count;\n+}\n+\n@@ -1507,1 +1520,1 @@\n-  \/\/ There's alway an extra itable entry so we can null-terminate it.\n+  \/\/ There's always an extra itable entry so we can null-terminate it.\n","filename":"src\/hotspot\/share\/oops\/klassVtable.cpp","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -298,1 +298,4 @@\n-  int size_offset_table()                { return _size_offset_table; }\n+  InstanceKlass* klass() const          { return _klass; }\n+  int table_offset() const              { return _table_offset; }\n+  int size_offset_table() const         { return _size_offset_table; }\n+  int size_method_table() const         { return _size_method_table; }\n","filename":"src\/hotspot\/share\/oops\/klassVtable.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -120,1 +121,0 @@\n-\n@@ -157,0 +157,5 @@\n+address Method::get_c2i_inline_entry() {\n+  assert(adapter() != NULL, \"must have\");\n+  return adapter()->get_c2i_inline_entry();\n+}\n+\n@@ -162,0 +167,5 @@\n+address Method::get_c2i_unverified_inline_entry() {\n+  assert(adapter() != NULL, \"must have\");\n+  return adapter()->get_c2i_unverified_inline_entry();\n+}\n+\n@@ -621,0 +631,18 @@\n+\/\/ InlineKlass the method is declared to return. This must not\n+\/\/ safepoint as it is called with references live on the stack at\n+\/\/ locations the GC is unaware of.\n+InlineKlass* Method::returned_inline_type(Thread* thread) const {\n+  SignatureStream ss(signature());\n+  while (!ss.at_return_type()) {\n+    ss.next();\n+  }\n+  Handle class_loader(thread, method_holder()->class_loader());\n+  Handle protection_domain(thread, method_holder()->protection_domain());\n+  Klass* k = NULL;\n+  {\n+    NoSafepointVerifier nsv;\n+    k = ss.as_klass(class_loader, protection_domain, SignatureStream::ReturnNull, thread);\n+  }\n+  assert(k != NULL && !thread->has_pending_exception(), \"can't resolve klass\");\n+  return InlineKlass::cast(k);\n+}\n@@ -631,1 +659,1 @@\n-  \/\/   aload_0\n+  \/\/   aload_0, _fast_aload_0, or _nofast_aload_0\n@@ -655,1 +683,2 @@\n-  if (cb[0] != Bytecodes::_aload_0 || cb[1] != Bytecodes::_invokespecial || cb[last] != Bytecodes::_return) {\n+  if ((cb[0] != Bytecodes::_aload_0 && cb[0] != Bytecodes::_fast_aload_0 && cb[0] != Bytecodes::_nofast_aload_0) ||\n+       cb[1] != Bytecodes::_invokespecial || cb[last] != Bytecodes::_return) {\n@@ -835,2 +864,2 @@\n-bool Method::is_initializer() const {\n-  return is_object_initializer() || is_static_initializer();\n+bool Method::is_object_constructor_or_class_initializer() const {\n+  return (is_object_constructor() || is_class_initializer());\n@@ -839,6 +868,1 @@\n-bool Method::has_valid_initializer_flags() const {\n-  return (is_static() ||\n-          method_holder()->major_version() < 51);\n-}\n-\n-bool Method::is_static_initializer() const {\n+bool Method::is_class_initializer() const {\n@@ -848,2 +872,8 @@\n-  return name() == vmSymbols::class_initializer_name() &&\n-         has_valid_initializer_flags();\n+  return (name() == vmSymbols::class_initializer_name() &&\n+          (is_static() ||\n+           method_holder()->major_version() < 51));\n+}\n+\n+\/\/ A method named <init>, if non-static, is a classic object constructor.\n+bool Method::is_object_constructor() const {\n+   return name() == vmSymbols::object_initializer_name() && !is_static();\n@@ -852,2 +882,3 @@\n-bool Method::is_object_initializer() const {\n-   return name() == vmSymbols::object_initializer_name();\n+\/\/ A static method named <init> is a factory for an inline class.\n+bool Method::is_static_init_factory() const {\n+   return name() == vmSymbols::object_initializer_name() && is_static();\n@@ -911,1 +942,1 @@\n-  if( constants()->tag_at(klass_index).is_unresolved_klass() ) {\n+  if( constants()->tag_at(klass_index).is_unresolved_klass()) {\n@@ -927,1 +958,3 @@\n-    if (constants()->tag_at(klass_index).is_unresolved_klass()) return false;\n+    if (constants()->tag_at(klass_index).is_unresolved_klass()) {\n+      return false;\n+    }\n@@ -1096,0 +1129,2 @@\n+    _from_compiled_inline_entry = NULL;\n+    _from_compiled_inline_ro_entry = NULL;\n@@ -1098,0 +1133,2 @@\n+    _from_compiled_inline_entry = adapter()->get_c2i_inline_entry();\n+    _from_compiled_inline_ro_entry = adapter()->get_c2i_inline_ro_entry();\n@@ -1132,0 +1169,2 @@\n+  _from_compiled_inline_entry = NULL;\n+  _from_compiled_inline_ro_entry = NULL;\n@@ -1202,0 +1241,2 @@\n+  mh->_from_compiled_inline_entry = adapter->get_c2i_inline_entry();\n+  mh->_from_compiled_inline_ro_entry = adapter->get_c2i_inline_ro_entry();\n@@ -1209,1 +1250,1 @@\n-address Method::from_compiled_entry_no_trampoline() const {\n+address Method::from_compiled_entry_no_trampoline(bool caller_is_c1) const {\n@@ -1211,2 +1252,7 @@\n-  if (code) {\n-    return code->verified_entry_point();\n+  if (caller_is_c1) {\n+    \/\/ C1 - inline type arguments are passed as objects\n+    if (code) {\n+      return code->verified_inline_entry_point();\n+    } else {\n+      return adapter()->get_c2i_inline_entry();\n+    }\n@@ -1214,1 +1260,6 @@\n-    return adapter()->get_c2i_entry();\n+    \/\/ C2 - inline type arguments may be passed as fields\n+    if (code) {\n+      return code->verified_entry_point();\n+    } else {\n+      return adapter()->get_c2i_entry();\n+    }\n@@ -1231,0 +1282,12 @@\n+address Method::verified_inline_code_entry() {\n+  debug_only(NoSafepointVerifier nsv;)\n+  assert(_from_compiled_inline_entry != NULL, \"must be set\");\n+  return _from_compiled_inline_entry;\n+}\n+\n+address Method::verified_inline_ro_code_entry() {\n+  debug_only(NoSafepointVerifier nsv;)\n+  assert(_from_compiled_inline_ro_entry != NULL, \"must be set\");\n+  return _from_compiled_inline_ro_entry;\n+}\n+\n@@ -1262,0 +1325,2 @@\n+  mh->_from_compiled_inline_entry = code->verified_inline_entry_point();\n+  mh->_from_compiled_inline_ro_entry = code->verified_inline_ro_entry_point();\n@@ -2293,0 +2358,4 @@\n+#ifdef ASSERT\n+  if (valid_itable_index())\n+    st->print_cr(\" - itable index:      %d\",   itable_index());\n+#endif\n@@ -2300,1 +2369,3 @@\n-  st->print_cr(\" - compiled entry     \" INTPTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled entry           \" INTPTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled inline entry    \" INTPTR_FORMAT, p2i(from_compiled_inline_entry()));\n+  st->print_cr(\" - compiled inline ro entry \" INTPTR_FORMAT, p2i(from_compiled_inline_ro_entry()));\n@@ -2370,0 +2441,1 @@\n+  if (WizardMode) access_flags().print_on(st);\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":94,"deletions":22,"binary":false,"changes":116,"status":"modified"},{"patch":"@@ -94,1 +94,4 @@\n-    _scoped                = 1 << 8\n+    _scalarized_args       = 1 << 8,\n+    _c1_needs_stack_repair = 1 << 9,\n+    _c2_needs_stack_repair = 1 << 10,\n+    _scoped                = 1 << 11\n@@ -107,1 +110,3 @@\n-  volatile address _from_compiled_entry;        \/\/ Cache of: _code ? _code->entry_point() : _adapter->c2i_entry()\n+  volatile address _from_compiled_entry;           \/\/ Cache of: _code ? _code->verified_entry_point()           : _adapter->c2i_entry()\n+  volatile address _from_compiled_inline_ro_entry; \/\/ Cache of: _code ? _code->verified_inline_ro_entry_point() : _adapter->c2i_inline_ro_entry()\n+  volatile address _from_compiled_inline_entry;    \/\/ Cache of: _code ? _code->verified_inline_entry_point()    : _adapter->c2i_inline_entry()\n@@ -146,1 +151,3 @@\n-  address from_compiled_entry_no_trampoline() const;\n+  address from_compiled_inline_ro_entry() const;\n+  address from_compiled_inline_entry() const;\n+  address from_compiled_entry_no_trampoline(bool caller_is_c1) const;\n@@ -452,0 +459,2 @@\n+  address verified_inline_code_entry();\n+  address verified_inline_ro_code_entry();\n@@ -470,1 +479,7 @@\n-    _from_compiled_entry =  entry;\n+    _from_compiled_entry = entry;\n+  }\n+  void set_from_compiled_inline_ro_entry(address entry) {\n+    _from_compiled_inline_ro_entry = entry;\n+  }\n+  void set_from_compiled_inline_entry(address entry) {\n+    _from_compiled_inline_entry = entry;\n@@ -475,0 +490,1 @@\n+  address get_c2i_inline_entry();\n@@ -476,0 +492,1 @@\n+  address get_c2i_unverified_inline_entry();\n@@ -586,1 +603,1 @@\n-  bool is_returning_fp() const                   { BasicType r = result_type(); return (r == T_FLOAT || r == T_DOUBLE); }\n+  InlineKlass* returned_inline_type(Thread* thread) const;\n@@ -659,6 +676,0 @@\n-  \/\/ returns true if the method is an initializer (<init> or <clinit>).\n-  bool is_initializer() const;\n-\n-  \/\/ returns true if the method is static OR if the classfile version < 51\n-  bool has_valid_initializer_flags() const;\n-\n@@ -667,1 +678,4 @@\n-  bool is_static_initializer() const;\n+  bool is_class_initializer() const;\n+\n+  \/\/ returns true if the method name is <init> and the method is not a static factory\n+  bool is_object_constructor() const;\n@@ -669,2 +683,6 @@\n-  \/\/ returns true if the method name is <init>\n-  bool is_object_initializer() const;\n+  \/\/ returns true if the method is an object constructor or class initializer\n+  \/\/ (non-static <init> or <clinit>), but false for factories (static <init>).\n+  bool is_object_constructor_or_class_initializer() const;\n+\n+  \/\/ returns true if the method name is <init> and the method is static\n+  bool is_static_init_factory() const;\n@@ -694,0 +712,2 @@\n+  static ByteSize from_compiled_inline_offset()  { return byte_offset_of(Method, _from_compiled_inline_entry); }\n+  static ByteSize from_compiled_inline_ro_offset(){ return byte_offset_of(Method, _from_compiled_inline_ro_entry); }\n@@ -695,0 +715,1 @@\n+  static ByteSize flags_offset()                 { return byte_offset_of(Method, _flags); }\n@@ -903,0 +924,24 @@\n+  bool has_scalarized_args() {\n+    return (_flags & _scalarized_args) != 0;\n+  }\n+\n+  void set_has_scalarized_args(bool x) {\n+    _flags = x ? (_flags | _scalarized_args) : (_flags & ~_scalarized_args);\n+  }\n+\n+  bool c1_needs_stack_repair() {\n+    return (_flags & _c1_needs_stack_repair) != 0;\n+  }\n+\n+  bool c2_needs_stack_repair() {\n+    return (_flags & _c2_needs_stack_repair) != 0;\n+  }\n+\n+  void set_c1_needs_stack_repair(bool x) {\n+    _flags = x ? (_flags | _c1_needs_stack_repair) : (_flags & ~_c1_needs_stack_repair);\n+  }\n+\n+  void set_c2_needs_stack_repair(bool x) {\n+    _flags = x ? (_flags | _c2_needs_stack_repair) : (_flags & ~_c2_needs_stack_repair);\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":59,"deletions":14,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -142,1 +142,1 @@\n-    st->print(\"flags(%d) \", flags);\n+    st->print(\"flags(%d) %p\/%d\", flags, data(), in_bytes(DataLayout::flags_offset()));\n@@ -212,1 +212,1 @@\n-  assert(TypeStackSlotEntries::per_arg_count() > ReturnTypeEntry::static_cell_count(), \"code to test for arguments\/results broken\");\n+  assert(TypeStackSlotEntries::per_arg_count() > SingleTypeEntry::static_cell_count(), \"code to test for arguments\/results broken\");\n@@ -222,1 +222,1 @@\n-    ret_cell = ReturnTypeEntry::static_cell_count();\n+    ret_cell = SingleTypeEntry::static_cell_count();\n@@ -325,1 +325,1 @@\n-void ReturnTypeEntry::clean_weak_klass_links(bool always_clean) {\n+void SingleTypeEntry::clean_weak_klass_links(bool always_clean) {\n@@ -363,1 +363,1 @@\n-void ReturnTypeEntry::print_data_on(outputStream* st) const {\n+void SingleTypeEntry::print_data_on(outputStream* st) const {\n@@ -528,0 +528,4 @@\n+  if (data()->flags()) {\n+    tty->cr();\n+    tab(st);\n+  }\n@@ -651,0 +655,21 @@\n+void ArrayLoadStoreData::print_data_on(outputStream* st, const char* extra) const {\n+  print_shared(st, \"ArrayLoadStore\", extra);\n+  st->cr();\n+  tab(st, true);\n+  st->print(\"array\");\n+  _array.print_data_on(st);\n+  tab(st, true);\n+  st->print(\"element\");\n+  _element.print_data_on(st);\n+}\n+\n+void ACmpData::print_data_on(outputStream* st, const char* extra) const {\n+  BranchData::print_data_on(st, extra);\n+  tab(st, true);\n+  st->print(\"left\");\n+  _left.print_data_on(st);\n+  tab(st, true);\n+  st->print(\"right\");\n+  _right.print_data_on(st);\n+}\n+\n@@ -671,1 +696,0 @@\n-  case Bytecodes::_aastore:\n@@ -677,0 +701,3 @@\n+  case Bytecodes::_aaload:\n+  case Bytecodes::_aastore:\n+    return ArrayLoadStoreData::static_cell_count();\n@@ -716,2 +743,0 @@\n-  case Bytecodes::_if_acmpeq:\n-  case Bytecodes::_if_acmpne:\n@@ -721,0 +746,3 @@\n+  case Bytecodes::_if_acmpne:\n+  case Bytecodes::_if_acmpeq:\n+    return ACmpData::static_cell_count();\n@@ -779,0 +807,1 @@\n+  case Bytecodes::_aaload:\n@@ -982,1 +1011,0 @@\n-  case Bytecodes::_aastore:\n@@ -991,0 +1019,5 @@\n+  case Bytecodes::_aaload:\n+  case Bytecodes::_aastore:\n+    cell_count = ArrayLoadStoreData::static_cell_count();\n+    tag = DataLayout::array_load_store_data_tag;\n+    break;\n@@ -1062,2 +1095,0 @@\n-  case Bytecodes::_if_acmpeq:\n-  case Bytecodes::_if_acmpne:\n@@ -1069,0 +1100,5 @@\n+  case Bytecodes::_if_acmpeq:\n+  case Bytecodes::_if_acmpne:\n+    cell_count = ACmpData::static_cell_count();\n+    tag = DataLayout::acmp_data_tag;\n+    break;\n@@ -1136,0 +1172,4 @@\n+  case DataLayout::array_load_store_data_tag:\n+    return ((new ArrayLoadStoreData(this))->cell_count());\n+  case DataLayout::acmp_data_tag:\n+    return ((new ACmpData(this))->cell_count());\n@@ -1170,0 +1210,4 @@\n+  case DataLayout::array_load_store_data_tag:\n+    return new ArrayLoadStoreData(this);\n+  case DataLayout::acmp_data_tag:\n+    return new ACmpData(this);\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":55,"deletions":11,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"memory\/oopFactory.hpp\"\n@@ -100,19 +101,1 @@\n-  Symbol* name = NULL;\n-  {\n-    ResourceMark rm(THREAD);\n-    char *name_str = element_klass->name()->as_C_string();\n-    int len = element_klass->name()->utf8_length();\n-    char *new_str = NEW_RESOURCE_ARRAY(char, len + 4);\n-    int idx = 0;\n-    new_str[idx++] = JVM_SIGNATURE_ARRAY;\n-    if (element_klass->is_instance_klass()) { \/\/ it could be an array or simple type\n-      new_str[idx++] = JVM_SIGNATURE_CLASS;\n-    }\n-    memcpy(&new_str[idx], name_str, len * sizeof(char));\n-    idx += len;\n-    if (element_klass->is_instance_klass()) {\n-      new_str[idx++] = JVM_SIGNATURE_ENDCLASS;\n-    }\n-    new_str[idx++] = '\\0';\n-    name = SymbolTable::new_symbol(new_str);\n-  }\n+  Symbol* name = ArrayKlass::create_element_klass_array_name(element_klass, CHECK_NULL);\n@@ -146,0 +129,2 @@\n+  } else if (element_klass->is_flatArray_klass()) {\n+    bk = FlatArrayKlass::cast(element_klass)->element_klass();\n@@ -153,1 +138,7 @@\n-  set_layout_helper(array_layout_helper(T_OBJECT));\n+  jint lh = array_layout_helper(T_OBJECT);\n+  if (element_klass->is_inline_klass()) {\n+    lh = layout_helper_set_null_free(lh);\n+    set_prototype_header(markWord::nullfree_array_prototype());\n+    assert(prototype_header().is_nullfree_array(), \"sanity\");\n+  }\n+  set_layout_helper(lh);\n@@ -166,1 +157,2 @@\n-  return (objArrayOop)Universe::heap()->array_allocate(this, size, length,\n+  bool populate_null_free = is_null_free_array_klass();\n+  objArrayOop array =  (objArrayOop)Universe::heap()->array_allocate(this, size, length,\n@@ -168,0 +160,14 @@\n+  if (populate_null_free) {\n+    assert(dimension() == 1, \"Can only populate the final dimension\");\n+    assert(element_klass()->is_inline_klass(), \"Unexpected\");\n+    assert(!element_klass()->is_array_klass(), \"ArrayKlass unexpected here\");\n+    assert(!InlineKlass::cast(element_klass())->flatten_array(), \"Expected flatArrayOop allocation\");\n+    element_klass()->initialize(CHECK_NULL);\n+    \/\/ Populate default values...\n+    objArrayHandle array_h(THREAD, array);\n+    instanceOop value = (instanceOop) InlineKlass::cast(element_klass())->default_value();\n+    for (int i = 0; i < length; i++) {\n+      array_h->obj_at_put(i, value);\n+    }\n+  }\n+  return array;\n@@ -170,2 +176,0 @@\n-static int multi_alloc_counter = 0;\n-\n@@ -174,0 +178,8 @@\n+  if (rank == 1) { \/\/ last dim may be flatArray, check if we have any special storage requirements\n+    if (element_klass()->is_inline_klass()) {\n+      return oopFactory::new_flatArray(element_klass(), length, CHECK_NULL);\n+    } else {\n+      return oopFactory::new_objArray(element_klass(), length, CHECK_NULL);\n+    }\n+  }\n+  guarantee(rank > 1, \"Rank below 1\");\n@@ -180,16 +192,14 @@\n-  if (rank > 1) {\n-    if (length != 0) {\n-      for (int index = 0; index < length; index++) {\n-        ArrayKlass* ak = ArrayKlass::cast(ld_klass);\n-        oop sub_array = ak->multi_allocate(rank-1, &sizes[1], CHECK_NULL);\n-        h_array->obj_at_put(index, sub_array);\n-      }\n-    } else {\n-      \/\/ Since this array dimension has zero length, nothing will be\n-      \/\/ allocated, however the lower dimension values must be checked\n-      \/\/ for illegal values.\n-      for (int i = 0; i < rank - 1; ++i) {\n-        sizes += 1;\n-        if (*sizes < 0) {\n-          THROW_MSG_0(vmSymbols::java_lang_NegativeArraySizeException(), err_msg(\"%d\", *sizes));\n-        }\n+  if (length != 0) {\n+    for (int index = 0; index < length; index++) {\n+      ArrayKlass* ak = ArrayKlass::cast(ld_klass);\n+      oop sub_array = ak->multi_allocate(rank-1, &sizes[1], CHECK_NULL);\n+      h_array->obj_at_put(index, sub_array);\n+    }\n+  } else {\n+    \/\/ Since this array dimension has zero length, nothing will be\n+    \/\/ allocated, however the lower dimension values must be checked\n+    \/\/ for illegal values.\n+    for (int i = 0; i < rank - 1; ++i) {\n+      sizes += 1;\n+      if (*sizes < 0) {\n+        THROW_MSG_0(vmSymbols::java_lang_NegativeArraySizeException(), err_msg(\"%d\", *sizes));\n@@ -213,0 +223,3 @@\n+    \/\/ Perform null check if dst is null-free but src has no such guarantee\n+    bool null_check = ((!s->klass()->is_null_free_array_klass()) &&\n+        d->klass()->is_null_free_array_klass());\n@@ -214,2 +227,5 @@\n-      \/\/ elements are guaranteed to be subtypes, so no check necessary\n-      ArrayAccess<ARRAYCOPY_DISJOINT>::oop_arraycopy(s, src_offset, d, dst_offset, length);\n+      if (null_check) {\n+        ArrayAccess<ARRAYCOPY_DISJOINT | ARRAYCOPY_NOTNULL>::oop_arraycopy(s, src_offset, d, dst_offset, length);\n+      } else {\n+        ArrayAccess<ARRAYCOPY_DISJOINT>::oop_arraycopy(s, src_offset, d, dst_offset, length);\n+      }\n@@ -217,16 +233,4 @@\n-      \/\/ slow case: need individual subtype checks\n-      \/\/ note: don't use obj_at_put below because it includes a redundant store check\n-      if (!ArrayAccess<ARRAYCOPY_DISJOINT | ARRAYCOPY_CHECKCAST>::oop_arraycopy(s, src_offset, d, dst_offset, length)) {\n-        ResourceMark rm(THREAD);\n-        stringStream ss;\n-        if (!bound->is_subtype_of(stype)) {\n-          ss.print(\"arraycopy: type mismatch: can not copy %s[] into %s[]\",\n-                   stype->external_name(), bound->external_name());\n-        } else {\n-          \/\/ oop_arraycopy should return the index in the source array that\n-          \/\/ contains the problematic oop.\n-          ss.print(\"arraycopy: element type mismatch: can not cast one of the elements\"\n-                   \" of %s[] to the type of the destination array, %s\",\n-                   stype->external_name(), bound->external_name());\n-        }\n-        THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n+      if (null_check) {\n+        ArrayAccess<ARRAYCOPY_DISJOINT | ARRAYCOPY_CHECKCAST | ARRAYCOPY_NOTNULL>::oop_arraycopy(s, src_offset, d, dst_offset, length);\n+      } else {\n+        ArrayAccess<ARRAYCOPY_DISJOINT | ARRAYCOPY_CHECKCAST>::oop_arraycopy(s, src_offset, d, dst_offset, length);\n@@ -242,0 +246,7 @@\n+  if (EnableValhalla) {\n+    if (d->is_flatArray()) {\n+      FlatArrayKlass::cast(d->klass())->copy_array(s, src_pos, d, dst_pos, length, THREAD);\n+      return;\n+    }\n+  }\n+\n@@ -314,1 +325,0 @@\n-\n@@ -332,2 +342,1 @@\n-        Klass* k =\n-          ObjArrayKlass::allocate_objArray_klass(class_loader_data(), dim + 1, this, CHECK_NULL);\n+        Klass* k = ObjArrayKlass::allocate_objArray_klass(class_loader_data(), dim + 1, this, CHECK_NULL);\n@@ -375,1 +384,1 @@\n-    GrowableArray<Klass*>* secondaries = new GrowableArray<Klass*>(num_elem_supers+2);\n+    GrowableArray<Klass*>* secondaries = new GrowableArray<Klass*>(num_elem_supers+3);\n@@ -378,0 +387,1 @@\n+    secondaries->push(vmClasses::IdentityObject_klass());\n@@ -427,1 +437,1 @@\n-  st->print(\" - instance klass: \");\n+  st->print(\" - element klass: \");\n@@ -489,1 +499,2 @@\n-  guarantee(bk->is_instance_klass() || bk->is_typeArray_klass(),  \"invalid bottom klass\");\n+  guarantee(bk->is_instance_klass() || bk->is_typeArray_klass() || bk->is_flatArray_klass(),\n+            \"invalid bottom klass\");\n@@ -495,0 +506,1 @@\n+  guarantee(obj->is_nullfreeArray() || (!is_null_free_array_klass()), \"null-free klass but not object\");\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.cpp","additions":75,"deletions":63,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -45,1 +45,0 @@\n-  Klass* _element_klass;            \/\/ The klass of the elements of this array type\n@@ -55,5 +54,0 @@\n-  \/\/ Instance variables\n-  Klass* element_klass() const      { return _element_klass; }\n-  void set_element_klass(Klass* k)  { _element_klass = k; }\n-  Klass** element_klass_addr()      { return &_element_klass; }\n-\n@@ -67,3 +61,0 @@\n-  \/\/ Compiler\/Interpreter offset\n-  static ByteSize element_klass_offset() { return in_ByteSize(offset_of(ObjArrayKlass, _element_klass)); }\n-\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.hpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -98,1 +98,1 @@\n-  return ObjectSynchronizer::identity_hash_value_for(object);\n+  return ObjectSynchronizer::FastHashCode(THREAD, object());\n@@ -117,1 +117,1 @@\n-  return !SafepointSynchronize::is_at_safepoint();\n+  return !SafepointSynchronize::is_at_safepoint() ;\n@@ -140,0 +140,3 @@\n+bool oopDesc::is_value_noinline()             const { return is_inline_type();         }\n+bool oopDesc::is_flatArray_noinline()         const { return is_flatArray();           }\n+bool oopDesc::is_nullfreeArray_noinline()     const { return is_nullfreeArray();       }\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -209,0 +209,15 @@\n+bool oopDesc::is_inline_type() const { return mark().is_inline_type(); }\n+#if _LP64\n+bool oopDesc::is_flatArray() const {\n+  markWord mrk = mark();\n+  return (mrk.is_unlocked()) ? mrk.is_flat_array() : klass()->is_flatArray_klass();\n+}\n+bool oopDesc::is_nullfreeArray() const {\n+  markWord mrk = mark();\n+  return (mrk.is_unlocked()) ? mrk.is_nullfree_array() : klass()->is_null_free_array_klass();\n+}\n+#else\n+bool oopDesc::is_flatArray()     const { return klass()->is_flatArray_klass(); }\n+bool oopDesc::is_nullfreeArray() const { return klass()->is_null_free_array_klass(); }\n+#endif\n+\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+typedef class     flatArrayOopDesc*           flatArrayOop;\n@@ -149,0 +150,1 @@\n+DEF_OOP(flatArray);\n@@ -180,0 +182,1 @@\n+class     InlineKlass;\n@@ -183,0 +186,1 @@\n+class     FlatArrayKlass;\n","filename":"src\/hotspot\/share\/oops\/oopsHierarchy.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -98,1 +98,0 @@\n-  \/\/ For typeArrays this is only called for the last dimension\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -686,0 +686,6 @@\n+  if (tp->isa_aryptr()) {\n+    \/\/ In the case of a flattened inline type array, each field has its\n+    \/\/ own slice so we need to extract the field being accessed from\n+    \/\/ the address computation\n+    return tp->is_aryptr()->add_field_offset_and_offset(txoffset);\n+  }\n@@ -706,0 +712,6 @@\n+  if (p1->isa_aryptr()) {\n+    \/\/ In the case of a flattened inline type array, each field has its\n+    \/\/ own slice so we need to extract the field being accessed from\n+    \/\/ the address computation\n+    return p1->is_aryptr()->add_field_offset_and_offset(p2offset);\n+  }\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1252,0 +1252,2 @@\n+          \/\/ TODO re-enable\n+          \/*\n@@ -1255,0 +1257,1 @@\n+          *\/\n","filename":"src\/hotspot\/share\/opto\/block.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -505,0 +505,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:\n+  case vmIntrinsics::_finishPrivateBuffer:\n@@ -514,0 +516,1 @@\n+  case vmIntrinsics::_getValue:\n@@ -523,0 +526,1 @@\n+  case vmIntrinsics::_putValue:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -121,1 +122,1 @@\n-  \/\/ paths to facilitate late inlinig.\n+  \/\/ paths to facilitate late inlining.\n@@ -130,0 +131,1 @@\n+      _call_node(NULL),\n@@ -132,0 +134,8 @@\n+    if (InlineTypeReturnedAsFields && method->is_method_handle_intrinsic()) {\n+      \/\/ If that call has not been optimized by the time optimizations are over,\n+      \/\/ we'll need to add a call to create an inline type instance from the klass\n+      \/\/ returned by the call (see PhaseMacroExpand::expand_mh_intrinsic_return).\n+      \/\/ Separating memory and I\/O projections for exceptions is required to\n+      \/\/ perform that graph transformation.\n+      _separate_io_proj = true;\n+    }\n@@ -146,0 +156,1 @@\n+  PhaseGVN& gvn = kit.gvn();\n@@ -178,1 +189,4 @@\n-  kit.set_arguments_for_java_call(call);\n+  kit.set_arguments_for_java_call(call, is_late_inline());\n+  if (kit.stopped()) {\n+    return kit.transfer_exceptions_into_jvms();\n+  }\n@@ -219,1 +233,0 @@\n-\n@@ -231,1 +244,1 @@\n-  if (kit.gvn().type(receiver)->higher_equal(TypePtr::NULL_PTR)) {\n+  if (!receiver->is_InlineType() && kit.gvn().type(receiver)->higher_equal(TypePtr::NULL_PTR)) {\n@@ -279,0 +292,3 @@\n+  if (kit.stopped()) {\n+    return kit.transfer_exceptions_into_jvms();\n+  }\n@@ -372,0 +388,4 @@\n+  virtual CallGenerator* inline_cg() {\n+    return _inline_cg;\n+  }\n+\n@@ -425,0 +445,7 @@\n+    \/\/ AlwaysIncrementalInline causes for_method_handle_inline() to\n+    \/\/ return a LateInlineCallGenerator. Extract the\n+    \/\/ InlineCallGenerato from it.\n+    if (AlwaysIncrementalInline && cg->is_late_inline()) {\n+      cg = cg->inline_cg();\n+    }\n+\n@@ -623,3 +650,3 @@\n-  const TypeTuple *r = call->tf()->domain();\n-  for (int i1 = 0; i1 < method()->arg_size(); i1++) {\n-    if (call->in(TypeFunc::Parms + i1)->is_top() && r->field_at(TypeFunc::Parms + i1) != Type::HALF) {\n+  const TypeTuple* r = call->tf()->domain_cc();\n+  for (uint i1 = TypeFunc::Parms; i1 < r->cnt(); i1++) {\n+    if (call->in(i1)->is_top() && r->field_at(i1) != Type::HALF) {\n@@ -643,10 +670,8 @@\n-  CallProjections callprojs;\n-  call->extract_projections(&callprojs, true);\n-  if ((callprojs.fallthrough_catchproj == call->in(0)) ||\n-      (callprojs.catchall_catchproj    == call->in(0)) ||\n-      (callprojs.fallthrough_memproj   == call->in(TypeFunc::Memory)) ||\n-      (callprojs.catchall_memproj      == call->in(TypeFunc::Memory)) ||\n-      (callprojs.fallthrough_ioproj    == call->in(TypeFunc::I_O)) ||\n-      (callprojs.catchall_ioproj       == call->in(TypeFunc::I_O)) ||\n-      (callprojs.resproj != NULL && call->find_edge(callprojs.resproj) != -1) ||\n-      (callprojs.exobj   != NULL && call->find_edge(callprojs.exobj) != -1)) {\n+  CallProjections* callprojs = call->extract_projections(true);\n+  if ((callprojs->fallthrough_catchproj == call->in(0)) ||\n+      (callprojs->catchall_catchproj    == call->in(0)) ||\n+      (callprojs->fallthrough_memproj   == call->in(TypeFunc::Memory)) ||\n+      (callprojs->catchall_memproj      == call->in(TypeFunc::Memory)) ||\n+      (callprojs->fallthrough_ioproj    == call->in(TypeFunc::I_O)) ||\n+      (callprojs->catchall_ioproj       == call->in(TypeFunc::I_O)) ||\n+      (callprojs->exobj != NULL && call->find_edge(callprojs->exobj) != -1)) {\n@@ -665,1 +690,1 @@\n-    if (is_boxing_late_inline() && callprojs.resproj != nullptr) {\n+    if (is_boxing_late_inline() && callprojs->resproj[0] != nullptr) {\n@@ -668,2 +693,2 @@\n-        if (!has_non_debug_usages(callprojs.resproj) && is_box_cache_valid(call)) {\n-          scalarize_debug_usages(call, callprojs.resproj);\n+        if (!has_non_debug_usages(callprojs->resproj[0]) && is_box_cache_valid(call)) {\n+          scalarize_debug_usages(call, callprojs->resproj[0]);\n@@ -675,1 +700,11 @@\n-    result_not_used = (callprojs.resproj == NULL || callprojs.resproj->outcnt() == 0);\n+    result_not_used = true;\n+    for (uint i = 0; i < callprojs->nb_resproj; i++) {\n+      if (callprojs->resproj[i] != NULL) {\n+        if (callprojs->resproj[i]->outcnt() != 0) {\n+          result_not_used = false;\n+        }\n+        if (call->find_edge(callprojs->resproj[i]) != -1) {\n+          return;\n+        }\n+      }\n+    }\n@@ -691,0 +726,1 @@\n+    PhaseGVN& gvn = *C->initial_gvn();\n@@ -694,1 +730,1 @@\n-      C->initial_gvn()->set_type_bottom(mem);\n+      gvn.set_type_bottom(mem);\n@@ -698,4 +734,2 @@\n-    uint nargs = method()->arg_size();\n-    Node* top = C->top();\n-    for (uint i1 = 0; i1 < nargs; i1++) {\n-      map->set_req(TypeFunc::Parms + i1, top);\n+    for (uint i1 = TypeFunc::Parms; i1 < r->cnt(); i1++) {\n+      map->set_req(i1, C->top());\n@@ -709,0 +743,5 @@\n+    const TypeTuple* domain_sig = call->_tf->domain_sig();\n+    uint nargs = method()->arg_size();\n+    assert(domain_sig->cnt() - TypeFunc::Parms == nargs, \"inconsistent signature\");\n+\n+    uint j = TypeFunc::Parms;\n@@ -710,1 +749,11 @@\n-      map->set_argument(jvms, i1, call->in(TypeFunc::Parms + i1));\n+      const Type* t = domain_sig->field_at(TypeFunc::Parms + i1);\n+      if (method()->has_scalarized_args() && t->is_inlinetypeptr() && !t->maybe_null() && t->inline_klass()->can_be_passed_as_fields()) {\n+        \/\/ Inline type arguments are not passed by reference: we get an argument per\n+        \/\/ field of the inline type. Build InlineTypeNodes from the inline type arguments.\n+        GraphKit arg_kit(jvms, &gvn);\n+        InlineTypeNode* vt = InlineTypeNode::make_from_multi(&arg_kit, call, t->inline_klass(), j, true);\n+        map->set_control(arg_kit.control());\n+        map->set_argument(jvms, i1, vt);\n+      } else {\n+        map->set_argument(jvms, i1, call->in(j++));\n+      }\n@@ -726,0 +775,18 @@\n+    \/\/ Check if we are late inlining a method handle call that returns an inline type as fields.\n+    Node* buffer_oop = NULL;\n+    ciType* mh_rt = inline_cg()->method()->return_type();\n+    if (is_mh_late_inline() && mh_rt->is_inlinetype() && mh_rt->as_inline_klass()->can_be_returned_as_fields()) {\n+      \/\/ Allocate a buffer for the inline type returned as fields because the caller expects an oop return.\n+      \/\/ Do this before the method handle call in case the buffer allocation triggers deoptimization and\n+      \/\/ we need to \"re-execute\" the call in the interpreter (to make sure the call is only executed once).\n+      GraphKit arg_kit(jvms, &gvn);\n+      {\n+        PreserveReexecuteState preexecs(&arg_kit);\n+        arg_kit.jvms()->set_should_reexecute(true);\n+        arg_kit.inc_sp(nargs);\n+        Node* klass_node = arg_kit.makecon(TypeKlassPtr::make(mh_rt->as_inline_klass()));\n+        buffer_oop = arg_kit.new_instance(klass_node, NULL, NULL, \/* deoptimize_on_exception *\/ true);\n+      }\n+      jvms = arg_kit.transfer_exceptions_into_jvms();\n+    }\n+\n@@ -762,0 +829,29 @@\n+\n+    \/\/ Handle inline type returns\n+    InlineTypeNode* vt = result->isa_InlineType();\n+    if (vt != NULL) {\n+      if (call->tf()->returns_inline_type_as_fields()) {\n+        vt->replace_call_results(&kit, call, C);\n+      } else {\n+        \/\/ Only possible with is_mh_late_inline() when the callee does not \"know\" that the caller expects an oop\n+        assert(is_mh_late_inline(), \"sanity\");\n+        assert(buffer_oop != NULL, \"should have allocated a buffer\");\n+        \/\/ Result might still be allocated (for example, if it has been stored to a non-flattened field)\n+        if (!vt->is_allocated(&kit.gvn())) {\n+          vt->store(&kit, buffer_oop, buffer_oop, vt->type()->inline_klass());\n+          \/\/ Do not let stores that initialize this buffer be reordered with a subsequent\n+          \/\/ store that would make this buffer accessible by other threads.\n+          AllocateNode* alloc = AllocateNode::Ideal_allocation(buffer_oop, &kit.gvn());\n+          assert(alloc != NULL, \"must have an allocation node\");\n+          kit.insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out_or_null(AllocateNode::RawAddress));\n+          kit.gvn().hash_delete(vt);\n+          vt->set_oop(buffer_oop);\n+          vt = kit.gvn().transform(vt)->as_InlineType();\n+        }\n+        DEBUG_ONLY(buffer_oop = NULL);\n+        \/\/ Convert to InlineTypePtrNode to keep track of field values\n+        result = vt->as_ptr(&kit.gvn());\n+      }\n+    }\n+    assert(buffer_oop == NULL, \"unused buffer allocation\");\n+\n@@ -1061,0 +1157,22 @@\n+  \/\/ Allocate inline types if they are merged with objects (similar to Parse::merge_common())\n+  uint tos = kit.jvms()->stkoff() + kit.sp();\n+  uint limit = slow_map->req();\n+  for (uint i = TypeFunc::Parms; i < limit; i++) {\n+    Node* m = kit.map()->in(i);\n+    Node* n = slow_map->in(i);\n+    const Type* t = gvn.type(m)->meet_speculative(gvn.type(n));\n+    if (m->is_InlineType() && !t->isa_inlinetype()) {\n+      \/\/ Allocate inline type in fast path\n+      m = m->as_InlineType()->buffer(&kit);\n+      kit.map()->set_req(i, m);\n+    }\n+    if (n->is_InlineType() && !t->isa_inlinetype()) {\n+      \/\/ Allocate inline type in slow path\n+      PreserveJVMState pjvms(&kit);\n+      kit.set_map(slow_map);\n+      n = n->as_InlineType()->buffer(&kit);\n+      kit.map()->set_req(i, n);\n+      slow_map = kit.stop();\n+    }\n+  }\n+\n@@ -1084,2 +1202,0 @@\n-  uint tos = kit.jvms()->stkoff() + kit.sp();\n-  uint limit = slow_map->req();\n@@ -1121,2 +1237,2 @@\n-  if (IncrementalInlineMH && call_site_count > 0 &&\n-      (input_not_const || !C->inlining_incrementally() || C->over_inlining_cutoff())) {\n+  if (IncrementalInlineMH && (AlwaysIncrementalInline ||\n+                            (call_site_count > 0 && (input_not_const || !C->inlining_incrementally() || C->over_inlining_cutoff())))) {\n@@ -1130,0 +1246,20 @@\n+static void cast_argument(int nargs, int arg_nb, ciType* t, GraphKit& kit) {\n+  PhaseGVN& gvn = kit.gvn();\n+  Node* arg = kit.argument(arg_nb);\n+  const Type* arg_type = arg->bottom_type();\n+  const Type* sig_type = TypeOopPtr::make_from_klass(t->as_klass());\n+  if (t->as_klass()->is_inlinetype()) {\n+    sig_type = sig_type->join_speculative(TypePtr::NOTNULL);\n+  }\n+  if (arg_type->isa_oopptr() && !arg_type->higher_equal(sig_type)) {\n+    const Type* narrowed_arg_type = arg_type->join_speculative(sig_type); \/\/ keep speculative part\n+    arg = gvn.transform(new CheckCastPPNode(kit.control(), arg, narrowed_arg_type));\n+    kit.set_argument(arg_nb, arg);\n+  }\n+  if (sig_type->is_inlinetypeptr() && !arg->is_InlineType() &&\n+      !kit.gvn().type(arg)->maybe_null() && t->as_inline_klass()->is_scalarizable()) {\n+    arg = InlineTypeNode::make_from_oop(&kit, arg, t->as_inline_klass());\n+    kit.set_argument(arg_nb, arg);\n+  }\n+}\n+\n@@ -1184,2 +1320,4 @@\n-                                              allow_inline,\n-                                              PROB_ALWAYS);\n+                                              true \/* allow_inline *\/,\n+                                              PROB_ALWAYS,\n+                                              NULL,\n+                                              true);\n@@ -1199,0 +1337,1 @@\n+      int nargs = callee->arg_size();\n@@ -1200,1 +1339,1 @@\n-      Node* member_name = kit.argument(callee->arg_size() - 1);\n+      Node* member_name = kit.argument(nargs - 1);\n@@ -1220,8 +1359,1 @@\n-          Node* arg = kit.argument(0);\n-          const TypeOopPtr* arg_type = arg->bottom_type()->isa_oopptr();\n-          const Type*       sig_type = TypeOopPtr::make_from_klass(signature->accessing_klass());\n-          if (arg_type != NULL && !arg_type->higher_equal(sig_type)) {\n-            const Type* recv_type = arg_type->join_speculative(sig_type); \/\/ keep speculative part\n-            Node* cast_obj = gvn.transform(new CheckCastPPNode(kit.control(), arg, recv_type));\n-            kit.set_argument(0, cast_obj);\n-          }\n+          cast_argument(nargs, 0, signature->accessing_klass(), kit);\n@@ -1233,8 +1365,1 @@\n-            Node* arg = kit.argument(receiver_skip + j);\n-            const TypeOopPtr* arg_type = arg->bottom_type()->isa_oopptr();\n-            const Type*       sig_type = TypeOopPtr::make_from_klass(t->as_klass());\n-            if (arg_type != NULL && !arg_type->higher_equal(sig_type)) {\n-              const Type* narrowed_arg_type = arg_type->join_speculative(sig_type); \/\/ keep speculative part\n-              Node* cast_obj = gvn.transform(new CheckCastPPNode(kit.control(), arg, narrowed_arg_type));\n-              kit.set_argument(receiver_skip + j, cast_obj);\n-            }\n+            cast_argument(nargs, receiver_skip + j, t, kit);\n@@ -1271,1 +1396,2 @@\n-                                              speculative_receiver_type);\n+                                              speculative_receiver_type,\n+                                              true);\n@@ -1357,1 +1483,1 @@\n-    Node* receiver = kit.null_check_receiver_before_call(method());\n+    kit.null_check_receiver_before_call(method());\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":178,"deletions":52,"binary":false,"changes":230,"status":"modified"},{"patch":"@@ -48,1 +48,0 @@\n-  virtual CallGenerator* inline_cg()    const                             { ShouldNotReachHere(); return NULL;  }\n@@ -90,0 +89,2 @@\n+  virtual CallGenerator* inline_cg()    const                             { ShouldNotReachHere(); return NULL;  }\n+\n","filename":"src\/hotspot\/share\/opto\/callGenerator.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -37,0 +38,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -46,0 +48,1 @@\n+#include \"runtime\/stubRoutines.hpp\"\n@@ -81,1 +84,1 @@\n-Node *StartNode::match( const ProjNode *proj, const Matcher *match ) {\n+Node *StartNode::match(const ProjNode *proj, const Matcher *match, const RegMask* mask) {\n@@ -105,11 +108,0 @@\n-\/\/------------------------------StartOSRNode----------------------------------\n-\/\/ The method start node for an on stack replacement adapter\n-\n-\/\/------------------------------osr_domain-----------------------------\n-const TypeTuple *StartOSRNode::osr_domain() {\n-  const Type **fields = TypeTuple::fields(2);\n-  fields[TypeFunc::Parms+0] = TypeRawPtr::BOTTOM;  \/\/ address of osr buffer\n-\n-  return TypeTuple::make(TypeFunc::Parms+1, fields);\n-}\n-\n@@ -496,0 +488,8 @@\n+      } else if (cik->is_flat_array_klass()) {\n+        ciKlass* cie = cik->as_flat_array_klass()->base_element_klass();\n+        cie->print_name_on(st);\n+        st->print(\"[%d]\", spobj->n_fields());\n+        int ndim = cik->as_array_klass()->dimension() - 1;\n+        while (ndim-- > 0) {\n+          st->print(\"[]\");\n+        }\n@@ -709,1 +709,1 @@\n-const Type *CallNode::bottom_type() const { return tf()->range(); }\n+const Type *CallNode::bottom_type() const { return tf()->range_cc(); }\n@@ -711,2 +711,4 @@\n-  if (phase->type(in(0)) == Type::TOP)  return Type::TOP;\n-  return tf()->range();\n+  if (!in(0) || phase->type(in(0)) == Type::TOP) {\n+    return Type::TOP;\n+  }\n+  return tf()->range_cc();\n@@ -717,0 +719,7 @@\n+  if (_entry_point == StubRoutines::store_inline_type_fields_to_buf()) {\n+    \/\/ The call to that stub is a special case: its inputs are\n+    \/\/ multiple values returned from a call and so it should follow\n+    \/\/ the return convention.\n+    SharedRuntime::java_return_convention(sig_bt, parm_regs, argcnt);\n+    return;\n+  }\n@@ -725,2 +734,28 @@\n-Node *CallNode::match( const ProjNode *proj, const Matcher *match ) {\n-  switch (proj->_con) {\n+Node *CallNode::match(const ProjNode *proj, const Matcher *match, const RegMask* mask) {\n+  uint con = proj->_con;\n+  const TypeTuple *range_cc = tf()->range_cc();\n+  if (con >= TypeFunc::Parms) {\n+    if (is_CallRuntime()) {\n+      if (con == TypeFunc::Parms) {\n+        uint ideal_reg = range_cc->field_at(TypeFunc::Parms)->ideal_reg();\n+        OptoRegPair regs = match->c_return_value(ideal_reg);\n+        RegMask rm = RegMask(regs.first());\n+        if (OptoReg::is_valid(regs.second())) {\n+          rm.Insert(regs.second());\n+        }\n+        return new MachProjNode(this,con,rm,ideal_reg);\n+      } else {\n+        assert(con == TypeFunc::Parms+1, \"only one return value\");\n+        assert(range_cc->field_at(TypeFunc::Parms+1) == Type::HALF, \"\");\n+        return new MachProjNode(this,con, RegMask::Empty, (uint)OptoReg::Bad);\n+      }\n+    } else {\n+      \/\/ The Call may return multiple values (inline type fields): we\n+      \/\/ create one projection per returned value.\n+      assert(con <= TypeFunc::Parms+1 || InlineTypeReturnedAsFields, \"only for multi value return\");\n+      uint ideal_reg = range_cc->field_at(con)->ideal_reg();\n+      return new MachProjNode(this, con, mask[con-TypeFunc::Parms], ideal_reg);\n+    }\n+  }\n+\n+  switch (con) {\n@@ -732,16 +767,0 @@\n-  case TypeFunc::Parms+1:       \/\/ For LONG & DOUBLE returns\n-    assert(tf()->range()->field_at(TypeFunc::Parms+1) == Type::HALF, \"\");\n-    \/\/ 2nd half of doubles and longs\n-    return new MachProjNode(this,proj->_con, RegMask::Empty, (uint)OptoReg::Bad);\n-\n-  case TypeFunc::Parms: {       \/\/ Normal returns\n-    uint ideal_reg = tf()->range()->field_at(TypeFunc::Parms)->ideal_reg();\n-    OptoRegPair regs = is_CallRuntime()\n-      ? match->c_return_value(ideal_reg)  \/\/ Calls into C runtime\n-      : match->  return_value(ideal_reg); \/\/ Calls into compiled Java code\n-    RegMask rm = RegMask(regs.first());\n-    if( OptoReg::is_valid(regs.second()) )\n-      rm.Insert( regs.second() );\n-    return new MachProjNode(this,proj->_con,rm,ideal_reg);\n-  }\n-\n@@ -768,1 +787,1 @@\n-    const TypeTuple* args = _tf->domain();\n+    const TypeTuple* args = _tf->domain_sig();\n@@ -817,1 +836,1 @@\n-      const TypeTuple* d = tf()->domain();\n+      const TypeTuple* d = tf()->domain_cc();\n@@ -832,2 +851,2 @@\n-bool CallNode::has_non_debug_use(Node *n) {\n-  const TypeTuple * d = tf()->domain();\n+bool CallNode::has_non_debug_use(Node* n) {\n+  const TypeTuple* d = tf()->domain_cc();\n@@ -835,2 +854,1 @@\n-    Node *arg = in(i);\n-    if (arg == n) {\n+    if (in(i) == n) {\n@@ -843,0 +861,11 @@\n+bool CallNode::has_debug_use(Node* n) {\n+  if (jvms() != NULL) {\n+    for (uint i = jvms()->debug_start(); i < jvms()->debug_end(); i++) {\n+      if (in(i) == n) {\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -874,10 +903,15 @@\n-void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) {\n-  projs->fallthrough_proj      = NULL;\n-  projs->fallthrough_catchproj = NULL;\n-  projs->fallthrough_ioproj    = NULL;\n-  projs->catchall_ioproj       = NULL;\n-  projs->catchall_catchproj    = NULL;\n-  projs->fallthrough_memproj   = NULL;\n-  projs->catchall_memproj      = NULL;\n-  projs->resproj               = NULL;\n-  projs->exobj                 = NULL;\n+CallProjections* CallNode::extract_projections(bool separate_io_proj, bool do_asserts) {\n+  uint max_res = TypeFunc::Parms-1;\n+  for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+    ProjNode *pn = fast_out(i)->as_Proj();\n+    max_res = MAX2(max_res, pn->_con);\n+  }\n+\n+  assert(max_res < _tf->range_cc()->cnt(), \"result out of bounds\");\n+\n+  uint projs_size = sizeof(CallProjections);\n+  if (max_res > TypeFunc::Parms) {\n+    projs_size += (max_res-TypeFunc::Parms)*sizeof(Node*);\n+  }\n+  char* projs_storage = resource_allocate_bytes(projs_size);\n+  CallProjections* projs = new(projs_storage)CallProjections(max_res - TypeFunc::Parms + 1);\n@@ -929,1 +963,1 @@\n-      projs->resproj = pn;\n+      projs->resproj[0] = pn;\n@@ -932,1 +966,3 @@\n-      assert(false, \"unexpected projection from allocation node.\");\n+      assert(pn->_con <= max_res, \"unexpected projection from allocation node.\");\n+      projs->resproj[pn->_con-TypeFunc::Parms] = pn;\n+      break;\n@@ -939,1 +975,1 @@\n-  assert(projs->fallthrough_proj      != NULL, \"must be found\");\n+  assert(!do_asserts || projs->fallthrough_proj      != NULL, \"must be found\");\n@@ -949,0 +985,1 @@\n+  return projs;\n@@ -980,2 +1017,2 @@\n-  uint old_dbg_start = sfpt->is_Call() ? sfpt->as_Call()->tf()->domain()->cnt() : (uint)TypeFunc::Parms+1;\n-  uint new_dbg_start = tf()->domain()->cnt();\n+  uint old_dbg_start = sfpt->is_Call() ? sfpt->as_Call()->tf()->domain_sig()->cnt() : (uint)TypeFunc::Parms+1;\n+  uint new_dbg_start = tf()->domain_sig()->cnt();\n@@ -1022,0 +1059,4 @@\n+  Bytecodes::Code bc = jvms()->method()->java_code_at_bci(jvms()->bci());\n+  if (EnableValhalla && (bc == Bytecodes::_if_acmpeq || bc == Bytecodes::_if_acmpne)) {\n+    return true;\n+  }\n@@ -1055,0 +1096,10 @@\n+  if (can_reshape && uncommon_trap_request() != 0) {\n+    if (remove_useless_allocation(phase, in(0), in(TypeFunc::Memory), in(TypeFunc::Parms))) {\n+      if (!in(0)->is_Region()) {\n+        PhaseIterGVN* igvn = phase->is_IterGVN();\n+        igvn->replace_input_of(this, 0, phase->C->top());\n+      }\n+      return this;\n+    }\n+  }\n+\n@@ -1102,0 +1153,137 @@\n+bool CallStaticJavaNode::remove_useless_allocation(PhaseGVN *phase, Node* ctl, Node* mem, Node* unc_arg) {\n+  \/\/ Split if can cause the flattened array branch of an array load to\n+  \/\/ end in an uncommon trap. In that case, the allocation of the\n+  \/\/ loaded value and its initialization is useless. Eliminate it. use\n+  \/\/ the jvm state of the allocation to create a new uncommon trap\n+  \/\/ call at the load.\n+  if (ctl == NULL || ctl->is_top() || mem == NULL || mem->is_top() || !mem->is_MergeMem()) {\n+    return false;\n+  }\n+  PhaseIterGVN* igvn = phase->is_IterGVN();\n+  if (ctl->is_Region()) {\n+    bool res = false;\n+    for (uint i = 1; i < ctl->req(); i++) {\n+      MergeMemNode* mm = mem->clone()->as_MergeMem();\n+      for (MergeMemStream mms(mm); mms.next_non_empty(); ) {\n+        Node* m = mms.memory();\n+        if (m->is_Phi() && m->in(0) == ctl) {\n+          mms.set_memory(m->in(i));\n+        }\n+      }\n+      if (remove_useless_allocation(phase, ctl->in(i), mm, unc_arg)) {\n+        res = true;\n+        if (!ctl->in(i)->is_Region()) {\n+          igvn->replace_input_of(ctl, i, phase->C->top());\n+        }\n+      }\n+      igvn->remove_dead_node(mm);\n+    }\n+    return res;\n+  }\n+  \/\/ verify the control flow is ok\n+  Node* c = ctl;\n+  Node* copy = NULL;\n+  Node* alloc = NULL;\n+  for (;;) {\n+    if (c == NULL || c->is_top()) {\n+      return false;\n+    }\n+    if (c->is_Proj() || c->is_Catch() || c->is_MemBar()) {\n+      c = c->in(0);\n+    } else if (c->Opcode() == Op_CallLeaf &&\n+               c->as_Call()->entry_point() == CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_inline)) {\n+      copy = c;\n+      c = c->in(0);\n+    } else if (c->is_Allocate()) {\n+      Node* new_obj = c->as_Allocate()->result_cast();\n+      if (copy == NULL || new_obj == NULL) {\n+        return false;\n+      }\n+      Node* copy_dest = copy->in(TypeFunc::Parms + 2);\n+      if (copy_dest != new_obj) {\n+        return false;\n+      }\n+      alloc = c;\n+      break;\n+    } else {\n+      return false;\n+    }\n+  }\n+\n+  JVMState* jvms = alloc->jvms();\n+  if (phase->C->too_many_traps(jvms->method(), jvms->bci(), Deoptimization::trap_request_reason(uncommon_trap_request()))) {\n+    return false;\n+  }\n+\n+  Node* alloc_mem = alloc->in(TypeFunc::Memory);\n+  if (alloc_mem == NULL || alloc_mem->is_top()) {\n+    return false;\n+  }\n+  if (!alloc_mem->is_MergeMem()) {\n+    alloc_mem = MergeMemNode::make(alloc_mem);\n+    igvn->register_new_node_with_optimizer(alloc_mem);\n+  }\n+\n+  \/\/ and that there's no unexpected side effect\n+  for (MergeMemStream mms2(mem->as_MergeMem(), alloc_mem->as_MergeMem()); mms2.next_non_empty2(); ) {\n+    Node* m1 = mms2.is_empty() ? mms2.base_memory() : mms2.memory();\n+    Node* m2 = mms2.memory2();\n+\n+    for (uint i = 0; i < 100; i++) {\n+      if (m1 == m2) {\n+        break;\n+      } else if (m1->is_Proj()) {\n+        m1 = m1->in(0);\n+      } else if (m1->is_MemBar()) {\n+        m1 = m1->in(TypeFunc::Memory);\n+      } else if (m1->Opcode() == Op_CallLeaf &&\n+                 m1->as_Call()->entry_point() == CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_inline)) {\n+        if (m1 != copy) {\n+          return false;\n+        }\n+        m1 = m1->in(TypeFunc::Memory);\n+      } else if (m1->is_Allocate()) {\n+        if (m1 != alloc) {\n+          return false;\n+        }\n+        break;\n+      } else if (m1->is_MergeMem()) {\n+        MergeMemNode* mm = m1->as_MergeMem();\n+        int idx = mms2.alias_idx();\n+        if (idx == Compile::AliasIdxBot) {\n+          m1 = mm->base_memory();\n+        } else {\n+          m1 = mm->memory_at(idx);\n+        }\n+      } else {\n+        return false;\n+      }\n+    }\n+  }\n+  if (alloc_mem->outcnt() == 0) {\n+    igvn->remove_dead_node(alloc_mem);\n+  }\n+\n+  address call_addr = SharedRuntime::uncommon_trap_blob()->entry_point();\n+  CallNode* unc = new CallStaticJavaNode(OptoRuntime::uncommon_trap_Type(), call_addr, \"uncommon_trap\", NULL);\n+  unc->init_req(TypeFunc::Control, alloc->in(0));\n+  unc->init_req(TypeFunc::I_O, alloc->in(TypeFunc::I_O));\n+  unc->init_req(TypeFunc::Memory, alloc->in(TypeFunc::Memory));\n+  unc->init_req(TypeFunc::FramePtr,  alloc->in(TypeFunc::FramePtr));\n+  unc->init_req(TypeFunc::ReturnAdr, alloc->in(TypeFunc::ReturnAdr));\n+  unc->init_req(TypeFunc::Parms+0, unc_arg);\n+  unc->set_cnt(PROB_UNLIKELY_MAG(4));\n+  unc->copy_call_debug_info(igvn, alloc->as_Allocate());\n+\n+  igvn->replace_input_of(alloc, 0, phase->C->top());\n+\n+  igvn->register_new_node_with_optimizer(unc);\n+\n+  Node* ctrl = phase->transform(new ProjNode(unc, TypeFunc::Control));\n+  Node* halt = phase->transform(new HaltNode(ctrl, alloc->in(TypeFunc::FramePtr), \"uncommon trap returned which should never happen\"));\n+  phase->C->root()->add_req(halt);\n+\n+  return true;\n+}\n+\n+\n@@ -1206,1 +1394,1 @@\n-Node* CallNativeNode::match(const ProjNode *proj, const Matcher *matcher) {\n+Node* CallNativeNode::match(const ProjNode *proj, const Matcher *matcher, const RegMask* mask) {\n@@ -1216,1 +1404,1 @@\n-      const Type* field_at_con = tf()->range()->field_at(proj->_con);\n+      const Type* field_at_con = tf()->range_sig()->field_at(proj->_con);\n@@ -1231,1 +1419,1 @@\n-      assert(tf()->range()->field_at(proj->_con) == Type::HALF, \"Expected HALF\");\n+      assert(tf()->range_sig()->field_at(proj->_con) == Type::HALF, \"Expected HALF\");\n@@ -1266,0 +1454,7 @@\n+  if (_entry_point == NULL) {\n+    \/\/ The call to that stub is a special case: its inputs are\n+    \/\/ multiple values returned from a call and so it should follow\n+    \/\/ the return convention.\n+    SharedRuntime::java_return_convention(sig_bt, parm_regs, argcnt);\n+    return;\n+  }\n@@ -1270,1 +1465,1 @@\n-  assert((tf()->domain()->cnt() - TypeFunc::Parms) == argcnt, \"arg counts must match!\");\n+  assert((tf()->domain_sig()->cnt() - TypeFunc::Parms) == argcnt, \"arg counts must match!\");\n@@ -1273,1 +1468,1 @@\n-    assert(tf()->domain()->field_at(TypeFunc::Parms + i)->basic_type() == sig_bt[i], \"types must match!\");\n+    assert(tf()->domain_sig()->field_at(TypeFunc::Parms + i)->basic_type() == sig_bt[i], \"types must match!\");\n@@ -1316,0 +1511,6 @@\n+uint CallLeafNoFPNode::match_edge(uint idx) const {\n+  \/\/ Null entry point is a special case for which the target is in a\n+  \/\/ register. Need to match that edge.\n+  return entry_point() == NULL && idx == TypeFunc::Parms;\n+}\n+\n@@ -1532,1 +1733,1 @@\n-  if (!alloc->is_Allocate()\n+  if (alloc != NULL && !alloc->is_Allocate()\n@@ -1591,1 +1792,3 @@\n-                           Node *size, Node *klass_node, Node *initial_test)\n+                           Node *size, Node *klass_node,\n+                           Node* initial_test,\n+                           InlineTypeBaseNode* inline_type_node)\n@@ -1599,0 +1802,1 @@\n+  _larval = false;\n@@ -1610,0 +1814,3 @@\n+  init_req( InlineTypeNode     , inline_type_node);\n+  \/\/ DefaultValue defaults to NULL\n+  \/\/ RawDefaultValue defaults to NULL\n@@ -1616,3 +1823,2 @@\n-         initializer->is_initializer() &&\n-         !initializer->is_static(),\n-             \"unexpected initializer method\");\n+         initializer->is_object_constructor_or_class_initializer(),\n+         \"unexpected initializer method\");\n@@ -1629,1 +1835,2 @@\n-Node *AllocateNode::make_ideal_mark(PhaseGVN *phase, Node* obj, Node* control, Node* mem) {\n+\n+Node* AllocateNode::make_ideal_mark(PhaseGVN* phase, Node* control, Node* mem) {\n@@ -1631,2 +1838,1 @@\n-  \/\/ For now only enable fast locking for non-array types\n-  if (UseBiasedLocking && Opcode() == Op_Allocate) {\n+  if (EnableValhalla) {\n@@ -1639,1 +1845,3 @@\n-  return mark_node;\n+  mark_node = phase->transform(mark_node);\n+  \/\/ Avoid returning a constant (old node) here because this method is used by LoadNode::Ideal\n+  return new OrXNode(mark_node, phase->MakeConX(_larval ? markWord::larval_bit_in_place : 0));\n@@ -1642,0 +1850,1 @@\n+\n@@ -1644,1 +1853,4 @@\n-  if (remove_dead_region(phase, can_reshape))  return this;\n+  Node* res = SafePointNode::Ideal(phase, can_reshape);\n+  if (res != NULL) {\n+    return res;\n+  }\n@@ -2069,1 +2281,3 @@\n-  if (can_reshape && EliminateLocks && !is_non_esc_obj()) {\n+  const Type* obj_type = phase->type(obj_node());\n+  if (can_reshape && EliminateLocks && !is_non_esc_obj() &&\n+      !obj_type->isa_inlinetype() && !obj_type->is_inlinetypeptr()) {\n@@ -2237,1 +2451,3 @@\n-  if (can_reshape && EliminateLocks && !is_non_esc_obj()) {\n+  const Type* obj_type = phase->type(obj_node());\n+  if (can_reshape && EliminateLocks && !is_non_esc_obj() &&\n+      !obj_type->isa_inlinetype() && !obj_type->is_inlinetypeptr()) {\n@@ -2319,1 +2535,2 @@\n-    dest_t = dest_t->add_offset(Type::OffsetBot)->is_oopptr();\n+    dest_t = dest_t->is_aryptr()->with_field_offset(Type::OffsetBot)->add_offset(Type::OffsetBot)->is_oopptr();\n+    t_oop = t_oop->is_aryptr()->with_field_offset(Type::OffsetBot);\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":289,"deletions":72,"binary":false,"changes":361,"status":"modified"},{"patch":"@@ -79,1 +79,1 @@\n-  virtual Node *match( const ProjNode *proj, const Matcher *m );\n+  virtual Node *match(const ProjNode *proj, const Matcher *m, const RegMask* mask);\n@@ -93,1 +93,0 @@\n-  static  const TypeTuple *osr_domain();\n@@ -552,1 +551,1 @@\n-class CallProjections : public StackObj {\n+class CallProjections {\n@@ -561,1 +560,19 @@\n-  Node* resproj;\n+  uint nb_resproj;\n+  Node* resproj[1]; \/\/ at least one projection\n+\n+  CallProjections(uint nbres) {\n+    fallthrough_proj      = NULL;\n+    fallthrough_catchproj = NULL;\n+    fallthrough_memproj   = NULL;\n+    fallthrough_ioproj    = NULL;\n+    catchall_catchproj    = NULL;\n+    catchall_memproj      = NULL;\n+    catchall_ioproj       = NULL;\n+    exobj                 = NULL;\n+    nb_resproj            = nbres;\n+    resproj[0]            = NULL;\n+    for (uint i = 1; i < nb_resproj; i++) {\n+      resproj[i]          = NULL;\n+    }\n+  }\n+\n@@ -584,1 +601,1 @@\n-    : SafePointNode(tf->domain()->cnt(), jvms, adr_type),\n+    : SafePointNode(tf->domain_cc()->cnt(), jvms, adr_type),\n@@ -611,1 +628,1 @@\n-  virtual Node*       match(const ProjNode* proj, const Matcher* m);\n+  virtual Node*       match(const ProjNode* proj, const Matcher* m, const RegMask* mask);\n@@ -631,0 +648,1 @@\n+  bool                has_debug_use(Node* n);\n@@ -637,2 +655,3 @@\n-    const TypeTuple* r = tf()->range();\n-    return (r->cnt() > TypeFunc::Parms &&\n+    const TypeTuple* r = tf()->range_sig();\n+    return (!tf()->returns_inline_type_as_fields() &&\n+            r->cnt() > TypeFunc::Parms &&\n@@ -645,1 +664,1 @@\n-  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true);\n+  CallProjections* extract_projections(bool separate_io_proj, bool do_asserts = true);\n@@ -715,0 +734,3 @@\n+\n+  bool remove_useless_allocation(PhaseGVN *phase, Node* ctl, Node* mem, Node* unc_arg);\n+\n@@ -723,0 +745,11 @@\n+    const TypeTuple *r = tf->range_sig();\n+    if (InlineTypeReturnedAsFields &&\n+        method != NULL &&\n+        method->is_method_handle_intrinsic() &&\n+        r->cnt() > TypeFunc::Parms &&\n+        r->field_at(TypeFunc::Parms)->isa_oopptr() &&\n+        r->field_at(TypeFunc::Parms)->is_oopptr()->can_be_inline_type()) {\n+      \/\/ Make sure this call is processed by PhaseMacroExpand::expand_mh_intrinsic_return\n+      init_flags(Flag_is_macro);\n+      C->add_macro_node(this);\n+    }\n@@ -848,1 +881,1 @@\n-  virtual Node* match(const ProjNode *proj, const Matcher *m);\n+  virtual Node* match(const ProjNode *proj, const Matcher *m, const RegMask* mask);\n@@ -867,0 +900,1 @@\n+  virtual uint match_edge(uint idx) const;\n@@ -890,0 +924,3 @@\n+    InlineTypeNode,                   \/\/ InlineTypeNode if this is an inline type allocation\n+    DefaultValue,                     \/\/ default value in case of non-flattened inline type array\n+    RawDefaultValue,                  \/\/ same as above but as raw machine word\n@@ -899,0 +936,3 @@\n+    fields[InlineTypeNode] = Type::BOTTOM;\n+    fields[DefaultValue] = TypeInstPtr::NOTNULL;\n+    fields[RawDefaultValue] = TypeX_X;\n@@ -916,0 +956,1 @@\n+  bool _larval;\n@@ -919,1 +960,2 @@\n-               Node *size, Node *klass_node, Node *initial_test);\n+               Node *size, Node *klass_node, Node *initial_test,\n+               InlineTypeBaseNode* inline_type_node = NULL);\n@@ -984,1 +1026,1 @@\n-  Node* make_ideal_mark(PhaseGVN *phase, Node* obj, Node* control, Node* mem);\n+  Node* make_ideal_mark(PhaseGVN* phase, Node* control, Node* mem);\n@@ -995,4 +1037,2 @@\n-                    Node* count_val\n-                    )\n-    : AllocateNode(C, atype, ctrl, mem, abio, size, klass_node,\n-                   initial_test)\n+                    Node* count_val, Node* default_value, Node* raw_default_value)\n+    : AllocateNode(C, atype, ctrl, mem, abio, size, klass_node, initial_test)\n@@ -1002,0 +1042,2 @@\n+    init_req(AllocateNode::DefaultValue,  default_value);\n+    init_req(AllocateNode::RawDefaultValue, raw_default_value);\n@@ -1121,1 +1163,1 @@\n-    return TypeFunc::make(domain,range);\n+    return TypeFunc::make(domain, range);\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":59,"deletions":17,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -30,0 +30,2 @@\n+#include \"opto\/graphKit.hpp\"\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -32,0 +34,1 @@\n+#include \"opto\/rootnode.hpp\"\n@@ -361,0 +364,3 @@\n+  if (in(1)->is_InlineTypeBase() && _type->isa_oopptr() && phase->type(in(1))->inline_klass()->is_subtype_of(_type->is_oopptr()->klass())) {\n+    return in(1);\n+  }\n@@ -392,2 +398,11 @@\n-  if( in_type != NULL && my_type != NULL ) {\n-    TypePtr::PTR   in_ptr    = in_type->ptr();\n+  if (in_type != NULL && my_type != NULL) {\n+    if (!StressReflectiveCode && my_type->isa_aryptr() && in_type->isa_aryptr()) {\n+      \/\/ Propagate array properties (not flat\/null-free)\n+      \/\/ Don't do this when StressReflectiveCode is enabled because it might lead to\n+      \/\/ a dying data path while the corresponding flat\/null-free check is not folded.\n+      my_type = my_type->is_aryptr()->update_properties(in_type->is_aryptr());\n+      if (my_type == NULL) {\n+        return Type::TOP; \/\/ Inconsistent properties\n+      }\n+    }\n+    TypePtr::PTR in_ptr = in_type->ptr();\n@@ -548,0 +563,16 @@\n+\n+  if (t->is_zero_type() || !t->maybe_null()) {\n+    for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+      Node* u = fast_out(i);\n+      if (u->Opcode() == Op_OrL) {\n+        for (DUIterator_Fast jmax, j = u->fast_outs(jmax); j < jmax; j++) {\n+          Node* cmp = u->fast_out(j);\n+          if (cmp->Opcode() == Op_CmpL) {\n+            \/\/ Give CmpL a chance to get optimized\n+            phase->record_for_igvn(cmp);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/castnode.cpp","additions":33,"deletions":2,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -396,1 +397,1 @@\n-bool RegionNode::try_clean_mem_phi(PhaseGVN *phase) {\n+Node* PhiNode::try_clean_mem_phi(PhaseGVN *phase) {\n@@ -416,2 +417,1 @@\n-  PhiNode* phi = has_unique_phi();\n-  if (phi && phi->type() == Type::MEMORY && req() == 3 && phi->is_diamond_phi(true)) {\n+  if (type() == Type::MEMORY && is_diamond_phi(true)) {\n@@ -419,1 +419,2 @@\n-    assert(phi->req() == 3, \"same as region\");\n+    assert(req() == 3, \"same as region\");\n+    Node* r = in(0);\n@@ -421,2 +422,2 @@\n-      Node *mem = phi->in(i);\n-      if (mem && mem->is_MergeMem() && in(i)->outcnt() == 1) {\n+      Node *mem = in(i);\n+      if (mem && mem->is_MergeMem() && r->in(i)->outcnt() == 1) {\n@@ -426,1 +427,1 @@\n-        Node* other = phi->in(j);\n+        Node* other = in(j);\n@@ -430,2 +431,1 @@\n-          phase->is_IterGVN()->replace_node(phi, m);\n-          return true;\n+          return m;\n@@ -436,1 +436,1 @@\n-  return false;\n+  return NULL;\n@@ -451,2 +451,9 @@\n-    if (has_phis && try_clean_mem_phi(phase)) {\n-      has_phis = false;\n+    if (has_phis) {\n+      PhiNode* phi = has_unique_phi();\n+      if (phi != NULL) {\n+        Node* m = phi->try_clean_mem_phi(phase);\n+        if (m != NULL) {\n+          phase->is_IterGVN()->replace_node(phi, m);\n+          has_phis = false;\n+        }\n+      }\n@@ -845,1 +852,2 @@\n-             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck()) {\n+             cmp1->is_SubTypeCheck() || cmp2->is_SubTypeCheck() ||\n+             cmp1->is_FlatArrayCheck() || cmp2->is_FlatArrayCheck()) {\n@@ -926,1 +934,1 @@\n-  assert(t != Type::MEMORY || at == flatten_phi_adr_type(at), \"flatten at\");\n+  assert(t != Type::MEMORY || at == flatten_phi_adr_type(at) || (flatten_phi_adr_type(at) == TypeAryPtr::INLINES && Compile::current()->flattened_accesses_share_alias()), \"flatten at\");\n@@ -1063,0 +1071,8 @@\n+  \/\/ Flat array element shouldn't get their own memory slice until flattened_accesses_share_alias is cleared.\n+  \/\/ It could be the graph has no loads\/stores and flattened_accesses_share_alias is never cleared. EA could still\n+  \/\/ creates per element Phis but that wouldn't be a problem as there are no memory accesses for that array.\n+  assert(_adr_type == NULL || _adr_type->isa_aryptr() == NULL ||\n+         _adr_type->is_aryptr()->is_known_instance() ||\n+         !_adr_type->is_aryptr()->is_flat() ||\n+         !Compile::current()->flattened_accesses_share_alias() ||\n+         _adr_type == TypeAryPtr::INLINES, \"flat array element shouldn't get its own slice yet\");\n@@ -1136,9 +1152,4 @@\n-  if (ttip != NULL) {\n-    ciKlass* k = ttip->klass();\n-    if (k->is_loaded() && k->is_interface())\n-      is_intf = true;\n-  }\n-  if (ttkp != NULL) {\n-    ciKlass* k = ttkp->klass();\n-    if (k->is_loaded() && k->is_interface())\n-      is_intf = true;\n+  if (ttip != NULL && ttip->is_loaded() && ttip->klass()->is_interface()) {\n+    is_intf = true;\n+  } else if (ttkp != NULL && ttkp->is_loaded() && ttkp->klass()->is_interface()) {\n+    is_intf = true;\n@@ -1201,1 +1212,1 @@\n-    if (!t->empty() && ttip && ttip->is_loaded() && ttip->klass()->is_interface()) {\n+    if (!t->empty() && ttip != NULL && ttip->is_loaded() && ttip->klass()->is_interface()) {\n@@ -1203,1 +1214,1 @@\n-    } else if (!t->empty() && ttkp && ttkp->is_loaded() && ttkp->klass()->is_interface()) {\n+    } else if (!t->empty() && ttkp != NULL && ttkp->is_loaded() && ttkp->klass()->is_interface()) {\n@@ -1365,0 +1376,8 @@\n+  if (phase->is_IterGVN()) {\n+    Node* m = try_clean_mem_phi(phase);\n+    if (m != NULL) {\n+      return m;\n+    }\n+  }\n+\n+\n@@ -1900,0 +1919,18 @@\n+  \/\/ If all inputs are inline types of the same type, push the inline type node down\n+  \/\/ through the phi because inline type nodes should be merged through their input values.\n+  if (req() > 2 && in(1) != NULL && in(1)->is_InlineTypeBase() && (can_reshape || in(1)->is_InlineType())) {\n+    int opcode = in(1)->Opcode();\n+    uint i = 2;\n+    \/\/ Check if inputs are values of the same type\n+    for (; i < req() && in(i) && in(i)->is_InlineTypeBase() && in(i)->cmp(*in(1)); i++) {\n+      assert(in(i)->Opcode() == opcode, \"mixing pointers and values?\");\n+    }\n+    if (i == req()) {\n+      InlineTypeBaseNode* vt = in(1)->as_InlineTypeBase()->clone_with_phis(phase, in(0));\n+      for (uint i = 2; i < req(); ++i) {\n+        vt->merge_with(phase, in(i)->as_InlineTypeBase(), i, i == (req()-1));\n+      }\n+      return vt;\n+    }\n+  }\n+\n@@ -2187,0 +2224,2 @@\n+    \/\/ TODO revisit this with JDK-8247216\n+    bool mergemem_only = true;\n@@ -2199,0 +2238,2 @@\n+      } else {\n+        mergemem_only = false;\n@@ -2203,1 +2244,1 @@\n-    if (!saw_self && adr_type() == TypePtr::BOTTOM)  merge_width = 0;\n+    if (!mergemem_only && !saw_self && adr_type() == TypePtr::BOTTOM)  merge_width = 0;\n@@ -2274,0 +2315,5 @@\n+            if (igvn) {\n+              \/\/ TODO revisit this with JDK-8247216\n+              \/\/ Put 'n' on the worklist because it might be modified by MergeMemStream::iteration_setup\n+              igvn->_worklist.push(n);\n+            }\n@@ -2692,0 +2738,6 @@\n+\n+  \/\/ CheckCastPPNode::Ideal() for inline types reuses the exception\n+  \/\/ paths of a call to perform an allocation: we can see a Phi here.\n+  if (in(1)->is_Phi()) {\n+    return this;\n+  }\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":78,"deletions":26,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -1744,1 +1744,1 @@\n-          derived->bottom_type()->make_ptr()->is_ptr()->_offset == 0, \"sanity\");\n+         derived->bottom_type()->make_ptr()->is_ptr()->offset() == 0, \"sanity\");\n@@ -1747,1 +1747,1 @@\n-  if( tj == NULL || tj->_offset == 0 ) {\n+  if (tj == NULL || tj->offset() == 0) {\n@@ -1913,1 +1913,1 @@\n-                  derived->bottom_type()->make_ptr()->is_ptr()->_offset == 0, \"sanity\");\n+                 derived->bottom_type()->make_ptr()->is_ptr()->offset() == 0, \"sanity\");\n@@ -1915,1 +1915,1 @@\n-          if( tj && tj->_offset != 0 && tj->isa_oop_ptr() ) {\n+          if (tj && tj->offset() != 0 && tj->isa_oop_ptr()) {\n@@ -2205,1 +2205,1 @@\n-  const TypeTuple *domain = C->tf()->domain();\n+  const TypeTuple *domain = C->tf()->domain_cc();\n@@ -2414,1 +2414,1 @@\n-                  if (is_derived && check->bottom_type()->is_ptr()->_offset != 0) {\n+                  if (is_derived && check->bottom_type()->is_ptr()->offset() != 0) {\n@@ -2418,1 +2418,1 @@\n-                    assert(check->bottom_type()->is_ptr()->_offset == 0, \"Bad base pointer\");\n+                    assert(check->bottom_type()->is_ptr()->offset() == 0, \"Bad base pointer\");\n@@ -2427,1 +2427,1 @@\n-                } else if (check->bottom_type()->is_ptr()->_offset == 0) {\n+                } else if (check->bottom_type()->is_ptr()->offset() == 0) {\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -168,0 +168,1 @@\n+macro(FlatArrayCheck)\n@@ -342,0 +343,2 @@\n+macro(InlineType)\n+macro(InlineTypePtr)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -399,0 +400,3 @@\n+  if (dead->is_InlineTypeBase()) {\n+    remove_inline_type(dead);\n+  }\n@@ -440,0 +444,1 @@\n+  remove_useless_nodes(_inline_type_nodes,  useful); \/\/ remove useless inline type nodes\n@@ -574,0 +579,1 @@\n+                  _inline_type_nodes (comp_arena(), 8, 0, NULL),\n@@ -678,4 +684,2 @@\n-      const TypeTuple *domain = StartOSRNode::osr_domain();\n-      const TypeTuple *range = TypeTuple::make_range(method()->signature());\n-      init_tf(TypeFunc::make(domain, range));\n-      StartNode* s = new StartOSRNode(root(), domain);\n+      init_tf(TypeFunc::make(method(), \/* is_osr_compilation = *\/ true));\n+      StartNode* s = new StartOSRNode(root(), tf()->domain_sig());\n@@ -688,1 +692,1 @@\n-      StartNode* s = new StartNode(root(), tf()->domain());\n+      StartNode* s = new StartNode(root(), tf()->domain_cc());\n@@ -823,0 +827,4 @@\n+  if (needs_stack_repair()) {\n+    \/\/ One extra slot for the special stack increment value\n+    next_slot += 2;\n+  }\n@@ -980,0 +988,4 @@\n+  _has_flattened_accesses = false;\n+  _flattened_accesses_share_alias = true;\n+  _scalarize_in_safepoints = false;\n+\n@@ -1282,1 +1294,2 @@\n-    assert(InlineUnsafeOps, \"indeterminate pointers come only from unsafe ops\");\n+    bool default_value_load = EnableValhalla && tj->is_instptr()->klass() == ciEnv::current()->Class_klass();\n+    assert(InlineUnsafeOps || default_value_load, \"indeterminate pointers come only from unsafe ops\");\n@@ -1295,0 +1308,9 @@\n+  if (ta && ta->is_not_flat()) {\n+    \/\/ Erase not flat property for alias analysis.\n+    tj = ta = ta->cast_to_not_flat(false);\n+  }\n+  if (ta && ta->is_not_null_free()) {\n+    \/\/ Erase not null free property for alias analysis.\n+    tj = ta = ta->cast_to_not_null_free(false);\n+  }\n+\n@@ -1299,1 +1321,1 @@\n-      tj = ta = TypeAryPtr::make(ptr, ta->ary(), ta->klass(), true, offset, ta->instance_id());\n+      tj = ta = TypeAryPtr::make(ptr, ta->ary(), ta->klass(), true, Type::Offset(offset), ta->field_offset(), ta->instance_id());\n@@ -1305,0 +1327,2 @@\n+    \/\/ For flattened inline type array, each field has its own slice so\n+    \/\/ we must include the field offset.\n@@ -1308,1 +1332,1 @@\n-        tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),ta->ary(),ta->klass(),false,offset);\n+        tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),ta->ary(),ta->klass(),false,Type::Offset(offset), ta->field_offset());\n@@ -1322,1 +1346,1 @@\n-        tj = ta = TypeAryPtr::make(ptr,ta->ary(),ta->klass(),false,offset);\n+        tj = ta = TypeAryPtr::make(ptr,ta->ary(),ta->klass(),false,Type::Offset(offset), ta->field_offset());\n@@ -1328,1 +1352,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,ta->klass(),false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,ta->klass(),false,Type::Offset(offset), ta->field_offset());\n@@ -1333,1 +1357,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), ta->field_offset());\n@@ -1337,1 +1361,6 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), ta->field_offset());\n+    }\n+    \/\/ Initially all flattened array accesses share a single slice\n+    if (ta->is_flat() && ta->elem() != TypeInlineType::BOTTOM && _flattened_accesses_share_alias) {\n+      const TypeAry *tary = TypeAry::make(TypeInlineType::BOTTOM, ta->size());\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,NULL,false,Type::Offset(offset), Type::Offset(Type::OffsetBot));\n@@ -1344,1 +1373,1 @@\n-      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,aklass,false,offset);\n+      tj = ta = TypeAryPtr::make(ptr,ta->const_oop(),tary,aklass,false,Type::Offset(offset), ta->field_offset());\n@@ -1350,1 +1379,1 @@\n-      tj = ta = TypeAryPtr::make(TypePtr::BotPTR,ta->ary(),ta->klass(),false,offset);\n+      tj = ta = TypeAryPtr::make(TypePtr::BotPTR,ta->ary(),ta->klass(),false,Type::Offset(offset), ta->field_offset());\n@@ -1364,1 +1393,1 @@\n-        tj = to = TypeInstPtr::make(TypePtr::BotPTR,to->klass(),false,0,offset);\n+        tj = to = TypeInstPtr::make(TypePtr::BotPTR,to->klass(),false,0,Type::Offset(offset));\n@@ -1372,1 +1401,1 @@\n-      tj = to = TypeInstPtr::make(TypePtr::BotPTR,to->klass(),false,0,offset);\n+      tj = to = TypeInstPtr::make(TypePtr::BotPTR,to->klass(),false,0,Type::Offset(offset));\n@@ -1375,1 +1404,1 @@\n-      tj = to = TypeInstPtr::make(to->ptr(),to->klass(),to->klass_is_exact(),to->const_oop(),to->offset(), to->instance_id());\n+      tj = to = TypeInstPtr::make(to->ptr(),to->klass(),to->klass_is_exact(),to->const_oop(),Type::Offset(to->offset()), to->klass()->flatten_array(), to->instance_id());\n@@ -1382,1 +1411,1 @@\n-        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, NULL, offset);\n+        tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()->Object_klass(), false, NULL, Type::Offset(offset));\n@@ -1396,1 +1425,1 @@\n-          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, true, NULL, offset, to->instance_id());\n+          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, true, NULL, Type::Offset(offset), canonical_holder->flatten_array(), to->instance_id());\n@@ -1398,1 +1427,1 @@\n-          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, false, NULL, offset);\n+          tj = to = TypeInstPtr::make(to->ptr(), canonical_holder, false, NULL, Type::Offset(offset));\n@@ -1415,1 +1444,1 @@\n-                                   offset);\n+                                   Type::Offset(offset));\n@@ -1419,1 +1448,1 @@\n-    if( klass->is_obj_array_klass() ) {\n+    if (klass != NULL && klass->is_obj_array_klass()) {\n@@ -1423,1 +1452,1 @@\n-      tj = tk = TypeKlassPtr::make( TypePtr::NotNull, k, offset );\n+      tj = tk = TypeKlassPtr::make(TypePtr::NotNull, k, Type::Offset(offset));\n@@ -1439,1 +1468,1 @@\n-      tj = tk = TypeKlassPtr::make( TypePtr::NotNull, tk->klass(), offset );\n+      tj = tk = TypeKlassPtr::make(TypePtr::NotNull, tk->klass(), Type::Offset(offset));\n@@ -1578,1 +1607,1 @@\n-Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field) {\n+Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field, bool uncached) {\n@@ -1582,3 +1611,6 @@\n-  AliasCacheEntry* ace = probe_alias_cache(adr_type);\n-  if (ace->_adr_type == adr_type) {\n-    return alias_type(ace->_index);\n+  AliasCacheEntry* ace = NULL;\n+  if (!uncached) {\n+    ace = probe_alias_cache(adr_type);\n+    if (ace->_adr_type == adr_type) {\n+      return alias_type(ace->_index);\n+    }\n@@ -1634,0 +1666,1 @@\n+    ciField* field = NULL;\n@@ -1640,0 +1673,1 @@\n+      const Type* elemtype = flat->is_aryptr()->elem();\n@@ -1641,1 +1675,8 @@\n-        alias_type(idx)->set_element(flat->is_aryptr()->elem());\n+        alias_type(idx)->set_element(elemtype);\n+      }\n+      int field_offset = flat->is_aryptr()->field_offset().get();\n+      if (elemtype->isa_inlinetype() &&\n+          field_offset != Type::OffsetBot) {\n+        ciInlineKlass* vk = elemtype->inline_klass();\n+        field_offset += vk->first_field_offset();\n+        field = vk->get_field_by_offset(field_offset, false);\n@@ -1653,0 +1694,2 @@\n+      if (flat->offset() == in_bytes(Klass::layout_helper_offset()))\n+        alias_type(idx)->set_rewritable(false);\n@@ -1663,1 +1706,0 @@\n-      ciField* field;\n@@ -1670,0 +1712,4 @@\n+      } else if (tinst->klass()->is_inlinetype()) {\n+        \/\/ Inline type field\n+        ciInlineKlass* vk = tinst->inline_klass();\n+        field = vk->get_field_by_offset(tinst->offset(), false);\n@@ -1671,1 +1717,1 @@\n-        ciInstanceKlass *k = tinst->klass()->as_instance_klass();\n+        ciInstanceKlass* k = tinst->klass()->as_instance_klass();\n@@ -1674,7 +1720,14 @@\n-      assert(field == NULL ||\n-             original_field == NULL ||\n-             (field->holder() == original_field->holder() &&\n-              field->offset() == original_field->offset() &&\n-              field->is_static() == original_field->is_static()), \"wrong field?\");\n-      \/\/ Set field() and is_rewritable() attributes.\n-      if (field != NULL)  alias_type(idx)->set_field(field);\n+    }\n+    assert(field == NULL ||\n+           original_field == NULL ||\n+           (field->holder() == original_field->holder() &&\n+            field->offset() == original_field->offset() &&\n+            field->is_static() == original_field->is_static()), \"wrong field?\");\n+    \/\/ Set field() and is_rewritable() attributes.\n+    if (field != NULL) {\n+      alias_type(idx)->set_field(field);\n+      if (flat->isa_aryptr()) {\n+        \/\/ Fields of flat arrays are rewritable although they are declared final\n+        assert(flat->is_aryptr()->is_flat(), \"must be a flat array\");\n+        alias_type(idx)->set_rewritable(true);\n+      }\n@@ -1685,3 +1738,4 @@\n-  ace->_adr_type = adr_type;\n-  ace->_index    = idx;\n-  assert(alias_type(adr_type) == alias_type(idx),  \"type must be installed\");\n+  if (!uncached) {\n+    ace->_adr_type = adr_type;\n+    ace->_index    = idx;\n+    assert(alias_type(adr_type) == alias_type(idx),  \"type must be installed\");\n@@ -1689,6 +1743,7 @@\n-  \/\/ Might as well try to fill the cache for the flattened version, too.\n-  AliasCacheEntry* face = probe_alias_cache(flat);\n-  if (face->_adr_type == NULL) {\n-    face->_adr_type = flat;\n-    face->_index    = idx;\n-    assert(alias_type(flat) == alias_type(idx), \"flat type must work too\");\n+    \/\/ Might as well try to fill the cache for the flattened version, too.\n+    AliasCacheEntry* face = probe_alias_cache(flat);\n+    if (face->_adr_type == NULL) {\n+      face->_adr_type = flat;\n+      face->_index    = idx;\n+      assert(alias_type(flat) == alias_type(idx), \"flat type must work too\");\n+    }\n@@ -1862,0 +1917,377 @@\n+void Compile::add_inline_type(Node* n) {\n+  assert(n->is_InlineTypeBase(), \"unexpected node\");\n+  _inline_type_nodes.push(n);\n+}\n+\n+void Compile::remove_inline_type(Node* n) {\n+  assert(n->is_InlineTypeBase(), \"unexpected node\");\n+  if (_inline_type_nodes.contains(n)) {\n+    _inline_type_nodes.remove(n);\n+  }\n+}\n+\n+\/\/ Does the return value keep otherwise useless inline type allocations alive?\n+static bool return_val_keeps_allocations_alive(Node* ret_val) {\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(ret_val);\n+  bool some_allocations = false;\n+  for (uint i = 0; i < wq.size(); i++) {\n+    Node* n = wq.at(i);\n+    assert(!n->is_InlineType(), \"chain of inline type nodes\");\n+    if (n->outcnt() > 1) {\n+      \/\/ Some other use for the allocation\n+      return false;\n+    } else if (n->is_InlineTypePtr()) {\n+      wq.push(n->in(1));\n+    } else if (n->is_Phi()) {\n+      for (uint j = 1; j < n->req(); j++) {\n+        wq.push(n->in(j));\n+      }\n+    } else if (n->is_CheckCastPP() &&\n+               n->in(1)->is_Proj() &&\n+               n->in(1)->in(0)->is_Allocate()) {\n+      some_allocations = true;\n+    }\n+  }\n+  return some_allocations;\n+}\n+\n+void Compile::process_inline_types(PhaseIterGVN &igvn, bool remove) {\n+  \/\/ Make sure that the return value does not keep an otherwise unused allocation alive\n+  if (tf()->returns_inline_type_as_fields()) {\n+    Node* ret = NULL;\n+    for (uint i = 1; i < root()->req(); i++){\n+      Node* in = root()->in(i);\n+      if (in->Opcode() == Op_Return) {\n+        assert(ret == NULL, \"only one return\");\n+        ret = in;\n+      }\n+    }\n+    if (ret != NULL) {\n+      Node* ret_val = ret->in(TypeFunc::Parms);\n+      if (igvn.type(ret_val)->isa_oopptr() &&\n+          return_val_keeps_allocations_alive(ret_val)) {\n+        igvn.replace_input_of(ret, TypeFunc::Parms, InlineTypeNode::tagged_klass(igvn.type(ret_val)->inline_klass(), igvn));\n+        assert(ret_val->outcnt() == 0, \"should be dead now\");\n+        igvn.remove_dead_node(ret_val);\n+      }\n+    }\n+  }\n+  if (_inline_type_nodes.length() == 0) {\n+    return;\n+  }\n+  if (remove) {\n+    \/\/ Remove inline type nodes\n+    while (_inline_type_nodes.length() > 0) {\n+      InlineTypeBaseNode* vt = _inline_type_nodes.pop()->as_InlineTypeBase();\n+      if (vt->outcnt() == 0) {\n+        igvn.remove_dead_node(vt);\n+      } else if (vt->is_InlineTypePtr()) {\n+        igvn.replace_node(vt, vt->get_oop());\n+      } else {\n+#ifdef ASSERT\n+        for (DUIterator_Fast imax, i = vt->fast_outs(imax); i < imax; i++) {\n+          assert(vt->fast_out(i)->is_InlineTypeBase(), \"Unexpected inline type user\");\n+        }\n+#endif\n+        igvn.replace_node(vt, igvn.C->top());\n+      }\n+    }\n+  } else {\n+    \/\/ Give inline types a chance to be scalarized in safepoints\n+    \/\/ Delay this until all inlining is over to avoid getting inconsistent debug info\n+    set_scalarize_in_safepoints(true);\n+    for (int i = _inline_type_nodes.length()-1; i >= 0; i--) {\n+      igvn._worklist.push(_inline_type_nodes.at(i));\n+    }\n+  }\n+  igvn.optimize();\n+}\n+\n+void Compile::adjust_flattened_array_access_aliases(PhaseIterGVN& igvn) {\n+  if (!_has_flattened_accesses) {\n+    return;\n+  }\n+  \/\/ Initially, all flattened array accesses share the same slice to\n+  \/\/ keep dependencies with Object[] array accesses (that could be\n+  \/\/ to a flattened array) correct. We're done with parsing so we\n+  \/\/ now know all flattened array accesses in this compile\n+  \/\/ unit. Let's move flattened array accesses to their own slice,\n+  \/\/ one per element field. This should help memory access\n+  \/\/ optimizations.\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(root());\n+\n+  Node_List mergememnodes;\n+  Node_List memnodes;\n+\n+  \/\/ Alias index currently shared by all flattened memory accesses\n+  int index = get_alias_index(TypeAryPtr::INLINES);\n+\n+  \/\/ Find MergeMem nodes and flattened array accesses\n+  for (uint i = 0; i < wq.size(); i++) {\n+    Node* n = wq.at(i);\n+    if (n->is_Mem()) {\n+      const TypePtr* adr_type = NULL;\n+      if (n->Opcode() == Op_StoreCM) {\n+        adr_type = get_adr_type(get_alias_index(n->in(MemNode::OopStore)->adr_type()));\n+      } else {\n+        adr_type = get_adr_type(get_alias_index(n->adr_type()));\n+      }\n+      if (adr_type == TypeAryPtr::INLINES) {\n+        memnodes.push(n);\n+      }\n+    } else if (n->is_MergeMem()) {\n+      MergeMemNode* mm = n->as_MergeMem();\n+      if (mm->memory_at(index) != mm->base_memory()) {\n+        mergememnodes.push(n);\n+      }\n+    }\n+    for (uint j = 0; j < n->req(); j++) {\n+      Node* m = n->in(j);\n+      if (m != NULL) {\n+        wq.push(m);\n+      }\n+    }\n+  }\n+\n+  if (memnodes.size() > 0) {\n+    _flattened_accesses_share_alias = false;\n+\n+    \/\/ We are going to change the slice for the flattened array\n+    \/\/ accesses so we need to clear the cache entries that refer to\n+    \/\/ them.\n+    for (uint i = 0; i < AliasCacheSize; i++) {\n+      AliasCacheEntry* ace = &_alias_cache[i];\n+      if (ace->_adr_type != NULL &&\n+          ace->_adr_type->isa_aryptr() &&\n+          ace->_adr_type->is_aryptr()->is_flat()) {\n+        ace->_adr_type = NULL;\n+        ace->_index = (i != 0) ? 0 : AliasIdxTop; \/\/ Make sure the NULL adr_type resolves to AliasIdxTop\n+      }\n+    }\n+\n+    \/\/ Find what aliases we are going to add\n+    int start_alias = num_alias_types()-1;\n+    int stop_alias = 0;\n+\n+    for (uint i = 0; i < memnodes.size(); i++) {\n+      Node* m = memnodes.at(i);\n+      const TypePtr* adr_type = NULL;\n+      if (m->Opcode() == Op_StoreCM) {\n+        adr_type = m->in(MemNode::OopStore)->adr_type();\n+        if (adr_type != TypeAryPtr::INLINES) {\n+          \/\/ store was optimized out and we lost track of the adr_type\n+          Node* clone = new StoreCMNode(m->in(MemNode::Control), m->in(MemNode::Memory), m->in(MemNode::Address),\n+                                        m->adr_type(), m->in(MemNode::ValueIn), m->in(MemNode::OopStore),\n+                                        get_alias_index(adr_type));\n+          igvn.register_new_node_with_optimizer(clone);\n+          igvn.replace_node(m, clone);\n+        }\n+      } else {\n+        adr_type = m->adr_type();\n+#ifdef ASSERT\n+        m->as_Mem()->set_adr_type(adr_type);\n+#endif\n+      }\n+      int idx = get_alias_index(adr_type);\n+      start_alias = MIN2(start_alias, idx);\n+      stop_alias = MAX2(stop_alias, idx);\n+    }\n+\n+    assert(stop_alias >= start_alias, \"should have expanded aliases\");\n+\n+    Node_Stack stack(0);\n+#ifdef ASSERT\n+    VectorSet seen(Thread::current()->resource_area());\n+#endif\n+    \/\/ Now let's fix the memory graph so each flattened array access\n+    \/\/ is moved to the right slice. Start from the MergeMem nodes.\n+    uint last = unique();\n+    for (uint i = 0; i < mergememnodes.size(); i++) {\n+      MergeMemNode* current = mergememnodes.at(i)->as_MergeMem();\n+      Node* n = current->memory_at(index);\n+      MergeMemNode* mm = NULL;\n+      do {\n+        \/\/ Follow memory edges through memory accesses, phis and\n+        \/\/ narrow membars and push nodes on the stack. Once we hit\n+        \/\/ bottom memory, we pop element off the stack one at a\n+        \/\/ time, in reverse order, and move them to the right slice\n+        \/\/ by changing their memory edges.\n+        if ((n->is_Phi() && n->adr_type() != TypePtr::BOTTOM) || n->is_Mem() || n->adr_type() == TypeAryPtr::INLINES) {\n+          assert(!seen.test_set(n->_idx), \"\");\n+          \/\/ Uses (a load for instance) will need to be moved to the\n+          \/\/ right slice as well and will get a new memory state\n+          \/\/ that we don't know yet. The use could also be the\n+          \/\/ backedge of a loop. We put a place holder node between\n+          \/\/ the memory node and its uses. We replace that place\n+          \/\/ holder with the correct memory state once we know it,\n+          \/\/ i.e. when nodes are popped off the stack. Using the\n+          \/\/ place holder make the logic work in the presence of\n+          \/\/ loops.\n+          if (n->outcnt() > 1) {\n+            Node* place_holder = NULL;\n+            assert(!n->has_out_with(Op_Node), \"\");\n+            for (DUIterator k = n->outs(); n->has_out(k); k++) {\n+              Node* u = n->out(k);\n+              if (u != current && u->_idx < last) {\n+                bool success = false;\n+                for (uint l = 0; l < u->req(); l++) {\n+                  if (!stack.is_empty() && u == stack.node() && l == stack.index()) {\n+                    continue;\n+                  }\n+                  Node* in = u->in(l);\n+                  if (in == n) {\n+                    if (place_holder == NULL) {\n+                      place_holder = new Node(1);\n+                      place_holder->init_req(0, n);\n+                    }\n+                    igvn.replace_input_of(u, l, place_holder);\n+                    success = true;\n+                  }\n+                }\n+                if (success) {\n+                  --k;\n+                }\n+              }\n+            }\n+          }\n+          if (n->is_Phi()) {\n+            stack.push(n, 1);\n+            n = n->in(1);\n+          } else if (n->is_Mem()) {\n+            stack.push(n, n->req());\n+            n = n->in(MemNode::Memory);\n+          } else {\n+            assert(n->is_Proj() && n->in(0)->Opcode() == Op_MemBarCPUOrder, \"\");\n+            stack.push(n, n->req());\n+            n = n->in(0)->in(TypeFunc::Memory);\n+          }\n+        } else {\n+          assert(n->adr_type() == TypePtr::BOTTOM || (n->Opcode() == Op_Node && n->_idx >= last) || (n->is_Proj() && n->in(0)->is_Initialize()), \"\");\n+          \/\/ Build a new MergeMem node to carry the new memory state\n+          \/\/ as we build it. IGVN should fold extraneous MergeMem\n+          \/\/ nodes.\n+          mm = MergeMemNode::make(n);\n+          igvn.register_new_node_with_optimizer(mm);\n+          while (stack.size() > 0) {\n+            Node* m = stack.node();\n+            uint idx = stack.index();\n+            if (m->is_Mem()) {\n+              \/\/ Move memory node to its new slice\n+              const TypePtr* adr_type = m->adr_type();\n+              int alias = get_alias_index(adr_type);\n+              Node* prev = mm->memory_at(alias);\n+              igvn.replace_input_of(m, MemNode::Memory, prev);\n+              mm->set_memory_at(alias, m);\n+            } else if (m->is_Phi()) {\n+              \/\/ We need as many new phis as there are new aliases\n+              igvn.replace_input_of(m, idx, mm);\n+              if (idx == m->req()-1) {\n+                Node* r = m->in(0);\n+                for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+                  const Type* adr_type = get_adr_type(j);\n+                  if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat() || j == (uint)index) {\n+                    continue;\n+                  }\n+                  Node* phi = new PhiNode(r, Type::MEMORY, get_adr_type(j));\n+                  igvn.register_new_node_with_optimizer(phi);\n+                  for (uint k = 1; k < m->req(); k++) {\n+                    phi->init_req(k, m->in(k)->as_MergeMem()->memory_at(j));\n+                  }\n+                  mm->set_memory_at(j, phi);\n+                }\n+                Node* base_phi = new PhiNode(r, Type::MEMORY, TypePtr::BOTTOM);\n+                igvn.register_new_node_with_optimizer(base_phi);\n+                for (uint k = 1; k < m->req(); k++) {\n+                  base_phi->init_req(k, m->in(k)->as_MergeMem()->base_memory());\n+                }\n+                mm->set_base_memory(base_phi);\n+              }\n+            } else {\n+              \/\/ This is a MemBarCPUOrder node from\n+              \/\/ Parse::array_load()\/Parse::array_store(), in the\n+              \/\/ branch that handles flattened arrays hidden under\n+              \/\/ an Object[] array. We also need one new membar per\n+              \/\/ new alias to keep the unknown access that the\n+              \/\/ membars protect properly ordered with accesses to\n+              \/\/ known flattened array.\n+              assert(m->is_Proj(), \"projection expected\");\n+              Node* ctrl = m->in(0)->in(TypeFunc::Control);\n+              igvn.replace_input_of(m->in(0), TypeFunc::Control, top());\n+              for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+                const Type* adr_type = get_adr_type(j);\n+                if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat() || j == (uint)index) {\n+                  continue;\n+                }\n+                MemBarNode* mb = new MemBarCPUOrderNode(this, j, NULL);\n+                igvn.register_new_node_with_optimizer(mb);\n+                Node* mem = mm->memory_at(j);\n+                mb->init_req(TypeFunc::Control, ctrl);\n+                mb->init_req(TypeFunc::Memory, mem);\n+                ctrl = new ProjNode(mb, TypeFunc::Control);\n+                igvn.register_new_node_with_optimizer(ctrl);\n+                mem = new ProjNode(mb, TypeFunc::Memory);\n+                igvn.register_new_node_with_optimizer(mem);\n+                mm->set_memory_at(j, mem);\n+              }\n+              igvn.replace_node(m->in(0)->as_Multi()->proj_out(TypeFunc::Control), ctrl);\n+            }\n+            if (idx < m->req()-1) {\n+              idx += 1;\n+              stack.set_index(idx);\n+              n = m->in(idx);\n+              break;\n+            }\n+            \/\/ Take care of place holder nodes\n+            if (m->has_out_with(Op_Node)) {\n+              Node* place_holder = m->find_out_with(Op_Node);\n+              if (place_holder != NULL) {\n+                Node* mm_clone = mm->clone();\n+                igvn.register_new_node_with_optimizer(mm_clone);\n+                Node* hook = new Node(1);\n+                hook->init_req(0, mm);\n+                igvn.replace_node(place_holder, mm_clone);\n+                hook->destruct(&igvn);\n+              }\n+              assert(!m->has_out_with(Op_Node), \"place holder should be gone now\");\n+            }\n+            stack.pop();\n+          }\n+        }\n+      } while(stack.size() > 0);\n+      \/\/ Fix the memory state at the MergeMem we started from\n+      igvn.rehash_node_delayed(current);\n+      for (uint j = (uint)start_alias; j <= (uint)stop_alias; j++) {\n+        const Type* adr_type = get_adr_type(j);\n+        if (!adr_type->isa_aryptr() || !adr_type->is_aryptr()->is_flat()) {\n+          continue;\n+        }\n+        current->set_memory_at(j, mm);\n+      }\n+      current->set_memory_at(index, current->base_memory());\n+    }\n+    igvn.optimize();\n+  }\n+  print_method(PHASE_SPLIT_INLINES_ARRAY, 2);\n+#ifdef ASSERT\n+  if (!_flattened_accesses_share_alias) {\n+    wq.clear();\n+    wq.push(root());\n+    for (uint i = 0; i < wq.size(); i++) {\n+      Node* n = wq.at(i);\n+      assert(n->adr_type() != TypeAryPtr::INLINES, \"should have been removed from the graph\");\n+      for (uint j = 0; j < n->req(); j++) {\n+        Node* m = n->in(j);\n+        if (m != NULL) {\n+          wq.push(m);\n+        }\n+      }\n+    }\n+  }\n+#endif\n+}\n+\n+\n@@ -2207,0 +2639,5 @@\n+  \/\/ Process inline type nodes now that all inlining is over\n+  process_inline_types(igvn);\n+\n+  adjust_flattened_array_access_aliases(igvn);\n+\n@@ -2310,0 +2747,3 @@\n+  \/\/ Process inline type nodes again after loop opts\n+  process_inline_types(igvn);\n+\n@@ -2320,0 +2760,4 @@\n+  \/\/ Process inline type nodes again and remove them. From here\n+  \/\/ on we don't need to keep track of field values anymore.\n+  process_inline_types(igvn, \/* remove= *\/ true);\n+\n@@ -2918,0 +3362,1 @@\n+\n@@ -3071,1 +3516,16 @@\n-      n->add_prec(prec);\n+      if (prec->is_MergeMem()) {\n+        MergeMemNode* mm = prec->as_MergeMem();\n+        Node* base = mm->base_memory();\n+        for (int i = AliasIdxRaw + 1; i < num_alias_types(); i++) {\n+          const Type* adr_type = get_adr_type(i);\n+          if (adr_type->isa_aryptr() && adr_type->is_aryptr()->is_flat()) {\n+            Node* m = mm->memory_at(i);\n+            n->add_prec(m);\n+          }\n+        }\n+        if (mm->outcnt() == 0) {\n+          mm->disconnect_inputs(this);\n+        }\n+      } else {\n+        n->add_prec(prec);\n+      }\n@@ -3642,0 +4102,8 @@\n+#ifdef ASSERT\n+  case Op_InlineTypePtr:\n+  case Op_InlineType: {\n+    n->dump(-1);\n+    assert(false, \"inline type node was not removed\");\n+    break;\n+  }\n+#endif\n@@ -3989,2 +4457,2 @@\n-      if (accessing_method->is_static_initializer() ||\n-          accessing_method->is_object_initializer() ||\n+      if (accessing_method->is_class_initializer() ||\n+          accessing_method->is_object_constructor() ||\n@@ -3998,1 +4466,1 @@\n-      if (accessing_method->is_static_initializer()) {\n+      if (accessing_method->is_class_initializer()) {\n@@ -4119,1 +4587,1 @@\n-  if (StressReflectiveCode) {\n+  if (StressReflectiveCode || superk == NULL || subk == NULL) {\n@@ -4128,1 +4596,2 @@\n-  if (superelem->is_array_klass())\n+  if (superelem->is_array_klass()) {\n+    ciArrayKlass* ak = superelem->as_array_klass();\n@@ -4130,0 +4599,1 @@\n+  }\n@@ -4571,0 +5041,21 @@\n+Node* Compile::optimize_acmp(PhaseGVN* phase, Node* a, Node* b) {\n+  const TypeInstPtr* ta = phase->type(a)->isa_instptr();\n+  const TypeInstPtr* tb = phase->type(b)->isa_instptr();\n+  if (!EnableValhalla || ta == NULL || tb == NULL ||\n+      ta->is_zero_type() || tb->is_zero_type() ||\n+      !ta->can_be_inline_type() || !tb->can_be_inline_type()) {\n+    \/\/ Use old acmp if one operand is null or not an inline type\n+    return new CmpPNode(a, b);\n+  } else if (ta->is_inlinetypeptr() || tb->is_inlinetypeptr()) {\n+    \/\/ We know that one operand is an inline type. Therefore,\n+    \/\/ new acmp will only return true if both operands are NULL.\n+    \/\/ Check if both operands are null by or'ing the oops.\n+    a = phase->transform(new CastP2XNode(NULL, a));\n+    b = phase->transform(new CastP2XNode(NULL, b));\n+    a = phase->transform(new OrXNode(a, b));\n+    return new CmpXNode(a, phase->MakeConX(0));\n+  }\n+  \/\/ Use new acmp\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":544,"deletions":53,"binary":false,"changes":597,"status":"modified"},{"patch":"@@ -53,0 +53,1 @@\n+class CallNode;\n@@ -90,0 +91,1 @@\n+class InlineTypeBaseNode;\n@@ -306,0 +308,3 @@\n+  bool                  _has_flattened_accesses; \/\/ Any known flattened array accesses?\n+  bool                  _flattened_accesses_share_alias; \/\/ Initially all flattened array share a single slice\n+  bool                  _scalarize_in_safepoints; \/\/ Scalarize inline types in safepoint debug info\n@@ -321,0 +326,1 @@\n+  GrowableArray<Node*>  _inline_type_nodes;     \/\/ List of InlineType nodes\n@@ -597,0 +603,9 @@\n+  void          set_flattened_accesses()         { _has_flattened_accesses = true; }\n+  bool          flattened_accesses_share_alias() const { return _flattened_accesses_share_alias; }\n+  void          set_flattened_accesses_share_alias(bool z) { _flattened_accesses_share_alias = z; }\n+  bool          scalarize_in_safepoints() const { return _scalarize_in_safepoints; }\n+  void          set_scalarize_in_safepoints(bool z) { _scalarize_in_safepoints = z; }\n+\n+  \/\/ Support for scalarized inline type calling convention\n+  bool              has_scalarized_args() const  { return _method != NULL && _method->has_scalarized_args(); }\n+  bool              needs_stack_repair()  const  { return _method != NULL && _method->get_Method()->c2_needs_stack_repair(); }\n@@ -711,0 +726,7 @@\n+  \/\/ Keep track of inline type nodes for later processing\n+  void add_inline_type(Node* n);\n+  void remove_inline_type(Node* n);\n+  void process_inline_types(PhaseIterGVN &igvn, bool remove = false);\n+\n+  void adjust_flattened_array_access_aliases(PhaseIterGVN& igvn);\n+\n@@ -850,1 +872,1 @@\n-  AliasType*        alias_type(const TypePtr* adr_type, ciField* field = NULL) { return find_alias_type(adr_type, false, field); }\n+  AliasType*        alias_type(const TypePtr* adr_type, ciField* field = NULL, bool uncached = false) { return find_alias_type(adr_type, false, field, uncached); }\n@@ -854,1 +876,1 @@\n-  int               get_alias_index(const TypePtr* at)  { return alias_type(at)->index(); }\n+  int               get_alias_index(const TypePtr* at, bool uncached = false) { return alias_type(at, NULL, uncached)->index(); }\n@@ -1090,1 +1112,1 @@\n-  AliasType* find_alias_type(const TypePtr* adr_type, bool no_create, ciField* field);\n+  AliasType* find_alias_type(const TypePtr* adr_type, bool no_create, ciField* field, bool uncached = false);\n@@ -1163,1 +1185,3 @@\n-  \/\/ Auxiliary methods for randomized fuzzing\/stressing\n+  Node* optimize_acmp(PhaseGVN* phase, Node* a, Node* b);\n+\n+  \/\/ Auxiliary method for randomized fuzzing\/stressing\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":28,"deletions":4,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -560,1 +561,6 @@\n-    const TypeOopPtr* receiver_type = _gvn.type(receiver_node)->isa_oopptr();\n+    const TypeOopPtr* receiver_type = NULL;\n+    if (receiver_node->is_InlineType()) {\n+      receiver_type = TypeInstPtr::make(TypePtr::NotNull, _gvn.type(receiver_node)->inline_klass());\n+    } else {\n+      receiver_type = _gvn.type(receiver_node)->isa_oopptr();\n+    }\n@@ -576,1 +582,1 @@\n-  if (iter().cur_bc_raw() == Bytecodes::_invokespecial && !orig_callee->is_object_initializer()) {\n+  if (iter().cur_bc_raw() == Bytecodes::_invokespecial && !orig_callee->is_object_constructor()) {\n@@ -647,1 +653,1 @@\n-  if (receiver != NULL && !call_does_dispatch && !cg->is_string_late_inline()) {\n+  if (receiver != NULL && !receiver->is_InlineType() && !call_does_dispatch && !cg->is_string_late_inline()) {\n@@ -711,1 +717,1 @@\n-          \/\/ It's OK for a method  to return a value that is discarded.\n+          \/\/ It's OK for a method to return a value that is discarded.\n@@ -723,1 +729,4 @@\n-            if (arg_type != NULL && !arg_type->higher_equal(sig_type)) {\n+            if (ct == T_INLINE_TYPE) {\n+              sig_type = sig_type->join_speculative(TypePtr::NOTNULL);\n+            }\n+            if (arg_type != NULL && !arg_type->higher_equal(sig_type) && !peek()->is_InlineType()) {\n@@ -749,0 +758,9 @@\n+    if (rtype->basic_type() == T_INLINE_TYPE && !peek()->is_InlineType()) {\n+      Node* retnode = pop();\n+      assert(!gvn().type(retnode)->maybe_null(), \"should never be null\");\n+      if (rtype->as_inline_klass()->is_scalarizable()) {\n+        retnode = InlineTypeNode::make_from_oop(this, retnode, rtype->as_inline_klass());\n+      }\n+      push_node(T_INLINE_TYPE, retnode);\n+    }\n+\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":23,"deletions":5,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"memory\/metaspace.hpp\"\n@@ -147,0 +148,10 @@\n+    if ((n->Opcode() == Op_LoadX || n->Opcode() == Op_StoreX) &&\n+        !n->in(MemNode::Address)->is_AddP() &&\n+        _igvn->type(n->in(MemNode::Address))->isa_oopptr()) {\n+      \/\/ Load\/Store at mark work address is at offset 0 so has no AddP which confuses EA\n+      Node* addp = new AddPNode(n->in(MemNode::Address), n->in(MemNode::Address), _igvn->MakeConX(0));\n+      _igvn->register_new_node_with_optimizer(addp);\n+      _igvn->replace_input_of(n, MemNode::Address, addp);\n+      ideal_nodes.push(addp);\n+      _nodes.at_put_grow(addp->_idx, NULL, NULL);\n+    }\n@@ -392,1 +403,1 @@\n-      const TypeTuple* d = call->tf()->domain();\n+      const TypeTuple* d = call->tf()->domain_sig();\n@@ -466,0 +477,11 @@\n+      } else if (n->as_Call()->tf()->returns_inline_type_as_fields()) {\n+        bool returns_oop = false;\n+        for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax && !returns_oop; i++) {\n+          ProjNode* pn = n->fast_out(i)->as_Proj();\n+          if (pn->_con >= TypeFunc::Parms && pn->bottom_type()->isa_ptr()) {\n+            returns_oop = true;\n+          }\n+        }\n+        if (returns_oop) {\n+          add_call_node(n->as_Call());\n+        }\n@@ -497,0 +519,1 @@\n+    case Op_InlineTypePtr:\n@@ -569,2 +592,4 @@\n-      if (n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->is_Call() &&\n-          n->in(0)->as_Call()->returns_pointer()) {\n+      if (n->as_Proj()->_con >= TypeFunc::Parms && n->in(0)->is_Call() &&\n+          (n->in(0)->as_Call()->returns_pointer() || n->bottom_type()->isa_ptr())) {\n+        assert((n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->as_Call()->returns_pointer()) ||\n+               n->in(0)->as_Call()->tf()->returns_inline_type_as_fields(), \"what kind of oop return is it?\");\n@@ -666,0 +691,1 @@\n+    case Op_InlineTypePtr:\n@@ -729,2 +755,4 @@\n-      if (n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->is_Call() &&\n-          n->in(0)->as_Call()->returns_pointer()) {\n+      if (n->as_Proj()->_con >= TypeFunc::Parms && n->in(0)->is_Call() &&\n+          (n->in(0)->as_Call()->returns_pointer()|| n->bottom_type()->isa_ptr())) {\n+        assert((n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->as_Call()->returns_pointer()) ||\n+               n->in(0)->as_Call()->tf()->returns_inline_type_as_fields(), \"what kind of oop return is it?\");\n@@ -890,1 +918,1 @@\n-  assert(call->returns_pointer(), \"only for call which returns pointer\");\n+  assert(call->returns_pointer() || call->tf()->returns_inline_type_as_fields(), \"only for call which returns pointer\");\n@@ -983,1 +1011,1 @@\n-        const TypeTuple* d = call->tf()->domain();\n+        const TypeTuple* d = call->tf()->domain_cc();\n@@ -1030,1 +1058,1 @@\n-      const TypeTuple * d = call->tf()->domain();\n+      const TypeTuple * d = call->tf()->domain_sig();\n@@ -1061,1 +1089,4 @@\n-                               (aat->isa_aryptr() && aat->isa_aryptr()->klass()->is_obj_array_klass()));\n+                               (aat->isa_aryptr() && aat->isa_aryptr()->klass()->is_obj_array_klass()) ||\n+                               (aat->isa_aryptr() && aat->isa_aryptr()->elem() != NULL &&\n+                                aat->isa_aryptr()->is_flat() &&\n+                                aat->isa_aryptr()->elem()->inline_klass()->contains_oops()));\n@@ -1107,0 +1138,3 @@\n+                  strcmp(call->as_CallLeaf()->_name, \"vectorizedMismatch\") == 0 ||\n+                  strcmp(call->as_CallLeaf()->_name, \"load_unknown_inline\") == 0 ||\n+                  strcmp(call->as_CallLeaf()->_name, \"store_unknown_inline\") == 0 ||\n@@ -1168,1 +1202,1 @@\n-        const TypeTuple* d = call->tf()->domain();\n+        const TypeTuple* d = call->tf()->domain_cc();\n@@ -1212,1 +1246,1 @@\n-      const TypeTuple* d = call->tf()->domain();\n+      const TypeTuple* d = call->tf()->domain_cc();\n@@ -1631,0 +1665,1 @@\n+  PointsToNode* init_val = phantom_obj;\n@@ -1636,1 +1671,8 @@\n-    return 0;\n+    if (alloc->as_Allocate()->in(AllocateNode::DefaultValue) != NULL) {\n+      \/\/ Non-flattened inline type arrays are initialized with\n+      \/\/ the default value instead of null. Handle them here.\n+      init_val = ptnode_adr(alloc->as_Allocate()->in(AllocateNode::DefaultValue)->_idx);\n+      assert(init_val != NULL, \"default value should be registered\");\n+    } else {\n+      return 0;\n+    }\n@@ -1638,1 +1680,2 @@\n-  assert(pta->arraycopy_dst() || alloc->as_CallStaticJava(), \"sanity\");\n+  \/\/ Non-escaped allocation returned from Java or runtime call has unknown values in fields.\n+  assert(pta->arraycopy_dst() || alloc->is_CallStaticJava() || init_val != phantom_obj, \"sanity\");\n@@ -1640,1 +1683,1 @@\n-  if (!pta->arraycopy_dst() && alloc->as_CallStaticJava()->method() == NULL) {\n+  if (alloc->is_CallStaticJava() && alloc->as_CallStaticJava()->method() == NULL) {\n@@ -1650,1 +1693,1 @@\n-      if (add_edge(field, phantom_obj)) {\n+      if (add_edge(field, init_val)) {\n@@ -1665,1 +1708,1 @@\n-  if (!alloc->is_Allocate()) {\n+  if (!alloc->is_Allocate() || alloc->as_Allocate()->in(AllocateNode::DefaultValue) != NULL) {\n@@ -1751,1 +1794,1 @@\n-                tty->print_cr(\"----------missed referernce to object-----------\");\n+                tty->print_cr(\"----------missed reference to object------------\");\n@@ -1753,1 +1796,1 @@\n-                tty->print_cr(\"----------object referernced by init store -----\");\n+                tty->print_cr(\"----------object referenced by init store-------\");\n@@ -1822,1 +1865,1 @@\n-         ptn->set_scalar_replaceable(false);\n+        ptn->set_scalar_replaceable(false);\n@@ -1985,1 +2028,3 @@\n-          if (not_global_escape(alock->obj_node())) {\n+          const Type* obj_type = igvn->type(alock->obj_node());\n+          if (not_global_escape(alock->obj_node()) &&\n+              !obj_type->isa_inlinetype() && !obj_type->is_inlinetypeptr()) {\n@@ -2183,0 +2228,1 @@\n+  int field_offset = adr_type->isa_aryptr() ? adr_type->isa_aryptr()->field_offset().get() : Type::OffsetBot;\n@@ -2184,1 +2230,1 @@\n-  if (offset == Type::OffsetBot) {\n+  if (offset == Type::OffsetBot && field_offset == Type::OffsetBot) {\n@@ -2196,1 +2242,1 @@\n-      ciField* field = _compile->alias_type(adr_type->isa_instptr())->field();\n+      ciField* field = _compile->alias_type(adr_type->is_ptr())->field();\n@@ -2216,1 +2262,7 @@\n-        bt = elemtype->array_element_basic_type();\n+        if (elemtype->isa_inlinetype() && field_offset != Type::OffsetBot) {\n+          ciInlineKlass* vk = elemtype->inline_klass();\n+          field_offset += vk->first_field_offset();\n+          bt = vk->get_field_by_offset(field_offset, false)->layout_type();\n+        } else {\n+          bt = elemtype->array_element_basic_type();\n+        }\n@@ -2400,3 +2452,1 @@\n-  const TypePtr *t_ptr = adr_type->isa_ptr();\n-  assert(t_ptr != NULL, \"must be a pointer type\");\n-  return t_ptr->offset();\n+  return adr_type->is_ptr()->flattened_offset();\n@@ -2556,1 +2606,8 @@\n-    t = base_t->add_offset(offs)->is_oopptr();\n+    if (base_t->isa_aryptr() != NULL) {\n+      \/\/ In the case of a flattened inline type array, each field has its\n+      \/\/ own slice so we need to extract the field being accessed from\n+      \/\/ the address computation\n+      t = base_t->isa_aryptr()->add_field_offset_and_offset(offs)->is_oopptr();\n+    } else {\n+      t = base_t->add_offset(offs)->is_oopptr();\n+    }\n@@ -2558,1 +2615,1 @@\n-  int inst_id =  base_t->instance_id();\n+  int inst_id = base_t->instance_id();\n@@ -2572,1 +2629,1 @@\n-  \/\/ It could happened when CHA type is different from MDO type on a dead path\n+  \/\/ It could happen when CHA type is different from MDO type on a dead path\n@@ -2582,1 +2639,12 @@\n-  const TypeOopPtr *tinst = base_t->add_offset(t->offset())->is_oopptr();\n+  const TypePtr* tinst = base_t->add_offset(t->offset());\n+  if (tinst->isa_aryptr() && t->isa_aryptr()) {\n+    \/\/ In the case of a flattened inline type array, each field has its\n+    \/\/ own slice so we need to keep track of the field being accessed.\n+    tinst = tinst->is_aryptr()->with_field_offset(t->is_aryptr()->field_offset().get());\n+    \/\/ Keep array properties (not flat\/null-free)\n+    tinst = tinst->is_aryptr()->update_properties(t->is_aryptr());\n+    if (tinst == NULL) {\n+      return false; \/\/ Skip dead path with inconsistent properties\n+    }\n+  }\n+\n@@ -3262,0 +3330,7 @@\n+          if (tn_t->isa_aryptr()) {\n+            \/\/ Keep array properties (not flat\/null-free)\n+            tinst = tinst->is_aryptr()->update_properties(tn_t->is_aryptr());\n+            if (tinst == NULL) {\n+              continue; \/\/ Skip dead path with inconsistent properties\n+            }\n+          }\n@@ -3287,1 +3362,1 @@\n-      if(use->is_Mem() && use->in(MemNode::Address) == n) {\n+      if (use->is_Mem() && use->in(MemNode::Address) == n) {\n@@ -3323,0 +3398,3 @@\n+      } else if (use->Opcode() == Op_Return) {\n+        \/\/ Allocation is referenced by field of returned inline type\n+        assert(_compile->tf()->returns_inline_type_as_fields(), \"EA: unexpected reference by ReturnNode\");\n@@ -3334,1 +3412,1 @@\n-              op == Op_SubTypeCheck ||\n+              op == Op_SubTypeCheck || op == Op_InlineType || op == Op_InlineTypePtr || op == Op_FlatArrayCheck ||\n@@ -3404,0 +3482,3 @@\n+    } else if (n->is_CallLeaf() && n->as_CallLeaf()->_name != NULL &&\n+               strcmp(n->as_CallLeaf()->_name, \"store_unknown_inline\") == 0) {\n+      n = n->as_CallLeaf()->proj_out(TypeFunc::Memory);\n@@ -3446,1 +3527,1 @@\n-      } else if(use->is_Mem()) {\n+      } else if (use->is_Mem()) {\n@@ -3455,0 +3536,4 @@\n+      } else if (use->is_CallLeaf() && use->as_CallLeaf()->_name != NULL &&\n+                 strcmp(use->as_CallLeaf()->_name, \"store_unknown_inline\") == 0) {\n+        \/\/ store_unknown_inline overwrites destination array\n+        memnode_worklist.append_if_missing(use);\n@@ -3464,1 +3549,1 @@\n-              op == Op_StrEquals || op == Op_StrIndexOf || op == Op_StrIndexOfChar)) {\n+              op == Op_StrEquals || op == Op_StrIndexOf || op == Op_StrIndexOfChar || op == Op_FlatArrayCheck)) {\n@@ -3476,1 +3561,1 @@\n-  \/\/            instance type to the the input corresponding to its alias index.\n+  \/\/            instance type to the input corresponding to its alias index.\n@@ -3551,1 +3636,1 @@\n-  \/\/ chains as is done in split_memory_phi() since they  will\n+  \/\/ chains as is done in split_memory_phi() since they will\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":121,"deletions":36,"binary":false,"changes":157,"status":"modified"},{"patch":"@@ -26,0 +26,2 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -41,0 +43,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -44,0 +47,1 @@\n+#include \"opto\/narrowptrnode.hpp\"\n@@ -57,1 +61,1 @@\n-GraphKit::GraphKit(JVMState* jvms)\n+GraphKit::GraphKit(JVMState* jvms, PhaseGVN* gvn)\n@@ -60,1 +64,1 @@\n-    _gvn(*C->initial_gvn()),\n+    _gvn((gvn != NULL) ? *gvn : *C->initial_gvn()),\n@@ -63,0 +67,1 @@\n+  assert(gvn == NULL || !gvn->is_IterGVN() || gvn->is_IterGVN()->delay_transform(), \"delay transform should be enabled\");\n@@ -66,0 +71,7 @@\n+#ifdef ASSERT\n+  if (_gvn.is_IterGVN() != NULL) {\n+    assert(_gvn.is_IterGVN()->delay_transform(), \"Transformation must be delayed if IterGVN is used\");\n+    \/\/ Save the initial size of _for_igvn worklist for verification (see ~GraphKit)\n+    _worklist_size = _gvn.C->for_igvn()->size();\n+  }\n+#endif\n@@ -833,1 +845,1 @@\n-           (is_anewarray && code == Bytecodes::_multianewarray);\n+           (is_anewarray && (code == Bytecodes::_multianewarray));\n@@ -1093,0 +1105,9 @@\n+  case Bytecodes::_withfield: {\n+    bool ignored_will_link;\n+    ciField* field = method()->get_field_at_bci(bci(), ignored_will_link);\n+    int      size  = field->type()->size();\n+    inputs = size+1;\n+    depth = rsize - inputs;\n+    break;\n+  }\n+\n@@ -1175,1 +1196,1 @@\n-  return _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS));\n+  return _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n@@ -1218,0 +1239,1 @@\n+    case T_INLINE_TYPE : \/\/ fall through\n@@ -1389,0 +1411,16 @@\n+Node* GraphKit::null2default(Node* value, ciInlineKlass* vk) {\n+  assert(!vk->is_scalarizable(), \"Should only be used for non scalarizable inline klasses\");\n+  Node* null_ctl = top();\n+  value = null_check_oop(value, &null_ctl);\n+  if (!null_ctl->is_top()) {\n+    \/\/ Return default value if oop is null\n+    Node* region = new RegionNode(3);\n+    region->init_req(1, control());\n+    region->init_req(2, null_ctl);\n+    value = PhiNode::make(region, value, TypeInstPtr::make(TypePtr::BotPTR, vk));\n+    value->set_req(2, InlineTypeNode::default_oop(gvn(), vk));\n+    set_control(gvn().transform(region));\n+    value = gvn().transform(value);\n+  }\n+  return value;\n+}\n@@ -1393,0 +1431,3 @@\n+  if (obj->is_InlineType()) {\n+    return obj;\n+  }\n@@ -1402,0 +1443,5 @@\n+  if (t->is_inlinetypeptr() && t->inline_klass()->is_scalarizable()) {\n+    \/\/ Scalarize inline type now that we know it's non-null\n+    cast = InlineTypeNode::make_from_oop(this, cast, t->inline_klass())->as_ptr(&gvn());\n+  }\n+\n@@ -1526,1 +1572,2 @@\n-  if (((bt == T_OBJECT) && C->do_escape_analysis()) || C->eliminate_boxing()) {\n+\n+  if (((bt == T_OBJECT || bt == T_INLINE_TYPE) && C->do_escape_analysis()) || C->eliminate_boxing()) {\n@@ -1577,1 +1624,2 @@\n-                                DecoratorSet decorators) {\n+                                DecoratorSet decorators,\n+                                bool safe_for_replace) {\n@@ -1590,0 +1638,7 @@\n+  if (val->is_InlineType()) {\n+    \/\/ Store to non-flattened field. Buffer the inline type and make sure\n+    \/\/ the store is re-executed if the allocation triggers deoptimization.\n+    PreserveReexecuteState preexecs(this);\n+    jvms()->set_should_reexecute(true);\n+    val = val->as_InlineType()->buffer(this, safe_for_replace);\n+  }\n@@ -1606,1 +1661,2 @@\n-                               DecoratorSet decorators) {\n+                               DecoratorSet decorators,\n+                               Node* ctl) {\n@@ -1612,1 +1668,1 @@\n-  C2ParseAccess access(this, decorators | C2_READ_ACCESS, bt, obj, addr);\n+  C2ParseAccess access(this, decorators | C2_READ_ACCESS, bt, obj, addr, ctl);\n@@ -1710,2 +1766,2 @@\n-void GraphKit::access_clone(Node* src, Node* dst, Node* size, bool is_array) {\n-  return _barrier_set->clone(this, src, dst, size, is_array);\n+void GraphKit::access_clone(Node* src_base, Node* dst_base, Node* countx, bool is_array) {\n+  return _barrier_set->clone(this, src_base, dst_base, countx, is_array);\n@@ -1718,0 +1774,5 @@\n+  ciKlass* arytype_klass = _gvn.type(ary)->is_aryptr()->klass();\n+  if (arytype_klass != NULL && arytype_klass->is_flat_array_klass()) {\n+    ciFlatArrayKlass* vak = arytype_klass->as_flat_array_klass();\n+    shift = vak->log2_element_size();\n+  }\n@@ -1738,0 +1799,1 @@\n+  assert(elembt != T_INLINE_TYPE, \"inline types are not supported by this method\");\n@@ -1748,6 +1810,32 @@\n-void GraphKit::set_arguments_for_java_call(CallJavaNode* call) {\n-  \/\/ Add the call arguments:\n-  uint nargs = call->method()->arg_size();\n-  for (uint i = 0; i < nargs; i++) {\n-    Node* arg = argument(i);\n-    call->init_req(i + TypeFunc::Parms, arg);\n+void GraphKit::set_arguments_for_java_call(CallJavaNode* call, bool is_late_inline) {\n+  PreserveReexecuteState preexecs(this);\n+  if (EnableValhalla) {\n+    \/\/ Make sure the call is \"re-executed\", if buffering of inline type arguments triggers deoptimization.\n+    \/\/ At this point, the call hasn't been executed yet, so we will only ever execute the call once.\n+    jvms()->set_should_reexecute(true);\n+    int arg_size = method()->get_declared_signature_at_bci(bci())->arg_size_for_bc(java_bc());\n+    inc_sp(arg_size);\n+  }\n+  \/\/ Add the call arguments\n+  const TypeTuple* domain = call->tf()->domain_sig();\n+  uint nargs = domain->cnt();\n+  for (uint i = TypeFunc::Parms, idx = TypeFunc::Parms; i < nargs; i++) {\n+    Node* arg = argument(i-TypeFunc::Parms);\n+    const Type* t = domain->field_at(i);\n+    if (call->method()->has_scalarized_args() && t->is_inlinetypeptr() && !t->maybe_null() && t->inline_klass()->can_be_passed_as_fields()) {\n+      \/\/ We don't pass inline type arguments by reference but instead pass each field of the inline type\n+      InlineTypeNode* vt = arg->as_InlineType();\n+      vt->pass_fields(this, call, idx);\n+      \/\/ If an inline type argument is passed as fields, attach the Method* to the call site\n+      \/\/ to be able to access the extended signature later via attached_method_before_pc().\n+      \/\/ For example, see CompiledMethod::preserve_callee_argument_oops().\n+      call->set_override_symbolic_info(true);\n+      continue;\n+    } else if (arg->is_InlineType()) {\n+      \/\/ Pass inline type argument via oop to callee\n+      arg = arg->as_InlineType()->buffer(this);\n+      if (!is_late_inline) {\n+        arg = arg->as_InlineTypePtr()->get_oop();\n+      }\n+    }\n+    call->init_req(idx++, arg);\n@@ -1791,7 +1879,0 @@\n-  \/\/ Capture the return value, if any.\n-  Node* ret;\n-  if (call->method() == NULL ||\n-      call->method()->return_type()->basic_type() == T_VOID)\n-        ret = top();\n-  else  ret = _gvn.transform(new ProjNode(call, TypeFunc::Parms));\n-\n@@ -1810,0 +1891,15 @@\n+\n+  \/\/ Capture the return value, if any.\n+  Node* ret;\n+  if (call->method() == NULL || call->method()->return_type()->basic_type() == T_VOID) {\n+    ret = top();\n+  } else if (call->tf()->returns_inline_type_as_fields()) {\n+    \/\/ Return of multiple values (inline type fields): we create a\n+    \/\/ InlineType node, each field is a projection from the call.\n+    ciInlineKlass* vk = call->method()->return_type()->as_inline_klass();\n+    uint base_input = TypeFunc::Parms;\n+    ret = InlineTypeNode::make_from_multi(this, call, vk, base_input, false);\n+  } else {\n+    ret = _gvn.transform(new ProjNode(call, TypeFunc::Parms));\n+  }\n+\n@@ -1900,2 +1996,1 @@\n-  CallProjections callprojs;\n-  call->extract_projections(&callprojs, true);\n+  CallProjections* callprojs = call->extract_projections(true);\n@@ -1910,2 +2005,2 @@\n-  if (callprojs.fallthrough_catchproj != NULL) {\n-    C->gvn_replace_by(callprojs.fallthrough_catchproj, final_ctl);\n+  if (callprojs->fallthrough_catchproj != NULL) {\n+    C->gvn_replace_by(callprojs->fallthrough_catchproj, final_ctl);\n@@ -1913,1 +2008,1 @@\n-  if (callprojs.fallthrough_memproj != NULL) {\n+  if (callprojs->fallthrough_memproj != NULL) {\n@@ -1918,1 +2013,1 @@\n-    C->gvn_replace_by(callprojs.fallthrough_memproj,   final_mem);\n+    C->gvn_replace_by(callprojs->fallthrough_memproj,   final_mem);\n@@ -1921,2 +2016,2 @@\n-  if (callprojs.fallthrough_ioproj != NULL) {\n-    C->gvn_replace_by(callprojs.fallthrough_ioproj,    final_io);\n+  if (callprojs->fallthrough_ioproj != NULL) {\n+    C->gvn_replace_by(callprojs->fallthrough_ioproj,    final_io);\n@@ -1926,2 +2021,6 @@\n-  if (callprojs.resproj != NULL && result != NULL) {\n-    C->gvn_replace_by(callprojs.resproj, result);\n+  if (callprojs->resproj[0] != NULL && result != NULL) {\n+    \/\/ If the inlined code is dead, the result projections for an inline type returned as\n+    \/\/ fields have not been replaced. They will go away once the call is replaced by TOP below.\n+    assert(callprojs->nb_resproj == 1 || (call->tf()->returns_inline_type_as_fields() && stopped()),\n+           \"unexpected number of results\");\n+    C->gvn_replace_by(callprojs->resproj[0], result);\n@@ -1932,2 +2031,2 @@\n-    if (callprojs.catchall_catchproj != NULL) {\n-      C->gvn_replace_by(callprojs.catchall_catchproj, C->top());\n+    if (callprojs->catchall_catchproj != NULL) {\n+      C->gvn_replace_by(callprojs->catchall_catchproj, C->top());\n@@ -1935,2 +2034,2 @@\n-    if (callprojs.catchall_memproj != NULL) {\n-      C->gvn_replace_by(callprojs.catchall_memproj,   C->top());\n+    if (callprojs->catchall_memproj != NULL) {\n+      C->gvn_replace_by(callprojs->catchall_memproj,   C->top());\n@@ -1938,2 +2037,2 @@\n-    if (callprojs.catchall_ioproj != NULL) {\n-      C->gvn_replace_by(callprojs.catchall_ioproj,    C->top());\n+    if (callprojs->catchall_ioproj != NULL) {\n+      C->gvn_replace_by(callprojs->catchall_ioproj,    C->top());\n@@ -1942,2 +2041,2 @@\n-    if (callprojs.exobj != NULL) {\n-      C->gvn_replace_by(callprojs.exobj, C->top());\n+    if (callprojs->exobj != NULL) {\n+      C->gvn_replace_by(callprojs->exobj, C->top());\n@@ -1954,2 +2053,2 @@\n-    if (callprojs.catchall_catchproj != NULL) {\n-      C->gvn_replace_by(callprojs.catchall_catchproj, ekit.control());\n+    if (callprojs->catchall_catchproj != NULL) {\n+      C->gvn_replace_by(callprojs->catchall_catchproj, ekit.control());\n@@ -1958,1 +2057,1 @@\n-    if (callprojs.catchall_memproj != NULL) {\n+    if (callprojs->catchall_memproj != NULL) {\n@@ -1960,1 +2059,1 @@\n-      C->gvn_replace_by(callprojs.catchall_memproj,   ex_mem);\n+      C->gvn_replace_by(callprojs->catchall_memproj,   ex_mem);\n@@ -1963,2 +2062,2 @@\n-    if (callprojs.catchall_ioproj != NULL) {\n-      C->gvn_replace_by(callprojs.catchall_ioproj,    ekit.i_o());\n+    if (callprojs->catchall_ioproj != NULL) {\n+      C->gvn_replace_by(callprojs->catchall_ioproj,    ekit.i_o());\n@@ -1968,2 +2067,2 @@\n-    if (callprojs.exobj != NULL) {\n-      C->gvn_replace_by(callprojs.exobj, ex_oop);\n+    if (callprojs->exobj != NULL) {\n+      C->gvn_replace_by(callprojs->exobj, ex_oop);\n@@ -1983,1 +2082,1 @@\n-  if (callprojs.fallthrough_catchproj != NULL && !final_ctl->is_top() && do_replaced_nodes) {\n+  if (callprojs->fallthrough_catchproj != NULL && !final_ctl->is_top() && do_replaced_nodes) {\n@@ -2181,1 +2280,1 @@\n-    const TypePtr* ptr = (ptr_kind == ProfileMaybeNull && current_type->speculative_maybe_null()) ? TypePtr::BOTTOM : TypePtr::NOTNULL;\n+    const TypePtr* ptr = (ptr_kind != ProfileNeverNull && current_type->speculative_maybe_null()) ? TypePtr::BOTTOM : TypePtr::NOTNULL;\n@@ -2204,1 +2303,1 @@\n-    const TypeOopPtr* spec_type = TypeOopPtr::make(TypePtr::BotPTR, Type::OffsetBot, TypeOopPtr::InstanceBot, speculative);\n+    const TypeOopPtr* spec_type = TypeOopPtr::make(TypePtr::BotPTR, Type::Offset::bottom, TypeOopPtr::InstanceBot, speculative);\n@@ -2238,2 +2337,9 @@\n-      if (!data->as_BitData()->null_seen()) {\n-        ptr_kind = ProfileNeverNull;\n+      if (java_bc() == Bytecodes::_aastore) {\n+        ciKlass* array_type = NULL;\n+        ciKlass* element_type = NULL;\n+        ProfilePtrKind element_ptr = ProfileMaybeNull;\n+        bool flat_array = true;\n+        bool null_free_array = true;\n+        method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n+        exact_kls = element_type;\n+        ptr_kind = element_ptr;\n@@ -2241,7 +2347,11 @@\n-        assert(data->is_ReceiverTypeData(), \"bad profile data type\");\n-        ciReceiverTypeData* call = (ciReceiverTypeData*)data->as_ReceiverTypeData();\n-        uint i = 0;\n-        for (; i < call->row_limit(); i++) {\n-          ciKlass* receiver = call->receiver(i);\n-          if (receiver != NULL) {\n-            break;\n+        if (!data->as_BitData()->null_seen()) {\n+          ptr_kind = ProfileNeverNull;\n+        } else {\n+          assert(data->is_ReceiverTypeData(), \"bad profile data type\");\n+          ciReceiverTypeData* call = (ciReceiverTypeData*)data->as_ReceiverTypeData();\n+          uint i = 0;\n+          for (; i < call->row_limit(); i++) {\n+            ciKlass* receiver = call->receiver(i);\n+            if (receiver != NULL) {\n+              break;\n+            }\n@@ -2249,0 +2359,1 @@\n+          ptr_kind = (i == call->row_limit()) ? ProfileAlwaysNull : ProfileMaybeNull;\n@@ -2250,1 +2361,0 @@\n-        ptr_kind = (i == call->row_limit()) ? ProfileAlwaysNull : ProfileMaybeNull;\n@@ -2269,1 +2379,1 @@\n-  int             nargs = tf->domain()->cnt() - TypeFunc::Parms;\n+  int             nargs = tf->domain_sig()->cnt() - TypeFunc::Parms;\n@@ -2272,1 +2382,1 @@\n-    const Type *targ = tf->domain()->field_at(j + TypeFunc::Parms);\n+    const Type *targ = tf->domain_sig()->field_at(j + TypeFunc::Parms);\n@@ -2343,1 +2453,1 @@\n-    int             nargs = tf->domain()->cnt() - TypeFunc::Parms;\n+    int             nargs = tf->domain_sig()->cnt() - TypeFunc::Parms;\n@@ -2345,1 +2455,1 @@\n-      const Type *targ = tf->domain()->field_at(j + TypeFunc::Parms);\n+      const Type *targ = tf->domain_sig()->field_at(j + TypeFunc::Parms);\n@@ -2599,1 +2709,1 @@\n-      const Type* type = call_type->domain()->field_at(TypeFunc::Parms + vm_unfiltered_arg_pos);\n+      const Type* type = call_type->domain_sig()->field_at(TypeFunc::Parms + vm_unfiltered_arg_pos);\n@@ -2610,1 +2720,1 @@\n-  uint n_returns = call_type->range()->cnt() - TypeFunc::Parms;\n+  uint n_returns = call_type->range_sig()->cnt() - TypeFunc::Parms;\n@@ -2618,1 +2728,1 @@\n-      const Type* type = call_type->range()->field_at(TypeFunc::Parms + vm_ret_pos);\n+      const Type* type = call_type->range_sig()->field_at(TypeFunc::Parms + vm_ret_pos);\n@@ -2946,0 +3056,4 @@\n+  const Type* sub_t = _gvn.type(obj_or_subklass);\n+  if (sub_t->isa_inlinetype()) {\n+    obj_or_subklass = makecon(TypeKlassPtr::make(sub_t->inline_klass()));\n+  }\n@@ -2950,1 +3064,1 @@\n-    if (!_gvn.type(obj_or_subklass)->isa_klassptr()) {\n+    if (!sub_t->isa_klassptr() && !sub_t->isa_inlinetype()) {\n@@ -2953,1 +3067,0 @@\n-\n@@ -2959,1 +3072,0 @@\n-  const TypePtr* adr_type = TypeKlassPtr::make(TypePtr::NotNull, C->env()->Object_klass(), Type::OffsetBot);\n@@ -2969,2 +3081,13 @@\n-                                    float prob,\n-                                    Node* *casted_receiver) {\n+                                    float prob, Node* *casted_receiver) {\n+  Node* fail = top();\n+  const Type* rec_t = _gvn.type(receiver);\n+  if (rec_t->isa_inlinetype()) {\n+    if (klass->equals(rec_t->inline_klass())) {\n+      (*casted_receiver) = receiver; \/\/ Always passes\n+    } else {\n+      (*casted_receiver) = top();    \/\/ Always fails\n+      fail = control();\n+      set_control(top());\n+    }\n+    return fail;\n+  }\n@@ -2973,7 +3096,1 @@\n-  Node* want_klass = makecon(tklass);\n-  Node* cmp = _gvn.transform( new CmpPNode(recv_klass, want_klass) );\n-  Node* bol = _gvn.transform( new BoolNode(cmp, BoolTest::eq) );\n-  IfNode* iff = create_and_xform_if(control(), bol, prob, COUNT_UNKNOWN);\n-  set_control( _gvn.transform( new IfTrueNode (iff) ));\n-  Node* fail = _gvn.transform( new IfFalseNode(iff) );\n-\n+  fail = type_check(recv_klass, tklass, prob);\n@@ -2986,1 +3103,7 @@\n-  (*casted_receiver) = _gvn.transform(cast);\n+  Node* res = _gvn.transform(cast);\n+  if (recv_xtype->is_inlinetypeptr() && recv_xtype->inline_klass()->is_scalarizable()) {\n+    assert(!gvn().type(res)->maybe_null(), \"receiver should never be null\");\n+    res = InlineTypeNode::make_from_oop(this, res, recv_xtype->inline_klass())->as_ptr(&gvn());\n+  }\n+\n+  (*casted_receiver) = res;\n@@ -2992,0 +3115,11 @@\n+Node* GraphKit::type_check(Node* recv_klass, const TypeKlassPtr* tklass,\n+                           float prob) {\n+  Node* want_klass = makecon(tklass);\n+  Node* cmp = _gvn.transform( new CmpPNode(recv_klass, want_klass));\n+  Node* bol = _gvn.transform( new BoolNode(cmp, BoolTest::eq) );\n+  IfNode* iff = create_and_xform_if(control(), bol, prob, COUNT_UNKNOWN);\n+  set_control(  _gvn.transform( new IfTrueNode (iff)));\n+  Node* fail = _gvn.transform( new IfFalseNode(iff));\n+  return fail;\n+}\n+\n@@ -3031,0 +3165,3 @@\n+    if (java_bc() == Bytecodes::_aastore) {\n+      return ((ciArrayLoadStoreData*)data->as_ArrayLoadStoreData())->element()->ptr_kind() == ProfileNeverNull;\n+    }\n@@ -3110,1 +3247,14 @@\n-  ciKlass* exact_kls = spec_klass == NULL ? profile_has_unique_klass() : spec_klass;\n+  ciKlass* exact_kls = spec_klass;\n+  if (exact_kls == NULL) {\n+    if (java_bc() == Bytecodes::_aastore) {\n+      ciKlass* array_type = NULL;\n+      ciKlass* element_type = NULL;\n+      ProfilePtrKind element_ptr = ProfileMaybeNull;\n+      bool flat_array = true;\n+      bool null_free_array = true;\n+      method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n+      exact_kls = element_type;\n+    } else {\n+      exact_kls = profile_has_unique_klass();\n+    }\n+  }\n@@ -3215,0 +3365,1 @@\n+  bool is_value = obj->is_InlineType();\n@@ -3218,1 +3369,1 @@\n-  Node* not_null_obj = null_check_oop(obj, &null_ctl, never_see_null, safe_for_replace, speculative_not_null);\n+  Node* not_null_obj = is_value ? obj : null_check_oop(obj, &null_ctl, never_see_null, safe_for_replace, speculative_not_null);\n@@ -3236,7 +3387,9 @@\n-  bool known_statically = false;\n-  if (_gvn.type(superklass)->singleton()) {\n-    ciKlass* superk = _gvn.type(superklass)->is_klassptr()->klass();\n-    ciKlass* subk = _gvn.type(obj)->is_oopptr()->klass();\n-    if (subk != NULL && subk->is_loaded()) {\n-      int static_res = C->static_subtype_check(superk, subk);\n-      known_statically = (static_res == Compile::SSC_always_true || static_res == Compile::SSC_always_false);\n+  if (!is_value) {\n+    bool known_statically = false;\n+    if (_gvn.type(superklass)->singleton()) {\n+      ciKlass* superk = _gvn.type(superklass)->is_klassptr()->klass();\n+      ciKlass* subk = _gvn.type(obj)->is_oopptr()->klass();\n+      if (subk != NULL && subk->is_loaded()) {\n+        int static_res = C->static_subtype_check(superk, subk);\n+        known_statically = (static_res == Compile::SSC_always_true || static_res == Compile::SSC_always_false);\n+      }\n@@ -3244,14 +3397,17 @@\n-  }\n-  if (!known_statically) {\n-    const TypeOopPtr* obj_type = _gvn.type(obj)->is_oopptr();\n-    \/\/ We may not have profiling here or it may not help us. If we\n-    \/\/ have a speculative type use it to perform an exact cast.\n-    ciKlass* spec_obj_type = obj_type->speculative_type();\n-    if (spec_obj_type != NULL || (ProfileDynamicTypes && data != NULL)) {\n-      Node* cast_obj = maybe_cast_profiled_receiver(not_null_obj, NULL, spec_obj_type, safe_for_replace);\n-      if (stopped()) {            \/\/ Profile disagrees with this path.\n-        set_control(null_ctl);    \/\/ Null is the only remaining possibility.\n-        return intcon(0);\n-      }\n-      if (cast_obj != NULL) {\n-        not_null_obj = cast_obj;\n+    if (!known_statically) {\n+      const TypeOopPtr* obj_type = _gvn.type(obj)->is_oopptr();\n+      \/\/ We may not have profiling here or it may not help us. If we\n+      \/\/ have a speculative type use it to perform an exact cast.\n+      ciKlass* spec_obj_type = obj_type->speculative_type();\n+      if (spec_obj_type != NULL || (ProfileDynamicTypes && data != NULL)) {\n+        Node* cast_obj = maybe_cast_profiled_receiver(not_null_obj, NULL, spec_obj_type, safe_for_replace);\n+        if (stopped()) {            \/\/ Profile disagrees with this path.\n+          set_control(null_ctl);    \/\/ Null is the only remaining possibility.\n+          return intcon(0);\n+        }\n+        if (cast_obj != NULL &&\n+            \/\/ A value that's sometimes null is not something we can optimize well\n+            !(cast_obj->is_InlineType() && null_ctl != top())) {\n+          not_null_obj = cast_obj;\n+          is_value = not_null_obj->is_InlineType();\n+        }\n@@ -3281,1 +3437,1 @@\n-  if (safe_for_replace) {\n+  if (safe_for_replace && !is_value) {\n@@ -3296,2 +3452,1 @@\n-Node* GraphKit::gen_checkcast(Node *obj, Node* superklass,\n-                              Node* *failure_control) {\n+Node* GraphKit::gen_checkcast(Node *obj, Node* superklass, Node* *failure_control) {\n@@ -3299,2 +3454,6 @@\n-  const TypeKlassPtr *tk = _gvn.type(superklass)->is_klassptr();\n-  const Type *toop = TypeOopPtr::make_from_klass(tk->klass());\n+  const TypeKlassPtr* tk = _gvn.type(superklass)->is_klassptr();\n+  const TypeOopPtr* toop = TypeOopPtr::make_from_klass(tk->klass());\n+\n+  \/\/ Check if inline types are involved\n+  bool from_inline = obj->is_InlineType();\n+  bool to_inline = tk->klass()->is_inlinetype();\n@@ -3309,3 +3468,11 @@\n-    const TypeOopPtr* objtp = _gvn.type(obj)->isa_oopptr();\n-    if (objtp != NULL && objtp->klass() != NULL) {\n-      switch (C->static_subtype_check(tk->klass(), objtp->klass())) {\n+    ciKlass* klass = NULL;\n+    if (from_inline) {\n+      klass = _gvn.type(obj)->inline_klass();\n+    } else {\n+      const TypeOopPtr* objtp = _gvn.type(obj)->isa_oopptr();\n+      if (objtp != NULL) {\n+        klass = objtp->klass();\n+      }\n+    }\n+    if (klass != NULL) {\n+      switch (C->static_subtype_check(tk->klass(), klass)) {\n@@ -3316,1 +3483,10 @@\n-        return record_profiled_receiver_for_speculation(obj);\n+        if (!from_inline) {\n+          obj = record_profiled_receiver_for_speculation(obj);\n+          if (to_inline) {\n+            obj = null_check(obj);\n+            if (toop->inline_klass()->is_scalarizable()) {\n+              obj = InlineTypeNode::make_from_oop(this, obj, toop->inline_klass());\n+            }\n+          }\n+        }\n+        return obj;\n@@ -3318,4 +3494,6 @@\n-        \/\/ It needs a null check because a null will *pass* the cast check.\n-        \/\/ A non-null value will always produce an exception.\n-        if (!objtp->maybe_null()) {\n-          builtin_throw(Deoptimization::Reason_class_check, makecon(TypeKlassPtr::make(objtp->klass())));\n+        if (from_inline || to_inline) {\n+          if (!from_inline) {\n+            null_check(obj);\n+          }\n+          \/\/ Inline type is never null. Always throw an exception.\n+          builtin_throw(Deoptimization::Reason_class_check, makecon(TypeKlassPtr::make(klass)));\n@@ -3323,2 +3501,10 @@\n-        } else if (!too_many_traps_or_recompiles(Deoptimization::Reason_null_assert)) {\n-          return null_assert(obj);\n+        } else {\n+          \/\/ It needs a null check because a null will *pass* the cast check.\n+          const TypeOopPtr* objtp = _gvn.type(obj)->isa_oopptr();\n+          if (!objtp->maybe_null()) {\n+            builtin_throw(Deoptimization::Reason_class_check, makecon(TypeKlassPtr::make(objtp->klass())));\n+            return top();\n+          } else if (!too_many_traps_or_recompiles(Deoptimization::Reason_null_assert)) {\n+            return null_assert(obj);\n+          }\n+          break; \/\/ Fall through to full check\n@@ -3326,1 +3512,0 @@\n-        break; \/\/ Fall through to full check\n@@ -3337,1 +3522,3 @@\n-    data = method()->method_data()->bci_to_data(bci());\n+    if (method()->method_data()->is_mature()) {\n+      data = method()->method_data()->bci_to_data(bci());\n+    }\n@@ -3345,0 +3532,3 @@\n+  _gvn.set_type(region, Type::CONTROL);\n+  _gvn.set_type(phi, toop);\n+\n@@ -3354,1 +3544,8 @@\n-  Node* not_null_obj = null_check_oop(obj, &null_ctl, never_see_null, safe_for_replace, speculative_not_null);\n+  Node* not_null_obj = NULL;\n+  if (from_inline) {\n+    not_null_obj = obj;\n+  } else if (to_inline) {\n+    not_null_obj = null_check(obj);\n+  } else {\n+    not_null_obj = null_check_oop(obj, &null_ctl, never_see_null, safe_for_replace, speculative_not_null);\n+  }\n@@ -3372,1 +3569,1 @@\n-  if (tk->klass_is_exact()) {\n+  if (!from_inline && tk->klass_is_exact()) {\n@@ -3383,0 +3580,7 @@\n+      if (cast_obj != NULL && cast_obj->is_InlineType()) {\n+        if (null_ctl != top()) {\n+          cast_obj = NULL; \/\/ A value that's sometimes null is not something we can optimize well\n+        } else {\n+          return cast_obj;\n+        }\n+      }\n@@ -3394,1 +3598,1 @@\n-    Node* not_subtype_ctrl = gen_subtype_check(not_null_obj, superklass );\n+    Node* not_subtype_ctrl = gen_subtype_check(not_null_obj, superklass);\n@@ -3397,1 +3601,1 @@\n-    cast_obj = _gvn.transform(new CheckCastPPNode(control(), not_null_obj, toop));\n+    cast_obj = from_inline ? not_null_obj : _gvn.transform(new CheckCastPPNode(control(), not_null_obj, toop));\n@@ -3403,1 +3607,7 @@\n-        builtin_throw(Deoptimization::Reason_class_check, load_object_klass(not_null_obj));\n+        Node* obj_klass = NULL;\n+        if (from_inline) {\n+          obj_klass = makecon(TypeKlassPtr::make(_gvn.type(not_null_obj)->inline_klass()));\n+        } else {\n+          obj_klass = load_object_klass(not_null_obj);\n+        }\n+        builtin_throw(Deoptimization::Reason_class_check, obj_klass);\n@@ -3430,1 +3640,114 @@\n-  return record_profiled_receiver_for_speculation(res);\n+  bool not_inline = !toop->can_be_inline_type();\n+  bool not_flattened = !UseFlatArray || not_inline || (toop->is_inlinetypeptr() && !toop->inline_klass()->flatten_array());\n+  if (EnableValhalla && not_flattened) {\n+    \/\/ Check if obj has been loaded from an array\n+    obj = obj->isa_DecodeN() ? obj->in(1) : obj;\n+    Node* array = NULL;\n+    if (obj->isa_Load()) {\n+      Node* address = obj->in(MemNode::Address);\n+      if (address->isa_AddP()) {\n+        array = address->as_AddP()->in(AddPNode::Base);\n+      }\n+    } else if (obj->is_Phi()) {\n+      Node* region = obj->in(0);\n+      \/\/ TODO make this more robust (see JDK-8231346)\n+      if (region->req() == 3 && region->in(2) != NULL && region->in(2)->in(0) != NULL) {\n+        IfNode* iff = region->in(2)->in(0)->isa_If();\n+        if (iff != NULL) {\n+          iff->is_flat_array_check(&_gvn, &array);\n+        }\n+      }\n+    }\n+    if (array != NULL) {\n+      const TypeAryPtr* ary_t = _gvn.type(array)->isa_aryptr();\n+      if (ary_t != NULL) {\n+        if (!ary_t->is_not_null_free() && not_inline) {\n+          \/\/ Casting array element to a non-inline-type, mark array as not null-free.\n+          Node* cast = _gvn.transform(new CheckCastPPNode(control(), array, ary_t->cast_to_not_null_free()));\n+          replace_in_map(array, cast);\n+        } else if (!ary_t->is_not_flat()) {\n+          \/\/ Casting array element to a non-flattened type, mark array as not flat.\n+          Node* cast = _gvn.transform(new CheckCastPPNode(control(), array, ary_t->cast_to_not_flat()));\n+          replace_in_map(array, cast);\n+        }\n+      }\n+    }\n+  }\n+\n+  if (!stopped() && !from_inline) {\n+    res = record_profiled_receiver_for_speculation(res);\n+    if (to_inline && toop->inline_klass()->is_scalarizable()) {\n+      assert(!gvn().type(res)->maybe_null(), \"Inline types are null-free\");\n+      res = InlineTypeNode::make_from_oop(this, res, toop->inline_klass());\n+    }\n+  }\n+  return res;\n+}\n+\n+Node* GraphKit::inline_type_test(Node* obj, bool is_inline) {\n+  Node* mark_adr = basic_plus_adr(obj, oopDesc::mark_offset_in_bytes());\n+  Node* mark = make_load(NULL, mark_adr, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n+  Node* mask = MakeConX(markWord::inline_type_pattern);\n+  Node* masked = _gvn.transform(new AndXNode(mark, mask));\n+  Node* cmp = _gvn.transform(new CmpXNode(masked, mask));\n+  return _gvn.transform(new BoolNode(cmp, is_inline ? BoolTest::eq : BoolTest::ne));\n+}\n+\n+Node* GraphKit::array_lh_test(Node* klass, jint mask, jint val, bool eq) {\n+  Node* lh_adr = basic_plus_adr(klass, in_bytes(Klass::layout_helper_offset()));\n+  \/\/ Make sure to use immutable memory here to enable hoisting the check out of loops\n+  Node* lh_val = _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), lh_adr, lh_adr->bottom_type()->is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));\n+  Node* masked = _gvn.transform(new AndINode(lh_val, intcon(mask)));\n+  Node* cmp = _gvn.transform(new CmpINode(masked, intcon(val)));\n+  return _gvn.transform(new BoolNode(cmp, eq ? BoolTest::eq : BoolTest::ne));\n+}\n+\n+Node* GraphKit::flat_array_test(Node* ary, bool flat) {\n+  \/\/ We can't use immutable memory here because the mark word is mutable.\n+  \/\/ PhaseIdealLoop::move_flat_array_check_out_of_loop will make sure the\n+  \/\/ check is moved out of loops (mainly to enable loop unswitching).\n+  Node* mem = UseArrayMarkWordCheck ? memory(Compile::AliasIdxRaw) : immutable_memory();\n+  Node* cmp = _gvn.transform(new FlatArrayCheckNode(C, mem, ary));\n+  record_for_igvn(cmp); \/\/ Give it a chance to be optimized out by IGVN\n+  return _gvn.transform(new BoolNode(cmp, flat ? BoolTest::eq : BoolTest::ne));\n+}\n+\n+Node* GraphKit::null_free_array_test(Node* klass, bool null_free) {\n+  return array_lh_test(klass, Klass::_lh_null_free_bit_inplace, 0, !null_free);\n+}\n+\n+\/\/ Deoptimize if 'ary' is a null-free inline type array and 'val' is null\n+Node* GraphKit::inline_array_null_guard(Node* ary, Node* val, int nargs, bool safe_for_replace) {\n+  const Type* val_t = _gvn.type(val);\n+  if (val->is_InlineType() || !TypePtr::NULL_PTR->higher_equal(val_t)) {\n+    return ary; \/\/ Never null\n+  }\n+  RegionNode* region = new RegionNode(3);\n+  Node* null_ctl = top();\n+  null_check_oop(val, &null_ctl);\n+  if (null_ctl != top()) {\n+    PreserveJVMState pjvms(this);\n+    set_control(null_ctl);\n+    {\n+      \/\/ Deoptimize if null-free array\n+      BuildCutout unless(this, null_free_array_test(load_object_klass(ary), \/* null_free = *\/ false), PROB_MAX);\n+      inc_sp(nargs);\n+      uncommon_trap(Deoptimization::Reason_null_check,\n+                    Deoptimization::Action_none);\n+    }\n+    region->init_req(1, control());\n+  }\n+  region->init_req(2, control());\n+  set_control(_gvn.transform(region));\n+  record_for_igvn(region);\n+  const TypeAryPtr* ary_t = _gvn.type(ary)->is_aryptr();\n+  if (val_t == TypePtr::NULL_PTR && !ary_t->is_not_null_free()) {\n+    \/\/ Since we were just successfully storing null, the array can't be null free.\n+    ary_t = ary_t->cast_to_not_null_free();\n+    Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));\n+    if (safe_for_replace) {\n+      replace_in_map(ary, cast);\n+    }\n+    ary = cast;\n+  }\n+  return ary;\n@@ -3498,0 +3821,1 @@\n+\n@@ -3570,0 +3894,1 @@\n+  assert(!obj->is_InlineTypeBase(), \"should not unlock on inline type\");\n@@ -3610,2 +3935,8 @@\n-    bool    xklass = inst_klass->klass_is_exact();\n-    if (xklass || klass->is_array_klass()) {\n+    assert(klass != NULL, \"klass should not be NULL\");\n+    bool xklass = inst_klass->klass_is_exact();\n+    bool can_be_flattened = false;\n+    if (UseFlatArray && klass->is_obj_array_klass()) {\n+      ciKlass* elem = klass->as_obj_array_klass()->element_klass();\n+      can_be_flattened = elem->can_be_inline_klass() && (!elem->is_inlinetype() || elem->flatten_array());\n+    }\n+    if (xklass || (klass->is_array_klass() && !can_be_flattened)) {\n@@ -3634,1 +3965,3 @@\n-  kit.set_memory(init_out_raw, alias_idx);\n+  if (init_out_raw != NULL) {\n+    kit.set_memory(init_out_raw, alias_idx);\n+  }\n@@ -3673,0 +4006,1 @@\n+    _gvn.set_type(minit_in, Type::MEMORY);\n@@ -3680,3 +4014,29 @@\n-      const TypePtr* telemref = oop_type->add_offset(Type::OffsetBot);\n-      int            elemidx  = C->get_alias_index(telemref);\n-      hook_memory_on_init(*this, elemidx, minit_in, minit_out);\n+      const TypeAryPtr* arytype = oop_type->is_aryptr();\n+      if (arytype->klass()->is_flat_array_klass()) {\n+        \/\/ Initially all flattened array accesses share a single slice\n+        \/\/ but that changes after parsing. Prepare the memory graph so\n+        \/\/ it can optimize flattened array accesses properly once they\n+        \/\/ don't share a single slice.\n+        assert(C->flattened_accesses_share_alias(), \"should be set at parse time\");\n+        C->set_flattened_accesses_share_alias(false);\n+        ciFlatArrayKlass* vak = arytype->klass()->as_flat_array_klass();\n+        ciInlineKlass* vk = vak->element_klass()->as_inline_klass();\n+        for (int i = 0, len = vk->nof_nonstatic_fields(); i < len; i++) {\n+          ciField* field = vk->nonstatic_field_at(i);\n+          if (field->offset() >= TrackedInitializationLimit * HeapWordSize)\n+            continue;  \/\/ do not bother to track really large numbers of fields\n+          int off_in_vt = field->offset() - vk->first_field_offset();\n+          const TypePtr* adr_type = arytype->with_field_offset(off_in_vt)->add_offset(Type::OffsetBot);\n+          int fieldidx = C->get_alias_index(adr_type, true);\n+          \/\/ Pass NULL for init_out. Having per flat array element field memory edges as uses of the Initialize node\n+          \/\/ can result in per flat array field Phis to be created which confuses the logic of\n+          \/\/ Compile::adjust_flattened_array_access_aliases().\n+          hook_memory_on_init(*this, fieldidx, minit_in, NULL);\n+        }\n+        C->set_flattened_accesses_share_alias(true);\n+        hook_memory_on_init(*this, C->get_alias_index(TypeAryPtr::INLINES), minit_in, minit_out);\n+      } else {\n+        const TypePtr* telemref = oop_type->add_offset(Type::OffsetBot);\n+        int            elemidx  = C->get_alias_index(telemref);\n+        hook_memory_on_init(*this, elemidx, minit_in, minit_out);\n+      }\n@@ -3684,0 +4044,1 @@\n+      set_memory(minit_out, C->get_alias_index(oop_type)); \/\/ mark word\n@@ -3734,1 +4095,2 @@\n-                             bool deoptimize_on_exception) {\n+                             bool deoptimize_on_exception,\n+                             InlineTypeBaseNode* inline_type_node) {\n@@ -3741,1 +4103,1 @@\n-  int   layout_is_con = (layout_val == NULL);\n+  bool  layout_is_con = (layout_val == NULL);\n@@ -3792,1 +4154,1 @@\n-  \/\/ since GC and deoptimization can happened.\n+  \/\/ since GC and deoptimization can happen.\n@@ -3799,1 +4161,1 @@\n-                                         initial_slow_test);\n+                                         initial_slow_test, inline_type_node);\n@@ -3805,1 +4167,1 @@\n-\/\/ helper for both newarray and anewarray\n+\/\/ helper for newarray and anewarray\n@@ -3815,1 +4177,1 @@\n-  int   layout_is_con = (layout_val == NULL);\n+  bool  layout_is_con = (layout_val == NULL);\n@@ -3845,1 +4207,1 @@\n-    fast_size_limit <<= (LogBytesPerLong - log2_esize);\n+    fast_size_limit <<= MAX2(LogBytesPerLong - log2_esize, 0);\n@@ -3863,1 +4225,1 @@\n-    BasicType etype  = Klass::layout_helper_element_type(layout_con);\n+    bool is_flat_array = Klass::layout_helper_is_flatArray(layout_con);\n@@ -3866,1 +4228,1 @@\n-    assert((hsize & right_n_bits(eshift)) == 0, \"hsize is pre-rounded\");\n+    assert(is_flat_array || (hsize & right_n_bits(eshift)) == 0, \"hsize is pre-rounded\");\n@@ -3950,1 +4312,1 @@\n-  \/\/ since GC and deoptimization can happened.\n+  \/\/ since GC and deoptimization can happen.\n@@ -3959,0 +4321,63 @@\n+  const TypeKlassPtr* ary_klass = _gvn.type(klass_node)->isa_klassptr();\n+  const TypeOopPtr* ary_type = ary_klass->as_instance_type();\n+  const TypeAryPtr* ary_ptr = ary_type->isa_aryptr();\n+\n+  \/\/ Inline type array variants:\n+  \/\/ - null-ok:              MyValue.ref[] (ciObjArrayKlass \"[LMyValue$ref\")\n+  \/\/ - null-free:            MyValue.val[] (ciObjArrayKlass \"[QMyValue$val\")\n+  \/\/ - null-free, flattened: MyValue.val[] (ciFlatArrayKlass \"[QMyValue$val\")\n+  \/\/ Check if array is a null-free, non-flattened inline type array\n+  \/\/ that needs to be initialized with the default inline type.\n+  Node* default_value = NULL;\n+  Node* raw_default_value = NULL;\n+  if (ary_ptr != NULL && ary_ptr->klass_is_exact()) {\n+    \/\/ Array type is known\n+    ciKlass* elem_klass = ary_ptr->klass()->as_array_klass()->element_klass();\n+    if (elem_klass != NULL && elem_klass->is_inlinetype()) {\n+      ciInlineKlass* vk = elem_klass->as_inline_klass();\n+      if (!vk->flatten_array()) {\n+        default_value = InlineTypeNode::default_oop(gvn(), vk);\n+      }\n+    }\n+  } else if (ary_klass->klass()->can_be_inline_array_klass()) {\n+    \/\/ Array type is not known, add runtime checks\n+    assert(!ary_klass->klass_is_exact(), \"unexpected exact type\");\n+    Node* r = new RegionNode(3);\n+    default_value = new PhiNode(r, TypeInstPtr::BOTTOM);\n+\n+    Node* bol = array_lh_test(klass_node, Klass::_lh_array_tag_vt_value_bit_inplace | Klass::_lh_null_free_bit_inplace, Klass::_lh_null_free_bit_inplace);\n+    IfNode* iff = create_and_map_if(control(), bol, PROB_FAIR, COUNT_UNKNOWN);\n+\n+    \/\/ Null-free, non-flattened inline type array, initialize with the default value\n+    set_control(_gvn.transform(new IfTrueNode(iff)));\n+    Node* p = basic_plus_adr(klass_node, in_bytes(ArrayKlass::element_klass_offset()));\n+    Node* eklass = _gvn.transform(LoadKlassNode::make(_gvn, control(), immutable_memory(), p, TypeInstPtr::KLASS));\n+    Node* adr_fixed_block_addr = basic_plus_adr(eklass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset()));\n+    Node* adr_fixed_block = make_load(control(), adr_fixed_block_addr, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n+    Node* default_value_offset_addr = basic_plus_adr(adr_fixed_block, in_bytes(InlineKlass::default_value_offset_offset()));\n+    Node* default_value_offset = make_load(control(), default_value_offset_addr, TypeInt::INT, T_INT, MemNode::unordered);\n+    Node* elem_mirror = load_mirror_from_klass(eklass);\n+    Node* default_value_addr = basic_plus_adr(elem_mirror, ConvI2X(default_value_offset));\n+    Node* val = access_load_at(elem_mirror, default_value_addr, _gvn.type(default_value_addr)->is_ptr(), TypeInstPtr::BOTTOM, T_OBJECT, IN_HEAP);\n+    r->init_req(1, control());\n+    default_value->init_req(1, val);\n+\n+    \/\/ Otherwise initialize with all zero\n+    r->init_req(2, _gvn.transform(new IfFalseNode(iff)));\n+    default_value->init_req(2, null());\n+\n+    set_control(_gvn.transform(r));\n+    default_value = _gvn.transform(default_value);\n+  }\n+  if (default_value != NULL) {\n+    if (UseCompressedOops) {\n+      \/\/ With compressed oops, the 64-bit init value is built from two 32-bit compressed oops\n+      default_value = _gvn.transform(new EncodePNode(default_value, default_value->bottom_type()->make_narrowoop()));\n+      Node* lower = _gvn.transform(new CastP2XNode(control(), default_value));\n+      Node* upper = _gvn.transform(new LShiftLNode(lower, intcon(32)));\n+      raw_default_value = _gvn.transform(new OrLNode(lower, upper));\n+    } else {\n+      raw_default_value = _gvn.transform(new CastP2XNode(control(), default_value));\n+    }\n+  }\n+\n@@ -3960,6 +4385,6 @@\n-  AllocateArrayNode* alloc\n-    = new AllocateArrayNode(C, AllocateArrayNode::alloc_type(TypeInt::INT),\n-                            control(), mem, i_o(),\n-                            size, klass_node,\n-                            initial_slow_test,\n-                            length);\n+  AllocateArrayNode* alloc = new AllocateArrayNode(C, AllocateArrayNode::alloc_type(TypeInt::INT),\n+                                                   control(), mem, i_o(),\n+                                                   size, klass_node,\n+                                                   initial_slow_test,\n+                                                   length, default_value,\n+                                                   raw_default_value);\n@@ -3972,1 +4397,0 @@\n-  const TypeOopPtr* ary_type = _gvn.type(klass_node)->is_klassptr()->as_instance_type();\n@@ -4130,1 +4554,1 @@\n-                                                     false, NULL, 0);\n+                                                     false, NULL, Type::Offset(0));\n@@ -4133,2 +4557,2 @@\n-                                                  TypeAry::make(TypeInt::BYTE, TypeInt::POS),\n-                                                  ciTypeArrayKlass::make(T_BYTE), true, 0);\n+                                                  TypeAry::make(TypeInt::BYTE, TypeInt::POS, false, true, true),\n+                                                  ciTypeArrayKlass::make(T_BYTE), true, Type::Offset(0));\n@@ -4147,1 +4571,1 @@\n-                                                     false, NULL, 0);\n+                                                     false, NULL, Type::Offset(0));\n@@ -4159,1 +4583,1 @@\n-                                                     false, NULL, 0);\n+                                                     false, NULL, Type::Offset(0));\n@@ -4169,1 +4593,1 @@\n-                                                     false, NULL, 0);\n+                                                     false, NULL, Type::Offset(0));\n@@ -4282,1 +4706,9 @@\n-    return makecon(con_type);\n+    Node* con = makecon(con_type);\n+    \/\/ Check type of constant which might be more precise\n+    if (con_type->is_inlinetypeptr() && con_type->inline_klass()->is_scalarizable()) {\n+      assert(!con_type->is_zero_type(), \"Inline types are null-free\");\n+      con = InlineTypeNode::make_from_oop(this, con, con_type->inline_klass());\n+    } else if (con_type->is_zero_type() && field->type()->is_inlinetype()) {\n+      con = InlineTypeNode::default_oop(gvn(), field->type()->as_inline_klass());\n+    }\n+    return con;\n@@ -4286,0 +4718,9 @@\n+\n+\/\/---------------------------load_mirror_from_klass----------------------------\n+\/\/ Given a klass oop, load its java mirror (a java.lang.Class oop).\n+Node* GraphKit::load_mirror_from_klass(Node* klass) {\n+  Node* p = basic_plus_adr(klass, in_bytes(Klass::java_mirror_offset()));\n+  Node* load = make_load(NULL, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n+  \/\/ mirror = ((OopHandle)mirror)->resolve();\n+  return access_load(load, TypeInstPtr::MIRROR, T_OBJECT, IN_NATIVE);\n+}\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":599,"deletions":158,"binary":false,"changes":757,"status":"modified"},{"patch":"@@ -1194,0 +1194,17 @@\n+\/\/ Returns true if this IfNode belongs to a flat array check\n+\/\/ and returns the corresponding array in the 'array' parameter.\n+bool IfNode::is_flat_array_check(PhaseTransform* phase, Node** array) {\n+  Node* bol = in(1);\n+  if (!bol->is_Bool()) {\n+    return false;\n+  }\n+  Node* cmp = bol->in(1);\n+  if (cmp->isa_FlatArrayCheck()) {\n+    if (array != NULL) {\n+      *array = cmp->in(FlatArrayCheckNode::Array);\n+    }\n+    return true;\n+  }\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/ifnode.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -0,0 +1,968 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n+#include \"gc\/shared\/barrierSet.hpp\"\n+#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"opto\/addnode.hpp\"\n+#include \"opto\/castnode.hpp\"\n+#include \"opto\/graphKit.hpp\"\n+#include \"opto\/inlinetypenode.hpp\"\n+#include \"opto\/rootnode.hpp\"\n+#include \"opto\/phaseX.hpp\"\n+\n+\/\/ Clones the inline type to handle control flow merges involving multiple inline types.\n+\/\/ The inputs are replaced by PhiNodes to represent the merged values for the given region.\n+InlineTypeBaseNode* InlineTypeBaseNode::clone_with_phis(PhaseGVN* gvn, Node* region) {\n+  InlineTypeBaseNode* vt = clone()->as_InlineTypeBase();\n+\n+  \/\/ Create a PhiNode for merging the oop values\n+  const Type* phi_type = Type::get_const_type(inline_klass());\n+  PhiNode* oop = PhiNode::make(region, vt->get_oop(), phi_type);\n+  gvn->set_type(oop, phi_type);\n+  vt->set_oop(oop);\n+\n+  \/\/ Create a PhiNode each for merging the field values\n+  for (uint i = 0; i < vt->field_count(); ++i) {\n+    ciType* type = vt->field_type(i);\n+    Node*  value = vt->field_value(i);\n+    if (value->is_InlineTypeBase()) {\n+      \/\/ Handle flattened inline type fields recursively\n+      value = value->as_InlineTypeBase()->clone_with_phis(gvn, region);\n+    } else {\n+      phi_type = Type::get_const_type(type);\n+      value = PhiNode::make(region, value, phi_type);\n+      gvn->set_type(value, phi_type);\n+    }\n+    vt->set_field_value(i, value);\n+  }\n+  gvn->set_type(vt, vt->bottom_type());\n+  return vt;\n+}\n+\n+\/\/ Checks if the inputs of the InlineTypeBaseTypeNode were replaced by PhiNodes\n+\/\/ for the given region (see InlineTypeBaseTypeNode::clone_with_phis).\n+bool InlineTypeBaseNode::has_phi_inputs(Node* region) {\n+  \/\/ Check oop input\n+  bool result = get_oop()->is_Phi() && get_oop()->as_Phi()->region() == region;\n+#ifdef ASSERT\n+  if (result) {\n+    \/\/ Check all field value inputs for consistency\n+    for (uint i = Oop; i < field_count(); ++i) {\n+      Node* n = in(i);\n+      if (n->is_InlineTypeBase()) {\n+        assert(n->as_InlineTypeBase()->has_phi_inputs(region), \"inconsistent phi inputs\");\n+      } else {\n+        assert(n->is_Phi() && n->as_Phi()->region() == region, \"inconsistent phi inputs\");\n+      }\n+    }\n+  }\n+#endif\n+  return result;\n+}\n+\n+\/\/ Merges 'this' with 'other' by updating the input PhiNodes added by 'clone_with_phis'\n+InlineTypeBaseNode* InlineTypeBaseNode::merge_with(PhaseGVN* gvn, const InlineTypeBaseNode* other, int pnum, bool transform) {\n+  \/\/ Merge oop inputs\n+  PhiNode* phi = get_oop()->as_Phi();\n+  phi->set_req(pnum, other->get_oop());\n+  if (transform) {\n+    set_oop(gvn->transform(phi));\n+    gvn->record_for_igvn(phi);\n+  }\n+  \/\/ Merge field values\n+  for (uint i = 0; i < field_count(); ++i) {\n+    Node* val1 =        field_value(i);\n+    Node* val2 = other->field_value(i);\n+    if (val1->is_InlineTypeBase()) {\n+      val1->as_InlineTypeBase()->merge_with(gvn, val2->as_InlineTypeBase(), pnum, transform);\n+    } else {\n+      assert(val1->is_Phi(), \"must be a phi node\");\n+      val1->set_req(pnum, val2);\n+    }\n+    if (transform) {\n+      set_field_value(i, gvn->transform(val1));\n+      gvn->record_for_igvn(val1);\n+    }\n+  }\n+  return this;\n+}\n+\n+\/\/ Adds a new merge path to an inline type node with phi inputs\n+void InlineTypeBaseNode::add_new_path(Node* region) {\n+  assert(has_phi_inputs(region), \"must have phi inputs\");\n+\n+  PhiNode* phi = get_oop()->as_Phi();\n+  phi->add_req(NULL);\n+  assert(phi->req() == region->req(), \"must be same size as region\");\n+\n+  for (uint i = 0; i < field_count(); ++i) {\n+    Node* val = field_value(i);\n+    if (val->is_InlineType()) {\n+      val->as_InlineType()->add_new_path(region);\n+    } else {\n+      val->as_Phi()->add_req(NULL);\n+      assert(val->req() == region->req(), \"must be same size as region\");\n+    }\n+  }\n+}\n+\n+Node* InlineTypeBaseNode::field_value(uint index) const {\n+  assert(index < field_count(), \"index out of bounds\");\n+  return in(Values + index);\n+}\n+\n+\/\/ Get the value of the field at the given offset.\n+\/\/ If 'recursive' is true, flattened inline type fields will be resolved recursively.\n+Node* InlineTypeBaseNode::field_value_by_offset(int offset, bool recursive) const {\n+  \/\/ If the field at 'offset' belongs to a flattened inline type field, 'index' refers to the\n+  \/\/ corresponding InlineTypeNode input and 'sub_offset' is the offset in flattened inline type.\n+  int index = inline_klass()->field_index_by_offset(offset);\n+  int sub_offset = offset - field_offset(index);\n+  Node* value = field_value(index);\n+  assert(value != NULL, \"field value not found\");\n+  if (recursive && value->is_InlineType()) {\n+    InlineTypeNode* vt = value->as_InlineType();\n+    if (field_is_flattened(index)) {\n+      \/\/ Flattened inline type field\n+      sub_offset += vt->inline_klass()->first_field_offset(); \/\/ Add header size\n+      return vt->field_value_by_offset(sub_offset, recursive);\n+    } else {\n+      assert(sub_offset == 0, \"should not have a sub offset\");\n+      return vt;\n+    }\n+  }\n+  assert(!(recursive && value->is_InlineType()), \"should not be an inline type\");\n+  assert(sub_offset == 0, \"offset mismatch\");\n+  return value;\n+}\n+\n+void InlineTypeBaseNode::set_field_value(uint index, Node* value) {\n+  assert(index < field_count(), \"index out of bounds\");\n+  set_req(Values + index, value);\n+}\n+\n+void InlineTypeBaseNode::set_field_value_by_offset(int offset, Node* value) {\n+  set_field_value(field_index(offset), value);\n+}\n+\n+int InlineTypeBaseNode::field_offset(uint index) const {\n+  assert(index < field_count(), \"index out of bounds\");\n+  return inline_klass()->declared_nonstatic_field_at(index)->offset();\n+}\n+\n+uint InlineTypeBaseNode::field_index(int offset) const {\n+  uint i = 0;\n+  for (; i < field_count() && field_offset(i) != offset; i++) { }\n+  assert(i < field_count(), \"field not found\");\n+  return i;\n+}\n+\n+ciType* InlineTypeBaseNode::field_type(uint index) const {\n+  assert(index < field_count(), \"index out of bounds\");\n+  return inline_klass()->declared_nonstatic_field_at(index)->type();\n+}\n+\n+bool InlineTypeBaseNode::field_is_flattened(uint index) const {\n+  assert(index < field_count(), \"index out of bounds\");\n+  ciField* field = inline_klass()->declared_nonstatic_field_at(index);\n+  assert(!field->is_flattened() || field->type()->is_inlinetype(), \"must be an inline type\");\n+  return field->is_flattened();\n+}\n+\n+int InlineTypeBaseNode::make_scalar_in_safepoint(PhaseIterGVN* igvn, Unique_Node_List& worklist, SafePointNode* sfpt) {\n+  ciInlineKlass* vk = inline_klass();\n+  uint nfields = vk->nof_nonstatic_fields();\n+  JVMState* jvms = sfpt->jvms();\n+  \/\/ Replace safepoint edge by SafePointScalarObjectNode and add field values\n+  assert(jvms != NULL, \"missing JVMS\");\n+  uint first_ind = (sfpt->req() - jvms->scloff());\n+  SafePointScalarObjectNode* sobj = new SafePointScalarObjectNode(inline_ptr(),\n+#ifdef ASSERT\n+                                                                  NULL,\n+#endif\n+                                                                  first_ind, nfields);\n+  sobj->init_req(0, igvn->C->root());\n+  \/\/ Iterate over the inline type fields in order of increasing\n+  \/\/ offset and add the field values to the safepoint.\n+  for (uint j = 0; j < nfields; ++j) {\n+    int offset = vk->nonstatic_field_at(j)->offset();\n+    Node* value = field_value_by_offset(offset, true \/* include flattened inline type fields *\/);\n+    if (value->is_InlineTypeBase()) {\n+      \/\/ Add inline type field to the worklist to process later\n+      worklist.push(value);\n+    }\n+    sfpt->add_req(value);\n+  }\n+  jvms->set_endoff(sfpt->req());\n+  sobj = igvn->transform(sobj)->as_SafePointScalarObject();\n+  igvn->rehash_node_delayed(sfpt);\n+  return sfpt->replace_edges_in_range(this, sobj, jvms->debug_start(), jvms->debug_end(), igvn);\n+}\n+\n+void InlineTypeBaseNode::make_scalar_in_safepoints(PhaseIterGVN* igvn, bool allow_oop) {\n+  \/\/ Process all safepoint uses and scalarize inline type\n+  Unique_Node_List worklist;\n+  for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+    SafePointNode* sfpt = fast_out(i)->isa_SafePoint();\n+    if (sfpt != NULL && !sfpt->is_CallLeaf() && (!sfpt->is_Call() || sfpt->as_Call()->has_debug_use(this))) {\n+      int nb = 0;\n+      if (allow_oop && is_allocated(igvn) && get_oop()->is_Con()) {\n+        \/\/ Inline type is allocated with a constant oop, link it directly\n+        nb = sfpt->replace_edges_in_range(this, get_oop(), sfpt->jvms()->debug_start(), sfpt->jvms()->debug_end(), igvn);\n+        igvn->rehash_node_delayed(sfpt);\n+      } else {\n+        nb = make_scalar_in_safepoint(igvn, worklist, sfpt);\n+      }\n+      --i; imax -= nb;\n+    }\n+  }\n+  \/\/ Now scalarize non-flattened fields\n+  for (uint i = 0; i < worklist.size(); ++i) {\n+    InlineTypeBaseNode* vt = worklist.at(i)->isa_InlineTypeBase();\n+    vt->make_scalar_in_safepoints(igvn);\n+  }\n+  if (outcnt() == 0) {\n+    igvn->_worklist.push(this);\n+  }\n+}\n+\n+const TypePtr* InlineTypeBaseNode::field_adr_type(Node* base, int offset, ciInstanceKlass* holder, DecoratorSet decorators, PhaseGVN& gvn) const {\n+  const TypeAryPtr* ary_type = gvn.type(base)->isa_aryptr();\n+  const TypePtr* adr_type = NULL;\n+  bool is_array = ary_type != NULL;\n+  if ((decorators & C2_MISMATCHED) != 0) {\n+    adr_type = TypeRawPtr::BOTTOM;\n+  } else if (is_array) {\n+    \/\/ In the case of a flattened inline type array, each field has its own slice\n+    adr_type = ary_type->with_field_offset(offset)->add_offset(Type::OffsetBot);\n+  } else {\n+    ciField* field = holder->get_field_by_offset(offset, false);\n+    assert(field != NULL, \"field not found\");\n+    adr_type = gvn.C->alias_type(field)->adr_type();\n+  }\n+  return adr_type;\n+}\n+\n+void InlineTypeBaseNode::load(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) {\n+  \/\/ Initialize the inline type by loading its field values from\n+  \/\/ memory and adding the values as input edges to the node.\n+  for (uint i = 0; i < field_count(); ++i) {\n+    int offset = holder_offset + field_offset(i);\n+    Node* value = NULL;\n+    ciType* ft = field_type(i);\n+    if (ft->is_inlinetype() && ft->as_inline_klass()->is_empty()) {\n+      \/\/ Loading from a field of an empty inline type. Just return the default instance.\n+      value = InlineTypeNode::make_default(kit->gvn(), ft->as_inline_klass());\n+    } else if (field_is_flattened(i)) {\n+      \/\/ Recursively load the flattened inline type field\n+      value = InlineTypeNode::make_from_flattened(kit, ft->as_inline_klass(), base, ptr, holder, offset, decorators);\n+    } else {\n+      const TypeOopPtr* oop_ptr = kit->gvn().type(base)->isa_oopptr();\n+      bool is_array = (oop_ptr->isa_aryptr() != NULL);\n+      if (base->is_Con() && !is_array) {\n+        \/\/ If the oop to the inline type is constant (static final field), we can\n+        \/\/ also treat the fields as constants because the inline type is immutable.\n+        ciObject* constant_oop = oop_ptr->const_oop();\n+        ciField* field = holder->get_field_by_offset(offset, false);\n+        assert(field != NULL, \"field not found\");\n+        ciConstant constant = constant_oop->as_instance()->field_value(field);\n+        const Type* con_type = Type::make_from_constant(constant, \/*require_const=*\/ true);\n+        assert(con_type != NULL, \"type not found\");\n+        value = kit->gvn().transform(kit->makecon(con_type));\n+        \/\/ Check type of constant which might be more precise than the static field type\n+        if (con_type->is_inlinetypeptr()) {\n+          assert(!con_type->is_zero_type(), \"Inline types are null-free\");\n+          ft = con_type->inline_klass();\n+        }\n+      } else {\n+        \/\/ Load field value from memory\n+        const TypePtr* adr_type = field_adr_type(base, offset, holder, decorators, kit->gvn());\n+        Node* adr = kit->basic_plus_adr(base, ptr, offset);\n+        BasicType bt = type2field[ft->basic_type()];\n+        assert(is_java_primitive(bt) || adr->bottom_type()->is_ptr_to_narrowoop() == UseCompressedOops, \"inconsistent\");\n+        const Type* val_type = Type::get_const_type(ft);\n+        if (is_array) {\n+          decorators |= IS_ARRAY;\n+        }\n+        value = kit->access_load_at(base, adr, adr_type, val_type, bt, decorators);\n+      }\n+      if (ft->is_inlinetype()) {\n+        \/\/ Loading a non-flattened inline type from memory\n+        if (ft->as_inline_klass()->is_scalarizable()) {\n+          value = InlineTypeNode::make_from_oop(kit, value, ft->as_inline_klass());\n+        } else {\n+          value = kit->null2default(value, ft->as_inline_klass());\n+        }\n+      }\n+    }\n+    set_field_value(i, value);\n+  }\n+}\n+\n+void InlineTypeBaseNode::store_flattened(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) const {\n+  if (kit->gvn().type(base)->isa_aryptr()) {\n+    kit->C->set_flattened_accesses();\n+  }\n+  \/\/ The inline type is embedded into the object without an oop header. Subtract the\n+  \/\/ offset of the first field to account for the missing header when storing the values.\n+  if (holder == NULL) {\n+    holder = inline_klass();\n+  }\n+  holder_offset -= inline_klass()->first_field_offset();\n+  store(kit, base, ptr, holder, holder_offset, decorators);\n+}\n+\n+void InlineTypeBaseNode::store(GraphKit* kit, Node* base, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) const {\n+  \/\/ Write field values to memory\n+  for (uint i = 0; i < field_count(); ++i) {\n+    int offset = holder_offset + field_offset(i);\n+    Node* value = field_value(i);\n+    ciType* ft = field_type(i);\n+    if (field_is_flattened(i)) {\n+      \/\/ Recursively store the flattened inline type field\n+      if (!value->is_InlineType()) {\n+        assert(!kit->gvn().type(value)->maybe_null(), \"Inline types are null-free\");\n+        value = InlineTypeNode::make_from_oop(kit, value, ft->as_inline_klass());\n+      }\n+      value->as_InlineType()->store_flattened(kit, base, ptr, holder, offset, decorators);\n+    } else {\n+      \/\/ Store field value to memory\n+      const TypePtr* adr_type = field_adr_type(base, offset, holder, decorators, kit->gvn());\n+      Node* adr = kit->basic_plus_adr(base, ptr, offset);\n+      BasicType bt = type2field[ft->basic_type()];\n+      assert(is_java_primitive(bt) || adr->bottom_type()->is_ptr_to_narrowoop() == UseCompressedOops, \"inconsistent\");\n+      const Type* val_type = Type::get_const_type(ft);\n+      const TypeAryPtr* ary_type = kit->gvn().type(base)->isa_aryptr();\n+      if (ary_type != NULL) {\n+        decorators |= IS_ARRAY;\n+      }\n+      kit->access_store_at(base, adr, adr_type, value, val_type, bt, decorators);\n+    }\n+  }\n+}\n+\n+InlineTypePtrNode* InlineTypeBaseNode::buffer(GraphKit* kit, bool safe_for_replace) {\n+  assert(is_InlineType(), \"sanity\");\n+  \/\/ Check if inline type is already allocated\n+  Node* null_ctl = kit->top();\n+  Node* not_null_oop = kit->null_check_oop(get_oop(), &null_ctl);\n+  if (null_ctl->is_top()) {\n+    \/\/ Inline type is allocated\n+    return as_ptr(&kit->gvn());\n+  }\n+  assert(!is_allocated(&kit->gvn()), \"should not be allocated\");\n+  RegionNode* region = new RegionNode(3);\n+\n+  \/\/ Oop is non-NULL, use it\n+  region->init_req(1, kit->control());\n+  PhiNode* oop = PhiNode::make(region, not_null_oop, inline_ptr()->join_speculative(TypePtr::NOTNULL));\n+  PhiNode* io  = PhiNode::make(region, kit->i_o(), Type::ABIO);\n+  PhiNode* mem = PhiNode::make(region, kit->merged_memory(), Type::MEMORY, TypePtr::BOTTOM);\n+\n+  int bci = kit->bci();\n+  bool reexecute = kit->jvms()->should_reexecute();\n+  {\n+    \/\/ Oop is NULL, allocate and initialize buffer\n+    PreserveJVMState pjvms(kit);\n+    \/\/ Propagate re-execution state and bci\n+    kit->set_bci(bci);\n+    kit->jvms()->set_bci(bci);\n+    kit->jvms()->set_should_reexecute(reexecute);\n+    kit->set_control(null_ctl);\n+    kit->kill_dead_locals();\n+    ciInlineKlass* vk = inline_klass();\n+    Node* klass_node = kit->makecon(TypeKlassPtr::make(vk));\n+    Node* alloc_oop  = kit->new_instance(klass_node, NULL, NULL, \/* deoptimize_on_exception *\/ true, this);\n+    store(kit, alloc_oop, alloc_oop, vk);\n+\n+    \/\/ Do not let stores that initialize this buffer be reordered with a subsequent\n+    \/\/ store that would make this buffer accessible by other threads.\n+    AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_oop, &kit->gvn());\n+    assert(alloc != NULL, \"must have an allocation node\");\n+    kit->insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out_or_null(AllocateNode::RawAddress));\n+\n+    region->init_req(2, kit->control());\n+    oop   ->init_req(2, alloc_oop);\n+    io    ->init_req(2, kit->i_o());\n+    mem   ->init_req(2, kit->merged_memory());\n+  }\n+\n+  \/\/ Update GraphKit\n+  kit->set_control(kit->gvn().transform(region));\n+  kit->set_i_o(kit->gvn().transform(io));\n+  kit->set_all_memory(kit->gvn().transform(mem));\n+  kit->record_for_igvn(region);\n+  kit->record_for_igvn(oop);\n+  kit->record_for_igvn(io);\n+  kit->record_for_igvn(mem);\n+\n+  \/\/ Use cloned InlineTypeNode to propagate oop from now on\n+  Node* res_oop = kit->gvn().transform(oop);\n+  InlineTypeBaseNode* vt = clone()->as_InlineTypeBase();\n+  vt->set_oop(res_oop);\n+  vt = kit->gvn().transform(vt)->as_InlineTypeBase();\n+  if (safe_for_replace) {\n+    kit->replace_in_map(this, vt);\n+  }\n+  \/\/ InlineTypeNode::remove_redundant_allocations piggybacks on split if.\n+  \/\/ Make sure it gets a chance to remove this allocation.\n+  kit->C->set_has_split_ifs(true);\n+  return vt->as_ptr(&kit->gvn());\n+}\n+\n+bool InlineTypeBaseNode::is_allocated(PhaseGVN* phase) const {\n+  Node* oop = get_oop();\n+  const Type* oop_type = (phase != NULL) ? phase->type(oop) : oop->bottom_type();\n+  return !oop_type->maybe_null();\n+}\n+\n+InlineTypePtrNode* InlineTypeBaseNode::as_ptr(PhaseGVN* phase) const {\n+  assert(is_allocated(phase), \"must be allocated\");\n+  if (is_InlineTypePtr()) {\n+    return as_InlineTypePtr();\n+  }\n+  return phase->transform(new InlineTypePtrNode(this))->as_InlineTypePtr();\n+}\n+\n+\/\/ When a call returns multiple values, it has several result\n+\/\/ projections, one per field. Replacing the result of the call by an\n+\/\/ inline type node (after late inlining) requires that for each result\n+\/\/ projection, we find the corresponding inline type field.\n+void InlineTypeBaseNode::replace_call_results(GraphKit* kit, Node* call, Compile* C) {\n+  ciInlineKlass* vk = inline_klass();\n+  for (DUIterator_Fast imax, i = call->fast_outs(imax); i < imax; i++) {\n+    ProjNode* pn = call->fast_out(i)->as_Proj();\n+    uint con = pn->_con;\n+    Node* field = NULL;\n+    if (con == TypeFunc::Parms) {\n+      field = get_oop();\n+    } else if (con > TypeFunc::Parms) {\n+      uint field_nb = con - (TypeFunc::Parms+1);\n+      int extra = 0;\n+      for (uint j = 0; j < field_nb - extra; j++) {\n+        ciField* f = vk->nonstatic_field_at(j);\n+        BasicType bt = f->type()->basic_type();\n+        if (bt == T_LONG || bt == T_DOUBLE) {\n+          extra++;\n+        }\n+      }\n+      ciField* f = vk->nonstatic_field_at(field_nb - extra);\n+      field = field_value_by_offset(f->offset(), true);\n+      if (field->is_InlineType()) {\n+        assert(field->as_InlineType()->is_allocated(&kit->gvn()), \"must be allocated\");\n+        field = field->as_InlineType()->get_oop();\n+      }\n+    }\n+    if (field != NULL) {\n+      C->gvn_replace_by(pn, field);\n+      C->initial_gvn()->hash_delete(pn);\n+      pn->set_req(0, C->top());\n+      --i; --imax;\n+    }\n+  }\n+}\n+\n+Node* InlineTypeBaseNode::allocate_fields(GraphKit* kit) {\n+  InlineTypeBaseNode* vt = clone()->as_InlineTypeBase();\n+  for (uint i = 0; i < field_count(); i++) {\n+     InlineTypeNode* value = field_value(i)->isa_InlineType();\n+     if (field_is_flattened(i)) {\n+       \/\/ Flattened inline type field\n+       vt->set_field_value(i, value->allocate_fields(kit));\n+     } else if (value != NULL) {\n+       \/\/ Non-flattened inline type field\n+       vt->set_field_value(i, value->buffer(kit));\n+     }\n+  }\n+  vt = kit->gvn().transform(vt)->as_InlineTypeBase();\n+  kit->replace_in_map(this, vt);\n+  return vt;\n+}\n+\n+Node* InlineTypeBaseNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  if (phase->C->scalarize_in_safepoints() && can_reshape) {\n+    PhaseIterGVN* igvn = phase->is_IterGVN();\n+    make_scalar_in_safepoints(igvn);\n+  }\n+  return NULL;\n+}\n+\n+InlineTypeNode* InlineTypeNode::make_uninitialized(PhaseGVN& gvn, ciInlineKlass* vk) {\n+  \/\/ Create a new InlineTypeNode with uninitialized values and NULL oop\n+  Node* oop = vk->is_empty() ? default_oop(gvn, vk) : gvn.zerocon(T_INLINE_TYPE);\n+  return new InlineTypeNode(vk, oop);\n+}\n+\n+Node* InlineTypeNode::default_oop(PhaseGVN& gvn, ciInlineKlass* vk) {\n+  \/\/ Returns the constant oop of the default inline type allocation\n+  return gvn.makecon(TypeInstPtr::make(vk->default_instance()));\n+}\n+\n+InlineTypeNode* InlineTypeNode::make_default(PhaseGVN& gvn, ciInlineKlass* vk) {\n+  \/\/ Create a new InlineTypeNode with default values\n+  InlineTypeNode* vt = new InlineTypeNode(vk, default_oop(gvn, vk));\n+  for (uint i = 0; i < vt->field_count(); ++i) {\n+    ciType* field_type = vt->field_type(i);\n+    Node* value = NULL;\n+    if (field_type->is_inlinetype()) {\n+      ciInlineKlass* field_klass = field_type->as_inline_klass();\n+      if (field_klass->is_scalarizable()) {\n+        value = make_default(gvn, field_klass);\n+      } else {\n+        value = default_oop(gvn, field_klass);\n+      }\n+    } else {\n+      value = gvn.zerocon(field_type->basic_type());\n+    }\n+    vt->set_field_value(i, value);\n+  }\n+  vt = gvn.transform(vt)->as_InlineType();\n+  assert(vt->is_default(&gvn), \"must be the default inline type\");\n+  return vt;\n+}\n+\n+bool InlineTypeNode::is_default(PhaseGVN* gvn) const {\n+  for (uint i = 0; i < field_count(); ++i) {\n+    Node* value = field_value(i);\n+    if (!gvn->type(value)->is_zero_type() &&\n+        !(value->is_InlineType() && value->as_InlineType()->is_default(gvn)) &&\n+        !(field_type(i)->is_inlinetype() && value == default_oop(*gvn, field_type(i)->as_inline_klass()))) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+InlineTypeNode* InlineTypeNode::make_from_oop(GraphKit* kit, Node* oop, ciInlineKlass* vk) {\n+  PhaseGVN& gvn = kit->gvn();\n+  if (vk->is_empty()) {\n+    return make_default(gvn, vk);\n+  }\n+  \/\/ Create and initialize an InlineTypeNode by loading all field\n+  \/\/ values from a heap-allocated version and also save the oop.\n+  InlineTypeNode* vt = new InlineTypeNode(vk, oop);\n+\n+  if (oop->isa_InlineTypePtr()) {\n+    \/\/ Can happen with late inlining\n+    InlineTypePtrNode* vtptr = oop->as_InlineTypePtr();\n+    vt->set_oop(vtptr->get_oop());\n+    for (uint i = Oop+1; i < vtptr->req(); ++i) {\n+      vt->init_req(i, vtptr->in(i));\n+    }\n+  } else if (gvn.type(oop)->maybe_null()) {\n+    \/\/ Add a null check because the oop may be null\n+    Node* null_ctl = kit->top();\n+    Node* not_null_oop = kit->null_check_oop(oop, &null_ctl);\n+    if (kit->stopped()) {\n+      \/\/ Constant null\n+      kit->set_control(null_ctl);\n+      return make_default(gvn, vk);\n+    }\n+    vt->set_oop(not_null_oop);\n+    vt->load(kit, not_null_oop, not_null_oop, vk, \/* holder_offset *\/ 0);\n+\n+    if (null_ctl != kit->top()) {\n+      \/\/ Return default inline type if oop is null\n+      InlineTypeNode* def = make_default(gvn, vk);\n+      Node* region = new RegionNode(3);\n+      region->init_req(1, kit->control());\n+      region->init_req(2, null_ctl);\n+\n+      vt = vt->clone_with_phis(&gvn, region)->as_InlineType();\n+      vt->merge_with(&gvn, def, 2, true);\n+      kit->set_control(gvn.transform(region));\n+    }\n+  } else {\n+    \/\/ Oop can never be null\n+    Node* init_ctl = kit->control();\n+    vt->load(kit, oop, oop, vk, \/* holder_offset *\/ 0);\n+    assert(vt->is_default(&gvn) || init_ctl != kit->control() || !gvn.type(oop)->is_inlinetypeptr() || oop->is_Con() || oop->Opcode() == Op_InlineTypePtr ||\n+           AllocateNode::Ideal_allocation(oop, &gvn) != NULL || vt->is_loaded(&gvn) == oop, \"inline type should be loaded\");\n+  }\n+\n+  assert(vt->is_allocated(&gvn), \"inline type should be allocated\");\n+  return gvn.transform(vt)->as_InlineType();\n+}\n+\n+\/\/ GraphKit wrapper for the 'make_from_flattened' method\n+InlineTypeNode* InlineTypeNode::make_from_flattened(GraphKit* kit, ciInlineKlass* vk, Node* obj, Node* ptr, ciInstanceKlass* holder, int holder_offset, DecoratorSet decorators) {\n+  if (kit->gvn().type(obj)->isa_aryptr()) {\n+    kit->C->set_flattened_accesses();\n+  }\n+  \/\/ Create and initialize an InlineTypeNode by loading all field values from\n+  \/\/ a flattened inline type field at 'holder_offset' or from an inline type array.\n+  InlineTypeNode* vt = make_uninitialized(kit->gvn(), vk);\n+  \/\/ The inline type is flattened into the object without an oop header. Subtract the\n+  \/\/ offset of the first field to account for the missing header when loading the values.\n+  holder_offset -= vk->first_field_offset();\n+  vt->load(kit, obj, ptr, holder, holder_offset, decorators);\n+  assert(vt->is_loaded(&kit->gvn()) != obj, \"holder oop should not be used as flattened inline type oop\");\n+  return kit->gvn().transform(vt)->as_InlineType();\n+}\n+\n+InlineTypeNode* InlineTypeNode::make_from_multi(GraphKit* kit, MultiNode* multi, ciInlineKlass* vk, uint& base_input, bool in) {\n+  InlineTypeNode* vt = make_uninitialized(kit->gvn(), vk);\n+  if (!in) {\n+    \/\/ Keep track of the oop. The returned inline type might already be buffered.\n+    Node* oop = kit->gvn().transform(new ProjNode(multi, base_input++));\n+    vt->set_oop(oop);\n+  }\n+  vt->initialize_fields(kit, multi, base_input, in);\n+  return kit->gvn().transform(vt)->as_InlineType();\n+}\n+\n+InlineTypeNode* InlineTypeNode::make_larval(GraphKit* kit, bool allocate) const {\n+  ciInlineKlass* vk = inline_klass();\n+  InlineTypeNode* res = clone()->as_InlineType();\n+  if (allocate) {\n+    \/\/ Re-execute if buffering triggers deoptimization\n+    PreserveReexecuteState preexecs(kit);\n+    kit->jvms()->set_should_reexecute(true);\n+    Node* klass_node = kit->makecon(TypeKlassPtr::make(vk));\n+    Node* alloc_oop  = kit->new_instance(klass_node, NULL, NULL, true);\n+    AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_oop, &kit->gvn());\n+    alloc->_larval = true;\n+\n+    store(kit, alloc_oop, alloc_oop, vk);\n+    res->set_oop(alloc_oop);\n+  }\n+  res->set_type(TypeInlineType::make(vk, true));\n+  res = kit->gvn().transform(res)->as_InlineType();\n+  assert(!allocate || res->is_allocated(&kit->gvn()), \"must be allocated\");\n+  return res;\n+}\n+\n+InlineTypeNode* InlineTypeNode::finish_larval(GraphKit* kit) const {\n+  Node* obj = get_oop();\n+  Node* mark_addr = kit->basic_plus_adr(obj, oopDesc::mark_offset_in_bytes());\n+  Node* mark = kit->make_load(NULL, mark_addr, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n+  mark = kit->gvn().transform(new AndXNode(mark, kit->MakeConX(~markWord::larval_bit_in_place)));\n+  kit->store_to_memory(kit->control(), mark_addr, mark, TypeX_X->basic_type(), kit->gvn().type(mark_addr)->is_ptr(), MemNode::unordered);\n+\n+  \/\/ Do not let stores that initialize this buffer be reordered with a subsequent\n+  \/\/ store that would make this buffer accessible by other threads.\n+  AllocateNode* alloc = AllocateNode::Ideal_allocation(obj, &kit->gvn());\n+  assert(alloc != NULL, \"must have an allocation node\");\n+  kit->insert_mem_bar(Op_MemBarStoreStore, alloc->proj_out_or_null(AllocateNode::RawAddress));\n+\n+  ciInlineKlass* vk = inline_klass();\n+  InlineTypeNode* res = clone()->as_InlineType();\n+  res->set_type(TypeInlineType::make(vk, false));\n+  res = kit->gvn().transform(res)->as_InlineType();\n+  return res;\n+}\n+\n+Node* InlineTypeNode::is_loaded(PhaseGVN* phase, ciInlineKlass* vk, Node* base, int holder_offset) {\n+  if (vk == NULL) {\n+    vk = inline_klass();\n+  }\n+  if (field_count() == 0) {\n+    assert(is_allocated(phase), \"must be allocated\");\n+    return get_oop();\n+  }\n+  for (uint i = 0; i < field_count(); ++i) {\n+    int offset = holder_offset + field_offset(i);\n+    Node* value = field_value(i);\n+    if (value->is_InlineType()) {\n+      InlineTypeNode* vt = value->as_InlineType();\n+      if (vt->inline_klass()->is_empty()) {\n+        continue;\n+      } else if (field_is_flattened(i)) {\n+        \/\/ Check inline type field load recursively\n+        base = vt->is_loaded(phase, vk, base, offset - vt->inline_klass()->first_field_offset());\n+        if (base == NULL) {\n+          return NULL;\n+        }\n+        continue;\n+      } else {\n+        value = vt->get_oop();\n+        if (value->Opcode() == Op_CastPP) {\n+          \/\/ Skip CastPP\n+          value = value->in(1);\n+        }\n+      }\n+    }\n+    if (value->isa_DecodeN()) {\n+      \/\/ Skip DecodeN\n+      value = value->in(1);\n+    }\n+    if (value->isa_Load()) {\n+      \/\/ Check if base and offset of field load matches inline type layout\n+      intptr_t loffset = 0;\n+      Node* lbase = AddPNode::Ideal_base_and_offset(value->in(MemNode::Address), phase, loffset);\n+      if (lbase == NULL || (lbase != base && base != NULL) || loffset != offset) {\n+        return NULL;\n+      } else if (base == NULL) {\n+        \/\/ Set base and check if pointer type matches\n+        base = lbase;\n+        const TypeInstPtr* vtptr = phase->type(base)->isa_instptr();\n+        if (vtptr == NULL || !vtptr->klass()->equals(vk)) {\n+          return NULL;\n+        }\n+      }\n+    } else {\n+      return NULL;\n+    }\n+  }\n+  return base;\n+}\n+\n+Node* InlineTypeNode::tagged_klass(ciInlineKlass* vk, PhaseGVN& gvn) {\n+  const TypeKlassPtr* tk = TypeKlassPtr::make(vk);\n+  intptr_t bits = tk->get_con();\n+  set_nth_bit(bits, 0);\n+  return gvn.makecon(TypeRawPtr::make((address)bits));\n+}\n+\n+void InlineTypeNode::pass_fields(GraphKit* kit, Node* n, uint& base_input) {\n+  for (uint i = 0; i < field_count(); i++) {\n+    int offset = field_offset(i);\n+    ciType* type = field_type(i);\n+    Node* arg = field_value(i);\n+\n+    if (field_is_flattened(i)) {\n+      \/\/ Flattened inline type field\n+      InlineTypeNode* vt = arg->as_InlineType();\n+      vt->pass_fields(kit, n, base_input);\n+    } else {\n+      if (arg->is_InlineType()) {\n+        \/\/ Non-flattened inline type field\n+        InlineTypeNode* vt = arg->as_InlineType();\n+        assert(n->Opcode() != Op_Return || vt->is_allocated(&kit->gvn()), \"inline type field should be allocated on return\");\n+        arg = vt->buffer(kit);\n+      }\n+      \/\/ Initialize call\/return arguments\n+      BasicType bt = field_type(i)->basic_type();\n+      n->init_req(base_input++, arg);\n+      if (type2size[bt] == 2) {\n+        n->init_req(base_input++, kit->top());\n+      }\n+    }\n+  }\n+}\n+\n+void InlineTypeNode::initialize_fields(GraphKit* kit, MultiNode* multi, uint& base_input, bool in) {\n+  PhaseGVN& gvn = kit->gvn();\n+  for (uint i = 0; i < field_count(); ++i) {\n+    ciType* type = field_type(i);\n+    Node* parm = NULL;\n+    if (field_is_flattened(i)) {\n+      \/\/ Flattened inline type field\n+      InlineTypeNode* vt = make_uninitialized(gvn, type->as_inline_klass());\n+      vt->initialize_fields(kit, multi, base_input, in);\n+      parm = gvn.transform(vt);\n+    } else {\n+      if (multi->is_Start()) {\n+        assert(in, \"return from start?\");\n+        parm = gvn.transform(new ParmNode(multi->as_Start(), base_input));\n+      } else if (in) {\n+        parm = multi->as_Call()->in(base_input);\n+      } else {\n+        parm = gvn.transform(new ProjNode(multi->as_Call(), base_input));\n+      }\n+      if (type->is_inlinetype()) {\n+        \/\/ Non-flattened inline type field\n+        if (type->as_inline_klass()->is_scalarizable()) {\n+          parm = make_from_oop(kit, parm, type->as_inline_klass());\n+        } else {\n+          parm = kit->null2default(parm, type->as_inline_klass());\n+        }\n+      }\n+      BasicType bt = type->basic_type();\n+      base_input += type2size[bt];\n+    }\n+    assert(parm != NULL, \"should never be null\");\n+    assert(field_value(i) == NULL, \"already set\");\n+    set_field_value(i, parm);\n+    gvn.record_for_igvn(parm);\n+  }\n+}\n+\n+\/\/ Replace a buffer allocation by a dominating allocation\n+static void replace_allocation(PhaseIterGVN* igvn, Node* res, Node* dom) {\n+  \/\/ Remove initializing stores and GC barriers\n+  for (DUIterator_Fast imax, i = res->fast_outs(imax); i < imax; i++) {\n+    Node* use = res->fast_out(i);\n+    if (use->is_AddP()) {\n+      for (DUIterator_Fast jmax, j = use->fast_outs(jmax); j < jmax; j++) {\n+        Node* store = use->fast_out(j)->isa_Store();\n+        if (store != NULL) {\n+          igvn->rehash_node_delayed(store);\n+          igvn->replace_in_uses(store, store->in(MemNode::Memory));\n+        }\n+      }\n+    } else if (use->Opcode() == Op_CastP2X) {\n+      if (UseG1GC && use->find_out_with(Op_XorX)->in(1) != use) {\n+        \/\/ The G1 pre-barrier uses a CastP2X both for the pointer of the object\n+        \/\/ we store into, as well as the value we are storing. Skip if this is a\n+        \/\/ barrier for storing 'res' into another object.\n+        continue;\n+      }\n+      BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+      bs->eliminate_gc_barrier(igvn, use);\n+      --i; --imax;\n+    }\n+  }\n+  igvn->replace_node(res, dom);\n+}\n+\n+Node* InlineTypeNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* oop = get_oop();\n+  if (is_default(phase) && (!oop->is_Con() || phase->type(oop)->is_zero_type())) {\n+    \/\/ Use the pre-allocated oop for default inline types\n+    set_oop(default_oop(*phase, inline_klass()));\n+    assert(is_allocated(phase), \"should now be allocated\");\n+    return this;\n+  } else if (oop->isa_InlineTypePtr()) {\n+    \/\/ Can happen with late inlining\n+    InlineTypePtrNode* vtptr = oop->as_InlineTypePtr();\n+    set_oop(vtptr->get_oop());\n+    for (uint i = Oop+1; i < vtptr->req(); ++i) {\n+      set_req(i, vtptr->in(i));\n+    }\n+    return this;\n+  }\n+\n+  if (!is_allocated(phase)) {\n+    \/\/ Save base oop if fields are loaded from memory and the inline\n+    \/\/ type is not buffered (in this case we should not use the oop).\n+    Node* base = is_loaded(phase);\n+    if (base != NULL) {\n+      set_oop(base);\n+      assert(is_allocated(phase), \"should now be allocated\");\n+      return this;\n+    }\n+  }\n+\n+  if (can_reshape) {\n+    PhaseIterGVN* igvn = phase->is_IterGVN();\n+\n+    if (is_allocated(phase)) {\n+      \/\/ Search for and remove re-allocations of this inline type. Ignore scalar replaceable ones,\n+      \/\/ they will be removed anyway and changing the memory chain will confuse other optimizations.\n+      \/\/ This can happen with late inlining when we first allocate an inline type argument\n+      \/\/ but later decide to inline the call after the callee code also triggered allocation.\n+      for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+        AllocateNode* alloc = fast_out(i)->isa_Allocate();\n+        if (alloc != NULL && alloc->in(AllocateNode::InlineTypeNode) == this && !alloc->_is_scalar_replaceable) {\n+          \/\/ Found a re-allocation\n+          Node* res = alloc->result_cast();\n+          if (res != NULL && res->is_CheckCastPP()) {\n+            \/\/ Replace allocation by oop and unlink AllocateNode\n+            replace_allocation(igvn, res, get_oop());\n+            igvn->replace_input_of(alloc, AllocateNode::InlineTypeNode, igvn->C->top());\n+            --i; --imax;\n+          }\n+        }\n+      }\n+    }\n+  }\n+  return InlineTypeBaseNode::Ideal(phase, can_reshape);\n+}\n+\n+\/\/ Search for multiple allocations of this inline type and try to replace them by dominating allocations.\n+void InlineTypeNode::remove_redundant_allocations(PhaseIterGVN* igvn, PhaseIdealLoop* phase) {\n+  \/\/ Search for allocations of this inline type. Ignore scalar replaceable ones, they\n+  \/\/ will be removed anyway and changing the memory chain will confuse other optimizations.\n+  for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+    AllocateNode* alloc = fast_out(i)->isa_Allocate();\n+    if (alloc != NULL && alloc->in(AllocateNode::InlineTypeNode) == this && !alloc->_is_scalar_replaceable) {\n+      Node* res = alloc->result_cast();\n+      if (res == NULL || !res->is_CheckCastPP()) {\n+        break; \/\/ No unique CheckCastPP\n+      }\n+      assert(!is_default(igvn) && !is_allocated(igvn), \"re-allocation should be removed by Ideal transformation\");\n+      \/\/ Search for a dominating allocation of the same inline type\n+      Node* res_dom = res;\n+      for (DUIterator_Fast jmax, j = fast_outs(jmax); j < jmax; j++) {\n+        AllocateNode* alloc_other = fast_out(j)->isa_Allocate();\n+        if (alloc_other != NULL && alloc_other->in(AllocateNode::InlineTypeNode) == this && !alloc_other->_is_scalar_replaceable) {\n+          Node* res_other = alloc_other->result_cast();\n+          if (res_other != NULL && res_other->is_CheckCastPP() && res_other != res_dom &&\n+              phase->is_dominator(res_other->in(0), res_dom->in(0))) {\n+            res_dom = res_other;\n+          }\n+        }\n+      }\n+      if (res_dom != res) {\n+        \/\/ Replace allocation by dominating one.\n+        replace_allocation(igvn, res, res_dom);\n+        \/\/ The result of the dominated allocation is now unused and will be removed\n+        \/\/ later in PhaseMacroExpand::eliminate_allocate_node to not confuse loop opts.\n+        igvn->_worklist.push(alloc);\n+      }\n+    }\n+  }\n+\n+  \/\/ Process users\n+  for (DUIterator_Fast imax, i = fast_outs(imax); i < imax; i++) {\n+    Node* out = fast_out(i);\n+    if (out->is_InlineType()) {\n+      \/\/ Recursively process inline type users\n+      igvn->rehash_node_delayed(out);\n+      out->as_InlineType()->remove_redundant_allocations(igvn, phase);\n+    } else if (out->isa_Allocate() != NULL) {\n+      \/\/ Unlink AllocateNode\n+      assert(out->in(AllocateNode::InlineTypeNode) == this, \"should be linked\");\n+      igvn->replace_input_of(out, AllocateNode::InlineTypeNode, igvn->C->top());\n+      --i; --imax;\n+    }\n+  }\n+}\n+\n+Node* InlineTypePtrNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  if (can_reshape) {\n+    \/\/ Remove useless InlineTypePtr nodes that might keep other nodes alive\n+    ResourceMark rm;\n+    Unique_Node_List users;\n+    users.push(this);\n+    bool useless = true;\n+    for (uint i = 0; i < users.size(); ++i) {\n+      Node* use = users.at(i);\n+      if (use->is_Cmp() || use->Opcode() == Op_Return || use->Opcode() == Op_CastP2X || (use == this && i != 0) ||\n+          (use->is_Load() && use->outcnt() == 1 && use->unique_out() == this)) {\n+        \/\/ No need to keep track of field values, we can just use the oop\n+        continue;\n+      }\n+      if (use->is_Load() || use->is_Store() || (use->is_InlineTypeBase() && use != this) || use->is_SafePoint()) {\n+        \/\/ We need to keep track of field values to allow the use to be folded\/scalarized\n+        useless = false;\n+        break;\n+      }\n+      for (DUIterator_Fast jmax, j = use->fast_outs(jmax); j < jmax; j++) {\n+        users.push(use->fast_out(j));\n+      }\n+    }\n+    if (useless) {\n+      PhaseIterGVN* igvn = phase->is_IterGVN();\n+      igvn->_worklist.push(this);\n+      igvn->replace_in_uses(this, get_oop());\n+      return NULL;\n+    }\n+  }\n+\n+  return InlineTypeBaseNode::Ideal(phase, can_reshape);\n+}\n","filename":"src\/hotspot\/share\/opto\/inlinetypenode.cpp","additions":968,"deletions":0,"binary":false,"changes":968,"status":"added"},{"patch":"@@ -277,1 +277,1 @@\n-        if (offset == Type::OffsetBot || tptr->_offset == Type::OffsetBot)\n+        if (offset == Type::OffsetBot || tptr->offset() == Type::OffsetBot)\n@@ -279,1 +279,1 @@\n-        offset += tptr->_offset; \/\/ correct if base is offseted\n+        offset += tptr->offset(); \/\/ correct if base is offseted\n@@ -316,1 +316,5 @@\n-      Block *inb = get_block_for_node(mach->in(j));\n+      Block* inb = get_block_for_node(mach->in(j));\n+      if (mach->in(j)->is_Con() && inb == get_block_for_node(mach)) {\n+        \/\/ Ignore constant loads scheduled in the same block (we can simply hoist them as well)\n+        continue;\n+      }\n@@ -392,0 +396,20 @@\n+  } else {\n+    \/\/ Hoist constant load inputs as well.\n+    for (uint i = 1; i < best->req(); ++i) {\n+      Node* n = best->in(i);\n+      if (n->is_Con() && get_block_for_node(n) == get_block_for_node(best)) {\n+        get_block_for_node(n)->find_remove(n);\n+        block->add_inst(n);\n+        map_node_to_block(n, block);\n+        \/\/ Constant loads may kill flags (for example, when XORing a register).\n+        \/\/ Check for flag-killing projections that also need to be hoisted.\n+        for (DUIterator_Fast jmax, j = n->fast_outs(jmax); j < jmax; j++) {\n+          Node* proj = n->fast_out(j);\n+          if (proj->is_MachProj()) {\n+            get_block_for_node(proj)->find_remove(proj);\n+            block->add_inst(proj);\n+            map_node_to_block(proj, block);\n+          }\n+        }\n+      }\n+    }\n@@ -393,0 +417,1 @@\n+\n@@ -846,1 +871,1 @@\n-  uint r_cnt = mcall->tf()->range()->cnt();\n+  uint r_cnt = mcall->tf()->range_cc()->cnt();\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":29,"deletions":4,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -319,0 +320,2 @@\n+  case vmIntrinsics::_makePrivateBuffer:        return inline_unsafe_make_private_buffer();\n+  case vmIntrinsics::_finishPrivateBuffer:      return inline_unsafe_finish_private_buffer();\n@@ -328,0 +331,1 @@\n+  case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_INLINE_TYPE,Relaxed, false);\n@@ -338,0 +342,1 @@\n+  case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_INLINE_TYPE,Relaxed, false);\n@@ -2178,2 +2183,2 @@\n-      assert(rtype == type, \"getter must return the expected value\");\n-      assert(sig->count() == 2, \"oop getter has 2 arguments\");\n+      assert(rtype == type || (rtype == T_OBJECT && type == T_INLINE_TYPE), \"getter must return the expected value\");\n+      assert(sig->count() == 2 || (type == T_INLINE_TYPE && sig->count() == 3), \"oop getter has 2 or 3 arguments\");\n@@ -2185,1 +2190,1 @@\n-      assert(sig->count() == 3, \"oop putter has 3 arguments\");\n+      assert(sig->count() == 3 || (type == T_INLINE_TYPE && sig->count() == 4), \"oop putter has 3 arguments\");\n@@ -2189,1 +2194,1 @@\n-      assert(vtype == type, \"putter must accept the expected value\");\n+      assert(vtype == type || (type == T_INLINE_TYPE && vtype == T_OBJECT), \"putter must accept the expected value\");\n@@ -2211,0 +2216,48 @@\n+\n+  ciInlineKlass* inline_klass = NULL;\n+  if (type == T_INLINE_TYPE) {\n+    const TypeInstPtr* cls = _gvn.type(argument(4))->isa_instptr();\n+    if (cls == NULL || cls->const_oop() == NULL) {\n+      return false;\n+    }\n+    ciType* mirror_type = cls->const_oop()->as_instance()->java_mirror_type();\n+    if (!mirror_type->is_inlinetype()) {\n+      return false;\n+    }\n+    inline_klass = mirror_type->as_inline_klass();\n+  }\n+\n+  if (base->is_InlineType()) {\n+    InlineTypeNode* vt = base->as_InlineType();\n+    if (is_store) {\n+      if (!vt->is_allocated(&_gvn) || !_gvn.type(vt)->is_inlinetype()->larval()) {\n+        return false;\n+      }\n+      base = vt->get_oop();\n+    } else {\n+      if (offset->is_Con()) {\n+        long off = find_long_con(offset, 0);\n+        ciInlineKlass* vk = vt->type()->inline_klass();\n+        if ((long)(int)off != off || !vk->contains_field_offset(off)) {\n+          return false;\n+        }\n+\n+        ciField* field = vk->get_non_flattened_field_by_offset(off);\n+        if (field != NULL) {\n+          BasicType bt = field->layout_type();\n+          if (bt == T_ARRAY || bt == T_NARROWOOP || (bt == T_INLINE_TYPE && !field->is_flattened())) {\n+            bt = T_OBJECT;\n+          }\n+          if (bt == type && (bt != T_INLINE_TYPE || field->type() == inline_klass)) {\n+            set_result(vt->field_value_by_offset(off, false));\n+            return true;\n+          }\n+        }\n+      }\n+      \/\/ Re-execute the unsafe access if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      base = vt->buffer(this)->get_oop();\n+    }\n+  }\n+\n@@ -2221,1 +2274,1 @@\n-    if (type != T_OBJECT) {\n+    if (type != T_OBJECT && (inline_klass == NULL || !inline_klass->has_object_fields())) {\n@@ -2239,1 +2292,1 @@\n-  Node* val = is_store ? argument(4) : NULL;\n+  Node* val = is_store ? argument(4 + (type == T_INLINE_TYPE ? 1 : 0)) : NULL;\n@@ -2260,1 +2313,25 @@\n-  BasicType bt = alias_type->basic_type();\n+  BasicType bt = T_ILLEGAL;\n+  ciField* field = NULL;\n+  if (adr_type->isa_instptr()) {\n+    const TypeInstPtr* instptr = adr_type->is_instptr();\n+    ciInstanceKlass* k = instptr->klass()->as_instance_klass();\n+    int off = instptr->offset();\n+    if (instptr->const_oop() != NULL &&\n+        instptr->klass() == ciEnv::current()->Class_klass() &&\n+        instptr->offset() >= (instptr->klass()->as_instance_klass()->size_helper() * wordSize)) {\n+      k = instptr->const_oop()->as_instance()->java_lang_Class_klass()->as_instance_klass();\n+      field = k->get_field_by_offset(off, true);\n+    } else {\n+      field = k->get_non_flattened_field_by_offset(off);\n+    }\n+    if (field != NULL) {\n+      bt = field->layout_type();\n+    }\n+    assert(bt == alias_type->basic_type() || bt == T_INLINE_TYPE, \"should match\");\n+    if (field != NULL && bt == T_INLINE_TYPE && !field->is_flattened()) {\n+      bt = T_OBJECT;\n+    }\n+  } else {\n+    bt = alias_type->basic_type();\n+  }\n+\n@@ -2283,0 +2360,23 @@\n+  if (type == T_INLINE_TYPE) {\n+    if (adr_type->isa_instptr()) {\n+      if (field == NULL || field->type() != inline_klass) {\n+        mismatched = true;\n+      }\n+    } else if (adr_type->isa_aryptr()) {\n+      const Type* elem = adr_type->is_aryptr()->elem();\n+      if (!elem->isa_inlinetype()) {\n+        mismatched = true;\n+      } else if (elem->inline_klass() != inline_klass) {\n+        mismatched = true;\n+      }\n+    }\n+    if (is_store) {\n+      const Type* val_t = _gvn.type(val);\n+      if (!val_t->isa_inlinetype() || val_t->inline_klass() != inline_klass) {\n+        set_map(old_map);\n+        set_sp(old_sp);\n+        return false;\n+      }\n+    }\n+  }\n+\n@@ -2296,4 +2396,8 @@\n-  if (!is_store && type == T_OBJECT) {\n-    const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);\n-    if (tjp != NULL) {\n-      value_type = tjp;\n+  if (!is_store) {\n+    if (type == T_OBJECT) {\n+      const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);\n+      if (tjp != NULL) {\n+        value_type = tjp;\n+      }\n+    } else if (type == T_INLINE_TYPE) {\n+      value_type = NULL;\n@@ -2315,2 +2419,2 @@\n-    ciField* field = alias_type->field();\n-    if (heap_base_oop != top() && field != NULL && field->is_constant() && !mismatched) {\n+\n+    if (heap_base_oop != top() && field != NULL && field->is_constant() && !field->is_flattened() && !mismatched) {\n@@ -2322,1 +2426,11 @@\n-      p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);\n+      if (type == T_INLINE_TYPE) {\n+        if (adr_type->isa_instptr() && !mismatched) {\n+          ciInstanceKlass* holder = adr_type->is_instptr()->klass()->as_instance_klass();\n+          int offset = adr_type->is_instptr()->offset();\n+          p = InlineTypeNode::make_from_flattened(this, inline_klass, base, base, holder, offset, decorators);\n+        } else {\n+          p = InlineTypeNode::make_from_flattened(this, inline_klass, base, adr, NULL, 0, decorators);\n+        }\n+      } else {\n+        p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);\n+      }\n@@ -2349,0 +2463,8 @@\n+    if (field != NULL && field->type()->is_inlinetype() && !field->is_flattened()) {\n+      \/\/ Load a non-flattened inline type from memory\n+      if (value_type->inline_klass()->is_scalarizable()) {\n+        p = InlineTypeNode::make_from_oop(this, p, value_type->inline_klass());\n+      } else {\n+        p = null2default(p, value_type->inline_klass());\n+      }\n+    }\n@@ -2360,1 +2482,27 @@\n-    access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);\n+    if (type == T_INLINE_TYPE) {\n+      if (adr_type->isa_instptr() && !mismatched) {\n+        ciInstanceKlass* holder = adr_type->is_instptr()->klass()->as_instance_klass();\n+        int offset = adr_type->is_instptr()->offset();\n+        val->as_InlineType()->store_flattened(this, base, base, holder, offset, decorators);\n+      } else {\n+        val->as_InlineType()->store_flattened(this, base, adr, NULL, 0, decorators);\n+      }\n+    } else {\n+      access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);\n+    }\n+  }\n+\n+  if (argument(1)->is_InlineType() && is_store) {\n+    Node* value = InlineTypeNode::make_from_oop(this, base, _gvn.type(base)->inline_klass());\n+    value = value->as_InlineType()->make_larval(this, false);\n+    replace_in_map(argument(1), value);\n+  }\n+\n+  return true;\n+}\n+\n+bool LibraryCallKit::inline_unsafe_make_private_buffer() {\n+  Node* receiver = argument(0);\n+  Node* value = argument(1);\n+  if (!value->is_InlineType()) {\n+    return false;\n@@ -2363,0 +2511,26 @@\n+  receiver = null_check(receiver);\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  set_result(value->as_InlineType()->make_larval(this, true));\n+  return true;\n+}\n+\n+bool LibraryCallKit::inline_unsafe_finish_private_buffer() {\n+  Node* receiver = argument(0);\n+  Node* buffer = argument(1);\n+  if (!buffer->is_InlineType()) {\n+    return false;\n+  }\n+  InlineTypeNode* vt = buffer->as_InlineType();\n+  if (!vt->is_allocated(&_gvn) || !_gvn.type(vt)->is_inlinetype()->larval()) {\n+    return false;\n+  }\n+\n+  receiver = null_check(receiver);\n+  if (stopped()) {\n+    return true;\n+  }\n+\n+  set_result(vt->finish_larval(this));\n@@ -2832,9 +3006,0 @@\n-\/\/---------------------------load_mirror_from_klass----------------------------\n-\/\/ Given a klass oop, load its java mirror (a java.lang.Class oop).\n-Node* LibraryCallKit::load_mirror_from_klass(Node* klass) {\n-  Node* p = basic_plus_adr(klass, in_bytes(Klass::java_mirror_offset()));\n-  Node* load = make_load(NULL, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);\n-  \/\/ mirror = ((OopHandle)mirror)->resolve();\n-  return access_load(load, TypeInstPtr::MIRROR, T_OBJECT, IN_NATIVE);\n-}\n-\n@@ -2883,0 +3048,1 @@\n+\n@@ -2890,0 +3056,4 @@\n+Node* LibraryCallKit::generate_value_guard(Node* kls, RegionNode* region) {\n+  return generate_access_flags_guard(kls, JVM_ACC_INLINE, 0, region);\n+}\n+\n@@ -3087,1 +3257,7 @@\n-  const TypeOopPtr* tp = _gvn.type(obj)->isa_oopptr();\n+  ciKlass* obj_klass = NULL;\n+  const Type* obj_t = _gvn.type(obj);\n+  if (obj->is_InlineType()) {\n+    obj_klass = obj_t->inline_klass();\n+  } else if (obj_t->isa_oopptr()) {\n+    obj_klass = obj_t->is_oopptr()->klass();\n+  }\n@@ -3091,0 +3267,1 @@\n+  bool requires_null_check = false;\n@@ -3092,3 +3269,2 @@\n-  if (tm != NULL && tm->is_klass() &&\n-      tp != NULL && tp->klass() != NULL) {\n-    if (!tp->klass()->is_loaded()) {\n+  if (tm != NULL && tm->is_klass() && obj_klass != NULL) {\n+    if (!obj_klass->is_loaded()) {\n@@ -3098,1 +3274,4 @@\n-      int static_res = C->static_subtype_check(tm->as_klass(), tp->klass());\n+      \/\/ Check for null if casting to .val\n+      requires_null_check = !obj->is_InlineType() && tm->as_klass()->is_inlinetype();\n+\n+      int static_res = C->static_subtype_check(tm->as_klass(), obj_klass);\n@@ -3101,0 +3280,3 @@\n+        if (requires_null_check) {\n+          obj = null_check(obj);\n+        }\n@@ -3121,0 +3303,3 @@\n+  if (requires_null_check) {\n+    obj = null_check(obj);\n+  }\n@@ -3128,1 +3313,1 @@\n-  enum { _bad_type_path = 1, _prim_path = 2, PATH_LIMIT };\n+  enum { _bad_type_path = 1, _prim_path = 2, _npe_path = 3, PATH_LIMIT };\n@@ -3139,0 +3324,19 @@\n+    if (EnableValhalla && !obj->is_InlineType() && !requires_null_check) {\n+      \/\/ Check if we are casting to .val\n+      Node* is_val_kls = generate_value_guard(kls, NULL);\n+      if (is_val_kls != NULL) {\n+        RegionNode* r = new RegionNode(3);\n+        record_for_igvn(r);\n+        r->init_req(1, control());\n+\n+        \/\/ Casting to .val, check for null\n+        set_control(is_val_kls);\n+        Node* null_ctr = top();\n+        null_check_oop(obj, &null_ctr);\n+        region->init_req(_npe_path, null_ctr);\n+        r->init_req(2, control());\n+\n+        set_control(_gvn.transform(r));\n+      }\n+    }\n+\n@@ -3145,1 +3349,2 @@\n-      region->in(_bad_type_path) != top()) {\n+      region->in(_bad_type_path) != top() ||\n+      region->in(_npe_path) != top()) {\n@@ -3182,0 +3387,1 @@\n+  RegionNode* prim_region = new RegionNode(2);\n@@ -3184,0 +3390,1 @@\n+  record_for_igvn(prim_region);\n@@ -3208,2 +3415,5 @@\n-    int prim_path = (which_arg == 0 ? _prim_0_path : _prim_1_path);\n-    region->init_req(prim_path, null_ctl);\n+    if (which_arg == 0) {\n+      prim_region->init_req(1, null_ctl);\n+    } else {\n+      region->init_req(_prim_1_path, null_ctl);\n+    }\n@@ -3226,1 +3436,2 @@\n-  set_control(region->in(_prim_0_path)); \/\/ go back to first null check\n+  \/\/ This path is also used if superc is a value mirror.\n+  set_control(_gvn.transform(prim_region));\n@@ -3231,1 +3442,1 @@\n-    generate_guard(bol_eq, region, PROB_FAIR);\n+    generate_fair_guard(bol_eq, region);\n@@ -3262,2 +3473,1 @@\n-Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region,\n-                                                  bool obj_array, bool not_array) {\n+Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region, ArrayKind kind) {\n@@ -3269,9 +3479,0 @@\n-  \/\/ If obj_array\/non_array==false\/false:\n-  \/\/ Branch around if the given klass is in fact an array (either obj or prim).\n-  \/\/ If obj_array\/non_array==false\/true:\n-  \/\/ Branch around if the given klass is not an array klass of any kind.\n-  \/\/ If obj_array\/non_array==true\/true:\n-  \/\/ Branch around if the kls is not an oop array (kls is int[], String, etc.)\n-  \/\/ If obj_array\/non_array==true\/false:\n-  \/\/ Branch around if the kls is an oop array (Object[] or subtype)\n-  \/\/\n@@ -3282,4 +3483,13 @@\n-    bool query = (obj_array\n-                  ? Klass::layout_helper_is_objArray(layout_con)\n-                  : Klass::layout_helper_is_array(layout_con));\n-    if (query == not_array) {\n+    bool query = 0;\n+    switch(kind) {\n+      case ObjectArray:    query = Klass::layout_helper_is_objArray(layout_con); break;\n+      case NonObjectArray: query = !Klass::layout_helper_is_objArray(layout_con); break;\n+      case TypeArray:      query = Klass::layout_helper_is_typeArray(layout_con); break;\n+      case FlatArray:      query = Klass::layout_helper_is_flatArray(layout_con); break;\n+      case NonFlatArray:   query = !Klass::layout_helper_is_flatArray(layout_con); break;\n+      case AnyArray:       query = Klass::layout_helper_is_array(layout_con); break;\n+      case NonArray:       query = !Klass::layout_helper_is_array(layout_con); break;\n+      default:\n+        ShouldNotReachHere();\n+    }\n+    if (!query) {\n@@ -3295,0 +3505,28 @@\n+  unsigned int value = 0;\n+  BoolTest::mask btest = BoolTest::illegal;\n+  switch(kind) {\n+    case ObjectArray:\n+    case NonObjectArray: {\n+      value = Klass::_lh_array_tag_obj_value;\n+      layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+      btest = (kind == ObjectArray) ? BoolTest::eq : BoolTest::ne;\n+      break;\n+    }\n+    case TypeArray: {\n+      value = Klass::_lh_array_tag_type_value;\n+      layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+      btest = BoolTest::eq;\n+      break;\n+    }\n+    case FlatArray:\n+    case NonFlatArray: {\n+      value = 0;\n+      layout_val = _gvn.transform(new AndINode(layout_val, intcon(Klass::_lh_array_tag_vt_value_bit_inplace)));\n+      btest = (kind == FlatArray) ? BoolTest::ne : BoolTest::eq;\n+      break;\n+    }\n+    case AnyArray:    value = Klass::_lh_neutral_value; btest = BoolTest::lt; break;\n+    case NonArray:    value = Klass::_lh_neutral_value; btest = BoolTest::gt; break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n@@ -3296,4 +3534,1 @@\n-  jint  nval = (obj_array\n-                ? (jint)(Klass::_lh_array_tag_type_value\n-                   <<    Klass::_lh_array_tag_shift)\n-                : Klass::_lh_neutral_value);\n+  jint nval = (jint)value;\n@@ -3301,3 +3536,0 @@\n-  BoolTest::mask btest = BoolTest::lt;  \/\/ correct for testing is_[obj]array\n-  \/\/ invert the test if we are looking for a non-array\n-  if (not_array)  btest = BoolTest(btest).negate();\n@@ -3310,1 +3542,1 @@\n-\/\/ private static native Object java.lang.reflect.newArray(Class<?> componentType, int length);\n+\/\/ private static native Object java.lang.reflect.Array.newArray(Class<?> componentType, int length);\n@@ -3455,1 +3687,13 @@\n-    Node* not_objArray = generate_non_objArray_guard(klass_node, bailout);\n+    \/\/ Inline type array may have object field that would require a\n+    \/\/ write barrier. Conservatively, go to slow path.\n+    \/\/ TODO 8251971: Optimize for the case when flat src\/dst are later found\n+    \/\/ to not contain oops (i.e., move this check to the macro expansion phase).\n+    BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+    const TypeAryPtr* orig_t = _gvn.type(original)->isa_aryptr();\n+    ciKlass* klass = _gvn.type(klass_node)->is_klassptr()->klass();\n+    bool exclude_flat = UseFlatArray && bs->array_copy_requires_gc_barriers(true, T_OBJECT, false, BarrierSetC2::Parsing) &&\n+                        \/\/ Can src array be flat and contain oops?\n+                        (orig_t == NULL || (!orig_t->is_not_flat() && (!orig_t->is_flat() || orig_t->elem()->inline_klass()->contains_oops()))) &&\n+                        \/\/ Can dest array be flat and contain oops?\n+                        klass->can_be_inline_array_klass() && (!klass->is_flat_array_klass() || klass->as_flat_array_klass()->element_klass()->as_inline_klass()->contains_oops());\n+    Node* not_objArray = exclude_flat ? generate_non_objArray_guard(klass_node, bailout) : generate_typeArray_guard(klass_node, bailout);\n@@ -3459,1 +3703,1 @@\n-      const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, 0\/*offset*\/);\n+      const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0));\n@@ -3465,0 +3709,22 @@\n+    Node* original_kls = load_object_klass(original);\n+    \/\/ ArrayCopyNode:Ideal may transform the ArrayCopyNode to\n+    \/\/ loads\/stores but it is legal only if we're sure the\n+    \/\/ Arrays.copyOf would succeed. So we need all input arguments\n+    \/\/ to the copyOf to be validated, including that the copy to the\n+    \/\/ new array won't trigger an ArrayStoreException. That subtype\n+    \/\/ check can be optimized if we know something on the type of\n+    \/\/ the input array from type speculation.\n+    if (_gvn.type(klass_node)->singleton() && !stopped()) {\n+      ciKlass* subk   = _gvn.type(original_kls)->is_klassptr()->klass();\n+      ciKlass* superk = _gvn.type(klass_node)->is_klassptr()->klass();\n+\n+      int test = C->static_subtype_check(superk, subk);\n+      if (test != Compile::SSC_always_true && test != Compile::SSC_always_false) {\n+        const TypeOopPtr* t_original = _gvn.type(original)->is_oopptr();\n+        if (t_original->speculative_type() != NULL) {\n+          original = maybe_cast_profiled_obj(original, t_original->speculative_type(), true);\n+          original_kls = load_object_klass(original);\n+        }\n+      }\n+    }\n+\n@@ -3480,0 +3746,32 @@\n+    \/\/ Handle inline type arrays\n+    bool can_validate = !too_many_traps(Deoptimization::Reason_class_check);\n+    if (!stopped()) {\n+      orig_t = _gvn.type(original)->isa_aryptr();\n+      if (orig_t != NULL && orig_t->is_flat()) {\n+        \/\/ Src is flat, check that dest is flat as well\n+        if (exclude_flat) {\n+          \/\/ Dest can't be flat, bail out\n+          bailout->add_req(control());\n+          set_control(top());\n+        } else {\n+          generate_non_flatArray_guard(klass_node, bailout);\n+        }\n+      } else if (UseFlatArray && (orig_t == NULL || !orig_t->is_not_flat()) &&\n+                 \/\/ If dest is flat, src must be flat as well (guaranteed by src <: dest check if validated).\n+                 ((!klass->is_flat_array_klass() && klass->can_be_inline_array_klass()) || !can_validate)) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat.\n+        generate_flatArray_guard(original_kls, bailout);\n+        if (orig_t != NULL) {\n+          orig_t = orig_t->cast_to_not_flat();\n+          original = _gvn.transform(new CheckCastPPNode(control(), original, orig_t));\n+        }\n+      }\n+      if (!can_validate) {\n+        \/\/ No validation. The subtype check emitted at macro expansion time will not go to the slow\n+        \/\/ path but call checkcast_arraycopy which can not handle flat\/null-free inline type arrays.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat\/null-free.\n+        generate_fair_guard(null_free_array_test(klass_node), bailout);\n+      }\n+    }\n+\n@@ -3499,20 +3797,0 @@\n-      \/\/ ArrayCopyNode:Ideal may transform the ArrayCopyNode to\n-      \/\/ loads\/stores but it is legal only if we're sure the\n-      \/\/ Arrays.copyOf would succeed. So we need all input arguments\n-      \/\/ to the copyOf to be validated, including that the copy to the\n-      \/\/ new array won't trigger an ArrayStoreException. That subtype\n-      \/\/ check can be optimized if we know something on the type of\n-      \/\/ the input array from type speculation.\n-      if (_gvn.type(klass_node)->singleton()) {\n-        ciKlass* subk   = _gvn.type(load_object_klass(original))->is_klassptr()->klass();\n-        ciKlass* superk = _gvn.type(klass_node)->is_klassptr()->klass();\n-\n-        int test = C->static_subtype_check(superk, subk);\n-        if (test != Compile::SSC_always_true && test != Compile::SSC_always_false) {\n-          const TypeOopPtr* t_original = _gvn.type(original)->is_oopptr();\n-          if (t_original->speculative_type() != NULL) {\n-            original = maybe_cast_profiled_obj(original, t_original->speculative_type(), true);\n-          }\n-        }\n-      }\n-\n@@ -3522,1 +3800,1 @@\n-      if (!too_many_traps(Deoptimization::Reason_class_check)) {\n+      if (can_validate) {\n@@ -3539,1 +3817,1 @@\n-                                                load_object_klass(original), klass_node);\n+                                                original_kls, klass_node);\n@@ -3661,1 +3939,6 @@\n-  Node* obj = NULL;\n+  Node* obj = argument(0);\n+\n+  if (obj->is_InlineType() || gvn().type(obj)->is_inlinetypeptr()) {\n+    return false;\n+  }\n+\n@@ -3671,1 +3954,0 @@\n-    obj = argument(0);\n@@ -3711,0 +3993,1 @@\n+  \/\/ This also serves as guard against inline types (they have the always_locked_pattern set).\n@@ -3777,1 +4060,7 @@\n-  Node* obj = null_check_receiver();\n+  Node* obj = argument(0);\n+  if (obj->is_InlineType()) {\n+    ciKlass* vk = _gvn.type(obj)->inline_klass();\n+    set_result(makecon(TypeInstPtr::make(vk->java_mirror())));\n+    return true;\n+  }\n+  obj = null_check_receiver();\n@@ -4039,1 +4328,8 @@\n-  access_clone(obj, alloc_obj, size, is_array);\n+  \/\/ Exclude the header but include array length to copy by 8 bytes words.\n+  \/\/ Can't use base_offset_in_bytes(bt) since basic type is unknown.\n+  int base_off = BarrierSetC2::arraycopy_payload_base_offset(is_array);\n+  Node* countx = size;\n+  countx = _gvn.transform(new SubXNode(countx, MakeConX(base_off)));\n+  countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));\n+\n+  access_clone(obj, alloc_obj, countx, is_array);\n@@ -4082,1 +4378,6 @@\n-    Node* obj = null_check_receiver();\n+    Node* obj = argument(0);\n+    if (obj->is_InlineType()) {\n+      return false;\n+    }\n+\n+    obj = null_check_receiver();\n@@ -4092,1 +4393,2 @@\n-        obj_type->speculative_type()->is_instance_klass()) {\n+        obj_type->speculative_type()->is_instance_klass() &&\n+        !obj_type->speculative_type()->is_inlinetype()) {\n@@ -4124,0 +4426,5 @@\n+    \/\/ We only go to the fast case code if we pass a number of guards.\n+    \/\/ The paths which do not pass are accumulated in the slow_region.\n+    RegionNode* slow_region = new RegionNode(1);\n+    record_for_igvn(slow_region);\n+\n@@ -4129,3 +4436,0 @@\n-      Node* obj_length = load_array_length(obj);\n-      Node* obj_size  = NULL;\n-      Node* alloc_obj = new_array(obj_klass, obj_length, 0, &obj_size, \/*deoptimize_on_exception=*\/true);\n@@ -4134,20 +4438,7 @@\n-      if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing)) {\n-        \/\/ If it is an oop array, it requires very special treatment,\n-        \/\/ because gc barriers are required when accessing the array.\n-        Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);\n-        if (is_obja != NULL) {\n-          PreserveJVMState pjvms2(this);\n-          set_control(is_obja);\n-          \/\/ Generate a direct call to the right arraycopy function(s).\n-          \/\/ Clones are always tightly coupled.\n-          ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n-          ac->set_clone_oop_array();\n-          Node* n = _gvn.transform(ac);\n-          assert(n == ac, \"cannot disappear\");\n-          ac->connect_outputs(this, \/*deoptimize_on_exception=*\/true);\n-\n-          result_reg->init_req(_objArray_path, control());\n-          result_val->init_req(_objArray_path, alloc_obj);\n-          result_i_o ->set_req(_objArray_path, i_o());\n-          result_mem ->set_req(_objArray_path, reset_memory());\n-        }\n+      const TypeAryPtr* ary_ptr = obj_type->isa_aryptr();\n+      if (UseFlatArray && bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing) &&\n+          obj_type->klass()->can_be_inline_array_klass() &&\n+          (ary_ptr == NULL || (!ary_ptr->is_not_flat() && (!ary_ptr->is_flat() || ary_ptr->elem()->inline_klass()->contains_oops())))) {\n+        \/\/ Flattened inline type array may have object field that would require a\n+        \/\/ write barrier. Conservatively, go to slow path.\n+        generate_flatArray_guard(obj_klass, slow_region);\n@@ -4155,7 +4446,0 @@\n-      \/\/ Otherwise, there are no barriers to worry about.\n-      \/\/ (We can dispense with card marks if we know the allocation\n-      \/\/  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks\n-      \/\/  causes the non-eden paths to take compensating steps to\n-      \/\/  simulate a fresh allocation, so that no further\n-      \/\/  card marks are required in compiled code to initialize\n-      \/\/  the object.)\n@@ -4164,7 +4448,43 @@\n-        copy_to_clone(obj, alloc_obj, obj_size, true);\n-\n-        \/\/ Present the results of the copy.\n-        result_reg->init_req(_array_path, control());\n-        result_val->init_req(_array_path, alloc_obj);\n-        result_i_o ->set_req(_array_path, i_o());\n-        result_mem ->set_req(_array_path, reset_memory());\n+        Node* obj_length = load_array_length(obj);\n+        Node* obj_size  = NULL;\n+        Node* alloc_obj = new_array(obj_klass, obj_length, 0, &obj_size, \/*deoptimize_on_exception=*\/true);\n+\n+        BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+        if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing)) {\n+          \/\/ If it is an oop array, it requires very special treatment,\n+          \/\/ because gc barriers are required when accessing the array.\n+          Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);\n+          if (is_obja != NULL) {\n+            PreserveJVMState pjvms2(this);\n+            set_control(is_obja);\n+            \/\/ Generate a direct call to the right arraycopy function(s).\n+            \/\/ Clones are always tightly coupled.\n+            ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n+            ac->set_clone_oop_array();\n+            Node* n = _gvn.transform(ac);\n+            assert(n == ac, \"cannot disappear\");\n+            ac->connect_outputs(this, \/*deoptimize_on_exception=*\/true);\n+\n+            result_reg->init_req(_objArray_path, control());\n+            result_val->init_req(_objArray_path, alloc_obj);\n+            result_i_o ->set_req(_objArray_path, i_o());\n+            result_mem ->set_req(_objArray_path, reset_memory());\n+          }\n+        }\n+        \/\/ Otherwise, there are no barriers to worry about.\n+        \/\/ (We can dispense with card marks if we know the allocation\n+        \/\/  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks\n+        \/\/  causes the non-eden paths to take compensating steps to\n+        \/\/  simulate a fresh allocation, so that no further\n+        \/\/  card marks are required in compiled code to initialize\n+        \/\/  the object.)\n+\n+        if (!stopped()) {\n+          copy_to_clone(obj, alloc_obj, obj_size, true);\n+\n+          \/\/ Present the results of the copy.\n+          result_reg->init_req(_array_path, control());\n+          result_val->init_req(_array_path, alloc_obj);\n+          result_i_o ->set_req(_array_path, i_o());\n+          result_mem ->set_req(_array_path, reset_memory());\n+        }\n@@ -4174,4 +4494,0 @@\n-    \/\/ We only go to the instance fast case code if we pass a number of guards.\n-    \/\/ The paths which do not pass are accumulated in the slow_region.\n-    RegionNode* slow_region = new RegionNode(1);\n-    record_for_igvn(slow_region);\n@@ -4338,2 +4654,1 @@\n-    CallProjections callprojs;\n-    alloc->extract_projections(&callprojs, true);\n+    CallProjections* callprojs = alloc->extract_projections(true);\n@@ -4342,1 +4657,1 @@\n-    C->gvn_replace_by(callprojs.fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n+    C->gvn_replace_by(callprojs->fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n@@ -4354,1 +4669,1 @@\n-    set_i_o(callprojs.fallthrough_ioproj);\n+    set_i_o(callprojs->fallthrough_ioproj);\n@@ -4528,0 +4843,2 @@\n+          src_type = _gvn.type(src);\n+          top_src = src_type->isa_aryptr();\n@@ -4531,0 +4848,2 @@\n+          dest_type = _gvn.type(dest);\n+          top_dest = dest_type->isa_aryptr();\n@@ -4546,2 +4865,1 @@\n-      can_emit_guards &&\n-      !src->is_top() && !dest->is_top()) {\n+      can_emit_guards && !src->is_top() && !dest->is_top()) {\n@@ -4590,0 +4908,2 @@\n+      slow_region->add_req(not_subtype_ctrl);\n+    }\n@@ -4591,6 +4911,28 @@\n-      if (not_subtype_ctrl != top()) {\n-        PreserveJVMState pjvms(this);\n-        set_control(not_subtype_ctrl);\n-        uncommon_trap(Deoptimization::Reason_intrinsic,\n-                      Deoptimization::Action_make_not_entrant);\n-        assert(stopped(), \"Should be stopped\");\n+    const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)->is_klassptr();\n+    const Type* toop = TypeOopPtr::make_from_klass(dest_klass_t->klass());\n+    src = _gvn.transform(new CheckCastPPNode(control(), src, toop));\n+    src_type = _gvn.type(src);\n+    top_src  = src_type->isa_aryptr();\n+\n+    \/\/ Handle flat inline type arrays (null-free arrays are handled by the subtype check above)\n+    if (!stopped() && UseFlatArray) {\n+      \/\/ If dest is flat, src must be flat as well (guaranteed by src <: dest check). Handle flat src here.\n+      assert(top_dest == NULL || !top_dest->is_flat() || top_src->is_flat(), \"src array must be flat\");\n+      if (top_src != NULL && top_src->is_flat()) {\n+        \/\/ Src is flat, check that dest is flat as well\n+        if (top_dest != NULL && !top_dest->is_flat()) {\n+          generate_non_flatArray_guard(dest_klass, slow_region);\n+          \/\/ Since dest is flat and src <: dest, dest must have the same type as src.\n+          top_dest = TypeOopPtr::make_from_klass(top_src->klass())->isa_aryptr();\n+          assert(top_dest->is_flat(), \"dest must be flat\");\n+          dest = _gvn.transform(new CheckCastPPNode(control(), dest, top_dest));\n+        }\n+      } else if (top_src == NULL || !top_src->is_not_flat()) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        \/\/ TODO 8251971: Optimize for the case when src\/dest are later found to be both flat.\n+        assert(top_dest == NULL || !top_dest->is_flat(), \"dest array must not be flat\");\n+        generate_flatArray_guard(load_object_klass(src), slow_region);\n+        if (top_src != NULL) {\n+          top_src = top_src->cast_to_not_flat();\n+          src = _gvn.transform(new CheckCastPPNode(control(), src, top_src));\n+        }\n@@ -4599,0 +4941,1 @@\n+\n@@ -4606,4 +4949,0 @@\n-\n-    const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)->is_klassptr();\n-    const Type *toop = TypeOopPtr::make_from_klass(dest_klass_t->klass());\n-    src = _gvn.transform(new CheckCastPPNode(control(), src, toop));\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":484,"deletions":145,"binary":false,"changes":629,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -108,3 +109,11 @@\n-    if (!stopped() && result() != NULL) {\n-      BasicType bt = result()->bottom_type()->basic_type();\n-      push_node(bt, result());\n+    Node* res = result();\n+    if (!stopped() && res != NULL) {\n+      BasicType bt = res->bottom_type()->basic_type();\n+      if (C->inlining_incrementally() && res->is_InlineType()) {\n+        \/\/ The caller expects an oop when incrementally inlining an intrinsic that returns an\n+        \/\/ inline type. Make sure the call is re-executed if the allocation triggers a deoptimization.\n+        PreserveReexecuteState preexecs(this);\n+        jvms()->set_should_reexecute(true);\n+        res = res->as_InlineType()->buffer(this);\n+      }\n+      push_node(bt, res);\n@@ -138,1 +147,0 @@\n-  Node* load_mirror_from_klass(Node* klass);\n@@ -160,0 +168,12 @@\n+  Node* generate_value_guard(Node* kls, RegionNode* region);\n+\n+  enum ArrayKind {\n+    AnyArray,\n+    NonArray,\n+    ObjectArray,\n+    NonObjectArray,\n+    TypeArray,\n+    FlatArray,\n+    NonFlatArray\n+  };\n+\n@@ -161,0 +181,1 @@\n+\n@@ -162,1 +183,1 @@\n-    return generate_array_guard_common(kls, region, false, false);\n+    return generate_array_guard_common(kls, region, AnyArray);\n@@ -165,1 +186,1 @@\n-    return generate_array_guard_common(kls, region, false, true);\n+    return generate_array_guard_common(kls, region, NonArray);\n@@ -168,1 +189,1 @@\n-    return generate_array_guard_common(kls, region, true, false);\n+    return generate_array_guard_common(kls, region, ObjectArray);\n@@ -171,1 +192,12 @@\n-    return generate_array_guard_common(kls, region, true, true);\n+    return generate_array_guard_common(kls, region, NonObjectArray);\n+  }\n+  Node* generate_typeArray_guard(Node* kls, RegionNode* region) {\n+    return generate_array_guard_common(kls, region, TypeArray);\n+  }\n+  Node* generate_flatArray_guard(Node* kls, RegionNode* region) {\n+    assert(UseFlatArray, \"can never be flattened\");\n+    return generate_array_guard_common(kls, region, FlatArray);\n+  }\n+  Node* generate_non_flatArray_guard(Node* kls, RegionNode* region) {\n+    assert(UseFlatArray, \"can never be flattened\");\n+    return generate_array_guard_common(kls, region, NonFlatArray);\n@@ -173,2 +205,1 @@\n-  Node* generate_array_guard_common(Node* kls, RegionNode* region,\n-                                    bool obj_array, bool not_array);\n+  Node* generate_array_guard_common(Node* kls, RegionNode* region, ArrayKind kind);\n@@ -232,0 +263,2 @@\n+  bool inline_unsafe_make_private_buffer();\n+  bool inline_unsafe_finish_private_buffer();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":43,"deletions":10,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -81,1 +81,2 @@\n-         TransformedLongOuterLoop = 1<<19};\n+         TransformedLongOuterLoop = 1<<19,\n+         FlattenedArrays     = 1<<20};\n@@ -108,0 +109,1 @@\n+  bool is_flattened_arrays() const { return _loop_flags & FlattenedArrays; }\n@@ -124,0 +126,1 @@\n+  void mark_flattened_arrays() { _loop_flags |= FlattenedArrays; }\n@@ -1369,1 +1372,1 @@\n-  IfNode* find_unswitching_candidate(const IdealLoopTree *loop) const;\n+  IfNode* find_unswitching_candidate(const IdealLoopTree *loop, Node_List& unswitch_iffs) const;\n@@ -1490,0 +1493,1 @@\n+  void move_flat_array_check_out_of_loop(Node* n);\n@@ -1491,0 +1495,1 @@\n+  bool flatten_array_element_type_check(Node *n);\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -64,0 +65,6 @@\n+  \/\/ Inline types should not be split through Phis because they cannot be merged\n+  \/\/ through Phi nodes but each value input needs to be merged individually.\n+  if (n->is_InlineType()) {\n+    return NULL;\n+  }\n+\n@@ -969,0 +976,50 @@\n+\/\/ If UseArrayMarkWordCheck is enabled, we can't use immutable memory for the flat array check\n+\/\/ because we are loading the mark word which is mutable. Although the bits we are interested in\n+\/\/ are immutable (we check for markWord::unlocked_value), we need to use raw memory to not break\n+\/\/ anti dependency analysis. Below code will attempt to still move flat array checks out of loops,\n+\/\/ mainly to enable loop unswitching.\n+void PhaseIdealLoop::move_flat_array_check_out_of_loop(Node* n) {\n+  \/\/ Skip checks for more than one array\n+  if (n->req() > 3) {\n+    return;\n+  }\n+  Node* mem = n->in(FlatArrayCheckNode::Memory);\n+  Node* array = n->in(FlatArrayCheckNode::Array)->uncast();\n+  IdealLoopTree* check_loop = get_loop(get_ctrl(n));\n+  IdealLoopTree* ary_loop = get_loop(get_ctrl(array));\n+\n+  \/\/ Check if array is loop invariant\n+  if (!check_loop->is_member(ary_loop)) {\n+    \/\/ Walk up memory graph from the check until we leave the loop\n+    ResourceMark rm;\n+    VectorSet wq;\n+    wq.set(mem->_idx);\n+    while (check_loop->is_member(get_loop(ctrl_or_self(mem)))) {\n+      if (mem->is_Phi()) {\n+        mem = mem->in(1);\n+      } else if (mem->is_MergeMem()) {\n+        mem = mem->as_MergeMem()->memory_at(Compile::AliasIdxRaw);\n+      } else if (mem->is_Proj()) {\n+        mem = mem->in(0);\n+      } else if (mem->is_MemBar() || mem->is_SafePoint()) {\n+        mem = mem->in(TypeFunc::Memory);\n+      } else if (mem->is_Store() || mem->is_LoadStore() || mem->is_ClearArray()) {\n+        mem = mem->in(MemNode::Memory);\n+      } else {\n+#ifdef ASSERT\n+        mem->dump();\n+#endif\n+        ShouldNotReachHere();\n+      }\n+      if (wq.test_set(mem->_idx)) {\n+        return;\n+      }\n+    }\n+    \/\/ Replace memory input and re-compute ctrl to move the check out of the loop\n+    _igvn.replace_input_of(n, 1, mem);\n+    set_ctrl_and_loop(n, get_early_ctrl(n));\n+    Node* bol = n->unique_out();\n+    set_ctrl_and_loop(bol, get_early_ctrl(bol));\n+  }\n+}\n+\n@@ -981,0 +1038,6 @@\n+\n+  if (UseArrayMarkWordCheck && n->isa_FlatArrayCheck()) {\n+    move_flat_array_check_out_of_loop(n);\n+    return n;\n+  }\n+\n@@ -1246,0 +1309,96 @@\n+bool PhaseIdealLoop::flatten_array_element_type_check(Node *n) {\n+  \/\/ If the CmpP is a subtype check for a value that has just been\n+  \/\/ loaded from an array, the subtype check guarantees the value\n+  \/\/ can't be stored in a flattened array and the load of the value\n+  \/\/ happens with a flattened array check then: push the type check\n+  \/\/ through the phi of the flattened array check. This needs special\n+  \/\/ logic because the subtype check's input is not a phi but a\n+  \/\/ LoadKlass that must first be cloned through the phi.\n+  if (n->Opcode() != Op_CmpP) {\n+    return false;\n+  }\n+\n+  Node* klassptr = n->in(1);\n+  Node* klasscon = n->in(2);\n+\n+  if (klassptr->is_DecodeNarrowPtr()) {\n+    klassptr = klassptr->in(1);\n+  }\n+\n+  if (klassptr->Opcode() != Op_LoadKlass && klassptr->Opcode() != Op_LoadNKlass) {\n+    return false;\n+  }\n+\n+  if (!klasscon->is_Con()) {\n+    return false;\n+  }\n+\n+  Node* addr = klassptr->in(MemNode::Address);\n+\n+  if (!addr->is_AddP()) {\n+    return false;\n+  }\n+\n+  intptr_t offset;\n+  Node* obj = AddPNode::Ideal_base_and_offset(addr, &_igvn, offset);\n+\n+  if (obj == NULL) {\n+    return false;\n+  }\n+\n+  assert(obj != NULL && addr->in(AddPNode::Base) == addr->in(AddPNode::Address), \"malformed AddP?\");\n+  if (obj->Opcode() == Op_CastPP) {\n+    obj = obj->in(1);\n+  }\n+\n+  if (!obj->is_Phi()) {\n+    return false;\n+  }\n+\n+  Node* region = obj->in(0);\n+\n+  Node* phi = PhiNode::make_blank(region, n->in(1));\n+  for (uint i = 1; i < region->req(); i++) {\n+    Node* in = obj->in(i);\n+    Node* ctrl = region->in(i);\n+    if (addr->in(AddPNode::Base) != obj) {\n+      Node* cast = addr->in(AddPNode::Base);\n+      assert(cast->Opcode() == Op_CastPP && cast->in(0) != NULL, \"inconsistent subgraph\");\n+      Node* cast_clone = cast->clone();\n+      cast_clone->set_req(0, ctrl);\n+      cast_clone->set_req(1, in);\n+      register_new_node(cast_clone, ctrl);\n+      _igvn.set_type(cast_clone, cast_clone->Value(&_igvn));\n+      in = cast_clone;\n+    }\n+    Node* addr_clone = addr->clone();\n+    addr_clone->set_req(AddPNode::Base, in);\n+    addr_clone->set_req(AddPNode::Address, in);\n+    register_new_node(addr_clone, ctrl);\n+    _igvn.set_type(addr_clone, addr_clone->Value(&_igvn));\n+    Node* klassptr_clone = klassptr->clone();\n+    klassptr_clone->set_req(2, addr_clone);\n+    register_new_node(klassptr_clone, ctrl);\n+    _igvn.set_type(klassptr_clone, klassptr_clone->Value(&_igvn));\n+    if (klassptr != n->in(1)) {\n+      Node* decode = n->in(1);\n+      assert(decode->is_DecodeNarrowPtr(), \"inconsistent subgraph\");\n+      Node* decode_clone = decode->clone();\n+      decode_clone->set_req(1, klassptr_clone);\n+      register_new_node(decode_clone, ctrl);\n+      _igvn.set_type(decode_clone, decode_clone->Value(&_igvn));\n+      klassptr_clone = decode_clone;\n+    }\n+    phi->set_req(i, klassptr_clone);\n+  }\n+  register_new_node(phi, region);\n+  Node* orig = n->in(1);\n+  _igvn.replace_input_of(n, 1, phi);\n+  split_if_with_blocks_post(n);\n+  if (n->outcnt() != 0) {\n+    _igvn.replace_input_of(n, 1, orig);\n+    _igvn.remove_dead_node(phi);\n+  }\n+  return true;\n+}\n+\n@@ -1252,0 +1411,4 @@\n+  if (flatten_array_element_type_check(n)) {\n+    return;\n+  }\n+\n@@ -1528,0 +1691,5 @@\n+  \/\/ Remove multiple allocations of the same inline type\n+  if (n->is_InlineType()) {\n+    n->as_InlineType()->remove_redundant_allocations(&_igvn, this);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":168,"deletions":0,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+class MachVEPNode;\n@@ -489,0 +490,30 @@\n+\/\/------------------------------MachVEPNode-----------------------------------\n+\/\/ Machine Inline Type Entry Point Node\n+class MachVEPNode : public MachIdealNode {\n+public:\n+  Label* _verified_entry;\n+\n+  MachVEPNode(Label* verified_entry, bool verified, bool receiver_only) :\n+    _verified_entry(verified_entry),\n+    _verified(verified),\n+    _receiver_only(receiver_only) {\n+    init_class_id(Class_MachVEP);\n+  }\n+  virtual bool cmp(const Node &n) const {\n+    return (_verified_entry == ((MachVEPNode&)n)._verified_entry) &&\n+           (_verified == ((MachVEPNode&)n)._verified) &&\n+           (_receiver_only == ((MachVEPNode&)n)._receiver_only) &&\n+           MachIdealNode::cmp(n);\n+  }\n+  virtual uint size_of() const { return sizeof(*this); }\n+  virtual void emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const;\n+\n+#ifndef PRODUCT\n+  virtual const char* Name() const { return \"InlineType Entry-Point\"; }\n+  virtual void format(PhaseRegAlloc*, outputStream* st) const;\n+#endif\n+private:\n+  bool   _verified;\n+  bool   _receiver_only;\n+};\n+\n@@ -495,1 +526,0 @@\n-  virtual uint size(PhaseRegAlloc *ra_) const;\n@@ -507,1 +537,9 @@\n-  MachPrologNode( ) {}\n+  Label* _verified_entry;\n+\n+  MachPrologNode(Label* verified_entry) : _verified_entry(verified_entry) {\n+    init_class_id(Class_MachProlog);\n+  }\n+  virtual bool cmp(const Node &n) const {\n+    return (_verified_entry == ((MachPrologNode&)n)._verified_entry) && MachIdealNode::cmp(n);\n+  }\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -509,1 +547,0 @@\n-  virtual uint size(PhaseRegAlloc *ra_) const;\n@@ -524,1 +561,0 @@\n-  virtual uint size(PhaseRegAlloc *ra_) const;\n@@ -918,0 +954,1 @@\n+  bool returns_scalarized() const;\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":41,"deletions":4,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -39,0 +40,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -55,0 +57,1 @@\n+#include \"runtime\/stubRoutines.hpp\"\n@@ -87,12 +90,0 @@\n-void PhaseMacroExpand::migrate_outs(Node *old, Node *target) {\n-  assert(old != NULL, \"sanity\");\n-  for (DUIterator_Fast imax, i = old->fast_outs(imax); i < imax; i++) {\n-    Node* use = old->fast_out(i);\n-    _igvn.rehash_node_delayed(use);\n-    imax -= replace_input(use, old, target);\n-    \/\/ back up iterator\n-    --i;\n-  }\n-  assert(old->outcnt() == 0, \"all uses must be deleted\");\n-}\n-\n@@ -161,1 +152,1 @@\n-  bs->eliminate_gc_barrier(this, p2x);\n+  bs->eliminate_gc_barrier(&_igvn, p2x);\n@@ -210,1 +201,1 @@\n-        int adr_offset = atype->offset();\n+        int adr_offset = atype->flattened_offset();\n@@ -255,1 +246,1 @@\n-   } else if (mem->Opcode() == Op_StrInflatedCopy) {\n+    } else if (mem->Opcode() == Op_StrInflatedCopy) {\n@@ -300,1 +291,7 @@\n-      const TypePtr* adr_type = NULL;\n+      Node* base = ac->in(ArrayCopyNode::Src);\n+      const TypePtr* adr_type = _igvn.type(base)->is_ptr();\n+      assert(adr_type->isa_aryptr(), \"only arrays here\");\n+      if (adr_type->is_aryptr()->is_flat()) {\n+        ciFlatArrayKlass* vak = adr_type->is_aryptr()->klass()->as_flat_array_klass();\n+        shift = vak->log2_element_size();\n+      }\n@@ -303,2 +300,2 @@\n-        Node* base = ac->in(ArrayCopyNode::Src);\n-        adr_type = _igvn.type(base)->is_ptr()->add_offset(off);\n+        adr_type = _igvn.type(adr)->is_ptr();\n+        assert(adr_type == _igvn.type(base)->is_aryptr()->add_field_offset_and_offset(off), \"incorrect address type\");\n@@ -311,0 +308,5 @@\n+        if (ac->in(ArrayCopyNode::Src) == ac->in(ArrayCopyNode::Dest)) {\n+          \/\/ Non constant offset in the array: we can't statically\n+          \/\/ determine the value\n+          return NULL;\n+        }\n@@ -318,7 +320,5 @@\n-        Node* base = ac->in(ArrayCopyNode::Src);\n-        adr_type = _igvn.type(base)->is_ptr()->add_offset(Type::OffsetBot);\n-        if (ac->in(ArrayCopyNode::Src) == ac->in(ArrayCopyNode::Dest)) {\n-          \/\/ Non constant offset in the array: we can't statically\n-          \/\/ determine the value\n-          return NULL;\n-        }\n+        \/\/ In the case of a flattened inline type array, each field has its\n+        \/\/ own slice so we need to extract the field being accessed from\n+        \/\/ the address computation\n+        adr_type = adr_type->is_aryptr()->add_field_offset_and_offset(offset)->add_offset(Type::OffsetBot);\n+        adr = _igvn.transform(new CastPPNode(adr, adr_type));\n@@ -335,0 +335,1 @@\n+      assert(res->isa_DecodeN(), \"should be narrow oop\");\n@@ -350,1 +351,1 @@\n-  int offset = adr_t->offset();\n+  int offset = adr_t->flattened_offset();\n@@ -389,1 +390,7 @@\n-        values.at_put(j, _igvn.zerocon(ft));\n+        Node* default_value = alloc->in(AllocateNode::DefaultValue);\n+        if (default_value != NULL) {\n+          values.at_put(j, default_value);\n+        } else {\n+          assert(alloc->in(AllocateNode::RawDefaultValue) == NULL, \"default value may not be null\");\n+          values.at_put(j, _igvn.zerocon(ft));\n+        }\n@@ -409,1 +416,7 @@\n-        values.at_put(j, _igvn.zerocon(ft));\n+        Node* default_value = alloc->in(AllocateNode::DefaultValue);\n+        if (default_value != NULL) {\n+          values.at_put(j, default_value);\n+        } else {\n+          assert(alloc->in(AllocateNode::RawDefaultValue) == NULL, \"default value may not be null\");\n+          values.at_put(j, _igvn.zerocon(ft));\n+        }\n@@ -453,1 +466,1 @@\n-  int offset = adr_t->offset();\n+  int offset = adr_t->flattened_offset();\n@@ -455,1 +468,0 @@\n-  Node *alloc_ctrl = alloc->in(TypeFunc::Control);\n@@ -471,1 +483,1 @@\n-        done = true; \/\/ Something go wrong.\n+        done = true; \/\/ Something went wrong.\n@@ -481,1 +493,1 @@\n-             atype->is_known_instance_field() && atype->offset() == offset &&\n+             atype->is_known_instance_field() && atype->flattened_offset() == offset &&\n@@ -514,0 +526,5 @@\n+      Node* default_value = alloc->in(AllocateNode::DefaultValue);\n+      if (default_value != NULL) {\n+        return default_value;\n+      }\n+      assert(alloc->in(AllocateNode::RawDefaultValue) == NULL, \"default value may not be null\");\n@@ -545,1 +562,1 @@\n-  \/\/ Something go wrong.\n+  \/\/ Something went wrong.\n@@ -549,0 +566,42 @@\n+\/\/ Search the last value stored into the inline type's fields.\n+Node* PhaseMacroExpand::inline_type_from_mem(Node* mem, Node* ctl, ciInlineKlass* vk, const TypeAryPtr* adr_type, int offset, AllocateNode* alloc) {\n+  \/\/ Subtract the offset of the first field to account for the missing oop header\n+  offset -= vk->first_field_offset();\n+  \/\/ Create a new InlineTypeNode and retrieve the field values from memory\n+  InlineTypeNode* vt = InlineTypeNode::make_uninitialized(_igvn, vk)->as_InlineType();\n+  transform_later(vt);\n+  for (int i = 0; i < vk->nof_declared_nonstatic_fields(); ++i) {\n+    ciType* field_type = vt->field_type(i);\n+    int field_offset = offset + vt->field_offset(i);\n+    Node* value = NULL;\n+    if (vt->field_is_flattened(i)) {\n+      value = inline_type_from_mem(mem, ctl, field_type->as_inline_klass(), adr_type, field_offset, alloc);\n+    } else {\n+      const Type* ft = Type::get_const_type(field_type);\n+      BasicType bt = field_type->basic_type();\n+      if (UseCompressedOops && !is_java_primitive(bt)) {\n+        ft = ft->make_narrowoop();\n+        bt = T_NARROWOOP;\n+      }\n+      \/\/ Each inline type field has its own memory slice\n+      adr_type = adr_type->with_field_offset(field_offset);\n+      value = value_from_mem(mem, ctl, bt, ft, adr_type, alloc);\n+      if (value != NULL && ft->isa_narrowoop()) {\n+        assert(UseCompressedOops, \"unexpected narrow oop\");\n+        if (value->is_EncodeP()) {\n+          value = value->in(1);\n+        } else {\n+          value = transform_later(new DecodeNNode(value, value->get_ptr_type()));\n+        }\n+      }\n+    }\n+    if (value != NULL) {\n+      vt->set_field_value(i, value);\n+    } else {\n+      \/\/ We might have reached the TrackedInitializationLimit\n+      return NULL;\n+    }\n+  }\n+  return vt;\n+}\n+\n@@ -557,0 +616,1 @@\n+  Unique_Node_List worklist;\n@@ -565,0 +625,1 @@\n+    worklist.push(res);\n@@ -578,3 +639,3 @@\n-  if (can_eliminate && res != NULL) {\n-    for (DUIterator_Fast jmax, j = res->fast_outs(jmax);\n-                               j < jmax && can_eliminate; j++) {\n+  while (can_eliminate && worklist.size() > 0) {\n+    res = worklist.pop();\n+    for (DUIterator_Fast jmax, j = res->fast_outs(jmax); j < jmax && can_eliminate; j++) {\n@@ -601,1 +662,1 @@\n-              NOT_PRODUCT(fail_eliminate = \"Not store field referrence\";)\n+              NOT_PRODUCT(fail_eliminate = \"Not store field reference\";)\n@@ -629,0 +690,8 @@\n+      } else if (use->is_InlineType() && use->isa_InlineType()->get_oop() == res) {\n+        \/\/ ok to eliminate\n+      } else if (use->is_InlineTypePtr() && use->isa_InlineTypePtr()->get_oop() == res) {\n+        \/\/ Process users\n+        worklist.push(use);\n+      } else if (use->Opcode() == Op_StoreX && use->in(MemNode::Address) == res) {\n+        \/\/ Store to mark word of inline type larval buffer\n+        assert(res_type->is_inlinetypeptr(), \"Unexpected store to mark word\");\n@@ -640,1 +709,1 @@\n-          }else {\n+          } else {\n@@ -646,0 +715,3 @@\n+      } else {\n+        assert(use->Opcode() == Op_CastP2X, \"should be\");\n+        assert(!use->has_out_with(Op_OrL), \"should have been removed because oop is never null\");\n@@ -658,1 +730,1 @@\n-    } else if (alloc->_is_scalar_replaceable) {\n+    } else {\n@@ -708,0 +780,4 @@\n+      if (elem_type->is_inlinetype() && !klass->is_flat_array_klass()) {\n+        assert(basic_elem_type == T_INLINE_TYPE, \"unexpected element basic type\");\n+        basic_elem_type = T_OBJECT;\n+      }\n@@ -710,0 +786,4 @@\n+      if (klass->is_flat_array_klass()) {\n+        \/\/ Flattened inline type array\n+        element_size = klass->as_flat_array_klass()->element_byte_size();\n+      }\n@@ -715,0 +795,1 @@\n+  Unique_Node_List value_worklist;\n@@ -741,0 +822,1 @@\n+        assert(!field->is_flattened(), \"flattened inline type fields should not have safepoint uses\");\n@@ -768,3 +850,9 @@\n-      const TypeOopPtr *field_addr_type = res_type->add_offset(offset)->isa_oopptr();\n-\n-      Node *field_val = value_from_mem(mem, ctl, basic_elem_type, field_type, field_addr_type, alloc);\n+      Node* field_val = NULL;\n+      const TypeOopPtr* field_addr_type = res_type->add_offset(offset)->isa_oopptr();\n+      if (klass->is_flat_array_klass()) {\n+        ciInlineKlass* vk = elem_type->as_inline_klass();\n+        assert(vk->flatten_array(), \"must be flattened\");\n+        field_val = inline_type_from_mem(mem, ctl, vk, field_addr_type->isa_aryptr(), 0, alloc);\n+      } else {\n+        field_val = value_from_mem(mem, ctl, basic_elem_type, field_type, field_addr_type, alloc);\n+      }\n@@ -833,1 +921,1 @@\n-        } else {\n+        } else if (!field_val->is_InlineTypeBase()) {\n@@ -837,0 +925,4 @@\n+      if (field_val->is_InlineTypeBase()) {\n+        \/\/ Keep track of inline types to scalarize them later\n+        value_worklist.push(field_val);\n+      }\n@@ -849,0 +941,8 @@\n+  \/\/ Scalarize inline types that were added to the safepoint.\n+  \/\/ Don't allow linking a constant oop (if available) for flat array elements\n+  \/\/ because Deoptimization::reassign_flat_array_elements needs field values.\n+  bool allow_oop = (klass == NULL) || !klass->is_flat_array_klass();\n+  for (uint i = 0; i < value_worklist.size(); ++i) {\n+    InlineTypeBaseNode* vt = value_worklist.at(i)->as_InlineTypeBase();\n+    vt->make_scalar_in_safepoints(&_igvn, allow_oop);\n+  }\n@@ -864,1 +964,2 @@\n-void PhaseMacroExpand::process_users_of_allocation(CallNode *alloc) {\n+void PhaseMacroExpand::process_users_of_allocation(CallNode *alloc, bool inline_alloc) {\n+  Unique_Node_List worklist;\n@@ -867,0 +968,4 @@\n+    worklist.push(res);\n+  }\n+  while (worklist.size() > 0) {\n+    res = worklist.pop();\n@@ -876,10 +981,7 @@\n-#ifdef ASSERT\n-            \/\/ Verify that there is no dependent MemBarVolatile nodes,\n-            \/\/ they should be removed during IGVN, see MemBarNode::Ideal().\n-            for (DUIterator_Fast pmax, p = n->fast_outs(pmax);\n-                                       p < pmax; p++) {\n-              Node* mb = n->fast_out(p);\n-              assert(mb->is_Initialize() || !mb->is_MemBar() ||\n-                     mb->req() <= MemBarNode::Precedent ||\n-                     mb->in(MemBarNode::Precedent) != n,\n-                     \"MemBarVolatile should be eliminated for non-escaping object\");\n+            for (DUIterator_Fast pmax, p = n->fast_outs(pmax); p < pmax; p++) {\n+              MemBarNode* mb = n->fast_out(p)->isa_MemBar();\n+              if (mb != NULL && mb->req() <= MemBarNode::Precedent && mb->in(MemBarNode::Precedent) == n) {\n+                \/\/ MemBarVolatiles should have been removed by MemBarNode::Ideal() for non-inline allocations\n+                assert(inline_alloc, \"MemBarVolatile should be eliminated for non-escaping object\");\n+                mb->remove(&_igvn);\n+              }\n@@ -887,1 +989,0 @@\n-#endif\n@@ -911,2 +1012,1 @@\n-          CallProjections callprojs;\n-          ac->extract_projections(&callprojs, true);\n+          CallProjections* callprojs = ac->extract_projections(true);\n@@ -914,3 +1014,3 @@\n-          _igvn.replace_node(callprojs.fallthrough_ioproj, ac->in(TypeFunc::I_O));\n-          _igvn.replace_node(callprojs.fallthrough_memproj, ac->in(TypeFunc::Memory));\n-          _igvn.replace_node(callprojs.fallthrough_catchproj, ac->in(TypeFunc::Control));\n+          _igvn.replace_node(callprojs->fallthrough_ioproj, ac->in(TypeFunc::I_O));\n+          _igvn.replace_node(callprojs->fallthrough_memproj, ac->in(TypeFunc::Memory));\n+          _igvn.replace_node(callprojs->fallthrough_catchproj, ac->in(TypeFunc::Control));\n@@ -933,0 +1033,14 @@\n+      } else if (use->is_InlineType()) {\n+        assert(use->isa_InlineType()->get_oop() == res, \"unexpected inline type use\");\n+        _igvn.rehash_node_delayed(use);\n+        use->isa_InlineType()->set_oop(_igvn.zerocon(T_INLINE_TYPE));\n+      } else if (use->is_InlineTypePtr()) {\n+        assert(use->isa_InlineTypePtr()->get_oop() == res, \"unexpected inline type ptr use\");\n+        _igvn.rehash_node_delayed(use);\n+        use->isa_InlineTypePtr()->set_oop(_igvn.zerocon(T_INLINE_TYPE));\n+        \/\/ Process users\n+        worklist.push(use);\n+      } else if (use->Opcode() == Op_StoreX && use->in(MemNode::Address) == res) {\n+        \/\/ Store to mark word of inline type larval buffer\n+        assert(inline_alloc, \"Unexpected store to mark word\");\n+        _igvn.replace_node(use, use->in(MemNode::Memory));\n@@ -945,1 +1059,1 @@\n-  if (_callprojs.resproj != NULL && _callprojs.resproj->outcnt() != 0) {\n+  if (_callprojs->resproj[0] != NULL && _callprojs->resproj[0]->outcnt() != 0) {\n@@ -949,2 +1063,2 @@\n-    for (DUIterator_Fast jmax, j = _callprojs.resproj->fast_outs(jmax);  j < jmax; j++) {\n-      Node* use = _callprojs.resproj->fast_out(j);\n+    for (DUIterator_Fast jmax, j = _callprojs->resproj[0]->fast_outs(jmax);  j < jmax; j++) {\n+      Node* use = _callprojs->resproj[0]->fast_out(j);\n@@ -957,3 +1071,3 @@\n-    for (DUIterator_Last jmin, j = _callprojs.resproj->last_outs(jmin); j >= jmin; ) {\n-      Node* use = _callprojs.resproj->last_out(j);\n-      uint oc1 = _callprojs.resproj->outcnt();\n+    for (DUIterator_Last jmin, j = _callprojs->resproj[0]->last_outs(jmin); j >= jmin; ) {\n+      Node* use = _callprojs->resproj[0]->last_out(j);\n+      uint oc1 = _callprojs->resproj[0]->outcnt();\n@@ -966,0 +1080,5 @@\n+          \/\/ Inline type buffer allocations are followed by a membar\n+          Node* membar_after = ctrl_proj->unique_ctrl_out();\n+          if (inline_alloc && membar_after->Opcode() == Op_MemBarCPUOrder) {\n+            membar_after->as_MemBar()->remove(&_igvn);\n+          }\n@@ -969,1 +1088,1 @@\n-          assert(tmp == _callprojs.fallthrough_catchproj, \"allocation control projection\");\n+          assert(tmp == _callprojs->fallthrough_catchproj, \"allocation control projection\");\n@@ -977,1 +1096,1 @@\n-            assert(mem->in(TypeFunc::Memory) == _callprojs.fallthrough_memproj, \"allocation memory projection\");\n+            assert(mem->in(TypeFunc::Memory) == _callprojs->fallthrough_memproj, \"allocation memory projection\");\n@@ -979,1 +1098,1 @@\n-            assert(mem == _callprojs.fallthrough_memproj, \"allocation memory projection\");\n+            assert(mem == _callprojs->fallthrough_memproj, \"allocation memory projection\");\n@@ -984,0 +1103,4 @@\n+      } else if (use->Opcode() == Op_MemBarStoreStore) {\n+        \/\/ Inline type buffer allocations are followed by a membar\n+        assert(inline_alloc, \"Unexpected MemBarStoreStore\");\n+        use->as_MemBar()->remove(&_igvn);\n@@ -987,1 +1110,1 @@\n-      j -= (oc1 - _callprojs.resproj->outcnt());\n+      j -= (oc1 - _callprojs->resproj[0]->outcnt());\n@@ -990,2 +1113,2 @@\n-  if (_callprojs.fallthrough_catchproj != NULL) {\n-    _igvn.replace_node(_callprojs.fallthrough_catchproj, alloc->in(TypeFunc::Control));\n+  if (_callprojs->fallthrough_catchproj != NULL) {\n+    _igvn.replace_node(_callprojs->fallthrough_catchproj, alloc->in(TypeFunc::Control));\n@@ -993,2 +1116,2 @@\n-  if (_callprojs.fallthrough_memproj != NULL) {\n-    _igvn.replace_node(_callprojs.fallthrough_memproj, alloc->in(TypeFunc::Memory));\n+  if (_callprojs->fallthrough_memproj != NULL) {\n+    _igvn.replace_node(_callprojs->fallthrough_memproj, alloc->in(TypeFunc::Memory));\n@@ -996,2 +1119,2 @@\n-  if (_callprojs.catchall_memproj != NULL) {\n-    _igvn.replace_node(_callprojs.catchall_memproj, C->top());\n+  if (_callprojs->catchall_memproj != NULL) {\n+    _igvn.replace_node(_callprojs->catchall_memproj, C->top());\n@@ -999,2 +1122,2 @@\n-  if (_callprojs.fallthrough_ioproj != NULL) {\n-    _igvn.replace_node(_callprojs.fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n+  if (_callprojs->fallthrough_ioproj != NULL) {\n+    _igvn.replace_node(_callprojs->fallthrough_ioproj, alloc->in(TypeFunc::I_O));\n@@ -1002,2 +1125,2 @@\n-  if (_callprojs.catchall_ioproj != NULL) {\n-    _igvn.replace_node(_callprojs.catchall_ioproj, C->top());\n+  if (_callprojs->catchall_ioproj != NULL) {\n+    _igvn.replace_node(_callprojs->catchall_ioproj, C->top());\n@@ -1005,2 +1128,2 @@\n-  if (_callprojs.catchall_catchproj != NULL) {\n-    _igvn.replace_node(_callprojs.catchall_catchproj, C->top());\n+  if (_callprojs->catchall_catchproj != NULL) {\n+    _igvn.replace_node(_callprojs->catchall_catchproj, C->top());\n@@ -1016,1 +1139,1 @@\n-  if (!EliminateAllocations || !alloc->_is_non_escaping) {\n+  if (!EliminateAllocations) {\n@@ -1021,1 +1144,7 @@\n-  Node* res = alloc->result_cast();\n+\n+  \/\/ Attempt to eliminate inline type buffer allocations\n+  \/\/ regardless of usage and escape\/replaceable status.\n+  bool inline_alloc = tklass->klass()->is_inlinetype();\n+  if (!alloc->_is_non_escaping && !inline_alloc) {\n+    return false;\n+  }\n@@ -1023,3 +1152,4 @@\n-  \/\/ regardless scalar replacable status.\n-  bool boxing_alloc = C->eliminate_boxing() &&\n-                      tklass->klass()->is_instance_klass()  &&\n+  \/\/ regardless of scalar replaceable status.\n+  Node* res = alloc->result_cast();\n+  bool boxing_alloc = (res == NULL) && C->eliminate_boxing() &&\n+                      tklass->klass()->is_instance_klass() &&\n@@ -1027,1 +1157,1 @@\n-  if (!alloc->_is_scalar_replaceable && (!boxing_alloc || (res != NULL))) {\n+  if (!alloc->_is_scalar_replaceable && !boxing_alloc && !inline_alloc) {\n@@ -1031,1 +1161,1 @@\n-  alloc->extract_projections(&_callprojs, false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n+  _callprojs = alloc->extract_projections(false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n@@ -1039,1 +1169,1 @@\n-    assert(res == NULL, \"sanity\");\n+    assert(res == NULL || inline_alloc, \"sanity\");\n@@ -1044,0 +1174,1 @@\n+      assert(!inline_alloc || !tklass->klass()->as_inline_klass()->is_scalarizable(), \"Scalarizable inline type allocations should not have safepoint uses\");\n@@ -1064,1 +1195,1 @@\n-  process_users_of_allocation(alloc);\n+  process_users_of_allocation(alloc, inline_alloc);\n@@ -1086,1 +1217,1 @@\n-  boxing->extract_projections(&_callprojs, false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n+  _callprojs = boxing->extract_projections(false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n@@ -1088,1 +1219,1 @@\n-  const TypeTuple* r = boxing->tf()->range();\n+  const TypeTuple* r = boxing->tf()->range_sig();\n@@ -1289,1 +1420,1 @@\n-    IfNode *toobig_iff = new IfNode(ctrl, initial_slow_test, PROB_MIN, COUNT_UNKNOWN);\n+    IfNode* toobig_iff = new IfNode(ctrl, initial_slow_test, PROB_MIN, COUNT_UNKNOWN);\n@@ -1292,1 +1423,1 @@\n-    Node *toobig_true = new IfTrueNode( toobig_iff );\n+    Node* toobig_true = new IfTrueNode(toobig_iff);\n@@ -1295,1 +1426,1 @@\n-    toobig_false = new IfFalseNode( toobig_iff );\n+    toobig_false = new IfFalseNode(toobig_iff);\n@@ -1334,0 +1465,1 @@\n+\n@@ -1391,0 +1523,3 @@\n+  } else {\n+    \/\/ Let the runtime know if this is a larval allocation\n+    call->init_req(TypeFunc::Parms+1, _igvn.intcon(alloc->_larval));\n@@ -1416,1 +1551,1 @@\n-  call->extract_projections(&_callprojs, false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n+  _callprojs = call->extract_projections(false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n@@ -1422,2 +1557,2 @@\n-  if (expand_fast_path && _callprojs.fallthrough_memproj != NULL) {\n-    migrate_outs(_callprojs.fallthrough_memproj, result_phi_rawmem);\n+  if (expand_fast_path && _callprojs->fallthrough_memproj != NULL) {\n+    _igvn.replace_in_uses(_callprojs->fallthrough_memproj, result_phi_rawmem);\n@@ -1427,4 +1562,4 @@\n-  if (_callprojs.catchall_memproj != NULL ) {\n-    if (_callprojs.fallthrough_memproj == NULL) {\n-      _callprojs.fallthrough_memproj = new ProjNode(call, TypeFunc::Memory);\n-      transform_later(_callprojs.fallthrough_memproj);\n+  if (_callprojs->catchall_memproj != NULL) {\n+    if (_callprojs->fallthrough_memproj == NULL) {\n+      _callprojs->fallthrough_memproj = new ProjNode(call, TypeFunc::Memory);\n+      transform_later(_callprojs->fallthrough_memproj);\n@@ -1432,2 +1567,2 @@\n-    migrate_outs(_callprojs.catchall_memproj, _callprojs.fallthrough_memproj);\n-    _igvn.remove_dead_node(_callprojs.catchall_memproj);\n+    _igvn.replace_in_uses(_callprojs->catchall_memproj, _callprojs->fallthrough_memproj);\n+    _igvn.remove_dead_node(_callprojs->catchall_memproj);\n@@ -1441,2 +1576,2 @@\n-  if (_callprojs.fallthrough_ioproj != NULL) {\n-    migrate_outs(_callprojs.fallthrough_ioproj, result_phi_i_o);\n+  if (_callprojs->fallthrough_ioproj != NULL) {\n+    _igvn.replace_in_uses(_callprojs->fallthrough_ioproj, result_phi_i_o);\n@@ -1446,4 +1581,4 @@\n-  if (_callprojs.catchall_ioproj != NULL ) {\n-    if (_callprojs.fallthrough_ioproj == NULL) {\n-      _callprojs.fallthrough_ioproj = new ProjNode(call, TypeFunc::I_O);\n-      transform_later(_callprojs.fallthrough_ioproj);\n+  if (_callprojs->catchall_ioproj != NULL) {\n+    if (_callprojs->fallthrough_ioproj == NULL) {\n+      _callprojs->fallthrough_ioproj = new ProjNode(call, TypeFunc::I_O);\n+      transform_later(_callprojs->fallthrough_ioproj);\n@@ -1451,2 +1586,2 @@\n-    migrate_outs(_callprojs.catchall_ioproj, _callprojs.fallthrough_ioproj);\n-    _igvn.remove_dead_node(_callprojs.catchall_ioproj);\n+    _igvn.replace_in_uses(_callprojs->catchall_ioproj, _callprojs->fallthrough_ioproj);\n+    _igvn.remove_dead_node(_callprojs->catchall_ioproj);\n@@ -1471,2 +1606,2 @@\n-  if (_callprojs.fallthrough_catchproj != NULL) {\n-    ctrl = _callprojs.fallthrough_catchproj->clone();\n+  if (_callprojs->fallthrough_catchproj != NULL) {\n+    ctrl = _callprojs->fallthrough_catchproj->clone();\n@@ -1474,1 +1609,1 @@\n-    _igvn.replace_node(_callprojs.fallthrough_catchproj, result_region);\n+    _igvn.replace_node(_callprojs->fallthrough_catchproj, result_region);\n@@ -1479,1 +1614,1 @@\n-  if (_callprojs.resproj == NULL) {\n+  if (_callprojs->resproj[0] == NULL) {\n@@ -1483,1 +1618,1 @@\n-    slow_result = _callprojs.resproj->clone();\n+    slow_result = _callprojs->resproj[0]->clone();\n@@ -1485,1 +1620,1 @@\n-    _igvn.replace_node(_callprojs.resproj, result_phi_rawoop);\n+    _igvn.replace_node(_callprojs->resproj[0], result_phi_rawoop);\n@@ -1495,1 +1630,1 @@\n-  result_phi_rawmem->init_req(slow_result_path, _callprojs.fallthrough_memproj);\n+  result_phi_rawmem->init_req(slow_result_path, _callprojs->fallthrough_memproj);\n@@ -1507,4 +1642,4 @@\n-  alloc->extract_projections(&_callprojs, false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n-  if (_callprojs.resproj != NULL) {\n-    for (DUIterator_Fast imax, i = _callprojs.resproj->fast_outs(imax); i < imax; i++) {\n-      Node* use = _callprojs.resproj->fast_out(i);\n+  _callprojs = alloc->extract_projections(false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n+  if (_callprojs->resproj[0] != NULL) {\n+    for (DUIterator_Fast imax, i = _callprojs->resproj[0]->fast_outs(imax); i < imax; i++) {\n+      Node* use = _callprojs->resproj[0]->fast_out(i);\n@@ -1515,2 +1650,2 @@\n-    assert(_callprojs.resproj->outcnt() == 0, \"all uses must be deleted\");\n-    _igvn.remove_dead_node(_callprojs.resproj);\n+    assert(_callprojs->resproj[0]->outcnt() == 0, \"all uses must be deleted\");\n+    _igvn.remove_dead_node(_callprojs->resproj[0]);\n@@ -1518,3 +1653,3 @@\n-  if (_callprojs.fallthrough_catchproj != NULL) {\n-    migrate_outs(_callprojs.fallthrough_catchproj, ctrl);\n-    _igvn.remove_dead_node(_callprojs.fallthrough_catchproj);\n+  if (_callprojs->fallthrough_catchproj != NULL) {\n+    _igvn.replace_in_uses(_callprojs->fallthrough_catchproj, ctrl);\n+    _igvn.remove_dead_node(_callprojs->fallthrough_catchproj);\n@@ -1522,3 +1657,3 @@\n-  if (_callprojs.catchall_catchproj != NULL) {\n-    _igvn.rehash_node_delayed(_callprojs.catchall_catchproj);\n-    _callprojs.catchall_catchproj->set_req(0, top());\n+  if (_callprojs->catchall_catchproj != NULL) {\n+    _igvn.rehash_node_delayed(_callprojs->catchall_catchproj);\n+    _callprojs->catchall_catchproj->set_req(0, top());\n@@ -1526,2 +1661,2 @@\n-  if (_callprojs.fallthrough_proj != NULL) {\n-    Node* catchnode = _callprojs.fallthrough_proj->unique_ctrl_out();\n+  if (_callprojs->fallthrough_proj != NULL) {\n+    Node* catchnode = _callprojs->fallthrough_proj->unique_ctrl_out();\n@@ -1529,1 +1664,1 @@\n-    _igvn.remove_dead_node(_callprojs.fallthrough_proj);\n+    _igvn.remove_dead_node(_callprojs->fallthrough_proj);\n@@ -1531,3 +1666,3 @@\n-  if (_callprojs.fallthrough_memproj != NULL) {\n-    migrate_outs(_callprojs.fallthrough_memproj, mem);\n-    _igvn.remove_dead_node(_callprojs.fallthrough_memproj);\n+  if (_callprojs->fallthrough_memproj != NULL) {\n+    _igvn.replace_in_uses(_callprojs->fallthrough_memproj, mem);\n+    _igvn.remove_dead_node(_callprojs->fallthrough_memproj);\n@@ -1535,3 +1670,3 @@\n-  if (_callprojs.fallthrough_ioproj != NULL) {\n-    migrate_outs(_callprojs.fallthrough_ioproj, i_o);\n-    _igvn.remove_dead_node(_callprojs.fallthrough_ioproj);\n+  if (_callprojs->fallthrough_ioproj != NULL) {\n+    _igvn.replace_in_uses(_callprojs->fallthrough_ioproj, i_o);\n+    _igvn.remove_dead_node(_callprojs->fallthrough_ioproj);\n@@ -1539,3 +1674,3 @@\n-  if (_callprojs.catchall_memproj != NULL) {\n-    _igvn.rehash_node_delayed(_callprojs.catchall_memproj);\n-    _callprojs.catchall_memproj->set_req(0, top());\n+  if (_callprojs->catchall_memproj != NULL) {\n+    _igvn.rehash_node_delayed(_callprojs->catchall_memproj);\n+    _callprojs->catchall_memproj->set_req(0, top());\n@@ -1543,3 +1678,3 @@\n-  if (_callprojs.catchall_ioproj != NULL) {\n-    _igvn.rehash_node_delayed(_callprojs.catchall_ioproj);\n-    _callprojs.catchall_ioproj->set_req(0, top());\n+  if (_callprojs->catchall_ioproj != NULL) {\n+    _igvn.rehash_node_delayed(_callprojs->catchall_ioproj);\n+    _callprojs->catchall_ioproj->set_req(0, top());\n@@ -1662,5 +1797,4 @@\n-Node*\n-PhaseMacroExpand::initialize_object(AllocateNode* alloc,\n-                                    Node* control, Node* rawmem, Node* object,\n-                                    Node* klass_node, Node* length,\n-                                    Node* size_in_bytes) {\n+Node* PhaseMacroExpand::initialize_object(AllocateNode* alloc,\n+                                          Node* control, Node* rawmem, Node* object,\n+                                          Node* klass_node, Node* length,\n+                                          Node* size_in_bytes) {\n@@ -1669,1 +1803,1 @@\n-  Node* mark_node = alloc->make_ideal_mark(&_igvn, object, control, rawmem);\n+  Node* mark_node = alloc->make_ideal_mark(&_igvn, control, rawmem);\n@@ -1701,0 +1835,2 @@\n+                                            alloc->in(AllocateNode::DefaultValue),\n+                                            alloc->in(AllocateNode::RawDefaultValue),\n@@ -2069,0 +2205,43 @@\n+void PhaseMacroExpand::inline_type_guard(Node** ctrl, LockNode* lock) {\n+  Node* obj = lock->obj_node();\n+  const TypePtr* obj_type = _igvn.type(obj)->make_ptr();\n+  if (!obj_type->can_be_inline_type()) {\n+    return;\n+  }\n+  Node* mark = make_load(*ctrl, lock->memory(), obj, oopDesc::mark_offset_in_bytes(), TypeX_X, TypeX_X->basic_type());\n+  Node* value_mask = _igvn.MakeConX(markWord::inline_type_pattern);\n+  Node* is_value = _igvn.transform(new AndXNode(mark, value_mask));\n+  Node* cmp = _igvn.transform(new CmpXNode(is_value, value_mask));\n+  Node* bol = _igvn.transform(new BoolNode(cmp, BoolTest::eq));\n+  Node* unc_ctrl = generate_slow_guard(ctrl, bol, NULL);\n+\n+  int trap_request = Deoptimization::make_trap_request(Deoptimization::Reason_class_check, Deoptimization::Action_none);\n+  address call_addr = SharedRuntime::uncommon_trap_blob()->entry_point();\n+  const TypePtr* no_memory_effects = NULL;\n+  CallNode* unc = new CallStaticJavaNode(OptoRuntime::uncommon_trap_Type(), call_addr, \"uncommon_trap\",\n+                                         no_memory_effects);\n+  unc->init_req(TypeFunc::Control, unc_ctrl);\n+  unc->init_req(TypeFunc::I_O, lock->i_o());\n+  unc->init_req(TypeFunc::Memory, lock->memory());\n+  unc->init_req(TypeFunc::FramePtr,  lock->in(TypeFunc::FramePtr));\n+  unc->init_req(TypeFunc::ReturnAdr, lock->in(TypeFunc::ReturnAdr));\n+  unc->init_req(TypeFunc::Parms+0, _igvn.intcon(trap_request));\n+  unc->set_cnt(PROB_UNLIKELY_MAG(4));\n+  unc->copy_call_debug_info(&_igvn, lock);\n+\n+  assert(unc->peek_monitor_box() == lock->box_node(), \"wrong monitor\");\n+  assert((obj_type->is_inlinetypeptr() && unc->peek_monitor_obj()->is_SafePointScalarObject()) ||\n+         (obj->is_InlineTypePtr() && obj->in(1) == unc->peek_monitor_obj()) ||\n+         (obj == unc->peek_monitor_obj()), \"wrong monitor\");\n+\n+  \/\/ pop monitor and push obj back on stack: we trap before the monitorenter\n+  unc->pop_monitor();\n+  unc->grow_stack(unc->jvms(), 1);\n+  unc->set_stack(unc->jvms(), unc->jvms()->stk_size()-1, obj);\n+  _igvn.register_new_node_with_optimizer(unc);\n+\n+  unc_ctrl = _igvn.transform(new ProjNode(unc, TypeFunc::Control));\n+  Node* halt = _igvn.transform(new HaltNode(unc_ctrl, lock->in(TypeFunc::FramePtr), \"monitor enter on inline type\"));\n+  C->root()->add_req(halt);\n+}\n+\n@@ -2104,1 +2283,1 @@\n-  alock->extract_projections(&_callprojs, false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n+  _callprojs = alock->extract_projections(false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n@@ -2108,2 +2287,2 @@\n-         _callprojs.fallthrough_proj != NULL &&\n-         _callprojs.fallthrough_memproj != NULL,\n+         _callprojs->fallthrough_proj != NULL &&\n+         _callprojs->fallthrough_memproj != NULL,\n@@ -2112,2 +2291,2 @@\n-  Node* fallthroughproj = _callprojs.fallthrough_proj;\n-  Node* memproj_fallthrough = _callprojs.fallthrough_memproj;\n+  Node* fallthroughproj = _callprojs->fallthrough_proj;\n+  Node* memproj_fallthrough = _callprojs->fallthrough_memproj;\n@@ -2119,0 +2298,3 @@\n+    \/\/ Deoptimize and re-execute if object is an inline type\n+    inline_type_guard(&ctrl, alock->as_Lock());\n+\n@@ -2362,0 +2544,3 @@\n+  \/\/ Deoptimize and re-execute if object is an inline type\n+  inline_type_guard(&slow_path, lock);\n+\n@@ -2367,1 +2552,1 @@\n-  call->extract_projections(&_callprojs, false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n+  _callprojs = call->extract_projections(false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n@@ -2373,2 +2558,2 @@\n-  assert(_callprojs.fallthrough_ioproj == NULL && _callprojs.catchall_ioproj == NULL &&\n-         _callprojs.catchall_memproj == NULL && _callprojs.catchall_catchproj == NULL, \"Unexpected projection from Lock\");\n+  assert(_callprojs->fallthrough_ioproj == NULL && _callprojs->catchall_ioproj == NULL &&\n+         _callprojs->catchall_memproj == NULL && _callprojs->catchall_catchproj == NULL, \"Unexpected projection from Lock\");\n@@ -2379,1 +2564,1 @@\n-  Node *slow_ctrl = _callprojs.fallthrough_proj->clone();\n+  Node *slow_ctrl = _callprojs->fallthrough_proj->clone();\n@@ -2381,2 +2566,2 @@\n-  _igvn.hash_delete(_callprojs.fallthrough_proj);\n-  _callprojs.fallthrough_proj->disconnect_inputs(C);\n+  _igvn.hash_delete(_callprojs->fallthrough_proj);\n+  _callprojs->fallthrough_proj->disconnect_inputs(C);\n@@ -2386,1 +2571,1 @@\n-  _igvn.replace_node(_callprojs.fallthrough_proj, region);\n+  _igvn.replace_node(_callprojs->fallthrough_proj, region);\n@@ -2391,1 +2576,1 @@\n-  _igvn.replace_node(_callprojs.fallthrough_memproj, mem_phi);\n+  _igvn.replace_node(_callprojs->fallthrough_memproj, mem_phi);\n@@ -2438,3 +2623,3 @@\n-  call->extract_projections(&_callprojs, false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n-  assert(_callprojs.fallthrough_ioproj == NULL && _callprojs.catchall_ioproj == NULL &&\n-         _callprojs.catchall_memproj == NULL && _callprojs.catchall_catchproj == NULL, \"Unexpected projection from Lock\");\n+  _callprojs = call->extract_projections(false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n+  assert(_callprojs->fallthrough_ioproj == NULL && _callprojs->catchall_ioproj == NULL &&\n+         _callprojs->catchall_memproj == NULL && _callprojs->catchall_catchproj == NULL, \"Unexpected projection from Lock\");\n@@ -2446,1 +2631,1 @@\n-  Node *slow_ctrl = _callprojs.fallthrough_proj->clone();\n+  Node *slow_ctrl = _callprojs->fallthrough_proj->clone();\n@@ -2448,2 +2633,2 @@\n-  _igvn.hash_delete(_callprojs.fallthrough_proj);\n-  _callprojs.fallthrough_proj->disconnect_inputs(C);\n+  _igvn.hash_delete(_callprojs->fallthrough_proj);\n+  _callprojs->fallthrough_proj->disconnect_inputs(C);\n@@ -2453,1 +2638,1 @@\n-  _igvn.replace_node(_callprojs.fallthrough_proj, region);\n+  _igvn.replace_node(_callprojs->fallthrough_proj, region);\n@@ -2459,1 +2644,1 @@\n-  _igvn.replace_node(_callprojs.fallthrough_memproj, mem_phi);\n+  _igvn.replace_node(_callprojs->fallthrough_memproj, mem_phi);\n@@ -2462,0 +2647,197 @@\n+\/\/ An inline type might be returned from the call but we don't know its\n+\/\/ type. Either we get a buffered inline type (and nothing needs to be done)\n+\/\/ or one of the inlines being returned is the klass of the inline type\n+\/\/ and we need to allocate an inline type instance of that type and\n+\/\/ initialize it with other values being returned. In that case, we\n+\/\/ first try a fast path allocation and initialize the value with the\n+\/\/ inline klass's pack handler or we fall back to a runtime call.\n+void PhaseMacroExpand::expand_mh_intrinsic_return(CallStaticJavaNode* call) {\n+  assert(call->method()->is_method_handle_intrinsic(), \"must be a method handle intrinsic call\");\n+  Node* ret = call->proj_out_or_null(TypeFunc::Parms);\n+  if (ret == NULL) {\n+    return;\n+  }\n+  const TypeFunc* tf = call->_tf;\n+  const TypeTuple* domain = OptoRuntime::store_inline_type_fields_Type()->domain_cc();\n+  const TypeFunc* new_tf = TypeFunc::make(tf->domain_sig(), tf->domain_cc(), tf->range_sig(), domain);\n+  call->_tf = new_tf;\n+  \/\/ Make sure the change of type is applied before projections are processed by igvn\n+  _igvn.set_type(call, call->Value(&_igvn));\n+  _igvn.set_type(ret, ret->Value(&_igvn));\n+\n+  \/\/ Before any new projection is added:\n+  CallProjections* projs = call->extract_projections(true, true);\n+\n+  \/\/ Create temporary hook nodes that will be replaced below.\n+  \/\/ Add an input to prevent hook nodes from being dead.\n+  Node* ctl = new Node(call);\n+  Node* mem = new Node(ctl);\n+  Node* io = new Node(ctl);\n+  Node* ex_ctl = new Node(ctl);\n+  Node* ex_mem = new Node(ctl);\n+  Node* ex_io = new Node(ctl);\n+  Node* res = new Node(ctl);\n+\n+  \/\/ Allocate a new buffered inline type only if a new one is not returned\n+  Node* cast = transform_later(new CastP2XNode(ctl, res));\n+  Node* mask = MakeConX(0x1);\n+  Node* masked = transform_later(new AndXNode(cast, mask));\n+  Node* cmp = transform_later(new CmpXNode(masked, mask));\n+  Node* bol = transform_later(new BoolNode(cmp, BoolTest::eq));\n+  IfNode* allocation_iff = new IfNode(ctl, bol, PROB_MAX, COUNT_UNKNOWN);\n+  transform_later(allocation_iff);\n+  Node* allocation_ctl = transform_later(new IfTrueNode(allocation_iff));\n+  Node* no_allocation_ctl = transform_later(new IfFalseNode(allocation_iff));\n+  Node* no_allocation_res = transform_later(new CheckCastPPNode(no_allocation_ctl, res, TypeInstPtr::BOTTOM));\n+\n+  \/\/ Try to allocate a new buffered inline instance either from TLAB or eden space\n+  Node* needgc_ctrl = NULL; \/\/ needgc means slowcase, i.e. allocation failed\n+  CallLeafNoFPNode* handler_call;\n+  const bool alloc_in_place = (UseTLAB || Universe::heap()->supports_inline_contig_alloc());\n+  if (alloc_in_place) {\n+    Node* fast_oop_ctrl = NULL;\n+    Node* fast_oop_rawmem = NULL;\n+    Node* mask2 = MakeConX(-2);\n+    Node* masked2 = transform_later(new AndXNode(cast, mask2));\n+    Node* rawklassptr = transform_later(new CastX2PNode(masked2));\n+    Node* klass_node = transform_later(new CheckCastPPNode(allocation_ctl, rawklassptr, TypeKlassPtr::OBJECT_OR_NULL));\n+    Node* layout_val = make_load(NULL, mem, klass_node, in_bytes(Klass::layout_helper_offset()), TypeInt::INT, T_INT);\n+    Node* size_in_bytes = ConvI2X(layout_val);\n+    BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+    Node* fast_oop = bs->obj_allocate(this, allocation_ctl, mem, allocation_ctl, size_in_bytes, io, needgc_ctrl,\n+                                      fast_oop_ctrl, fast_oop_rawmem,\n+                                      AllocateInstancePrefetchLines);\n+    \/\/ Allocation succeed, initialize buffered inline instance header firstly,\n+    \/\/ and then initialize its fields with an inline class specific handler\n+    Node* mark_node = makecon(TypeRawPtr::make((address)markWord::inline_type_prototype().value()));\n+    fast_oop_rawmem = make_store(fast_oop_ctrl, fast_oop_rawmem, fast_oop, oopDesc::mark_offset_in_bytes(), mark_node, T_ADDRESS);\n+    fast_oop_rawmem = make_store(fast_oop_ctrl, fast_oop_rawmem, fast_oop, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);\n+    if (UseCompressedClassPointers) {\n+      fast_oop_rawmem = make_store(fast_oop_ctrl, fast_oop_rawmem, fast_oop, oopDesc::klass_gap_offset_in_bytes(), intcon(0), T_INT);\n+    }\n+    Node* fixed_block  = make_load(fast_oop_ctrl, fast_oop_rawmem, klass_node, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset()), TypeRawPtr::BOTTOM, T_ADDRESS);\n+    Node* pack_handler = make_load(fast_oop_ctrl, fast_oop_rawmem, fixed_block, in_bytes(InlineKlass::pack_handler_offset()), TypeRawPtr::BOTTOM, T_ADDRESS);\n+    handler_call = new CallLeafNoFPNode(OptoRuntime::pack_inline_type_Type(),\n+                                        NULL,\n+                                        \"pack handler\",\n+                                        TypeRawPtr::BOTTOM);\n+    handler_call->init_req(TypeFunc::Control, fast_oop_ctrl);\n+    handler_call->init_req(TypeFunc::Memory, fast_oop_rawmem);\n+    handler_call->init_req(TypeFunc::I_O, top());\n+    handler_call->init_req(TypeFunc::FramePtr, call->in(TypeFunc::FramePtr));\n+    handler_call->init_req(TypeFunc::ReturnAdr, top());\n+    handler_call->init_req(TypeFunc::Parms, pack_handler);\n+    handler_call->init_req(TypeFunc::Parms+1, fast_oop);\n+  } else {\n+    needgc_ctrl = allocation_ctl;\n+  }\n+\n+  \/\/ Allocation failed, fall back to a runtime call\n+  CallStaticJavaNode* slow_call = new CallStaticJavaNode(OptoRuntime::store_inline_type_fields_Type(),\n+                                                         StubRoutines::store_inline_type_fields_to_buf(),\n+                                                         \"store_inline_type_fields\",\n+                                                         TypePtr::BOTTOM);\n+  slow_call->init_req(TypeFunc::Control, needgc_ctrl);\n+  slow_call->init_req(TypeFunc::Memory, mem);\n+  slow_call->init_req(TypeFunc::I_O, io);\n+  slow_call->init_req(TypeFunc::FramePtr, call->in(TypeFunc::FramePtr));\n+  slow_call->init_req(TypeFunc::ReturnAdr, call->in(TypeFunc::ReturnAdr));\n+  slow_call->init_req(TypeFunc::Parms, res);\n+\n+  Node* slow_ctl = transform_later(new ProjNode(slow_call, TypeFunc::Control));\n+  Node* slow_mem = transform_later(new ProjNode(slow_call, TypeFunc::Memory));\n+  Node* slow_io = transform_later(new ProjNode(slow_call, TypeFunc::I_O));\n+  Node* slow_res = transform_later(new ProjNode(slow_call, TypeFunc::Parms));\n+  Node* slow_catc = transform_later(new CatchNode(slow_ctl, slow_io, 2));\n+  Node* slow_norm = transform_later(new CatchProjNode(slow_catc, CatchProjNode::fall_through_index, CatchProjNode::no_handler_bci));\n+  Node* slow_excp = transform_later(new CatchProjNode(slow_catc, CatchProjNode::catch_all_index,    CatchProjNode::no_handler_bci));\n+\n+  Node* ex_r = new RegionNode(3);\n+  Node* ex_mem_phi = new PhiNode(ex_r, Type::MEMORY, TypePtr::BOTTOM);\n+  Node* ex_io_phi = new PhiNode(ex_r, Type::ABIO);\n+  ex_r->init_req(1, slow_excp);\n+  ex_mem_phi->init_req(1, slow_mem);\n+  ex_io_phi->init_req(1, slow_io);\n+  ex_r->init_req(2, ex_ctl);\n+  ex_mem_phi->init_req(2, ex_mem);\n+  ex_io_phi->init_req(2, ex_io);\n+  transform_later(ex_r);\n+  transform_later(ex_mem_phi);\n+  transform_later(ex_io_phi);\n+\n+  \/\/ We don't know how many values are returned. This assumes the\n+  \/\/ worst case, that all available registers are used.\n+  for (uint i = TypeFunc::Parms+1; i < domain->cnt(); i++) {\n+    if (domain->field_at(i) == Type::HALF) {\n+      slow_call->init_req(i, top());\n+      if (alloc_in_place) {\n+        handler_call->init_req(i+1, top());\n+      }\n+      continue;\n+    }\n+    Node* proj = transform_later(new ProjNode(call, i));\n+    slow_call->init_req(i, proj);\n+    if (alloc_in_place) {\n+      handler_call->init_req(i+1, proj);\n+    }\n+  }\n+  \/\/ We can safepoint at that new call\n+  slow_call->copy_call_debug_info(&_igvn, call);\n+  transform_later(slow_call);\n+  if (alloc_in_place) {\n+    transform_later(handler_call);\n+  }\n+\n+  Node* fast_ctl = NULL;\n+  Node* fast_res = NULL;\n+  MergeMemNode* fast_mem = NULL;\n+  if (alloc_in_place) {\n+    fast_ctl = transform_later(new ProjNode(handler_call, TypeFunc::Control));\n+    Node* rawmem = transform_later(new ProjNode(handler_call, TypeFunc::Memory));\n+    fast_res = transform_later(new ProjNode(handler_call, TypeFunc::Parms));\n+    fast_mem = MergeMemNode::make(mem);\n+    fast_mem->set_memory_at(Compile::AliasIdxRaw, rawmem);\n+    transform_later(fast_mem);\n+  }\n+\n+  Node* r = new RegionNode(alloc_in_place ? 4 : 3);\n+  Node* mem_phi = new PhiNode(r, Type::MEMORY, TypePtr::BOTTOM);\n+  Node* io_phi = new PhiNode(r, Type::ABIO);\n+  Node* res_phi = new PhiNode(r, TypeInstPtr::BOTTOM);\n+  r->init_req(1, no_allocation_ctl);\n+  mem_phi->init_req(1, mem);\n+  io_phi->init_req(1, io);\n+  res_phi->init_req(1, no_allocation_res);\n+  r->init_req(2, slow_norm);\n+  mem_phi->init_req(2, slow_mem);\n+  io_phi->init_req(2, slow_io);\n+  res_phi->init_req(2, slow_res);\n+  if (alloc_in_place) {\n+    r->init_req(3, fast_ctl);\n+    mem_phi->init_req(3, fast_mem);\n+    io_phi->init_req(3, io);\n+    res_phi->init_req(3, fast_res);\n+  }\n+  transform_later(r);\n+  transform_later(mem_phi);\n+  transform_later(io_phi);\n+  transform_later(res_phi);\n+\n+  assert(projs->nb_resproj == 1, \"unexpected number of results\");\n+  _igvn.replace_in_uses(projs->fallthrough_catchproj, r);\n+  _igvn.replace_in_uses(projs->fallthrough_memproj, mem_phi);\n+  _igvn.replace_in_uses(projs->fallthrough_ioproj, io_phi);\n+  _igvn.replace_in_uses(projs->resproj[0], res_phi);\n+  _igvn.replace_in_uses(projs->catchall_catchproj, ex_r);\n+  _igvn.replace_in_uses(projs->catchall_memproj, ex_mem_phi);\n+  _igvn.replace_in_uses(projs->catchall_ioproj, ex_io_phi);\n+\n+  _igvn.replace_node(ctl, projs->fallthrough_catchproj);\n+  _igvn.replace_node(mem, projs->fallthrough_memproj);\n+  _igvn.replace_node(io, projs->fallthrough_ioproj);\n+  _igvn.replace_node(res, projs->resproj[0]);\n+  _igvn.replace_node(ex_ctl, projs->catchall_catchproj);\n+  _igvn.replace_node(ex_mem, projs->catchall_memproj);\n+  _igvn.replace_node(ex_io, projs->catchall_ioproj);\n+ }\n+\n@@ -2487,1 +2869,1 @@\n-      subklass = _igvn.transform(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), k_adr, TypeInstPtr::KLASS));\n+      subklass = _igvn.transform(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n@@ -2499,0 +2881,96 @@\n+\/\/ FlatArrayCheckNode (array1 array2 ...) is expanded into:\n+\/\/\n+\/\/ long mark = array1.mark | array2.mark | ...;\n+\/\/ long locked_bit = markWord::unlocked_value & array1.mark & array2.mark & ...;\n+\/\/ if (locked_bit == 0) {\n+\/\/   \/\/ One array is locked, load prototype header from the klass\n+\/\/   mark = array1.klass.proto | array2.klass.proto | ...\n+\/\/ }\n+\/\/ if ((mark & markWord::flat_array_bit_in_place) == 0) {\n+\/\/    ...\n+\/\/ }\n+void PhaseMacroExpand::expand_flatarraycheck_node(FlatArrayCheckNode* check) {\n+  if (UseArrayMarkWordCheck) {\n+    Node* mark = MakeConX(0);\n+    Node* locked_bit = MakeConX(markWord::unlocked_value);\n+    Node* mem = check->in(FlatArrayCheckNode::Memory);\n+    for (uint i = FlatArrayCheckNode::Array; i < check->req(); ++i) {\n+      Node* ary = check->in(i);\n+      if (ary->is_top()) continue;\n+      const TypeAryPtr* t = _igvn.type(ary)->isa_aryptr();\n+      assert(!t->is_flat() && !t->is_not_flat(), \"Should have been optimized out\");\n+      Node* mark_adr = basic_plus_adr(ary, oopDesc::mark_offset_in_bytes());\n+      Node* mark_load = _igvn.transform(LoadNode::make(_igvn, NULL, mem, mark_adr, mark_adr->bottom_type()->is_ptr(), TypeX_X, TypeX_X->basic_type(), MemNode::unordered));\n+      mark = _igvn.transform(new OrXNode(mark, mark_load));\n+      locked_bit = _igvn.transform(new AndXNode(locked_bit, mark_load));\n+    }\n+    assert(!mark->is_Con(), \"Should have been optimized out\");\n+    Node* cmp = _igvn.transform(new CmpXNode(locked_bit, MakeConX(0)));\n+    Node* is_unlocked = _igvn.transform(new BoolNode(cmp, BoolTest::ne));\n+\n+    \/\/ BoolNode might be shared, replace each if user\n+    Node* old_bol = check->unique_out();\n+    assert(old_bol->is_Bool() && old_bol->as_Bool()->_test._test == BoolTest::ne, \"unexpected condition\");\n+    for (DUIterator_Last imin, i = old_bol->last_outs(imin); i >= imin; --i) {\n+      IfNode* old_iff = old_bol->last_out(i)->as_If();\n+      Node* ctrl = old_iff->in(0);\n+      RegionNode* region = new RegionNode(3);\n+      Node* mark_phi = new PhiNode(region, TypeX_X);\n+\n+      \/\/ Check if array is unlocked\n+      IfNode* iff = _igvn.transform(new IfNode(ctrl, is_unlocked, PROB_MAX, COUNT_UNKNOWN))->as_If();\n+\n+      \/\/ Unlocked: Use bits from mark word\n+      region->init_req(1, _igvn.transform(new IfTrueNode(iff)));\n+      mark_phi->init_req(1, mark);\n+\n+      \/\/ Locked: Load prototype header from klass\n+      ctrl = _igvn.transform(new IfFalseNode(iff));\n+      Node* proto = MakeConX(0);\n+      for (uint i = FlatArrayCheckNode::Array; i < check->req(); ++i) {\n+        Node* ary = check->in(i);\n+        if (ary->is_top()) continue;\n+        \/\/ Make loads control dependent to make sure they are only executed if array is locked\n+        Node* klass_adr = basic_plus_adr(ary, oopDesc::klass_offset_in_bytes());\n+        Node* klass = _igvn.transform(LoadKlassNode::make(_igvn, ctrl, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+        Node* proto_adr = basic_plus_adr(klass, in_bytes(Klass::prototype_header_offset()));\n+        Node* proto_load = _igvn.transform(LoadNode::make(_igvn, ctrl, C->immutable_memory(), proto_adr, proto_adr->bottom_type()->is_ptr(), TypeX_X, TypeX_X->basic_type(), MemNode::unordered));\n+        proto = _igvn.transform(new OrXNode(proto, proto_load));\n+      }\n+      region->init_req(2, ctrl);\n+      mark_phi->init_req(2, proto);\n+\n+      \/\/ Check if flat array bits are set\n+      Node* mask = MakeConX(markWord::flat_array_bit_in_place);\n+      Node* masked = _igvn.transform(new AndXNode(_igvn.transform(mark_phi), mask));\n+      cmp = _igvn.transform(new CmpXNode(masked, MakeConX(0)));\n+      Node* is_not_flat = _igvn.transform(new BoolNode(cmp, BoolTest::eq));\n+\n+      ctrl = _igvn.transform(region);\n+      iff = _igvn.transform(new IfNode(ctrl, is_not_flat, PROB_MAX, COUNT_UNKNOWN))->as_If();\n+      _igvn.replace_node(old_iff, iff);\n+    }\n+    _igvn.replace_node(check, C->top());\n+  } else {\n+    \/\/ Fall back to layout helper check\n+    Node* lhs = intcon(0);\n+    for (uint i = FlatArrayCheckNode::Array; i < check->req(); ++i) {\n+      Node* ary = check->in(i);\n+      if (ary->is_top()) continue;\n+      const TypeAryPtr* t = _igvn.type(ary)->isa_aryptr();\n+      assert(!t->is_flat() && !t->is_not_flat(), \"Should have been optimized out\");\n+      Node* klass_adr = basic_plus_adr(ary, oopDesc::klass_offset_in_bytes());\n+      Node* klass = transform_later(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+      Node* lh_addr = basic_plus_adr(klass, in_bytes(Klass::layout_helper_offset()));\n+      Node* lh_val = _igvn.transform(LoadNode::make(_igvn, NULL, C->immutable_memory(), lh_addr, lh_addr->bottom_type()->is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));\n+      lhs = _igvn.transform(new OrINode(lhs, lh_val));\n+    }\n+    Node* masked = transform_later(new AndINode(lhs, intcon(Klass::_lh_array_tag_vt_value_bit_inplace)));\n+    Node* cmp = transform_later(new CmpINode(masked, intcon(0)));\n+    Node* bol = transform_later(new BoolNode(cmp, BoolTest::eq));\n+    Node* old_bol = check->unique_out();\n+    _igvn.replace_node(old_bol, bol);\n+    _igvn.replace_node(check, C->top());\n+  }\n+}\n+\n@@ -2543,2 +3021,5 @@\n-      case Node::Class_CallStaticJava:\n-        success = eliminate_boxing_node(n->as_CallStaticJava());\n+      case Node::Class_CallStaticJava: {\n+        CallStaticJavaNode* call = n->as_CallStaticJava();\n+        if (!call->method()->is_method_handle_intrinsic()) {\n+          success = eliminate_boxing_node(n->as_CallStaticJava());\n+        }\n@@ -2546,0 +3027,1 @@\n+      }\n@@ -2559,0 +3041,2 @@\n+      case Node::Class_FlatArrayCheck:\n+        break;\n@@ -2592,4 +3076,7 @@\n-        \/\/ Remove it from macro list and put on IGVN worklist to optimize.\n-        C->remove_macro_node(n);\n-        _igvn._worklist.push(n);\n-        success = true;\n+        CallStaticJavaNode* call = n->as_CallStaticJava();\n+        if (!call->method()->is_method_handle_intrinsic()) {\n+          \/\/ Remove it from macro list and put on IGVN worklist to optimize.\n+          C->remove_macro_node(n);\n+          _igvn._worklist.push(n);\n+          success = true;\n+        }\n@@ -2685,0 +3172,7 @@\n+    case Node::Class_CallStaticJava:\n+      expand_mh_intrinsic_return(n->as_CallStaticJava());\n+      C->remove_macro_node(n);\n+      break;\n+    case Node::Class_FlatArrayCheck:\n+      expand_flatarraycheck_node(n->as_FlatArrayCheck());\n+      break;\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":675,"deletions":181,"binary":false,"changes":856,"status":"modified"},{"patch":"@@ -85,1 +85,1 @@\n-  CallProjections _callprojs;\n+  CallProjections* _callprojs;\n@@ -100,0 +100,1 @@\n+  Node* inline_type_from_mem(Node* mem, Node* ctl, ciInlineKlass* vk, const TypeAryPtr* adr_type, int offset, AllocateNode* alloc);\n@@ -105,1 +106,1 @@\n-  void process_users_of_allocation(CallNode *alloc);\n+  void process_users_of_allocation(CallNode *alloc, bool inline_alloc = false);\n@@ -112,0 +113,1 @@\n+  void inline_type_guard(Node** ctrl, LockNode* lock);\n@@ -113,0 +115,1 @@\n+  void expand_mh_intrinsic_return(CallStaticJavaNode* call);\n@@ -122,0 +125,1 @@\n+  Node* generate_fair_guard(Node** ctrl, Node* test, RegionNode* region);\n@@ -132,0 +136,5 @@\n+  Node* array_lh_test(Node* array, jint mask);\n+  Node* generate_flat_array_guard(Node** ctrl, Node* array, RegionNode* region);\n+  Node* generate_null_free_array_guard(Node** ctrl, Node* array, RegionNode* region);\n+  Node* generate_array_guard(Node** ctrl, Node* mem, Node* obj, RegionNode* region, jint lh_con);\n+\n@@ -141,0 +150,1 @@\n+                           Node* dest_length,\n@@ -147,0 +157,2 @@\n+                            Node* val,\n+                            Node* raw_val,\n@@ -182,1 +194,3 @@\n-\n+  const TypePtr* adjust_for_flat_array(const TypeAryPtr* top_dest, Node*& src_offset,\n+                                       Node*& dest_offset, Node*& length, BasicType& dest_elem,\n+                                       Node*& dest_length);\n@@ -187,0 +201,2 @@\n+  void expand_flatarraycheck_node(FlatArrayCheckNode* check);\n+\n@@ -188,2 +204,0 @@\n-  void migrate_outs(Node *old, Node *target);\n-  void copy_call_debug_info(CallNode *oldcall, CallNode * newcall);\n@@ -203,0 +217,2 @@\n+  bool can_try_zeroing_elimination(AllocateArrayNode* alloc, Node* src, Node* dest) const;\n+\n","filename":"src\/hotspot\/share\/opto\/macro.hpp","additions":21,"deletions":5,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -141,1 +142,1 @@\n-inline Node* PhaseMacroExpand::generate_slow_guard(Node** ctrl, Node* test, RegionNode* region) {\n+Node* PhaseMacroExpand::generate_slow_guard(Node** ctrl, Node* test, RegionNode* region) {\n@@ -145,0 +146,4 @@\n+inline Node* PhaseMacroExpand::generate_fair_guard(Node** ctrl, Node* test, RegionNode* region) {\n+  return generate_guard(ctrl, test, region, PROB_FAIR);\n+}\n+\n@@ -282,0 +287,40 @@\n+Node* PhaseMacroExpand::array_lh_test(Node* array, jint mask) {\n+  Node* klass_adr = basic_plus_adr(array, oopDesc::klass_offset_in_bytes());\n+  Node* klass = transform_later(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+  Node* lh_addr = basic_plus_adr(klass, in_bytes(Klass::layout_helper_offset()));\n+  Node* lh_val = _igvn.transform(LoadNode::make(_igvn, NULL, C->immutable_memory(), lh_addr, lh_addr->bottom_type()->is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));\n+  Node* masked = transform_later(new AndINode(lh_val, intcon(mask)));\n+  Node* cmp = transform_later(new CmpINode(masked, intcon(0)));\n+  return transform_later(new BoolNode(cmp, BoolTest::ne));\n+}\n+\n+Node* PhaseMacroExpand::generate_flat_array_guard(Node** ctrl, Node* array, RegionNode* region) {\n+  assert(UseFlatArray, \"can never be flattened\");\n+  return generate_fair_guard(ctrl, array_lh_test(array, Klass::_lh_array_tag_vt_value_bit_inplace), region);\n+}\n+\n+Node* PhaseMacroExpand::generate_null_free_array_guard(Node** ctrl, Node* array, RegionNode* region) {\n+  assert(EnableValhalla, \"can never be null free\");\n+  return generate_fair_guard(ctrl, array_lh_test(array, Klass::_lh_null_free_bit_inplace), region);\n+}\n+\n+Node* PhaseMacroExpand::generate_array_guard(Node** ctrl, Node* mem, Node* obj_or_klass, RegionNode* region, jint lh_con) {\n+  if ((*ctrl)->is_top())  return NULL;\n+\n+  Node* kls = NULL;\n+  if (_igvn.type(obj_or_klass)->isa_oopptr()) {\n+    Node* k_adr = basic_plus_adr(obj_or_klass, oopDesc::klass_offset_in_bytes());\n+    kls = transform_later(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+  } else {\n+    assert(_igvn.type(obj_or_klass)->isa_klassptr(), \"what else?\");\n+    kls = obj_or_klass;\n+  }\n+  Node* layout_val = make_load(NULL, mem, kls, in_bytes(Klass::layout_helper_offset()), TypeInt::INT, T_INT);\n+\n+  layout_val = transform_later(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));\n+  Node* cmp = transform_later(new CmpINode(layout_val, intcon(lh_con)));\n+  Node* bol = transform_later(new BoolNode(cmp, BoolTest::eq));\n+\n+  return generate_fair_guard(ctrl, bol, region);\n+}\n+\n@@ -334,0 +379,19 @@\n+bool PhaseMacroExpand::can_try_zeroing_elimination(AllocateArrayNode* alloc,\n+                                                   Node* src,\n+                                                   Node* dest) const {\n+  const TypeAryPtr* top_dest = _igvn.type(dest)->isa_aryptr();\n+\n+  if (top_dest != NULL) {\n+    if (top_dest->klass() == NULL) {\n+      return false;\n+    }\n+  }\n+\n+  return ReduceBulkZeroing\n+    && !(UseTLAB && ZeroTLAB) \/\/ pointless if already zeroed\n+    && !src->eqv_uncast(dest)\n+    && alloc != NULL\n+    && _igvn.find_int_con(alloc->in(AllocateNode::ALength), 1) > 0\n+    && alloc->maybe_set_complete(&_igvn);\n+}\n+\n@@ -376,0 +440,1 @@\n+                                           Node* dest_length,\n@@ -387,0 +452,2 @@\n+  Node* default_value = NULL;\n+  Node* raw_default_value = NULL;\n@@ -417,0 +484,2 @@\n+      default_value = alloc->in(AllocateNode::DefaultValue);\n+      raw_default_value = alloc->in(AllocateNode::RawDefaultValue);\n@@ -486,1 +555,0 @@\n-      Node* dest_length = alloc->in(AllocateNode::ALength);\n@@ -493,1 +561,3 @@\n-                             adr_type, dest, basic_elem_type,\n+                             adr_type, dest,\n+                             default_value, raw_default_value,\n+                             basic_elem_type,\n@@ -524,1 +594,0 @@\n-    Node* dest_length = alloc->in(AllocateNode::ALength);\n@@ -530,1 +599,3 @@\n-                           adr_type, dest, basic_elem_type,\n+                           adr_type, dest,\n+                           default_value, raw_default_value,\n+                           basic_elem_type,\n@@ -579,1 +650,3 @@\n-                             adr_type, dest, basic_elem_type,\n+                             adr_type, dest,\n+                             default_value, raw_default_value,\n+                             basic_elem_type,\n@@ -589,1 +662,3 @@\n-                             adr_type, dest, basic_elem_type,\n+                             adr_type, dest,\n+                             default_value, raw_default_value,\n+                             basic_elem_type,\n@@ -767,1 +842,3 @@\n-                           adr_type, dest, basic_elem_type,\n+                           adr_type, dest,\n+                           default_value, raw_default_value,\n+                           basic_elem_type,\n@@ -820,0 +897,4 @@\n+    \/\/ Do not let reads from the destination float above the arraycopy.\n+    \/\/ Since we cannot type the arrays, we don't know which slices\n+    \/\/ might be affected.  We could restrict this barrier only to those\n+    \/\/ memory slices which pertain to array elements--but don't bother.\n@@ -829,3 +910,3 @@\n-  _igvn.replace_node(_callprojs.fallthrough_memproj, out_mem);\n-  _igvn.replace_node(_callprojs.fallthrough_ioproj, *io);\n-  _igvn.replace_node(_callprojs.fallthrough_catchproj, *ctrl);\n+  _igvn.replace_node(_callprojs->fallthrough_memproj, out_mem);\n+  _igvn.replace_node(_callprojs->fallthrough_ioproj, *io);\n+  _igvn.replace_node(_callprojs->fallthrough_catchproj, *ctrl);\n@@ -871,0 +952,2 @@\n+                                            Node* val,\n+                                            Node* raw_val,\n@@ -886,0 +969,1 @@\n+  assert(basic_elem_type != T_INLINE_TYPE, \"should have been converted to a basic type copy\");\n@@ -909,1 +993,1 @@\n-    mem = ClearArrayNode::clear_memory(ctrl, mem, dest,\n+    mem = ClearArrayNode::clear_memory(ctrl, mem, dest, val, raw_val,\n@@ -914,1 +998,1 @@\n-    mem = ClearArrayNode::clear_memory(ctrl, mem, dest,\n+    mem = ClearArrayNode::clear_memory(ctrl, mem, dest, val, raw_val,\n@@ -927,1 +1011,1 @@\n-    mem = ClearArrayNode::clear_memory(ctrl, mem, dest,\n+    mem = ClearArrayNode::clear_memory(ctrl, mem, dest, val, raw_val,\n@@ -956,1 +1040,7 @@\n-        mem = StoreNode::make(_igvn, ctrl, mem, p1, adr_type, intcon(0), T_INT, MemNode::unordered);\n+        if (val == NULL) {\n+          assert(raw_val == NULL, \"val may not be null\");\n+          mem = StoreNode::make(_igvn, ctrl, mem, p1, adr_type, intcon(0), T_INT, MemNode::unordered);\n+        } else {\n+          assert(_igvn.type(val)->isa_narrowoop(), \"should be narrow oop\");\n+          mem = new StoreNNode(ctrl, mem, p1, adr_type, val, MemNode::unordered);\n+        }\n@@ -961,1 +1051,1 @@\n-    mem = ClearArrayNode::clear_memory(ctrl, mem, dest,\n+    mem = ClearArrayNode::clear_memory(ctrl, mem, dest, raw_val,\n@@ -1077,2 +1167,2 @@\n-  call->extract_projections(&_callprojs, false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n-  *ctrl = _callprojs.fallthrough_catchproj->clone();\n+  _callprojs = call->extract_projections(false \/*separate_io_proj*\/, false \/*do_asserts*\/);\n+  *ctrl = _callprojs->fallthrough_catchproj->clone();\n@@ -1081,1 +1171,1 @@\n-  Node* m = _callprojs.fallthrough_memproj->clone();\n+  Node* m = _callprojs->fallthrough_memproj->clone();\n@@ -1094,1 +1184,1 @@\n-  *io = _callprojs.fallthrough_ioproj->clone();\n+  *io = _callprojs->fallthrough_ioproj->clone();\n@@ -1223,0 +1313,36 @@\n+const TypePtr* PhaseMacroExpand::adjust_for_flat_array(const TypeAryPtr* top_dest, Node*& src_offset,\n+                                                       Node*& dest_offset, Node*& length, BasicType& dest_elem,\n+                                                       Node*& dest_length) {\n+#ifdef ASSERT\n+  BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+  bool needs_barriers = top_dest->elem()->inline_klass()->contains_oops() &&\n+                        bs->array_copy_requires_gc_barriers(dest_length != NULL, T_OBJECT, false, BarrierSetC2::Optimization);\n+  assert(!needs_barriers || StressReflectiveCode, \"Flat arracopy would require GC barriers\");\n+#endif\n+  int elem_size = top_dest->klass()->as_flat_array_klass()->element_byte_size();\n+  if (elem_size >= 8) {\n+    if (elem_size > 8) {\n+      \/\/ treat as array of long but scale length, src offset and dest offset\n+      assert((elem_size % 8) == 0, \"not a power of 2?\");\n+      int factor = elem_size \/ 8;\n+      length = transform_later(new MulINode(length, intcon(factor)));\n+      src_offset = transform_later(new MulINode(src_offset, intcon(factor)));\n+      dest_offset = transform_later(new MulINode(dest_offset, intcon(factor)));\n+      if (dest_length != NULL) {\n+        dest_length = transform_later(new MulINode(dest_length, intcon(factor)));\n+      }\n+      elem_size = 8;\n+    }\n+    dest_elem = T_LONG;\n+  } else if (elem_size == 4) {\n+    dest_elem = T_INT;\n+  } else if (elem_size == 2) {\n+    dest_elem = T_CHAR;\n+  } else if (elem_size == 1) {\n+    dest_elem = T_BYTE;\n+  } else {\n+    ShouldNotReachHere();\n+  }\n+  return TypeRawPtr::BOTTOM;\n+}\n+\n@@ -1238,0 +1364,17 @@\n+    const Type* src_type = _igvn.type(src);\n+    const Type* dest_type = _igvn.type(dest);\n+    const TypeAryPtr* top_src = src_type->isa_aryptr();\n+    const TypeAryPtr* top_dest = dest_type->isa_aryptr();\n+    BasicType dest_elem = T_OBJECT;\n+    if (top_dest != NULL && top_dest->klass() != NULL) {\n+      dest_elem = top_dest->klass()->as_array_klass()->element_type()->basic_type();\n+    }\n+    if (dest_elem == T_ARRAY || (dest_elem == T_INLINE_TYPE && top_dest->klass()->is_obj_array_klass())) {\n+      dest_elem = T_OBJECT;\n+    }\n+    if (top_src != NULL && top_src->is_flat()) {\n+      \/\/ If src is flat, dest is guaranteed to be flat as well\n+      dest_elem = T_INLINE_TYPE;\n+      top_dest = top_src;\n+    }\n+\n@@ -1243,0 +1386,1 @@\n+    Node* dest_length = NULL;\n@@ -1246,0 +1390,1 @@\n+      dest_length = alloc->in(AllocateNode::ALength);\n@@ -1248,3 +1393,15 @@\n-    const TypePtr* adr_type = _igvn.type(dest)->is_oopptr()->add_offset(Type::OffsetBot);\n-    if (ac->_dest_type != TypeOopPtr::BOTTOM) {\n-      adr_type = ac->_dest_type->add_offset(Type::OffsetBot)->is_ptr();\n+    const TypePtr* adr_type = NULL;\n+    if (dest_elem == T_INLINE_TYPE) {\n+      assert(dest_length != NULL || StressReflectiveCode, \"must be tightly coupled\");\n+      \/\/ Copy to a flat array modifies multiple memory slices. Conservatively insert a barrier\n+      \/\/ on all slices to prevent writes into the source from floating below the arraycopy.\n+      insert_mem_bar(&ctrl, &mem, Op_MemBarCPUOrder);\n+      adr_type = adjust_for_flat_array(top_dest, src_offset, dest_offset, length, dest_elem, dest_length);\n+    } else {\n+      adr_type = dest_type->is_oopptr()->add_offset(Type::OffsetBot);\n+      if (ac->_dest_type != TypeOopPtr::BOTTOM) {\n+        adr_type = ac->_dest_type->add_offset(Type::OffsetBot)->is_ptr();\n+      }\n+      if (ac->_src_type != ac->_dest_type) {\n+        adr_type = TypeRawPtr::BOTTOM;\n+      }\n@@ -1253,1 +1410,1 @@\n-                       adr_type, T_OBJECT,\n+                       adr_type, dest_elem,\n@@ -1255,0 +1412,1 @@\n+                       dest_length,\n@@ -1256,1 +1414,0 @@\n-\n@@ -1287,2 +1444,6 @@\n-  if (is_reference_type(src_elem))  src_elem  = T_OBJECT;\n-  if (is_reference_type(dest_elem)) dest_elem = T_OBJECT;\n+  if (src_elem == T_ARRAY || (src_elem == T_INLINE_TYPE && top_src->klass()->is_obj_array_klass())) {\n+    src_elem = T_OBJECT;\n+  }\n+  if (dest_elem == T_ARRAY || (dest_elem == T_INLINE_TYPE && top_dest->klass()->is_obj_array_klass())) {\n+    dest_elem = T_OBJECT;\n+  }\n@@ -1290,3 +1451,1 @@\n-  if (ac->is_arraycopy_validated() &&\n-      dest_elem != T_CONFLICT &&\n-      src_elem == T_CONFLICT) {\n+  if (ac->is_arraycopy_validated() && dest_elem != T_CONFLICT && src_elem == T_CONFLICT) {\n@@ -1311,0 +1470,1 @@\n+                                   NULL,\n@@ -1317,1 +1477,2 @@\n-  assert(!ac->is_arraycopy_validated() || (src_elem == dest_elem && dest_elem != T_VOID), \"validated but different basic types\");\n+  assert(!ac->is_arraycopy_validated() || (src_elem == dest_elem && dest_elem != T_VOID) ||\n+         (src_elem == T_INLINE_TYPE && StressReflectiveCode), \"validated but different basic types\");\n@@ -1321,1 +1482,8 @@\n-  if (src_elem != dest_elem || dest_elem == T_VOID) {\n+  \/\/\n+  \/\/ We have no stub to copy flattened inline type arrays with oop\n+  \/\/ fields if we need to emit write barriers.\n+  \/\/\n+  BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+  if (src_elem != dest_elem || dest_elem == T_VOID ||\n+      (dest_elem == T_INLINE_TYPE && top_dest->elem()->inline_klass()->contains_oops() &&\n+       bs->array_copy_requires_gc_barriers(alloc != NULL, T_OBJECT, false, BarrierSetC2::Optimization))) {\n@@ -1329,3 +1497,3 @@\n-    _igvn.replace_node(_callprojs.fallthrough_memproj, merge_mem);\n-    _igvn.replace_node(_callprojs.fallthrough_ioproj, io);\n-    _igvn.replace_node(_callprojs.fallthrough_catchproj, ctrl);\n+    _igvn.replace_node(_callprojs->fallthrough_memproj, merge_mem);\n+    _igvn.replace_node(_callprojs->fallthrough_ioproj, io);\n+    _igvn.replace_node(_callprojs->fallthrough_catchproj, ctrl);\n@@ -1348,5 +1516,3 @@\n-  {\n-    Node* mem = ac->in(TypeFunc::Memory);\n-    merge_mem = MergeMemNode::make(mem);\n-    transform_later(merge_mem);\n-  }\n+  Node* mem = ac->in(TypeFunc::Memory);\n+  merge_mem = MergeMemNode::make(mem);\n+  transform_later(merge_mem);\n@@ -1393,0 +1559,15 @@\n+\n+    \/\/ Handle inline type arrays\n+    if (!top_src->is_flat()) {\n+      if (UseFlatArray && !top_src->is_not_flat()) {\n+        \/\/ Src might be flat and dest might not be flat. Go to the slow path if src is flat.\n+        generate_flat_array_guard(&ctrl, src, slow_region);\n+      }\n+      if (EnableValhalla) {\n+        \/\/ No validation. The subtype check emitted at macro expansion time will not go to the slow\n+        \/\/ path but call checkcast_arraycopy which can not handle flat\/null-free inline type arrays.\n+        generate_null_free_array_guard(&ctrl, dest, slow_region);\n+      }\n+    } else {\n+      assert(top_dest->is_flat(), \"dest array must be flat\");\n+    }\n@@ -1394,0 +1575,1 @@\n+\n@@ -1396,1 +1578,8 @@\n-  if (ac->_dest_type != TypeOopPtr::BOTTOM) {\n+  Node* dest_length = (alloc != NULL) ? alloc->in(AllocateNode::ALength) : NULL;\n+\n+  if (dest_elem == T_INLINE_TYPE) {\n+    \/\/ Copy to a flat array modifies multiple memory slices. Conservatively insert a barrier\n+    \/\/ on all slices to prevent writes into the source from floating below the arraycopy.\n+    insert_mem_bar(&ctrl, &mem, Op_MemBarCPUOrder);\n+    adr_type = adjust_for_flat_array(top_dest, src_offset, dest_offset, length, dest_elem, dest_length);\n+  } else if (ac->_dest_type != TypeOopPtr::BOTTOM) {\n@@ -1405,0 +1594,1 @@\n+                     dest_length,\n@@ -1407,1 +1597,2 @@\n-                     false, ac->has_negative_length_guard(), slow_region);\n+                     false, ac->has_negative_length_guard(),\n+                     slow_region);\n","filename":"src\/hotspot\/share\/opto\/macroArrayCopy.cpp","additions":233,"deletions":42,"binary":false,"changes":275,"status":"modified"},{"patch":"@@ -185,0 +185,46 @@\n+\/\/ Array of RegMask, one per returned values (inline type instances can\n+\/\/ be returned as multiple return values, one per field)\n+RegMask* Matcher::return_values_mask(const TypeTuple *range) {\n+  uint cnt = range->cnt() - TypeFunc::Parms;\n+  if (cnt == 0) {\n+    return NULL;\n+  }\n+  RegMask* mask = NEW_RESOURCE_ARRAY(RegMask, cnt);\n+\n+  if (!InlineTypeReturnedAsFields) {\n+    \/\/ Get ideal-register return type\n+    uint ireg = range->field_at(TypeFunc::Parms)->ideal_reg();\n+    \/\/ Get machine return register\n+    OptoRegPair regs = return_value(ireg);\n+\n+    \/\/ And mask for same\n+    mask[0].Clear();\n+    mask[0].Insert(regs.first());\n+    if (OptoReg::is_valid(regs.second())) {\n+      mask[0].Insert(regs.second());\n+    }\n+  } else {\n+    BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, cnt);\n+    VMRegPair* vm_parm_regs = NEW_RESOURCE_ARRAY(VMRegPair, cnt);\n+\n+    for (uint i = 0; i < cnt; i++) {\n+      sig_bt[i] = range->field_at(i+TypeFunc::Parms)->basic_type();\n+    }\n+\n+    int regs = SharedRuntime::java_return_convention(sig_bt, vm_parm_regs, cnt);\n+    assert(regs > 0, \"should have been tested during graph construction\");\n+    for (uint i = 0; i < cnt; i++) {\n+      mask[i].Clear();\n+\n+      OptoReg::Name reg1 = OptoReg::as_OptoReg(vm_parm_regs[i].first());\n+      if (OptoReg::is_valid(reg1)) {\n+        mask[i].Insert(reg1);\n+      }\n+      OptoReg::Name reg2 = OptoReg::as_OptoReg(vm_parm_regs[i].second());\n+      if (OptoReg::is_valid(reg2)) {\n+        mask[i].Insert(reg2);\n+      }\n+    }\n+  }\n+  return mask;\n+}\n@@ -200,15 +246,4 @@\n-  \/\/ Map a Java-signature return type into return register-value\n-  \/\/ machine registers for 0, 1 and 2 returned values.\n-  const TypeTuple *range = C->tf()->range();\n-  if( range->cnt() > TypeFunc::Parms ) { \/\/ If not a void function\n-    \/\/ Get ideal-register return type\n-    uint ireg = range->field_at(TypeFunc::Parms)->ideal_reg();\n-    \/\/ Get machine return register\n-    uint sop = C->start()->Opcode();\n-    OptoRegPair regs = return_value(ireg);\n-\n-    \/\/ And mask for same\n-    _return_value_mask = RegMask(regs.first());\n-    if( OptoReg::is_valid(regs.second()) )\n-      _return_value_mask.Insert(regs.second());\n-  }\n+  \/\/ Map Java-signature return types into return register-value\n+  \/\/ machine registers.\n+  const TypeTuple *range = C->tf()->range_cc();\n+  _return_values_mask = return_values_mask(range);\n@@ -222,1 +257,1 @@\n-  const TypeTuple *domain = C->tf()->domain();\n+  const TypeTuple *domain = C->tf()->domain_cc();\n@@ -507,0 +542,1 @@\n+\n@@ -756,1 +792,1 @@\n-  uint ret_edge_cnt = TypeFunc::Parms + ((C->tf()->range()->cnt() == TypeFunc::Parms) ? 0 : 1);\n+  uint ret_edge_cnt = C->tf()->range_cc()->cnt();\n@@ -758,4 +794,3 @@\n-  \/\/ Returns have 0 or 1 returned values depending on call signature.\n-  \/\/ Return register is specified by return_value in the AD file.\n-  if (ret_edge_cnt > TypeFunc::Parms)\n-    ret_rms[TypeFunc::Parms+0] = _return_value_mask;\n+  for (i = TypeFunc::Parms; i < ret_edge_cnt; i++) {\n+    ret_rms[i] = _return_values_mask[i-TypeFunc::Parms];\n+  }\n@@ -828,1 +863,1 @@\n-  int proj_cnt = C->tf()->domain()->cnt();\n+  int proj_cnt = C->tf()->domain_cc()->cnt();\n@@ -1100,1 +1135,5 @@\n-              m = n->in(0)->as_Multi()->match( n->as_Proj(), this );\n+              RegMask* mask = NULL;\n+              if (n->in(0)->is_Call()) {\n+                mask = return_values_mask(n->in(0)->as_Call()->tf()->range_cc());\n+              }\n+              m = n->in(0)->as_Multi()->match(n->as_Proj(), this, mask);\n@@ -1245,1 +1284,1 @@\n-    domain = call->tf()->domain();\n+    domain = call->tf()->domain_cc();\n@@ -1333,1 +1372,4 @@\n-  int argcnt = cnt - TypeFunc::Parms;\n+  \/\/ Null entry point is a special cast where the target of the call\n+  \/\/ is in a register.\n+  int adj = (call != NULL && call->entry_point() == NULL) ? 1 : 0;\n+  int argcnt = cnt - TypeFunc::Parms - adj;\n@@ -1339,1 +1381,1 @@\n-      sig_bt[i] = domain->field_at(i+TypeFunc::Parms)->basic_type();\n+      sig_bt[i] = domain->field_at(i+TypeFunc::Parms+adj)->basic_type();\n@@ -1380,1 +1422,1 @@\n-      RegMask *rm = &mcall->_in_rms[i+TypeFunc::Parms];\n+      RegMask *rm = &mcall->_in_rms[i+TypeFunc::Parms+adj];\n@@ -1387,1 +1429,1 @@\n-      if (OptoReg::is_valid(reg1))\n+      if (OptoReg::is_valid(reg1)) {\n@@ -1389,0 +1431,1 @@\n+      }\n@@ -1391,1 +1434,1 @@\n-      if (OptoReg::is_valid(reg2))\n+      if (OptoReg::is_valid(reg2)) {\n@@ -1393,0 +1436,1 @@\n+      }\n@@ -1408,1 +1452,1 @@\n-    uint r_cnt = mcall->tf()->range()->cnt();\n+    uint r_cnt = mcall->tf()->range_sig()->cnt();\n@@ -1429,1 +1473,1 @@\n-         (mcall->jvms()->debug_start() + mcall->_jvmadj == mcall->tf()->domain()->cnt()), \"\");\n+         (mcall->jvms()->debug_start() + mcall->_jvmadj == mcall->tf()->domain_cc()->cnt()), \"\");\n@@ -2115,1 +2159,1 @@\n-      for (int i = n->req() - 1; i >= 0; --i) { \/\/ For my children\n+      for (int i = n->len() - 1; i >= 0; --i) { \/\/ For my children\n@@ -2397,0 +2441,7 @@\n+    case Op_ClearArray: {\n+      Node* pair = new BinaryNode(n->in(2), n->in(3));\n+      n->set_req(2, pair);\n+      n->set_req(3, n->in(4));\n+      n->del_req(4);\n+      break;\n+    }\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":83,"deletions":32,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -262,0 +262,2 @@\n+  RegMask* return_values_mask(const TypeTuple *range);\n+\n@@ -388,1 +390,1 @@\n-  RegMask                     _return_value_mask;\n+  RegMask*            _return_values_mask;\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -27,0 +28,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -40,0 +42,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -241,1 +244,1 @@\n-               tp->isa_aryptr() &&        tp->offset() == Type::OffsetBot &&\n+        tp->isa_aryptr() &&        tp->offset() == Type::OffsetBot &&\n@@ -889,0 +892,1 @@\n+  case T_INLINE_TYPE:\n@@ -1016,1 +1020,1 @@\n-      BasicType ary_elem  = ary_t->klass()->as_array_klass()->element_type()->basic_type();\n+      BasicType ary_elem = ary_t->klass()->as_array_klass()->element_type()->basic_type();\n@@ -1019,0 +1023,4 @@\n+      if (ary_t->klass()->is_flat_array_klass()) {\n+        ciFlatArrayKlass* vak = ary_t->klass()->as_flat_array_klass();\n+        shift = vak->log2_element_size();\n+      }\n@@ -1146,0 +1154,6 @@\n+      assert(memory_type() != T_INLINE_TYPE, \"should not be used for inline types\");\n+      Node* default_value = ld_alloc->in(AllocateNode::DefaultValue);\n+      if (default_value != NULL) {\n+        return default_value;\n+      }\n+      assert(ld_alloc->in(AllocateNode::RawDefaultValue) == NULL, \"default value may not be null\");\n@@ -1213,0 +1227,27 @@\n+  \/\/ Loading from an InlineTypePtr? The InlineTypePtr has the values of\n+  \/\/ all fields as input. Look for the field with matching offset.\n+  Node* addr = in(Address);\n+  intptr_t offset;\n+  Node* base = AddPNode::Ideal_base_and_offset(addr, phase, offset);\n+  if (base != NULL && base->is_InlineTypePtr() && offset > oopDesc::klass_offset_in_bytes()) {\n+    Node* value = base->as_InlineTypePtr()->field_value_by_offset((int)offset, true);\n+    if (value->is_InlineType()) {\n+      \/\/ Non-flattened inline type field\n+      InlineTypeNode* vt = value->as_InlineType();\n+      if (vt->is_allocated(phase)) {\n+        value = vt->get_oop();\n+      } else {\n+        \/\/ Not yet allocated, bail out\n+        value = NULL;\n+      }\n+    }\n+    if (value != NULL) {\n+      if (Opcode() == Op_LoadN) {\n+        \/\/ Encode oop value if we are loading a narrow oop\n+        assert(!phase->type(value)->isa_narrowoop(), \"should already be decoded\");\n+        value = phase->transform(new EncodePNode(value, bottom_type()));\n+      }\n+      return value;\n+    }\n+  }\n+\n@@ -1823,2 +1864,6 @@\n-  AllocateNode* alloc = is_new_object_mark_load(phase);\n-  if (alloc != NULL && alloc->Opcode() == Op_Allocate && UseBiasedLocking) {\n+  AllocateNode* alloc = AllocateNode::Ideal_allocation(address, phase);\n+  if (alloc != NULL && mem->is_Proj() &&\n+      mem->in(0) != NULL &&\n+      mem->in(0) == alloc->initialization() &&\n+      Opcode() == Op_LoadX &&\n+      alloc->initialization()->proj_out_or_null(0) != NULL) {\n@@ -1827,1 +1872,1 @@\n-    return alloc->make_ideal_mark(phase, address, control, mem);\n+    return alloc->make_ideal_mark(phase, control, mem);\n@@ -1919,0 +1964,1 @@\n+        && t->isa_inlinetype() == NULL\n@@ -1953,0 +1999,1 @@\n+            tp->is_oopptr()->klass() == ciEnv::current()->Class_klass() ||\n@@ -1958,1 +2005,3 @@\n-    \/\/ Optimize loads from constant fields.\n+    BasicType bt = memory_type();\n+\n+    \/\/ Optimize loads from constant fields.\n@@ -1962,1 +2011,10 @@\n-      const Type* con_type = Type::make_constant_from_field(const_oop->as_instance(), off, is_unsigned(), memory_type());\n+      ciType* mirror_type = const_oop->as_instance()->java_mirror_type();\n+      if (mirror_type != NULL && mirror_type->is_inlinetype()) {\n+        ciInlineKlass* vk = mirror_type->as_inline_klass();\n+        if (off == vk->default_value_offset()) {\n+          \/\/ Loading a special hidden field that contains the oop of the default inline type\n+          const Type* const_oop = TypeInstPtr::make(vk->default_instance());\n+          return (bt == T_NARROWOOP) ? const_oop->make_narrowoop() : const_oop;\n+        }\n+      }\n+      const Type* con_type = Type::make_constant_from_field(const_oop->as_instance(), off, is_unsigned(), bt);\n@@ -1970,0 +2028,1 @@\n+            tp->is_klassptr()->klass() == NULL ||\n@@ -1976,15 +2035,31 @@\n-  } else if (tp->base() == Type::RawPtr && adr->is_Load() && off == 0) {\n-    \/* With mirrors being an indirect in the Klass*\n-     * the VM is now using two loads. LoadKlass(LoadP(LoadP(Klass, mirror_offset), zero_offset))\n-     * The LoadP from the Klass has a RawPtr type (see LibraryCallKit::load_mirror_from_klass).\n-     *\n-     * So check the type and klass of the node before the LoadP.\n-     *\/\n-    Node* adr2 = adr->in(MemNode::Address);\n-    const TypeKlassPtr* tkls = phase->type(adr2)->isa_klassptr();\n-    if (tkls != NULL && !StressReflectiveCode) {\n-      ciKlass* klass = tkls->klass();\n-      if (klass->is_loaded() && tkls->klass_is_exact() && tkls->offset() == in_bytes(Klass::java_mirror_offset())) {\n-        assert(adr->Opcode() == Op_LoadP, \"must load an oop from _java_mirror\");\n-        assert(Opcode() == Op_LoadP, \"must load an oop from _java_mirror\");\n-        return TypeInstPtr::make(klass->java_mirror());\n+  } else if (tp->base() == Type::RawPtr && !StressReflectiveCode) {\n+    if (adr->is_Load() && off == 0) {\n+      \/* With mirrors being an indirect in the Klass*\n+       * the VM is now using two loads. LoadKlass(LoadP(LoadP(Klass, mirror_offset), zero_offset))\n+       * The LoadP from the Klass has a RawPtr type (see LibraryCallKit::load_mirror_from_klass).\n+       *\n+       * So check the type and klass of the node before the LoadP.\n+       *\/\n+      Node* adr2 = adr->in(MemNode::Address);\n+      const TypeKlassPtr* tkls = phase->type(adr2)->isa_klassptr();\n+      if (tkls != NULL) {\n+        ciKlass* klass = tkls->klass();\n+        if (klass != NULL && klass->is_loaded() && tkls->klass_is_exact() && tkls->offset() == in_bytes(Klass::java_mirror_offset())) {\n+          assert(adr->Opcode() == Op_LoadP, \"must load an oop from _java_mirror\");\n+          assert(Opcode() == Op_LoadP, \"must load an oop from _java_mirror\");\n+          return TypeInstPtr::make(klass->java_mirror());\n+        }\n+      }\n+    } else {\n+      \/\/ Check for a load of the default value offset from the InlineKlassFixedBlock:\n+      \/\/ LoadI(LoadP(inline_klass, adr_inlineklass_fixed_block_offset), default_value_offset_offset)\n+      intptr_t offset = 0;\n+      Node* base = AddPNode::Ideal_base_and_offset(adr, phase, offset);\n+      if (base != NULL && base->is_Load() && offset == in_bytes(InlineKlass::default_value_offset_offset())) {\n+        const TypeKlassPtr* tkls = phase->type(base->in(MemNode::Address))->isa_klassptr();\n+        if (tkls != NULL && tkls->is_loaded() && tkls->klass_is_exact() && tkls->isa_inlinetype() &&\n+            tkls->offset() == in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())) {\n+          assert(base->Opcode() == Op_LoadP, \"must load an oop from klass\");\n+          assert(Opcode() == Op_LoadI, \"must load an int from fixed block\");\n+          return TypeInt::make(tkls->klass()->as_inline_klass()->default_value_offset());\n+        }\n@@ -1998,1 +2073,1 @@\n-    if (klass->is_loaded() && tkls->klass_is_exact()) {\n+    if (tkls->is_loaded() && tkls->klass_is_exact()) {\n@@ -2025,1 +2100,1 @@\n-    if (klass->is_loaded() ) {\n+    if (tkls->is_loaded()) {\n@@ -2090,1 +2165,0 @@\n-\n@@ -2093,1 +2167,11 @@\n-    return TypeX::make(markWord::prototype().value());\n+    if (EnableValhalla) {\n+      \/\/ The mark word may contain property bits (inline, flat, null-free)\n+      Node* klass_node = alloc->in(AllocateNode::KlassNode);\n+      const TypeKlassPtr* tkls = phase->type(klass_node)->is_klassptr();\n+      ciKlass* klass = tkls->klass();\n+      if (klass != NULL && klass->is_loaded() && tkls->klass_is_exact()) {\n+        return TypeX::make(klass->prototype_header().value());\n+      }\n+    } else {\n+      return TypeX::make(markWord::prototype().value());\n+    }\n@@ -2244,1 +2328,2 @@\n-Node* LoadKlassNode::make(PhaseGVN& gvn, Node* ctl, Node* mem, Node* adr, const TypePtr* at, const TypeKlassPtr* tk) {\n+Node* LoadKlassNode::make(PhaseGVN& gvn, Node* ctl, Node* mem, Node* adr, const TypePtr* at,\n+                          const TypeKlassPtr* tk) {\n@@ -2331,1 +2416,1 @@\n-      return TypeKlassPtr::make(TypePtr::NotNull, ik, 0\/*offset*\/);\n+      return TypeKlassPtr::make(TypePtr::NotNull, ik, Type::Offset(0), tinst->flatten_array());\n@@ -2337,1 +2422,1 @@\n-  if( tary != NULL ) {\n+  if (tary != NULL) {\n@@ -2344,1 +2429,1 @@\n-      ciArrayKlass *ak = tary->klass()->as_array_klass();\n+      ciArrayKlass* ak = tary_klass->as_array_klass();\n@@ -2347,2 +2432,2 @@\n-      if( ak->is_obj_array_klass() ) {\n-        assert( ak->is_loaded(), \"\" );\n+      if (ak->is_obj_array_klass()) {\n+        assert(ak->is_loaded(), \"\");\n@@ -2350,2 +2435,2 @@\n-        if( base_k->is_loaded() && base_k->is_instance_klass() ) {\n-          ciInstanceKlass* ik = base_k->as_instance_klass();\n+        if (base_k->is_loaded() && base_k->is_instance_klass()) {\n+          ciInstanceKlass *ik = base_k->as_instance_klass();\n@@ -2362,3 +2447,2 @@\n-        return TypeKlassPtr::make(TypePtr::NotNull, ak, 0\/*offset*\/);\n-      } else {                  \/\/ Found a type-array?\n-        assert( ak->is_type_array_klass(), \"\" );\n+        return TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0), false, tary->is_not_flat(), tary->is_not_null_free());\n+      } else if (ak->is_type_array_klass()) {\n@@ -2373,2 +2457,1 @@\n-    ciKlass* klass = tkls->klass();\n-    if( !klass->is_loaded() )\n+    if (!tkls->is_loaded()) {\n@@ -2376,0 +2459,2 @@\n+    }\n+    ciKlass* klass = tkls->klass();\n@@ -2385,1 +2470,5 @@\n-      return TypeKlassPtr::make(tkls->ptr(), elem, 0\/*offset*\/);\n+      return TypeKlassPtr::make(tkls->ptr(), elem, Type::Offset(0));\n+    } else if (klass->is_flat_array_klass() &&\n+               tkls->offset() == in_bytes(ObjArrayKlass::element_klass_offset())) {\n+      ciKlass* elem = klass->as_flat_array_klass()->element_klass();\n+      return TypeKlassPtr::make(tkls->ptr(), elem, Type::Offset(0), \/* flatten_array= *\/ true);\n@@ -2593,0 +2682,1 @@\n+  case T_INLINE_TYPE:\n@@ -2654,1 +2744,1 @@\n-  {\n+  if (phase->C->get_adr_type(phase->C->get_alias_index(adr_type())) != TypeAryPtr::INLINES) {\n@@ -2674,0 +2764,1 @@\n+             (Opcode() == Op_StoreL && st->Opcode() == Op_StoreN) ||\n@@ -2770,2 +2861,1 @@\n-  if (result == this &&\n-      ReduceFieldZeroing && phase->type(val)->is_zero_type()) {\n+  if (result == this && ReduceFieldZeroing) {\n@@ -2773,1 +2863,3 @@\n-    if (mem->is_Proj() && mem->in(0)->is_Allocate()) {\n+    if (mem->is_Proj() && mem->in(0)->is_Allocate() &&\n+        (phase->type(val)->is_zero_type() || mem->in(0)->in(AllocateNode::DefaultValue) == val)) {\n+      assert(!phase->type(val)->is_zero_type() || mem->in(0)->in(AllocateNode::DefaultValue) == NULL, \"storing null to inline type array is forbidden\");\n@@ -2786,1 +2878,9 @@\n-          result = mem;\n+          if (phase->type(val)->is_zero_type()) {\n+            result = mem;\n+          } else if (prev_mem->is_Proj() && prev_mem->in(0)->is_Initialize()) {\n+            InitializeNode* init = prev_mem->in(0)->as_Initialize();\n+            AllocateNode* alloc = init->allocation();\n+            if (alloc != NULL && alloc->in(AllocateNode::DefaultValue) == val) {\n+              result = mem;\n+            }\n+          }\n@@ -2962,3 +3062,7 @@\n-    Node* mem = my_store->as_MergeMem()->memory_at(oop_alias_idx());\n-    set_req_X(MemNode::OopStore, mem, phase);\n-    return this;\n+    if (oop_alias_idx() != phase->C->get_alias_index(TypeAryPtr::INLINES) ||\n+        phase->C->flattened_accesses_share_alias()) {\n+      \/\/ The alias that was recorded is no longer accurate enough.\n+      Node* mem = my_store->as_MergeMem()->memory_at(oop_alias_idx());\n+      set_req_X(MemNode::OopStore, mem, phase);\n+      return this;\n+    }\n@@ -3123,1 +3227,1 @@\n-    return new ClearArrayNode(in(0), in(1), in(2), in(3), true);\n+    return new ClearArrayNode(in(0), in(1), in(2), in(3), in(4), true);\n@@ -3140,1 +3244,1 @@\n-  Node *zero = phase->makecon(TypeLong::ZERO);\n+  Node *val = in(4);\n@@ -3142,1 +3246,1 @@\n-  mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);\n+  mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);\n@@ -3147,1 +3251,1 @@\n-    mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);\n+    mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);\n@@ -3181,0 +3285,2 @@\n+                                   Node* val,\n+                                   Node* raw_val,\n@@ -3191,1 +3297,7 @@\n-    mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    if (val != NULL) {\n+      assert(phase->type(val)->isa_narrowoop(), \"should be narrow oop\");\n+      mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);\n+    } else {\n+      assert(raw_val == NULL, \"val may not be null\");\n+      mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    }\n@@ -3198,1 +3310,1 @@\n-  return clear_memory(ctl, mem, dest, phase->MakeConX(offset), end_offset, phase);\n+  return clear_memory(ctl, mem, dest, raw_val, phase->MakeConX(offset), end_offset, phase);\n@@ -3202,0 +3314,1 @@\n+                                   Node* raw_val,\n@@ -3224,1 +3337,4 @@\n-  mem = new ClearArrayNode(ctl, mem, zsize, adr, false);\n+  if (raw_val == NULL) {\n+    raw_val = phase->MakeConX(0);\n+  }\n+  mem = new ClearArrayNode(ctl, mem, zsize, adr, raw_val, false);\n@@ -3229,0 +3345,2 @@\n+                                   Node* val,\n+                                   Node* raw_val,\n@@ -3243,1 +3361,1 @@\n-    mem = clear_memory(ctl, mem, dest,\n+    mem = clear_memory(ctl, mem, dest, val, raw_val,\n@@ -3250,1 +3368,7 @@\n-    mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    if (val != NULL) {\n+      assert(phase->type(val)->isa_narrowoop(), \"should be narrow oop\");\n+      mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);\n+    } else {\n+      assert(raw_val == NULL, \"val may not be null\");\n+      mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    }\n@@ -3389,1 +3513,1 @@\n-Node *MemBarNode::match( const ProjNode *proj, const Matcher *m ) {\n+Node *MemBarNode::match(const ProjNode *proj, const Matcher *m, const RegMask* mask) {\n@@ -3675,1 +3799,3 @@\n-  if (init == NULL || init->is_complete())  return false;\n+  if (init == NULL || init->is_complete()) {\n+    return false;\n+  }\n@@ -3853,0 +3979,6 @@\n+                if (base->is_Phi()) {\n+                  \/\/ In rare case, base may be a PhiNode and it may read\n+                  \/\/ the same memory slice between InitializeNode and store.\n+                  failed = true;\n+                  break;\n+                }\n@@ -4437,0 +4569,2 @@\n+                                              allocation()->in(AllocateNode::DefaultValue),\n+                                              allocation()->in(AllocateNode::RawDefaultValue),\n@@ -4496,0 +4630,2 @@\n+                                            allocation()->in(AllocateNode::DefaultValue),\n+                                            allocation()->in(AllocateNode::RawDefaultValue),\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":195,"deletions":59,"binary":false,"changes":254,"status":"modified"},{"patch":"@@ -129,0 +129,4 @@\n+#ifdef ASSERT\n+  void set_adr_type(const TypePtr* adr_type) { _adr_type = adr_type; }\n+#endif\n+\n@@ -551,1 +555,0 @@\n-\n@@ -1135,0 +1138,1 @@\n+  bool _word_copy_only;\n@@ -1136,2 +1140,3 @@\n-  ClearArrayNode( Node *ctrl, Node *arymem, Node *word_cnt, Node *base, bool is_large)\n-    : Node(ctrl,arymem,word_cnt,base), _is_large(is_large) {\n+  ClearArrayNode( Node *ctrl, Node *arymem, Node *word_cnt, Node *base, Node* val, bool is_large)\n+    : Node(ctrl, arymem, word_cnt, base, val), _is_large(is_large),\n+      _word_copy_only(val->bottom_type()->isa_long() && (!val->bottom_type()->is_long()->is_con() || val->bottom_type()->is_long()->get_con() != 0)) {\n@@ -1149,0 +1154,1 @@\n+  bool word_copy_only() const { return _word_copy_only; }\n@@ -1155,0 +1161,2 @@\n+                            Node* val,\n+                            Node* raw_val,\n@@ -1159,0 +1167,2 @@\n+                            Node* val,\n+                            Node* raw_val,\n@@ -1163,0 +1173,1 @@\n+                            Node* raw_val,\n@@ -1214,1 +1225,1 @@\n-  virtual Node *match( const ProjNode *proj, const Matcher *m );\n+  virtual Node *match(const ProjNode *proj, const Matcher *m, const RegMask* mask);\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -160,0 +160,12 @@\n+  \/\/ Code pattern on return from a call that returns an __Value.  Can\n+  \/\/ be optimized away if the return value turns out to be an oop.\n+  if (op == Op_AndX &&\n+      in(1) != NULL &&\n+      in(1)->Opcode() == Op_CastP2X &&\n+      in(1)->in(1) != NULL &&\n+      phase->type(in(1)->in(1))->isa_oopptr() &&\n+      t2->isa_intptr_t()->_lo >= 0 &&\n+      t2->isa_intptr_t()->_hi <= MinObjAlignmentInBytesMask) {\n+    return add_id();\n+  }\n+\n@@ -591,0 +603,8 @@\n+\n+    \/\/ Check if this is part of an inline type test\n+    if (con == markWord::inline_type_pattern && in(1)->is_Load() &&\n+        phase->type(in(1)->in(MemNode::Address))->is_inlinetypeptr() &&\n+        phase->type(in(1)->in(MemNode::Address))->is_ptr()->offset() == oopDesc::mark_offset_in_bytes()) {\n+      assert(EnableValhalla, \"should only be used for inline types\");\n+      return in(2); \/\/ Obj is known to be an inline type\n+    }\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -571,0 +571,3 @@\n+  if (n->is_InlineTypeBase()) {\n+    C->add_inline_type(n);\n+  }\n@@ -653,0 +656,3 @@\n+  if (is_InlineTypeBase()) {\n+    compile->remove_inline_type(this);\n+  }\n@@ -2191,1 +2197,3 @@\n-      assert(i >= req() || i == 0 || is_Region() || is_Phi() || is_ArrayCopy() || (is_Unlock() && i == req()-1)\n+      assert(i >= req() || i == 0 || is_Region() || is_Phi() || is_ArrayCopy() ||\n+             (is_Allocate() && i >= AllocateNode::InlineTypeNode) ||\n+             (is_Unlock() && i == req()-1)\n@@ -2193,1 +2201,1 @@\n-              \"only region, phi, arraycopy, unlock or membar nodes have null data edges\");\n+             \"only region, phi, arraycopy, allocate or unlock nodes have null data edges\");\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -81,0 +81,1 @@\n+class FlatArrayCheckNode;\n@@ -113,0 +114,1 @@\n+class MachPrologNode;\n@@ -119,0 +121,1 @@\n+class MachVEPNode;\n@@ -163,0 +166,3 @@\n+class InlineTypeBaseNode;\n+class InlineTypeNode;\n+class InlineTypePtrNode;\n@@ -681,0 +687,2 @@\n+      DEFINE_CLASS_ID(MachProlog,       Mach, 8)\n+      DEFINE_CLASS_ID(MachVEP,          Mach, 9)\n@@ -698,0 +706,3 @@\n+      DEFINE_CLASS_ID(InlineTypeBase, Type, 8)\n+        DEFINE_CLASS_ID(InlineType, InlineTypeBase, 0)\n+        DEFINE_CLASS_ID(InlineTypePtr, InlineTypeBase, 1)\n@@ -732,3 +743,4 @@\n-        DEFINE_CLASS_ID(FastLock,   Cmp, 0)\n-        DEFINE_CLASS_ID(FastUnlock, Cmp, 1)\n-        DEFINE_CLASS_ID(SubTypeCheck,Cmp, 2)\n+        DEFINE_CLASS_ID(FastLock,       Cmp, 0)\n+        DEFINE_CLASS_ID(FastUnlock,     Cmp, 1)\n+        DEFINE_CLASS_ID(SubTypeCheck,   Cmp, 2)\n+        DEFINE_CLASS_ID(FlatArrayCheck, Cmp, 3)\n@@ -859,0 +871,1 @@\n+  DEFINE_CLASS_QUERY(FlatArrayCheck)\n@@ -891,0 +904,1 @@\n+  DEFINE_CLASS_QUERY(MachProlog)\n@@ -897,0 +911,1 @@\n+  DEFINE_CLASS_QUERY(MachVEP)\n@@ -921,0 +936,3 @@\n+  DEFINE_CLASS_QUERY(InlineType)\n+  DEFINE_CLASS_QUERY(InlineTypeBase)\n+  DEFINE_CLASS_QUERY(InlineTypePtr)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":21,"deletions":3,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -312,0 +312,2 @@\n+    _sp_inc_slot(0),\n+    _sp_inc_slot_offset_in_bytes(0),\n@@ -317,1 +319,6 @@\n-    _orig_pc_slot = C->fixed_slots() - (sizeof(address) \/ VMRegImpl::stack_slot_size);\n+    int fixed_slots = C->fixed_slots();\n+    if (C->needs_stack_repair()) {\n+      fixed_slots -= 2;\n+      _sp_inc_slot = fixed_slots;\n+    }\n+    _orig_pc_slot = fixed_slots - (sizeof(address) \/ VMRegImpl::stack_slot_size);\n@@ -356,1 +363,2 @@\n-  MachPrologNode *prolog = new MachPrologNode();\n+  Label verified_entry;\n+  MachPrologNode* prolog = new MachPrologNode(&verified_entry);\n@@ -362,3 +370,2 @@\n-\n-  if( C->is_osr_compilation() ) {\n-    if( PoisonOSREntry ) {\n+  if (C->is_osr_compilation()) {\n+    if (PoisonOSREntry) {\n@@ -369,3 +376,14 @@\n-    if( C->method() && !C->method()->flags().is_static() ) {\n-      \/\/ Insert unvalidated entry point\n-      C->cfg()->insert( broot, 0, new MachUEPNode() );\n+    if (C->method()) {\n+      if (C->method()->has_scalarized_args()) {\n+        \/\/ Add entry point to unpack all inline type arguments\n+        C->cfg()->insert(broot, 0, new MachVEPNode(&verified_entry, \/* verified *\/ true, \/* receiver_only *\/ false));\n+        if (!C->method()->is_static()) {\n+          \/\/ Add verified\/unverified entry points to only unpack inline type receiver at interface calls\n+          C->cfg()->insert(broot, 0, new MachVEPNode(&verified_entry, \/* verified *\/ false, \/* receiver_only *\/ false));\n+          C->cfg()->insert(broot, 0, new MachVEPNode(&verified_entry, \/* verified *\/ true,  \/* receiver_only *\/ true));\n+          C->cfg()->insert(broot, 0, new MachVEPNode(&verified_entry, \/* verified *\/ false, \/* receiver_only *\/ true));\n+        }\n+      } else if (!C->method()->is_static()) {\n+        \/\/ Insert unvalidated entry point\n+        C->cfg()->insert(broot, 0, new MachUEPNode());\n+      }\n@@ -373,1 +391,0 @@\n-\n@@ -413,0 +430,25 @@\n+  if (!C->is_osr_compilation() && C->has_scalarized_args()) {\n+    \/\/ Compute the offsets of the entry points required by the inline type calling convention\n+    if (!C->method()->is_static()) {\n+      \/\/ We have entries at the beginning of the method, implemented by the first 4 nodes.\n+      \/\/ Entry                     (unverified) @ offset 0\n+      \/\/ Verified_Inline_Entry_RO\n+      \/\/ Inline_Entry              (unverified)\n+      \/\/ Verified_Inline_Entry\n+      uint offset = 0;\n+      _code_offsets.set_value(CodeOffsets::Entry, offset);\n+\n+      offset += ((MachVEPNode*)broot->get_node(0))->size(C->regalloc());\n+      _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry_RO, offset);\n+\n+      offset += ((MachVEPNode*)broot->get_node(1))->size(C->regalloc());\n+      _code_offsets.set_value(CodeOffsets::Inline_Entry, offset);\n+\n+      offset += ((MachVEPNode*)broot->get_node(2))->size(C->regalloc());\n+      _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry, offset);\n+    } else {\n+      _code_offsets.set_value(CodeOffsets::Entry, -1); \/\/ will be patched later\n+      _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry, 0);\n+    }\n+  }\n+\n@@ -570,1 +612,3 @@\n-          mcall->method_set((intptr_t)mcall->entry_point());\n+          if (mcall->entry_point() != NULL) {\n+            mcall->method_set((intptr_t)mcall->entry_point());\n+          }\n@@ -1009,0 +1053,1 @@\n+  bool return_scalarized = false;\n@@ -1031,1 +1076,1 @@\n-    if (mcall->returns_pointer()) {\n+    if (mcall->returns_pointer() || mcall->returns_scalarized()) {\n@@ -1034,0 +1079,3 @@\n+    if (mcall->returns_scalarized()) {\n+      return_scalarized = true;\n+    }\n@@ -1159,0 +1207,1 @@\n+      return_scalarized,\n@@ -1269,0 +1318,4 @@\n+  if (C->needs_stack_repair()) {\n+    \/\/ Compute the byte offset of the stack increment value\n+    _sp_inc_slot_offset_in_bytes = C->regalloc()->reg2offset(OptoReg::stack2reg(_sp_inc_slot));\n+  }\n@@ -1548,2 +1601,4 @@\n-          \/\/ This destination address is NOT PC-relative\n-          mcall->method_set((intptr_t)mcall->entry_point());\n+          if (mcall->entry_point() != NULL) {\n+            \/\/ This destination address is NOT PC-relative\n+            mcall->method_set((intptr_t)mcall->entry_point());\n+          }\n@@ -1713,1 +1768,0 @@\n-\n@@ -3280,0 +3334,10 @@\n+    if (C->has_scalarized_args()) {\n+      \/\/ Inline type entry points (MachVEPNodes) require lots of space for GC barriers and oop verification\n+      \/\/ when loading object fields from the buffered argument. Increase scratch buffer size accordingly.\n+      int barrier_size = UseZGC ? 200 : (7 DEBUG_ONLY(+ 37));\n+      for (ciSignatureStream str(C->method()->signature()); !str.at_return_type(); str.next()) {\n+        if (str.type()->is_inlinetype() && str.type()->as_inline_klass()->can_be_passed_as_fields()) {\n+          size += str.type()->as_inline_klass()->oop_count() * barrier_size;\n+        }\n+      }\n+    }\n@@ -3344,0 +3408,6 @@\n+  } else if (n->is_MachProlog()) {\n+    saveL = ((MachPrologNode*)n)->_verified_entry;\n+    ((MachPrologNode*)n)->_verified_entry = &fakeL;\n+  } else if (n->is_MachVEP()) {\n+    saveL = ((MachVEPNode*)n)->_verified_entry;\n+    ((MachVEPNode*)n)->_verified_entry = &fakeL;\n@@ -3350,1 +3420,2 @@\n-  if (is_branch) \/\/ Restore label.\n+  \/\/ Restore label.\n+  if (is_branch) {\n@@ -3352,0 +3423,5 @@\n+  } else if (n->is_MachProlog()) {\n+    ((MachPrologNode*)n)->_verified_entry = saveL;\n+  } else if (n->is_MachVEP()) {\n+    ((MachVEPNode*)n)->_verified_entry = saveL;\n+  }\n@@ -3396,0 +3472,9 @@\n+      if (_code_offsets.value(CodeOffsets::Verified_Inline_Entry) == -1) {\n+        _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry, _first_block_size);\n+      }\n+      if (_code_offsets.value(CodeOffsets::Verified_Inline_Entry_RO) == -1) {\n+        _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry_RO, _first_block_size);\n+      }\n+      if (_code_offsets.value(CodeOffsets::Entry) == -1) {\n+        _code_offsets.set_value(CodeOffsets::Entry, _first_block_size);\n+      }\n@@ -3400,13 +3485,13 @@\n-                                     entry_bci,\n-                                     &_code_offsets,\n-                                     _orig_pc_slot_offset_in_bytes,\n-                                     code_buffer(),\n-                                     frame_size_in_words(),\n-                                     oop_map_set(),\n-                                     &_handler_table,\n-                                     inc_table(),\n-                                     compiler,\n-                                     has_unsafe_access,\n-                                     SharedRuntime::is_wide_vector(C->max_vector_size()),\n-                                     C->rtm_state(),\n-                                     C->native_invokers());\n+                              entry_bci,\n+                              &_code_offsets,\n+                              _orig_pc_slot_offset_in_bytes,\n+                              code_buffer(),\n+                              frame_size_in_words(),\n+                              _oop_map_set,\n+                              &_handler_table,\n+                              &_inc_table,\n+                              compiler,\n+                              has_unsafe_access,\n+                              SharedRuntime::is_wide_vector(C->max_vector_size()),\n+                              C->rtm_state(),\n+                              C->native_invokers());\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":113,"deletions":28,"binary":false,"changes":141,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -104,4 +105,10 @@\n-Node *Parse::fetch_interpreter_state(int index,\n-                                     BasicType bt,\n-                                     Node *local_addrs,\n-                                     Node *local_addrs_base) {\n+Node* Parse::fetch_interpreter_state(int index,\n+                                     const Type* type,\n+                                     Node* local_addrs,\n+                                     Node* local_addrs_base) {\n+  BasicType bt = type->basic_type();\n+  if (type == TypePtr::NULL_PTR) {\n+    \/\/ Ptr types are mixed together with T_ADDRESS but NULL is\n+    \/\/ really for T_OBJECT types so correct it.\n+    bt = T_OBJECT;\n+  }\n@@ -119,0 +126,1 @@\n+  case T_INLINE_TYPE:\n@@ -149,1 +157,5 @@\n-\n+  if (type->isa_inlinetype() != NULL) {\n+    \/\/ The interpreter passes inline types as oops\n+    tp = TypeOopPtr::make_from_klass(type->inline_klass());\n+    tp = tp->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+  }\n@@ -173,0 +185,6 @@\n+    if (tp->klass()->is_inlinetype()) {\n+      \/\/ Check inline types for null here to prevent checkcast from adding an\n+      \/\/ exception state before the bytecode entry (use 'bad_type_ctrl' instead).\n+      l = null_check_oop(l, &bad_type_ctrl);\n+      bad_type_exit->control()->add_req(bad_type_ctrl);\n+    }\n@@ -176,3 +194,0 @@\n-\n-  BasicType bt_l = _gvn.type(l)->basic_type();\n-  BasicType bt_t = type->basic_type();\n@@ -191,1 +206,0 @@\n-\n@@ -229,1 +243,0 @@\n-\n@@ -233,1 +246,1 @@\n-    Node *lock_object = fetch_interpreter_state(index*2, T_OBJECT, monitors_addr, osr_buf);\n+    Node* lock_object = fetch_interpreter_state(index*2, Type::get_const_basic_type(T_OBJECT), monitors_addr, osr_buf);\n@@ -235,2 +248,1 @@\n-    Node *displaced_hdr = fetch_interpreter_state((index*2) + 1, T_ADDRESS, monitors_addr, osr_buf);\n-\n+    Node* displaced_hdr = fetch_interpreter_state((index*2) + 1, Type::get_const_basic_type(T_ADDRESS), monitors_addr, osr_buf);\n@@ -303,7 +315,1 @@\n-    BasicType bt = type->basic_type();\n-    if (type == TypePtr::NULL_PTR) {\n-      \/\/ Ptr types are mixed together with T_ADDRESS but NULL is\n-      \/\/ really for T_OBJECT types so correct it.\n-      bt = T_OBJECT;\n-    }\n-    Node *value = fetch_interpreter_state(index, bt, locals_addr, osr_buf);\n+    Node* value = fetch_interpreter_state(index, type, locals_addr, osr_buf);\n@@ -597,0 +603,21 @@\n+  \/\/ Handle inline type arguments\n+  int arg_size_sig = tf()->domain_sig()->cnt();\n+  for (uint i = 0; i < (uint)arg_size_sig; i++) {\n+    Node* parm = map()->in(i);\n+    const Type* t = _gvn.type(parm);\n+    if (t->is_inlinetypeptr() && t->inline_klass()->is_scalarizable() && !t->maybe_null()) {\n+      \/\/ Create InlineTypeNode from the oop and replace the parameter\n+      Node* vt = InlineTypeNode::make_from_oop(this, parm, t->inline_klass());\n+      map()->replace_edge(parm, vt);\n+    } else if (UseTypeSpeculation && (i == (uint)(arg_size_sig - 1)) && !is_osr_parse() &&\n+               method()->has_vararg() && t->isa_aryptr() != NULL && !t->is_aryptr()->is_not_null_free()) {\n+      \/\/ Speculate on varargs Object array being not null-free (and therefore also not flattened)\n+      const TypePtr* spec_type = t->speculative();\n+      spec_type = (spec_type != NULL && spec_type->isa_aryptr() != NULL) ? spec_type : t->is_aryptr();\n+      spec_type = spec_type->remove_speculative()->is_aryptr()->cast_to_not_null_free();\n+      spec_type = TypeOopPtr::make(TypePtr::BotPTR, Type::Offset::bottom, TypeOopPtr::InstanceBot, spec_type);\n+      Node* cast = _gvn.transform(new CheckCastPPNode(control(), parm, t->join_speculative(spec_type)));\n+      replace_in_map(parm, cast);\n+    }\n+  }\n+\n@@ -779,2 +806,2 @@\n-  if (tf()->range()->cnt() > TypeFunc::Parms) {\n-    const Type* ret_type = tf()->range()->field_at(TypeFunc::Parms);\n+  if (tf()->range_sig()->cnt() > TypeFunc::Parms) {\n+    const Type* ret_type = tf()->range_sig()->field_at(TypeFunc::Parms);\n@@ -798,0 +825,5 @@\n+    \/\/ Scalarize inline type when returning as fields or inlining non-incrementally\n+    if ((tf()->returns_inline_type_as_fields() || (_caller->has_method() && !Compile::current()->inlining_incrementally())) &&\n+        ret_type->is_inlinetypeptr() && ret_type->inline_klass()->is_scalarizable() && !ret_type->maybe_null()) {\n+      ret_type = TypeInlineType::make(ret_type->inline_klass());\n+    }\n@@ -802,1 +834,1 @@\n-    assert((int)(tf()->range()->cnt() - TypeFunc::Parms) == ret_size, \"good tf range\");\n+    assert((int)(tf()->range_sig()->cnt() - TypeFunc::Parms) == ret_size, \"good tf range\");\n@@ -809,1 +841,0 @@\n-\n@@ -814,2 +845,2 @@\n-  int        arg_size = tf->domain()->cnt();\n-  int        max_size = MAX2(arg_size, (int)tf->range()->cnt());\n+  int        arg_size = tf->domain_sig()->cnt();\n+  int        max_size = MAX2(arg_size, (int)tf->range_cc()->cnt());\n@@ -818,0 +849,1 @@\n+  jvms->set_map(map);\n@@ -829,3 +861,19 @@\n-  uint i;\n-  for (i = 0; i < (uint)arg_size; i++) {\n-    Node* parm = initial_gvn()->transform(new ParmNode(start, i));\n+  PhaseGVN& gvn = *initial_gvn();\n+  uint i = 0;\n+  for (uint j = 0; i < (uint)arg_size; i++) {\n+    const Type* t = tf->domain_sig()->field_at(i);\n+    Node* parm = NULL;\n+    if (has_scalarized_args() && t->is_inlinetypeptr() && !t->maybe_null() && t->inline_klass()->can_be_passed_as_fields()) {\n+      \/\/ Inline type arguments are not passed by reference: we get an argument per\n+      \/\/ field of the inline type. Build InlineTypeNodes from the inline type arguments.\n+      GraphKit kit(jvms, &gvn);\n+      kit.set_control(map->control());\n+      Node* old_mem = map->memory();\n+      \/\/ Use immutable memory for inline type loads and restore it below\n+      kit.set_all_memory(C->immutable_memory());\n+      parm = InlineTypeNode::make_from_multi(&kit, start, t->inline_klass(), j, true);\n+      map->set_control(kit.control());\n+      map->set_memory(old_mem);\n+    } else {\n+      parm = gvn.transform(new ParmNode(start, j++));\n+    }\n@@ -841,1 +889,0 @@\n-  jvms->set_map(map);\n@@ -868,1 +915,1 @@\n-  int ret_size = tf()->range()->cnt() - TypeFunc::Parms;\n+  int ret_size = tf()->range_sig()->cnt() - TypeFunc::Parms;\n@@ -872,2 +919,18 @@\n-    ret->add_req(kit.argument(0));\n-    \/\/ Note:  The second dummy edge is not needed by a ReturnNode.\n+    Node* res = kit.argument(0);\n+    if (tf()->returns_inline_type_as_fields()) {\n+      \/\/ Multiple return values (inline type fields): add as many edges\n+      \/\/ to the Return node as returned values.\n+      assert(res->is_InlineType(), \"what else supports multi value return?\");\n+      InlineTypeNode* vt = res->as_InlineType();\n+      ret->add_req_batch(NULL, tf()->range_cc()->cnt() - TypeFunc::Parms);\n+      if (vt->is_allocated(&kit.gvn()) && !StressInlineTypeReturnedAsFields) {\n+        ret->init_req(TypeFunc::Parms, vt->get_oop());\n+      } else {\n+        ret->init_req(TypeFunc::Parms, vt->tagged_klass(kit.gvn()));\n+      }\n+      uint idx = TypeFunc::Parms + 1;\n+      vt->pass_fields(&kit, ret, idx);\n+    } else {\n+      ret->add_req(res);\n+      \/\/ Note:  The second dummy edge is not needed by a ReturnNode.\n+    }\n@@ -997,1 +1060,1 @@\n-  if (method()->is_initializer() &&\n+  if (method()->is_object_constructor_or_class_initializer() &&\n@@ -1035,2 +1098,2 @@\n-  if (tf()->range()->cnt() > TypeFunc::Parms) {\n-    const Type* ret_type = tf()->range()->field_at(TypeFunc::Parms);\n+  if (tf()->range_sig()->cnt() > TypeFunc::Parms) {\n+    const Type* ret_type = tf()->range_sig()->field_at(TypeFunc::Parms);\n@@ -1129,1 +1192,1 @@\n-    kit.null_check_receiver_before_call(method());\n+    kit.null_check_receiver_before_call(method(), false);\n@@ -1167,1 +1230,1 @@\n-  uint arg_size = tf()->domain()->cnt();\n+  uint arg_size = tf()->domain_sig()->cnt();\n@@ -1214,0 +1277,1 @@\n+      assert(!_gvn.type(lock_obj)->make_oopptr()->can_be_inline_type(), \"can't be an inline type\");\n@@ -1625,0 +1689,33 @@\n+  \/\/ Check for merge conflicts involving inline types\n+  JVMState* old_jvms = map()->jvms();\n+  int old_bci = bci();\n+  JVMState* tmp_jvms = old_jvms->clone_shallow(C);\n+  tmp_jvms->set_should_reexecute(true);\n+  tmp_jvms->bind_map(map());\n+  \/\/ Execution needs to restart a the next bytecode (entry of next\n+  \/\/ block)\n+  if (target->is_merged() ||\n+      pnum > PhiNode::Input ||\n+      target->is_handler() ||\n+      target->is_loop_head()) {\n+    set_parse_bci(target->start());\n+    for (uint j = TypeFunc::Parms; j < map()->req(); j++) {\n+      Node* n = map()->in(j);                 \/\/ Incoming change to target state.\n+      const Type* t = NULL;\n+      if (tmp_jvms->is_loc(j)) {\n+        t = target->local_type_at(j - tmp_jvms->locoff());\n+      } else if (tmp_jvms->is_stk(j) && j < (uint)sp() + tmp_jvms->stkoff()) {\n+        t = target->stack_type_at(j - tmp_jvms->stkoff());\n+      }\n+      if (t != NULL && t != Type::BOTTOM) {\n+        if (n->is_InlineType() && !t->isa_inlinetype()) {\n+          \/\/ Allocate inline type in src block to be able to merge it with oop in target block\n+          map()->set_req(j, n->as_InlineType()->buffer(this));\n+        }\n+        assert(!t->isa_inlinetype() || n->is_InlineType(), \"inconsistent typeflow info\");\n+      }\n+    }\n+  }\n+  old_jvms->bind_map(map());\n+  set_parse_bci(old_bci);\n+\n@@ -1678,0 +1775,1 @@\n+\n@@ -1713,0 +1811,1 @@\n+    bool last_merge = (pnum == PhiNode::Input);\n@@ -1717,1 +1816,1 @@\n-      if (m->is_Phi() && m->as_Phi()->region() == r)\n+      if (m->is_Phi() && m->as_Phi()->region() == r) {\n@@ -1719,1 +1818,3 @@\n-      else\n+      } else if (m->is_InlineType() && m->as_InlineType()->has_phi_inputs(r)){\n+        phi = m->as_InlineType()->get_oop()->as_Phi();\n+      } else {\n@@ -1721,0 +1822,1 @@\n+      }\n@@ -1754,1 +1856,24 @@\n-      if (phi != NULL) {\n+      \/\/ Merging two inline types?\n+      if (phi != NULL && n->is_InlineType()) {\n+        \/\/ Reload current state because it may have been updated by ensure_phi\n+        m = map()->in(j);\n+        InlineTypeNode* vtm = m->as_InlineType(); \/\/ Current inline type\n+        InlineTypeNode* vtn = n->as_InlineType(); \/\/ Incoming inline type\n+        assert(vtm->get_oop() == phi, \"Inline type should have Phi input\");\n+        if (TraceOptoParse) {\n+#ifdef ASSERT\n+          tty->print_cr(\"\\nMerging inline types\");\n+          tty->print_cr(\"Current:\");\n+          vtm->dump(2);\n+          tty->print_cr(\"Incoming:\");\n+          vtn->dump(2);\n+          tty->cr();\n+#endif\n+        }\n+        \/\/ Do the merge\n+        vtm->merge_with(&_gvn, vtn, pnum, last_merge);\n+        if (last_merge) {\n+          map()->set_req(j, _gvn.transform_no_reclaim(vtm));\n+          record_for_igvn(vtm);\n+        }\n+      } else if (phi != NULL) {\n@@ -1758,1 +1883,1 @@\n-        if (pnum == PhiNode::Input) {\n+        if (last_merge) {\n@@ -1774,2 +1899,1 @@\n-    if (pnum == PhiNode::Input &&\n-        !r->in(0)) {         \/\/ The occasional useless Region\n+    if (last_merge && !r->in(0)) {         \/\/ The occasional useless Region\n@@ -1927,0 +2051,2 @@\n+      } else if (n->is_InlineType() && n->as_InlineType()->has_phi_inputs(r)) {\n+        n->as_InlineType()->add_new_path(r);\n@@ -1949,0 +2075,4 @@\n+  InlineTypeBaseNode* vt = o->isa_InlineType();\n+  if (vt != NULL && vt->has_phi_inputs(region)) {\n+    return vt->get_oop()->as_Phi();\n+  }\n@@ -1968,2 +2098,2 @@\n-  \/\/ is mixing ints and oops or some such.  Forcing it to top\n-  \/\/ makes it go dead.\n+  \/\/ is already dead or is mixing ints and oops or some such.\n+  \/\/ Forcing it to top makes it go dead.\n@@ -1982,5 +2112,14 @@\n-  PhiNode* phi = PhiNode::make(region, o, t);\n-  gvn().set_type(phi, t);\n-  if (C->do_escape_analysis()) record_for_igvn(phi);\n-  map->set_req(idx, phi);\n-  return phi;\n+  if (vt != NULL) {\n+    \/\/ Inline types are merged by merging their field values.\n+    \/\/ Create a cloned InlineTypeNode with phi inputs that\n+    \/\/ represents the merged inline type and update the map.\n+    vt = vt->clone_with_phis(&_gvn, region);\n+    map->set_req(idx, vt);\n+    return vt->get_oop()->as_Phi();\n+  } else {\n+    PhiNode* phi = PhiNode::make(region, o, t);\n+    gvn().set_type(phi, t);\n+    if (C->do_escape_analysis()) record_for_igvn(phi);\n+    map->set_req(idx, phi);\n+    return phi;\n+  }\n@@ -2179,1 +2318,4 @@\n-  set_bci(InvocationEntryBci);\n+  \/\/ vreturn can trigger an allocation so vreturn can throw. Setting\n+  \/\/ the bci here breaks exception handling. Commenting this out\n+  \/\/ doesn't seem to break anything.\n+  \/\/  set_bci(InvocationEntryBci);\n@@ -2186,17 +2328,0 @@\n-  SafePointNode* exit_return = _exits.map();\n-  exit_return->in( TypeFunc::Control  )->add_req( control() );\n-  exit_return->in( TypeFunc::I_O      )->add_req( i_o    () );\n-  Node *mem = exit_return->in( TypeFunc::Memory   );\n-  for (MergeMemStream mms(mem->as_MergeMem(), merged_memory()); mms.next_non_empty2(); ) {\n-    if (mms.is_empty()) {\n-      \/\/ get a copy of the base memory, and patch just this one input\n-      const TypePtr* adr_type = mms.adr_type(C);\n-      Node* phi = mms.force_memory()->as_Phi()->slice_memory(adr_type);\n-      assert(phi->as_Phi()->region() == mms.base_memory()->in(0), \"\");\n-      gvn().set_type_bottom(phi);\n-      phi->del_req(phi->req()-1);  \/\/ prepare to re-patch\n-      mms.set_memory(phi);\n-    }\n-    mms.memory()->add_req(mms.memory2());\n-  }\n-\n@@ -2205,9 +2330,29 @@\n-    \/\/ If returning oops to an interface-return, there is a silent free\n-    \/\/ cast from oop to interface allowed by the Verifier.  Make it explicit\n-    \/\/ here.\n-    const TypeInstPtr *tr = phi->bottom_type()->isa_instptr();\n-    if (tr && tr->klass()->is_loaded() &&\n-        tr->klass()->is_interface()) {\n-      const TypeInstPtr *tp = value->bottom_type()->isa_instptr();\n-      if (tp && tp->klass()->is_loaded() &&\n-          !tp->klass()->is_interface()) {\n+    const Type* return_type = phi->bottom_type();\n+    const TypeOopPtr* tr = return_type->isa_oopptr();\n+    \/\/ The return_type is set in Parse::build_exits().\n+    if (return_type->isa_inlinetype()) {\n+      \/\/ Inline type is returned as fields, make sure it is scalarized\n+      if (!value->is_InlineType()) {\n+        value = InlineTypeNode::make_from_oop(this, value, return_type->inline_klass());\n+      }\n+      if (!_caller->has_method() || Compile::current()->inlining_incrementally()) {\n+        \/\/ Returning from root or an incrementally inlined method. Make sure all non-flattened\n+        \/\/ fields are buffered and re-execute if allocation triggers deoptimization.\n+        PreserveReexecuteState preexecs(this);\n+        assert(tf()->returns_inline_type_as_fields(), \"must be returned as fields\");\n+        jvms()->set_should_reexecute(true);\n+        inc_sp(1);\n+        value = value->as_InlineType()->allocate_fields(this);\n+      }\n+    } else if (value->is_InlineType()) {\n+      \/\/ Inline type is returned as oop, make sure it is buffered and re-execute\n+      \/\/ if allocation triggers deoptimization.\n+      PreserveReexecuteState preexecs(this);\n+      jvms()->set_should_reexecute(true);\n+      inc_sp(1);\n+      value = value->as_InlineType()->buffer(this);\n+    } else if (tr && tr->isa_instptr() && tr->klass()->is_loaded() && tr->klass()->is_interface()) {\n+      \/\/ If returning oops to an interface-return, there is a silent free\n+      \/\/ cast from oop to interface allowed by the Verifier. Make it explicit here.\n+      const TypeInstPtr* tp = value->bottom_type()->isa_instptr();\n+      if (tp && tp->klass()->is_loaded() && !tp->klass()->is_interface()) {\n@@ -2216,1 +2361,1 @@\n-        if (tp->higher_equal(TypeInstPtr::NOTNULL))\n+        if (tp->higher_equal(TypeInstPtr::NOTNULL)) {\n@@ -2218,0 +2363,1 @@\n+        }\n@@ -2221,1 +2367,1 @@\n-      \/\/ Also handle returns of oop-arrays to an arrays-of-interface return\n+      \/\/ Handle returns of oop-arrays to an arrays-of-interface return\n@@ -2224,1 +2370,1 @@\n-      Type::get_arrays_base_elements(phi->bottom_type(), value->bottom_type(), &phi_tip, &val_tip);\n+      Type::get_arrays_base_elements(return_type, value->bottom_type(), &phi_tip, &val_tip);\n@@ -2227,1 +2373,1 @@\n-        value = _gvn.transform(new CheckCastPPNode(0, value, phi->bottom_type()));\n+        value = _gvn.transform(new CheckCastPPNode(0, value, return_type));\n@@ -2233,0 +2379,17 @@\n+  SafePointNode* exit_return = _exits.map();\n+  exit_return->in( TypeFunc::Control  )->add_req( control() );\n+  exit_return->in( TypeFunc::I_O      )->add_req( i_o    () );\n+  Node *mem = exit_return->in( TypeFunc::Memory   );\n+  for (MergeMemStream mms(mem->as_MergeMem(), merged_memory()); mms.next_non_empty2(); ) {\n+    if (mms.is_empty()) {\n+      \/\/ get a copy of the base memory, and patch just this one input\n+      const TypePtr* adr_type = mms.adr_type(C);\n+      Node* phi = mms.force_memory()->as_Phi()->slice_memory(adr_type);\n+      assert(phi->as_Phi()->region() == mms.base_memory()->in(0), \"\");\n+      gvn().set_type_bottom(phi);\n+      phi->del_req(phi->req()-1);  \/\/ prepare to re-patch\n+      mms.set_memory(phi);\n+    }\n+    mms.memory()->add_req(mms.memory2());\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":245,"deletions":82,"binary":false,"changes":327,"status":"modified"},{"patch":"@@ -1224,6 +1224,0 @@\n-  if (_delay_transform) {\n-    \/\/ Register the node but don't optimize for now\n-    register_new_node_with_optimizer(n);\n-    return n;\n-  }\n-\n@@ -1236,0 +1230,6 @@\n+  if (_delay_transform) {\n+    \/\/ Add the node to the worklist but don't optimize for now\n+    _worklist.push(n);\n+    return n;\n+  }\n+\n@@ -1498,0 +1498,13 @@\n+void PhaseIterGVN::replace_in_uses(Node* n, Node* m) {\n+  assert(n != NULL, \"sanity\");\n+  for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+    Node* u = n->fast_out(i);\n+    if (u != n) {\n+      rehash_node_delayed(u);\n+      int nb = u->replace_edge(n, m);\n+      --i, imax -= nb;\n+    }\n+  }\n+  assert(n->outcnt() == 0, \"all uses must be deleted\");\n+}\n+\n@@ -1598,0 +1611,9 @@\n+    \/\/ Inline type nodes can have other inline types as users. If an input gets\n+    \/\/ updated, make sure that inline type users get a chance for optimization.\n+    if (use->is_InlineTypeBase()) {\n+      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+        Node* u = use->fast_out(i2);\n+        if (u->is_InlineTypeBase())\n+          _worklist.push(u);\n+      }\n+    }\n@@ -1643,0 +1665,8 @@\n+    if (use_op == Op_CastP2X) {\n+      for (DUIterator_Fast i2max, i2 = use->fast_outs(i2max); i2 < i2max; i2++) {\n+        Node* u = use->fast_out(i2);\n+        if (u->Opcode() == Op_AndX) {\n+          _worklist.push(u);\n+        }\n+      }\n+    }\n@@ -1667,0 +1697,11 @@\n+\n+    \/\/ Give CallStaticJavaNode::remove_useless_allocation a chance to run\n+    if (use->is_Region()) {\n+      Node* c = use;\n+      do {\n+        c = c->unique_ctrl_out();\n+      } while (c != NULL && c->is_Region());\n+      if (c != NULL && c->is_CallStaticJava() && c->as_CallStaticJava()->uncommon_trap_request() != 0) {\n+        _worklist.push(c);\n+      }\n+    }\n@@ -1837,0 +1878,8 @@\n+        if (m_op == Op_CastP2X) {\n+          for (DUIterator_Fast i2max, i2 = m->fast_outs(i2max); i2 < i2max; i2++) {\n+            Node* u = m->fast_out(i2);\n+            if (u->Opcode() == Op_AndX) {\n+              worklist.push(u);\n+            }\n+          }\n+        }\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":55,"deletions":6,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -470,1 +470,1 @@\n-  virtual void record_for_igvn(Node *n) { }\n+  virtual void record_for_igvn(Node *n) { _worklist.push(n); }\n@@ -520,0 +520,2 @@\n+  void replace_in_uses(Node* n, Node* m);\n+\n","filename":"src\/hotspot\/share\/opto\/phaseX.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -71,0 +71,2 @@\n+  PHASE_SPLIT_INLINES_ARRAY,\n+  PHASE_SPLIT_INLINES_ARRAY_IGVN,\n@@ -72,1 +74,0 @@\n-\n@@ -122,0 +123,2 @@\n+      case PHASE_SPLIT_INLINES_ARRAY:        return \"Split inlines array\";\n+      case PHASE_SPLIT_INLINES_ARRAY_IGVN:   return \"IGVN after split inlines array\";\n","filename":"src\/hotspot\/share\/opto\/phasetype.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -49,0 +49,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n@@ -200,1 +202,1 @@\n-JRT_BLOCK_ENTRY(void, OptoRuntime::new_instance_C(Klass* klass, JavaThread* current))\n+JRT_BLOCK_ENTRY(void, OptoRuntime::new_instance_C(Klass* klass, bool is_larval, JavaThread* current))\n@@ -220,1 +222,5 @@\n-    oop result = InstanceKlass::cast(klass)->allocate_instance(THREAD);\n+    instanceOop result = InstanceKlass::cast(klass)->allocate_instance(THREAD);\n+    if (is_larval) {\n+      \/\/ Check if this is a larval buffer allocation\n+      result->set_mark(result->mark().enter_larval_state());\n+    }\n@@ -248,1 +254,4 @@\n-  if (array_type->is_typeArray_klass()) {\n+  if (array_type->is_flatArray_klass()) {\n+    Klass* elem_type = FlatArrayKlass::cast(array_type)->element_klass();\n+    result = oopFactory::new_flatArray(elem_type, len, THREAD);\n+  } else if (array_type->is_typeArray_klass()) {\n@@ -254,3 +263,0 @@\n-    \/\/ Although the oopFactory likes to work with the elem_type,\n-    \/\/ the compiler prefers the array_type, since it must already have\n-    \/\/ that latter value in hand for the fast path.\n@@ -258,2 +264,1 @@\n-    Klass* elem_type = ObjArrayKlass::cast(array_type)->element_klass();\n-    result = oopFactory::new_objArray(elem_type, len, THREAD);\n+    result = ObjArrayKlass::cast(array_type)->allocate(len, THREAD);\n@@ -453,1 +458,1 @@\n-  const Type **fields = TypeTuple::fields(1);\n+  const Type **fields = TypeTuple::fields(2);\n@@ -455,1 +460,2 @@\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+1, fields);\n+  fields[TypeFunc::Parms+1] = TypeInt::BOOL;        \/\/ is_larval\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n@@ -573,1 +579,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1499,1 +1505,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1517,1 +1523,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1533,1 +1539,1 @@\n-  return TypeFunc::make(domain,range);\n+  return TypeFunc::make(domain, range);\n@@ -1665,0 +1671,106 @@\n+\n+const TypeFunc *OptoRuntime::store_inline_type_fields_Type() {\n+  \/\/ create input type (domain)\n+  uint total = SharedRuntime::java_return_convention_max_int + SharedRuntime::java_return_convention_max_float*2;\n+  const Type **fields = TypeTuple::fields(total);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypePtr::BOTTOM;\n+  uint i = 1;\n+  for (; i < SharedRuntime::java_return_convention_max_int; i++) {\n+    fields[TypeFunc::Parms+i] = TypeInt::INT;\n+  }\n+  for (; i < total; i+=2) {\n+    fields[TypeFunc::Parms+i] = Type::DOUBLE;\n+    fields[TypeFunc::Parms+i+1] = Type::HALF;\n+  }\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + total, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1,fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+const TypeFunc *OptoRuntime::pack_inline_type_Type() {\n+  \/\/ create input type (domain)\n+  uint total = 1 + SharedRuntime::java_return_convention_max_int + SharedRuntime::java_return_convention_max_float*2;\n+  const Type **fields = TypeTuple::fields(total);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypeRawPtr::BOTTOM;\n+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;\n+  uint i = 2;\n+  for (; i < SharedRuntime::java_return_convention_max_int+1; i++) {\n+    fields[TypeFunc::Parms+i] = TypeInt::INT;\n+  }\n+  for (; i < total; i+=2) {\n+    fields[TypeFunc::Parms+i] = Type::DOUBLE;\n+    fields[TypeFunc::Parms+i+1] = Type::HALF;\n+  }\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + total, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1,fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+JRT_LEAF(void, OptoRuntime::load_unknown_inline(flatArrayOopDesc* array, int index, instanceOopDesc* buffer))\n+{\n+  array->value_copy_from_index(index, buffer);\n+}\n+JRT_END\n+\n+const TypeFunc* OptoRuntime::load_unknown_inline_type() {\n+  \/\/ create input type (domain)\n+  const Type** fields = TypeTuple::fields(3);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypeOopPtr::NOTNULL;\n+  fields[TypeFunc::Parms+1] = TypeInt::POS;\n+  fields[TypeFunc::Parms+2] = TypeInstPtr::NOTNULL;\n+\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(0);\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms+0, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n+JRT_LEAF(void, OptoRuntime::store_unknown_inline(instanceOopDesc* buffer, flatArrayOopDesc* array, int index))\n+{\n+  assert(buffer != NULL, \"can't store null into flat array\");\n+  array->value_copy_to_index(buffer, index);\n+}\n+JRT_END\n+\n+const TypeFunc* OptoRuntime::store_unknown_inline_type() {\n+  \/\/ create input type (domain)\n+  const Type** fields = TypeTuple::fields(3);\n+  \/\/ We don't know the number of returned values and their\n+  \/\/ types. Assume all registers available to the return convention\n+  \/\/ are used.\n+  fields[TypeFunc::Parms] = TypeInstPtr::NOTNULL;\n+  fields[TypeFunc::Parms+1] = TypeOopPtr::NOTNULL;\n+  fields[TypeFunc::Parms+2] = TypeInt::POS;\n+\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(0);\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms+0, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":126,"deletions":14,"binary":false,"changes":140,"status":"modified"},{"patch":"@@ -158,1 +158,1 @@\n-  static void new_instance_C(Klass* instance_klass, JavaThread* current);\n+  static void new_instance_C(Klass* instance_klass, bool is_larval, JavaThread* current);\n@@ -311,0 +311,8 @@\n+  static const TypeFunc* store_inline_type_fields_Type();\n+  static const TypeFunc* pack_inline_type_Type();\n+\n+  static void load_unknown_inline(flatArrayOopDesc* array, int index, instanceOopDesc* buffer);\n+  static const TypeFunc* load_unknown_inline_type();\n+  static void store_unknown_inline(instanceOopDesc* buffer, flatArrayOopDesc* array, int index);\n+  static const TypeFunc* store_unknown_inline_type();\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -787,1 +787,8 @@\n-Node *CmpLNode::Ideal( PhaseGVN *phase, bool can_reshape ) {\n+\/\/------------------------------Ideal------------------------------------------\n+Node* CmpLNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* a = NULL;\n+  Node* b = NULL;\n+  if (is_double_null_check(phase, a, b) && (phase->type(a)->is_zero_type() || phase->type(b)->is_zero_type())) {\n+    \/\/ Degraded to a simple null check, use old acmp\n+    return new CmpPNode(a, b);\n+  }\n@@ -798,0 +805,25 @@\n+\/\/ Match double null check emitted by Compile::optimize_acmp()\n+bool CmpLNode::is_double_null_check(PhaseGVN* phase, Node*& a, Node*& b) const {\n+  if (in(1)->Opcode() == Op_OrL &&\n+      in(1)->in(1)->Opcode() == Op_CastP2X &&\n+      in(1)->in(2)->Opcode() == Op_CastP2X &&\n+      in(2)->bottom_type()->is_zero_type()) {\n+    assert(EnableValhalla, \"unexpected double null check\");\n+    a = in(1)->in(1)->in(1);\n+    b = in(1)->in(2)->in(1);\n+    return true;\n+  }\n+  return false;\n+}\n+\n+\/\/------------------------------Value------------------------------------------\n+const Type* CmpLNode::Value(PhaseGVN* phase) const {\n+  Node* a = NULL;\n+  Node* b = NULL;\n+  if (is_double_null_check(phase, a, b) && (!phase->type(a)->maybe_null() || !phase->type(b)->maybe_null())) {\n+    \/\/ One operand is never NULL, emit constant false\n+    return TypeInt::CC_GT;\n+  }\n+  return SubNode::Value(phase);\n+}\n+\n@@ -956,0 +988,16 @@\n+      if (!unrelated_classes) {\n+        \/\/ Handle inline type arrays\n+        if ((r0->flatten_array() && (!r1->can_be_inline_type() || (klass1->is_inlinetype() && !klass1->flatten_array()))) ||\n+            (r1->flatten_array() && (!r0->can_be_inline_type() || (klass0->is_inlinetype() && !klass0->flatten_array())))) {\n+          \/\/ One type is flattened in arrays but the other type is not. Must be unrelated.\n+          unrelated_classes = true;\n+        } else if ((r0->is_not_flat() && klass1->is_flat_array_klass()) ||\n+                   (r1->is_not_flat() && klass0->is_flat_array_klass())) {\n+          \/\/ One type is a non-flattened array and the other type is a flattened array. Must be unrelated.\n+          unrelated_classes = true;\n+        } else if ((r0->is_not_null_free() && klass1->is_obj_array_klass() && klass1->as_obj_array_klass()->element_klass()->is_inlinetype()) ||\n+                   (r1->is_not_null_free() && klass0->is_obj_array_klass() && klass0->as_obj_array_klass()->element_klass()->is_inlinetype())) {\n+          \/\/ One type is a non-null-free array and the other type is a null-free array. Must be unrelated.\n+          unrelated_classes = true;\n+        }\n+      }\n@@ -1041,1 +1089,1 @@\n-Node *CmpPNode::Ideal( PhaseGVN *phase, bool can_reshape ) {\n+Node* CmpPNode::Ideal(PhaseGVN *phase, bool can_reshape) {\n@@ -1256,0 +1304,39 @@\n+\/\/=============================================================================\n+\/\/------------------------------Value------------------------------------------\n+const Type* FlatArrayCheckNode::Value(PhaseGVN* phase) const {\n+  bool all_not_flat = true;\n+  for (uint i = Array; i < req(); ++i) {\n+    Node* array = in(i);\n+    if (!array->is_top()) {\n+      const Type* t = phase->type(array);\n+      if (t == Type::TOP) {\n+        return Type::TOP;\n+      } else if (t->is_aryptr()->is_flat()) {\n+        \/\/ One of the input arrays is flat, check always passes\n+        return TypeInt::CC_EQ;\n+      } else if (!t->is_aryptr()->is_not_flat()) {\n+        \/\/ One of the input arrays might be flat\n+        all_not_flat = false;\n+      }\n+    }\n+  }\n+  if (all_not_flat) {\n+    \/\/ None of the input arrays can be flat, check always fails\n+    return TypeInt::CC_GT;\n+  }\n+  return TypeInt::CC;\n+}\n+\n+\/\/------------------------------Ideal------------------------------------------\n+Node* FlatArrayCheckNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  bool changed = false;\n+  \/\/ Remove array inputs that are known to be non-flat\n+  for (uint i = Array; i < req(); ++i) {\n+    const TypeAryPtr* t = phase->type(in(i))->isa_aryptr();\n+    if (t != NULL && t->is_not_flat()) {\n+      set_req(i, phase->C->top());\n+      changed = true;\n+    }\n+  }\n+  return changed ? this : NULL;\n+}\n","filename":"src\/hotspot\/share\/opto\/subnode.cpp","additions":89,"deletions":2,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -79,0 +79,14 @@\n+    if (!unrelated_classes) {\n+      \/\/ Handle inline type arrays\n+      if (sub_t->isa_aryptr() && sub_t->is_aryptr()->is_not_flat() && superk->is_flat_array_klass()) {\n+        \/\/ Subtype is not a flat array but supertype is. Must be unrelated.\n+        unrelated_classes = true;\n+      } else if (sub_t->isa_aryptr() && sub_t->is_aryptr()->is_not_null_free() &&\n+                 superk->is_obj_array_klass() && superk->as_obj_array_klass()->element_klass()->is_inlinetype()) {\n+        \/\/ Subtype is not a null-free array but supertype is. Must be unrelated.\n+        unrelated_classes = true;\n+      } else if (sub_t->is_ptr()->flatten_array() && (!superk->can_be_inline_klass() || (superk->is_inlinetype() && !superk->flatten_array()))) {\n+        \/\/ Subtype is flattened in arrays but supertype is not. Must be unrelated.\n+        unrelated_classes = true;\n+      }\n+    }\n","filename":"src\/hotspot\/share\/opto\/subtypenode.cpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -26,0 +26,3 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n+#include \"ci\/ciField.hpp\"\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -51,0 +54,46 @@\n+const Type::Offset Type::Offset::top(Type::OffsetTop);\n+const Type::Offset Type::Offset::bottom(Type::OffsetBot);\n+\n+const Type::Offset Type::Offset::meet(const Type::Offset other) const {\n+  \/\/ Either is 'TOP' offset?  Return the other offset!\n+  int offset = other._offset;\n+  if (_offset == OffsetTop) return Offset(offset);\n+  if (offset == OffsetTop) return Offset(_offset);\n+  \/\/ If either is different, return 'BOTTOM' offset\n+  if (_offset != offset) return bottom;\n+  return Offset(_offset);\n+}\n+\n+const Type::Offset Type::Offset::dual() const {\n+  if (_offset == OffsetTop) return bottom;\/\/ Map 'TOP' into 'BOTTOM'\n+  if (_offset == OffsetBot) return top;\/\/ Map 'BOTTOM' into 'TOP'\n+  return Offset(_offset);               \/\/ Map everything else into self\n+}\n+\n+const Type::Offset Type::Offset::add(intptr_t offset) const {\n+  \/\/ Adding to 'TOP' offset?  Return 'TOP'!\n+  if (_offset == OffsetTop || offset == OffsetTop) return top;\n+  \/\/ Adding to 'BOTTOM' offset?  Return 'BOTTOM'!\n+  if (_offset == OffsetBot || offset == OffsetBot) return bottom;\n+  \/\/ Addition overflows or \"accidentally\" equals to OffsetTop? Return 'BOTTOM'!\n+  offset += (intptr_t)_offset;\n+  if (offset != (int)offset || offset == OffsetTop) return bottom;\n+\n+  \/\/ assert( _offset >= 0 && _offset+offset >= 0, \"\" );\n+  \/\/ It is possible to construct a negative offset during PhaseCCP\n+\n+  return Offset((int)offset);        \/\/ Sum valid offsets\n+}\n+\n+void Type::Offset::dump2(outputStream *st) const {\n+  if (_offset == 0) {\n+    return;\n+  } else if (_offset == OffsetTop) {\n+    st->print(\"+top\");\n+  }\n+  else if (_offset == OffsetBot) {\n+    st->print(\"+bot\");\n+  } else if (_offset) {\n+    st->print(\"+%d\", _offset);\n+  }\n+}\n@@ -90,0 +139,1 @@\n+  { Bad,             T_INLINE_TYPE, \"inline:\",      false, Node::NotAMachineReg, relocInfo::none          },  \/\/ InlineType\n@@ -220,0 +270,9 @@\n+  case T_INLINE_TYPE: {\n+    ciInlineKlass* vk = type->as_inline_klass();\n+    if (vk->is_scalarizable()) {\n+      return TypeInlineType::make(vk);\n+    } else {\n+      return TypeOopPtr::make_from_klass(vk)->join_speculative(TypePtr::NOTNULL);\n+    }\n+  }\n+\n@@ -248,0 +307,1 @@\n+    case T_INLINE_TYPE:\n@@ -285,0 +345,1 @@\n+    case T_INLINE_TYPE: conbt = T_OBJECT; break;\n@@ -291,0 +352,1 @@\n+    case T_INLINE_TYPE: loadbt = T_OBJECT; break;\n@@ -526,3 +588,3 @@\n-  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, 0);\n-  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, OffsetBot);\n-  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, OffsetBot);\n+  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, Offset(0));\n+  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, Offset::bottom);\n+  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, Offset::bottom);\n@@ -545,1 +607,1 @@\n-                                           false, 0, oopDesc::mark_offset_in_bytes());\n+                                           false, 0, Offset(oopDesc::mark_offset_in_bytes()));\n@@ -547,2 +609,2 @@\n-                                           false, 0, oopDesc::klass_offset_in_bytes());\n-  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, OffsetBot, TypeOopPtr::InstanceBot);\n+                                           false, 0, Offset(oopDesc::klass_offset_in_bytes()));\n+  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, Offset::bottom, TypeOopPtr::InstanceBot);\n@@ -550,1 +612,3 @@\n-  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, NULL, OffsetBot);\n+  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, NULL, Offset::bottom);\n+\n+  TypeInlineType::BOTTOM = TypeInlineType::make(NULL);\n@@ -567,1 +631,1 @@\n-  TypeAryPtr::RANGE   = TypeAryPtr::make( TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), NULL \/* current->env()->Object_klass() *\/, false, arrayOopDesc::length_offset_in_bytes());\n+  TypeAryPtr::RANGE   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), NULL \/* current->env()->Object_klass() *\/, false, Offset(arrayOopDesc::length_offset_in_bytes()));\n@@ -569,1 +633,1 @@\n-  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Type::OffsetBot);\n+  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Offset::bottom);\n@@ -579,1 +643,1 @@\n-    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Type::OffsetBot);\n+    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), NULL \/*ciArrayKlass::make(o)*\/,  false,  Offset::bottom);\n@@ -581,7 +645,8 @@\n-  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Type::OffsetBot);\n-  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Type::OffsetBot);\n-  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Type::OffsetBot);\n-  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Type::OffsetBot);\n-  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Type::OffsetBot);\n-  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Type::OffsetBot);\n-  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Type::OffsetBot);\n+  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Offset::bottom);\n+  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Offset::bottom);\n+  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Offset::bottom);\n+  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Offset::bottom);\n+  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Offset::bottom);\n+  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Offset::bottom);\n+  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Offset::bottom);\n+  TypeAryPtr::INLINES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInlineType::BOTTOM,TypeInt::POS), NULL, false,  Offset::bottom);\n@@ -592,0 +657,1 @@\n+  TypeAryPtr::_array_body_type[T_INLINE_TYPE] = TypeAryPtr::OOPS;\n@@ -602,2 +668,2 @@\n-  TypeKlassPtr::OBJECT = TypeKlassPtr::make( TypePtr::NotNull, current->env()->Object_klass(), 0 );\n-  TypeKlassPtr::OBJECT_OR_NULL = TypeKlassPtr::make( TypePtr::BotPTR, current->env()->Object_klass(), 0 );\n+  TypeKlassPtr::OBJECT = TypeKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), Offset(0));\n+  TypeKlassPtr::OBJECT_OR_NULL = TypeKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), Offset(0));\n@@ -642,0 +708,1 @@\n+  _const_basic_type[T_INLINE_TYPE] = TypeInstPtr::BOTTOM;\n@@ -658,0 +725,1 @@\n+  _zero_type[T_INLINE_TYPE] = TypePtr::NULL_PTR;\n@@ -947,0 +1015,3 @@\n+  case InlineType:\n+    return t->xmeet(this);\n+\n@@ -1114,0 +1185,1 @@\n+    case Type::InlineType:\n@@ -1483,0 +1555,1 @@\n+  case InlineType:\n@@ -1968,0 +2041,12 @@\n+static void collect_inline_fields(ciInlineKlass* vk, const Type** field_array, uint& pos) {\n+  for (int j = 0; j < vk->nof_nonstatic_fields(); j++) {\n+    ciField* field = vk->nonstatic_field_at(j);\n+    BasicType bt = field->type()->basic_type();\n+    const Type* ft = Type::get_const_type(field->type());\n+    field_array[pos++] = ft;\n+    if (type2size[bt] == 2) {\n+      field_array[pos++] = Type::HALF;\n+    }\n+  }\n+}\n+\n@@ -1970,1 +2055,1 @@\n-const TypeTuple *TypeTuple::make_range(ciSignature* sig) {\n+const TypeTuple *TypeTuple::make_range(ciSignature* sig, bool ret_vt_fields) {\n@@ -1973,0 +2058,4 @@\n+  if (ret_vt_fields) {\n+    arg_cnt = return_type->as_inline_klass()->inline_arg_slots() + 1;\n+  }\n+\n@@ -1993,0 +2082,9 @@\n+  case T_INLINE_TYPE:\n+    if (ret_vt_fields) {\n+      uint pos = TypeFunc::Parms;\n+      field_array[pos++] = get_const_type(return_type);\n+      collect_inline_fields(return_type->as_inline_klass(), field_array, pos);\n+    } else {\n+      field_array[TypeFunc::Parms] = get_const_type(return_type)->join_speculative(TypePtr::NOTNULL);\n+    }\n+    break;\n@@ -2002,2 +2100,9 @@\n-const TypeTuple *TypeTuple::make_domain(ciInstanceKlass* recv, ciSignature* sig) {\n-  uint arg_cnt = sig->size();\n+const TypeTuple *TypeTuple::make_domain(ciMethod* method, bool vt_fields_as_args) {\n+  ciSignature* sig = method->signature();\n+  uint arg_cnt = sig->size() + (method->is_static() ? 0 : 1);\n+  if (vt_fields_as_args) {\n+    arg_cnt = 0;\n+    for (ExtendedSignature sig_cc = ExtendedSignature(method->get_sig_cc(), SigEntryFilter()); !sig_cc.at_end(); ++sig_cc) {\n+      arg_cnt += type2size[(*sig_cc)._bt];\n+    }\n+  }\n@@ -2006,8 +2111,8 @@\n-  const Type **field_array;\n-  if (recv != NULL) {\n-    arg_cnt++;\n-    field_array = fields(arg_cnt);\n-    \/\/ Use get_const_type here because it respects UseUniqueSubclasses:\n-    field_array[pos++] = get_const_type(recv)->join_speculative(TypePtr::NOTNULL);\n-  } else {\n-    field_array = fields(arg_cnt);\n+  const Type** field_array = fields(arg_cnt);\n+  if (!method->is_static()) {\n+    ciInstanceKlass* recv = method->holder();\n+    if (vt_fields_as_args && recv->is_inlinetype() && recv->as_inline_klass()->can_be_passed_as_fields()) {\n+      collect_inline_fields(recv->as_inline_klass(), field_array, pos);\n+    } else {\n+      field_array[pos++] = get_const_type(recv)->join_speculative(TypePtr::NOTNULL);\n+    }\n@@ -2019,0 +2124,1 @@\n+    BasicType bt = type->basic_type();\n@@ -2020,1 +2126,1 @@\n-    switch (type->basic_type()) {\n+    switch (bt) {\n@@ -2041,0 +2147,8 @@\n+    case T_INLINE_TYPE: {\n+      if (vt_fields_as_args && type->as_inline_klass()->can_be_passed_as_fields()) {\n+        collect_inline_fields(type->as_inline_klass(), field_array, pos);\n+      } else {\n+        field_array[pos++] = get_const_type(type)->join_speculative(TypePtr::NOTNULL);\n+      }\n+      break;\n+    }\n@@ -2046,0 +2160,1 @@\n+  assert(pos == TypeFunc::Parms + arg_cnt, \"wrong number of arguments\");\n@@ -2180,1 +2295,2 @@\n-const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable) {\n+const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable,\n+                             bool not_flat, bool not_null_free) {\n@@ -2185,1 +2301,1 @@\n-  return (TypeAry*)(new TypeAry(elem,size,stable))->hashcons();\n+  return (TypeAry*)(new TypeAry(elem, size, stable, not_flat, not_null_free))->hashcons();\n@@ -2207,1 +2323,3 @@\n-                         _stable && a->_stable);\n+                         _stable && a->_stable,\n+                         _not_flat && a->_not_flat,\n+                         _not_null_free && a->_not_null_free);\n@@ -2220,1 +2338,1 @@\n-  return new TypeAry(_elem->dual(), size_dual, !_stable);\n+  return new TypeAry(_elem->dual(), size_dual, !_stable, !_not_flat, !_not_null_free);\n@@ -2229,1 +2347,4 @@\n-    _size == a->_size;\n+    _size == a->_size &&\n+    _not_flat == a->_not_flat &&\n+    _not_null_free == a->_not_null_free;\n+\n@@ -2242,1 +2363,1 @@\n-  return make(_elem->remove_speculative(), _size, _stable);\n+  return make(_elem->remove_speculative(), _size, _stable, _not_flat, _not_null_free);\n@@ -2249,1 +2370,1 @@\n-  return make(_elem->cleanup_speculative(), _size, _stable);\n+  return make(_elem->cleanup_speculative(), _size, _stable, _not_flat, _not_null_free);\n@@ -2283,0 +2404,4 @@\n+  if (Verbose) {\n+    if (_not_flat) st->print(\"not flat:\");\n+    if (_not_null_free) st->print(\"not null free:\");\n+  }\n@@ -2336,0 +2461,124 @@\n+\/\/==============================TypeInlineType=======================================\n+\n+const TypeInlineType* TypeInlineType::BOTTOM;\n+\n+\/\/------------------------------make-------------------------------------------\n+const TypeInlineType* TypeInlineType::make(ciInlineKlass* vk, bool larval) {\n+  return (TypeInlineType*)(new TypeInlineType(vk, larval))->hashcons();\n+}\n+\n+\/\/------------------------------meet-------------------------------------------\n+\/\/ Compute the MEET of two types.  It returns a new Type object.\n+const Type* TypeInlineType::xmeet(const Type* t) const {\n+  \/\/ Perform a fast test for common case; meeting the same types together.\n+  if(this == t) return this;  \/\/ Meeting same type-rep?\n+\n+  \/\/ Current \"this->_base\" is InlineType\n+  switch (t->base()) {          \/\/ switch on original type\n+\n+  case Int:\n+  case Long:\n+  case FloatTop:\n+  case FloatCon:\n+  case FloatBot:\n+  case DoubleTop:\n+  case DoubleCon:\n+  case DoubleBot:\n+  case NarrowKlass:\n+  case Bottom:\n+    return Type::BOTTOM;\n+\n+  case OopPtr:\n+  case MetadataPtr:\n+  case KlassPtr:\n+  case RawPtr:\n+    return TypePtr::BOTTOM;\n+\n+  case Top:\n+    return this;\n+\n+  case NarrowOop: {\n+    const Type* res = t->make_ptr()->xmeet(this);\n+    if (res->isa_ptr()) {\n+      return res->make_narrowoop();\n+    }\n+    return res;\n+  }\n+\n+  case AryPtr:\n+  case InstPtr: {\n+    return t->xmeet(this);\n+  }\n+\n+  case InlineType: {\n+    \/\/ All inline types inherit from Object\n+    const TypeInlineType* other = t->is_inlinetype();\n+    if (_vk == NULL) {\n+      return this;\n+    } else if (other->_vk == NULL) {\n+      return other;\n+    } else if (_vk == other->_vk) {\n+      if (_larval == other->_larval ||\n+          !_larval) {\n+        return this;\n+      } else {\n+        return t;\n+      }\n+    }\n+    return TypeInstPtr::NOTNULL;\n+  }\n+\n+  default:                      \/\/ All else is a mistake\n+    typerr(t);\n+\n+  }\n+  return this;\n+}\n+\n+\/\/------------------------------xdual------------------------------------------\n+const Type* TypeInlineType::xdual() const {\n+  return this;\n+}\n+\n+\/\/------------------------------eq---------------------------------------------\n+\/\/ Structural equality check for Type representations\n+bool TypeInlineType::eq(const Type* t) const {\n+  const TypeInlineType* vt = t->is_inlinetype();\n+  return (_vk == vt->inline_klass() && _larval == vt->larval());\n+}\n+\n+\/\/------------------------------hash-------------------------------------------\n+\/\/ Type-specific hashing function.\n+int TypeInlineType::hash(void) const {\n+  return (intptr_t)_vk;\n+}\n+\n+\/\/------------------------------singleton--------------------------------------\n+\/\/ TRUE if Type is a singleton type, FALSE otherwise. Singletons are simple constants.\n+bool TypeInlineType::singleton(void) const {\n+  return false;\n+}\n+\n+\/\/------------------------------empty------------------------------------------\n+\/\/ TRUE if Type is a type with no values, FALSE otherwise.\n+bool TypeInlineType::empty(void) const {\n+  return false;\n+}\n+\n+\/\/------------------------------dump2------------------------------------------\n+#ifndef PRODUCT\n+void TypeInlineType::dump2(Dict &d, uint depth, outputStream* st) const {\n+  if (_vk == NULL) {\n+    st->print(\"BOTTOM inlinetype\");\n+    return;\n+  }\n+  int count = _vk->nof_declared_nonstatic_fields();\n+  st->print(\"inlinetype[%d]:{\", count);\n+  st->print(\"%s\", count != 0 ? _vk->declared_nonstatic_field_at(0)->type()->name() : \"empty\");\n+  for (int i = 1; i < count; ++i) {\n+    st->print(\", %s\", _vk->declared_nonstatic_field_at(i)->type()->name());\n+  }\n+  st->print(\"}%s\", _larval?\" : larval\":\"\");\n+}\n+#endif\n+\n@@ -2508,1 +2757,1 @@\n-const TypePtr *TypePtr::make(TYPES t, enum PTR ptr, int offset, const TypePtr* speculative, int inline_depth) {\n+const TypePtr* TypePtr::make(TYPES t, enum PTR ptr, Offset offset, const TypePtr* speculative, int inline_depth) {\n@@ -2522,1 +2771,1 @@\n-  return _offset;\n+  return offset();\n@@ -2591,7 +2840,2 @@\n-int TypePtr::meet_offset( int offset ) const {\n-  \/\/ Either is 'TOP' offset?  Return the other offset!\n-  if( _offset == OffsetTop ) return offset;\n-  if( offset == OffsetTop ) return _offset;\n-  \/\/ If either is different, return 'BOTTOM' offset\n-  if( _offset != offset ) return OffsetBot;\n-  return _offset;\n+Type::Offset TypePtr::meet_offset(int offset) const {\n+  return _offset.meet(Offset(offset));\n@@ -2601,4 +2845,2 @@\n-int TypePtr::dual_offset( ) const {\n-  if( _offset == OffsetTop ) return OffsetBot;\/\/ Map 'TOP' into 'BOTTOM'\n-  if( _offset == OffsetBot ) return OffsetTop;\/\/ Map 'BOTTOM' into 'TOP'\n-  return _offset;               \/\/ Map everything else into self\n+Type::Offset TypePtr::dual_offset() const {\n+  return _offset.dual();\n@@ -2617,13 +2859,2 @@\n-int TypePtr::xadd_offset( intptr_t offset ) const {\n-  \/\/ Adding to 'TOP' offset?  Return 'TOP'!\n-  if( _offset == OffsetTop || offset == OffsetTop ) return OffsetTop;\n-  \/\/ Adding to 'BOTTOM' offset?  Return 'BOTTOM'!\n-  if( _offset == OffsetBot || offset == OffsetBot ) return OffsetBot;\n-  \/\/ Addition overflows or \"accidentally\" equals to OffsetTop? Return 'BOTTOM'!\n-  offset += (intptr_t)_offset;\n-  if (offset != (int)offset || offset == OffsetTop) return OffsetBot;\n-\n-  \/\/ assert( _offset >= 0 && _offset+offset >= 0, \"\" );\n-  \/\/ It is possible to construct a negative offset during PhaseCCP\n-\n-  return (int)offset;        \/\/ Sum valid offsets\n+Type::Offset TypePtr::xadd_offset(intptr_t offset) const {\n+  return _offset.add(offset);\n@@ -2641,1 +2872,1 @@\n-  return _ptr == a->ptr() && _offset == a->offset() && eq_speculative(a) && _inline_depth == a->_inline_depth;\n+  return _ptr == a->ptr() && _offset == a->_offset && eq_speculative(a) && _inline_depth == a->_inline_depth;\n@@ -2647,1 +2878,1 @@\n-  return java_add(java_add((jint)_ptr, (jint)_offset), java_add((jint)hash_speculative(), (jint)_inline_depth));\n+  return java_add(java_add((jint)_ptr, (jint)offset()), java_add((jint)hash_speculative(), (jint)_inline_depth));\n@@ -2907,3 +3138,1 @@\n-  if( _offset == OffsetTop ) st->print(\"+top\");\n-  else if( _offset == OffsetBot ) st->print(\"+bot\");\n-  else if( _offset ) st->print(\"+%d\", _offset);\n+  _offset.dump2(st);\n@@ -2944,1 +3173,1 @@\n-  return (_offset != OffsetBot) && !below_centerline(_ptr);\n+  return (_offset != Offset::bottom) && !below_centerline(_ptr);\n@@ -2948,1 +3177,1 @@\n-  return (_offset == OffsetTop) || above_centerline(_ptr);\n+  return (_offset == Offset::top) || above_centerline(_ptr);\n@@ -3090,1 +3319,1 @@\n-TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset,\n+TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset, Offset field_offset,\n@@ -3100,2 +3329,2 @@\n-      (offset > 0) && xk && (k != 0) && k->is_instance_klass()) {\n-    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset);\n+      (offset.get() > 0) && xk && (k != 0) && k->is_instance_klass()) {\n+    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset.get());\n@@ -3104,2 +3333,2 @@\n-  if (_offset > 0 || _offset == Type::OffsetTop || _offset == Type::OffsetBot) {\n-    if (_offset == oopDesc::klass_offset_in_bytes()) {\n+  if (this->offset() > 0 || this->offset() == Type::OffsetTop || this->offset() == Type::OffsetBot) {\n+    if (this->offset() == oopDesc::klass_offset_in_bytes()) {\n@@ -3111,3 +3340,12 @@\n-    } else if (this->isa_aryptr()) {\n-      _is_ptr_to_narrowoop = (UseCompressedOops && klass()->is_obj_array_klass() &&\n-                             _offset != arrayOopDesc::length_offset_in_bytes());\n+    } else if (UseCompressedOops && this->isa_aryptr() && this->offset() != arrayOopDesc::length_offset_in_bytes()) {\n+      if (klass()->is_obj_array_klass()) {\n+        _is_ptr_to_narrowoop = true;\n+      } else if (klass()->is_flat_array_klass() && field_offset != Offset::top && field_offset != Offset::bottom) {\n+        \/\/ Check if the field of the inline type array element contains oops\n+        ciInlineKlass* vk = klass()->as_flat_array_klass()->element_klass()->as_inline_klass();\n+        int foffset = field_offset.get() + vk->first_field_offset();\n+        ciField* field = vk->get_field_by_offset(foffset, false);\n+        assert(field != NULL, \"missing field\");\n+        BasicType bt = field->layout_type();\n+        _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(bt);\n+      }\n@@ -3115,2 +3353,0 @@\n-      ciInstanceKlass* ik = klass()->as_instance_klass();\n-      ciField* field = NULL;\n@@ -3119,1 +3355,1 @@\n-      } else if (_offset == OffsetBot || _offset == OffsetTop) {\n+      } else if (_offset == Offset::bottom || _offset == Offset::top) {\n@@ -3124,3 +3360,2 @@\n-\n-            (_offset == java_lang_Class::klass_offset() ||\n-             _offset == java_lang_Class::array_klass_offset())) {\n+            (this->offset() == java_lang_Class::klass_offset() ||\n+             this->offset() == java_lang_Class::array_klass_offset())) {\n@@ -3132,1 +3367,1 @@\n-                   _offset >= InstanceMirrorKlass::offset_of_static_fields()) {\n+                   this->offset() >= InstanceMirrorKlass::offset_of_static_fields()) {\n@@ -3137,8 +3372,14 @@\n-            field = k->get_field_by_offset(_offset, true);\n-          }\n-          if (field != NULL) {\n-            BasicType basic_elem_type = field->layout_type();\n-            _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(basic_elem_type);\n-          } else {\n-            \/\/ unsafe access\n-            _is_ptr_to_narrowoop = UseCompressedOops;\n+            if (k->is_inlinetype() && this->offset() == k->as_inline_klass()->default_value_offset()) {\n+              \/\/ Special hidden field that contains the oop of the default inline type\n+              \/\/ basic_elem_type = T_INLINE_TYPE;\n+             _is_ptr_to_narrowoop = UseCompressedOops;\n+            } else {\n+              field = k->get_field_by_offset(this->offset(), true);\n+              if (field != NULL) {\n+                BasicType basic_elem_type = field->layout_type();\n+                _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(basic_elem_type);\n+              } else {\n+                \/\/ unsafe access\n+                _is_ptr_to_narrowoop = UseCompressedOops;\n+              }\n+            }\n@@ -3148,1 +3389,2 @@\n-          field = ik->get_field_by_offset(_offset, false);\n+          ciInstanceKlass* ik = klass()->as_instance_klass();\n+          ciField* field = ik->get_field_by_offset(this->offset(), false);\n@@ -3168,2 +3410,2 @@\n-const TypeOopPtr *TypeOopPtr::make(PTR ptr, int offset, int instance_id,\n-                                     const TypePtr* speculative, int inline_depth) {\n+const TypeOopPtr *TypeOopPtr::make(PTR ptr, Offset offset, int instance_id,\n+                                   const TypePtr* speculative, int inline_depth) {\n@@ -3174,1 +3416,1 @@\n-  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, xk, o, offset, instance_id, speculative, inline_depth))->hashcons();\n+  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, xk, o, offset, Offset::bottom, instance_id, speculative, inline_depth))->hashcons();\n@@ -3199,1 +3441,0 @@\n-\n@@ -3209,1 +3450,1 @@\n-    return TypeKlassPtr::make(xk? Constant: NotNull, k, 0);\n+    return TypeKlassPtr::make(xk? Constant: NotNull, k, Offset(0));\n@@ -3247,1 +3488,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3289,1 +3530,1 @@\n-  return new TypeOopPtr(_base, dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n+  return new TypeOopPtr(_base, dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), Offset::bottom, dual_instance_id(), dual_speculative(), dual_inline_depth());\n@@ -3295,1 +3536,1 @@\n-  if (klass->is_instance_klass()) {\n+  if (klass->is_instance_klass() || klass->is_inlinetype()) {\n@@ -3321,1 +3562,1 @@\n-    return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, 0);\n+    return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, Offset(0));\n@@ -3323,2 +3564,14 @@\n-    \/\/ Element is an object array. Recursively call ourself.\n-    const TypeOopPtr *etype = TypeOopPtr::make_from_klass_common(klass->as_obj_array_klass()->element_klass(), false, try_for_exact);\n+    \/\/ Element is an object or inline type array. Recursively call ourself.\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), \/* klass_change= *\/ false, try_for_exact);\n+    if (etype->is_inlinetypeptr()) {\n+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n+    \/\/ Determine null-free\/flattened properties\n+    const TypeOopPtr* exact_etype = etype;\n+    if (etype->can_be_inline_type()) {\n+      \/\/ Use exact type if element can be an inline type\n+      exact_etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), \/* klass_change= *\/ true, \/* try_for_exact= *\/ true);\n+    }\n+    bool not_null_free = !exact_etype->can_be_inline_type();\n+    bool not_flat = !UseFlatArray || not_null_free || (exact_etype->is_inlinetypeptr() && !exact_etype->inline_klass()->flatten_array());\n+\n@@ -3326,1 +3579,1 @@\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, false, not_flat, not_null_free);\n@@ -3330,1 +3583,1 @@\n-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, 0);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, Offset(0));\n@@ -3335,1 +3588,2 @@\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS,\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3338,1 +3592,6 @@\n-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, 0);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));\n+    return arr;\n+  } else if (klass->is_flat_array_klass()) {\n+    ciInlineKlass* vk = klass->as_array_klass()->element_klass()->as_inline_klass();\n+    const TypeAry* arr0 = TypeAry::make(TypeInlineType::make(vk), TypeInt::POS);\n+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));\n@@ -3354,2 +3613,2 @@\n-  if (klass->is_instance_klass()) {\n-    \/\/ Element is an instance\n+  if (klass->is_instance_klass() || klass->is_inlinetype()) {\n+    \/\/ Element is an instance or inline type\n@@ -3359,1 +3618,1 @@\n-      return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, 0);\n+      return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, Offset(0));\n@@ -3363,3 +3622,8 @@\n-    const TypeOopPtr *etype =\n-      TypeOopPtr::make_from_klass_raw(klass->as_obj_array_klass()->element_klass());\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));\n+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_raw(klass->as_array_klass()->element_klass());\n+    bool null_free = false;\n+    if (etype->is_inlinetypeptr()) {\n+      null_free = true;\n+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();\n+    }\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ !null_free);\n@@ -3370,1 +3634,1 @@\n-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n@@ -3372,1 +3636,1 @@\n-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n@@ -3376,3 +3640,3 @@\n-    const Type* etype =\n-      (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());\n-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));\n+    const Type* etype = (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());\n+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),\n+                                        \/* stable= *\/ false, \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n@@ -3382,1 +3646,12 @@\n-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n+    } else {\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n+    }\n+  } else if (klass->is_flat_array_klass()) {\n+    ciInlineKlass* vk = klass->as_array_klass()->element_klass()->as_inline_klass();\n+    const TypeAry* arr0 = TypeAry::make(TypeInlineType::make(vk), TypeInt::make(o->as_array()->length()));\n+    \/\/ We used to pass NotNull in here, asserting that the sub-arrays\n+    \/\/ are all not-null.  This is not true in generally, as code can\n+    \/\/ slam NULLs down in the subarrays.\n+    if (make_constant) {\n+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));\n@@ -3384,1 +3659,1 @@\n-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);\n+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));\n@@ -3395,1 +3670,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -3397,1 +3672,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -3490,6 +3765,1 @@\n-  switch( _offset ) {\n-  case OffsetTop: st->print(\"+top\"); break;\n-  case OffsetBot: st->print(\"+any\"); break;\n-  case         0: break;\n-  default:        st->print(\"+%d\",_offset); break;\n-  }\n+  _offset.dump2(st);\n@@ -3512,1 +3782,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -3604,7 +3874,10 @@\n-TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, int off,\n-                         int instance_id, const TypePtr* speculative, int inline_depth)\n-  : TypeOopPtr(InstPtr, ptr, k, xk, o, off, instance_id, speculative, inline_depth),\n-    _name(k->name()) {\n-   assert(k != NULL &&\n-          (k->is_loaded() || o == NULL),\n-          \"cannot have constants with non-loaded klass\");\n+TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset off,\n+                         bool flatten_array, int instance_id, const TypePtr* speculative,\n+                         int inline_depth)\n+  : TypeOopPtr(InstPtr, ptr, k, xk, o, off, Offset::bottom, instance_id, speculative, inline_depth),\n+    _name(k->name()), _flatten_array(flatten_array) {\n+  assert(k != NULL &&\n+         (k->is_loaded() || o == NULL),\n+         \"cannot have constants with non-loaded klass\");\n+  assert(!klass()->flatten_array() || flatten_array, \"Should be flat in array\");\n+  assert(!flatten_array || can_be_inline_type(), \"Only inline types can be flat in array\");\n@@ -3618,1 +3891,2 @@\n-                                     int offset,\n+                                     Offset offset,\n+                                     bool flatten_array,\n@@ -3639,0 +3913,3 @@\n+  \/\/ Check if this type is known to be flat in arrays\n+  flatten_array = flatten_array || k->flatten_array();\n+\n@@ -3641,1 +3918,1 @@\n-    (TypeInstPtr*)(new TypeInstPtr(ptr, k, xk, o ,offset, instance_id, speculative, inline_depth))->hashcons();\n+    (TypeInstPtr*)(new TypeInstPtr(ptr, k, xk, o, offset, flatten_array, instance_id, speculative, inline_depth))->hashcons();\n@@ -3674,1 +3951,1 @@\n-  return make(ptr, klass(), klass_is_exact(), const_oop(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr, klass(), klass_is_exact(), const_oop(), _offset, _flatten_array, _instance_id, _speculative, _inline_depth);\n@@ -3685,1 +3962,1 @@\n-  return make(ptr(), klass(), klass_is_exact, const_oop(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), klass(), klass_is_exact, const_oop(), _offset, _flatten_array, _instance_id, _speculative, _inline_depth);\n@@ -3691,1 +3968,1 @@\n-  return make(_ptr, klass(), _klass_is_exact, const_oop(), _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, klass(), _klass_is_exact, const_oop(), _offset, _flatten_array, instance_id, _speculative, _inline_depth);\n@@ -3698,1 +3975,1 @@\n-    int off = meet_offset(tinst->offset());\n+    Offset off = meet_offset(tinst->offset());\n@@ -3723,1 +4000,1 @@\n-      else if (loaded->ptr() == TypePtr::AnyNull) { return TypeInstPtr::make(ptr, unloaded->klass(), false, NULL, off, instance_id, speculative, depth); }\n+      else if (loaded->ptr() == TypePtr::AnyNull) { return TypeInstPtr::make(ptr, unloaded->klass(), false, NULL, off, false, instance_id, speculative, depth); }\n@@ -3782,1 +4059,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3791,1 +4068,1 @@\n-                  (ptr == Constant ? const_oop() : NULL), offset, instance_id, speculative, depth);\n+                  (ptr == Constant ? const_oop() : NULL), offset, flatten_array(), instance_id, speculative, depth);\n@@ -3807,1 +4084,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -3819,1 +4096,1 @@\n-                  (ptr == Constant ? const_oop() : NULL), offset, instance_id, speculative, depth);\n+                  (ptr == Constant ? const_oop() : NULL), offset, flatten_array(), instance_id, speculative, depth);\n@@ -3847,1 +4124,1 @@\n-    int off = meet_offset( tinst->offset() );\n+    Offset off = meet_offset( tinst->offset() );\n@@ -3857,2 +4134,3 @@\n-    if (ptr != Constant && klass()->equals(tinst->klass()) && klass_is_exact() == tinst->klass_is_exact()) {\n-      return make(ptr, klass(), klass_is_exact(), NULL, off, instance_id, speculative, depth);\n+    if (ptr != Constant && klass()->equals(tinst->klass()) && klass_is_exact() == tinst->klass_is_exact() &&\n+        flatten_array() == tinst->flatten_array()) {\n+      return make(ptr, klass(), klass_is_exact(), NULL, off, flatten_array(), instance_id, speculative, depth);\n@@ -3866,0 +4144,2 @@\n+    bool tinst_flatten_array = tinst->flatten_array();\n+    bool this_flatten_array  = this->flatten_array();\n@@ -3888,0 +4168,3 @@\n+      tmp2 = tinst_flatten_array;\n+      tinst_flatten_array = this_flatten_array;\n+      this_flatten_array = tmp2;\n@@ -3899,0 +4182,1 @@\n+      bool flat_array;\n@@ -3907,0 +4191,1 @@\n+        flat_array = below_centerline(ptr) ? tinst_flatten_array    : this_flatten_array;\n@@ -3913,0 +4198,1 @@\n+        flat_array = above_centerline(ptr) ? tinst_flatten_array : false;\n@@ -3926,1 +4212,1 @@\n-      return make(ptr, k, xk, o, off, instance_id, speculative, depth);\n+      return make(ptr, k, xk, o, off, flat_array, instance_id, speculative, depth);\n@@ -3958,1 +4244,2 @@\n-    if( tinst_klass->equals(this_klass) ) {\n+    bool flat_array = false;\n+    if (tinst_klass->equals(this_klass)) {\n@@ -3961,1 +4248,2 @@\n-    } else if( !tinst_xk && this_klass->is_subtype_of( tinst_klass ) ) {\n+      flat_array = below_centerline(ptr) ? (this_flatten_array && tinst_flatten_array) : (this_flatten_array || tinst_flatten_array);\n+    } else if(!tinst_xk && this_klass->is_subtype_of(tinst_klass) && (!tinst_flatten_array || this_flatten_array)) {\n@@ -3964,1 +4252,2 @@\n-    } else if( !this_xk && tinst_klass->is_subtype_of( this_klass ) ) {\n+      flat_array = this_flatten_array;\n+    } else if(!this_xk && tinst_klass->is_subtype_of(this_klass) && (!this_flatten_array || tinst_flatten_array)) {\n@@ -3967,0 +4256,1 @@\n+      flat_array = tinst_flatten_array;\n@@ -3969,2 +4259,2 @@\n-    if( subtype ) {\n-      if( above_centerline(ptr) ) { \/\/ both are up?\n+    if (subtype) {\n+      if (above_centerline(ptr)) { \/\/ both are up?\n@@ -3973,1 +4263,2 @@\n-      } else if( above_centerline(this ->_ptr) && !above_centerline(tinst->_ptr) ) {\n+        this_flatten_array = tinst_flatten_array = flat_array;\n+      } else if (above_centerline(this ->_ptr) && !above_centerline(tinst->_ptr)) {\n@@ -3976,1 +4267,2 @@\n-      } else if( above_centerline(tinst->_ptr) && !above_centerline(this ->_ptr) ) {\n+        this_flatten_array = tinst_flatten_array;\n+      } else if (above_centerline(tinst->_ptr) && !above_centerline(this ->_ptr)) {\n@@ -3979,0 +4271,1 @@\n+        tinst_flatten_array = this_flatten_array;\n@@ -3981,0 +4274,1 @@\n+        this_flatten_array = flat_array;\n@@ -4003,1 +4297,1 @@\n-      return make(ptr, this_klass, this_xk, o, off, instance_id, speculative, depth);\n+      return make(ptr, this_klass, this_xk, o, off, this_flatten_array, instance_id, speculative, depth);\n@@ -4015,1 +4309,1 @@\n-    return make(ptr, k, false, NULL, off, instance_id, speculative, depth);\n+    return make(ptr, k, false, NULL, off, false, instance_id, speculative, depth);\n@@ -4018,0 +4312,21 @@\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return t;\n+      } else {\n+        return TypeInstPtr::NOTNULL;\n+      }\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return TypeInstPtr::make(ptr, _klass);\n+      } else {\n+        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass());\n+      }\n+    }\n+  }\n+\n@@ -4030,1 +4345,0 @@\n-\n@@ -4039,1 +4353,1 @@\n-  return new TypeInstPtr(dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n+  return new TypeInstPtr(dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), flatten_array(), dual_instance_id(), dual_speculative(), dual_inline_depth());\n@@ -4048,0 +4362,1 @@\n+    flatten_array() == p->flatten_array() &&\n@@ -4054,1 +4369,1 @@\n-  int hash = java_add((jint)klass()->hash(), (jint)TypeOopPtr::hash());\n+  int hash = java_add(java_add((jint)klass()->hash(), (jint)TypeOopPtr::hash()), (jint)flatten_array());\n@@ -4094,5 +4409,1 @@\n-  if( _offset ) {               \/\/ Dump offset, if any\n-    if( _offset == OffsetBot )      st->print(\"+any\");\n-    else if( _offset == OffsetTop ) st->print(\"+unknown\");\n-    else st->print(\"+%d\", _offset);\n-  }\n+  _offset.dump2(st);\n@@ -4101,0 +4412,5 @@\n+\n+  if (flatten_array() && !klass()->is_inlinetype()) {\n+    st->print(\" (flatten array)\");\n+  }\n+\n@@ -4113,1 +4429,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), xadd_offset(offset),\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), xadd_offset(offset), flatten_array(),\n@@ -4122,1 +4438,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset,\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(),\n@@ -4130,1 +4446,1 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, _instance_id, _speculative, depth);\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(), _instance_id, _speculative, depth);\n@@ -4135,1 +4451,5 @@\n-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flatten_array(), instance_id, _speculative, _inline_depth);\n+}\n+\n+const TypeInstPtr *TypeInstPtr::cast_to_flatten_array() const {\n+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, true, _instance_id, _speculative, _inline_depth);\n@@ -4138,0 +4458,1 @@\n+\n@@ -4150,0 +4471,1 @@\n+const TypeAryPtr *TypeAryPtr::INLINES;\n@@ -4152,1 +4474,1 @@\n-const TypeAryPtr *TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+const TypeAryPtr* TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,\n@@ -4158,1 +4480,1 @@\n-  return (TypeAryPtr*)(new TypeAryPtr(ptr, NULL, ary, k, xk, offset, instance_id, false, speculative, inline_depth))->hashcons();\n+  return (TypeAryPtr*)(new TypeAryPtr(ptr, NULL, ary, k, xk, offset, field_offset, instance_id, false, speculative, inline_depth))->hashcons();\n@@ -4162,1 +4484,1 @@\n-const TypeAryPtr *TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+const TypeAryPtr* TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,\n@@ -4170,1 +4492,1 @@\n-  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();\n+  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, field_offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();\n@@ -4176,1 +4498,1 @@\n-  return make(ptr, const_oop(), _ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr, const_oop(), _ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4184,1 +4506,7 @@\n-  return make(ptr(), const_oop(), _ary, klass(), klass_is_exact, _offset, _instance_id, _speculative, _inline_depth);\n+\n+  const TypeAry* new_ary = _ary;\n+  if (klass() != NULL && klass()->is_obj_array_klass() && klass_is_exact) {\n+    \/\/ An object array can't be flat or null-free if the klass is exact\n+    new_ary = TypeAry::make(elem(), size(), is_stable(), \/* not_flat= *\/ true, \/* not_null_free= *\/ true);\n+  }\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact, _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4190,1 +4518,1 @@\n-  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4246,2 +4574,36 @@\n-  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable());\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable(), is_not_flat(), is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/-------------------------------cast_to_not_flat------------------------------\n+const TypeAryPtr* TypeAryPtr::cast_to_not_flat(bool not_flat) const {\n+  if (not_flat == is_not_flat()) {\n+    return this;\n+  }\n+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), not_flat, is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/-------------------------------cast_to_not_null_free-------------------------\n+const TypeAryPtr* TypeAryPtr::cast_to_not_null_free(bool not_null_free) const {\n+  if (not_null_free == is_not_null_free()) {\n+    return this;\n+  }\n+  \/\/ Not null free implies not flat\n+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), not_null_free ? true : is_not_flat(), not_null_free);\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+\/\/---------------------------------update_properties---------------------------\n+const TypeAryPtr* TypeAryPtr::update_properties(const TypeAryPtr* from) const {\n+  if ((from->is_flat()          && is_not_flat()) ||\n+      (from->is_not_flat()      && is_flat()) ||\n+      (from->is_null_free()     && is_not_null_free()) ||\n+      (from->is_not_null_free() && is_null_free())) {\n+    return NULL; \/\/ Inconsistent properties\n+  } else if (from->is_not_null_free()) {\n+    return cast_to_not_null_free(); \/\/ Implies not flat\n+  } else if (from->is_not_flat()) {\n+    return cast_to_not_flat();\n+  }\n+  return this;\n@@ -4263,1 +4625,1 @@\n-  const TypeAry* new_ary = TypeAry::make(elem, size(), stable);\n+  const TypeAry* new_ary = TypeAry::make(elem, size(), stable, is_not_flat(), is_not_null_free());\n@@ -4265,1 +4627,1 @@\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n@@ -4285,2 +4647,2 @@\n-  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable());\n-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth, \/*is_autobox_cache=*\/true);\n+  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable(), is_not_flat(), is_not_null_free());\n+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, \/*is_autobox_cache=*\/true);\n@@ -4295,1 +4657,2 @@\n-    TypeOopPtr::eq(p);  \/\/ Check sub-parts\n+    TypeOopPtr::eq(p) &&\/\/ Check sub-parts\n+    _field_offset == p->_field_offset;\n@@ -4301,1 +4664,1 @@\n-  return (intptr_t)_ary + TypeOopPtr::hash();\n+  return (intptr_t)_ary + TypeOopPtr::hash() + _field_offset.get();\n@@ -4334,1 +4697,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4343,1 +4706,1 @@\n-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4357,1 +4720,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4373,1 +4736,1 @@\n-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4385,1 +4748,2 @@\n-    int off = meet_offset(tap->offset());\n+    Offset off = meet_offset(tap->offset());\n+    Offset field_off = meet_field_offset(tap->field_offset());\n@@ -4403,1 +4767,1 @@\n-        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable);\n+        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);\n@@ -4410,1 +4774,1 @@\n-          tap->_klass != NULL  && this->_klass != NULL   &&\n+          tap->_klass != NULL && this->_klass != NULL &&\n@@ -4413,1 +4777,1 @@\n-           \/\/ 'tap'  is exact and super or unrelated:\n+           \/\/ 'tap' is exact and super or unrelated:\n@@ -4417,2 +4781,15 @@\n-      if (above_centerline(ptr) || (tary->_elem->make_ptr() && above_centerline(tary->_elem->make_ptr()->_ptr))) {\n-        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable);\n+      if (above_centerline(ptr) || (tary->_elem->make_ptr() && above_centerline(tary->_elem->make_ptr()->_ptr)) ||\n+          tary->_elem->isa_inlinetype()) {\n+        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);\n+      }\n+      return make(NotNull, NULL, tary, lazy_klass, false, off, field_off, InstanceBot, speculative, depth);\n+    } else if (klass() != NULL && tap->klass() != NULL && klass()->is_flat_array_klass() != tap->klass()->is_flat_array_klass()) {\n+      \/\/ Meeting flattened inline type array with non-flattened array. Adjust (field) offset accordingly.\n+      if (tary->_elem->isa_inlinetype()) {\n+        \/\/ Result is flattened\n+        off = Offset(is_flat() ? offset() : tap->offset());\n+        field_off = is_flat() ? field_offset() : tap->field_offset();\n+      } else if (tary->_elem->make_oopptr() != NULL && tary->_elem->make_oopptr()->isa_instptr() && below_centerline(ptr)) {\n+        \/\/ Result is non-flattened\n+        off = Offset(flattened_offset()).meet(Offset(tap->flattened_offset()));\n+        field_off = Offset::bottom;\n@@ -4420,1 +4797,0 @@\n-      return make(NotNull, NULL, tary, lazy_klass, false, off, InstanceBot, speculative, depth);\n@@ -4433,1 +4809,1 @@\n-      return make(ptr, const_oop(), tary, lazy_klass, xk, off, instance_id, speculative, depth);\n+      return make(ptr, const_oop(), tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n@@ -4452,1 +4828,1 @@\n-      return make(ptr, o, tary, lazy_klass, xk, off, instance_id, speculative, depth);\n+      return make(ptr, o, tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n@@ -4463,1 +4839,1 @@\n-      return make(ptr, NULL, tary, lazy_klass, xk, off, instance_id, speculative, depth);\n+      return make(ptr, NULL, tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n@@ -4471,1 +4847,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4482,2 +4858,2 @@\n-      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {\n-        return make(ptr, _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flatten_array()) {\n+        return make(ptr, _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4488,1 +4864,1 @@\n-        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL,offset, instance_id, speculative, depth);\n+        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);\n@@ -4500,1 +4876,1 @@\n-        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {\n+        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flatten_array()) {\n@@ -4503,1 +4879,1 @@\n-                      _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);\n+                      _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);\n@@ -4514,1 +4890,1 @@\n-      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, instance_id, speculative, depth);\n+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);\n@@ -4518,0 +4894,13 @@\n+\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      return TypeInstPtr::NOTNULL;\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass());\n+    }\n+  }\n@@ -4525,1 +4914,10 @@\n-  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(),_klass, _klass_is_exact, dual_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());\n+  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(), _klass, _klass_is_exact, dual_offset(), dual_field_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());\n+}\n+\n+Type::Offset TypeAryPtr::meet_field_offset(const Type::Offset offset) const {\n+  return _field_offset.meet(offset);\n+}\n+\n+\/\/------------------------------dual_offset------------------------------------\n+Type::Offset TypeAryPtr::dual_field_offset() const {\n+  return _field_offset.dual();\n@@ -4562,1 +4960,6 @@\n-  if( _offset != 0 ) {\n+  if (is_flat()) {\n+    st->print(\"(\");\n+    _field_offset.dump2(st);\n+    st->print(\")\");\n+  }\n+  if (offset() != 0) {\n@@ -4564,3 +4967,3 @@\n-    if( _offset == OffsetTop )       st->print(\"+undefined\");\n-    else if( _offset == OffsetBot )  st->print(\"+any\");\n-    else if( _offset < header_size ) st->print(\"+%d\", _offset);\n+    if( _offset == Offset::top )       st->print(\"+undefined\");\n+    else if( _offset == Offset::bottom )  st->print(\"+any\");\n+    else if( offset() < header_size ) st->print(\"+%d\", offset());\n@@ -4571,1 +4974,1 @@\n-      st->print(\"[%d]\", (_offset - array_base)\/elem_size);\n+      st->print(\"[%d]\", (offset() - array_base)\/elem_size);\n@@ -4592,1 +4995,1 @@\n-  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _instance_id, add_offset_speculative(offset), _inline_depth);\n+  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _field_offset, _instance_id, add_offset_speculative(offset), _inline_depth, _is_autobox_cache);\n@@ -4600,1 +5003,13 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, NULL, _inline_depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, NULL, _inline_depth, _is_autobox_cache);\n+}\n+\n+const Type* TypeAryPtr::cleanup_speculative() const {\n+  if (speculative() == NULL) {\n+    return this;\n+  }\n+  \/\/ Keep speculative part if it contains information about flat-\/nullability\n+  const TypeAryPtr* spec_aryptr = speculative()->isa_aryptr();\n+  if (spec_aryptr != NULL && (spec_aryptr->is_not_flat() || spec_aryptr->is_not_null_free())) {\n+    return this;\n+  }\n+  return TypeOopPtr::cleanup_speculative();\n@@ -4607,1 +5022,52 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, _speculative, depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, _speculative, depth, _is_autobox_cache);\n+}\n+\n+const TypeAryPtr* TypeAryPtr::with_field_offset(int offset) const {\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, Offset(offset), _instance_id, _speculative, _inline_depth, _is_autobox_cache);\n+}\n+\n+const TypePtr* TypeAryPtr::add_field_offset_and_offset(intptr_t offset) const {\n+  int adj = 0;\n+  if (offset != Type::OffsetBot && offset != Type::OffsetTop) {\n+    const Type* elemtype = elem();\n+    if (elemtype->isa_inlinetype()) {\n+      if (_offset.get() != OffsetBot && _offset.get() != OffsetTop) {\n+        adj = _offset.get();\n+        offset += _offset.get();\n+      }\n+      uint header = arrayOopDesc::base_offset_in_bytes(T_OBJECT);\n+      if (_field_offset.get() != OffsetBot && _field_offset.get() != OffsetTop) {\n+        offset += _field_offset.get();\n+        if (_offset.get() == OffsetBot || _offset.get() == OffsetTop) {\n+          offset += header;\n+        }\n+      }\n+      if (offset >= (intptr_t)header || offset < 0) {\n+        \/\/ Try to get the field of the inline type array element we are pointing to\n+        ciKlass* arytype_klass = klass();\n+        ciFlatArrayKlass* vak = arytype_klass->as_flat_array_klass();\n+        ciInlineKlass* vk = vak->element_klass()->as_inline_klass();\n+        int shift = vak->log2_element_size();\n+        int mask = (1 << shift) - 1;\n+        intptr_t field_offset = ((offset - header) & mask);\n+        ciField* field = vk->get_field_by_offset(field_offset + vk->first_field_offset(), false);\n+        if (field == NULL) {\n+          \/\/ This may happen with nested AddP(base, AddP(base, base, offset), longcon(16))\n+          return add_offset(offset);\n+        } else {\n+          return with_field_offset(field_offset)->add_offset(offset - field_offset - adj);\n+        }\n+      }\n+    }\n+  }\n+  return add_offset(offset - adj);\n+}\n+\n+\/\/ Return offset incremented by field_offset for flattened inline type arrays\n+const int TypeAryPtr::flattened_offset() const {\n+  int offset = _offset.get();\n+  if (offset != Type::OffsetBot && offset != Type::OffsetTop &&\n+      _field_offset != Offset::bottom && _field_offset != Offset::top) {\n+    offset += _field_offset.get();\n+  }\n+  return offset;\n@@ -4612,1 +5078,1 @@\n-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);\n+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth);\n@@ -4617,0 +5083,1 @@\n+\n@@ -4705,1 +5172,0 @@\n-\n@@ -4711,0 +5177,3 @@\n+  case InlineType:\n+    return t->xmeet(this);\n+\n@@ -4789,1 +5258,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -4809,1 +5278,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -4811,1 +5280,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -4862,1 +5331,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4888,1 +5357,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -4921,1 +5390,1 @@\n-  switch( _offset ) {\n+  switch (offset()) {\n@@ -4925,1 +5394,1 @@\n-  default:        st->print(\"+%d\",_offset); break;\n+  default:        st->print(\"+%d\",offset()); break;\n@@ -4935,1 +5404,1 @@\n-TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset):\n+TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset):\n@@ -4940,1 +5409,1 @@\n-  return make(Constant, m, 0);\n+  return make(Constant, m, Offset(0));\n@@ -4943,1 +5412,1 @@\n-  return make(Constant, m, 0);\n+  return make(Constant, m, Offset(0));\n@@ -4948,1 +5417,1 @@\n-const TypeMetadataPtr *TypeMetadataPtr::make(PTR ptr, ciMetadata* m, int offset) {\n+const TypeMetadataPtr* TypeMetadataPtr::make(PTR ptr, ciMetadata* m, Offset offset) {\n@@ -4962,2 +5431,5 @@\n-TypeKlassPtr::TypeKlassPtr( PTR ptr, ciKlass* klass, int offset )\n-  : TypePtr(KlassPtr, ptr, offset), _klass(klass), _klass_is_exact(ptr == Constant) {\n+TypeKlassPtr::TypeKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flatten_array, bool not_flat, bool not_null_free)\n+  : TypePtr(KlassPtr, ptr, offset), _klass(klass), _klass_is_exact(ptr == Constant),\n+    _flatten_array(flatten_array), _not_flat(not_flat), _not_null_free(not_null_free) {\n+  assert(!klass->flatten_array() || flatten_array, \"Should be flat in array\");\n+  assert(!flatten_array || can_be_inline_type(), \"Only inline types can be flat in array\");\n@@ -4968,7 +5440,5 @@\n-const TypeKlassPtr *TypeKlassPtr::make( PTR ptr, ciKlass* k, int offset ) {\n-  assert( k != NULL, \"Expect a non-NULL klass\");\n-  assert(k->is_instance_klass() || k->is_array_klass(), \"Incorrect type of klass oop\");\n-  TypeKlassPtr *r =\n-    (TypeKlassPtr*)(new TypeKlassPtr(ptr, k, offset))->hashcons();\n-\n-  return r;\n+const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array, bool not_flat, bool not_null_free) {\n+  assert(k == NULL || k->is_instance_klass() || k->is_array_klass(), \"Incorrect type of klass oop\");\n+  \/\/ Check if this type is known to be flat in arrays\n+  flatten_array = flatten_array || k->flatten_array();\n+  return (TypeKlassPtr*)(new TypeKlassPtr(ptr, k, offset, flatten_array, not_flat, not_null_free))->hashcons();\n@@ -4981,3 +5451,2 @@\n-  return\n-    klass()->equals(p->klass()) &&\n-    TypePtr::eq(p);\n+  return klass() == p->klass() && TypePtr::eq(p) && flatten_array() == p->flatten_array() &&\n+      is_not_flat() == p->is_not_flat() && is_not_null_free() == p->is_not_null_free();\n@@ -4989,1 +5458,2 @@\n-  return java_add((jint)klass()->hash(), (jint)TypePtr::hash());\n+  return java_add(java_add(java_add(java_add(klass() != NULL ? klass()->hash() : (jint)0, (jint)TypePtr::hash()),\n+      (jint)flatten_array()), (jint)is_not_flat()), (jint)is_not_null_free());\n@@ -4998,1 +5468,1 @@\n-  return (_offset == 0) && !below_centerline(_ptr);\n+  return (offset() == 0) && !below_centerline(_ptr);\n@@ -5010,1 +5480,1 @@\n-    if (!empty() && ktkp != NULL && ktkp->klass()->is_loaded() && ktkp->klass()->is_interface())\n+    if (!empty() && ktkp != NULL && ktkp->is_loaded() && ktkp->klass()->is_interface())\n@@ -5033,1 +5503,0 @@\n-  const TypeInstPtr *tinst;\n@@ -5041,3 +5510,8 @@\n-  if ((tinst = el->isa_instptr()) != NULL) {\n-    \/\/ Compute array klass from element klass\n-    k_ary = ciObjArrayKlass::make(tinst->klass());\n+  if (el->isa_instptr()) {\n+    \/\/ Compute object array klass from element klass\n+    k_ary = ciArrayKlass::make(el->is_oopptr()->klass());\n+  } else if (el->isa_inlinetype()) {\n+    \/\/ If element type is TypeInlineType::BOTTOM, inline_klass() will be null.\n+    if (el->inline_klass() != NULL) {\n+      k_ary = ciArrayKlass::make(el->inline_klass());\n+    }\n@@ -5108,1 +5582,1 @@\n-        _offset != 0 && _offset != arrayOopDesc::length_offset_in_bytes()) {\n+        offset() != 0 && offset() != arrayOopDesc::length_offset_in_bytes()) {\n@@ -5119,1 +5593,1 @@\n-  return make( _ptr, klass(), xadd_offset(offset) );\n+  return make(_ptr, klass(), xadd_offset(offset), flatten_array(), is_not_flat(), is_not_null_free());\n@@ -5126,1 +5600,1 @@\n-  return make(ptr, _klass, _offset);\n+  return make(ptr, _klass, _offset, _flatten_array, _not_flat, _not_null_free);\n@@ -5133,1 +5607,1 @@\n-  return make(klass_is_exact ? Constant : NotNull, _klass, _offset);\n+  return make(klass_is_exact ? Constant : NotNull, _klass, _offset, _flatten_array, _not_flat, _not_null_free);\n@@ -5142,0 +5616,1 @@\n+  assert(k != NULL, \"klass should not be NULL\");\n@@ -5143,1 +5618,0 @@\n-  \/\/return TypeInstPtr::make(TypePtr::NotNull, k, xk, NULL, 0);\n@@ -5147,0 +5621,7 @@\n+  if (flatten_array() && !klass()->is_inlinetype()) {\n+    toop = toop->is_instptr()->cast_to_flatten_array();\n+  } else if (is_not_null_free()) {\n+    toop = toop->is_aryptr()->cast_to_not_null_free();\n+  } else if (is_not_flat()) {\n+    toop = toop->is_aryptr()->cast_to_not_flat();\n+  }\n@@ -5181,1 +5662,1 @@\n-    int offset = meet_offset(tp->offset());\n+    Offset offset = meet_offset(tp->offset());\n@@ -5189,1 +5670,1 @@\n-      return make( ptr, klass(), offset );\n+      return make(ptr, klass(), offset, flatten_array(), is_not_flat(), is_not_null_free());\n@@ -5222,1 +5703,1 @@\n-    int  off     = meet_offset(tkls->offset());\n+    Offset  off  = meet_offset(tkls->offset());\n@@ -5225,0 +5706,8 @@\n+    if (klass() == NULL || tkls->klass() == NULL) {\n+      ciKlass* k = NULL;\n+      if (ptr == Constant) {\n+        k = (klass() == NULL) ? tkls->klass() : klass();\n+      }\n+      return make(ptr, k, off);\n+    }\n+\n@@ -5229,2 +5718,2 @@\n-    if( ptr != Constant && tkls->klass()->equals(klass()) ) {\n-      return make( ptr, klass(), off );\n+    if (ptr != Constant && tkls->klass()->equals(klass()) && flatten_array() == tkls->flatten_array() && is_not_flat() == tkls->is_not_flat() && is_not_null_free() && tkls->is_not_null_free()) {\n+      return make(ptr, klass(), off, flatten_array(), is_not_flat(), is_not_null_free());\n@@ -5238,0 +5727,3 @@\n+    bool flatten_array = below_centerline(ptr) ? (this->flatten_array() && tkls->flatten_array()) : (this->flatten_array() || tkls->flatten_array());\n+    bool is_not_flat = this->is_not_flat() && tkls->is_not_flat();\n+    bool is_not_null_free = this->is_not_null_free() && tkls->is_not_null_free();\n@@ -5265,1 +5757,1 @@\n-      return make( ptr, this_klass, off );\n+      return make(ptr, this_klass, off, flatten_array, is_not_flat, is_not_null_free);\n@@ -5274,1 +5766,1 @@\n-    return   make( ptr, k, off );\n+    return make(ptr, k, off, false, is_not_flat, is_not_null_free);\n@@ -5284,1 +5776,1 @@\n-  return new TypeKlassPtr( dual_ptr(), klass(), dual_offset() );\n+  return new TypeKlassPtr(dual_ptr(), klass(), dual_offset(), flatten_array(), !is_not_flat(), !is_not_null_free());\n@@ -5290,1 +5782,1 @@\n-  assert( _offset >= 0, \"\" );\n+  assert(offset() >= 0, \"\");\n@@ -5292,1 +5784,1 @@\n-  if (_offset != 0) {\n+  if (offset() != 0) {\n@@ -5315,2 +5807,2 @@\n-      const char *name = klass()->name()->as_utf8();\n-      if( name ) {\n+      if (klass() != NULL) {\n+        const char* name = klass()->name()->as_utf8();\n@@ -5319,1 +5811,1 @@\n-        ShouldNotReachHere();\n+        st->print(\"klass BOTTOM\");\n@@ -5332,5 +5824,4 @@\n-\n-  if( _offset ) {               \/\/ Dump offset, if any\n-    if( _offset == OffsetBot )      { st->print(\"+any\"); }\n-    else if( _offset == OffsetTop ) { st->print(\"+unknown\"); }\n-    else                            { st->print(\"+%d\", _offset); }\n+  if (Verbose) {\n+    if (_flatten_array) st->print(\":flatten array\");\n+    if (_not_flat) st->print(\":not flat\");\n+    if (_not_null_free) st->print(\":not null free\");\n@@ -5339,0 +5830,2 @@\n+  _offset.dump2(st);\n+\n@@ -5349,2 +5842,14 @@\n-const TypeFunc *TypeFunc::make( const TypeTuple *domain, const TypeTuple *range ) {\n-  return (TypeFunc*)(new TypeFunc(domain,range))->hashcons();\n+const TypeFunc *TypeFunc::make(const TypeTuple *domain_sig, const TypeTuple* domain_cc,\n+                               const TypeTuple *range_sig, const TypeTuple *range_cc) {\n+  return (TypeFunc*)(new TypeFunc(domain_sig, domain_cc, range_sig, range_cc))->hashcons();\n+}\n+\n+const TypeFunc *TypeFunc::make(const TypeTuple *domain, const TypeTuple *range) {\n+  return make(domain, domain, range, range);\n+}\n+\n+\/\/------------------------------osr_domain-----------------------------\n+const TypeTuple* osr_domain() {\n+  const Type **fields = TypeTuple::fields(2);\n+  fields[TypeFunc::Parms+0] = TypeRawPtr::BOTTOM;  \/\/ address of osr buffer\n+  return TypeTuple::make(TypeFunc::Parms+1, fields);\n@@ -5354,1 +5859,1 @@\n-const TypeFunc *TypeFunc::make(ciMethod* method) {\n+const TypeFunc* TypeFunc::make(ciMethod* method, bool is_osr_compilation) {\n@@ -5356,7 +5861,20 @@\n-  const TypeFunc* tf = C->last_tf(method); \/\/ check cache\n-  if (tf != NULL)  return tf;  \/\/ The hit rate here is almost 50%.\n-  const TypeTuple *domain;\n-  if (method->is_static()) {\n-    domain = TypeTuple::make_domain(NULL, method->signature());\n-  } else {\n-    domain = TypeTuple::make_domain(method->holder(), method->signature());\n+  const TypeFunc* tf = NULL;\n+  if (!is_osr_compilation) {\n+    tf = C->last_tf(method); \/\/ check cache\n+    if (tf != NULL)  return tf;  \/\/ The hit rate here is almost 50%.\n+  }\n+  \/\/ Inline types are not passed\/returned by reference, instead each field of\n+  \/\/ the inline type is passed\/returned as an argument. We maintain two views of\n+  \/\/ the argument\/return list here: one based on the signature (with an inline\n+  \/\/ type argument\/return as a single slot), one based on the actual calling\n+  \/\/ convention (with an inline type argument\/return as a list of its fields).\n+  bool has_scalar_args = method->has_scalarized_args() && !is_osr_compilation;\n+  const TypeTuple* domain_sig = is_osr_compilation ? osr_domain() : TypeTuple::make_domain(method, false);\n+  const TypeTuple* domain_cc = has_scalar_args ? TypeTuple::make_domain(method, true) : domain_sig;\n+  ciSignature* sig = method->signature();\n+  bool has_scalar_ret = sig->return_type()->is_inlinetype() && sig->return_type()->as_inline_klass()->can_be_returned_as_fields();\n+  const TypeTuple* range_sig = TypeTuple::make_range(sig, false);\n+  const TypeTuple* range_cc = has_scalar_ret ? TypeTuple::make_range(sig, true) : range_sig;\n+  tf = TypeFunc::make(domain_sig, domain_cc, range_sig, range_cc);\n+  if (!is_osr_compilation) {\n+    C->set_last_tf(method, tf);  \/\/ fill cache\n@@ -5364,3 +5882,0 @@\n-  const TypeTuple *range  = TypeTuple::make_range(method->signature());\n-  tf = TypeFunc::make(domain, range);\n-  C->set_last_tf(method, tf);  \/\/ fill cache\n@@ -5401,2 +5916,4 @@\n-  return _domain == a->_domain &&\n-    _range == a->_range;\n+  return _domain_sig == a->_domain_sig &&\n+    _domain_cc == a->_domain_cc &&\n+    _range_sig == a->_range_sig &&\n+    _range_cc == a->_range_cc;\n@@ -5408,1 +5925,1 @@\n-  return (intptr_t)_domain + (intptr_t)_range;\n+  return (intptr_t)_domain_sig + (intptr_t)_domain_cc + (intptr_t)_range_sig + (intptr_t)_range_cc;\n@@ -5415,1 +5932,1 @@\n-  if( _range->cnt() <= Parms )\n+  if( _range_sig->cnt() <= Parms )\n@@ -5419,2 +5936,2 @@\n-    for (i = Parms; i < _range->cnt()-1; i++) {\n-      _range->field_at(i)->dump2(d,depth,st);\n+    for (i = Parms; i < _range_sig->cnt()-1; i++) {\n+      _range_sig->field_at(i)->dump2(d,depth,st);\n@@ -5423,1 +5940,1 @@\n-    _range->field_at(i)->dump2(d,depth,st);\n+    _range_sig->field_at(i)->dump2(d,depth,st);\n@@ -5432,3 +5949,3 @@\n-  if (Parms < _domain->cnt())\n-    _domain->field_at(Parms)->dump2(d,depth-1,st);\n-  for (uint i = Parms+1; i < _domain->cnt(); i++) {\n+  if (Parms < _domain_sig->cnt())\n+    _domain_sig->field_at(Parms)->dump2(d,depth-1,st);\n+  for (uint i = Parms+1; i < _domain_sig->cnt(); i++) {\n@@ -5436,1 +5953,1 @@\n-    _domain->field_at(i)->dump2(d,depth-1,st);\n+    _domain_sig->field_at(i)->dump2(d,depth-1,st);\n@@ -5456,1 +5973,1 @@\n-  if (range()->cnt() == TypeFunc::Parms) {\n+  if (range_sig()->cnt() == TypeFunc::Parms) {\n@@ -5459,1 +5976,1 @@\n-  return range()->field_at(TypeFunc::Parms)->basic_type();\n+  return range_sig()->field_at(TypeFunc::Parms)->basic_type();\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":818,"deletions":301,"binary":false,"changes":1119,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n@@ -56,0 +58,1 @@\n+class   TypeInlineType;\n@@ -101,0 +104,1 @@\n+    InlineType,                 \/\/ Inline type\n@@ -132,0 +136,24 @@\n+  class Offset {\n+  private:\n+    int _offset;\n+\n+  public:\n+    explicit Offset(int offset) : _offset(offset) {}\n+\n+    const Offset meet(const Offset other) const;\n+    const Offset dual() const;\n+    const Offset add(intptr_t offset) const;\n+    bool operator==(const Offset& other) const {\n+      return _offset == other._offset;\n+    }\n+    bool operator!=(const Offset& other) const {\n+      return _offset != other._offset;\n+    }\n+    int get() const { return _offset; }\n+\n+    void dump2(outputStream *st) const;\n+\n+    static const Offset top;\n+    static const Offset bottom;\n+  };\n+\n@@ -279,3 +307,0 @@\n-  bool is_ptr_to_boxing_obj() const;\n-\n-\n@@ -319,0 +344,2 @@\n+  const TypeInlineType* isa_inlinetype() const;  \/\/ Returns NULL if not Inline Type\n+  const TypeInlineType* is_inlinetype() const;   \/\/ Inline Type\n@@ -328,0 +355,3 @@\n+  bool is_inlinetypeptr() const;\n+  virtual ciInlineKlass* inline_klass() const;\n+\n@@ -715,2 +745,2 @@\n-  static const TypeTuple *make_range(ciSignature *sig);\n-  static const TypeTuple *make_domain(ciInstanceKlass* recv, ciSignature *sig);\n+  static const TypeTuple *make_range(ciSignature* sig, bool ret_vt_fields = false);\n+  static const TypeTuple *make_domain(ciMethod* method, bool vt_fields_as_args = false);\n@@ -745,2 +775,2 @@\n-  TypeAry(const Type* elem, const TypeInt* size, bool stable) : Type(Array),\n-      _elem(elem), _size(size), _stable(stable) {}\n+  TypeAry(const Type* elem, const TypeInt* size, bool stable, bool not_flat, bool not_null_free) : Type(Array),\n+      _elem(elem), _size(size), _stable(stable), _not_flat(not_flat), _not_null_free(not_null_free) {}\n@@ -757,0 +787,5 @@\n+\n+  \/\/ Inline type array properties\n+  const bool _not_flat;         \/\/ Array is never flattened\n+  const bool _not_null_free;    \/\/ Array is never null-free\n+\n@@ -760,1 +795,2 @@\n-  static const TypeAry* make(const Type* elem, const TypeInt* size, bool stable = false);\n+  static const TypeAry* make(const Type* elem, const TypeInt* size, bool stable = false,\n+                             bool not_flat = false, bool not_null_free = false);\n@@ -767,0 +803,1 @@\n+\n@@ -776,0 +813,37 @@\n+\n+\/\/------------------------------TypeValue---------------------------------------\n+\/\/ Class of Inline Type Types\n+class TypeInlineType : public Type {\n+private:\n+  ciInlineKlass* _vk;\n+  bool _larval;\n+\n+protected:\n+  TypeInlineType(ciInlineKlass* vk, bool larval)\n+    : Type(InlineType),\n+      _vk(vk), _larval(larval) {\n+  }\n+\n+public:\n+  static const TypeInlineType* make(ciInlineKlass* vk, bool larval = false);\n+  virtual ciInlineKlass* inline_klass() const { return _vk; }\n+  bool larval() const { return _larval; }\n+\n+  virtual bool eq(const Type* t) const;\n+  virtual int  hash() const;             \/\/ Type specific hashing\n+  virtual bool singleton(void) const;    \/\/ TRUE if type is a singleton\n+  virtual bool empty(void) const;        \/\/ TRUE if type is vacuous\n+\n+  virtual const Type* xmeet(const Type* t) const;\n+  virtual const Type* xdual() const;     \/\/ Compute dual right now.\n+\n+  virtual bool would_improve_type(ciKlass* exact_kls, int inline_depth) const { return false; }\n+  virtual bool would_improve_ptr(ProfilePtrKind ptr_kind) const { return false; }\n+\n+  static const TypeInlineType* BOTTOM;\n+\n+#ifndef PRODUCT\n+  virtual void dump2(Dict &d, uint, outputStream* st) const; \/\/ Specialized per-Type dumping\n+#endif\n+};\n+\n@@ -877,1 +951,1 @@\n-  TypePtr(TYPES t, PTR ptr, int offset,\n+  TypePtr(TYPES t, PTR ptr, Offset offset,\n@@ -920,1 +994,1 @@\n-  const int _offset;            \/\/ Offset into oop, with TOP & BOT\n+  const Offset _offset;         \/\/ Offset into oop, with TOP & BOT\n@@ -923,1 +997,1 @@\n-  const int offset() const { return _offset; }\n+  const int offset() const { return _offset.get(); }\n@@ -926,1 +1000,1 @@\n-  static const TypePtr *make(TYPES t, PTR ptr, int offset,\n+  static const TypePtr* make(TYPES t, PTR ptr, Offset offset,\n@@ -935,1 +1009,1 @@\n-  int xadd_offset( intptr_t offset ) const;\n+  Offset xadd_offset(intptr_t offset) const;\n@@ -937,0 +1011,2 @@\n+  virtual const int flattened_offset() const { return offset(); }\n+\n@@ -944,2 +1020,2 @@\n-  int meet_offset( int offset ) const;\n-  int dual_offset( ) const;\n+  Offset meet_offset(int offset) const;\n+  Offset dual_offset() const;\n@@ -973,0 +1049,5 @@\n+  virtual bool can_be_inline_type() const { return false; }\n+  virtual bool flatten_array() const { return false; }\n+  virtual bool is_not_flat() const { return false; }\n+  virtual bool is_not_null_free() const { return false; }\n+\n@@ -990,1 +1071,1 @@\n-  TypeRawPtr( PTR ptr, address bits ) : TypePtr(RawPtr,ptr,0), _bits(bits){}\n+  TypeRawPtr(PTR ptr, address bits) : TypePtr(RawPtr,ptr,Offset(0)), _bits(bits){}\n@@ -1021,2 +1102,2 @@\n-  TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset, int instance_id,\n-             const TypePtr* speculative, int inline_depth);\n+  TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset, Offset field_offset,\n+             int instance_id, const TypePtr* speculative, int inline_depth);\n@@ -1081,1 +1162,1 @@\n-  static const TypeOopPtr* make(PTR ptr, int offset, int instance_id,\n+  static const TypeOopPtr* make(PTR ptr, Offset offset, int instance_id,\n@@ -1096,1 +1177,3 @@\n-  bool is_known_instance_field() const { return is_known_instance() && _offset >= 0; }\n+  bool is_known_instance_field() const { return is_known_instance() && _offset.get() >= 0; }\n+\n+  virtual bool can_be_inline_type() const { return EnableValhalla && (_klass == NULL || _klass->can_be_inline_klass(_klass_is_exact)); }\n@@ -1134,2 +1217,3 @@\n-  TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset, int instance_id,\n-              const TypePtr* speculative, int inline_depth);\n+  TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset,\n+              bool flatten_array, int instance_id, const TypePtr* speculative,\n+              int inline_depth);\n@@ -1140,0 +1224,1 @@\n+  bool _flatten_array;     \/\/ Type is flat in arrays\n@@ -1148,1 +1233,1 @@\n-    return make(TypePtr::Constant, o->klass(), true, o, 0, InstanceBot);\n+    return make(TypePtr::Constant, o->klass(), true, o, Offset(0));\n@@ -1151,2 +1236,2 @@\n-  static const TypeInstPtr *make(ciObject* o, int offset) {\n-    return make(TypePtr::Constant, o->klass(), true, o, offset, InstanceBot);\n+  static const TypeInstPtr* make(ciObject* o, Offset offset) {\n+    return make(TypePtr::Constant, o->klass(), true, o, offset);\n@@ -1157,1 +1242,1 @@\n-    return make(ptr, klass, false, NULL, 0, InstanceBot);\n+    return make(ptr, klass, false, NULL, Offset(0));\n@@ -1162,1 +1247,1 @@\n-    return make(ptr, klass, true, NULL, 0, InstanceBot);\n+    return make(ptr, klass, true, NULL, Offset(0));\n@@ -1166,2 +1251,2 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* klass, int offset) {\n-    return make(ptr, klass, false, NULL, offset, InstanceBot);\n+  static const TypeInstPtr *make(PTR ptr, ciKlass* klass, Offset offset) {\n+    return make(ptr, klass, false, NULL, offset);\n@@ -1171,1 +1256,2 @@\n-  static const TypeInstPtr *make(PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset,\n+  static const TypeInstPtr* make(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset,\n+                                 bool flatten_array = false,\n@@ -1197,0 +1283,3 @@\n+  virtual const TypeInstPtr* cast_to_flatten_array() const;\n+  virtual bool flatten_array() const { return _flatten_array; }\n+\n@@ -1216,4 +1305,4 @@\n-  TypeAryPtr( PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk,\n-              int offset, int instance_id, bool is_autobox_cache,\n-              const TypePtr* speculative, int inline_depth)\n-    : TypeOopPtr(AryPtr,ptr,k,xk,o,offset, instance_id, speculative, inline_depth),\n+  TypeAryPtr(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk,\n+             Offset offset, Offset field_offset, int instance_id, bool is_autobox_cache,\n+             const TypePtr* speculative, int inline_depth)\n+    : TypeOopPtr(AryPtr, ptr, k, xk, o, offset, field_offset, instance_id, speculative, inline_depth),\n@@ -1221,1 +1310,2 @@\n-    _is_autobox_cache(is_autobox_cache)\n+    _is_autobox_cache(is_autobox_cache),\n+    _field_offset(field_offset)\n@@ -1244,0 +1334,6 @@\n+  \/\/ For flattened inline type arrays, each field of the inline type in\n+  \/\/ the array has its own memory slice so we need to keep track of\n+  \/\/ which field is accessed\n+  const Offset _field_offset;\n+  Offset meet_field_offset(const Type::Offset offset) const;\n+  Offset dual_field_offset() const;\n@@ -1255,0 +1351,6 @@\n+  \/\/ Inline type array properties\n+  bool is_flat()          const { return _ary->_elem->isa_inlinetype() != NULL; }\n+  bool is_not_flat()      const { return _ary->_not_flat; }\n+  bool is_null_free()     const { return is_flat() || (_ary->_elem->make_ptr() != NULL && _ary->_elem->make_ptr()->is_inlinetypeptr()); }\n+  bool is_not_null_free() const { return _ary->_not_null_free; }\n+\n@@ -1257,1 +1359,2 @@\n-  static const TypeAryPtr *make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+  static const TypeAryPtr* make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset,\n+                                Offset field_offset = Offset::bottom,\n@@ -1262,1 +1365,2 @@\n-  static const TypeAryPtr *make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,\n+  static const TypeAryPtr* make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset,\n+                                Offset field_offset = Offset::bottom,\n@@ -1265,1 +1369,2 @@\n-                                int inline_depth = InlineDepthBottom, bool is_autobox_cache = false);\n+                                int inline_depth = InlineDepthBottom,\n+                                bool is_autobox_cache = false);\n@@ -1282,0 +1387,1 @@\n+  virtual const Type* cleanup_speculative() const;\n@@ -1289,0 +1395,5 @@\n+  \/\/ Inline type array properties\n+  const TypeAryPtr* cast_to_not_flat(bool not_flat = true) const;\n+  const TypeAryPtr* cast_to_not_null_free(bool not_null_free = true) const;\n+  const TypeAryPtr* update_properties(const TypeAryPtr* new_type) const;\n+\n@@ -1294,1 +1405,8 @@\n-  static jint max_array_length(BasicType etype) ;\n+  static jint max_array_length(BasicType etype);\n+\n+  const int flattened_offset() const;\n+  const Offset field_offset() const { return _field_offset; }\n+  const TypeAryPtr* with_field_offset(int offset) const;\n+  const TypePtr* add_field_offset_and_offset(intptr_t offset) const;\n+\n+  virtual bool can_be_inline_type() const { return false; }\n@@ -1307,0 +1425,1 @@\n+  static const TypeAryPtr *INLINES;\n@@ -1327,1 +1446,1 @@\n-  TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset);\n+  TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset);\n@@ -1339,1 +1458,1 @@\n-  static const TypeMetadataPtr* make(PTR ptr, ciMetadata* m, int offset);\n+  static const TypeMetadataPtr* make(PTR ptr, ciMetadata* m, Offset offset);\n@@ -1366,1 +1485,1 @@\n-  TypeKlassPtr( PTR ptr, ciKlass* klass, int offset );\n+  TypeKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flatten_array, bool not_flat, bool not_null_free);\n@@ -1376,2 +1495,0 @@\n-  static const TypeKlassPtr* make_from_klass_common(ciKlass* klass, bool klass_change, bool try_for_exact);\n-\n@@ -1381,1 +1498,4 @@\n-  bool          _klass_is_exact;\n+  bool _klass_is_exact;\n+  const bool _flatten_array; \/\/ Type is flat in arrays\n+  const bool _not_flat;      \/\/ Array is never flattened\n+  const bool _not_null_free; \/\/ Array is never null-free\n@@ -1384,2 +1504,0 @@\n-  ciSymbol* name()  const { return klass()->name(); }\n-\n@@ -1389,18 +1507,4 @@\n-  bool  is_loaded() const { return klass()->is_loaded(); }\n-\n-  \/\/ Creates a type given a klass. Correctly handles multi-dimensional arrays\n-  \/\/ Respects UseUniqueSubclasses.\n-  \/\/ If the klass is final, the resulting type will be exact.\n-  static const TypeKlassPtr* make_from_klass(ciKlass* klass) {\n-    return make_from_klass_common(klass, true, false);\n-  }\n-  \/\/ Same as before, but will produce an exact type, even if\n-  \/\/ the klass is not final, as long as it has exactly one implementation.\n-  static const TypeKlassPtr* make_from_klass_unique(ciKlass* klass) {\n-    return make_from_klass_common(klass, true, true);\n-  }\n-  \/\/ Same as before, but does not respects UseUniqueSubclasses.\n-  \/\/ Use this only for creating array element types.\n-  static const TypeKlassPtr* make_from_klass_raw(ciKlass* klass) {\n-    return make_from_klass_common(klass, false, false);\n-  }\n+  virtual bool can_be_inline_type() const { return EnableValhalla && (_klass == NULL || _klass->can_be_inline_klass(_klass_is_exact)); }\n+  virtual bool flatten_array() const { return _flatten_array; }\n+  virtual bool is_not_flat() const { return _not_flat; }\n+  virtual bool is_not_null_free() const { return _not_null_free; }\n@@ -1408,2 +1512,1 @@\n-  \/\/ Make a generic (unclassed) pointer to metadata.\n-  static const TypeKlassPtr* make(PTR ptr, int offset);\n+  bool  is_loaded() const { return klass() != NULL && klass()->is_loaded(); }\n@@ -1412,3 +1515,6 @@\n-  static const TypeKlassPtr *make( ciKlass* k ) { return make( TypePtr::Constant, k, 0); }\n-  \/\/ ptr to klass 'k' with offset\n-  static const TypeKlassPtr *make( ciKlass* k, int offset ) { return make( TypePtr::Constant, k, offset); }\n+  static const TypeKlassPtr* make(ciKlass* k) {\n+    bool not_null_free = k->is_array_klass() && ( k->as_array_klass()->element_klass() == NULL ||\n+                                                 !k->as_array_klass()->element_klass()->can_be_inline_klass(true));\n+    bool not_flat = k->is_array_klass() && !k->is_flat_array_klass();\n+    return make(TypePtr::Constant, k, Offset(0), false, not_flat, not_null_free);\n+  }\n@@ -1416,1 +1522,1 @@\n-  static const TypeKlassPtr *make( PTR ptr, ciKlass* k, int offset);\n+  static const TypeKlassPtr* make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array = false, bool not_flat = false, bool not_null_free = false);\n@@ -1567,1 +1673,2 @@\n-  TypeFunc( const TypeTuple *domain, const TypeTuple *range ) : Type(Function),  _domain(domain), _range(range) {}\n+  TypeFunc(const TypeTuple *domain_sig, const TypeTuple *domain_cc, const TypeTuple *range_sig, const TypeTuple *range_cc)\n+    : Type(Function), _domain_sig(domain_sig), _domain_cc(domain_cc), _range_sig(range_sig), _range_cc(range_cc) {}\n@@ -1573,2 +1680,13 @@\n-  const TypeTuple* const _domain;     \/\/ Domain of inputs\n-  const TypeTuple* const _range;      \/\/ Range of results\n+  \/\/ Domains of inputs: inline type arguments are not passed by\n+  \/\/ reference, instead each field of the inline type is passed as an\n+  \/\/ argument. We maintain 2 views of the argument list here: one\n+  \/\/ based on the signature (with an inline type argument as a single\n+  \/\/ slot), one based on the actual calling convention (with a value\n+  \/\/ type argument as a list of its fields).\n+  const TypeTuple* const _domain_sig;\n+  const TypeTuple* const _domain_cc;\n+  \/\/ Range of results. Similar to domains: an inline type result can be\n+  \/\/ returned in registers in which case range_cc lists all fields and\n+  \/\/ is the actual calling convention.\n+  const TypeTuple* const _range_sig;\n+  const TypeTuple* const _range_cc;\n@@ -1588,5 +1706,8 @@\n-  const TypeTuple* domain() const { return _domain; }\n-  const TypeTuple* range()  const { return _range; }\n-\n-  static const TypeFunc *make(ciMethod* method);\n-  static const TypeFunc *make(ciSignature signature, const Type* extra);\n+  const TypeTuple* domain_sig() const { return _domain_sig; }\n+  const TypeTuple* domain_cc()  const { return _domain_cc; }\n+  const TypeTuple* range_sig()  const { return _range_sig; }\n+  const TypeTuple* range_cc()   const { return _range_cc; }\n+\n+  static const TypeFunc* make(ciMethod* method, bool is_osr_compilation = false);\n+  static const TypeFunc *make(const TypeTuple* domain_sig, const TypeTuple* domain_cc,\n+                              const TypeTuple* range_sig, const TypeTuple* range_cc);\n@@ -1600,0 +1721,2 @@\n+  bool returns_inline_type_as_fields() const { return range_sig() != range_cc(); }\n+\n@@ -1771,0 +1894,9 @@\n+inline const TypeInlineType* Type::isa_inlinetype() const {\n+  return (_base == InlineType) ? (TypeInlineType*)this : NULL;\n+}\n+\n+inline const TypeInlineType* Type::is_inlinetype() const {\n+  assert(_base == InlineType, \"Not an inline type\");\n+  return (TypeInlineType*)this;\n+}\n+\n@@ -1837,5 +1969,8 @@\n-inline bool Type::is_ptr_to_boxing_obj() const {\n-  const TypeInstPtr* tp = isa_instptr();\n-  return (tp != NULL) && (tp->offset() == 0) &&\n-         tp->klass()->is_instance_klass()  &&\n-         tp->klass()->as_instance_klass()->is_box_klass();\n+inline bool Type::is_inlinetypeptr() const {\n+  return isa_instptr() != NULL && is_instptr()->klass()->is_inlinetype();\n+}\n+\n+\n+inline ciInlineKlass* Type::inline_klass() const {\n+  assert(is_inlinetypeptr(), \"must be an inline type ptr\");\n+  return is_instptr()->klass()->as_inline_klass();\n@@ -1870,0 +2005,1 @@\n+#define CmpUXNode    CmpULNode\n@@ -1890,0 +2026,1 @@\n+#define Op_StoreX    Op_StoreL\n@@ -1918,0 +2055,1 @@\n+#define CmpUXNode    CmpUNode\n@@ -1938,0 +2076,1 @@\n+#define Op_StoreX    Op_StoreI\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":223,"deletions":84,"binary":false,"changes":307,"status":"modified"},{"patch":"@@ -190,1 +190,1 @@\n-      for (uint i = TypeFunc::Parms; i < call->tf()->domain()->cnt(); i++) {\n+      for (uint i = TypeFunc::Parms; i < call->tf()->domain_sig()->cnt(); i++) {\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -58,0 +58,2 @@\n+#include \"oops\/flatArrayOop.inline.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -424,0 +426,1 @@\n+  bool is_inlined = InstanceKlass::cast(k1)->field_is_inlined(slot);\n@@ -425,1 +428,1 @@\n-  ret = jfieldIDWorkaround::to_instance_jfieldID(k1, offset);\n+  ret = jfieldIDWorkaround::to_instance_jfieldID(k1, offset, is_inlined);\n@@ -442,1 +445,1 @@\n-  if (m->is_initializer()) {\n+  if (m->is_object_constructor() || m->is_static_init_factory()) {\n@@ -500,1 +503,0 @@\n-\n@@ -805,1 +807,2 @@\n-    case T_OBJECT:      push_object(va_arg(_ap, jobject)); break;\n+    case T_OBJECT:\n+    case T_INLINE_TYPE: push_object(va_arg(_ap, jobject)); break;\n@@ -845,1 +848,2 @@\n-    case T_OBJECT:      push_object((_ap++)->l); break;\n+    case T_OBJECT:\n+    case T_INLINE_TYPE: push_object((_ap++)->l); break;\n@@ -981,5 +985,19 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n-  obj = JNIHandles::make_local(THREAD, i);\n-  JavaValue jvalue(T_VOID);\n-  JNI_ArgumentPusherArray ap(methodID, args);\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == NULL) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);\n+  }\n+\n+  if (!k->is_inline_klass()) {\n+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n+    obj = JNIHandles::make_local(THREAD, i);\n+    JavaValue jvalue(T_VOID);\n+    JNI_ArgumentPusherArray ap(methodID, args);\n+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+  } else {\n+    JavaValue jvalue(T_INLINE_TYPE);\n+    JNI_ArgumentPusherArray ap(methodID, args);\n+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);\n+    obj = jvalue.get_jobject();\n+  }\n@@ -987,1 +1005,1 @@\n-JNI_END\n+  JNI_END\n@@ -999,5 +1017,19 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n-  obj = JNIHandles::make_local(THREAD, i);\n-  JavaValue jvalue(T_VOID);\n-  JNI_ArgumentPusherVaArg ap(methodID, args);\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == NULL) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);\n+  }\n+\n+  if (!k->is_inline_klass()) {\n+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n+    obj = JNIHandles::make_local(THREAD, i);\n+    JavaValue jvalue(T_VOID);\n+    JNI_ArgumentPusherVaArg ap(methodID, args);\n+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+  } else {\n+    JavaValue jvalue(T_INLINE_TYPE);\n+    JNI_ArgumentPusherVaArg ap(methodID, args);\n+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);\n+    obj = jvalue.get_jobject();\n+  }\n@@ -1017,8 +1049,25 @@\n-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);\n-  obj = JNIHandles::make_local(THREAD, i);\n-  va_list args;\n-  va_start(args, methodID);\n-  JavaValue jvalue(T_VOID);\n-  JNI_ArgumentPusherVaArg ap(methodID, args);\n-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n-  va_end(args);\n+  oop clazzoop = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(clazzoop);\n+  if (k == NULL) {\n+    ResourceMark rm(THREAD);\n+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);\n+  }\n+\n+  if (!k->is_inline_klass()) {\n+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);\n+    obj = JNIHandles::make_local(THREAD, i);\n+    va_list args;\n+    va_start(args, methodID);\n+    JavaValue jvalue(T_VOID);\n+    JNI_ArgumentPusherVaArg ap(methodID, args);\n+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);\n+    va_end(args);\n+  } else {\n+    va_list args;\n+    va_start(args, methodID);\n+    JavaValue jvalue(T_INLINE_TYPE);\n+    JNI_ArgumentPusherVaArg ap(methodID, args);\n+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);\n+    va_end(args);\n+    obj = jvalue.get_jobject();\n+  }\n@@ -1775,1 +1824,1 @@\n-  ret = jfieldIDWorkaround::to_instance_jfieldID(k, fd.offset());\n+  ret = jfieldIDWorkaround::to_instance_jfieldID(k, fd.offset(), fd.is_inlined());\n@@ -1785,0 +1834,1 @@\n+  oop res = NULL;\n@@ -1790,2 +1840,12 @@\n-  oop loaded_obj = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(o, offset);\n-  jobject ret = JNIHandles::make_local(THREAD, loaded_obj);\n+  if (!jfieldIDWorkaround::is_inlined_jfieldID(fieldID)) {\n+    res = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(o, offset);\n+  } else {\n+    assert(k->is_instance_klass(), \"Only instance can have inlined fields\");\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    fieldDescriptor fd;\n+    ik->find_field_from_offset(offset, false, &fd);  \/\/ performance bottleneck\n+    InstanceKlass* holder = fd.field_holder();\n+    InlineKlass* field_vklass = InlineKlass::cast(holder->get_inline_type_field_klass(fd.index()));\n+    res = field_vklass->read_inlined_field(o, ik->field_offset(fd.index()), CHECK_NULL);\n+  }\n+  jobject ret = JNIHandles::make_local(THREAD, res);\n@@ -1883,1 +1943,12 @@\n-  HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(o, offset, JNIHandles::resolve(value));\n+  if (!jfieldIDWorkaround::is_inlined_jfieldID(fieldID)) {\n+    HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(o, offset, JNIHandles::resolve(value));\n+  } else {\n+    assert(k->is_instance_klass(), \"Only instances can have inlined fields\");\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    fieldDescriptor fd;\n+    ik->find_field_from_offset(offset, false, &fd);\n+    InstanceKlass* holder = fd.field_holder();\n+    InlineKlass* vklass = InlineKlass::cast(holder->get_inline_type_field_klass(fd.index()));\n+    oop v = JNIHandles::resolve_non_null(value);\n+    vklass->write_inlined_field(o, offset, v, CHECK);\n+  }\n@@ -2300,4 +2371,13 @@\n-  objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n-  if (a->is_within_bounds(index)) {\n-    ret = JNIHandles::make_local(THREAD, a->obj_at(index));\n-    return ret;\n+  oop res = NULL;\n+  arrayOop arr((arrayOop)JNIHandles::resolve_non_null(array));\n+  if (arr->is_within_bounds(index)) {\n+    if (arr->is_flatArray()) {\n+      flatArrayOop a = flatArrayOop(JNIHandles::resolve_non_null(array));\n+      flatArrayHandle vah(thread, a);\n+      res = flatArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK_NULL);\n+      assert(res != NULL, \"Must be set in one of two paths above\");\n+    } else {\n+      assert(arr->is_objArray(), \"If not a valueArray. must be an objArray\");\n+      objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n+      res = a->obj_at(index);\n+    }\n@@ -2307,1 +2387,1 @@\n-    ss.print(\"Index %d out of bounds for length %d\", index, a->length());\n+    ss.print(\"Index %d out of bounds for length %d\", index,arr->length());\n@@ -2310,0 +2390,2 @@\n+  ret = JNIHandles::make_local(THREAD, res);\n+  return ret;\n@@ -2319,24 +2401,51 @@\n-  objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n-  oop v = JNIHandles::resolve(value);\n-  if (a->is_within_bounds(index)) {\n-    if (v == NULL || v->is_a(ObjArrayKlass::cast(a->klass())->element_klass())) {\n-      a->obj_at_put(index, v);\n-    } else {\n-      ResourceMark rm(THREAD);\n-      stringStream ss;\n-      Klass *bottom_kl = ObjArrayKlass::cast(a->klass())->bottom_klass();\n-      ss.print(\"type mismatch: can not store %s to %s[%d]\",\n-               v->klass()->external_name(),\n-               bottom_kl->is_typeArray_klass() ? type2name_tab[ArrayKlass::cast(bottom_kl)->element_type()] : bottom_kl->external_name(),\n-               index);\n-      for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n-        ss.print(\"[]\");\n-      }\n-      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n-    }\n-  } else {\n-    ResourceMark rm(THREAD);\n-    stringStream ss;\n-    ss.print(\"Index %d out of bounds for length %d\", index, a->length());\n-    THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());\n-  }\n+   bool oob = false;\n+   int length = -1;\n+   oop res = NULL;\n+   arrayOop arr((arrayOop)JNIHandles::resolve_non_null(array));\n+   if (arr->is_within_bounds(index)) {\n+     if (arr->is_flatArray()) {\n+       flatArrayOop a = flatArrayOop(JNIHandles::resolve_non_null(array));\n+       oop v = JNIHandles::resolve(value);\n+       FlatArrayKlass* vaklass = FlatArrayKlass::cast(a->klass());\n+       InlineKlass* element_vklass = vaklass->element_klass();\n+       if (v != NULL && v->is_a(element_vklass)) {\n+         a->value_copy_to_index(v, index);\n+       } else {\n+         ResourceMark rm(THREAD);\n+         stringStream ss;\n+         Klass *kl = FlatArrayKlass::cast(a->klass());\n+         ss.print(\"type mismatch: can not store %s to %s[%d]\",\n+             v->klass()->external_name(),\n+             kl->external_name(),\n+             index);\n+         for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n+           ss.print(\"[]\");\n+         }\n+         THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n+       }\n+     } else {\n+       assert(arr->is_objArray(), \"If not a valueArray. must be an objArray\");\n+       objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));\n+       oop v = JNIHandles::resolve(value);\n+       if (v == NULL || v->is_a(ObjArrayKlass::cast(a->klass())->element_klass())) {\n+         a->obj_at_put(index, v);\n+       } else {\n+         ResourceMark rm(THREAD);\n+         stringStream ss;\n+         Klass *bottom_kl = ObjArrayKlass::cast(a->klass())->bottom_klass();\n+         ss.print(\"type mismatch: can not store %s to %s[%d]\",\n+             v->klass()->external_name(),\n+             bottom_kl->is_typeArray_klass() ? type2name_tab[ArrayKlass::cast(bottom_kl)->element_type()] : bottom_kl->external_name(),\n+                 index);\n+         for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {\n+           ss.print(\"[]\");\n+         }\n+         THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());\n+       }\n+     }\n+   } else {\n+     ResourceMark rm(THREAD);\n+     stringStream ss;\n+     ss.print(\"Index %d out of bounds for length %d\", index, arr->length());\n+     THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());\n+   }\n@@ -3116,0 +3225,261 @@\n+JNI_ENTRY(void*, jni_GetFlattenedArrayElements(JNIEnv* env, jarray array, jboolean* isCopy))\n+  if (isCopy != NULL) {\n+    *isCopy = JNI_FALSE;\n+  }\n+  arrayOop ar = arrayOop(JNIHandles::resolve_non_null(array));\n+  if (!ar->is_array()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not an array\");\n+  }\n+  if (!ar->is_flatArray()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not a flattened array\");\n+  }\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass());\n+  if (vak->contains_oops()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Flattened array contains oops\");\n+  }\n+  oop a = lock_gc_or_pin_object(thread, array);\n+  flatArrayOop vap = flatArrayOop(a);\n+  void* ret = vap->value_at_addr(0, vak->layout_helper());\n+  return ret;\n+JNI_END\n+\n+JNI_ENTRY(void, jni_ReleaseFlattenedArrayElements(JNIEnv* env, jarray array, void* elem, jint mode))\n+  unlock_gc_or_unpin_object(thread, array);\n+JNI_END\n+\n+JNI_ENTRY(jsize, jni_GetFlattenedArrayElementSize(JNIEnv* env, jarray array)) {\n+  arrayOop a = arrayOop(JNIHandles::resolve_non_null(array));\n+  if (!a->is_array()) {\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Not an array\");\n+  }\n+  if (!a->is_flatArray()) {\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Not a flattened array\");\n+  }\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(a->klass());\n+  jsize ret = vak->element_byte_size();\n+  return ret;\n+}\n+JNI_END\n+\n+JNI_ENTRY(jclass, jni_GetFlattenedArrayElementClass(JNIEnv* env, jarray array))\n+  arrayOop a = arrayOop(JNIHandles::resolve_non_null(array));\n+  if (!a->is_array()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not an array\");\n+  }\n+  if (!a->is_flatArray()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not a flattened array\");\n+  }\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(a->klass());\n+  InlineKlass* vk = vak->element_klass();\n+  return (jclass) JNIHandles::make_local(vk->java_mirror());\n+JNI_END\n+\n+JNI_ENTRY(jsize, jni_GetFieldOffsetInFlattenedLayout(JNIEnv* env, jclass clazz, const char *name, const char *signature, jboolean* is_inlined))\n+  oop mirror = JNIHandles::resolve_non_null(clazz);\n+  Klass* k = java_lang_Class::as_Klass(mirror);\n+  if (!k->is_inline_klass()) {\n+    ResourceMark rm;\n+        THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), err_msg(\"%s has not flattened layout\", k->external_name()));\n+  }\n+  InlineKlass* vk = InlineKlass::cast(k);\n+\n+  TempNewSymbol fieldname = SymbolTable::probe(name, (int)strlen(name));\n+  TempNewSymbol signame = SymbolTable::probe(signature, (int)strlen(signature));\n+  if (fieldname == NULL || signame == NULL) {\n+    ResourceMark rm;\n+    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg(\"%s.%s %s\", vk->external_name(), name, signature));\n+  }\n+\n+  assert(vk->is_initialized(), \"If a flattened array has been created, the element klass must have been initialized\");\n+\n+  fieldDescriptor fd;\n+  if (!vk->is_instance_klass() ||\n+      !InstanceKlass::cast(vk)->find_field(fieldname, signame, false, &fd)) {\n+    ResourceMark rm;\n+    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg(\"%s.%s %s\", vk->external_name(), name, signature));\n+  }\n+\n+  int offset = fd.offset() - vk->first_field_offset();\n+  if (is_inlined != NULL) {\n+    *is_inlined = fd.is_inlined();\n+  }\n+  return (jsize)offset;\n+JNI_END\n+\n+JNI_ENTRY(jobject, jni_CreateSubElementSelector(JNIEnv* env, jarray array))\n+  oop ar = JNIHandles::resolve_non_null(array);\n+  if (!ar->is_array()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not an array\");\n+  }\n+  if (!ar->is_flatArray()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not a flattened array\");\n+  }\n+  flatArrayHandle ar_h(THREAD, flatArrayOop(ar));\n+  Klass* ses_k = SystemDictionary::resolve_or_null(vmSymbols::jdk_internal_vm_jni_SubElementSelector(),\n+        Handle(THREAD, SystemDictionary::java_system_loader()), Handle(), CHECK_NULL);\n+  InstanceKlass* ses_ik = InstanceKlass::cast(ses_k);\n+  ses_ik->initialize(CHECK_NULL);\n+  Klass* elementKlass = ArrayKlass::cast(ar_h()->klass())->element_klass();\n+  oop ses = ses_ik->allocate_instance(CHECK_NULL);\n+  Handle ses_h(THREAD, ses);\n+  jdk_internal_vm_jni_SubElementSelector::setArrayElementType(ses_h(), elementKlass->java_mirror());\n+  jdk_internal_vm_jni_SubElementSelector::setSubElementType(ses_h(), elementKlass->java_mirror());\n+  jdk_internal_vm_jni_SubElementSelector::setOffset(ses_h(), 0);\n+  jdk_internal_vm_jni_SubElementSelector::setIsInlined(ses_h(), true);   \/\/ by definition, top element of a flattened array is inlined\n+  jdk_internal_vm_jni_SubElementSelector::setIsInlineType(ses_h(), true); \/\/ by definition, top element of a flattened array is an inline type\n+  return JNIHandles::make_local(ses_h());\n+JNI_END\n+\n+JNI_ENTRY(jobject, jni_GetSubElementSelector(JNIEnv* env, jobject selector, jfieldID fieldID))\n+  oop slct = JNIHandles::resolve_non_null(selector);\n+  if (slct->klass()->name() != vmSymbols::jdk_internal_vm_jni_SubElementSelector()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Not a SubElementSelector\");\n+  }\n+  jboolean is_inlined = jdk_internal_vm_jni_SubElementSelector::getIsInlined(slct);\n+  if (!is_inlined) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"SubElement is not inlined\");\n+  }\n+  oop semirror = jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct);\n+  Klass* k = java_lang_Class::as_Klass(semirror);\n+  if (!k->is_inline_klass()) {\n+    ResourceMark rm;\n+        THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), err_msg(\"%s is not an inline type\", k->external_name()));\n+  }\n+  InlineKlass* vk = InlineKlass::cast(k);\n+  assert(vk->is_initialized(), \"If a flattened array has been created, the element klass must have been initialized\");\n+  int field_offset = jfieldIDWorkaround::from_instance_jfieldID(vk, fieldID);\n+  fieldDescriptor fd;\n+  if (!vk->find_field_from_offset(field_offset, false, &fd)) {\n+    THROW_NULL(vmSymbols::java_lang_NoSuchFieldError());\n+  }\n+  Handle arrayElementMirror(THREAD, jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct));\n+  \/\/ offset of the SubElement is offset of the original SubElement plus the offset of the field inside the element\n+  int offset = fd.offset() - vk->first_field_offset() + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);\n+  InstanceKlass* sesklass = InstanceKlass::cast(JNIHandles::resolve_non_null(selector)->klass());\n+  oop res = sesklass->allocate_instance(CHECK_NULL);\n+  Handle res_h(THREAD, res);\n+  jdk_internal_vm_jni_SubElementSelector::setArrayElementType(res_h(), arrayElementMirror());\n+  InstanceKlass* holder = fd.field_holder();\n+  BasicType bt = Signature::basic_type(fd.signature());\n+  if (is_java_primitive(bt)) {\n+    jdk_internal_vm_jni_SubElementSelector::setSubElementType(res_h(), java_lang_Class::primitive_mirror(bt));\n+  } else {\n+    Klass* fieldKlass = SystemDictionary::resolve_or_fail(fd.signature(), Handle(THREAD, holder->class_loader()),\n+        Handle(THREAD, holder->protection_domain()), true, CHECK_NULL);\n+    jdk_internal_vm_jni_SubElementSelector::setSubElementType(res_h(),fieldKlass->java_mirror());\n+  }\n+  jdk_internal_vm_jni_SubElementSelector::setOffset(res_h(), offset);\n+  jdk_internal_vm_jni_SubElementSelector::setIsInlined(res_h(), fd.is_inlined());\n+  jdk_internal_vm_jni_SubElementSelector::setIsInlineType(res_h(), fd.is_inline_type());\n+  return JNIHandles::make_local(res_h());\n+JNI_END\n+\n+JNI_ENTRY(jobject, jni_GetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+  flatArrayOop ar =  (flatArrayOop)JNIHandles::resolve_non_null(array);\n+  oop slct = JNIHandles::resolve_non_null(selector);\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass());\n+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) {\n+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), \"Array\/Selector mismatch\");\n+  }\n+  oop res = NULL;\n+  if (!jdk_internal_vm_jni_SubElementSelector::getIsInlined(slct)) {\n+    int offset = (address)ar->base() - cast_from_oop<address>(ar) + index * vak->element_byte_size()\n+                      + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);\n+    res = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(ar, offset);\n+  } else {\n+    Handle slct_h(THREAD, slct);\n+    InlineKlass* fieldKlass = InlineKlass::cast(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)));\n+    res = fieldKlass->allocate_instance_buffer(CHECK_NULL);\n+    \/\/ The array might have been moved by the GC, refreshing the arrayOop\n+    ar =  (flatArrayOop)JNIHandles::resolve_non_null(array);\n+    address addr = (address)ar->value_at_addr(index, vak->layout_helper())\n+              + jdk_internal_vm_jni_SubElementSelector::getOffset(slct_h());\n+    fieldKlass->inline_copy_payload_to_new_oop(addr, res);\n+  }\n+  return JNIHandles::make_local(res);\n+JNI_END\n+\n+JNI_ENTRY(void, jni_SetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index, jobject value))\n+  flatArrayOop ar =  (flatArrayOop)JNIHandles::resolve_non_null(array);\n+  oop slct = JNIHandles::resolve_non_null(selector);\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass());\n+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) {\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Array\/Selector mismatch\");\n+  }\n+  oop val = JNIHandles::resolve(value);\n+  if (val == NULL) {\n+    if (jdk_internal_vm_jni_SubElementSelector::getIsInlineType(slct)) {\n+      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), \"null cannot be stored in a flattened array\");\n+    }\n+  } else {\n+    if (!val->is_a(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)))) {\n+      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), \"type mismatch\");\n+    }\n+  }\n+  if (!jdk_internal_vm_jni_SubElementSelector::getIsInlined(slct)) {\n+    int offset = (address)ar->base() - cast_from_oop<address>(ar) + index * vak->element_byte_size()\n+                  + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);\n+    HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(ar, offset, JNIHandles::resolve(value));\n+  } else {\n+    InlineKlass* fieldKlass = InlineKlass::cast(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)));\n+    address addr = (address)ar->value_at_addr(index, vak->layout_helper())\n+                  + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);\n+    fieldKlass->inline_copy_oop_to_payload(JNIHandles::resolve_non_null(value), addr);\n+  }\n+JNI_END\n+\n+#define DEFINE_GETSUBELEMENT(ElementType,Result,ElementBasicType) \\\n+\\\n+JNI_ENTRY(ElementType, \\\n+          jni_Get##Result##SubElement(JNIEnv *env, jarray array, jobject selector, int index)) \\\n+  flatArrayOop ar = (flatArrayOop)JNIHandles::resolve_non_null(array); \\\n+  oop slct = JNIHandles::resolve_non_null(selector); \\\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass()); \\\n+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) { \\\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Array\/Selector mismatch\"); \\\n+  } \\\n+  if (jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct) != java_lang_Class::primitive_mirror(ElementBasicType)) { \\\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong SubElement type\"); \\\n+  } \\\n+  address addr = (address)ar->value_at_addr(index, vak->layout_helper()) \\\n+               + jdk_internal_vm_jni_SubElementSelector::getOffset(slct); \\\n+  ElementType result = *(ElementType*)addr; \\\n+  return result; \\\n+JNI_END\n+\n+DEFINE_GETSUBELEMENT(jboolean, Boolean,T_BOOLEAN)\n+DEFINE_GETSUBELEMENT(jbyte, Byte, T_BYTE)\n+DEFINE_GETSUBELEMENT(jshort, Short,T_SHORT)\n+DEFINE_GETSUBELEMENT(jchar, Char,T_CHAR)\n+DEFINE_GETSUBELEMENT(jint, Int,T_INT)\n+DEFINE_GETSUBELEMENT(jlong, Long,T_LONG)\n+DEFINE_GETSUBELEMENT(jfloat, Float,T_FLOAT)\n+DEFINE_GETSUBELEMENT(jdouble, Double,T_DOUBLE)\n+\n+#define DEFINE_SETSUBELEMENT(ElementType,Result,ElementBasicType) \\\n+\\\n+JNI_ENTRY(void, \\\n+          jni_Set##Result##SubElement(JNIEnv *env, jarray array, jobject selector, int index, ElementType value)) \\\n+  flatArrayOop ar = (flatArrayOop)JNIHandles::resolve_non_null(array); \\\n+  oop slct = JNIHandles::resolve_non_null(selector); \\\n+  FlatArrayKlass* vak = FlatArrayKlass::cast(ar->klass()); \\\n+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) { \\\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Array\/Selector mismatch\"); \\\n+  } \\\n+  if (jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct) != java_lang_Class::primitive_mirror(ElementBasicType)) { \\\n+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), \"Wrong SubElement type\"); \\\n+  } \\\n+  address addr = (address)ar->value_at_addr(index, vak->layout_helper()) \\\n+               + jdk_internal_vm_jni_SubElementSelector::getOffset(slct); \\\n+  *(ElementType*)addr = value; \\\n+JNI_END\n+\n+DEFINE_SETSUBELEMENT(jboolean, Boolean,T_BOOLEAN)\n+DEFINE_SETSUBELEMENT(jbyte, Byte, T_BYTE)\n+DEFINE_SETSUBELEMENT(jshort, Short,T_SHORT)\n+DEFINE_SETSUBELEMENT(jchar, Char,T_CHAR)\n+DEFINE_SETSUBELEMENT(jint, Int,T_INT)\n+DEFINE_SETSUBELEMENT(jlong, Long,T_LONG)\n+DEFINE_SETSUBELEMENT(jfloat, Float,T_FLOAT)\n+DEFINE_SETSUBELEMENT(jdouble, Double,T_DOUBLE)\n+\n@@ -3399,1 +3769,32 @@\n-    jni_GetModule\n+    jni_GetModule,\n+\n+    \/\/ Flattened arrays features\n+\n+    jni_GetFlattenedArrayElements,\n+    jni_ReleaseFlattenedArrayElements,\n+    jni_GetFlattenedArrayElementClass,\n+    jni_GetFlattenedArrayElementSize,\n+    jni_GetFieldOffsetInFlattenedLayout,\n+\n+    jni_CreateSubElementSelector,\n+    jni_GetSubElementSelector,\n+    jni_GetObjectSubElement,\n+    jni_SetObjectSubElement,\n+\n+    jni_GetBooleanSubElement,\n+    jni_GetByteSubElement,\n+    jni_GetShortSubElement,\n+    jni_GetCharSubElement,\n+    jni_GetIntSubElement,\n+    jni_GetLongSubElement,\n+    jni_GetFloatSubElement,\n+    jni_GetDoubleSubElement,\n+\n+    jni_SetBooleanSubElement,\n+    jni_SetByteSubElement,\n+    jni_SetShortSubElement,\n+    jni_SetCharSubElement,\n+    jni_SetIntSubElement,\n+    jni_SetLongSubElement,\n+    jni_SetFloatSubElement,\n+    jni_SetDoubleSubElement\n","filename":"src\/hotspot\/share\/prims\/jni.cpp","additions":459,"deletions":58,"binary":false,"changes":517,"status":"modified"},{"patch":"@@ -284,1 +284,2 @@\n-      !(fd.field_type() == T_ARRAY && ftype == T_OBJECT)) {\n+      !(fd.field_type() == T_ARRAY && ftype == T_OBJECT) &&\n+      !(fd.field_type() == T_INLINE_TYPE && ftype == T_OBJECT)) {\n@@ -321,1 +322,2 @@\n-      !(fd.field_type() == T_ARRAY && ftype == T_OBJECT)) {\n+      !(fd.field_type() == T_ARRAY && ftype == T_OBJECT) &&\n+      !(fd.field_type() == T_INLINE_TYPE && ftype == T_OBJECT)) {\n@@ -372,1 +374,1 @@\n-check_is_obj_array(JavaThread* thr, jarray jArray) {\n+check_is_obj_or_inline_array(JavaThread* thr, jarray jArray) {\n@@ -374,1 +376,1 @@\n-  if (!aOop->is_objArray()) {\n+  if (!aOop->is_objArray() && !aOop->is_flatArray()) {\n@@ -494,1 +496,1 @@\n-      name[0] == JVM_SIGNATURE_CLASS &&            \/\/ 'L'\n+      (name[0] == JVM_SIGNATURE_CLASS || name[0] == JVM_SIGNATURE_INLINE_TYPE) && \/\/ 'L' or 'Q'\n@@ -1643,1 +1645,1 @@\n-      check_is_obj_array(thr, array);\n+      check_is_obj_or_inline_array(thr, array);\n@@ -1657,1 +1659,1 @@\n-      check_is_obj_array(thr, array);\n+      check_is_obj_or_inline_array(thr, array);\n@@ -2022,0 +2024,201 @@\n+JNI_ENTRY_CHECKED(void*,\n+    checked_jni_GetFlattenedArrayElements(JNIEnv* env, jarray array, jboolean* isCopy))\n+    functionEnter(thr);\n+    void* result = UNCHECKED()->GetFlattenedArrayElements(env, array, isCopy);\n+    functionExit(thr);\n+    return result;\n+\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_ReleaseFlattenedArrayElements(JNIEnv* env, jarray array, void* elem, jint mode))\n+    functionEnter(thr);\n+    UNCHECKED()->ReleaseFlattenedArrayElements(env, array, elem, mode);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jclass,\n+    checked_jni_GetFlattenedArrayElementClass(JNIEnv* env, jarray array))\n+    functionEnter(thr);\n+    jclass clazz = UNCHECKED()->GetFlattenedArrayElementClass(env, array);\n+    functionExit(thr);\n+    return clazz;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jsize,\n+    checked_jni_GetFlattenedArrayElementSize(JNIEnv* env, jarray array))\n+    functionEnter(thr);\n+    jsize size = UNCHECKED()->GetFlattenedArrayElementSize(env, array);\n+    functionExit(thr);\n+    return size;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jsize,\n+    checked_jni_GetFieldOffsetInFlattenedLayout(JNIEnv* env, jclass clazz, const char *name, const char *signature, jboolean* isFlattened))\n+    functionEnter(thr);\n+    jsize offset = UNCHECKED()->GetFieldOffsetInFlattenedLayout(env, clazz, name, signature, isFlattened);\n+    functionExit(thr);\n+    return offset;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jobject,\n+    checked_jni_CreateSubElementSelector(JNIEnv* env, jarray array))\n+    functionEnter(thr);\n+    jobject selector = UNCHECKED()->CreateSubElementSelector(env, array);\n+    functionExit(thr);\n+    return selector;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jobject,\n+    checked_jni_GetSubElementSelector(JNIEnv* env, jobject selector, jfieldID fieldID))\n+    functionEnter(thr);\n+    jobject res = UNCHECKED()->GetSubElementSelector(env, selector, fieldID);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jobject,\n+    checked_jni_GetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jobject res = UNCHECKED()->GetObjectSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index, jobject value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetObjectSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jboolean,\n+    checked_jni_GetBooleanSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jboolean res = UNCHECKED()->GetBooleanSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetBooleanSubElement(JNIEnv* env, jarray array, jobject selector, int index, jboolean value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetBooleanSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jbyte,\n+    checked_jni_GetByteSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jbyte res = UNCHECKED()->GetByteSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetByteSubElement(JNIEnv* env, jarray array, jobject selector, int index, jbyte value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetByteSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jshort,\n+    checked_jni_GetShortSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jshort res = UNCHECKED()->GetShortSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetShortSubElement(JNIEnv* env, jarray array, jobject selector, int index, jshort value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetShortSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jchar,\n+    checked_jni_GetCharSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jchar res = UNCHECKED()->GetCharSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetCharSubElement(JNIEnv* env, jarray array, jobject selector, int index, jchar value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetCharSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jint,\n+    checked_jni_GetIntSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jint res = UNCHECKED()->GetIntSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetIntSubElement(JNIEnv* env, jarray array, jobject selector, int index, jint value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetIntSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jlong,\n+    checked_jni_GetLongSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jlong res = UNCHECKED()->GetLongSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetLongSubElement(JNIEnv* env, jarray array, jobject selector, int index, jlong value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetLongSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jfloat,\n+    checked_jni_GetFloatSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jfloat res = UNCHECKED()->GetFloatSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetFloatSubElement(JNIEnv* env, jarray array, jobject selector, int index, jfloat value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetFloatSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(jdouble,\n+    checked_jni_GetDoubleSubElement(JNIEnv* env, jarray array, jobject selector, int index))\n+    functionEnter(thr);\n+    jdouble res = UNCHECKED()->GetDoubleSubElement(env, array, selector, index);\n+    functionExit(thr);\n+    return res;\n+JNI_END\n+\n+JNI_ENTRY_CHECKED(void,\n+    checked_jni_SetDoubleSubElement(JNIEnv* env, jarray array, jobject selector, int index, jdouble value))\n+    functionEnter(thr);\n+    UNCHECKED()->SetDoubleSubElement(env, array, selector, index, value);\n+    functionExit(thr);\n+    return;\n+JNI_END\n+\n@@ -2307,1 +2510,31 @@\n-    checked_jni_GetModule\n+    checked_jni_GetModule,\n+\n+    \/\/ Flattened arrays Features\n+    checked_jni_GetFlattenedArrayElements,\n+    checked_jni_ReleaseFlattenedArrayElements,\n+    checked_jni_GetFlattenedArrayElementClass,\n+    checked_jni_GetFlattenedArrayElementSize,\n+    checked_jni_GetFieldOffsetInFlattenedLayout,\n+\n+    checked_jni_CreateSubElementSelector,\n+    checked_jni_GetSubElementSelector,\n+    checked_jni_GetObjectSubElement,\n+    checked_jni_SetObjectSubElement,\n+\n+    checked_jni_GetBooleanSubElement,\n+    checked_jni_GetByteSubElement,\n+    checked_jni_GetShortSubElement,\n+    checked_jni_GetCharSubElement,\n+    checked_jni_GetIntSubElement,\n+    checked_jni_GetLongSubElement,\n+    checked_jni_GetFloatSubElement,\n+    checked_jni_GetDoubleSubElement,\n+\n+    checked_jni_SetBooleanSubElement,\n+    checked_jni_SetByteSubElement,\n+    checked_jni_SetShortSubElement,\n+    checked_jni_SetCharSubElement,\n+    checked_jni_SetIntSubElement,\n+    checked_jni_SetLongSubElement,\n+    checked_jni_SetFloatSubElement,\n+    checked_jni_SetDoubleSubElement\n","filename":"src\/hotspot\/share\/prims\/jniCheck.cpp","additions":241,"deletions":8,"binary":false,"changes":249,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n@@ -595,1 +596,22 @@\n-  return handle == NULL ? 0 : ObjectSynchronizer::FastHashCode (THREAD, JNIHandles::resolve_non_null(handle)) ;\n+  if (handle == NULL) {\n+    return 0;\n+  }\n+  oop obj = JNIHandles::resolve_non_null(handle);\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+      JavaValue result(T_INT);\n+      JavaCallArguments args;\n+      Handle ho(THREAD, obj);\n+      args.push_oop(ho);\n+      methodHandle method(THREAD, Universe::inline_type_hash_code_method());\n+      JavaCalls::call(&result, method, &args, THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in hashCode\", e, false);\n+        }\n+      }\n+      return result.get_jint();\n+  } else {\n+    return ObjectSynchronizer::FastHashCode(THREAD, obj);\n+  }\n@@ -647,0 +669,1 @@\n+       klass->is_inline_klass() ||\n@@ -1146,1 +1169,2 @@\n-    size = InstanceKlass::cast(klass)->local_interfaces()->length();\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    size = ik->local_interfaces()->length();\n@@ -1149,1 +1173,1 @@\n-    size = 2;\n+    size = 3;\n@@ -1159,1 +1183,2 @@\n-      Klass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);\n+      InstanceKlass* ik = InstanceKlass::cast(klass);\n+      Klass* k = ik->local_interfaces()->at(index);\n@@ -1163,1 +1188,1 @@\n-    \/\/ All arrays implement java.lang.Cloneable and java.io.Serializable\n+    \/\/ All arrays implement java.lang.Cloneable, java.io.Serializable and java.lang.IdentityObject\n@@ -1166,0 +1191,1 @@\n+    result->obj_at_put(2, vmClasses::IdentityObject_klass()->java_mirror());\n@@ -1761,0 +1787,2 @@\n+  bool is_ctor = (method->is_object_constructor() ||\n+                  method->is_static_init_factory());\n@@ -1762,1 +1790,1 @@\n-    return (method->is_initializer() && !method->is_static());\n+    return is_ctor;\n@@ -1764,1 +1792,3 @@\n-    return  (!method->is_initializer() && !method->is_overpass());\n+    return (!is_ctor &&\n+            !method->is_class_initializer() &&\n+            !method->is_overpass());\n@@ -1827,0 +1857,2 @@\n+        assert(method->is_object_constructor() ||\n+               method->is_static_init_factory(), \"must be\");\n@@ -2109,3 +2141,1 @@\n-  if (!m->is_initializer() || m->is_static()) {\n-    method = Reflection::new_method(m, true, CHECK_NULL);\n-  } else {\n+  if (m->is_object_constructor() || m->is_static_init_factory()) {\n@@ -2113,0 +2143,2 @@\n+  } else {\n+    method = Reflection::new_method(m, true, CHECK_NULL);\n@@ -2383,0 +2415,37 @@\n+\/\/ Arrays support \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+JVM_ENTRY(jboolean, JVM_ArrayIsAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == NULL) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  return ArrayKlass::cast(k)->element_access_is_atomic();\n+JVM_END\n+\n+JVM_ENTRY(jobject, JVM_ArrayEnsureAccessAtomic(JNIEnv *env, jclass unused, jobject array))\n+  oop o = JNIHandles::resolve(array);\n+  Klass* k = o->klass();\n+  if ((o == NULL) || (!k->is_array_klass())) {\n+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());\n+  }\n+  if (k->is_flatArray_klass()) {\n+    FlatArrayKlass* vk = FlatArrayKlass::cast(k);\n+    if (!vk->element_access_is_atomic()) {\n+      \/**\n+       * Need to decide how to implement:\n+       *\n+       * 1) Change to objArrayOop layout, therefore oop->klass() differs so\n+       * then \"<atomic>[Qfoo;\" klass needs to subclass \"[Qfoo;\" to pass through\n+       * \"checkcast\" & \"instanceof\"\n+       *\n+       * 2) Use extra header in the flatArrayOop to flag atomicity required and\n+       * possibly per instance lock structure. Said info, could be placed in\n+       * \"trailer\" rather than disturb the current arrayOop\n+       *\/\n+      Unimplemented();\n+    }\n+  }\n+  return array;\n+JVM_END\n+\n@@ -2545,1 +2614,1 @@\n-  return method->name() == vmSymbols::object_initializer_name();\n+  return method->is_object_constructor();\n@@ -3517,1 +3586,1 @@\n-    objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n+    objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3537,0 +3606,1 @@\n+  objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);\n@@ -3538,1 +3608,0 @@\n-  objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":82,"deletions":13,"binary":false,"changes":95,"status":"modified"},{"patch":"@@ -2509,1 +2509,2 @@\n-                                            src_st.access_flags().is_static());\n+                                            src_st.access_flags().is_static(),\n+                                            src_st.field_descriptor().is_inlined());\n@@ -2546,2 +2547,3 @@\n-    Array<InstanceKlass*>* interface_list = InstanceKlass::cast(k)->local_interfaces();\n-    const int result_length = (interface_list == NULL ? 0 : interface_list->length());\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    Array<InstanceKlass*>* interface_list = ik->local_interfaces();\n+    int result_length = (interface_list == NULL ? 0 : interface_list->length());\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -973,2 +973,4 @@\n-    \/\/ Revoke any biases before querying the mark word\n-    BiasedLocking::revoke_at_safepoint(hobj);\n+    if (UseBiasedLocking) {\n+      \/\/ Revoke any biases before querying the mark word\n+      BiasedLocking::revoke_at_safepoint(hobj);\n+    }\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnvBase.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -337,0 +337,9 @@\n+  \/\/ Cannot redefine or retransform interface java.lang.IdentityObject.\n+  if (k->name() == vmSymbols::java_lang_IdentityObject()) {\n+    return false;\n+  }\n+  \/\/ Cannot redefine or retransform interface java.lang.PrimitiveObject.\n+  if (k->name() == vmSymbols::java_lang_PrimitiveObject()) {\n+    return false;\n+  }\n+\n@@ -603,2 +612,1 @@\n-    \/\/ At this stage JVM_CONSTANT_UnresolvedClassInError should not be\n-    \/\/ here\n+    \/\/ At this stage JVM_CONSTANT_UnresolvedClassInError should not be here\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -129,5 +129,5 @@\n-  IS_METHOD            = java_lang_invoke_MemberName::MN_IS_METHOD,\n-  IS_CONSTRUCTOR       = java_lang_invoke_MemberName::MN_IS_CONSTRUCTOR,\n-  IS_FIELD             = java_lang_invoke_MemberName::MN_IS_FIELD,\n-  IS_TYPE              = java_lang_invoke_MemberName::MN_IS_TYPE,\n-  CALLER_SENSITIVE     = java_lang_invoke_MemberName::MN_CALLER_SENSITIVE,\n+  IS_METHOD             = java_lang_invoke_MemberName::MN_IS_METHOD,\n+  IS_OBJECT_CONSTRUCTOR = java_lang_invoke_MemberName::MN_IS_OBJECT_CONSTRUCTOR,\n+  IS_FIELD              = java_lang_invoke_MemberName::MN_IS_FIELD,\n+  IS_TYPE               = java_lang_invoke_MemberName::MN_IS_TYPE,\n+  CALLER_SENSITIVE      = java_lang_invoke_MemberName::MN_CALLER_SENSITIVE,\n@@ -135,8 +135,8 @@\n-  REFERENCE_KIND_SHIFT = java_lang_invoke_MemberName::MN_REFERENCE_KIND_SHIFT,\n-  REFERENCE_KIND_MASK  = java_lang_invoke_MemberName::MN_REFERENCE_KIND_MASK,\n-  SEARCH_SUPERCLASSES  = java_lang_invoke_MemberName::MN_SEARCH_SUPERCLASSES,\n-  SEARCH_INTERFACES    = java_lang_invoke_MemberName::MN_SEARCH_INTERFACES,\n-  LM_UNCONDITIONAL     = java_lang_invoke_MemberName::MN_UNCONDITIONAL_MODE,\n-  LM_MODULE            = java_lang_invoke_MemberName::MN_MODULE_MODE,\n-  LM_TRUSTED           = java_lang_invoke_MemberName::MN_TRUSTED_MODE,\n-  ALL_KINDS      = IS_METHOD | IS_CONSTRUCTOR | IS_FIELD | IS_TYPE\n+  REFERENCE_KIND_SHIFT  = java_lang_invoke_MemberName::MN_REFERENCE_KIND_SHIFT,\n+  REFERENCE_KIND_MASK   = java_lang_invoke_MemberName::MN_REFERENCE_KIND_MASK,\n+  SEARCH_SUPERCLASSES   = java_lang_invoke_MemberName::MN_SEARCH_SUPERCLASSES,\n+  SEARCH_INTERFACES     = java_lang_invoke_MemberName::MN_SEARCH_INTERFACES,\n+  LM_UNCONDITIONAL      = java_lang_invoke_MemberName::MN_UNCONDITIONAL_MODE,\n+  LM_MODULE             = java_lang_invoke_MemberName::MN_MODULE_MODE,\n+  LM_TRUSTED            = java_lang_invoke_MemberName::MN_TRUSTED_MODE,\n+  ALL_KINDS      = IS_METHOD | IS_OBJECT_CONSTRUCTOR | IS_FIELD | IS_TYPE\n@@ -153,1 +153,1 @@\n-    flags |= IS_CONSTRUCTOR;\n+    flags |= IS_OBJECT_CONSTRUCTOR;\n@@ -172,1 +172,1 @@\n-    case IS_CONSTRUCTOR:\n+    case IS_OBJECT_CONSTRUCTOR:\n@@ -314,2 +314,2 @@\n-    } else if (m->is_initializer()) {\n-      flags |= IS_CONSTRUCTOR | (JVM_REF_invokeSpecial << REFERENCE_KIND_SHIFT);\n+    } else if (m->is_object_constructor()) {\n+      flags |= IS_OBJECT_CONSTRUCTOR | (JVM_REF_invokeSpecial << REFERENCE_KIND_SHIFT);\n@@ -353,0 +353,3 @@\n+  if (fd.is_inlined()) {\n+    flags |= JVM_ACC_FIELD_INLINED;\n+  }\n@@ -807,1 +810,1 @@\n-  case IS_CONSTRUCTOR:\n+  case IS_OBJECT_CONSTRUCTOR:\n@@ -813,1 +816,3 @@\n-        if (name == vmSymbols::object_initializer_name()) {\n+        if (name != vmSymbols::object_initializer_name()) {\n+          break;                \/\/ will throw after end of switch\n+        } else if (type->is_void_method_signature()) {\n@@ -816,1 +821,2 @@\n-          break;                \/\/ will throw after end of switch\n+          \/\/ LinkageError unless it returns something reasonable\n+          LinkResolver::resolve_static_call(result, link_info, false, THREAD);\n@@ -876,1 +882,1 @@\n-  case IS_CONSTRUCTOR:\n+  case IS_OBJECT_CONSTRUCTOR:\n@@ -955,1 +961,1 @@\n-      match_flags &= ~(IS_CONSTRUCTOR | IS_METHOD);\n+      match_flags &= ~(IS_OBJECT_CONSTRUCTOR | IS_METHOD);\n@@ -985,1 +991,1 @@\n-  if ((match_flags & (IS_METHOD | IS_CONSTRUCTOR)) != 0) {\n+  if ((match_flags & (IS_METHOD | IS_OBJECT_CONSTRUCTOR)) != 0) {\n@@ -990,2 +996,2 @@\n-    bool negate_name_test = false;\n-    \/\/ fix name so that it captures the intention of IS_CONSTRUCTOR\n+    bool ctor_ok = true, sfac_ok = true;\n+    \/\/ fix name so that it captures the intention of IS_OBJECT_CONSTRUCTOR\n@@ -999,1 +1005,2 @@\n-    } else if (!(match_flags & IS_CONSTRUCTOR)) {\n+      sfac_ok = false;\n+    } else if (!(match_flags & IS_OBJECT_CONSTRUCTOR)) {\n@@ -1001,6 +1008,1 @@\n-      if (name == NULL) {\n-        name = init_name;\n-        negate_name_test = true; \/\/ if we see the name, we *omit* the entry\n-      } else if (name == init_name) {\n-        return 0;               \/\/ no methods of this constructor name\n-      }\n+      ctor_ok = false;  \/\/ but sfac_ok is true, so we might find <init>\n@@ -1016,1 +1018,1 @@\n-      if (name != NULL && ((m_name != name) ^ negate_name_test))\n+      if (name != NULL && m_name != name)\n@@ -1020,0 +1022,4 @@\n+      if (m_name == init_name) {  \/\/ might be either ctor or sfac\n+        if (m->is_object_constructor()  && !ctor_ok)  continue;\n+        if (m->is_static_init_factory() && !sfac_ok)  continue;\n+      }\n@@ -1119,1 +1125,1 @@\n-    template(java_lang_invoke_MemberName,MN_IS_CONSTRUCTOR) \\\n+    template(java_lang_invoke_MemberName,MN_IS_OBJECT_CONSTRUCTOR) \\\n@@ -1263,1 +1269,1 @@\n-               (flags & ALL_KINDS) == IS_CONSTRUCTOR) {\n+               (flags & ALL_KINDS) == IS_OBJECT_CONSTRUCTOR) {\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":41,"deletions":35,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -37,0 +37,2 @@\n+#include \"logging\/log.hpp\"\n+#include \"logging\/logStream.hpp\"\n@@ -39,0 +41,3 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.inline.hpp\"\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -45,0 +50,1 @@\n+#include \"runtime\/fieldDescriptor.inline.hpp\"\n@@ -151,1 +157,0 @@\n-\n@@ -236,0 +241,1 @@\n+      assert(!_obj->is_inline_type() || _obj->mark().is_larval_state(), \"must be an object instance or a larval inline type\");\n@@ -240,1 +246,0 @@\n-\n@@ -262,0 +267,62 @@\n+#ifdef ASSERT\n+\/*\n+ * Get the field descriptor of the field of the given object at the given offset.\n+ *\/\n+static bool get_field_descriptor(oop p, jlong offset, fieldDescriptor* fd) {\n+  bool found = false;\n+  Klass* k = p->klass();\n+  if (k->is_instance_klass()) {\n+    InstanceKlass* ik = InstanceKlass::cast(k);\n+    found = ik->find_field_from_offset((int)offset, false, fd);\n+    if (!found && ik->is_mirror_instance_klass()) {\n+      Klass* k2 = java_lang_Class::as_Klass(p);\n+      if (k2->is_instance_klass()) {\n+        ik = InstanceKlass::cast(k2);\n+        found = ik->find_field_from_offset((int)offset, true, fd);\n+      }\n+    }\n+  }\n+  return found;\n+}\n+#endif \/\/ ASSERT\n+\n+static void assert_and_log_unsafe_value_access(oop p, jlong offset, InlineKlass* vk) {\n+  Klass* k = p->klass();\n+#ifdef ASSERT\n+  if (k->is_instance_klass()) {\n+    assert_field_offset_sane(p, offset);\n+    fieldDescriptor fd;\n+    bool found = get_field_descriptor(p, offset, &fd);\n+    if (found) {\n+      assert(found, \"value field not found\");\n+      assert(fd.is_inlined(), \"field not flat\");\n+    } else {\n+      if (log_is_enabled(Trace, valuetypes)) {\n+        log_trace(valuetypes)(\"not a field in %s at offset \" SIZE_FORMAT_HEX,\n+                              p->klass()->external_name(), offset);\n+      }\n+    }\n+  } else if (k->is_flatArray_klass()) {\n+    FlatArrayKlass* vak = FlatArrayKlass::cast(k);\n+    int index = (offset - vak->array_header_in_bytes()) \/ vak->element_byte_size();\n+    address dest = (address)((flatArrayOop)p)->value_at_addr(index, vak->layout_helper());\n+    assert(dest == (cast_from_oop<address>(p) + offset), \"invalid offset\");\n+  } else {\n+    ShouldNotReachHere();\n+  }\n+#endif \/\/ ASSERT\n+  if (log_is_enabled(Trace, valuetypes)) {\n+    if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* vak = FlatArrayKlass::cast(k);\n+      int index = (offset - vak->array_header_in_bytes()) \/ vak->element_byte_size();\n+      address dest = (address)((flatArrayOop)p)->value_at_addr(index, vak->layout_helper());\n+      log_trace(valuetypes)(\"%s array type %s index %d element size %d offset \" SIZE_FORMAT_HEX \" at \" INTPTR_FORMAT,\n+                            p->klass()->external_name(), vak->external_name(),\n+                            index, vak->element_byte_size(), offset, p2i(dest));\n+    } else {\n+      log_trace(valuetypes)(\"%s field type %s at offset \" SIZE_FORMAT_HEX,\n+                            p->klass()->external_name(), vk->external_name(), offset);\n+    }\n+  }\n+}\n+\n@@ -276,0 +343,1 @@\n+  assert(!p->is_inline_type() || p->mark().is_larval_state(), \"must be an object instance or a larval inline type\");\n@@ -279,0 +347,58 @@\n+UNSAFE_ENTRY(jlong, Unsafe_ValueHeaderSize(JNIEnv *env, jobject unsafe, jclass c)) {\n+  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(c));\n+  InlineKlass* vk = InlineKlass::cast(k);\n+  return vk->first_field_offset();\n+} UNSAFE_END\n+\n+UNSAFE_ENTRY(jboolean, Unsafe_IsFlattenedArray(JNIEnv *env, jobject unsafe, jclass c)) {\n+  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(c));\n+  return k->is_flatArray_klass();\n+} UNSAFE_END\n+\n+UNSAFE_ENTRY(jobject, Unsafe_UninitializedDefaultValue(JNIEnv *env, jobject unsafe, jclass vc)) {\n+  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(vc));\n+  InlineKlass* vk = InlineKlass::cast(k);\n+  oop v = vk->default_value();\n+  return JNIHandles::make_local(THREAD, v);\n+} UNSAFE_END\n+\n+UNSAFE_ENTRY(jobject, Unsafe_GetValue(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jclass vc)) {\n+  oop base = JNIHandles::resolve(obj);\n+  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(vc));\n+  InlineKlass* vk = InlineKlass::cast(k);\n+  assert_and_log_unsafe_value_access(base, offset, vk);\n+  Handle base_h(THREAD, base);\n+  oop v = vk->read_inlined_field(base_h(), offset, CHECK_NULL);\n+  return JNIHandles::make_local(THREAD, v);\n+} UNSAFE_END\n+\n+UNSAFE_ENTRY(void, Unsafe_PutValue(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jclass vc, jobject value)) {\n+  oop base = JNIHandles::resolve(obj);\n+  Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(vc));\n+  InlineKlass* vk = InlineKlass::cast(k);\n+  assert(!base->is_inline_type() || base->mark().is_larval_state(), \"must be an object instance or a larval inline type\");\n+  assert_and_log_unsafe_value_access(base, offset, vk);\n+  oop v = JNIHandles::resolve(value);\n+  vk->write_inlined_field(base, offset, v, CHECK);\n+} UNSAFE_END\n+\n+UNSAFE_ENTRY(jobject, Unsafe_MakePrivateBuffer(JNIEnv *env, jobject unsafe, jobject value)) {\n+  oop v = JNIHandles::resolve_non_null(value);\n+  assert(v->is_inline_type(), \"must be an inline type instance\");\n+  Handle vh(THREAD, v);\n+  InlineKlass* vk = InlineKlass::cast(v->klass());\n+  instanceOop new_value = vk->allocate_instance_buffer(CHECK_NULL);\n+  vk->inline_copy_oop_to_new_oop(vh(),  new_value);\n+  markWord mark = new_value->mark();\n+  new_value->set_mark(mark.enter_larval_state());\n+  return JNIHandles::make_local(THREAD, new_value);\n+} UNSAFE_END\n+\n+UNSAFE_ENTRY(jobject, Unsafe_FinishPrivateBuffer(JNIEnv *env, jobject unsafe, jobject value)) {\n+  oop v = JNIHandles::resolve(value);\n+  assert(v->mark().is_larval_state(), \"must be a larval value\");\n+  markWord mark = v->mark();\n+  v->set_mark(mark.exit_larval_state());\n+  return JNIHandles::make_local(THREAD, v);\n+} UNSAFE_END\n+\n@@ -618,0 +744,5 @@\n+  } else if (k->is_flatArray_klass()) {\n+    FlatArrayKlass* vak = FlatArrayKlass::cast(k);\n+    InlineKlass* vklass = vak->element_klass();\n+    base = vak->array_header_in_bytes();\n+    scale = vak->element_byte_size();\n@@ -653,0 +784,6 @@\n+UNSAFE_ENTRY(jlong, Unsafe_GetObjectSize0(JNIEnv* env, jobject o, jobject obj))\n+  oop p = JNIHandles::resolve(obj);\n+  return p->size() * HeapWordSize;\n+UNSAFE_END\n+\n+\n@@ -782,0 +919,2 @@\n+\/\/\n+\/\/ An anonymous class cannot be an inline type.\n@@ -873,0 +1012,1 @@\n+  assert(!anonk->is_inline_klass(), \"unsafe anonymous class cannot be inline class\");\n@@ -1066,4 +1206,4 @@\n-    {CC \"get\" #Type,      CC \"(\" OBJ \"J)\" #Desc,       FN_PTR(Unsafe_Get##Type)}, \\\n-    {CC \"put\" #Type,      CC \"(\" OBJ \"J\" #Desc \")V\",   FN_PTR(Unsafe_Put##Type)}, \\\n-    {CC \"get\" #Type \"Volatile\",      CC \"(\" OBJ \"J)\" #Desc,       FN_PTR(Unsafe_Get##Type##Volatile)}, \\\n-    {CC \"put\" #Type \"Volatile\",      CC \"(\" OBJ \"J\" #Desc \")V\",   FN_PTR(Unsafe_Put##Type##Volatile)}\n+    {CC \"get\"  #Type,      CC \"(\" OBJ \"J)\" #Desc,                 FN_PTR(Unsafe_Get##Type)}, \\\n+    {CC \"put\"  #Type,      CC \"(\" OBJ \"J\" #Desc \")V\",             FN_PTR(Unsafe_Put##Type)}, \\\n+    {CC \"get\"  #Type \"Volatile\",      CC \"(\" OBJ \"J)\" #Desc,      FN_PTR(Unsafe_Get##Type##Volatile)}, \\\n+    {CC \"put\"  #Type \"Volatile\",      CC \"(\" OBJ \"J\" #Desc \")V\",  FN_PTR(Unsafe_Put##Type##Volatile)}\n@@ -1078,0 +1218,8 @@\n+    {CC \"isFlattenedArray\", CC \"(\" CLS \")Z\",                     FN_PTR(Unsafe_IsFlattenedArray)},\n+    {CC \"getValue\",         CC \"(\" OBJ \"J\" CLS \")\" OBJ,          FN_PTR(Unsafe_GetValue)},\n+    {CC \"putValue\",         CC \"(\" OBJ \"J\" CLS OBJ \")V\",         FN_PTR(Unsafe_PutValue)},\n+    {CC \"uninitializedDefaultValue\", CC \"(\" CLS \")\" OBJ,         FN_PTR(Unsafe_UninitializedDefaultValue)},\n+    {CC \"makePrivateBuffer\",     CC \"(\" OBJ \")\" OBJ,             FN_PTR(Unsafe_MakePrivateBuffer)},\n+    {CC \"finishPrivateBuffer\",   CC \"(\" OBJ \")\" OBJ,             FN_PTR(Unsafe_FinishPrivateBuffer)},\n+    {CC \"valueHeaderSize\",       CC \"(\" CLS \")J\",                FN_PTR(Unsafe_ValueHeaderSize)},\n+\n@@ -1100,0 +1248,1 @@\n+    {CC \"getObjectSize0\",     CC \"(Ljava\/lang\/Object;)J\", FN_PTR(Unsafe_GetObjectSize0)},\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":155,"deletions":6,"binary":false,"changes":161,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+#include \"memory\/iterator.inline.hpp\"\n@@ -58,0 +59,1 @@\n+#include \"oops\/compressedOops.inline.hpp\"\n@@ -64,0 +66,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -1824,0 +1827,87 @@\n+WB_ENTRY(jobjectArray, WB_getObjectsViaKlassOopMaps(JNIEnv* env, jobject wb, jobject thing))\n+  oop aoop = JNIHandles::resolve(thing);\n+  if (!aoop->is_instance()) {\n+    return NULL;\n+  }\n+  instanceHandle ih(THREAD, (instanceOop) aoop);\n+  InstanceKlass* klass = InstanceKlass::cast(ih->klass());\n+  if (klass->nonstatic_oop_map_count() == 0) {\n+    return NULL;\n+  }\n+  const OopMapBlock* map = klass->start_of_nonstatic_oop_maps();\n+  const OopMapBlock* const end = map + klass->nonstatic_oop_map_count();\n+  int oop_count = 0;\n+  while (map < end) {\n+    oop_count += map->count();\n+    map++;\n+  }\n+\n+  objArrayHandle result_array =\n+      oopFactory::new_objArray_handle(vmClasses::Object_klass(), oop_count, CHECK_NULL);\n+  map = klass->start_of_nonstatic_oop_maps();\n+  int index = 0;\n+  while (map < end) {\n+    int offset = map->offset();\n+    for (unsigned int j = 0; j < map->count(); j++) {\n+      result_array->obj_at_put(index++, ih->obj_field(offset));\n+      offset += heapOopSize;\n+    }\n+    map++;\n+  }\n+  return (jobjectArray)JNIHandles::make_local(THREAD, result_array());\n+WB_END\n+\n+class CollectOops : public BasicOopIterateClosure {\n+ public:\n+  GrowableArray<Handle>* array;\n+\n+  jobjectArray create_jni_result(JNIEnv* env, TRAPS) {\n+    objArrayHandle result_array =\n+        oopFactory::new_objArray_handle(vmClasses::Object_klass(), array->length(), CHECK_NULL);\n+    for (int i = 0 ; i < array->length(); i++) {\n+      result_array->obj_at_put(i, array->at(i)());\n+    }\n+    return (jobjectArray)JNIHandles::make_local(THREAD, result_array());\n+  }\n+\n+  void add_oop(oop o) {\n+    Handle oh = Handle(Thread::current(), o);\n+    \/\/ Value might be oop, but JLS can't see as Object, just iterate through it...\n+    if (oh != NULL && oh->is_inline_type()) {\n+      oh->oop_iterate(this);\n+    } else {\n+      array->append(oh);\n+    }\n+  }\n+\n+  void do_oop(oop* o) { add_oop(HeapAccess<>::oop_load(o)); }\n+  void do_oop(narrowOop* v) { add_oop(HeapAccess<>::oop_load(v)); }\n+};\n+\n+\n+WB_ENTRY(jobjectArray, WB_getObjectsViaOopIterator(JNIEnv* env, jobject wb, jobject thing))\n+  ResourceMark rm(thread);\n+  Handle objh(thread, JNIHandles::resolve(thing));\n+  GrowableArray<Handle>* array = new GrowableArray<Handle>(128);\n+  CollectOops collectOops;\n+  collectOops.array = array;\n+  objh->oop_iterate(&collectOops);\n+  return collectOops.create_jni_result(env, THREAD);\n+WB_END\n+\n+WB_ENTRY(jobjectArray, WB_getObjectsViaFrameOopIterator(JNIEnv* env, jobject wb, jint depth))\n+  ResourceMark rm(THREAD);\n+  GrowableArray<Handle>* array = new GrowableArray<Handle>(128);\n+  CollectOops collectOops;\n+  collectOops.array = array;\n+  StackFrameStream sfs(thread, false \/* update *\/, true \/* process_frames *\/);\n+  while (depth > 0) { \/\/ Skip the native WB API frame\n+    sfs.next();\n+    frame* f = sfs.current();\n+    f->oops_do(&collectOops, NULL, sfs.register_map());\n+    depth--;\n+  }\n+  return collectOops.create_jni_result(env, THREAD);\n+WB_END\n+\n+\n@@ -2528,0 +2618,6 @@\n+  {CC\"getObjectsViaKlassOopMaps0\",\n+      CC\"(Ljava\/lang\/Object;)[Ljava\/lang\/Object;\",    (void*)&WB_getObjectsViaKlassOopMaps},\n+  {CC\"getObjectsViaOopIterator0\",\n+          CC\"(Ljava\/lang\/Object;)[Ljava\/lang\/Object;\",(void*)&WB_getObjectsViaOopIterator},\n+  {CC\"getObjectsViaFrameOopIterator\",\n+      CC\"(I)[Ljava\/lang\/Object;\",                     (void*)&WB_getObjectsViaFrameOopIterator},\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":96,"deletions":0,"binary":false,"changes":96,"status":"modified"},{"patch":"@@ -2011,0 +2011,10 @@\n+  if (AMD64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypePassFieldsAsArgs)) {\n+    FLAG_SET_CMDLINE(InlineTypePassFieldsAsArgs, false);\n+    warning(\"InlineTypePassFieldsAsArgs is not supported on this platform\");\n+  }\n+\n+  if (AMD64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypeReturnedAsFields)) {\n+    FLAG_SET_CMDLINE(InlineTypeReturnedAsFields, false);\n+    warning(\"InlineTypeReturnedAsFields is not supported on this platform\");\n+  }\n+\n@@ -2935,0 +2945,18 @@\n+  if (EnableValhalla) {\n+    \/\/ create_property(\"valhalla.enableValhalla\", \"true\", InternalProperty)\n+    const char* prop_name = \"valhalla.enableValhalla\";\n+    const char* prop_value = \"true\";\n+    const size_t prop_len = strlen(prop_name) + strlen(prop_value) + 2;\n+    char* property = AllocateHeap(prop_len, mtArguments);\n+    int ret = jio_snprintf(property, prop_len, \"%s=%s\", prop_name, prop_value);\n+    if (ret < 0 || ret >= (int)prop_len) {\n+      FreeHeap(property);\n+      return JNI_ENOMEM;\n+    }\n+    bool added = add_property(property, UnwriteableProperty, InternalProperty);\n+    FreeHeap(property);\n+    if (!added) {\n+      return JNI_ENOMEM;\n+    }\n+  }\n+\n@@ -3049,0 +3077,5 @@\n+  if (UseBiasedLocking) {\n+    jio_fprintf(defaultStream::error_stream(), \"Valhalla does not support use with UseBiasedLocking\");\n+    return JNI_ERR;\n+  }\n+\n@@ -4068,0 +4101,5 @@\n+  if (!EnableValhalla || (is_interpreter_only() && !is_dumping_archive())) {\n+    \/\/ Disable calling convention optimizations if inline types are not supported\n+    InlineTypePassFieldsAsArgs = false;\n+    InlineTypeReturnedAsFields = false;\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":38,"deletions":0,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -54,1 +54,3 @@\n-  k->set_prototype_header(markWord::biased_locking_prototype());\n+  if (!k->is_inline_klass()) {\n+    k->set_prototype_header(markWord::biased_locking_prototype());\n+  }\n@@ -733,0 +735,1 @@\n+  assert(UseBiasedLocking, \"biased locking not enabled\");\n@@ -754,0 +757,1 @@\n+  assert(UseBiasedLocking, \"biased locking not enabled\");\n@@ -856,0 +860,1 @@\n+  assert(UseBiasedLocking, \"biased locking not enabled\");\n@@ -872,0 +877,1 @@\n+  assert(UseBiasedLocking, \"biased locking not enabled\");\n","filename":"src\/hotspot\/share\/runtime\/biasedLocking.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -46,0 +46,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/flatArrayOop.hpp\"\n@@ -51,0 +53,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -204,2 +207,13 @@\n-  bool save_oop_result = chunk->at(0)->scope()->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n-  Handle return_value;\n+  ScopeDesc* scope = chunk->at(0)->scope();\n+  bool save_oop_result = scope->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);\n+  \/\/ In case of the return of multiple values, we must take care\n+  \/\/ of all oop return values.\n+  GrowableArray<Handle> return_oops;\n+  InlineKlass* vk = NULL;\n+  if (save_oop_result && scope->return_scalarized()) {\n+    vk = InlineKlass::returned_inline_klass(map);\n+    if (vk != NULL) {\n+      vk->save_oop_fields(map, return_oops);\n+      save_oop_result = false;\n+    }\n+  }\n@@ -211,1 +225,1 @@\n-    return_value = Handle(thread, result);\n+    return_oops.push(Handle(thread, result));\n@@ -218,1 +232,1 @@\n-  if (objects != NULL) {\n+  if (objects != NULL || vk != NULL) {\n@@ -223,1 +237,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+      if (vk != NULL) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, CHECK_AND_CLEAR_(true));\n+      }\n+      if (objects != NULL) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, CHECK_AND_CLEAR_(true));\n+        bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, CHECK_AND_CLEAR_(true));\n+      }\n@@ -228,1 +249,8 @@\n-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+      if (vk != NULL) {\n+        realloc_failures = Deoptimization::realloc_inline_type_result(vk, map, return_oops, THREAD);\n+      }\n+      if (objects != NULL) {\n+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);\n+        bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, THREAD);\n+      }\n@@ -231,2 +259,0 @@\n-    bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();\n-    Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal);\n@@ -241,1 +267,1 @@\n-  if (save_oop_result) {\n+  if (save_oop_result || vk != NULL) {\n@@ -243,1 +269,2 @@\n-    deoptee.set_saved_oop_result(&map, return_value());\n+    assert(return_oops.length() == 1, \"no inline type\");\n+    deoptee.set_saved_oop_result(&map, return_oops.pop()());\n@@ -572,1 +599,1 @@\n-  \/\/ If the sender is deoptimized the we must retrieve the address of the handler\n+  \/\/ If the sender is deoptimized we must retrieve the address of the handler\n@@ -1072,0 +1099,4 @@\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* ak = FlatArrayKlass::cast(k);\n+      \/\/ Inline type array must be zeroed because not all memory is reassigned\n+      obj = ak->allocate(sv->field_size(), THREAD);\n@@ -1101,0 +1132,15 @@\n+\/\/ We're deoptimizing at the return of a call, inline type fields are\n+\/\/ in registers. When we go back to the interpreter, it will expect a\n+\/\/ reference to an inline type instance. Allocate and initialize it from\n+\/\/ the register values here.\n+bool Deoptimization::realloc_inline_type_result(InlineKlass* vk, const RegisterMap& map, GrowableArray<Handle>& return_oops, TRAPS) {\n+  oop new_vt = vk->realloc_result(map, return_oops, THREAD);\n+  if (new_vt == NULL) {\n+    CLEAR_PENDING_EXCEPTION;\n+    THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), true);\n+  }\n+  return_oops.clear();\n+  return_oops.push(Handle(THREAD, new_vt));\n+  return false;\n+}\n+\n@@ -1273,0 +1319,1 @@\n+  InstanceKlass* _klass;\n@@ -1277,0 +1324,1 @@\n+    _klass = NULL;\n@@ -1286,1 +1334,1 @@\n-static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal) {\n+static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {\n@@ -1295,0 +1343,8 @@\n+        if (field._type == T_INLINE_TYPE) {\n+          if (fs.is_inlined()) {\n+            \/\/ Resolve klass of flattened inline type field\n+            field._klass = InlineKlass::cast(klass->get_inline_type_field_klass(fs.index()));\n+          } else {\n+            field._type = T_OBJECT;\n+          }\n+        }\n@@ -1302,0 +1358,11 @@\n+    BasicType type = fields->at(i)._type;\n+    int offset = base_offset + fields->at(i)._offset;\n+    \/\/ Check for flattened inline type field before accessing the ScopeValue because it might not have any fields\n+    if (type == T_INLINE_TYPE) {\n+      \/\/ Recursively re-assign flattened inline type fields\n+      InstanceKlass* vk = fields->at(i)._klass;\n+      assert(vk != NULL, \"must be resolved\");\n+      offset -= InlineKlass::cast(vk)->first_field_offset(); \/\/ Adjust offset to omit oop header\n+      svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);\n+      continue; \/\/ Continue because we don't need to increment svIndex\n+    }\n@@ -1305,3 +1372,2 @@\n-    int offset = fields->at(i)._offset;\n-    BasicType type = fields->at(i)._type;\n-      case T_OBJECT: case T_ARRAY:\n+      case T_OBJECT:\n+      case T_ARRAY:\n@@ -1388,0 +1454,14 @@\n+\/\/ restore fields of an eliminated inline type array\n+void Deoptimization::reassign_flat_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, flatArrayOop obj, FlatArrayKlass* vak, bool skip_internal, TRAPS) {\n+  InlineKlass* vk = vak->element_klass();\n+  assert(vk->flatten_array(), \"should only be used for flattened inline type arrays\");\n+  \/\/ Adjust offset to omit oop header\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE) - InlineKlass::cast(vk)->first_field_offset();\n+  \/\/ Initialize all elements of the flattened inline type array\n+  for (int i = 0; i < sv->field_size(); i++) {\n+    ScopeValue* val = sv->field_at(i);\n+    int offset = base_offset + (i << Klass::layout_helper_log2_element_size(vak->layout_helper()));\n+    reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, skip_internal, offset, CHECK);\n+  }\n+}\n+\n@@ -1389,1 +1469,1 @@\n-void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal) {\n+void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal, TRAPS) {\n@@ -1428,1 +1508,4 @@\n-      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal);\n+      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, CHECK);\n+    } else if (k->is_flatArray_klass()) {\n+      FlatArrayKlass* vak = FlatArrayKlass::cast(k);\n+      reassign_flat_array_elements(fr, reg_map, sv, (flatArrayOop) obj(), vak, skip_internal, CHECK);\n@@ -1494,1 +1577,0 @@\n-\n@@ -1498,1 +1580,3 @@\n-    Handle obj = sv->value();\n+    print_object(k, sv->value(), realloc_failures);\n+  }\n+}\n@@ -1500,9 +1584,10 @@\n-    tty->print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(sv->value()()));\n-    k->print_value();\n-    assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n-    if (obj.is_null()) {\n-      tty->print(\" allocation failed\");\n-    } else {\n-      tty->print(\" allocated (%d bytes)\", obj->size() * HeapWordSize);\n-    }\n-    tty->cr();\n+void Deoptimization::print_object(Klass* k, Handle obj, bool realloc_failures) {\n+  tty->print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(obj()));\n+  k->print_value();\n+  assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n+  if (obj.is_null()) {\n+    tty->print(\" allocation failed\");\n+  } else {\n+    tty->print(\" allocated (%d bytes)\", obj->size() * HeapWordSize);\n+  }\n+  tty->cr();\n@@ -1510,3 +1595,2 @@\n-    if (Verbose && !obj.is_null()) {\n-      k->oop_print_on(obj(), tty);\n-    }\n+  if (Verbose && !obj.is_null()) {\n+    k->oop_print_on(obj(), tty);\n@@ -1724,1 +1808,1 @@\n-  \/\/ Deoptimize only if the frame comes from compile code.\n+  \/\/ Deoptimize only if the frame comes from compiled code.\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":116,"deletions":32,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -185,0 +185,1 @@\n+  static bool realloc_inline_type_result(InlineKlass* vk, const RegisterMap& map, GrowableArray<Handle>& return_oops, TRAPS);\n@@ -187,1 +188,2 @@\n-  static void reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal);\n+  static void reassign_flat_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, flatArrayOop obj, FlatArrayKlass* vak, bool skip_internal, TRAPS);\n+  static void reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal, TRAPS);\n@@ -191,1 +193,4 @@\n-  NOT_PRODUCT(static void print_objects(GrowableArray<ScopeValue*>* objects, bool realloc_failures);)\n+#ifndef PRODUCT\n+  static void print_objects(GrowableArray<ScopeValue*>* objects, bool realloc_failures);\n+  static void print_object(Klass* k, Handle obj, bool realloc_failures);\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.hpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -63,1 +64,1 @@\n-  return is_final() && (is_static() || ik->is_hidden() || ik->is_record());\n+  return is_final() && (is_static() || ik->is_hidden() || ik->is_record() || ik->is_inline_klass());\n@@ -156,1 +157,3 @@\n-  print_on(st);\n+  if (ft != T_INLINE_TYPE) {\n+    print_on(st);\n+  }\n@@ -195,7 +198,10 @@\n-    case T_ARRAY:\n-      st->print(\" \");\n-      NOT_LP64(as_int = obj->int_field(offset()));\n-      if (obj->obj_field(offset()) != NULL) {\n-        obj->obj_field(offset())->print_value_on(st);\n-      } else {\n-        st->print(\"NULL\");\n+    case T_INLINE_TYPE:\n+      if (is_inlined()) {\n+        \/\/ Print fields of inlined fields (recursively)\n+        InlineKlass* vk = InlineKlass::cast(field_holder()->get_inline_type_field_klass(index()));\n+        int field_offset = offset() - vk->first_field_offset();\n+        obj = cast_to_oop(cast_from_oop<address>(obj) + field_offset);\n+        st->print_cr(\"Inline type field inlined '%s':\", vk->name()->as_C_string());\n+        FieldPrinter print_field(st, obj);\n+        vk->do_nonstatic_fields(&print_field);\n+        return; \/\/ Do not print underlying representation\n@@ -203,1 +209,2 @@\n-      break;\n+      \/\/ inline type field not inlined, fall through\n+    case T_ARRAY:\n@@ -230,0 +237,1 @@\n+  st->cr();\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.cpp","additions":18,"deletions":10,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -56,0 +57,3 @@\n+#ifdef COMPILER1\n+#include \"c1\/c1_Runtime1.hpp\"\n+#endif\n@@ -290,0 +294,19 @@\n+\n+#ifdef COMPILER1\n+  if (cm->is_compiled_by_c1() && cm->method()->has_scalarized_args() &&\n+      pc() < cm->verified_inline_entry_point()) {\n+    \/\/ The VEP and VIEP(RO) of C1-compiled methods call into the runtime to buffer scalarized value\n+    \/\/ type args. We can't deoptimize at that point because the buffers have not yet been initialized.\n+    \/\/ Also, if the method is synchronized, we first need to acquire the lock.\n+    \/\/ Don't patch the return pc to delay deoptimization until we enter the method body (the check\n+    \/\/ addedin LIRGenerator::do_Base will detect the pending deoptimization by checking the original_pc).\n+#ifdef ASSERT\n+    NativeCall* call = nativeCall_before(this->pc());\n+    address dest = call->destination();\n+    assert(dest == Runtime1::entry_for(Runtime1::buffer_inline_args_no_receiver_id) ||\n+           dest == Runtime1::entry_for(Runtime1::buffer_inline_args_id), \"unexpected safepoint in entry point\");\n+#endif\n+    return;\n+  }\n+#endif\n+\n@@ -687,1 +710,1 @@\n-                          OopClosure* f) {\n+                          OopClosure* f, BufferedValueClosure* bvt_f) {\n@@ -699,1 +722,3 @@\n-      _f->do_oop(addr);\n+      if (_f != NULL) {\n+        _f->do_oop(addr);\n+      }\n@@ -711,1 +736,3 @@\n-        _f->do_oop(addr);\n+        if (_f != NULL) {\n+          _f->do_oop(addr);\n+        }\n@@ -886,1 +913,1 @@\n-  InterpreterFrameClosure blk(this, max_locals, m->max_stack(), f);\n+  InterpreterFrameClosure blk(this, max_locals, m->max_stack(), f, NULL);\n@@ -898,0 +925,17 @@\n+void frame::buffered_values_interpreted_do(BufferedValueClosure* f) {\n+  assert(is_interpreted_frame(), \"Not an interpreted frame\");\n+  Thread *thread = Thread::current();\n+  methodHandle m (thread, interpreter_frame_method());\n+  jint      bci = interpreter_frame_bci();\n+\n+  assert(m->is_method(), \"checking frame value\");\n+  assert(!m->is_native() && bci >= 0 && bci < m->code_size(),\n+         \"invalid bci value\");\n+\n+  InterpreterFrameClosure blk(this, m->max_locals(), m->max_stack(), NULL, f);\n+\n+  \/\/ process locals & expression stack\n+  InterpreterOopMap mask;\n+  m->mask_for(bci, &mask);\n+  mask.iterate_oop(&blk);\n+}\n@@ -945,0 +989,1 @@\n+    assert(_offset < _arg_size, \"out of bounds\");\n@@ -962,5 +1007,1 @@\n-    _arg_size  = ArgumentSizeComputer(signature).size() + (has_receiver ? 1 : 0) + (has_appendix ? 1 : 0);\n-\n-    int arg_size;\n-    _regs = SharedRuntime::find_callee_arguments(signature, has_receiver, has_appendix, &arg_size);\n-    assert(arg_size == _arg_size, \"wrong arg size\");\n+    _regs = SharedRuntime::find_callee_arguments(signature, has_receiver, has_appendix, &_arg_size);\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":50,"deletions":9,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -374,0 +374,1 @@\n+  void buffered_values_interpreted_do(BufferedValueClosure* f);\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -796,0 +796,18 @@\n+  notproduct(bool, PrintInlineLayout, false,                                \\\n+          \"Print field layout for each inline type\")                        \\\n+                                                                            \\\n+  notproduct(bool, PrintFlatArrayLayout, false,                             \\\n+          \"Print array layout for each inline type array\")                  \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxSize, -1,                                \\\n+          \"Max size for flattening inline array elements, <0 no limit\")     \\\n+                                                                            \\\n+  product(intx, InlineFieldMaxFlatSize, 128,                                \\\n+          \"Max size for flattening inline type fields, <0 no limit\")        \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxOops, 4,                                 \\\n+          \"Max nof embedded object references in an inline type to flatten, <0 no limit\")  \\\n+                                                                            \\\n+  product(bool, InlineArrayAtomicAccess, false,                             \\\n+          \"Atomic inline array accesses by-default, for all inline arrays\") \\\n+                                                                            \\\n@@ -811,2 +829,2 @@\n-  product(bool, UseBiasedLocking, false,                                    \\\n-          \"(Deprecated) Enable biased locking in JVM\")                      \\\n+  product(bool, UseBiasedLocking, false,                                     \\\n+          \"(Deprecated) Enable biased locking in JVM (completely disabled by Valhalla)\") \\\n@@ -2073,0 +2091,23 @@\n+  product(bool, EnableValhalla, true,                                       \\\n+          \"Enable experimental Valhalla features\")                          \\\n+                                                                            \\\n+  product_pd(bool, InlineTypePassFieldsAsArgs,                              \\\n+          \"Pass each inline type field as an argument at calls\")            \\\n+                                                                            \\\n+  product_pd(bool, InlineTypeReturnedAsFields,                              \\\n+          \"Return fields instead of an inline type reference\")              \\\n+                                                                            \\\n+  develop(bool, StressInlineTypeReturnedAsFields, false,                    \\\n+          \"Stress return of fields instead of an inline type reference\")    \\\n+                                                                            \\\n+  develop(bool, ScalarizeInlineTypes, true,                                 \\\n+          \"Scalarize inline types in compiled code\")                        \\\n+                                                                            \\\n+  product(bool, UseArrayMarkWordCheck, NOT_LP64(false) LP64_ONLY(true),     \\\n+          \"Use bits in the mark word to check for flat\/null-free arrays\")   \\\n+                                                                            \\\n+  product(ccstrlist, ForceNonTearable, \"\", DIAGNOSTIC,                      \\\n+          \"List of inline classes which are forced to be atomic \"           \\\n+          \"(whitespace and commas separate names, \"                         \\\n+          \"and leading and trailing stars '*' are wildcards)\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":43,"deletions":2,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+class InlineKlass;\n@@ -127,0 +128,1 @@\n+DEF_HANDLE(flatArray        , is_flatArray_noinline        )\n","filename":"src\/hotspot\/share\/runtime\/handles.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -121,0 +121,1 @@\n+  VMRegImpl::set_regName();       \/\/ need this before generate_stubs (for printing oop maps).\n@@ -132,1 +133,0 @@\n-  VMRegImpl::set_regName(); \/\/ need this before generate_stubs (for printing oop maps).\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -163,4 +164,4 @@\n-    case T_BOOLEAN: \/\/ fall through\n-    case T_CHAR   : \/\/ fall through\n-    case T_SHORT  : \/\/ fall through\n-    case T_INT    : \/\/ fall through\n+    case T_BOOLEAN  : \/\/ fall through\n+    case T_CHAR     : \/\/ fall through\n+    case T_SHORT    : \/\/ fall through\n+    case T_INT      : \/\/ fall through\n@@ -168,2 +169,3 @@\n-    case T_OBJECT : \/\/ fall through\n-    case T_ARRAY  : \/\/ fall through\n+    case T_OBJECT   : \/\/ fall through\n+    case T_ARRAY    : \/\/ fall through\n+    case T_INLINE_TYPE: \/\/ fall through\n@@ -171,5 +173,5 @@\n-    case T_BYTE   : \/\/ fall through\n-    case T_VOID   : return T_INT;\n-    case T_LONG   : return T_LONG;\n-    case T_FLOAT  : return T_FLOAT;\n-    case T_DOUBLE : return T_DOUBLE;\n+    case T_BYTE     : \/\/ fall through\n+    case T_VOID     : return T_INT;\n+    case T_LONG     : return T_LONG;\n+    case T_FLOAT    : return T_FLOAT;\n+    case T_DOUBLE   : return T_DOUBLE;\n@@ -177,2 +179,3 @@\n-    case T_ARRAY  : \/\/ fall through\n-    case T_OBJECT:  return T_OBJECT;\n+    case T_ARRAY    : \/\/ fall through\n+    case T_OBJECT   : return T_OBJECT;\n+    case T_INLINE_TYPE: return T_INLINE_TYPE;\n@@ -306,0 +309,13 @@\n+\n+  \/\/ Special case for factory methods\n+  if (!constructor_signature->is_void_method_signature()) {\n+    assert(klass->is_inline_klass(), \"inline classes must use factory methods\");\n+    JavaValue factory_result(T_OBJECT);\n+    JavaCalls::call_static(&factory_result, klass,\n+                           vmSymbols::object_initializer_name(),\n+                           constructor_signature, args, CHECK_NH);\n+    return Handle(THREAD, factory_result.get_oop());\n+  }\n+\n+  \/\/ main branch of code creates a non-inline object:\n+  assert(!klass->is_inline_klass(), \"classic constructors are only for non-inline classes\");\n@@ -408,0 +424,12 @@\n+  jobject value_buffer = NULL;\n+  if (InlineTypeReturnedAsFields && result->get_type() == T_INLINE_TYPE) {\n+    \/\/ Pre allocate a buffered inline type in case the result is returned\n+    \/\/ flattened by compiled code\n+    InlineKlass* vk = method->returned_inline_type(thread);\n+    if (vk->can_be_returned_as_fields()) {\n+      oop instance = vk->allocate_instance(CHECK);\n+      value_buffer = JNIHandles::make_local(thread, instance);\n+      result->set_jobject(value_buffer);\n+    }\n+  }\n+\n@@ -458,0 +486,1 @@\n+    JNIHandles::destroy_local(value_buffer);\n@@ -594,0 +623,1 @@\n+    case T_INLINE_TYPE:\n@@ -606,1 +636,1 @@\n-  if (is_reference_type(return_type)) return_type = T_OBJECT;\n+  if (return_type == T_ARRAY) return_type = T_OBJECT;\n","filename":"src\/hotspot\/share\/runtime\/javaCalls.cpp","additions":44,"deletions":14,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"classfile\/vmSymbols.hpp\"\n@@ -35,0 +36,1 @@\n+#include \"runtime\/javaCalls.hpp\"\n@@ -308,0 +310,37 @@\n+bool JNIHandles::is_same_object(jobject handle1, jobject handle2) {\n+  oop obj1 = resolve_no_keepalive(handle1);\n+  oop obj2 = resolve_no_keepalive(handle2);\n+\n+  bool ret = obj1 == obj2;\n+\n+  if (EnableValhalla) {\n+    if (!ret && obj1 != NULL && obj2 != NULL && obj1->klass() == obj2->klass() && obj1->klass()->is_inline_klass()) {\n+      \/\/ The two references are different, they are not null and they are both inline types,\n+      \/\/ a full substitutability test is required, calling ValueBootstrapMethods.isSubstitutable()\n+      \/\/ (similarly to InterpreterRuntime::is_substitutable)\n+      Thread* THREAD = Thread::current();\n+      Handle ha(THREAD, obj1);\n+      Handle hb(THREAD, obj2);\n+      JavaValue result(T_BOOLEAN);\n+      JavaCallArguments args;\n+      args.push_oop(ha);\n+      args.push_oop(hb);\n+      methodHandle method(THREAD, Universe::is_substitutable_method());\n+      JavaCalls::call(&result, method, &args, THREAD);\n+      if (HAS_PENDING_EXCEPTION) {\n+        \/\/ Something really bad happened because isSubstitutable() should not throw exceptions\n+        \/\/ If it is an error, just let it propagate\n+        \/\/ If it is an exception, wrap it into an InternalError\n+        if (!PENDING_EXCEPTION->is_a(vmClasses::Error_klass())) {\n+          Handle e(THREAD, PENDING_EXCEPTION);\n+          CLEAR_PENDING_EXCEPTION;\n+          THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), \"Internal error in substitutability test\", e, false);\n+        }\n+      }\n+      ret = result.get_jboolean();\n+    }\n+  }\n+\n+  return ret;\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/jniHandles.cpp","additions":39,"deletions":0,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -86,1 +86,1 @@\n-                          \/\/ 'B','Z','J','I','S','C','D','F','V','L','['\n+                          \/\/ 'B','Z','J','I','S','C','D','F','V','L','Q','['\n","filename":"src\/hotspot\/share\/runtime\/perfMemory.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -55,0 +56,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -350,1 +352,5 @@\n-    return oopFactory::new_objArray(k, length, THREAD);\n+    if (k->is_inline_klass()) {\n+      return oopFactory::new_flatArray(k, length, THREAD);\n+    } else {\n+      return oopFactory::new_objArray(k, length, THREAD);\n+    }\n@@ -792,3 +798,0 @@\n-  if (log_is_enabled(Debug, class, resolve)) {\n-    trace_class_resolution(nt);\n-  }\n@@ -801,2 +804,1 @@\n-  assert(!method()->is_initializer() ||\n-         (for_constant_pool_access && method()->is_static()),\n+  assert(!method()->name()->starts_with('<') || for_constant_pool_access,\n@@ -851,1 +853,3 @@\n-  assert(method()->is_initializer(), \"should call new_method instead\");\n+  assert(method()->is_object_constructor() ||\n+         method()->is_static_init_factory(),\n+         \"should call new_method instead\");\n@@ -904,1 +908,5 @@\n-  java_lang_reflect_Field::set_modifiers(rh(), fd->access_flags().as_int() & JVM_RECOGNIZED_FIELD_MODIFIERS);\n+  int modifiers = fd->access_flags().as_int() & JVM_RECOGNIZED_FIELD_MODIFIERS;\n+  if (fd->is_inlined()) {\n+    modifiers |= JVM_ACC_FIELD_INLINED;\n+  }\n+  java_lang_reflect_Field::set_modifiers(rh(), modifiers);\n@@ -1179,0 +1187,2 @@\n+  } else if (java_lang_Class::as_Klass(return_type_mirror)->is_inline_klass()) {\n+    rtype = T_INLINE_TYPE;\n@@ -1213,0 +1223,16 @@\n+\n+  \/\/ Special case for factory methods\n+  if (!method->signature()->is_void_method_signature()) {\n+    assert(klass->is_inline_klass(), \"inline classes must use factory methods\");\n+    Handle no_receiver; \/\/ null instead of receiver\n+    BasicType rtype;\n+    if (klass->is_hidden()) {\n+      rtype = T_OBJECT;\n+    } else {\n+      rtype = T_INLINE_TYPE;\n+    }\n+    return invoke(klass, method, no_receiver, override, ptypes, rtype, args, false, CHECK_NULL);\n+  }\n+\n+  \/\/ main branch of code creates a non-inline object:\n+  assert(!klass->is_inline_klass(), \"classic constructors are only for non-inline classes\");\n","filename":"src\/hotspot\/share\/runtime\/reflection.cpp","additions":34,"deletions":8,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -929,0 +930,1 @@\n+    ResourceMark rm;\n@@ -930,2 +932,25 @@\n-    bool return_oop = nm->method()->is_returning_oop();\n-    Handle return_value;\n+    Method* method = nm->method();\n+    bool return_oop = method->is_returning_oop();\n+\n+    GrowableArray<Handle> return_values;\n+    InlineKlass* vk = NULL;\n+\n+    if (return_oop && InlineTypeReturnedAsFields) {\n+      SignatureStream ss(method->signature());\n+      while (!ss.at_return_type()) {\n+        ss.next();\n+      }\n+      if (ss.type() == T_INLINE_TYPE) {\n+        \/\/ Check if inline type is returned as fields\n+        vk = InlineKlass::returned_inline_klass(map);\n+        if (vk != NULL) {\n+          \/\/ We're at a safepoint at the return of a method that returns\n+          \/\/ multiple values. We must make sure we preserve the oop values\n+          \/\/ across the safepoint.\n+          assert(vk == method->returned_inline_type(thread()), \"bad inline klass\");\n+          vk->save_oop_fields(map, return_values);\n+          return_oop = false;\n+        }\n+      }\n+    }\n+\n@@ -938,1 +963,1 @@\n-      return_value = Handle(self, result);\n+      return_values.push(Handle(self, result));\n@@ -952,1 +977,4 @@\n-      caller_fr.set_saved_oop_result(&map, return_value());\n+      assert(return_values.length() == 1, \"only one return value\");\n+      caller_fr.set_saved_oop_result(&map, return_values.pop()());\n+    } else if (vk != NULL) {\n+      vk->restore_oop_results(map, return_values);\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":32,"deletions":4,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+#include \"memory\/oopFactory.hpp\"\n@@ -50,0 +51,2 @@\n+#include \"oops\/access.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -54,0 +57,1 @@\n+#include \"oops\/objArrayOop.inline.hpp\"\n@@ -55,0 +59,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -91,1 +96,0 @@\n-address             SharedRuntime::_resolve_static_call_entry;\n@@ -111,1 +115,0 @@\n-  _resolve_static_call_entry           = _resolve_static_call_blob->entry_point();\n@@ -1089,0 +1092,15 @@\n+  \/\/ Substitutability test implementation piggy backs on static call resolution\n+  Bytecodes::Code code = caller->java_code_at(bci);\n+  if (code == Bytecodes::_if_acmpeq || code == Bytecodes::_if_acmpne) {\n+    bc = Bytecodes::_invokestatic;\n+    methodHandle attached_method(THREAD, extract_attached_method(vfst));\n+    assert(attached_method.not_null(), \"must have attached method\");\n+    vmClasses::ValueBootstrapMethods_klass()->initialize(CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, false, CHECK_NH);\n+#ifdef ASSERT\n+    Method* is_subst = vmClasses::ValueBootstrapMethods_klass()->find_method(vmSymbols::isSubstitutable_name(), vmSymbols::object_object_boolean_signature());\n+    assert(callinfo.selected_method() == is_subst, \"must be isSubstitutable method\");\n+#endif\n+    return receiver;\n+  }\n+\n@@ -1124,0 +1142,6 @@\n+    } else {\n+      assert(attached_method->has_scalarized_args(), \"invalid use of attached method\");\n+      if (!attached_method->method_holder()->is_inline_klass()) {\n+        \/\/ Ignore the attached method in this case to not confuse below code\n+        attached_method = methodHandle(current, NULL);\n+      }\n@@ -1132,0 +1156,1 @@\n+  bool check_null_and_abstract = true;\n@@ -1141,0 +1166,5 @@\n+    bool caller_is_c1 = false;\n+\n+    if (callerFrame.is_compiled_frame() && !callerFrame.is_deoptimized_frame()) {\n+      caller_is_c1 = callerFrame.cb()->is_compiled_by_c1();\n+    }\n@@ -1142,2 +1172,3 @@\n-    if (attached_method.is_null()) {\n-      Method* callee = bytecode.static_target(CHECK_NH);\n+    Method* callee = attached_method();\n+    if (callee == NULL) {\n+      callee = bytecode.static_target(CHECK_NH);\n@@ -1148,6 +1179,15 @@\n-\n-    \/\/ Retrieve from a compiled argument list\n-    receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n-\n-    if (receiver.is_null()) {\n-      THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+    if (!caller_is_c1 && callee->has_scalarized_args() && callee->method_holder()->is_inline_klass() &&\n+        InlineKlass::cast(callee->method_holder())->can_be_passed_as_fields()) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      \/\/ Resolve the call without receiver null checking.\n+      assert(attached_method.not_null() && !attached_method->is_abstract(), \"must have non-abstract attached method\");\n+      if (bc == Bytecodes::_invokeinterface) {\n+        bc = Bytecodes::_invokevirtual; \/\/ C2 optimistically replaces interface calls by virtual calls\n+      }\n+      check_null_and_abstract = false;\n+    } else {\n+      \/\/ Retrieve from a compiled argument list\n+      receiver = Handle(current, callerFrame.retrieve_receiver(&reg_map2));\n+      if (receiver.is_null()) {\n+        THROW_(vmSymbols::java_lang_NullPointerException(), nullHandle);\n+      }\n@@ -1160,1 +1200,1 @@\n-    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, CHECK_NH);\n+    LinkResolver::resolve_invoke(callinfo, receiver, attached_method, bc, check_null_and_abstract, CHECK_NH);\n@@ -1169,1 +1209,1 @@\n-  if (has_receiver) {\n+  if (has_receiver && check_null_and_abstract) {\n@@ -1227,1 +1267,1 @@\n-methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, TRAPS) {\n+methodHandle SharedRuntime::resolve_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS) {\n@@ -1229,1 +1269,1 @@\n-  callee_method = resolve_sub_helper(is_virtual, is_optimized, THREAD);\n+  callee_method = resolve_sub_helper(is_virtual, is_optimized, caller_is_c1, THREAD);\n@@ -1246,1 +1286,1 @@\n-      callee_method = resolve_sub_helper(is_virtual, is_optimized, THREAD);\n+      callee_method = resolve_sub_helper(is_virtual, is_optimized, caller_is_c1, THREAD);\n@@ -1277,0 +1317,1 @@\n+  bool caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1279,1 +1320,9 @@\n-    assert(receiver.not_null() || invoke_code == Bytecodes::_invokehandle, \"sanity check\");\n+    Klass* receiver_klass = NULL;\n+    if (!caller_is_c1 && callee_method->has_scalarized_args() && callee_method->method_holder()->is_inline_klass() &&\n+        InlineKlass::cast(callee_method->method_holder())->can_be_passed_as_fields()) {\n+      \/\/ If the receiver is an inline type that is passed as fields, no oop is available\n+      receiver_klass = callee_method->method_holder();\n+    } else {\n+      assert(receiver.not_null() || invoke_code == Bytecodes::_invokehandle, \"sanity check\");\n+      receiver_klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver->klass();\n+    }\n@@ -1281,3 +1330,2 @@\n-    Klass* klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver->klass();\n-    CompiledIC::compute_monomorphic_entry(callee_method, klass,\n-                     is_optimized, static_bound, is_nmethod, virtual_call_info,\n+    CompiledIC::compute_monomorphic_entry(callee_method, receiver_klass,\n+                     is_optimized, static_bound, is_nmethod, caller_is_c1, virtual_call_info,\n@@ -1287,1 +1335,1 @@\n-    CompiledStaticCall::compute_entry(callee_method, is_nmethod, static_call_info);\n+    CompiledStaticCall::compute_entry(callee_method, caller_nm, static_call_info);\n@@ -1337,1 +1385,1 @@\n-methodHandle SharedRuntime::resolve_sub_helper(bool is_virtual, bool is_optimized, TRAPS) {\n+methodHandle SharedRuntime::resolve_sub_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS) {\n@@ -1346,0 +1394,1 @@\n+  *caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1446,0 +1495,2 @@\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1447,1 +1498,1 @@\n-    callee_method = SharedRuntime::handle_ic_miss_helper(CHECK_NULL);\n+    callee_method = SharedRuntime::handle_ic_miss_helper(is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1452,2 +1503,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  return entry_for_handle_wrong_method(callee_method, false, is_optimized, caller_is_c1);\n@@ -1496,0 +1546,3 @@\n+  bool is_static_call = false;\n+  bool is_optimized = false;\n+  bool caller_is_c1 = false;\n@@ -1498,1 +1551,1 @@\n-    callee_method = SharedRuntime::reresolve_call_site(CHECK_NULL);\n+    callee_method = SharedRuntime::reresolve_call_site(is_static_call, is_optimized, caller_is_c1, CHECK_NULL);\n@@ -1502,2 +1555,1 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  return entry_for_handle_wrong_method(callee_method, is_static_call, is_optimized, caller_is_c1);\n@@ -1541,0 +1593,1 @@\n+  bool caller_is_c1;\n@@ -1542,1 +1595,1 @@\n-    callee_method = SharedRuntime::resolve_helper(false, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(false, false, &caller_is_c1, CHECK_NULL);\n@@ -1546,2 +1599,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1554,0 +1609,1 @@\n+  bool caller_is_c1;\n@@ -1555,1 +1611,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, false, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, false, &caller_is_c1, CHECK_NULL);\n@@ -1559,2 +1615,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_inline_ro_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1568,0 +1626,1 @@\n+  bool caller_is_c1;\n@@ -1569,1 +1628,1 @@\n-    callee_method = SharedRuntime::resolve_helper(true, true, CHECK_NULL);\n+    callee_method = SharedRuntime::resolve_helper(true, true, &caller_is_c1, CHECK_NULL);\n@@ -1573,2 +1632,4 @@\n-  assert(callee_method->verified_code_entry() != NULL, \" Jump to zero!\");\n-  return callee_method->verified_code_entry();\n+  address entry = caller_is_c1 ?\n+    callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();\n+  assert(entry != NULL, \"Jump to zero!\");\n+  return entry;\n@@ -1585,1 +1646,1 @@\n-                                                   bool& needs_ic_stub_refill, TRAPS) {\n+                                                   bool& needs_ic_stub_refill, bool& is_optimized, bool caller_is_c1, TRAPS) {\n@@ -1596,0 +1657,1 @@\n+    is_optimized = true;\n@@ -1633,0 +1695,1 @@\n+                                            caller_nm->is_compiled_by_c1(),\n@@ -1641,1 +1704,1 @@\n-    bool successful = inline_cache->set_to_megamorphic(&call_info, bc, needs_ic_stub_refill, CHECK_false);\n+    bool successful = inline_cache->set_to_megamorphic(&call_info, bc, needs_ic_stub_refill, caller_is_c1, CHECK_false);\n@@ -1657,1 +1720,1 @@\n-methodHandle SharedRuntime::handle_ic_miss_helper(TRAPS) {\n+methodHandle SharedRuntime::handle_ic_miss_helper(bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1677,1 +1740,3 @@\n-    methodHandle callee_method = SharedRuntime::reresolve_call_site(CHECK_(methodHandle()));\n+    bool is_static_call = false;\n+    methodHandle callee_method = SharedRuntime::reresolve_call_site(is_static_call, is_optimized, caller_is_c1, CHECK_(methodHandle()));\n+    assert(!is_static_call, \"IC miss at static call?\");\n@@ -1727,0 +1792,1 @@\n+  caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1732,1 +1798,1 @@\n-                                                     bc, call_info, needs_ic_stub_refill, CHECK_(methodHandle()));\n+                                                     bc, call_info, needs_ic_stub_refill, is_optimized, caller_is_c1, CHECK_(methodHandle()));\n@@ -1764,1 +1830,1 @@\n-methodHandle SharedRuntime::reresolve_call_site(TRAPS) {\n+methodHandle SharedRuntime::reresolve_call_site(bool& is_static_call, bool& is_optimized, bool& caller_is_c1, TRAPS) {\n@@ -1781,1 +1847,1 @@\n-    bool is_static_call = false;\n+    caller_is_c1 = caller_nm->is_compiled_by_c1();\n@@ -1826,0 +1892,1 @@\n+          is_optimized = (iter.type() == relocInfo::opt_virtual_call_type);\n@@ -1851,1 +1918,0 @@\n-\n@@ -1945,2 +2011,0 @@\n-  address entry_point = moop->from_compiled_entry_no_trampoline();\n-\n@@ -1958,1 +2022,5 @@\n-  if (cb == NULL || !cb->is_compiled() || entry_point == moop->get_c2i_entry()) {\n+  if (cb == NULL || !cb->is_compiled()) {\n+    return;\n+  }\n+  address entry_point = moop->from_compiled_entry_no_trampoline(cb->is_compiled_by_c1());\n+  if (entry_point == moop->get_c2i_entry()) {\n@@ -2339,1 +2407,1 @@\n-  static int adapter_encoding(BasicType in) {\n+  static BasicType adapter_encoding(BasicType in) {\n@@ -2345,1 +2413,1 @@\n-        \/\/ There are all promoted to T_INT in the calling convention\n+        \/\/ They are all promoted to T_INT in the calling convention\n@@ -2372,1 +2440,1 @@\n-  AdapterFingerPrint(int total_args_passed, BasicType* sig_bt) {\n+  AdapterFingerPrint(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2375,0 +2443,1 @@\n+    int total_args_passed = (sig != NULL) ? sig->length() : 0;\n@@ -2392,0 +2461,2 @@\n+    BasicType prev_bt = T_ILLEGAL;\n+    int vt_count = 0;\n@@ -2395,5 +2466,26 @@\n-        int bt = ((sig_index < total_args_passed)\n-                  ? adapter_encoding(sig_bt[sig_index++])\n-                  : 0);\n-        assert((bt & _basic_type_mask) == bt, \"must fit in 4 bits\");\n-        value = (value << _basic_type_bits) | bt;\n+        BasicType bt = T_ILLEGAL;\n+        if (sig_index < total_args_passed) {\n+          bt = sig->at(sig_index++)._bt;\n+          if (bt == T_INLINE_TYPE) {\n+            \/\/ Found start of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected start of inline type\");\n+            if (sig_index == 1 && has_ro_adapter) {\n+              \/\/ With a ro_adapter, replace receiver inline type delimiter by T_VOID to prevent matching\n+              \/\/ with other adapters that have the same inline type as first argument and no receiver.\n+              bt = T_VOID;\n+            }\n+            vt_count++;\n+          } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {\n+            \/\/ Found end of inline type in signature\n+            assert(InlineTypePassFieldsAsArgs, \"unexpected end of inline type\");\n+            vt_count--;\n+            assert(vt_count >= 0, \"invalid vt_count\");\n+          } else if (vt_count == 0) {\n+            \/\/ Widen fields that are not part of a scalarized inline type argument\n+            bt = adapter_encoding(bt);\n+          }\n+          prev_bt = bt;\n+        }\n+        int bt_val = (bt == T_ILLEGAL) ? 0 : bt;\n+        assert((bt_val & _basic_type_mask) == bt_val, \"must fit in 4 bits\");\n+        value = (value << _basic_type_bits) | bt_val;\n@@ -2403,0 +2495,1 @@\n+    assert(vt_count == 0, \"invalid vt_count\");\n@@ -2488,1 +2581,3 @@\n-  AdapterHandlerEntry* new_entry(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry, address c2i_unverified_entry, address c2i_no_clinit_check_entry) {\n+  AdapterHandlerEntry* new_entry(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry,\n+                                 address c2i_inline_entry, address c2i_inline_ro_entry,\n+                                 address c2i_unverified_entry, address c2i_unverified_inline_entry, address c2i_no_clinit_check_entry) {\n@@ -2490,1 +2585,2 @@\n-    entry->init(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+    entry->init(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry,\n+                c2i_unverified_entry, c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n@@ -2506,1 +2602,1 @@\n-  AdapterHandlerEntry* lookup(int total_args_passed, BasicType* sig_bt) {\n+  AdapterHandlerEntry* lookup(const GrowableArray<SigEntry>* sig, bool has_ro_adapter = false) {\n@@ -2508,1 +2604,1 @@\n-    AdapterFingerPrint fp(total_args_passed, sig_bt);\n+    AdapterFingerPrint fp(sig, has_ro_adapter);\n@@ -2604,1 +2700,1 @@\n-const int AdapterHandlerLibrary_size = 16*K;\n+const int AdapterHandlerLibrary_size = 32*K;\n@@ -2628,1 +2724,1 @@\n-  _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(0, NULL),\n+  _abstract_method_handler = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),\n@@ -2630,0 +2726,1 @@\n+                                                              wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n@@ -2636,0 +2733,2 @@\n+                                                      address c2i_inline_entry,\n+                                                      address c2i_inline_ro_entry,\n@@ -2637,0 +2736,1 @@\n+                                                      address c2i_unverified_inline_entry,\n@@ -2638,1 +2738,142 @@\n-  return _adapters->new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+  return _adapters->new_entry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry,\n+                              c2i_unverified_inline_entry, c2i_no_clinit_check_entry);\n+}\n+\n+CompiledEntrySignature::CompiledEntrySignature(Method* method) :\n+  _method(method), _num_inline_args(0), _has_inline_recv(false),\n+  _sig_cc(NULL), _sig_cc_ro(NULL), _regs(NULL), _regs_cc(NULL), _regs_cc_ro(NULL),\n+  _args_on_stack(0), _args_on_stack_cc(0), _args_on_stack_cc_ro(0),\n+  _c1_needs_stack_repair(false), _c2_needs_stack_repair(false), _has_scalarized_args(false) {\n+  _sig = new GrowableArray<SigEntry>(method->size_of_parameters());\n+\n+}\n+\n+int CompiledEntrySignature::compute_scalarized_cc(GrowableArray<SigEntry>*& sig_cc, VMRegPair*& regs_cc, bool scalar_receiver) {\n+  InstanceKlass* holder = _method->method_holder();\n+  sig_cc = new GrowableArray<SigEntry>(_method->size_of_parameters());\n+  if (!_method->is_static()) {\n+    if (holder->is_inline_klass() && scalar_receiver && InlineKlass::cast(holder)->can_be_passed_as_fields()) {\n+      sig_cc->appendAll(InlineKlass::cast(holder)->extended_sig());\n+    } else {\n+      SigEntry::add_entry(sig_cc, T_OBJECT, holder->name());\n+    }\n+  }\n+  for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {\n+    if (ss.type() == T_INLINE_TYPE) {\n+      InlineKlass* vk = ss.as_inline_klass(holder);\n+      if (vk->can_be_passed_as_fields()) {\n+        sig_cc->appendAll(vk->extended_sig());\n+      } else {\n+        SigEntry::add_entry(sig_cc, T_OBJECT, ss.as_symbol());\n+      }\n+    } else {\n+      SigEntry::add_entry(sig_cc, ss.type(), ss.as_symbol());\n+    }\n+  }\n+  regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, sig_cc->length() + 2);\n+  return SharedRuntime::java_calling_convention(sig_cc, regs_cc);\n+}\n+\n+\/\/ See if we can save space by sharing the same entry for VIEP and VIEP(RO),\n+\/\/ or the same entry for VEP and VIEP(RO).\n+CodeOffsets::Entries CompiledEntrySignature::c1_inline_ro_entry_type() const {\n+  if (!has_scalarized_args()) {\n+    \/\/ VEP\/VIEP\/VIEP(RO) all share the same entry. There's no packing.\n+    return CodeOffsets::Verified_Entry;\n+  }\n+  if (_method->is_static()) {\n+    \/\/ Static methods don't need VIEP(RO)\n+    return CodeOffsets::Verified_Entry;\n+  }\n+\n+  if (has_inline_recv()) {\n+    if (num_inline_args() == 1) {\n+      \/\/ Share same entry for VIEP and VIEP(RO).\n+      \/\/ This is quite common: we have an instance method in an InlineKlass that has\n+      \/\/ no inline type args other than <this>.\n+      return CodeOffsets::Verified_Inline_Entry;\n+    } else {\n+      assert(num_inline_args() > 1, \"must be\");\n+      \/\/ No sharing:\n+      \/\/   VIEP(RO) -- <this> is passed as object\n+      \/\/   VEP      -- <this> is passed as fields\n+      return CodeOffsets::Verified_Inline_Entry_RO;\n+    }\n+  }\n+\n+  \/\/ Either a static method, or <this> is not an inline type\n+  if (args_on_stack_cc() != args_on_stack_cc_ro()) {\n+    \/\/ No sharing:\n+    \/\/ Some arguments are passed on the stack, and we have inserted reserved entries\n+    \/\/ into the VEP, but we never insert reserved entries into the VIEP(RO).\n+    return CodeOffsets::Verified_Inline_Entry_RO;\n+  } else {\n+    \/\/ Share same entry for VEP and VIEP(RO).\n+    return CodeOffsets::Verified_Entry;\n+  }\n+}\n+\n+\n+void CompiledEntrySignature::compute_calling_conventions() {\n+  \/\/ Get the (non-scalarized) signature and check for inline type arguments\n+  if (!_method->is_static()) {\n+    if (_method->method_holder()->is_inline_klass() && InlineKlass::cast(_method->method_holder())->can_be_passed_as_fields()) {\n+      _has_inline_recv = true;\n+      _num_inline_args++;\n+    }\n+    SigEntry::add_entry(_sig, T_OBJECT, _method->name());\n+  }\n+  for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {\n+    BasicType bt = ss.type();\n+    if (bt == T_INLINE_TYPE) {\n+      if (ss.as_inline_klass(_method->method_holder())->can_be_passed_as_fields()) {\n+        _num_inline_args++;\n+      }\n+      bt = T_OBJECT;\n+    }\n+    SigEntry::add_entry(_sig, bt, ss.as_symbol());\n+  }\n+  if (_method->is_abstract() && !has_inline_arg()) {\n+    return;\n+  }\n+\n+  \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n+  _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig->length());\n+  _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);\n+\n+  \/\/ Now compute the scalarized calling convention if there are inline types in the signature\n+  _sig_cc = _sig;\n+  _sig_cc_ro = _sig;\n+  _regs_cc = _regs;\n+  _regs_cc_ro = _regs;\n+  _args_on_stack_cc = _args_on_stack;\n+  _args_on_stack_cc_ro = _args_on_stack;\n+\n+  if (has_inline_arg() && !_method->is_native()) {\n+    _args_on_stack_cc = compute_scalarized_cc(_sig_cc, _regs_cc, \/* scalar_receiver = *\/ true);\n+\n+    _sig_cc_ro = _sig_cc;\n+    _regs_cc_ro = _regs_cc;\n+    _args_on_stack_cc_ro = _args_on_stack_cc;\n+    if (_has_inline_recv) {\n+      \/\/ For interface calls, we need another entry point \/ adapter to unpack the receiver\n+      _args_on_stack_cc_ro = compute_scalarized_cc(_sig_cc_ro, _regs_cc_ro, \/* scalar_receiver = *\/ false);\n+    }\n+\n+    \/\/ Upper bound on stack arguments to avoid hitting the argument limit and\n+    \/\/ bailing out of compilation (\"unsupported incoming calling sequence\").\n+    \/\/ TODO we need a reasonable limit (flag?) here\n+    if (_args_on_stack_cc > 50) {\n+      \/\/ Don't scalarize inline type arguments\n+      _sig_cc = _sig;\n+      _sig_cc_ro = _sig;\n+      _regs_cc = _regs;\n+      _regs_cc_ro = _regs;\n+      _args_on_stack_cc = _args_on_stack;\n+      _args_on_stack_cc_ro = _args_on_stack;\n+    } else {\n+      _c1_needs_stack_repair = (_args_on_stack_cc < _args_on_stack) || (_args_on_stack_cc_ro < _args_on_stack);\n+      _c2_needs_stack_repair = (_args_on_stack_cc > _args_on_stack) || (_args_on_stack_cc > _args_on_stack_cc_ro);\n+      _has_scalarized_args = true;\n+    }\n+  }\n@@ -2649,1 +2890,1 @@\n-  NOT_PRODUCT(int insts_size);\n+  NOT_PRODUCT(int insts_size = 0);\n@@ -2653,0 +2894,1 @@\n+\n@@ -2658,2 +2900,4 @@\n-    if (method->is_abstract()) {\n-      return _abstract_method_handler;\n+    CompiledEntrySignature ces(method());\n+    {\n+       MutexUnlocker mul(AdapterHandlerLibrary_lock);\n+       ces.compute_calling_conventions();\n@@ -2661,0 +2905,6 @@\n+    GrowableArray<SigEntry>& sig       = ces.sig();\n+    GrowableArray<SigEntry>& sig_cc    = ces.sig_cc();\n+    GrowableArray<SigEntry>& sig_cc_ro = ces.sig_cc_ro();\n+    VMRegPair* regs         = ces.regs();\n+    VMRegPair* regs_cc      = ces.regs_cc();\n+    VMRegPair* regs_cc_ro   = ces.regs_cc_ro();\n@@ -2662,2 +2912,5 @@\n-    \/\/ Fill in the signature array, for the calling-convention call.\n-    int total_args_passed = method->size_of_parameters(); \/\/ All args on stack\n+    if (ces.has_scalarized_args()) {\n+      method->set_has_scalarized_args(true);\n+      method->set_c1_needs_stack_repair(ces.c1_needs_stack_repair());\n+      method->set_c2_needs_stack_repair(ces.c2_needs_stack_repair());\n+    }\n@@ -2665,9 +2918,15 @@\n-    BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, total_args_passed);\n-    VMRegPair* regs   = NEW_RESOURCE_ARRAY(VMRegPair, total_args_passed);\n-    int i = 0;\n-    if (!method->is_static())  \/\/ Pass in receiver first\n-      sig_bt[i++] = T_OBJECT;\n-    for (SignatureStream ss(method->signature()); !ss.at_return_type(); ss.next()) {\n-      sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n-      if (ss.type() == T_LONG || ss.type() == T_DOUBLE)\n-        sig_bt[i++] = T_VOID;   \/\/ Longs & doubles take 2 Java slots\n+    if (method->is_abstract()) {\n+      if (ces.has_scalarized_args()) {\n+        \/\/ Save a C heap allocated version of the signature for abstract methods with scalarized inline type arguments\n+        address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();\n+        entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),\n+                                                 StubRoutines::throw_AbstractMethodError_entry(),\n+                                                 wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,\n+                                                 wrong_method_abstract, wrong_method_abstract);\n+        GrowableArray<SigEntry>* heap_sig = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<SigEntry>(sig_cc_ro.length(), mtInternal);\n+        heap_sig->appendAll(&sig_cc_ro);\n+        entry->set_sig_cc(heap_sig);\n+        return entry;\n+      } else {\n+        return _abstract_method_handler;\n+      }\n@@ -2675,1 +2934,0 @@\n-    assert(i == total_args_passed, \"\");\n@@ -2678,1 +2936,1 @@\n-    entry = _adapters->lookup(total_args_passed, sig_bt);\n+    entry = _adapters->lookup(&sig_cc, regs_cc != regs_cc_ro);\n@@ -2693,4 +2951,1 @@\n-    \/\/ Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage\n-    int comp_args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, total_args_passed);\n-\n-    fingerprint = new AdapterFingerPrint(total_args_passed, sig_bt);\n+    fingerprint = new AdapterFingerPrint(&sig_cc, regs_cc != regs_cc_ro);\n@@ -2715,3 +2970,2 @@\n-                                                     total_args_passed,\n-                                                     comp_args_on_stack,\n-                                                     sig_bt,\n+                                                     ces.args_on_stack(),\n+                                                     &sig,\n@@ -2719,1 +2973,14 @@\n-                                                     fingerprint);\n+                                                     &sig_cc,\n+                                                     regs_cc,\n+                                                     &sig_cc_ro,\n+                                                     regs_cc_ro,\n+                                                     fingerprint,\n+                                                     new_adapter);\n+\n+      if (ces.has_scalarized_args()) {\n+        \/\/ Save a C heap allocated version of the scalarized signature and store it in the adapter\n+        GrowableArray<SigEntry>* heap_sig = new (ResourceObj::C_HEAP, mtInternal) GrowableArray<SigEntry>(sig_cc.length(), mtInternal);\n+        heap_sig->appendAll(&sig_cc);\n+        entry->set_sig_cc(heap_sig);\n+      }\n+\n@@ -2723,0 +2990,3 @@\n+          if (!shared_entry->compare_code(buf->code_begin(), buffer.insts_size())) {\n+            method->print();\n+          }\n@@ -2733,1 +3003,0 @@\n-      new_adapter = AdapterBlob::create(&buffer);\n@@ -2789,0 +3058,2 @@\n+  assert(base <= _c2i_inline_entry || _c2i_inline_entry == NULL, \"\");\n+  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == NULL, \"\");\n@@ -2790,0 +3061,1 @@\n+  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == NULL, \"\");\n@@ -2802,0 +3074,4 @@\n+  if (_c2i_inline_entry != NULL)\n+    _c2i_inline_entry += delta;\n+  if (_c2i_inline_ro_entry != NULL)\n+    _c2i_inline_ro_entry += delta;\n@@ -2804,0 +3080,2 @@\n+  if (_c2i_unverified_inline_entry != NULL)\n+    _c2i_unverified_inline_entry += delta;\n@@ -2812,0 +3090,3 @@\n+  if (_sig_cc != NULL) {\n+    delete _sig_cc;\n+  }\n@@ -2895,1 +3176,2 @@\n-        sig_bt[i++] = ss.type();  \/\/ Collect remaining bits of signature\n+        BasicType bt = ss.type();\n+        sig_bt[i++] = bt;  \/\/ Collect remaining bits of signature\n@@ -3121,0 +3403,6 @@\n+  if (get_c2i_entry() != NULL) {\n+    st->print(\" c2iVE: \" INTPTR_FORMAT, p2i(get_c2i_inline_entry()));\n+  }\n+  if (get_c2i_entry() != NULL) {\n+    st->print(\" c2iVROE: \" INTPTR_FORMAT, p2i(get_c2i_inline_ro_entry()));\n+  }\n@@ -3122,1 +3410,4 @@\n-    st->print(\" c2iUV: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+    st->print(\" c2iUE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));\n+  }\n+  if (get_c2i_unverified_entry() != NULL) {\n+    st->print(\" c2iUVE: \" INTPTR_FORMAT, p2i(get_c2i_unverified_inline_entry()));\n@@ -3207,0 +3498,206 @@\n+\n+\/\/ We are at a compiled code to interpreter call. We need backing\n+\/\/ buffers for all inline type arguments. Allocate an object array to\n+\/\/ hold them (convenient because once we're done with it we don't have\n+\/\/ to worry about freeing it).\n+oop SharedRuntime::allocate_inline_types_impl(JavaThread* current, methodHandle callee, bool allocate_receiver, TRAPS) {\n+  assert(InlineTypePassFieldsAsArgs, \"no reason to call this\");\n+  ResourceMark rm;\n+\n+  int nb_slots = 0;\n+  InstanceKlass* holder = callee->method_holder();\n+  allocate_receiver &= !callee->is_static() && holder->is_inline_klass();\n+  if (allocate_receiver) {\n+    nb_slots++;\n+  }\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    if (ss.type() == T_INLINE_TYPE) {\n+      nb_slots++;\n+    }\n+  }\n+  objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);\n+  objArrayHandle array(THREAD, array_oop);\n+  int i = 0;\n+  if (allocate_receiver) {\n+    InlineKlass* vk = InlineKlass::cast(holder);\n+    oop res = vk->allocate_instance(CHECK_NULL);\n+    array->obj_at_put(i, res);\n+    i++;\n+  }\n+  for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {\n+    if (ss.type() == T_INLINE_TYPE) {\n+      InlineKlass* vk = ss.as_inline_klass(holder);\n+      oop res = vk->allocate_instance(CHECK_NULL);\n+      array->obj_at_put(i, res);\n+      i++;\n+    }\n+  }\n+  return array();\n+}\n+\n+JRT_ENTRY(void, SharedRuntime::allocate_inline_types(JavaThread* current, Method* callee_method, bool allocate_receiver))\n+  methodHandle callee(current, callee_method);\n+  oop array = SharedRuntime::allocate_inline_types_impl(current, callee, allocate_receiver, CHECK);\n+  current->set_vm_result(array);\n+  current->set_vm_result_2(callee()); \/\/ TODO: required to keep callee live?\n+JRT_END\n+\n+\/\/ TODO remove this once the AARCH64 dependency is gone\n+\/\/ Iterate over the array of heap allocated inline types and apply the GC post barrier to all reference fields.\n+\/\/ This is called from the C2I adapter after inline type arguments are heap allocated and initialized.\n+JRT_LEAF(void, SharedRuntime::apply_post_barriers(JavaThread* current, objArrayOopDesc* array))\n+{\n+  assert(InlineTypePassFieldsAsArgs, \"no reason to call this\");\n+  assert(oopDesc::is_oop(array), \"should be oop\");\n+  for (int i = 0; i < array->length(); ++i) {\n+    instanceOop valueOop = (instanceOop)array->obj_at(i);\n+    InlineKlass* vk = InlineKlass::cast(valueOop->klass());\n+    if (vk->contains_oops()) {\n+      const address dst_oop_addr = ((address) (void*) valueOop);\n+      OopMapBlock* map = vk->start_of_nonstatic_oop_maps();\n+      OopMapBlock* const end = map + vk->nonstatic_oop_map_count();\n+      while (map != end) {\n+        address doop_address = dst_oop_addr + map->offset();\n+        barrier_set_cast<ModRefBarrierSet>(BarrierSet::barrier_set())->\n+          write_ref_array((HeapWord*) doop_address, map->count());\n+        map++;\n+      }\n+    }\n+  }\n+}\n+JRT_END\n+\n+\/\/ We're returning from an interpreted method: load each field into a\n+\/\/ register following the calling convention\n+JRT_LEAF(void, SharedRuntime::load_inline_type_fields_in_regs(JavaThread* current, oopDesc* res))\n+{\n+  assert(res->klass()->is_inline_klass(), \"only inline types here\");\n+  ResourceMark rm;\n+  RegisterMap reg_map(current);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+  assert(callerFrame.is_interpreted_frame(), \"should be coming from interpreter\");\n+\n+  InlineKlass* vk = InlineKlass::cast(res->klass());\n+\n+  const Array<SigEntry>* sig_vk = vk->extended_sig();\n+  const Array<VMRegPair>* regs = vk->return_regs();\n+\n+  if (regs == NULL) {\n+    \/\/ The fields of the inline klass don't fit in registers, bail out\n+    return;\n+  }\n+\n+  int j = 1;\n+  for (int i = 0; i < sig_vk->length(); i++) {\n+    BasicType bt = sig_vk->at(i)._bt;\n+    if (bt == T_INLINE_TYPE) {\n+      continue;\n+    }\n+    if (bt == T_VOID) {\n+      if (sig_vk->at(i-1)._bt == T_LONG ||\n+          sig_vk->at(i-1)._bt == T_DOUBLE) {\n+        j++;\n+      }\n+      continue;\n+    }\n+    int off = sig_vk->at(i)._offset;\n+    assert(off > 0, \"offset in object should be positive\");\n+    VMRegPair pair = regs->at(j);\n+    address loc = reg_map.location(pair.first());\n+    switch(bt) {\n+    case T_BOOLEAN:\n+      *(jboolean*)loc = res->bool_field(off);\n+      break;\n+    case T_CHAR:\n+      *(jchar*)loc = res->char_field(off);\n+      break;\n+    case T_BYTE:\n+      *(jbyte*)loc = res->byte_field(off);\n+      break;\n+    case T_SHORT:\n+      *(jshort*)loc = res->short_field(off);\n+      break;\n+    case T_INT: {\n+      *(jint*)loc = res->int_field(off);\n+      break;\n+    }\n+    case T_LONG:\n+#ifdef _LP64\n+      *(intptr_t*)loc = res->long_field(off);\n+#else\n+      Unimplemented();\n+#endif\n+      break;\n+    case T_OBJECT:\n+    case T_ARRAY: {\n+      *(oop*)loc = res->obj_field(off);\n+      break;\n+    }\n+    case T_FLOAT:\n+      *(jfloat*)loc = res->float_field(off);\n+      break;\n+    case T_DOUBLE:\n+      *(jdouble*)loc = res->double_field(off);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+    j++;\n+  }\n+  assert(j == regs->length(), \"missed a field?\");\n+\n+#ifdef ASSERT\n+  VMRegPair pair = regs->at(0);\n+  address loc = reg_map.location(pair.first());\n+  assert(*(oopDesc**)loc == res, \"overwritten object\");\n+#endif\n+\n+  current->set_vm_result(res);\n+}\n+JRT_END\n+\n+\/\/ We've returned to an interpreted method, the interpreter needs a\n+\/\/ reference to an inline type instance. Allocate it and initialize it\n+\/\/ from field's values in registers.\n+JRT_BLOCK_ENTRY(void, SharedRuntime::store_inline_type_fields_to_buf(JavaThread* current, intptr_t res))\n+{\n+  ResourceMark rm;\n+  RegisterMap reg_map(current);\n+  frame stubFrame = current->last_frame();\n+  frame callerFrame = stubFrame.sender(&reg_map);\n+\n+#ifdef ASSERT\n+  InlineKlass* verif_vk = InlineKlass::returned_inline_klass(reg_map);\n+#endif\n+\n+  if (!is_set_nth_bit(res, 0)) {\n+    \/\/ We're not returning with inline type fields in registers (the\n+    \/\/ calling convention didn't allow it for this inline klass)\n+    assert(!Metaspace::contains((void*)res), \"should be oop or pointer in buffer area\");\n+    current->set_vm_result((oopDesc*)res);\n+    assert(verif_vk == NULL, \"broken calling convention\");\n+    return;\n+  }\n+\n+  clear_nth_bit(res, 0);\n+  InlineKlass* vk = (InlineKlass*)res;\n+  assert(verif_vk == vk, \"broken calling convention\");\n+  assert(Metaspace::contains((void*)res), \"should be klass\");\n+\n+  \/\/ Allocate handles for every oop field so they are safe in case of\n+  \/\/ a safepoint when allocating\n+  GrowableArray<Handle> handles;\n+  vk->save_oop_fields(reg_map, handles);\n+\n+  \/\/ It's unsafe to safepoint until we are here\n+  JRT_BLOCK;\n+  {\n+    Thread* THREAD = current;\n+    oop vt = vk->realloc_result(reg_map, handles, CHECK);\n+    current->set_vm_result(vt);\n+  }\n+  JRT_BLOCK_END;\n+}\n+JRT_END\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":586,"deletions":89,"binary":false,"changes":675,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"asm\/codeBuffer.hpp\"\n@@ -34,0 +35,1 @@\n+#include \"runtime\/signature.hpp\"\n@@ -41,0 +43,1 @@\n+class SigEntry;\n@@ -55,1 +58,1 @@\n-  static methodHandle resolve_sub_helper(bool is_virtual, bool is_optimized, TRAPS);\n+  static methodHandle resolve_sub_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS);\n@@ -65,1 +68,0 @@\n-  static address             _resolve_static_call_entry;\n@@ -86,1 +88,0 @@\n-\n@@ -317,1 +318,1 @@\n-  static methodHandle resolve_helper(bool is_virtual, bool is_optimized, TRAPS);\n+  static methodHandle resolve_helper(bool is_virtual, bool is_optimized, bool* caller_is_c1, TRAPS);\n@@ -325,1 +326,1 @@\n-                                             bool& needs_ic_stub_refill, TRAPS);\n+                                             bool& needs_ic_stub_refill, bool& is_optimized, bool caller_is_c1, TRAPS);\n@@ -331,1 +332,1 @@\n-  static methodHandle reresolve_call_site(TRAPS);\n+  static methodHandle reresolve_call_site(bool& is_static_call, bool& is_optimized, bool& caller_is_c1, TRAPS);\n@@ -335,1 +336,1 @@\n-  static methodHandle handle_ic_miss_helper(TRAPS);\n+  static methodHandle handle_ic_miss_helper(bool& is_optimized, bool& caller_is_c1, TRAPS);\n@@ -344,0 +345,13 @@\n+  static address entry_for_handle_wrong_method(methodHandle callee_method, bool is_static_call, bool is_optimized, bool caller_is_c1) {\n+    assert(callee_method->verified_code_entry() != NULL, \"Jump to zero!\");\n+    assert(callee_method->verified_inline_code_entry() != NULL, \"Jump to zero!\");\n+    assert(callee_method->verified_inline_ro_code_entry() != NULL, \"Jump to zero!\");\n+    if (caller_is_c1) {\n+      return callee_method->verified_inline_code_entry();\n+    } else if (is_static_call || is_optimized) {\n+      return callee_method->verified_code_entry();\n+    } else {\n+      return callee_method->verified_inline_ro_code_entry();\n+    }\n+  }\n+\n@@ -366,0 +380,8 @@\n+  static int java_calling_convention(const GrowableArray<SigEntry>* sig, VMRegPair* regs) {\n+    BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig->length());\n+    int total_args_passed = SigEntry::fill_sig_bt(sig, sig_bt);\n+    return java_calling_convention(sig_bt, regs, total_args_passed);\n+  }\n+  static int java_return_convention(const BasicType* sig_bt, VMRegPair* regs, int total_args_passed);\n+  static const uint java_return_convention_max_int;\n+  static const uint java_return_convention_max_float;\n@@ -411,6 +433,10 @@\n-  static AdapterHandlerEntry* generate_i2c2i_adapters(MacroAssembler *_masm,\n-                                                      int total_args_passed,\n-                                                      int max_arg,\n-                                                      const BasicType *sig_bt,\n-                                                      const VMRegPair *regs,\n-                                                      AdapterFingerPrint* fingerprint);\n+  static AdapterHandlerEntry* generate_i2c2i_adapters(MacroAssembler *masm,\n+                                                      int comp_args_on_stack,\n+                                                      const GrowableArray<SigEntry>* sig,\n+                                                      const VMRegPair* regs,\n+                                                      const GrowableArray<SigEntry>* sig_cc,\n+                                                      const VMRegPair* regs_cc,\n+                                                      const GrowableArray<SigEntry>* sig_cc_ro,\n+                                                      const VMRegPair* regs_cc_ro,\n+                                                      AdapterFingerPrint* fingerprint,\n+                                                      AdapterBlob*& new_adapter);\n@@ -419,2 +445,1 @@\n-                              int total_args_passed,\n-                              const BasicType *sig_bt,\n+                              const GrowableArray<SigEntry>* sig,\n@@ -496,0 +521,3 @@\n+  static void load_inline_type_fields_in_regs(JavaThread* current, oopDesc* res);\n+  static void store_inline_type_fields_to_buf(JavaThread* current, intptr_t res);\n+\n@@ -506,0 +534,3 @@\n+  static void allocate_inline_types(JavaThread* current, Method* callee, bool allocate_receiver);\n+  static oop allocate_inline_types_impl(JavaThread* current, methodHandle callee, bool allocate_receiver, TRAPS);\n+  static void apply_post_barriers(JavaThread* current, objArrayOopDesc* array);\n@@ -509,0 +540,1 @@\n+  static BufferedInlineTypeBlob* generate_buffered_inline_type_adapter(const InlineKlass* vk);\n@@ -628,0 +660,2 @@\n+  address _c2i_inline_entry;\n+  address _c2i_inline_ro_entry;\n@@ -629,0 +663,1 @@\n+  address _c2i_unverified_inline_entry;\n@@ -631,0 +666,3 @@\n+  \/\/ Support for scalarized inline type calling convention\n+  const GrowableArray<SigEntry>* _sig_cc;\n+\n@@ -638,1 +676,2 @@\n-  void init(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry, address c2i_unverified_entry, address c2i_no_clinit_check_entry) {\n+  void init(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry, address c2i_inline_entry,\n+            address c2i_inline_ro_entry, address c2i_unverified_entry, address c2i_unverified_inline_entry, address c2i_no_clinit_check_entry) {\n@@ -642,0 +681,2 @@\n+    _c2i_inline_entry = c2i_inline_entry;\n+    _c2i_inline_ro_entry = c2i_inline_ro_entry;\n@@ -643,0 +684,1 @@\n+    _c2i_unverified_inline_entry = c2i_unverified_inline_entry;\n@@ -644,0 +686,1 @@\n+    _sig_cc = NULL;\n@@ -656,4 +699,7 @@\n-  address get_i2c_entry()                  const { return _i2c_entry; }\n-  address get_c2i_entry()                  const { return _c2i_entry; }\n-  address get_c2i_unverified_entry()       const { return _c2i_unverified_entry; }\n-  address get_c2i_no_clinit_check_entry()  const { return _c2i_no_clinit_check_entry; }\n+  address get_i2c_entry()                   const { return _i2c_entry; }\n+  address get_c2i_entry()                   const { return _c2i_entry; }\n+  address get_c2i_inline_entry()            const { return _c2i_inline_entry; }\n+  address get_c2i_inline_ro_entry()         const { return _c2i_inline_ro_entry; }\n+  address get_c2i_unverified_entry()        const { return _c2i_unverified_entry; }\n+  address get_c2i_unverified_inline_entry() const { return _c2i_unverified_inline_entry; }\n+  address get_c2i_no_clinit_check_entry()   const { return _c2i_no_clinit_check_entry; }\n@@ -664,0 +710,4 @@\n+  \/\/ Support for scalarized inline type calling convention\n+  void set_sig_cc(const GrowableArray<SigEntry>* sig)  { _sig_cc = sig; }\n+  const GrowableArray<SigEntry>* get_sig_cc()    const { return _sig_cc; }\n+\n@@ -691,4 +741,2 @@\n-                                        address i2c_entry,\n-                                        address c2i_entry,\n-                                        address c2i_unverified_entry,\n-                                        address c2i_no_clinit_check_entry = NULL);\n+                                        address i2c_entry, address c2i_entry, address c2i_inline_entry, address c2i_inline_ro_entry,\n+                                        address c2i_unverified_entry, address c2i_unverified_inline_entry, address c2i_no_clinit_check_entry = NULL);\n@@ -707,0 +755,60 @@\n+\/\/ Utility class for computing the calling convention of the 3 types\n+\/\/ of compiled method entries:\n+\/\/     Method::_from_compiled_entry               - sig_cc\n+\/\/     Method::_from_compiled_inline_ro_entry     - sig_cc_ro\n+\/\/     Method::_from_compiled_inline_entry        - sig\n+class CompiledEntrySignature : public StackObj {\n+  Method* _method;\n+  int  _num_inline_args;\n+  bool _has_inline_recv;\n+  GrowableArray<SigEntry> *_sig;\n+  GrowableArray<SigEntry> *_sig_cc;\n+  GrowableArray<SigEntry> *_sig_cc_ro;\n+  VMRegPair* _regs;\n+  VMRegPair* _regs_cc;\n+  VMRegPair* _regs_cc_ro;\n+\n+  int _args_on_stack;\n+  int _args_on_stack_cc;\n+  int _args_on_stack_cc_ro;\n+\n+  bool _c1_needs_stack_repair;\n+  bool _c2_needs_stack_repair;\n+  bool _has_scalarized_args;\n+\n+public:\n+  Method* method()                     const { return _method; }\n+\n+  \/\/ Used by Method::_from_compiled_inline_entry\n+  GrowableArray<SigEntry>& sig()       const { return *_sig; }\n+\n+  \/\/ Used by Method::_from_compiled_entry\n+  GrowableArray<SigEntry>& sig_cc()    const { return *_sig_cc; }\n+\n+  \/\/ Used by Method::_from_compiled_inline_ro_entry\n+  GrowableArray<SigEntry>& sig_cc_ro() const { return *_sig_cc_ro; }\n+\n+  VMRegPair* regs()                    const { return _regs; }\n+  VMRegPair* regs_cc()                 const { return _regs_cc; }\n+  VMRegPair* regs_cc_ro()              const { return _regs_cc_ro; }\n+\n+  int args_on_stack()                  const { return _args_on_stack; }\n+  int args_on_stack_cc()               const { return _args_on_stack_cc; }\n+  int args_on_stack_cc_ro()            const { return _args_on_stack_cc_ro; }\n+\n+  int  num_inline_args()               const { return _num_inline_args; }\n+  bool has_inline_arg()                const { return _num_inline_args > 0; }\n+  bool has_inline_recv()               const { return _has_inline_recv; }\n+\n+  bool has_scalarized_args()           const { return _has_scalarized_args; }\n+  bool c1_needs_stack_repair()         const { return _c1_needs_stack_repair; }\n+  bool c2_needs_stack_repair()         const { return _c2_needs_stack_repair; }\n+  CodeOffsets::Entries c1_inline_ro_entry_type() const;\n+\n+  CompiledEntrySignature(Method* method);\n+  void compute_calling_conventions();\n+\n+private:\n+  int compute_scalarized_cc(GrowableArray<SigEntry>*& sig_cc, VMRegPair*& regs_cc, bool scalar_receiver);\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":132,"deletions":24,"binary":false,"changes":156,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -49,1 +50,1 @@\n-\/\/ FieldType  = \"B\" | \"C\" | \"D\" | \"F\" | \"I\" | \"J\" | \"S\" | \"Z\" | \"L\" ClassName \";\" | \"[\" FieldType.\n+\/\/ FieldType  = \"B\" | \"C\" | \"D\" | \"F\" | \"I\" | \"J\" | \"S\" | \"Z\" | \"L\" ClassName \";\" | \"Q\" ValueClassName \";\" | \"[\" FieldType.\n@@ -222,0 +223,1 @@\n+  case T_INLINE_TYPE:\n@@ -301,0 +303,1 @@\n+  case JVM_SIGNATURE_INLINE_TYPE:\n@@ -382,0 +385,9 @@\n+InlineKlass* SignatureStream::as_inline_klass(InstanceKlass* holder) {\n+  Thread* THREAD = Thread::current();\n+  Handle class_loader(THREAD, holder->class_loader());\n+  Handle protection_domain(THREAD, holder->protection_domain());\n+  Klass* k = as_klass(class_loader, protection_domain, SignatureStream::ReturnNull, THREAD);\n+  assert(k != NULL && !HAS_PENDING_EXCEPTION, \"unresolved inline klass\");\n+  return InlineKlass::cast(k);\n+}\n+\n@@ -478,1 +490,0 @@\n-\n@@ -497,1 +508,1 @@\n-bool SignatureVerifier::is_valid_method_signature(Symbol* sig) {\n+bool SignatureVerifier::is_valid_method_signature(const Symbol* sig) {\n@@ -520,1 +531,1 @@\n-bool SignatureVerifier::is_valid_type_signature(Symbol* sig) {\n+bool SignatureVerifier::is_valid_type_signature(const Symbol* sig) {\n@@ -549,0 +560,1 @@\n+    case JVM_SIGNATURE_INLINE_TYPE: \/\/ fall through\n@@ -567,0 +579,53 @@\n+\n+\/\/ Adds an argument to the signature\n+void SigEntry::add_entry(GrowableArray<SigEntry>* sig, BasicType bt, Symbol* symbol, int offset) {\n+  sig->append(SigEntry(bt, offset, symbol));\n+  if (bt == T_LONG || bt == T_DOUBLE) {\n+    sig->append(SigEntry(T_VOID, offset, symbol)); \/\/ Longs and doubles take two stack slots\n+  }\n+}\n+\n+\/\/ Returns true if the argument at index 'i' is not an inline type delimiter\n+bool SigEntry::skip_value_delimiters(const GrowableArray<SigEntry>* sig, int i) {\n+  return (sig->at(i)._bt != T_INLINE_TYPE &&\n+          (sig->at(i)._bt != T_VOID || sig->at(i-1)._bt == T_LONG || sig->at(i-1)._bt == T_DOUBLE));\n+}\n+\n+\/\/ Fill basic type array from signature array\n+int SigEntry::fill_sig_bt(const GrowableArray<SigEntry>* sig, BasicType* sig_bt) {\n+  int count = 0;\n+  for (int i = 0; i < sig->length(); i++) {\n+    if (skip_value_delimiters(sig, i)) {\n+      sig_bt[count++] = sig->at(i)._bt;\n+    }\n+  }\n+  return count;\n+}\n+\n+\/\/ Create a temporary symbol from the signature array\n+TempNewSymbol SigEntry::create_symbol(const GrowableArray<SigEntry>* sig) {\n+  ResourceMark rm;\n+  int length = sig->length();\n+  char* sig_str = NEW_RESOURCE_ARRAY(char, 2*length + 3);\n+  int idx = 0;\n+  sig_str[idx++] = '(';\n+  for (int i = 0; i < length; i++) {\n+    BasicType bt = sig->at(i)._bt;\n+    if (bt == T_INLINE_TYPE || bt == T_VOID) {\n+      \/\/ Ignore\n+    } else {\n+      if (bt == T_ARRAY) {\n+        bt = T_OBJECT; \/\/ We don't know the element type, treat as Object\n+      }\n+      sig_str[idx++] = type2char(bt);\n+      if (bt == T_OBJECT) {\n+        sig_str[idx++] = ';';\n+      }\n+    }\n+  }\n+  sig_str[idx++] = ')';\n+  \/\/ Add a dummy return type. It won't be used but SignatureStream needs it.\n+  sig_str[idx++] = 'V';\n+  sig_str[idx++] = '\\0';\n+  return SymbolTable::new_symbol(sig_str);\n+}\n","filename":"src\/hotspot\/share\/runtime\/signature.cpp","additions":69,"deletions":4,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"classfile\/symbolTable.hpp\"\n@@ -127,1 +128,1 @@\n-    return (signature_char == JVM_SIGNATURE_CLASS);\n+    return (signature_char == JVM_SIGNATURE_CLASS) || (signature_char == JVM_SIGNATURE_INLINE_TYPE);\n@@ -272,1 +273,2 @@\n-    case T_OBJECT:  type_name(\"jobject\" ); break;\n+    case T_OBJECT:\n+    case T_INLINE_TYPE:  type_name(\"jobject\" ); break;\n@@ -410,0 +412,1 @@\n+    case T_INLINE_TYPE:\n@@ -565,0 +568,1 @@\n+\n@@ -566,0 +570,1 @@\n+  InlineKlass* as_inline_klass(InstanceKlass* holder);\n@@ -569,0 +574,51 @@\n+class SigEntryFilter;\n+typedef GrowableArrayFilterIterator<SigEntry, SigEntryFilter> ExtendedSignature;\n+\n+\/\/ Used for adapter generation. One SigEntry is used per element of\n+\/\/ the signature of the method. Inline type arguments are treated\n+\/\/ specially. See comment for InlineKlass::collect_fields().\n+class SigEntry {\n+ public:\n+  BasicType _bt;\n+  int _offset;\n+  Symbol* _symbol;\n+\n+  SigEntry()\n+    : _bt(T_ILLEGAL), _offset(-1), _symbol(NULL) {}\n+\n+  SigEntry(BasicType bt, int offset, Symbol* symbol)\n+    : _bt(bt), _offset(offset), _symbol(symbol) {}\n+\n+  static int compare(SigEntry* e1, SigEntry* e2) {\n+    if (e1->_offset != e2->_offset) {\n+      return e1->_offset - e2->_offset;\n+    }\n+    assert((e1->_bt == T_LONG && (e2->_bt == T_LONG || e2->_bt == T_VOID)) ||\n+           (e1->_bt == T_DOUBLE && (e2->_bt == T_DOUBLE || e2->_bt == T_VOID)) ||\n+           e1->_bt == T_INLINE_TYPE || e2->_bt == T_INLINE_TYPE || e1->_bt == T_VOID || e2->_bt == T_VOID, \"bad bt\");\n+    if (e1->_bt == e2->_bt) {\n+      assert(e1->_bt == T_INLINE_TYPE || e1->_bt == T_VOID, \"only ones with duplicate offsets\");\n+      return 0;\n+    }\n+    if (e1->_bt == T_VOID ||\n+        e2->_bt == T_INLINE_TYPE) {\n+      return 1;\n+    }\n+    if (e1->_bt == T_INLINE_TYPE ||\n+        e2->_bt == T_VOID) {\n+      return -1;\n+    }\n+    ShouldNotReachHere();\n+    return 0;\n+  }\n+  static void add_entry(GrowableArray<SigEntry>* sig, BasicType bt, Symbol* symbol, int offset = -1);\n+  static bool skip_value_delimiters(const GrowableArray<SigEntry>* sig, int i);\n+  static int fill_sig_bt(const GrowableArray<SigEntry>* sig, BasicType* sig_bt);\n+  static TempNewSymbol create_symbol(const GrowableArray<SigEntry>* sig);\n+};\n+\n+class SigEntryFilter {\n+public:\n+  bool operator()(const SigEntry& entry) { return entry._bt != T_INLINE_TYPE && entry._bt != T_VOID; }\n+};\n+\n@@ -640,1 +696,1 @@\n- #ifdef ASSERT\n+#ifdef ASSERT\n@@ -643,2 +699,2 @@\n-    static bool is_valid_method_signature(Symbol* sig);\n-    static bool is_valid_type_signature(Symbol* sig);\n+    static bool is_valid_method_signature(const Symbol* sig);\n+    static bool is_valid_type_signature(const Symbol* sig);\n","filename":"src\/hotspot\/share\/runtime\/signature.hpp","additions":61,"deletions":5,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -185,0 +185,3 @@\n+address StubRoutines::_load_inline_type_fields_in_regs = NULL;\n+address StubRoutines::_store_inline_type_fields_to_buf = NULL;\n+\n@@ -486,0 +489,1 @@\n+  case T_INLINE_TYPE:\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -244,0 +244,15 @@\n+\/\/ TODO The THREAD declarations below should be removed\n+#define CHECK_THROW_NOSYNC_IMSE(obj)  \\\n+  if (EnableValhalla && (obj)->mark().is_inline_type()) {  \\\n+    JavaThread* THREAD = current;           \\\n+    ResourceMark rm(THREAD);                \\\n+    THROW_MSG(vmSymbols::java_lang_IllegalMonitorStateException(), obj->klass()->external_name()); \\\n+  }\n+\n+#define CHECK_THROW_NOSYNC_IMSE_0(obj)  \\\n+  if (EnableValhalla && (obj)->mark().is_inline_type()) {  \\\n+    JavaThread* THREAD = current;             \\\n+    ResourceMark rm(THREAD);                  \\\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalMonitorStateException(), obj->klass()->external_name()); \\\n+  }\n+\n@@ -270,0 +285,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -318,0 +334,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -429,0 +446,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -438,1 +456,1 @@\n-  assert(!mark.has_bias_pattern(), \"should not see bias pattern here\");\n+  assert(!UseBiasedLocking || !mark.has_bias_pattern(), \"should not see bias pattern here\");\n@@ -474,0 +492,4 @@\n+  if (EnableValhalla && mark.is_inline_type()) {\n+    return;\n+  }\n+  assert(!EnableValhalla || !object->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -476,0 +498,1 @@\n+         !UseBiasedLocking ||\n@@ -537,0 +560,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -551,0 +575,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -577,0 +602,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -597,0 +623,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -601,0 +628,1 @@\n+    assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n@@ -602,1 +630,0 @@\n-  assert(!obj->mark().has_bias_pattern(), \"biases should be revoked by now\");\n@@ -640,0 +667,1 @@\n+  CHECK_THROW_NOSYNC_IMSE_0(obj);\n@@ -666,0 +694,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -679,0 +708,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -698,0 +728,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -848,0 +879,4 @@\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+    \/\/ VM should be calling bootstrap method\n+    ShouldNotReachHere();\n+  }\n@@ -875,1 +910,1 @@\n-    assert(!mark.has_bias_pattern(), \"invariant\");\n+    assert(!UseBiasedLocking || !mark.has_bias_pattern(), \"invariant\");\n@@ -978,6 +1013,0 @@\n-\/\/ Deprecated -- use FastHashCode() instead.\n-\n-intptr_t ObjectSynchronizer::identity_hash_value_for(Handle obj) {\n-  return FastHashCode(Thread::current(), obj());\n-}\n-\n@@ -987,0 +1016,3 @@\n+  if (EnableValhalla && h_obj->mark().is_inline_type()) {\n+    return false;\n+  }\n@@ -1200,0 +1232,4 @@\n+  if (EnableValhalla) {\n+    guarantee(!object->klass()->is_inline_klass(), \"Attempt to inflate inline type\");\n+  }\n+\n@@ -1204,1 +1240,1 @@\n-    assert(!mark.has_bias_pattern(), \"invariant\");\n+    assert(!UseBiasedLocking || !mark.has_bias_pattern(), \"invariant\");\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":46,"deletions":10,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -70,0 +70,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -1183,0 +1184,1 @@\n+  _return_buffered_value(nullptr),\n@@ -1242,1 +1244,0 @@\n-\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -431,0 +431,1 @@\n+ public:\n@@ -871,0 +872,1 @@\n+  friend class VTBuffer;\n@@ -928,0 +930,1 @@\n+  oop           _return_buffered_value; \/\/ buffered value being returned\n@@ -1374,0 +1377,3 @@\n+  oop return_buffered_value() const              { return _return_buffered_value; }\n+  void set_return_buffered_value(oop val)        { _return_buffered_value = val; }\n+\n@@ -1438,0 +1444,1 @@\n+  static ByteSize return_buffered_value_offset() { return byte_offset_of(JavaThread, _return_buffered_value); }\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -98,1 +98,1 @@\n-          assert(monitor->owner() == NULL || (!monitor->owner()->is_unlocked() && !monitor->owner()->has_bias_pattern()), \"object must be null or locked, and unbiased\");\n+          assert(monitor->owner() == NULL || (!monitor->owner()->is_unlocked() && (!UseBiasedLocking || !monitor->owner()->has_bias_pattern())), \"object must be null or locked, and unbiased\");\n","filename":"src\/hotspot\/share\/runtime\/vframeArray.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -461,0 +461,1 @@\n+    case T_INLINE_TYPE:\n","filename":"src\/hotspot\/share\/runtime\/vframe_hp.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -112,0 +112,1 @@\n+  template(ClassPrintLayout)                      \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -500,0 +500,4 @@\n+\n+void VM_PrintClassLayout::doit() {\n+  PrintClassLayout::print_class_layout(_out, _class_name);\n+}\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -229,1 +229,1 @@\n-  volatile_nonstatic_field(InstanceKlass,      _array_klasses,                                ObjArrayKlass*)                        \\\n+  volatile_nonstatic_field(InstanceKlass,      _array_klasses,                                ArrayKlass*)                        \\\n@@ -244,1 +244,1 @@\n-  nonstatic_field(InstanceKlass,               _misc_flags,                                   u2)                                    \\\n+  nonstatic_field(InstanceKlass,               _misc_flags,                                   u4)                                    \\\n@@ -1630,0 +1630,1 @@\n+  declare_c2_type(MachVEPNode, MachIdealNode)                             \\\n@@ -2313,0 +2314,2 @@\n+  declare_constant(InstanceKlass::_misc_invalid_inline_super)             \\\n+  declare_constant(InstanceKlass::_misc_invalid_identity_super)           \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -105,0 +105,1 @@\n+  DCmdFactory::register_DCmdFactory(new DCmdFactoryImpl<PrintClassLayoutDCmd>(full_export, true, false));\n@@ -138,1 +139,0 @@\n-\n@@ -905,1 +905,25 @@\n-#endif\n+\n+PrintClassLayoutDCmd::PrintClassLayoutDCmd(outputStream* output, bool heap) :\n+                                       DCmdWithParser(output, heap),\n+  _classname(\"classname\", \"Name of class whose layout should be printed. \",\n+             \"STRING\", true) {\n+  _dcmdparser.add_dcmd_argument(&_classname);\n+}\n+\n+void PrintClassLayoutDCmd::execute(DCmdSource source, TRAPS) {\n+  VM_PrintClassLayout printClassLayoutOp(output(), _classname.value());\n+  VMThread::execute(&printClassLayoutOp);\n+}\n+\n+int PrintClassLayoutDCmd::num_arguments() {\n+  ResourceMark rm;\n+  PrintClassLayoutDCmd* dcmd = new PrintClassLayoutDCmd(NULL, false);\n+  if (dcmd != NULL) {\n+    DCmdMark mark(dcmd);\n+    return dcmd->_dcmdparser.num_arguments();\n+  } else {\n+    return 0;\n+  }\n+}\n+\n+#endif \/\/ INCLUDE_SERVICES\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":26,"deletions":2,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -387,0 +387,25 @@\n+class PrintClassLayoutDCmd : public DCmdWithParser {\n+protected:\n+  DCmdArgument<char*> _classname; \/\/ lass name whose layout should be printed.\n+public:\n+  PrintClassLayoutDCmd(outputStream* output, bool heap);\n+  static const char* name() {\n+    return \"VM.class_print_layout\";\n+  }\n+  static const char* description() {\n+    return \"Print the layout of an instance of a class, including inlined fields. \"\n+           \"The name of each class is followed by the ClassLoaderData* of its ClassLoader, \"\n+           \"or \\\"null\\\" if loaded by the bootstrap class loader.\";\n+  }\n+  static const char* impact() {\n+      return \"Medium: Depends on number of loaded classes.\";\n+  }\n+  static const JavaPermission permission() {\n+    JavaPermission p = {\"java.lang.management.ManagementPermission\",\n+                        \"monitor\", NULL};\n+    return p;\n+  }\n+  static int num_arguments();\n+  virtual void execute(DCmdSource source, TRAPS);\n+};\n+\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.hpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -257,0 +257,2 @@\n+#define THREAD_AND_LOCATION_DECL                 TRAPS, const char* file, int line\n+#define THREAD_AND_LOCATION_ARGS                 THREAD, file, line\n","filename":"src\/hotspot\/share\/utilities\/exceptions.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -113,1 +113,1 @@\n-  assert(num_type_chars == 11, \"must have tested the right number of mappings\");\n+  assert(num_type_chars == 12, \"must have tested the right number of mappings\");\n@@ -131,0 +131,1 @@\n+      case T_INLINE_TYPE:\n@@ -196,0 +197,1 @@\n+  _type2aelembytes[T_INLINE_TYPE]  = heapOopSize;\n@@ -207,2 +209,2 @@\n-  JVM_SIGNATURE_VOID,    0,\n-  0, 0, 0, 0\n+  JVM_SIGNATURE_INLINE_TYPE, JVM_SIGNATURE_VOID,\n+  0, 0, 0, 0, 0\n@@ -224,0 +226,1 @@\n+  \"inline_type\",\n@@ -243,1 +246,1 @@\n-int type2size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, -1};\n+int type2size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, -1};\n@@ -260,6 +263,7 @@\n-  T_VOID,                  \/\/ T_VOID     = 14,\n-  T_ADDRESS,               \/\/ T_ADDRESS  = 15,\n-  T_NARROWOOP,             \/\/ T_NARROWOOP= 16,\n-  T_METADATA,              \/\/ T_METADATA = 17,\n-  T_NARROWKLASS,           \/\/ T_NARROWKLASS = 18,\n-  T_CONFLICT               \/\/ T_CONFLICT = 19,\n+  T_INLINE_TYPE,           \/\/ T_INLINE_TYPE = 14,\n+  T_VOID,                  \/\/ T_VOID     = 15,\n+  T_ADDRESS,               \/\/ T_ADDRESS  = 16,\n+  T_NARROWOOP,             \/\/ T_NARROWOOP= 17,\n+  T_METADATA,              \/\/ T_METADATA = 18,\n+  T_NARROWKLASS,           \/\/ T_NARROWKLASS = 19,\n+  T_CONFLICT               \/\/ T_CONFLICT = 20\n@@ -284,6 +288,7 @@\n-  T_VOID,    \/\/ T_VOID     = 14,\n-  T_ADDRESS, \/\/ T_ADDRESS  = 15,\n-  T_NARROWOOP, \/\/ T_NARROWOOP  = 16,\n-  T_METADATA,  \/\/ T_METADATA   = 17,\n-  T_NARROWKLASS, \/\/ T_NARROWKLASS  = 18,\n-  T_CONFLICT \/\/ T_CONFLICT = 19,\n+  T_OBJECT,  \/\/ T_INLINE_TYPE = 14,\n+  T_VOID,    \/\/ T_VOID     = 15,\n+  T_ADDRESS, \/\/ T_ADDRESS  = 16,\n+  T_NARROWOOP, \/\/ T_NARROWOOP  = 17,\n+  T_METADATA,  \/\/ T_METADATA   = 18,\n+  T_NARROWKLASS, \/\/ T_NARROWKLASS  = 19,\n+  T_CONFLICT \/\/ T_CONFLICT = 20\n@@ -308,6 +313,7 @@\n-  0,                         \/\/ T_VOID     = 14,\n-  T_OBJECT_aelem_bytes,      \/\/ T_ADDRESS  = 15,\n-  T_NARROWOOP_aelem_bytes,   \/\/ T_NARROWOOP= 16,\n-  T_OBJECT_aelem_bytes,      \/\/ T_METADATA = 17,\n-  T_NARROWKLASS_aelem_bytes, \/\/ T_NARROWKLASS= 18,\n-  0                          \/\/ T_CONFLICT = 19,\n+  T_INLINE_TYPE_aelem_bytes,   \/\/ T_INLINE_TYPE = 14,\n+  0,                         \/\/ T_VOID     = 15,\n+  T_OBJECT_aelem_bytes,      \/\/ T_ADDRESS  = 16,\n+  T_NARROWOOP_aelem_bytes,   \/\/ T_NARROWOOP= 17,\n+  T_OBJECT_aelem_bytes,      \/\/ T_METADATA = 18,\n+  T_NARROWKLASS_aelem_bytes, \/\/ T_NARROWKLASS= 19,\n+  0                          \/\/ T_CONFLICT = 20\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.cpp","additions":28,"deletions":22,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -571,0 +571,9 @@\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ Prototyping\n+\/\/ \"Code Missing Here\" macro, un-define when integrating back from prototyping stage and break\n+\/\/ compilation on purpose (i.e. \"forget me not\")\n+#define PROTOTYPE\n+#ifdef PROTOTYPE\n+#define CMH(m)\n+#endif\n+\n@@ -656,6 +665,7 @@\n-  T_VOID        = 14,\n-  T_ADDRESS     = 15,\n-  T_NARROWOOP   = 16,\n-  T_METADATA    = 17,\n-  T_NARROWKLASS = 18,\n-  T_CONFLICT    = 19, \/\/ for stack value type with conflicting contents\n+  T_INLINE_TYPE = 14,\n+  T_VOID        = 15,\n+  T_ADDRESS     = 16,\n+  T_NARROWOOP   = 17,\n+  T_METADATA    = 18,\n+  T_NARROWKLASS = 19,\n+  T_CONFLICT    = 20, \/\/ for stack value type with conflicting contents\n@@ -676,0 +686,1 @@\n+    F(JVM_SIGNATURE_INLINE_TYPE, T_INLINE_TYPE, N) \\\n@@ -701,1 +712,1 @@\n-  return (t == T_OBJECT || t == T_ARRAY);\n+  return (t == T_OBJECT || t == T_ARRAY || t == T_INLINE_TYPE);\n@@ -754,1 +765,2 @@\n-  T_VOID_size        = 0\n+  T_VOID_size        = 0,\n+  T_INLINE_TYPE_size = 1\n@@ -784,0 +796,1 @@\n+  T_INLINE_TYPE_aelem_bytes = 8,\n@@ -787,0 +800,1 @@\n+  T_INLINE_TYPE_aelem_bytes = 4,\n@@ -876,1 +890,1 @@\n-  vtos = 9,             \/\/ tos not cached\n+  vtos = 9,             \/\/ tos not cached,\n@@ -893,1 +907,2 @@\n-    case T_ARRAY  : \/\/ fall through\n+    case T_INLINE_TYPE: \/\/ fall through\n+    case T_ARRAY  :   \/\/ fall through\n@@ -1211,0 +1226,6 @@\n+\/\/ TEMP!!!!\n+\/\/ This should be removed after LW2 arrays are implemented (JDK-8220790).\n+\/\/ It's an alias to (EnableValhalla && (FlatArrayElementMaxSize != 0)),\n+\/\/ which is actually not 100% correct, but works for the current set of C1\/C2\n+\/\/ implementation and test cases.\n+#define UseFlatArray (EnableValhalla && (FlatArrayElementMaxSize != 0))\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":31,"deletions":10,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+import java.lang.reflect.InaccessibleObjectException;\n@@ -501,0 +502,1 @@\n+        boolean isPrimitiveClass = cl.isPrimitiveClass();\n@@ -572,0 +574,2 @@\n+            } else if (isPrimitiveClass && writeReplaceMethod == null) {\n+                deserializeEx = new ExceptionInfo(name, \"primitive class\");\n@@ -1569,1 +1573,1 @@\n-        } catch (NoSuchMethodException ex) {\n+        } catch (NoSuchMethodException | InaccessibleObjectException ex) {\n@@ -1899,0 +1903,1 @@\n+                \/\/ Skip IdentityObject to keep the computed SVUID the same.\n@@ -1900,1 +1905,2 @@\n-                    dout.writeUTF(ifaceNames[i]);\n+                    if (!\"java.lang.IdentityObject\".equals(ifaceNames[i]))\n+                        dout.writeUTF(ifaceNames[i]);\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectStreamClass.java","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -201,3 +201,4 @@\n-    private static final int ANNOTATION= 0x00002000;\n-    private static final int ENUM      = 0x00004000;\n-    private static final int SYNTHETIC = 0x00001000;\n+    private static final int ANNOTATION = 0x00002000;\n+    private static final int ENUM       = 0x00004000;\n+    private static final int SYNTHETIC  = 0x00001000;\n+    private static final int PRIMITIVE_CLASS = 0x00000100;\n@@ -235,2 +236,3 @@\n-        return (isInterface() ? \"interface \" : (isPrimitive() ? \"\" : \"class \"))\n-            + getName();\n+        return (isPrimitiveClass() ? \"primitive \" : \"\")\n+               + (isInterface() ? \"interface \" : (isPrimitive() ? \"\" : \"class \"))\n+               + getName();\n@@ -297,0 +299,3 @@\n+                if (isPrimitiveClass()) {\n+                    sb.append(\"primitive \");\n+                }\n@@ -471,2 +476,2 @@\n-                                            ClassLoader loader,\n-                                            Class<?> caller)\n+                                    ClassLoader loader,\n+                                    Class<?> caller)\n@@ -549,0 +554,162 @@\n+    \/**\n+     * Returns {@code true} if this class is a primitive class.\n+     *\n+     * @return {@code true} if this class is a primitive class, otherwise {@code false}\n+     * @since Valhalla\n+     *\/\n+    public boolean isPrimitiveClass() {\n+        return (this.getModifiers() & PRIMITIVE_CLASS) != 0;\n+    }\n+\n+    \/**\n+     * Returns an {@code Optional<Class>} object representing the <em>primitive value type<\/em>\n+     * of this class if this {@code Class} represents the <em>reference type<\/em>\n+     * of a {@linkplain #isPrimitiveClass() primitive class}.\n+     * If this {@code Class} represents the value type of a primitive class,\n+     * then this method returns this class.\n+     * Otherwise an empty {@link Optional} is returned.\n+     *\n+     * @return the {@code Optional<Class>} representing the primitive value type of\n+     *         this class if this class is either the value type\n+     *         or the reference type of a primitive class;\n+     *         an empty {@link Optional} otherwise\n+     * @since Valhalla\n+     *\/\n+    public Optional<Class<?>> valueType() {\n+        if (isPrimitive() || isInterface() || isArray())\n+            return Optional.empty();\n+\n+        Class<?>[] valRefTypes = getPrimitiveTypes();\n+        return valRefTypes.length > 0 ? Optional.of(valRefTypes[0]) : Optional.empty();\n+    }\n+\n+    \/**\n+     * Returns a {@code Class} object representing the reference type\n+     * of this class.\n+     * <p>\n+     * If this {@code Class} represents a {@linkplain #isPrimitiveClass()\n+     * primitive reference type}, then this method\n+     * returns the <em>primitive reference type<\/em> type of this primitive class.\n+     * <p>\n+     * If this {@code Class} represents the reference type\n+     * of a primitive class, then this method returns this class.\n+     * <p>\n+     * If this class is an identity class, then this method returns this class.\n+     * <p>\n+     * Otherwise this method returns an empty {@code Optional}.\n+     *\n+     * @return the {@code Optional<Class>} object representing the reference type for\n+     *         this class, if present; an empty {@link Optional} otherwise.\n+     * @since Valhalla\n+     *\/\n+    public Optional<Class<?>> referenceType() {\n+        if (isPrimitive()) return Optional.empty();\n+        if (isInterface() || isArray()) return Optional.of(this);\n+\n+        Class<?>[] valRefTypes = getPrimitiveTypes();\n+        return valRefTypes.length == 2 ? Optional.of(valRefTypes[1]) : Optional.empty();\n+    }\n+\n+    \/*\n+     * Returns true if this Class object represents a primitive reference\n+     * type for a primitive class.\n+     *\n+     * A primitive reference type must be a sealed abstract class that\n+     * permits the primitive value type to extend.  The primitive value type\n+     * and primitive reference type for a primitive type must be of the same package.\n+     *\/\n+    private boolean isPrimitiveReferenceType() {\n+        if (isPrimitive() || isArray() || isInterface() || isPrimitiveClass())\n+            return false;\n+\n+        int mods = getModifiers();\n+        if (!Modifier.isAbstract(mods)) {\n+            return false;\n+        }\n+\n+        Class<?>[] valRefTypes = getPrimitiveTypes();\n+        return valRefTypes.length == 2 && valRefTypes[1] == this;\n+    }\n+\n+    private transient Class<?>[] primitiveTypes;\n+    private Class<?>[] getPrimitiveTypes() {\n+        if (isPrimitive() || isArray() || isInterface())\n+            return null;\n+\n+        Class<?>[] valRefTypes = primitiveTypes;\n+        if (valRefTypes == null) {\n+            \/\/ So newPrimitiveTypeArray is called without holding any lock to\n+            \/\/ avoid potential deadlock when multiple threads attempt to\n+            \/\/ initialize the primitive types for C and E where D is\n+            \/\/ the superclass of both C and E (which is an error case)\n+            valRefTypes = newTypeArrayForPrimitiveClass();\n+        }\n+        synchronized (this) {\n+            \/\/ set the value and reference types if not set\n+            if (primitiveTypes == null) {\n+                primitiveTypes = valRefTypes;\n+            }\n+        }\n+        return primitiveTypes;\n+    }\n+\n+    \/*\n+     * Returns an array of Class objects whose element at index 0 represents the\n+     * primitive value type and element at index 1 represents the\n+     * primitive reference type, if present.\n+     *\n+     * If this Class object is neither a primitive value type nor\n+     * a primitive reference type for a primitive class, then an empty array\n+     * is returned.\n+     *\/\n+    private Class<?>[] newTypeArrayForPrimitiveClass() {\n+        if (isPrimitive() || isArray() || isInterface())\n+            return null;\n+\n+        if (isPrimitiveClass()) {\n+            Class<?> superClass = getSuperclass();\n+            if (superClass != Object.class && superClass.isPrimitiveReferenceType()) {\n+                return new Class<?>[] { this, superClass };\n+            } else {\n+                return new Class<?>[] { this };\n+            }\n+        } else {\n+            Class<?> valType = primitiveValueType();\n+            if (valType != null) {\n+                return new Class<?>[] { valType, this};\n+            } else {\n+                return EMPTY_CLASS_ARRAY;\n+            }\n+        }\n+    }\n+\n+    \/*\n+     * Returns the primitive value type if this Class represents\n+     * a primitive reference type.  If this class is a primitive class\n+     * then this method returns this class.  Otherwise, returns null.\n+     *\/\n+    private Class<?> primitiveValueType() {\n+        if (isPrimitive() || isArray() || isInterface())\n+            return null;\n+\n+        if (isPrimitiveClass())\n+            return this;\n+\n+        int mods = getModifiers();\n+        if (!Modifier.isAbstract(mods)) {\n+            return null;\n+        }\n+\n+        \/\/ A primitive reference type must be a sealed abstract class\n+        \/\/ that permits the primitive class type to extend.\n+        \/\/ The primitive class project type and primitive reference type for\n+        \/\/ a primitive class type must be of the same package.\n+        Class<?>[] subclasses = getPermittedSubclasses0();\n+        if ((subclasses.length == 1) &&\n+                (subclasses[0].isPrimitiveClass()) &&\n+                (getPackageName().equals(subclasses[0].getPackageName()))) {\n+            return subclasses[0];\n+        }\n+        return null;\n+    }\n+\n@@ -830,0 +997,2 @@\n+     * <tr><th scope=\"row\"> {@linkplain #isPrimitiveClass() primitive class} with <a href=\"ClassLoader.html#binary-name\">binary name<\/a> <i>N<\/i>\n+     *                                      <td style=\"text-align:center\"> {@code Q}<em>N<\/em>{@code ;}\n@@ -848,0 +1017,2 @@\n+     * Point.class.getName()\n+     *     returns \"Point\"\n@@ -850,0 +1021,4 @@\n+     * (new Point[3]).getClass().getName()\n+     *     returns \"[QPoint;\"\n+     * (new Point.ref[3][4]).getClass().getName()\n+     *     returns \"[[LPoint$ref;\"\n@@ -1282,1 +1457,0 @@\n-\n@@ -1293,1 +1467,0 @@\n-\n@@ -1677,1 +1850,1 @@\n-                return cl.getName() + \"[]\".repeat(dimensions);\n+                return cl.getTypeName() + \"[]\".repeat(dimensions);\n@@ -3837,1 +4010,3 @@\n-     * null and is not assignable to the type T.\n+     * {@code null} and is not assignable to the type T.\n+     * @throws NullPointerException if this is an {@linkplain #isPrimitiveClass()\n+     * primitive class} and the object is {@code null}\n@@ -3844,0 +4019,3 @@\n+        if (isPrimitiveClass() && obj == null)\n+            throw new NullPointerException(getName() + \" is a primitive class\");\n+\n@@ -4139,1 +4317,1 @@\n-         return TypeAnnotationParser.buildAnnotatedInterfaces(getRawTypeAnnotations(), getConstantPool(), this);\n+        return TypeAnnotationParser.buildAnnotatedInterfaces(getRawTypeAnnotations(), getConstantPool(), this);\n@@ -4352,1 +4530,3 @@\n-        } else if (isHidden()) {\n+        }\n+        String typeDesc = isPrimitiveClass() ? \"Q\" : \"L\";\n+        if (isHidden()) {\n@@ -4355,1 +4535,1 @@\n-            return \"L\" + name.substring(0, index).replace('.', '\/')\n+            return typeDesc + name.substring(0, index).replace('.', '\/')\n@@ -4358,1 +4538,1 @@\n-            return \"L\" + getName().replace('.', '\/') + \";\";\n+            return typeDesc + getName().replace('.', '\/') + \";\";\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":195,"deletions":15,"binary":false,"changes":210,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2016, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2017, Oracle and\/or its affiliates. All rights reserved.\n@@ -37,2 +37,0 @@\n-import static java.lang.invoke.LambdaForm.BasicType.V_TYPE_NUM;\n-import static java.lang.invoke.LambdaForm.BasicType.V_TYPE_NUM;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/BoundMethodHandle.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -999,1 +999,2 @@\n-        if (member.isConstructor())  return false;\n+        if (member.isObjectConstructorOrStaticInitMethod())  return false;\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/InvokerBytecodeGenerator.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -284,0 +284,4 @@\n+        GET_VALUE(\"getValue\"),\n+        PUT_VALUE(\"putValue\"),\n+        GET_VALUE_VOLATILE(\"getValueVolatile\"),\n+        PUT_VALUE_VOLATILE(\"putValueVolatile\"),\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/LambdaForm.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+import java.lang.invoke.MethodHandles.Lookup;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/LambdaFormEditor.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -194,1 +194,1 @@\n-        if (isConstructor() && getReferenceKind() == REF_newInvokeSpecial)\n+        if (isObjectConstructor() && getReferenceKind() == REF_newInvokeSpecial)\n@@ -286,1 +286,1 @@\n-        } else if (isConstructor()) {\n+        } else if (isObjectConstructor()) {\n@@ -430,0 +430,2 @@\n+        \/\/ all fields declared in a value type are effectively final\n+        assert(!clazz.isPrimitiveClass() || !isField() || Modifier.isFinal(flags));\n@@ -451,5 +453,7 @@\n-    static final int BRIDGE    = 0x00000040;\n-    static final int VARARGS   = 0x00000080;\n-    static final int SYNTHETIC = 0x00001000;\n-    static final int ANNOTATION= 0x00002000;\n-    static final int ENUM      = 0x00004000;\n+    static final int BRIDGE      = 0x00000040;\n+    static final int VARARGS     = 0x00000080;\n+    static final int SYNTHETIC   = 0x00001000;\n+    static final int ANNOTATION  = 0x00002000;\n+    static final int ENUM        = 0x00004000;\n+    static final int FLATTENED   = 0x00008000;\n+\n@@ -469,0 +473,12 @@\n+    \/** Query whether this member is a flattened field *\/\n+    public boolean isFlattened() { return (flags & FLATTENED) == FLATTENED; }\n+\n+    \/** Query whether this member is a field of a primitive class. *\/\n+    public boolean isInlineableField()  {\n+        if (isField()) {\n+            Class<?> type = getFieldType();\n+            return type.isPrimitiveClass();\n+        }\n+        return false;\n+    }\n+\n@@ -476,6 +492,6 @@\n-            IS_METHOD        = MN_IS_METHOD,        \/\/ method (not constructor)\n-            IS_CONSTRUCTOR   = MN_IS_CONSTRUCTOR,   \/\/ constructor\n-            IS_FIELD         = MN_IS_FIELD,         \/\/ field\n-            IS_TYPE          = MN_IS_TYPE,          \/\/ nested type\n-            CALLER_SENSITIVE = MN_CALLER_SENSITIVE, \/\/ @CallerSensitive annotation detected\n-            TRUSTED_FINAL    = MN_TRUSTED_FINAL;    \/\/ trusted final field\n+            IS_METHOD             = MN_IS_METHOD,              \/\/ method (not object constructor)\n+            IS_OBJECT_CONSTRUCTOR = MN_IS_OBJECT_CONSTRUCTOR,  \/\/ object constructor\n+            IS_FIELD              = MN_IS_FIELD,               \/\/ field\n+            IS_TYPE               = MN_IS_TYPE,                \/\/ nested type\n+            CALLER_SENSITIVE      = MN_CALLER_SENSITIVE,       \/\/ @CallerSensitive annotation detected\n+            TRUSTED_FINAL         = MN_TRUSTED_FINAL;    \/\/ trusted final field\n@@ -484,2 +500,2 @@\n-    static final int ALL_KINDS = IS_METHOD | IS_CONSTRUCTOR | IS_FIELD | IS_TYPE;\n-    static final int IS_INVOCABLE = IS_METHOD | IS_CONSTRUCTOR;\n+    static final int ALL_KINDS = IS_METHOD | IS_OBJECT_CONSTRUCTOR | IS_FIELD | IS_TYPE;\n+    static final int IS_INVOCABLE = IS_METHOD | IS_OBJECT_CONSTRUCTOR;\n@@ -502,2 +518,6 @@\n-    public boolean isConstructor() {\n-        return testAllFlags(IS_CONSTRUCTOR);\n+    public boolean isObjectConstructor() {\n+        return testAllFlags(IS_OBJECT_CONSTRUCTOR);\n+    }\n+    \/** Query whether this member is an object constructor or static <init> factory *\/\n+    public boolean isObjectConstructorOrStaticInitMethod() {\n+        return isObjectConstructor() || (getName().equals(CONSTRUCTOR_NAME) && testAllFlags(IS_METHOD));\n@@ -634,1 +654,1 @@\n-    public MemberName asConstructor() {\n+    public MemberName asObjectConstructor() {\n@@ -675,2 +695,8 @@\n-        if (this.type == null)\n-            this.type = new Object[] { void.class, ctor.getParameterTypes() };\n+        if (this.type == null) {\n+            Class<?> rtype = void.class;\n+            if (isStatic()) {  \/\/ a static init factory, not a true constructor\n+                rtype = getDeclaringClass();\n+                \/\/ FIXME: If it's a hidden class, this sig won't work.\n+            }\n+            this.type = new Object[] { rtype, ctor.getParameterTypes() };\n+        }\n@@ -817,1 +843,1 @@\n-        int initFlags = (name != null && name.equals(CONSTRUCTOR_NAME) ? IS_CONSTRUCTOR : IS_METHOD);\n+        int initFlags = (name != null && name.equals(CONSTRUCTOR_NAME) && type.returnType() == void.class ? IS_OBJECT_CONSTRUCTOR : IS_METHOD);\n@@ -835,1 +861,1 @@\n-            kindFlags = IS_CONSTRUCTOR;\n+            kindFlags = IS_OBJECT_CONSTRUCTOR;\n@@ -958,1 +984,1 @@\n-        else if (isConstructor())\n+        else if (isObjectConstructor())\n@@ -971,1 +997,1 @@\n-        else if (isConstructor())\n+        else if (isObjectConstructor())\n@@ -1152,1 +1178,1 @@\n-        \/** Return a list of all constructors defined by the given class.\n+        \/** Return a list of all object constructors defined by the given class.\n@@ -1156,2 +1182,2 @@\n-        public List<MemberName> getConstructors(Class<?> defc, Class<?> lookupClass) {\n-            return getMembers(defc, null, null, IS_CONSTRUCTOR, lookupClass);\n+        public List<MemberName> getObjectConstructors(Class<?> defc, Class<?> lookupClass) {\n+            return getMembers(defc, null, null, IS_OBJECT_CONSTRUCTOR, lookupClass);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MemberName.java","additions":53,"deletions":27,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -1486,0 +1486,4 @@\n+            @Override\n+            public String inlineObjectToString(Object o) {\n+                return ValueBootstrapMethods.inlineObjectToString(o);\n+            }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandleImpl.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -117,8 +117,8 @@\n-            MN_IS_METHOD           = 0x00010000, \/\/ method (not constructor)\n-            MN_IS_CONSTRUCTOR      = 0x00020000, \/\/ constructor\n-            MN_IS_FIELD            = 0x00040000, \/\/ field\n-            MN_IS_TYPE             = 0x00080000, \/\/ nested type\n-            MN_CALLER_SENSITIVE    = 0x00100000, \/\/ @CallerSensitive annotation detected\n-            MN_TRUSTED_FINAL       = 0x00200000, \/\/ trusted final field\n-            MN_REFERENCE_KIND_SHIFT = 24, \/\/ refKind\n-            MN_REFERENCE_KIND_MASK = 0x0F000000 >> MN_REFERENCE_KIND_SHIFT,\n+            MN_IS_METHOD             = 0x00010000, \/\/ method (not object constructor)\n+            MN_IS_OBJECT_CONSTRUCTOR = 0x00020000, \/\/ object constructor\n+            MN_IS_FIELD              = 0x00040000, \/\/ field\n+            MN_IS_TYPE               = 0x00080000, \/\/ nested type\n+            MN_CALLER_SENSITIVE      = 0x00100000, \/\/ @CallerSensitive annotation detected\n+            MN_TRUSTED_FINAL         = 0x00200000, \/\/ trusted final field\n+            MN_REFERENCE_KIND_SHIFT  = 24, \/\/ refKind\n+            MN_REFERENCE_KIND_MASK   = 0x0F000000 >> MN_REFERENCE_KIND_SHIFT,\n@@ -126,2 +126,2 @@\n-            MN_SEARCH_SUPERCLASSES = 0x00100000,\n-            MN_SEARCH_INTERFACES   = 0x00200000;\n+            MN_SEARCH_SUPERCLASSES   = 0x00100000,\n+            MN_SEARCH_INTERFACES     = 0x00200000;\n@@ -181,1 +181,1 @@\n-    static boolean refKindIsConstructor(byte refKind) {\n+    static boolean refKindIsObjectConstructor(byte refKind) {\n@@ -590,1 +590,1 @@\n-            sb.append(getCharType(pt));\n+            sb.append(getCharErasedType(pt));\n@@ -592,1 +592,1 @@\n-        sb.append('_').append(getCharType(guardType.returnType()));\n+        sb.append('_').append(getCharErasedType(guardType.returnType()));\n@@ -595,1 +595,1 @@\n-    static char getCharType(Class<?> pt) {\n+    static char getCharErasedType(Class<?> pt) {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandleNatives.java","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -2595,0 +2595,6 @@\n+            \/\/ resolveOrFail could return a non-static <init> method if present\n+            \/\/ detect and throw NSME before producing a MethodHandle\n+            if (!method.isStatic() && name.equals(\"<init>\")) {\n+                throw new NoSuchMethodException(\"illegal method name: \" + name);\n+            }\n+\n@@ -2740,0 +2746,7 @@\n+         *\n+         * @apiNote\n+         * This method does not find a static {@code <init>} factory method as it is invoked\n+         * via {@code invokestatic} bytecode as opposed to {@code invokespecial} for an\n+         * object constructor.  To look up static {@code <init>} factory method, use\n+         * the {@link #findStatic(Class, String, MethodType) findStatic} method.\n+         *\n@@ -2755,0 +2768,3 @@\n+            if (type.returnType() != void.class) {\n+                throw new NoSuchMethodException(\"Constructors must have void return type: \" + refc.getName());\n+            }\n@@ -3430,1 +3446,1 @@\n-            assert(ctor.isConstructor());\n+            assert(ctor.isObjectConstructorOrStaticInitMethod());\n@@ -3433,1 +3449,9 @@\n-            return lookup.getDirectConstructorNoSecurityManager(ctor.getDeclaringClass(), ctor);\n+            if (ctor.isObjectConstructor()) {\n+                assert(ctor.getReturnType() == void.class);\n+                return lookup.getDirectConstructorNoSecurityManager(ctor.getDeclaringClass(), ctor);\n+            } else {\n+                \/\/ static init factory is a static method\n+                assert(ctor.isMethod() && ctor.getReturnType() == ctor.getDeclaringClass() && ctor.getReferenceKind() == REF_invokeStatic);\n+                assert(!MethodHandleNatives.isCallerSensitive(ctor));  \/\/ must not be caller-sensitive\n+                return lookup.getDirectMethodNoSecurityManager(ctor.getReferenceKind(), ctor.getDeclaringClass(), ctor, lookup);\n+            }\n@@ -3698,2 +3722,5 @@\n-            if (name.startsWith(\"<\") && refKind != REF_newInvokeSpecial)\n-                throw new NoSuchMethodException(\"illegal method name: \"+name);\n+            \/\/ \"<init>\" can only be invoked via invokespecial or it's a static init factory\n+            if (name.startsWith(\"<\") && refKind != REF_newInvokeSpecial &&\n+                    !(refKind == REF_invokeStatic && name.equals(\"<init>\"))) {\n+                    throw new NoSuchMethodException(\"illegal method name: \" + name);\n+            }\n@@ -3809,1 +3836,1 @@\n-            if (m.isConstructor())\n+            if (m.isObjectConstructor())\n@@ -4110,1 +4137,1 @@\n-            assert(ctor.isConstructor());\n+            assert(ctor.isObjectConstructor());\n@@ -4300,0 +4327,3 @@\n+        if (arrayClass.isPrimitiveClass()) {\n+            throw new UnsupportedOperationException();\n+        }\n@@ -5061,1 +5091,7 @@\n-        return type.isPrimitive() ?  zero(Wrapper.forPrimitiveType(type), type) : zero(Wrapper.OBJECT, type);\n+        if (type.isPrimitive()) {\n+            return zero(Wrapper.forPrimitiveType(type), type);\n+        } else if (type.isPrimitiveClass()) {\n+            throw new UnsupportedOperationException();\n+        } else {\n+            return zero(Wrapper.OBJECT, type);\n+        }\n@@ -5091,1 +5127,1 @@\n-        MethodType mtype = methodType(ptype, ptype);\n+        MethodType mtype = MethodType.methodType(ptype, ptype);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandles.java","additions":44,"deletions":8,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -34,1 +34,0 @@\n-import java.lang.reflect.Parameter;\n@@ -37,2 +36,0 @@\n-import java.util.LinkedHashMap;\n-import java.util.Map;\n@@ -49,1 +46,0 @@\n-import static java.util.stream.Collectors.toList;\n@@ -64,1 +60,6 @@\n-                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields\n+                if (f.isFlattened()) {\n+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields\n+                        ? new VarHandleValues.FieldInstanceReadOnly(refc, foffset, type)\n+                        : new VarHandleValues.FieldInstanceReadWrite(refc, foffset, type));\n+                } else {\n+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields\n@@ -67,0 +68,1 @@\n+                }\n@@ -125,3 +127,9 @@\n-                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields\n-                       ? new VarHandleReferences.FieldStaticReadOnly(base, foffset, type)\n-                       : new VarHandleReferences.FieldStaticReadWrite(base, foffset, type));\n+                if (f.isFlattened()) {\n+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields\n+                            ? new VarHandleValues.FieldStaticReadOnly(refc, foffset, type)\n+                            : new VarHandleValues.FieldStaticReadWrite(refc, foffset, type));\n+                } else {\n+                    return f.isFinal() && !isWriteAllowedOnFinalFields\n+                            ? new VarHandleReferences.FieldStaticReadOnly(base, foffset, type)\n+                            : new VarHandleReferences.FieldStaticReadWrite(base, foffset, type);\n+                }\n@@ -218,1 +226,7 @@\n-            return maybeAdapt(new VarHandleReferences.Array(aoffset, ashift, arrayClass));\n+            \/\/ the redundant componentType.isValue() check is there to\n+            \/\/ minimize the performance impact to non-value array.\n+            \/\/ It should be removed when Unsafe::isFlattenedArray is intrinsified.\n+\n+            return maybeAdapt(componentType.isPrimitiveClass() && UNSAFE.isFlattenedArray(arrayClass)\n+                ? new VarHandleValues.Array(aoffset, ashift, arrayClass)\n+                : new VarHandleReferences.Array(aoffset, ashift, arrayClass));\n@@ -620,1 +634,1 @@\n-            } else if (MethodHandleNatives.refKindIsConstructor(refKind)) {\n+            } else if (MethodHandleNatives.refKindIsObjectConstructor(refKind)) {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/VarHandles.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -739,1 +739,3 @@\n-     *     hidden class}; and<\/li>\n+     *     hidden class};<\/li>\n+     * <li>the field's declaring class is not a {@linkplain Class#isPrimitiveClass()\n+     *     primitive class}; and<\/li>\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Field.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -456,1 +456,1 @@\n-        visit(V14, accessFlags, dotToSlash(className), null,\n+        visit(V17, accessFlags, dotToSlash(className), null,\n@@ -866,1 +866,5 @@\n-                mv.visitTypeInsn(CHECKCAST, dotToSlash(type.getName()));\n+                String internalName = dotToSlash(type.getName());\n+                if (type.isPrimitiveClass()) {\n+                    internalName = 'Q' + internalName + \";\";\n+                }\n+                mv.visitTypeInsn(CHECKCAST, internalName);\n@@ -917,3 +921,5 @@\n-         * class to get its Class object at runtime.  The code is written to\n-         * the supplied stream.  Note that the code generated by this method\n-         * may cause the checked ClassNotFoundException to be thrown.\n+         * class to get its Class object at runtime.  And also generate code\n+         * to invoke Class.asPrimaryType if the class is regular value type.\n+         *\n+         * The code is written to the supplied stream.  Note that the code generated\n+         * by this method may caused the checked ClassNotFoundException to be thrown.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/ProxyGenerator.java","additions":12,"deletions":6,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -133,1 +133,0 @@\n-\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -417,0 +417,19 @@\n+    public boolean isPrimitiveClass() {\n+        return (flags() & PRIMITIVE_CLASS) != 0;\n+    }\n+\n+    \/**\n+     * Is this a *derived* reference projection symbol ??\n+     *\/\n+    public boolean isReferenceProjection() {\n+        return false;\n+    }\n+\n+    \/**\n+     * If this is the symbol for a reference projection class, what is the class for which\n+     * this is a projection ??\n+     *\/\n+    public ClassSymbol valueProjection() {\n+        return null;\n+    }\n+\n@@ -458,1 +477,7 @@\n-        return name == name.table.names.init;\n+        return name == name.table.names.init && (flags() & STATIC) == 0;\n+    }\n+\n+    \/** Is this symbol a value factory?\n+     *\/\n+    public boolean isValueFactory() {\n+        return ((name == name.table.names.init && this.type.getReturnType().tsym == this.owner));\n@@ -521,0 +546,2 @@\n+     * 'outermost' being a lexical construct, should transcend\n+     *  projections\n@@ -529,1 +556,1 @@\n-        return (ClassSymbol) prev;\n+        return (ClassSymbol) (prev!= null && prev.isReferenceProjection() ? prev.valueProjection() : prev);\n@@ -1355,1 +1382,2 @@\n-                                              type.getMetadata());\n+                                              type.getMetadata(),\n+                                              type.isReferenceProjection());\n@@ -1363,1 +1391,1 @@\n-            else\n+\n@@ -2017,1 +2045,1 @@\n-                types.asSuper(owner.type, other.owner) != null &&\n+                types.asSuper(owner.type.referenceProjectionOrSelf(), other.owner) != null &&\n@@ -2086,1 +2114,1 @@\n-                types.asSuper(owner.type, other.owner) != null) {\n+                types.asSuper(owner.type.referenceProjectionOrSelf(), other.owner) != null) {\n@@ -2135,0 +2163,1 @@\n+\n@@ -2442,1 +2471,1 @@\n-        \/** Access codes for dereferencing, assignment,\n+        \/** Access codes for dereferencing, assignment, withfield\n@@ -2462,1 +2491,2 @@\n-            FIRSTASGOP(12, Tag.NO_TAG);\n+            WITHFIELD(12, Tag.WITHFIELD),\n+            FIRSTASGOP(14, Tag.NO_TAG);\n@@ -2495,0 +2525,2 @@\n+                    case WITHFIELD:\n+                        return AccessCode.WITHFIELD.code;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Symbol.java","additions":40,"deletions":8,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -238,0 +238,36 @@\n+    public boolean isPrimitiveClass() {\n+        return false;\n+    }\n+\n+    \/**\n+     * @return true IFF the receiver is a reference projection of an inline type and false\n+     * for primitives or plain references\n+     *\/\n+    public boolean isReferenceProjection() {\n+        return false;\n+    }\n+\n+    \/**\n+     * @return the value projection type IFF the receiver is a reference projection of an inline type\n+     * and null otherwise\n+     *\/\n+    public Type valueProjection() {\n+        return null;\n+    }\n+\n+    \/**\n+     * @return the reference projection type IFF the receiver is a primitive class type\n+     * and null otherwise\n+     *\/\n+    public Type referenceProjection() {\n+        return null;\n+    }\n+\n+    \/**\n+     * @return the reference projection type IFF the receiver is a primitive class type or self otherwise.\n+     *\/\n+    public Type referenceProjectionOrSelf() {\n+        Type projection = referenceProjection();\n+        return projection != null ? projection : this;\n+    }\n+\n@@ -252,1 +288,1 @@\n-            else return new ClassType(outer1, typarams1, t.tsym, t.metadata) {\n+            else return new ClassType(outer1, typarams1, t.tsym, t.metadata, t.isReferenceProjection()) {\n@@ -946,0 +982,34 @@\n+    public static class ConstantPoolQType implements PoolConstant {\n+\n+        public final Type type;\n+        final Types types;\n+\n+        public ConstantPoolQType(Type type, Types types) {\n+            this.type = type;\n+            this.types = types;\n+        }\n+\n+        @Override\n+        public Object poolKey(Types types) {\n+            return this;\n+        }\n+\n+        @Override\n+        public int poolTag() {\n+            return ClassFile.CONSTANT_Class;\n+        }\n+\n+        public int hashCode() {\n+            return types.hashCode(type);\n+        }\n+\n+        public boolean equals(Object obj) {\n+            return (obj instanceof ConstantPoolQType) &&\n+                    types.isSameType(type, ((ConstantPoolQType)obj).type);\n+        }\n+\n+        public String toString() {\n+            return type.toString();\n+        }\n+    }\n+\n@@ -977,0 +1047,9 @@\n+        \/** The 'other' projection: If 'this' is type of a primitive class, then 'projection' is the\n+         *  reference projection type and vice versa. Lazily initialized, not to be accessed directly.\n+        *\/\n+        public ClassType projection;\n+\n+        \/** Is this class type a reference projection of a primitive class type ?\n+         *\/\n+        private boolean isReferenceProjection;\n+\n@@ -978,1 +1057,1 @@\n-            this(outer, typarams, tsym, TypeMetadata.EMPTY);\n+            this(outer, typarams, tsym, TypeMetadata.EMPTY, false);\n@@ -983,0 +1062,5 @@\n+            this(outer, typarams, tsym, metadata, false);\n+        }\n+\n+        public ClassType(Type outer, List<Type> typarams, TypeSymbol tsym,\n+                         TypeMetadata metadata, boolean isReferenceProjection) {\n@@ -984,1 +1068,1 @@\n-            this.outer_field = outer;\n+            this.outer_field = outer != null && outer.isReferenceProjection() ? outer.valueProjection() : outer;\n@@ -989,0 +1073,1 @@\n+            this.isReferenceProjection = isReferenceProjection;\n@@ -997,1 +1082,1 @@\n-            return new ClassType(outer_field, typarams_field, tsym, md) {\n+            return new ClassType(outer_field, typarams_field, tsym, md, isReferenceProjection) {\n@@ -1015,1 +1100,1 @@\n-            return new ClassType(getEnclosingType(), typarams_field, tsym, metadata) {\n+            return new ClassType(getEnclosingType(), typarams_field, tsym, metadata, isReferenceProjection) {\n@@ -1042,0 +1127,5 @@\n+            if (isReferenceProjection) {\n+                buf.append('.');\n+                buf.append(tsym.name.table.names.ref);\n+            }\n+\n@@ -1073,2 +1163,4 @@\n-                } else if (longform) {\n-                    return sym.getQualifiedName().toString();\n+                }\n+                String s;\n+                if (longform) {\n+                    s =  sym.getQualifiedName().toString();\n@@ -1076,1 +1168,1 @@\n-                    return sym.name.toString();\n+                    s = sym.name.toString();\n@@ -1078,0 +1170,1 @@\n+                return s;\n@@ -1100,1 +1193,1 @@\n-            outer_field = outer;\n+            outer_field = outer != null && outer.isReferenceProjection() ? outer.valueProjection() : outer;\n@@ -1127,0 +1220,48 @@\n+        @Override\n+        public boolean isPrimitiveClass() {\n+            return !isReferenceProjection && tsym != null && tsym.isPrimitiveClass();\n+        }\n+\n+        @Override\n+        public boolean isReferenceProjection() {\n+            return isReferenceProjection;\n+        }\n+\n+        @Override\n+        public Type valueProjection() {\n+            if (!isReferenceProjection())\n+                return null;\n+\n+            if (projection !=  null)\n+                return projection;\n+\n+            projection = new ClassType(outer_field, typarams_field, tsym, getMetadata(), false);\n+            projection.allparams_field = allparams_field;\n+            projection.supertype_field = supertype_field;\n+\n+            projection.interfaces_field = interfaces_field;\n+            projection.all_interfaces_field = all_interfaces_field;\n+            projection.projection = this;\n+            return projection;\n+        }\n+\n+        \/\/ return the reference projection type preserving parameterizations\n+        @Override\n+        public ClassType referenceProjection() {\n+\n+            if (!isPrimitiveClass())\n+                return null;\n+\n+            if (projection != null)\n+                return projection;\n+\n+            projection = new ClassType(outer_field, typarams_field, tsym, getMetadata(), true);\n+            projection.allparams_field = allparams_field;\n+            projection.supertype_field = supertype_field;\n+\n+            projection.interfaces_field = interfaces_field;\n+            projection.all_interfaces_field = all_interfaces_field;\n+            projection.projection = this;\n+            return projection;\n+        }\n+\n@@ -1175,1 +1316,1 @@\n-            super(outer, List.nil(), tsym, metadata);\n+            super(outer, List.nil(), tsym, metadata, false);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Type.java","additions":151,"deletions":10,"binary":false,"changes":161,"status":"modified"},{"patch":"@@ -53,0 +53,1 @@\n+import com.sun.tools.javac.jvm.Target;\n@@ -96,0 +97,1 @@\n+    final boolean allowValueBasedClasses;\n@@ -125,0 +127,2 @@\n+        Options options = Options.instance(context);\n+        allowValueBasedClasses = options.isSet(\"allowValueBasedClasses\");\n@@ -273,1 +277,1 @@\n-                else return new ClassType(outer1, typarams1.toList(), t.tsym, t.getMetadata()) {\n+                else return new ClassType(outer1, typarams1.toList(), t.tsym, t.getMetadata(), t.isReferenceProjection()) {\n@@ -604,0 +608,9 @@\n+\n+        boolean tValue = t.isPrimitiveClass();\n+        boolean sValue = s.isPrimitiveClass();\n+        if (tValue != sValue) {\n+            return tValue ?\n+                    isSubtype(t.referenceProjection(), s) :\n+                    !t.hasTag(BOT) && isSubtype(t, s.referenceProjection());\n+        }\n+\n@@ -997,0 +1010,4 @@\n+    public boolean isPrimitiveClass(Type t) {\n+        return t != null && !t.isReferenceProjection() && t.tsym != null && (t.tsym.flags_field & Flags.PRIMITIVE_CLASS) != 0;\n+    }\n+\n@@ -1020,1 +1037,11 @@\n-                    return isSubtypeUncheckedInternal(elemtype(t), elemtype(s), false, warn);\n+                    \/\/ if T.ref <: S, then T[] <: S[]\n+                    Type es = elemtype(s);\n+                    Type et = elemtype(t);\n+                    if (isPrimitiveClass(et)) {\n+                        et = et.referenceProjection();\n+                        if (isPrimitiveClass(es))\n+                            es = es.referenceProjection();  \/\/ V <: V, surely\n+                    }\n+                    if (!isSubtypeUncheckedInternal(et, es, false, warn))\n+                        return false;\n+                    return true;\n@@ -1117,1 +1144,1 @@\n-                         s.hasTag(BOT) || s.hasTag(CLASS) ||\n+                         s.hasTag(BOT) || (s.hasTag(CLASS) && !isPrimitiveClass(s)) ||\n@@ -1184,0 +1211,1 @@\n+                    && (t.tsym != s.tsym || t.isReferenceProjection() == s.isReferenceProjection())\n@@ -1195,2 +1223,11 @@\n-                    else\n-                        return isSubtypeNoCapture(t.elemtype, elemtype(s));\n+                    else {\n+                        \/\/ if T.ref <: S, then T[] <: S[]\n+                        Type es = elemtype(s);\n+                        Type et = elemtype(t);\n+                        if (isPrimitiveClass(et)) {\n+                            et = et.referenceProjection();\n+                            if (isPrimitiveClass(es))\n+                                es = es.referenceProjection();  \/\/ V <: V, surely\n+                        }\n+                        return isSubtypeNoCapture(et, es);\n+                    }\n@@ -1203,1 +1240,2 @@\n-                        || sname == names.java_io_Serializable;\n+                        || sname == names.java_io_Serializable\n+                        || sname == names.java_lang_IdentityObject;\n@@ -1419,1 +1457,2 @@\n-                    && visit(t.getEnclosingType(), s.getEnclosingType())\n+                    && t.isReferenceProjection() == s.isReferenceProjection()\n+                    && visit(getEnclosingType(t), getEnclosingType(s))\n@@ -1422,0 +1461,8 @@\n+                \/\/ where\n+                private Type getEnclosingType(Type t) {\n+                    Type et = t.getEnclosingType();\n+                    if (et.isReferenceProjection()) {\n+                        et = et.valueProjection();\n+                    }\n+                    return et;\n+                }\n@@ -1581,0 +1628,9 @@\n+\n+                    \/\/ -----------------------------------  Unspecified behavior ----------------\n+\n+                    \/* If a value class V implements an interface I, then does \"? extends I\" contain V?\n+                       It seems widening must be applied here to answer yes to compile some common code\n+                       patterns.\n+                    *\/\n+\n+                    \/\/ ---------------------------------------------------------------------------\n@@ -1725,1 +1781,1 @@\n-                if (s.hasTag(ERROR) || s.hasTag(BOT))\n+                if (s.hasTag(ERROR) || (s.hasTag(BOT) && !isPrimitiveClass(t)))\n@@ -1744,0 +1800,8 @@\n+                    if (isPrimitiveClass(t)) {\n+                        \/\/ (s) Value ? == (s) Value.ref\n+                        t = t.referenceProjection();\n+                    }\n+                    if (isPrimitiveClass(s)) {\n+                        \/\/ (Value) t ? == (Value.ref) t\n+                        s = s.referenceProjection();\n+                    }\n@@ -1802,1 +1866,1 @@\n-                            return ((t.tsym.flags() & FINAL) == 0)\n+                            return (dynamicTypeMayImplementAdditionalInterfaces(t.tsym))\n@@ -1849,1 +1913,5 @@\n-                        return visit(elemtype(t), elemtype(s));\n+                        Type et = elemtype(t);\n+                        Type es = elemtype(s);\n+                        if (!visit(et, es))\n+                            return false;\n+                        return true;\n@@ -2137,0 +2205,29 @@\n+     * Further caveats in Valhalla: There are two \"hazards\" we need to watch out for when using\n+     * this method.\n+     *\n+     * 1. Since Foo.ref and Foo.val share the same symbol, that of Foo.class, a call to\n+     *    asSuper(Foo.ref.type, Foo.val.type.tsym) would return non-null. This MAY NOT BE correct\n+     *    depending on the call site. Foo.val is NOT a super type of Foo.ref either in the language\n+     *    model or in the VM's world view. An example of such an hazardous call used to exist in\n+     *    Gen.visitTypeCast. When we emit code for  (Foo) Foo.ref.instance a check for whether we\n+     *    really need the cast cannot\/shouldn't be gated on\n+     *\n+     *        asSuper(tree.expr.type, tree.clazz.type.tsym) == null)\n+     *\n+     *    but use !types.isSubtype(tree.expr.type, tree.clazz.type) which operates in terms of\n+     *    types. When we operate in terms of symbols, there is a loss of type information leading\n+     *    to a hazard. Whether a call to asSuper should be transformed into a isSubtype call is\n+     *    tricky. isSubtype returns just a boolean while asSuper returns richer information which\n+     *    may be required at the call site. Also where the concerned symbol corresponds to a\n+     *    generic class, an asSuper call cannot be conveniently rewritten as an isSubtype call\n+     *    (see that asSuper(ArrayList<String>.type, List<T>.tsym) != null while\n+     *    isSubType(ArrayList<String>.type, List<T>.type) is false;) So care needs to be exercised.\n+     *\n+     * 2. Given a primitive class Foo, a call to asSuper(Foo.type, SuperclassOfFoo.tsym) and\/or\n+     *    a call to asSuper(Foo.type, SuperinterfaceOfFoo.tsym) would answer null. In many places\n+     *    that is NOT what we want. An example of such a hazardous call used to occur in\n+     *    Attr.visitForeachLoop when checking to make sure the for loop's control variable of a type\n+     *    that implements Iterable: viz: types.asSuper(exprType, syms.iterableType.tsym);\n+     *    These hazardous calls should be rewritten as\n+     *    types.asSuper(exprType.referenceProjectionOrSelf(), syms.iterableType.tsym); instead.\n+     *\n@@ -2149,0 +2246,1 @@\n+\n@@ -2150,1 +2248,18 @@\n-            return syms.objectType;\n+            if (!isPrimitiveClass(t))\n+                return syms.objectType;\n+        }\n+        if (sym == syms.identityObjectType.tsym) {\n+            \/\/ IdentityObject is super interface of every concrete identity class other than jlO\n+            if (t.isPrimitiveClass() || t.tsym == syms.objectType.tsym)\n+                return null;\n+            if (t.hasTag(ARRAY))\n+                return syms.identityObjectType;\n+            if (t.hasTag(CLASS) && !t.isReferenceProjection() && !t.tsym.isInterface() && !t.tsym.isAbstract()) {\n+                return syms.identityObjectType;\n+            } \/\/ else fall through and look for explicit coded super interface\n+        } else if (sym == syms.primitiveObjectType.tsym) {\n+            if (t.isPrimitiveClass() || t.isReferenceProjection())\n+                return syms.primitiveObjectType;\n+            if (t.hasTag(ARRAY) || t.tsym == syms.objectType.tsym)\n+                return null;\n+            \/\/ else fall through and look for explicit coded super interface\n@@ -2168,0 +2283,4 @@\n+                \/\/ No man may be an island, but the bell tolls for a value.\n+                if (isPrimitiveClass(t))\n+                    return null;\n+\n@@ -2279,3 +2398,12 @@\n-        return (sym.flags() & STATIC) != 0\n-            ? sym.type\n-            : memberType.visit(t, sym);\n+\n+        if ((sym.flags() & STATIC) != 0)\n+            return sym.type;\n+\n+        \/* If any inline types are involved, switch over to the reference universe,\n+           where the hierarchy is navigable. V and V.ref have identical membership\n+           with no bridging needs.\n+        *\/\n+        if (t.isPrimitiveClass())\n+            t = t.referenceProjection();\n+\n+        return memberType.visit(t, sym);\n@@ -2434,7 +2562,19 @@\n-                Type erased = t.tsym.erasure(Types.this);\n-                if (recurse) {\n-                    erased = new ErasedClassType(erased.getEnclosingType(),erased.tsym,\n-                            t.getMetadata().without(Kind.ANNOTATIONS));\n-                    return erased;\n-                } else {\n-                    return combineMetadata(erased, t);\n+                \/\/ erasure(projection(primitive)) = projection(erasure(primitive))\n+                Type erased = eraseClassType(t, recurse);\n+                if (t.isReferenceProjection()) {\n+                    erased = new ClassType(erased.getEnclosingType(),\n+                            List.nil(), erased.tsym,\n+                            erased.getMetadata(), true);\n+                }\n+                return erased;\n+            }\n+                \/\/ where\n+                private Type eraseClassType(ClassType t, Boolean recurse) {\n+                    Type erased = t.tsym.erasure(Types.this);\n+                    if (recurse) {\n+                        erased = new ErasedClassType(erased.getEnclosingType(), erased.tsym,\n+                                t.getMetadata().without(Kind.ANNOTATIONS));\n+                        return erased;\n+                    } else {\n+                        return combineMetadata(erased, t);\n+                    }\n@@ -2442,1 +2582,0 @@\n-            }\n@@ -2491,0 +2630,3 @@\n+        long flags = ABSTRACT | PUBLIC | SYNTHETIC | COMPOUND | ACYCLIC;\n+        if (isPrimitiveClass(bounds.head))\n+            flags |= PRIMITIVE_CLASS;\n@@ -2492,1 +2634,1 @@\n-            new ClassSymbol(ABSTRACT|PUBLIC|SYNTHETIC|COMPOUND|ACYCLIC,\n+            new ClassSymbol(flags,\n@@ -2762,1 +2904,1 @@\n-                                         t.getMetadata());\n+                                         t.getMetadata(), t.isReferenceProjection());\n@@ -3965,1 +4107,0 @@\n-\n@@ -4085,1 +4226,1 @@\n-                        syms.cloneableType), true);\n+                        syms.cloneableType, syms.identityObjectType), true);\n@@ -4451,1 +4592,1 @@\n-                                 cls.getMetadata());\n+                                 cls.getMetadata(), cls.isReferenceProjection());\n@@ -4521,1 +4662,1 @@\n-        Assert.check((from.tsym.flags() & FINAL) != 0);\n+        Assert.check(!dynamicTypeMayImplementAdditionalInterfaces(from.tsym));\n@@ -4533,0 +4674,4 @@\n+    private boolean dynamicTypeMayImplementAdditionalInterfaces(TypeSymbol tsym) {\n+        return (tsym.flags() & FINAL) == 0 && !tsym.isReferenceProjection();\n+    }\n+\n@@ -4862,0 +5007,1 @@\n+        private boolean encodeTypeSig;\n@@ -4863,1 +5009,1 @@\n-        public UniqueType(Type type, Types types) {\n+        public UniqueType(Type type, Types types, boolean encodeTypeSig) {\n@@ -4866,0 +5012,5 @@\n+            this.encodeTypeSig = encodeTypeSig;\n+        }\n+\n+        public UniqueType(Type type, Types types) {\n+            this(type, types, true);\n@@ -4877,0 +5028,4 @@\n+        public boolean encodeTypeSig() {\n+            return encodeTypeSig;\n+        }\n+\n@@ -5109,1 +5264,4 @@\n-                    append('L');\n+                    if (types.isPrimitiveClass(type))\n+                        append('Q');\n+                    else\n+                        append('L');\n@@ -5198,0 +5356,4 @@\n+            if (ct.isReferenceProjection()) {\n+                append('$');\n+                append(types.names.ref);\n+            }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Types.java","additions":192,"deletions":30,"binary":false,"changes":222,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-import java.util.stream.Collectors;\n@@ -171,0 +170,1 @@\n+        allowPrimitiveClasses = Feature.PRIMITIVE_CLASSES.allowedInSource(source);\n@@ -177,0 +177,1 @@\n+        allowValueMemberCycles = options.isSet(\"allowValueMemberCycles\");\n@@ -203,0 +204,4 @@\n+    \/** Switch: allow primitive classes ?\n+     *\/\n+    boolean allowPrimitiveClasses;\n+\n@@ -221,0 +226,5 @@\n+    \/**\n+     * Switch: Allow value type member cycles?\n+     *\/\n+    boolean allowValueMemberCycles;\n+\n@@ -317,1 +327,11 @@\n-                log.error(pos, Errors.CantAssignValToFinalVar(v));\n+                boolean complain = true;\n+                \/* Allow updates to instance fields of value classes by any method in the same nest via the\n+                   withfield operator -This does not result in mutation of final fields; the code generator\n+                   would implement `copy on write' semantics via the opcode `withfield'.\n+                *\/\n+                if (env.info.inWithField && v.getKind() == ElementKind.FIELD && (v.flags() & STATIC) == 0 && types.isPrimitiveClass(v.owner.type)) {\n+                    if (env.enclClass.sym.outermostClass() == v.owner.outermostClass())\n+                        complain = false;\n+                }\n+                if (complain)\n+                    log.error(pos, Errors.CantAssignValToFinalVar(v));\n@@ -811,1 +831,1 @@\n-                List<Type> bounds = List.of(attribType(tvar.bounds.head, env));\n+                List<Type> bounds = List.of(chk.checkRefType(tvar.bounds.head, attribType(tvar.bounds.head, env), false));\n@@ -813,1 +833,1 @@\n-                    bounds = bounds.prepend(attribType(bound, env));\n+                    bounds = bounds.prepend(chk.checkRefType(bound, attribType(bound, env), false));\n@@ -974,0 +994,3 @@\n+                if (env.tree.hasTag(NEWCLASS) && types.isPrimitiveClass(c.getSuperclass())) {\n+                    c.flags_field |= PRIMITIVE_CLASS; \/\/ avoid further secondary errors.\n+                }\n@@ -1195,1 +1218,1 @@\n-                            TreeInfo.getConstructorInvocationName(body.stats, names) == names.empty) {\n+                            TreeInfo.getConstructorInvocationName(body.stats, names, true) == names.empty) {\n@@ -1226,0 +1249,6 @@\n+                if (m.isConstructor() && m.type.getParameterTypes().size() == 0) {\n+                    if ((owner.type == syms.objectType) ||\n+                            (tree.body.stats.size() == 1 && TreeInfo.getConstructorInvocationName(tree.body.stats, names, false) == names._super)) {\n+                        m.flags_field |= EMPTYNOARGCONSTR;\n+                    }\n+                }\n@@ -1295,0 +1324,3 @@\n+            \/* Don't want constant propagation\/folding for instance fields of value classes,\n+               as these can undergo updates via copy on write.\n+            *\/\n@@ -1296,1 +1328,1 @@\n-                if ((v.flags_field & FINAL) == 0 ||\n+                if ((v.flags_field & FINAL) == 0 || ((v.flags_field & STATIC) == 0 && types.isPrimitiveClass(v.owner.type)) ||\n@@ -1420,1 +1452,5 @@\n-            if ((tree.flags & STATIC) != 0) localEnv.info.staticLevel++;\n+            if ((tree.flags & STATIC) != 0)\n+                localEnv.info.staticLevel++;\n+            else if (tree.stats.size() > 0)\n+                env.info.scope.owner.flags_field |= HASINITBLOCK;\n+\n@@ -1485,0 +1521,33 @@\n+    public void visitWithField(JCWithField tree) {\n+        boolean inWithField = env.info.inWithField;\n+        try {\n+            env.info.inWithField = true;\n+            Type fieldtype = attribTree(tree.field, env.dup(tree), varAssignmentInfo);\n+            attribExpr(tree.value, env, fieldtype);\n+            Type capturedType = syms.errType;\n+            if (tree.field.type != null && !tree.field.type.isErroneous()) {\n+                final Symbol sym = TreeInfo.symbol(tree.field);\n+                if (sym == null || sym.kind != VAR || sym.owner.kind != TYP ||\n+                        (sym.flags() & STATIC) != 0 || !types.isPrimitiveClass(sym.owner.type)) {\n+                    log.error(tree.field.pos(), Errors.PrimitiveClassInstanceFieldExpectedHere);\n+                } else {\n+                    Type ownType = sym.owner.type;\n+                    switch(tree.field.getTag()) {\n+                        case IDENT:\n+                            JCIdent ident = (JCIdent) tree.field;\n+                            ownType = ident.sym.owner.type;\n+                            break;\n+                        case SELECT:\n+                            JCFieldAccess fieldAccess = (JCFieldAccess) tree.field;\n+                            ownType = fieldAccess.selected.type;\n+                            break;\n+                    }\n+                    capturedType = capture(ownType);\n+                }\n+            }\n+            result = check(tree, capturedType, KindSelector.VAL, resultInfo);\n+        } finally {\n+            env.info.inWithField = inWithField;\n+        }\n+    }\n+\n@@ -1528,1 +1597,1 @@\n-                Type base = types.asSuper(exprType, syms.iterableType.tsym);\n+                Type base = types.asSuper(exprType.referenceProjectionOrSelf(), syms.iterableType.tsym);\n@@ -1754,1 +1823,1 @@\n-        chk.checkRefType(tree.pos(), attribExpr(tree.lock, env));\n+        chk.checkRefType(tree.pos(), attribExpr(tree.lock, env), false);\n@@ -1850,1 +1919,1 @@\n-            types.asSuper(resource, syms.autoCloseableType.tsym) != null &&\n+            types.asSuper(resource.referenceProjectionOrSelf(), syms.autoCloseableType.tsym) != null &&\n@@ -2040,1 +2109,2 @@\n-            \/\/ Those were all the cases that could result in a primitive\n+            \/\/ Those were all the cases that could result in a primitive. See if primitive boxing and inline\n+            \/\/ narrowing conversions bring about a convergence.\n@@ -2042,1 +2112,2 @@\n-                                 .map(t -> t.isPrimitive() ? types.boxedClass(t).type : t)\n+                                 .map(t -> t.isPrimitive() ? types.boxedClass(t).type\n+                                         : t.isReferenceProjection() ? t.valueProjection() : t)\n@@ -2053,1 +2124,1 @@\n-                                 .map(t -> chk.checkNonVoid(posIt.next(), t))\n+                                 .map(t -> chk.checkNonVoid(posIt.next(), t.isPrimitiveClass() ? t.referenceProjection() : t))\n@@ -2056,1 +2127,1 @@\n-            \/\/ both are known to be reference types.  The result is\n+            \/\/ both are known to be reference types (or projections).  The result is\n@@ -2477,0 +2548,36 @@\n+            final Symbol symbol = TreeInfo.symbol(tree.meth);\n+            if (symbol != null) {\n+                \/* Is this an ill conceived attempt to invoke jlO methods not available on value types ??\n+                 *\/\n+                boolean superCallOnValueReceiver = types.isPrimitiveClass(env.enclClass.sym.type)\n+                        && (tree.meth.hasTag(SELECT))\n+                        && ((JCFieldAccess)tree.meth).selected.hasTag(IDENT)\n+                        && TreeInfo.name(((JCFieldAccess)tree.meth).selected) == names._super;\n+                if (types.isPrimitiveClass(qualifier) || superCallOnValueReceiver) {\n+                    int argSize = argtypes.size();\n+                    Name name = symbol.name;\n+                    switch (name.toString()) {\n+                        case \"wait\":\n+                            if (argSize == 0\n+                                    || (types.isConvertible(argtypes.head, syms.longType) &&\n+                                    (argSize == 1 || (argSize == 2 && types.isConvertible(argtypes.tail.head, syms.intType))))) {\n+                                log.error(tree.pos(), Errors.PrimitiveClassDoesNotSupport(name));\n+                            }\n+                            break;\n+                        case \"notify\":\n+                        case \"notifyAll\":\n+                        case \"clone\":\n+                        case \"finalize\":\n+                            if (argSize == 0)\n+                                log.error(tree.pos(), Errors.PrimitiveClassDoesNotSupport(name));\n+                            break;\n+                        case \"hashCode\":\n+                        case \"equals\":\n+                        case \"toString\":\n+                            if (superCallOnValueReceiver)\n+                                log.error(tree.pos(), Errors.PrimitiveClassDoesNotSupport(names.fromString(\"invocation of super.\" + name)));\n+                            break;\n+                    }\n+                }\n+            }\n+\n@@ -2491,0 +2598,9 @@\n+                \/\/ Temporary treatment for inline class: Given an inline class V that implements\n+                \/\/ I1, I2, ... In, v.getClass() is typed to be Class<? extends Object & I1 & I2 .. & In>\n+                Type wcb;\n+                if (qualifierType.isPrimitiveClass()) {\n+                    List<Type> bounds = List.of(syms.objectType).appendList(((ClassSymbol) qualifierType.tsym).getInterfaces());\n+                    wcb = bounds.size() > 1 ? types.makeIntersectionType(bounds) : syms.objectType;\n+                } else {\n+                    wcb = types.erasure(qualifierType);\n+                }\n@@ -2492,1 +2608,1 @@\n-                        List.of(new WildcardType(types.erasure(qualifierType),\n+                        List.of(new WildcardType(wcb,\n@@ -2496,1 +2612,2 @@\n-                        restype.getMetadata());\n+                        restype.getMetadata(),\n+                        restype.isReferenceProjection());\n@@ -2665,0 +2782,8 @@\n+            \/\/ Check that it is an instantiation of a class and not a projection type\n+            if (clazz.hasTag(SELECT)) {\n+                JCFieldAccess fieldAccess = (JCFieldAccess) clazz;\n+                if (fieldAccess.selected.type.isPrimitiveClass() &&\n+                        (fieldAccess.name == names.ref || fieldAccess.name == names.val)) {\n+                    log.error(tree.pos(), Errors.ProjectionCantBeInstantiated);\n+                }\n+            }\n@@ -2689,1 +2814,2 @@\n-                                               clazztype.getMetadata());\n+                                               clazztype.getMetadata(),\n+                                               clazztype.isReferenceProjection());\n@@ -2836,0 +2962,1 @@\n+                    chk.checkParameterizationWithValues(tree, clazztype);\n@@ -2908,0 +3035,3 @@\n+        \/\/ Likewise arg can't be null if it is a value.\n+        if (types.isPrimitiveClass(arg.type))\n+            return arg;\n@@ -3922,0 +4052,1 @@\n+                chk.checkForSuspectClassLiteralComparison(tree, left, right);\n@@ -4157,1 +4288,1 @@\n-                return ;\n+                return;\n@@ -4165,0 +4296,1 @@\n+\n@@ -4257,1 +4389,1 @@\n-                Type site1 = types.asSuper(env.enclClass.sym.type, site.tsym);\n+                Type site1 = types.asSuper(env.enclClass.sym.type.referenceProjectionOrSelf(), site.tsym);\n@@ -4300,0 +4432,2 @@\n+                } else if (site.isPrimitiveClass() && isType(location) && resultInfo.pkind.contains(KindSelector.TYP) && (name == names.ref || name == names.val)) {\n+                    return site.tsym;\n@@ -4403,1 +4537,1 @@\n-                \/\/ except for two situations:\n+                \/\/ except for three situations:\n@@ -4409,1 +4543,8 @@\n-                    \/\/ (a) If the symbol's type is parameterized, erase it\n+                    \/\/ (a) If symbol is a primitive class and its reference projection\n+                    \/\/ is requested via the .ref notation, then adjust the computed type to\n+                    \/\/ reflect this.\n+                    if (owntype.isPrimitiveClass() && tree.hasTag(SELECT) && ((JCFieldAccess) tree).name == names.ref) {\n+                        owntype = new ClassType(owntype.getEnclosingType(), owntype.getTypeArguments(), (TypeSymbol)sym, owntype.getMetadata(), true);\n+                    }\n+\n+                    \/\/ (b) If the symbol's type is parameterized, erase it\n@@ -4416,1 +4557,1 @@\n-                    \/\/ (b) If the symbol's type is an inner class, then\n+                    \/\/ (c) If the symbol's type is an inner class, then\n@@ -4436,1 +4577,1 @@\n-                                owntype.getMetadata());\n+                                owntype.getMetadata(), owntype.isReferenceProjection());\n@@ -4753,0 +4894,28 @@\n+    public void visitDefaultValue(JCDefaultValue tree) {\n+        if (!allowPrimitiveClasses) {\n+            log.error(DiagnosticFlag.SOURCE_LEVEL, tree.pos(),\n+                    Feature.PRIMITIVE_CLASSES.error(sourceName));\n+        }\n+\n+        \/\/ Attribute the qualifier expression, and determine its symbol (if any).\n+        Type site = attribTree(tree.clazz, env, new ResultInfo(KindSelector.TYP_PCK, Type.noType));\n+        if (!pkind().contains(KindSelector.TYP_PCK))\n+            site = capture(site); \/\/ Capture field access\n+\n+        Symbol sym = switch (site.getTag()) {\n+                case WILDCARD -> throw new AssertionError(tree);\n+                case PACKAGE -> {\n+                    log.error(tree.pos, Errors.CantResolveLocation(Kinds.KindName.CLASS, site.tsym.getQualifiedName(), null, null,\n+                            Fragments.Location(Kinds.typeKindName(env.enclClass.type), env.enclClass.type, null)));\n+                    yield syms.errSymbol;\n+                }\n+                case ERROR -> types.createErrorType(names._default, site.tsym, site).tsym;\n+                default -> new VarSymbol(STATIC, names._default, site, site.tsym);\n+        };\n+\n+        if (site.hasTag(TYPEVAR) && sym.kind != ERR) {\n+            site = types.skipTypeVars(site, true);\n+        }\n+        result = checkId(tree, site, sym, env, resultInfo);\n+    }\n+\n@@ -4819,1 +4988,1 @@\n-                                        clazztype.getMetadata());\n+                                        clazztype.getMetadata(), clazztype.isReferenceProjection());\n@@ -4946,1 +5115,1 @@\n-                make.Modifiers(PUBLIC | ABSTRACT),\n+                make.Modifiers(PUBLIC | ABSTRACT | (extending != null && TreeInfo.symbol(extending).isPrimitiveClass() ? PRIMITIVE_CLASS : 0)),\n@@ -4969,1 +5138,1 @@\n-        result = check(tree, new WildcardType(chk.checkRefType(tree.pos(), type),\n+        result = check(tree, new WildcardType(chk.checkRefType(tree.pos(), type, false),\n@@ -5076,0 +5245,7 @@\n+            if (types.isPrimitiveClass(c.type)) {\n+                final Env<AttrContext> env = typeEnvs.get(c);\n+                if (!allowValueMemberCycles) {\n+                    if (env != null && env.tree != null && env.tree.hasTag(CLASSDEF))\n+                        chk.checkNonCyclicMembership((JCClassDecl)env.tree);\n+                }\n+            }\n@@ -5186,1 +5362,1 @@\n-            } else {\n+            } else if ((c.flags_field & Flags.COMPOUND) == 0) {\n@@ -5241,0 +5417,8 @@\n+                if ((c.flags() & (PRIMITIVE_CLASS | ABSTRACT)) == PRIMITIVE_CLASS) { \/\/ for non-intersection, concrete values.\n+                    Assert.check(env.tree.hasTag(CLASSDEF));\n+                    JCClassDecl classDecl = (JCClassDecl) env.tree;\n+                    if (classDecl.extending != null) {\n+                        chk.checkSuperConstraintsOfPrimitiveClass(env.tree.pos(), c);\n+                    }\n+                }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":211,"deletions":27,"binary":false,"changes":238,"status":"modified"},{"patch":"@@ -422,37 +422,54 @@\n-        switch ((short)(sym.flags() & AccessFlags)) {\n-        case PRIVATE:\n-            return\n-                (env.enclClass.sym == sym.owner \/\/ fast special case\n-                 ||\n-                 env.enclClass.sym.outermostClass() ==\n-                 sym.owner.outermostClass())\n-                &&\n-                sym.isInheritedIn(site.tsym, types);\n-        case 0:\n-            return\n-                (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n-                 ||\n-                 env.toplevel.packge == sym.packge())\n-                &&\n-                isAccessible(env, site, checkInner)\n-                &&\n-                sym.isInheritedIn(site.tsym, types)\n-                &&\n-                notOverriddenIn(site, sym);\n-        case PROTECTED:\n-            return\n-                (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n-                 ||\n-                 env.toplevel.packge == sym.packge()\n-                 ||\n-                 isProtectedAccessible(sym, env.enclClass.sym, site)\n-                 ||\n-                 \/\/ OK to select instance method or field from 'super' or type name\n-                 \/\/ (but type names should be disallowed elsewhere!)\n-                 env.info.selectSuper && (sym.flags() & STATIC) == 0 && sym.kind != TYP)\n-                &&\n-                isAccessible(env, site, checkInner)\n-                &&\n-                notOverriddenIn(site, sym);\n-        default: \/\/ this case includes erroneous combinations as well\n-            return isAccessible(env, site, checkInner) && notOverriddenIn(site, sym);\n+        ClassSymbol enclosingCsym = env.enclClass.sym;\n+        if (sym.kind == MTH || sym.kind == VAR) {\n+            \/* If any inline types are involved, ask the same question in the reference universe,\n+               where the hierarchy is navigable\n+            *\/\n+            if (site.isPrimitiveClass())\n+                site = site.referenceProjection();\n+        } else if (sym.kind == TYP) {\n+            \/\/ A type is accessible in a reference projection if it was\n+            \/\/ accessible in the value projection.\n+            if (site.isReferenceProjection())\n+                site = site.valueProjection();\n+        }\n+        try {\n+            switch ((short)(sym.flags() & AccessFlags)) {\n+                case PRIVATE:\n+                    return\n+                            (env.enclClass.sym == sym.owner \/\/ fast special case\n+                                    ||\n+                                    env.enclClass.sym.outermostClass() ==\n+                                            sym.owner.outermostClass())\n+                                    &&\n+                                    sym.isInheritedIn(site.tsym, types);\n+                case 0:\n+                    return\n+                            (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n+                                    ||\n+                                    env.toplevel.packge == sym.packge())\n+                                    &&\n+                                    isAccessible(env, site, checkInner)\n+                                    &&\n+                                    sym.isInheritedIn(site.tsym, types)\n+                                    &&\n+                                    notOverriddenIn(site, sym);\n+                case PROTECTED:\n+                    return\n+                            (env.toplevel.packge == sym.owner.owner \/\/ fast special case\n+                                    ||\n+                                    env.toplevel.packge == sym.packge()\n+                                    ||\n+                                    isProtectedAccessible(sym, env.enclClass.sym, site)\n+                                    ||\n+                                    \/\/ OK to select instance method or field from 'super' or type name\n+                                    \/\/ (but type names should be disallowed elsewhere!)\n+                                    env.info.selectSuper && (sym.flags() & STATIC) == 0 && sym.kind != TYP)\n+                                    &&\n+                                    isAccessible(env, site, checkInner)\n+                                    &&\n+                                    notOverriddenIn(site, sym);\n+                default: \/\/ this case includes erroneous combinations as well\n+                    return isAccessible(env, site, checkInner) && notOverriddenIn(site, sym);\n+            }\n+        } finally {\n+            env.enclClass.sym = enclosingCsym;\n@@ -471,5 +488,10 @@\n-        else {\n-            Symbol s2 = ((MethodSymbol)sym).implementation(site.tsym, types, true);\n-            return (s2 == null || s2 == sym || sym.owner == s2.owner ||\n-                    !types.isSubSignature(types.memberType(site, s2), types.memberType(site, sym)));\n-        }\n+\n+        \/* If any inline types are involved, ask the same question in the reference universe,\n+           where the hierarchy is navigable\n+        *\/\n+        if (site.isPrimitiveClass())\n+            site = site.referenceProjection();\n+\n+        Symbol s2 = ((MethodSymbol)sym).implementation(site.tsym, types, true);\n+        return (s2 == null || s2 == sym || sym.owner == s2.owner ||\n+                !types.isSubSignature(types.memberType(site, s2), types.memberType(site, sym)));\n@@ -1696,1 +1718,1 @@\n-                    if (types.asSuper(m1Owner.type, m2Owner) != null &&\n+                    if (types.asSuper(m1Owner.type.referenceProjectionOrSelf(), m2Owner) != null &&\n@@ -1701,1 +1723,1 @@\n-                    if (types.asSuper(m2Owner.type, m1Owner) != null &&\n+                    if (types.asSuper(m2Owner.type.referenceProjectionOrSelf(), m1Owner) != null &&\n@@ -2288,0 +2310,16 @@\n+        return findMemberTypeInternal(env,site, name, c);\n+    }\n+\n+    \/** Find qualified member type.\n+     *  @param env       The current environment.\n+     *  @param site      The original type from where the selection takes\n+     *                   place.\n+     *  @param name      The type's name.\n+     *  @param c         The class to search for the member type. This is\n+     *                   always a superclass or implemented interface of\n+     *                   site's class.\n+     *\/\n+    Symbol findMemberTypeInternal(Env<AttrContext> env,\n+                          Type site,\n+                          Name name,\n+                          TypeSymbol c) {\n@@ -2349,0 +2387,8 @@\n+        return findTypeInternal(env, name);\n+    }\n+\n+    \/** Find an unqualified type symbol.\n+     *  @param env       The current environment.\n+     *  @param name      The type's name.\n+     *\/\n+    Symbol findTypeInternal(Env<AttrContext> env, Name name) {\n@@ -3566,1 +3612,1 @@\n-                        types.isSubtypeUnchecked(inferenceContext.asUndetVar(argtypes.head), originalSite))) {\n+                        types.isSubtypeUnchecked(inferenceContext.asUndetVar(argtypes.head.referenceProjectionOrSelf()), originalSite))) {\n@@ -3619,1 +3665,1 @@\n-                Type asSuperSite = types.asSuper(argtypes.head, site.tsym);\n+                Type asSuperSite = types.asSuper(argtypes.head.referenceProjectionOrSelf(), site.tsym);\n@@ -3678,1 +3724,1 @@\n-                this.site = new ClassType(site.getEnclosingType(), site.tsym.type.getTypeArguments(), site.tsym, site.getMetadata());\n+                this.site = new ClassType(site.getEnclosingType(), site.tsym.type.getTypeArguments(), site.tsym, site.getMetadata(), site.isReferenceProjection());\n@@ -3768,1 +3814,1 @@\n-                            types.asSuper(env.enclClass.type, c), env.enclClass.sym);\n+                            types.asSuper(env.enclClass.type.referenceProjectionOrSelf(), c), env.enclClass.sym);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Resolve.java","additions":94,"deletions":48,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+import com.sun.tools.javac.jvm.Target;\n@@ -683,0 +684,1 @@\n+            final boolean isValueType = (tree.mods.flags & Flags.PRIMITIVE_CLASS) != 0;\n@@ -734,1 +736,0 @@\n-\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n- *     classig    ::= 'L' name [typeargs] ';'\n+ *     classig    ::= 'L' name [typeargs] ';' | 'Q' name [typeargs] ';'\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/ClassFile.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+import com.sun.tools.javac.code.Scope.WriteableScope;\n@@ -144,0 +145,2 @@\n+    private final Symtab syms;\n+\n@@ -177,0 +180,1 @@\n+        syms = Symtab.instance(context);\n@@ -820,1 +824,2 @@\n-    \/** Write \"inner classes\" attribute.\n+    \/** Write \"inner classes\" attribute. If a primitive class happens to be an inner class,\n+     *  the reference projection class will also be an inner class.\n@@ -824,1 +829,2 @@\n-        databuf.appendChar(poolWriter.innerClasses.size());\n+        int icCountIdx = beginAttrs();\n+        int icCount = 0;\n@@ -841,0 +847,11 @@\n+            icCount++;\n+            if (inner.isPrimitiveClass()) {\n+                databuf.appendChar(poolWriter.putClass(inner.type.referenceProjection()));\n+                databuf.appendChar(\n+                        inner.owner.kind == TYP && !inner.name.isEmpty() ? poolWriter.putClass((ClassSymbol)inner.owner) : 0);\n+                databuf.appendChar(\n+                        !inner.name.isEmpty() ? poolWriter.putName(inner.name.append('$', names.ref)) : 0);\n+                flags = (char) ((flags & ~(ACC_PRIMITIVE | FINAL)) | ABSTRACT);\n+                databuf.appendChar(flags);\n+                icCount++;\n+            }\n@@ -842,0 +859,1 @@\n+        endAttrs(icCountIdx, icCount);\n@@ -866,8 +884,26 @@\n-        ListBuffer<ClassSymbol> nested = new ListBuffer<>();\n-        listNested(csym, nested);\n-        Set<ClassSymbol> nestedUnique = new LinkedHashSet<>(nested);\n-        if (csym.owner.kind == PCK && !nestedUnique.isEmpty()) {\n-            int alenIdx = writeAttr(names.NestMembers);\n-            databuf.appendChar(nestedUnique.size());\n-            for (ClassSymbol s : nestedUnique) {\n-                databuf.appendChar(poolWriter.putClass(s));\n+        Set<ClassSymbol> nestedUnique = new LinkedHashSet<>();\n+        if (csym.owner.kind == PCK) {\n+            if (csym.isPrimitiveClass()) {\n+                \/\/ reference projection is the host\n+            } else if (csym.isReferenceProjection()) {\n+                ClassSymbol valueProjection = csym.valueProjection();\n+                nestedUnique.add(valueProjection);\n+                listNested(valueProjection, nestedUnique);\n+            } else {\n+                listNested(csym, nestedUnique);\n+            }\n+            if (!nestedUnique.isEmpty()) {\n+                int alenIdx = writeAttr(names.NestMembers);\n+                int nmcIdx = beginAttrs();\n+                int nmc = 0;\n+                for (ClassSymbol s : nestedUnique) {\n+                    databuf.appendChar(poolWriter.putClass(s));\n+                    nmc++;\n+                    if (s.isPrimitiveClass() && s.owner.kind != PCK) {\n+                        databuf.appendChar(poolWriter.putClass(s.type.referenceProjection()));\n+                        nmc++;\n+                    }\n+                }\n+                endAttrs(nmcIdx, nmc);\n+                endAttr(alenIdx);\n+                return 1;\n@@ -875,2 +911,0 @@\n-            endAttr(alenIdx);\n-            return 1;\n@@ -885,1 +919,1 @@\n-        if (csym.owner.kind != PCK) {\n+        if (csym.owner.kind != PCK || csym.isPrimitiveClass()) {\n@@ -887,1 +921,6 @@\n-            databuf.appendChar(poolWriter.putClass(csym.outermostClass()));\n+            ClassSymbol outerMost = csym.outermostClass();\n+            if (outerMost.isPrimitiveClass()) {\n+                databuf.appendChar(poolWriter.putClass(outerMost.type.referenceProjection()));\n+            } else {\n+                databuf.appendChar(poolWriter.putClass(outerMost));\n+            }\n@@ -894,1 +933,1 @@\n-    private void listNested(Symbol sym, ListBuffer<ClassSymbol> seen) {\n+    private void listNested(Symbol sym, Set<ClassSymbol> seen) {\n@@ -1227,0 +1266,4 @@\n+                if (debugstackmap) System.out.print(\"object(\" + types.erasure(t).tsym + \")\");\n+                databuf.appendByte(7);\n+                databuf.appendChar(types.isPrimitiveClass(t) ? poolWriter.putClass(new ConstantPoolQType(types.erasure(t), types)) : poolWriter.putClass(types.erasure(t)));\n+                break;\n@@ -1488,0 +1531,61 @@\n+    {\n+        JavaFileObject javaFileObject = writeClassInternal(c);\n+        if (c.isPrimitiveClass()) {\n+            writeClassInternal(getReferenceProjection(c));\n+        }\n+        return javaFileObject;\n+    }\n+\n+        \/\/ where\n+        private static ClassSymbol getReferenceProjection(ClassSymbol c) {\n+\n+            ClassSymbol projection;\n+            ClassType projectedType;\n+\n+            ClassType ct = (ClassType) c.type;\n+            projectedType = new ClassType(ct.getEnclosingType(), ct.typarams_field, null, ct.getMetadata(), false);\n+            projectedType.allparams_field = ct.allparams_field;\n+            projectedType.supertype_field = ct.supertype_field;\n+\n+            projectedType.interfaces_field = ct.interfaces_field;\n+            projectedType.all_interfaces_field = ct.all_interfaces_field;\n+            projectedType.projection = null;\n+\n+            Name projectionName = c.name.append('$', c.name.table.names.ref);\n+            long projectionFlags = (c.flags() & ~(PRIMITIVE_CLASS | UNATTRIBUTED | FINAL)) | (ABSTRACT | SEALED);\n+\n+            projection = new ClassSymbol(projectionFlags, projectionName, projectedType, c.owner) {\n+                @Override\n+                public boolean isReferenceProjection() {\n+                    return true;\n+                }\n+\n+                @Override\n+                public ClassSymbol valueProjection() {\n+                    return c;\n+                }\n+            };\n+            projection.members_field = WriteableScope.create(projection);\n+            for (Symbol s : c.members().getSymbols(s->(s.kind == MTH || s.kind == VAR), NON_RECURSIVE)) {\n+                Symbol clone = null;\n+                if (s.kind == MTH) {\n+                    MethodSymbol valMethod = (MethodSymbol)s;\n+                    MethodSymbol refMethod = valMethod.clone(projection);\n+                    clone = refMethod;\n+                } else if (s.kind == VAR) {\n+                    VarSymbol valVar = (VarSymbol)s;\n+                    VarSymbol refVar = valVar.clone(projection);\n+                    clone = refVar;\n+                }\n+                projection.members_field.enter(clone);\n+            }\n+            projection.completer = Completer.NULL_COMPLETER;\n+            projection.sourcefile = c.sourcefile;\n+            projection.flatname = c.flatname.append('$', c.name.table.names.ref);\n+            projection.permitted = List.of(c);\n+            projectedType.tsym = projection;\n+            return projection;\n+        }\n+\n+    private JavaFileObject writeClassInternal(ClassSymbol c)\n+        throws IOException, PoolOverflow, StringOverflow\n@@ -1530,2 +1634,2 @@\n-        Type supertype = types.supertype(c.type);\n-        List<Type> interfaces = types.interfaces(c.type);\n+        Type supertype = c.isPrimitiveClass() ? c.type.referenceProjection() : types.supertype(c.type);\n+        List<Type> interfaces = c.isPrimitiveClass() ? List.nil() : types.interfaces(c.type);\n@@ -1540,1 +1644,1 @@\n-            flags = flags & ClassFlags & ~STRICTFP;\n+            flags = flags & (ClassFlags | ACC_PRIMITIVE) & ~STRICTFP;\n@@ -1558,1 +1662,1 @@\n-        databuf.appendChar(supertype.hasTag(CLASS) ? poolWriter.putClass((ClassSymbol)supertype.tsym) : 0);\n+        databuf.appendChar(supertype.hasTag(CLASS) ? poolWriter.putClass(supertype) : 0);\n@@ -1564,7 +1668,16 @@\n-        for (Symbol sym : c.members().getSymbols(NON_RECURSIVE)) {\n-            switch (sym.kind) {\n-            case VAR: fieldsCount++; break;\n-            case MTH: if ((sym.flags() & HYPOTHETICAL) == 0) methodsCount++;\n-                      break;\n-            case TYP: poolWriter.enterInner((ClassSymbol)sym); break;\n-            default : Assert.error();\n+        boolean referenceProjection = c.isReferenceProjection();\n+        if (!referenceProjection) {\n+            for (Symbol sym : c.members().getSymbols(NON_RECURSIVE)) {\n+                switch (sym.kind) {\n+                    case VAR:\n+                        fieldsCount++;\n+                        break;\n+                    case MTH:\n+                        if ((sym.flags() & HYPOTHETICAL) == 0) methodsCount++;\n+                        break;\n+                    case TYP:\n+                        poolWriter.enterInner((ClassSymbol)sym);\n+                        break;\n+                    default:\n+                        Assert.error();\n+                }\n@@ -1572,4 +1685,4 @@\n-        }\n-        if (c.trans_local != null) {\n-            for (ClassSymbol local : c.trans_local) {\n-                poolWriter.enterInner(local);\n+            if (c.trans_local != null) {\n+                for (ClassSymbol local : c.trans_local) {\n+                    poolWriter.enterInner(local);\n+                }\n@@ -1581,1 +1694,2 @@\n-        writeFields(c.members());\n+        if (!referenceProjection)\n+            writeFields(c.members());\n@@ -1583,1 +1697,2 @@\n-        writeMethods(c.members());\n+        if (!referenceProjection)\n+            writeMethods(c.members());\n@@ -1706,0 +1821,2 @@\n+        if ((flags & PRIMITIVE_CLASS) != 0)\n+            result |= ACC_PRIMITIVE;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/ClassWriter.java","additions":149,"deletions":32,"binary":false,"changes":181,"status":"modified"},{"patch":"@@ -1023,1 +1023,6 @@\n-            state.push(uninitializedObject(t.tsym.erasure(types), cp-3));\n+            state.push(uninitializedObject(t.tsym.erasure(types), cp - 3));\n+            break;\n+        }\n+        case defaultvalue: {\n+            Type t = (Type)data;\n+            state.push(t.tsym.erasure(types));\n@@ -1052,0 +1057,3 @@\n+        case withfield:\n+            state.pop(((Symbol)data).erasure(types));\n+            break;\n@@ -1062,1 +1070,1 @@\n-            Type t = types.erasure((Type)data);\n+            Type t = types.erasure(data instanceof  ConstantPoolQType ? ((ConstantPoolQType)data).type: (Type)data);\n@@ -1776,2 +1784,2 @@\n-                Assert.check(types.isSubtype(types.erasure(old),\n-                                       types.erasure(t)));\n+                Assert.check(types.isSubtype(types.erasure(old), types.erasure(t)) ||\n+                        (old.isPrimitiveClass() != t.isPrimitiveClass() && types.isConvertible(types.erasure(old), types.erasure(t))));\n@@ -2451,0 +2459,2 @@\n+            mnem[defaultvalue] = \"defaultvalue\";\n+            mnem[withfield] = \"withfield\";\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/Code.java","additions":14,"deletions":4,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+import com.sun.tools.javac.code.Flags.Flag;\n@@ -51,0 +52,1 @@\n+import static com.sun.tools.javac.code.Flags.asFlagSet;\n@@ -59,0 +61,1 @@\n+import static com.sun.tools.javac.parser.Tokens.TokenKind.SYNCHRONIZED;\n@@ -187,0 +190,1 @@\n+        this.allowWithFieldOperator = fac.options.isSet(\"allowWithFieldOperator\");\n@@ -206,0 +210,4 @@\n+    \/** Switch: should we allow withField operator at source level ?\n+    *\/\n+    boolean allowWithFieldOperator;\n+\n@@ -305,0 +313,7 @@\n+    protected boolean peekToken(int lookahead, Filter<TokenKind> tk1, Filter<TokenKind> tk2, Filter<TokenKind> tk3, Filter<TokenKind> tk4) {\n+        return tk1.accepts(S.token(lookahead + 1).kind) &&\n+                tk2.accepts(S.token(lookahead + 2).kind) &&\n+                tk3.accepts(S.token(lookahead + 3).kind) &&\n+                tk4.accepts(S.token(lookahead + 4).kind);\n+    }\n+\n@@ -474,0 +489,16 @@\n+    \/** If next input token matches one of the two given tokens, skip it, otherwise report\n+     *  an error.\n+     *\n+     * @return The actual token kind.\n+     *\/\n+    public TokenKind accept2(TokenKind tk1, TokenKind tk2) {\n+        TokenKind returnValue = token.kind;\n+        if (token.kind == tk1 || token.kind == tk2) {\n+            nextToken();\n+        } else {\n+            setErrorEndPos(token.pos);\n+            reportSyntaxError(S.prevToken().endPos, Errors.Expected2(tk1, tk2));\n+        }\n+        return returnValue;\n+    }\n+\n@@ -1143,0 +1174,15 @@\n+        case WITHFIELD:\n+            if (!allowWithFieldOperator) {\n+                log.error(pos, Errors.WithFieldOperatorDisallowed);\n+            }\n+            if (typeArgs == null && (mode & EXPR) != 0) {\n+                nextToken();\n+                accept(LPAREN);\n+                mode = EXPR;\n+                t = term();\n+                accept(COMMA);\n+                mode = EXPR;\n+                JCExpression v = term();\n+                accept(RPAREN);\n+                return F.at(pos).WithField(t, v);\n+            } else return illegal();\n@@ -1311,0 +1357,6 @@\n+                            case DEFAULT:\n+                                if (typeArgs != null) return illegal();\n+                                selectExprMode();\n+                                t = to(F.at(pos).DefaultValue(t));\n+                                nextToken();\n+                                break loop;\n@@ -1368,3 +1420,4 @@\n-                        if ((mode & TYPE) == 0 && isUnboundMemberRef()) {\n-                            \/\/this is an unbound method reference whose qualifier\n-                            \/\/is a generic type i.e. A<S>::m\n+                        if ((mode & TYPE) == 0 && isParameterizedTypePrefix()) {\n+                            \/\/this is either an unbound method reference whose qualifier\n+                            \/\/is a generic type i.e. A<S>::m or a default value creation of\n+                            \/\/the form ValueType<S>.default\n@@ -1383,0 +1436,6 @@\n+                                if (token.kind == DEFAULT) {\n+                                    t =  toP(F.at(token.pos).DefaultValue(t));\n+                                    nextToken();\n+                                    selectExprMode();\n+                                    return term3Rest(t, typeArgs);\n+                                }\n@@ -1547,1 +1606,1 @@\n-                } else if (token.kind == NEW && (mode & EXPR) != 0) {\n+                } else if ((token.kind == NEW) && (mode & EXPR) != 0) {\n@@ -1601,1 +1660,2 @@\n-     * method reference or a binary expression. To disambiguate, look for a\n+     * method reference or a default value creation that uses a parameterized type\n+     * or a binary expression. To disambiguate, look for a\n@@ -1605,1 +1665,1 @@\n-    boolean isUnboundMemberRef() {\n+    boolean isParameterizedTypePrefix() {\n@@ -1727,2 +1787,2 @@\n-                    if (peekToken(lookahead, LAX_IDENTIFIER)) {\n-                        \/\/ Identifier, Identifier\/'_'\/'assert'\/'enum' -> explicit lambda\n+                    if (peekToken(lookahead, LAX_IDENTIFIER) || (peekToken(lookahead, QUES, LAX_IDENTIFIER) && (peekToken(lookahead + 2, RPAREN) || peekToken(lookahead + 2, COMMA)))) {\n+                        \/\/ Identifier[?], Identifier\/'_'\/'assert'\/'enum' -> explicit lambda\n@@ -1804,0 +1864,2 @@\n+                                peekToken(lookahead, QUES, LAX_IDENTIFIER, COMMA) ||\n+                                peekToken(lookahead, QUES, LAX_IDENTIFIER, RPAREN, ARROW) ||\n@@ -2200,1 +2262,1 @@\n-            accept(CLASS);\n+            TokenKind selector = accept2(CLASS, DEFAULT);\n@@ -2218,1 +2280,5 @@\n-                t = toP(F.at(pos).Select(t, names._class));\n+                if (selector == CLASS) {\n+                    t = toP(F.at(pos).Select(t, names._class));\n+                } else {\n+                    t = toP(F.at(pos).DefaultValue(t));\n+                }\n@@ -2263,2 +2329,5 @@\n-        List<JCAnnotation> newAnnotations = typeAnnotationsOpt();\n-\n+        final JCModifiers mods = modifiersOpt();\n+        List<JCAnnotation> newAnnotations = mods.annotations;\n+        if (!newAnnotations.isEmpty()) {\n+            checkSourceLevel(newAnnotations.head.pos, Feature.TYPE_ANNOTATIONS);\n+        }\n@@ -2268,0 +2337,4 @@\n+            if (mods.flags != 0) {\n+                long badModifiers = (mods.flags & Flags.PRIMITIVE_CLASS) != 0 ? mods.flags & ~Flags.FINAL : mods.flags;\n+                log.error(token.pos, Errors.ModNotAllowedHere(asFlagSet(badModifiers)));\n+            }\n@@ -2336,0 +2409,3 @@\n+            long badModifiers = mods.flags & ~(Flags.PRIMITIVE_CLASS | Flags.FINAL);\n+            if (badModifiers != 0)\n+                log.error(token.pos, Errors.ModNotAllowedHere(asFlagSet(badModifiers)));\n@@ -2340,1 +2416,6 @@\n-            return classCreatorRest(newpos, null, typeArgs, t);\n+            JCNewClass newClass = classCreatorRest(newpos, null, typeArgs, t, mods.flags);\n+            if ((newClass.def == null) && (mods.flags != 0)) {\n+                badModifiers = (mods.flags & Flags.PRIMITIVE_CLASS) != 0 ? mods.flags & ~Flags.FINAL : mods.flags;\n+                log.error(newClass.pos, Errors.ModNotAllowedHere(asFlagSet(badModifiers)));\n+            }\n+            return newClass;\n@@ -2365,1 +2446,1 @@\n-        return classCreatorRest(newpos, encl, typeArgs, t);\n+        return classCreatorRest(newpos, encl, typeArgs, t, 0);\n@@ -2447,1 +2528,2 @@\n-                                  JCExpression t)\n+                                  JCExpression t,\n+                                  long flags)\n@@ -2454,1 +2536,1 @@\n-            JCModifiers mods = F.at(Position.NOPOS).Modifiers(0);\n+            JCModifiers mods = F.at(Position.NOPOS).Modifiers(flags);\n@@ -2457,1 +2539,2 @@\n-        return toP(F.at(newpos).NewClass(encl, typeArgs, t, args, body));\n+        JCNewClass newClass = toP(F.at(newpos).NewClass(encl, typeArgs, t, args, body));\n+        return newClass;\n@@ -2588,0 +2671,1 @@\n+        token = recastToken(token);\n@@ -2598,0 +2682,1 @@\n+        case PRIMITIVE:\n@@ -3050,1 +3135,4 @@\n-                return variableDeclarators(modifiersOpt(), t, stats, true).toList();\n+                pos = token.pos;\n+                JCModifiers mods = F.at(Position.NOPOS).Modifiers(0);\n+                F.at(pos);\n+                return variableDeclarators(mods, t, stats, true).toList();\n@@ -3120,0 +3208,1 @@\n+            token = recastToken(token);\n@@ -3129,0 +3218,1 @@\n+            case PRIMITIVE   : flag = Flags.PRIMITIVE_CLASS; break;\n@@ -3160,2 +3250,7 @@\n-                    annotations.append(ann);\n-                    flag = 0;\n+                    final Name name = TreeInfo.name(ann.annotationType);\n+                    if (name == names.__primitive__ || name == names.java_lang___primitive__) {\n+                        flag = Flags.PRIMITIVE_CLASS;\n+                    } else {\n+                        annotations.append(ann);\n+                        flag = 0;\n+                    }\n@@ -3177,0 +3272,5 @@\n+        \/\/ Force value classes to be automatically final.\n+        if ((flags & (Flags.PRIMITIVE_CLASS | Flags.ABSTRACT | Flags.INTERFACE | Flags.ENUM)) == Flags.PRIMITIVE_CLASS) {\n+            flags |= Flags.FINAL;\n+        }\n+\n@@ -3366,0 +3466,36 @@\n+    \/\/ Does the given token signal a primitive modifier ? If yes, suitably reclassify token.\n+    Token recastToken(Token token) {\n+        if (token.kind != IDENTIFIER || token.name() != names.primitive) {\n+            return token;\n+        }\n+        if (peekToken(t->t == PRIVATE ||\n+                         t == PROTECTED ||\n+                         t == PUBLIC ||\n+                         t == STATIC ||\n+                         t == TRANSIENT ||\n+                         t == FINAL ||\n+                         t == ABSTRACT ||\n+                         t == NATIVE ||\n+                         t == VOLATILE ||\n+                         t == SYNCHRONIZED ||\n+                         t == STRICTFP ||\n+                         t == MONKEYS_AT ||\n+                         t == DEFAULT ||\n+                         t == BYTE ||\n+                         t == SHORT ||\n+                         t == CHAR ||\n+                         t == INT ||\n+                         t == LONG ||\n+                         t == FLOAT ||\n+                         t == DOUBLE ||\n+                         t == BOOLEAN ||\n+                         t == CLASS ||\n+                         t == INTERFACE ||\n+                         t == ENUM ||\n+                         t == IDENTIFIER)) { \/\/ new value Comparable() {}\n+            checkSourceLevel(Feature.PRIMITIVE_CLASSES);\n+            return new Token(PRIMITIVE, token.pos, token.endPos, token.comments);\n+        }\n+        return token;\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":156,"deletions":20,"binary":false,"changes":176,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+        PRIMITIVE(), \/\/ a phantom token never returned by the scanner, but can result from a reclassification by the parser.\n@@ -147,0 +148,1 @@\n+        WITHFIELD(\"__WithField\"),\n@@ -247,0 +249,2 @@\n+            case PRIMITIVE:\n+                return \"primitive\";\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/Tokens.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -746,0 +746,9 @@\n+    public void visitDefaultValue(JCDefaultValue tree) {\n+        try {\n+            printExpr(tree.clazz, TreeInfo.postfixPrec);\n+            print(\".default\");\n+        } catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n@@ -782,0 +791,12 @@\n+    public void visitWithField(JCWithField tree) {\n+        try {\n+            print(\"__WithField(\");\n+            printExpr(tree.field);\n+            print(\", \");\n+            printExpr(tree.value);\n+            print(\")\");\n+        } catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/Pretty.java","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -113,0 +113,1 @@\n+     *  Optionally, check only for no-arg ctor invocation\n@@ -114,1 +115,1 @@\n-    public static Name getConstructorInvocationName(List<? extends JCTree> trees, Names names) {\n+    public static Name getConstructorInvocationName(List<? extends JCTree> trees, Names names, boolean argsAllowed) {\n@@ -120,4 +121,6 @@\n-                    Name methName = TreeInfo.name(apply.meth);\n-                    if (methName == names._this ||\n-                        methName == names._super) {\n-                        return methName;\n+                    if (argsAllowed || apply.args.size() == 0) {\n+                        Name methName = TreeInfo.name(apply.meth);\n+                        if (methName == names._this ||\n+                                methName == names._super) {\n+                            return methName;\n+                        }\n@@ -487,0 +490,2 @@\n+            case DEFAULT_VALUE:\n+                return getStartPos(((JCDefaultValue) tree).clazz);\n@@ -629,0 +634,2 @@\n+            case WITHFIELD:\n+                return getEndPos(((JCWithField) tree).value, endPosTable);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/TreeInfo.java","additions":12,"deletions":5,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -90,0 +90,1 @@\n+    private HotSpotResolvedObjectTypeImpl identityObjectType;\n@@ -126,0 +127,7 @@\n+    HotSpotResolvedObjectTypeImpl getJavaLangIdentityObject() {\n+        if (identityObjectType == null) {\n+            identityObjectType = (HotSpotResolvedObjectTypeImpl) fromClass(IdentityObject.class);\n+        }\n+        return identityObjectType;\n+    }\n+\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk.vm.ci.hotspot\/src\/jdk\/vm\/ci\/hotspot\/HotSpotJVMCIRuntime.java","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2571,1 +2571,1 @@\n-        return isKind(doctree, VALUE);\n+        return isKind(doctree, Kind.VALUE);\n","filename":"src\/jdk.javadoc\/share\/classes\/jdk\/javadoc\/internal\/doclets\/toolkit\/util\/Utils.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1150,0 +1150,2 @@\n+            case METHOD:\n+                \/\/ Ditto for a synthetic method injected by the compiler (for value types)\n","filename":"src\/jdk.javadoc\/share\/classes\/jdk\/javadoc\/internal\/doclint\/Checker.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -143,0 +143,117 @@\n+\n+static void assert_unlocked_state(markWord mark) {\n+  EXPECT_FALSE(mark.has_displaced_mark_helper());\n+  EXPECT_FALSE(mark.has_locker());\n+  EXPECT_FALSE(mark.has_monitor());\n+  EXPECT_FALSE(mark.is_being_inflated());\n+  EXPECT_FALSE(mark.is_locked());\n+  EXPECT_TRUE(mark.is_unlocked());\n+}\n+\n+static void assert_copy_set_hash(markWord mark) {\n+  const intptr_t hash = 4711;\n+  EXPECT_TRUE(mark.has_no_hash());\n+  markWord copy = mark.copy_set_hash(hash);\n+  EXPECT_EQ(hash, copy.hash());\n+  EXPECT_FALSE(copy.has_no_hash());\n+}\n+\n+static void assert_type(markWord mark) {\n+  EXPECT_FALSE(mark.is_flat_array());\n+  EXPECT_FALSE(mark.is_inline_type());\n+  EXPECT_FALSE(mark.is_larval_state());\n+  EXPECT_FALSE(mark.is_nullfree_array());\n+}\n+\n+TEST_VM(markWord, prototype) {\n+  markWord mark = markWord::prototype();\n+  assert_unlocked_state(mark);\n+  EXPECT_TRUE(mark.is_neutral());\n+\n+  assert_type(mark);\n+\n+  EXPECT_TRUE(mark.has_no_hash());\n+  EXPECT_FALSE(mark.is_marked());\n+  EXPECT_TRUE(mark.decode_pointer() == NULL);\n+\n+  assert_copy_set_hash(mark);\n+  assert_type(mark);\n+}\n+\n+static void assert_inline_type(markWord mark) {\n+  EXPECT_FALSE(mark.is_flat_array());\n+  EXPECT_TRUE(mark.is_inline_type());\n+  EXPECT_FALSE(mark.is_nullfree_array());\n+}\n+\n+TEST_VM(markWord, inline_type_prototype) {\n+  markWord mark = markWord::inline_type_prototype();\n+  assert_unlocked_state(mark);\n+  EXPECT_FALSE(mark.is_neutral());\n+\n+  assert_inline_type(mark);\n+  EXPECT_FALSE(mark.is_larval_state());\n+\n+  EXPECT_TRUE(mark.has_no_hash());\n+  EXPECT_FALSE(mark.is_marked());\n+  EXPECT_TRUE(mark.decode_pointer() == NULL);\n+\n+  markWord larval = mark.enter_larval_state();\n+  EXPECT_TRUE(larval.is_larval_state());\n+  assert_inline_type(larval);\n+  mark = larval.exit_larval_state();\n+  EXPECT_FALSE(mark.is_larval_state());\n+  assert_inline_type(mark);\n+\n+  EXPECT_TRUE(mark.has_no_hash());\n+  EXPECT_FALSE(mark.is_marked());\n+  EXPECT_TRUE(mark.decode_pointer() == NULL);\n+}\n+\n+#if _LP64\n+\n+static void assert_flat_array_type(markWord mark) {\n+  EXPECT_TRUE(mark.is_flat_array());\n+  EXPECT_FALSE(mark.is_inline_type());\n+  EXPECT_FALSE(mark.is_larval_state());\n+  EXPECT_TRUE(mark.is_nullfree_array());\n+}\n+\n+TEST_VM(markWord, flat_array_prototype) {\n+  markWord mark = markWord::flat_array_prototype();\n+  assert_unlocked_state(mark);\n+  EXPECT_TRUE(mark.is_neutral());\n+\n+  assert_flat_array_type(mark);\n+\n+  EXPECT_TRUE(mark.has_no_hash());\n+  EXPECT_FALSE(mark.is_marked());\n+  EXPECT_TRUE(mark.decode_pointer() == NULL);\n+\n+  assert_copy_set_hash(mark);\n+  assert_flat_array_type(mark);\n+}\n+\n+static void assert_nullfree_array_type(markWord mark) {\n+  EXPECT_FALSE(mark.is_flat_array());\n+  EXPECT_FALSE(mark.is_inline_type());\n+  EXPECT_FALSE(mark.is_larval_state());\n+  EXPECT_TRUE(mark.is_nullfree_array());\n+}\n+\n+TEST_VM(markWord, nullfree_array_prototype) {\n+  markWord mark = markWord::nullfree_array_prototype();\n+  assert_unlocked_state(mark);\n+  EXPECT_TRUE(mark.is_neutral());\n+\n+  assert_nullfree_array_type(mark);\n+\n+  EXPECT_TRUE(mark.has_no_hash());\n+  EXPECT_FALSE(mark.is_marked());\n+  EXPECT_TRUE(mark.decode_pointer() == NULL);\n+\n+  assert_copy_set_hash(mark);\n+  assert_nullfree_array_type(mark);\n+}\n+#endif \/\/ _LP64\n+\n","filename":"test\/hotspot\/gtest\/oops\/test_markWord.cpp","additions":117,"deletions":0,"binary":false,"changes":117,"status":"modified"},{"patch":"@@ -65,0 +65,69 @@\n+# Valhalla\n+compiler\/aot\/cli\/DisabledAOTWithLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/SingleAOTOptionTest.java 8226295 generic-all\n+compiler\/aot\/cli\/MultipleAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileClassWithDebugTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileModuleTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/AtFileTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionWrongFileTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ClasspathOptionUnknownClassTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileDirectoryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionNotExistingTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileClassTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileJarTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/IgnoreErrorsTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileAbsoluteDirectoryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/NonExistingAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/SingleAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/IncorrectAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/RecompilationTest.java 8226295 generic-all\n+compiler\/aot\/SharedUsageTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/ClassSearchTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/SearchPathTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/module\/ModuleSourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/ClassSourceTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/directory\/DirectorySourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/jar\/JarSourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/NativeOrderOutputStreamTest.java 8226295 generic-all\n+compiler\/aot\/verification\/vmflags\/TrackedFlagTest.java 8226295 generic-all\n+compiler\/aot\/verification\/vmflags\/NotTrackedFlagTest.java 8226295 generic-all\n+compiler\/aot\/verification\/ClassAndLibraryNotMatchTest.java 8226295 generic-all\n+compiler\/aot\/DeoptimizationTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SelfChanged.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SelfChangedCDS.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SuperChanged.java 8226295 generic-all\n+\n@@ -94,0 +163,39 @@\n+# Valhalla TODO:\n+runtime\/CompressedOops\/CompressedClassPointers.java 8210258 generic-all\n+runtime\/RedefineTests\/RedefineLeak.java 8205032 generic-all\n+runtime\/SharedArchiveFile\/BootAppendTests.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/CdsDifferentCompactStrings.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/CdsDifferentObjectAlignment.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/NonBootLoaderClasses.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/PrintSharedArchiveAndExit.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedArchiveFile.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedStringsDedup.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedStringsRunAuto.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedSymbolTableBucketSize.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SpaceUtilizationCheck.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/TestInterpreterMethodEntries.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformInterfaceAndImplementor.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformSuperAndSubClasses.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformSuperSubTwoPckgs.java 8210258 generic-all\n+runtime\/appcds\/ClassLoaderTest.java 8210258 generic-all\n+runtime\/appcds\/HelloTest.java 8210258 generic-all\n+runtime\/appcds\/sharedStrings\/SharedStringsBasic.java 8210258 generic-all\n+\n+runtime\/cds\/appcds\/cacheObject\/CheckCachedMirrorTest.java 8265719 generic-all\n+runtime\/cds\/appcds\/cacheObject\/CheckCachedResolvedReferences.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/ClassListFormatA.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/ClassListFormatD.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/ClassListFormatE.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/HelloCustom.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/HelloCustom_JFR.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/LoaderSegregationTest.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/ParallelTestMultiFP.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/ParallelTestSingleFP.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/PrintSharedArchiveAndExit.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/ProtectionDomain.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/SameNameInTwoLoadersTest.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/UnintendedLoadersTest.java 8265719 generic-all\n+runtime\/cds\/appcds\/customLoader\/UnloadUnregisteredLoaderTest.java 8265719 generic-all\n+runtime\/cds\/appcds\/jvmti\/transformRelatedClasses\/TransformInterfaceImplementorAppCDS.java 8265719 generic-all\n+runtime\/cds\/appcds\/jvmti\/transformRelatedClasses\/TransformSuperSubAppCDS.java 8265719 generic-all\n+\n@@ -106,0 +214,28 @@\n+# Valhalla TODO:\n+serviceability\/sa\/ClhsdbCDSCore.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbFindPC.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbInspect.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbLongConstant.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJdis.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJstack.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAs.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintStatics.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSource.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSymbol.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbWhere.java 8190936 generic-all\n+serviceability\/sa\/JhsdbThreadInfoTest.java 8190936 generic-all\n+serviceability\/sa\/TestClassDump.java 8190936 generic-all\n+serviceability\/sa\/TestClhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestCpoolForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForLargeArray.java 8190936 generic-all\n+serviceability\/sa\/TestIntConstant.java 8190936 generic-all\n+serviceability\/sa\/TestJhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCore.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8190936 generic-all\n+serviceability\/sa\/TestPrintMdo.java 8190936 generic-all\n+serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 8190936 generic-all\n+\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":136,"deletions":0,"binary":false,"changes":136,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-  runtime\n+  runtime \\\n@@ -57,0 +57,7 @@\n+hotspot_valhalla = \\\n+  runtime\/valhalla \\\n+  compiler\/valhalla\n+\n+hotspot_valhalla_runtime = \\\n+  runtime\/valhalla\n+\n@@ -95,1 +102,1 @@\n-  compiler\/codegen\/aes \\\n+  compiler\/codegen\/aes \\\n@@ -144,0 +151,1 @@\n+  compiler\/valhalla\/ \\\n@@ -161,0 +169,7 @@\n+tier1_compiler_no_valhalla = \\\n+  :tier1_compiler_1 \\\n+  :tier1_compiler_2 \\\n+  :tier1_compiler_3 \\\n+  :tier1_compiler_not_xcomp \\\n+  -compiler\/valhalla\n+\n@@ -311,0 +326,4 @@\n+tier1_runtime_no_valhalla = \\\n+  :tier1_runtime \\\n+  -runtime\/valhalla\n+\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":21,"deletions":2,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+ * @requires vm.opt.final.TieredCompilation\n","filename":"test\/hotspot\/jtreg\/compiler\/tiered\/ConstantGettersTransitionsTest.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+ * @requires vm.opt.final.TieredCompilation\n","filename":"test\/hotspot\/jtreg\/compiler\/types\/TestMeetIncompatibleInterfaceArrays.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,3420 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.test.lib.Asserts;\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+import java.util.Arrays;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test inline type arrays\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestArrays.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestArrays\n+ *\/\n+public class TestArrays extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 2: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:-UncommonNullCast\", \"-XX:+StressArrayCopyMacroNode\"};\n+        case 3: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:FlatArrayElementMaxSize=-1\", \"-XX:-UncommonNullCast\"};\n+        case 4: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:-UncommonNullCast\"};\n+        case 5: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:-UncommonNullCast\", \"-XX:+StressArrayCopyMacroNode\"};\n+        }\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestArrays test = new TestArrays();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class);\n+    }\n+\n+    \/\/ Helper methods\n+\n+    protected long hash() {\n+        return hash(rI, rL);\n+    }\n+\n+    protected long hash(int x, long y) {\n+        return MyValue1.createWithFieldsInline(x, y).hash();\n+    }\n+\n+    \/\/ Test inline type array creation and initialization\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { ALLOCA }, matchCount = { 1 })\n+    @Test(valid = InlineTypeArrayFlattenOff, match = { ALLOCA }, matchCount = { 1 }, failOn = LOAD)\n+    public MyValue1[] test1(int len) {\n+        MyValue1[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        }\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        int len = Math.abs(rI % 10);\n+        MyValue1[] va = test1(len);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(va[i].hash(), hash());\n+        }\n+    }\n+\n+    \/\/ Test creation of an inline type array and element access\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public long test2() {\n+        MyValue1[] va = new MyValue1[1];\n+        va[0] = MyValue1.createWithFieldsInline(rI, rL);\n+        return va[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        long result = test2();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Test receiving an inline type array from the interpreter,\n+    \/\/ updating its elements in a loop and computing a hash.\n+    @Test(failOn = ALLOCA)\n+    public long test3(MyValue1[] va) {\n+        long result = 0;\n+        for (int i = 0; i < 10; ++i) {\n+            result += va[i].hash();\n+            va[i] = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[10];\n+        long expected = 0;\n+        for (int i = 0; i < 10; ++i) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI + i, rL + i);\n+            expected += va[i].hash();\n+        }\n+        long result = test3(va);\n+        Asserts.assertEQ(expected, result);\n+        for (int i = 0; i < 10; ++i) {\n+            if (va[i].hash() != hash(rI + 1, rL + 1)) {\n+                Asserts.assertEQ(va[i].hash(), hash(rI + 1, rL + 1));\n+            }\n+        }\n+    }\n+\n+    \/\/ Test returning an inline type array received from the interpreter\n+    @Test(failOn = ALLOC + ALLOCA + LOAD + STORE + LOOP + TRAP)\n+    public MyValue1[] test4(MyValue1[] va) {\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[10];\n+        for (int i = 0; i < 10; ++i) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI + i, rL + i);\n+        }\n+        va = test4(va);\n+        for (int i = 0; i < 10; ++i) {\n+            Asserts.assertEQ(va[i].hash(), hash(rI + i, rL + i));\n+        }\n+    }\n+\n+    \/\/ Merge inline type arrays created from two branches\n+    @Test\n+    public MyValue1[] test5(boolean b) {\n+        MyValue1[] va;\n+        if (b) {\n+            va = new MyValue1[5];\n+            for (int i = 0; i < 5; ++i) {\n+                va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+            }\n+        } else {\n+            va = new MyValue1[10];\n+            for (int i = 0; i < 10; ++i) {\n+                va[i] = MyValue1.createWithFieldsInline(rI + i, rL + i);\n+            }\n+        }\n+        long sum = va[0].hashInterpreted();\n+        if (b) {\n+            va[0] = MyValue1.createWithFieldsDontInline(rI, sum);\n+        } else {\n+            va[0] = MyValue1.createWithFieldsDontInline(rI + 1, sum + 1);\n+        }\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        MyValue1[] va = test5(true);\n+        Asserts.assertEQ(va.length, 5);\n+        Asserts.assertEQ(va[0].hash(), hash(rI, hash()));\n+        for (int i = 1; i < 5; ++i) {\n+            Asserts.assertEQ(va[i].hash(), hash());\n+        }\n+        va = test5(false);\n+        Asserts.assertEQ(va.length, 10);\n+        Asserts.assertEQ(va[0].hash(), hash(rI + 1, hash(rI, rL) + 1));\n+        for (int i = 1; i < 10; ++i) {\n+            Asserts.assertEQ(va[i].hash(), hash(rI + i, rL + i));\n+        }\n+    }\n+\n+    \/\/ Test creation of inline type array with single element\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public MyValue1 test6() {\n+        MyValue1[] va = new MyValue1[1];\n+        return va[0];\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[1];\n+        MyValue1 v = test6();\n+        Asserts.assertEQ(v.hashPrimitive(), va[0].hashPrimitive());\n+    }\n+\n+    \/\/ Test default initialization of inline type arrays\n+    @Test(failOn = LOAD)\n+    public MyValue1[] test7(int len) {\n+        return new MyValue1[len];\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        int len = Math.abs(rI % 10);\n+        MyValue1[] va = new MyValue1[len];\n+        MyValue1[] var = test7(len);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(va[i].hashPrimitive(), var[i].hashPrimitive());\n+        }\n+    }\n+\n+    \/\/ Test creation of inline type array with zero length\n+    @Test(failOn = ALLOC + LOAD + STORE + LOOP + TRAP)\n+    public MyValue1[] test8() {\n+        return new MyValue1[0];\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        MyValue1[] va = test8();\n+        Asserts.assertEQ(va.length, 0);\n+    }\n+\n+    static MyValue1[] test9_va;\n+\n+    \/\/ Test that inline type array loaded from field has correct type\n+    @Test(failOn = LOOP)\n+    public long test9() {\n+        return test9_va[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        test9_va = new MyValue1[1];\n+        test9_va[0] = MyValue1.createWithFieldsInline(rI, rL);\n+        long result = test9();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Multi-dimensional arrays\n+    @Test\n+    public MyValue1[][][] test10(int len1, int len2, int len3) {\n+        MyValue1[][][] arr = new MyValue1[len1][len2][len3];\n+        for (int i = 0; i < len1; i++) {\n+            for (int j = 0; j < len2; j++) {\n+                for (int k = 0; k < len3; k++) {\n+                    arr[i][j][k] = MyValue1.createWithFieldsDontInline(rI + i , rL + j + k);\n+                }\n+            }\n+        }\n+        return arr;\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        MyValue1[][][] arr = test10(2, 3, 4);\n+        for (int i = 0; i < 2; i++) {\n+            for (int j = 0; j < 3; j++) {\n+                for (int k = 0; k < 4; k++) {\n+                    Asserts.assertEQ(arr[i][j][k].hash(), MyValue1.createWithFieldsDontInline(rI + i , rL + j + k).hash());\n+                }\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test11(MyValue1[][][] arr, long[] res) {\n+        int l = 0;\n+        for (int i = 0; i < arr.length; i++) {\n+            for (int j = 0; j < arr[i].length; j++) {\n+                for (int k = 0; k < arr[i][j].length; k++) {\n+                    res[l] = arr[i][j][k].hash();\n+                    l++;\n+                }\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        MyValue1[][][] arr = new MyValue1[2][3][4];\n+        long[] res = new long[2*3*4];\n+        long[] verif = new long[2*3*4];\n+        int l = 0;\n+        for (int i = 0; i < 2; i++) {\n+            for (int j = 0; j < 3; j++) {\n+                for (int k = 0; k < 4; k++) {\n+                    arr[i][j][k] = MyValue1.createWithFieldsDontInline(rI + i, rL + j + k);\n+                    verif[l] = arr[i][j][k].hash();\n+                    l++;\n+                }\n+            }\n+        }\n+        test11(arr, res);\n+        for (int i = 0; i < verif.length; i++) {\n+            Asserts.assertEQ(res[i], verif[i]);\n+        }\n+    }\n+\n+    \/\/ Array load out of bounds (upper bound) at compile time\n+    @Test\n+    public int test12() {\n+        int arraySize = Math.abs(rI) % 10;;\n+        MyValue1[] va = new MyValue1[arraySize];\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI + 1, rL);\n+        }\n+\n+        try {\n+            return va[arraySize + 1].x;\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            return rI;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        Asserts.assertEQ(test12(), rI);\n+    }\n+\n+    \/\/ Array load  out of bounds (lower bound) at compile time\n+    @Test\n+    public int test13() {\n+        int arraySize = Math.abs(rI) % 10;;\n+        MyValue1[] va = new MyValue1[arraySize];\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI + i, rL);\n+        }\n+\n+        try {\n+            return va[-arraySize].x;\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            return rI;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        Asserts.assertEQ(test13(), rI);\n+    }\n+\n+    \/\/ Array load out of bound not known to compiler (both lower and upper bound)\n+    @Test\n+    public int test14(MyValue1[] va, int index)  {\n+        return va[index].x;\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean warmup) {\n+        int arraySize = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[arraySize];\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        }\n+\n+        int result;\n+        for (int i = -20; i < 20; i++) {\n+            try {\n+                result = test14(va, i);\n+            } catch (ArrayIndexOutOfBoundsException e) {\n+                result = rI;\n+            }\n+            Asserts.assertEQ(result, rI);\n+        }\n+    }\n+\n+    \/\/ Array store out of bounds (upper bound) at compile time\n+    @Test\n+    public int test15() {\n+        int arraySize = Math.abs(rI) % 10;;\n+        MyValue1[] va = new MyValue1[arraySize];\n+\n+        try {\n+            for (int i = 0; i <= arraySize; i++) {\n+                va[i] = MyValue1.createWithFieldsDontInline(rI + 1, rL);\n+            }\n+            return rI - 1;\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            return rI;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean warmup) {\n+        Asserts.assertEQ(test15(), rI);\n+    }\n+\n+    \/\/ Array store out of bounds (lower bound) at compile time\n+    @Test\n+    public int test16() {\n+        int arraySize = Math.abs(rI) % 10;;\n+        MyValue1[] va = new MyValue1[arraySize];\n+\n+        try {\n+            for (int i = -1; i <= arraySize; i++) {\n+                va[i] = MyValue1.createWithFieldsDontInline(rI + 1, rL);\n+            }\n+            return rI - 1;\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            return rI;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean warmup) {\n+        Asserts.assertEQ(test16(), rI);\n+    }\n+\n+    \/\/ Array store out of bound not known to compiler (both lower and upper bound)\n+    @Test\n+    public int test17(MyValue1[] va, int index, MyValue1 vt)  {\n+        va[index] = vt;\n+        return va[index].x;\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean warmup) {\n+        int arraySize = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[arraySize];\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        }\n+\n+        MyValue1 vt = MyValue1.createWithFieldsDontInline(rI + 1, rL);\n+        int result;\n+        for (int i = -20; i < 20; i++) {\n+            try {\n+                result = test17(va, i, vt);\n+            } catch (ArrayIndexOutOfBoundsException e) {\n+                result = rI + 1;\n+            }\n+            Asserts.assertEQ(result, rI + 1);\n+        }\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            Asserts.assertEQ(va[i].x, rI + 1);\n+        }\n+    }\n+\n+    \/\/ clone() as stub call\n+    @Test\n+    public MyValue1[] test18(MyValue1[] va) {\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        MyValue1[] result = test18(va);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(result[i].hash(), va[i].hash());\n+        }\n+    }\n+\n+    \/\/ clone() as series of loads\/stores\n+    static MyValue1[] test19_orig = null;\n+\n+    @Test\n+    public MyValue1[] test19() {\n+        MyValue1[] va = new MyValue1[8];\n+        for (int i = 0; i < va.length; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        test19_orig = va;\n+\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        MyValue1[] result = test19();\n+        for (int i = 0; i < test19_orig.length; ++i) {\n+            Asserts.assertEQ(result[i].hash(), test19_orig[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array with oop fields\n+    @Test\n+    public void test20(MyValue1[] src, MyValue1[] dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] src = new MyValue1[len];\n+        MyValue1[] dst = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        test20(src, dst);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array with no oop field\n+    @Test\n+    public void test21(MyValue2[] src, MyValue2[] dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2[] src = new MyValue2[len];\n+        MyValue2[] dst = new MyValue2[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test21(src, dst);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array with oop field and tightly\n+    \/\/ coupled allocation as dest\n+    @Test\n+    public MyValue1[] test22(MyValue1[] src) {\n+        MyValue1[] dst = new MyValue1[src.length];\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+        return dst;\n+    }\n+\n+    @DontCompile\n+    public void test22_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] src = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        MyValue1[] dst = test22(src);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array with oop fields and tightly\n+    \/\/ coupled allocation as dest\n+    @Test\n+    public MyValue1[] test23(MyValue1[] src) {\n+        MyValue1[] dst = new MyValue1[src.length + 10];\n+        System.arraycopy(src, 0, dst, 5, src.length);\n+        return dst;\n+    }\n+\n+    @DontCompile\n+    public void test23_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] src = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        MyValue1[] dst = test23(src);\n+        for (int i = 5; i < len; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array passed as Object\n+    @Test\n+    public void test24(MyValue1[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test24_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] src = new MyValue1[len];\n+        MyValue1[] dst1 = new MyValue1[len];\n+        Object[] dst2 = new Object[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        test24(src, dst1);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst1[i].hash());\n+        }\n+        test24(src, dst2);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(src[i].hash(), ((MyValue1)dst2[i]).hash());\n+        }\n+    }\n+\n+    \/\/ short arraycopy() with no oop field\n+    @Test\n+    public void test25(MyValue2[] src, MyValue2[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test25_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[8];\n+        MyValue2[] dst = new MyValue2[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test25(src, dst);\n+        for (int i = 0; i < 8; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    \/\/ short arraycopy() with oop fields\n+    @Test\n+    public void test26(MyValue1[] src, MyValue1[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test26_verifier(boolean warmup) {\n+        MyValue1[] src = new MyValue1[8];\n+        MyValue1[] dst = new MyValue1[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        test26(src, dst);\n+        for (int i = 0; i < 8; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    \/\/ short arraycopy() with oop fields and offsets\n+    @Test\n+    public void test27(MyValue1[] src, MyValue1[] dst) {\n+        System.arraycopy(src, 1, dst, 2, 6);\n+    }\n+\n+    @DontCompile\n+    public void test27_verifier(boolean warmup) {\n+        MyValue1[] src = new MyValue1[8];\n+        MyValue1[] dst = new MyValue1[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        test27(src, dst);\n+        for (int i = 2; i < 8; ++i) {\n+            Asserts.assertEQ(src[i-1].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    \/\/ non escaping allocations\n+    \/\/ TODO 8252027: Make sure this is optimized with ZGC\n+    @Test(valid = ZGCOff, failOn = ALLOCA + LOOP + LOAD + TRAP)\n+    @Test(valid = ZGCOn)\n+    public MyValue2 test28() {\n+        MyValue2[] src = new MyValue2[10];\n+        src[0] = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2[] dst = (MyValue2[])src.clone();\n+        return dst[0];\n+    }\n+\n+    @DontCompile\n+    public void test28_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2 result = test28();\n+        Asserts.assertEQ(result.hash(), v.hash());\n+    }\n+\n+    \/\/ non escaping allocations\n+    \/\/ TODO 8227588: shouldn't this have the same IR matching rules as test6?\n+    \/\/ @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    @Test(valid = InlineTypeArrayFlattenOn, failOn = ALLOCA + LOOP + LOAD + TRAP)\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = ALLOCA + LOOP + TRAP)\n+    public MyValue2 test29(MyValue2[] src) {\n+        MyValue2[] dst = new MyValue2[10];\n+        System.arraycopy(src, 0, dst, 0, 10);\n+        return dst[0];\n+    }\n+\n+    @DontCompile\n+    public void test29_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[10];\n+        for (int i = 0; i < 10; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        MyValue2 v = test29(src);\n+        Asserts.assertEQ(src[0].hash(), v.hash());\n+    }\n+\n+    \/\/ non escaping allocation with uncommon trap that needs\n+    \/\/ eliminated inline type array element as debug info\n+    @Test\n+    @Warmup(10000)\n+    public MyValue2 test30(MyValue2[] src, boolean flag) {\n+        MyValue2[] dst = new MyValue2[10];\n+        System.arraycopy(src, 0, dst, 0, 10);\n+        if (flag) { }\n+        return dst[0];\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[10];\n+        for (int i = 0; i < 10; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        MyValue2 v = test30(src, !warmup);\n+        Asserts.assertEQ(src[0].hash(), v.hash());\n+    }\n+\n+    \/\/ non escaping allocation with memory phi\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public long test31(boolean b, boolean deopt) {\n+        MyValue2[] src = new MyValue2[1];\n+        if (b) {\n+            src[0] = MyValue2.createWithFieldsInline(rI, rD);\n+        } else {\n+            src[0] = MyValue2.createWithFieldsInline(rI+1, rD+1);\n+        }\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test31\"));\n+        }\n+        return src[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test31_verifier(boolean warmup) {\n+        MyValue2 v1 = MyValue2.createWithFieldsInline(rI, rD);\n+        long result1 = test31(true, !warmup);\n+        Asserts.assertEQ(result1, v1.hash());\n+        MyValue2 v2 = MyValue2.createWithFieldsInline(rI+1, rD+1);\n+        long result2 = test31(false, !warmup);\n+        Asserts.assertEQ(result2, v2.hash());\n+    }\n+\n+    \/\/ Tests with Object arrays and clone\/arraycopy\n+    \/\/ clone() as stub call\n+    @Test\n+    public Object[] test32(Object[] va) {\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test32_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        MyValue1[] result = (MyValue1[])test32(va);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(((MyValue1)result[i]).hash(), ((MyValue1)va[i]).hash());\n+        }\n+    }\n+\n+    @Test\n+    public Object[] test33(Object[] va) {\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] va = new Object[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        Object[] result = test33(va);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(((MyValue1)result[i]).hash(), ((MyValue1)va[i]).hash());\n+            \/\/ Check that array has correct properties (null-ok)\n+            result[i] = null;\n+        }\n+    }\n+\n+    \/\/ clone() as series of loads\/stores\n+    static Object[] test34_orig = null;\n+\n+    @ForceInline\n+    public Object[] test34_helper(boolean flag) {\n+        Object[] va = null;\n+        if (flag) {\n+            va = new MyValue1[8];\n+            for (int i = 0; i < va.length; ++i) {\n+                va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+            }\n+        } else {\n+            va = new Object[8];\n+        }\n+        return va;\n+    }\n+\n+    @Test\n+    public Object[] test34(boolean flag) {\n+        Object[] va = test34_helper(flag);\n+        test34_orig = va;\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        test34(false);\n+        for (int i = 0; i < 10; i++) { \/\/ make sure we do deopt\n+            Object[] result = test34(true);\n+            verify(test34_orig, result);\n+            \/\/ Check that array has correct properties (null-free)\n+            try {\n+                result[0] = null;\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test34\")) {\n+            Object[] result = test34(true);\n+            verify(test34_orig, result);\n+            \/\/ Check that array has correct properties (null-free)\n+            try {\n+                result[0] = null;\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    static void verify(Object[] src, Object[] dst) {\n+        if (src instanceof MyInterface[] && dst instanceof MyInterface[]) {\n+            for (int i = 0; i < src.length; ++i) {\n+                Asserts.assertEQ(((MyInterface)src[i]).hash(), ((MyInterface)dst[i]).hash());\n+            }\n+        } else {\n+            for (int i = 0; i < src.length; ++i) {\n+                Asserts.assertEQ(src[i], dst[i]);\n+            }\n+        }\n+    }\n+\n+    static void verify(MyValue1[] src, MyValue1[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    static void verify(MyValue1[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            Asserts.assertEQ(src[i].hash(), ((MyInterface)dst[i]).hash());\n+        }\n+    }\n+\n+    static void verify(MyValue2[] src, MyValue2[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    static void verify(MyValue2[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            Asserts.assertEQ(src[i].hash(), ((MyInterface)dst[i]).hash());\n+        }\n+    }\n+\n+    static boolean compile_and_run_again_if_deoptimized(boolean warmup, String test) {\n+        if (!warmup) {\n+            Method m = tests.get(test);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false)) {\n+                if (!InlineTypeArrayFlatten && !XCOMP && !STRESS_CC) {\n+                    throw new RuntimeException(\"Unexpected deoptimization\");\n+                }\n+                enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    \/\/ arraycopy() of inline type array of unknown size\n+    @Test\n+    public void test35(Object src, Object dst, int len) {\n+        System.arraycopy(src, 0, dst, 0, len);\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] src = new MyValue1[len];\n+        MyValue1[] dst1 = new MyValue1[len];\n+        Object[] dst2 = new Object[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        test35(src, dst1, src.length);\n+        verify(src, dst1);\n+        test35(src, dst2, src.length);\n+        verify(src, dst2);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test35\")) {\n+            test35(src, dst1, src.length);\n+            verify(src, dst1);\n+        }\n+    }\n+\n+    @Test\n+    public void test36(Object src, MyValue2[] dst) {\n+        System.arraycopy(src, 0, dst, 0, dst.length);\n+    }\n+\n+    @DontCompile\n+    public void test36_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2[] src = new MyValue2[len];\n+        MyValue2[] dst = new MyValue2[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test36(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test36\")) {\n+            test36(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test37(MyValue2[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2[] src = new MyValue2[len];\n+        MyValue2[] dst = new MyValue2[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test37(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test37\")) {\n+            test37(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(1) \/\/ Avoid early compilation\n+    public void test38(Object src, MyValue2[] dst) {\n+        System.arraycopy(src, 0, dst, 0, dst.length);\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] src = new Object[len];\n+        MyValue2[] dst = new MyValue2[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test38(src, dst);\n+        verify(dst, src);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestArrays::test38\");\n+            assertDeoptimizedByC2(m);\n+            enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            test38(src, dst);\n+            verify(dst, src);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test39(MyValue2[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2[] src = new MyValue2[len];\n+        Object[] dst = new Object[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test39(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test39\")) {\n+            test39(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(1) \/\/ Avoid early compilation\n+    public void test40(Object[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] src = new Object[len];\n+        MyValue2[] dst = new MyValue2[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test40(src, dst);\n+        verify(dst, src);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestArrays::test40\");\n+            assertDeoptimizedByC2(m);\n+            enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            test40(src, dst);\n+            verify(dst, src);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test41(Object src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, dst.length);\n+    }\n+\n+    @DontCompile\n+    public void test41_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2[] src = new MyValue2[len];\n+        Object[] dst = new Object[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test41(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test41\")) {\n+            test41(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test42(Object[] src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test42_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] src = new Object[len];\n+        Object[] dst = new Object[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test42(src, dst);\n+        verify(src, dst);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestArrays::test42\");\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    \/\/ short arraycopy()'s\n+    @Test\n+    public void test43(Object src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test43_verifier(boolean warmup) {\n+        MyValue1[] src = new MyValue1[8];\n+        MyValue1[] dst = new MyValue1[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        test43(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test43\")) {\n+            test43(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test44(Object src, MyValue2[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test44_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[8];\n+        MyValue2[] dst = new MyValue2[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test44(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test44\")) {\n+            test44(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test45(MyValue2[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test45_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[8];\n+        MyValue2[] dst = new MyValue2[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test45(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test45\")) {\n+            test45(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(1) \/\/ Avoid early compilation\n+    public void test46(Object[] src, MyValue2[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test46_verifier(boolean warmup) {\n+        Object[] src = new Object[8];\n+        MyValue2[] dst = new MyValue2[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test46(src, dst);\n+        verify(dst, src);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestArrays::test46\");\n+            assertDeoptimizedByC2(m);\n+            enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            test46(src, dst);\n+            verify(dst, src);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test47(MyValue2[] src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test47_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[8];\n+        Object[] dst = new Object[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test47(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test47\")) {\n+            test47(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(1) \/\/ Avoid early compilation\n+    public void test48(Object[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test48_verifier(boolean warmup) {\n+        Object[] src = new Object[8];\n+        MyValue2[] dst = new MyValue2[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test48(src, dst);\n+        verify(dst, src);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestArrays::test48\");\n+            assertDeoptimizedByC2(m);\n+            enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            test48(src, dst);\n+            verify(dst, src);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test49(Object src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test49_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[8];\n+        Object[] dst = new Object[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test49(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test49\")) {\n+            test49(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test50(Object[] src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test50_verifier(boolean warmup) {\n+        Object[] src = new Object[8];\n+        Object[] dst = new Object[8];\n+        for (int i = 0; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test50(src, dst);\n+        verify(src, dst);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestArrays::test50\");\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public MyValue1[] test51(MyValue1[] va) {\n+        \/\/ TODO 8244562: Remove cast as workaround once javac is fixed\n+        Object[] res = Arrays.copyOf(va, va.length, MyValue1[].class);\n+        return (MyValue1[]) res;\n+    }\n+\n+    @DontCompile\n+    public void test51_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        MyValue1[] result = test51(va);\n+        verify(va, result);\n+    }\n+\n+    static final MyValue1[] test52_va = new MyValue1[8];\n+\n+    @Test\n+    public MyValue1[] test52() {\n+        \/\/ TODO 8244562: Remove cast as workaround once javac is fixed\n+        Object[] res = Arrays.copyOf(test52_va, 8, MyValue1[].class);\n+        return (MyValue1[]) res;\n+    }\n+\n+    @DontCompile\n+    public void test52_verifier(boolean warmup) {\n+        for (int i = 0; i < 8; ++i) {\n+            test52_va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        MyValue1[] result = test52();\n+        verify(test52_va, result);\n+    }\n+\n+    @Test\n+    public MyValue1[] test53(Object[] va) {\n+        \/\/ TODO 8244562: Remove cast as workaround once javac is fixed\n+        Object[] res = Arrays.copyOf(va, va.length, MyValue1[].class);\n+        return (MyValue1[]) res;\n+    }\n+\n+    @DontCompile\n+    public void test53_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        MyValue1[] result = test53(va);\n+        verify(result, va);\n+    }\n+\n+    @Test\n+    public Object[] test54(MyValue1[] va) {\n+        return Arrays.copyOf(va, va.length, Object[].class);\n+    }\n+\n+    @DontCompile\n+    public void test54_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        Object[] result = test54(va);\n+        verify(va, result);\n+    }\n+\n+    @Test\n+    public Object[] test55(Object[] va) {\n+        return Arrays.copyOf(va, va.length, Object[].class);\n+    }\n+\n+    @DontCompile\n+    public void test55_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        Object[] result = test55(va);\n+        verify(va, result);\n+    }\n+\n+    @Test\n+    public MyValue1[] test56(Object[] va) {\n+        \/\/ TODO 8244562: Remove cast as workaround once javac is fixed\n+        Object[] res = Arrays.copyOf(va, va.length, MyValue1[].class);\n+        return (MyValue1[]) res;\n+    }\n+\n+    @DontCompile\n+    public void test56_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] va = new Object[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        MyValue1[] result = test56(va);\n+        verify(result, va);\n+    }\n+\n+   @Test\n+    public Object[] test57(Object[] va, Class klass) {\n+        return Arrays.copyOf(va, va.length, klass);\n+    }\n+\n+    @DontCompile\n+    public void test57_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        Object[] result = test57(va, MyValue1[].class);\n+        verify(va, result);\n+    }\n+\n+    @Test\n+    public Object[] test58(MyValue1[] va, Class klass) {\n+        return Arrays.copyOf(va, va.length, klass);\n+    }\n+\n+    @DontCompile\n+    public void test58_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        for (int i = 0; i < 10; i++) {\n+            Object[] result = test58(va, MyValue1[].class);\n+            verify(va, result);\n+        }\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestArrays::test58\")) {\n+            Object[] result = test58(va, MyValue1[].class);\n+            verify(va, result);\n+        }\n+    }\n+\n+    @Test\n+    public Object[] test59(MyValue1[] va) {\n+        return Arrays.copyOf(va, va.length+1, MyValue1[].class);\n+    }\n+\n+    @DontCompile\n+    public void test59_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        MyValue1[] verif = new MyValue1[len+1];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+            verif[i] = va[i];\n+        }\n+        Object[] result = test59(va);\n+        verify(verif, result);\n+    }\n+\n+    @Test\n+    public Object[] test60(Object[] va, Class klass) {\n+        return Arrays.copyOf(va, va.length+1, klass);\n+    }\n+\n+    @DontCompile\n+    public void test60_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        MyValue1[] verif = new MyValue1[len+1];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+            verif[i] = (MyValue1)va[i];\n+        }\n+        Object[] result = test60(va, MyValue1[].class);\n+        verify(verif, result);\n+    }\n+\n+    @Test\n+    public Object[] test61(Object[] va, Class klass) {\n+        return Arrays.copyOf(va, va.length+1, klass);\n+    }\n+\n+    @DontCompile\n+    public void test61_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] va = new Integer[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = Integer.valueOf(rI);\n+        }\n+        Object[] result = test61(va, Integer[].class);\n+        for (int i = 0; i < va.length; ++i) {\n+            Asserts.assertEQ(va[i], result[i]);\n+        }\n+    }\n+\n+    @ForceInline\n+    public Object[] test62_helper(int i, MyValue1[] va, Integer[] oa) {\n+        Object[] arr = null;\n+        if (i == 10) {\n+            arr = oa;\n+        } else {\n+            arr = va;\n+        }\n+        return arr;\n+    }\n+\n+    @Test\n+    public Object[] test62(MyValue1[] va, Integer[] oa) {\n+        int i = 0;\n+        for (; i < 10; i++);\n+\n+        Object[] arr = test62_helper(i, va, oa);\n+\n+        return Arrays.copyOf(arr, arr.length+1, arr.getClass());\n+    }\n+\n+    @DontCompile\n+    public void test62_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        Integer[] oa = new Integer[len];\n+        for (int i = 0; i < len; ++i) {\n+            oa[i] = Integer.valueOf(rI);\n+        }\n+        test62_helper(42, va, oa);\n+        Object[] result = test62(va, oa);\n+        for (int i = 0; i < va.length; ++i) {\n+            Asserts.assertEQ(oa[i], result[i]);\n+        }\n+    }\n+\n+    @ForceInline\n+    public Object[] test63_helper(int i, MyValue1[] va, Integer[] oa) {\n+        Object[] arr = null;\n+        if (i == 10) {\n+            arr = va;\n+        } else {\n+            arr = oa;\n+        }\n+        return arr;\n+    }\n+\n+    @Test\n+    public Object[] test63(MyValue1[] va, Integer[] oa) {\n+        int i = 0;\n+        for (; i < 10; i++);\n+\n+        Object[] arr = test63_helper(i, va, oa);\n+\n+        return Arrays.copyOf(arr, arr.length+1, arr.getClass());\n+    }\n+\n+    @DontCompile\n+    public void test63_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        MyValue1[] verif = new MyValue1[len+1];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+            verif[i] = va[i];\n+        }\n+        Integer[] oa = new Integer[len];\n+        test63_helper(42, va, oa);\n+        Object[] result = test63(va, oa);\n+        verify(verif, result);\n+    }\n+\n+    \/\/ Test default initialization of inline type arrays: small array\n+    @Test\n+    public MyValue1[] test64() {\n+        return new MyValue1[8];\n+    }\n+\n+    @DontCompile\n+    public void test64_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[8];\n+        MyValue1[] var = test64();\n+        for (int i = 0; i < 8; ++i) {\n+            Asserts.assertEQ(va[i].hashPrimitive(), var[i].hashPrimitive());\n+        }\n+    }\n+\n+    \/\/ Test default initialization of inline type arrays: large array\n+    @Test\n+    public MyValue1[] test65() {\n+        return new MyValue1[32];\n+    }\n+\n+    @DontCompile\n+    public void test65_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[32];\n+        MyValue1[] var = test65();\n+        for (int i = 0; i < 32; ++i) {\n+            Asserts.assertEQ(va[i].hashPrimitive(), var[i].hashPrimitive());\n+        }\n+    }\n+\n+    \/\/ Check init store elimination\n+    @Test(match = { ALLOCA }, matchCount = { 1 })\n+    public MyValue1[] test66(MyValue1 vt) {\n+        MyValue1[] va = new MyValue1[1];\n+        va[0] = vt;\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test66_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1[] va = test66(vt);\n+        Asserts.assertEQ(va[0].hashPrimitive(), vt.hashPrimitive());\n+    }\n+\n+    \/\/ Zeroing elimination and arraycopy\n+    @Test\n+    public MyValue1[] test67(MyValue1[] src) {\n+        MyValue1[] dst = new MyValue1[16];\n+        System.arraycopy(src, 0, dst, 0, 13);\n+        return dst;\n+    }\n+\n+    @DontCompile\n+    public void test67_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[16];\n+        MyValue1[] var = test67(va);\n+        for (int i = 0; i < 16; ++i) {\n+            Asserts.assertEQ(va[i].hashPrimitive(), var[i].hashPrimitive());\n+        }\n+    }\n+\n+    \/\/ A store with a default value can be eliminated\n+    @Test\n+    public MyValue1[] test68() {\n+        MyValue1[] va = new MyValue1[2];\n+        va[0] = va[1];\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test68_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[2];\n+        MyValue1[] var = test68();\n+        for (int i = 0; i < 2; ++i) {\n+            Asserts.assertEQ(va[i].hashPrimitive(), var[i].hashPrimitive());\n+        }\n+    }\n+\n+    \/\/ Requires individual stores to init array\n+    @Test\n+    public MyValue1[] test69(MyValue1 vt) {\n+        MyValue1[] va = new MyValue1[4];\n+        va[0] = vt;\n+        va[3] = vt;\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test69_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1[] va = new MyValue1[4];\n+        va[0] = vt;\n+        va[3] = vt;\n+        MyValue1[] var = test69(vt);\n+        for (int i = 0; i < va.length; ++i) {\n+            Asserts.assertEQ(va[i].hashPrimitive(), var[i].hashPrimitive());\n+        }\n+    }\n+\n+    \/\/ A store with a default value can be eliminated: same as test68\n+    \/\/ but store is farther away from allocation\n+    @Test\n+    public MyValue1[] test70(MyValue1[] other) {\n+        other[1] = other[0];\n+        MyValue1[] va = new MyValue1[2];\n+        other[0] = va[1];\n+        va[0] = va[1];\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test70_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[2];\n+        MyValue1[] var = test70(va);\n+        for (int i = 0; i < 2; ++i) {\n+            Asserts.assertEQ(va[i].hashPrimitive(), var[i].hashPrimitive());\n+        }\n+    }\n+\n+    \/\/ EA needs to consider oop fields in flattened arrays\n+    @Test\n+    public void test71() {\n+        int len = 10;\n+        MyValue2[] src = new MyValue2[len];\n+        MyValue2[] dst = new MyValue2[len];\n+        for (int i = 0; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsDontInline(rI+i, rD+i);\n+        }\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test71_verifier(boolean warmup) {\n+        test71();\n+    }\n+\n+    \/\/ Test EA with leaf call to 'store_unknown_inline'\n+    @Test\n+    public void test72(Object[] o, boolean b, Object element) {\n+        Object[] arr1 = new Object[10];\n+        Object[] arr2 = new Object[10];\n+        if (b) {\n+            arr1 = o;\n+        }\n+        arr1[0] = element;\n+        arr2[0] = element;\n+    }\n+\n+    @DontCompile\n+    public void test72_verifier(boolean warmup) {\n+        Object[] arr = new Object[1];\n+        Object elem = new Object();\n+        test72(arr, true, elem);\n+        test72(arr, false, elem);\n+    }\n+\n+    @Test\n+    public void test73(Object[] oa, MyValue1 v, Object o) {\n+        \/\/ TestLWorld.test38 use a C1 Phi node for the array. This test\n+        \/\/ adds the case where the stored value is a C1 Phi node.\n+        Object o2 = (o == null) ? v : o;\n+        oa[0] = v;  \/\/ The stored value is known to be flattenable\n+        oa[1] = o;  \/\/ The stored value may be flattenable\n+        oa[2] = o2; \/\/ The stored value may be flattenable (a C1 Phi node)\n+        oa[0] = oa; \/\/ The stored value is known to be not flattenable (an Object[])\n+    }\n+\n+    @DontCompile\n+    public void test73_verifier(boolean warmup) {\n+        MyValue1 v0 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1 v1 = MyValue1.createWithFieldsDontInline(rI+1, rL+1);\n+        MyValue1[] arr = new MyValue1[3];\n+        try {\n+            test73(arr, v0, v1);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+        Asserts.assertEQ(arr[0].hash(), v0.hash());\n+        Asserts.assertEQ(arr[1].hash(), v1.hash());\n+        Asserts.assertEQ(arr[2].hash(), v1.hash());\n+    }\n+\n+    public static void test74Callee(MyValue1[] va) { }\n+\n+    \/\/ Tests invoking unloaded method with inline type array in signature\n+    @Test\n+    @Warmup(0)\n+    public void test74(MethodHandle m, MyValue1[] va) throws Throwable {\n+        m.invoke(va);\n+    }\n+\n+    @DontCompile\n+    public void test74_verifier(boolean warmup) throws Throwable {\n+        MethodHandle m = MethodHandles.lookup().findStatic(TestArrays.class, \"test74Callee\", MethodType.methodType(void.class, MyValue1[].class));\n+        MyValue1[] va = new MyValue1[0];\n+        test74(m, va);\n+    }\n+\n+    \/\/ Some more array clone tests\n+    @ForceInline\n+    public Object[] test75_helper(int i, MyValue1[] va, Integer[] oa) {\n+        Object[] arr = null;\n+        if (i == 10) {\n+            arr = oa;\n+        } else {\n+            arr = va;\n+        }\n+        return arr;\n+    }\n+\n+    @Test\n+    public Object[] test75(MyValue1[] va, Integer[] oa) {\n+        int i = 0;\n+        for (; i < 10; i++);\n+\n+        Object[] arr = test75_helper(i, va, oa);\n+        return arr.clone();\n+    }\n+\n+    @DontCompile\n+    public void test75_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        Integer[] oa = new Integer[len];\n+        for (int i = 0; i < len; ++i) {\n+            oa[i] = Integer.valueOf(rI);\n+        }\n+        test75_helper(42, va, oa);\n+        Object[] result = test75(va, oa);\n+\n+        for (int i = 0; i < va.length; ++i) {\n+            Asserts.assertEQ(oa[i], result[i]);\n+            \/\/ Check that array has correct properties (null-ok)\n+            result[i] = null;\n+        }\n+    }\n+\n+    @ForceInline\n+    public Object[] test76_helper(int i, MyValue1[] va, Integer[] oa) {\n+        Object[] arr = null;\n+        if (i == 10) {\n+            arr = va;\n+        } else {\n+            arr = oa;\n+        }\n+        return arr;\n+    }\n+\n+    @Test\n+    public Object[] test76(MyValue1[] va, Integer[] oa) {\n+        int i = 0;\n+        for (; i < 10; i++);\n+\n+        Object[] arr = test76_helper(i, va, oa);\n+        return arr.clone();\n+    }\n+\n+    @DontCompile\n+    public void test76_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1[] va = new MyValue1[len];\n+        MyValue1[] verif = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+            verif[i] = va[i];\n+        }\n+        Integer[] oa = new Integer[len];\n+        test76_helper(42, va, oa);\n+        Object[] result = test76(va, oa);\n+        verify(verif, result);\n+        \/\/ Check that array has correct properties (null-free)\n+        if (len > 0) {\n+            try {\n+                result[0] = null;\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test77() {\n+        MyValue1 v0 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1 v1 = MyValue1.createWithFieldsDontInline(rI+1, rL+1);\n+        MyValue1[] arr = new MyValue1[1];\n+\n+        Object[] oa = arr;\n+        Object o1 = v1;\n+        Object o = (o1 == null) ? v0 : o1;\n+\n+        oa[0] = o; \/\/ For C1, due to IfOp optimization, the declared_type of o becomes NULL.\n+\n+        Asserts.assertEQ(arr[0].hash(), v1.hash());\n+    }\n+\n+\n+    @DontCompile\n+    public void test77_verifier(boolean warmup) {\n+        test77();\n+    }\n+\n+    @Test\n+    public long test78(MyValue1 v, int n) {\n+        long x = 0;\n+        for (int i = 0; i<n; i++) {\n+        }\n+\n+        MyValue1[] a = new MyValue1[n];\n+        a[0] = v;\n+        for (int i = 0; i<n; i++) {\n+            x += a[i].hash(); \/\/ C1 PhiSimplifier changes \"a\" from a Phi node to a NewObjectArray node\n+        }\n+\n+        return x;\n+    }\n+\n+    @DontCompile\n+    public void test78_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        Asserts.assertEQ(test78(v, 1), v.hash());\n+    }\n+\n+    \/\/ Verify that casting an array element to a non-flattenable type marks the array as not-flat\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { ALLOC_G, LOAD_UNKNOWN_INLINE }, matchCount = { 1, 1 })\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE)\n+    public Object test79(Object[] array, int i) {\n+        Integer i1 = (Integer)array[0];\n+        Object o = array[1];\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test79_verifier(boolean warmup) {\n+        Integer i = Integer.valueOf(rI);\n+        Integer[] array = new Integer[2];\n+        array[1] = i;\n+        Object result = test79(array, 1);\n+        Asserts.assertEquals(result, i);\n+    }\n+\n+    primitive static class NotFlattenable {\n+        private final Object o1 = null;\n+        private final Object o2 = null;\n+        private final Object o3 = null;\n+        private final Object o4 = null;\n+        private final Object o5 = null;\n+        private final Object o6 = null;\n+    }\n+\n+    \/\/ Same as test79 but with not-flattenable inline type\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { ALLOC_G, LOAD_UNKNOWN_INLINE }, matchCount = { 1, 1 })\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE)\n+    public Object test80(Object[] array, int i) {\n+        NotFlattenable vt = (NotFlattenable)array[0];\n+        Object o = array[1];\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test80_verifier(boolean warmup) {\n+        NotFlattenable vt = new NotFlattenable();\n+        NotFlattenable[] array = new NotFlattenable[2];\n+        array[1] = vt;\n+        Object result = test80(array, 1);\n+        Asserts.assertEquals(result, vt);\n+    }\n+\n+    \/\/ Verify that writing an object of a non-inline, non-null type to an array marks the array as not-null-free and not-flat\n+    @Test(failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    public Object test81(Object[] array, Integer v, Object o, int i) {\n+        if (v == null) {\n+          return null;\n+        }\n+        array[0] = v;\n+        array[1] = array[0];\n+        array[2] = o;\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test81_verifier(boolean warmup) {\n+        Integer i = Integer.valueOf(rI);\n+        Integer[] array1 = new Integer[3];\n+        Object[] array2 = new Object[3];\n+        Object result = test81(array1, i, i, 0);\n+        Asserts.assertEquals(array1[0], i);\n+        Asserts.assertEquals(array1[1], i);\n+        Asserts.assertEquals(array1[2], i);\n+        Asserts.assertEquals(result, i);\n+        result = test81(array2, i, i, 1);\n+        Asserts.assertEquals(array2[0], i);\n+        Asserts.assertEquals(array2[1], i);\n+        Asserts.assertEquals(array2[2], i);\n+        Asserts.assertEquals(result, i);\n+    }\n+\n+    \/\/ Verify that writing an object of a non-flattenable inline type to an array marks the array as not-flat\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, failOn = ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE)\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE)\n+    public Object test82(Object[] array, NotFlattenable vt, Object o, int i) {\n+        array[0] = vt;\n+        array[1] = array[0];\n+        array[2] = o;\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test82_verifier(boolean warmup) {\n+        NotFlattenable vt = new NotFlattenable();\n+        NotFlattenable[] array1 = new NotFlattenable[3];\n+        Object[] array2 = new Object[3];\n+        Object result = test82(array1, vt, vt, 0);\n+        Asserts.assertEquals(array1[0], vt);\n+        Asserts.assertEquals(array1[1], vt);\n+        Asserts.assertEquals(array1[2], vt);\n+        Asserts.assertEquals(result, vt);\n+        result = test82(array2, vt, vt, 1);\n+        Asserts.assertEquals(array2[0], vt);\n+        Asserts.assertEquals(array2[1], vt);\n+        Asserts.assertEquals(array2[2], vt);\n+        Asserts.assertEquals(result, vt);\n+    }\n+\n+    \/\/ Verify that casting an array element to a non-inline type type marks the array as not-null-free and not-flat\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { ALLOC_G, LOAD_UNKNOWN_INLINE }, matchCount = { 1, 1 }, failOn = ALLOCA_G + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    public void test83(Object[] array, Object o) {\n+        Integer i = (Integer)array[0];\n+        array[1] = o;\n+    }\n+\n+    @DontCompile\n+    public void test83_verifier(boolean warmup) {\n+        Integer i = Integer.valueOf(rI);\n+        Integer[] array1 = new Integer[2];\n+        Object[] array2 = new Object[2];\n+        test83(array1, i);\n+        Asserts.assertEquals(array1[1], i);\n+        test83(array2, null);\n+        Asserts.assertEquals(array2[1], null);\n+    }\n+\n+    \/\/ Verify that writing constant null into an array marks the array as not-null-free and not-flat\n+    @Test(failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE, match = { INLINE_ARRAY_NULL_GUARD }, matchCount = { 1 })\n+    public Object test84(Object[] array, int i) {\n+        array[0] = null;\n+        array[1] = null;\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test84_verifier(boolean warmup) {\n+        NotFlattenable.ref[] array1 = new NotFlattenable.ref[2];\n+        Object[] array2 = new Object[2];\n+        Object result = test84(array1, 0);\n+        Asserts.assertEquals(array1[0], null);\n+        Asserts.assertEquals(result, null);\n+        result = test84(array2, 1);\n+        Asserts.assertEquals(array2[0], null);\n+        Asserts.assertEquals(result, null);\n+        if (!warmup) {\n+            NotFlattenable[] array3 = new NotFlattenable[2];\n+            try {\n+                test84(array3, 1);\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    \/\/ Same as test84 but with branches\n+    @Test(failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE, match = { INLINE_ARRAY_NULL_GUARD }, matchCount = { 2 })\n+    public void test85(Object[] array, Object o, boolean b) {\n+        if (b) {\n+            array[0] = null;\n+        } else {\n+            array[1] = null;\n+        }\n+        array[1] = o;\n+    }\n+\n+    @DontCompile\n+    public void test85_verifier(boolean warmup) {\n+        Integer i = Integer.valueOf(rI);\n+        Integer[] array1 = new Integer[2];\n+        Object[] array2 = new Object[2];\n+        test85(array1, i, true);\n+        Asserts.assertEquals(array1[1], i);\n+        test85(array1, null, false);\n+        Asserts.assertEquals(array1[1], null);\n+        test85(array2, i, true);\n+        Asserts.assertEquals(array2[1], i);\n+        test85(array2, null, false);\n+        Asserts.assertEquals(array2[1], null);\n+        if (!warmup) {\n+            NotFlattenable[] array3 = new NotFlattenable[2];\n+            try {\n+                test85(array3, null, true);\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    \/\/ Same as test85 but with not-flattenable inline type array\n+    @Test(failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE, match = { INLINE_ARRAY_NULL_GUARD }, matchCount = { 2 })\n+    public void test86(NotFlattenable.ref[] array, NotFlattenable.ref o, boolean b) {\n+        if (b) {\n+            array[0] = null;\n+        } else {\n+            array[1] = null;\n+        }\n+        array[1] = o;\n+    }\n+\n+    @DontCompile\n+    public void test86_verifier(boolean warmup) {\n+        NotFlattenable vt = new NotFlattenable();\n+        NotFlattenable.ref[] array1 = new NotFlattenable.ref[2];\n+        test86(array1, vt, true);\n+        Asserts.assertEquals(array1[1], vt);\n+        test86(array1, null, false);\n+        Asserts.assertEquals(array1[1], null);\n+        if (!warmup) {\n+            NotFlattenable[] array2 = new NotFlattenable[2];\n+            try {\n+                test86(array2, null, true);\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    \/\/ Same as test85 but with inline type array\n+    @Test(failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE, match = { INLINE_ARRAY_NULL_GUARD }, matchCount = { 2 })\n+    public void test87(MyValue1.ref[] array, MyValue1.ref o, boolean b) {\n+        if (b) {\n+            array[0] = null;\n+        } else {\n+            array[1] = null;\n+        }\n+        array[1] = o;\n+    }\n+\n+    @DontCompile\n+    public void test87_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1.ref[] array1 = new MyValue1.ref[2];\n+        test87(array1, vt, true);\n+        Asserts.assertEquals(array1[1], vt);\n+        test87(array1, null, false);\n+        Asserts.assertEquals(array1[1], null);\n+        if (!warmup) {\n+            MyValue1[] array2 = new MyValue1[2];\n+            try {\n+                test87(array2, null, true);\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    \/\/ Additional correctness tests to make sure we have the required null checks\n+    @Test()\n+    public void test88(Object[] array, Integer v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test88_verifier(boolean warmup) {\n+        Integer[] array1 = new Integer[1];\n+        Object[] array2 = new Object[1];\n+        test88(array1, null);\n+        Asserts.assertEquals(array1[0], null);\n+        test88(array2, null);\n+        Asserts.assertEquals(array2[0], null);\n+        if (!warmup) {\n+            MyValue1[] array3 = new MyValue1[1];\n+            try {\n+                test88(array3, null);\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test()\n+    public void test89(MyValue1.ref[] array, Integer v) {\n+        Object o = v;\n+        array[0] = (MyValue1.ref)o;\n+    }\n+\n+    @DontCompile\n+    public void test89_verifier(boolean warmup) {\n+        MyValue1.ref[] array1 = new MyValue1.ref[1];\n+        test89(array1, null);\n+        Asserts.assertEquals(array1[0], null);\n+        if (!warmup) {\n+            MyValue1[] array2 = new MyValue1[1];\n+            try {\n+                test89(array2, null);\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public boolean test90() {\n+        boolean b = true;\n+\n+        MyValue1[] qArray = new MyValue1[0];\n+        MyValue1.ref[] lArray = new MyValue1.ref[0];\n+\n+        b = b && (qArray instanceof MyValue1[]);\n+        b = b && (lArray instanceof MyValue1.ref[]);\n+\n+        MyValue1[][] qArray2 = new MyValue1[0][0];\n+        MyValue1.ref[][] lArray2 = new MyValue1.ref[0][0];\n+\n+        b = b && (qArray2 instanceof MyValue1[][]);\n+        b = b && (lArray2 instanceof MyValue1.ref[][]);\n+\n+        return b;\n+    }\n+\n+    @DontCompile\n+    public void test90_verifier(boolean warmup) {\n+        Asserts.assertEQ(test90(), true);\n+    }\n+\n+    primitive static final class Test91Value {\n+        public final int f0;\n+        public final int f1;\n+        public final int f2;\n+        public final int f3;\n+        public final int f4;\n+        public final int f5;\n+\n+        public Test91Value(int i) {\n+            this.f0 = i;\n+            this.f1 = i;\n+            this.f2 = i;\n+            this.f3 = i;\n+            this.f4 = i;\n+            this.f5 = i;\n+        }\n+\n+        public void verify() {\n+            if ((f0 != f1) || (f1 != f2) || (f2 != f3) || (f3 != f4) || (f4 != f5)) {\n+                throw new RuntimeException(\"test91 failed\");\n+            }\n+        }\n+    }\n+\n+    \/\/ Test anti-dependencies between loads and stores from flattened array\n+    @Test\n+    @Warmup(0)\n+    public int test91(Test91Value[] array, int lo, int val) {\n+        int i = 3;\n+        while (lo < i) {\n+            Test91Value tmp = array[lo];\n+            array[lo++] = array[i];\n+            array[i--] = tmp;\n+        }\n+        return val;\n+    }\n+\n+    @DontCompile\n+    public void test91_verifier(boolean warmup) {\n+        Test91Value[] array = new Test91Value[5];\n+        for (int i = 0; i < 5; ++i) {\n+            array[i] = new Test91Value(i);\n+            array[i].verify();\n+        }\n+        Asserts.assertEQ(test91(array, 0, 5), 5);\n+        for (int i = 0; i < 5; ++i) {\n+            array[i].verify();\n+        }\n+    }\n+\n+    @Test\n+    public void test92(Object[] src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test92_verifier(boolean warmup) {\n+        MyValue1[] a = new MyValue1[1];\n+        MyValue1[] b = new MyValue1[1];\n+        try {\n+            test92(a, null);\n+            throw new RuntimeException(\"Should throw NullPointerException\");\n+        } catch (NullPointerException expected) {}\n+\n+        try {\n+            test92(null, b);\n+            throw new RuntimeException(\"Should throw NullPointerException\");\n+        } catch (NullPointerException expected) {}\n+\n+        a[0] = MyValue1.createWithFieldsInline(rI, rL);\n+        test92(a, b);\n+        verify(a, b);\n+    }\n+\n+    \/\/ Same as test30 but accessing all elements of the non-escaping array\n+    @Test\n+    @Warmup(10000)\n+    public long test93(MyValue2[] src, boolean flag) {\n+        MyValue2[] dst = new MyValue2[10];\n+        System.arraycopy(src, 0, dst, 0, 10);\n+        if (flag) {  }\n+        return dst[0].hash() + dst[1].hash() + dst[2].hash() + dst[3].hash() + dst[4].hash() +\n+               dst[5].hash() + dst[6].hash() + dst[7].hash() + dst[8].hash() + dst[9].hash();\n+    }\n+\n+    @DontCompile\n+    public void test93_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[10];\n+        for (int i = 0; i < 10; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        long res = test93(src, !warmup);\n+        long expected = 0;\n+        for (int i = 0; i < 10; ++i) {\n+            expected += src[i].hash();\n+        }\n+        Asserts.assertEQ(res, expected);\n+    }\n+\n+    \/\/ Same as test93 but with variable source array offset\n+    @Test\n+    @Warmup(10000)\n+    public long test94(MyValue2[] src, int i, boolean flag) {\n+        MyValue2[] dst = new MyValue2[10];\n+        System.arraycopy(src, i, dst, 0, 1);\n+        if (flag) {  }\n+        return dst[0].hash() + dst[1].hash() + dst[2].hash() + dst[3].hash() + dst[4].hash() +\n+               dst[5].hash() + dst[6].hash() + dst[7].hash() + dst[8].hash() + dst[9].hash();\n+    }\n+\n+    @DontCompile\n+    public void test94_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[10];\n+        for (int i = 0; i < 10; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        for (int i = 0; i < 10; ++i) {\n+            long res = test94(src, i, !warmup);\n+            long expected = src[i].hash() + 9*MyValue2.default.hash();\n+            Asserts.assertEQ(res, expected);\n+        }\n+    }\n+\n+    \/\/ Test propagation of not null-free\/flat information\n+    @Test(failOn = CHECKCAST_ARRAY)\n+    public MyValue1[] test95(Object[] array) {\n+        array[0] = null;\n+        \/\/ Always throws a ClassCastException because we just successfully\n+        \/\/ stored null and therefore the array can't be an inline type array.\n+        return (MyValue1[])array;\n+    }\n+\n+    @DontCompile\n+    public void test95_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[1];\n+        Integer[] array2 = new Integer[1];\n+        try {\n+            test95(array1);\n+            throw new RuntimeException(\"Should throw NullPointerException\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test95(array2);\n+            throw new RuntimeException(\"Should throw ClassCastException\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Same as test95 but with cmp user of cast result\n+    @Test(failOn = CHECKCAST_ARRAY)\n+    public boolean test96(Object[] array) {\n+        array[0] = null;\n+        \/\/ Always throws a ClassCastException because we just successfully\n+        \/\/ stored null and therefore the array can't be an inline type array.\n+        MyValue1[] casted = (MyValue1[])array;\n+        return casted != null;\n+    }\n+\n+    @DontCompile\n+    public void test96_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[1];\n+        Integer[] array2 = new Integer[1];\n+        try {\n+            test96(array1);\n+            throw new RuntimeException(\"Should throw NullPointerException\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test96(array2);\n+            throw new RuntimeException(\"Should throw ClassCastException\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Same as test95 but with instanceof instead of cast\n+    @Test(failOn = CHECKCAST_ARRAY)\n+    public boolean test97(Object[] array) {\n+        array[0] = 42;\n+        \/\/ Always throws a ClassCastException because we just successfully stored\n+        \/\/ a non-inline value and therefore the array can't be an inline type array.\n+        return array instanceof MyValue1[];\n+    }\n+\n+    @DontCompile\n+    public void test97_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[1];\n+        Integer[] array2 = new Integer[1];\n+        try {\n+            test97(array1);\n+            throw new RuntimeException(\"Should throw ArrayStoreException\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        boolean res = test97(array2);\n+        Asserts.assertFalse(res);\n+    }\n+\n+    \/\/ Same as test95 but with non-flattenable store\n+    @Test(valid = InlineTypeArrayFlattenOn, failOn = CHECKCAST_ARRAY)\n+    @Test(valid = InlineTypeArrayFlattenOff)\n+    public MyValue1[] test98(Object[] array) {\n+        array[0] = NotFlattenable.default;\n+        \/\/ Always throws a ClassCastException because we just successfully stored a\n+        \/\/ non-flattenable value and therefore the array can't be a flat array.\n+        return (MyValue1[])array;\n+    }\n+\n+    @DontCompile\n+    public void test98_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[1];\n+        NotFlattenable[] array2 = new NotFlattenable[1];\n+        try {\n+            test98(array1);\n+            throw new RuntimeException(\"Should throw ArrayStoreException\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test98(array2);\n+            throw new RuntimeException(\"Should throw ClassCastException\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Same as test98 but with cmp user of cast result\n+    @Test(valid = InlineTypeArrayFlattenOn, failOn = CHECKCAST_ARRAY)\n+    @Test(valid = InlineTypeArrayFlattenOff)\n+    public boolean test99(Object[] array) {\n+        array[0] = NotFlattenable.default;\n+        \/\/ Always throws a ClassCastException because we just successfully stored a\n+        \/\/ non-flattenable value and therefore the array can't be a flat array.\n+        MyValue1[] casted = (MyValue1[])array;\n+        return casted != null;\n+    }\n+\n+    @DontCompile\n+    public void test99_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[1];\n+        NotFlattenable[] array2 = new NotFlattenable[1];\n+        try {\n+            test99(array1);\n+            throw new RuntimeException(\"Should throw ArrayStoreException\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test99(array2);\n+            throw new RuntimeException(\"Should throw ClassCastException\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Same as test98 but with instanceof instead of cast\n+    @Test(valid = InlineTypeArrayFlattenOn, failOn = CHECKCAST_ARRAY)\n+    @Test(valid = InlineTypeArrayFlattenOff)\n+    public boolean test100(Object[] array) {\n+        array[0] = NotFlattenable.default;\n+        \/\/ Always throws a ClassCastException because we just successfully stored a\n+        \/\/ non-flattenable value and therefore the array can't be a flat array.\n+        return array instanceof MyValue1[];\n+    }\n+\n+    @DontCompile\n+    public void test100_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[1];\n+        NotFlattenable[] array2 = new NotFlattenable[1];\n+        try {\n+            test100(array1);\n+            throw new RuntimeException(\"Should throw ArrayStoreException\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        boolean res = test100(array2);\n+        Asserts.assertFalse(res);\n+    }\n+\n+    \/\/ Test that CHECKCAST_ARRAY matching works as expected\n+    @Test(match = { CHECKCAST_ARRAY }, matchCount = { 1 })\n+    public boolean test101(Object[] array) {\n+        return array instanceof MyValue1[];\n+    }\n+\n+    @DontCompile\n+    public void test101_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[1];\n+        NotFlattenable[] array2 = new NotFlattenable[1];\n+        Asserts.assertTrue(test101(array1));\n+        Asserts.assertFalse(test101(array2));\n+    }\n+\n+    static final MyValue2[] val_src = new MyValue2[8];\n+    static final MyValue2[] val_dst = new MyValue2[8];\n+    static final Object[]   obj_src = new Object[8];\n+    static final Object[]   obj_null_src = new Object[8];\n+    static final Object[]   obj_dst = new Object[8];\n+\n+    static Object get_val_src() { return val_src; }\n+    static Object get_val_dst() { return val_dst; }\n+    static Class get_val_class() { return MyValue2[].class; }\n+    static Class get_int_class() { return Integer[].class; }\n+    static Object get_obj_src() { return obj_src; }\n+    static Object get_obj_null_src() { return obj_null_src; }\n+    static Object get_obj_dst() { return obj_dst; }\n+    static Class get_obj_class() { return Object[].class; }\n+\n+    static {\n+        for (int i = 0; i < 8; ++i) {\n+            val_src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            obj_src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            obj_null_src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        obj_null_src[0] = null;\n+    }\n+\n+    \/\/ Arraycopy with constant source and destination arrays\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { INTRINSIC_SLOW_PATH }, matchCount = { 1 })\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = INTRINSIC_SLOW_PATH)\n+    public void test102() {\n+        System.arraycopy(val_src, 0, obj_dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test102_verifier(boolean warmup) {\n+        test102();\n+        verify(val_src, obj_dst);\n+    }\n+\n+    \/\/ Same as test102 but with MyValue2[] dst\n+    @Test(failOn = INTRINSIC_SLOW_PATH)\n+    public void test103() {\n+        System.arraycopy(val_src, 0, val_dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test103_verifier(boolean warmup) {\n+        test103();\n+        verify(val_src, val_dst);\n+    }\n+\n+    \/\/ Same as test102 but with Object[] src\n+    @Test(failOn = INTRINSIC_SLOW_PATH)\n+    public void test104() {\n+        System.arraycopy(obj_src, 0, obj_dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test104_verifier(boolean warmup) {\n+        test104();\n+        verify(obj_src, obj_dst);\n+    }\n+\n+    \/\/ Same as test103 but with Object[] src\n+    @Test(match = { INTRINSIC_SLOW_PATH }, matchCount = { 1 })\n+    public void test105() {\n+        System.arraycopy(obj_src, 0, val_dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test105_verifier(boolean warmup) {\n+        test105();\n+        verify(obj_src, val_dst);\n+    }\n+\n+    \/\/ Same as test103 but with Object[] src containing null\n+    @Test(match = { INTRINSIC_SLOW_PATH }, matchCount = { 1 })\n+    public void test105_null() {\n+        System.arraycopy(obj_null_src, 0, val_dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test105_null_verifier(boolean warmup) {\n+        try {\n+            test105_null();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    \/\/ Below tests are equal to test102-test105 but hide the src\/dst types until\n+    \/\/ after the arraycopy intrinsic is emitted (with incremental inlining).\n+\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { INTRINSIC_SLOW_PATH }, matchCount = { 1 })\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = INTRINSIC_SLOW_PATH)\n+    public void test106() {\n+        System.arraycopy(get_val_src(), 0, get_obj_dst(), 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test106_verifier(boolean warmup) {\n+        test106();\n+        verify(val_src, obj_dst);\n+    }\n+\n+    \/\/ TODO 8251971: Should be optimized but we are bailing out because\n+    \/\/ at parse time it looks as if src could be flat and dst could be not flat.\n+    @Test(valid = InlineTypeArrayFlattenOn)\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = INTRINSIC_SLOW_PATH)\n+    public void test107() {\n+        System.arraycopy(get_val_src(), 0, get_val_dst(), 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test107_verifier(boolean warmup) {\n+        test107();\n+        verify(val_src, val_dst);\n+    }\n+\n+    @Test(failOn = INTRINSIC_SLOW_PATH)\n+    public void test108() {\n+        System.arraycopy(get_obj_src(), 0, get_obj_dst(), 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test108_verifier(boolean warmup) {\n+        test108();\n+        verify(obj_src, obj_dst);\n+    }\n+\n+    @Test(match = { INTRINSIC_SLOW_PATH }, matchCount = { 1 })\n+    public void test109() {\n+        System.arraycopy(get_obj_src(), 0, get_val_dst(), 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test109_verifier(boolean warmup) {\n+        test109();\n+        verify(obj_src, val_dst);\n+    }\n+\n+    @Test(match = { INTRINSIC_SLOW_PATH }, matchCount = { 1 })\n+    public void test109_null() {\n+        System.arraycopy(get_obj_null_src(), 0, get_val_dst(), 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test109_null_verifier(boolean warmup) {\n+        try {\n+            test109_null();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    \/\/ Arrays.copyOf with constant source and destination arrays\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { INTRINSIC_SLOW_PATH }, matchCount = { 1 })\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP)\n+    public Object[] test110() {\n+        return Arrays.copyOf(val_src, 8, Object[].class);\n+    }\n+\n+    @DontCompile\n+    public void test110_verifier(boolean warmup) {\n+        Object[] res = test110();\n+        verify(val_src, res);\n+    }\n+\n+    \/\/ Same as test110 but with MyValue2[] dst\n+    @Test(failOn = INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP)\n+    public Object[] test111() {\n+        return Arrays.copyOf(val_src, 8, MyValue2[].class);\n+    }\n+\n+    @DontCompile\n+    public void test111_verifier(boolean warmup) {\n+        Object[] res = test111();\n+        verify(val_src, res);\n+    }\n+\n+    \/\/ Same as test110 but with Object[] src\n+    @Test(failOn = INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP)\n+    public Object[] test112() {\n+        return Arrays.copyOf(obj_src, 8, Object[].class);\n+    }\n+\n+    @DontCompile\n+    public void test112_verifier(boolean warmup) {\n+        Object[] res = test112();\n+        verify(obj_src, res);\n+    }\n+\n+    \/\/ Same as test111 but with Object[] src\n+    @Test(match = { INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP }, matchCount = { 1 })\n+    public Object[] test113() {\n+        return Arrays.copyOf(obj_src, 8, MyValue2[].class);\n+    }\n+\n+    @DontCompile\n+    public void test113_verifier(boolean warmup) {\n+        Object[] res = test113();\n+        verify(obj_src, res);\n+    }\n+\n+    \/\/ Same as test111 but with Object[] src containing null\n+    @Test(match = { INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP }, matchCount = { 1 })\n+    public Object[] test113_null() {\n+        return Arrays.copyOf(obj_null_src, 8, MyValue2[].class);\n+    }\n+\n+    @DontCompile\n+    public void test113_null_verifier(boolean warmup) {\n+        try {\n+            test113_null();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    \/\/ Below tests are equal to test110-test113 but hide the src\/dst types until\n+    \/\/ after the arraycopy intrinsic is emitted (with incremental inlining).\n+\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { INTRINSIC_SLOW_PATH }, matchCount = { 1 })\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP)\n+    public Object[] test114() {\n+        return Arrays.copyOf((Object[])get_val_src(), 8, get_obj_class());\n+    }\n+\n+    @DontCompile\n+    public void test114_verifier(boolean warmup) {\n+        Object[] res = test114();\n+        verify(val_src, res);\n+    }\n+\n+    \/\/ TODO 8251971: Should be optimized but we are bailing out because\n+    \/\/ at parse time it looks as if src could be flat and dst could be not flat\n+    @Test(valid = InlineTypeArrayFlattenOn)\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP)\n+    public Object[] test115() {\n+        return Arrays.copyOf((Object[])get_val_src(), 8, get_val_class());\n+    }\n+\n+    @DontCompile\n+    public void test115_verifier(boolean warmup) {\n+        Object[] res = test115();\n+        verify(val_src, res);\n+    }\n+\n+    @Test(failOn = INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP)\n+    public Object[] test116() {\n+        return Arrays.copyOf((Object[])get_obj_src(), 8, get_obj_class());\n+    }\n+\n+    @DontCompile\n+    public void test116_verifier(boolean warmup) {\n+        Object[] res = test116();\n+        verify(obj_src, res);\n+    }\n+\n+    @Test(match = { INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP }, matchCount = { 1 })\n+    public Object[] test117() {\n+        return Arrays.copyOf((Object[])get_obj_src(), 8, get_val_class());\n+    }\n+\n+    @DontCompile\n+    public void test117_verifier(boolean warmup) {\n+        Object[] res = test117();\n+        verify(obj_src, res);\n+    }\n+\n+    @Test(match = { INTRINSIC_SLOW_PATH + CLASS_CHECK_TRAP }, matchCount = { 1 })\n+    public Object[] test117_null() {\n+        return Arrays.copyOf((Object[])get_obj_null_src(), 8, get_val_class());\n+    }\n+\n+    @DontCompile\n+    public void test117_null_verifier(boolean warmup) {\n+        try {\n+            test117_null();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    \/\/ Some more Arrays.copyOf tests with only constant class\n+\n+    @Test(match = { CLASS_CHECK_TRAP }, matchCount = { 1 }, failOn = INTRINSIC_SLOW_PATH)\n+    public Object[] test118(Object[] src) {\n+        return Arrays.copyOf(src, 8, MyValue2[].class);\n+    }\n+\n+    @DontCompile\n+    public void test118_verifier(boolean warmup) {\n+        Object[] res = test118(obj_src);\n+        verify(obj_src, res);\n+        res = test118(val_src);\n+        verify(val_src, res);\n+        try {\n+            test118(obj_null_src);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    @Test\n+    public Object[] test119(Object[] src) {\n+        return Arrays.copyOf(src, 8, Object[].class);\n+    }\n+\n+    @DontCompile\n+    public void test119_verifier(boolean warmup) {\n+        Object[] res = test119(obj_src);\n+        verify(obj_src, res);\n+        res = test119(val_src);\n+        verify(val_src, res);\n+    }\n+\n+    @Test(match = { CLASS_CHECK_TRAP }, matchCount = { 1 }, failOn = INTRINSIC_SLOW_PATH)\n+    public Object[] test120(Object[] src) {\n+        return Arrays.copyOf(src, 8, Integer[].class);\n+    }\n+\n+    @DontCompile\n+    public void test120_verifier(boolean warmup) {\n+        Integer[] arr = new Integer[8];\n+        for (int i = 0; i < 8; ++i) {\n+            arr[i] = rI + i;\n+        }\n+        Object[] res = test120(arr);\n+        verify(arr, res);\n+        try {\n+            test120(val_src);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000) \/\/ Make sure we hit too_many_traps for the src <: dst check\n+    public Object[] test121(Object[] src) {\n+        return Arrays.copyOf(src, 8, MyValue2[].class);\n+    }\n+\n+    @DontCompile\n+    public void test121_verifier(boolean warmup) {\n+        Object[] res = test121(obj_src);\n+        verify(obj_src, res);\n+        res = test121(val_src);\n+        verify(val_src, res);\n+        try {\n+            test121(obj_null_src);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000) \/\/ Make sure we hit too_many_traps for the src <: dst check\n+    public Object[] test122(Object[] src) {\n+        return Arrays.copyOf(src, 8, get_val_class());\n+    }\n+\n+    @DontCompile\n+    public void test122_verifier(boolean warmup) {\n+        Object[] res = test122(obj_src);\n+        verify(obj_src, res);\n+        res = test122(val_src);\n+        verify(val_src, res);\n+        try {\n+            test122(obj_null_src);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000) \/\/ Make sure we hit too_many_traps for the src <: dst check\n+    public Object[] test123(Object[] src) {\n+        return Arrays.copyOf(src, 8, Integer[].class);\n+    }\n+\n+    @DontCompile\n+    public void test123_verifier(boolean warmup) {\n+        Integer[] arr = new Integer[8];\n+        for (int i = 0; i < 8; ++i) {\n+            arr[i] = rI + i;\n+        }\n+        Object[] res = test123(arr);\n+        verify(arr, res);\n+        try {\n+            test123(val_src);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000) \/\/ Make sure we hit too_many_traps for the src <: dst check\n+    public Object[] test124(Object[] src) {\n+        return Arrays.copyOf(src, 8, get_int_class());\n+    }\n+\n+    @DontCompile\n+    public void test124_verifier(boolean warmup) {\n+        Integer[] arr = new Integer[8];\n+        for (int i = 0; i < 8; ++i) {\n+            arr[i] = rI + i;\n+        }\n+        Object[] res = test124(arr);\n+        verify(arr, res);\n+        try {\n+            test124(val_src);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000) \/\/ Make sure we hit too_many_traps for the src <: dst check\n+    public Object[] test125(Object[] src, Class klass) {\n+        return Arrays.copyOf(src, 8, klass);\n+    }\n+\n+    @DontCompile\n+    public void test125_verifier(boolean warmup) {\n+        Integer[] arr = new Integer[8];\n+        for (int i = 0; i < 8; ++i) {\n+            arr[i] = rI + i;\n+        }\n+        Object[] res = test125(arr, Integer[].class);\n+        verify((Object[])arr, res);\n+        res = test125(val_src, MyValue2[].class);\n+        verify(val_src, res);\n+        res = test125(obj_src, MyValue2[].class);\n+        verify(val_src, res);\n+        try {\n+            test125(obj_null_src, MyValue2[].class);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+        try {\n+            test125(arr, MyValue2[].class);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+        try {\n+            test125(val_src, MyValue1[].class);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    \/\/ Verify that clone from (flat) inline type array not containing oops is always optimized.\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { JLONG_ARRAYCOPY }, matchCount = { 1 }, failOn = CHECKCAST_ARRAYCOPY + CLONE_INTRINSIC_SLOW_PATH)\n+    @Test(valid = InlineTypeArrayFlattenOff, failOn = CLONE_INTRINSIC_SLOW_PATH)\n+    public Object[] test126(MyValue2[] src) {\n+        return src.clone();\n+    }\n+\n+    @DontCompile\n+    public void test126_verifier(boolean warmup) {\n+        Object[] res = test126(val_src);\n+        verify(val_src, res);\n+    }\n+\n+    \/\/ Verify correctness of generic_copy stub\n+    @Test\n+    public void test127(Object src, Object dst, int len) {\n+        System.arraycopy(src, 0, dst, 0, len);\n+    }\n+\n+    @DontCompile\n+    public void test127_verifier(boolean warmup) {\n+        test127(val_src, obj_dst, 8);\n+        verify(val_src, obj_dst);\n+        test127(val_src, val_dst, 8);\n+        verify(val_src, val_dst);\n+        test127(obj_src, val_dst, 8);\n+        verify(obj_src, val_dst);\n+        try {\n+            test127(obj_null_src, val_dst, 8);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    \/\/ Verify that copyOf with known source and unknown destination class is optimized\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { JLONG_ARRAYCOPY }, matchCount = { 1 }, failOn = CHECKCAST_ARRAYCOPY)\n+    @Test(valid = InlineTypeArrayFlattenOff)\n+    public Object[] test128(MyValue2[] src, Class klass) {\n+        return Arrays.copyOf(src, 8, klass);\n+    }\n+\n+    @DontCompile\n+    public void test128_verifier(boolean warmup) {\n+        Object[] res = test128(val_src, MyValue2[].class);\n+        verify(val_src, res);\n+        res = test128(val_src, Object[].class);\n+        verify(val_src, res);\n+        try {\n+            test128(val_src, MyValue1[].class);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    \/\/ Arraycopy with non-array src\/dst\n+    @Test\n+    public void test129(Object src, Object dst, int len) {\n+        System.arraycopy(src, 0, dst, 0, len);\n+    }\n+\n+    @DontCompile\n+    public void test129_verifier(boolean warmup) {\n+        try {\n+            test129(new Object(), new Object[0], 0);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+        try {\n+            test129(new Object[0], new Object(), 0);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ expected\n+        }\n+    }\n+\n+    \/\/ Empty inline type array access\n+    @Test(failOn = ALLOC + ALLOCA + LOAD + STORE)\n+    public MyValueEmpty test130(MyValueEmpty[] array) {\n+        array[0] = new MyValueEmpty();\n+        return array[1];\n+    }\n+\n+    @DontCompile\n+    public void test130_verifier(boolean warmup) {\n+        MyValueEmpty[] array = new MyValueEmpty[2];\n+        MyValueEmpty empty = test130(array);\n+        Asserts.assertEquals(array[0], MyValueEmpty.default);\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+    }\n+\n+    static primitive class EmptyContainer {\n+        MyValueEmpty empty = MyValueEmpty.default;\n+    }\n+\n+    \/\/ Empty inline type container array access\n+    @Test(failOn = ALLOC + ALLOCA + LOAD + STORE)\n+    public MyValueEmpty test131(EmptyContainer[] array) {\n+        array[0] = new EmptyContainer();\n+        return array[1].empty;\n+    }\n+\n+    @DontCompile\n+    public void test131_verifier(boolean warmup) {\n+        EmptyContainer[] array = new EmptyContainer[2];\n+        MyValueEmpty empty = test131(array);\n+        Asserts.assertEquals(array[0], EmptyContainer.default);\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+    }\n+\n+    \/\/ Empty inline type array access with unknown array type\n+    @Test()\n+    public Object test132(Object[] array) {\n+        array[0] = new MyValueEmpty();\n+        return array[1];\n+    }\n+\n+    @DontCompile\n+    public void test132_verifier(boolean warmup) {\n+        Object[] array = new MyValueEmpty[2];\n+        Object empty = test132(array);\n+        Asserts.assertEquals(array[0], MyValueEmpty.default);\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+        array = new Object[2];\n+        empty = test132(array);\n+        Asserts.assertEquals(array[0], MyValueEmpty.default);\n+        Asserts.assertEquals(empty, null);\n+    }\n+\n+    \/\/ Empty inline type container array access with unknown array type\n+    @Test()\n+    public Object test133(Object[] array) {\n+        array[0] = new EmptyContainer();\n+        return array[1];\n+    }\n+\n+    @DontCompile\n+    public void test133_verifier(boolean warmup) {\n+        Object[] array = new EmptyContainer[2];\n+        Object empty = test133(array);\n+        Asserts.assertEquals(array[0], EmptyContainer.default);\n+        Asserts.assertEquals(empty, EmptyContainer.default);\n+        array = new Object[2];\n+        empty = test133(array);\n+        Asserts.assertEquals(array[0], EmptyContainer.default);\n+        Asserts.assertEquals(empty, null);\n+    }\n+\n+    \/\/ Non-escaping empty inline type array access\n+    @Test(failOn = ALLOC + ALLOCA + LOAD + STORE)\n+    public static MyValueEmpty test134(MyValueEmpty val) {\n+        MyValueEmpty[] array = new MyValueEmpty[1];\n+        array[0] = val;\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test134_verifier(boolean warmup) {\n+        MyValueEmpty empty = test134(MyValueEmpty.default);\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+    }\n+\n+    \/\/ Test accessing a locked (inline type) array\n+    @Test()\n+    public Object test135(Object[] array, Object val) {\n+        array[0] = val;\n+        return array[1];\n+    }\n+\n+    @DontCompile\n+    public void test135_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[2];\n+        array1[1] = MyValue1.createWithFieldsInline(rI, rL);\n+        synchronized (array1) {\n+            Object res = test135(array1, array1[1]);\n+            Asserts.assertEquals(((MyValue1)res).hash(), array1[1].hash());\n+            Asserts.assertEquals(array1[0].hash(), array1[1].hash());\n+        }\n+        Integer[] array2 = new Integer[2];\n+        array2[1] = rI;\n+        synchronized (array2) {\n+            Object res = test135(array2, array2[1]);\n+            Asserts.assertEquals(res, array2[1]);\n+            Asserts.assertEquals(array2[0], array2[1]);\n+        }\n+    }\n+\n+    \/\/ Same as test135 but with locking in compiled method\n+    @Test()\n+    public Object test136(Object[] array, Object val) {\n+        Object res = null;\n+        synchronized (array) {\n+            array[0] = val;\n+            res = array[1];\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test136_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[2];\n+        array1[1] = MyValue1.createWithFieldsInline(rI, rL);\n+        Object res = test136(array1, array1[1]);\n+        Asserts.assertEquals(((MyValue1)res).hash(), array1[1].hash());\n+        Asserts.assertEquals(array1[0].hash(), array1[1].hash());\n+        Integer[] array2 = new Integer[2];\n+        array2[1] = rI;\n+        res = test136(array2, array2[1]);\n+        Asserts.assertEquals(res, array2[1]);\n+        Asserts.assertEquals(array2[0], array2[1]);\n+    }\n+\n+    Object oFld1, oFld2;\n+\n+    \/\/ Test loop unwswitching with locked (inline type) array accesses\n+    @Test()\n+    public void test137(Object[] array1, Object[] array2) {\n+        for (int i = 0; i < array1.length; i++) {\n+            oFld1 = array1[i];\n+            oFld2 = array2[i];\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test137_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[100];\n+        Arrays.fill(array1, MyValue1.createWithFieldsInline(rI, rL));\n+        Integer[] array2 = new Integer[100];\n+        Arrays.fill(array2, rI);\n+        synchronized (array1) {\n+            test137(array1, array1);\n+            Asserts.assertEquals(oFld1, array1[0]);\n+            Asserts.assertEquals(oFld2, array1[0]);\n+            test137(array1, array2);\n+            Asserts.assertEquals(oFld1, array1[0]);\n+            Asserts.assertEquals(oFld2, array2[0]);\n+            test137(array2, array1);\n+            Asserts.assertEquals(oFld1, array2[0]);\n+            Asserts.assertEquals(oFld2, array1[0]);\n+        }\n+        synchronized (array2) {\n+            test137(array2, array2);\n+            Asserts.assertEquals(oFld1, array2[0]);\n+            Asserts.assertEquals(oFld2, array2[0]);\n+            test137(array1, array2);\n+            Asserts.assertEquals(oFld1, array1[0]);\n+            Asserts.assertEquals(oFld2, array2[0]);\n+            test137(array2, array1);\n+            Asserts.assertEquals(oFld1, array2[0]);\n+            Asserts.assertEquals(oFld2, array1[0]);\n+        }\n+    }\n+\n+    \/\/ Same as test137 but with locking in loop\n+    @Test()\n+    public void test138(Object[] array1, Object[] array2) {\n+        for (int i = 0; i < array1.length; i++) {\n+            synchronized (array1) {\n+                oFld1 = array1[i];\n+            }\n+            synchronized (array2) {\n+                oFld2 = array2[i];\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test138_verifier(boolean warmup) {\n+        MyValue1[] array1 = new MyValue1[100];\n+        Arrays.fill(array1, MyValue1.createWithFieldsInline(rI, rL));\n+        Integer[] array2 = new Integer[100];\n+        Arrays.fill(array2, rI);\n+        test138(array1, array1);\n+        Asserts.assertEquals(oFld1, array1[0]);\n+        Asserts.assertEquals(oFld2, array1[0]);\n+        test138(array1, array2);\n+        Asserts.assertEquals(oFld1, array1[0]);\n+        Asserts.assertEquals(oFld2, array2[0]);\n+        test138(array2, array1);\n+        Asserts.assertEquals(oFld1, array2[0]);\n+        Asserts.assertEquals(oFld2, array1[0]);\n+        test138(array2, array2);\n+        Asserts.assertEquals(oFld1, array2[0]);\n+        Asserts.assertEquals(oFld2, array2[0]);\n+        Asserts.assertEquals(oFld2, array2[0]);\n+    }\n+\n+    \/\/ Test load from array that is only known to be non-inline after parsing\n+    @Test(failOn = ALLOC + ALLOCA + ALLOC_G + ALLOCA_G + LOOP + LOAD + STORE + TRAP + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    public Object test139() {\n+        Object[]  array = null;\n+        Object[] iarray = new Integer[1];\n+        Object[] varray = new MyValue1[1];\n+        for (int i = 0; i < 10; i++) {\n+            array = varray;\n+            varray = iarray;\n+        }\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test139_verifier(boolean warmup) {\n+        Object res = test139();\n+        Asserts.assertEquals(res, null);\n+    }\n+\n+    \/\/ Test store to array that is only known to be non-inline after parsing\n+    @Test(failOn = ALLOC + ALLOCA + ALLOC_G + LOOP + LOAD + STORE + TRAP + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    public Object[] test140(Object val) {\n+        Object[]  array = null;\n+        Object[] iarray = new Integer[1];\n+        Object[] varray = new MyValue1[1];\n+        for (int i = 0; i < 10; i++) {\n+            array = varray;\n+            varray = iarray;\n+        }\n+        array[0] = val;\n+        return array;\n+    }\n+\n+    @DontCompile\n+    public void test140_verifier(boolean warmup) {\n+        Object[] res = test140(rI);\n+        Asserts.assertEquals(res[0], rI);\n+        res = test140(null);\n+        Asserts.assertEquals(res[0], null);\n+    }\n+\n+    \/\/ Test load from array that is only known to be inline after parsing\n+    \/\/ TODO 8255938\n+    \/\/ @Test(failOn = ALLOC + ALLOCA + ALLOC_G + ALLOCA_G + LOOP + LOAD + STORE + TRAP + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    @Test\n+    public Object test141() {\n+        Object[]  array = null;\n+        Object[] iarray = new Integer[1];\n+        Object[] varray = new MyValue1[1];\n+        for (int i = 0; i < 10; i++) {\n+            array = iarray;\n+            iarray = varray;\n+        }\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test141_verifier(boolean warmup) {\n+        Object res = test141();\n+        Asserts.assertEquals(res, MyValue1.default);\n+    }\n+\n+    \/\/ Test store to array that is only known to be inline after parsing\n+    \/\/ TODO 8255938\n+    \/\/ @Test(failOn = ALLOC + ALLOCA + ALLOC_G + LOOP + LOAD + STORE + TRAP + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    @Test\n+    public Object[] test142(Object val) {\n+        Object[]  array = null;\n+        Object[] iarray = new Integer[1];\n+        Object[] varray = new MyValue1[1];\n+        for (int i = 0; i < 10; i++) {\n+            array = iarray;\n+            iarray = varray;\n+        }\n+        array[0] = val;\n+        return array;\n+    }\n+\n+    @DontCompile\n+    public void test142_verifier(boolean warmup) {\n+        Object[] res = test142(MyValue1.default);\n+        Asserts.assertEquals(res[0], MyValue1.default);\n+        if (!warmup) {\n+            try {\n+                test142(null);\n+                throw new RuntimeException(\"Should throw NullPointerException\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    static interface MyInterface143 {\n+        public int hash();\n+    }\n+\n+    static class MyObject143 implements MyInterface143 {\n+        public int hash() { return 42; }\n+    }\n+\n+    volatile MyInterface143[] array143 = new MyObject143[1];\n+    int len143 = 0;\n+\n+    volatile int vf = 0;\n+\n+    \/\/ Test that triggers an anti dependency failure when array mark word is loaded from immutable memory\n+    @Test\n+    @Warmup(0)\n+    public void test143() {\n+        MyInterface143[] arr = array143;\n+        int tmp = arr.length;\n+        for (int i = 0; i < len143; i++) {\n+            if (arr[i].hash() > 0) {\n+                return;\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test143_verifier(boolean warmup) {\n+        test143();\n+    }\n+\n+    \/\/ Same as test143 but with two flat array checks that are unswitched\n+    @Test\n+    @Warmup(0)\n+    public void test144() {\n+        MyInterface143[] arr1 = array143;\n+        MyInterface143[] arr2 = array143;\n+        int tmp1 = arr1.length;\n+        int tmp2 = arr2.length;\n+        for (int i = 0; i < len143; i++) {\n+            if (arr1[i].hash() > 0 && arr2[i].hash() > 0) {\n+                return;\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test144_verifier(boolean warmup) {\n+        test144();\n+    }\n+\n+    \/\/ Test that array load slow path correctly initializes non-flattened field of empty inline type\n+    @Test()\n+    public Object test145(Object[] array) {\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test145_verifier(boolean warmup) {\n+        Object[] array = new EmptyContainer[1];\n+        EmptyContainer empty = (EmptyContainer)test145(array);\n+        Asserts.assertEquals(empty, EmptyContainer.default);\n+    }\n+\n+    \/\/ Test that non-flattened array does not block inline type scalarization\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE)\n+    @Warmup(50000)\n+    public void test146(boolean b) {\n+        MyValue2 vt = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2[] array = { vt };\n+        if (b) {\n+            for (int i = 0; i < 10; ++i) {\n+                if (array != array) {\n+                    array = null;\n+                }\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test146_verifier(boolean warmup) {\n+        test146(true);\n+    }\n+\n+    \/\/ Test that non-flattened array does not block inline type scalarization\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE)\n+    @Warmup(50000)\n+    public int test147(boolean deopt) {\n+        \/\/ Both vt and array should be scalarized\n+        MyValue2 vt = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2[] array = new MyValue2[1];\n+\n+        \/\/ Delay scalarization to after loop opts\n+        boolean store = false;\n+        for (int i = 0; i < 5; ++i) {\n+            if (i == 1) {\n+                store = true;\n+            }\n+        }\n+        if (store) {\n+            array[0] = vt;\n+        }\n+\n+        if (deopt) {\n+            \/\/ Uncommon trap referencing array\n+            return array[0].x + 42;\n+        }\n+        return array[0].x;\n+    }\n+\n+    @DontCompile\n+    public void test147_verifier(boolean warmup) {\n+        int res = test147(!warmup);\n+        Asserts.assertEquals(res, MyValue2.createWithFieldsInline(rI, rD).x + (warmup ? 0 : 42));\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestArrays.java","additions":3420,"deletions":0,"binary":false,"changes":3420,"status":"added"},{"patch":"@@ -0,0 +1,910 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.test.lib.Asserts;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test the basic inline type implementation in C2\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires os.simpleArch == \"x64\"\n+ * @compile TestBasicFunctionality.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestBasicFunctionality\n+ *\/\n+public class TestBasicFunctionality extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 2: return new String[] {\"-DVerifyIR=false\"};\n+        case 3: return new String[] {\"-XX:FlatArrayElementMaxSize=0\"};\n+        }\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestBasicFunctionality test = new TestBasicFunctionality();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class, MyValue3.class, MyValue3Inline.class);\n+    }\n+\n+    \/\/ Helper methods\n+\n+    protected long hash() {\n+        return hash(rI, rL);\n+    }\n+\n+    protected long hash(int x, long y) {\n+        return MyValue1.createWithFieldsInline(x, y).hash();\n+    }\n+\n+    \/\/ Receive inline type through call to interpreter\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test1() {\n+        MyValue1 v = MyValue1.createWithFieldsDontInline(rI, rL);\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        long result = test1();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Receive inline type from interpreter via parameter\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test2(MyValue1 v) {\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsDontInline(rI, rL);\n+        long result = test2(v);\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Return incoming inline type without accessing fields\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, match = {ALLOC, STORE}, matchCount = {1, 14}, failOn = LOAD + TRAP)\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, failOn = ALLOC + LOAD + STORE + TRAP)\n+    public MyValue1 test3(MyValue1 v) {\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        MyValue1 v1 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1 v2 = test3(v1);\n+        Asserts.assertEQ(v1.x, v2.x);\n+        Asserts.assertEQ(v1.y, v2.y);\n+    }\n+\n+    \/\/ Create an inline type in compiled code and only use fields.\n+    \/\/ Allocation should go away because inline type does not escape.\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public long test4() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        long result = test4();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type in compiled code and pass it to\n+    \/\/ an inlined compiled method via a call.\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public long test5() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        return test5Inline(v);\n+    }\n+\n+    @ForceInline\n+    public long test5Inline(MyValue1 v) {\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        long result = test5();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type in compiled code and pass it to\n+    \/\/ the interpreter via a call.\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, failOn = LOAD + TRAP + ALLOC)\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, match = {ALLOC}, matchCount = {1}, failOn = LOAD + TRAP)\n+    public long test6() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        \/\/ Pass to interpreter\n+        return v.hashInterpreted();\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        long result = test6();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type in compiled code and pass it to\n+    \/\/ the interpreter by returning.\n+    @Test(match = {ALLOC}, matchCount = {1}, failOn = LOAD + TRAP)\n+    public MyValue1 test7(int x, long y) {\n+        return MyValue1.createWithFieldsInline(x, y);\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        MyValue1 v = test7(rI, rL);\n+        Asserts.assertEQ(v.hash(), hash());\n+    }\n+\n+    \/\/ Merge inline types created from two branches\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test8(boolean b) {\n+        MyValue1 v;\n+        if (b) {\n+            v = MyValue1.createWithFieldsInline(rI, rL);\n+        } else {\n+            v = MyValue1.createWithFieldsDontInline(rI + 1, rL + 1);\n+        }\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        Asserts.assertEQ(test8(true), hash());\n+        Asserts.assertEQ(test8(false), hash(rI + 1, rL + 1));\n+    }\n+\n+    \/\/ Merge inline types created from two branches\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, match = {LOAD}, matchCount = {14}, failOn = TRAP + ALLOC + STORE)\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, match = {ALLOC, STORE}, matchCount = {1, 13}, failOn = LOAD + TRAP)\n+    public MyValue1 test9(boolean b, int localrI, long localrL) {\n+        MyValue1 v;\n+        if (b) {\n+            \/\/ Inline type is not allocated\n+            \/\/ Do not use rI\/rL directly here as null values may cause\n+            \/\/ some redundant null initializations to be optimized out\n+            \/\/ and matching to fail.\n+            v = MyValue1.createWithFieldsInline(localrI, localrL);\n+        } else {\n+            \/\/ Inline type is allocated by the callee\n+            v = MyValue1.createWithFieldsDontInline(rI + 1, rL + 1);\n+        }\n+        \/\/ Need to allocate inline type if 'b' is true\n+        long sum = v.hashInterpreted();\n+        if (b) {\n+            v = MyValue1.createWithFieldsDontInline(rI, sum);\n+        } else {\n+            v = MyValue1.createWithFieldsDontInline(rI, sum + 1);\n+        }\n+        \/\/ Don't need to allocate inline type because both branches allocate\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        MyValue1 v = test9(true, rI, rL);\n+        Asserts.assertEQ(v.x, rI);\n+        Asserts.assertEQ(v.y, hash());\n+        v = test9(false, rI, rL);\n+        Asserts.assertEQ(v.x, rI);\n+        Asserts.assertEQ(v.y, hash(rI + 1, rL + 1) + 1);\n+    }\n+\n+    \/\/ Merge inline types created in a loop (not inlined)\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test10(int x, long y) {\n+        MyValue1 v = MyValue1.createWithFieldsDontInline(x, y);\n+        for (int i = 0; i < 10; ++i) {\n+            v = MyValue1.createWithFieldsDontInline(v.x + 1, v.y + 1);\n+        }\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        long result = test10(rI, rL);\n+        Asserts.assertEQ(result, hash(rI + 10, rL + 10));\n+    }\n+\n+    \/\/ Merge inline types created in a loop (inlined)\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public long test11(int x, long y) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(x, y);\n+        for (int i = 0; i < 10; ++i) {\n+            v = MyValue1.createWithFieldsInline(v.x + 1, v.y + 1);\n+        }\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        long result = test11(rI, rL);\n+        Asserts.assertEQ(result, hash(rI + 10, rL + 10));\n+    }\n+\n+    \/\/ Test loop with uncommon trap referencing an inline type\n+    @Test(match = {SCOBJ}, matchCount = {-1 \/* at least 1 *\/}, failOn = LOAD)\n+    public long test12(boolean b) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1[] va = new MyValue1[Math.abs(rI) % 10];\n+        for (int i = 0; i < va.length; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        long result = rL;\n+        for (int i = 0; i < 1000; ++i) {\n+            if (b) {\n+                result += v.x;\n+            } else {\n+                \/\/ Uncommon trap referencing v. We delegate allocation to the\n+                \/\/ interpreter by adding a SafePointScalarObjectNode.\n+                result = v.hashInterpreted();\n+                for (int j = 0; j < va.length; ++j) {\n+                    result += va[j].hash();\n+                }\n+            }\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        long result = test12(warmup);\n+        Asserts.assertEQ(result, warmup ? rL + (1000 * rI) : ((Math.abs(rI) % 10) + 1) * hash());\n+    }\n+\n+    \/\/ Test loop with uncommon trap referencing an inline type\n+    @Test\n+    public long test13(boolean b) {\n+        MyValue1 v = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1[] va = new MyValue1[Math.abs(rI) % 10];\n+        for (int i = 0; i < va.length; ++i) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        }\n+        long result = rL;\n+        for (int i = 0; i < 1000; ++i) {\n+            if (b) {\n+                result += v.x;\n+            } else {\n+                \/\/ Uncommon trap referencing v. Should not allocate\n+                \/\/ but just pass the existing oop to the uncommon trap.\n+                result = v.hashInterpreted();\n+                for (int j = 0; j < va.length; ++j) {\n+                    result += va[j].hashInterpreted();\n+                }\n+            }\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        long result = test13(warmup);\n+        Asserts.assertEQ(result, warmup ? rL + (1000 * rI) : ((Math.abs(rI) % 10) + 1) * hash());\n+    }\n+\n+    \/\/ Create an inline type in a non-inlined method and then call a\n+    \/\/ non-inlined method on that inline type.\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, failOn = (ALLOC + STORE + TRAP), match = {LOAD}, matchCount = {14})\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, failOn = (ALLOC + LOAD + STORE + TRAP))\n+    public long test14() {\n+        MyValue1 v = MyValue1.createWithFieldsDontInline(rI, rL);\n+        return v.hashInterpreted();\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean b) {\n+        long result = test14();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type in an inlined method and then call a\n+    \/\/ non-inlined method on that inline type.\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, failOn = (LOAD + TRAP + ALLOC))\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, failOn = (LOAD + TRAP), match = {ALLOC}, matchCount = {1})\n+    public long test15() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        return v.hashInterpreted();\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean b) {\n+        long result = test15();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type in a non-inlined method and then call an\n+    \/\/ inlined method on that inline type.\n+    @Test(failOn = (ALLOC + STORE + TRAP))\n+    public long test16() {\n+        MyValue1 v = MyValue1.createWithFieldsDontInline(rI, rL);\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean b) {\n+        long result = test16();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type in an inlined method and then call an\n+    \/\/ inlined method on that inline type.\n+    @Test(failOn = (ALLOC + LOAD + STORE + TRAP))\n+    public long test17() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean b) {\n+        long result = test17();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type in compiled code and pass it to the\n+    \/\/ interpreter via a call. The inline type is live at the first call so\n+    \/\/ debug info should include a reference to all its fields.\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, failOn = ALLOC + LOAD + TRAP)\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, match = {ALLOC}, matchCount = {1}, failOn = LOAD + TRAP)\n+    public long test18() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        v.hashInterpreted();\n+        return v.hashInterpreted();\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        long result = test18();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type in compiled code and pass it to the\n+    \/\/ interpreter via a call. The inline type is passed twice but\n+    \/\/ should only be allocated once.\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, failOn = ALLOC + LOAD + TRAP)\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, match = {ALLOC}, matchCount = {1}, failOn = LOAD + TRAP)\n+    public long test19() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        return sumValue(v, v);\n+    }\n+\n+    @DontCompile\n+    public long sumValue(MyValue1 v, MyValue1 dummy) {\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        long result = test19();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Create an inline type (array) in compiled code and pass it to the\n+    \/\/ interpreter via a call. The inline type is live at the uncommon\n+    \/\/ trap: verify that deoptimization causes the inline type to be\n+    \/\/ correctly allocated.\n+    @Test(valid = InlineTypePassFieldsAsArgsOn, failOn = LOAD + ALLOC + STORE)\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, match = {ALLOC}, matchCount = {1}, failOn = LOAD)\n+    public long test20(boolean deopt) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue2[] va = new MyValue2[3];\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test20\"));\n+        }\n+        return v.hashInterpreted() + va[0].hashInterpreted() +\n+                va[1].hashInterpreted() + va[2].hashInterpreted();\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        MyValue2[] va = new MyValue2[42];\n+        long result = test20(!warmup);\n+        Asserts.assertEQ(result, hash() + va[0].hash() + va[1].hash() + va[2].hash());\n+    }\n+\n+    \/\/ Inline type fields in regular object\n+    MyValue1 val1;\n+    MyValue2 val2;\n+    final MyValue1 val3 = MyValue1.createWithFieldsInline(rI, rL);\n+    static MyValue1 val4;\n+    static final MyValue1 val5 = MyValue1.createWithFieldsInline(rI, rL);\n+\n+    \/\/ Test inline type fields in objects\n+    @Test(match = {ALLOC}, matchCount = {1}, failOn = (TRAP))\n+    public long test21(int x, long y) {\n+        \/\/ Compute hash of inline type fields\n+        long result = val1.hash() + val2.hash() + val3.hash() + val4.hash() + val5.hash();\n+        \/\/ Update fields\n+        val1 = MyValue1.createWithFieldsInline(x, y);\n+        val2 = MyValue2.createWithFieldsInline(x, rD);\n+        val4 = MyValue1.createWithFieldsInline(x, y);\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        \/\/ Check if hash computed by test18 is correct\n+        val1 = MyValue1.createWithFieldsInline(rI, rL);\n+        val2 = val1.v2;\n+        \/\/ val3 is initialized in the constructor\n+        val4 = val1;\n+        \/\/ val5 is initialized in the static initializer\n+        long hash = val1.hash() + val2.hash() + val3.hash() + val4.hash() + val5.hash();\n+        long result = test21(rI + 1, rL + 1);\n+        Asserts.assertEQ(result, hash);\n+        \/\/ Check if inline type fields were updated\n+        Asserts.assertEQ(val1.hash(), hash(rI + 1, rL + 1));\n+        Asserts.assertEQ(val2.hash(), MyValue2.createWithFieldsInline(rI + 1, rD).hash());\n+        Asserts.assertEQ(val4.hash(), hash(rI + 1, rL + 1));\n+    }\n+\n+    \/\/ Test folding of constant inline type fields\n+    @Test(failOn = ALLOC + LOAD + STORE + LOOP + TRAP)\n+    public long test22() {\n+        \/\/ This should be constant folded\n+        return val5.hash() + val5.v3.hash();\n+    }\n+\n+    @DontCompile\n+    public void test22_verifier(boolean warmup) {\n+        long result = test22();\n+        Asserts.assertEQ(result, val5.hash() + val5.v3.hash());\n+    }\n+\n+    \/\/ Test defaultvalue\n+    @Test(failOn = ALLOC + LOAD + STORE + LOOP + TRAP)\n+    public long test23() {\n+        MyValue2 v = MyValue2.createDefaultInline();\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test23_verifier(boolean warmup) {\n+        long result = test23();\n+        Asserts.assertEQ(result, MyValue2.createDefaultInline().hash());\n+    }\n+\n+    \/\/ Test defaultvalue\n+    @Test(failOn = ALLOC + STORE + LOOP + TRAP)\n+    public long test24() {\n+        MyValue1 v1 = MyValue1.createDefaultInline();\n+        MyValue1 v2 = MyValue1.createDefaultDontInline();\n+        return v1.hashPrimitive() + v2.hashPrimitive();\n+    }\n+\n+    @DontCompile\n+    public void test24_verifier(boolean warmup) {\n+        long result = test24();\n+        Asserts.assertEQ(result, 2 * MyValue1.createDefaultInline().hashPrimitive());\n+    }\n+\n+    \/\/ Test withfield\n+    @Test(failOn = ALLOC + LOAD + STORE + LOOP + TRAP)\n+    public long test25() {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test25_verifier(boolean warmup) {\n+        long result = test25();\n+        Asserts.assertEQ(result, MyValue2.createWithFieldsInline(rI, rD).hash());\n+    }\n+\n+    \/\/ Test withfield\n+    @Test(failOn = ALLOC + STORE + LOOP + TRAP)\n+    public long test26() {\n+        MyValue1 v1 = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1 v2 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        return v1.hash() + v2.hash();\n+    }\n+\n+    @DontCompile\n+    public void test26_verifier(boolean warmup) {\n+        long result = test26();\n+        Asserts.assertEQ(result, 2 * hash());\n+    }\n+\n+    class TestClass27 {\n+        public MyValue1 v;\n+    }\n+\n+    \/\/ Test allocation elimination of unused object with initialized inline type field\n+    @Test(failOn = ALLOC + LOAD + STORE + LOOP)\n+    public void test27(boolean deopt) {\n+        TestClass27 unused = new TestClass27();\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        unused.v = v;\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test27\"));\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test27_verifier(boolean warmup) {\n+        test27(!warmup);\n+    }\n+\n+    static MyValue3 staticVal3;\n+    static MyValue3 staticVal3_copy;\n+\n+    \/\/ Check elimination of redundant inline type allocations\n+    @Test(match = {ALLOC}, matchCount = {1})\n+    public MyValue3 test28(MyValue3[] va) {\n+        \/\/ Create inline type and force allocation\n+        MyValue3 vt = MyValue3.create();\n+        va[0] = vt;\n+        staticVal3 = vt;\n+        vt.verify(staticVal3);\n+\n+        \/\/ Inline type is now allocated, make a copy and force allocation.\n+        \/\/ Because copy is equal to vt, C2 should remove this redundant allocation.\n+        MyValue3 copy = MyValue3.setC(vt, vt.c);\n+        va[0] = copy;\n+        staticVal3_copy = copy;\n+        copy.verify(staticVal3_copy);\n+        return copy;\n+    }\n+\n+    @DontCompile\n+    public void test28_verifier(boolean warmup) {\n+        MyValue3[] va = new MyValue3[1];\n+        MyValue3 vt = test28(va);\n+        staticVal3.verify(vt);\n+        staticVal3.verify(va[0]);\n+        staticVal3_copy.verify(vt);\n+        staticVal3_copy.verify(va[0]);\n+    }\n+\n+    \/\/ Verify that only dominating allocations are re-used\n+    @Test()\n+    public MyValue3 test29(boolean warmup) {\n+        MyValue3 vt = MyValue3.create();\n+        if (warmup) {\n+            staticVal3 = vt; \/\/ Force allocation\n+        }\n+        \/\/ Force allocation to verify that above\n+        \/\/ non-dominating allocation is not re-used\n+        MyValue3 copy = MyValue3.setC(vt, vt.c);\n+        staticVal3_copy = copy;\n+        copy.verify(vt);\n+        return copy;\n+    }\n+\n+    @DontCompile\n+    public void test29_verifier(boolean warmup) {\n+        MyValue3 vt = test29(warmup);\n+        if (warmup) {\n+            staticVal3.verify(vt);\n+        }\n+    }\n+\n+    \/\/ Verify that C2 recognizes inline type loads and re-uses the oop to avoid allocations\n+    @Test(failOn = ALLOC + ALLOCA + STORE)\n+    public MyValue3 test30(MyValue3[] va) {\n+        \/\/ C2 can re-use the oop of staticVal3 because staticVal3 is equal to copy\n+        MyValue3 copy = MyValue3.copy(staticVal3);\n+        va[0] = copy;\n+        staticVal3 = copy;\n+        copy.verify(staticVal3);\n+        return copy;\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) {\n+        staticVal3 = MyValue3.create();\n+        MyValue3[] va = new MyValue3[1];\n+        MyValue3 vt = test30(va);\n+        staticVal3.verify(vt);\n+        staticVal3.verify(va[0]);\n+    }\n+\n+    \/\/ Verify that C2 recognizes inline type loads and re-uses the oop to avoid allocations\n+    @Test(valid = InlineTypeReturnedAsFieldsOn)\n+    @Test(valid = InlineTypeReturnedAsFieldsOff, failOn = ALLOC + ALLOCA + STORE)\n+    public MyValue3 test31(MyValue3[] va) {\n+        \/\/ C2 can re-use the oop returned by createDontInline()\n+        \/\/ because the corresponding inline type is equal to 'copy'.\n+        MyValue3 copy = MyValue3.copy(MyValue3.createDontInline());\n+        va[0] = copy;\n+        staticVal3 = copy;\n+        copy.verify(staticVal3);\n+        return copy;\n+    }\n+\n+    @DontCompile\n+    public void test31_verifier(boolean warmup) {\n+        MyValue3[] va = new MyValue3[1];\n+        MyValue3 vt = test31(va);\n+        staticVal3.verify(vt);\n+        staticVal3.verify(va[0]);\n+    }\n+\n+    \/\/ Verify that C2 recognizes inline type loads and re-uses the oop to avoid allocations\n+    @Test(valid = InlineTypePassFieldsAsArgsOn)\n+    @Test(valid = InlineTypePassFieldsAsArgsOff, failOn = ALLOC + ALLOCA + STORE)\n+    public MyValue3 test32(MyValue3 vt, MyValue3[] va) {\n+        \/\/ C2 can re-use the oop of vt because vt is equal to 'copy'.\n+        MyValue3 copy = MyValue3.copy(vt);\n+        va[0] = copy;\n+        staticVal3 = copy;\n+        copy.verify(staticVal3);\n+        return copy;\n+    }\n+\n+    @DontCompile\n+    public void test32_verifier(boolean warmup) {\n+        MyValue3 vt = MyValue3.create();\n+        MyValue3[] va = new MyValue3[1];\n+        MyValue3 result = test32(vt, va);\n+        staticVal3.verify(vt);\n+        va[0].verify(vt);\n+        result.verify(vt);\n+    }\n+\n+    \/\/ Test correct identification of inline type copies\n+    @Test()\n+    public MyValue3 test33(MyValue3[] va) {\n+        MyValue3 vt = MyValue3.copy(staticVal3);\n+        vt = MyValue3.setI(vt, vt.c);\n+        \/\/ vt is not equal to staticVal3, so C2 should not re-use the oop\n+        va[0] = vt;\n+        staticVal3 = vt;\n+        vt.verify(staticVal3);\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) {\n+        staticVal3 = MyValue3.create();\n+        MyValue3[] va = new MyValue3[1];\n+        MyValue3 vt = test33(va);\n+        Asserts.assertEQ(staticVal3.i, (int)staticVal3.c);\n+        Asserts.assertEQ(va[0].i, (int)staticVal3.c);\n+        Asserts.assertEQ(vt.i, (int)staticVal3.c);\n+    }\n+\n+    \/\/ Verify that the default inline type is never allocated.\n+    \/\/ C2 code should load and use the default oop from the java mirror.\n+    @Test(failOn = ALLOC + ALLOCA + LOAD + STORE + LOOP + TRAP)\n+    public MyValue3 test34(MyValue3[] va) {\n+        \/\/ Explicitly create default value\n+        MyValue3 vt = MyValue3.createDefault();\n+        va[0] = vt;\n+        staticVal3 = vt;\n+        vt.verify(vt);\n+\n+        \/\/ Load default value from uninitialized inline type array\n+        MyValue3[] dva = new MyValue3[1];\n+        staticVal3_copy = dva[0];\n+        va[1] = dva[0];\n+        dva[0].verify(dva[0]);\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        MyValue3 vt = MyValue3.createDefault();\n+        MyValue3[] va = new MyValue3[2];\n+        va[0] = MyValue3.create();\n+        va[1] = MyValue3.create();\n+        MyValue3 res = test34(va);\n+        res.verify(vt);\n+        staticVal3.verify(vt);\n+        staticVal3_copy.verify(vt);\n+        va[0].verify(vt);\n+        va[1].verify(vt);\n+    }\n+\n+    \/\/ Same as above but manually initialize inline type fields to default.\n+    @Test(failOn = ALLOC + ALLOCA + LOAD + STORE + LOOP + TRAP)\n+    public MyValue3 test35(MyValue3 vt, MyValue3[] va) {\n+        vt = MyValue3.setC(vt, (char)0);\n+        vt = MyValue3.setBB(vt, (byte)0);\n+        vt = MyValue3.setS(vt, (short)0);\n+        vt = MyValue3.setI(vt, 0);\n+        vt = MyValue3.setL(vt, 0);\n+        vt = MyValue3.setO(vt, null);\n+        vt = MyValue3.setF1(vt, 0);\n+        vt = MyValue3.setF2(vt, 0);\n+        vt = MyValue3.setF3(vt, 0);\n+        vt = MyValue3.setF4(vt, 0);\n+        vt = MyValue3.setF5(vt, 0);\n+        vt = MyValue3.setF6(vt, 0);\n+        vt = MyValue3.setV1(vt, MyValue3Inline.createDefault());\n+        va[0] = vt;\n+        staticVal3 = vt;\n+        vt.verify(vt);\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) {\n+        MyValue3 vt = MyValue3.createDefault();\n+        MyValue3[] va = new MyValue3[1];\n+        va[0] = MyValue3.create();\n+        MyValue3 res = test35(va[0], va);\n+        res.verify(vt);\n+        staticVal3.verify(vt);\n+        va[0].verify(vt);\n+    }\n+\n+    \/\/ Merge inline types created from two branches\n+\n+    private Object test36_helper(Object v) {\n+        return v;\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test36(boolean b) {\n+        Object o;\n+        if (b) {\n+            o = test36_helper(MyValue1.createWithFieldsInline(rI, rL));\n+        } else {\n+            o = test36_helper(MyValue1.createWithFieldsDontInline(rI + 1, rL + 1));\n+        }\n+        MyValue1 v = (MyValue1)o;\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test36_verifier(boolean warmup) {\n+        Asserts.assertEQ(test36(true), hash());\n+        Asserts.assertEQ(test36(false), hash(rI + 1, rL + 1));\n+    }\n+\n+    \/\/ Test correct loading of flattened fields\n+    primitive class Test37Value2 {\n+        final int x = 0;\n+        final int y = 0;\n+    }\n+\n+    primitive class Test37Value1 {\n+        final double d = 0;\n+        final float f = 0;\n+        final Test37Value2 v = new Test37Value2();\n+    }\n+\n+    @Test\n+    public Test37Value1 test37(Test37Value1 vt) {\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) {\n+        Test37Value1 vt = new Test37Value1();\n+        Asserts.assertEQ(test37(vt), vt);\n+    }\n+\n+    \/\/ Test elimination of inline type allocations without a unique CheckCastPP\n+    primitive class Test38Value {\n+        public int i;\n+        public Test38Value(int i) { this.i = i; }\n+    }\n+\n+    static Test38Value test38Field;\n+\n+    @Test\n+    public void test38() {\n+        for (int i = 3; i < 100; ++i) {\n+            int j = 1;\n+            while (++j < 11) {\n+                try {\n+                    test38Field = new Test38Value(i);\n+                } catch (ArithmeticException ae) { }\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        test38Field = Test38Value.default;\n+        test38();\n+        Asserts.assertEQ(test38Field, new Test38Value(99));\n+    }\n+\n+    \/\/ Tests split if with inline type Phi users\n+    static primitive class Test39Value {\n+        public int iFld1;\n+        public int iFld2;\n+\n+        public Test39Value(int i1, int i2) { iFld1 = i1; iFld2 = i2; }\n+    }\n+\n+    static int test39A1[][] = new int[400][400];\n+    static double test39A2[] = new double[400];\n+    static Test39Value test39Val = Test39Value.default;\n+\n+    @DontInline\n+    public int[] getArray() {\n+        return new int[400];\n+    }\n+\n+    @Test\n+    @Warmup(10)\n+    public int test39() {\n+        int result = 0;\n+        for (int i = 0; i < 100; ++i) {\n+            switch ((i >>> 1) % 3) {\n+            case 0:\n+                test39A1[i][i] = i;\n+                break;\n+            case 1:\n+                for (int j = 0; j < 100; ++j) {\n+                    test39A1[i] = getArray();\n+                    test39Val = new Test39Value(j, test39Val.iFld2);\n+                }\n+                break;\n+            case 2:\n+                for (float f = 142; f > i; f--) {\n+                    test39A2[i + 1] += 3;\n+                }\n+                result += test39Val.iFld1;\n+                break;\n+            }\n+            double d1 = 1;\n+            while (++d1 < 142) {\n+                test39A1[(i >>> 1) % 400][i + 1] = result;\n+                test39Val = new Test39Value(i, test39Val.iFld2);\n+            }\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        int result = test39();\n+        Asserts.assertEQ(result, 1552);\n+    }\n+\n+    \/\/ Test scalar replacement of inline type array containing inline type with oop fields\n+    @Test()\n+    public long test40(boolean b) {\n+        MyValue1[] va = {MyValue1.createWithFieldsInline(rI, rL)};\n+        long result = 0;\n+        for (int i = 0; i < 1000; ++i) {\n+            if (!b) {\n+                result = va[0].hash();\n+            }\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) {\n+        long result = test40(warmup);\n+        Asserts.assertEQ(result, warmup ? 0 : hash());\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestBasicFunctionality.java","additions":910,"deletions":0,"binary":false,"changes":910,"status":"added"},{"patch":"@@ -0,0 +1,380 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+import java.util.Arrays;\n+\n+import jdk.test.lib.Asserts;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Various tests that are specific for C1.\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires os.simpleArch == \"x64\"\n+ * @compile -XDallowWithFieldOperator TestC1.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestC1\n+ *\/\n+public class TestC1 extends InlineTypeTest {\n+    public static final int C1 = COMP_LEVEL_SIMPLE;\n+    public static final int C2 = COMP_LEVEL_FULL_OPTIMIZATION;\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestC1 test = new TestC1();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class, MyValue3.class, MyValue3Inline.class);\n+    }\n+\n+    @Override\n+    public int getNumScenarios() {\n+        return 5;\n+    }\n+\n+    @Override\n+    public String[] getVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 0: return new String[] { \/\/ C1 only\n+                \"-XX:TieredStopAtLevel=1\",\n+                \"-XX:+TieredCompilation\",\n+            };\n+        case 1: return new String[] { \/\/ C2 only. (Make sure the tests are correctly written)\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:-TieredCompilation\",\n+            };\n+        case 2: return new String[] { \/\/ interpreter only\n+                \"-Xint\",\n+            };\n+        case 3: return new String[] {\n+                \/\/ Xcomp Only C1.\n+                \"-XX:TieredStopAtLevel=1\",\n+                \"-XX:+TieredCompilation\",\n+                \"-Xcomp\",\n+            };\n+        case 4: return new String[] {\n+                \/\/ Xcomp Only C2.\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:-TieredCompilation\",\n+                \"-Xcomp\",\n+            };\n+        }\n+        return null;\n+    }\n+\n+    \/\/ JDK-8229799\n+    @Test(compLevel=C1)\n+    public long test1(Object a, Object b, long n) {\n+        long r;\n+        n += (a == b) ? 0x5678123456781234L : 0x1234567812345678L;\n+        n -= 1;\n+        return n;\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        MyValue1 v1 = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1 v2 = MyValue1.createWithFieldsInline(rI, rL+1);\n+        long r1 = test1(v1, v1, 1);\n+        long r2 = test1(v1, v2, 1);\n+        Asserts.assertEQ(r1, 0x5678123456781234L);\n+        Asserts.assertEQ(r2, 0x1234567812345678L);\n+    }\n+\n+    static primitive class SimpleValue2 {\n+        final int value;\n+        SimpleValue2(int value) {\n+            this.value = value;\n+        }\n+    }\n+\n+    \/\/ JDK-8231961\n+    \/\/ Test that the value numbering optimization does not remove\n+    \/\/ the second load from the buffered array element.\n+    @Test(compLevel=C1)\n+    public int test2(SimpleValue2[] array) {\n+        return array[0].value + array[0].value;\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        SimpleValue2[] array = new SimpleValue2[1];\n+        array[0] = new SimpleValue2(rI);\n+        int result = test2(array);\n+        Asserts.assertEQ(result, 2*rI);\n+    }\n+\n+\n+    \/\/ Tests below (3 to 8) check the behavior of the C1 optimization to access\n+    \/\/ sub-elements of a flattened array without copying the element first\n+\n+    \/\/ Test access to a null array\n+    @Test(compLevel=C1)\n+    public int test3(MyValue2[] array, int index) {\n+        return array[index].x;\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        NullPointerException npe = null;\n+        try {\n+            test3(null, 0);\n+        } catch(NullPointerException e) {\n+            npe = e;\n+        }\n+        Asserts.assertNE(npe, null);\n+    }\n+\n+    \/\/ Test out of bound accesses\n+    @Test(compLevel=C1)\n+    public int test4(MyValue2[] array, int index) {\n+        return array[index].x;\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        MyValue2[] array = new MyValue2[2];\n+        ArrayIndexOutOfBoundsException aioob = null;\n+        try {\n+            test3(array, -1);\n+        } catch(ArrayIndexOutOfBoundsException e) {\n+            aioob = e;\n+        }\n+        Asserts.assertNE(aioob, null);\n+        aioob = null;\n+        try {\n+            test3(array, 2);\n+        } catch(ArrayIndexOutOfBoundsException e) {\n+            aioob = e;\n+        }\n+        Asserts.assertNE(aioob, null);\n+    }\n+\n+    \/\/ Test 1st level sub-element access to primitive field\n+    @Test(compLevel=C1)\n+    public int test5(MyValue2[] array, int index) {\n+        return array[index].x;\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        MyValue2[] array = new MyValue2[2];\n+        MyValue2 v = new MyValue2(1,(byte)2, new MyValue2Inline(5.0d, 345L));\n+        array[1] = v;\n+        int x = test5(array, 1);\n+        Asserts.assertEQ(x, 1);\n+    }\n+\n+    \/\/ Test 1st level sub-element access to flattened field\n+    @Test(compLevel=C1)\n+    public MyValue2Inline test6(MyValue2[] array, int index) {\n+        return array[index].v;\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        MyValue2[] array = new MyValue2[2];\n+        MyValue2Inline vi = new MyValue2Inline(3.5d, 678L);\n+        MyValue2 v = new MyValue2(1,(byte)2, vi);\n+        array[0] = v;\n+        MyValue2Inline vi2 = test6(array, 0);\n+        Asserts.assertEQ(vi, vi2);\n+    }\n+\n+    \/\/ Test 1st level sub-element access to non-flattened field\n+    static primitive class Big {\n+        long l0,l1,l2,l3,l4,l5,l6,l7,l8,l9,l10,l11,l12,l13,l14,l15,l16,l17,l18,l19 ;\n+\n+        Big(long n) {\n+            l0 = n++; l1 = n++; l2 = n++; l3 = n++; l4 = n++; l5 = n++; l6 = n++; l7 = n++; l8 = n++;\n+            l9 = n++; l10 = n++; l11 = n++; l12 = n++; l13 = n++; l14 = n++; l15 = n++; l16= n++;\n+            l17 = n++; l18 = n++; l19 = n++;\n+        }\n+\n+        void check(long n, int i) {\n+            Asserts.assertEQ(l0, n); n += i;\n+            Asserts.assertEQ(l1, n); n += i;\n+            Asserts.assertEQ(l2, n); n += i;\n+            Asserts.assertEQ(l3, n); n += i;\n+            Asserts.assertEQ(l4, n); n += i;\n+            Asserts.assertEQ(l5, n); n += i;\n+            Asserts.assertEQ(l6, n); n += i;\n+            Asserts.assertEQ(l7, n); n += i;\n+            Asserts.assertEQ(l8, n); n += i;\n+            Asserts.assertEQ(l9, n); n += i;\n+            Asserts.assertEQ(l10, n); n += i;\n+            Asserts.assertEQ(l11, n); n += i;\n+            Asserts.assertEQ(l12, n); n += i;\n+            Asserts.assertEQ(l13, n); n += i;\n+            Asserts.assertEQ(l14, n); n += i;\n+            Asserts.assertEQ(l15, n); n += i;\n+            Asserts.assertEQ(l16, n); n += i;\n+            Asserts.assertEQ(l17, n); n += i;\n+            Asserts.assertEQ(l18, n); n += i;\n+            Asserts.assertEQ(l19, n);\n+        }\n+    }\n+\n+    static primitive class TestValue {\n+        int i;\n+        Big big;\n+\n+        TestValue(int n) {\n+            i = n;\n+            big = new Big(n);\n+        }\n+    }\n+\n+    @Test(compLevel=C1)\n+    public Big test7(TestValue[] array, int index) {\n+        return array[index].big;\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        TestValue[] array = new TestValue[7];\n+        Big b0 = test7(array, 3);\n+        b0.check(0, 0);\n+        TestValue tv = new TestValue(9);\n+        array[5] = tv;\n+        Big b1 = test7(array, 5);\n+        b1.check(9, 1);\n+    }\n+\n+    \/\/ Test 2nd level sub-element access to primitive field\n+    @Test(compLevel=C1)\n+    public byte test8(MyValue1[] array, int index) {\n+        return array[index].v2.y;\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        MyValue1[] array = new MyValue1[23];\n+        MyValue2 mv2a = MyValue2.createWithFieldsInline(7, 63L, 8.9d);\n+        MyValue2 mv2b = MyValue2.createWithFieldsInline(11, 69L, 17.3d);\n+        MyValue1 mv1 = new MyValue1(1, 2L, (short)3, 4, null, mv2a, mv2b, 'z');\n+        array[19] = mv1;\n+        byte b = test8(array, 19);\n+        Asserts.assertEQ(b, (byte)11);\n+    }\n+\n+\n+    \/\/ Test optimizations for arrays of empty types\n+    \/\/ (read\/write are not performed, pre-allocated instance is used for reads)\n+    \/\/ Most tests check that error conditions are still correctly handled\n+    \/\/ (OOB, null pointer)\n+    static primitive class EmptyType {}\n+\n+    @Test(compLevel=C1)\n+    public EmptyType test9() {\n+        EmptyType[] array = new EmptyType[10];\n+        return array[4];\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        EmptyType et = test9();\n+        Asserts.assertEQ(et, EmptyType.default);\n+    }\n+\n+    @Test(compLevel=C1)\n+    public EmptyType test10(EmptyType[] array) {\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        EmptyType[] array = new EmptyType[16];\n+        EmptyType et = test10(array);\n+        Asserts.assertEQ(et, EmptyType.default);\n+    }\n+\n+    @Test(compLevel=C1)\n+    public EmptyType test11(EmptyType[] array, int index) {\n+        return array[index];\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        Exception e = null;\n+        EmptyType[] array = new EmptyType[10];\n+        try {\n+            EmptyType et = test11(array, 11);\n+        } catch (ArrayIndexOutOfBoundsException ex) {\n+            e = ex;\n+        }\n+        Asserts.assertNotNull(e);\n+        e = null;\n+        try {\n+            EmptyType et = test11(array, -1);\n+        } catch (ArrayIndexOutOfBoundsException ex) {\n+            e = ex;\n+        }\n+        Asserts.assertNotNull(e);\n+        e = null;\n+        try {\n+            EmptyType et = test11(null, 1);\n+        } catch (NullPointerException ex) {\n+            e = ex;\n+        }\n+        Asserts.assertNotNull(e);\n+    }\n+\n+    @Test(compLevel=C1)\n+    public void test12(EmptyType[] array, int index, EmptyType value) {\n+        array[index] = value;\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        EmptyType[] array = new EmptyType[16];\n+        test12(array, 2, EmptyType.default);\n+        Exception e = null;\n+        try {\n+            test12(null, 2, EmptyType.default);\n+        } catch(NullPointerException ex) {\n+            e = ex;\n+        }\n+        Asserts.assertNotNull(e);\n+        e = null;\n+        try {\n+            test12(array, 17, EmptyType.default);\n+        } catch(ArrayIndexOutOfBoundsException ex) {\n+            e = ex;\n+        }\n+        Asserts.assertNotNull(e);\n+        e = null;\n+        try {\n+            test12(array, -8, EmptyType.default);\n+        } catch(ArrayIndexOutOfBoundsException ex) {\n+            e = ex;\n+        }\n+        Asserts.assertNotNull(e);\n+    }\n+\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestC1.java","additions":380,"deletions":0,"binary":false,"changes":380,"status":"added"},{"patch":"@@ -0,0 +1,630 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/**\n+ * @test\n+ * @key randomness\n+ * @summary Test inline type calling convention with compiled to compiled calls.\n+ * @library \/test\/lib \/test\/lib \/compiler\/whitebox \/\n+ * @compile TestC2CCalls.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   TestC2CCalls\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:-UseBimorphicInlining -Xbatch\n+ *                   -XX:CompileCommand=compileonly,TestC2CCalls*::test*\n+ *                   -XX:CompileCommand=dontinline,TestC2CCalls*::test*\n+ *                   TestC2CCalls\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:-UseBimorphicInlining -Xbatch -XX:-ProfileInterpreter\n+ *                   -XX:CompileCommand=compileonly,TestC2CCalls*::test*\n+ *                   -XX:CompileCommand=dontinline,TestC2CCalls*::test*\n+ *                   TestC2CCalls\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:-UseBimorphicInlining -Xbatch\n+ *                   -XX:CompileCommand=compileonly,TestC2CCalls::test*\n+ *                   -XX:CompileCommand=dontinline,TestC2CCalls*::test*\n+ *                   TestC2CCalls\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:-UseBimorphicInlining -Xbatch -XX:-ProfileInterpreter\n+ *                   -XX:CompileCommand=compileonly,TestC2CCalls::test*\n+ *                   -XX:CompileCommand=dontinline,TestC2CCalls*::test*\n+ *                   TestC2CCalls\n+ *\/\n+\n+import java.lang.reflect.Method;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.Utils;\n+\n+import sun.hotspot.WhiteBox;\n+\n+public class TestC2CCalls {\n+    public static final WhiteBox WHITE_BOX = WhiteBox.getWhiteBox();\n+    public static final int COMP_LEVEL_FULL_OPTIMIZATION = 4; \/\/ C2 or JVMCI\n+    public static final int rI = Utils.getRandomInstance().nextInt() % 1000;\n+\n+    static primitive class OtherVal {\n+        public final int x;\n+\n+        private OtherVal(int x) {\n+            this.x = x;\n+        }\n+    }\n+\n+    static interface MyInterface1 {\n+        public MyInterface1 test1(OtherVal other, int y);\n+        public MyInterface1 test2(OtherVal other1, OtherVal.ref other2, int y);\n+        public MyInterface1 test3(OtherVal other1, OtherVal.ref other2, int y, boolean deopt);\n+        public MyInterface1 test4(OtherVal other1, OtherVal.ref other2, int y);\n+        public MyInterface1 test5(OtherVal other1, OtherVal.ref other2, int y);\n+        public MyInterface1 test6();\n+        public MyInterface1 test7(int i1, int i2, int i3, int i4, int i5, int i6);\n+        public MyInterface1 test8(int i1, int i2, int i3, int i4, int i5, int i6, int i7);\n+        public MyInterface1 test9(MyValue3 other, int i1, int i2, int i3, int i4, int i5, int i6);\n+        public MyInterface1 test10(MyValue4 other, int i1, int i2, int i3, int i4, int i5, int i6);\n+\n+        public int getValue();\n+    }\n+\n+    static primitive class MyValue1 implements MyInterface1 {\n+        public final int x;\n+\n+        private MyValue1(int x) {\n+            this.x = x;\n+        }\n+\n+        @Override\n+        public int getValue() {\n+            return x;\n+        }\n+\n+        @Override\n+        public MyValue1 test1(OtherVal other, int y) {\n+            return new MyValue1(x + other.x + y);\n+        }\n+\n+        @Override\n+        public MyValue1 test2(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyValue1(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyValue1 test3(OtherVal other1, OtherVal.ref other2, int y, boolean deopt) {\n+            if (!deopt) {\n+              return new MyValue1(x + other1.x + other2.x + y);\n+            } else {\n+              \/\/ Uncommon trap\n+              return test1(other1, y);\n+            }\n+        }\n+\n+        @Override\n+        public MyValue1 test4(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyValue1(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyValue1 test5(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyValue1(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyValue1 test6() {\n+            return this;\n+        }\n+\n+        @Override\n+        public MyValue1 test7(int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue1(x + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        @Override\n+        public MyValue1 test8(int i1, int i2, int i3, int i4, int i5, int i6, int i7) {\n+            return new MyValue1(x + i1 + i2 + i3 + i4 + i5 + i6 + i7);\n+        }\n+\n+        public MyValue1 test9(MyValue3 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue1(x + (int)(other.d1 + other.d2 + other.d3 + other.d4) + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        public MyValue1 test10(MyValue4 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue1(x + other.x1 + other.x2 + other.x3 + other.x4 + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+    }\n+\n+    static primitive class MyValue2 implements MyInterface1 {\n+        public final int x;\n+\n+        private MyValue2(int x) {\n+            this.x = x;\n+        }\n+\n+        @Override\n+        public int getValue() {\n+            return x;\n+        }\n+\n+        @Override\n+        public MyValue2 test1(OtherVal other, int y) {\n+            return new MyValue2(x + other.x + y);\n+        }\n+\n+        @Override\n+        public MyValue2 test2(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyValue2(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyValue2 test3(OtherVal other1, OtherVal.ref other2, int y, boolean deopt) {\n+            if (!deopt) {\n+              return new MyValue2(x + other1.x + other2.x + y);\n+            } else {\n+              \/\/ Uncommon trap\n+              return test1(other1, y);\n+            }\n+        }\n+\n+        @Override\n+        public MyValue2 test4(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyValue2(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyValue2 test5(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyValue2(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyValue2 test6() {\n+            return this;\n+        }\n+\n+        @Override\n+        public MyValue2 test7(int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue2(x + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        @Override\n+        public MyValue2 test8(int i1, int i2, int i3, int i4, int i5, int i6, int i7) {\n+            return new MyValue2(x + i1 + i2 + i3 + i4 + i5 + i6 + i7);\n+        }\n+\n+        public MyValue2 test9(MyValue3 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue2(x + (int)(other.d1 + other.d2 + other.d3 + other.d4) + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        public MyValue2 test10(MyValue4 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue2(x + other.x1 + other.x2 + other.x3 + other.x4 + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+    }\n+\n+    static primitive class MyValue3 implements MyInterface1 {\n+        public final double d1;\n+        public final double d2;\n+        public final double d3;\n+        public final double d4;\n+\n+        private MyValue3(double d) {\n+            this.d1 = d;\n+            this.d2 = d;\n+            this.d3 = d;\n+            this.d4 = d;\n+        }\n+\n+        @Override\n+        public int getValue() {\n+            return (int)d4;\n+        }\n+\n+        @Override\n+        public MyValue3 test1(OtherVal other, int y) { return MyValue3.default; }\n+        @Override\n+        public MyValue3 test2(OtherVal other1, OtherVal.ref other2, int y)  { return MyValue3.default; }\n+        @Override\n+        public MyValue3 test3(OtherVal other1, OtherVal.ref other2, int y, boolean deopt)  { return MyValue3.default; }\n+        @Override\n+        public MyValue3 test4(OtherVal other1, OtherVal.ref other2, int y)  { return MyValue3.default; }\n+        @Override\n+        public MyValue3 test5(OtherVal other1, OtherVal.ref other2, int y)  { return MyValue3.default; }\n+        @Override\n+        public MyValue3 test6()  { return MyValue3.default; }\n+\n+        @Override\n+        public MyValue3 test7(int i1, int i2, int i3, int i4, int i5, int i6)  {\n+            return new MyValue3(d1 + d2 + d3 + d4 + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        @Override\n+        public MyValue3 test8(int i1, int i2, int i3, int i4, int i5, int i6, int i7) {\n+            return new MyValue3(d1 + d2 + d3 + d4 + i1 + i2 + i3 + i4 + i5 + i6 + i7);\n+        }\n+\n+        public MyValue3 test9(MyValue3 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue3(d1 + d2 + d3 + d4 + other.d1 + other.d2 + other.d3 + other.d4 + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        public MyValue3 test10(MyValue4 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue3(d1 + d2 + d3 + d4 + other.x1 + other.x2 + other.x3 + other.x4 + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+    }\n+\n+    static primitive class MyValue4 implements MyInterface1 {\n+        public final int x1;\n+        public final int x2;\n+        public final int x3;\n+        public final int x4;\n+\n+        private MyValue4(int i) {\n+            this.x1 = i;\n+            this.x2 = i;\n+            this.x3 = i;\n+            this.x4 = i;\n+        }\n+\n+        @Override\n+        public int getValue() {\n+            return x4;\n+        }\n+\n+        @Override\n+        public MyValue4 test1(OtherVal other, int y) { return MyValue4.default; }\n+        @Override\n+        public MyValue4 test2(OtherVal other1, OtherVal.ref other2, int y)  { return MyValue4.default; }\n+        @Override\n+        public MyValue4 test3(OtherVal other1, OtherVal.ref other2, int y, boolean deopt)  { return MyValue4.default; }\n+        @Override\n+        public MyValue4 test4(OtherVal other1, OtherVal.ref other2, int y)  { return MyValue4.default; }\n+        @Override\n+        public MyValue4 test5(OtherVal other1, OtherVal.ref other2, int y)  { return MyValue4.default; }\n+        @Override\n+        public MyValue4 test6()  { return MyValue4.default; }\n+\n+        @Override\n+        public MyValue4 test7(int i1, int i2, int i3, int i4, int i5, int i6)  {\n+            return new MyValue4(x1 + x2 + x3 + x4 + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        @Override\n+        public MyValue4 test8(int i1, int i2, int i3, int i4, int i5, int i6, int i7) {\n+            return new MyValue4(x1 + x2 + x3 + x4 + i1 + i2 + i3 + i4 + i5 + i6 + i7);\n+        }\n+\n+        public MyValue4 test9(MyValue3 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue4(x1 + x2 + x3 + x4 + (int)(other.d1 + other.d2 + other.d3 + other.d4) + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        public MyValue4 test10(MyValue4 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyValue4(x1 + x2 + x3 + x4 + other.x1 + other.x2 + other.x3 + other.x4 + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+    }\n+\n+    static class MyObject implements MyInterface1 {\n+        private final int x;\n+\n+        private MyObject(int x) {\n+            this.x = x;\n+        }\n+\n+        @Override\n+        public int getValue() {\n+            return x;\n+        }\n+\n+        @Override\n+        public MyObject test1(OtherVal other, int y) {\n+            return new MyObject(x + other.x + y);\n+        }\n+\n+        @Override\n+        public MyObject test2(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyObject(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyObject test3(OtherVal other1, OtherVal.ref other2, int y, boolean deopt) {\n+            if (!deopt) {\n+              return new MyObject(x + other1.x + other2.x + y);\n+            } else {\n+              \/\/ Uncommon trap\n+              return test1(other1, y);\n+            }\n+        }\n+\n+        @Override\n+        public MyObject test4(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyObject(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyObject test5(OtherVal other1, OtherVal.ref other2, int y) {\n+            return new MyObject(x + other1.x + other2.x + y);\n+        }\n+\n+        @Override\n+        public MyObject test6() {\n+            return this;\n+        }\n+\n+        @Override\n+        public MyObject test7(int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyObject(x + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        @Override\n+        public MyObject test8(int i1, int i2, int i3, int i4, int i5, int i6, int i7) {\n+            return new MyObject(x + i1 + i2 + i3 + i4 + i5 + i6 + i7);\n+        }\n+\n+        public MyObject test9(MyValue3 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyObject(x + (int)(other.d1 + other.d2 + other.d3 + other.d4) + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+\n+        public MyObject test10(MyValue4 other, int i1, int i2, int i3, int i4, int i5, int i6) {\n+            return new MyObject(x + other.x1 + other.x2 + other.x3 + other.x4 + i1 + i2 + i3 + i4 + i5 + i6);\n+        }\n+    }\n+\n+    \/\/ Test calling methods with inline type arguments through an interface\n+    public static int test1(MyInterface1 intf, OtherVal other, int y) {\n+        return intf.test1(other, y).getValue();\n+    }\n+\n+    public static int test2(MyInterface1 intf, OtherVal other, int y) {\n+        return intf.test2(other, other, y).getValue();\n+    }\n+\n+    \/\/ Test mixing null-tolerant and null-free inline type arguments\n+    public static int test3(MyValue1 vt, OtherVal other, int y) {\n+        return vt.test2(other, other, y).getValue();\n+    }\n+\n+    public static int test4(MyObject obj, OtherVal other, int y) {\n+        return obj.test2(other, other, y).getValue();\n+    }\n+\n+    \/\/ Optimized interface call with inline type receiver\n+    public static int test5(MyInterface1 intf, OtherVal other, int y) {\n+        return intf.test1(other, y).getValue();\n+    }\n+\n+    public static int test6(MyInterface1 intf, OtherVal other, int y) {\n+        return intf.test2(other, other, y).getValue();\n+    }\n+\n+    \/\/ Optimized interface call with object receiver\n+    public static int test7(MyInterface1 intf, OtherVal other, int y) {\n+        return intf.test1(other, y).getValue();\n+    }\n+\n+    public static int test8(MyInterface1 intf, OtherVal other, int y) {\n+        return intf.test2(other, other, y).getValue();\n+    }\n+\n+    \/\/ Interface calls with deoptimized callee\n+    public static int test9(MyInterface1 intf, OtherVal other, int y, boolean deopt) {\n+        return intf.test3(other, other, y, deopt).getValue();\n+    }\n+\n+    public static int test10(MyInterface1 intf, OtherVal other, int y, boolean deopt) {\n+        return intf.test3(other, other, y, deopt).getValue();\n+    }\n+\n+    \/\/ Optimized interface calls with deoptimized callee\n+    public static int test11(MyInterface1 intf, OtherVal other, int y, boolean deopt) {\n+        return intf.test3(other, other, y, deopt).getValue();\n+    }\n+\n+    public static int test12(MyInterface1 intf, OtherVal other, int y, boolean deopt) {\n+        return intf.test3(other, other, y, deopt).getValue();\n+    }\n+\n+    public static int test13(MyInterface1 intf, OtherVal other, int y, boolean deopt) {\n+        return intf.test3(other, other, y, deopt).getValue();\n+    }\n+\n+    public static int test14(MyInterface1 intf, OtherVal other, int y, boolean deopt) {\n+        return intf.test3(other, other, y, deopt).getValue();\n+    }\n+\n+    \/\/ Interface calls without warmed up \/ compiled callees\n+    public static int test15(MyInterface1 intf, OtherVal other, int y) {\n+        return intf.test4(other, other, y).getValue();\n+    }\n+\n+    public static int test16(MyInterface1 intf, OtherVal other, int y) {\n+        return intf.test5(other, other, y).getValue();\n+    }\n+\n+    \/\/ Interface call with no arguments\n+    public static int test17(MyInterface1 intf) {\n+        return intf.test6().getValue();\n+    }\n+\n+    \/\/ Calls that require stack extension\n+    public static int test18(MyInterface1 intf, int y) {\n+        return intf.test7(y, y, y, y, y, y).getValue();\n+    }\n+\n+    public static int test19(MyInterface1 intf, int y) {\n+        return intf.test8(y, y, y, y, y, y, y).getValue();\n+    }\n+\n+    public static int test20(MyInterface1 intf, MyValue3 v, int y) {\n+        return intf.test9(v, y, y, y, y, y, y).getValue();\n+    }\n+\n+    public static int test21(MyInterface1 intf, MyValue4 v, int y) {\n+        return intf.test10(v, y, y, y, y, y, y).getValue();\n+    }\n+\n+    public static void main(String[] args) {\n+        \/\/ Sometimes, exclude some methods from compilation with C2 to stress test the calling convention\n+        if (Utils.getRandomInstance().nextBoolean()) {\n+            ArrayList<Method> methods = new ArrayList<Method>();\n+            Collections.addAll(methods, MyValue1.class.getDeclaredMethods());\n+            Collections.addAll(methods, MyValue2.class.getDeclaredMethods());\n+            Collections.addAll(methods, MyValue3.class.getDeclaredMethods());\n+            Collections.addAll(methods, MyValue4.class.getDeclaredMethods());\n+            Collections.addAll(methods, MyObject.class.getDeclaredMethods());\n+            Collections.addAll(methods, TestC2CCalls.class.getDeclaredMethods());\n+            System.out.println(\"Excluding methods from C2 compilation:\");\n+            for (Method m : methods) {\n+                if (Utils.getRandomInstance().nextBoolean()) {\n+                    System.out.println(m);\n+                    WHITE_BOX.makeMethodNotCompilable(m, COMP_LEVEL_FULL_OPTIMIZATION, false);\n+                }\n+            }\n+        }\n+\n+        MyValue1 val1 = new MyValue1(rI);\n+        MyValue2 val2 = new MyValue2(rI+1);\n+        MyValue3 val3 = new MyValue3(rI+2);\n+        MyValue4 val4 = new MyValue4(rI+3);\n+        OtherVal other = new OtherVal(rI+4);\n+        MyObject obj = new MyObject(rI+5);\n+\n+        \/\/ Make sure callee methods are compiled\n+        for (int i = 0; i < 10_000; ++i) {\n+            Asserts.assertEQ(val1.test1(other, rI).getValue(), val1.x + other.x + rI);\n+            Asserts.assertEQ(val2.test1(other, rI).getValue(), val2.x + other.x + rI);\n+            Asserts.assertEQ(obj.test1(other, rI).getValue(), obj.x + other.x + rI);\n+            Asserts.assertEQ(val1.test2(other, other, rI).getValue(), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(val2.test2(other, other, rI).getValue(), val2.x + 2*other.x + rI);\n+            Asserts.assertEQ(obj.test2(other, other, rI).getValue(), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(val1.test3(other, other, rI, false).getValue(), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(val2.test3(other, other, rI, false).getValue(), val2.x + 2*other.x + rI);\n+            Asserts.assertEQ(obj.test3(other, other, rI, false).getValue(), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(val1.test7(rI, rI, rI, rI, rI, rI).getValue(), val1.x + 6*rI);\n+            Asserts.assertEQ(val2.test7(rI, rI, rI, rI, rI, rI).getValue(), val2.x + 6*rI);\n+            Asserts.assertEQ(val3.test7(rI, rI, rI, rI, rI, rI).getValue(), (int)(4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(val4.test7(rI, rI, rI, rI, rI, rI).getValue(), (int)(4*val4.x1 + 6*rI));\n+            Asserts.assertEQ(obj.test7(rI, rI, rI, rI, rI, rI).getValue(), obj.x + 6*rI);\n+            Asserts.assertEQ(val1.test8(rI, rI, rI, rI, rI, rI, rI).getValue(), val1.x + 7*rI);\n+            Asserts.assertEQ(val2.test8(rI, rI, rI, rI, rI, rI, rI).getValue(), val2.x + 7*rI);\n+            Asserts.assertEQ(val3.test8(rI, rI, rI, rI, rI, rI, rI).getValue(), (int)(4*val3.d1 + 7*rI));\n+            Asserts.assertEQ(val4.test8(rI, rI, rI, rI, rI, rI, rI).getValue(), (int)(4*val4.x1 + 7*rI));\n+            Asserts.assertEQ(obj.test8(rI, rI, rI, rI, rI, rI, rI).getValue(), obj.x + 7*rI);\n+            Asserts.assertEQ(val1.test9(val3, rI, rI, rI, rI, rI, rI).getValue(), (int)(val1.x + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(val2.test9(val3, rI, rI, rI, rI, rI, rI).getValue(), (int)(val2.x + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(val3.test9(val3, rI, rI, rI, rI, rI, rI).getValue(), (int)(4*val3.d1 + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(val4.test9(val3, rI, rI, rI, rI, rI, rI).getValue(), (int)(4*val4.x1 + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(obj.test9(val3, rI, rI, rI, rI, rI, rI).getValue(), (int)(obj.x + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(val1.test10(val4, rI, rI, rI, rI, rI, rI).getValue(), (int)(val1.x + 4*val4.x1 + 6*rI));\n+            Asserts.assertEQ(val2.test10(val4, rI, rI, rI, rI, rI, rI).getValue(), (int)(val2.x + 4*val4.x1 + 6*rI));\n+            Asserts.assertEQ(val3.test10(val4, rI, rI, rI, rI, rI, rI).getValue(), (int)(4*val3.d1 + 4*val4.x1 + 6*rI));\n+            Asserts.assertEQ(val4.test10(val4, rI, rI, rI, rI, rI, rI).getValue(), (int)(4*val4.x1 + 4*val4.x1 + 6*rI));\n+            Asserts.assertEQ(obj.test10(val4, rI, rI, rI, rI, rI, rI).getValue(), (int)(obj.x + 4*val4.x1 + 6*rI));\n+        }\n+\n+        \/\/ Polute call profile\n+        for (int i = 0; i < 100; ++i) {\n+            Asserts.assertEQ(test15(val1, other, rI), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test16(obj, other, rI), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test17(obj), obj.x);\n+        }\n+\n+        \/\/ Trigger compilation of caller methods\n+        for (int i = 0; i < 100_000; ++i) {\n+            val1 = new MyValue1(rI+i);\n+            val2 = new MyValue2(rI+i+1);\n+            val3 = new MyValue3(rI+i+2);\n+            val4 = new MyValue4(rI+i+3);\n+            other = new OtherVal(rI+i+4);\n+            obj = new MyObject(rI+i+5);\n+\n+            Asserts.assertEQ(test1(val1, other, rI), val1.x + other.x + rI);\n+            Asserts.assertEQ(test1(obj, other, rI), obj.x + other.x + rI);\n+            Asserts.assertEQ(test2(obj, other, rI), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test2(val1, other, rI), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test3(val1, other, rI), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test4(obj, other, rI), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test5(val1, other, rI), val1.x + other.x + rI);\n+            Asserts.assertEQ(test6(val1, other, rI), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test7(obj, other, rI), obj.x + other.x + rI);\n+            Asserts.assertEQ(test8(obj, other, rI), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test9(val1, other, rI, false), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test9(obj, other, rI, false), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test10(val1, other, rI, false), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test10(obj, other, rI, false), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test11(val1, other, rI, false), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test12(val1, other, rI, false), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test13(obj, other, rI, false), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test14(obj, other, rI, false), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test15(obj, other, rI), obj.x + 2*other.x + rI);\n+            Asserts.assertEQ(test16(val1, other, rI), val1.x + 2*other.x + rI);\n+            Asserts.assertEQ(test17(val1), val1.x);\n+            Asserts.assertEQ(test18(val1, rI), val1.x + 6*rI);\n+            Asserts.assertEQ(test18(val2, rI), val2.x + 6*rI);\n+            Asserts.assertEQ(test18(val3, rI), (int)(4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(test18(val4, rI), 4*val4.x1 + 6*rI);\n+            Asserts.assertEQ(test18(obj, rI), obj.x + 6*rI);\n+            Asserts.assertEQ(test19(val1, rI), val1.x + 7*rI);\n+            Asserts.assertEQ(test19(val2, rI), val2.x + 7*rI);\n+            Asserts.assertEQ(test19(val3, rI), (int)(4*val3.d1 + 7*rI));\n+            Asserts.assertEQ(test19(val4, rI), 4*val4.x1 + 7*rI);\n+            Asserts.assertEQ(test19(obj, rI), obj.x + 7*rI);\n+            Asserts.assertEQ(test20(val1, val3, rI), (int)(val1.x + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(test20(val2, val3, rI), (int)(val2.x + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(test20(val3, val3, rI), (int)(4*val3.d1 + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(test20(val4, val3, rI), (int)(4*val4.x1 + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(test20(obj, val3, rI), (int)(obj.x + 4*val3.d1 + 6*rI));\n+            Asserts.assertEQ(test21(val1, val4, rI), val1.x + 4*val4.x1 + 6*rI);\n+            Asserts.assertEQ(test21(val2, val4, rI), val2.x + 4*val4.x1 + 6*rI);\n+            Asserts.assertEQ(test21(val3, val4, rI), (int)(4*val3.d1 + 4*val4.x1 + 6*rI));\n+            Asserts.assertEQ(test21(val4, val4, rI), 4*val4.x1 + 4*val4.x1 + 6*rI);\n+            Asserts.assertEQ(test21(obj, val4, rI), obj.x + 4*val4.x1 + 6*rI);\n+        }\n+\n+        \/\/ Trigger deoptimization\n+        Asserts.assertEQ(val1.test3(other, other, rI, true).getValue(), val1.x + other.x + rI);\n+        Asserts.assertEQ(obj.test3(other, other, rI, true).getValue(), obj.x + other.x + rI);\n+\n+        \/\/ Check results of methods still calling the deoptimized methods\n+        Asserts.assertEQ(test9(val1, other, rI, false), val1.x + 2*other.x + rI);\n+        Asserts.assertEQ(test9(obj, other, rI, false), obj.x + 2*other.x + rI);\n+        Asserts.assertEQ(test10(obj, other, rI, false), obj.x + 2*other.x + rI);\n+        Asserts.assertEQ(test10(val1, other, rI, false), val1.x + 2*other.x + rI);\n+        Asserts.assertEQ(test11(val1, other, rI, false), val1.x + 2*other.x + rI);\n+        Asserts.assertEQ(test11(obj, other, rI, false), obj.x + 2*other.x + rI);\n+        Asserts.assertEQ(test12(obj, other, rI, false), obj.x + 2*other.x + rI);\n+        Asserts.assertEQ(test12(val1, other, rI, false), val1.x + 2*other.x + rI);\n+        Asserts.assertEQ(test13(val1, other, rI, false), val1.x + 2*other.x + rI);\n+        Asserts.assertEQ(test13(obj, other, rI, false), obj.x + 2*other.x + rI);\n+        Asserts.assertEQ(test14(obj, other, rI, false), obj.x + 2*other.x + rI);\n+        Asserts.assertEQ(test14(val1, other, rI, false), val1.x + 2*other.x + rI);\n+\n+        \/\/ Check with unexpected arguments\n+        Asserts.assertEQ(test1(val2, other, rI), val2.x + other.x + rI);\n+        Asserts.assertEQ(test2(val2, other, rI), val2.x + 2*other.x + rI);\n+        Asserts.assertEQ(test5(val2, other, rI), val2.x + other.x + rI);\n+        Asserts.assertEQ(test6(val2, other, rI), val2.x + 2*other.x + rI);\n+        Asserts.assertEQ(test7(val1, other, rI), val1.x + other.x + rI);\n+        Asserts.assertEQ(test8(val1, other, rI), val1.x + 2*other.x + rI);\n+        Asserts.assertEQ(test15(val1, other, rI), val1.x + 2*other.x + rI);\n+        Asserts.assertEQ(test16(obj, other, rI), obj.x + 2*other.x + rI);\n+        Asserts.assertEQ(test17(obj), obj.x);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestC2CCalls.java","additions":630,"deletions":0,"binary":false,"changes":630,"status":"added"},{"patch":"@@ -0,0 +1,1091 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.test.lib.Asserts;\n+\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test inline type calling convention optimizations\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestCallingConvention.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestCallingConvention\n+ *\/\n+public class TestCallingConvention extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 0: return new String[] {\"-Dsun.reflect.inflationThreshold=10000\"}; \/\/ Don't generate bytecodes but call through runtime for reflective calls\n+        case 1: return new String[] {\"-Dsun.reflect.inflationThreshold=10000\"};\n+        case 3: return new String[] {\"-XX:FlatArrayElementMaxSize=0\"};\n+        case 4: return new String[] {\"-XX:-UseTLAB\"};\n+        }\n+        return null;\n+    }\n+\n+    static {\n+        try {\n+            Class<?> clazz = TestCallingConvention.class;\n+            MethodHandles.Lookup lookup = MethodHandles.lookup();\n+\n+            MethodType mt = MethodType.methodType(MyValue2.class, boolean.class);\n+            test32_mh = lookup.findVirtual(clazz, \"test32_interp\", mt);\n+\n+            mt = MethodType.methodType(Object.class, boolean.class);\n+            test33_mh = lookup.findVirtual(clazz, \"test33_interp\", mt);\n+\n+            mt = MethodType.methodType(int.class);\n+            test37_mh = lookup.findVirtual(Test37Value.class, \"test\", mt);\n+        } catch (NoSuchMethodException | IllegalAccessException e) {\n+            e.printStackTrace();\n+            throw new RuntimeException(\"Method handle lookup failed\");\n+        }\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestCallingConvention test = new TestCallingConvention();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class, MyValue3.class, MyValue3Inline.class, MyValue4.class,\n+                 Test27Value1.class, Test27Value2.class, Test27Value3.class, Test37Value.class, EmptyContainer.class, MixedContainer.class);\n+    }\n+\n+    \/\/ Test interpreter to compiled code with various signatures\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test1(MyValue2 v) {\n+        return v.hash();\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test1(v);\n+        Asserts.assertEQ(result, v.hashInterpreted());\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test2(int i1, MyValue2 v, int i2) {\n+        return v.hash() + i1 - i2;\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test2(rI, v, 2*rI);\n+        Asserts.assertEQ(result, v.hashInterpreted() - rI);\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test3(long l1, MyValue2 v, long l2) {\n+        return v.hash() + l1 - l2;\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test3(rL, v, 2*rL);\n+        Asserts.assertEQ(result, v.hashInterpreted() - rL);\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test4(int i, MyValue2 v, long l) {\n+        return v.hash() + i + l;\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test4(rI, v, rL);\n+        Asserts.assertEQ(result, v.hashInterpreted() + rL + rI);\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test5(long l, MyValue2 v, int i) {\n+        return v.hash() + i + l;\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test5(rL, v, rI);\n+        Asserts.assertEQ(result, v.hashInterpreted() + rL + rI);\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test6(long l, MyValue1 v1, int i, MyValue2 v2) {\n+        return v1.hash() + i + l + v2.hash();\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        MyValue1 v1 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue2 v2 = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test6(rL, v1, rI, v2);\n+        Asserts.assertEQ(result, v1.hashInterpreted() + rL + rI + v2.hashInterpreted());\n+    }\n+\n+    \/\/ Test compiled code to interpreter with various signatures\n+    @DontCompile\n+    public long test7_interp(MyValue2 v) {\n+        return v.hash();\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test7(MyValue2 v) {\n+        return test7_interp(v);\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test7(v);\n+        Asserts.assertEQ(result, v.hashInterpreted());\n+    }\n+\n+    @DontCompile\n+    public long test8_interp(int i1, MyValue2 v, int i2) {\n+        return v.hash() + i1 - i2;\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test8(int i1, MyValue2 v, int i2) {\n+        return test8_interp(i1, v, i2);\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test8(rI, v, 2*rI);\n+        Asserts.assertEQ(result, v.hashInterpreted() - rI);\n+    }\n+\n+    @DontCompile\n+    public long test9_interp(long l1, MyValue2 v, long l2) {\n+        return v.hash() + l1 - l2;\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test9(long l1, MyValue2 v, long l2) {\n+        return test9_interp(l1, v, l2);\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test9(rL, v, 2*rL);\n+        Asserts.assertEQ(result, v.hashInterpreted() - rL);\n+    }\n+\n+    @DontCompile\n+    public long test10_interp(int i, MyValue2 v, long l) {\n+        return v.hash() + i + l;\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test10(int i, MyValue2 v, long l) {\n+        return test10_interp(i, v, l);\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test10(rI, v, rL);\n+        Asserts.assertEQ(result, v.hashInterpreted() + rL + rI);\n+    }\n+\n+    @DontCompile\n+    public long test11_interp(long l, MyValue2 v, int i) {\n+        return v.hash() + i + l;\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test11(long l, MyValue2 v, int i) {\n+        return test11_interp(l, v, i);\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test11(rL, v, rI);\n+        Asserts.assertEQ(result, v.hashInterpreted() + rL + rI);\n+    }\n+\n+    @DontCompile\n+    public long test12_interp(long l, MyValue1 v1, int i, MyValue2 v2) {\n+        return v1.hash() + i + l + v2.hash();\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test12(long l, MyValue1 v1, int i, MyValue2 v2) {\n+        return test12_interp(l, v1, i, v2);\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        MyValue1 v1 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue2 v2 = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test12(rL, v1, rI, v2);\n+        Asserts.assertEQ(result, v1.hashInterpreted() + rL + rI + v2.hashInterpreted());\n+    }\n+\n+    \/\/ Test that debug info at a call is correct\n+    @DontCompile\n+    public long test13_interp(MyValue2 v, MyValue1[] va, boolean deopt) {\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test13\"));\n+        }\n+        return v.hash() + va[0].hash() + va[1].hash();\n+    }\n+\n+    @Test(failOn = ALLOC + STORE + TRAP)\n+    public long test13(MyValue2 v, MyValue1[] va, boolean flag, long l) {\n+        return test13_interp(v, va, flag) + l;\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue1[] va = new MyValue1[2];\n+        va[0] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        va[1] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        long result = test13(v, va, !warmup, rL);\n+        Asserts.assertEQ(result, v.hashInterpreted() + va[0].hash() + va[1].hash() + rL);\n+    }\n+\n+    \/\/ Test deoptimization at call return with inline type returned in registers\n+    @DontCompile\n+    public MyValue2 test14_interp(boolean deopt) {\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test14\"));\n+        }\n+        return MyValue2.createWithFieldsInline(rI, rD);\n+    }\n+\n+    @Test()\n+    public MyValue2 test14(boolean flag) {\n+        return test14_interp(flag);\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean warmup) {\n+        MyValue2 result = test14(!warmup);\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        Asserts.assertEQ(result.hash(), v.hash());\n+    }\n+\n+    \/\/ Return inline types in registers from interpreter -> compiled\n+    final MyValue3 test15_vt = MyValue3.create();\n+    @DontCompile\n+    public MyValue3 test15_interp() {\n+        return test15_vt;\n+    }\n+\n+    MyValue3 test15_vt2;\n+    @Test(valid = InlineTypeReturnedAsFieldsOn, failOn = ALLOC + LOAD + TRAP)\n+    @Test(valid = InlineTypeReturnedAsFieldsOff)\n+    public void test15() {\n+        test15_vt2 = test15_interp();\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean warmup) {\n+        test15();\n+        test15_vt.verify(test15_vt2);\n+    }\n+\n+    \/\/ Return inline types in registers from compiled -> interpreter\n+    final MyValue3 test16_vt = MyValue3.create();\n+    @Test(valid = InlineTypeReturnedAsFieldsOn, failOn = ALLOC + STORE + TRAP)\n+    @Test(valid = InlineTypeReturnedAsFieldsOff)\n+    public MyValue3 test16() {\n+        return test16_vt;\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean warmup) {\n+        MyValue3 vt = test16();\n+        test16_vt.verify(vt);\n+    }\n+\n+    \/\/ Return inline types in registers from compiled -> compiled\n+    final MyValue3 test17_vt = MyValue3.create();\n+    @DontInline\n+    public MyValue3 test17_comp() {\n+        return test17_vt;\n+    }\n+\n+    MyValue3 test17_vt2;\n+    @Test(valid = InlineTypeReturnedAsFieldsOn, failOn = ALLOC + LOAD + TRAP)\n+    @Test(valid = InlineTypeReturnedAsFieldsOff)\n+    public void test17() {\n+        test17_vt2 = test17_comp();\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean warmup) throws Exception {\n+        Method helper_m = getClass().getDeclaredMethod(\"test17_comp\");\n+        if (!warmup && USE_COMPILER && !WHITE_BOX.isMethodCompiled(helper_m, false)) {\n+            enqueueMethodForCompilation(helper_m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            Asserts.assertTrue(WHITE_BOX.isMethodCompiled(helper_m, false), \"test17_comp not compiled\");\n+        }\n+        test17();\n+        test17_vt.verify(test17_vt2);\n+    }\n+\n+    \/\/ Same tests as above but with an inline type that cannot be returned in registers\n+\n+    \/\/ Return inline types in registers from interpreter -> compiled\n+    final MyValue4 test18_vt = MyValue4.create();\n+    @DontCompile\n+    public MyValue4 test18_interp() {\n+        return test18_vt;\n+    }\n+\n+    MyValue4 test18_vt2;\n+    @Test\n+    public void test18() {\n+        test18_vt2 = test18_interp();\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        test18();\n+        test18_vt.verify(test18_vt2);\n+    }\n+\n+    \/\/ Return inline types in registers from compiled -> interpreter\n+    final MyValue4 test19_vt = MyValue4.create();\n+    @Test\n+    public MyValue4 test19() {\n+        return test19_vt;\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        MyValue4 vt = test19();\n+        test19_vt.verify(vt);\n+    }\n+\n+    \/\/ Return inline types in registers from compiled -> compiled\n+    final MyValue4 test20_vt = MyValue4.create();\n+    @DontInline\n+    public MyValue4 test20_comp() {\n+        return test20_vt;\n+    }\n+\n+    MyValue4 test20_vt2;\n+    @Test\n+    public void test20() {\n+        test20_vt2 = test20_comp();\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) throws Exception {\n+        Method helper_m = getClass().getDeclaredMethod(\"test20_comp\");\n+        if (!warmup && USE_COMPILER && !WHITE_BOX.isMethodCompiled(helper_m, false)) {\n+            enqueueMethodForCompilation(helper_m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            Asserts.assertTrue(WHITE_BOX.isMethodCompiled(helper_m, false), \"test20_comp not compiled\");\n+        }\n+        test20();\n+        test20_vt.verify(test20_vt2);\n+    }\n+\n+    \/\/ Test no result from inlined method for incremental inlining\n+    final MyValue3 test21_vt = MyValue3.create();\n+    public MyValue3 test21_inlined() {\n+        throw new RuntimeException();\n+    }\n+\n+    @Test\n+    public MyValue3 test21() {\n+        try {\n+            return test21_inlined();\n+        } catch (RuntimeException ex) {\n+            return test21_vt;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        MyValue3 vt = test21();\n+        test21_vt.verify(vt);\n+    }\n+\n+    \/\/ Test returning a non-flattened inline type as fields\n+    MyValue3.ref test22_vt = MyValue3.create();\n+\n+    @Test\n+    public MyValue3 test22() {\n+        return (MyValue3) test22_vt;\n+    }\n+\n+    @DontCompile\n+    public void test22_verifier(boolean warmup) {\n+        MyValue3 vt = test22();\n+        test22_vt.verify(vt);\n+    }\n+\n+    \/\/ Test calling a method that has circular register\/stack dependencies when unpacking inline type arguments\n+    primitive class TestValue23 {\n+        final double f1;\n+        TestValue23(double val) {\n+            f1 = val;\n+        }\n+    }\n+\n+    static double test23Callee(int i1, int i2, int i3, int i4, int i5, int i6,\n+                               TestValue23 v1, TestValue23 v2, TestValue23 v3, TestValue23 v4, TestValue23 v5, TestValue23 v6, TestValue23 v7, TestValue23 v8,\n+                               double d1, double d2, double d3, double d4, double d5, double d6, double d7, double d8) {\n+        return i1 + i2 + i3 + i4 + i5 + i6 + v1.f1 + v2.f1 + v3.f1 + v4.f1 + v5.f1 + v6.f1 + v7.f1 + v8.f1 + d1 + d2 + d3 + d4 + d5 + d6 + d7 + d8;\n+    }\n+\n+    @Test\n+    public double test23(int i1, int i2, int i3, int i4, int i5, int i6,\n+                         TestValue23 v1, TestValue23 v2, TestValue23 v3, TestValue23 v4, TestValue23 v5, TestValue23 v6, TestValue23 v7, TestValue23 v8,\n+                         double d1, double d2, double d3, double d4, double d5, double d6, double d7, double d8) {\n+        return test23Callee(i1, i2, i3, i4, i5, i6,\n+                            v1, v2, v3, v4, v5, v6, v7, v8,\n+                            d1, d2, d3, d4, d5, d6, d7, d8);\n+    }\n+\n+    @DontCompile\n+    public void test23_verifier(boolean warmup) {\n+        TestValue23 vt = new TestValue23(rI);\n+        double res1 = test23(rI, rI, rI, rI, rI, rI,\n+                            vt, vt, vt, vt, vt, vt, vt, vt,\n+                            rI, rI, rI, rI, rI, rI, rI, rI);\n+        double res2 = test23Callee(rI, rI, rI, rI, rI, rI,\n+                                   vt, vt, vt, vt, vt, vt, vt, vt,\n+                                   rI, rI, rI, rI, rI, rI, rI, rI);\n+        double res3 = 6*rI + 8*rI + 8*rI;\n+        Asserts.assertEQ(res1, res2);\n+        Asserts.assertEQ(res2, res3);\n+    }\n+\n+    \/\/ Should not return a nullable inline type as fields\n+    @Test\n+    public MyValue2.ref test24() {\n+        return null;\n+    }\n+\n+    @DontCompile\n+    public void test24_verifier(boolean warmup) {\n+        MyValue2.ref vt = test24();\n+        Asserts.assertEQ(vt, null);\n+    }\n+\n+    \/\/ Same as test24 but with control flow and inlining\n+    @ForceInline\n+    public MyValue2.ref test26_callee(boolean b) {\n+        if (b) {\n+            return null;\n+        } else {\n+            return MyValue2.createWithFieldsInline(rI, rD);\n+        }\n+    }\n+\n+    @Test\n+    public MyValue2.ref test26(boolean b) {\n+        return test26_callee(b);\n+    }\n+\n+    @DontCompile\n+    public void test26_verifier(boolean warmup) {\n+        MyValue2.ref vt = test26(true);\n+        Asserts.assertEQ(vt, null);\n+        vt = test26(false);\n+        Asserts.assertEQ(vt.hash(), MyValue2.createWithFieldsInline(rI, rD).hash());\n+    }\n+\n+    \/\/ Test calling convention with deep hierarchy of flattened fields\n+    final primitive class Test27Value1 {\n+        final Test27Value2 valueField;\n+\n+        private Test27Value1(Test27Value2 val2) {\n+            valueField = val2;\n+        }\n+\n+        @DontInline\n+        public int test(Test27Value1 val1) {\n+            return valueField.test(valueField) + val1.valueField.test(valueField);\n+        }\n+    }\n+\n+    final primitive class Test27Value2 {\n+        final Test27Value3 valueField;\n+\n+        private Test27Value2(Test27Value3 val3) {\n+            valueField = val3;\n+        }\n+\n+        @DontInline\n+        public int test(Test27Value2 val2) {\n+            return valueField.test(valueField) + val2.valueField.test(valueField);\n+        }\n+    }\n+\n+    final primitive class Test27Value3 {\n+        final int x;\n+\n+        private Test27Value3(int x) {\n+            this.x = x;\n+        }\n+\n+        @DontInline\n+        public int test(Test27Value3 val3) {\n+            return x + val3.x;\n+        }\n+    }\n+\n+    @Test\n+    public int test27(Test27Value1 val) {\n+        return val.test(val);\n+    }\n+\n+    @DontCompile\n+    public void test27_verifier(boolean warmup) {\n+        Test27Value3 val3 = new Test27Value3(rI);\n+        Test27Value2 val2 = new Test27Value2(val3);\n+        Test27Value1 val1 = new Test27Value1(val2);\n+        int result = test27(val1);\n+        Asserts.assertEQ(result, 8*rI);\n+    }\n+\n+    static final MyValue1.ref test28Val = MyValue1.createWithFieldsDontInline(rI, rL);\n+\n+    @Test\n+    @Warmup(0)\n+    public String test28() {\n+        return test28Val.toString();\n+    }\n+\n+    @DontCompile\n+    public void test28_verifier(boolean warmup) {\n+        String result = test28();\n+    }\n+\n+    \/\/ Test calling a method returning an inline type as fields via reflection\n+    MyValue3 test29_vt = MyValue3.create();\n+\n+    @Test\n+    public MyValue3 test29() {\n+        return test29_vt;\n+    }\n+\n+    @DontCompile\n+    public void test29_verifier(boolean warmup) throws Exception {\n+        MyValue3 vt = (MyValue3)TestCallingConvention.class.getDeclaredMethod(\"test29\").invoke(this);\n+        test29_vt.verify(vt);\n+    }\n+\n+    @Test\n+    public MyValue3 test30(MyValue3[] array) {\n+        MyValue3 result = MyValue3.create();\n+        array[0] = result;\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) throws Exception {\n+        MyValue3[] array = new MyValue3[1];\n+        MyValue3 vt = (MyValue3)TestCallingConvention.class.getDeclaredMethod(\"test30\", MyValue3[].class).invoke(this, (Object)array);\n+        array[0].verify(vt);\n+    }\n+\n+    MyValue3 test31_vt;\n+\n+    @Test\n+    public MyValue3 test31() {\n+        MyValue3 result = MyValue3.create();\n+        test31_vt = result;\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test31_verifier(boolean warmup) throws Exception {\n+        MyValue3 vt = (MyValue3)TestCallingConvention.class.getDeclaredMethod(\"test31\").invoke(this);\n+        test31_vt.verify(vt);\n+    }\n+\n+    \/\/ Test deoptimization at call return with inline type returned in registers.\n+    \/\/ Same as test14, except the interpreted method is called via a MethodHandle.\n+    static MethodHandle test32_mh;\n+\n+    @DontCompile\n+    public MyValue2 test32_interp(boolean deopt) {\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test32\"));\n+        }\n+        return MyValue2.createWithFieldsInline(rI+32, rD);\n+    }\n+\n+    @Test()\n+    public MyValue2 test32(boolean flag) throws Throwable {\n+        return (MyValue2)test32_mh.invokeExact(this, flag);\n+    }\n+\n+    @DontCompile\n+    public void test32_verifier(boolean warmup) throws Throwable {\n+        MyValue2 result = test32(!warmup);\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI+32, rD);\n+        Asserts.assertEQ(result.hash(), v.hash());\n+    }\n+\n+    \/\/ Same as test32, except the return type is not flattenable.\n+    static MethodHandle test33_mh;\n+\n+    @DontCompile\n+    public Object test33_interp(boolean deopt) {\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test33\"));\n+        }\n+        return MyValue2.createWithFieldsInline(rI+33, rD);\n+    }\n+\n+    @Test()\n+    public MyValue2 test33(boolean flag) throws Throwable {\n+        Object o = test33_mh.invokeExact(this, flag);\n+        return (MyValue2)o;\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) throws Throwable {\n+        MyValue2 result = test33(!warmup);\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI+33, rD);\n+        Asserts.assertEQ(result.hash(), v.hash());\n+    }\n+\n+    \/\/ Test selection of correct entry point in SharedRuntime::handle_wrong_method\n+    static boolean test34_deopt = false;\n+\n+    @DontInline\n+    public static long test34_callee(MyValue2 vt, int i1, int i2, int i3, int i4) {\n+        Asserts.assertEQ(i1, rI);\n+        Asserts.assertEQ(i2, rI);\n+        Asserts.assertEQ(i3, rI);\n+        Asserts.assertEQ(i4, rI);\n+\n+        if (test34_deopt) {\n+            \/\/ uncommon trap\n+            int result = 0;\n+            for (int i = 0; i < 10; ++i) {\n+                result += rL;\n+            }\n+            return vt.hash() + i1 + i2 + i3 + i4 + result;\n+        }\n+        return vt.hash() + i1 + i2 + i3 + i4;\n+    }\n+\n+    @Test()\n+    @Warmup(10000) \/\/ Make sure test34_callee is compiled\n+    public static long test34(MyValue2 vt, int i1, int i2, int i3, int i4) {\n+        return test34_callee(vt, i1, i2, i3, i4);\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        MyValue2 vt = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test34(vt, rI, rI, rI, rI);\n+        Asserts.assertEQ(result, vt.hash()+4*rI);\n+        if (!warmup) {\n+            test34_deopt = true;\n+            for (int i = 0; i < 100; ++i) {\n+                result = test34(vt, rI, rI, rI, rI);\n+                Asserts.assertEQ(result, vt.hash()+4*rI+10*rL);\n+            }\n+        }\n+    }\n+\n+    \/\/ Test OSR compilation of method with scalarized argument\n+    @Test()\n+    public static long test35(MyValue2 vt, int i1, int i2, int i3, int i4) {\n+        int result = 0;\n+        \/\/ Trigger OSR compilation\n+        for (int i = 0; i < 10_000; ++i) {\n+            result += i1;\n+        }\n+        return vt.hash() + i1 + i2 + i3 + i4 + result;\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) {\n+        MyValue2 vt = MyValue2.createWithFieldsInline(rI, rD);\n+        long result = test35(vt, rI, rI, rI, rI);\n+        Asserts.assertEQ(result, vt.hash()+10004*rI);\n+    }\n+\n+    \/\/ Same as test31 but with GC in callee to verify that the\n+    \/\/ pre-allocated buffer for the returned inline type remains valid.\n+    MyValue3 test36_vt;\n+\n+    @Test\n+    public MyValue3 test36() {\n+        MyValue3 result = MyValue3.create();\n+        test36_vt = result;\n+        System.gc();\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test36_verifier(boolean warmup) throws Exception {\n+        MyValue3 vt = (MyValue3)TestCallingConvention.class.getDeclaredMethod(\"test36\").invoke(this);\n+        test36_vt.verify(vt);\n+    }\n+\n+    \/\/ Test method resolution with scalarized inline type receiver at invokespecial\n+    static final MethodHandle test37_mh;\n+\n+    primitive class Test37Value {\n+        int x = rI;\n+\n+        @DontInline\n+        public int test() {\n+            return x;\n+        }\n+    }\n+\n+    @Test\n+    public int test37(Test37Value vt) throws Throwable {\n+        \/\/ Generates invokespecial call of Test37Value::test\n+        return (int)test37_mh.invokeExact(vt);\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) throws Throwable {\n+        Test37Value vt = new Test37Value();\n+        int res = test37(vt);\n+        Asserts.assertEQ(res, rI);\n+    }\n+\n+    \/\/ Test passing\/returning an empty inline type\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public MyValueEmpty test38(MyValueEmpty vt) {\n+        return vt.copy(vt);\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        MyValueEmpty vt = new MyValueEmpty();\n+        MyValueEmpty res = test38(vt);\n+        Asserts.assertEQ(res, vt);\n+    }\n+\n+    static primitive class LargeValueWithOops {\n+        \/\/ Use all 6 int registers + 50\/2 on stack = 29\n+        Object o1 = null;\n+        Object o2 = null;\n+        Object o3 = null;\n+        Object o4 = null;\n+        Object o5 = null;\n+        Object o6 = null;\n+        Object o7 = null;\n+        Object o8 = null;\n+        Object o9 = null;\n+        Object o10 = null;\n+        Object o11 = null;\n+        Object o12 = null;\n+        Object o13 = null;\n+        Object o14 = null;\n+        Object o15 = null;\n+        Object o16 = null;\n+        Object o17 = null;\n+        Object o18 = null;\n+        Object o19 = null;\n+        Object o20 = null;\n+        Object o21 = null;\n+        Object o22 = null;\n+        Object o23 = null;\n+        Object o24 = null;\n+        Object o25 = null;\n+        Object o26 = null;\n+        Object o27 = null;\n+        Object o28 = null;\n+        Object o29 = null;\n+    }\n+\n+    static primitive class LargeValueWithoutOops {\n+        \/\/ Use all 6 int registers + 50\/2 on stack = 29\n+        int i1 = 0;\n+        int i2 = 0;\n+        int i3 = 0;\n+        int i4 = 0;\n+        int i5 = 0;\n+        int i6 = 0;\n+        int i7 = 0;\n+        int i8 = 0;\n+        int i9 = 0;\n+        int i10 = 0;\n+        int i11 = 0;\n+        int i12 = 0;\n+        int i13 = 0;\n+        int i14 = 0;\n+        int i15 = 0;\n+        int i16 = 0;\n+        int i17 = 0;\n+        int i18 = 0;\n+        int i19 = 0;\n+        int i20 = 0;\n+        int i21 = 0;\n+        int i22 = 0;\n+        int i23 = 0;\n+        int i24 = 0;\n+        int i25 = 0;\n+        int i26 = 0;\n+        int i27 = 0;\n+        int i28 = 0;\n+        int i29 = 0;\n+        \/\/ Use all 7 float registers\n+        double d1 = 0;\n+        double d2 = 0;\n+        double d3 = 0;\n+        double d4 = 0;\n+        double d5 = 0;\n+        double d6 = 0;\n+        double d7 = 0;\n+        double d8 = 0;\n+    }\n+\n+    \/\/ Test passing\/returning a large inline type with oop fields\n+    @Test()\n+    public static LargeValueWithOops test39(LargeValueWithOops vt) {\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        LargeValueWithOops vt = new LargeValueWithOops();\n+        LargeValueWithOops res = test39(vt);\n+        Asserts.assertEQ(res, vt);\n+    }\n+\n+    \/\/ Test passing\/returning a large inline type with only int\/float fields\n+    @Test()\n+    public static LargeValueWithoutOops test40(LargeValueWithoutOops vt) {\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) {\n+        LargeValueWithoutOops vt = new LargeValueWithoutOops();\n+        LargeValueWithoutOops res = test40(vt);\n+        Asserts.assertEQ(res, vt);\n+    }\n+\n+    \/\/ Test passing\/returning an empty inline type together with non-empty\n+    \/\/ inline types such that only some inline type arguments are scalarized.\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public MyValueEmpty test41(MyValue1 vt1, MyValueEmpty vt2, MyValue1 vt3) {\n+        return vt2.copy(vt2);\n+    }\n+\n+    @DontCompile\n+    public void test41_verifier(boolean warmup) {\n+        MyValueEmpty res = test41(MyValue1.default, MyValueEmpty.default, MyValue1.default);\n+        Asserts.assertEQ(res, MyValueEmpty.default);\n+    }\n+\n+    \/\/ More empty inline type tests with containers\n+\n+    static primitive class EmptyContainer {\n+        private MyValueEmpty empty;\n+\n+        EmptyContainer(MyValueEmpty empty) {\n+            this.empty = empty;\n+        }\n+\n+        @ForceInline\n+        MyValueEmpty getInline() { return empty; }\n+\n+        @DontInline\n+        MyValueEmpty getNoInline() { return empty; }\n+    }\n+\n+    static primitive class MixedContainer {\n+        public int val;\n+        private EmptyContainer empty;\n+\n+        MixedContainer(int val, EmptyContainer empty) {\n+            this.val = val;\n+            this.empty = empty;\n+        }\n+\n+        @ForceInline\n+        EmptyContainer getInline() { return empty; }\n+\n+        @DontInline\n+        EmptyContainer getNoInline() { return empty; }\n+    }\n+\n+    \/\/ Empty inline type return\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public MyValueEmpty test42() {\n+        EmptyContainer c = new EmptyContainer(MyValueEmpty.default);\n+        return c.getInline();\n+    }\n+\n+    @DontCompile\n+    public void test42_verifier(boolean warmup) {\n+        MyValueEmpty empty = test42();\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+    }\n+\n+    \/\/ Empty inline type container return\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public EmptyContainer test43(EmptyContainer c) {\n+        return c;\n+    }\n+\n+    @DontCompile\n+    public void test43_verifier(boolean warmup) {\n+        EmptyContainer c = test43(EmptyContainer. default);\n+        Asserts.assertEquals(c, EmptyContainer.default);\n+    }\n+\n+    \/\/ Empty inline type container (mixed) return\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public MixedContainer test44() {\n+        MixedContainer c = new MixedContainer(rI, EmptyContainer.default);\n+        c = new MixedContainer(rI, c.getInline());\n+        return c;\n+    }\n+\n+    @DontCompile\n+    public void test44_verifier(boolean warmup) {\n+        MixedContainer c = test44();\n+        Asserts.assertEquals(c, new MixedContainer(rI, EmptyContainer.default));\n+    }\n+\n+    \/\/ Empty inline type container argument\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public EmptyContainer test45(EmptyContainer c) {\n+        return new EmptyContainer(c.getInline());\n+    }\n+\n+    @DontCompile\n+    public void test45_verifier(boolean warmup) {\n+        EmptyContainer empty = test45(EmptyContainer.default);\n+        Asserts.assertEquals(empty, EmptyContainer.default);\n+    }\n+\n+    \/\/ Empty inline type container and mixed container arguments\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public MyValueEmpty test46(EmptyContainer c1, MixedContainer c2, MyValueEmpty empty) {\n+        c2 = new MixedContainer(c2.val, c1);\n+        return c2.getNoInline().getNoInline();\n+    }\n+\n+    @DontCompile\n+    public void test46_verifier(boolean warmup) {\n+        MyValueEmpty empty = test46(EmptyContainer.default, MixedContainer.default, MyValueEmpty.default);\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+    }\n+\n+    \/\/ No receiver and only empty argument\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public static MyValueEmpty test47(MyValueEmpty empty) {\n+        return empty;\n+    }\n+\n+    @DontCompile\n+    public void test47_verifier(boolean warmup) {\n+        MyValueEmpty empty = test47(MyValueEmpty.default);\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+    }\n+\n+    \/\/ No receiver and only empty container argument\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public static MyValueEmpty test48(EmptyContainer empty) {\n+        return empty.getNoInline();\n+    }\n+\n+    @DontCompile\n+    public void test48_verifier(boolean warmup) {\n+        MyValueEmpty empty = test48(EmptyContainer.default);\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+    }\n+\n+    \/\/ Test conditional inline type return with incremental inlining\n+    public MyValue3 test49_inlined1(boolean b) {\n+        if (b) {\n+            return MyValue3.create();\n+        } else {\n+            return MyValue3.create();\n+        }\n+    }\n+\n+    public MyValue3 test49_inlined2(boolean b) {\n+        return test49_inlined1(b);\n+    }\n+\n+    @Test\n+    public void test49(boolean b) {\n+        test49_inlined2(b);\n+    }\n+\n+    @DontCompile\n+    public void test49_verifier(boolean warmup) {\n+        test49(true);\n+        test49(false);\n+    }\n+\n+    \/\/ Variant of test49 with result verification (triggered different failure mode)\n+    final MyValue3 test50_vt = MyValue3.create();\n+    final MyValue3 test50_vt2 = test50_vt;\n+\n+    public MyValue3 test50_inlined1(boolean b) {\n+        if (b) {\n+            return test50_vt;\n+        } else {\n+            return test50_vt2;\n+        }\n+    }\n+\n+    public MyValue3 test50_inlined2(boolean b) {\n+        return test50_inlined1(b);\n+    }\n+\n+    @Test\n+    public void test50(boolean b) {\n+        MyValue3 vt = test50_inlined2(b);\n+        test50_vt.verify(vt);\n+    }\n+\n+    @DontCompile\n+    public void test50_verifier(boolean warmup) {\n+        test50(true);\n+        test50(false);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestCallingConvention.java","additions":1091,"deletions":0,"binary":false,"changes":1091,"status":"added"},{"patch":"@@ -0,0 +1,2362 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import sun.hotspot.WhiteBox;\n+import jdk.test.lib.Asserts;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test calls from {C1} to {C2, Interpreter}, and vice versa.\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestCallingConventionC1.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestCallingConventionC1\n+ *\/\n+public class TestCallingConventionC1 extends InlineTypeTest {\n+    public static final int C1 = COMP_LEVEL_SIMPLE;\n+    public static final int C2 = COMP_LEVEL_FULL_OPTIMIZATION;\n+\n+    @Override\n+    public int getNumScenarios() {\n+        return 5;\n+    }\n+\n+    @Override\n+    public String[] getVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 0: return new String[] {\n+                \/\/ Default: both C1 and C2 are enabled, tiered compilation enabled\n+                \"-XX:CICompilerCount=2\",\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:+TieredCompilation\",\n+            };\n+        case 1: return new String[] {\n+                \/\/ Default: both C1 and C2 are enabled, tiered compilation enabled\n+                \"-XX:CICompilerCount=2\",\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:+TieredCompilation\",\n+                \"-XX:+StressInlineTypeReturnedAsFields\"\n+            };\n+        case 2: return new String[] {\n+                \/\/ Same as above, but flip all the compLevel=C1 and compLevel=C2, so we test\n+                \/\/ the compliment of the above scenario.\n+                \"-XX:CICompilerCount=2\",\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:+TieredCompilation\",\n+                \"-DFlipC1C2=true\"\n+            };\n+        case 3: return new String[] {\n+                \/\/ Only C1. Tiered compilation disabled.\n+                \"-XX:TieredStopAtLevel=1\",\n+                \"-XX:+TieredCompilation\",\n+            };\n+        case 4: return new String[] {\n+                \/\/ Only C2.\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:-TieredCompilation\",\n+            };\n+        }\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        System.gc(); \/\/ Resolve this call, to avoid C1 code patching in the test cases.\n+        TestCallingConventionC1 test = new TestCallingConventionC1();\n+        test.run(args,\n+                 Point.class,\n+                 Functor.class,\n+                 Functor1.class,\n+                 Functor2.class,\n+                 Functor3.class,\n+                 Functor4.class,\n+                 MyImplPojo0.class,\n+                 MyImplPojo1.class,\n+                 MyImplPojo2.class,\n+                 MyImplPojo3.class,\n+                 MyImplVal1.class,\n+                 MyImplVal2.class,\n+                 MyImplVal1X.class,\n+                 MyImplVal2X.class,\n+                 FixedPoints.class,\n+                 FloatPoint.class,\n+                 RefPoint.class,\n+                 RefPoint_Access_Impl1.class,\n+                 RefPoint_Access_Impl2.class);\n+    }\n+\n+    static primitive class Point {\n+        final int x;\n+        final int y;\n+        public Point(int x, int y) {\n+            this.x = x;\n+            this.y = y;\n+        }\n+\n+        @DontCompile\n+        @DontInline\n+        public int func() {\n+            return x + y;\n+        }\n+\n+        @ForceCompile(compLevel = C1)\n+        @DontInline\n+        public int func_c1(Point p) {\n+            return x + y + p.x + p.y;\n+        }\n+    }\n+\n+    static interface FunctorInterface {\n+        public int apply_interp(Point p);\n+    }\n+\n+    static class Functor implements FunctorInterface {\n+        @DontCompile\n+        @DontInline\n+        public int apply_interp(Point p) {\n+            return p.func() + 0;\n+        }\n+    }\n+    static class Functor1 extends Functor {\n+        @DontCompile\n+        @DontInline\n+        public int apply_interp(Point p) {\n+            return p.func() + 10000;\n+        }\n+    }\n+    static class Functor2 extends Functor {\n+        @DontCompile\n+        @DontInline\n+        public int apply_interp(Point p) {\n+            return p.func() + 20000;\n+        }\n+    }\n+    static class Functor3 extends Functor {\n+        @DontCompile\n+        @DontInline\n+        public int apply_interp(Point p) {\n+            return p.func() + 30000;\n+        }\n+    }\n+    static class Functor4 extends Functor {\n+        @DontCompile\n+        @DontInline\n+        public int apply_interp(Point p) {\n+            return p.func() + 40000;\n+        }\n+    }\n+\n+    static Functor functors[] = {\n+        new Functor(),\n+        new Functor1(),\n+        new Functor2(),\n+        new Functor3(),\n+        new Functor4()\n+    };\n+    static int functorCounter = 0;\n+    static Functor getFunctor() {\n+        int n = (++ functorCounter) % functors.length;\n+        return functors[n];\n+    }\n+\n+    static Point pointField  = new Point(123, 456);\n+    static Point pointField1 = new Point(1123, 1456);\n+    static Point pointField2 = new Point(2123, 2456);\n+\n+    static interface Intf {\n+        public int func1(int a, int b);\n+        public int func2(int a, int b, Point p);\n+    }\n+\n+    static class MyImplPojo0 implements Intf {\n+        int field = 0;\n+        @DontInline @DontCompile\n+        public int func1(int a, int b)             { return field + a + b + 1; }\n+        @DontInline @DontCompile\n+        public int func2(int a, int b, Point p)     { return field + a + b + p.x + p.y + 1; }\n+    }\n+\n+    static class MyImplPojo1 implements Intf {\n+        int field = 1000;\n+\n+        @DontInline @ForceCompile(compLevel = C1)\n+        public int func1(int a, int b)             { return field + a + b + 20; }\n+        @DontInline @ForceCompile(compLevel = C1)\n+        public int func2(int a, int b, Point p)    { return field + a + b + p.x + p.y + 20; }\n+    }\n+\n+    static class MyImplPojo2 implements Intf {\n+        int field = 2000;\n+\n+        @DontInline @ForceCompile(compLevel = C2)\n+        public int func1(int a, int b)             { return field + a + b + 20; }\n+        @DontInline @ForceCompile(compLevel = C2)\n+        public int func2(int a, int b, Point p)    { return field + a + b + p.x + p.y + 20; }\n+    }\n+\n+    static class MyImplPojo3 implements Intf {\n+        int field = 0;\n+        @DontInline \/\/ will be compiled with counters\n+        public int func1(int a, int b)             { return field + a + b + 1; }\n+        @DontInline \/\/ will be compiled with counters\n+        public int func2(int a, int b, Point p)     { return field + a + b + p.x + p.y + 1; }\n+    }\n+\n+    static primitive class MyImplVal1 implements Intf {\n+        final int field;\n+        MyImplVal1() {\n+            field = 11000;\n+        }\n+\n+        @DontInline @ForceCompile(compLevel = C1)\n+        public int func1(int a, int b)             { return field + a + b + 300; }\n+\n+        @DontInline @ForceCompile(compLevel = C1)\n+        public int func2(int a, int b, Point p)    { return field + a + b + p.x + p.y + 300; }\n+    }\n+\n+    static primitive class MyImplVal2 implements Intf {\n+        final int field;\n+        MyImplVal2() {\n+            field = 12000;\n+        }\n+\n+        @DontInline @ForceCompile(compLevel = C2)\n+        public int func1(int a, int b)             { return field + a + b + 300; }\n+\n+        @DontInline @ForceCompile(compLevel = C2)\n+        public int func2(int a, int b, Point p)    { return field + a + b + p.x + p.y + 300; }\n+    }\n+\n+    static primitive class MyImplVal1X implements Intf {\n+        final int field;\n+        MyImplVal1X() {\n+            field = 11000;\n+        }\n+\n+        @DontInline @DontCompile\n+        public int func1(int a, int b)             { return field + a + b + 300; }\n+\n+        @DontInline @DontCompile\n+        public int func2(int a, int b, Point p)    { return field + a + b + p.x + p.y + 300; }\n+    }\n+\n+    static primitive class MyImplVal2X implements Intf {\n+        final int field;\n+        MyImplVal2X() {\n+            field = 12000;\n+        }\n+\n+        @DontInline \/\/ will be compiled with counters\n+        public int func1(int a, int b)             { return field + a + b + 300; }\n+\n+        @DontInline \/\/ will be compiled with counters\n+        public int func2(int a, int b, Point p)    { return field + a + b + p.x + p.y + 300; }\n+    }\n+\n+    static Intf intfs[] = {\n+        new MyImplPojo0(), \/\/ methods not compiled\n+        new MyImplPojo1(), \/\/ methods compiled by C1\n+        new MyImplPojo2(), \/\/ methods compiled by C2\n+        new MyImplVal1(),  \/\/ methods compiled by C1\n+        new MyImplVal2()   \/\/ methods compiled by C2\n+    };\n+    static Intf getIntf(int i) {\n+        int n = i % intfs.length;\n+        return intfs[n];\n+    }\n+\n+    static primitive class FixedPoints {\n+        final boolean Z0 = false;\n+        final boolean Z1 = true;\n+        final byte    B  = (byte)2;\n+        final char    C  = (char)34;\n+        final short   S  = (short)456;\n+        final int     I  = 5678;\n+        final long    J  = 0x1234567800abcdefL;\n+    }\n+    static FixedPoints fixedPointsField = new FixedPoints();\n+\n+    static primitive class FloatPoint {\n+        final float x;\n+        final float y;\n+        public FloatPoint(float x, float y) {\n+            this.x = x;\n+            this.y = y;\n+        }\n+    }\n+    static primitive class DoublePoint {\n+        final double x;\n+        final double y;\n+        public DoublePoint(double x, double y) {\n+            this.x = x;\n+            this.y = y;\n+        }\n+    }\n+    static FloatPoint floatPointField = new FloatPoint(123.456f, 789.012f);\n+    static DoublePoint doublePointField = new DoublePoint(123.456, 789.012);\n+\n+    static primitive class EightFloats {\n+        float f1, f2, f3, f4, f5, f6, f7, f8;\n+        public EightFloats() {\n+            f1 = 1.1f;\n+            f2 = 2.2f;\n+            f3 = 3.3f;\n+            f4 = 4.4f;\n+            f5 = 5.5f;\n+            f6 = 6.6f;\n+            f7 = 7.7f;\n+            f8 = 8.8f;\n+        }\n+    }\n+    static EightFloats eightFloatsField = new EightFloats();\n+\n+    static class Number {\n+        int n;\n+        Number(int v) {\n+            n = v;\n+        }\n+        void set(int v) {\n+            n = v;\n+        }\n+    }\n+\n+    static interface RefPoint_Access {\n+        public int func1(RefPoint rp2);\n+        public int func2(RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2);\n+    }\n+\n+    static primitive class RefPoint implements RefPoint_Access {\n+        final Number x;\n+        final Number y;\n+        public RefPoint(int x, int y) {\n+            this.x = new Number(x);\n+            this.y = new Number(y);\n+        }\n+        public RefPoint(Number x, Number y) {\n+            this.x = x;\n+            this.y = y;\n+        }\n+\n+        @DontInline\n+        @ForceCompile(compLevel = C1)\n+        public final int final_func(RefPoint rp2) { \/\/ opt_virtual_call\n+            return this.x.n + this.y.n + rp2.x.n + rp2.y.n;\n+        }\n+\n+        @DontInline\n+        @ForceCompile(compLevel = C1)\n+        public int func1(RefPoint rp2) {\n+            return this.x.n + this.y.n + rp2.x.n + rp2.y.n;\n+        }\n+\n+        @DontInline\n+        @ForceCompile(compLevel = C1)\n+        public int func2(RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2) {\n+            return x.n + y.n +\n+                   rp1.x.n + rp1.y.n +\n+                   rp2.x.n + rp2.y.n +\n+                   n1.n +\n+                   rp3.x.n + rp3.y.n +\n+                   rp4.x.n + rp4.y.n +\n+                   n2.n;\n+        }\n+    }\n+\n+    static class RefPoint_Access_Impl1 implements RefPoint_Access {\n+        @DontInline @DontCompile\n+        public int func1(RefPoint rp2) {\n+            return rp2.x.n + rp2.y.n + 1111111;\n+        }\n+        @DontInline\n+        @ForceCompile(compLevel = C1)\n+        public int func2(RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2) {\n+            return 111111 +\n+                   rp1.x.n + rp1.y.n +\n+                   rp2.x.n + rp2.y.n +\n+                   n1.n +\n+                   rp3.x.n + rp3.y.n +\n+                   rp4.x.n + rp4.y.n +\n+                   n2.n;\n+        }\n+    }\n+    static class RefPoint_Access_Impl2 implements RefPoint_Access {\n+        @DontInline @DontCompile\n+        public int func1(RefPoint rp2) {\n+            return rp2.x.n + rp2.y.n + 2222222;\n+        }\n+        @DontInline\n+        @ForceCompile(compLevel = C1)\n+        public int func2(RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2) {\n+            return 222222 +\n+                   rp1.x.n + rp1.y.n +\n+                   rp2.x.n + rp2.y.n +\n+                   n1.n +\n+                   rp3.x.n + rp3.y.n +\n+                   rp4.x.n + rp4.y.n +\n+                   n2.n;\n+        }\n+    }\n+\n+    static RefPoint_Access refPoint_Access_impls[] = {\n+        new RefPoint_Access_Impl1(),\n+        new RefPoint_Access_Impl2(),\n+        new RefPoint(0x12345, 0x6789a)\n+    };\n+\n+    static int next_RefPoint_Access = 0;\n+    static RefPoint_Access get_RefPoint_Access() {\n+        int i = next_RefPoint_Access ++;\n+        return refPoint_Access_impls[i % refPoint_Access_impls.length];\n+    }\n+\n+    static RefPoint refPointField1 = new RefPoint(12, 34);\n+    static RefPoint refPointField2 = new RefPoint(56789, 0x12345678);\n+\n+    \/\/ This inline class has too many fields to fit in registers on x64 for\n+    \/\/ InlineTypeReturnedAsFields.\n+    static primitive class TooBigToReturnAsFields {\n+        int a0 = 0;\n+        int a1 = 1;\n+        int a2 = 2;\n+        int a3 = 3;\n+        int a4 = 4;\n+        int a5 = 5;\n+        int a6 = 6;\n+        int a7 = 7;\n+        int a8 = 8;\n+        int a9 = 9;\n+    }\n+\n+    static TooBigToReturnAsFields tooBig = new TooBigToReturnAsFields();\n+\n+    \/\/**********************************************************************\n+    \/\/ PART 1 - C1 calls interpreted code\n+    \/\/**********************************************************************\n+\n+\n+    \/\/** C1 passes inline type to interpreter (static)\n+    @Test(compLevel = C1)\n+    public int test1() {\n+        return test1_helper(pointField);\n+    }\n+\n+    @DontInline\n+    @DontCompile\n+    private static int test1_helper(Point p) {\n+        return p.func();\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 10;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test1() + i;\n+            Asserts.assertEQ(result, pointField.func() + i);\n+        }\n+    }\n+\n+\n+    \/\/** C1 passes inline type to interpreter (monomorphic)\n+    @Test(compLevel = C1)\n+    public int test2() {\n+        return test2_helper(pointField);\n+    }\n+\n+    @DontInline\n+    @DontCompile\n+    private int test2_helper(Point p) {\n+        return p.func();\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 10;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test2() + i;\n+            Asserts.assertEQ(result, pointField.func() + i);\n+        }\n+    }\n+\n+    \/\/ C1 passes inline type to interpreter (megamorphic: vtable)\n+    @Test(compLevel = C1)\n+    public int test3(Functor functor) {\n+        return functor.apply_interp(pointField);\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 100;\n+        for (int i=0; i<count; i++) {  \/\/ need a loop to test inline cache and vtable indexing\n+            Functor functor = warmup ? functors[0] : getFunctor();\n+            int result = test3(functor) + i;\n+            Asserts.assertEQ(result, functor.apply_interp(pointField) + i);\n+        }\n+    }\n+\n+    \/\/ Same as test3, but compiled with C2. Test the hastable of VtableStubs\n+    @Test(compLevel = C2)\n+    public int test3b(Functor functor) {\n+        return functor.apply_interp(pointField);\n+    }\n+\n+    @DontCompile\n+    public void test3b_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 100;\n+        for (int i=0; i<count; i++) {  \/\/ need a loop to test inline cache and vtable indexing\n+            Functor functor = warmup ? functors[0] : getFunctor();\n+            int result = test3b(functor) + i;\n+            Asserts.assertEQ(result, functor.apply_interp(pointField) + i);\n+        }\n+    }\n+\n+    \/\/ C1 passes inline type to interpreter (megamorphic: itable)\n+    @Test(compLevel = C1)\n+    public int test4(FunctorInterface fi) {\n+        return fi.apply_interp(pointField);\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 100;\n+        for (int i=0; i<count; i++) {  \/\/ need a loop to test inline cache and itable indexing\n+            Functor functor = warmup ? functors[0] : getFunctor();\n+            int result = test4(functor) + i;\n+            Asserts.assertEQ(result, functor.apply_interp(pointField) + i);\n+        }\n+    }\n+\n+    \/\/**********************************************************************\n+    \/\/ PART 2 - interpreter calls C1\n+    \/\/**********************************************************************\n+\n+    \/\/ Interpreter passes inline type to C1 (static)\n+    @Test(compLevel = C1)\n+    static public int test20(Point p1, long l, Point p2) {\n+        return p1.x + p2.y;\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        int result = test20(pointField1, 0, pointField2);\n+        int n = pointField1.x + pointField2.y;\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+    \/\/ Interpreter passes inline type to C1 (instance method in inline class)\n+    @Test\n+    public int test21(Point p) {\n+        return test21_helper(p);\n+    }\n+\n+    @DontCompile\n+    @DontInline\n+    int test21_helper(Point p) {\n+        return p.func_c1(p);\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        int result = test21(pointField);\n+        int n = 2 * (pointField.x + pointField.y);\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+\n+    \/\/**********************************************************************\n+    \/\/ PART 3 - C2 calls C1\n+    \/\/**********************************************************************\n+\n+    \/\/ C2->C1 invokestatic, single inline arg\n+    @Test(compLevel = C2)\n+    public int test30() {\n+        return test30_helper(pointField);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test30_helper(Point p) {\n+        return p.x + p.y;\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test30();\n+            int n = pointField.x + pointField.y;\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, two single inline args\n+    @Test(compLevel = C2)\n+    public int test31() {\n+      return test31_helper(pointField1, pointField2);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test31_helper(Point p1, Point p2) {\n+        return p1.x + p2.y;\n+    }\n+\n+    @DontCompile\n+    public void test31_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test31();\n+            int n = pointField1.x + pointField2.y;\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, two single inline args and interleaving ints (all passed in registers on x64)\n+    @Test(compLevel = C2)\n+    public int test32() {\n+      return test32_helper(0, pointField1, 1, pointField2);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test32_helper(int x, Point p1, int y, Point p2) {\n+        return p1.x + p2.y + x + y;\n+    }\n+\n+    @DontCompile\n+    public void test32_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test32();\n+            int n = pointField1.x + pointField2.y + 0 + 1;\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokeinterface -- no verified_ro_entry (no inline args except for receiver)\n+    @Test(compLevel = C2)\n+    public int test33(Intf intf, int a, int b) {\n+        return intf.func1(a, b);\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = warmup ? intfs[0] : getIntf(i+1);\n+            int result = test33(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func1(123, 456) + i);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokeinterface -- use verified_ro_entry (has inline args other than receiver)\n+    @Test(compLevel = C2)\n+    public int test34(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = warmup ? intfs[0] : getIntf(i+1);\n+            int result = test34(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func2(123, 456, pointField) + i);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, Point.y is on stack (x64)\n+    @Test(compLevel = C2)\n+    public int test35() {\n+        return test35_helper(1, 2, 3, 4, 5, pointField);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test35_helper(int a1, int a2, int a3, int a4, int a5, Point p) {\n+        return a1 + a2 + a3 + a4 + a5 + p.x + p.y;\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test35();\n+            int n = 1 + 2 + 3  + 4 + 5 + pointField.x + pointField.y;\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, shuffling arguments that are passed on stack\n+    @Test(compLevel = C2)\n+    public int test36() {\n+        return test36_helper(pointField, 1, 2, 3, 4, 5, 6, 7, 8);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test36_helper(Point p, int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8) {\n+        return a6 + a8;\n+    }\n+\n+    @DontCompile\n+    public void test36_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test36();\n+            int n = 6 + 8;\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, shuffling long arguments\n+    @Test(compLevel = C2)\n+    public int test37() {\n+        return test37_helper(pointField, 1, 2, 3, 4, 5, 6, 7, 8);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test37_helper(Point p, long a1, long a2, long a3, long a4, long a5, long a6, long a7, long a8) {\n+        return (int)(a6 + a8);\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test37();\n+            int n = 6 + 8;\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, shuffling boolean, byte, char, short, int, long arguments\n+    @Test(compLevel = C2)\n+    public int test38() {\n+        return test38_helper(pointField, true, (byte)1, (char)2, (short)3, 4, 5, (byte)6, (short)7, 8);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test38_helper(Point p, boolean a0, byte a1, char a2, short a3, int a4, long a5, byte a6, short a7, int a8) {\n+        if (a0) {\n+            return (int)(a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8);\n+        } else {\n+            return -1;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test38();\n+            int n = 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8;\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, packing an inline type with all types of fixed point primitive fields.\n+    @Test(compLevel = C2)\n+    public long test39() {\n+        return test39_helper(1, fixedPointsField, 2, fixedPointsField);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static long test39_helper(int a1, FixedPoints f1, int a2, FixedPoints f2) {\n+        if (f1.Z0 == false && f1.Z1 == true && f2.Z0 == false && f2.Z1 == true) {\n+            return f1.B + f2.C + f1.S + f2.I + f1.J;\n+        } else {\n+            return -1;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            long result = test39();\n+            long n = test39_helper(1, fixedPointsField, 2, fixedPointsField);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, shuffling floating point args\n+    @Test(compLevel = C2)\n+    public double test40() {\n+        return test40_helper(1.1f, 1.2, floatPointField, doublePointField, 1.3f, 1.4, 1.5f, 1.7, 1.7, 1.8, 1.9, 1.10, 1.11, 1.12);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static double test40_helper(float a1, double a2, FloatPoint fp, DoublePoint dp, float a3, double a4, float a5, double a6, double a7, double a8, double a9, double a10, double a11, double a12) {\n+        return a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8 + a9 + a10 + a11 + a12 + fp.x + fp.y - dp.x - dp.y;\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            double result = test40();\n+            double n = test40_helper(1.1f, 1.2, floatPointField, doublePointField, 1.3f, 1.4, 1.5f, 1.7, 1.7, 1.8, 1.9, 1.10, 1.11, 1.12);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, mixing floats and ints\n+    @Test(compLevel = C2)\n+    public double test41() {\n+        return test41_helper(1, 1.2, pointField, floatPointField, doublePointField, 1.3f, 4, 1.5f, 1.7, 1.7, 1.8, 9, 1.10, 1.11, 1.12);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static double test41_helper(int a1, double a2, Point p, FloatPoint fp, DoublePoint dp, float a3, int a4, float a5, double a6, double a7, double a8, long a9, double a10, double a11, double a12) {\n+      return a1 + a2  + fp.x + fp.y - dp.x - dp.y + a3 + a4 + a5 + a6 + a7 + a8 + a9 + a10 + a11 + a12;\n+    }\n+\n+    @DontCompile\n+    public void test41_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            double result = test41();\n+            double n = test41_helper(1, 1.2, pointField, floatPointField, doublePointField, 1.3f, 4, 1.5f, 1.7, 1.7, 1.8, 9, 1.10, 1.11, 1.12);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, circular dependency (between rdi and first stack slot on x64)\n+    @Test(compLevel = C2)\n+    public float test42() {\n+        return test42_helper(eightFloatsField, pointField, 3, 4, 5, floatPointField, 7);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test42_helper(EightFloats ep1, \/\/ (xmm0 ... xmm7) -> rsi\n+                                       Point p2,        \/\/ (rsi, rdx) -> rdx\n+                                       int i3,          \/\/ rcx -> rcx\n+                                       int i4,          \/\/ r8 -> r8\n+                                       int i5,          \/\/ r9 -> r9\n+                                       FloatPoint fp6,  \/\/ (stk[0], stk[1]) -> rdi   ** circ depend\n+                                       int i7)          \/\/ rdi -> stk[0]             ** circ depend\n+    {\n+        return ep1.f1 + ep1.f2 + ep1.f3 + ep1.f4 + ep1.f5 + ep1.f6 + ep1.f7 + ep1.f8 +\n+            p2.x + p2.y + i3 + i4 + i5 + fp6.x + fp6.y + i7;\n+    }\n+\n+    @DontCompile\n+    public void test42_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            float result = test42();\n+            float n = test42_helper(eightFloatsField, pointField, 3, 4, 5, floatPointField, 7);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, packing causes stack growth (1 extra stack word)\n+    @Test(compLevel = C2)\n+    public float test43() {\n+        return test43_helper(floatPointField, 1, 2, 3, 4, 5, 6);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test43_helper(FloatPoint fp, int a1, int a2, int a3, int a4, int a5, int a6) {\n+        \/\/ On x64:\n+        \/\/    Scalarized entry -- all parameters are passed in registers\n+        \/\/    Non-scalarized entry -- a6 is passed on stack[0]\n+        return fp.x + fp.y + a1 + a2 + a3 + a4 + a5 + a6;\n+    }\n+\n+    @DontCompile\n+    public void test43_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            float result = test43();\n+            float n = test43_helper(floatPointField, 1, 2, 3, 4, 5, 6);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, packing causes stack growth (2 extra stack words)\n+    @Test(compLevel = C2)\n+    public float test44() {\n+      return test44_helper(floatPointField, floatPointField, 1, 2, 3, 4, 5, 6);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test44_helper(FloatPoint fp1, FloatPoint fp2, int a1, int a2, int a3, int a4, int a5, int a6) {\n+        \/\/ On x64:\n+        \/\/    Scalarized entry -- all parameters are passed in registers\n+        \/\/    Non-scalarized entry -- a5 is passed on stack[0]\n+        \/\/    Non-scalarized entry -- a6 is passed on stack[1]\n+        return fp1.x + fp1.y +\n+               fp2.x + fp2.y +\n+               a1 + a2 + a3 + a4 + a5 + a6;\n+    }\n+\n+    @DontCompile\n+    public void test44_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            float result = test44();\n+            float n = test44_helper(floatPointField, floatPointField, 1, 2, 3, 4, 5, 6);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, packing causes stack growth (5 extra stack words)\n+    @Test(compLevel = C2)\n+    public float test45() {\n+      return test45_helper(floatPointField, floatPointField, floatPointField, floatPointField, floatPointField, 1, 2, 3, 4, 5, 6, 7);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test45_helper(FloatPoint fp1, FloatPoint fp2, FloatPoint fp3, FloatPoint fp4, FloatPoint fp5, int a1, int a2, int a3, int a4, int a5, int a6, int a7) {\n+        return fp1.x + fp1.y +\n+               fp2.x + fp2.y +\n+               fp3.x + fp3.y +\n+               fp4.x + fp4.y +\n+               fp5.x + fp5.y +\n+               a1 + a2 + a3 + a4 + a5 + a6 + a7;\n+    }\n+\n+    @DontCompile\n+    public void test45_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            float result = test45();\n+            float n = test45_helper(floatPointField, floatPointField, floatPointField, floatPointField, floatPointField, 1, 2, 3, 4, 5, 6, 7);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, packing causes stack growth (1 extra stack word -- mixing Point and FloatPoint)\n+    @Test(compLevel = C2)\n+    public float test46() {\n+      return test46_helper(floatPointField, floatPointField, pointField, floatPointField, floatPointField, pointField, floatPointField, 1, 2, 3, 4, 5, 6, 7);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test46_helper(FloatPoint fp1, FloatPoint fp2, Point p1, FloatPoint fp3, FloatPoint fp4, Point p2, FloatPoint fp5, int a1, int a2, int a3, int a4, int a5, int a6, int a7) {\n+        return p1.x + p1.y +\n+               p2.x + p2.y +\n+               fp1.x + fp1.y +\n+               fp2.x + fp2.y +\n+               fp3.x + fp3.y +\n+               fp4.x + fp4.y +\n+               fp5.x + fp5.y +\n+               a1 + a2 + a3 + a4 + a5 + a6 + a7;\n+    }\n+\n+    @DontCompile\n+    public void test46_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 2;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            float result = test46();\n+            float n = test46_helper(floatPointField, floatPointField, pointField, floatPointField, floatPointField, pointField, floatPointField, 1, 2, 3, 4, 5, 6, 7);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    static class MyRuntimeException extends RuntimeException {\n+        MyRuntimeException(String s) {\n+            super(s);\n+        }\n+    }\n+\n+    static void checkStackTrace(Throwable t, String... methodNames) {\n+        StackTraceElement[] trace = t.getStackTrace();\n+        for (int i=0; i<methodNames.length; i++) {\n+            if (!methodNames[i].equals(trace[i].getMethodName())) {\n+                String error = \"Unexpected stack trace: level \" + i + \" should be \" + methodNames[i];\n+                System.out.println(error);\n+                t.printStackTrace(System.out);\n+                throw new RuntimeException(error, t);\n+            }\n+        }\n+    }\n+    \/\/*\n+\n+    \/\/ C2->C1 invokestatic, make sure stack walking works (with static variable)\n+    @Test(compLevel = C2)\n+    public void test47(int n) {\n+        try {\n+            test47_helper(floatPointField, 1, 2, 3, 4, 5);\n+            test47_value = 666;\n+        } catch (MyRuntimeException e) {\n+            \/\/ expected;\n+        }\n+        test47_value = n;\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test47_helper(FloatPoint fp, int a1, int a2, int a3, int a4, int a5) {\n+        test47_thrower();\n+        return 0.0f;\n+    }\n+\n+    @DontInline @DontCompile\n+    private static void test47_thrower() {\n+        MyRuntimeException e = new MyRuntimeException(\"This exception should have been caught!\");\n+        checkStackTrace(e, \"test47_thrower\", \"test47_helper\", \"test47\", \"test47_verifier\");\n+        throw e;\n+    }\n+\n+    static int test47_value = 999;\n+\n+    @DontCompile\n+    public void test47_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            test47_value = 777 + i;\n+            test47(i);\n+            Asserts.assertEQ(test47_value, i);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, make sure stack walking works (with returned inline type)\n+    @Test(compLevel = C2)\n+    public int test48(int n) {\n+        try {\n+            test48_helper(floatPointField, 1, 2, 3, 4, 5);\n+            return 666;\n+        } catch (MyRuntimeException e) {\n+            \/\/ expected;\n+        }\n+        return n;\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test48_helper(FloatPoint fp, int a1, int a2, int a3, int a4, int a5) {\n+        test48_thrower();\n+        return 0.0f;\n+    }\n+\n+    @DontInline @DontCompile\n+    private static void test48_thrower() {\n+        MyRuntimeException e = new MyRuntimeException(\"This exception should have been caught!\");\n+        checkStackTrace(e, \"test48_thrower\", \"test48_helper\", \"test48\", \"test48_verifier\");\n+        throw e;\n+    }\n+\n+    @DontCompile\n+    public void test48_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int n = test48(i);\n+            Asserts.assertEQ(n, i);\n+        }\n+    }\n+\n+    \/\/ C2->interpreter invokestatic, make sure stack walking works (same as test 48, but with stack extension\/repair)\n+    \/\/ (this is the baseline for test50 --\n+    \/\/ the only difference is: test49_helper is interpreted but test50_helper is compiled by C1).\n+    @Test(compLevel = C2)\n+    public int test49(int n) {\n+        try {\n+            test49_helper(floatPointField, 1, 2, 3, 4, 5, 6);\n+            return 666;\n+        } catch (MyRuntimeException e) {\n+            \/\/ expected;\n+        }\n+        return n;\n+    }\n+\n+    @DontInline @DontCompile\n+    private static float test49_helper(FloatPoint fp, int a1, int a2, int a3, int a4, int a5, int a6) {\n+        test49_thrower();\n+        return 0.0f;\n+    }\n+\n+    @DontInline @DontCompile\n+    private static void test49_thrower() {\n+        MyRuntimeException e = new MyRuntimeException(\"This exception should have been caught!\");\n+        checkStackTrace(e, \"test49_thrower\", \"test49_helper\", \"test49\", \"test49_verifier\");\n+        throw e;\n+    }\n+\n+    @DontCompile\n+    public void test49_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int n = test49(i);\n+            Asserts.assertEQ(n, i);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, make sure stack walking works (same as test 48, but with stack extension\/repair)\n+    @Test(compLevel = C2)\n+    public int test50(int n) {\n+        try {\n+            test50_helper(floatPointField, 1, 2, 3, 4, 5, 6);\n+            return 666;\n+        } catch (MyRuntimeException e) {\n+            \/\/ expected;\n+        }\n+        return n;\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test50_helper(FloatPoint fp, int a1, int a2, int a3, int a4, int a5, int a6) {\n+        test50_thrower();\n+        return 0.0f;\n+    }\n+\n+    @DontInline @DontCompile\n+    private static void test50_thrower() {\n+        MyRuntimeException e = new MyRuntimeException(\"This exception should have been caught!\");\n+        checkStackTrace(e, \"test50_thrower\", \"test50_helper\", \"test50\", \"test50_verifier\");\n+        throw e;\n+    }\n+\n+    @DontCompile\n+    public void test50_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int n = test50(i);\n+            Asserts.assertEQ(n, i);\n+        }\n+    }\n+\n+\n+    \/\/ C2->C1 invokestatic, inline class with ref fields (RefPoint)\n+    @Test(compLevel = C2)\n+    public int test51() {\n+        return test51_helper(refPointField1);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test51_helper(RefPoint rp1) {\n+        return rp1.x.n + rp1.y.n;\n+    }\n+\n+    @DontCompile\n+    public void test51_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test51();\n+            int n = test51_helper(refPointField1);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, inline class with ref fields (Point, RefPoint)\n+    @Test(compLevel = C2)\n+    public int test52() {\n+        return test52_helper(pointField, refPointField1);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test52_helper(Point p1, RefPoint rp1) {\n+        return p1.x + p1.y + rp1.x.n + rp1.y.n;\n+    }\n+\n+    @DontCompile\n+    public void test52_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test52();\n+            int n = test52_helper(pointField, refPointField1);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, inline class with ref fields (RefPoint, RefPoint, RefPoint, RefPoint)\n+    @Test(compLevel = C2)\n+    public int test53() {\n+        return test53_helper(refPointField1, refPointField2, refPointField1, refPointField2);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test53_helper(RefPoint rp1, RefPoint rp2, RefPoint rp3, RefPoint rp4) {\n+        return rp1.x.n + rp1.y.n +\n+               rp2.x.n + rp2.y.n +\n+               rp3.x.n + rp3.y.n +\n+               rp4.x.n + rp4.y.n;\n+    }\n+\n+    @DontCompile\n+    public void test53_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test53();\n+            int n = test53_helper(refPointField1, refPointField2, refPointField1, refPointField2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, inline class with ref fields (RefPoint, RefPoint, float, int, RefPoint, RefPoint)\n+    @Test(compLevel = C2)\n+    public int test54() {\n+        return test54_helper(refPointField1, refPointField2, 1.0f, 2, refPointField1, refPointField2);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test54_helper(RefPoint rp1, RefPoint rp2, float f, int i, RefPoint rp3, RefPoint rp4) {\n+        return rp1.x.n + rp1.y.n +\n+               rp2.x.n + rp2.y.n +\n+               (int)(f) + i +\n+               rp3.x.n + rp3.y.n +\n+               rp4.x.n + rp4.y.n;\n+    }\n+\n+    @DontCompile\n+    public void test54_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            int result = test54();\n+            int n = test54_helper(refPointField1, refPointField2, 1.0f, 2, refPointField1, refPointField2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    static final WhiteBox WHITE_BOX = WhiteBox.getWhiteBox();\n+    static final String ScavengeALot = \"ScavengeALot\";\n+\n+\n+    \/**\n+     * Each allocation with a \"try\" block like this will cause a GC\n+     *\n+     *       try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+     *           result = test55(p1);\n+     *       }\n+     *\/\n+    static class ForceGCMarker implements java.io.Closeable {\n+        static final WhiteBox WHITE_BOX = WhiteBox.getWhiteBox();\n+\n+        ForceGCMarker() {\n+            WHITE_BOX.setBooleanVMFlag(ScavengeALot, true);\n+        }\n+        public void close() {\n+            WHITE_BOX.setBooleanVMFlag(ScavengeALot, false);\n+        }\n+\n+        static ForceGCMarker mark(boolean warmup) {\n+            return warmup ? null : new ForceGCMarker();\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, force GC for every allocation when entering a C1 VEP (Point)\n+    @Test(compLevel = C2)\n+    public int test55(Point p1) {\n+        return test55_helper(p1);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test55_helper(Point p1) {\n+        return p1.x + p1.y;\n+    }\n+\n+    @DontCompile\n+    public void test55_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            Point p1 = new Point(1, 2);\n+            int result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test55(p1);\n+            }\n+            int n = test55_helper(p1);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, force GC for every allocation when entering a C1 VEP (RefPoint)\n+    @Test(compLevel = C2)\n+    public int test56(RefPoint rp1) {\n+        return test56_helper(rp1);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test56_helper(RefPoint rp1) {\n+        return rp1.x.n + rp1.y.n;\n+    }\n+\n+    @DontCompile\n+    public void test56_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint rp1 = new RefPoint(1, 2);\n+            int result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test56(rp1);\n+            }\n+            int n = test56_helper(rp1);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->Interpreter (same as test56, but test c2i entry instead of C1)\n+    @Test(compLevel = C2)\n+    public int test57(RefPoint rp1) {\n+        return test57_helper(rp1);\n+    }\n+\n+    @DontInline @DontCompile\n+    private static int test57_helper(RefPoint rp1) {\n+        return rp1.x.n + rp1.y.n;\n+    }\n+\n+    @DontCompile\n+    public void test57_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint rp1 = new RefPoint(1, 2);\n+            int result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test57(rp1);\n+            }\n+            int n = test57_helper(rp1);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, force GC for every allocation when entering a C1 VEP (a bunch of RefPoints and Numbers);\n+    @Test(compLevel = C2)\n+    public int test58(RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2) {\n+        return test58_helper(rp1, rp2, n1, rp3, rp4, n2);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test58_helper(RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2) {\n+        return rp1.x.n + rp1.y.n +\n+               rp2.x.n + rp2.y.n +\n+               n1.n +\n+               rp3.x.n + rp3.y.n +\n+               rp4.x.n + rp4.y.n +\n+               n2.n;\n+    }\n+\n+    @DontCompile\n+    public void test58_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint rp1 = new RefPoint(1, 2);\n+            RefPoint rp2 = refPointField1;\n+            RefPoint rp3 = new RefPoint(222, 777);\n+            RefPoint rp4 = refPointField2;\n+            Number n1 = new Number(5878);\n+            Number n2 = new Number(1234);\n+            int result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test58(rp1, rp2, n1, rp3, rp4, n2);\n+            }\n+            int n = test58_helper(rp1, rp2, n1, rp3, rp4, n2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, GC inside main body of C1-compiled method (caller's args should not be GC'ed).\n+    @Test(compLevel = C2)\n+    public int test59(RefPoint rp1, boolean doGC) {\n+      return test59_helper(rp1, 11, 222, 3333, 4444, doGC);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test59_helper(RefPoint rp1, int a1, int a2, int a3, int a4, boolean doGC) {\n+        if (doGC) {\n+            System.gc();\n+        }\n+        return rp1.x.n + rp1.y.n + a1 + a2 + a3 + a4;\n+    }\n+\n+    @DontCompile\n+    public void test59_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        boolean doGC = !warmup;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint rp1 = new RefPoint(1, 2);\n+            int result = test59(rp1, doGC);\n+            int n = test59_helper(rp1, 11, 222, 3333, 4444, doGC);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic, GC inside main body of C1-compiled method (caller's args should not be GC'ed).\n+    \/\/ same as test59, but the incoming (scalarized) oops are passed in both registers and stack.\n+    @Test(compLevel = C2)\n+    public int test60(RefPoint rp1, RefPoint rp2, boolean doGC) {\n+        return test60_helper(555, 6666, 77777, rp1, rp2, 11, 222, 3333, 4444, doGC);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static int test60_helper(int x0, int x1, int x2, RefPoint rp1, RefPoint rp2,int a1, int a2, int a3, int a4, boolean doGC) {\n+        \/\/ On x64, C2 passes:   reg0=x1, reg1=x1, reg2=x2, reg3=rp1.x, reg4=rp1.y, reg5=rp2.x stack0=rp2.y ....\n+        \/\/         C1 expects:  reg0=x1, reg1=x1, reg2=x2, reg3=rp1,   reg4=rp2,   reg5=a1    stack0=a2 ...\n+        \/\/ When GC happens, make sure it does not treat reg5 and stack0 as oops!\n+        if (doGC) {\n+            System.gc();\n+        }\n+        return x0 + x1 + x2 + rp1.x.n + rp1.y.n + rp2.x.n + rp2.y.n + a1 + a2 + a3 + a4;\n+    }\n+\n+    @DontCompile\n+    public void test60_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        boolean doGC = !warmup;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint rp1 = new RefPoint(1, 2);\n+            RefPoint rp2 = new RefPoint(33, 44);\n+            int result = test60(rp1, rp2, doGC);\n+            int n = test60_helper(555, 6666, 77777, rp1, rp2, 11, 222, 3333, 4444, doGC);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokeinterface via VVEP(RO)\n+    @Test(compLevel = C2)\n+    public int test61(RefPoint_Access rpa, RefPoint rp2) {\n+        return rpa.func1(rp2);\n+    }\n+\n+    @DontCompile\n+    public void test61_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint_Access rpa = get_RefPoint_Access();\n+            RefPoint rp2 = refPointField2;\n+            int result = test61(rpa, rp2);\n+            int n = rpa.func1(rp2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokeinterface via VVEP(RO) -- force GC for every allocation when entering a C1 VVEP(RO) (RefPoint)\n+    @Test(compLevel = C2)\n+    public int test62(RefPoint_Access rpa, RefPoint rp2) {\n+        return rpa.func1(rp2);\n+    }\n+\n+    @DontCompile\n+    public void test62_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint_Access rpa = get_RefPoint_Access();\n+            RefPoint rp2 = new RefPoint(111, 2222);\n+            int result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test62(rpa, rp2);\n+            }\n+            int n = rpa.func1(rp2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokeinterface via VVEP(RO) -- force GC for every allocation when entering a C1 VVEP(RO) (a bunch of RefPoints and Numbers)\n+    @Test(compLevel = C2)\n+    public int test63(RefPoint_Access rpa, RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2) {\n+        return rpa.func2(rp1, rp2, n1, rp3, rp4, n2);\n+    }\n+\n+    @DontCompile\n+    public void test63_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint_Access rpa = get_RefPoint_Access();\n+            RefPoint rp1 = new RefPoint(1, 2);\n+            RefPoint rp2 = refPointField1;\n+            RefPoint rp3 = new RefPoint(222, 777);\n+            RefPoint rp4 = refPointField2;\n+            Number n1 = new Number(5878);\n+            Number n2 = new Number(1234);\n+            int result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test63(rpa, rp1, rp2, n1, rp3, rp4, n2);\n+            }\n+            int n = rpa.func2(rp1, rp2, n1, rp3, rp4, n2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokestatic (same as test63, but use invokestatic instead)\n+    @Test(compLevel = C2)\n+    public int test64(RefPoint_Access rpa, RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2) {\n+        return test64_helper(rpa, rp1, rp2, n1, rp3, rp4, n2);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    public static int test64_helper(RefPoint_Access rpa, RefPoint rp1, RefPoint rp2, Number n1, RefPoint rp3, RefPoint rp4, Number n2) {\n+        return rp3.y.n;\n+    }\n+\n+    @DontCompile\n+    public void test64_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint_Access rpa = get_RefPoint_Access();\n+            RefPoint rp1 = new RefPoint(1, 2);\n+            RefPoint rp2 = refPointField1;\n+            RefPoint rp3 = new RefPoint(222, 777);\n+            RefPoint rp4 = refPointField2;\n+            Number n1 = new Number(5878);\n+            Number n2 = new Number(1234);\n+            int result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test64(rpa, rp1, rp2, n1, rp3, rp4, n2);\n+            }\n+            int n = test64_helper(rpa, rp1, rp2, n1, rp3, rp4, n2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokevirtual via VVEP(RO) (opt_virtual_call)\n+    @Test(compLevel = C2)\n+    public int test76(RefPoint rp1, RefPoint rp2) {\n+        return rp1.final_func(rp2);\n+    }\n+\n+    @DontCompile\n+    public void test76_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint rp1 = refPointField1;\n+            RefPoint rp2 = refPointField2;\n+            int result = test76(rp1, rp2);\n+            int n = rp1.final_func(rp2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokevirtual, force GC for every allocation when entering a C1 VEP (RefPoint)\n+    \/\/ Same as test56, except we call the VVEP(RO) instead of VEP.\n+    @Test(compLevel = C2)\n+    public int test77(RefPoint rp1, RefPoint rp2) {\n+        return rp1.final_func(rp2);\n+    }\n+\n+    @DontCompile\n+    public void test77_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) { \/\/ need a loop to test inline cache\n+            RefPoint rp1 = new RefPoint(1, 2);\n+            RefPoint rp2 = new RefPoint(22, 33);\n+            int result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test77(rp1, rp2);\n+            }\n+            int n = rp1.final_func(rp2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/-------------------------------------------------------------------------------\n+    \/\/ Tests for how C1 handles InlineTypeReturnedAsFields in both calls and returns\n+    \/\/-------------------------------------------------------------------------------\n+    \/\/ C2->C1 invokestatic with InlineTypeReturnedAsFields (Point)\n+    @Test(compLevel = C2)\n+    public int test78(Point p) {\n+        Point np = test78_helper(p);\n+        return np.x + np.y;\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static Point test78_helper(Point p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test78_verifier(boolean warmup) {\n+        int result = test78(pointField1);\n+        int n = pointField1.x + pointField1.y;\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+    \/\/ C2->C1 invokestatic with InlineTypeReturnedAsFields (RefPoint)\n+    @Test(compLevel = C2)\n+    public int test79(RefPoint p) {\n+        RefPoint np = test79_helper(p);\n+        return np.x.n + np.y.n;\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static RefPoint test79_helper(RefPoint p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test79_verifier(boolean warmup) {\n+        int result = test79(refPointField1);\n+        int n = refPointField1.x.n + refPointField1.y.n;\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+    \/\/ C1->C2 invokestatic with InlineTypeReturnedAsFields (RefPoint)\n+    @Test(compLevel = C1)\n+    public int test80(RefPoint p) {\n+        RefPoint np = test80_helper(p);\n+        return np.x.n + np.y.n;\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C2)\n+    private static RefPoint test80_helper(RefPoint p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test80_verifier(boolean warmup) {\n+        int result = test80(refPointField1);\n+        int n = refPointField1.x.n + refPointField1.y.n;\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+    \/\/ Interpreter->C1 invokestatic with InlineTypeReturnedAsFields (Point)\n+    @Test(compLevel = C1)\n+    public Point test81(Point p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test81_verifier(boolean warmup) {\n+        Point p = test81(pointField1);\n+        Asserts.assertEQ(p.x, pointField1.x);\n+        Asserts.assertEQ(p.y, pointField1.y);\n+        p = test81(pointField2);\n+        Asserts.assertEQ(p.x, pointField2.x);\n+        Asserts.assertEQ(p.y, pointField2.y);\n+    }\n+\n+    \/\/ C1->Interpreter invokestatic with InlineTypeReturnedAsFields (RefPoint)\n+    @Test(compLevel = C1)\n+    public int test82(RefPoint p) {\n+        RefPoint np = test82_helper(p);\n+        return np.x.n + np.y.n;\n+    }\n+\n+    @DontInline @DontCompile\n+    private static RefPoint test82_helper(RefPoint p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test82_verifier(boolean warmup) {\n+        int result = test82(refPointField1);\n+        int n = refPointField1.x.n + refPointField1.y.n;\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+    \/\/-------------------------------------------------------------------------------\n+    \/\/ Tests for InlineTypeReturnedAsFields vs the inline class TooBigToReturnAsFields\n+    \/\/-------------------------------------------------------------------------------\n+\n+    \/\/ C2->C1 invokestatic with InlineTypeReturnedAsFields (TooBigToReturnAsFields)\n+    @Test(compLevel = C2)\n+    public int test83(TooBigToReturnAsFields p) {\n+        TooBigToReturnAsFields np = test83_helper(p);\n+        return p.a0 + p.a5;\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static TooBigToReturnAsFields test83_helper(TooBigToReturnAsFields p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test83_verifier(boolean warmup) {\n+        int result = test83(tooBig);\n+        int n = tooBig.a0 + tooBig.a5;\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+    \/\/ C1->C2 invokestatic with InlineTypeReturnedAsFields (TooBigToReturnAsFields)\n+    @Test(compLevel = C1)\n+    public int test84(TooBigToReturnAsFields p) {\n+        TooBigToReturnAsFields np = test84_helper(p);\n+        return p.a0 + p.a5;\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C2)\n+    private static TooBigToReturnAsFields test84_helper(TooBigToReturnAsFields p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test84_verifier(boolean warmup) {\n+        int result = test84(tooBig);\n+        int n = tooBig.a0 + tooBig.a5;\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+    \/\/ Interpreter->C1 invokestatic with InlineTypeReturnedAsFields (TooBigToReturnAsFields)\n+    @Test(compLevel = C1)\n+    public TooBigToReturnAsFields test85(TooBigToReturnAsFields p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test85_verifier(boolean warmup) {\n+        TooBigToReturnAsFields p = test85(tooBig);\n+        Asserts.assertEQ(p.a0, tooBig.a0);\n+        Asserts.assertEQ(p.a2, tooBig.a2);\n+    }\n+\n+    \/\/ C1->Interpreter invokestatic with InlineTypeReturnedAsFields (TooBigToReturnAsFields)\n+    @Test(compLevel = C1)\n+    public int test86(TooBigToReturnAsFields p) {\n+        TooBigToReturnAsFields np = test86_helper(p);\n+        return p.a0 + p.a5;\n+    }\n+\n+    @DontInline @DontCompile\n+    private static TooBigToReturnAsFields test86_helper(TooBigToReturnAsFields p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test86_verifier(boolean warmup) {\n+        int result = test86(tooBig);\n+        int n = tooBig.a0 + tooBig.a5;\n+        Asserts.assertEQ(result, n);\n+    }\n+\n+    \/\/-------------------------------------------------------------------------------\n+    \/\/ Tests for how C1 handles InlineTypeReturnedAsFields in both calls and returns (RefPoint?)\n+    \/\/-------------------------------------------------------------------------------\n+\n+    \/\/ C2->C1 invokestatic with InlineTypeReturnedAsFields (RefPoint.ref)\n+    @Test(compLevel = C2)\n+    public RefPoint.ref test87(RefPoint.ref p) {\n+        return test87_helper(p);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static RefPoint.ref test87_helper(RefPoint.ref p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test87_verifier(boolean warmup) {\n+        Object result = test87(null);\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    \/\/ C2->C1 invokestatic with InlineTypeReturnedAsFields (RefPoint.ref with constant null)\n+    @Test(compLevel = C2)\n+    public RefPoint.ref test88() {\n+        return test88_helper();\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static RefPoint.ref test88_helper() {\n+        return null;\n+    }\n+\n+    @DontCompile\n+    public void test88_verifier(boolean warmup) {\n+        Object result = test88();\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    \/\/ C1->C2 invokestatic with InlineTypeReturnedAsFields (RefPoint.ref)\n+    @Test(compLevel = C1)\n+    public RefPoint.ref test89(RefPoint.ref p) {\n+        return test89_helper(p);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C2)\n+    private static RefPoint.ref test89_helper(RefPoint.ref p) {\n+        return p;\n+    }\n+\n+    @DontCompile\n+    public void test89_verifier(boolean warmup) {\n+        Object result = test89(null);\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    \/\/----------------------------------------------------------------------------------\n+    \/\/ Tests for unverified entries: there are 6 cases:\n+    \/\/ C1 -> Unverified Value Entry compiled by C1\n+    \/\/ C1 -> Unverified Value Entry compiled by C2\n+    \/\/ C2 -> Unverified Entry compiled by C1 (target is NOT an inline type)\n+    \/\/ C2 -> Unverified Entry compiled by C2 (target is NOT an inline type)\n+    \/\/ C2 -> Unverified Entry compiled by C1 (target IS an inline type, i.e., has VVEP_RO)\n+    \/\/ C2 -> Unverified Entry compiled by C2 (target IS an inline type, i.e., has VVEP_RO)\n+    \/\/----------------------------------------------------------------------------------\n+\n+    \/\/ C1->C1 invokeinterface -- call Unverified Value Entry of MyImplPojo1.func2 (compiled by C1)\n+    @Test(compLevel = C1)\n+    public int test90(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    static Intf test90_intfs[] = {\n+        new MyImplPojo1(),\n+        new MyImplPojo2(),\n+    };\n+\n+    @DontCompile\n+    public void test90_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = test90_intfs[i % test90_intfs.length];\n+            int result = test90(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func2(123, 456, pointField) + i);\n+        }\n+    }\n+\n+    \/\/ C1->C2 invokeinterface -- call Unverified Value Entry of MyImplPojo2.func2 (compiled by C2)\n+    @Test(compLevel = C1)\n+    public int test91(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    static Intf test91_intfs[] = {\n+        new MyImplPojo2(),\n+        new MyImplPojo1(),\n+    };\n+\n+    @DontCompile\n+    public void test91_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = test91_intfs[i % test91_intfs.length];\n+            int result = test91(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func2(123, 456, pointField) + i);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokeinterface -- call Unverified Entry of MyImplPojo1.func2 (compiled by C1)\n+    @Test(compLevel = C2)\n+    public int test92(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    static Intf test92_intfs[] = {\n+        new MyImplPojo1(),\n+        new MyImplPojo2(),\n+    };\n+\n+    @DontCompile\n+    public void test92_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = test92_intfs[i % test92_intfs.length];\n+            int result = test92(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func2(123, 456, pointField) + i);\n+        }\n+    }\n+\n+    \/\/ C2->C2 invokeinterface -- call Unverified Entry of MyImplPojo2.func2 (compiled by C2)\n+    @Test(compLevel = C2)\n+    public int test93(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    static Intf test93_intfs[] = {\n+        new MyImplPojo2(),\n+        new MyImplPojo1(),\n+    };\n+\n+    @DontCompile\n+    public void test93_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = test93_intfs[i % test93_intfs.length];\n+            int result = test93(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func2(123, 456, pointField) + i);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokeinterface -- call Unverified Entry of MyImplVal1.func2 (compiled by C1 - has VVEP_RO)\n+    @Test(compLevel = C2)\n+    public int test94(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    static Intf test94_intfs[] = {\n+        new MyImplVal1(),\n+        new MyImplVal2(),\n+    };\n+\n+    @DontCompile\n+    public void test94_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = test94_intfs[i % test94_intfs.length];\n+            int result = test94(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func2(123, 456, pointField) + i);\n+        }\n+    }\n+\n+    \/\/ C2->C2 invokeinterface -- call Unverified Entry of MyImplVal2.func2 (compiled by C2 - has VVEP_RO)\n+    @Test(compLevel = C2)\n+    public int test95(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    static Intf test95_intfs[] = {\n+        new MyImplVal2(),\n+        new MyImplVal1(),\n+    };\n+\n+    @DontCompile\n+    public void test95_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = test95_intfs[i % test95_intfs.length];\n+            int result = test95(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func2(123, 456, pointField) + i);\n+        }\n+    }\n+\n+    \/\/ C1->C2 GC handling in StubRoutines::store_inline_type_fields_to_buf()\n+    @Test(compLevel = C1)\n+    public RefPoint test96(RefPoint rp, boolean b) {\n+        RefPoint p = test96_helper(rp);\n+        if (b) {\n+            return rp;\n+        }\n+        return p;\n+    }\n+\n+    @DontInline @ForceCompile(compLevel = C2)\n+    public RefPoint test96_helper(RefPoint rp) {\n+        return rp;\n+    }\n+\n+    @DontCompile\n+    public void test96_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20000; \/\/ Do enough iteration to cause GC inside StubRoutines::store_inline_type_fields_to_buf\n+        Number x = new Number(10); \/\/ old object\n+        for (int i=0; i<count; i++) {\n+            Number y = new Number(i); \/\/ new object for each iteraton\n+            RefPoint rp1 = new RefPoint(x, y);\n+            RefPoint rp2 = test96(rp1, warmup);\n+\n+            Asserts.assertEQ(rp1.x, x);\n+            Asserts.assertEQ(rp1.y, y);\n+            Asserts.assertEQ(rp1.y.n, i);\n+        }\n+    }\n+\n+    \/\/ C1->C1  - caller is compiled first. It invokes callee(test97) a few times while the\n+    \/\/           callee is executed by the interpreter. Then, callee is compiled\n+    \/\/           and SharedRuntime::fixup_callers_callsite is called to fix up the\n+    \/\/           callsite from test97_verifier->test97.\n+    @Test(compLevel = C1)\n+    public int test97(Point p1, Point p2) {\n+        return test97_helper(p1, p2);\n+    }\n+\n+    @DontInline @DontCompile\n+    public int test97_helper(Point p1, Point p2) {\n+        return p1.x + p1.y + p2.x + p2.y;\n+    }\n+\n+    @ForceCompile(compLevel = C1)\n+    public void test97_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            int result = test97(pointField1, pointField2);\n+            int n = test97_helper(pointField1, pointField2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C1->C2  - same as test97, except the callee is compiled by c2.\n+    @Test(compLevel = C2)\n+    public int test98(Point p1, Point p2) {\n+        return test98_helper(p1, p2);\n+    }\n+\n+    @DontInline @DontCompile\n+    public int test98_helper(Point p1, Point p2) {\n+        return p1.x + p1.y + p2.x + p2.y;\n+    }\n+\n+    @ForceCompile(compLevel = C1)\n+    public void test98_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            int result = test98(pointField1, pointField2);\n+            int n = test98_helper(pointField1, pointField2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C1->C2  - same as test97, except the callee is a static method.\n+    @Test(compLevel = C1)\n+    public static int test99(Point p1, Point p2) {\n+        return test99_helper(p1, p2);\n+    }\n+\n+    @DontInline @DontCompile\n+    public static int test99_helper(Point p1, Point p2) {\n+        return p1.x + p1.y + p2.x + p2.y;\n+    }\n+\n+    @ForceCompile(compLevel = C1)\n+    public void test99_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            int result = test99(pointField1, pointField2);\n+            int n = test99_helper(pointField1, pointField2);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+\n+    \/\/ C2->C1 invokestatic, packing causes stack growth (1 extra stack word).\n+    \/\/ Make sure stack frame is set up properly for GC.\n+    @Test(compLevel = C2)\n+    public float test100(FloatPoint fp1, FloatPoint fp2, RefPoint rp, int a1, int a2, int a3, int a4) {\n+        return test100_helper(fp1, fp2, rp, a1, a2, a3, a4);\n+    }\n+\n+    @DontInline\n+    @ForceCompile(compLevel = C1)\n+    private static float test100_helper(FloatPoint fp1, FloatPoint fp2, RefPoint rp, int a1, int a2, int a3, int a4) {\n+        \/\/ On x64:\n+        \/\/    Scalarized entry -- all parameters are passed in registers\n+        \/\/          xmm0 = fp1.x\n+        \/\/          xmm1 = fp1.y\n+        \/\/          xmm2 = fp2.x\n+        \/\/          xmm3 = fp2.y\n+        \/\/          rsi  = rp.x  (oop)\n+        \/\/          rdx  = rp.y  (oop)\n+        \/\/          cx   = a1\n+        \/\/          r8   = a2\n+        \/\/          r9   = a3\n+        \/\/          di   = a4\n+        \/\/    Non-scalarized entry -- a6 is passed on stack[0]\n+        \/\/          rsi  = fp1\n+        \/\/          rdx  = fp2\n+        \/\/          rcx  = rp\n+        \/\/          r8   = a1\n+        \/\/          r9   = a2\n+        \/\/          di   = a3\n+        \/\/    [sp + ??]  = a4\n+        return fp1.x + fp1.y + fp2.x + fp2.y + rp.x.n + rp.y.n + a1 + a2 + a3 + a4;\n+    }\n+\n+    @DontCompile\n+    public void test100_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 4;\n+        for (int i=0; i<count; i++) {\n+            FloatPoint fp1 = new FloatPoint(i+0,  i+11);\n+            FloatPoint fp2 = new FloatPoint(i+222, i+3333);\n+            RefPoint rp = new RefPoint(i+44444, i+555555);\n+            float result;\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test100(fp1, fp2, rp, 1, 2, 3, 4);\n+            }\n+            float n = test100_helper(fp1, fp2, rp, 1, 2, 3, 4);\n+            Asserts.assertEQ(result, n);\n+        }\n+    }\n+\n+    \/\/ C1->C2 force GC for every allocation when storing the returned\n+    \/\/ fields back into a buffered object.\n+    @Test(compLevel = C1)\n+    public RefPoint test101(RefPoint rp) {\n+        return test101_helper(rp);\n+    }\n+\n+    @ForceCompile(compLevel = C2) @DontInline\n+    public RefPoint test101_helper(RefPoint rp) {\n+        return rp;\n+    }\n+\n+    @DontCompile\n+    public void test101_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) {\n+            RefPoint rp = new RefPoint(1, 2);\n+            Object x = rp.x;\n+            Object y = rp.y;\n+            RefPoint result = new RefPoint(3, 4);\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test101(rp);\n+            }\n+            Asserts.assertEQ(rp.x, result.x);\n+            Asserts.assertEQ(rp.y, result.y);\n+            Asserts.assertEQ(x, result.x);\n+            Asserts.assertEQ(y, result.y);\n+        }\n+    }\n+\n+    \/\/ Same as test101, except we have Interpreter->C2 instead.\n+    @Test(compLevel = C1)\n+    public RefPoint test102(RefPoint rp) {\n+        return test102_interp(rp);\n+    }\n+\n+    @DontCompile @DontInline\n+    public RefPoint test102_interp(RefPoint rp) {\n+        return test102_helper(rp);\n+    }\n+\n+    @ForceCompile(compLevel = C2) @DontInline\n+    public RefPoint test102_helper(RefPoint rp) {\n+        return rp;\n+    }\n+\n+    @DontCompile\n+    public void test102_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 5;\n+        for (int i=0; i<count; i++) {\n+            RefPoint rp = new RefPoint(11, 22);\n+            Object x = rp.x;\n+            Object y = rp.y;\n+            RefPoint result = new RefPoint(333, 444);\n+            try (ForceGCMarker m = ForceGCMarker.mark(warmup)) {\n+                result = test102(rp);\n+            }\n+            Asserts.assertEQ(rp.x, result.x);\n+            Asserts.assertEQ(rp.y, result.y);\n+            Asserts.assertEQ(x, result.x);\n+            Asserts.assertEQ(y, result.y);\n+        }\n+    }\n+\n+    @Test(compLevel = C1)\n+    public void test103() {\n+        \/\/ when this method is compiled by C1, the Test103Value class is not yet loaded.\n+        test103_v = new Test103Value(); \/\/ invokestatic \"Test103Value.<init>()QTest103Value;\"\n+    }\n+\n+    static primitive class Test103Value {\n+        int x = rI;\n+    }\n+\n+    static Object test103_v;\n+\n+    @DontCompile\n+    public void test103_verifier(boolean warmup) {\n+        if (warmup) {\n+            \/\/ Make sure test103() is compiled before Test103Value is loaded\n+            return;\n+        }\n+        test103();\n+        Test103Value v = (Test103Value)test103_v;\n+        Asserts.assertEQ(v.x, rI);\n+    }\n+\n+\n+    \/\/ Same as test103, but with an inline class that's too big to return as fields.\n+    @Test(compLevel = C1)\n+    public void test104() {\n+        \/\/ when this method is compiled by C1, the Test104Value class is not yet loaded.\n+        test104_v = new Test104Value(); \/\/ invokestatic \"Test104Value.<init>()QTest104Value;\"\n+    }\n+\n+    static primitive class Test104Value {\n+        long x0 = rL;\n+        long x1 = rL;\n+        long x2 = rL;\n+        long x3 = rL;\n+        long x4 = rL;\n+        long x5 = rL;\n+        long x6 = rL;\n+        long x7 = rL;\n+        long x8 = rL;\n+        long x9 = rL;\n+        long xa = rL;\n+        long xb = rL;\n+        long xc = rL;\n+        long xd = rL;\n+        long xe = rL;\n+        long xf = rL;\n+    }\n+\n+    static Object test104_v;\n+\n+    @DontCompile\n+    public void test104_verifier(boolean warmup) {\n+        if (warmup) {\n+            \/\/ Make sure test104() is compiled before Test104Value is loaded\n+            return;\n+        }\n+        test104();\n+        Test104Value v = (Test104Value)test104_v;\n+        Asserts.assertEQ(v.x0, rL);\n+    }\n+\n+    \/\/ C2->C1 invokeinterface -- call Unverified Entry of MyImplVal1.func1 (compiled by C1 - has VVEP_RO)\n+    \/\/\/ (same as test94, except we are calling func1, which shares VVEP and VVEP_RO\n+    @Test(compLevel = C2)\n+    public int test105(Intf intf, int a, int b) {\n+        return intf.func1(a, b);\n+    }\n+\n+    static Intf test105_intfs[] = {\n+        new MyImplVal1(),\n+        new MyImplVal2(),\n+    };\n+\n+    @DontCompile\n+    public void test105_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = test105_intfs[i % test105_intfs.length];\n+            int result = test105(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func1(123, 456) + i);\n+        }\n+    }\n+\n+    \/\/ C2->C2 invokeinterface -- call Unverified Entry of MyImplVal2.func1 (compiled by C2 - has VVEP_RO)\n+    \/\/\/ (same as test95, except we are calling func1, which shares VVEP and VVEP_RO\n+    @Test(compLevel = C2)\n+    public int test106(Intf intf, int a, int b) {\n+        return intf.func1(a, b);\n+    }\n+\n+    static Intf test106_intfs[] = {\n+        new MyImplVal2(),\n+        new MyImplVal1(),\n+    };\n+\n+    @DontCompile\n+    public void test106_verifier(boolean warmup) {\n+        int count = warmup ? 1 : 20;\n+        for (int i=0; i<count; i++) {\n+            Intf intf = test106_intfs[i % test106_intfs.length];\n+            int result = test106(intf, 123, 456) + i;\n+            Asserts.assertEQ(result, intf.func1(123, 456) + i);\n+        }\n+    }\n+\n+    \/\/ C2->C1 invokeinterface -- C2 calls call Unverified Entry of MyImplVal2X.func1 (compiled by\n+    \/\/                           C1, with VVEP_RO==VVEP)\n+    \/\/ This test is developed to validate JDK-8230325.\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public int test107(Intf intf, int a, int b) {\n+        return intf.func1(a, b);\n+    }\n+\n+    @ForceCompile\n+    public void test107_verifier(boolean warmup) {\n+        Intf intf1 = new MyImplVal1X();\n+        Intf intf2 = new MyImplVal2X();\n+\n+        for (int i=0; i<1000; i++) {\n+            test107(intf1, 123, 456);\n+        }\n+        for (int i=0; i<500_000; i++) {\n+            \/\/ Run enough loops so that test107 will be compiled by C2.\n+            if (i % 30 == 0) {\n+                \/\/ This will indirectly call MyImplVal2X.func1, but the call frequency is low, so\n+                \/\/ test107 will be compiled by C2, but MyImplVal2X.func1 will compiled by C1 only.\n+                int result = test107(intf2, 123, 456) + i;\n+                Asserts.assertEQ(result, intf2.func1(123, 456) + i);\n+            } else {\n+                \/\/ Call test107 with a mix of intf1 and intf2, so C2 will use a virtual call (not an optimized call)\n+                \/\/ for the invokeinterface bytecode in test107.\n+                test107(intf1, 123, 456);\n+            }\n+        }\n+    }\n+\n+    \/\/ Same as test107, except we call MyImplVal2X.func2 (compiled by C1, VVEP_RO != VVEP)\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public int test108(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    @ForceCompile\n+    public void test108_verifier(boolean warmup) {\n+        Intf intf1 = new MyImplVal1X();\n+        Intf intf2 = new MyImplVal2X();\n+\n+        for (int i=0; i<1000; i++) {\n+            test108(intf1, 123, 456);\n+        }\n+        for (int i=0; i<500_000; i++) {\n+            \/\/ Run enough loops so that test108 will be compiled by C2.\n+            if (i % 30 == 0) {\n+                \/\/ This will indirectly call MyImplVal2X.func2, but the call frequency is low, so\n+                \/\/ test108 will be compiled by C2, but MyImplVal2X.func2 will compiled by C1 only.\n+                int result = test108(intf2, 123, 456) + i;\n+                Asserts.assertEQ(result, intf2.func2(123, 456, pointField) + i);\n+            } else {\n+                \/\/ Call test108 with a mix of intf1 and intf2, so C2 will use a virtual call (not an optimized call)\n+                \/\/ for the invokeinterface bytecode in test108.\n+                test108(intf1, 123, 456);\n+            }\n+        }\n+    }\n+\n+    \/\/ Same as test107, except we call MyImplPojo3.func2 (compiled by C1, VVEP_RO == VEP)\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public int test109(Intf intf, int a, int b) {\n+        return intf.func2(a, b, pointField);\n+    }\n+\n+    @ForceCompile\n+    public void test109_verifier(boolean warmup) {\n+        Intf intf1 = new MyImplPojo0();\n+        Intf intf2 = new MyImplPojo3();\n+\n+        for (int i=0; i<1000; i++) {\n+            test109(intf1, 123, 456);\n+        }\n+        for (int i=0; i<500_000; i++) {\n+            \/\/ Run enough loops so that test109 will be compiled by C2.\n+            if (i % 30 == 0) {\n+                \/\/ This will indirectly call MyImplPojo3.func2, but the call frequency is low, so\n+                \/\/ test109 will be compiled by C2, but MyImplPojo3.func2 will compiled by C1 only.\n+                int result = test109(intf2, 123, 456) + i;\n+                Asserts.assertEQ(result, intf2.func2(123, 456, pointField) + i);\n+            } else {\n+                \/\/ Call test109 with a mix of intf1 and intf2, so C2 will use a virtual call (not an optimized call)\n+                \/\/ for the invokeinterface bytecode in test109.\n+                test109(intf1, 123, 456);\n+            }\n+        }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestCallingConventionC1.java","additions":2362,"deletions":0,"binary":false,"changes":2362,"status":"added"},{"patch":"@@ -0,0 +1,246 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+\n+import jdk.test.lib.Asserts;\n+\n+import sun.hotspot.WhiteBox;\n+\n+\/**\n+ * @test TestDeoptimizationWhenBuffering\n+ * @summary Test correct execution after deoptimizing from inline type specific runtime calls.\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @compile -XDallowWithFieldOperator TestDeoptimizationWhenBuffering.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:+DeoptimizeALot -XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.*::test*\n+ *                   compiler.valhalla.inlinetypes.TestDeoptimizationWhenBuffering C1\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:+DeoptimizeALot -XX:-UseTLAB -Xbatch\n+ *                   compiler.valhalla.inlinetypes.TestDeoptimizationWhenBuffering\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:+DeoptimizeALot -XX:-UseTLAB -Xbatch -XX:-MonomorphicArrayCheck -XX:-AlwaysIncrementalInline\n+ *                   -XX:-InlineTypePassFieldsAsArgs -XX:-InlineTypeReturnedAsFields -XX:FlatArrayElementMaxSize=1\n+ *                   -XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.*::test*\n+ *                   compiler.valhalla.inlinetypes.TestDeoptimizationWhenBuffering\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:+DeoptimizeALot -XX:-UseTLAB -Xbatch -XX:-MonomorphicArrayCheck -XX:+AlwaysIncrementalInline\n+ *                   -XX:-InlineTypePassFieldsAsArgs -XX:-InlineTypeReturnedAsFields -XX:FlatArrayElementMaxSize=1\n+ *                   -XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.*::test*\n+ *                   compiler.valhalla.inlinetypes.TestDeoptimizationWhenBuffering\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:+DeoptimizeALot -XX:-UseTLAB -Xbatch -XX:-MonomorphicArrayCheck -XX:-AlwaysIncrementalInline\n+ *                   -XX:+InlineTypePassFieldsAsArgs -XX:+InlineTypeReturnedAsFields -XX:FlatArrayElementMaxSize=-1\n+ *                   -XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.*::test*\n+ *                   compiler.valhalla.inlinetypes.TestDeoptimizationWhenBuffering\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:+DeoptimizeALot -XX:-UseTLAB -Xbatch -XX:-MonomorphicArrayCheck -XX:+AlwaysIncrementalInline\n+ *                   -XX:+InlineTypePassFieldsAsArgs -XX:+InlineTypeReturnedAsFields -XX:FlatArrayElementMaxSize=-1\n+ *                   -XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.*::test*\n+ *                   compiler.valhalla.inlinetypes.TestDeoptimizationWhenBuffering\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:+DeoptimizeALot -XX:-UseTLAB -Xbatch -XX:-MonomorphicArrayCheck -XX:-AlwaysIncrementalInline\n+ *                   -XX:+InlineTypePassFieldsAsArgs -XX:+InlineTypeReturnedAsFields -XX:FlatArrayElementMaxSize=-1 -XX:InlineFieldMaxFlatSize=0\n+ *                   -XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.*::test*\n+ *                   compiler.valhalla.inlinetypes.TestDeoptimizationWhenBuffering\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   -XX:+DeoptimizeALot -XX:-UseTLAB -Xbatch -XX:-MonomorphicArrayCheck -XX:+AlwaysIncrementalInline\n+ *                   -XX:+InlineTypePassFieldsAsArgs -XX:+InlineTypeReturnedAsFields -XX:FlatArrayElementMaxSize=-1 -XX:InlineFieldMaxFlatSize=0\n+ *                   -XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.*::test*\n+ *                   compiler.valhalla.inlinetypes.TestDeoptimizationWhenBuffering\n+ *\/\n+\n+final primitive class MyValue1 {\n+    static int cnt = 0;\n+    final int x;\n+    final MyValue2 vtField1;\n+    final MyValue2.ref vtField2;\n+\n+    public MyValue1() {\n+        this.x = ++cnt;\n+        this.vtField1 = new MyValue2();\n+        this.vtField2 = new MyValue2();\n+    }\n+\n+    public int hash() {\n+        return x + vtField1.x + vtField2.x;\n+    }\n+\n+    public MyValue1 testWithField(int x) {\n+        return __WithField(this.x, x);\n+    }\n+}\n+\n+final primitive class MyValue2 {\n+    static int cnt = 0;\n+    final int x;\n+    public MyValue2() {\n+        this.x = ++cnt;\n+    }\n+}\n+\n+public class TestDeoptimizationWhenBuffering {\n+    static final WhiteBox WHITE_BOX = WhiteBox.getWhiteBox();\n+    static final int COMP_LEVEL_FULL_OPTIMIZATION = 4; \/\/ C2 or JVMCI\n+\n+    static {\n+        try {\n+            Class<?> clazz = TestDeoptimizationWhenBuffering.class;\n+            MethodHandles.Lookup lookup = MethodHandles.lookup();\n+\n+            MethodType mt = MethodType.methodType(MyValue1.class);\n+            test9_mh = lookup.findStatic(clazz, \"test9Callee\", mt);\n+            test10_mh = lookup.findStatic(clazz, \"test10Callee\", mt);\n+        } catch (NoSuchMethodException | IllegalAccessException e) {\n+            e.printStackTrace();\n+            throw new RuntimeException(\"Method handle lookup failed\");\n+        }\n+    }\n+\n+    MyValue1 test1() {\n+        return new MyValue1();\n+    }\n+\n+    static MyValue1 vtField1;\n+\n+    MyValue1 test2() {\n+        vtField1 = new MyValue1();\n+        return vtField1;\n+    }\n+\n+    public int test3Callee(MyValue1 vt) {\n+        return vt.hash();\n+    }\n+\n+    int test3() {\n+        MyValue1 vt = new MyValue1();\n+        return test3Callee(vt);\n+    }\n+\n+    static MyValue1[] vtArray = new MyValue1[1];\n+\n+    MyValue1 test4() {\n+        vtArray[0] = new MyValue1();\n+        return vtArray[0];\n+    }\n+\n+    Object test5(Object[] array) {\n+        array[0] = new MyValue1();\n+        return array[0];\n+    }\n+\n+    boolean test6(Object obj) {\n+        MyValue1 vt = new MyValue1();\n+        return vt == obj;\n+    }\n+\n+    Object test7(Object[] obj) {\n+        return obj[0];\n+    }\n+\n+    MyValue1.ref test8(MyValue1.ref[] obj) {\n+        return obj[0];\n+    }\n+\n+    static final MethodHandle test9_mh;\n+\n+    public static MyValue1 test9Callee() {\n+        return new MyValue1();\n+    }\n+\n+    MyValue1 test9() throws Throwable {\n+        return (MyValue1)test9_mh.invokeExact();\n+    }\n+\n+    static final MethodHandle test10_mh;\n+    static final MyValue1 test10Field = new MyValue1();\n+    static int test10Counter = 0;\n+\n+    public static MyValue1 test10Callee() {\n+        test10Counter++;\n+        return test10Field;\n+    }\n+\n+    Object test10() throws Throwable {\n+        return test10_mh.invoke();\n+    }\n+\n+    MyValue1 test11(MyValue1 vt) {\n+        return vt.testWithField(42);\n+    }\n+\n+    MyValue1 vtField2;\n+\n+    MyValue1 test12() {\n+        vtField2 = new MyValue1();\n+        return vtField2;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        if (args.length > 0) {\n+            \/\/ Compile callees with C1 only, to exercise deoptimization while buffering at method entry\n+            Asserts.assertEQ(args[0], \"C1\", \"unsupported mode\");\n+            Method m = MyValue1.class.getMethod(\"testWithField\", int.class);\n+            WHITE_BOX.makeMethodNotCompilable(m, COMP_LEVEL_FULL_OPTIMIZATION, false);\n+            m = TestDeoptimizationWhenBuffering.class.getMethod(\"test3Callee\", MyValue1.class);\n+            WHITE_BOX.makeMethodNotCompilable(m, COMP_LEVEL_FULL_OPTIMIZATION, false);\n+            m = TestDeoptimizationWhenBuffering.class.getMethod(\"test9Callee\");\n+            WHITE_BOX.makeMethodNotCompilable(m, COMP_LEVEL_FULL_OPTIMIZATION, false);\n+            m = TestDeoptimizationWhenBuffering.class.getMethod(\"test10Callee\");\n+            WHITE_BOX.makeMethodNotCompilable(m, COMP_LEVEL_FULL_OPTIMIZATION, false);\n+        }\n+\n+        MyValue1[] va = new MyValue1[3];\n+        va[0] = new MyValue1();\n+        Object[] oa = new Object[3];\n+        oa[0] = va[0];\n+        TestDeoptimizationWhenBuffering t = new TestDeoptimizationWhenBuffering();\n+        for (int i = 0; i < 100_000; ++i) {\n+            \/\/ Check counters to make sure that we don't accidentially reexecute calls when deoptimizing\n+            int expected = MyValue1.cnt + MyValue2.cnt + MyValue2.cnt;\n+            Asserts.assertEQ(t.test1().hash(), expected + 4);\n+            vtField1 = MyValue1.default;\n+            Asserts.assertEQ(t.test2().hash(), expected + 9);\n+            Asserts.assertEQ(vtField1.hash(), expected + 9);\n+            Asserts.assertEQ(t.test3(), expected + 14);\n+            Asserts.assertEQ(t.test4().hash(), expected + 19);\n+            Asserts.assertEQ(((MyValue1)t.test5(vtArray)).hash(), expected + 24);\n+            Asserts.assertEQ(t.test6(vtField1), false);\n+            Asserts.assertEQ(t.test7(((i % 2) == 0) ? va : oa), va[0]);\n+            Asserts.assertEQ(t.test8(va), va[0]);\n+            Asserts.assertEQ(t.test8(va), va[0]);\n+            Asserts.assertEQ(t.test9().hash(), expected + 34);\n+            int count = test10Counter;\n+            Asserts.assertEQ(((MyValue1)t.test10()).hash(), test10Field.hash());\n+            Asserts.assertEQ(t.test10Counter, count + 1);\n+            Asserts.assertEQ(t.test11(va[0]).hash(), va[0].testWithField(42).hash());\n+            t.vtField2 = MyValue1.default;\n+            Asserts.assertEQ(t.test12().hash(), expected + 39);\n+            Asserts.assertEQ(t.vtField2.hash(), expected + 39);\n+        }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestDeoptimizationWhenBuffering.java","additions":246,"deletions":0,"binary":false,"changes":246,"status":"added"},{"patch":"@@ -0,0 +1,217 @@\n+\/*\n+ * Copyright (c) 2020, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+import java.nio.file.NoSuchFileException;\n+import java.util.Arrays;\n+\n+import jdk.test.lib.Asserts;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Verify that chains of getfields on flattened fields are correctly optimized\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires os.simpleArch == \"x64\"\n+ * @compile TestGetfieldChains.java NamedRectangle.java Rectangle.java Point.java GetfieldChains.jcod\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestGetfieldChains\n+ *\/\n+\n+public class TestGetfieldChains extends InlineTypeTest {\n+    public static final int C1 = COMP_LEVEL_SIMPLE;\n+    public static final int C2 = COMP_LEVEL_FULL_OPTIMIZATION;\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestGetfieldChains test = new TestGetfieldChains();\n+        test.run(args, TestGetfieldChains.class);\n+    }\n+\n+    @Override\n+    public int getNumScenarios() {\n+        return 5;\n+    }\n+\n+    @Override\n+    public String[] getVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 0: return new String[] { \/\/ C1 only\n+                \"-XX:TieredStopAtLevel=1\",\n+                \"-XX:+TieredCompilation\",\n+            };\n+        case 1: return new String[] { \/\/ C2 only. (Make sure the tests are correctly written)\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:-TieredCompilation\",\n+                \"-XX:-OmitStackTraceInFastThrow\",\n+            };\n+        case 2: return new String[] { \/\/ interpreter only\n+                \"-Xint\",\n+            };\n+        case 3: return new String[] {\n+                \/\/ Xcomp Only C1.\n+                \"-XX:TieredStopAtLevel=1\",\n+                \"-XX:+TieredCompilation\",\n+                \"-Xcomp\",\n+            };\n+        case 4: return new String[] {\n+                \/\/ Xcomp Only C2.\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:-TieredCompilation\",\n+                \"-XX:-OmitStackTraceInFastThrow\",\n+                \"-Xcomp\",\n+            };\n+        }\n+        return null;\n+    }\n+\n+    \/\/ Simple chain of getfields ending with primitive field\n+    @Test(compLevel=C1)\n+    public int test1() {\n+        return NamedRectangle.getP1X(new NamedRectangle());\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        int res = test1();\n+        Asserts.assertEQ(res, 4);\n+    }\n+\n+    \/\/ Simple chain of getfields ending with a flattened field\n+    @Test(compLevel=C1)\n+    public Point test2() {\n+        return NamedRectangle.getP1(new NamedRectangle());\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        Point p = test2();\n+        Asserts.assertEQ(p.x, 4);\n+        Asserts.assertEQ(p.y, 7);\n+    }\n+\n+    \/\/ Chain of getfields but the initial receiver is null\n+    @Test(compLevel=C1)\n+    public NullPointerException test3() {\n+        NullPointerException npe = null;\n+        try {\n+            NamedRectangle.getP1X(null);\n+        } catch(NullPointerException e) {\n+            npe = e;\n+        }\n+        return npe;\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        NullPointerException npe = test3();\n+        Asserts.assertNE(npe, null);\n+        StackTraceElement st = npe.getStackTrace()[0];\n+        Asserts.assertEQ(st.getMethodName(), \"getP1X\");\n+        Asserts.assertEQ(st.getLineNumber(), 31);       \/\/ line number depends on file NamedRectangle.java\n+    }\n+\n+    \/\/ Chain of getfields but one getfield in the middle of the chain trigger an illegal access\n+    @Test(compLevel=C1)\n+    public IllegalAccessError test4() {\n+        IllegalAccessError iae = null;\n+        try {\n+            int i = NamedRectangleP.getP1X(new NamedRectangleP());\n+        } catch(IllegalAccessError e) {\n+            iae = e;\n+        }\n+        return iae;\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        IllegalAccessError iae = test4();\n+        Asserts.assertNE(iae, null);\n+        StackTraceElement st = iae.getStackTrace()[0];\n+        Asserts.assertEQ(st.getMethodName(), \"getP1X\");\n+        Asserts.assertEQ(st.getLineNumber(), 31);       \/\/ line number depends on jcod file generated from NamedRectangle.java\n+        Asserts.assertTrue(iae.getMessage().contains(\"class compiler.valhalla.inlinetypes.NamedRectangleP tried to access private field compiler.valhalla.inlinetypes.RectangleP.p1\"));\n+    }\n+\n+    \/\/ Chain of getfields but the last getfield trigger a NoSuchFieldError\n+    @Test(compLevel=C1)\n+    public NoSuchFieldError test5() {\n+        NoSuchFieldError nsfe = null;\n+        try {\n+            int i = NamedRectangleN.getP1X(new NamedRectangleN());\n+        } catch(NoSuchFieldError e) {\n+            nsfe = e;\n+        }\n+        return nsfe;\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        NoSuchFieldError nsfe = test5();\n+        Asserts.assertNE(nsfe, null);\n+        StackTraceElement st = nsfe.getStackTrace()[0];\n+        Asserts.assertEQ(st.getMethodName(), \"getP1X\");\n+        Asserts.assertEQ(st.getLineNumber(), 31);       \/\/ line number depends on jcod file generated from NamedRectangle.java\n+        Asserts.assertEQ(nsfe.getMessage(), \"x\");\n+    }\n+\n+    static primitive class EmptyType { }\n+    static primitive class EmptyContainer {\n+        int i = 0;\n+        EmptyType et = new EmptyType();\n+    }\n+    static primitive class Container {\n+        EmptyContainer container0 = new EmptyContainer();\n+        EmptyContainer container1 = new EmptyContainer();\n+    }\n+\n+    @Test(compLevel=C1)\n+    public EmptyType test6() {\n+        Container c = new Container();\n+        return c.container1.et;\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        EmptyType et = test6();\n+        Asserts.assertEQ(et, EmptyType.default);\n+    }\n+\n+    @Test(compLevel=C1)\n+    public EmptyType test7() {\n+        Container[] ca = new Container[10];\n+        return ca[3].container0.et;\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        EmptyType et = test7();\n+        Asserts.assertEQ(et, EmptyType.default);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestGetfieldChains.java","additions":217,"deletions":0,"binary":false,"changes":217,"status":"added"},{"patch":"@@ -0,0 +1,1133 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import java.lang.reflect.Array;\n+import java.lang.reflect.Field;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.internal.misc.Unsafe;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test intrinsic support for inline types\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @modules java.base\/jdk.internal.misc\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestIntrinsics.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestIntrinsics\n+ *\/\n+public class TestIntrinsics extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 3: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:FlatArrayElementMaxSize=-1\"};\n+        case 4: return new String[] {\"-XX:-MonomorphicArrayCheck\"};\n+        }\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestIntrinsics test = new TestIntrinsics();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class);\n+    }\n+\n+    \/\/ Test correctness of the Class::isAssignableFrom intrinsic\n+    @Test()\n+    public boolean test1(Class<?> supercls, Class<?> subcls) {\n+        return supercls.isAssignableFrom(subcls);\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        Asserts.assertTrue(test1(java.util.AbstractList.class, java.util.ArrayList.class), \"test1_1 failed\");\n+        Asserts.assertTrue(test1(MyValue1.ref.class, MyValue1.ref.class), \"test1_2 failed\");\n+        Asserts.assertTrue(test1(MyValue1.class, MyValue1.class), \"test1_3 failed\");\n+        Asserts.assertTrue(test1(MyValue1.ref.class, MyValue1.class), \"test1_4 failed\");\n+        Asserts.assertFalse(test1(MyValue1.class, MyValue1.ref.class), \"test1_5 failed\");\n+        Asserts.assertTrue(test1(Object.class, java.util.ArrayList.class), \"test1_6 failed\");\n+        Asserts.assertTrue(test1(Object.class, MyValue1.ref.class), \"test1_7 failed\");\n+        Asserts.assertTrue(test1(Object.class, MyValue1.class), \"test1_8 failed\");\n+        Asserts.assertTrue(!test1(MyValue1.ref.class, Object.class), \"test1_9 failed\");\n+        Asserts.assertTrue(!test1(MyValue1.class, Object.class), \"test1_10 failed\");\n+    }\n+\n+    \/\/ Verify that Class::isAssignableFrom checks with statically known classes are folded\n+    @Test(failOn = LOADK)\n+    public boolean test2() {\n+        boolean check1 = java.util.AbstractList.class.isAssignableFrom(java.util.ArrayList.class);\n+        boolean check2 = MyValue1.ref.class.isAssignableFrom(MyValue1.ref.class);\n+        boolean check3 = MyValue1.class.isAssignableFrom(MyValue1.class);\n+        boolean check4 = MyValue1.ref.class.isAssignableFrom(MyValue1.class);\n+        boolean check5 = !MyValue1.class.isAssignableFrom(MyValue1.ref.class);\n+        boolean check6 = Object.class.isAssignableFrom(java.util.ArrayList.class);\n+        boolean check7 = Object.class.isAssignableFrom(MyValue1.ref.class);\n+        boolean check8 = Object.class.isAssignableFrom(MyValue1.class);\n+        boolean check9 = !MyValue1.ref.class.isAssignableFrom(Object.class);\n+        boolean check10 = !MyValue1.class.isAssignableFrom(Object.class);\n+        return check1 && check2 && check3 && check4 && check5 && check6 && check7 && check8 && check9 && check10;\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        Asserts.assertTrue(test2(), \"test2 failed\");\n+    }\n+\n+    \/\/ Test correctness of the Class::getSuperclass intrinsic\n+    @Test()\n+    public Class<?> test3(Class<?> cls) {\n+        return cls.getSuperclass();\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        Asserts.assertTrue(test3(Object.class) == null, \"test3_1 failed\");\n+        Asserts.assertTrue(test3(MyValue1.ref.class) == MyAbstract.class, \"test3_2 failed\");\n+        Asserts.assertTrue(test3(MyValue1.val.class) == MyValue1.ref.class, \"test3_3 failed\");\n+        Asserts.assertTrue(test3(Class.class) == Object.class, \"test3_4 failed\");\n+    }\n+\n+    \/\/ Verify that Class::getSuperclass checks with statically known classes are folded\n+    @Test(failOn = LOADK)\n+    public boolean test4() {\n+        boolean check1 = Object.class.getSuperclass() == null;\n+        \/\/ TODO 8244562: Remove cast as workaround once javac is fixed\n+        boolean check2 = (Class<?>)MyValue1.ref.class.getSuperclass() == MyAbstract.class;\n+        \/\/ TODO 8244562: Remove cast as workaround once javac is fixed\n+        boolean check3 = (Class<?>)MyValue1.val.class.getSuperclass() == MyValue1.ref.class;\n+        boolean check4 = Class.class.getSuperclass() == Object.class;\n+        return check1 && check2 && check3 && check4;\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        Asserts.assertTrue(test4(), \"test4 failed\");\n+    }\n+\n+    \/\/ Test toString() method\n+    @Test()\n+    public String test5(MyValue1 v) {\n+        return v.toString();\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createDefaultInline();\n+        test5(v);\n+    }\n+\n+    \/\/ Test hashCode() method\n+    @Test()\n+    public int test6(MyValue1 v) {\n+        return v.hashCode();\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        int res = test6(v);\n+        Asserts.assertEQ(res, v.hashCode());\n+    }\n+\n+    \/\/ Test default inline type array creation via reflection\n+    @Test()\n+    public Object[] test7(Class<?> componentType, int len) {\n+        Object[] va = (Object[])Array.newInstance(componentType, len);\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 42;\n+        long hash = MyValue1.createDefaultDontInline().hashPrimitive();\n+        Object[] va = test7(MyValue1.class, len);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(((MyValue1)va[i]).hashPrimitive(), hash);\n+        }\n+    }\n+\n+    \/\/ Class.isInstance\n+    @Test()\n+    public boolean test8(Class c, MyValue1 vt) {\n+        return c.isInstance(vt);\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        boolean result = test8(MyValue1.class, vt);\n+        Asserts.assertTrue(result);\n+        result = test8(MyValue1.ref.class, vt);\n+        Asserts.assertTrue(result);\n+    }\n+\n+    @Test()\n+    public boolean test9(Class c, MyValue1 vt) {\n+        return c.isInstance(vt);\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        boolean result = test9(MyValue2.class, vt);\n+        Asserts.assertFalse(result);\n+        result = test9(MyValue2.ref.class, vt);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ Class.cast\n+    @Test()\n+    public Object test10(Class c, MyValue1 vt) {\n+        return c.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object result = test10(MyValue1.class, vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+    }\n+\n+    @Test()\n+    public Object test11(Class c, MyValue1 vt) {\n+        return c.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        try {\n+            test11(MyValue2.class, vt);\n+            throw new RuntimeException(\"should have thrown\");\n+        } catch (ClassCastException cce) {\n+        }\n+    }\n+\n+    @Test()\n+    public Object test12(MyValue1 vt) {\n+        return MyValue1.class.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object result = test12(vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+    }\n+\n+    @Test()\n+    public Object test13(MyValue1 vt) {\n+        return MyValue2.class.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        try {\n+            test13(vt);\n+            throw new RuntimeException(\"should have thrown\");\n+        } catch (ClassCastException cce) {\n+        }\n+    }\n+\n+    \/\/ inline type array creation via reflection\n+    @Test()\n+    public void test14(int len, long hash) {\n+        Object[] va = (Object[])Array.newInstance(MyValue1.val.class, len);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(((MyValue1)va[i]).hashPrimitive(), hash);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 42;\n+        long hash = MyValue1.createDefaultDontInline().hashPrimitive();\n+        test14(len, hash);\n+    }\n+\n+    \/\/ Test hashCode() method\n+    @Test()\n+    public int test15(Object v) {\n+        return v.hashCode();\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        int res = test15(v);\n+        Asserts.assertEQ(res, v.hashCode());\n+    }\n+\n+    @Test()\n+    public int test16(Object v) {\n+        return System.identityHashCode(v);\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        int res = test16(v);\n+        Asserts.assertEQ(res, System.identityHashCode((Object)v));\n+    }\n+\n+    @Test()\n+    public int test17(Object v) {\n+        return System.identityHashCode(v);\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean warmup) {\n+        Integer v = Integer.valueOf(rI);\n+        int res = test17(v);\n+        Asserts.assertEQ(res, System.identityHashCode(v));\n+    }\n+\n+    @Test()\n+    public int test18(Object v) {\n+        return System.identityHashCode(v);\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        Object v = null;\n+        int res = test18(v);\n+        Asserts.assertEQ(res, System.identityHashCode(v));\n+    }\n+\n+    \/\/ hashCode() and toString() with different inline types\n+    @Test()\n+    public int test19(MyValue1 vt1, MyValue1 vt2, boolean b) {\n+        MyValue1 res = b ? vt1 : vt2;\n+        return res.hashCode();\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        int res = test19(vt, vt, true);\n+        Asserts.assertEQ(res, vt.hashCode());\n+        res = test19(vt, vt, false);\n+        Asserts.assertEQ(res, vt.hashCode());\n+    }\n+\n+    @Test()\n+    public String test20(MyValue1 vt1, MyValue1 vt2, boolean b) {\n+        MyValue1 res = b ? vt1 : vt2;\n+        return res.toString();\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        String res = test20(vt, vt, true);\n+        Asserts.assertEQ(res, vt.toString());\n+        res = test20(vt, vt, false);\n+        Asserts.assertEQ(res, vt.toString());\n+    }\n+\n+    private static final Unsafe U = Unsafe.getUnsafe();\n+    private static final long X_OFFSET;\n+    private static final long Y_OFFSET;\n+    private static final long V1_OFFSET;\n+    private static final boolean V1_FLATTENED;\n+    static {\n+        try {\n+            Field xField = MyValue1.class.getDeclaredField(\"x\");\n+            X_OFFSET = U.objectFieldOffset(xField);\n+            Field yField = MyValue1.class.getDeclaredField(\"y\");\n+            Y_OFFSET = U.objectFieldOffset(yField);\n+            Field v1Field = MyValue1.class.getDeclaredField(\"v1\");\n+            V1_OFFSET = U.objectFieldOffset(v1Field);\n+            V1_FLATTENED = U.isFlattened(v1Field);\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    protected static final String CALL_Unsafe = START + \"CallStaticJava\" + MID + \"# Static  jdk.internal.misc.Unsafe::\" + END;\n+\n+    @Test(failOn=CALL_Unsafe)\n+    public int test21(MyValue1 v) {\n+       return U.getInt(v, X_OFFSET);\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        int res = test21(v);\n+        Asserts.assertEQ(res, v.x);\n+    }\n+\n+    MyValue1 test22_vt;\n+    @Test(failOn=CALL_Unsafe + ALLOC)\n+    public void test22(MyValue1 v) {\n+        v = U.makePrivateBuffer(v);\n+        U.putInt(v, X_OFFSET, rI);\n+        v = U.finishPrivateBuffer(v);\n+        test22_vt = v;\n+    }\n+\n+    @DontCompile\n+    public void test22_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        test22(v.setX(v, 0));\n+        Asserts.assertEQ(test22_vt.hash(), v.hash());\n+    }\n+\n+    @Test(failOn=CALL_Unsafe)\n+    public int test23(MyValue1 v, long offset) {\n+        return U.getInt(v, offset);\n+    }\n+\n+    @DontCompile\n+    public void test23_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        int res = test23(v, X_OFFSET);\n+        Asserts.assertEQ(res, v.x);\n+    }\n+\n+    MyValue1 test24_vt = MyValue1.createWithFieldsInline(rI, rL);\n+\n+    @Test(failOn=CALL_Unsafe)\n+    public int test24(long offset) {\n+        return U.getInt(test24_vt, offset);\n+    }\n+\n+    @DontCompile\n+    public void test24_verifier(boolean warmup) {\n+        int res = test24(X_OFFSET);\n+        Asserts.assertEQ(res, test24_vt.x);\n+    }\n+\n+    \/\/ Test copyOf intrinsic with allocated inline type in it's debug information\n+    final primitive class Test25Value {\n+        final int x;\n+        public Test25Value() {\n+            this.x = 42;\n+        }\n+    }\n+\n+    final Test25Value[] test25Array = new Test25Value[10];\n+\n+    @Test\n+    public Test25Value[] test25(Test25Value element) {\n+        Object[] newArray = Arrays.copyOf(test25Array, test25Array.length + 1);\n+        newArray[test25Array.length] = element;\n+        return (Test25Value[]) newArray;\n+    }\n+\n+    @DontCompile\n+    public void test25_verifier(boolean warmup) {\n+        Test25Value vt = new Test25Value();\n+        test25(vt);\n+    }\n+\n+    @Test\n+    public Object test26() {\n+        Class<?>[] ca = new Class<?>[1];\n+        for (int i = 0; i < 1; ++i) {\n+          \/\/ Folds during loop opts\n+          ca[i] = MyValue1.val.class;\n+        }\n+        return Array.newInstance(ca[0], 1);\n+    }\n+\n+    @DontCompile\n+    public void test26_verifier(boolean warmup) {\n+        Object[] res = (Object[])test26();\n+        Asserts.assertEQ(((MyValue1)res[0]).hashPrimitive(), MyValue1.createDefaultInline().hashPrimitive());\n+    }\n+\n+    \/\/ Load non-flattenable inline type field with unsafe\n+    MyValue1.ref test27_vt = MyValue1.createWithFieldsInline(rI, rL);\n+    private static final long TEST27_OFFSET;\n+    static {\n+        try {\n+            Field field = TestIntrinsics.class.getDeclaredField(\"test27_vt\");\n+            TEST27_OFFSET = U.objectFieldOffset(field);\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @Test(failOn=CALL_Unsafe)\n+    public MyValue1 test27() {\n+        return (MyValue1)U.getReference(this, TEST27_OFFSET);\n+    }\n+\n+    @DontCompile\n+    public void test27_verifier(boolean warmup) {\n+        MyValue1 res = test27();\n+        Asserts.assertEQ(res.hash(), test24_vt.hash());\n+    }\n+\n+    \/\/ Mismatched type\n+    @Test(failOn=CALL_Unsafe)\n+    public int test28(MyValue1 v) {\n+        return U.getByte(v, X_OFFSET);\n+    }\n+\n+    @DontCompile\n+    public void test28_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        int res = test28(v);\n+        if (java.nio.ByteOrder.nativeOrder() == java.nio.ByteOrder.LITTLE_ENDIAN) {\n+            Asserts.assertEQ(res, (int)((byte)v.x));\n+        } else {\n+            Asserts.assertEQ(res, (int)((byte)Integer.reverseBytes(v.x)));\n+        }\n+    }\n+\n+    \/\/ Wrong alignment\n+    @Test(failOn=CALL_Unsafe)\n+    public long test29(MyValue1 v) {\n+        \/\/ Read the field that's guaranteed to not be last in the\n+        \/\/ inline type so we don't read out of bounds.\n+        if (X_OFFSET < Y_OFFSET) {\n+            return U.getInt(v, X_OFFSET+1);\n+        }\n+        return U.getLong(v, Y_OFFSET+1);\n+    }\n+\n+    @DontCompile\n+    public void test29_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        long res = test29(v);\n+        if (java.nio.ByteOrder.nativeOrder() == java.nio.ByteOrder.LITTLE_ENDIAN) {\n+            if (X_OFFSET < Y_OFFSET) {\n+                Asserts.assertEQ(((int)res) << 8, (v.x >> 8) << 8);\n+            } else {\n+                Asserts.assertEQ(res << 8, (v.y >> 8) << 8);\n+            }\n+        } else {\n+            if (X_OFFSET < Y_OFFSET) {\n+                Asserts.assertEQ(((int)res), v.x >>> 8);\n+            } else {\n+                Asserts.assertEQ(res, v.y >>> 8);\n+            }\n+        }\n+    }\n+\n+    \/\/ getValue to retrieve flattened field from inline type\n+    @Test(failOn=CALL_Unsafe)\n+    public MyValue2 test30(MyValue1 v) {\n+        if (V1_FLATTENED) {\n+            return U.getValue(v, V1_OFFSET, MyValue2.val.class);\n+        }\n+        return (MyValue2)U.getReference(v, V1_OFFSET);\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue2 res = test30(v);\n+        Asserts.assertEQ(res.hash(), v.v1.hash());\n+    }\n+\n+    MyValue1 test31_vt;\n+    private static final long TEST31_VT_OFFSET;\n+    private static final boolean TEST31_VT_FLATTENED;\n+    static {\n+        try {\n+            Field test31_vt_Field = TestIntrinsics.class.getDeclaredField(\"test31_vt\");\n+            TEST31_VT_OFFSET = U.objectFieldOffset(test31_vt_Field);\n+            TEST31_VT_FLATTENED = U.isFlattened(test31_vt_Field);\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    \/\/ getValue to retrieve flattened field from object\n+    @Test(failOn=CALL_Unsafe)\n+    public MyValue1 test31() {\n+        if (TEST31_VT_FLATTENED) {\n+            return U.getValue(this, TEST31_VT_OFFSET, MyValue1.val.class);\n+        }\n+        return (MyValue1)U.getReference(this, TEST31_VT_OFFSET);\n+    }\n+\n+    @DontCompile\n+    public void test31_verifier(boolean warmup) {\n+        test31_vt = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1 res = test31();\n+        Asserts.assertEQ(res.hash(), test31_vt.hash());\n+    }\n+\n+    \/\/ putValue to set flattened field in object\n+    @Test(failOn=CALL_Unsafe)\n+    public void test32(MyValue1 vt) {\n+        if (TEST31_VT_FLATTENED) {\n+            U.putValue(this, TEST31_VT_OFFSET, MyValue1.val.class, vt);\n+        } else {\n+            U.putReference(this, TEST31_VT_OFFSET, vt);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test32_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        test31_vt = MyValue1.createDefaultInline();\n+        test32(vt);\n+        Asserts.assertEQ(vt.hash(), test31_vt.hash());\n+    }\n+\n+    private static final int TEST33_BASE_OFFSET;\n+    private static final int TEST33_INDEX_SCALE;\n+    private static final boolean TEST33_FLATTENED_ARRAY;\n+    static {\n+        try {\n+            TEST33_BASE_OFFSET = U.arrayBaseOffset(MyValue1[].class);\n+            TEST33_INDEX_SCALE = U.arrayIndexScale(MyValue1[].class);\n+            TEST33_FLATTENED_ARRAY = U.isFlattenedArray(MyValue1[].class);\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+    \/\/ getValue to retrieve flattened field from array\n+    @Test(failOn=CALL_Unsafe)\n+    public MyValue1 test33(MyValue1[] arr) {\n+        if (TEST33_FLATTENED_ARRAY) {\n+            return U.getValue(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE, MyValue1.val.class);\n+        }\n+        return (MyValue1)U.getReference(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE);\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) {\n+        MyValue1[] arr = new MyValue1[2];\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        arr[1] = vt;\n+        MyValue1 res = test33(arr);\n+        Asserts.assertEQ(res.hash(), vt.hash());\n+    }\n+\n+    \/\/ putValue to set flattened field in array\n+    @Test(failOn=CALL_Unsafe)\n+    public void test34(MyValue1[] arr, MyValue1 vt) {\n+        if (TEST33_FLATTENED_ARRAY) {\n+            U.putValue(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE, MyValue1.val.class, vt);\n+        } else {\n+            U.putReference(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE, vt);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        MyValue1[] arr = new MyValue1[2];\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        test34(arr, vt);\n+        Asserts.assertEQ(arr[1].hash(), vt.hash());\n+    }\n+\n+    \/\/ getValue to retrieve flattened field from object with unknown\n+    \/\/ container type\n+    @Test(failOn=CALL_Unsafe)\n+    public MyValue1 test35(Object o) {\n+        if (TEST31_VT_FLATTENED) {\n+            return U.getValue(o, TEST31_VT_OFFSET, MyValue1.val.class);\n+        }\n+        return (MyValue1)U.getReference(o, TEST31_VT_OFFSET);\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) {\n+        test31_vt = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1 res = test35(this);\n+        Asserts.assertEQ(res.hash(), test31_vt.hash());\n+    }\n+\n+    \/\/ getValue to retrieve flattened field from object at unknown\n+    \/\/ offset\n+    @Test(failOn=CALL_Unsafe)\n+    public MyValue1 test36(long offset) {\n+        if (TEST31_VT_FLATTENED) {\n+            return U.getValue(this, offset, MyValue1.val.class);\n+        }\n+        return (MyValue1)U.getReference(this, offset);\n+    }\n+\n+    @DontCompile\n+    public void test36_verifier(boolean warmup) {\n+        test31_vt = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1 res = test36(TEST31_VT_OFFSET);\n+        Asserts.assertEQ(res.hash(), test31_vt.hash());\n+    }\n+\n+    \/\/ putValue to set flattened field in object with unknown\n+    \/\/ container\n+    @Test(failOn=CALL_Unsafe)\n+    public void test37(Object o, MyValue1 vt) {\n+        if (TEST31_VT_FLATTENED) {\n+            U.putValue(o, TEST31_VT_OFFSET, MyValue1.val.class, vt);\n+        } else {\n+            U.putReference(o, TEST31_VT_OFFSET, vt);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        test31_vt = MyValue1.createDefaultInline();\n+        test37(this, vt);\n+        Asserts.assertEQ(vt.hash(), test31_vt.hash());\n+    }\n+\n+    \/\/ putValue to set flattened field in object, non inline argument\n+    \/\/ to store\n+    @Test(match = { CALL_Unsafe }, matchCount = { 1 })\n+    public void test38(Object o) {\n+        if (TEST31_VT_FLATTENED) {\n+            U.putValue(this, TEST31_VT_OFFSET, MyValue1.val.class, o);\n+        } else {\n+            U.putReference(this, TEST31_VT_OFFSET, o);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        test31_vt = MyValue1.createDefaultInline();\n+        test38(vt);\n+        Asserts.assertEQ(vt.hash(), test31_vt.hash());\n+    }\n+\n+    @Test(failOn=CALL_Unsafe)\n+    public MyValue1 test39(MyValue1 v) {\n+        v = U.makePrivateBuffer(v);\n+        U.putInt(v, X_OFFSET, rI);\n+        v = U.finishPrivateBuffer(v);\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1 res = test39(v.setX(v, 0));\n+        Asserts.assertEQ(res.hash(), v.hash());\n+    }\n+\n+    \/\/ Test default inline type array creation via reflection\n+    @Test()\n+    public Object[] test40(Class<?> componentType, int len) {\n+        Object[] va = (Object[])Array.newInstance(componentType, len);\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 42;\n+        Object[] va = test40(MyValue1.ref.class, len);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(va[i], null);\n+        }\n+    }\n+\n+    \/\/ Class.isInstance\n+    @Test()\n+    public boolean test41(Class c, MyValue1.ref vt) {\n+        return c.isInstance(vt);\n+    }\n+\n+    @DontCompile\n+    public void test41_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);\n+        boolean result = test41(MyValue1.ref.class, vt);\n+        Asserts.assertTrue(result);\n+        result = test41(MyValue1.class, vt);\n+        Asserts.assertTrue(result);\n+    }\n+\n+    @Test()\n+    public boolean test42(Class c, MyValue1.ref vt) {\n+        return c.isInstance(vt);\n+    }\n+\n+    @DontCompile\n+    public void test42_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);\n+        boolean result = test42(MyValue2.ref.class, vt);\n+        Asserts.assertFalse(result);\n+        result = test42(MyValue2.class, vt);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ Class.cast\n+    @Test()\n+    public Object test43(Class c, MyValue1.ref vt) {\n+        return c.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test43_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object result = test43(MyValue1.ref.class, vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+        result = test43(MyValue1.ref.class, null);\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    @Test()\n+    public Object test44(Class c, MyValue1.ref vt) {\n+        return c.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test44_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);\n+        try {\n+            test44(MyValue2.ref.class, vt);\n+            throw new RuntimeException(\"should have thrown\");\n+        } catch (ClassCastException cce) {\n+        }\n+    }\n+\n+    @Test()\n+    public Object test45(MyValue1.ref vt) {\n+        return MyValue1.ref.class.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test45_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object result = test45(vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+        result = test45(null);\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    @Test()\n+    public Object test46(MyValue1.ref vt) {\n+        return MyValue2.ref.class.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test46_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);\n+        test46(null);\n+        try {\n+            test46(vt);\n+            throw new RuntimeException(\"should have thrown\");\n+        } catch (ClassCastException cce) {\n+        }\n+    }\n+\n+    @Test()\n+    public Object test47(MyValue1.ref vt) {\n+        return MyValue1.val.class.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test47_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object result = test47(vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+        try {\n+            test47(null);\n+            throw new RuntimeException(\"should have thrown\");\n+        } catch (NullPointerException npe) {\n+        }\n+    }\n+\n+    @Test()\n+    public Object test48(Class c, MyValue1.ref vt) {\n+        return c.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test48_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object result = test48(MyValue1.class, vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+        try {\n+            test48(MyValue1.class, null);\n+            throw new RuntimeException(\"should have thrown\");\n+        } catch (NullPointerException npe) {\n+        }\n+    }\n+\n+    @Test()\n+    public Object test49(MyValue1 vt) {\n+        return MyValue1.ref.class.cast(vt);\n+    }\n+\n+    @DontCompile\n+    public void test49_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object result = test49(vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+    }\n+\n+    @Test()\n+    public Object test50(Class c, Object obj) {\n+        return c.cast(obj);\n+    }\n+\n+    @DontCompile\n+    public void test50_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1[] va  = new MyValue1[42];\n+        MyValue1.ref[] vba = new MyValue1.ref[42];\n+        Object result = test50(MyValue1.class, vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+        result = test50(MyValue1.ref.class, vt);\n+        Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());\n+        result = test50(MyValue1[].class, va);\n+        Asserts.assertEQ(result, va);\n+        result = test50(MyValue1.ref[].class, vba);\n+        Asserts.assertEQ(result, vba);\n+        result = test50(MyValue1.ref[].class, va);\n+        Asserts.assertEQ(result, va);\n+        try {\n+            test50(MyValue1.class, null);\n+            throw new RuntimeException(\"should have thrown\");\n+        } catch (NullPointerException npe) {\n+        }\n+        try {\n+            test50(MyValue1[].class, vba);\n+            throw new RuntimeException(\"should have thrown\");\n+        } catch (ClassCastException cce) {\n+        }\n+    }\n+\n+    \/\/ inline type array creation via reflection\n+    @Test()\n+    public void test51(int len) {\n+        Object[] va = (Object[])Array.newInstance(MyValue1.ref.class, len);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(va[i], null);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test51_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 42;\n+        test51(len);\n+    }\n+\n+    \/\/ multidimensional inline type array creation via reflection\n+    @Test()\n+    public Object[][] test52(int len, int val) {\n+        MyValue1[][] va1 = (MyValue1[][])Array.newInstance(MyValue1[].class, len);\n+        MyValue1.ref[][] va2 = (MyValue1.ref[][])Array.newInstance(MyValue1.ref[].class, len);\n+        Object[][] result;\n+        if (val == 1) {\n+            va1[0] = new MyValue1[1];\n+            result = va1;\n+        } else {\n+            va2[0] = new MyValue1.ref[1];\n+            result = va2;\n+        }\n+        if (val == 1) {\n+            Asserts.assertEQ(va1[0][0].hash(), ((MyValue1)result[0][0]).hash());\n+        } else {\n+            Asserts.assertEQ(result[0][0], null);\n+            result[0][0] = null;\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test52_verifier(boolean warmup) {\n+        test52(1, 1);\n+        test52(1, 2);\n+    }\n+\n+    @Test()\n+    public Object[][] test53(Class<?> c1, Class<?> c2, int len, int val) {\n+        MyValue1[][] va1 = (MyValue1[][])Array.newInstance(MyValue1[].class, len);\n+        MyValue1.ref[][] va2 = (MyValue1.ref[][])Array.newInstance(MyValue1.ref[].class, len);\n+        Object[][] va3 = (Object[][])Array.newInstance(c1, len);\n+        Object[][] va4 = (Object[][])Array.newInstance(c2, len);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(va1[i], null);\n+            Asserts.assertEQ(va2[i], null);\n+            Asserts.assertEQ(va3[i], null);\n+            Asserts.assertEQ(va4[i], null);\n+            va1[i] = new MyValue1[1];\n+            va2[i] = new MyValue1.ref[1];\n+            va3[i] = new MyValue1[1];\n+            va4[i] = new MyValue1.ref[1];\n+            Asserts.assertEQ(va1[i][0].hash(), ((MyValue1)va3[i][0]).hash());\n+            Asserts.assertEQ(va2[i][0], null);\n+            Asserts.assertEQ(va4[i][0], null);\n+        }\n+        Object[][] result;\n+        if (val == 1) {\n+            result = va1;\n+        } else if (val == 2) {\n+            result = va2;\n+        } else if (val == 3) {\n+            result = va3;\n+        } else {\n+            result = va4;\n+        }\n+        if ((val == 1 || val == 3) && len > 0) {\n+            Asserts.assertEQ(va1[0][0].hash(), ((MyValue1)result[0][0]).hash());\n+        } else if (len > 0) {\n+            Asserts.assertEQ(result[0][0], null);\n+            result[0][0] = null;\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test53_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 42;\n+        test53(MyValue1[].class, MyValue1.ref[].class, len, 1);\n+        test53(MyValue1[].class, MyValue1.ref[].class, len, 2);\n+        test53(MyValue1[].class, MyValue1.ref[].class, len, 3);\n+        test53(MyValue1[].class, MyValue1.ref[].class, len, 4);\n+    }\n+\n+    \/\/ Same as test39 but Unsafe.putInt to buffer is not intrinsified\/compiled\n+    @DontCompile\n+    public void test54_callee(MyValue1.ref v) { \/\/ Use .ref here to make sure the argument is not scalarized (otherwise larval information is lost)\n+        U.putInt(v, X_OFFSET, rI);\n+    }\n+\n+    @Test()\n+    @Warmup(10000) \/\/ Fill up the TLAB to trigger slow path allocation\n+    public MyValue1 test54(MyValue1 v) {\n+        v = U.makePrivateBuffer(v);\n+        test54_callee(v);\n+        v = U.finishPrivateBuffer(v);\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test54_verifier(boolean warmup) {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1 res = test54(v.setX(v, 0));\n+        Asserts.assertEQ(res.hash(), v.hash());\n+    }\n+\n+    static final MyValue1 test55_vt = MyValue1.createWithFieldsInline(rI, rL);\n+\n+    \/\/ Same as test30 but with constant field holder\n+    @Test(failOn=CALL_Unsafe)\n+    public MyValue2 test55() {\n+        if (V1_FLATTENED) {\n+            return U.getValue(test55_vt, V1_OFFSET, MyValue2.val.class);\n+        }\n+        return (MyValue2)U.getReference(test55_vt, V1_OFFSET);\n+    }\n+\n+    @DontCompile\n+    public void test55_verifier(boolean warmup) {\n+        MyValue2 res = test55();\n+        Asserts.assertEQ(res.hash(), test55_vt.v1.hash());\n+    }\n+\n+    \/\/ Test OptimizePtrCompare part of Escape Analysis\n+    @Test()\n+    public void test56(int idx) {\n+        Object[] va = (Object[])Array.newInstance(MyValue1.val.class, 1);\n+        if (va[idx] == null) {\n+            throw new RuntimeException(\"Unexpected null\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test56_verifier(boolean warmup) {\n+        test56(0);\n+    }\n+\n+    \/\/ Same as test56 but with load from known array index\n+    @Test()\n+    public void test57() {\n+        Object[] va = (Object[])Array.newInstance(MyValue1.val.class, 1);\n+        if (va[0] == null) {\n+            throw new RuntimeException(\"Unexpected null\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test57_verifier(boolean warmup) {\n+        test57();\n+    }\n+\n+    \/\/ Test unsafe allocation\n+    @Test()\n+    public boolean test58(Class<?> c1, Class<?> c2) throws Exception {\n+        Object obj1 = U.allocateInstance(c1);\n+        Object obj2 = U.allocateInstance(c2);\n+        return obj1 == obj2;\n+    }\n+\n+    @DontCompile\n+    public void test58_verifier(boolean warmup) throws Exception {\n+        boolean res = test58(MyValue1.class, MyValue1.class);\n+        Asserts.assertTrue(res);\n+        res = test58(Object.class, MyValue1.class);\n+        Asserts.assertFalse(res);\n+        res = test58(MyValue1.class, Object.class);\n+        Asserts.assertFalse(res);\n+    }\n+\n+    \/\/ Test synchronization on unsafe inline type allocation\n+    @Test()\n+    public void test59(Class<?> c) throws Exception {\n+        Object obj = U.allocateInstance(c);\n+        synchronized (obj) {\n+\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test59_verifier(boolean warmup) throws Exception {\n+        test59(Integer.class);\n+        try {\n+            test59(MyValue1.class);\n+            throw new RuntimeException(\"test59 failed: synchronization on inline type should not succeed\");\n+        } catch (IllegalMonitorStateException e) {\n+\n+        }\n+    }\n+\n+    \/\/ Test mark word load optimization on unsafe inline type allocation\n+    @Test()\n+    public boolean test60(Class<?> c1, Class<?> c2, boolean b1, boolean b2) throws Exception {\n+        Object obj1 = b1 ? new Object() : U.allocateInstance(c1);\n+        Object obj2 = b2 ? new Object() : U.allocateInstance(c2);\n+        return obj1 == obj2;\n+    }\n+\n+    @DontCompile\n+    public void test60_verifier(boolean warmup) throws Exception {\n+        Asserts.assertTrue(test60(MyValue1.class, MyValue1.class, false, false));\n+        Asserts.assertFalse(test60(MyValue1.class, MyValue2.class, false, false));\n+        Asserts.assertFalse(test60(MyValue1.class, MyValue1.class, false, true));\n+        Asserts.assertFalse(test60(MyValue1.class, MyValue1.class, true, false));\n+        Asserts.assertFalse(test60(MyValue1.class, MyValue1.class, true, true));\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestIntrinsics.java","additions":1133,"deletions":0,"binary":false,"changes":1133,"status":"added"},{"patch":"@@ -0,0 +1,119 @@\n+\/*\n+ * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.test.lib.Asserts;\n+\n+import java.lang.reflect.Method;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test calling native methods with inline type arguments from compiled code.\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestJNICalls.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestJNICalls\n+ *\/\n+public class TestJNICalls extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestJNICalls test = new TestJNICalls();\n+        test.run(args, MyValue1.class);\n+    }\n+\n+    static {\n+        System.loadLibrary(\"TestJNICalls\");\n+    }\n+\n+    public native Object testMethod1(MyValue1 o);\n+    public native long testMethod2(MyValue1 o);\n+\n+    \/\/ Pass an inline type to a native method that calls back into Java code and returns an inline type\n+    @Test\n+    @Warmup(10000) \/\/ Make sure native method is compiled\n+    public MyValue1 test1(MyValue1 vt, boolean callback) {\n+        if (!callback) {\n+          return (MyValue1)testMethod1(vt);\n+        } else {\n+          return vt;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1 result = test1(vt, false);\n+        Asserts.assertEQ(result.hash(), vt.hash());\n+        result = test1(vt, true);\n+        Asserts.assertEQ(result.hash(), vt.hash());\n+    }\n+\n+    \/\/ Pass an inline type to a native method that calls the hash method and returns the result\n+    @Test\n+    @Warmup(10000) \/\/ Make sure native method is compiled\n+    public long test2(MyValue1 vt) {\n+        return testMethod2(vt);\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        long result = test2(vt);\n+        Asserts.assertEQ(result, vt.hash());\n+    }\n+\n+    static primitive class MyValueWithNative {\n+        public final int x;\n+\n+        private MyValueWithNative(int x) {\n+            this.x = x;\n+        }\n+\n+        public native int testMethod3();\n+    }\n+\n+    \/\/ Call a native method with an inline type receiver\n+    @Test\n+    @Warmup(10000) \/\/ Make sure native method is compiled\n+    public int test3(MyValueWithNative vt) {\n+        return vt.testMethod3();\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        MyValueWithNative vt = new MyValueWithNative(rI);\n+        int result = test3(vt);\n+        Asserts.assertEQ(result, rI);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestJNICalls.java","additions":119,"deletions":0,"binary":false,"changes":119,"status":"added"},{"patch":"@@ -0,0 +1,3783 @@\n+\/*\n+ * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+import java.util.Arrays;\n+\n+import jdk.test.lib.Asserts;\n+import test.java.lang.invoke.lib.InstructionHelper;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test inline types in LWorld.\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common \/testlibrary \/compiler\/whitebox \/\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestLWorld.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestLWorld\n+ *\/\n+public class TestLWorld extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 2: return new String[] {\"-DVerifyIR=false\"};\n+        case 3: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:FlatArrayElementMaxSize=-1\"};\n+        case 4: return new String[] {\"-XX:-MonomorphicArrayCheck\"};\n+        }\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        \/\/ Make sure Test140Value is loaded but not linked\n+        Class<?> class1 = Test140Value.class;\n+        \/\/ Make sure Test141Value is linked but not initialized\n+        Class<?> class2 = Test141Value.class;\n+        class2.getDeclaredFields();\n+\n+        TestLWorld test = new TestLWorld();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class, MyValue3.class,\n+                 MyValue3Inline.class, Test51Value.class);\n+    }\n+\n+    \/\/ Helper methods\n+\n+    private static final MyValue1 testValue1 = MyValue1.createWithFieldsInline(rI, rL);\n+    private static final MyValue2 testValue2 = MyValue2.createWithFieldsInline(rI, rD);\n+\n+    protected long hash() {\n+        return testValue1.hash();\n+    }\n+\n+    \/\/ Test passing an inline type as an Object\n+    @DontInline\n+    public Object test1_dontinline1(Object o) {\n+        return o;\n+    }\n+\n+    @DontInline\n+    public MyValue1 test1_dontinline2(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @ForceInline\n+    public Object test1_inline1(Object o) {\n+        return o;\n+    }\n+\n+    @ForceInline\n+    public MyValue1 test1_inline2(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test()\n+    public MyValue1 test1() {\n+        MyValue1 vt = testValue1;\n+        vt = (MyValue1)test1_dontinline1(vt);\n+        vt =           test1_dontinline2(vt);\n+        vt = (MyValue1)test1_inline1(vt);\n+        vt =           test1_inline2(vt);\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        Asserts.assertEQ(test1().hash(), hash());\n+    }\n+\n+    \/\/ Test storing\/loading inline types to\/from Object and inline type fields\n+    Object objectField1 = null;\n+    Object objectField2 = null;\n+    Object objectField3 = null;\n+    Object objectField4 = null;\n+    Object objectField5 = null;\n+    Object objectField6 = null;\n+\n+    MyValue1 valueField1 = testValue1;\n+    MyValue1 valueField2 = testValue1;\n+    MyValue1.ref valueField3 = testValue1;\n+    MyValue1 valueField4;\n+    MyValue1.ref valueField5;\n+\n+    static MyValue1.ref staticValueField1 = testValue1;\n+    static MyValue1 staticValueField2 = testValue1;\n+    static MyValue1 staticValueField3;\n+    static MyValue1.ref staticValueField4;\n+\n+    @DontInline\n+    public Object readValueField5() {\n+        return (Object)valueField5;\n+    }\n+\n+    @DontInline\n+    public Object readStaticValueField4() {\n+        return (Object)staticValueField4;\n+    }\n+\n+    @Test()\n+    public long test2(MyValue1 vt1, Object vt2) {\n+        objectField1 = vt1;\n+        objectField2 = (MyValue1)vt2;\n+        objectField3 = testValue1;\n+        objectField4 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        objectField5 = valueField1;\n+        objectField6 = valueField3;\n+        valueField1 = (MyValue1)objectField1;\n+        valueField2 = (MyValue1)vt2;\n+        valueField3 = (MyValue1)vt2;\n+        staticValueField1 = (MyValue1)objectField1;\n+        staticValueField2 = (MyValue1)vt1;\n+        \/\/ Don't inline these methods because reading NULL will trigger a deoptimization\n+        if (readValueField5() != null || readStaticValueField4() != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+        return ((MyValue1)objectField1).hash() + ((MyValue1)objectField2).hash() +\n+               ((MyValue1)objectField3).hash() + ((MyValue1)objectField4).hash() +\n+               ((MyValue1)objectField5).hash() + ((MyValue1)objectField6).hash() +\n+                valueField1.hash() + valueField2.hash() + valueField3.hash() + valueField4.hashPrimitive() +\n+                staticValueField1.hash() + staticValueField2.hash() + staticValueField3.hashPrimitive();\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        MyValue1 def = MyValue1.createDefaultDontInline();\n+        long result = test2(vt, vt);\n+        Asserts.assertEQ(result, 11*vt.hash() + 2*def.hashPrimitive());\n+    }\n+\n+    \/\/ Test merging inline types and objects\n+    @Test()\n+    public Object test3(int state) {\n+        Object res = null;\n+        if (state == 0) {\n+            res = Integer.valueOf(rI);\n+        } else if (state == 1) {\n+            res = MyValue1.createWithFieldsInline(rI, rL);\n+        } else if (state == 2) {\n+            res = MyValue1.createWithFieldsDontInline(rI, rL);\n+        } else if (state == 3) {\n+            res = (MyValue1)objectField1;\n+        } else if (state == 4) {\n+            res = valueField1;\n+        } else if (state == 5) {\n+            res = null;\n+        } else if (state == 6) {\n+            res = MyValue2.createWithFieldsInline(rI, rD);\n+        } else if (state == 7) {\n+            res = testValue2;\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        objectField1 = valueField1;\n+        Object result = null;\n+        result = test3(0);\n+        Asserts.assertEQ((Integer)result, rI);\n+        result = test3(1);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test3(2);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test3(3);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test3(4);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test3(5);\n+        Asserts.assertEQ(result, null);\n+        result = test3(6);\n+        Asserts.assertEQ(((MyValue2)result).hash(), testValue2.hash());\n+        result = test3(7);\n+        Asserts.assertEQ(((MyValue2)result).hash(), testValue2.hash());\n+    }\n+\n+    \/\/ Test merging inline types and objects in loops\n+    @Test()\n+    public Object test4(int iters) {\n+        Object res = Integer.valueOf(rI);\n+        for (int i = 0; i < iters; ++i) {\n+            if (res instanceof Integer) {\n+                res = MyValue1.createWithFieldsInline(rI, rL);\n+            } else {\n+                res = MyValue1.createWithFieldsInline(((MyValue1)res).x + 1, rL);\n+            }\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        Integer result1 = (Integer)test4(0);\n+        Asserts.assertEQ(result1, rI);\n+        int iters = (Math.abs(rI) % 10) + 1;\n+        MyValue1 result2 = (MyValue1)test4(iters);\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + iters - 1, rL);\n+        Asserts.assertEQ(result2.hash(), vt.hash());\n+    }\n+\n+    \/\/ Test inline types in object variables that are live at safepoint\n+    @Test(failOn = ALLOC + STORE + LOOP)\n+    public long test5(MyValue1 arg, boolean deopt) {\n+        Object vt1 = MyValue1.createWithFieldsInline(rI, rL);\n+        Object vt2 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        Object vt3 = arg;\n+        Object vt4 = valueField1;\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test5\"));\n+        }\n+        return ((MyValue1)vt1).hash() + ((MyValue1)vt2).hash() +\n+               ((MyValue1)vt3).hash() + ((MyValue1)vt4).hash();\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        long result = test5(valueField1, !warmup);\n+        Asserts.assertEQ(result, 4*hash());\n+    }\n+\n+    \/\/ Test comparing inline types with objects\n+    @Test(failOn = LOAD + LOOP)\n+    public boolean test6(Object arg) {\n+        Object vt = MyValue1.createWithFieldsInline(rI, rL);\n+        if (vt == arg || vt == (Object)valueField1 || vt == objectField1 || vt == null ||\n+            arg == vt || (Object)valueField1 == vt || objectField1 == vt || null == vt) {\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        boolean result = test6(null);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ merge of inline type and non-inline type\n+    @Test\n+    public Object test7(boolean flag) {\n+        Object res = null;\n+        if (flag) {\n+            res = valueField1;\n+        } else {\n+            res = objectField1;\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        test7(true);\n+        test7(false);\n+    }\n+\n+    @Test\n+    public Object test8(boolean flag) {\n+        Object res = null;\n+        if (flag) {\n+            res = objectField1;\n+        } else {\n+            res = valueField1;\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        test8(true);\n+        test8(false);\n+    }\n+\n+    \/\/ merge of inline types in a loop, stored in an object local\n+    @Test\n+    public Object test9() {\n+        Object o = valueField1;\n+        for (int i = 1; i < 100; i *= 2) {\n+            MyValue1 v = (MyValue1)o;\n+            o = MyValue1.setX(v, v.x + 1);\n+        }\n+        return o;\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        test9();\n+    }\n+\n+    \/\/ merge of inline types in an object local\n+    @ForceInline\n+    public Object test10_helper() {\n+        return valueField1;\n+    }\n+\n+    @Test(failOn = ALLOC + LOAD + STORE)\n+    public void test10(boolean flag) {\n+        Object o = null;\n+        if (flag) {\n+            o = valueField1;\n+        } else {\n+            o = test10_helper();\n+        }\n+        valueField1 = (MyValue1)o;\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        test10(true);\n+        test10(false);\n+    }\n+\n+    \/\/ Interface tests\n+\n+    @DontInline\n+    public MyInterface test11_dontinline1(MyInterface o) {\n+        return o;\n+    }\n+\n+    @DontInline\n+    public MyValue1 test11_dontinline2(MyInterface o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @ForceInline\n+    public MyInterface test11_inline1(MyInterface o) {\n+        return o;\n+    }\n+\n+    @ForceInline\n+    public MyValue1 test11_inline2(MyInterface o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test()\n+    public MyValue1 test11() {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        vt = (MyValue1)test11_dontinline1(vt);\n+        vt =           test11_dontinline2(vt);\n+        vt = (MyValue1)test11_inline1(vt);\n+        vt =           test11_inline2(vt);\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        Asserts.assertEQ(test11().hash(), hash());\n+    }\n+\n+    \/\/ Test storing\/loading inline types to\/from interface and inline type fields\n+    MyInterface interfaceField1 = null;\n+    MyInterface interfaceField2 = null;\n+    MyInterface interfaceField3 = null;\n+    MyInterface interfaceField4 = null;\n+    MyInterface interfaceField5 = null;\n+    MyInterface interfaceField6 = null;\n+\n+    @DontInline\n+    public MyInterface readValueField5AsInterface() {\n+        return (MyInterface)valueField5;\n+    }\n+\n+    @DontInline\n+    public MyInterface readStaticValueField4AsInterface() {\n+        return (MyInterface)staticValueField4;\n+    }\n+\n+    @Test()\n+    public long test12(MyValue1 vt1, MyInterface vt2) {\n+        interfaceField1 = vt1;\n+        interfaceField2 = (MyValue1)vt2;\n+        interfaceField3 = MyValue1.createWithFieldsInline(rI, rL);\n+        interfaceField4 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        interfaceField5 = valueField1;\n+        interfaceField6 = valueField3;\n+        valueField1 = (MyValue1)interfaceField1;\n+        valueField2 = (MyValue1)vt2;\n+        valueField3 = (MyValue1)vt2;\n+        staticValueField1 = (MyValue1)interfaceField1;\n+        staticValueField2 = (MyValue1)vt1;\n+        \/\/ Don't inline these methods because reading NULL will trigger a deoptimization\n+        if (readValueField5AsInterface() != null || readStaticValueField4AsInterface() != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+        return ((MyValue1)interfaceField1).hash() + ((MyValue1)interfaceField2).hash() +\n+               ((MyValue1)interfaceField3).hash() + ((MyValue1)interfaceField4).hash() +\n+               ((MyValue1)interfaceField5).hash() + ((MyValue1)interfaceField6).hash() +\n+                valueField1.hash() + valueField2.hash() + valueField3.hash() + valueField4.hashPrimitive() +\n+                staticValueField1.hash() + staticValueField2.hash() + staticValueField3.hashPrimitive();\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        MyValue1 def = MyValue1.createDefaultDontInline();\n+        long result = test12(vt, vt);\n+        Asserts.assertEQ(result, 11*vt.hash() + 2*def.hashPrimitive());\n+    }\n+\n+    class MyObject1 implements MyInterface {\n+        public int x;\n+\n+        public MyObject1(int x) {\n+            this.x = x;\n+        }\n+\n+        @ForceInline\n+        public long hash() {\n+            return x;\n+        }\n+    }\n+\n+    \/\/ Test merging inline types and interfaces\n+    @Test()\n+    public MyInterface test13(int state) {\n+        MyInterface res = null;\n+        if (state == 0) {\n+            res = new MyObject1(rI);\n+        } else if (state == 1) {\n+            res = MyValue1.createWithFieldsInline(rI, rL);\n+        } else if (state == 2) {\n+            res = MyValue1.createWithFieldsDontInline(rI, rL);\n+        } else if (state == 3) {\n+            res = (MyValue1)objectField1;\n+        } else if (state == 4) {\n+            res = valueField1;\n+        } else if (state == 5) {\n+            res = null;\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        objectField1 = valueField1;\n+        MyInterface result = null;\n+        result = test13(0);\n+        Asserts.assertEQ(((MyObject1)result).x, rI);\n+        result = test13(1);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test13(2);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test13(3);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test13(4);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test13(5);\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    \/\/ Test merging inline types and interfaces in loops\n+    @Test()\n+    public MyInterface test14(int iters) {\n+        MyInterface res = new MyObject1(rI);\n+        for (int i = 0; i < iters; ++i) {\n+            if (res instanceof MyObject1) {\n+                res = MyValue1.createWithFieldsInline(rI, rL);\n+            } else {\n+                res = MyValue1.createWithFieldsInline(((MyValue1)res).x + 1, rL);\n+            }\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean warmup) {\n+        MyObject1 result1 = (MyObject1)test14(0);\n+        Asserts.assertEQ(result1.x, rI);\n+        int iters = (Math.abs(rI) % 10) + 1;\n+        MyValue1 result2 = (MyValue1)test14(iters);\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + iters - 1, rL);\n+        Asserts.assertEQ(result2.hash(), vt.hash());\n+    }\n+\n+    \/\/ Test inline types in interface variables that are live at safepoint\n+    @Test(failOn = ALLOC + STORE + LOOP)\n+    public long test15(MyValue1 arg, boolean deopt) {\n+        MyInterface vt1 = MyValue1.createWithFieldsInline(rI, rL);\n+        MyInterface vt2 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyInterface vt3 = arg;\n+        MyInterface vt4 = valueField1;\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test15\"));\n+        }\n+        return ((MyValue1)vt1).hash() + ((MyValue1)vt2).hash() +\n+               ((MyValue1)vt3).hash() + ((MyValue1)vt4).hash();\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean warmup) {\n+        long result = test15(valueField1, !warmup);\n+        Asserts.assertEQ(result, 4*hash());\n+    }\n+\n+    \/\/ Test comparing inline types with interfaces\n+    @Test(failOn = LOAD + LOOP)\n+    public boolean test16(Object arg) {\n+        MyInterface vt = MyValue1.createWithFieldsInline(rI, rL);\n+        if (vt == arg || vt == (MyInterface)valueField1 || vt == interfaceField1 || vt == null ||\n+            arg == vt || (MyInterface)valueField1 == vt || interfaceField1 == vt || null == vt) {\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean warmup) {\n+        boolean result = test16(null);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ Test subtype check when casting to inline type\n+    @Test\n+    public MyValue1 test17(MyValue1 vt, Object obj) {\n+        try {\n+            vt = (MyValue1)obj;\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        MyValue1 result = test17(vt, Integer.valueOf(rI));\n+        Asserts.assertEquals(result.hash(), vt.hash());\n+    }\n+\n+    @Test\n+    public MyValue1 test18(MyValue1 vt) {\n+        Object obj = vt;\n+        vt = (MyValue1)obj;\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        MyValue1 result = test18(vt);\n+        Asserts.assertEquals(result.hash(), vt.hash());\n+    }\n+\n+    @Test\n+    public void test19(MyValue1 vt) {\n+        Object obj = vt;\n+        try {\n+            MyValue2 vt2 = (MyValue2)obj;\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        test19(valueField1);\n+    }\n+\n+    @Test\n+    public void test20(MyValue1 vt) {\n+        Object obj = vt;\n+        try {\n+            Integer i = (Integer)obj;\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        test20(valueField1);\n+    }\n+\n+    \/\/ Array tests\n+\n+    private static final MyValue1[] testValue1Array = new MyValue1[] {testValue1,\n+                                                                      testValue1,\n+                                                                      testValue1};\n+\n+    private static final MyValue1[][] testValue1Array2 = new MyValue1[][] {testValue1Array,\n+                                                                           testValue1Array,\n+                                                                           testValue1Array};\n+\n+    private static final MyValue2[] testValue2Array = new MyValue2[] {testValue2,\n+                                                                      testValue2,\n+                                                                      testValue2};\n+\n+    private static final Integer[] testIntegerArray = new Integer[42];\n+\n+    \/\/ Test load from (flattened) inline type array disguised as object array\n+    @Test()\n+    public Object test21(Object[] oa, int index) {\n+        return oa[index];\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        MyValue1 result = (MyValue1)test21(testValue1Array, Math.abs(rI) % 3);\n+        Asserts.assertEQ(result.hash(), hash());\n+    }\n+\n+    \/\/ Test load from (flattened) inline type array disguised as interface array\n+    @Test()\n+    public Object test22Interface(MyInterface[] ia, int index) {\n+        return ia[index];\n+    }\n+\n+    @DontCompile\n+    public void test22Interface_verifier(boolean warmup) {\n+        MyValue1 result = (MyValue1)test22Interface(testValue1Array, Math.abs(rI) % 3);\n+        Asserts.assertEQ(result.hash(), hash());\n+    }\n+\n+    \/\/ Test load from (flattened) inline type array disguised as abstract array\n+    @Test()\n+    public Object test22Abstract(MyAbstract[] ia, int index) {\n+        return ia[index];\n+    }\n+\n+    @DontCompile\n+    public void test22Abstract_verifier(boolean warmup) {\n+        MyValue1 result = (MyValue1)test22Abstract(testValue1Array, Math.abs(rI) % 3);\n+        Asserts.assertEQ(result.hash(), hash());\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as object array\n+    @ForceInline\n+    public void test23_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test23(Object[] oa, MyValue1 vt, int index) {\n+        test23_inline(oa, vt, index);\n+    }\n+\n+    @DontCompile\n+    public void test23_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test23(testValue1Array, vt, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt.hash());\n+        testValue1Array[index] = testValue1;\n+        try {\n+            test23(testValue2Array, vt, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue2Array[index].hash(), testValue2.hash());\n+    }\n+\n+    @ForceInline\n+    public void test24_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test24(Object[] oa, MyValue1 vt, int index) {\n+        test24_inline(oa, vt, index);\n+    }\n+\n+    @DontCompile\n+    public void test24_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test24(testIntegerArray, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @ForceInline\n+    public void test25_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test25(Object[] oa, MyValue1 vt, int index) {\n+        test25_inline(oa, vt, index);\n+    }\n+\n+    @DontCompile\n+    public void test25_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test25(null, testValue1, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as interface array\n+    @ForceInline\n+    public void test26Interface_inline(MyInterface[] ia, MyInterface i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test()\n+    public void test26Interface(MyInterface[] ia, MyValue1 vt, int index) {\n+      test26Interface_inline(ia, vt, index);\n+    }\n+\n+    @DontCompile\n+    public void test26Interface_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test26Interface(testValue1Array, vt, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt.hash());\n+        testValue1Array[index] = testValue1;\n+        try {\n+            test26Interface(testValue2Array, vt, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue2Array[index].hash(), testValue2.hash());\n+    }\n+\n+    @ForceInline\n+    public void test27Interface_inline(MyInterface[] ia, MyInterface i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test()\n+    public void test27Interface(MyInterface[] ia, MyValue1 vt, int index) {\n+        test27Interface_inline(ia, vt, index);\n+    }\n+\n+    @DontCompile\n+    public void test27Interface_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test27Interface(null, testValue1, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as abstract array\n+    @ForceInline\n+    public void test26Abstract_inline(MyAbstract[] ia, MyAbstract i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test()\n+    public void test26Abstract(MyAbstract[] ia, MyValue1 vt, int index) {\n+      test26Abstract_inline(ia, vt, index);\n+    }\n+\n+    @DontCompile\n+    public void test26Abstract_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test26Abstract(testValue1Array, vt, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt.hash());\n+        testValue1Array[index] = testValue1;\n+        try {\n+            test26Abstract(testValue2Array, vt, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue2Array[index].hash(), testValue2.hash());\n+    }\n+\n+    @ForceInline\n+    public void test27Abstract_inline(MyAbstract[] ia, MyAbstract i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test()\n+    public void test27Abstract(MyAbstract[] ia, MyValue1 vt, int index) {\n+        test27Abstract_inline(ia, vt, index);\n+    }\n+\n+    @DontCompile\n+    public void test27Abstract_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test27Abstract(null, testValue1, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test object store to (flattened) inline type array disguised as object array\n+    @ForceInline\n+    public void test28_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test28(Object[] oa, Object o, int index) {\n+        test28_inline(oa, o, index);\n+    }\n+\n+    @DontCompile\n+    public void test28_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test28(testValue1Array, vt1, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        try {\n+            test28(testValue1Array, testValue2, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        testValue1Array[index] = testValue1;\n+    }\n+\n+    @ForceInline\n+    public void test29_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test29(Object[] oa, Object o, int index) {\n+        test29_inline(oa, o, index);\n+    }\n+\n+    @DontCompile\n+    public void test29_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test29(testValue2Array, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue2Array[index].hash(), testValue2.hash());\n+    }\n+\n+    @ForceInline\n+    public void test30_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test30(Object[] oa, Object o, int index) {\n+        test30_inline(oa, o, index);\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test30(testIntegerArray, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as interface array\n+    @ForceInline\n+    public void test31Interface_inline(MyInterface[] ia, MyInterface i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test()\n+    public void test31Interface(MyInterface[] ia, MyInterface i, int index) {\n+        test31Interface_inline(ia, i, index);\n+    }\n+\n+    @DontCompile\n+    public void test31Interface_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test31Interface(testValue1Array, vt1, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        try {\n+            test31Interface(testValue1Array, testValue2, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        testValue1Array[index] = testValue1;\n+    }\n+\n+    @ForceInline\n+    public void test32Interface_inline(MyInterface[] ia, MyInterface i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test()\n+    public void test32Interface(MyInterface[] ia, MyInterface i, int index) {\n+        test32Interface_inline(ia, i, index);\n+    }\n+\n+    @DontCompile\n+    public void test32Interface_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test32Interface(testValue2Array, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test inline store to (flattened) inline type array disguised as abstract array\n+    @ForceInline\n+    public void test31Abstract_inline(MyAbstract[] ia, MyAbstract i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test()\n+    public void test31Abstract(MyAbstract[] ia, MyAbstract i, int index) {\n+        test31Abstract_inline(ia, i, index);\n+    }\n+\n+    @DontCompile\n+    public void test31Abstract_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test31Abstract(testValue1Array, vt1, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        try {\n+            test31Abstract(testValue1Array, testValue2, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        testValue1Array[index] = testValue1;\n+    }\n+\n+    @ForceInline\n+    public void test32Abstract_inline(MyAbstract[] ia, MyAbstract i, int index) {\n+        ia[index] = i;\n+    }\n+\n+    @Test()\n+    public void test32Abstract(MyAbstract[] ia, MyAbstract i, int index) {\n+        test32Abstract_inline(ia, i, index);\n+    }\n+\n+    @DontCompile\n+    public void test32Abstract_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test32Abstract(testValue2Array, testValue1, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test writing null to a (flattened) inline type array disguised as object array\n+    @ForceInline\n+    public void test33_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test33(Object[] oa, Object o, int index) {\n+        test33_inline(oa, o, index);\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test33(testValue1Array, null, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ Test writing constant null to a (flattened) inline type array disguised as object array\n+\n+    @ForceInline\n+    public void test34_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test34(Object[] oa, int index) {\n+        test34_inline(oa, null, index);\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test34(testValue1Array, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ Test writing constant null to a (flattened) inline type array\n+\n+    private static final MethodHandle setArrayElementNull = InstructionHelper.loadCode(MethodHandles.lookup(),\n+        \"setArrayElementNull\",\n+        MethodType.methodType(void.class, TestLWorld.class, MyValue1[].class, int.class),\n+        CODE -> {\n+            CODE.\n+            aload_1().\n+            iload_2().\n+            aconst_null().\n+            aastore().\n+            return_();\n+        });\n+\n+    @Test()\n+    public void test35(MyValue1[] va, int index) throws Throwable {\n+        setArrayElementNull.invoke(this, va, index);\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) throws Throwable {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test35(testValue1Array, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ Test writing an inline type to a null inline type array\n+    @Test()\n+    public void test36(MyValue1[] va, MyValue1 vt, int index) {\n+        va[index] = vt;\n+    }\n+\n+    @DontCompile\n+    public void test36_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test36(null, testValue1Array[index], index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test incremental inlining\n+    @ForceInline\n+    public void test37_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test37(MyValue1[] va, Object o, int index) {\n+        test37_inline(va, o, index);\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        test37(testValue1Array, vt1, index);\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        try {\n+            test37(testValue1Array, testValue2, index);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), vt1.hash());\n+        testValue1Array[index] = testValue1;\n+    }\n+\n+    \/\/ Test merging of inline type arrays\n+\n+    @ForceInline\n+    public Object[] test38_inline() {\n+        return new MyValue1[42];\n+    }\n+\n+    @Test()\n+    public Object[] test38(Object[] oa, Object o, int i1, int i2, int num) {\n+        Object[] result = null;\n+        switch (num) {\n+        case 0:\n+            result = test38_inline();\n+            break;\n+        case 1:\n+            result = oa;\n+            break;\n+        case 2:\n+            result = testValue1Array;\n+            break;\n+        case 3:\n+            result = testValue2Array;\n+            break;\n+        case 4:\n+            result = testIntegerArray;\n+            break;\n+        case 5:\n+            result = null;\n+            break;\n+        case 6:\n+            result = testValue1Array2;\n+            break;\n+        }\n+        result[i1] = result[i2];\n+        result[i2] = o;\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1[] va = new MyValue1[42];\n+        Object[] result = test38(null, testValue1, index, index, 0);\n+        Asserts.assertEQ(((MyValue1)result[index]).hash(), testValue1.hash());\n+        result = test38(testValue1Array, testValue1, index, index, 1);\n+        Asserts.assertEQ(((MyValue1)result[index]).hash(), testValue1.hash());\n+        result = test38(null, testValue1, index, index, 2);\n+        Asserts.assertEQ(((MyValue1)result[index]).hash(), testValue1.hash());\n+        result = test38(null, testValue2, index, index, 3);\n+        Asserts.assertEQ(((MyValue2)result[index]).hash(), testValue2.hash());\n+        try {\n+            result = test38(null, null, index, index, 3);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        result = test38(null, null, index, index, 4);\n+        try {\n+            result = test38(null, testValue1, index, index, 4);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            result = test38(null, testValue1, index, index, 5);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        result = test38(null, testValue1Array, index, index, 6);\n+        Asserts.assertEQ(((MyValue1[][])result)[index][index].hash(), testValue1.hash());\n+    }\n+\n+    @ForceInline\n+    public Object test39_inline() {\n+        return new MyValue1[42];\n+    }\n+\n+    \/\/ Same as above but merging into Object instead of Object[]\n+    @Test()\n+    public Object test39(Object oa, Object o, int i1, int i2, int num) {\n+        Object result = null;\n+        switch (num) {\n+        case 0:\n+            result = test39_inline();\n+            break;\n+        case 1:\n+            result = oa;\n+            break;\n+        case 2:\n+            result = testValue1Array;\n+            break;\n+        case 3:\n+            result = testValue2Array;\n+            break;\n+        case 4:\n+            result = testIntegerArray;\n+            break;\n+        case 5:\n+            result = null;\n+            break;\n+        case 6:\n+            result = testValue1;\n+            break;\n+        case 7:\n+            result = testValue2;\n+            break;\n+        case 8:\n+            result = MyValue1.createWithFieldsInline(rI, rL);\n+            break;\n+        case 9:\n+            result = Integer.valueOf(42);\n+            break;\n+        case 10:\n+            result = testValue1Array2;\n+            break;\n+        }\n+        if (result instanceof Object[]) {\n+            ((Object[])result)[i1] = ((Object[])result)[i2];\n+            ((Object[])result)[i2] = o;\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        MyValue1[] va = new MyValue1[42];\n+        Object result = test39(null, testValue1, index, index, 0);\n+        Asserts.assertEQ(((MyValue1[])result)[index].hash(), testValue1.hash());\n+        result = test39(testValue1Array, testValue1, index, index, 1);\n+        Asserts.assertEQ(((MyValue1[])result)[index].hash(), testValue1.hash());\n+        result = test39(null, testValue1, index, index, 2);\n+        Asserts.assertEQ(((MyValue1[])result)[index].hash(), testValue1.hash());\n+        result = test39(null, testValue2, index, index, 3);\n+        Asserts.assertEQ(((MyValue2[])result)[index].hash(), testValue2.hash());\n+        try {\n+            result = test39(null, null, index, index, 3);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        result = test39(null, null, index, index, 4);\n+        try {\n+            result = test39(null, testValue1, index, index, 4);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        result = test39(null, testValue1, index, index, 5);\n+        Asserts.assertEQ(result, null);\n+        result = test39(null, testValue1, index, index, 6);\n+        Asserts.assertEQ(((MyValue1)result).hash(), testValue1.hash());\n+        result = test39(null, testValue1, index, index, 7);\n+        Asserts.assertEQ(((MyValue2)result).hash(), testValue2.hash());\n+        result = test39(null, testValue1, index, index, 8);\n+        Asserts.assertEQ(((MyValue1)result).hash(), testValue1.hash());\n+        result = test39(null, testValue1, index, index, 9);\n+        Asserts.assertEQ(((Integer)result), 42);\n+        result = test39(null, testValue1Array, index, index, 10);\n+        Asserts.assertEQ(((MyValue1[][])result)[index][index].hash(), testValue1.hash());\n+    }\n+\n+    \/\/ Test instanceof with inline types and arrays\n+    @Test()\n+    public long test40(Object o, int index) {\n+        if (o instanceof MyValue1) {\n+          return ((MyValue1)o).hashInterpreted();\n+        } else if (o instanceof MyValue1[]) {\n+          return ((MyValue1[])o)[index].hashInterpreted();\n+        } else if (o instanceof MyValue2) {\n+          return ((MyValue2)o).hash();\n+        } else if (o instanceof MyValue2[]) {\n+          return ((MyValue2[])o)[index].hash();\n+        } else if (o instanceof MyValue1[][]) {\n+          return ((MyValue1[][])o)[index][index].hash();\n+        } else if (o instanceof Long) {\n+          return (long)o;\n+        }\n+        return 0;\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        long result = test40(testValue1, 0);\n+        Asserts.assertEQ(result, testValue1.hash());\n+        result = test40(testValue1Array, index);\n+        Asserts.assertEQ(result, testValue1.hash());\n+        result = test40(testValue2, index);\n+        Asserts.assertEQ(result, testValue2.hash());\n+        result = test40(testValue2Array, index);\n+        Asserts.assertEQ(result, testValue2.hash());\n+        result = test40(testValue1Array2, index);\n+        Asserts.assertEQ(result, testValue1.hash());\n+        result = test40(Long.valueOf(42), index);\n+        Asserts.assertEQ(result, 42L);\n+    }\n+\n+    \/\/ Test for bug in Escape Analysis\n+    @DontInline\n+    public void test41_dontinline(Object o) {\n+        Asserts.assertEQ(o, rI);\n+    }\n+\n+    @Test()\n+    public void test41() {\n+        MyValue1[] vals = new MyValue1[] {testValue1};\n+        test41_dontinline(vals[0].oa[0]);\n+        test41_dontinline(vals[0].oa[0]);\n+    }\n+\n+    @DontCompile\n+    public void test41_verifier(boolean warmup) {\n+        test41();\n+    }\n+\n+    \/\/ Test for bug in Escape Analysis\n+    private static final MyValue1.ref test42VT1 = MyValue1.createWithFieldsInline(rI, rL);\n+    private static final MyValue1.ref test42VT2 = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+\n+    @Test()\n+    public void test42() {\n+        MyValue1[] vals = new MyValue1[] {(MyValue1) test42VT1, (MyValue1) test42VT2};\n+        Asserts.assertEQ(vals[0].hash(), test42VT1.hash());\n+        Asserts.assertEQ(vals[1].hash(), test42VT2.hash());\n+    }\n+\n+    @DontCompile\n+    public void test42_verifier(boolean warmup) {\n+        if (!warmup) test42(); \/\/ We need -Xcomp behavior\n+    }\n+\n+    \/\/ Test for bug in Escape Analysis\n+    @Test()\n+    public long test43(boolean deopt) {\n+        MyValue1[] vals = new MyValue1[] {(MyValue1) test42VT1, (MyValue1) test42VT2};\n+\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test43\"));\n+            Asserts.assertEQ(vals[0].hash(), test42VT1.hash());\n+            Asserts.assertEQ(vals[1].hash(), test42VT2.hash());\n+        }\n+\n+        return vals[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test43_verifier(boolean warmup) {\n+        test43(!warmup);\n+    }\n+\n+    \/\/ Tests writing an array element with a (statically known) incompatible type\n+    private static final MethodHandle setArrayElementIncompatible = InstructionHelper.loadCode(MethodHandles.lookup(),\n+        \"setArrayElementIncompatible\",\n+        MethodType.methodType(void.class, TestLWorld.class, MyValue1[].class, int.class, MyValue2.class),\n+        CODE -> {\n+            CODE.\n+            aload_1().\n+            iload_2().\n+            aload_3().\n+            aastore().\n+            return_();\n+        });\n+\n+    @Test()\n+    public void test44(MyValue1[] va, int index, MyValue2 v) throws Throwable {\n+        setArrayElementIncompatible.invoke(this, va, index, v);\n+    }\n+\n+    @DontCompile\n+    public void test44_verifier(boolean warmup) throws Throwable {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test44(testValue1Array, index, testValue2);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ Tests writing an array element with a (statically known) incompatible type\n+    @ForceInline\n+    public void test45_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test45(MyValue1[] va, int index, MyValue2 v) throws Throwable {\n+        test45_inline(va, v, index);\n+    }\n+\n+    @DontCompile\n+    public void test45_verifier(boolean warmup) throws Throwable {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test45(testValue1Array, index, testValue2);\n+            throw new RuntimeException(\"No ArrayStoreException thrown\");\n+        } catch (ArrayStoreException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), hash());\n+    }\n+\n+    \/\/ instanceof tests with inline types\n+    @Test\n+    public boolean test46(MyValue1 vt) {\n+        Object obj = vt;\n+        return obj instanceof MyValue1;\n+    }\n+\n+    @DontCompile\n+    public void test46_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        boolean result = test46(vt);\n+        Asserts.assertTrue(result);\n+    }\n+\n+    @Test\n+    public boolean test47(MyValue1 vt) {\n+        Object obj = vt;\n+        return obj instanceof MyValue2;\n+    }\n+\n+    @DontCompile\n+    public void test47_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        boolean result = test47(vt);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    @Test\n+    public boolean test48(Object obj) {\n+        return obj instanceof MyValue1;\n+    }\n+\n+    @DontCompile\n+    public void test48_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        boolean result = test48(vt);\n+        Asserts.assertTrue(result);\n+    }\n+\n+    @Test\n+    public boolean test49(Object obj) {\n+        return obj instanceof MyValue2;\n+    }\n+\n+    @DontCompile\n+    public void test49_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        boolean result = test49(vt);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    @Test\n+    public boolean test50(Object obj) {\n+        return obj instanceof MyValue1;\n+    }\n+\n+    @DontCompile\n+    public void test50_verifier(boolean warmup) {\n+        boolean result = test49(Integer.valueOf(42));\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ Inline type with some non-flattened fields\n+    final primitive class Test51Value {\n+        final Object objectField1;\n+        final Object objectField2;\n+        final Object objectField3;\n+        final Object objectField4;\n+        final Object objectField5;\n+        final Object objectField6;\n+\n+        final MyValue1 valueField1;\n+        final MyValue1 valueField2;\n+        final MyValue1.ref valueField3;\n+        final MyValue1 valueField4;\n+        final MyValue1.ref valueField5;\n+\n+        public Test51Value() {\n+            objectField1 = null;\n+            objectField2 = null;\n+            objectField3 = null;\n+            objectField4 = null;\n+            objectField5 = null;\n+            objectField6 = null;\n+            valueField1 = testValue1;\n+            valueField2 = testValue1;\n+            valueField3 = testValue1;\n+            valueField4 = MyValue1.createDefaultDontInline();\n+            valueField5 = MyValue1.createDefaultDontInline();\n+        }\n+\n+        public Test51Value(Object o1, Object o2, Object o3, Object o4, Object o5, Object o6,\n+                           MyValue1 vt1, MyValue1 vt2, MyValue1.ref vt3, MyValue1 vt4, MyValue1.ref vt5) {\n+            objectField1 = o1;\n+            objectField2 = o2;\n+            objectField3 = o3;\n+            objectField4 = o4;\n+            objectField5 = o5;\n+            objectField6 = o6;\n+            valueField1 = vt1;\n+            valueField2 = vt2;\n+            valueField3 = vt3;\n+            valueField4 = vt4;\n+            valueField5 = vt5;\n+        }\n+\n+        @ForceInline\n+        public long test(Test51Value holder, MyValue1 vt1, Object vt2) {\n+            holder = new Test51Value(vt1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, (MyValue1)vt2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, testValue1, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, MyValue1.createWithFieldsDontInline(rI, rL), holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.valueField1, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.valueField3,\n+                                     holder.valueField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     (MyValue1)holder.objectField1, holder.valueField2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, (MyValue1)vt2, holder.valueField3, holder.valueField4, holder.valueField5);\n+            holder = new Test51Value(holder.objectField1, holder.objectField2, holder.objectField3, holder.objectField4, holder.objectField5, holder.objectField6,\n+                                     holder.valueField1, holder.valueField2, (MyValue1)vt2, holder.valueField4, holder.valueField5);\n+\n+            return ((MyValue1)holder.objectField1).hash() +\n+                   ((MyValue1)holder.objectField2).hash() +\n+                   ((MyValue1)holder.objectField3).hash() +\n+                   ((MyValue1)holder.objectField4).hash() +\n+                   ((MyValue1)holder.objectField5).hash() +\n+                   ((MyValue1)holder.objectField6).hash() +\n+                   holder.valueField1.hash() +\n+                   holder.valueField2.hash() +\n+                   holder.valueField3.hash() +\n+                   holder.valueField4.hashPrimitive();\n+        }\n+    }\n+\n+    \/\/ Same as test2 but with field holder being an inline type\n+    @Test()\n+    public long test51(Test51Value holder, MyValue1 vt1, Object vt2) {\n+        return holder.test(holder, vt1, vt2);\n+    }\n+\n+    @DontCompile\n+    public void test51_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        MyValue1 def = MyValue1.createDefaultDontInline();\n+        Test51Value holder = new Test51Value();\n+        Asserts.assertEQ(testValue1.hash(), vt.hash());\n+        Asserts.assertEQ(holder.valueField1.hash(), vt.hash());\n+        long result = test51(holder, vt, vt);\n+        Asserts.assertEQ(result, 9*vt.hash() + def.hashPrimitive());\n+    }\n+\n+    \/\/ Access non-flattened, uninitialized inline type field with inline type holder\n+    @Test()\n+    public void test52(Test51Value holder) {\n+        if ((Object)holder.valueField5 != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test52_verifier(boolean warmup) {\n+        Test51Value vt = Test51Value.default;\n+        test52(vt);\n+    }\n+\n+    \/\/ Merging inline types of different types\n+    @Test()\n+    public Object test53(Object o, boolean b) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        return b ? vt : o;\n+    }\n+\n+    @DontCompile\n+    public void test53_verifier(boolean warmup) {\n+        test53(new Object(), false);\n+        MyValue1 result = (MyValue1)test53(new Object(), true);\n+        Asserts.assertEQ(result.hash(), hash());\n+    }\n+\n+    @Test()\n+    public Object test54(boolean b) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        return b ? vt : testValue2;\n+    }\n+\n+    @DontCompile\n+    public void test54_verifier(boolean warmup) {\n+        MyValue1 result1 = (MyValue1)test54(true);\n+        Asserts.assertEQ(result1.hash(), hash());\n+        MyValue2 result2 = (MyValue2)test54(false);\n+        Asserts.assertEQ(result2.hash(), testValue2.hash());\n+    }\n+\n+    @Test()\n+    public Object test55(boolean b) {\n+        MyValue1 vt1 = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue2 vt2 = MyValue2.createWithFieldsInline(rI, rD);\n+        return b ? vt1 : vt2;\n+    }\n+\n+    @DontCompile\n+    public void test55_verifier(boolean warmup) {\n+        MyValue1 result1 = (MyValue1)test55(true);\n+        Asserts.assertEQ(result1.hash(), hash());\n+        MyValue2 result2 = (MyValue2)test55(false);\n+        Asserts.assertEQ(result2.hash(), testValue2.hash());\n+    }\n+\n+    \/\/ Test synchronization on inline types\n+    @Test()\n+    public void test56(Object vt) {\n+        synchronized (vt) {\n+            throw new RuntimeException(\"test56 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test56_verifier(boolean warmup) {\n+        try {\n+            test56(testValue1);\n+            throw new RuntimeException(\"test56 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @ForceInline\n+    public void test57_inline(Object vt) {\n+        synchronized (vt) {\n+            throw new RuntimeException(\"test57 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Test()\n+    public void test57(MyValue1 vt) {\n+        test57_inline(vt);\n+    }\n+\n+    @DontCompile\n+    public void test57_verifier(boolean warmup) {\n+        try {\n+            test57(testValue1);\n+            throw new RuntimeException(\"test57 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @ForceInline\n+    public void test58_inline(Object vt) {\n+        synchronized (vt) {\n+            throw new RuntimeException(\"test58 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @Test()\n+    public void test58() {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        test58_inline(vt);\n+    }\n+\n+    @DontCompile\n+    public void test58_verifier(boolean warmup) {\n+        try {\n+            test58();\n+            throw new RuntimeException(\"test58 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Test()\n+    public void test59(Object o, boolean b) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object sync = b ? vt : o;\n+        synchronized (sync) {\n+            if (b) {\n+                throw new RuntimeException(\"test59 failed: synchronization on inline type should not succeed\");\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test59_verifier(boolean warmup) {\n+        test59(new Object(), false);\n+        try {\n+            test59(new Object(), true);\n+            throw new RuntimeException(\"test59 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Test()\n+    public void test60(boolean b) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        Object sync = b ? vt : testValue2;\n+        synchronized (sync) {\n+            throw new RuntimeException(\"test60 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test60_verifier(boolean warmup) {\n+        try {\n+            test60(false);\n+            throw new RuntimeException(\"test60 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test60(true);\n+            throw new RuntimeException(\"test60 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test catching the IllegalMonitorStateException in compiled code\n+    @Test()\n+    public void test61(Object vt) {\n+        boolean thrown = false;\n+        try {\n+            synchronized (vt) {\n+                throw new RuntimeException(\"test61 failed: no exception thrown\");\n+            }\n+        } catch (IllegalMonitorStateException ex) {\n+            thrown = true;\n+        }\n+        if (!thrown) {\n+            throw new RuntimeException(\"test61 failed: no exception thrown\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test61_verifier(boolean warmup) {\n+        test61(testValue1);\n+    }\n+\n+    @Test()\n+    public void test62(Object o) {\n+        try {\n+            synchronized (o) { }\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+            return;\n+        }\n+        throw new RuntimeException(\"test62 failed: no exception thrown\");\n+    }\n+\n+    @DontCompile\n+    public void test62_verifier(boolean warmup) {\n+        test62(testValue1);\n+    }\n+\n+    \/\/ Test synchronization without any instructions in the synchronized block\n+    @Test()\n+    public void test63(Object o) {\n+        synchronized (o) { }\n+    }\n+\n+    @DontCompile\n+    public void test63_verifier(boolean warmup) {\n+        try {\n+            test63(testValue1);\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+            return;\n+        }\n+        throw new RuntimeException(\"test63 failed: no exception thrown\");\n+    }\n+\n+    \/\/ type system test with interface and inline type\n+    @ForceInline\n+    public MyInterface test64Interface_helper(MyValue1 vt) {\n+        return vt;\n+    }\n+\n+    @Test()\n+    public MyInterface test64Interface(MyValue1 vt) {\n+        return test64Interface_helper(vt);\n+    }\n+\n+    @DontCompile\n+    public void test64Interface_verifier(boolean warmup) {\n+        test64Interface(testValue1);\n+    }\n+\n+    \/\/ type system test with abstract and inline type\n+    @ForceInline\n+    public MyAbstract test64Abstract_helper(MyValue1 vt) {\n+        return vt;\n+    }\n+\n+    @Test()\n+    public MyAbstract test64Abstract(MyValue1 vt) {\n+        return test64Abstract_helper(vt);\n+    }\n+\n+    @DontCompile\n+    public void test64Abstract_verifier(boolean warmup) {\n+        test64Abstract(testValue1);\n+    }\n+\n+    \/\/ Array store tests\n+    @Test()\n+    public void test65(Object[] array, MyValue1 vt) {\n+        array[0] = vt;\n+    }\n+\n+    @DontCompile\n+    public void test65_verifier(boolean warmup) {\n+        Object[] array = new Object[1];\n+        test65(array, testValue1);\n+        Asserts.assertEQ(((MyValue1)array[0]).hash(), testValue1.hash());\n+    }\n+\n+    @Test()\n+    public void test66(Object[] array, MyValue1 vt) {\n+        array[0] = vt;\n+    }\n+\n+    @DontCompile\n+    public void test66_verifier(boolean warmup) {\n+        MyValue1[] array = new MyValue1[1];\n+        test66(array, testValue1);\n+        Asserts.assertEQ(array[0].hash(), testValue1.hash());\n+    }\n+\n+    @Test()\n+    public void test67(Object[] array, Object vt) {\n+        array[0] = vt;\n+    }\n+\n+    @DontCompile\n+    public void test67_verifier(boolean warmup) {\n+        MyValue1[] array = new MyValue1[1];\n+        test67(array, testValue1);\n+        Asserts.assertEQ(array[0].hash(), testValue1.hash());\n+    }\n+\n+    @Test()\n+    public void test68(Object[] array, Integer o) {\n+        array[0] = o;\n+    }\n+\n+    @DontCompile\n+    public void test68_verifier(boolean warmup) {\n+        Integer[] array = new Integer[1];\n+        test68(array, 1);\n+        Asserts.assertEQ(array[0], Integer.valueOf(1));\n+    }\n+\n+    \/\/ Test convertion between an inline type and java.lang.Object without an allocation\n+    @ForceInline\n+    public Object test69_sum(Object a, Object b) {\n+        int sum = ((MyValue1)a).x + ((MyValue1)b).x;\n+        return MyValue1.setX(((MyValue1)a), sum);\n+    }\n+\n+    @Test(failOn = ALLOC + STORE)\n+    public int test69(MyValue1[] array) {\n+        MyValue1 result = MyValue1.createDefaultInline();\n+        for (int i = 0; i < array.length; ++i) {\n+            result = (MyValue1)test69_sum(result, array[i]);\n+        }\n+        return result.x;\n+    }\n+\n+    @DontCompile\n+    public void test69_verifier(boolean warmup) {\n+        int result = test69(testValue1Array);\n+        Asserts.assertEQ(result, rI * testValue1Array.length);\n+    }\n+\n+    \/\/ Same as test69 but with an Interface\n+    @ForceInline\n+    public MyInterface test70Interface_sum(MyInterface a, MyInterface b) {\n+        int sum = ((MyValue1)a).x + ((MyValue1)b).x;\n+        return MyValue1.setX(((MyValue1)a), sum);\n+    }\n+\n+    @Test(failOn = ALLOC + STORE)\n+    public int test70Interface(MyValue1[] array) {\n+        MyValue1 result = MyValue1.createDefaultInline();\n+        for (int i = 0; i < array.length; ++i) {\n+            result = (MyValue1)test70Interface_sum(result, array[i]);\n+        }\n+        return result.x;\n+    }\n+\n+    @DontCompile\n+    public void test70Interface_verifier(boolean warmup) {\n+        int result = test70Interface(testValue1Array);\n+        Asserts.assertEQ(result, rI * testValue1Array.length);\n+    }\n+\n+    \/\/ Same as test69 but with an Abstract\n+    @ForceInline\n+    public MyAbstract test70Abstract_sum(MyAbstract a, MyAbstract b) {\n+        int sum = ((MyValue1)a).x + ((MyValue1)b).x;\n+        return MyValue1.setX(((MyValue1)a), sum);\n+    }\n+\n+    @Test(failOn = ALLOC + STORE)\n+    public int test70Abstract(MyValue1[] array) {\n+        MyValue1 result = MyValue1.createDefaultInline();\n+        for (int i = 0; i < array.length; ++i) {\n+            result = (MyValue1)test70Abstract_sum(result, array[i]);\n+        }\n+        return result.x;\n+    }\n+\n+    @DontCompile\n+    public void test70Abstract_verifier(boolean warmup) {\n+        int result = test70Abstract(testValue1Array);\n+        Asserts.assertEQ(result, rI * testValue1Array.length);\n+    }\n+\n+    \/\/ Test that allocated inline type is not used in non-dominated path\n+    public MyValue1 test71_inline(Object obj) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        try {\n+            vt = (MyValue1)obj;\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        return vt;\n+    }\n+\n+    @Test\n+    public MyValue1 test71() {\n+        return test71_inline(null);\n+    }\n+\n+    @DontCompile\n+    public void test71_verifier(boolean warmup) {\n+        MyValue1 vt = test71();\n+        Asserts.assertEquals(vt.hash(), hash());\n+    }\n+\n+    \/\/ Test calling a method on an uninitialized inline type\n+    final primitive class Test72Value {\n+        final int x = 42;\n+        public int get() {\n+            return x;\n+        }\n+    }\n+\n+    \/\/ Make sure Test72Value is loaded but not initialized\n+    public void unused(Test72Value vt) { }\n+\n+    @Test\n+    @Warmup(0)\n+    public int test72() {\n+        Test72Value vt = Test72Value.default;\n+        return vt.get();\n+    }\n+\n+    @DontCompile\n+    public void test72_verifier(boolean warmup) {\n+        int result = test72();\n+        Asserts.assertEquals(result, 0);\n+    }\n+\n+    \/\/ Tests for loading\/storing unkown values\n+    @Test\n+    public Object test73(Object[] va) {\n+        return va[0];\n+    }\n+\n+    @DontCompile\n+    public void test73_verifier(boolean warmup) {\n+        MyValue1 vt = (MyValue1)test73(testValue1Array);\n+        Asserts.assertEquals(testValue1Array[0].hash(), vt.hash());\n+    }\n+\n+    @Test\n+    public void test74(Object[] va, Object vt) {\n+        va[0] = vt;\n+    }\n+\n+    @DontCompile\n+    public void test74_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[1];\n+        test74(va, testValue1);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+    }\n+\n+    \/\/ Verify that mixing instances and arrays with the clone api\n+    \/\/ doesn't break anything\n+    @Test\n+    public Object test75(Object o) {\n+        MyValue1[] va = new MyValue1[1];\n+        Object[] next = va;\n+        Object[] arr = va;\n+        for (int i = 0; i < 10; i++) {\n+            arr = next;\n+            next = new Integer[1];\n+        }\n+        return arr[0];\n+    }\n+\n+    @DontCompile\n+    public void test75_verifier(boolean warmup) {\n+        test75(42);\n+    }\n+\n+    \/\/ Casting a null Integer to a (non-nullable) inline type should throw a NullPointerException\n+    @ForceInline\n+    public MyValue1 test76_helper(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test\n+    public MyValue1 test76(Integer i) throws Throwable {\n+        return test76_helper(i);\n+    }\n+\n+    @DontCompile\n+    public void test76_verifier(boolean warmup) throws Throwable {\n+        try {\n+            test76(null);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"test76 failed: unexpected exception\", e);\n+        }\n+    }\n+\n+    \/\/ Casting an Integer to a (non-nullable) inline type should throw a ClassCastException\n+    @ForceInline\n+    public MyValue1 test77_helper(Object o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test\n+    public MyValue1 test77(Integer i) throws Throwable {\n+        return test77_helper(i);\n+    }\n+\n+    @DontCompile\n+    public void test77_verifier(boolean warmup) throws Throwable {\n+        try {\n+            test77(Integer.valueOf(42));\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"test77 failed: unexpected exception\", e);\n+        }\n+    }\n+\n+    \/\/ Casting a null Integer to a nullable inline type should not throw\n+    @ForceInline\n+    public MyValue1.ref test78_helper(Object o) {\n+        return (MyValue1.ref)o;\n+    }\n+\n+    @Test\n+    public MyValue1.ref test78(Integer i) throws Throwable {\n+        return test78_helper(i);\n+    }\n+\n+    @DontCompile\n+    public void test78_verifier(boolean warmup) throws Throwable {\n+        try {\n+            test78(null); \/\/ Should not throw\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"test78 failed: unexpected exception\", e);\n+        }\n+    }\n+\n+    \/\/ Casting an Integer to a nullable inline type should throw a ClassCastException\n+    @ForceInline\n+    public MyValue1.ref test79_helper(Object o) {\n+        return (MyValue1.ref)o;\n+    }\n+\n+    @Test\n+    public MyValue1.ref test79(Integer i) throws Throwable {\n+        return test79_helper(i);\n+    }\n+\n+    @DontCompile\n+    public void test79_verifier(boolean warmup) throws Throwable {\n+        try {\n+            test79(Integer.valueOf(42));\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"test79 failed: unexpected exception\", e);\n+        }\n+    }\n+\n+    \/\/ Test flattened field with non-flattenend (but flattenable) inline type field\n+    static primitive class Small {\n+        final int i;\n+        final Big big; \/\/ Too big to be flattened\n+\n+        private Small() {\n+            i = rI;\n+            big = new Big();\n+        }\n+    }\n+\n+    static primitive class Big {\n+        long l0,l1,l2,l3,l4,l5,l6,l7,l8,l9;\n+        long l10,l11,l12,l13,l14,l15,l16,l17,l18,l19;\n+        long l20,l21,l22,l23,l24,l25,l26,l27,l28,l29;\n+\n+        private Big() {\n+            l0 = l1 = l2 = l3 = l4 = l5 = l6 = l7 = l8 = l9 = rL;\n+            l10 = l11 = l12 = l13 = l14 = l15 = l16 = l17 = l18 = l19 = rL+1;\n+            l20 = l21 = l22 = l23 = l24 = l25 = l26 = l27 = l28 = l29 = rL+2;\n+        }\n+    }\n+\n+    Small small = new Small();\n+    Small smallDefault;\n+    Big big = new Big();\n+    Big bigDefault;\n+\n+    @Test\n+    public long test80() {\n+        return small.i + small.big.l0 + smallDefault.i + smallDefault.big.l29 + big.l0 + bigDefault.l29;\n+    }\n+\n+    @DontCompile\n+    public void test80_verifier(boolean warmup) throws Throwable {\n+        long result = test80();\n+        Asserts.assertEQ(result, rI + 2*rL);\n+    }\n+\n+    \/\/ Test scalarization with exceptional control flow\n+    public int test81Callee(MyValue1 vt)  {\n+        return vt.x;\n+    }\n+\n+    @Test(failOn = ALLOC + LOAD + STORE)\n+    public int test81()  {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        int result = 0;\n+        for (int i = 0; i < 10; i++) {\n+            try {\n+                result += test81Callee(vt);\n+            } catch (NullPointerException npe) {\n+                result += rI;\n+            }\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test81_verifier(boolean warmup) {\n+        int result = test81();\n+        Asserts.assertEQ(result, 10*rI);\n+    }\n+\n+    \/\/ Test check for null free array when storing to inline tpye array\n+    @Test\n+    public void test82(Object[] dst, Object v) {\n+        dst[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test82_verifier(boolean warmup) {\n+        MyValue2[] dst = new MyValue2[1];\n+        test82(dst, testValue2);\n+        if (!warmup) {\n+            try {\n+                test82(dst, null);\n+                throw new RuntimeException(\"No ArrayStoreException thrown\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(10000)\n+    public void test83(Object[] dst, Object v, boolean flag) {\n+        if (dst == null) { \/\/ null check\n+        }\n+        if (flag) {\n+            if (dst.getClass() == MyValue1[].class) { \/\/ trigger split if\n+            }\n+        } else {\n+            dst = new MyValue2[1]; \/\/ constant null free property\n+        }\n+        dst[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test83_verifier(boolean warmup) {\n+        MyValue2[] dst = new MyValue2[1];\n+        test83(dst, testValue2, false);\n+        test83(dst, testValue2, true);\n+        if (!warmup) {\n+            try {\n+                test83(dst, null, true);\n+                throw new RuntimeException(\"No ArrayStoreException thrown\");\n+            } catch (NullPointerException e) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    private void rerun_and_recompile_for(String name, int num, Runnable test) {\n+        Method m = tests.get(name);\n+\n+        for (int i = 1; i < num; i++) {\n+            test.run();\n+\n+            if (!WHITE_BOX.isMethodCompiled(m, false)) {\n+                enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            }\n+        }\n+    }\n+\n+    \/\/ Tests for the Loop Unswitching optimization\n+    \/\/ Should make 2 copies of the loop, one for non flattened arrays, one for other cases.\n+    @Test(match = { COUNTEDLOOP_MAIN }, matchCount = { 2 } )\n+    @Warmup(0)\n+    public void test84(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; i++) {\n+            dst[i] = src[i];\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test84_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[100];\n+        Arrays.fill(src, testValue2);\n+        MyValue2[] dst = new MyValue2[100];\n+        rerun_and_recompile_for(\"TestLWorld::test84\", 10,\n+                                () ->  { test84(src, dst);\n+                                         Asserts.assertTrue(Arrays.equals(src, dst)); });\n+    }\n+\n+    @Test(valid = G1GCOn, match = { COUNTEDLOOP, LOAD_UNKNOWN_INLINE }, matchCount = { 2, 1 } )\n+    @Test(valid = G1GCOff, match = { COUNTEDLOOP_MAIN, LOAD_UNKNOWN_INLINE }, matchCount = { 2, 4 } )\n+    @Warmup(0)\n+    public void test85(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; i++) {\n+            dst[i] = src[i];\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test85_verifier(boolean warmup) {\n+        Object[] src = new Object[100];\n+        Arrays.fill(src, new Object());\n+        src[0] = null;\n+        Object[] dst = new Object[100];\n+        rerun_and_recompile_for(\"TestLWorld::test85\", 10,\n+                                () -> { test85(src, dst);\n+                                        Asserts.assertTrue(Arrays.equals(src, dst)); });\n+    }\n+\n+    @Test(valid = G1GCOn, match = { COUNTEDLOOP }, matchCount = { 2 } )\n+    @Test(valid = G1GCOff, match = { COUNTEDLOOP_MAIN }, matchCount = { 2 } )\n+    @Warmup(0)\n+    public void test86(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; i++) {\n+            dst[i] = src[i];\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test86_verifier(boolean warmup) {\n+        MyValue2[] src = new MyValue2[100];\n+        Arrays.fill(src, testValue2);\n+        Object[] dst = new Object[100];\n+        rerun_and_recompile_for(\"TestLWorld::test86\", 10,\n+                                () -> { test86(src, dst);\n+                                        Asserts.assertTrue(Arrays.equals(src, dst)); });\n+    }\n+\n+    @Test(match = { COUNTEDLOOP_MAIN }, matchCount = { 2 } )\n+    @Warmup(0)\n+    public void test87(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; i++) {\n+            dst[i] = src[i];\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test87_verifier(boolean warmup) {\n+        Object[] src = new Object[100];\n+        Arrays.fill(src, testValue2);\n+        MyValue2[] dst = new MyValue2[100];\n+\n+        rerun_and_recompile_for(\"TestLWorld::test87\", 10,\n+                                () -> { test87(src, dst);\n+                                        Asserts.assertTrue(Arrays.equals(src, dst)); });\n+    }\n+\n+    @Test(match = { COUNTEDLOOP_MAIN }, matchCount = { 2 } )\n+    @Warmup(0)\n+    public void test88(Object[] src1, Object[] dst1, Object[] src2, Object[] dst2) {\n+        for (int i = 0; i < src1.length; i++) {\n+            dst1[i] = src1[i];\n+            dst2[i] = src2[i];\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test88_verifier(boolean warmup) {\n+        MyValue2[] src1 = new MyValue2[100];\n+        Arrays.fill(src1, testValue2);\n+        MyValue2[] dst1 = new MyValue2[100];\n+        Object[] src2 = new Object[100];\n+        Arrays.fill(src2, new Object());\n+        Object[] dst2 = new Object[100];\n+\n+        rerun_and_recompile_for(\"TestLWorld::test88\", 10,\n+                                () -> { test88(src1, dst1, src2, dst2);\n+                                        Asserts.assertTrue(Arrays.equals(src1, dst1));\n+                                        Asserts.assertTrue(Arrays.equals(src2, dst2)); });\n+    }\n+\n+    @Test\n+    public boolean test89(Object obj) {\n+        return obj.getClass() == Integer.class;\n+    }\n+\n+    @DontCompile\n+    public void test89_verifier(boolean warmup) {\n+        Asserts.assertTrue(test89(Integer.valueOf(42)));\n+        Asserts.assertFalse(test89(new Object()));\n+    }\n+\n+    @Test\n+    public Integer test90(Object obj) {\n+        return (Integer)obj;\n+    }\n+\n+    @DontCompile\n+    public void test90_verifier(boolean warmup) {\n+        test90(Integer.valueOf(42));\n+        try {\n+            test90(new Object());\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Test\n+    public boolean test91(Object obj) {\n+        return obj.getClass() == MyValue2[].class;\n+    }\n+\n+    @DontCompile\n+    public void test91_verifier(boolean warmup) {\n+        Asserts.assertTrue(test91(new MyValue2[1]));\n+        Asserts.assertFalse(test91(new Object()));\n+    }\n+\n+    static primitive class Test92Value {\n+        final int field;\n+        public Test92Value() {\n+            field = 0x42;\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(match = { CLASS_CHECK_TRAP }, matchCount = { 2 }, failOn = LOAD_UNKNOWN_INLINE + ALLOC_G + MEMBAR)\n+    public Object test92(Object[] array) {\n+        \/\/ Dummy loops to ensure we run enough passes of split if\n+        for (int i = 0; i < 2; i++) {\n+            for (int j = 0; j < 2; j++) {\n+              for (int k = 0; k < 2; k++) {\n+              }\n+            }\n+        }\n+\n+        return (Integer)array[0];\n+    }\n+\n+    @DontCompile\n+    public void test92_verifier(boolean warmup) {\n+        Object[] array = new Object[1];\n+        array[0] = 0x42;\n+        Object result = test92(array);\n+        Asserts.assertEquals(result, 0x42);\n+    }\n+\n+    \/\/ If the class check succeeds, the flattened array check that\n+    \/\/ precedes will never succeed and the flat array branch should\n+    \/\/ trigger an uncommon trap.\n+    @Test\n+    @Warmup(10000)\n+    public Object test93(Object[] array) {\n+        for (int i = 0; i < 2; i++) {\n+            for (int j = 0; j < 2; j++) {\n+            }\n+        }\n+\n+        Object v = (Integer)array[0];\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test93_verifier(boolean warmup) {\n+        if (warmup) {\n+            Object[] array = new Object[1];\n+            array[0] = 0x42;\n+            Object result = test93(array);\n+            Asserts.assertEquals(result, 0x42);\n+        } else {\n+            Object[] array = new Test92Value[1];\n+            Method m = tests.get(\"TestLWorld::test93\");\n+            int extra = 3;\n+            for (int j = 0; j < extra; j++) {\n+                for (int i = 0; i < 10; i++) {\n+                    try {\n+                        test93(array);\n+                    } catch (ClassCastException cce) {\n+                    }\n+                }\n+                boolean compiled = isCompiledByC2(m);\n+                Asserts.assertTrue(!USE_COMPILER || XCOMP || STRESS_CC || TEST_C1 || !ProfileInterpreter || compiled || (j != extra-1));\n+                if (!compiled) {\n+                    enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+                }\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(match = { CLASS_CHECK_TRAP, LOOP }, matchCount = { 2, 1 }, failOn = LOAD_UNKNOWN_INLINE + ALLOC_G + MEMBAR)\n+    public int test94(Object[] array) {\n+        int res = 0;\n+        for (int i = 1; i < 4; i *= 2) {\n+            Object v = array[i];\n+            res += (Integer)v;\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test94_verifier(boolean warmup) {\n+        Object[] array = new Object[4];\n+        array[0] = 0x42;\n+        array[1] = 0x42;\n+        array[2] = 0x42;\n+        array[3] = 0x42;\n+        int result = test94(array);\n+        Asserts.assertEquals(result, 0x42 * 2);\n+    }\n+\n+    @Warmup(10000)\n+    @Test\n+    public boolean test95(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test95_verifier(boolean warmup) {\n+        Object o1 = new Object();\n+        Object o2 = new Object();\n+        Asserts.assertTrue(test95(o1, o1));\n+        Asserts.assertTrue(test95(null, null));\n+        Asserts.assertFalse(test95(o1, null));\n+        Asserts.assertFalse(test95(o1, o2));\n+    }\n+\n+    @Warmup(10000)\n+    @Test\n+    public boolean test96(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test96_verifier(boolean warmup) {\n+        Object o1 = new Object();\n+        Object o2 = new Object();\n+        Asserts.assertTrue(test96(o1, o1));\n+        Asserts.assertFalse(test96(o1, o2));\n+        if (!warmup) {\n+            Asserts.assertTrue(test96(null, null));\n+            Asserts.assertFalse(test96(o1, null));\n+        }\n+    }\n+\n+    \/\/ Abstract class tests\n+\n+    @DontInline\n+    public MyAbstract test97_dontinline1(MyAbstract o) {\n+        return o;\n+    }\n+\n+    @DontInline\n+    public MyValue1 test97_dontinline2(MyAbstract o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @ForceInline\n+    public MyAbstract test97_inline1(MyAbstract o) {\n+        return o;\n+    }\n+\n+    @ForceInline\n+    public MyValue1 test97_inline2(MyAbstract o) {\n+        return (MyValue1)o;\n+    }\n+\n+    @Test()\n+    public MyValue1 test97() {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        vt = (MyValue1)test97_dontinline1(vt);\n+        vt =           test97_dontinline2(vt);\n+        vt = (MyValue1)test97_inline1(vt);\n+        vt =           test97_inline2(vt);\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test97_verifier(boolean warmup) {\n+        Asserts.assertEQ(test97().hash(), hash());\n+    }\n+\n+    \/\/ Test storing\/loading inline types to\/from abstract and inline type fields\n+    MyAbstract abstractField1 = null;\n+    MyAbstract abstractField2 = null;\n+    MyAbstract abstractField3 = null;\n+    MyAbstract abstractField4 = null;\n+    MyAbstract abstractField5 = null;\n+    MyAbstract abstractField6 = null;\n+\n+    @DontInline\n+    public MyAbstract readValueField5AsAbstract() {\n+        return (MyAbstract)valueField5;\n+    }\n+\n+    @DontInline\n+    public MyAbstract readStaticValueField4AsAbstract() {\n+        return (MyAbstract)staticValueField4;\n+    }\n+\n+    @Test()\n+    public long test98(MyValue1 vt1, MyAbstract vt2) {\n+        abstractField1 = vt1;\n+        abstractField2 = (MyValue1)vt2;\n+        abstractField3 = MyValue1.createWithFieldsInline(rI, rL);\n+        abstractField4 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        abstractField5 = valueField1;\n+        abstractField6 = valueField3;\n+        valueField1 = (MyValue1)abstractField1;\n+        valueField2 = (MyValue1)vt2;\n+        valueField3 = (MyValue1)vt2;\n+        staticValueField1 = (MyValue1)abstractField1;\n+        staticValueField2 = (MyValue1)vt1;\n+        \/\/ Don't inline these methods because reading NULL will trigger a deoptimization\n+        if (readValueField5AsAbstract() != null || readStaticValueField4AsAbstract() != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+        return ((MyValue1)abstractField1).hash() + ((MyValue1)abstractField2).hash() +\n+               ((MyValue1)abstractField3).hash() + ((MyValue1)abstractField4).hash() +\n+               ((MyValue1)abstractField5).hash() + ((MyValue1)abstractField6).hash() +\n+                valueField1.hash() + valueField2.hash() + valueField3.hash() + valueField4.hashPrimitive() +\n+                staticValueField1.hash() + staticValueField2.hash() + staticValueField3.hashPrimitive();\n+    }\n+\n+    @DontCompile\n+    public void test98_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        MyValue1 def = MyValue1.createDefaultDontInline();\n+        long result = test98(vt, vt);\n+        Asserts.assertEQ(result, 11*vt.hash() + 2*def.hashPrimitive());\n+    }\n+\n+    class MyObject2 extends MyAbstract {\n+        public int x;\n+\n+        public MyObject2(int x) {\n+            this.x = x;\n+        }\n+\n+        @ForceInline\n+        public long hash() {\n+            return x;\n+        }\n+    }\n+\n+    \/\/ Test merging inline types and abstract classes\n+    @Test()\n+    public MyAbstract test99(int state) {\n+        MyAbstract res = null;\n+        if (state == 0) {\n+            res = new MyObject2(rI);\n+        } else if (state == 1) {\n+            res = MyValue1.createWithFieldsInline(rI, rL);\n+        } else if (state == 2) {\n+            res = MyValue1.createWithFieldsDontInline(rI, rL);\n+        } else if (state == 3) {\n+            res = (MyValue1)objectField1;\n+        } else if (state == 4) {\n+            res = valueField1;\n+        } else if (state == 5) {\n+            res = null;\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test99_verifier(boolean warmup) {\n+        objectField1 = valueField1;\n+        MyAbstract result = null;\n+        result = test99(0);\n+        Asserts.assertEQ(((MyObject2)result).x, rI);\n+        result = test99(1);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test99(2);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test99(3);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test99(4);\n+        Asserts.assertEQ(((MyValue1)result).hash(), hash());\n+        result = test99(5);\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    \/\/ Test merging inline types and abstract classes in loops\n+    @Test()\n+    public MyAbstract test100(int iters) {\n+        MyAbstract res = new MyObject2(rI);\n+        for (int i = 0; i < iters; ++i) {\n+            if (res instanceof MyObject2) {\n+                res = MyValue1.createWithFieldsInline(rI, rL);\n+            } else {\n+                res = MyValue1.createWithFieldsInline(((MyValue1)res).x + 1, rL);\n+            }\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test100_verifier(boolean warmup) {\n+        MyObject2 result1 = (MyObject2)test100(0);\n+        Asserts.assertEQ(result1.x, rI);\n+        int iters = (Math.abs(rI) % 10) + 1;\n+        MyValue1 result2 = (MyValue1)test100(iters);\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI + iters - 1, rL);\n+        Asserts.assertEQ(result2.hash(), vt.hash());\n+    }\n+\n+    \/\/ Test inline types in abstract class variables that are live at safepoint\n+    @Test(failOn = ALLOC + STORE + LOOP)\n+    public long test101(MyValue1 arg, boolean deopt) {\n+        MyAbstract vt1 = MyValue1.createWithFieldsInline(rI, rL);\n+        MyAbstract vt2 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyAbstract vt3 = arg;\n+        MyAbstract vt4 = valueField1;\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test101\"));\n+        }\n+        return ((MyValue1)vt1).hash() + ((MyValue1)vt2).hash() +\n+               ((MyValue1)vt3).hash() + ((MyValue1)vt4).hash();\n+    }\n+\n+    @DontCompile\n+    public void test101_verifier(boolean warmup) {\n+        long result = test101(valueField1, !warmup);\n+        Asserts.assertEQ(result, 4*hash());\n+    }\n+\n+    \/\/ Test comparing inline types with abstract classes\n+    @Test(failOn = LOAD + LOOP)\n+    public boolean test102(Object arg) {\n+        MyAbstract vt = MyValue1.createWithFieldsInline(rI, rL);\n+        if (vt == arg || vt == (MyAbstract)valueField1 || vt == abstractField1 || vt == null ||\n+            arg == vt || (MyAbstract)valueField1 == vt || abstractField1 == vt || null == vt) {\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    @DontCompile\n+    public void test102_verifier(boolean warmup) {\n+        boolean result = test102(null);\n+        Asserts.assertFalse(result);\n+    }\n+\n+    \/\/ An abstract class with a non-static field can never be implemented by an inline type\n+    abstract class NoValueImplementors1 {\n+        int field = 42;\n+    }\n+\n+    class MyObject3 extends NoValueImplementors1 {\n+\n+    }\n+\n+    class MyObject4 extends NoValueImplementors1 {\n+\n+    }\n+\n+    \/\/ Loading from an abstract class array does not require a flatness check if the abstract class has a non-static field\n+    @Test(failOn = ALLOC_G + MEMBAR + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    public NoValueImplementors1 test103(NoValueImplementors1[] array, int i) {\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test103_verifier(boolean warmup) {\n+        NoValueImplementors1[] array1 = new NoValueImplementors1[3];\n+        MyObject3[] array2 = new MyObject3[3];\n+        MyObject4[] array3 = new MyObject4[3];\n+        NoValueImplementors1 result = test103(array1, 0);\n+        Asserts.assertEquals(result, array1[0]);\n+\n+        result = test103(array2, 1);\n+        Asserts.assertEquals(result, array1[1]);\n+\n+        result = test103(array3, 2);\n+        Asserts.assertEquals(result, array1[2]);\n+    }\n+\n+    \/\/ Storing to an abstract class array does not require a flatness\/null check if the abstract class has a non-static field\n+    @Test(failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    public NoValueImplementors1 test104(NoValueImplementors1[] array, NoValueImplementors1 v, MyObject3 o, int i) {\n+        array[0] = v;\n+        array[1] = array[0];\n+        array[2] = o;\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test104_verifier(boolean warmup) {\n+        MyObject4 v = new MyObject4();\n+        MyObject3 o = new MyObject3();\n+        NoValueImplementors1[] array1 = new NoValueImplementors1[3];\n+        MyObject3[] array2 = new MyObject3[3];\n+        MyObject4[] array3 = new MyObject4[3];\n+        NoValueImplementors1 result = test104(array1, v, o, 0);\n+        Asserts.assertEquals(array1[0], v);\n+        Asserts.assertEquals(array1[1], v);\n+        Asserts.assertEquals(array1[2], o);\n+        Asserts.assertEquals(result, v);\n+\n+        result = test104(array2, o, o, 1);\n+        Asserts.assertEquals(array2[0], o);\n+        Asserts.assertEquals(array2[1], o);\n+        Asserts.assertEquals(array2[2], o);\n+        Asserts.assertEquals(result, o);\n+\n+        result = test104(array3, v, null, 1);\n+        Asserts.assertEquals(array3[0], v);\n+        Asserts.assertEquals(array3[1], v);\n+        Asserts.assertEquals(array3[2], null);\n+        Asserts.assertEquals(result, v);\n+    }\n+\n+    \/\/ An abstract class with a single, non-inline implementor\n+    abstract class NoValueImplementors2 {\n+\n+    }\n+\n+    class MyObject5 extends NoValueImplementors2 {\n+\n+    }\n+\n+    \/\/ Loading from an abstract class array does not require a flatness check if the abstract class has no inline implementor\n+    @Test(failOn = ALLOC_G + MEMBAR + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    public NoValueImplementors2 test105(NoValueImplementors2[] array, int i) {\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test105_verifier(boolean warmup) {\n+        NoValueImplementors2[] array1 = new NoValueImplementors2[3];\n+        MyObject5[] array2 = new MyObject5[3];\n+        NoValueImplementors2 result = test105(array1, 0);\n+        Asserts.assertEquals(result, array1[0]);\n+\n+        result = test105(array2, 1);\n+        Asserts.assertEquals(result, array1[1]);\n+    }\n+\n+    \/\/ Storing to an abstract class array does not require a flatness\/null check if the abstract class has no inline implementor\n+    @Test(failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_INLINE + STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD)\n+    public NoValueImplementors2 test106(NoValueImplementors2[] array, NoValueImplementors2 v, MyObject5 o, int i) {\n+        array[0] = v;\n+        array[1] = array[0];\n+        array[2] = o;\n+        return array[i];\n+    }\n+\n+    @DontCompile\n+    public void test106_verifier(boolean warmup) {\n+        MyObject5 v = new MyObject5();\n+        NoValueImplementors2[] array1 = new NoValueImplementors2[3];\n+        MyObject5[] array2 = new MyObject5[3];\n+        NoValueImplementors2 result = test106(array1, v, null, 0);\n+        Asserts.assertEquals(array1[0], v);\n+        Asserts.assertEquals(array1[1], v);\n+        Asserts.assertEquals(array1[2], null);\n+        Asserts.assertEquals(result, v);\n+\n+        result = test106(array2, v, v, 1);\n+        Asserts.assertEquals(array2[0], v);\n+        Asserts.assertEquals(array2[1], v);\n+        Asserts.assertEquals(array2[2], v);\n+        Asserts.assertEquals(result, v);\n+    }\n+\n+    \/\/ More tests for the Loop Unswitching optimization (similar to test84 and following)\n+    Object oFld1, oFld2;\n+\n+    @Test(valid = G1GCOn, failOn = STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD, match = { COUNTEDLOOP, LOAD_UNKNOWN_INLINE }, matchCount = { 2, 2 } )\n+    @Test(valid = G1GCOff, failOn = STORE_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD, match = { COUNTEDLOOP, LOAD_UNKNOWN_INLINE }, matchCount = { 3, 2 } )\n+    @Warmup(0)\n+    public void test107(Object[] src1, Object[] src2) {\n+        for (int i = 0; i < src1.length; i++) {\n+            oFld1 = src1[i];\n+            oFld2 = src2[i];\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test107_verifier(boolean warmup) {\n+        MyValue2[] src1 = new MyValue2[100];\n+        Arrays.fill(src1, testValue2);\n+        Object[] src2 = new Object[100];\n+        Object obj = new Object();\n+        Arrays.fill(src2, obj);\n+        rerun_and_recompile_for(\"TestLWorld::test107\", 10,\n+                                () -> { test107(src1, src2);\n+                                        Asserts.assertEquals(oFld1, testValue2);\n+                                        Asserts.assertEquals(oFld2, obj);\n+                                        test107(src2, src1);\n+                                        Asserts.assertEquals(oFld1, obj);\n+                                        Asserts.assertEquals(oFld2, testValue2);  });\n+    }\n+\n+    @Test(valid = G1GCOn, failOn = LOAD_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD, match = { COUNTEDLOOP, STORE_UNKNOWN_INLINE }, matchCount = { 4, 9 } )\n+    @Test(valid = G1GCOff, failOn = LOAD_UNKNOWN_INLINE + INLINE_ARRAY_NULL_GUARD, match = { COUNTEDLOOP, STORE_UNKNOWN_INLINE }, matchCount = { 4, 12 } )\n+    @Warmup(0)\n+    public void test108(Object[] dst1, Object[] dst2, Object o1, Object o2) {\n+        for (int i = 0; i < dst1.length; i++) {\n+            dst1[i] = o1;\n+            dst2[i] = o2;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test108_verifier(boolean warmup) {\n+        MyValue2[] dst1 = new MyValue2[100];\n+        Object[] dst2 = new Object[100];\n+        Object o1 = new Object();\n+        rerun_and_recompile_for(\"TestLWorld::test108\", 10,\n+                                () -> { test108(dst1, dst2, testValue2, o1);\n+                                        for (int i = 0; i < dst1.length; i++) {\n+                                            Asserts.assertEquals(dst1[i], testValue2);\n+                                            Asserts.assertEquals(dst2[i], o1);\n+                                        }\n+                                        test108(dst2, dst1, o1, testValue2);\n+                                        for (int i = 0; i < dst1.length; i++) {\n+                                            Asserts.assertEquals(dst1[i], testValue2);\n+                                            Asserts.assertEquals(dst2[i], o1);\n+                                        } });\n+    }\n+\n+    \/\/ Escape analysis tests\n+\n+    static interface WrapperInterface {\n+        long value();\n+\n+        final static WrapperInterface ZERO = new LongWrapper(0);\n+\n+        static WrapperInterface wrap(long val) {\n+            return (val == 0L) ? ZERO : new LongWrapper(val);\n+        }\n+    }\n+\n+    static primitive class LongWrapper implements WrapperInterface {\n+        final static LongWrapper ZERO = new LongWrapper(0);\n+        private long val;\n+\n+        LongWrapper(long val) {\n+            this.val = val;\n+        }\n+\n+        static LongWrapper wrap(long val) {\n+            return (val == 0L) ? ZERO : new LongWrapper(val);\n+        }\n+\n+        public long value() {\n+            return val;\n+        }\n+    }\n+\n+    static class InterfaceBox {\n+        WrapperInterface content;\n+\n+        InterfaceBox(WrapperInterface content) {\n+            this.content = content;\n+        }\n+\n+        static InterfaceBox box_sharp(long val) {\n+            return new InterfaceBox(LongWrapper.wrap(val));\n+        }\n+\n+        static InterfaceBox box(long val) {\n+            return new InterfaceBox(WrapperInterface.wrap(val));\n+        }\n+    }\n+\n+    static class ObjectBox {\n+        Object content;\n+\n+        ObjectBox(Object content) {\n+            this.content = content;\n+        }\n+\n+        static ObjectBox box_sharp(long val) {\n+            return new ObjectBox(LongWrapper.wrap(val));\n+        }\n+\n+        static ObjectBox box(long val) {\n+            return new ObjectBox(WrapperInterface.wrap(val));\n+        }\n+    }\n+\n+    static class RefBox {\n+        LongWrapper.ref content;\n+\n+        RefBox(LongWrapper.ref content) {\n+            this.content = content;\n+        }\n+\n+        static RefBox box_sharp(long val) {\n+            return new RefBox(LongWrapper.wrap(val));\n+        }\n+\n+        static RefBox box(long val) {\n+            return new RefBox((LongWrapper.ref)WrapperInterface.wrap(val));\n+        }\n+    }\n+\n+    static class InlineBox {\n+        LongWrapper content;\n+\n+        InlineBox(long val) {\n+            this.content = LongWrapper.wrap(val);\n+        }\n+\n+        static InlineBox box(long val) {\n+            return new InlineBox(val);\n+        }\n+    }\n+\n+    static class GenericBox<T> {\n+        T content;\n+\n+        static GenericBox<LongWrapper.ref> box_sharp(long val) {\n+            GenericBox<LongWrapper.ref> res = new GenericBox<>();\n+            res.content = LongWrapper.wrap(val);\n+            return res;\n+        }\n+\n+        static GenericBox<WrapperInterface> box(long val) {\n+            GenericBox<WrapperInterface> res = new GenericBox<>();\n+            res.content = WrapperInterface.wrap(val);\n+            return res;\n+        }\n+    }\n+\n+    long[] lArr = {0L, rL, 0L, rL, 0L, rL, 0L, rL, 0L, rL};\n+\n+    \/\/ Test removal of allocations when inline type instance is wrapped into box object\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    public long test109() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += InterfaceBox.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test109_verifier(boolean warmup) {\n+        long res = test109();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    public long test109_sharp() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += InterfaceBox.box_sharp(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test109_sharp_verifier(boolean warmup) {\n+        long res = test109_sharp();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test109 but with ObjectBox\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public long test110() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += ((WrapperInterface)ObjectBox.box(lArr[i]).content).value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test110_verifier(boolean warmup) {\n+        long res = test110();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public long test110_sharp() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += ((WrapperInterface)ObjectBox.box_sharp(lArr[i]).content).value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test110_sharp_verifier(boolean warmup) {\n+        long res = test110_sharp();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test109 but with RefBox\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    public long test111() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += RefBox.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test111_verifier(boolean warmup) {\n+        long res = test111();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    public long test111_sharp() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += RefBox.box_sharp(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test111_sharp_verifier(boolean warmup) {\n+        long res = test111_sharp();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test109 but with InlineBox\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    public long test112() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += InlineBox.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test112_verifier(boolean warmup) {\n+        long res = test112();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test109 but with GenericBox\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public long test113() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += GenericBox.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test113_verifier(boolean warmup) {\n+        long res = test113();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    @Warmup(10000) \/\/ Make sure interface calls are inlined\n+    public long test113_sharp() {\n+        long res = 0;\n+        for (int i = 0 ; i < lArr.length; i++) {\n+            res += GenericBox.box_sharp(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test113_sharp_verifier(boolean warmup) {\n+        long res = test113_sharp();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    static interface WrapperInterface2 {\n+        public long value();\n+\n+        static final InlineWrapper.ref ZERO = new InlineWrapper(0);\n+\n+        public static WrapperInterface2 wrap(long val) {\n+            return (val == 0) ? ZERO.content : new LongWrapper2(val);\n+        }\n+\n+        public static WrapperInterface2 wrap_default(long val) {\n+            return (val == 0) ? LongWrapper2.default : new LongWrapper2(val);\n+        }\n+    }\n+\n+    static primitive class LongWrapper2 implements WrapperInterface2 {\n+        private long val;\n+\n+        public LongWrapper2(long val) {\n+            this.val = val;\n+        }\n+\n+        public long value() {\n+            return val;\n+        }\n+    }\n+\n+    static primitive class InlineWrapper {\n+        WrapperInterface2 content;\n+\n+        public InlineWrapper(long val) {\n+            content = new LongWrapper2(val);\n+        }\n+    }\n+\n+    static class InterfaceBox2 {\n+        WrapperInterface2 content;\n+\n+        public InterfaceBox2(long val, boolean def) {\n+            this.content = def ? WrapperInterface2.wrap_default(val) : WrapperInterface2.wrap(val);\n+        }\n+\n+        static InterfaceBox2 box(long val) {\n+            return new InterfaceBox2(val, false);\n+        }\n+\n+        static InterfaceBox2 box_default(long val) {\n+            return new InterfaceBox2(val, true);\n+        }\n+    }\n+\n+    \/\/ Same as tests above but with ZERO hidden in field of another inline type\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    @Warmup(10000)\n+    public long test114() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += InterfaceBox2.box(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test114_verifier(boolean warmup) {\n+        long res = test114();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    \/\/ Same as test114 but with .default instead of ZERO field\n+    @Test(failOn = ALLOC_G + MEMBAR, match = { PREDICATE_TRAP }, matchCount = { 1 })\n+    @Warmup(10000)\n+    public long test115() {\n+        long res = 0;\n+        for (int i = 0; i < lArr.length; i++) {\n+            res += InterfaceBox2.box_default(lArr[i]).content.value();\n+        }\n+        return res;\n+    }\n+\n+    @DontCompile\n+    public void test115_verifier(boolean warmup) {\n+        long res = test115();\n+        Asserts.assertEquals(res, 5*rL);\n+    }\n+\n+    static MyValueEmpty     fEmpty1;\n+    static MyValueEmpty.ref fEmpty2 = MyValueEmpty.default;\n+           MyValueEmpty     fEmpty3;\n+           MyValueEmpty.ref fEmpty4 = MyValueEmpty.default;\n+\n+    \/\/ Test fields loads\/stores with empty inline types\n+    @Test(failOn = ALLOC + ALLOC_G + LOAD + STORE + TRAP)\n+    public void test116() {\n+        fEmpty1 = fEmpty4;\n+        fEmpty2 = fEmpty1;\n+        fEmpty3 = fEmpty2;\n+        fEmpty4 = fEmpty3;\n+    }\n+\n+    @DontCompile\n+    public void test116_verifier(boolean warmup) {\n+        test116();\n+        Asserts.assertEquals(fEmpty1, fEmpty2);\n+        Asserts.assertEquals(fEmpty2, fEmpty3);\n+        Asserts.assertEquals(fEmpty3, fEmpty4);\n+    }\n+\n+    \/\/ Test array loads\/stores with empty inline types\n+    @Test(failOn = ALLOC + ALLOC_G)\n+    public MyValueEmpty test117(MyValueEmpty[] arr1, MyValueEmpty.ref[] arr2) {\n+        arr1[0] = arr2[0];\n+        arr2[0] = new MyValueEmpty();\n+        return arr1[0];\n+    }\n+\n+    @DontCompile\n+    public void test117_verifier(boolean warmup) {\n+        MyValueEmpty[] arr1 = new MyValueEmpty[]{MyValueEmpty.default};\n+        MyValueEmpty res = test117(arr1, arr1);\n+        Asserts.assertEquals(res, MyValueEmpty.default);\n+        Asserts.assertEquals(arr1[0], MyValueEmpty.default);\n+    }\n+\n+    \/\/ Test acmp with empty inline types\n+    @Test(failOn = ALLOC + ALLOC_G)\n+    public boolean test118(MyValueEmpty v1, MyValueEmpty.ref v2, Object o1) {\n+        return (v1 == v2) && (v2 == o1);\n+    }\n+\n+    @DontCompile\n+    public void test118_verifier(boolean warmup) {\n+        boolean res = test118(MyValueEmpty.default, MyValueEmpty.default, new MyValueEmpty());\n+        Asserts.assertTrue(res);\n+    }\n+\n+    static primitive class EmptyContainer {\n+        private MyValueEmpty empty = MyValueEmpty.default;\n+    }\n+\n+    static primitive class MixedContainer {\n+        public int val = rI;\n+        private EmptyContainer empty = EmptyContainer.default;\n+    }\n+\n+    \/\/ Test re-allocation of empty inline type array during deoptimization\n+    @Test\n+    public void test119(boolean deopt) {\n+        MyValueEmpty[]   array1 = new MyValueEmpty[]{MyValueEmpty.default};\n+        EmptyContainer[] array2 = new EmptyContainer[]{EmptyContainer.default};\n+        MixedContainer[] array3 = new MixedContainer[]{MixedContainer.default};\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test119\"));\n+        }\n+        Asserts.assertEquals(array1[0], MyValueEmpty.default);\n+        Asserts.assertEquals(array2[0], EmptyContainer.default);\n+        Asserts.assertEquals(array3[0], MixedContainer.default);\n+    }\n+\n+    @DontCompile\n+    public void test119_verifier(boolean warmup) {\n+        test119(!warmup);\n+    }\n+\n+    \/\/ Test removal of empty inline type field stores\n+    @Test(failOn = ALLOC + ALLOC_G + LOAD + STORE + FIELD_ACCESS + NULL_CHECK_TRAP + TRAP)\n+    public void test120(MyValueEmpty empty) {\n+        fEmpty1 = empty;\n+        fEmpty3 = empty;\n+        \/\/ fEmpty2 and fEmpty4 could be null, store can't be removed\n+    }\n+\n+    @DontCompile\n+    public void test120_verifier(boolean warmup) {\n+        test120(MyValueEmpty.default);\n+        Asserts.assertEquals(fEmpty1, MyValueEmpty.default);\n+        Asserts.assertEquals(fEmpty2, MyValueEmpty.default);\n+    }\n+\n+    \/\/ Test removal of empty inline type field loads\n+    @Test(failOn = ALLOC + ALLOC_G + LOAD + STORE + FIELD_ACCESS + NULL_CHECK_TRAP + TRAP)\n+    public boolean test121() {\n+        return fEmpty1.equals(fEmpty3);\n+        \/\/ fEmpty2 and fEmpty4 could be null, load can't be removed\n+    }\n+\n+    @DontCompile\n+    public void test121_verifier(boolean warmup) {\n+        boolean res = test121();\n+        Asserts.assertTrue(res);\n+    }\n+\n+    \/\/ Verify that empty inline type field loads check for null holder\n+    @Test()\n+    public MyValueEmpty test122(TestLWorld t) {\n+        return t.fEmpty3;\n+    }\n+\n+    @DontCompile\n+    public void test122_verifier(boolean warmup) {\n+        MyValueEmpty res = test122(this);\n+        Asserts.assertEquals(res, MyValueEmpty.default);\n+        try {\n+            test122(null);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Verify that empty inline type field stores check for null holder\n+    @Test()\n+    public void test123(TestLWorld t) {\n+        t.fEmpty3 = MyValueEmpty.default;\n+    }\n+\n+    @DontCompile\n+    public void test123_verifier(boolean warmup) {\n+        test123(this);\n+        Asserts.assertEquals(fEmpty3, MyValueEmpty.default);\n+        try {\n+            test123(null);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ acmp doesn't need substitutability test when one input is known\n+    \/\/ not to be a value type\n+    @Test(failOn = SUBSTITUTABILITY_TEST)\n+    public boolean test124(Integer o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test124_verifier(boolean warmup) {\n+        test124(42, 42);\n+        test124(42, testValue1);\n+    }\n+\n+    \/\/ acmp doesn't need substitutability test when one input null\n+    @Test(failOn = SUBSTITUTABILITY_TEST)\n+    public boolean test125(Object o1) {\n+        Object o2 = null;\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test125_verifier(boolean warmup) {\n+        test125(testValue1);\n+        test125(null);\n+    }\n+\n+    \/\/ Test inline type that can only be scalarized after loop opts\n+    @Test(failOn = ALLOC + LOAD + STORE)\n+    @Warmup(10000)\n+    public long test126(boolean trap) {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2.ref val = null;\n+\n+        for (int i = 0; i < 4; i++) {\n+            if ((i % 2) == 0) {\n+                val = nonNull;\n+            }\n+        }\n+        \/\/ 'val' is always non-null here but that's only known after loop opts\n+        if (trap) {\n+            \/\/ Uncommon trap with an inline input that can only be scalarized after loop opts\n+            return val.hash();\n+        }\n+        return 0;\n+    }\n+\n+    @DontCompile\n+    public void test126_verifier(boolean warmup) {\n+        long res = test126(false);\n+        Asserts.assertEquals(res, 0L);\n+        if (!warmup) {\n+            res = test126(true);\n+            Asserts.assertEquals(res, testValue2.hash());\n+        }\n+    }\n+\n+    \/\/ Same as test126 but with interface type\n+    @Test(failOn = ALLOC + LOAD + STORE)\n+    @Warmup(10000)\n+    public long test127(boolean trap) {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyInterface val = null;\n+\n+        for (int i = 0; i < 4; i++) {\n+            if ((i % 2) == 0) {\n+                val = nonNull;\n+            }\n+        }\n+        \/\/ 'val' is always non-null here but that's only known after loop opts\n+        if (trap) {\n+            \/\/ Uncommon trap with an inline input that can only be scalarized after loop opts\n+            return val.hash();\n+        }\n+        return 0;\n+    }\n+\n+    @DontCompile\n+    public void test127_verifier(boolean warmup) {\n+        long res = test127(false);\n+        Asserts.assertEquals(res, 0L);\n+        if (!warmup) {\n+            res = test127(true);\n+            Asserts.assertEquals(res, testValue2.hash());\n+        }\n+    }\n+\n+    \/\/ Test inline type that can only be scalarized after CCP\n+    @Test(failOn = ALLOC + LOAD + STORE)\n+    @Warmup(10000)\n+    public long test128(boolean trap) {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2.ref val = null;\n+\n+        int limit = 2;\n+        for (; limit < 4; limit *= 2);\n+        for (int i = 2; i < limit; i++) {\n+            val = nonNull;\n+        }\n+        \/\/ 'val' is always non-null here but that's only known after CCP\n+        if (trap) {\n+            \/\/ Uncommon trap with an inline input that can only be scalarized after CCP\n+            return val.hash();\n+        }\n+        return 0;\n+    }\n+\n+    @DontCompile\n+    public void test128_verifier(boolean warmup) {\n+        long res = test128(false);\n+        Asserts.assertEquals(res, 0L);\n+        if (!warmup) {\n+            res = test128(true);\n+            Asserts.assertEquals(res, testValue2.hash());\n+        }\n+    }\n+\n+    \/\/ Same as test128 but with interface type\n+    @Test(failOn = ALLOC + LOAD + STORE)\n+    @Warmup(10000)\n+    public long test129(boolean trap) {\n+        MyValue2 nonNull = MyValue2.createWithFieldsInline(rI, rD);\n+        MyInterface val = null;\n+\n+        int limit = 2;\n+        for (; limit < 4; limit *= 2);\n+        for (int i = 0; i < limit; i++) {\n+            val = nonNull;\n+        }\n+        \/\/ 'val' is always non-null here but that's only known after CCP\n+        if (trap) {\n+            \/\/ Uncommon trap with an inline input that can only be scalarized after CCP\n+            return val.hash();\n+        }\n+        return 0;\n+    }\n+\n+    @DontCompile\n+    public void test129_verifier(boolean warmup) {\n+        long res = test129(false);\n+        Asserts.assertEquals(res, 0L);\n+        if (!warmup) {\n+            res = test129(true);\n+            Asserts.assertEquals(res, testValue2.hash());\n+        }\n+    }\n+\n+    \/\/ Lock on inline type (known after inlining)\n+    @ForceInline\n+    public Object test130_inlinee() {\n+        return MyValue1.createWithFieldsInline(rI, rL);\n+    }\n+\n+    @Test()\n+    public void test130() {\n+        Object obj = test130_inlinee();\n+        synchronized (obj) {\n+            throw new RuntimeException(\"test130 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test130_verifier(boolean warmup) {\n+        try {\n+            test130();\n+            throw new RuntimeException(\"test130 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Same as test130 but with field load instead of allocation\n+    @ForceInline\n+    public Object test131_inlinee() {\n+        return testValue1;\n+    }\n+\n+    @Test()\n+    public void test131() {\n+        Object obj = test131_inlinee();\n+        synchronized (obj) {\n+            throw new RuntimeException(\"test131 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test131_verifier(boolean warmup) {\n+        try {\n+            test131();\n+            throw new RuntimeException(\"test131 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test locking on object that is known to be an inline type only after CCP\n+    @Test()\n+    @Warmup(10000)\n+    public void test132() {\n+        MyValue2 vt = MyValue2.createWithFieldsInline(rI, rD);\n+        Object obj = Integer.valueOf(42);\n+\n+        int limit = 2;\n+        for (; limit < 4; limit *= 2);\n+        for (int i = 2; i < limit; i++) {\n+            obj = vt;\n+        }\n+        synchronized (obj) {\n+            throw new RuntimeException(\"test132 failed: synchronization on inline type should not succeed\");\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test132_verifier(boolean warmup) {\n+        try {\n+            test132();\n+            throw new RuntimeException(\"test132 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test conditional locking on inline type and non-escaping object\n+    @Test()\n+    public void test133(boolean b) {\n+        Object obj = b ? Integer.valueOf(42) : MyValue2.createWithFieldsInline(rI, rD);\n+        synchronized (obj) {\n+            if (!b) {\n+                throw new RuntimeException(\"test133 failed: synchronization on inline type should not succeed\");\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test133_verifier(boolean warmup) {\n+        test133(true);\n+        try {\n+            test133(false);\n+            throw new RuntimeException(\"test133 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Variant with non-scalarized inline type\n+    @Test()\n+    public static void test134(boolean b) {\n+        Object obj = null;\n+        if (b) {\n+            obj = MyValue2.createWithFieldsInline(rI, rD);\n+        }\n+        synchronized (obj) {\n+\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test134_verifier(boolean warmup) {\n+        try {\n+            test134(true);\n+            throw new RuntimeException(\"test134 failed: no exception thrown\");\n+        } catch (IllegalMonitorStateException ex) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test that acmp of the same inline object is removed\n+    @Test(failOn = ALLOC + LOAD + STORE + NULL_CHECK_TRAP + TRAP)\n+    public static boolean test135() {\n+        MyValue1 val = MyValue1.createWithFieldsInline(rI, rL);\n+        return val == val;\n+    }\n+\n+    @DontCompile\n+    public void test135_verifier(boolean warmup) {\n+        Asserts.assertTrue(test135());\n+    }\n+\n+    \/\/ Same as test135 but with .ref\n+    @Test(failOn = ALLOC + LOAD + STORE + NULL_CHECK_TRAP + TRAP)\n+    public static boolean test136(boolean b) {\n+        MyValue1.ref val = MyValue1.createWithFieldsInline(rI, rL);\n+        if (b) {\n+            val = null;\n+        }\n+        return val == val;\n+    }\n+\n+    @DontCompile\n+    public void test136_verifier(boolean warmup) {\n+        Asserts.assertTrue(test136(false));\n+        Asserts.assertTrue(test136(true));\n+    }\n+\n+    static final primitive class SimpleInlineType {\n+        final int x;\n+        public SimpleInlineType(int x) {\n+            this.x = x;\n+        }\n+    }\n+\n+    \/\/ Test that acmp of different inline objects with same content is removed\n+    @Test(failOn = ALLOC + LOAD + STORE + NULL_CHECK_TRAP + TRAP)\n+    public static boolean test137(int i) {\n+        SimpleInlineType val1 = new SimpleInlineType(i);\n+        SimpleInlineType val2 = new SimpleInlineType(i);\n+        return val1 == val2;\n+    }\n+\n+    @DontCompile\n+    public void test137_verifier(boolean warmup) {\n+        Asserts.assertTrue(test137(rI));\n+    }\n+\n+    \/\/ Same as test137 but with .ref\n+    @Test(failOn = ALLOC + LOAD + STORE + NULL_CHECK_TRAP + TRAP)\n+    public static boolean test138(int i, boolean b) {\n+        SimpleInlineType.ref val1 = new SimpleInlineType(i);\n+        SimpleInlineType.ref val2 = new SimpleInlineType(i);\n+        if (b) {\n+            val1 = null;\n+            val2 = null;\n+        }\n+        return val1 == val2;\n+    }\n+\n+    @DontCompile\n+    public void test138_verifier(boolean warmup) {\n+        Asserts.assertTrue(test138(rI, false));\n+        Asserts.assertTrue(test138(rI, true));\n+    }\n+\n+    static primitive class Test139Value {\n+        Object obj = null;\n+        MyValueEmpty empty = MyValueEmpty.default;\n+    }\n+\n+    static primitive class Test139Wrapper {\n+        Test139Value value = Test139Value.default;\n+    }\n+\n+    @Test(failOn = ALLOC + LOAD + STORE + TRAP)\n+    public MyValueEmpty test139() {\n+        Test139Wrapper w = new Test139Wrapper();\n+        return w.value.empty;\n+    }\n+\n+    @DontCompile\n+    public void test139_verifier(boolean warmup) {\n+        MyValueEmpty empty = test139();\n+        Asserts.assertEquals(empty, MyValueEmpty.default);\n+    }\n+\n+    \/\/ Test calling a method on a loaded but not linked inline type\n+    final primitive class Test140Value {\n+        final int x = 42;\n+        public int get() {\n+            return x;\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(0)\n+    public int test140() {\n+        Test140Value vt = Test140Value.default;\n+        return vt.get();\n+    }\n+\n+    @DontCompile\n+    public void test140_verifier(boolean warmup) {\n+        int result = test140();\n+        Asserts.assertEquals(result, 0);\n+    }\n+\n+    \/\/ Test calling a method on a linked but not initialized inline type\n+    final primitive class Test141Value {\n+        final int x = 42;\n+        public int get() {\n+            return x;\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(0)\n+    public int test141() {\n+        Test141Value vt = Test141Value.default;\n+        return vt.get();\n+    }\n+\n+    @DontCompile\n+    public void test141_verifier(boolean warmup) {\n+        int result = test141();\n+        Asserts.assertEquals(result, 0);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestLWorld.java","additions":3783,"deletions":0,"binary":false,"changes":3783,"status":"added"},{"patch":"@@ -0,0 +1,974 @@\n+\/*\n+ * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.test.lib.Asserts;\n+import java.lang.reflect.Method;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test inline type specific profiling\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires (os.simpleArch == \"x64\")\n+ * @compile TestLWorldProfiling.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI -XX:FlatArrayElementMaxSize=-1\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestLWorldProfiling\n+ *\/\n+public class TestLWorldProfiling extends InlineTypeTest {\n+\n+    static final String[][] scenarios = {\n+        {\"-XX:-UseArrayLoadStoreProfile\",\n+         \"-XX:-UseACmpProfile\",\n+         \"-XX:TypeProfileLevel=0\",\n+         \"-XX:-MonomorphicArrayCheck\" },\n+        { \"-XX:+UseArrayLoadStoreProfile\",\n+          \"-XX:+UseACmpProfile\",\n+          \"-XX:TypeProfileLevel=0\" },\n+        { \"-XX:-UseArrayLoadStoreProfile\",\n+          \"-XX:-UseACmpProfile\",\n+          \"-XX:TypeProfileLevel=222\",\n+          \"-XX:-MonomorphicArrayCheck\" },\n+        { \"-XX:-UseArrayLoadStoreProfile\",\n+          \"-XX:-UseACmpProfile\",\n+          \"-XX:TypeProfileLevel=0\",\n+          \"-XX:-MonomorphicArrayCheck\",\n+          \"-XX:TieredStopAtLevel=4\",\n+          \"-XX:-TieredCompilation\" },\n+        { \"-XX:+UseArrayLoadStoreProfile\",\n+          \"-XX:+UseACmpProfile\",\n+          \"-XX:TypeProfileLevel=0\",\n+          \"-XX:TieredStopAtLevel=4\",\n+          \"-XX:-TieredCompilation\" },\n+        { \"-XX:-UseArrayLoadStoreProfile\",\n+          \"-XX:-UseACmpProfile\",\n+          \"-XX:TypeProfileLevel=222\",\n+          \"-XX:-MonomorphicArrayCheck\",\n+          \"-XX:TieredStopAtLevel=4\",\n+          \"-XX:-TieredCompilation\" }\n+    };\n+\n+    public int getNumScenarios() {\n+        return scenarios.length;\n+    }\n+\n+    public String[] getVMParameters(int scenario) {\n+        return scenarios[scenario];\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestLWorldProfiling test = new TestLWorldProfiling();\n+        test.run(args, MyValue1.class, MyValue2.class);\n+    }\n+\n+    private static final MyValue1 testValue1 = MyValue1.createWithFieldsInline(rI, rL);\n+    private static final MyValue2 testValue2 = MyValue2.createWithFieldsInline(rI, rD);\n+    private static final MyValue1[] testValue1Array = new MyValue1[] {testValue1};\n+    private static final MyValue2[] testValue2Array = new MyValue2[] {testValue2};\n+    private static final Integer[] testIntegerArray = new Integer[] {42};\n+    private static final Long[] testLongArray = new Long[] {42L};\n+    private static final Double[] testDoubleArray = new Double[] {42.0D};\n+    private static final MyValue1.ref[] testValue1NotFlatArray = new MyValue1.ref[] {testValue1};\n+    private static final MyValue1[][] testValue1ArrayArray = new MyValue1[][] {testValue1Array};\n+\n+    \/\/ aaload\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, failOn = LOAD_UNKNOWN_INLINE)\n+    @Test(valid = TypeProfileOn, failOn = LOAD_UNKNOWN_INLINE)\n+    @Test(match = { LOAD_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public Object test1(Object[] array) {\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        if (warmup) {\n+            Object o = test1(testValue1Array);\n+            Asserts.assertEQ(((MyValue1)o).hash(), testValue1.hash());\n+        } else {\n+            Object o = test1(testValue2Array);\n+            Asserts.assertEQ(((MyValue2)o).hash(), testValue2.hash());\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, failOn = LOAD_UNKNOWN_INLINE)\n+    @Test(valid = TypeProfileOn, failOn = LOAD_UNKNOWN_INLINE)\n+    @Test(match = { LOAD_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public Object test2(Object[] array) {\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        if (warmup) {\n+            Object o = test2(testIntegerArray);\n+            Asserts.assertEQ(o, 42);\n+        } else {\n+            Object o = test2(testLongArray);\n+            Asserts.assertEQ(o, 42L);\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(match = { LOAD_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public Object test3(Object[] array) {\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        Object o = test3(testValue1Array);\n+        Asserts.assertEQ(((MyValue1)o).hash(), testValue1.hash());\n+        o = test3(testValue2Array);\n+        Asserts.assertEQ(((MyValue2)o).hash(), testValue2.hash());\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, failOn = LOAD_UNKNOWN_INLINE)\n+    @Test(match = { LOAD_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public Object test4(Object[] array) {\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        if (warmup) {\n+            Object o = test4(testIntegerArray);\n+            Asserts.assertEQ(o, 42);\n+            o = test4(testLongArray);\n+            Asserts.assertEQ(o, 42L);\n+        } else {\n+            Object o = test4(testValue2Array);\n+            Asserts.assertEQ(((MyValue2)o).hash(), testValue2.hash());\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(match = { LOAD_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public Object test5(Object[] array) {\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        Object o = test5(testValue1Array);\n+        Asserts.assertEQ(((MyValue1)o).hash(), testValue1.hash());\n+        o = test5(testValue1NotFlatArray);\n+        Asserts.assertEQ(((MyValue1)o).hash(), testValue1.hash());\n+    }\n+\n+    \/\/ Check that profile data that's useless at the aaload is\n+    \/\/ leveraged at a later point\n+    @DontInline\n+    public void test6_no_inline() {\n+    }\n+\n+\n+    public void test6_helper(Number[] arg) {\n+        if (arg instanceof Long[]) {\n+            test6_no_inline();\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, match = { CALL, CLASS_CHECK_TRAP, NULL_CHECK_TRAP, RANGE_CHECK_TRAP }, matchCount = { 3, 1, 1, 1 })\n+    @Test(valid = TypeProfileOn, match = { CALL, CLASS_CHECK_TRAP, NULL_CHECK_TRAP, RANGE_CHECK_TRAP }, matchCount = { 3, 1, 1, 1 })\n+    @Test(match = { CALL, RANGE_CHECK_TRAP, NULL_CHECK_TRAP }, matchCount = { 5, 1, 1 })\n+    public Object test6(Number[] array) {\n+        Number v = array[0];\n+        test6_helper(array);\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        if (warmup) {\n+            \/\/ pollute profile\n+            test6_helper(testLongArray);\n+            test6_helper(testDoubleArray);\n+        }\n+        test6(testIntegerArray);\n+    }\n+\n+    @DontInline\n+    public void test7_no_inline() {\n+    }\n+\n+\n+    public void test7_helper(Number arg) {\n+        if (arg instanceof Long) {\n+            test7_no_inline();\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, match = { CALL, CLASS_CHECK_TRAP, NULL_CHECK_TRAP, RANGE_CHECK_TRAP }, matchCount = { 4, 1, 2, 1 })\n+    @Test(valid = TypeProfileOn, match = { CALL, CLASS_CHECK_TRAP, NULL_CHECK_TRAP, RANGE_CHECK_TRAP }, matchCount = { 4, 1, 2, 1 })\n+    @Test(match = { CALL, RANGE_CHECK_TRAP, NULL_CHECK_TRAP }, matchCount = { 6, 1, 2 })\n+    public Object test7(Number[] array) {\n+        Number v = array[0];\n+        test7_helper(v);\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        if (warmup) {\n+            \/\/ pollute profile\n+            test7_helper(42L);\n+            test7_helper(42.0D);\n+        }\n+        test7(testIntegerArray);\n+    }\n+\n+    @DontInline\n+    public void test8_no_inline() {\n+    }\n+\n+\n+    public void test8_helper(Object arg) {\n+        if (arg instanceof Long) {\n+            test8_no_inline();\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, match = { CALL, CLASS_CHECK_TRAP, NULL_CHECK_TRAP, RANGE_CHECK_TRAP, UNHANDLED_TRAP, ALLOC_G }, matchCount = { 6, 1, 2, 1, 1, 1 })\n+    @Test(match = { CALL, RANGE_CHECK_TRAP, NULL_CHECK_TRAP, UNHANDLED_TRAP, ALLOC_G }, matchCount = { 6, 1, 2, 1, 1 })\n+    public Object test8(Object[] array) {\n+        Object v = array[0];\n+        test8_helper(v);\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        if (warmup) {\n+            \/\/ pollute profile\n+            test8_helper(42L);\n+            test8_helper(42.0D);\n+        }\n+        test8(testValue1Array);\n+        test8(testValue1NotFlatArray);\n+    }\n+\n+    \/\/ aastore\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(valid = TypeProfileOn, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(match = { STORE_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public void test9(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        test9(testValue1Array, testValue1);\n+        Asserts.assertEQ(testValue1Array[0].hash(), testValue1.hash());\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(valid = TypeProfileOn, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(match = { STORE_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public void test10(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        test10(testIntegerArray, 42);\n+    }\n+\n+    @Warmup(10000)\n+    @Test(match = { STORE_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public void test11(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        test11(testValue1Array, testValue1);\n+        test11(testValue2Array, testValue2);\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(match = { STORE_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public void test12(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        test12(testIntegerArray, 42);\n+        test12(testLongArray, 42L);\n+    }\n+\n+    @Warmup(10000)\n+    @Test(match = { STORE_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public void test13(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        test13(testValue1Array, testValue1);\n+        test13(testValue1NotFlatArray, testValue1);\n+    }\n+\n+    \/\/ MonomorphicArrayCheck\n+    @Warmup(10000)\n+    @Test\n+    public void test14(Number[] array, Number v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean warmup) {\n+        if (warmup) {\n+            test14(testIntegerArray, 42);\n+        } else {\n+            Method m = tests.get(\"TestLWorldProfiling::test14\");\n+            boolean deopt = false;\n+            for (int i = 0; i < 100; i++) {\n+                test14(testIntegerArray, 42);\n+                if (!WHITE_BOX.isMethodCompiled(m, false)) {\n+                    deopt = true;\n+                }\n+            }\n+            if (deopt && !TieredCompilation && !STRESS_CC && ProfileInterpreter && (UseArrayLoadStoreProfile || TypeProfileLevel == 222)) {\n+                throw new RuntimeException(\"Monomorphic array check should rely on profiling and be accurate\");\n+            }\n+        }\n+    }\n+\n+    \/\/ null free array profiling\n+\n+    primitive static class NotFlattenable {\n+        private final Object o1 = null;\n+        private final Object o2 = null;\n+        private final Object o3 = null;\n+        private final Object o4 = null;\n+        private final Object o5 = null;\n+        private final Object o6 = null;\n+    }\n+\n+    private static final NotFlattenable notFlattenable = new NotFlattenable();\n+    private static final NotFlattenable[] testNotFlattenableArray = new NotFlattenable[] { notFlattenable };\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, match = { NULL_CHECK_TRAP }, matchCount = { 2 }, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(valid = TypeProfileOn, match = { NULL_CHECK_TRAP }, matchCount = { 2 }, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(match = { NULL_CHECK_TRAP, STORE_UNKNOWN_INLINE }, matchCount = { 3, 1 })\n+    public void test15(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean warmup) {\n+        test15(testNotFlattenableArray, notFlattenable);\n+        try {\n+            test15(testNotFlattenableArray, null);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException npe) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, match = { NULL_CHECK_TRAP }, matchCount = { 2 }, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(match = { NULL_CHECK_TRAP, STORE_UNKNOWN_INLINE }, matchCount = { 3, 1 })\n+    public void test16(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean warmup) {\n+        test16(testNotFlattenableArray, notFlattenable);\n+        try {\n+            test16(testNotFlattenableArray, null);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException npe) {\n+            \/\/ Expected\n+        }\n+        test16(testIntegerArray, 42);\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, match = { NULL_CHECK_TRAP }, matchCount = { 1 }, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(match = { NULL_CHECK_TRAP, STORE_UNKNOWN_INLINE }, matchCount = { 3, 1 })\n+    public void test17(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean warmup) {\n+        test17(testIntegerArray, 42);\n+        test17(testIntegerArray, null);\n+        testIntegerArray[0] = 42;\n+        test17(testLongArray, 42L);\n+    }\n+\n+    public void test18_helper(Object[] array, Object v) {\n+        array[0] = v;\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, match = { NULL_CHECK_TRAP }, matchCount = { 1 }, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(match = { NULL_CHECK_TRAP, STORE_UNKNOWN_INLINE }, matchCount = { 3, 1 })\n+    public Object test18(Object[] array, Object v1) {\n+        Object v2 = array[0];\n+        test18_helper(array, v1);\n+        return v2;\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        test18_helper(testValue1Array, testValue1); \/\/ pollute profile\n+        test18(testIntegerArray, 42);\n+        test18(testIntegerArray, null);\n+        testIntegerArray[0] = 42;\n+        test18(testLongArray, 42L);\n+    }\n+\n+    \/\/ maybe null free, not flat\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, failOn = LOAD_UNKNOWN_INLINE)\n+    @Test(match = { LOAD_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public Object test19(Object[] array) {\n+        return array[0];\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        Object o = test19(testIntegerArray);\n+        Asserts.assertEQ(o, 42);\n+        o = test19(testNotFlattenableArray);\n+        Asserts.assertEQ(o, notFlattenable);\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ArrayLoadStoreProfileOn, failOn = STORE_UNKNOWN_INLINE)\n+    @Test(match = { STORE_UNKNOWN_INLINE }, matchCount = { 1 })\n+    public void test20(Object[] array, Object o) {\n+        array[0] = o;\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        test20(testIntegerArray, 42);\n+        test20(testNotFlattenableArray, notFlattenable);\n+    }\n+\n+    \/\/ acmp tests\n+\n+    \/\/ branch frequency profiling causes not equal branch to be optimized out\n+    @Warmup(10000)\n+    @Test(failOn = SUBSTITUTABILITY_TEST)\n+    public boolean test21(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        test21(42, 42);\n+        test21(testValue1, testValue1);\n+    }\n+\n+    \/\/ Input profiled non null\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_ASSERT_TRAP }, matchCount = { 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test22(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test22_verifier(boolean warmup) {\n+        test22(42, null);\n+        test22(42.0, null);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test22\"));\n+            test22(42, 42.0);\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test22\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_ASSERT_TRAP }, matchCount = { 1})\n+    @Test(valid = TypeProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_ASSERT_TRAP }, matchCount = { 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test23(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test23_verifier(boolean warmup) {\n+        test23(null, 42);\n+        test23(null, 42.0);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test23\"));\n+            test23(42, 42.0);\n+            if (UseACmpProfile || TypeProfileLevel != 0) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test23\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_ASSERT_TRAP }, matchCount = { 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test24(Object o1, Object o2) {\n+        return o1 != o2;\n+    }\n+\n+    @DontCompile\n+    public void test24_verifier(boolean warmup) {\n+        test24(42, null);\n+        test24(42.0, null);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test24\"));\n+            test24(42, 42.0);\n+             if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test24\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_ASSERT_TRAP }, matchCount = { 1})\n+    @Test(valid = TypeProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_ASSERT_TRAP }, matchCount = { 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test25(Object o1, Object o2) {\n+        return o1 != o2;\n+    }\n+\n+    @DontCompile\n+    public void test25_verifier(boolean warmup) {\n+        test25(null, 42);\n+        test25(null, 42.0);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test25\"));\n+            test25(42, 42.0);\n+            if (UseACmpProfile || TypeProfileLevel != 0) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test25\"));\n+            }\n+        }\n+    }\n+\n+    \/\/ Input profiled not inline type with known type\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(valid = TypeProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test26(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test26_verifier(boolean warmup) {\n+        test26(42, 42);\n+        test26(42, 42.0);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test26\"));\n+            for (int i = 0; i < 10; i++) {\n+                test26(42.0, 42);\n+            }\n+            if (UseACmpProfile || TypeProfileLevel != 0) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test26\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test27(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test27_verifier(boolean warmup) {\n+        test27(42, 42);\n+        test27(42.0, 42);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test27\"));\n+            for (int i = 0; i < 10; i++) {\n+                test27(42, 42.0);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test27\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(valid = TypeProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test28(Object o1, Object o2) {\n+        return o1 != o2;\n+    }\n+\n+    @DontCompile\n+    public void test28_verifier(boolean warmup) {\n+        test28(42, 42);\n+        test28(42, 42.0);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test28\"));\n+            for (int i = 0; i < 10; i++) {\n+                test28(42.0, 42);\n+            }\n+            if (UseACmpProfile || TypeProfileLevel != 0) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test28\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test29(Object o1, Object o2) {\n+        return o1 != o2;\n+    }\n+\n+    @DontCompile\n+    public void test29_verifier(boolean warmup) {\n+        test29(42, 42);\n+        test29(42.0, 42);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test29\"));\n+            for (int i = 0; i < 10; i++) {\n+                test29(42, 42.0);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test29\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST + NULL_CHECK_TRAP, match = { CLASS_CHECK_TRAP }, matchCount = { 1})\n+    @Test(valid = TypeProfileOn, failOn = SUBSTITUTABILITY_TEST + NULL_CHECK_TRAP, match = { CLASS_CHECK_TRAP }, matchCount = { 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test30(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) {\n+        test30(42, 42);\n+        test30(42, 42.0);\n+        test30(null, 42);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test30\"));\n+            for (int i = 0; i < 10; i++) {\n+                test30(42.0, 42);\n+            }\n+            if (UseACmpProfile || TypeProfileLevel != 0) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test30\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST + NULL_CHECK_TRAP)\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test31(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test31_verifier(boolean warmup) {\n+        test31(42, 42);\n+        test31(42.0, 42);\n+        test31(42, null);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test31\"));\n+            for (int i = 0; i < 10; i++) {\n+                test31(42, 42.0);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test31\"));\n+            }\n+        }\n+    }\n+\n+    \/\/ Input profiled not inline type with unknown type\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test32(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test32_verifier(boolean warmup) {\n+        test32(42, 42);\n+        test32(42, testValue1);\n+        test32(42.0, 42);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test32\"));\n+            for (int i = 0; i < 10; i++) {\n+                test32(testValue1, 42);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test32\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test33(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) {\n+        test33(42, 42);\n+        test33(testValue1, 42);\n+        test33(42, 42.0);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test33\"));\n+            for (int i = 0; i < 10; i++) {\n+                test33(42, testValue1);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test33\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test34(Object o1, Object o2) {\n+        return o1 != o2;\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        test34(42, 42);\n+        test34(42, testValue1);\n+        test34(42.0, 42);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test34\"));\n+            for (int i = 0; i < 10; i++) {\n+                test34(testValue1, 42);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test34\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { NULL_CHECK_TRAP, CLASS_CHECK_TRAP }, matchCount = { 1, 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test35(Object o1, Object o2) {\n+        return o1 != o2;\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) {\n+        test35(42, 42);\n+        test35(testValue1, 42);\n+        test35(42, 42.0);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test35\"));\n+            for (int i = 0; i < 10; i++) {\n+                test35(42, testValue1);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test35\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST + NULL_CHECK_TRAP, match = { CLASS_CHECK_TRAP }, matchCount = { 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test36(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test36_verifier(boolean warmup) {\n+        test36(42, 42.0);\n+        test36(42.0, testValue1);\n+        test36(null, 42);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test36\"));\n+            for (int i = 0; i < 10; i++) {\n+                test36(testValue1, 42);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test36\"));\n+            }\n+        }\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST + NULL_CHECK_TRAP)\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1})\n+    public boolean test37(Object o1, Object o2) {\n+        return o1 == o2;\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) {\n+        test37(42.0, 42);\n+        test37(testValue1, 42.0);\n+        test37(42, null);\n+        if (!warmup) {\n+            assertCompiledByC2(tests.get(\"TestLWorldProfiling::test37\"));\n+            for (int i = 0; i < 10; i++) {\n+                test37(42, testValue1);\n+            }\n+            if (UseACmpProfile) {\n+                assertDeoptimizedByC2(tests.get(\"TestLWorldProfiling::test37\"));\n+            }\n+        }\n+    }\n+\n+    \/\/ Test that acmp profile data that's unused at the acmp is fed to\n+    \/\/ speculation and leverage later\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { CLASS_CHECK_TRAP }, matchCount = { 1})\n+    @Test(valid = TypeProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { CLASS_CHECK_TRAP }, matchCount = { 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1 })\n+    public void test38(Object o1, Object o2, Object o3) {\n+        if (o1 == o2) {\n+            test38_helper2();\n+        }\n+        test38_helper(o1, o3);\n+    }\n+\n+    public void test38_helper(Object o1, Object o2) {\n+        if (o1 == o2) {\n+        }\n+    }\n+\n+    public void test38_helper2() {\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        test38(42, 42, 42);\n+        test38_helper(testValue1, testValue2);\n+    }\n+\n+    @Warmup(10000)\n+    @Test(valid = ACmpProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { CLASS_CHECK_TRAP }, matchCount = { 1})\n+    @Test(valid = TypeProfileOn, failOn = SUBSTITUTABILITY_TEST, match = { CLASS_CHECK_TRAP }, matchCount = { 1})\n+    @Test(match = { SUBSTITUTABILITY_TEST }, matchCount = { 1 })\n+    public void test39(Object o1, Object o2, Object o3) {\n+        if (o1 == o2) {\n+            test39_helper2();\n+        }\n+        test39_helper(o2, o3);\n+    }\n+\n+    public void test39_helper(Object o1, Object o2) {\n+        if (o1 == o2) {\n+        }\n+    }\n+\n+    public void test39_helper2() {\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        test39(42, 42, 42);\n+        test39_helper(testValue1, testValue2);\n+    }\n+\n+    \/\/ Test array access with polluted array type profile\n+    static abstract class Test40Abstract { }\n+    static class Test40Class extends Test40Abstract { }\n+    static primitive class Test40Inline extends Test40Abstract { }\n+\n+    @ForceInline\n+    public Object test40_access(Object[] array) {\n+        return array[0];\n+    }\n+\n+    @Warmup(10000)\n+    @Test()\n+    public Object test40(Test40Abstract[] array) {\n+        return test40_access(array);\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) {\n+        \/\/ Make sure multiple implementors of Test40Abstract are loaded\n+        Test40Inline tmp1 = new Test40Inline();\n+        Test40Class tmp2 = new Test40Class();\n+        if (warmup) {\n+            \/\/ Pollute profile with Object[] (exact)\n+            test40_access(new Object[1]);\n+        } else {\n+            \/\/ When inlining test40_access, profiling contradicts actual type of array\n+            test40(new Test40Class[1]);\n+        }\n+    }\n+\n+    \/\/ Same as test40 but with array store\n+    @ForceInline\n+    public void test41_access(Object[] array, Object val) {\n+        array[0] = val;\n+    }\n+\n+    @Warmup(10000)\n+    @Test()\n+    public void test41(Test40Inline[] array, Object val) {\n+        test41_access(array, val);\n+    }\n+\n+    @DontCompile\n+    public void test41_verifier(boolean warmup) {\n+        \/\/ Make sure multiple implementors of Test40Abstract are loaded\n+        Test40Inline tmp1 = new Test40Inline();\n+        Test40Class tmp2 = new Test40Class();\n+        if (warmup) {\n+            \/\/ Pollute profile with exact Object[]\n+            test41_access(new Object[1], new Object());\n+        } else {\n+            \/\/ When inlining test41_access, profiling contradicts actual type of array\n+            test41(new Test40Inline[1], new Test40Inline());\n+        }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestLWorldProfiling.java","additions":974,"deletions":0,"binary":false,"changes":974,"status":"added"},{"patch":"@@ -0,0 +1,492 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+\n+import jdk.test.lib.Asserts;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test method handle support for inline types\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires os.simpleArch == \"x64\"\n+ * @compile TestMethodHandles.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestMethodHandles\n+ *\/\n+public class TestMethodHandles extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        \/\/ Prevent inlining through MethodHandle linkTo adapters to stress the calling convention\n+        case 2: return new String[] {\"-DVerifyIR=false\", \"-XX:CompileCommand=dontinline,java.lang.invoke.DirectMethodHandle::internalMemberName\"};\n+        case 4: return new String[] {\"-XX:CompileCommand=dontinline,java.lang.invoke.DirectMethodHandle::internalMemberName\"};\n+        }\n+        return null;\n+    }\n+\n+    static {\n+        try {\n+            Class<?> clazz = TestMethodHandles.class;\n+            MethodHandles.Lookup lookup = MethodHandles.lookup();\n+\n+            MethodType mt = MethodType.methodType(MyValue3.class);\n+            test1_mh = lookup.findVirtual(clazz, \"test1_target\", mt);\n+            test2_mh = lookup.findVirtual(clazz, \"test2_target\", mt);\n+            test3_mh = lookup.findVirtual(clazz, \"test3_target\", mt);\n+\n+            MethodType test4_mt1 = MethodType.methodType(int.class, MyValue1.class);\n+            MethodType test4_mt2 = MethodType.methodType(MyValue1.class);\n+            MethodHandle test4_mh1 = lookup.findStatic(clazz, \"test4_helper1\", test4_mt1);\n+            MethodHandle test4_mh2 = lookup.findStatic(clazz, \"test4_helper2\", test4_mt2);\n+            test4_mh = MethodHandles.filterReturnValue(test4_mh2, test4_mh1);\n+\n+            MethodType test5_mt = MethodType.methodType(int.class, MyValue1.class);\n+            test5_mh = lookup.findVirtual(clazz, \"test5_target\", test5_mt);\n+\n+            MethodType test6_mt = MethodType.methodType(MyValue3.class);\n+            MethodHandle test6_mh1 = lookup.findVirtual(clazz, \"test6_target1\", test6_mt);\n+            MethodHandle test6_mh2 = lookup.findVirtual(clazz, \"test6_target2\", test6_mt);\n+            MethodType boolean_mt = MethodType.methodType(boolean.class);\n+            MethodHandle test6_mh_test = lookup.findVirtual(clazz, \"test6_test\", boolean_mt);\n+            test6_mh = MethodHandles.guardWithTest(test6_mh_test, test6_mh1, test6_mh2);\n+\n+            MethodType myvalue2_mt = MethodType.methodType(MyValue2.class);\n+            test7_mh1 = lookup.findStatic(clazz, \"test7_target1\", myvalue2_mt);\n+            MethodHandle test7_mh2 = lookup.findStatic(clazz, \"test7_target2\", myvalue2_mt);\n+            MethodHandle test7_mh_test = lookup.findStatic(clazz, \"test7_test\", boolean_mt);\n+            test7_mh = MethodHandles.guardWithTest(test7_mh_test,\n+                                                    MethodHandles.invoker(myvalue2_mt),\n+                                                    MethodHandles.dropArguments(test7_mh2, 0, MethodHandle.class));\n+\n+            MethodHandle test8_mh1 = lookup.findStatic(clazz, \"test8_target1\", myvalue2_mt);\n+            test8_mh2 = lookup.findStatic(clazz, \"test8_target2\", myvalue2_mt);\n+            MethodHandle test8_mh_test = lookup.findStatic(clazz, \"test8_test\", boolean_mt);\n+            test8_mh = MethodHandles.guardWithTest(test8_mh_test,\n+                                                    MethodHandles.dropArguments(test8_mh1, 0, MethodHandle.class),\n+                                                    MethodHandles.invoker(myvalue2_mt));\n+\n+            MethodType test9_mt = MethodType.methodType(MyValue3.class);\n+            MethodHandle test9_mh1 = lookup.findVirtual(clazz, \"test9_target1\", test9_mt);\n+            MethodHandle test9_mh2 = lookup.findVirtual(clazz, \"test9_target2\", test9_mt);\n+            MethodHandle test9_mh3 = lookup.findVirtual(clazz, \"test9_target3\", test9_mt);\n+            MethodType test9_mt2 = MethodType.methodType(boolean.class);\n+            MethodHandle test9_mh_test1 = lookup.findVirtual(clazz, \"test9_test1\", test9_mt2);\n+            MethodHandle test9_mh_test2 = lookup.findVirtual(clazz, \"test9_test2\", test9_mt2);\n+            test9_mh = MethodHandles.guardWithTest(test9_mh_test1,\n+                                                    test9_mh1,\n+                                                    MethodHandles.guardWithTest(test9_mh_test2, test9_mh2, test9_mh3));\n+\n+            MethodType test10_mt = MethodType.methodType(MyValue2.class);\n+            MethodHandle test10_mh1 = lookup.findStatic(clazz, \"test10_target1\", test10_mt);\n+            test10_mh2 = lookup.findStatic(clazz, \"test10_target2\", test10_mt);\n+            test10_mh3 = lookup.findStatic(clazz, \"test10_target3\", test10_mt);\n+            MethodType test10_mt2 = MethodType.methodType(boolean.class);\n+            MethodType test10_mt3 = MethodType.methodType(MyValue2.class);\n+            MethodHandle test10_mh_test1 = lookup.findStatic(clazz, \"test10_test1\", test10_mt2);\n+            MethodHandle test10_mh_test2 = lookup.findStatic(clazz, \"test10_test2\", test10_mt2);\n+            test10_mh = MethodHandles.guardWithTest(test10_mh_test1,\n+                                                    MethodHandles.dropArguments(test10_mh1, 0, MethodHandle.class, MethodHandle.class),\n+                                                    MethodHandles.guardWithTest(test10_mh_test2,\n+                                                                                MethodHandles.dropArguments(MethodHandles.invoker(test10_mt3), 1, MethodHandle.class),\n+                                                                                MethodHandles.dropArguments(MethodHandles.invoker(test10_mt3), 0, MethodHandle.class))\n+                                                    );\n+\n+            MethodHandle test11_mh1 = lookup.findStatic(clazz, \"test11_target1\", myvalue2_mt);\n+            test11_mh2 = lookup.findStatic(clazz, \"test11_target2\", myvalue2_mt);\n+            MethodHandle test11_mh_test = lookup.findStatic(clazz, \"test11_test\", boolean_mt);\n+            test11_mh = MethodHandles.guardWithTest(test11_mh_test,\n+                                                    MethodHandles.dropArguments(test11_mh1, 0, MethodHandle.class),\n+                                                    MethodHandles.invoker(myvalue2_mt));\n+        } catch (NoSuchMethodException | IllegalAccessException e) {\n+            e.printStackTrace();\n+            throw new RuntimeException(\"Method handle lookup failed\");\n+        }\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestMethodHandles test = new TestMethodHandles();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class, MyValue3.class, MyValue3Inline.class);\n+    }\n+\n+    \/\/ Everything inlined\n+    final MyValue3 test1_vt = MyValue3.create();\n+\n+    @ForceInline\n+    MyValue3 test1_target() {\n+        return test1_vt;\n+    }\n+\n+    static final MethodHandle test1_mh;\n+\n+    @Test(valid = InlineTypeReturnedAsFieldsOn, failOn = ALLOC + STORE + CALL)\n+    @Test(valid = InlineTypeReturnedAsFieldsOff, match = { ALLOC, STORE }, matchCount = { 1, 14 })\n+    public MyValue3 test1() throws Throwable {\n+        return (MyValue3)test1_mh.invokeExact(this);\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) throws Throwable {\n+        MyValue3 vt = test1();\n+        test1_vt.verify(vt);\n+    }\n+\n+    \/\/ Leaf method not inlined but returned type is known\n+    final MyValue3 test2_vt = MyValue3.create();\n+    @DontInline\n+    MyValue3 test2_target() {\n+        return test2_vt;\n+    }\n+\n+    static final MethodHandle test2_mh;\n+\n+    @Test\n+    public MyValue3 test2() throws Throwable {\n+        return (MyValue3)test2_mh.invokeExact(this);\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) throws Throwable {\n+        Method helper_m = getClass().getDeclaredMethod(\"test2_target\");\n+        if (!warmup && USE_COMPILER && !WHITE_BOX.isMethodCompiled(helper_m, false)) {\n+            enqueueMethodForCompilation(helper_m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            Asserts.assertTrue(WHITE_BOX.isMethodCompiled(helper_m, false), \"test2_target not compiled\");\n+        }\n+        MyValue3 vt = test2();\n+        test2_vt.verify(vt);\n+    }\n+\n+    \/\/ Leaf method not inlined and returned type not known\n+    final MyValue3 test3_vt = MyValue3.create();\n+    @DontInline\n+    MyValue3 test3_target() {\n+        return test3_vt;\n+    }\n+\n+    static final MethodHandle test3_mh;\n+\n+    @Test\n+    public MyValue3 test3() throws Throwable {\n+        return (MyValue3)test3_mh.invokeExact(this);\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) throws Throwable {\n+        \/\/ hack so C2 doesn't know the target of the invoke call\n+        Class c = Class.forName(\"java.lang.invoke.DirectMethodHandle\");\n+        Method m = c.getDeclaredMethod(\"internalMemberName\", Object.class);\n+        WHITE_BOX.testSetDontInlineMethod(m, warmup);\n+        MyValue3 vt = test3();\n+        test3_vt.verify(vt);\n+    }\n+\n+    \/\/ When test75_helper1 is inlined in test75, the method handle\n+    \/\/ linker that called it is passed a pointer to a copy of vt\n+    \/\/ stored in memory. The method handle linker needs to load the\n+    \/\/ fields from memory before it inlines test75_helper1.\n+    static public int test4_helper1(MyValue1 vt) {\n+        return vt.x;\n+    }\n+\n+    static MyValue1 test4_vt = MyValue1.createWithFieldsInline(rI, rL);\n+    static public MyValue1 test4_helper2() {\n+        return test4_vt;\n+    }\n+\n+    static final MethodHandle test4_mh;\n+\n+    @Test\n+    public int test4() throws Throwable {\n+        return (int)test4_mh.invokeExact();\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) throws Throwable {\n+        int i = test4();\n+        Asserts.assertEQ(i, test4_vt.x);\n+    }\n+\n+    \/\/ Test method handle call with inline type argument\n+    public int test5_target(MyValue1 vt) {\n+        return vt.x;\n+    }\n+\n+    static final MethodHandle test5_mh;\n+    MyValue1 test5_vt = MyValue1.createWithFieldsInline(rI, rL);\n+\n+    @Test\n+    public int test5() throws Throwable {\n+        return (int)test5_mh.invokeExact(this, test5_vt);\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) throws Throwable {\n+        int i = test5();\n+        Asserts.assertEQ(i, test5_vt.x);\n+    }\n+\n+    \/\/ Return of target1 and target2 merged in a Lambda Form as an\n+    \/\/ Object. Shouldn't cause any allocation\n+    final MyValue3 test6_vt1 = MyValue3.create();\n+    @ForceInline\n+    MyValue3 test6_target1() {\n+        return test6_vt1;\n+    }\n+\n+    final MyValue3 test6_vt2 = MyValue3.create();\n+    @ForceInline\n+    MyValue3 test6_target2() {\n+        return test6_vt2;\n+    }\n+\n+    boolean test6_bool = true;\n+    @ForceInline\n+    boolean test6_test() {\n+        return test6_bool;\n+    }\n+\n+    static final MethodHandle test6_mh;\n+\n+    @Test(valid = InlineTypeReturnedAsFieldsOn, failOn = ALLOC + ALLOCA + STORE + STORE_INLINE_FIELDS)\n+    @Test(valid = InlineTypeReturnedAsFieldsOff)\n+    public MyValue3 test6() throws Throwable {\n+        return (MyValue3)test6_mh.invokeExact(this);\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) throws Throwable {\n+        test6_bool = !test6_bool;\n+        MyValue3 vt = test6();\n+        vt.verify(test6_bool ? test6_vt1 : test6_vt2);\n+    }\n+\n+    \/\/ Similar as above but with the method handle for target1 not\n+    \/\/ constant. Shouldn't cause any allocation.\n+    @ForceInline\n+    static MyValue2 test7_target1() {\n+        return MyValue2.createWithFieldsInline(rI, rD);\n+    }\n+\n+    @ForceInline\n+    static MyValue2 test7_target2() {\n+        return MyValue2.createWithFieldsInline(rI+1, rD+1);\n+    }\n+\n+    static boolean test7_bool = true;\n+    @ForceInline\n+    static boolean test7_test() {\n+        return test7_bool;\n+    }\n+\n+    static final MethodHandle test7_mh;\n+    static MethodHandle test7_mh1;\n+\n+    @Test\n+    public long test7() throws Throwable {\n+        return ((MyValue2)test7_mh.invokeExact(test7_mh1)).hash();\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) throws Throwable {\n+        test7_bool = !test7_bool;\n+        long hash = test7();\n+        Asserts.assertEQ(hash, MyValue2.createWithFieldsInline(rI+(test7_bool ? 0 : 1), rD+(test7_bool ? 0 : 1)).hash());\n+    }\n+\n+    \/\/ Same as above but with the method handle for target2 not\n+    \/\/ constant. Shouldn't cause any allocation.\n+    @ForceInline\n+    static MyValue2 test8_target1() {\n+        return MyValue2.createWithFieldsInline(rI, rD);\n+    }\n+\n+    @ForceInline\n+    static MyValue2 test8_target2() {\n+        return MyValue2.createWithFieldsInline(rI+1, rD+1);\n+    }\n+\n+    static boolean test8_bool = true;\n+    @ForceInline\n+    static boolean test8_test() {\n+        return test8_bool;\n+    }\n+\n+    static final MethodHandle test8_mh;\n+    static MethodHandle test8_mh2;\n+\n+    @Test\n+    public long test8() throws Throwable {\n+        return ((MyValue2)test8_mh.invokeExact(test8_mh2)).hash();\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) throws Throwable {\n+        test8_bool = !test8_bool;\n+        long hash = test8();\n+        Asserts.assertEQ(hash, MyValue2.createWithFieldsInline(rI+(test8_bool ? 0 : 1), rD+(test8_bool ? 0 : 1)).hash());\n+    }\n+\n+    \/\/ Return of target1, target2 and target3 merged in Lambda Forms\n+    \/\/ as an Object. Shouldn't cause any allocation\n+    final MyValue3 test9_vt1 = MyValue3.create();\n+    @ForceInline\n+    MyValue3 test9_target1() {\n+        return test9_vt1;\n+    }\n+\n+    final MyValue3 test9_vt2 = MyValue3.create();\n+    @ForceInline\n+    MyValue3 test9_target2() {\n+        return test9_vt2;\n+    }\n+\n+    final MyValue3 test9_vt3 = MyValue3.create();\n+    @ForceInline\n+    MyValue3 test9_target3() {\n+        return test9_vt3;\n+    }\n+\n+    boolean test9_bool1 = true;\n+    @ForceInline\n+    boolean test9_test1() {\n+        return test9_bool1;\n+    }\n+\n+    boolean test9_bool2 = true;\n+    @ForceInline\n+    boolean test9_test2() {\n+        return test9_bool2;\n+    }\n+\n+    static final MethodHandle test9_mh;\n+\n+    @Test(valid = InlineTypeReturnedAsFieldsOn, failOn = ALLOC + ALLOCA + STORE + STORE_INLINE_FIELDS)\n+    @Test(valid = InlineTypeReturnedAsFieldsOff)\n+    public MyValue3 test9() throws Throwable {\n+        return (MyValue3)test9_mh.invokeExact(this);\n+    }\n+\n+    static int test9_i = 0;\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) throws Throwable {\n+        test9_i++;\n+        test9_bool1 = (test9_i % 2) == 0;\n+        test9_bool2 = (test9_i % 3) == 0;\n+        MyValue3 vt = test9();\n+        vt.verify(test9_bool1 ? test9_vt1 : (test9_bool2 ? test9_vt2 : test9_vt3));\n+    }\n+\n+    \/\/ Same as above but with non constant target2 and target3\n+    @ForceInline\n+    static MyValue2 test10_target1() {\n+        return MyValue2.createWithFieldsInline(rI, rD);\n+    }\n+\n+    @ForceInline\n+    static MyValue2 test10_target2() {\n+        return MyValue2.createWithFieldsInline(rI+1, rD+1);\n+    }\n+\n+    @ForceInline\n+    static MyValue2 test10_target3() {\n+        return MyValue2.createWithFieldsInline(rI+2, rD+2);\n+    }\n+\n+    static boolean test10_bool1 = true;\n+    @ForceInline\n+    static boolean test10_test1() {\n+        return test10_bool1;\n+    }\n+\n+    static boolean test10_bool2 = true;\n+    @ForceInline\n+    static boolean test10_test2() {\n+        return test10_bool2;\n+    }\n+\n+    static final MethodHandle test10_mh;\n+    static MethodHandle test10_mh2;\n+    static MethodHandle test10_mh3;\n+\n+    @Test\n+    public long test10() throws Throwable {\n+        return ((MyValue2)test10_mh.invokeExact(test10_mh2, test10_mh3)).hash();\n+    }\n+\n+    static int test10_i = 0;\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) throws Throwable {\n+        test10_i++;\n+        test10_bool1 = (test10_i % 2) == 0;\n+        test10_bool2 = (test10_i % 3) == 0;\n+        long hash = test10();\n+        int i = rI + (test10_bool1 ? 0 : (test10_bool2 ? 1 : 2));\n+        double d = rD + (test10_bool1 ? 0 : (test10_bool2 ? 1 : 2));\n+        Asserts.assertEQ(hash, MyValue2.createWithFieldsInline(i, d).hash());\n+    }\n+\n+    static int test11_i = 0;\n+\n+    @ForceInline\n+    static MyValue2 test11_target1() {\n+        return MyValue2.createWithFieldsInline(rI+test11_i, rD+test11_i);\n+    }\n+\n+    @ForceInline\n+    static MyValue2 test11_target2() {\n+        return MyValue2.createWithFieldsInline(rI-test11_i, rD-test11_i);\n+    }\n+\n+    @ForceInline\n+    static boolean test11_test() {\n+        return (test11_i % 100) == 0;\n+    }\n+\n+    static final MethodHandle test11_mh;\n+    static MethodHandle test11_mh2;\n+\n+    \/\/ Check that a buffered inline type returned by a compiled lambda form\n+    \/\/ is properly handled by the caller.\n+    @Test\n+    @Warmup(11000)\n+    public long test11() throws Throwable {\n+        return ((MyValue2)test11_mh.invokeExact(test11_mh2)).hash();\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) throws Throwable {\n+        test11_i++;\n+        long hash = test11();\n+        boolean b = (test11_i % 100) == 0;\n+        Asserts.assertEQ(hash, MyValue2.createWithFieldsInline(rI+test11_i * (b ? 1 : -1), rD+test11_i * (b ? 1 : -1)).hash());\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestMethodHandles.java","additions":492,"deletions":0,"binary":false,"changes":492,"status":"added"},{"patch":"@@ -0,0 +1,1908 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/**\n+ * @test TestNewAcmp\n+ * @summary Verifies correctness of the new acmp bytecode.\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @compile TestNewAcmp.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.TestNewAcmp\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.process.ProcessTools;\n+import jdk.test.lib.process.OutputAnalyzer;\n+import java.lang.annotation.Retention;\n+import java.lang.annotation.RetentionPolicy;\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+import java.util.regex.Pattern;\n+import java.util.regex.Matcher;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import sun.hotspot.WhiteBox;\n+\n+\n+interface MyInterface {\n+\n+}\n+\n+abstract class MyAbstract implements MyInterface {\n+\n+\n+}\n+\n+primitive class MyValue1 extends MyAbstract {\n+    final int x;\n+\n+    MyValue1(int x) {\n+        this.x = x;\n+    }\n+\n+    static MyValue1 createDefault() {\n+        return MyValue1.default;\n+    }\n+\n+    static MyValue1 setX(MyValue1 v, int x) {\n+        return new MyValue1(x);\n+    }\n+}\n+\n+primitive class MyValue2 extends MyAbstract {\n+    final int x;\n+\n+    MyValue2(int x) {\n+        this.x = x;\n+    }\n+\n+    static MyValue2 createDefault() {\n+        return MyValue2.default;\n+    }\n+\n+    static MyValue2 setX(MyValue2 v, int x) {\n+        return new MyValue2(x);\n+    }\n+}\n+\n+class MyObject extends MyAbstract {\n+    int x;\n+}\n+\n+\/\/ Mark test methods that return false if the argument is null\n+@Retention(RetentionPolicy.RUNTIME)\n+@interface FalseIfNull { }\n+\n+\/\/ Mark test methods that return true if the argument is null\n+@Retention(RetentionPolicy.RUNTIME)\n+@interface TrueIfNull { }\n+\n+public class TestNewAcmp {\n+\n+    public boolean testEq01_1(Object u1, Object u2) {\n+        return get(u1) == u2; \/\/ new acmp\n+    }\n+\n+    public boolean testEq01_2(Object u1, Object u2) {\n+        return u1 == get(u2); \/\/ new acmp\n+    }\n+\n+    public boolean testEq01_3(Object u1, Object u2) {\n+        return get(u1) == get(u2); \/\/ new acmp\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq01_4(Object u1, Object u2) {\n+        return getNotNull(u1) == u2; \/\/ new acmp without null check\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq01_5(Object u1, Object u2) {\n+        return u1 == getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq01_6(Object u1, Object u2) {\n+        return getNotNull(u1) == getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    public boolean testEq02_1(MyValue1 v1, MyValue1 v2) {\n+        return get(v1) == (Object)v2; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq02_2(MyValue1 v1, MyValue1 v2) {\n+        return (Object)v1 == get(v2); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq02_3(MyValue1 v1, MyValue1 v2) {\n+        return get(v1) == get(v2); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq03_1(MyValue1 v, Object u) {\n+        return get(v) == u; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq03_2(MyValue1 v, Object u) {\n+        return (Object)v == get(u); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq03_3(MyValue1 v, Object u) {\n+        return get(v) == get(u); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq04_1(Object u, MyValue1 v) {\n+        return get(u) == (Object)v; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq04_2(Object u, MyValue1 v) {\n+        return u == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq04_3(Object u, MyValue1 v) {\n+        return get(u) == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq05_1(MyObject o, MyValue1 v) {\n+        return get(o) == (Object)v; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq05_2(MyObject o, MyValue1 v) {\n+        return o == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq05_3(MyObject o, MyValue1 v) {\n+        return get(o) == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq06_1(MyValue1 v, MyObject o) {\n+        return get(v) == o; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq06_2(MyValue1 v, MyObject o) {\n+        return (Object)v == get(o); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq06_3(MyValue1 v, MyObject o) {\n+        return get(v) == get(o); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq07_1(MyValue1 v1, MyValue1 v2) {\n+        return getNotNull(v1) == (Object)v2; \/\/ false\n+    }\n+\n+    public boolean testEq07_2(MyValue1 v1, MyValue1 v2) {\n+        return (Object)v1 == getNotNull(v2); \/\/ false\n+    }\n+\n+    public boolean testEq07_3(MyValue1 v1, MyValue1 v2) {\n+        return getNotNull(v1) == getNotNull(v2); \/\/ false\n+    }\n+\n+    public boolean testEq08_1(MyValue1 v, Object u) {\n+        return getNotNull(v) == u; \/\/ false\n+    }\n+\n+    public boolean testEq08_2(MyValue1 v, Object u) {\n+        return (Object)v == getNotNull(u); \/\/ false\n+    }\n+\n+    public boolean testEq08_3(MyValue1 v, Object u) {\n+        return getNotNull(v) == getNotNull(u); \/\/ false\n+    }\n+\n+    public boolean testEq09_1(Object u, MyValue1 v) {\n+        return getNotNull(u) == (Object)v; \/\/ false\n+    }\n+\n+    public boolean testEq09_2(Object u, MyValue1 v) {\n+        return u == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq09_3(Object u, MyValue1 v) {\n+        return getNotNull(u) == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq10_1(MyObject o, MyValue1 v) {\n+        return getNotNull(o) == (Object)v; \/\/ false\n+    }\n+\n+    public boolean testEq10_2(MyObject o, MyValue1 v) {\n+        return o == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq10_3(MyObject o, MyValue1 v) {\n+        return getNotNull(o) == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq11_1(MyValue1 v, MyObject o) {\n+        return getNotNull(v) == o; \/\/ false\n+    }\n+\n+    public boolean testEq11_2(MyValue1 v, MyObject o) {\n+        return (Object)v == getNotNull(o); \/\/ false\n+    }\n+\n+    public boolean testEq11_3(MyValue1 v, MyObject o) {\n+        return getNotNull(v) == getNotNull(o); \/\/ false\n+    }\n+\n+    public boolean testEq12_1(MyObject o1, MyObject o2) {\n+        return get(o1) == o2; \/\/ old acmp\n+    }\n+\n+    public boolean testEq12_2(MyObject o1, MyObject o2) {\n+        return o1 == get(o2); \/\/ old acmp\n+    }\n+\n+    public boolean testEq12_3(MyObject o1, MyObject o2) {\n+        return get(o1) == get(o2); \/\/ old acmp\n+    }\n+\n+    public boolean testEq13_1(Object u, MyObject o) {\n+        return get(u) == o; \/\/ old acmp\n+    }\n+\n+    public boolean testEq13_2(Object u, MyObject o) {\n+        return u == get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testEq13_3(Object u, MyObject o) {\n+        return get(u) == get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testEq14_1(MyObject o, Object u) {\n+        return get(o) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testEq14_2(MyObject o, Object u) {\n+        return o == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq14_3(MyObject o, Object u) {\n+        return get(o) == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq15_1(Object[] a, Object u) {\n+        return get(a) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testEq15_2(Object[] a, Object u) {\n+        return a == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq15_3(Object[] a, Object u) {\n+        return get(a) == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq16_1(Object u, Object[] a) {\n+        return get(u) == a; \/\/ old acmp\n+    }\n+\n+    public boolean testEq16_2(Object u, Object[] a) {\n+        return u == get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testEq16_3(Object u, Object[] a) {\n+        return get(u) == get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testEq17_1(Object[] a, MyValue1 v) {\n+        return get(a) == (Object)v; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq17_2(Object[] a, MyValue1 v) {\n+        return a == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq17_3(Object[] a, MyValue1 v) {\n+        return get(a) == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq18_1(MyValue1 v, Object[] a) {\n+        return get(v) == a; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq18_2(MyValue1 v, Object[] a) {\n+        return (Object)v == get(a); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq18_3(MyValue1 v, Object[] a) {\n+        return get(v) == get(a); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq19_1(Object[] a, MyValue1 v) {\n+        return getNotNull(a) == (Object)v; \/\/ false\n+    }\n+\n+    public boolean testEq19_2(Object[] a, MyValue1 v) {\n+        return a == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq19_3(Object[] a, MyValue1 v) {\n+        return getNotNull(a) == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq20_1(MyValue1 v, Object[] a) {\n+        return getNotNull(v) == a; \/\/ false\n+    }\n+\n+    public boolean testEq20_2(MyValue1 v, Object[] a) {\n+        return (Object)v == getNotNull(a); \/\/ false\n+    }\n+\n+    public boolean testEq20_3(MyValue1 v, Object[] a) {\n+        return getNotNull(v) == getNotNull(a); \/\/ false\n+    }\n+\n+    public boolean testEq21_1(MyInterface u1, MyInterface u2) {\n+        return get(u1) == u2; \/\/ new acmp\n+    }\n+\n+    public boolean testEq21_2(MyInterface u1, MyInterface u2) {\n+        return u1 == get(u2); \/\/ new acmp\n+    }\n+\n+    public boolean testEq21_3(MyInterface u1, MyInterface u2) {\n+        return get(u1) == get(u2); \/\/ new acmp\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq21_4(MyInterface u1, MyInterface u2) {\n+        return getNotNull(u1) == u2; \/\/ new acmp without null check\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq21_5(MyInterface u1, MyInterface u2) {\n+        return u1 == getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq21_6(MyInterface u1, MyInterface u2) {\n+        return getNotNull(u1) == getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    public boolean testEq21_7(MyAbstract u1, MyAbstract u2) {\n+        return get(u1) == u2; \/\/ new acmp\n+    }\n+\n+    public boolean testEq21_8(MyAbstract u1, MyAbstract u2) {\n+        return u1 == get(u2); \/\/ new acmp\n+    }\n+\n+    public boolean testEq21_9(MyAbstract u1, MyAbstract u2) {\n+        return get(u1) == get(u2); \/\/ new acmp\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq21_10(MyAbstract u1, MyAbstract u2) {\n+        return getNotNull(u1) == u2; \/\/ new acmp without null check\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq21_11(MyAbstract u1, MyAbstract u2) {\n+        return u1 == getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    @FalseIfNull\n+    public boolean testEq21_12(MyAbstract u1, MyAbstract u2) {\n+        return getNotNull(u1) == getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    public boolean testEq22_1(MyValue1 v, MyInterface u) {\n+        return get(v) == u; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq22_2(MyValue1 v, MyInterface u) {\n+        return (Object)v == get(u); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq22_3(MyValue1 v, MyInterface u) {\n+        return get(v) == get(u); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq22_4(MyValue1 v, MyAbstract u) {\n+        return get(v) == u; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq22_5(MyValue1 v, MyAbstract u) {\n+        return (Object)v == get(u); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq22_6(MyValue1 v, MyAbstract u) {\n+        return get(v) == get(u); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq23_1(MyInterface u, MyValue1 v) {\n+        return get(u) == (Object)v; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq23_2(MyInterface u, MyValue1 v) {\n+        return u == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq23_3(MyInterface u, MyValue1 v) {\n+        return get(u) == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq23_4(MyAbstract u, MyValue1 v) {\n+        return get(u) == (Object)v; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq23_5(MyAbstract u, MyValue1 v) {\n+        return u == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq23_6(MyAbstract u, MyValue1 v) {\n+        return get(u) == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq24_1(MyValue1 v, MyInterface u) {\n+        return getNotNull(v) == u; \/\/ false\n+    }\n+\n+    public boolean testEq24_2(MyValue1 v, MyInterface u) {\n+        return (Object)v == getNotNull(u); \/\/ false\n+    }\n+\n+    public boolean testEq24_3(MyValue1 v, MyInterface u) {\n+        return getNotNull(v) == getNotNull(u); \/\/ false\n+    }\n+\n+    public boolean testEq24_4(MyValue1 v, MyAbstract u) {\n+        return getNotNull(v) == u; \/\/ false\n+    }\n+\n+    public boolean testEq24_5(MyValue1 v, MyAbstract u) {\n+        return (Object)v == getNotNull(u); \/\/ false\n+    }\n+\n+    public boolean testEq24_6(MyValue1 v, MyAbstract u) {\n+        return getNotNull(v) == getNotNull(u); \/\/ false\n+    }\n+\n+    public boolean testEq25_1(MyInterface u, MyValue1 v) {\n+        return getNotNull(u) == (Object)v; \/\/ false\n+    }\n+\n+    public boolean testEq25_2(MyInterface u, MyValue1 v) {\n+        return u == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq25_3(MyInterface u, MyValue1 v) {\n+        return getNotNull(u) == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq25_4(MyAbstract u, MyValue1 v) {\n+        return getNotNull(u) == (Object)v; \/\/ false\n+    }\n+\n+    public boolean testEq25_5(MyAbstract u, MyValue1 v) {\n+        return u == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq25_6(MyAbstract u, MyValue1 v) {\n+        return getNotNull(u) == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq26_1(MyInterface u, MyObject o) {\n+        return get(u) == o; \/\/ old acmp\n+    }\n+\n+    public boolean testEq26_2(MyInterface u, MyObject o) {\n+        return u == get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testEq26_3(MyInterface u, MyObject o) {\n+        return get(u) == get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testEq26_4(MyAbstract u, MyObject o) {\n+        return get(u) == o; \/\/ old acmp\n+    }\n+\n+    public boolean testEq26_5(MyAbstract u, MyObject o) {\n+        return u == get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testEq26_6(MyAbstract u, MyObject o) {\n+        return get(u) == get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testEq27_1(MyObject o, MyInterface u) {\n+        return get(o) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testEq27_2(MyObject o, MyInterface u) {\n+        return o == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq27_3(MyObject o, MyInterface u) {\n+        return get(o) == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq27_4(MyObject o, MyAbstract u) {\n+        return get(o) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testEq27_5(MyObject o, MyAbstract u) {\n+        return o == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq27_6(MyObject o, MyAbstract u) {\n+        return get(o) == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq28_1(MyInterface[] a, MyInterface u) {\n+        return get(a) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testEq28_2(MyInterface[] a, MyInterface u) {\n+        return a == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq28_3(MyInterface[] a, MyInterface u) {\n+        return get(a) == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq28_4(MyAbstract[] a, MyAbstract u) {\n+        return get(a) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testEq28_5(MyAbstract[] a, MyAbstract u) {\n+        return a == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq28_6(MyAbstract[] a, MyAbstract u) {\n+        return get(a) == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testEq29_1(MyInterface u, MyInterface[] a) {\n+        return get(u) == a; \/\/ old acmp\n+    }\n+\n+    public boolean testEq29_2(MyInterface u, MyInterface[] a) {\n+        return u == get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testEq29_3(MyInterface u, MyInterface[] a) {\n+        return get(u) == get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testEq29_4(MyAbstract u, MyAbstract[] a) {\n+        return get(u) == a; \/\/ old acmp\n+    }\n+\n+    public boolean testEq29_5(MyAbstract u, MyAbstract[] a) {\n+        return u == get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testEq29_6(MyAbstract u, MyAbstract[] a) {\n+        return get(u) == get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testEq30_1(MyInterface[] a, MyValue1 v) {\n+        return get(a) == (Object)v; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq30_2(MyInterface[] a, MyValue1 v) {\n+        return a == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq30_3(MyInterface[] a, MyValue1 v) {\n+        return get(a) == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq30_4(MyAbstract[] a, MyValue1 v) {\n+        return get(a) == (Object)v; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq30_5(MyAbstract[] a, MyValue1 v) {\n+        return a == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq30_6(MyAbstract[] a, MyValue1 v) {\n+        return get(a) == get(v); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq31_1(MyValue1 v, MyInterface[] a) {\n+        return get(v) == a; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq31_2(MyValue1 v, MyInterface[] a) {\n+        return (Object)v == get(a); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq31_3(MyValue1 v, MyInterface[] a) {\n+        return get(v) == get(a); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq31_4(MyValue1 v, MyAbstract[] a) {\n+        return get(v) == a; \/\/ only true if both null\n+    }\n+\n+    public boolean testEq31_5(MyValue1 v, MyAbstract[] a) {\n+        return (Object)v == get(a); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq31_6(MyValue1 v, MyAbstract[] a) {\n+        return get(v) == get(a); \/\/ only true if both null\n+    }\n+\n+    public boolean testEq32_1(MyInterface[] a, MyValue1 v) {\n+        return getNotNull(a) == (Object)v; \/\/ false\n+    }\n+\n+    public boolean testEq32_2(MyInterface[] a, MyValue1 v) {\n+        return a == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq32_3(MyInterface[] a, MyValue1 v) {\n+        return getNotNull(a) == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq32_4(MyAbstract[] a, MyValue1 v) {\n+        return getNotNull(a) == (Object)v; \/\/ false\n+    }\n+\n+    public boolean testEq32_5(MyAbstract[] a, MyValue1 v) {\n+        return a == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq32_6(MyAbstract[] a, MyValue1 v) {\n+        return getNotNull(a) == getNotNull(v); \/\/ false\n+    }\n+\n+    public boolean testEq33_1(MyValue1 v, MyInterface[] a) {\n+        return getNotNull(v) == a; \/\/ false\n+    }\n+\n+    public boolean testEq33_2(MyValue1 v, MyInterface[] a) {\n+        return (Object)v == getNotNull(a); \/\/ false\n+    }\n+\n+    public boolean testEq33_3(MyValue1 v, MyInterface[] a) {\n+        return getNotNull(v) == getNotNull(a); \/\/ false\n+    }\n+\n+    public boolean testEq33_4(MyValue1 v, MyAbstract[] a) {\n+        return getNotNull(v) == a; \/\/ false\n+    }\n+\n+    public boolean testEq33_5(MyValue1 v, MyAbstract[] a) {\n+        return (Object)v == getNotNull(a); \/\/ false\n+    }\n+\n+    public boolean testEq33_6(MyValue1 v, MyAbstract[] a) {\n+        return getNotNull(v) == getNotNull(a); \/\/ false\n+    }\n+\n+\n+    \/\/ Null tests\n+\n+    public boolean testNull01_1(MyValue1 v) {\n+        return (Object)v == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull01_2(MyValue1 v) {\n+        return get(v) == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull01_3(MyValue1 v) {\n+        return (Object)v == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull01_4(MyValue1 v) {\n+        return get(v) == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull02_1(MyValue1 v) {\n+        return null == (Object)v; \/\/ old acmp\n+    }\n+\n+    public boolean testNull02_2(MyValue1 v) {\n+        return get((Object)null) == (Object)v; \/\/ old acmp\n+    }\n+\n+    public boolean testNull02_3(MyValue1 v) {\n+        return null == get(v); \/\/ old acmp\n+    }\n+\n+    public boolean testNull02_4(MyValue1 v) {\n+        return get((Object)null) == get(v); \/\/ old acmp\n+    }\n+\n+    public boolean testNull03_1(Object u) {\n+        return u == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull03_2(Object u) {\n+        return get(u) == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull03_3(Object u) {\n+        return u == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull03_4(Object u) {\n+        return get(u) == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull04_1(Object u) {\n+        return null == u; \/\/ old acmp\n+    }\n+\n+    public boolean testNull04_2(Object u) {\n+        return get((Object)null) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testNull04_3(Object u) {\n+        return null == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNull04_4(Object u) {\n+        return get((Object)null) == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNull05_1(MyObject o) {\n+        return o == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull05_2(MyObject o) {\n+        return get(o) == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull05_3(MyObject o) {\n+        return o == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull05_4(MyObject o) {\n+        return get(o) == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull06_1(MyObject o) {\n+        return null == o; \/\/ old acmp\n+    }\n+\n+    public boolean testNull06_2(MyObject o) {\n+        return get((Object)null) == o; \/\/ old acmp\n+    }\n+\n+    public boolean testNull06_3(MyObject o) {\n+        return null == get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNull06_4(MyObject o) {\n+        return get((Object)null) == get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNull07_1(MyInterface u) {\n+        return u == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull07_2(MyInterface u) {\n+        return get(u) == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull07_3(MyInterface u) {\n+        return u == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull07_4(MyInterface u) {\n+        return get(u) == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull07_5(MyAbstract u) {\n+        return u == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull07_6(MyAbstract u) {\n+        return get(u) == null; \/\/ old acmp\n+    }\n+\n+    public boolean testNull07_7(MyAbstract u) {\n+        return u == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull07_8(MyAbstract u) {\n+        return get(u) == get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNull08_1(MyInterface u) {\n+        return null == u; \/\/ old acmp\n+    }\n+\n+    public boolean testNull08_2(MyInterface u) {\n+        return get((Object)null) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testNull08_3(MyInterface u) {\n+        return null == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNull08_4(MyInterface u) {\n+        return get((Object)null) == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNull08_5(MyAbstract u) {\n+        return null == u; \/\/ old acmp\n+    }\n+\n+    public boolean testNull08_6(MyAbstract u) {\n+        return get((Object)null) == u; \/\/ old acmp\n+    }\n+\n+    public boolean testNull08_7(MyAbstract u) {\n+        return null == get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNull08_8(MyAbstract u) {\n+        return get((Object)null) == get(u); \/\/ old acmp\n+    }\n+\n+    \/\/ Same tests as above but negated\n+\n+    public boolean testNotEq01_1(Object u1, Object u2) {\n+        return get(u1) != u2; \/\/ new acmp\n+    }\n+\n+    public boolean testNotEq01_2(Object u1, Object u2) {\n+        return u1 != get(u2); \/\/ new acmp\n+    }\n+\n+    public boolean testNotEq01_3(Object u1, Object u2) {\n+        return get(u1) != get(u2); \/\/ new acmp\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq01_4(Object u1, Object u2) {\n+        return getNotNull(u1) != u2; \/\/ new acmp without null check\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq01_5(Object u1, Object u2) {\n+        return u1 != getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq01_6(Object u1, Object u2) {\n+        return getNotNull(u1) != getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    public boolean testNotEq02_1(MyValue1 v1, MyValue1 v2) {\n+        return get(v1) != (Object)v2; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq02_2(MyValue1 v1, MyValue1 v2) {\n+        return (Object)v1 != get(v2); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq02_3(MyValue1 v1, MyValue1 v2) {\n+        return get(v1) != get(v2); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq03_1(MyValue1 v, Object u) {\n+        return get(v) != u; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq03_2(MyValue1 v, Object u) {\n+        return (Object)v != get(u); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq03_3(MyValue1 v, Object u) {\n+        return get(v) != get(u); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq04_1(Object u, MyValue1 v) {\n+        return get(u) != (Object)v; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq04_2(Object u, MyValue1 v) {\n+        return u != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq04_3(Object u, MyValue1 v) {\n+        return get(u) != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq05_1(MyObject o, MyValue1 v) {\n+        return get(o) != (Object)v; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq05_2(MyObject o, MyValue1 v) {\n+        return o != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq05_3(MyObject o, MyValue1 v) {\n+        return get(o) != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq06_1(MyValue1 v, MyObject o) {\n+        return get(v) != o; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq06_2(MyValue1 v, MyObject o) {\n+        return (Object)v != get(o); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq06_3(MyValue1 v, MyObject o) {\n+        return get(v) != get(o); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq07_1(MyValue1 v1, MyValue1 v2) {\n+        return getNotNull(v1) != (Object)v2; \/\/ true\n+    }\n+\n+    public boolean testNotEq07_2(MyValue1 v1, MyValue1 v2) {\n+        return (Object)v1 != getNotNull(v2); \/\/ true\n+    }\n+\n+    public boolean testNotEq07_3(MyValue1 v1, MyValue1 v2) {\n+        return getNotNull(v1) != getNotNull(v2); \/\/ true\n+    }\n+\n+    public boolean testNotEq08_1(MyValue1 v, Object u) {\n+        return getNotNull(v) != u; \/\/ true\n+    }\n+\n+    public boolean testNotEq08_2(MyValue1 v, Object u) {\n+        return (Object)v != getNotNull(u); \/\/ true\n+    }\n+\n+    public boolean testNotEq08_3(MyValue1 v, Object u) {\n+        return getNotNull(v) != getNotNull(u); \/\/ true\n+    }\n+\n+    public boolean testNotEq09_1(Object u, MyValue1 v) {\n+        return getNotNull(u) != (Object)v; \/\/ true\n+    }\n+\n+    public boolean testNotEq09_2(Object u, MyValue1 v) {\n+        return u != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq09_3(Object u, MyValue1 v) {\n+        return getNotNull(u) != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq10_1(MyObject o, MyValue1 v) {\n+        return getNotNull(o) != (Object)v; \/\/ true\n+    }\n+\n+    public boolean testNotEq10_2(MyObject o, MyValue1 v) {\n+        return o != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq10_3(MyObject o, MyValue1 v) {\n+        return getNotNull(o) != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq11_1(MyValue1 v, MyObject o) {\n+        return getNotNull(v) != o; \/\/ true\n+    }\n+\n+    public boolean testNotEq11_2(MyValue1 v, MyObject o) {\n+        return (Object)v != getNotNull(o); \/\/ true\n+    }\n+\n+    public boolean testNotEq11_3(MyValue1 v, MyObject o) {\n+        return getNotNull(v) != getNotNull(o); \/\/ true\n+    }\n+\n+    public boolean testNotEq12_1(MyObject o1, MyObject o2) {\n+        return get(o1) != o2; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq12_2(MyObject o1, MyObject o2) {\n+        return o1 != get(o2); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq12_3(MyObject o1, MyObject o2) {\n+        return get(o1) != get(o2); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq13_1(Object u, MyObject o) {\n+        return get(u) != o; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq13_2(Object u, MyObject o) {\n+        return u != get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq13_3(Object u, MyObject o) {\n+        return get(u) != get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq14_1(MyObject o, Object u) {\n+        return get(o) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq14_2(MyObject o, Object u) {\n+        return o != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq14_3(MyObject o, Object u) {\n+        return get(o) != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq15_1(Object[] a, Object u) {\n+        return get(a) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq15_2(Object[] a, Object u) {\n+        return a != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq15_3(Object[] a, Object u) {\n+        return get(a) != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq16_1(Object u, Object[] a) {\n+        return get(u) != a; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq16_2(Object u, Object[] a) {\n+        return u != get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq16_3(Object u, Object[] a) {\n+        return get(u) != get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq17_1(Object[] a, MyValue1 v) {\n+        return get(a) != (Object)v; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq17_2(Object[] a, MyValue1 v) {\n+        return a != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq17_3(Object[] a, MyValue1 v) {\n+        return get(a) != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq18_1(MyValue1 v, Object[] a) {\n+        return get(v) != a; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq18_2(MyValue1 v, Object[] a) {\n+        return (Object)v != get(a); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq18_3(MyValue1 v, Object[] a) {\n+        return get(v) != get(a); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq19_1(Object[] a, MyValue1 v) {\n+        return getNotNull(a) != (Object)v; \/\/ true\n+    }\n+\n+    public boolean testNotEq19_2(Object[] a, MyValue1 v) {\n+        return a != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq19_3(Object[] a, MyValue1 v) {\n+        return getNotNull(a) != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq20_1(MyValue1 v, Object[] a) {\n+        return getNotNull(v) != a; \/\/ true\n+    }\n+\n+    public boolean testNotEq20_2(MyValue1 v, Object[] a) {\n+        return (Object)v != getNotNull(a); \/\/ true\n+    }\n+\n+    public boolean testNotEq20_3(MyValue1 v, Object[] a) {\n+        return getNotNull(v) != getNotNull(a); \/\/ true\n+    }\n+\n+    public boolean testNotEq21_1(MyInterface u1, MyInterface u2) {\n+        return get(u1) != u2; \/\/ new acmp\n+    }\n+\n+    public boolean testNotEq21_2(MyInterface u1, MyInterface u2) {\n+        return u1 != get(u2); \/\/ new acmp\n+    }\n+\n+    public boolean testNotEq21_3(MyInterface u1, MyInterface u2) {\n+        return get(u1) != get(u2); \/\/ new acmp\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq21_4(MyInterface u1, MyInterface u2) {\n+        return getNotNull(u1) != u2; \/\/ new acmp without null check\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq21_5(MyInterface u1, MyInterface u2) {\n+        return u1 != getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq21_6(MyInterface u1, MyInterface u2) {\n+        return getNotNull(u1) != getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    public boolean testNotEq21_7(MyAbstract u1, MyAbstract u2) {\n+        return get(u1) != u2; \/\/ new acmp\n+    }\n+\n+    public boolean testNotEq21_8(MyAbstract u1, MyAbstract u2) {\n+        return u1 != get(u2); \/\/ new acmp\n+    }\n+\n+    public boolean testNotEq21_9(MyAbstract u1, MyAbstract u2) {\n+        return get(u1) != get(u2); \/\/ new acmp\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq21_10(MyAbstract u1, MyAbstract u2) {\n+        return getNotNull(u1) != u2; \/\/ new acmp without null check\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq21_11(MyAbstract u1, MyAbstract u2) {\n+        return u1 != getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    @TrueIfNull\n+    public boolean testNotEq21_12(MyAbstract u1, MyAbstract u2) {\n+        return getNotNull(u1) != getNotNull(u2); \/\/ new acmp without null check\n+    }\n+\n+    public boolean testNotEq22_1(MyValue1 v, MyInterface u) {\n+        return get(v) != u; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq22_2(MyValue1 v, MyInterface u) {\n+        return (Object)v != get(u); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq22_3(MyValue1 v, MyInterface u) {\n+        return get(v) != get(u); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq22_4(MyValue1 v, MyAbstract u) {\n+        return get(v) != u; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq22_5(MyValue1 v, MyAbstract u) {\n+        return (Object)v != get(u); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq22_6(MyValue1 v, MyAbstract u) {\n+        return get(v) != get(u); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq23_1(MyInterface u, MyValue1 v) {\n+        return get(u) != (Object)v; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq23_2(MyInterface u, MyValue1 v) {\n+        return u != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq23_3(MyInterface u, MyValue1 v) {\n+        return get(u) != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq23_4(MyAbstract u, MyValue1 v) {\n+        return get(u) != (Object)v; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq23_5(MyAbstract u, MyValue1 v) {\n+        return u != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq23_6(MyAbstract u, MyValue1 v) {\n+        return get(u) != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq24_1(MyValue1 v, MyInterface u) {\n+        return getNotNull(v) != u; \/\/ true\n+    }\n+\n+    public boolean testNotEq24_2(MyValue1 v, MyInterface u) {\n+        return (Object)v != getNotNull(u); \/\/ true\n+    }\n+\n+    public boolean testNotEq24_3(MyValue1 v, MyInterface u) {\n+        return getNotNull(v) != getNotNull(u); \/\/ true\n+    }\n+\n+    public boolean testNotEq24_4(MyValue1 v, MyAbstract u) {\n+        return getNotNull(v) != u; \/\/ true\n+    }\n+\n+    public boolean testNotEq24_5(MyValue1 v, MyAbstract u) {\n+        return (Object)v != getNotNull(u); \/\/ true\n+    }\n+\n+    public boolean testNotEq24_6(MyValue1 v, MyAbstract u) {\n+        return getNotNull(v) != getNotNull(u); \/\/ true\n+    }\n+\n+    public boolean testNotEq25_1(MyInterface u, MyValue1 v) {\n+        return getNotNull(u) != (Object)v; \/\/ true\n+    }\n+\n+    public boolean testNotEq25_2(MyInterface u, MyValue1 v) {\n+        return u != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq25_3(MyInterface u, MyValue1 v) {\n+        return getNotNull(u) != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq25_4(MyAbstract u, MyValue1 v) {\n+        return getNotNull(u) != (Object)v; \/\/ true\n+    }\n+\n+    public boolean testNotEq25_5(MyAbstract u, MyValue1 v) {\n+        return u != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq25_6(MyAbstract u, MyValue1 v) {\n+        return getNotNull(u) != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq26_1(MyInterface u, MyObject o) {\n+        return get(u) != o; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq26_2(MyInterface u, MyObject o) {\n+        return u != get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq26_3(MyInterface u, MyObject o) {\n+        return get(u) != get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq26_4(MyAbstract u, MyObject o) {\n+        return get(u) != o; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq26_5(MyAbstract u, MyObject o) {\n+        return u != get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq26_6(MyAbstract u, MyObject o) {\n+        return get(u) != get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq27_1(MyObject o, MyInterface u) {\n+        return get(o) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq27_2(MyObject o, MyInterface u) {\n+        return o != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq27_3(MyObject o, MyInterface u) {\n+        return get(o) != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq27_4(MyObject o, MyAbstract u) {\n+        return get(o) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq27_5(MyObject o, MyAbstract u) {\n+        return o != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq27_6(MyObject o, MyAbstract u) {\n+        return get(o) != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq28_1(MyInterface[] a, MyInterface u) {\n+        return get(a) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq28_2(MyInterface[] a, MyInterface u) {\n+        return a != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq28_3(MyInterface[] a, MyInterface u) {\n+        return get(a) != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq28_4(MyAbstract[] a, MyAbstract u) {\n+        return get(a) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq28_5(MyAbstract[] a, MyAbstract u) {\n+        return a != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq28_6(MyAbstract[] a, MyAbstract u) {\n+        return get(a) != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq29_1(MyInterface u, MyInterface[] a) {\n+        return get(u) != a; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq29_2(MyInterface u, MyInterface[] a) {\n+        return u != get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq29_3(MyInterface u, MyInterface[] a) {\n+        return get(u) != get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq29_4(MyAbstract u, MyAbstract[] a) {\n+        return get(u) != a; \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq29_5(MyAbstract u, MyAbstract[] a) {\n+        return u != get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq29_6(MyAbstract u, MyAbstract[] a) {\n+        return get(u) != get(a); \/\/ old acmp\n+    }\n+\n+    public boolean testNotEq30_1(MyInterface[] a, MyValue1 v) {\n+        return get(a) != (Object)v; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq30_2(MyInterface[] a, MyValue1 v) {\n+        return a != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq30_3(MyInterface[] a, MyValue1 v) {\n+        return get(a) != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq30_4(MyAbstract[] a, MyValue1 v) {\n+        return get(a) != (Object)v; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq30_5(MyAbstract[] a, MyValue1 v) {\n+        return a != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq30_6(MyAbstract[] a, MyValue1 v) {\n+        return get(a) != get(v); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq31_1(MyValue1 v, MyInterface[] a) {\n+        return get(v) != a; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq31_2(MyValue1 v, MyInterface[] a) {\n+        return (Object)v != get(a); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq31_3(MyValue1 v, MyInterface[] a) {\n+        return get(v) != get(a); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq31_4(MyValue1 v, MyAbstract[] a) {\n+        return get(v) != a; \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq31_5(MyValue1 v, MyAbstract[] a) {\n+        return (Object)v != get(a); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq31_6(MyValue1 v, MyAbstract[] a) {\n+        return get(v) != get(a); \/\/ only false if both null\n+    }\n+\n+    public boolean testNotEq32_1(MyInterface[] a, MyValue1 v) {\n+        return getNotNull(a) != (Object)v; \/\/ true\n+    }\n+\n+    public boolean testNotEq32_2(MyInterface[] a, MyValue1 v) {\n+        return a != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq32_3(MyInterface[] a, MyValue1 v) {\n+        return getNotNull(a) != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq32_4(MyAbstract[] a, MyValue1 v) {\n+        return getNotNull(a) != (Object)v; \/\/ true\n+    }\n+\n+    public boolean testNotEq32_5(MyAbstract[] a, MyValue1 v) {\n+        return a != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq32_6(MyAbstract[] a, MyValue1 v) {\n+        return getNotNull(a) != getNotNull(v); \/\/ true\n+    }\n+\n+    public boolean testNotEq33_1(MyValue1 v, MyInterface[] a) {\n+        return getNotNull(v) != a; \/\/ true\n+    }\n+\n+    public boolean testNotEq33_2(MyValue1 v, MyInterface[] a) {\n+        return (Object)v != getNotNull(a); \/\/ true\n+    }\n+\n+    public boolean testNotEq33_3(MyValue1 v, MyInterface[] a) {\n+        return getNotNull(v) != getNotNull(a); \/\/ true\n+    }\n+\n+    public boolean testNotEq33_4(MyValue1 v, MyAbstract[] a) {\n+        return getNotNull(v) != a; \/\/ true\n+    }\n+\n+    public boolean testNotEq33_5(MyValue1 v, MyAbstract[] a) {\n+        return (Object)v != getNotNull(a); \/\/ true\n+    }\n+\n+    public boolean testNotEq33_6(MyValue1 v, MyAbstract[] a) {\n+        return getNotNull(v) != getNotNull(a); \/\/ true\n+    }\n+\n+    \/\/ Null tests\n+\n+    public boolean testNotNull01_1(MyValue1 v) {\n+        return (Object)v != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull01_2(MyValue1 v) {\n+        return get(v) != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull01_3(MyValue1 v) {\n+        return (Object)v != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull01_4(MyValue1 v) {\n+        return get(v) != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull02_1(MyValue1 v) {\n+        return null != (Object)v; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull02_2(MyValue1 v) {\n+        return get((Object)null) != (Object)v; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull02_3(MyValue1 v) {\n+        return null != get(v); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull02_4(MyValue1 v) {\n+        return get((Object)null) != get(v); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull03_1(Object u) {\n+        return u != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull03_2(Object u) {\n+        return get(u) != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull03_3(Object u) {\n+        return u != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull03_4(Object u) {\n+        return get(u) != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull04_1(Object u) {\n+        return null != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull04_2(Object u) {\n+        return get((Object)null) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull04_3(Object u) {\n+        return null != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull04_4(Object u) {\n+        return get((Object)null) != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull05_1(MyObject o) {\n+        return o != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull05_2(MyObject o) {\n+        return get(o) != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull05_3(MyObject o) {\n+        return o != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull05_4(MyObject o) {\n+        return get(o) != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull06_1(MyObject o) {\n+        return null != o; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull06_2(MyObject o) {\n+        return get((Object)null) != o; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull06_3(MyObject o) {\n+        return null != get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull06_4(MyObject o) {\n+        return get((Object)null) != get(o); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull07_1(MyInterface u) {\n+        return u != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull07_2(MyInterface u) {\n+        return get(u) != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull07_3(MyInterface u) {\n+        return u != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull07_4(MyInterface u) {\n+        return get(u) != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull07_5(MyAbstract u) {\n+        return u != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull07_6(MyAbstract u) {\n+        return get(u) != null; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull07_7(MyAbstract u) {\n+        return u != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull07_8(MyAbstract u) {\n+        return get(u) != get((Object)null); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull08_1(MyInterface u) {\n+        return null != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull08_2(MyInterface u) {\n+        return get((Object)null) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull08_3(MyInterface u) {\n+        return null != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull08_4(MyInterface u) {\n+        return get((Object)null) != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull08_5(MyAbstract u) {\n+        return null != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull08_6(MyAbstract u) {\n+        return get((Object)null) != u; \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull08_7(MyAbstract u) {\n+        return null != get(u); \/\/ old acmp\n+    }\n+\n+    public boolean testNotNull08_8(MyAbstract u) {\n+        return get((Object)null) != get(u); \/\/ old acmp\n+    }\n+\n+    \/\/ The following methods are used with -XX:+AlwaysIncrementalInline to hide exact types during parsing\n+\n+    public Object get(Object u) {\n+        return u;\n+    }\n+\n+    public Object getNotNull(Object u) {\n+        return (u != null) ? u : new Object();\n+    }\n+\n+    public Object get(MyValue1 v) {\n+        return v;\n+    }\n+\n+    public Object getNotNull(MyValue1 v) {\n+        return ((Object)v != null) ? v : MyValue1.createDefault();\n+    }\n+\n+    public Object get(MyObject o) {\n+        return o;\n+    }\n+\n+    public Object getNotNull(MyObject o) {\n+        return (o != null) ? o : MyValue1.createDefault();\n+    }\n+\n+    public Object get(Object[] a) {\n+        return a;\n+    }\n+\n+    public Object getNotNull(Object[] a) {\n+        return (a != null) ? a : new Object[1];\n+    }\n+\n+    public boolean trueIfNull(Method m) {\n+        return m.isAnnotationPresent(TrueIfNull.class);\n+    }\n+\n+    public boolean falseIfNull(Method m) {\n+        return m.isAnnotationPresent(FalseIfNull.class);\n+    }\n+\n+    public boolean isNegated(Method m) {\n+        return m.getName().startsWith(\"testNot\");\n+    }\n+\n+    \/\/ Tests with profiling\n+    public boolean cmpAlwaysEqual1(Object a, Object b) {\n+        return a == b;\n+    }\n+\n+    public boolean cmpAlwaysEqual2(Object a, Object b) {\n+        return a != b;\n+    }\n+\n+    public boolean cmpAlwaysEqual3(Object a) {\n+        return a == a;\n+    }\n+\n+    public boolean cmpAlwaysEqual4(Object a) {\n+        return a != a;\n+    }\n+\n+    public boolean cmpAlwaysUnEqual1(Object a, Object b) {\n+        return a == b;\n+    }\n+\n+    public boolean cmpAlwaysUnEqual2(Object a, Object b) {\n+        return a != b;\n+    }\n+\n+    public boolean cmpAlwaysUnEqual3(Object a) {\n+        return a == a;\n+    }\n+\n+    public boolean cmpAlwaysUnEqual4(Object a) {\n+        return a != a;\n+    }\n+\n+    public boolean cmpSometimesEqual1(Object a) {\n+        return a == a;\n+    }\n+\n+    public boolean cmpSometimesEqual2(Object a) {\n+        return a != a;\n+    }\n+\n+    static int get_full_opt_level() {\n+        int n = (int)TieredStopAtLevel;\n+        if (n >= 4) {\n+            n = 4;\n+        }\n+        return n;\n+    }\n+    protected static final WhiteBox WHITE_BOX = WhiteBox.getWhiteBox();\n+    protected static final long TieredStopAtLevel = (Long)WHITE_BOX.getVMFlag(\"TieredStopAtLevel\");\n+    protected static final int COMP_LEVEL_FULL_OPTIMIZATION = get_full_opt_level();\n+\n+    public void runTest(Method m, Object[] args, int warmup, int nullMode, boolean[][] equalities) throws Exception {\n+        Class<?>[] parameterTypes = m.getParameterTypes();\n+        int parameterCount = parameterTypes.length;\n+        \/\/ Nullness mode for first argument\n+        \/\/ 0: default, 1: never null, 2: always null\n+        int start = (nullMode != 1) ? 0 : 1;\n+        int end = (nullMode != 2) ? args.length : 1;\n+        for (int i = start; i < end; ++i) {\n+            if (args[i] != null && !parameterTypes[0].isInstance(args[i])) {\n+                continue;\n+            }\n+            if (args[i] == null && parameterTypes[0] == MyValue1.class) {\n+                continue;\n+            }\n+            if (parameterCount == 1) {\n+                \/\/ Null checks\n+                System.out.print(\"Testing \" + m.getName() + \"(\" + args[i] + \")\");\n+                \/\/ Avoid acmp in the computation of the expected result!\n+                boolean expected = isNegated(m) ? (i != 0) : (i == 0);\n+                for (int run = 0; run < warmup; ++run) {\n+                    Boolean result = (Boolean)m.invoke(this, args[i]);\n+                    if (result != expected && WHITE_BOX.isMethodCompiled(m, false)) {\n+                        System.out.println(\" = \" + result);\n+                        throw new RuntimeException(\"Test failed: should return \" + expected);\n+                    }\n+                }\n+                System.out.println(\" = \" + expected);\n+            } else {\n+                \/\/ Equality checks\n+                for (int j = 0; j < args.length; ++j) {\n+                    if (args[j] != null && !parameterTypes[1].isInstance(args[j])) {\n+                        continue;\n+                    }\n+                    if (args[j] == null && parameterTypes[1] == MyValue1.class) {\n+                        continue;\n+                    }\n+                    System.out.print(\"Testing \" + m.getName() + \"(\" + args[i] + \", \" + args[j] + \")\");\n+                    \/\/ Avoid acmp in the computation of the expected result!\n+                    boolean equal = equalities[i][j];\n+                    equal = isNegated(m) ? !equal : equal;\n+                    boolean expected = ((i == 0 || j == 0) && trueIfNull(m)) || (equal && !(i == 0 && falseIfNull(m)));\n+                    for (int run = 0; run < warmup; ++run) {\n+                        Boolean result = (Boolean)m.invoke(this, args[i], args[j]);\n+                        if (result != expected && WHITE_BOX.isMethodCompiled(m, false) && warmup == 1) {\n+                            System.out.println(\" = \" + result);\n+                            throw new RuntimeException(\"Test failed: should return \" + expected);\n+                        }\n+                    }\n+                    System.out.println(\" = \" + expected);\n+                }\n+            }\n+        }\n+    }\n+\n+    public void run(int nullMode) throws Exception {\n+        \/\/ Prepare test arguments\n+        Object[] args =  { null,\n+                           new Object(),\n+                           new MyObject(),\n+                           MyValue1.setX(MyValue1.createDefault(), 42),\n+                           new Object[10],\n+                           new MyObject[10],\n+                           MyValue1.setX(MyValue1.createDefault(), 0x42),\n+                           MyValue1.setX(MyValue1.createDefault(), 42),\n+                           MyValue2.setX(MyValue2.createDefault(), 42), };\n+\n+        boolean[][] equalities = { { true,  false, false, false, false, false, false, false, false },\n+                                   { false, true,  false, false, false, false, false, false, false },\n+                                   { false, false, true,  false, false, false, false, false, false },\n+                                   { false, false, false, true,  false, false, false, true,  false },\n+                                   { false, false, false, false, true,  false, false, false, false },\n+                                   { false, false, false, false, false, true,  false, false, false },\n+                                   { false, false, false, false, false, false, true,  false, false },\n+                                   { false, false, false, true,  false, false, false, true,  false },\n+                                   { false, false, false, false, false, false, false, false, true  } };\n+\n+        \/\/ Run tests\n+        for (Method m : getClass().getMethods()) {\n+            if (m.getName().startsWith(\"test\")) {\n+                \/\/ Do some warmup runs\n+                runTest(m, args, 1000, nullMode, equalities);\n+                \/\/ Make sure method is compiled\n+                InlineTypeTest.enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+                Asserts.assertTrue(WHITE_BOX.isMethodCompiled(m, false), m + \" not compiled\");\n+                \/\/ Run again to verify correctness of compiled code\n+                runTest(m, args, 1, nullMode, equalities);\n+            }\n+        }\n+\n+        Method cmpAlwaysUnEqual3_m = getClass().getMethod(\"cmpAlwaysUnEqual3\", Object.class);\n+        Method cmpAlwaysUnEqual4_m = getClass().getMethod(\"cmpAlwaysUnEqual4\", Object.class);\n+        Method cmpSometimesEqual1_m = getClass().getMethod(\"cmpSometimesEqual1\", Object.class);\n+        Method cmpSometimesEqual2_m = getClass().getMethod(\"cmpSometimesEqual2\", Object.class);\n+\n+        for (int i = 0; i < 20_000; ++i) {\n+            Asserts.assertTrue(cmpAlwaysEqual1(args[1], args[1]));\n+            Asserts.assertFalse(cmpAlwaysEqual2(args[1], args[1]));\n+            Asserts.assertTrue(cmpAlwaysEqual3(args[1]));\n+            Asserts.assertFalse(cmpAlwaysEqual4(args[1]));\n+\n+            Asserts.assertFalse(cmpAlwaysUnEqual1(args[1], args[2]));\n+            Asserts.assertTrue(cmpAlwaysUnEqual2(args[1], args[2]));\n+            boolean res = cmpAlwaysUnEqual3(args[3]);\n+            Asserts.assertTrue(res);\n+            res = cmpAlwaysUnEqual4(args[3]);\n+            Asserts.assertFalse(res);\n+\n+            int idx = i % args.length;\n+            res = cmpSometimesEqual1(args[idx]);\n+            Asserts.assertTrue(res);\n+            res = cmpSometimesEqual2(args[idx]);\n+            Asserts.assertFalse(res);\n+        }\n+    }\n+\n+    public static void main(String[] args) throws Exception {\n+        if (args.length == 0) {\n+            enumerateVMOptions();\n+        } else {\n+            int nullMode = Integer.valueOf(args[0]);\n+            TestNewAcmp t = new TestNewAcmp();\n+            t.run(nullMode);\n+        }\n+    }\n+\n+    private static String[] addOptions(String prefix[], String... extra) {\n+        ArrayList<String> list = new ArrayList<String>();\n+        if (prefix != null) {\n+            for (String s : prefix) {\n+                list.add(s);\n+            }\n+        }\n+        if (extra != null) {\n+            for (String s : extra) {\n+                System.out.println(\"    \" + s);\n+                list.add(s);\n+            }\n+        }\n+\n+        return list.toArray(new String[list.size()]);\n+    }\n+\n+    private static void enumerateVMOptions() throws Exception {\n+        String[] baseOptions = {\n+            \"-Xbootclasspath\/a:.\",\n+            \"-XX:+UnlockDiagnosticVMOptions\",\n+            \"-XX:+WhiteBoxAPI\",\n+            \"-Xbatch\",\n+            \"-XX:TypeProfileLevel=222\",\n+            \"-XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.TestNewAcmp::test*\",\n+            \"-XX:CompileCommand=dontinline,compiler.valhalla.inlinetypes.TestNewAcmp::cmp*\"};\n+\n+        String SCENARIOS = System.getProperty(\"Scenarios\", \"\");\n+        List<String> scenarios = null;\n+        if (!SCENARIOS.isEmpty()) {\n+           scenarios = Arrays.asList(SCENARIOS.split(\",\"));\n+        }\n+\n+        int scenario = -1;\n+        for (int nullMode = 0; nullMode <= 2; nullMode++) {          \/\/ null mode\n+            for (int incrInline = 0; incrInline < 2; incrInline++) { \/\/ 0 = default, 1 = -XX:+AlwaysIncrementalInline\n+                scenario++;\n+                System.out.println(\"Scenario #\" + scenario + \" -------------------\");\n+                String[] cmds = baseOptions;\n+                if (incrInline != 0) {\n+                    cmds = addOptions(cmds, \"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+AlwaysIncrementalInline\");\n+                }\n+\n+                cmds = addOptions(cmds, \"compiler.valhalla.inlinetypes.TestNewAcmp\");\n+                cmds = addOptions(cmds, Integer.toString(nullMode));\n+\n+                if (scenarios != null && !scenarios.contains(Integer.toString(scenario))) {\n+                    System.out.println(\"Scenario #\" + scenario + \" is skipped due to -Dscenarios=\" + SCENARIOS);\n+                    continue;\n+                }\n+\n+                OutputAnalyzer oa = ProcessTools.executeTestJvm(cmds);\n+                String output = oa.getOutput();\n+                oa.shouldHaveExitValue(0);\n+                System.out.println(output);\n+            }\n+        }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestNewAcmp.java","additions":1908,"deletions":0,"binary":false,"changes":1908,"status":"added"},{"patch":"@@ -0,0 +1,2880 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.test.lib.Asserts;\n+import java.lang.reflect.Method;\n+import java.util.Arrays;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test nullable inline type arrays\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestNullableArrays.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestNullableArrays\n+ *\/\n+public class TestNullableArrays extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 2: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:-UncommonNullCast\", \"-XX:+StressArrayCopyMacroNode\"};\n+        case 3: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:-UncommonNullCast\"};\n+        case 4: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:-UncommonNullCast\"};\n+        case 5: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:-UncommonNullCast\", \"-XX:+StressArrayCopyMacroNode\"};\n+        }\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestNullableArrays test = new TestNullableArrays();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class);\n+    }\n+\n+    \/\/ Helper methods\n+\n+    protected long hash() {\n+        return hash(rI, rL);\n+    }\n+\n+    protected long hash(int x, long y) {\n+        return MyValue1.createWithFieldsInline(x, y).hash();\n+    }\n+\n+    private static final MyValue1 testValue1 = MyValue1.createWithFieldsInline(rI, rL);\n+\n+    \/\/ Test nullable inline type array creation and initialization\n+    @Test(valid = InlineTypeArrayFlattenOn, match = { ALLOCA }, matchCount = { 1 })\n+    @Test(valid = InlineTypeArrayFlattenOff, match = { ALLOCA }, matchCount = { 1 }, failOn = LOAD)\n+    public MyValue1.ref[] test1(int len) {\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        if (len > 0) {\n+            va[0] = null;\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        }\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        int len = Math.abs(rI % 10);\n+        MyValue1.ref[] va = test1(len);\n+        if (len > 0) {\n+            Asserts.assertEQ(va[0], null);\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            Asserts.assertEQ(va[i].hash(), hash());\n+        }\n+    }\n+\n+    \/\/ Test creation of an inline type array and element access\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public long test2() {\n+        MyValue1.ref[] va = new MyValue1.ref[1];\n+        va[0] = MyValue1.createWithFieldsInline(rI, rL);\n+        return va[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        long result = test2();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Test receiving an inline type array from the interpreter,\n+    \/\/ updating its elements in a loop and computing a hash.\n+    @Test(failOn = ALLOCA)\n+    public long test3(MyValue1.ref[] va) {\n+        long result = 0;\n+        for (int i = 0; i < 10; ++i) {\n+            if (va[i] != null) {\n+                result += va[i].hash();\n+            }\n+            va[i] = MyValue1.createWithFieldsInline(rI + 1, rL + 1);\n+        }\n+        va[0] = null;\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        MyValue1.ref[] va = new MyValue1.ref[10];\n+        long expected = 0;\n+        for (int i = 1; i < 10; ++i) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI + i, rL + i);\n+            expected += va[i].hash();\n+        }\n+        long result = test3(va);\n+        Asserts.assertEQ(expected, result);\n+        Asserts.assertEQ(va[0], null);\n+        for (int i = 1; i < 10; ++i) {\n+            if (va[i].hash() != hash(rI + 1, rL + 1)) {\n+                Asserts.assertEQ(va[i].hash(), hash(rI + 1, rL + 1));\n+            }\n+        }\n+    }\n+\n+    \/\/ Test returning an inline type array received from the interpreter\n+    @Test(failOn = ALLOC + ALLOCA + LOAD + STORE + LOOP + TRAP)\n+    public MyValue1.ref[] test4(MyValue1.ref[] va) {\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        MyValue1.ref[] va = new MyValue1.ref[10];\n+        for (int i = 0; i < 10; ++i) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI + i, rL + i);\n+        }\n+        va = test4(va);\n+        for (int i = 0; i < 10; ++i) {\n+            Asserts.assertEQ(va[i].hash(), hash(rI + i, rL + i));\n+        }\n+    }\n+\n+    \/\/ Merge inline type arrays created from two branches\n+    @Test\n+    public MyValue1.ref[] test5(boolean b) {\n+        MyValue1.ref[] va;\n+        if (b) {\n+            va = new MyValue1.ref[5];\n+            for (int i = 0; i < 5; ++i) {\n+                va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+            }\n+            va[4] = null;\n+        } else {\n+            va = new MyValue1.ref[10];\n+            for (int i = 0; i < 10; ++i) {\n+                va[i] = MyValue1.createWithFieldsInline(rI + i, rL + i);\n+            }\n+            va[9] = null;\n+        }\n+        long sum = va[0].hashInterpreted();\n+        if (b) {\n+            va[0] = MyValue1.createWithFieldsDontInline(rI, sum);\n+        } else {\n+            va[0] = MyValue1.createWithFieldsDontInline(rI + 1, sum + 1);\n+        }\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        MyValue1.ref[] va = test5(true);\n+        Asserts.assertEQ(va.length, 5);\n+        Asserts.assertEQ(va[0].hash(), hash(rI, hash()));\n+        for (int i = 1; i < 4; ++i) {\n+            Asserts.assertEQ(va[i].hash(), hash());\n+        }\n+        Asserts.assertEQ(va[4], null);\n+        va = test5(false);\n+        Asserts.assertEQ(va.length, 10);\n+        Asserts.assertEQ(va[0].hash(), hash(rI + 1, hash(rI, rL) + 1));\n+        for (int i = 1; i < 9; ++i) {\n+            Asserts.assertEQ(va[i].hash(), hash(rI + i, rL + i));\n+        }\n+        Asserts.assertEQ(va[9], null);\n+    }\n+\n+    \/\/ Test creation of inline type array with single element\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public MyValue1.ref test6() {\n+        MyValue1.ref[] va = new MyValue1.ref[1];\n+        return va[0];\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        MyValue1.ref[] va = new MyValue1.ref[1];\n+        MyValue1.ref v = test6();\n+        Asserts.assertEQ(v, null);\n+    }\n+\n+    \/\/ Test default initialization of inline type arrays\n+    @Test(failOn = LOAD)\n+    public MyValue1.ref[] test7(int len) {\n+        return new MyValue1.ref[len];\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        int len = Math.abs(rI % 10);\n+        MyValue1.ref[] va = test7(len);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(va[i], null);\n+            va[i] = null;\n+        }\n+    }\n+\n+    \/\/ Test creation of inline type array with zero length\n+    @Test(failOn = ALLOC + LOAD + STORE + LOOP + TRAP)\n+    public MyValue1.ref[] test8() {\n+        return new MyValue1.ref[0];\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        MyValue1.ref[] va = test8();\n+        Asserts.assertEQ(va.length, 0);\n+    }\n+\n+    static MyValue1.ref[] test9_va;\n+\n+    \/\/ Test that inline type array loaded from field has correct type\n+    @Test(failOn = LOOP)\n+    public long test9() {\n+        return test9_va[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        test9_va = new MyValue1.ref[1];\n+        test9_va[0] = testValue1;\n+        long result = test9();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Multi-dimensional arrays\n+    @Test\n+    public MyValue1.ref[][][] test10(int len1, int len2, int len3) {\n+        MyValue1.ref[][][] arr = new MyValue1.ref[len1][len2][len3];\n+        for (int i = 0; i < len1; i++) {\n+            for (int j = 0; j < len2; j++) {\n+                for (int k = 0; k < len3; k++) {\n+                    arr[i][j][k] = MyValue1.createWithFieldsDontInline(rI + i , rL + j + k);\n+                    if (k == 0) {\n+                        arr[i][j][k] = null;\n+                    }\n+                }\n+            }\n+        }\n+        return arr;\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        MyValue1.ref[][][] arr = test10(2, 3, 4);\n+        for (int i = 0; i < 2; i++) {\n+            for (int j = 0; j < 3; j++) {\n+                for (int k = 0; k < 4; k++) {\n+                    if (k == 0) {\n+                        Asserts.assertEQ(arr[i][j][k], null);\n+                    } else {\n+                        Asserts.assertEQ(arr[i][j][k].hash(), MyValue1.createWithFieldsDontInline(rI + i , rL + j + k).hash());\n+                    }\n+                    arr[i][j][k] = null;\n+                }\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test11(MyValue1.ref[][][] arr, long[] res) {\n+        int l = 0;\n+        for (int i = 0; i < arr.length; i++) {\n+            for (int j = 0; j < arr[i].length; j++) {\n+                for (int k = 0; k < arr[i][j].length; k++) {\n+                    if (arr[i][j][k] != null) {\n+                        res[l] = arr[i][j][k].hash();\n+                    }\n+                    arr[i][j][k] = null;\n+                    l++;\n+                }\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        MyValue1.ref[][][] arr = new MyValue1.ref[2][3][4];\n+        long[] res = new long[2*3*4];\n+        long[] verif = new long[2*3*4];\n+        int l = 0;\n+        for (int i = 0; i < 2; i++) {\n+            for (int j = 0; j < 3; j++) {\n+                for (int k = 0; k < 4; k++) {\n+                    if (j != 2) {\n+                        arr[i][j][k] = MyValue1.createWithFieldsDontInline(rI + i, rL + j + k);\n+                        verif[l] = arr[i][j][k].hash();\n+                    }\n+                    l++;\n+                }\n+            }\n+        }\n+        test11(arr, res);\n+        for (int i = 0; i < verif.length; i++) {\n+            Asserts.assertEQ(res[i], verif[i]);\n+        }\n+    }\n+\n+    \/\/ Array load out of bounds (upper bound) at compile time\n+    @Test\n+    public int test12() {\n+        int arraySize = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[arraySize];\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI + 1, rL);\n+        }\n+\n+        try {\n+            return va[arraySize + 1].x;\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            return rI;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        Asserts.assertEQ(test12(), rI);\n+    }\n+\n+    \/\/ Array load  out of bounds (lower bound) at compile time\n+    @Test\n+    public int test13() {\n+        int arraySize = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[arraySize];\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI + i, rL);\n+        }\n+\n+        try {\n+            return va[-arraySize].x;\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            return rI;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        Asserts.assertEQ(test13(), rI);\n+    }\n+\n+    \/\/ Array load out of bound not known to compiler (both lower and upper bound)\n+    @Test\n+    public int test14(MyValue1.ref[] va, int index)  {\n+        return va[index].x;\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean warmup) {\n+        int arraySize = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[arraySize];\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        }\n+\n+        int result;\n+        for (int i = -20; i < 20; i++) {\n+            try {\n+                result = test14(va, i);\n+            } catch (ArrayIndexOutOfBoundsException e) {\n+                result = rI;\n+            }\n+            Asserts.assertEQ(result, rI);\n+        }\n+    }\n+\n+    \/\/ Array store out of bounds (upper bound) at compile time\n+    @Test\n+    public int test15() {\n+        int arraySize = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[arraySize];\n+\n+        try {\n+            for (int i = 0; i <= arraySize; i++) {\n+                va[i] = MyValue1.createWithFieldsDontInline(rI + 1, rL);\n+            }\n+            return rI - 1;\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            return rI;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean warmup) {\n+        Asserts.assertEQ(test15(), rI);\n+    }\n+\n+    \/\/ Array store out of bounds (lower bound) at compile time\n+    @Test\n+    public int test16() {\n+        int arraySize = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[arraySize];\n+\n+        try {\n+            for (int i = -1; i <= arraySize; i++) {\n+                va[i] = MyValue1.createWithFieldsDontInline(rI + 1, rL);\n+            }\n+            return rI - 1;\n+        } catch (ArrayIndexOutOfBoundsException e) {\n+            return rI;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean warmup) {\n+        Asserts.assertEQ(test16(), rI);\n+    }\n+\n+    \/\/ Array store out of bound not known to compiler (both lower and upper bound)\n+    @Test\n+    public int test17(MyValue1.ref[] va, int index, MyValue1 vt)  {\n+        va[index] = vt;\n+        return va[index].x;\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean warmup) {\n+        int arraySize = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[arraySize];\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+        }\n+\n+        MyValue1 vt = MyValue1.createWithFieldsDontInline(rI + 1, rL);\n+        int result;\n+        for (int i = -20; i < 20; i++) {\n+            try {\n+                result = test17(va, i, vt);\n+            } catch (ArrayIndexOutOfBoundsException e) {\n+                result = rI + 1;\n+            }\n+            Asserts.assertEQ(result, rI + 1);\n+        }\n+\n+        for (int i = 0; i < arraySize; i++) {\n+            Asserts.assertEQ(va[i].x, rI + 1);\n+        }\n+    }\n+\n+    \/\/ clone() as stub call\n+    @Test\n+    public MyValue1.ref[] test18(MyValue1.ref[] va) {\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va1 = new MyValue1.ref[len];\n+        MyValue1[]  va2 = new MyValue1[len];\n+        for (int i = 1; i < len; ++i) {\n+            va1[i] = testValue1;\n+            va2[i] = testValue1;\n+        }\n+        MyValue1.ref[] result1 = test18(va1);\n+        if (len > 0) {\n+            Asserts.assertEQ(result1[0], null);\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            Asserts.assertEQ(result1[i].hash(), va1[i].hash());\n+        }\n+        \/\/ make sure we do deopt: GraphKit::new_array assumes an\n+        \/\/ array of references\n+        for (int j = 0; j < 10; j++) {\n+            MyValue1.ref[] result2 = test18(va2);\n+\n+            for (int i = 0; i < len; ++i) {\n+                Asserts.assertEQ(result2[i].hash(), va2[i].hash());\n+            }\n+        }\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test18\")) {\n+            MyValue1.ref[] result2 = test18(va2);\n+            for (int i = 0; i < len; ++i) {\n+                Asserts.assertEQ(result2[i].hash(), va2[i].hash());\n+            }\n+        }\n+    }\n+\n+    \/\/ clone() as series of loads\/stores\n+    static MyValue1.ref[] test19_orig = null;\n+\n+    @Test\n+    public MyValue1.ref[] test19() {\n+        MyValue1.ref[] va = new MyValue1.ref[8];\n+        for (int i = 1; i < va.length; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        test19_orig = va;\n+\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        MyValue1.ref[] result = test19();\n+        Asserts.assertEQ(result[0], null);\n+        for (int i = 1; i < test19_orig.length; ++i) {\n+            Asserts.assertEQ(result[i].hash(), test19_orig[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array with oop fields\n+    @Test\n+    public void test20(MyValue1.ref[] src, MyValue1.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] src1 = new MyValue1.ref[len];\n+        MyValue1.ref[] src2 = new MyValue1.ref[len];\n+        MyValue1[]  src3 = new MyValue1[len];\n+        MyValue1[]  src4 = new MyValue1[len];\n+        MyValue1.ref[] dst1 = new MyValue1.ref[len];\n+        MyValue1[]  dst2 = new MyValue1[len];\n+        MyValue1.ref[] dst3 = new MyValue1.ref[len];\n+        MyValue1[]  dst4 = new MyValue1[len];\n+        if (len > 0) {\n+            src2[0] = testValue1;\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            src1[i] = testValue1;\n+            src2[i] = testValue1;\n+            src3[i] = testValue1;\n+            src4[i] = testValue1;\n+        }\n+        test20(src1, dst1);\n+        test20(src2, dst2);\n+        test20(src3, dst3);\n+        test20(src4, dst4);\n+        if (len > 0) {\n+            Asserts.assertEQ(dst1[0], null);\n+            Asserts.assertEQ(dst2[0].hash(), src2[0].hash());\n+            Asserts.assertEQ(dst3[0].hash(), src3[0].hash());\n+            Asserts.assertEQ(dst4[0].hash(), src4[0].hash());\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            Asserts.assertEQ(src1[i].hash(), dst1[i].hash());\n+            Asserts.assertEQ(src2[i].hash(), dst2[i].hash());\n+            Asserts.assertEQ(src3[i].hash(), dst3[i].hash());\n+            Asserts.assertEQ(src4[i].hash(), dst4[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array with no oop field\n+    @Test\n+    public void test21(MyValue2.ref[] src, MyValue2.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2.ref[] src1 = new MyValue2.ref[len];\n+        MyValue2.ref[] src2 = new MyValue2.ref[len];\n+        MyValue2[]  src3 = new MyValue2[len];\n+        MyValue2[]  src4 = new MyValue2[len];\n+        MyValue2.ref[] dst1 = new MyValue2.ref[len];\n+        MyValue2[]  dst2 = new MyValue2[len];\n+        MyValue2.ref[] dst3 = new MyValue2.ref[len];\n+        MyValue2[]  dst4 = new MyValue2[len];\n+        if (len > 0) {\n+            src2[0] = MyValue2.createWithFieldsInline(rI, rD);\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            src1[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            src2[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            src3[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            src4[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test21(src1, dst1);\n+        test21(src2, dst2);\n+        test21(src3, dst3);\n+        test21(src4, dst4);\n+        if (len > 0) {\n+            Asserts.assertEQ(dst1[0], null);\n+            Asserts.assertEQ(dst2[0].hash(), src2[0].hash());\n+            Asserts.assertEQ(dst3[0].hash(), src3[0].hash());\n+            Asserts.assertEQ(dst4[0].hash(), src4[0].hash());\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            Asserts.assertEQ(src1[i].hash(), dst1[i].hash());\n+            Asserts.assertEQ(src2[i].hash(), dst2[i].hash());\n+            Asserts.assertEQ(src3[i].hash(), dst3[i].hash());\n+            Asserts.assertEQ(src4[i].hash(), dst4[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array with oop field and tightly\n+    \/\/ coupled allocation as dest\n+    @Test\n+    public MyValue1.ref[] test22(MyValue1.ref[] src) {\n+        MyValue1.ref[] dst = new MyValue1.ref[src.length];\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+        return dst;\n+    }\n+\n+    @DontCompile\n+    public void test22_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] src1 = new MyValue1.ref[len];\n+        MyValue1[]  src2 = new MyValue1[len];\n+        for (int i = 1; i < len; ++i) {\n+            src1[i] = testValue1;\n+            src2[i] = testValue1;\n+        }\n+        MyValue1.ref[] dst1 = test22(src1);\n+        MyValue1.ref[] dst2 = test22(src2);\n+        if (len > 0) {\n+            Asserts.assertEQ(dst1[0], null);\n+            Asserts.assertEQ(dst2[0].hash(), MyValue1.default.hash());\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            Asserts.assertEQ(src1[i].hash(), dst1[i].hash());\n+            Asserts.assertEQ(src2[i].hash(), dst2[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array with oop fields and tightly\n+    \/\/ coupled allocation as dest\n+    @Test\n+    public MyValue1.ref[] test23(MyValue1.ref[] src) {\n+        MyValue1.ref[] dst = new MyValue1.ref[src.length + 10];\n+        System.arraycopy(src, 0, dst, 5, src.length);\n+        return dst;\n+    }\n+\n+    @DontCompile\n+    public void test23_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] src1 = new MyValue1.ref[len];\n+        MyValue1[] src2 = new MyValue1[len];\n+        for (int i = 0; i < len; ++i) {\n+            src1[i] = testValue1;\n+            src2[i] = testValue1;\n+        }\n+        MyValue1.ref[] dst1 = test23(src1);\n+        MyValue1.ref[] dst2 = test23(src2);\n+        for (int i = 0; i < 5; ++i) {\n+            Asserts.assertEQ(dst1[i], null);\n+            Asserts.assertEQ(dst2[i], null);\n+        }\n+        for (int i = 5; i < len; ++i) {\n+            Asserts.assertEQ(src1[i].hash(), dst1[i].hash());\n+            Asserts.assertEQ(src2[i].hash(), dst2[i].hash());\n+        }\n+    }\n+\n+    \/\/ arraycopy() of inline type array passed as Object\n+    @Test\n+    public void test24(MyValue1.ref[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test24_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] src1 = new MyValue1.ref[len];\n+        MyValue1.ref[] src2 = new MyValue1.ref[len];\n+        MyValue1[]  src3 = new MyValue1[len];\n+        MyValue1[]  src4 = new MyValue1[len];\n+        MyValue1.ref[] dst1 = new MyValue1.ref[len];\n+        MyValue1[]  dst2 = new MyValue1[len];\n+        MyValue1.ref[] dst3 = new MyValue1.ref[len];\n+        MyValue1[]  dst4 = new MyValue1[len];\n+        if (len > 0) {\n+            src2[0] = testValue1;\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            src1[i] = testValue1;\n+            src2[i] = testValue1;\n+            src3[i] = testValue1;\n+            src4[i] = testValue1;\n+        }\n+        test24(src1, dst1);\n+        test24(src2, dst2);\n+        test24(src3, dst3);\n+        test24(src4, dst4);\n+        if (len > 0) {\n+            Asserts.assertEQ(dst1[0], null);\n+            Asserts.assertEQ(dst2[0].hash(), src2[0].hash());\n+            Asserts.assertEQ(dst3[0].hash(), src3[0].hash());\n+            Asserts.assertEQ(dst4[0].hash(), src4[0].hash());\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            Asserts.assertEQ(src1[i].hash(), dst1[i].hash());\n+            Asserts.assertEQ(src2[i].hash(), dst2[i].hash());\n+            Asserts.assertEQ(src3[i].hash(), dst3[i].hash());\n+            Asserts.assertEQ(src4[i].hash(), dst4[i].hash());\n+        }\n+    }\n+\n+    \/\/ short arraycopy() with no oop field\n+    @Test\n+    public void test25(MyValue2.ref[] src, MyValue2.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test25_verifier(boolean warmup) {\n+        MyValue2.ref[] src1 = new MyValue2.ref[8];\n+        MyValue2.ref[] src2 = new MyValue2.ref[8];\n+        MyValue2[]  src3 = new MyValue2[8];\n+        MyValue2[]  src4 = new MyValue2[8];\n+        MyValue2.ref[] dst1 = new MyValue2.ref[8];\n+        MyValue2[]  dst2 = new MyValue2[8];\n+        MyValue2.ref[] dst3 = new MyValue2.ref[8];\n+        MyValue2[]  dst4 = new MyValue2[8];\n+        src2[0] = MyValue2.createWithFieldsInline(rI, rD);\n+        for (int i = 1; i < 8; ++i) {\n+            src1[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            src2[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            src3[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            src4[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test25(src1, dst1);\n+        test25(src2, dst2);\n+        test25(src3, dst3);\n+        test25(src4, dst4);\n+        Asserts.assertEQ(dst1[0], null);\n+        Asserts.assertEQ(dst2[0].hash(), src2[0].hash());\n+        Asserts.assertEQ(dst3[0].hash(), src3[0].hash());\n+        Asserts.assertEQ(dst4[0].hash(), src4[0].hash());\n+        for (int i = 1; i < 8; ++i) {\n+            Asserts.assertEQ(src1[i].hash(), dst1[i].hash());\n+            Asserts.assertEQ(src2[i].hash(), dst2[i].hash());\n+            Asserts.assertEQ(src3[i].hash(), dst3[i].hash());\n+            Asserts.assertEQ(src4[i].hash(), dst4[i].hash());\n+        }\n+    }\n+\n+    \/\/ short arraycopy() with oop fields\n+    @Test\n+    public void test26(MyValue1.ref[] src, MyValue1.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test26_verifier(boolean warmup) {\n+        MyValue1.ref[] src1 = new MyValue1.ref[8];\n+        MyValue1.ref[] src2 = new MyValue1.ref[8];\n+        MyValue1[]  src3 = new MyValue1[8];\n+        MyValue1[]  src4 = new MyValue1[8];\n+        MyValue1.ref[] dst1 = new MyValue1.ref[8];\n+        MyValue1[]  dst2 = new MyValue1[8];\n+        MyValue1.ref[] dst3 = new MyValue1.ref[8];\n+        MyValue1[]  dst4 = new MyValue1[8];\n+        src2[0] = testValue1;\n+        for (int i = 1; i < 8 ; ++i) {\n+            src1[i] = testValue1;\n+            src2[i] = testValue1;\n+            src3[i] = testValue1;\n+            src4[i] = testValue1;\n+        }\n+        test26(src1, dst1);\n+        test26(src2, dst2);\n+        test26(src3, dst3);\n+        test26(src4, dst4);\n+        Asserts.assertEQ(dst1[0], null);\n+        Asserts.assertEQ(dst2[0].hash(), src2[0].hash());\n+        Asserts.assertEQ(dst3[0].hash(), src3[0].hash());\n+        Asserts.assertEQ(dst4[0].hash(), src4[0].hash());\n+        for (int i = 1; i < 8; ++i) {\n+            Asserts.assertEQ(src1[i].hash(), dst1[i].hash());\n+            Asserts.assertEQ(src2[i].hash(), dst2[i].hash());\n+            Asserts.assertEQ(src3[i].hash(), dst3[i].hash());\n+            Asserts.assertEQ(src4[i].hash(), dst4[i].hash());\n+        }\n+    }\n+\n+    \/\/ short arraycopy() with oop fields and offsets\n+    @Test\n+    public void test27(MyValue1.ref[] src, MyValue1.ref[] dst) {\n+        System.arraycopy(src, 1, dst, 2, 6);\n+    }\n+\n+    @DontCompile\n+    public void test27_verifier(boolean warmup) {\n+        MyValue1.ref[] src1 = new MyValue1.ref[8];\n+        MyValue1.ref[] src2 = new MyValue1.ref[8];\n+        MyValue1[]  src3 = new MyValue1[8];\n+        MyValue1[]  src4 = new MyValue1[8];\n+        MyValue1.ref[] dst1 = new MyValue1.ref[8];\n+        MyValue1[]  dst2 = new MyValue1[8];\n+        MyValue1.ref[] dst3 = new MyValue1.ref[8];\n+        MyValue1[]  dst4 = new MyValue1[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src1[i] = testValue1;\n+            src2[i] = testValue1;\n+            src3[i] = testValue1;\n+            src4[i] = testValue1;\n+        }\n+        test27(src1, dst1);\n+        test27(src2, dst2);\n+        test27(src3, dst3);\n+        test27(src4, dst4);\n+        for (int i = 0; i < 2; ++i) {\n+            Asserts.assertEQ(dst1[i], null);\n+            Asserts.assertEQ(dst2[i].hash(), MyValue1.default.hash());\n+            Asserts.assertEQ(dst3[i], null);\n+            Asserts.assertEQ(dst4[i].hash(), MyValue1.default.hash());\n+        }\n+        for (int i = 2; i < 8; ++i) {\n+            Asserts.assertEQ(src1[i].hash(), dst1[i].hash());\n+            Asserts.assertEQ(src2[i].hash(), dst2[i].hash());\n+            Asserts.assertEQ(src3[i].hash(), dst3[i].hash());\n+            Asserts.assertEQ(src4[i].hash(), dst4[i].hash());\n+        }\n+    }\n+\n+    \/\/ non escaping allocations\n+    \/\/ TODO 8252027: Make sure this is optimized with ZGC\n+    @Test(valid = ZGCOff, failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    @Test(valid = ZGCOn)\n+    public MyValue2.ref test28() {\n+        MyValue2.ref[] src = new MyValue2.ref[10];\n+        src[0] = null;\n+        MyValue2.ref[] dst = (MyValue2.ref[])src.clone();\n+        return dst[0];\n+    }\n+\n+    @DontCompile\n+    public void test28_verifier(boolean warmup) {\n+        MyValue2 v = MyValue2.createWithFieldsInline(rI, rD);\n+        MyValue2.ref result = test28();\n+        Asserts.assertEQ(result, null);\n+    }\n+\n+    \/\/ non escaping allocations\n+    \/\/ TODO 8227588: shouldn't this have the same IR matching rules as test6?\n+    @Test(failOn = ALLOCA + LOOP + TRAP)\n+    public MyValue2.ref test29(MyValue2.ref[] src) {\n+        MyValue2.ref[] dst = new MyValue2.ref[10];\n+        System.arraycopy(src, 0, dst, 0, 10);\n+        return dst[0];\n+    }\n+\n+    @DontCompile\n+    public void test29_verifier(boolean warmup) {\n+        MyValue2.ref[] src1 = new MyValue2.ref[10];\n+        MyValue2.val[] src2 = new MyValue2.val[10];\n+        for (int i = 0; i < 10; ++i) {\n+            src1[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            src2[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        MyValue2.ref v = test29(src1);\n+        Asserts.assertEQ(src1[0].hash(), v.hash());\n+        if (!warmup) {\n+            v = test29(src2);\n+            Asserts.assertEQ(src2[0].hash(), v.hash());\n+        }\n+    }\n+\n+    \/\/ non escaping allocation with uncommon trap that needs\n+    \/\/ eliminated inline type array element as debug info\n+    @Test\n+    @Warmup(10000)\n+    public MyValue2.ref test30(MyValue2.ref[] src, boolean flag) {\n+        MyValue2.ref[] dst = new MyValue2.ref[10];\n+        System.arraycopy(src, 0, dst, 0, 10);\n+        if (flag) { }\n+        return dst[0];\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) {\n+        MyValue2.ref[] src1 = new MyValue2.ref[10];\n+        MyValue2.val[] src2 = new MyValue2.val[10];\n+        for (int i = 0; i < 10; ++i) {\n+            src1[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+            src2[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        MyValue2.ref v = test30(src1, !warmup);\n+        Asserts.assertEQ(src1[0].hash(), v.hash());\n+        if (!warmup) {\n+            v = test30(src2, true);\n+            Asserts.assertEQ(src2[0].hash(), v.hash());\n+        }\n+    }\n+\n+    \/\/ non escaping allocation with memory phi\n+    @Test()\n+    \/\/ TODO 8227588\n+    \/\/ @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public long test31(boolean b, boolean deopt) {\n+        MyValue2.ref[] src = new MyValue2.ref[1];\n+        if (b) {\n+            src[0] = MyValue2.createWithFieldsInline(rI, rD);\n+        } else {\n+            src[0] = MyValue2.createWithFieldsInline(rI+1, rD+1);\n+        }\n+        if (deopt) {\n+            \/\/ uncommon trap\n+            WHITE_BOX.deoptimizeMethod(tests.get(getClass().getSimpleName() + \"::test31\"));\n+        }\n+        return src[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test31_verifier(boolean warmup) {\n+        MyValue2 v1 = MyValue2.createWithFieldsInline(rI, rD);\n+        long result1 = test31(true, !warmup);\n+        Asserts.assertEQ(result1, v1.hash());\n+        MyValue2 v2 = MyValue2.createWithFieldsInline(rI+1, rD+1);\n+        long result2 = test31(false, !warmup);\n+        Asserts.assertEQ(result2, v2.hash());\n+    }\n+\n+    \/\/ Tests with Object arrays and clone\/arraycopy\n+    \/\/ clone() as stub call\n+    @Test\n+    public Object[] test32(Object[] va) {\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test32_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va1 = new MyValue1.ref[len];\n+        MyValue1[] va2 = new MyValue1[len];\n+        for (int i = 1; i < len; ++i) {\n+            va1[i] = testValue1;\n+            va2[i] = testValue1;\n+        }\n+        MyValue1.ref[] result1 = (MyValue1.ref[])test32(va1);\n+        MyValue1.ref[] result2 = (MyValue1.ref[])test32(va2);\n+        if (len > 0) {\n+            Asserts.assertEQ(result1[0], null);\n+            Asserts.assertEQ(result2[0].hash(), MyValue1.default.hash());\n+        }\n+        for (int i = 1; i < len; ++i) {\n+            Asserts.assertEQ(((MyValue1)result1[i]).hash(), ((MyValue1)va1[i]).hash());\n+            Asserts.assertEQ(((MyValue1)result2[i]).hash(), ((MyValue1)va2[i]).hash());\n+        }\n+    }\n+\n+    @Test\n+    public Object[] test33(Object[] va) {\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] va = new Object[len];\n+        for (int i = 0; i < len; ++i) {\n+            va[i] = testValue1;\n+        }\n+        Object[] result = test33(va);\n+        for (int i = 0; i < len; ++i) {\n+            Asserts.assertEQ(((MyValue1)result[i]).hash(), ((MyValue1)va[i]).hash());\n+        }\n+    }\n+\n+    \/\/ clone() as series of loads\/stores\n+    static Object[] test34_orig = null;\n+\n+    @ForceInline\n+    public Object[] test34_helper(boolean flag) {\n+        Object[] va = null;\n+        if (flag) {\n+            va = new MyValue1.ref[8];\n+            for (int i = 0; i < va.length; ++i) {\n+                va[i] = MyValue1.createWithFieldsDontInline(rI, rL);\n+            }\n+        } else {\n+            va = new Object[8];\n+        }\n+        return va;\n+    }\n+\n+    @Test\n+    public Object[] test34(boolean flag) {\n+        Object[] va = test34_helper(flag);\n+        test34_orig = va;\n+        return va.clone();\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        test34(false);\n+        for (int i = 0; i < 10; i++) { \/\/ make sure we do deopt\n+            Object[] result = test34(true);\n+            verify(test34_orig, result);\n+        }\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test34\")) {\n+            Object[] result = test34(true);\n+            verify(test34_orig, result);\n+        }\n+    }\n+\n+    static void verify(Object[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            if (src[i] != null) {\n+                Asserts.assertEQ(((MyInterface)src[i]).hash(), ((MyInterface)dst[i]).hash());\n+            } else {\n+                Asserts.assertEQ(dst[i], null);\n+            }\n+        }\n+    }\n+\n+    static void verify(MyValue1.ref[] src, MyValue1.ref[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            if (src[i] != null) {\n+                Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+            } else {\n+                Asserts.assertEQ(dst[i], null);\n+            }\n+        }\n+    }\n+\n+    static void verify(MyValue1.ref[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            if (src[i] != null) {\n+                Asserts.assertEQ(src[i].hash(), ((MyInterface)dst[i]).hash());\n+            } else {\n+                Asserts.assertEQ(dst[i], null);\n+            }\n+        }\n+    }\n+\n+    static void verify(MyValue2.ref[] src, MyValue2.ref[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            if (src[i] != null) {\n+                Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+            } else {\n+                Asserts.assertEQ(dst[i], null);\n+            }\n+        }\n+    }\n+\n+    static void verify(MyValue2.ref[] src, Object[] dst) {\n+        for (int i = 0; i < src.length; ++i) {\n+            if (src[i] != null) {\n+                Asserts.assertEQ(src[i].hash(), ((MyInterface)dst[i]).hash());\n+            } else {\n+                Asserts.assertEQ(dst[i], null);\n+            }\n+        }\n+    }\n+\n+    static boolean compile_and_run_again_if_deoptimized(boolean warmup, String test) {\n+        if (!warmup) {\n+            Method m = tests.get(test);\n+            if (USE_COMPILER &&  !WHITE_BOX.isMethodCompiled(m, false)) {\n+                if (!InlineTypeArrayFlatten && !XCOMP && !STRESS_CC) {\n+                    throw new RuntimeException(\"Unexpected deoptimization\");\n+                }\n+                enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    \/\/ arraycopy() of inline type array of unknown size\n+    @Test\n+    public void test35(Object src, Object dst, int len) {\n+        System.arraycopy(src, 0, dst, 0, len);\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] src = new MyValue1.ref[len];\n+        MyValue1.ref[] dst = new MyValue1.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = testValue1;\n+        }\n+        test35(src, dst, src.length);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test35\")) {\n+            test35(src, dst, src.length);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test36(Object src, MyValue2.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, dst.length);\n+    }\n+\n+    @DontCompile\n+    public void test36_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2.ref[] src = new MyValue2.ref[len];\n+        MyValue2.ref[] dst = new MyValue2.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test36(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test36\")) {\n+            test36(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test37(MyValue2.ref[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2.ref[] src = new MyValue2.ref[len];\n+        MyValue2.ref[] dst = new MyValue2.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test37(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test37\")) {\n+            test37(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(1) \/\/ Avoid early compilation\n+    public void test38(Object src, MyValue2.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, dst.length);\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] src = new Object[len];\n+        MyValue2.ref[] dst = new MyValue2.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test38(src, dst);\n+        verify(dst, src);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestNullableArrays::test38\");\n+            assertDeoptimizedByC2(m);\n+            enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            test38(src, dst);\n+            verify(dst, src);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test39(MyValue2.ref[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2.ref[] src = new MyValue2.ref[len];\n+        Object[] dst = new Object[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test39(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test39\")) {\n+            test39(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(1) \/\/ Avoid early compilation\n+    public void test40(Object[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] src = new Object[len];\n+        MyValue2.ref[] dst = new MyValue2.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test40(src, dst);\n+        verify(dst, src);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestNullableArrays::test40\");\n+            assertDeoptimizedByC2(m);\n+            enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            test40(src, dst);\n+            verify(dst, src);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test41(Object src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, dst.length);\n+    }\n+\n+    @DontCompile\n+    public void test41_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue2.ref[] src = new MyValue2.ref[len];\n+        Object[] dst = new Object[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test41(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test41\")) {\n+            test41(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test42(Object[] src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+    }\n+\n+    @DontCompile\n+    public void test42_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] src = new Object[len];\n+        Object[] dst = new Object[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test42(src, dst);\n+        verify(src, dst);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestNullableArrays::test42\");\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    \/\/ short arraycopy()'s\n+    @Test\n+    public void test43(Object src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test43_verifier(boolean warmup) {\n+        MyValue1.ref[] src = new MyValue1.ref[8];\n+        MyValue1.ref[] dst = new MyValue1.ref[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = testValue1;\n+        }\n+        test43(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test43\")) {\n+            test43(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test44(Object src, MyValue2.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test44_verifier(boolean warmup) {\n+        MyValue2.ref[] src = new MyValue2.ref[8];\n+        MyValue2.ref[] dst = new MyValue2.ref[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test44(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test44\")) {\n+            test44(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test45(MyValue2.ref[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test45_verifier(boolean warmup) {\n+        MyValue2.ref[] src = new MyValue2.ref[8];\n+        MyValue2.ref[] dst = new MyValue2.ref[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test45(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test45\")) {\n+            test45(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(1) \/\/ Avoid early compilation\n+    public void test46(Object[] src, MyValue2.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test46_verifier(boolean warmup) {\n+        Object[] src = new Object[8];\n+        MyValue2.ref[] dst = new MyValue2.ref[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test46(src, dst);\n+        verify(dst, src);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestNullableArrays::test46\");\n+            assertDeoptimizedByC2(m);\n+            enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            test46(src, dst);\n+            verify(dst, src);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test47(MyValue2.ref[] src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test47_verifier(boolean warmup) {\n+        MyValue2.ref[] src = new MyValue2.ref[8];\n+        Object[] dst = new Object[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test47(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test47\")) {\n+            test47(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    @Warmup(1) \/\/ Avoid early compilation\n+    public void test48(Object[] src, Object dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test48_verifier(boolean warmup) {\n+        Object[] src = new Object[8];\n+        MyValue2.ref[] dst = new MyValue2.ref[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test48(src, dst);\n+        verify(dst, src);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestNullableArrays::test48\");\n+            assertDeoptimizedByC2(m);\n+            enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);\n+            test48(src, dst);\n+            verify(dst, src);\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void test49(Object src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test49_verifier(boolean warmup) {\n+        MyValue2.ref[] src = new MyValue2.ref[8];\n+        Object[] dst = new Object[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test49(src, dst);\n+        verify(src, dst);\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test49\")) {\n+            test49(src, dst);\n+            verify(src, dst);\n+        }\n+    }\n+\n+    @Test\n+    public void test50(Object[] src, Object[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 8);\n+    }\n+\n+    @DontCompile\n+    public void test50_verifier(boolean warmup) {\n+        Object[] src = new Object[8];\n+        Object[] dst = new Object[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = MyValue2.createWithFieldsInline(rI+i, rD+i);\n+        }\n+        test50(src, dst);\n+        verify(src, dst);\n+        if (!warmup) {\n+            Method m = tests.get(\"TestNullableArrays::test50\");\n+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {\n+                throw new RuntimeException(\"unexpected deoptimization\");\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public MyValue1.ref[] test51(MyValue1.ref[] va) {\n+        return Arrays.copyOf(va, va.length, MyValue1.ref[].class);\n+    }\n+\n+    @DontCompile\n+    public void test51_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+        }\n+        MyValue1.ref[] result = test51(va);\n+        verify(va, result);\n+    }\n+\n+    static final MyValue1.ref[] test52_va = new MyValue1.ref[8];\n+\n+    @Test\n+    public MyValue1.ref[] test52() {\n+        return Arrays.copyOf(test52_va, 8, MyValue1.ref[].class);\n+    }\n+\n+    @DontCompile\n+    public void test52_verifier(boolean warmup) {\n+        for (int i = 1; i < 8; ++i) {\n+            test52_va[i] = testValue1;\n+        }\n+        MyValue1.ref[] result = test52();\n+        verify(test52_va, result);\n+    }\n+\n+    @Test\n+    public MyValue1.ref[] test53(Object[] va) {\n+        return Arrays.copyOf(va, va.length, MyValue1.ref[].class);\n+    }\n+\n+    @DontCompile\n+    public void test53_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+        }\n+        MyValue1.ref[] result = test53(va);\n+        verify(result, va);\n+    }\n+\n+    @Test\n+    public Object[] test54(MyValue1.ref[] va) {\n+        return Arrays.copyOf(va, va.length, Object[].class);\n+    }\n+\n+    @DontCompile\n+    public void test54_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+        }\n+        Object[] result = test54(va);\n+        verify(va, result);\n+    }\n+\n+    @Test\n+    public Object[] test55(Object[] va) {\n+        return Arrays.copyOf(va, va.length, Object[].class);\n+    }\n+\n+    @DontCompile\n+    public void test55_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+        }\n+        Object[] result = test55(va);\n+        verify(va, result);\n+    }\n+\n+    @Test\n+    public MyValue1.ref[] test56(Object[] va) {\n+        return Arrays.copyOf(va, va.length, MyValue1.ref[].class);\n+    }\n+\n+    @DontCompile\n+    public void test56_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] va = new Object[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+        }\n+        MyValue1.ref[] result = test56(va);\n+        verify(result, va);\n+    }\n+\n+   @Test\n+    public Object[] test57(Object[] va, Class klass) {\n+        return Arrays.copyOf(va, va.length, klass);\n+    }\n+\n+    @DontCompile\n+    public void test57_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] va = new MyValue1.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+        }\n+        Object[] result = test57(va, MyValue1.ref[].class);\n+        verify(va, result);\n+    }\n+\n+    @Test\n+    public Object[] test58(MyValue1.ref[] va, Class klass) {\n+        return Arrays.copyOf(va, va.length, klass);\n+    }\n+\n+    @DontCompile\n+    public void test58_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+        }\n+        for (int i = 1; i < 10; i++) {\n+            Object[] result = test58(va, MyValue1.ref[].class);\n+            verify(va, result);\n+        }\n+        if (compile_and_run_again_if_deoptimized(warmup, \"TestNullableArrays::test58\")) {\n+            Object[] result = test58(va, MyValue1.ref[].class);\n+            verify(va, result);\n+        }\n+    }\n+\n+    @Test\n+    public Object[] test59(MyValue1.ref[] va) {\n+        return Arrays.copyOf(va, va.length+1, MyValue1.ref[].class);\n+    }\n+\n+    @DontCompile\n+    public void test59_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        MyValue1.ref[] verif = new MyValue1.ref[len+1];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+            verif[i] = va[i];\n+        }\n+        Object[] result = test59(va);\n+        verify(verif, result);\n+    }\n+\n+    @Test\n+    public Object[] test60(Object[] va, Class klass) {\n+        return Arrays.copyOf(va, va.length+1, klass);\n+    }\n+\n+    @DontCompile\n+    public void test60_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        MyValue1.ref[] verif = new MyValue1.ref[len+1];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+            verif[i] = (MyValue1)va[i];\n+        }\n+        Object[] result = test60(va, MyValue1.ref[].class);\n+        verify(verif, result);\n+    }\n+\n+    @Test\n+    public Object[] test61(Object[] va, Class klass) {\n+        return Arrays.copyOf(va, va.length+1, klass);\n+    }\n+\n+    @DontCompile\n+    public void test61_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        Object[] va = new Integer[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = Integer.valueOf(rI);\n+        }\n+        Object[] result = test61(va, Integer[].class);\n+        for (int i = 0; i < va.length; ++i) {\n+            Asserts.assertEQ(va[i], result[i]);\n+        }\n+    }\n+\n+    @ForceInline\n+    public Object[] test62_helper(int i, MyValue1.ref[] va, Integer[] oa) {\n+        Object[] arr = null;\n+        if (i == 10) {\n+            arr = oa;\n+        } else {\n+            arr = va;\n+        }\n+        return arr;\n+    }\n+\n+    @Test\n+    public Object[] test62(MyValue1.ref[] va, Integer[] oa) {\n+        int i = 0;\n+        for (; i < 10; i++);\n+\n+        Object[] arr = test62_helper(i, va, oa);\n+\n+        return Arrays.copyOf(arr, arr.length+1, arr.getClass());\n+    }\n+\n+    @DontCompile\n+    public void test62_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        Integer[] oa = new Integer[len];\n+        for (int i = 1; i < len; ++i) {\n+            oa[i] = Integer.valueOf(rI);\n+        }\n+        test62_helper(42, va, oa);\n+        Object[] result = test62(va, oa);\n+        for (int i = 0; i < va.length; ++i) {\n+            Asserts.assertEQ(oa[i], result[i]);\n+        }\n+    }\n+\n+    @ForceInline\n+    public Object[] test63_helper(int i, MyValue1.ref[] va, Integer[] oa) {\n+        Object[] arr = null;\n+        if (i == 10) {\n+            arr = va;\n+        } else {\n+            arr = oa;\n+        }\n+        return arr;\n+    }\n+\n+    @Test\n+    public Object[] test63(MyValue1.ref[] va, Integer[] oa) {\n+        int i = 0;\n+        for (; i < 10; i++);\n+\n+        Object[] arr = test63_helper(i, va, oa);\n+\n+        return Arrays.copyOf(arr, arr.length+1, arr.getClass());\n+    }\n+\n+    @DontCompile\n+    public void test63_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        MyValue1.ref[] verif = new MyValue1.ref[len+1];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+            verif[i] = va[i];\n+        }\n+        Integer[] oa = new Integer[len];\n+        test63_helper(42, va, oa);\n+        Object[] result = test63(va, oa);\n+        verify(verif, result);\n+    }\n+\n+    \/\/ Test default initialization of inline type arrays: small array\n+    @Test\n+    public MyValue1.ref[] test64() {\n+        return new MyValue1.ref[8];\n+    }\n+\n+    @DontCompile\n+    public void test64_verifier(boolean warmup) {\n+        MyValue1.ref[] va = test64();\n+        for (int i = 0; i < 8; ++i) {\n+            Asserts.assertEQ(va[i], null);\n+        }\n+    }\n+\n+    \/\/ Test default initialization of inline type arrays: large array\n+    @Test\n+    public MyValue1.ref[] test65() {\n+        return new MyValue1.ref[32];\n+    }\n+\n+    @DontCompile\n+    public void test65_verifier(boolean warmup) {\n+        MyValue1.ref[] va = test65();\n+        for (int i = 0; i < 32; ++i) {\n+            Asserts.assertEQ(va[i], null);\n+        }\n+    }\n+\n+    \/\/ Check init store elimination\n+    @Test(match = { ALLOCA }, matchCount = { 1 })\n+    public MyValue1.ref[] test66(MyValue1.ref vt) {\n+        MyValue1.ref[] va = new MyValue1.ref[1];\n+        va[0] = vt;\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test66_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1.ref[] va = test66(vt);\n+        Asserts.assertEQ(va[0].hashPrimitive(), vt.hashPrimitive());\n+    }\n+\n+    \/\/ Zeroing elimination and arraycopy\n+    @Test\n+    public MyValue1.ref[] test67(MyValue1.ref[] src) {\n+        MyValue1.ref[] dst = new MyValue1.ref[16];\n+        System.arraycopy(src, 0, dst, 0, 13);\n+        return dst;\n+    }\n+\n+    @DontCompile\n+    public void test67_verifier(boolean warmup) {\n+        MyValue1.ref[] va = new MyValue1.ref[16];\n+        MyValue1.ref[] var = test67(va);\n+        for (int i = 0; i < 16; ++i) {\n+            Asserts.assertEQ(var[i], null);\n+        }\n+    }\n+\n+    \/\/ A store with a default value can be eliminated\n+    @Test\n+    public MyValue1.ref[] test68() {\n+        MyValue1.ref[] va = new MyValue1.ref[2];\n+        va[0] = va[1];\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test68_verifier(boolean warmup) {\n+        MyValue1.ref[] va = test68();\n+        for (int i = 0; i < 2; ++i) {\n+            Asserts.assertEQ(va[i], null);\n+        }\n+    }\n+\n+    \/\/ Requires individual stores to init array\n+    @Test\n+    public MyValue1.ref[] test69(MyValue1.ref vt) {\n+        MyValue1.ref[] va = new MyValue1.ref[4];\n+        va[0] = vt;\n+        va[3] = vt;\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test69_verifier(boolean warmup) {\n+        MyValue1.ref vt = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1.ref[] va = new MyValue1.ref[4];\n+        va[0] = vt;\n+        va[3] = vt;\n+        MyValue1.ref[] var = test69(vt);\n+        for (int i = 0; i < va.length; ++i) {\n+            Asserts.assertEQ(va[i], var[i]);\n+        }\n+    }\n+\n+    \/\/ A store with a default value can be eliminated: same as test68\n+    \/\/ but store is farther away from allocation\n+    @Test\n+    public MyValue1.ref[] test70(MyValue1.ref[] other) {\n+        other[1] = other[0];\n+        MyValue1.ref[] va = new MyValue1.ref[2];\n+        other[0] = va[1];\n+        va[0] = va[1];\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test70_verifier(boolean warmup) {\n+        MyValue1.ref[] va = new MyValue1.ref[2];\n+        MyValue1.ref[] var = test70(va);\n+        for (int i = 0; i < 2; ++i) {\n+            Asserts.assertEQ(va[i], var[i]);\n+        }\n+    }\n+\n+    \/\/ EA needs to consider oop fields in flattened arrays\n+    @Test\n+    public void test71() {\n+        int len = 10;\n+        MyValue2.ref[] src = new MyValue2.ref[len];\n+        MyValue2.ref[] dst = new MyValue2.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            src[i] = MyValue2.createWithFieldsDontInline(rI+i, rD+i);\n+        }\n+        System.arraycopy(src, 0, dst, 0, src.length);\n+        for (int i = 0; i < len; ++i) {\n+            if (src[i] == null) {\n+                Asserts.assertEQ(dst[i], null);\n+            } else {\n+                Asserts.assertEQ(src[i].hash(), dst[i].hash());\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test71_verifier(boolean warmup) {\n+        test71();\n+    }\n+\n+    \/\/ Test EA with leaf call to 'store_unknown_value'\n+    @Test\n+    public void test72(Object[] o, boolean b, Object element) {\n+        Object[] arr1 = new Object[10];\n+        Object[] arr2 = new Object[10];\n+        if (b) {\n+            arr1 = o;\n+        }\n+        arr1[0] = element;\n+        arr2[0] = element;\n+    }\n+\n+    @DontCompile\n+    public void test72_verifier(boolean warmup) {\n+        Object[] arr = new Object[1];\n+        Object elem = new Object();\n+        test72(arr, true, elem);\n+        test72(arr, false, elem);\n+    }\n+\n+    @Test\n+    public void test73(Object[] oa, MyValue1.ref v, Object o) {\n+        \/\/ TestLWorld.test38 use a C1 Phi node for the array. This test\n+        \/\/ adds the case where the stored value is a C1 Phi node.\n+        Object o2 = (o == null) ? v : o;\n+        oa[0] = v;  \/\/ The stored value is known to be flattenable\n+        oa[1] = o;  \/\/ The stored value may be flattenable\n+        oa[2] = o2; \/\/ The stored value may be flattenable (a C1 Phi node)\n+        oa[0] = oa; \/\/ The stored value is known to be not flattenable (an Object[])\n+    }\n+\n+    @DontCompile\n+    public void test73_verifier(boolean warmup) {\n+        MyValue1.ref v0 = MyValue1.createWithFieldsDontInline(rI, rL);\n+        MyValue1.ref v1 = MyValue1.createWithFieldsDontInline(rI+1, rL+1);\n+        MyValue1.ref[] arr = new MyValue1.ref[3];\n+        try {\n+            test73(arr, v0, v1);\n+            throw new RuntimeException(\"ArrayStoreException expected\");\n+        } catch (ArrayStoreException t) {\n+            \/\/ expected\n+        }\n+        Asserts.assertEQ(arr[0].hash(), v0.hash());\n+        Asserts.assertEQ(arr[1].hash(), v1.hash());\n+        Asserts.assertEQ(arr[2].hash(), v1.hash());\n+    }\n+\n+    \/\/ Some more array clone tests\n+    @ForceInline\n+    public Object[] test74_helper(int i, MyValue1.ref[] va, Integer[] oa) {\n+        Object[] arr = null;\n+        if (i == 10) {\n+            arr = oa;\n+        } else {\n+            arr = va;\n+        }\n+        return arr;\n+    }\n+\n+    @Test\n+    public Object[] test74(MyValue1.ref[] va, Integer[] oa) {\n+        int i = 0;\n+        for (; i < 10; i++);\n+\n+        Object[] arr = test74_helper(i, va, oa);\n+        return arr.clone();\n+    }\n+\n+    @DontCompile\n+    public void test74_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        Integer[] oa = new Integer[len];\n+        for (int i = 1; i < len; ++i) {\n+            oa[i] = Integer.valueOf(rI);\n+        }\n+        test74_helper(42, va, oa);\n+        Object[] result = test74(va, oa);\n+\n+        for (int i = 0; i < va.length; ++i) {\n+            Asserts.assertEQ(oa[i], result[i]);\n+            \/\/ Check that array has correct properties (null-ok)\n+            result[i] = null;\n+        }\n+    }\n+\n+    @ForceInline\n+    public Object[] test75_helper(int i, MyValue1.ref[] va, Integer[] oa) {\n+        Object[] arr = null;\n+        if (i == 10) {\n+            arr = va;\n+        } else {\n+            arr = oa;\n+        }\n+        return arr;\n+    }\n+\n+    @Test\n+    public Object[] test75(MyValue1.ref[] va, Integer[] oa) {\n+        int i = 0;\n+        for (; i < 10; i++);\n+\n+        Object[] arr = test75_helper(i, va, oa);\n+        return arr.clone();\n+    }\n+\n+    @DontCompile\n+    public void test75_verifier(boolean warmup) {\n+        int len = Math.abs(rI) % 10;\n+        MyValue1.ref[] va = new MyValue1.ref[len];\n+        MyValue1.ref[] verif = new MyValue1.ref[len];\n+        for (int i = 1; i < len; ++i) {\n+            va[i] = testValue1;\n+            verif[i] = va[i];\n+        }\n+        Integer[] oa = new Integer[len];\n+        test75_helper(42, va, oa);\n+        Object[] result = test75(va, oa);\n+        verify(verif, result);\n+        if (len > 0) {\n+            \/\/ Check that array has correct properties (null-ok)\n+            result[0] = null;\n+        }\n+    }\n+\n+    \/\/ Test mixing nullable and non-nullable arrays\n+    @Test\n+    public Object[] test76(MyValue1[] vva, MyValue1.ref[] vba, MyValue1 vt, Object[] out, int n) {\n+        Object[] result = null;\n+        if (n == 0) {\n+            result = vva;\n+        } else if (n == 1) {\n+            result = vba;\n+        } else if (n == 2) {\n+            result = new MyValue1[42];\n+        } else if (n == 3) {\n+            result = new MyValue1.ref[42];\n+        }\n+        result[0] = vt;\n+        out[0] = result[1];\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test76_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        Object[] out = new Object[1];\n+        MyValue1[] vva = new MyValue1[42];\n+        MyValue1[] vva_r = new MyValue1[42];\n+        vva_r[0] = vt;\n+        MyValue1.ref[] vba = new MyValue1.ref[42];\n+        MyValue1.ref[] vba_r = new MyValue1.ref[42];\n+        vba_r[0] = vt;\n+        Object[] result = test76(vva, vba, vt, out, 0);\n+        verify(result, vva_r);\n+        Asserts.assertEQ(out[0], vva_r[1]);\n+        result = test76(vva, vba, vt, out, 1);\n+        verify(result, vba_r);\n+        Asserts.assertEQ(out[0], vba_r[1]);\n+        result = test76(vva, vba, vt, out, 2);\n+        verify(result, vva_r);\n+        Asserts.assertEQ(out[0], vva_r[1]);\n+        result = test76(vva, vba, vt, out, 3);\n+        verify(result, vba_r);\n+        Asserts.assertEQ(out[0], vba_r[1]);\n+    }\n+\n+    @Test\n+    public Object[] test77(boolean b) {\n+        Object[] va;\n+        if (b) {\n+            va = new MyValue1.ref[5];\n+            for (int i = 0; i < 5; ++i) {\n+                va[i] = testValue1;\n+            }\n+        } else {\n+            va = new MyValue1[10];\n+            for (int i = 0; i < 10; ++i) {\n+                va[i] = MyValue1.createWithFieldsInline(rI + i, rL + i);\n+            }\n+        }\n+        long sum = ((MyValue1)va[0]).hashInterpreted();\n+        if (b) {\n+            va[0] = MyValue1.createWithFieldsDontInline(rI, sum);\n+        } else {\n+            va[0] = MyValue1.createWithFieldsDontInline(rI + 1, sum + 1);\n+        }\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test77_verifier(boolean warmup) {\n+        Object[] va = test77(true);\n+        Asserts.assertEQ(va.length, 5);\n+        Asserts.assertEQ(((MyValue1)va[0]).hash(), hash(rI, hash()));\n+        for (int i = 1; i < 5; ++i) {\n+            Asserts.assertEQ(((MyValue1)va[i]).hash(), hash());\n+        }\n+        va = test77(false);\n+        Asserts.assertEQ(va.length, 10);\n+        Asserts.assertEQ(((MyValue1)va[0]).hash(), hash(rI + 1, hash(rI, rL) + 1));\n+        for (int i = 1; i < 10; ++i) {\n+            Asserts.assertEQ(((MyValue1)va[i]).hash(), hash(rI + i, rL + i));\n+        }\n+    }\n+\n+    \/\/ Same as test76 but with non inline type array cases\n+    @Test\n+    public Object[] test78(MyValue1[] vva, MyValue1.ref[] vba, Object val, Object[] out, int n) {\n+        Object[] result = null;\n+        if (n == 0) {\n+            result = vva;\n+        } else if (n == 1) {\n+            result = vba;\n+        } else if (n == 2) {\n+            result = new MyValue1[42];\n+        } else if (n == 3) {\n+            result = new MyValue1.ref[42];\n+        } else if (n == 4) {\n+            result = new Integer[42];\n+        }\n+        result[0] = val;\n+        out[0] = result[1];\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test78_verifier(boolean warmup) {\n+        MyValue1 vt = testValue1;\n+        Integer i = Integer.valueOf(42);\n+        Object[] out = new Object[1];\n+        MyValue1[] vva = new MyValue1[42];\n+        MyValue1[] vva_r = new MyValue1[42];\n+        vva_r[0] = vt;\n+        MyValue1.ref[] vba = new MyValue1.ref[42];\n+        MyValue1.ref[] vba_r = new MyValue1.ref[42];\n+        vba_r[0] = vt;\n+        Object[] result = test78(vva, vba, vt, out, 0);\n+        verify(result, vva_r);\n+        Asserts.assertEQ(out[0], vva_r[1]);\n+        result = test78(vva, vba, vt, out, 1);\n+        verify(result, vba_r);\n+        Asserts.assertEQ(out[0], vba_r[1]);\n+        result = test78(vva, vba, vt, out, 2);\n+        verify(result, vva_r);\n+        Asserts.assertEQ(out[0], vva_r[1]);\n+        result = test78(vva, vba, vt, out, 3);\n+        verify(result, vba_r);\n+        Asserts.assertEQ(out[0], vba_r[1]);\n+        result = test78(vva, vba, i, out, 4);\n+        Asserts.assertEQ(result[0], i);\n+        Asserts.assertEQ(out[0], null);\n+    }\n+\n+    \/\/ Test widening conversions from [Q to [L\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public static MyValue1.ref[] test79(MyValue1[] va) {\n+        return va;\n+    }\n+\n+    @DontCompile\n+    public void test79_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[1];\n+        va[0] = testValue1;\n+        MyValue1.ref[] res = test79(va);\n+        Asserts.assertEquals(res[0].hash(), testValue1.hash());\n+        try {\n+            res[0] = null;\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException npe) {\n+            \/\/ Expected\n+        }\n+        res[0] = testValue1;\n+        test79(null); \/\/ Should not throw NPE\n+    }\n+\n+    \/\/ Same as test79 but with explicit cast and Object return\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public static Object[] test80(MyValue1[] va) {\n+        return (MyValue1.ref[])va;\n+    }\n+\n+    @DontCompile\n+    public void test80_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[1];\n+        va[0] = testValue1;\n+        Object[] res = test80(va);\n+        Asserts.assertEquals(((MyValue1)res[0]).hash(), testValue1.hash());\n+        try {\n+            res[0] = null;\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException npe) {\n+            \/\/ Expected\n+        }\n+        res[0] = testValue1;\n+        test80(null); \/\/ Should not throw NPE\n+    }\n+\n+    \/\/ Test mixing widened and boxed array type\n+    @Test()\n+    public static long test81(MyValue1[] va1, MyValue1.ref[] va2, MyValue1 vt, boolean b, boolean shouldThrow) {\n+        MyValue1.ref[] result = b ? va1 : va2;\n+        try {\n+            result[0] = vt;\n+        } catch (NullPointerException npe) {\n+            \/\/ Ignored\n+        }\n+        return result[1].hash();\n+    }\n+\n+    @DontCompile\n+    public void test81_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[2];\n+        MyValue1.ref[] vaB = new MyValue1.ref[2];\n+        va[1] = testValue1;\n+        vaB[1] = testValue1;\n+        long res = test81(va, vaB, testValue1, true, true);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res, testValue1.hash());\n+        res = test81(va, vaB, testValue1, false, false);\n+        Asserts.assertEquals(vaB[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res, testValue1.hash());\n+        res = test81(va, va, testValue1, false, true);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res, testValue1.hash());\n+    }\n+\n+    \/\/ Same as test81 but more cases and null writes\n+    @Test()\n+    public static long test82(MyValue1[] va1, MyValue1.ref[] va2, MyValue1 vt1, MyValue1.ref vt2, int i, boolean shouldThrow) {\n+        MyValue1.ref[] result = null;\n+        if (i == 0) {\n+            result = va1;\n+        } else if (i == 1) {\n+            result = va2;\n+        } else if (i == 2) {\n+            result = new MyValue1.ref[2];\n+            result[1] = vt1;\n+        } else if (i == 3) {\n+            result = new MyValue1[2];\n+            result[1] = vt1;\n+        }\n+        try {\n+            result[0] = (i <= 1) ? null : vt2;\n+            if (shouldThrow) {\n+                throw new RuntimeException(\"NullPointerException expected\");\n+            }\n+        } catch (NullPointerException npe) {\n+            Asserts.assertTrue(shouldThrow, \"NullPointerException thrown\");\n+        }\n+        result[0] = vt1;\n+        return result[1].hash();\n+    }\n+\n+    @DontCompile\n+    public void test82_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[2];\n+        MyValue1.ref[] vaB = new MyValue1.ref[2];\n+        va[1] = testValue1;\n+        vaB[1] = testValue1;\n+        long res = test82(va, vaB, testValue1, testValue1, 0, true);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res, testValue1.hash());\n+        res = test82(va, vaB, testValue1, testValue1, 1, false);\n+        Asserts.assertEquals(vaB[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res, testValue1.hash());\n+        res = test82(va, va, testValue1, testValue1, 1, true);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res, testValue1.hash());\n+        res = test82(va, va, testValue1, null, 2, false);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res, testValue1.hash());\n+        res = test82(va, va, testValue1, null, 3, true);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res, testValue1.hash());\n+    }\n+\n+    @Test(failOn = ALLOC + ALLOCA + STORE)\n+    public static long test83(MyValue1[] va) {\n+        MyValue1.ref[] result = va;\n+        return result[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test83_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[42];\n+        va[0] = testValue1;\n+        long res = test83(va);\n+        Asserts.assertEquals(res, testValue1.hash());\n+    }\n+\n+    @Test(valid = InlineTypeArrayFlattenOn, failOn = ALLOC + LOOP + STORE + TRAP)\n+    @Test(valid = InlineTypeArrayFlattenOff)\n+    public static MyValue1.ref[] test84(MyValue1 vt1, MyValue1.ref vt2) {\n+        MyValue1.ref[] result = new MyValue1[2];\n+        result[0] = vt1;\n+        result[1] = vt2;\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test84_verifier(boolean warmup) {\n+        MyValue1.ref[] res = test84(testValue1, testValue1);\n+        Asserts.assertEquals(res[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res[1].hash(), testValue1.hash());\n+        try {\n+            test84(testValue1, null);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException npe) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Test()\n+    public static long test85(MyValue1.ref[] va, MyValue1 val) {\n+        va[0] = val;\n+        return va[1].hash();\n+    }\n+\n+    @DontCompile\n+    public void test85_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[2];\n+        MyValue1.ref[] vab = new MyValue1.ref[2];\n+        va[1] = testValue1;\n+        vab[1] = testValue1;\n+        long res = test85(va, testValue1);\n+        Asserts.assertEquals(res, testValue1.hash());\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        res = test85(vab, testValue1);\n+        Asserts.assertEquals(res, testValue1.hash());\n+        Asserts.assertEquals(vab[0].hash(), testValue1.hash());\n+    }\n+\n+    \/\/ Same as test85 but with ref value\n+    @Test()\n+    public static long test86(MyValue1.ref[] va, MyValue1.ref val) {\n+        va[0] = val;\n+        return va[1].hash();\n+    }\n+\n+    @DontCompile\n+    public void test86_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[2];\n+        MyValue1.ref[] vab = new MyValue1.ref[2];\n+        va[1] = testValue1;\n+        vab[1] = testValue1;\n+        long res = test86(va, testValue1);\n+        Asserts.assertEquals(res, testValue1.hash());\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        try {\n+            test86(va, null);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException npe) {\n+            \/\/ Expected\n+        }\n+        res = test86(vab, testValue1);\n+        Asserts.assertEquals(res, testValue1.hash());\n+        Asserts.assertEquals(vab[0].hash(), testValue1.hash());\n+        res = test86(vab, null);\n+        Asserts.assertEquals(res, testValue1.hash());\n+        Asserts.assertEquals(vab[0], null);\n+    }\n+\n+    \/\/ Test initialization of nullable array with constant\n+    @Test()\n+    public long test87() {\n+        MyValue1.ref[] va = new MyValue1.ref[1];\n+        va[0] = testValue1;\n+        return va[0].hash();\n+    }\n+\n+    @DontCompile\n+    public void test87_verifier(boolean warmup) {\n+        long result = test87();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Test narrowing conversion from [L to [Q\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public static MyValue1[] test88(MyValue1.ref[] va) {\n+        return (MyValue1[])va;\n+    }\n+\n+    @DontCompile\n+    public void test88_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[1];\n+        va[0] = testValue1;\n+        MyValue1[] res = test88(va);\n+        Asserts.assertEquals(res[0].hash(), testValue1.hash());\n+        res[0] = testValue1;\n+        test88(null); \/\/ Should not throw NPE\n+        try {\n+            test88(new MyValue1.ref[1]);\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException cce) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Same as test88 but with explicit cast and Object argument\n+    @Test(failOn = ALLOC + ALLOCA + LOOP + LOAD + STORE + TRAP)\n+    public static MyValue1[] test89(Object[] va) {\n+        return (MyValue1[])va;\n+    }\n+\n+    @DontCompile\n+    public void test89_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[1];\n+        va[0] = testValue1;\n+        MyValue1[] res = test89(va);\n+        Asserts.assertEquals(((MyValue1)res[0]).hash(), testValue1.hash());\n+        res[0] = testValue1;\n+        test89(null); \/\/ Should not throw NPE\n+        try {\n+            test89(new MyValue1.ref[1]);\n+            throw new RuntimeException(\"ClassCastException expected\");\n+        } catch (ClassCastException cce) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ More cast tests\n+    @Test()\n+    public static MyValue1.ref[] test90(Object va) {\n+        return (MyValue1.ref[])va;\n+    }\n+\n+    @DontCompile\n+    public void test90_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[1];\n+        MyValue1.ref[] vab = new MyValue1.ref[1];\n+        try {\n+          \/\/ Trigger some ClassCastExceptions so C2 does not add an uncommon trap\n+          test90(new Integer[0]);\n+        } catch (ClassCastException cce) {\n+          \/\/ Expected\n+        }\n+        test90(va);\n+        test90(vab);\n+        test90(null);\n+    }\n+\n+    @Test()\n+    public static MyValue1.ref[] test91(Object[] va) {\n+        return (MyValue1.ref[])va;\n+    }\n+\n+    @DontCompile\n+    public void test91_verifier(boolean warmup) {\n+        MyValue1[] va = new MyValue1[1];\n+        MyValue1.ref[] vab = new MyValue1.ref[1];\n+        try {\n+          \/\/ Trigger some ClassCastExceptions so C2 does not add an uncommon trap\n+          test91(new Integer[0]);\n+        } catch (ClassCastException cce) {\n+          \/\/ Expected\n+        }\n+        test91(va);\n+        test91(vab);\n+        test91(null);\n+    }\n+\n+    \/\/ Test if arraycopy intrinsic correctly checks for flattened source array\n+    @Test()\n+    public static void test92(MyValue1.ref[] src, MyValue1.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 2);\n+    }\n+\n+    @DontCompile\n+    public void test92_verifier(boolean warmup) {\n+        MyValue1[]  va = new MyValue1[2];\n+        MyValue1.ref[] vab = new MyValue1.ref[2];\n+        va[0] = testValue1;\n+        vab[0] = testValue1;\n+        test92(va, vab);\n+        Asserts.assertEquals(va[0], vab[0]);\n+        Asserts.assertEquals(va[1], vab[1]);\n+    }\n+\n+    @Test()\n+    public static void test93(Object src, MyValue1.ref[] dst) {\n+        System.arraycopy(src, 0, dst, 0, 2);\n+    }\n+\n+    @DontCompile\n+    public void test93_verifier(boolean warmup) {\n+        MyValue1[]  va = new MyValue1[2];\n+        MyValue1.ref[] vab = new MyValue1.ref[2];\n+        va[0] = testValue1;\n+        vab[0] = testValue1;\n+        test93(va, vab);\n+        Asserts.assertEquals(va[0], vab[0]);\n+        Asserts.assertEquals(va[1], vab[1]);\n+    }\n+\n+    \/\/ Test non-escaping allocation with arraycopy\n+    \/\/ that does not modify loaded array element.\n+    @Test()\n+    public static long test94() {\n+        MyValue1.ref[] src = new MyValue1.ref[8];\n+        MyValue1[]  dst = new MyValue1[8];\n+        for (int i = 1; i < 8; ++i) {\n+            src[i] = testValue1;\n+        }\n+        System.arraycopy(src, 1, dst, 2, 6);\n+        return dst[0].hash();\n+    }\n+\n+    @DontCompile\n+    public static void test94_verifier(boolean warmup) {\n+        long result = test94();\n+        Asserts.assertEquals(result, MyValue1.default.hash());\n+    }\n+\n+    \/\/ Test meeting constant TypeInstPtr with InlineTypeNode\n+    @ForceInline\n+    public long test95_callee() {\n+        MyValue1.ref[] va = new MyValue1.ref[1];\n+        va[0] = testValue1;\n+        return va[0].hashInterpreted();\n+    }\n+\n+    @Test()\n+    @Warmup(0)\n+    public long test95() {\n+        return test95_callee();\n+    }\n+\n+    @DontCompile\n+    public void test95_verifier(boolean warmup) {\n+        long result = test95();\n+        Asserts.assertEQ(result, hash());\n+    }\n+\n+    \/\/ Matrix multiplication test to exercise type flow analysis with nullable inline type arrays\n+    primitive static class Complex {\n+        private final double re;\n+        private final double im;\n+\n+        Complex(double re, double im) {\n+            this.re = re;\n+            this.im = im;\n+        }\n+\n+        public Complex add(Complex that) {\n+            return new Complex(this.re + that.re, this.im + that.im);\n+        }\n+\n+        public Complex mul(Complex that) {\n+            return new Complex(this.re * that.re - this.im * that.im,\n+                               this.re * that.im + this.im * that.re);\n+        }\n+    }\n+\n+    @Test()\n+    public Complex.ref[][] test96(Complex.ref[][] A, Complex.ref[][] B) {\n+        int size = A.length;\n+        Complex.ref[][] R = new Complex.ref[size][size];\n+        for (int i = 0; i < size; i++) {\n+            for (int k = 0; k < size; k++) {\n+                Complex.ref aik = A[i][k];\n+                for (int j = 0; j < size; j++) {\n+                    R[i][j] = B[i][j].add(aik.mul((Complex)B[k][j]));\n+                }\n+            }\n+        }\n+        return R;\n+    }\n+\n+    static Complex.ref[][] test96_A = new Complex.ref[10][10];\n+    static Complex.ref[][] test96_B = new Complex.ref[10][10];\n+    static Complex.ref[][] test96_R;\n+\n+    static {\n+        for (int i = 0; i < 10; i++) {\n+            for (int j = 0; j < 10; j++) {\n+                test96_A[i][j] = new Complex(rI, rI);\n+                test96_B[i][j] = new Complex(rI, rI);\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test96_verifier(boolean warmup) {\n+        Complex.ref[][] result = test96(test96_A, test96_B);\n+        if (test96_R == null) {\n+            test96_R = result;\n+        }\n+        for (int i = 0; i < 10; i++) {\n+            for (int j = 0; j < 10; j++) {\n+                Asserts.assertEQ(result[i][j], test96_R[i][j]);\n+            }\n+        }\n+    }\n+\n+    \/\/ Test loads from vararg arrays\n+    @Test(failOn = LOAD_UNKNOWN_INLINE)\n+    public static Object test97(Object... args) {\n+        return args[0];\n+    }\n+\n+    @DontCompile\n+    public static void test97_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        Object result = test97(obj);\n+        Asserts.assertEquals(result, obj);\n+        Integer[] myInt = new Integer[1];\n+        myInt[0] = rI;\n+        result = test97((Object[])myInt);\n+        Asserts.assertEquals(result, rI);\n+    }\n+\n+    @Test()\n+    public static Object test98(Object... args) {\n+        return args[0];\n+    }\n+\n+    @DontCompile\n+    public static void test98_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        Object result = test98(obj);\n+        Asserts.assertEquals(result, obj);\n+        Integer[] myInt = new Integer[1];\n+        myInt[0] = rI;\n+        result = test98((Object[])myInt);\n+        Asserts.assertEquals(result, rI);\n+        if (!warmup) {\n+            MyValue1[] va = new MyValue1[1];\n+            MyValue1.ref[] vab = new MyValue1.ref[1];\n+            result = test98((Object[])va);\n+            Asserts.assertEquals(((MyValue1)result).hash(), MyValue1.default.hash());\n+            result = test98((Object[])vab);\n+            Asserts.assertEquals(result, null);\n+        }\n+    }\n+\n+    @Test()\n+    public static Object test99(Object... args) {\n+        return args[0];\n+    }\n+\n+    @DontCompile\n+    public static void test99_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        Object result = test99(obj);\n+        Asserts.assertEquals(result, obj);\n+        Integer[] myInt = new Integer[1];\n+        myInt[0] = rI;\n+        result = test99((Object[])myInt);\n+        Asserts.assertEquals(result, rI);\n+        if (!warmup) {\n+            try {\n+                test99((Object[])null);\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test()\n+    public static Object test100(Object... args) {\n+        return args[0];\n+    }\n+\n+    @DontCompile\n+    public static void test100_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        Object result = test100(obj);\n+        Asserts.assertEquals(result, obj);\n+        Integer[] myInt = new Integer[1];\n+        myInt[0] = rI;\n+        result = test100((Object[])myInt);\n+        Asserts.assertEquals(result, rI);\n+        if (!warmup) {\n+            try {\n+                test100();\n+                throw new RuntimeException(\"No AIOOBE thrown\");\n+            } catch (ArrayIndexOutOfBoundsException aioobe) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    \/\/ Test stores to varag arrays\n+    @Test(failOn = STORE_UNKNOWN_INLINE)\n+    public static void test101(Object val, Object... args) {\n+        args[0] = val;\n+    }\n+\n+    @DontCompile\n+    public static void test101_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        test101(obj, obj);\n+        Integer[] myInt = new Integer[1];\n+        test101(rI, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], rI);\n+        test101(null, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], null);\n+    }\n+\n+    @Test()\n+    public static void test102(Object val, Object... args) {\n+        args[0] = val;\n+    }\n+\n+    @DontCompile\n+    public static void test102_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        test102(obj, obj);\n+        Integer[] myInt = new Integer[1];\n+        test102(rI, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], rI);\n+        test102(null, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], null);\n+        if (!warmup) {\n+            MyValue1[] va = new MyValue1[1];\n+            MyValue1.ref[] vab = new MyValue1.ref[1];\n+            test102(testValue1, (Object[])va);\n+            Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+            test102(testValue1, (Object[])vab);\n+            Asserts.assertEquals(vab[0].hash(), testValue1.hash());\n+            test102(null, (Object[])vab);\n+            Asserts.assertEquals(vab[0], null);\n+        }\n+    }\n+\n+    @Test()\n+    public static void test103(Object val, Object... args) {\n+        args[0] = val;\n+    }\n+\n+    @DontCompile\n+    public static void test103_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        test103(obj, obj);\n+        Integer[] myInt = new Integer[1];\n+        test103(rI, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], rI);\n+        test103(null, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], null);\n+        if (!warmup) {\n+            MyValue1[] va = new MyValue1[1];\n+            try {\n+                test103(null, (Object[])va);\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test()\n+    public static void test104(Object val, Object... args) {\n+        args[0] = val;\n+    }\n+\n+    @DontCompile\n+    public static void test104_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        test104(obj, obj);\n+        Integer[] myInt = new Integer[1];\n+        test104(rI, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], rI);\n+        test104(null, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], null);\n+        if (!warmup) {\n+            try {\n+                test104(testValue1);\n+                throw new RuntimeException(\"No AIOOBE thrown\");\n+            } catch (ArrayIndexOutOfBoundsException aioobe) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test()\n+    public static void test105(Object val, Object... args) {\n+        args[0] = val;\n+    }\n+\n+    @DontCompile\n+    public static void test105_verifier(boolean warmup) {\n+        Object obj = new Object();\n+        test105(obj, obj);\n+        Integer[] myInt = new Integer[1];\n+        test105(rI, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], rI);\n+        test105(null, (Object[])myInt);\n+        Asserts.assertEquals(myInt[0], null);\n+        if (!warmup) {\n+            try {\n+                test105(testValue1, (Object[])null);\n+                throw new RuntimeException(\"No NPE thrown\");\n+            } catch (NullPointerException npe) {\n+                \/\/ Expected\n+            }\n+        }\n+    }\n+\n+    @Test()\n+    public static Object[] test106(Object[] dst, Object... args) {\n+        \/\/ Access array to speculate on non-flatness\n+        if (args[0] == null) {\n+            args[0] = testValue1;\n+        }\n+        System.arraycopy(args, 0, dst, 0, args.length);\n+        System.arraycopy(dst, 0, args, 0, dst.length);\n+        Object[] clone = args.clone();\n+        if (clone[0] == null) {\n+            throw new RuntimeException(\"Unexpected null\");\n+        }\n+        return Arrays.copyOf(args, args.length, Object[].class);\n+    }\n+\n+    @DontCompile\n+    public static void test106_verifier(boolean warmup) {\n+        Object[] dst = new Object[1];\n+        Object obj = new Object();\n+        Object[] result = test106(dst, obj);\n+        Asserts.assertEquals(result[0], obj);\n+        Integer[] myInt = new Integer[1];\n+        myInt[0] = rI;\n+        result = test106(myInt, (Object[])myInt);\n+        Asserts.assertEquals(result[0], rI);\n+        if (!warmup) {\n+            MyValue1[] va = new MyValue1[1];\n+            MyValue1.ref[] vab = new MyValue1.ref[1];\n+            result = test106(va, (Object[])va);\n+            Asserts.assertEquals(((MyValue1)result[0]).hash(), MyValue1.default.hash());\n+            result = test106(vab, (Object[])vab);\n+            Asserts.assertEquals(((MyValue1)result[0]).hash(), testValue1.hash());\n+        }\n+    }\n+\n+    \/\/ Test that allocation is not replaced by non-dominating allocation\n+    public long test107_helper(MyValue1.ref[] va, MyValue1 vt) {\n+        try {\n+            va[0] = vt;\n+        } catch (NullPointerException npe) { }\n+        return va[1].hash();\n+    }\n+\n+    @Test()\n+    public void test107() {\n+        MyValue1[] va = new MyValue1[2];\n+        MyValue1.ref[] tmp = new MyValue1.ref[2];\n+        long res1 = test107_helper(va, testValue1);\n+        long res2 = test107_helper(va, testValue1);\n+        Asserts.assertEquals(va[0].hash(), testValue1.hash());\n+        Asserts.assertEquals(res1, MyValue1.default.hash());\n+        Asserts.assertEquals(res2, MyValue1.default.hash());\n+    }\n+\n+    @DontCompile\n+    public void test107_verifier(boolean warmup) {\n+        test107();\n+    }\n+\n+    @Test\n+    @Warmup(10000)\n+    public Object test108(MyValue1.ref[] src, boolean flag) {\n+        MyValue1.ref[] dst = new MyValue1.ref[8];\n+        System.arraycopy(src, 1, dst, 2, 6);\n+        if (flag) {} \/\/ uncommon trap\n+        return dst[2];\n+    }\n+\n+    @DontCompile\n+    public void test108_verifier(boolean warmup) {\n+        MyValue1.ref[] src = new MyValue1.ref[8];\n+        test108(src, !warmup);\n+    }\n+\n+    \/\/ Test LoadNode::can_see_arraycopy_value optimization\n+    @Test()\n+    public static void test109() {\n+        MyValue1[] src = new MyValue1[1];\n+        MyValue1.ref[] dst = new MyValue1.ref[1];\n+        src[0] = testValue1;\n+        System.arraycopy(src, 0, dst, 0, 1);\n+        Asserts.assertEquals(src[0], dst[0]);\n+    }\n+\n+    @DontCompile\n+    public void test109_verifier(boolean warmup) {\n+        test109();\n+    }\n+\n+    \/\/ Same as test109 but with Object destination array\n+    @Test()\n+    public static void test110() {\n+        MyValue1[] src = new MyValue1[1];\n+        Object[] dst = new Object[1];\n+        src[0] = testValue1;\n+        System.arraycopy(src, 0, dst, 0, 1);\n+        Asserts.assertEquals(src[0], dst[0]);\n+    }\n+\n+    @DontCompile\n+    public void test110_verifier(boolean warmup) {\n+        test110();\n+    }\n+\n+    \/\/ Same as test109 but with Arrays.copyOf\n+    @Test()\n+    public static void test111() {\n+        MyValue1[] src = new MyValue1[1];\n+        src[0] = testValue1;\n+        MyValue1.ref[] dst = Arrays.copyOf(src, src.length, MyValue1.ref[].class);\n+        Asserts.assertEquals(src[0], dst[0]);\n+    }\n+\n+    @DontCompile\n+    public void test111_verifier(boolean warmup) {\n+        test111();\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestNullableArrays.java","additions":2880,"deletions":0,"binary":false,"changes":2880,"status":"added"},{"patch":"@@ -0,0 +1,976 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+\n+import jdk.test.lib.Asserts;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test correct handling of nullable inline types.\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestNullableInlineTypes.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestNullableInlineTypes\n+ *\/\n+public class TestNullableInlineTypes extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 3: return new String[] {\"-XX:-MonomorphicArrayCheck\", \"-XX:FlatArrayElementMaxSize=-1\"};\n+        case 4: return new String[] {\"-XX:-MonomorphicArrayCheck\"};\n+        }\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestNullableInlineTypes test = new TestNullableInlineTypes();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class, Test17Value.class, Test21Value.class);\n+    }\n+\n+    static {\n+        try {\n+            Class<?> clazz = TestNullableInlineTypes.class;\n+            MethodHandles.Lookup lookup = MethodHandles.lookup();\n+\n+            MethodType test18_mt = MethodType.methodType(void.class, MyValue1.ref.class);\n+            test18_mh1 = lookup.findStatic(clazz, \"test18_target1\", test18_mt);\n+            test18_mh2 = lookup.findStatic(clazz, \"test18_target2\", test18_mt);\n+\n+            MethodType test19_mt = MethodType.methodType(void.class, MyValue1.ref.class);\n+            test19_mh1 = lookup.findStatic(clazz, \"test19_target1\", test19_mt);\n+            test19_mh2 = lookup.findStatic(clazz, \"test19_target2\", test19_mt);\n+        } catch (NoSuchMethodException | IllegalAccessException e) {\n+            e.printStackTrace();\n+            throw new RuntimeException(\"Method handle lookup failed\");\n+        }\n+    }\n+\n+    private static final MyValue1 testValue1 = MyValue1.createWithFieldsInline(rI, rL);\n+    private static final MyValue1[] testValue1Array = new MyValue1[] {testValue1,\n+                                                                      testValue1,\n+                                                                      testValue1};\n+\n+    MyValue1.ref nullField;\n+    MyValue1 valueField1 = testValue1;\n+\n+    @Test\n+    public long test1(MyValue1.ref vt) {\n+        long result = 0;\n+        try {\n+            result = vt.hash();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) throws Throwable {\n+        long result = test1(null);\n+        Asserts.assertEquals(result, 0L);\n+    }\n+\n+    @Test\n+    public long test2(MyValue1.ref vt) {\n+        long result = 0;\n+        try {\n+            result = vt.hashInterpreted();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        long result = test2(nullField);\n+        Asserts.assertEquals(result, 0L);\n+    }\n+\n+    @Test\n+    public long test3() {\n+        long result = 0;\n+        try {\n+            if ((Object)nullField != null) {\n+                throw new RuntimeException(\"nullField should be null\");\n+            }\n+            result = nullField.hash();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        long result = test3();\n+        Asserts.assertEquals(result, 0L);\n+    }\n+\n+    @Test\n+    public void test4() {\n+        try {\n+            valueField1 = (MyValue1) nullField;\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        test4();\n+    }\n+\n+    @Test\n+    public MyValue1.ref test5(MyValue1.ref vt) {\n+        try {\n+            Object o = vt;\n+            vt = (MyValue1)o;\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+\n+        \/\/ Should not throw\n+        vt = test5_dontinline(vt);\n+        vt = test5_inline(vt);\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        MyValue1.ref vt = test5(nullField);\n+        Asserts.assertEquals((Object)vt, null);\n+    }\n+\n+    @DontInline\n+    public MyValue1.ref test5_dontinline(MyValue1.ref vt) {\n+        return vt;\n+    }\n+\n+    @ForceInline\n+    public MyValue1.ref test5_inline(MyValue1.ref vt) {\n+        return vt;\n+    }\n+\n+    @Test\n+    public MyValue1 test6(Object obj) {\n+        MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);\n+        try {\n+            vt = (MyValue1)obj;\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        MyValue1 vt = test6(null);\n+        Asserts.assertEquals(vt.hash(), testValue1.hash());\n+    }\n+\n+    @ForceInline\n+    public MyValue1.ref getNullInline() {\n+        return null;\n+    }\n+\n+    @DontInline\n+    public MyValue1.ref getNullDontInline() {\n+        return null;\n+    }\n+\n+    @Test\n+    public void test7() throws Throwable {\n+        nullField = getNullInline();     \/\/ Should not throw\n+        nullField = getNullDontInline(); \/\/ Should not throw\n+        try {\n+            valueField1 = (MyValue1) getNullInline();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            valueField1 = (MyValue1) getNullDontInline();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) throws Throwable {\n+        test7();\n+    }\n+\n+    @Test\n+    public void test8() throws Throwable {\n+        try {\n+            valueField1 = (MyValue1) nullField;\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) throws Throwable {\n+        test8();\n+    }\n+\n+    \/\/ merge of 2 inline types, one being null\n+    @Test\n+    public void test9(boolean flag1) {\n+        MyValue1 v;\n+        if (flag1) {\n+            v = valueField1;\n+        } else {\n+            v = (MyValue1) nullField;\n+        }\n+        valueField1 = v;\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        test9(true);\n+        try {\n+            test9(false);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ null constant\n+    @Test\n+    public void test10(boolean flag) throws Throwable {\n+        MyValue1.ref val = flag ? valueField1 : null;\n+        valueField1 = (MyValue1) val;\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) throws Throwable {\n+        test10(true);\n+        try {\n+            test10(false);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ null constant\n+    @Test\n+    public void test11(boolean flag) throws Throwable {\n+        MyValue1.ref val = flag ? null : valueField1;\n+        valueField1 = (MyValue1) val;\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) throws Throwable {\n+        test11(false);\n+        try {\n+            test11(true);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ null return\n+    int test12_cnt;\n+\n+    @DontInline\n+    public MyValue1.ref test12_helper() {\n+        test12_cnt++;\n+        return nullField;\n+    }\n+\n+    @Test\n+    public void test12() {\n+        valueField1 = (MyValue1) test12_helper();\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        try {\n+            test12_cnt = 0;\n+            test12();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        if (test12_cnt != 1) {\n+            throw new RuntimeException(\"call executed twice\");\n+        }\n+    }\n+\n+    \/\/ null return at virtual call\n+    class A {\n+        public MyValue1.ref test13_helper() {\n+            return nullField;\n+        }\n+    }\n+\n+    class B extends A {\n+        public MyValue1 test13_helper() {\n+            return (MyValue1) nullField;\n+        }\n+    }\n+\n+    class C extends A {\n+        public MyValue1.ref test13_helper() {\n+            return nullField;\n+        }\n+    }\n+\n+    class D extends C {\n+        public MyValue1 test13_helper() {\n+            return (MyValue1) nullField;\n+        }\n+    }\n+\n+    @Test\n+    public void test13(A a) {\n+        valueField1 = (MyValue1) a.test13_helper();\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        A a = new A();\n+        A b = new B();\n+        A c = new C();\n+        A d = new D();\n+        try {\n+            test13(a);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test13(b);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test13(c);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            test13(d);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    \/\/ Test writing null to a (flattened) inline type array\n+    @ForceInline\n+    public void test14_inline(Object[] oa, Object o, int index) {\n+        oa[index] = o;\n+    }\n+\n+    @Test()\n+    public void test14(MyValue1[] va, int index) {\n+        test14_inline(va, nullField, index);\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean warmup) {\n+        int index = Math.abs(rI) % 3;\n+        try {\n+            test14(testValue1Array, index);\n+            throw new RuntimeException(\"No NPE thrown\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        Asserts.assertEQ(testValue1Array[index].hash(), testValue1.hash());\n+    }\n+\n+    @DontInline\n+    MyValue1.ref getNullField1() {\n+        return nullField;\n+    }\n+\n+    @DontInline\n+    MyValue1 getNullField2() {\n+        return (MyValue1) nullField;\n+    }\n+\n+    @Test()\n+    public void test15() {\n+        nullField = getNullField1(); \/\/ should not throw\n+        try {\n+            valueField1 = (MyValue1) getNullField1();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        try {\n+            valueField1 = getNullField2();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean warmup) {\n+        test15();\n+    }\n+\n+    @DontInline\n+    public boolean test16_dontinline(MyValue1.ref vt) {\n+        return (Object)vt == null;\n+    }\n+\n+    \/\/ Test c2c call passing null for an inline type\n+    @Test\n+    @Warmup(10000) \/\/ Warmup to make sure 'test17_dontinline' is compiled\n+    public boolean test16(Object arg) throws Exception {\n+        Method test16method = getClass().getMethod(\"test16_dontinline\", MyValue1.ref.class);\n+        return (boolean)test16method.invoke(this, arg);\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean warmup) throws Exception {\n+        boolean res = test16(null);\n+        Asserts.assertTrue(res);\n+    }\n+\n+    \/\/ Test scalarization of default inline type with non-flattenable field\n+    final primitive class Test17Value {\n+        public final MyValue1.ref valueField;\n+\n+        @ForceInline\n+        public Test17Value(MyValue1.ref valueField) {\n+            this.valueField = valueField;\n+        }\n+    }\n+\n+    @Test()\n+    public Test17Value test17(boolean b) {\n+        Test17Value vt1 = Test17Value.default;\n+        if ((Object)vt1.valueField != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+        Test17Value vt2 = new Test17Value(testValue1);\n+        return b ? vt1 : vt2;\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean warmup) {\n+        test17(true);\n+        test17(false);\n+    }\n+\n+    static final MethodHandle test18_mh1;\n+    static final MethodHandle test18_mh2;\n+\n+    static MyValue1.ref nullValue;\n+\n+    @DontInline\n+    static void test18_target1(MyValue1.ref vt) {\n+        nullValue = vt;\n+    }\n+\n+    @ForceInline\n+    static void test18_target2(MyValue1.ref vt) {\n+        nullValue = vt;\n+    }\n+\n+    \/\/ Test passing null for an inline type\n+    @Test\n+    @Warmup(11000) \/\/ Make sure lambda forms get compiled\n+    public void test18() throws Throwable {\n+        test18_mh1.invokeExact(nullValue);\n+        test18_mh2.invokeExact(nullValue);\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        try {\n+            test18();\n+        } catch (Throwable t) {\n+            throw new RuntimeException(\"test18 failed\", t);\n+        }\n+    }\n+\n+    static MethodHandle test19_mh1;\n+    static MethodHandle test19_mh2;\n+\n+    @DontInline\n+    static void test19_target1(MyValue1.ref vt) {\n+        nullValue = vt;\n+    }\n+\n+    @ForceInline\n+    static void test19_target2(MyValue1.ref vt) {\n+        nullValue = vt;\n+    }\n+\n+    \/\/ Same as test12 but with non-final mh\n+    @Test\n+    @Warmup(11000) \/\/ Make sure lambda forms get compiled\n+    public void test19() throws Throwable {\n+        test19_mh1.invokeExact(nullValue);\n+        test19_mh2.invokeExact(nullValue);\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        try {\n+            test19();\n+        } catch (Throwable t) {\n+            throw new RuntimeException(\"test19 failed\", t);\n+        }\n+    }\n+\n+    \/\/ Same as test12\/13 but with constant null\n+    @Test\n+    @Warmup(11000) \/\/ Make sure lambda forms get compiled\n+    public void test20(MethodHandle mh) throws Throwable {\n+        mh.invoke(null);\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        try {\n+            test20(test18_mh1);\n+            test20(test18_mh2);\n+            test20(test19_mh1);\n+            test20(test19_mh2);\n+        } catch (Throwable t) {\n+            throw new RuntimeException(\"test20 failed\", t);\n+        }\n+    }\n+\n+    \/\/ Test writing null to a flattenable\/non-flattenable inline type field in an inline type\n+    final primitive class Test21Value {\n+        final MyValue1.ref valueField1;\n+        final MyValue1 valueField2;\n+        final MyValue1.ref alwaysNull = null;\n+\n+        @ForceInline\n+        public Test21Value(MyValue1.ref valueField1, MyValue1 valueField2) {\n+            this.valueField1 = testValue1;\n+            this.valueField2 = testValue1;\n+        }\n+\n+        @ForceInline\n+        public Test21Value test1() {\n+            return new Test21Value(alwaysNull, this.valueField2); \/\/ Should not throw NPE\n+        }\n+\n+        @ForceInline\n+        public Test21Value test2() {\n+            return new Test21Value(this.valueField1, (MyValue1) alwaysNull); \/\/ Should throw NPE\n+        }\n+    }\n+\n+    @Test\n+    public Test21Value test21(Test21Value vt) {\n+        vt = vt.test1();\n+        try {\n+            vt = vt.test2();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test21_verifier(boolean warmup) {\n+        test21(Test21Value.default);\n+    }\n+\n+    @DontInline\n+    public MyValue1 test22_helper() {\n+        return (MyValue1) nullField;\n+    }\n+\n+    @Test\n+    public void test22() {\n+        valueField1 = test22_helper();\n+    }\n+\n+    @DontCompile\n+    public void test22_verifier(boolean warmup) {\n+        try {\n+            test22();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @Test\n+    public void test23(MyValue1[] arr, MyValue1.ref b) {\n+        arr[0] = (MyValue1) b;\n+    }\n+\n+    @DontCompile\n+    public void test23_verifier(boolean warmup) {\n+        MyValue1[] arr = new MyValue1[2];\n+        MyValue1.ref b = null;\n+        try {\n+            test23(arr, b);\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    static MyValue1.ref nullBox;\n+\n+    @Test\n+    public MyValue1 test24() {\n+        return (MyValue1) nullBox;\n+    }\n+\n+    @DontCompile\n+    public void test24_verifier(boolean warmup) {\n+        try {\n+            test24();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @DontInline\n+    public void test25_callee(MyValue1 val) { }\n+\n+    \/\/ Test that when checkcasting from null-ok to null-free and back to null-ok we\n+    \/\/ keep track of the information that the inline type can never be null.\n+    @Test(failOn = ALLOC + STORE)\n+    public int test25(boolean b, MyValue1.ref vt1, MyValue1 vt2) {\n+        vt1 = (MyValue1)vt1;\n+        Object obj = b ? vt1 : vt2; \/\/ We should not allocate here\n+        test25_callee((MyValue1) vt1);\n+        return ((MyValue1)obj).x;\n+    }\n+\n+    @DontCompile\n+    public void test25_verifier(boolean warmup) {\n+        int res = test25(true, testValue1, testValue1);\n+        Asserts.assertEquals(res, testValue1.x);\n+        res = test25(false, testValue1, testValue1);\n+        Asserts.assertEquals(res, testValue1.x);\n+    }\n+\n+    \/\/ Test that chains of casts are folded and don't trigger an allocation\n+    @Test(failOn = ALLOC + STORE)\n+    public MyValue3 test26(MyValue3 vt) {\n+        return ((MyValue3)((Object)((MyValue3.ref)(MyValue3)((MyValue3.ref)((Object)vt)))));\n+    }\n+\n+    @DontCompile\n+    public void test26_verifier(boolean warmup) {\n+        MyValue3 vt = MyValue3.create();\n+        MyValue3 result = test26(vt);\n+        Asserts.assertEquals(result, vt);\n+    }\n+\n+    @Test(failOn = ALLOC + STORE)\n+    public MyValue3.ref test27(MyValue3.ref vt) {\n+        return ((MyValue3.ref)((Object)((MyValue3)(MyValue3.ref)((MyValue3)((Object)vt)))));\n+    }\n+\n+    @DontCompile\n+    public void test27_verifier(boolean warmup) {\n+        MyValue3 vt = MyValue3.create();\n+        MyValue3 result = (MyValue3) test27(vt);\n+        Asserts.assertEquals(result, vt);\n+    }\n+\n+    \/\/ Some more casting tests\n+    @Test()\n+    public MyValue1.ref test28(MyValue1 vt, MyValue1.ref vtBox, int i) {\n+        MyValue1.ref result = null;\n+        if (i == 0) {\n+            result = (MyValue1.ref)vt;\n+            result = null;\n+        } else if (i == 1) {\n+            result = (MyValue1.ref)vt;\n+        } else if (i == 2) {\n+            result = vtBox;\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test28_verifier(boolean warmup) {\n+        MyValue1.ref result = test28(testValue1, null, 0);\n+        Asserts.assertEquals(result, null);\n+        result = test28(testValue1, testValue1, 1);\n+        Asserts.assertEquals(result, testValue1);\n+        result = test28(testValue1, null, 2);\n+        Asserts.assertEquals(result, null);\n+        result = test28(testValue1, testValue1, 2);\n+        Asserts.assertEquals(result, testValue1);\n+    }\n+\n+    @Test()\n+    public long test29(MyValue1 vt, MyValue1.ref vtBox) {\n+        long result = 0;\n+        for (int i = 0; i < 100; ++i) {\n+            MyValue1.ref box;\n+            if (i == 0) {\n+                box = (MyValue1.ref)vt;\n+                box = null;\n+            } else if (i < 99) {\n+                box = (MyValue1.ref)vt;\n+            } else {\n+                box = vtBox;\n+            }\n+            if (box != null) {\n+                result += box.hash();\n+            }\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test29_verifier(boolean warmup) {\n+        long result = test29(testValue1, null);\n+        Asserts.assertEquals(result, testValue1.hash()*98);\n+        result = test29(testValue1, testValue1);\n+        Asserts.assertEquals(result, testValue1.hash()*99);\n+    }\n+\n+    \/\/ Test null check of inline type receiver with incremental inlining\n+    public long test30_callee(MyValue1.ref vt) {\n+        long result = 0;\n+        try {\n+            result = vt.hashInterpreted();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+        return result;\n+    }\n+\n+    @Test\n+    public long test30() {\n+        return test30_callee(nullField);\n+    }\n+\n+    @DontCompile\n+    public void test30_verifier(boolean warmup) {\n+        long result = test30();\n+        Asserts.assertEquals(result, 0L);\n+    }\n+\n+    \/\/ Test casting null to unloaded inline type\n+    final primitive class Test31Value {\n+        private final int i = 0;\n+    }\n+\n+    @Test\n+    public void test31(Object o) {\n+        try {\n+            o = (Test31Value)o;\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test31_verifier(boolean warmup) {\n+        test31(null);\n+    }\n+\n+    private static final MyValue1.ref constNullField = null;\n+\n+    @Test\n+    public MyValue1.ref test32() {\n+        return constNullField;\n+    }\n+\n+    @DontCompile\n+    public void test32_verifier(boolean warmup) {\n+        MyValue1.ref result = test32();\n+        Asserts.assertEquals(result, null);\n+    }\n+\n+    static primitive class Test33Value1 {\n+        int x = 0;\n+    }\n+\n+    static primitive class Test33Value2 {\n+        Test33Value1.ref vt;\n+\n+        public Test33Value2() {\n+            vt = new Test33Value1();\n+        }\n+    }\n+\n+    public static final Test33Value2 test33Val = new Test33Value2();\n+\n+    @Test\n+    public Test33Value2 test33() {\n+        return test33Val;\n+    }\n+\n+    @DontCompile\n+    public void test33_verifier(boolean warmup) {\n+        Test33Value2 result = test33();\n+        Asserts.assertEquals(result, test33Val);\n+    }\n+\n+    \/\/ Verify that static nullable inline-type fields are not\n+    \/\/ treated as never-null by C2 when initialized at compile time.\n+    private static MyValue1.ref test34Val;\n+\n+    @Test\n+    public void test34(MyValue1 vt) {\n+        if (test34Val == null) {\n+            test34Val = vt;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test34_verifier(boolean warmup) {\n+        test34(testValue1);\n+        if (!warmup) {\n+            test34Val = null;\n+            test34(testValue1);\n+            Asserts.assertEquals(test34Val, testValue1);\n+        }\n+    }\n+\n+    \/\/ Same as test17 but with non-allocated inline type at withfield\n+    @Test()\n+    public Test17Value test35(boolean b) {\n+        Test17Value vt1 = Test17Value.default;\n+        if ((Object)vt1.valueField != null) {\n+            throw new RuntimeException(\"Should be null\");\n+        }\n+        MyValue1 vt3 = MyValue1.createWithFieldsInline(rI, rL);\n+        Test17Value vt2 = new Test17Value(vt3);\n+        return b ? vt1 : vt2;\n+    }\n+\n+    @DontCompile\n+    public void test35_verifier(boolean warmup) {\n+        test35(true);\n+        test35(false);\n+    }\n+\n+    \/\/ Test that when explicitly null checking an inline type, we keep\n+    \/\/ track of the information that the inline type can never be null.\n+    @Test(failOn = ALLOC + STORE)\n+    public int test37(boolean b, MyValue1.ref vt1, MyValue1.val vt2) {\n+        if (vt1 == null) {\n+            return 0;\n+        }\n+        \/\/ vt1 should be scalarized because it's always non-null\n+        Object obj = b ? vt1 : vt2; \/\/ We should not allocate vt2 here\n+        test25_callee(vt1);\n+        return ((MyValue1)obj).x;\n+    }\n+\n+    @DontCompile\n+    public void test37_verifier(boolean warmup) {\n+        int res = test37(true, testValue1, testValue1);\n+        Asserts.assertEquals(res, testValue1.x);\n+        res = test37(false, testValue1, testValue1);\n+        Asserts.assertEquals(res, testValue1.x);\n+    }\n+\n+    \/\/ Test that when explicitly null checking an inline type receiver,\n+    \/\/ we keep track of the information that the inline type can never be null.\n+    @Test(failOn = ALLOC + STORE)\n+    public int test38(boolean b, MyValue1.ref vt1, MyValue1.val vt2) {\n+        vt1.hash(); \/\/ Inlined - Explicit null check\n+        \/\/ vt1 should be scalarized because it's always non-null\n+        Object obj = b ? vt1 : vt2; \/\/ We should not allocate vt2 here\n+        test25_callee(vt1);\n+        return ((MyValue1)obj).x;\n+    }\n+\n+    @DontCompile\n+    public void test38_verifier(boolean warmup) {\n+        int res = test38(true, testValue1, testValue1);\n+        Asserts.assertEquals(res, testValue1.x);\n+        res = test38(false, testValue1, testValue1);\n+        Asserts.assertEquals(res, testValue1.x);\n+    }\n+\n+    \/\/ Test that when implicitly null checking an inline type receiver,\n+    \/\/ we keep track of the information that the inline type can never be null.\n+    @Test(failOn = ALLOC + STORE)\n+    public int test39(boolean b, MyValue1.ref vt1, MyValue1.val vt2) {\n+        vt1.hashInterpreted(); \/\/ Not inlined - Implicit null check\n+        \/\/ vt1 should be scalarized because it's always non-null\n+        Object obj = b ? vt1 : vt2; \/\/ We should not allocate vt2 here\n+        test25_callee(vt1);\n+        return ((MyValue1)obj).x;\n+    }\n+\n+    @DontCompile\n+    public void test39_verifier(boolean warmup) {\n+        int res = test39(true, testValue1, testValue1);\n+        Asserts.assertEquals(res, testValue1.x);\n+        res = test39(false, testValue1, testValue1);\n+        Asserts.assertEquals(res, testValue1.x);\n+    }\n+\n+    \/\/ Test NPE when casting constant null to inline type\n+    @Test()\n+    public MyValue1 test40() throws Throwable {\n+        Object NULL = null;\n+        return (MyValue1)NULL;\n+    }\n+\n+    @DontCompile\n+    public void test40_verifier(boolean warmup) throws Throwable {\n+        try {\n+            test40();\n+            throw new RuntimeException(\"NullPointerException expected\");\n+        } catch (NullPointerException e) {\n+            \/\/ Expected\n+        }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestNullableInlineTypes.java","additions":976,"deletions":0,"binary":false,"changes":976,"status":"added"},{"patch":"@@ -0,0 +1,292 @@\n+\/*\n+ * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import jdk.test.lib.Asserts;\n+import java.lang.reflect.Method;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Test on stack replacement (OSR) with inline types\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires (os.simpleArch == \"x64\" | os.simpleArch == \"aarch64\")\n+ * @compile TestOnStackReplacement.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestOnStackReplacement\n+ *\/\n+public class TestOnStackReplacement extends InlineTypeTest {\n+    \/\/ Extra VM parameters for some test scenarios. See InlineTypeTest.getVMParameters()\n+    @Override\n+    public String[] getExtraVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 3: return new String[] {\"-XX:FlatArrayElementMaxSize=0\"};\n+        }\n+        return null;\n+    }\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestOnStackReplacement test = new TestOnStackReplacement();\n+        test.run(args, MyValue1.class, MyValue2.class, MyValue2Inline.class, MyValue3.class, MyValue3Inline.class);\n+    }\n+\n+    \/\/ Helper methods\n+\n+    protected long hash() {\n+        return hash(rI, rL);\n+    }\n+\n+    protected long hash(int x, long y) {\n+        return MyValue1.createWithFieldsInline(x, y).hash();\n+    }\n+\n+    \/\/ Test OSR compilation\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public long test1() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);\n+        MyValue1[] va = new MyValue1[Math.abs(rI) % 3];\n+        for (int i = 0; i < va.length; ++i) {\n+            va[i] = MyValue1.createWithFieldsInline(rI, rL);\n+        }\n+        long result = 0;\n+        \/\/ Long loop to trigger OSR compilation\n+        for (int i = 0 ; i < 50_000; ++i) {\n+            \/\/ Reference local inline type in interpreter state\n+            result = v.hash();\n+            for (int j = 0; j < va.length; ++j) {\n+                result += va[j].hash();\n+            }\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        long result = test1();\n+        Asserts.assertEQ(result, ((Math.abs(rI) % 3) + 1) * hash());\n+    }\n+\n+    \/\/ Test loop peeling\n+    @Test(failOn = ALLOC + LOAD + STORE) @Warmup(0) @OSRCompileOnly\n+    public void test2() {\n+        MyValue1 v = MyValue1.createWithFieldsInline(0, 1);\n+        \/\/ Trigger OSR compilation and loop peeling\n+        for (int i = 0; i < 50_000; ++i) {\n+            if (v.x != i || v.y != i + 1) {\n+                \/\/ Uncommon trap\n+                throw new RuntimeException(\"test2 failed\");\n+            }\n+            v = MyValue1.createWithFieldsInline(i + 1, i + 2);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        test2();\n+    }\n+\n+    \/\/ Test loop peeling and unrolling\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public void test3() {\n+        MyValue1 v1 = MyValue1.createWithFieldsInline(0, 0);\n+        MyValue1 v2 = MyValue1.createWithFieldsInline(1, 1);\n+        \/\/ Trigger OSR compilation and loop peeling\n+        for (int i = 0; i < 50_000; ++i) {\n+            if (v1.x != 2*i || v2.x != i+1 || v2.y != i+1) {\n+                \/\/ Uncommon trap\n+                throw new RuntimeException(\"test3 failed\");\n+            }\n+            v1 = MyValue1.createWithFieldsInline(2*(i+1), 0);\n+            v2 = MyValue1.createWithFieldsInline(i+2, i+2);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        test3();\n+    }\n+\n+    \/\/ OSR compilation with Object local\n+    @DontCompile\n+    public Object test4_init() {\n+        return MyValue1.createWithFieldsInline(rI, rL);\n+    }\n+\n+    @DontCompile\n+    public Object test4_body() {\n+        return MyValue1.createWithFieldsInline(rI, rL);\n+    }\n+\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public Object test4() {\n+        Object vt = test4_init();\n+        for (int i = 0; i < 50_000; i++) {\n+            if (i % 2 == 1) {\n+                vt = test4_body();\n+            }\n+        }\n+        return vt;\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        test4();\n+    }\n+\n+    \/\/ OSR compilation with null inline type local\n+\n+    MyValue1.ref nullField;\n+\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public void test5() {\n+        MyValue1.ref vt = nullField;\n+        for (int i = 0; i < 50_000; i++) {\n+            if (vt != null) {\n+                throw new RuntimeException(\"test5 failed: vt should be null\");\n+            }\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        test5();\n+    }\n+\n+    \/\/ Test OSR in method with inline type receiver\n+    primitive class Test6Value {\n+        public int f = 0;\n+\n+        public int test() {\n+            int res = 0;\n+            for (int i = 1; i < 20_000; ++i) {\n+                res -= i;\n+            }\n+            return res;\n+        }\n+    }\n+\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public void test6() {\n+        Test6Value tmp = new Test6Value();\n+        for (int i = 0; i < 100; ++i) {\n+            tmp.test();\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        test6();\n+    }\n+\n+    \/\/ Similar to test6 but with more fields and reserved stack entry\n+    static primitive class Test7Value1 {\n+        public int i1 = rI;\n+        public int i2 = rI;\n+        public int i3 = rI;\n+        public int i4 = rI;\n+        public int i5 = rI;\n+        public int i6 = rI;\n+    }\n+\n+    static primitive class Test7Value2 {\n+        public int i1 = rI;\n+        public int i2 = rI;\n+        public int i3 = rI;\n+        public int i4 = rI;\n+        public int i5 = rI;\n+        public int i6 = rI;\n+        public int i7 = rI;\n+        public int i8 = rI;\n+        public int i9 = rI;\n+        public int i10 = rI;\n+        public int i11 = rI;\n+        public int i12 = rI;\n+        public int i13 = rI;\n+        public int i14 = rI;\n+        public int i15 = rI;\n+        public int i16 = rI;\n+        public int i17 = rI;\n+        public int i18 = rI;\n+        public int i19 = rI;\n+        public int i20 = rI;\n+        public int i21 = rI;\n+\n+        public Test7Value1 vt = new Test7Value1();\n+\n+        public int test(String[] args) {\n+            int res = 0;\n+            for (int i = 1; i < 20_000; ++i) {\n+                res -= i;\n+            }\n+            return res;\n+        }\n+    }\n+\n+    @Test() @Warmup(0) @OSRCompileOnly\n+    public void test7() {\n+        Test7Value2 tmp = new Test7Value2();\n+        for (int i = 0; i < 10; ++i) {\n+            tmp.test(null);\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        test7();\n+    }\n+\n+    \/\/ Test OSR with scalarized inline type return\n+    MyValue3 test8_vt;\n+\n+    @DontInline\n+    public MyValue3 test8_callee(int len) {\n+        test8_vt = MyValue3.create();\n+        int val = 0;\n+        for (int i = 0; i < len; ++i) {\n+            val = i;\n+        }\n+        test8_vt = test8_vt.setI(test8_vt, val);\n+        return test8_vt;\n+    }\n+\n+    @Test() @Warmup(2)\n+    public int test8(int start) {\n+        MyValue3 vt = test8_callee(start);\n+        test8_vt.verify(vt);\n+        int result = 0;\n+        for (int i = 0; i < 50_000; ++i) {\n+            result += i;\n+        }\n+        return result;\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        test8(1);\n+        test8(50_000);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestOnStackReplacement.java","additions":292,"deletions":0,"binary":false,"changes":292,"status":"added"},{"patch":"@@ -0,0 +1,886 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.valhalla.inlinetypes;\n+import jdk.test.lib.Asserts;\n+\n+\/**\n+ * @test\n+ * @key randomness\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @summary Test the handling of fields of unloaded inline classes.\n+ * @compile hack\/GetUnresolvedInlineFieldWrongSignature.java\n+ * @compile TestUnloadedInlineTypeField.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=120 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestUnloadedInlineTypeField\n+ *\/\n+\n+public class TestUnloadedInlineTypeField extends InlineTypeTest {\n+    \/\/ Only prevent loading of classes when testing with C1. Load classes\n+    \/\/ early when executing with C2 to prevent uncommon traps. It's still\n+    \/\/ beneficial to execute this test with C2 because it also checks handling\n+    \/\/ of type mismatches.\n+    private static final boolean PREVENT_LOADING = TEST_C1;\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestUnloadedInlineTypeField test = new TestUnloadedInlineTypeField();\n+        test.run(args);\n+    }\n+\n+    static final String[][] scenarios = {\n+        {},\n+        {\"-XX:InlineFieldMaxFlatSize=0\"},\n+        {\"-XX:+PatchALot\"},\n+        {\"-XX:InlineFieldMaxFlatSize=0\", \"-XX:+PatchALot\"}\n+    };\n+\n+    @Override\n+    public int getNumScenarios() {\n+        return scenarios.length;\n+    }\n+\n+    @Override\n+    public String[] getVMParameters(int scenario) {\n+        return scenarios[scenario];\n+    }\n+\n+    \/\/ Test case 1:\n+    \/\/ The inline type field class has been loaded, but the holder class has not been loaded.\n+    \/\/\n+    \/\/     aload_0\n+    \/\/     getfield  MyValue1Holder.v:QMyValue1;\n+    \/\/               ^ not loaded      ^ already loaded\n+    \/\/\n+    \/\/ MyValue1 has already been loaded, because it's in the InlineType attribute of\n+    \/\/ TestUnloadedInlineTypeField, due to TestUnloadedInlineTypeField.test1_precondition().\n+    static final primitive class MyValue1 {\n+        final int foo;\n+\n+        MyValue1() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static class MyValue1Holder {\n+        MyValue1 v;\n+\n+        public MyValue1Holder() {\n+            v = new MyValue1();\n+        }\n+    }\n+\n+    static MyValue1 test1_precondition() {\n+        return new MyValue1();\n+    }\n+\n+    @Test\n+    public int test1(Object holder) {\n+        if (holder != null) {\n+            \/\/ Don't use MyValue1Holder in the signature, it might trigger class loading\n+            return ((MyValue1Holder)holder).v.foo;\n+        } else {\n+            return 0;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test1(null);\n+        } else {\n+            MyValue1Holder holder = new MyValue1Holder();\n+            Asserts.assertEQ(test1(holder), rI);\n+        }\n+    }\n+\n+    \/\/ Test case 2:\n+    \/\/ Both the inline type field class, and the holder class have not been loaded.\n+    \/\/\n+    \/\/     aload_0\n+    \/\/     getfield  MyValue2Holder.v:QMyValue2;\n+    \/\/               ^ not loaded     ^ not loaded\n+    \/\/\n+    \/\/ MyValue2 has not been loaded, because it is not explicitly referenced by\n+    \/\/ TestUnloadedInlineTypeField.\n+    static final primitive class MyValue2 {\n+        final int foo;\n+\n+        public MyValue2(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue2Holder {\n+        MyValue2 v;\n+\n+        public MyValue2Holder() {\n+            v = new MyValue2(rI);\n+        }\n+    }\n+\n+    @Test\n+    public int test2(Object holder) {\n+        if (holder != null) {\n+            \/\/ Don't use MyValue2Holder in the signature, it might trigger class loading\n+            return ((MyValue2Holder)holder).v.foo;\n+        } else {\n+            return 0;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test2(null);\n+        } else {\n+            MyValue2Holder holder = new MyValue2Holder();\n+            Asserts.assertEQ(test2(holder), rI);\n+        }\n+    }\n+\n+    \/\/ Test case 3: same as test1, except we are using an incorrect signature to\n+    \/\/ refer to the inline class.\n+    \/\/ The inline type field class has been loaded, but the holder class has not been loaded.\n+    \/\/\n+    \/\/ GetUnresolvedInlineFieldWrongSignature::test3() {\n+    \/\/     aload_0\n+    \/\/     getfield  MyValue3Holder.v:LMyValue3;\n+    \/\/               ^ not loaded    ^ already loaded (but should have been \"Q\")\n+    \/\/     ...\n+    \/\/ }\n+    \/\/\n+    \/\/ MyValue3 has already been loaded, because it's in the InlineType attribute of\n+    \/\/ TestUnloadedInlineTypeField, due to TestUnloadedInlineTypeField.test3_precondition().\n+    static final primitive class MyValue3 {\n+        final int foo;\n+\n+        public MyValue3() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static class MyValue3Holder {\n+        MyValue3 v;\n+\n+        public MyValue3Holder() {\n+            v = new MyValue3();\n+        }\n+    }\n+\n+    static MyValue3 test3_precondition() {\n+        return new MyValue3();\n+    }\n+\n+    @Test\n+    public int test3(Object holder) {\n+        \/\/ Don't use MyValue3Holder in the signature, it might trigger class loading\n+        return GetUnresolvedInlineFieldWrongSignature.test3(holder);\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test3(null);\n+        } else {\n+            \/\/ Make sure klass is resolved\n+            for (int i = 0; i < 10; ++i) {\n+                MyValue3Holder holder = new MyValue3Holder();\n+                try {\n+                    test3(holder);\n+                    Asserts.fail(\"Should have thrown NoSuchFieldError\");\n+                } catch (NoSuchFieldError e) {\n+                    \/\/ OK\n+                }\n+            }\n+        }\n+    }\n+\n+    \/\/ Test case 4:\n+    \/\/ Same as case 1, except we use putfield instead of getfield.\n+    static final primitive class MyValue4 {\n+        final int foo;\n+\n+        MyValue4(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue4Holder {\n+        MyValue4 v;\n+\n+        public MyValue4Holder() {\n+            v = new MyValue4(0);\n+        }\n+    }\n+\n+    @Test\n+    public void test4(Object holder, MyValue4 v) {\n+        if (holder != null) {\n+            \/\/ Don't use MyValue4Holder in the signature, it might trigger class loading\n+            ((MyValue4Holder)holder).v = v;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        MyValue4 v = new MyValue4(rI);\n+        if (warmup && PREVENT_LOADING) {\n+            test4(null, v);\n+        } else {\n+            MyValue4Holder holder = new MyValue4Holder();\n+            test4(holder, v);\n+            Asserts.assertEQ(holder.v.foo, rI);\n+        }\n+    }\n+\n+    \/\/ Test case 5:\n+    \/\/ Same as case 2, except we use putfield instead of getfield.\n+    static final primitive class MyValue5 {\n+        final int foo;\n+\n+        MyValue5(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue5Holder {\n+        MyValue5 v;\n+\n+        public MyValue5Holder() {\n+            v = new MyValue5(0);\n+        }\n+\n+        public Object make(int n) {\n+            return new MyValue5(n);\n+        }\n+    }\n+\n+    @Test\n+    public void test5(Object holder, Object o) {\n+        if (holder != null) {\n+            \/\/ Don't use MyValue5 and MyValue5Holder in the signature, it might trigger class loading\n+            MyValue5 v = (MyValue5)o;\n+            ((MyValue5Holder)holder).v = v;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test5(null, null);\n+        } else {\n+            MyValue5Holder holder = new MyValue5Holder();\n+            Object v = holder.make(rI);\n+            test5(holder, v);\n+            Asserts.assertEQ(holder.v.foo, rI);\n+        }\n+    }\n+\n+\n+    \/\/ Test case 6: (same as test1, except we use getstatic instead of getfield)\n+    \/\/ The inline type field class has been loaded, but the holder class has not been loaded.\n+    \/\/\n+    \/\/     getstatic  MyValue6Holder.v:QMyValue1;\n+    \/\/                ^ not loaded       ^ already loaded\n+    \/\/\n+    \/\/ MyValue6 has already been loaded, because it's in the InlineType attribute of\n+    \/\/ TestUnloadedInlineTypeField, due to TestUnloadedInlineTypeField.test1_precondition().\n+    static final primitive class MyValue6 {\n+        final int foo;\n+\n+        MyValue6() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static class MyValue6Holder {\n+        static MyValue6 v = new MyValue6();\n+    }\n+\n+    static MyValue6 test6_precondition() {\n+        return new MyValue6();\n+    }\n+\n+    @Test\n+    public int test6(int n) {\n+        if (n == 0) {\n+            return 0;\n+        } else {\n+            return MyValue6Holder.v.foo + n;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test6(0);\n+        } else {\n+            Asserts.assertEQ(test6(rI), 2*rI);\n+        }\n+    }\n+\n+\n+    \/\/ Test case 7:  (same as test2, except we use getstatic instead of getfield)\n+    \/\/ Both the inline type field class, and the holder class have not been loaded.\n+    \/\/\n+    \/\/     getstatic  MyValue7Holder.v:QMyValue7;\n+    \/\/                ^ not loaded       ^ not loaded\n+    \/\/\n+    \/\/ MyValue7 has not been loaded, because it is not explicitly referenced by\n+    \/\/ TestUnloadedInlineTypeField.\n+    static final primitive class MyValue7 {\n+        final int foo;\n+\n+        MyValue7(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue7Holder {\n+        static MyValue7 v = new MyValue7(rI);\n+    }\n+\n+    @Test\n+    public int test7(int n) {\n+        if (n == 0) {\n+            return 0;\n+        } else {\n+            return MyValue7Holder.v.foo + n;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test7(0);\n+        } else {\n+            Asserts.assertEQ(test7(rI), 2*rI);\n+        }\n+    }\n+\n+    \/\/ Test case 8:\n+    \/\/ Same as case 1, except holder is allocated in test method (-> no holder null check required)\n+    static final primitive class MyValue8 {\n+        final int foo;\n+\n+        MyValue8() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static class MyValue8Holder {\n+        MyValue8 v;\n+\n+        public MyValue8Holder() {\n+            v = new MyValue8();\n+        }\n+    }\n+\n+    static MyValue8 test8_precondition() {\n+        return new MyValue8();\n+    }\n+\n+    @Test\n+    public int test8(boolean warmup) {\n+        if (!warmup) {\n+            MyValue8Holder holder = new MyValue8Holder();\n+            return holder.v.foo;\n+        } else {\n+            return 0;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test8(true);\n+        } else {\n+            Asserts.assertEQ(test8(false), rI);\n+        }\n+    }\n+\n+    \/\/ Test case 9:\n+    \/\/ Same as case 2, except holder is allocated in test method (-> no holder null check required)\n+    static final primitive class MyValue9 {\n+        final int foo;\n+\n+        public MyValue9(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue9Holder {\n+        MyValue9 v;\n+\n+        public MyValue9Holder() {\n+            v = new MyValue9(rI);\n+        }\n+    }\n+\n+    @Test\n+    public int test9(boolean warmup) {\n+        if (!warmup) {\n+            MyValue9Holder holder = new MyValue9Holder();\n+            return holder.v.foo;\n+        } else {\n+            return 0;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test9(true);\n+        } else {\n+            Asserts.assertEQ(test9(false), rI);\n+        }\n+    }\n+\n+    \/\/ Test case 10:\n+    \/\/ Same as case 4, but with putfield\n+    static final primitive class MyValue10 {\n+        final int foo;\n+\n+        public MyValue10() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static class MyValue10Holder {\n+        MyValue10 v1;\n+        MyValue10 v2;\n+\n+        public MyValue10Holder() {\n+            v1 = new MyValue10();\n+            v2 = new MyValue10();\n+        }\n+    }\n+\n+    static MyValue10 test10_precondition() {\n+        return new MyValue10();\n+    }\n+\n+    @Test\n+    public void test10(Object holder) {\n+        \/\/ Don't use MyValue10Holder in the signature, it might trigger class loading\n+        GetUnresolvedInlineFieldWrongSignature.test10(holder);\n+    }\n+\n+    @DontCompile\n+    public void test10_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test10(null);\n+        } else {\n+            \/\/ Make sure klass is resolved\n+            for (int i = 0; i < 10; ++i) {\n+                MyValue10Holder holder = new MyValue10Holder();\n+                try {\n+                    test10(holder);\n+                    Asserts.fail(\"Should have thrown NoSuchFieldError\");\n+                } catch (NoSuchFieldError e) {\n+                    \/\/ OK\n+                }\n+            }\n+        }\n+    }\n+\n+    \/\/ Test case 11:\n+    \/\/ Same as case 4, except holder is allocated in test method (-> no holder null check required)\n+    static final primitive class MyValue11 {\n+        final int foo;\n+\n+        MyValue11(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue11Holder {\n+        MyValue11 v;\n+\n+        public MyValue11Holder() {\n+            v = new MyValue11(0);\n+        }\n+    }\n+\n+    @Test\n+    public Object test11(boolean warmup, MyValue11 v) {\n+        if (!warmup) {\n+            MyValue11Holder holder = new MyValue11Holder();\n+            holder.v = v;\n+            return holder;\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test11_verifier(boolean warmup) {\n+        MyValue11 v = new MyValue11(rI);\n+        if (warmup && PREVENT_LOADING) {\n+            test11(true, v);\n+        } else {\n+            MyValue11Holder holder = (MyValue11Holder)test11(false, v);\n+            Asserts.assertEQ(holder.v.foo, rI);\n+        }\n+    }\n+\n+    \/\/ Test case 12:\n+    \/\/ Same as case 5, except holder is allocated in test method (-> no holder null check required)\n+    static final primitive class MyValue12 {\n+        final int foo;\n+\n+        MyValue12(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue12Holder {\n+        MyValue12 v;\n+\n+        public MyValue12Holder() {\n+            v = new MyValue12(0);\n+        }\n+    }\n+\n+    @Test\n+    public Object test12(boolean warmup, Object o) {\n+        if (!warmup) {\n+            \/\/ Don't use MyValue12 in the signature, it might trigger class loading\n+            MyValue12Holder holder = new MyValue12Holder();\n+            holder.v = (MyValue12)o;\n+            return holder;\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test12_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test12(true, null);\n+        } else {\n+            MyValue12 v = new MyValue12(rI);\n+            MyValue12Holder holder = (MyValue12Holder)test12(false, v);\n+            Asserts.assertEQ(holder.v.foo, rI);\n+        }\n+    }\n+\n+    \/\/ Test case 13:\n+    \/\/ Same as case 10, except MyValue13 is allocated in test method\n+    static final primitive class MyValue13 {\n+        final int foo;\n+\n+        public MyValue13() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static class MyValue13Holder {\n+        MyValue13 v;\n+\n+        public MyValue13Holder() {\n+            v = new MyValue13();\n+        }\n+    }\n+\n+    static MyValue13 test13_precondition() {\n+        return new MyValue13();\n+    }\n+\n+    @Test\n+    public void test13(Object holder) {\n+        \/\/ Don't use MyValue13Holder in the signature, it might trigger class loading\n+        GetUnresolvedInlineFieldWrongSignature.test13(holder);\n+    }\n+\n+    @DontCompile\n+    public void test13_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test13(null);\n+        } else {\n+            \/\/ Make sure klass is resolved\n+            for (int i = 0; i < 10; ++i) {\n+                MyValue13Holder holder = new MyValue13Holder();\n+                try {\n+                    test13(holder);\n+                    Asserts.fail(\"Should have thrown InstantiationError\");\n+                } catch (InstantiationError e) {\n+                    \/\/ OK\n+                }\n+            }\n+        }\n+    }\n+\n+    \/\/ Test case 14:\n+    \/\/ Same as case 10, except storing null\n+    static final primitive class MyValue14 {\n+        final int foo;\n+\n+        public MyValue14() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static class MyValue14Holder {\n+        MyValue14 v;\n+\n+        public MyValue14Holder() {\n+            v = new MyValue14();\n+        }\n+    }\n+\n+    static MyValue14 test14_precondition() {\n+        return new MyValue14();\n+    }\n+\n+    @Test\n+    public void test14(Object holder) {\n+        \/\/ Don't use MyValue14Holder in the signature, it might trigger class loading\n+        GetUnresolvedInlineFieldWrongSignature.test14(holder);\n+    }\n+\n+    @DontCompile\n+    public void test14_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test14(null);\n+        } else {\n+            \/\/ Make sure klass is resolved\n+            for (int i = 0; i < 10; ++i) {\n+                MyValue14Holder holder = new MyValue14Holder();\n+                try {\n+                    test14(holder);\n+                    Asserts.fail(\"Should have thrown NoSuchFieldError\");\n+                } catch (NoSuchFieldError e) {\n+                    \/\/ OK\n+                }\n+            }\n+        }\n+    }\n+\n+    \/\/ Test case 15:\n+    \/\/ Same as case 13, except MyValue15 is unloaded\n+    static final primitive class MyValue15 {\n+        final int foo;\n+\n+        public MyValue15() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static class MyValue15Holder {\n+        MyValue15 v;\n+\n+        public MyValue15Holder() {\n+            v = new MyValue15();\n+        }\n+    }\n+\n+    @Test\n+    public void test15(Object holder) {\n+        \/\/ Don't use MyValue15Holder in the signature, it might trigger class loading\n+        GetUnresolvedInlineFieldWrongSignature.test15(holder);\n+    }\n+\n+    @DontCompile\n+    public void test15_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test15(null);\n+        } else {\n+            \/\/ Make sure klass is resolved\n+            for (int i = 0; i < 10; ++i) {\n+                MyValue15Holder holder = new MyValue15Holder();\n+                try {\n+                    test15(holder);\n+                    Asserts.fail(\"Should have thrown InstantiationError\");\n+                } catch (InstantiationError e) {\n+                    \/\/ OK\n+                }\n+            }\n+        }\n+    }\n+\n+    \/\/ Test case 16:\n+    \/\/ Defaultvalue with type which is not an inline type\n+    static final class MyValue16 {\n+        final int foo;\n+\n+        public MyValue16() {\n+            foo = rI;\n+        }\n+    }\n+\n+    static MyValue16 test16_precondition() {\n+        return new MyValue16();\n+    }\n+\n+    @Test\n+    public Object test16(boolean warmup) {\n+        return GetUnresolvedInlineFieldWrongSignature.test16(warmup);\n+    }\n+\n+    @DontCompile\n+    public void test16_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test16(true);\n+        } else {\n+            \/\/ Make sure klass is resolved\n+            for (int i = 0; i < 10; ++i) {\n+                try {\n+                    test16(false);\n+                    Asserts.fail(\"Should have thrown IncompatibleClassChangeError\");\n+                } catch (IncompatibleClassChangeError e) {\n+                    \/\/ OK\n+                }\n+            }\n+        }\n+    }\n+\n+    \/\/ Test case 17:\n+    \/\/ Same as test16 but with unloaded type at defaultvalue\n+    static final class MyValue17 {\n+        final int foo;\n+\n+        public MyValue17() {\n+            foo = rI;\n+        }\n+    }\n+\n+    @Test\n+    public Object test17(boolean warmup) {\n+        return GetUnresolvedInlineFieldWrongSignature.test17(warmup);\n+    }\n+\n+    @DontCompile\n+    public void test17_verifier(boolean warmup) {\n+        if (warmup && PREVENT_LOADING) {\n+            test17(true);\n+        } else {\n+            \/\/ Make sure klass is resolved\n+            for (int i = 0; i < 10; ++i) {\n+                try {\n+                    test17(false);\n+                    Asserts.fail(\"Should have thrown IncompatibleClassChangeError\");\n+                } catch (IncompatibleClassChangeError e) {\n+                    \/\/ OK\n+                }\n+            }\n+        }\n+    }\n+\n+    \/\/ Test case 18:\n+    \/\/ Same as test7 but with the holder being loaded\n+    static final primitive class MyValue18 {\n+        final int foo;\n+\n+        MyValue18(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue18Holder {\n+        static MyValue18 v = new MyValue18(rI);\n+    }\n+\n+    @Test\n+    public int test18(int n) {\n+        if (n == 0) {\n+            return 0;\n+        } else {\n+            return MyValue18Holder.v.foo + n;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test18_verifier(boolean warmup) {\n+        \/\/ Make sure MyValue18Holder is loaded\n+        MyValue18Holder holder = new MyValue18Holder();\n+        if (warmup && PREVENT_LOADING) {\n+            test18(0);\n+        } else {\n+            Asserts.assertEQ(test18(rI), 2*rI);\n+        }\n+    }\n+\n+    \/\/ Test case 19:\n+    \/\/ Same as test18 but uninitialized (null) static inline type field\n+    static final primitive class MyValue19 {\n+        final int foo;\n+\n+        MyValue19(int n) {\n+            foo = n;\n+        }\n+    }\n+\n+    static class MyValue19Holder {\n+        static MyValue19 v;\n+    }\n+\n+    @Test\n+    public int test19(int n) {\n+        if (n == 0) {\n+            return 0;\n+        } else {\n+            return MyValue19Holder.v.foo + n;\n+        }\n+    }\n+\n+    @DontCompile\n+    public void test19_verifier(boolean warmup) {\n+        \/\/ Make sure MyValue19Holder is loaded\n+        MyValue19Holder holder = new MyValue19Holder();\n+        if (warmup && PREVENT_LOADING) {\n+            test19(0);\n+        } else {\n+            Asserts.assertEQ(test19(rI), rI);\n+        }\n+    }\n+\n+    \/\/ Test case 20:\n+    \/\/ Inline type with object field of unloaded type.\n+    static class MyObject20 {\n+        int x = 42;\n+    }\n+\n+    static final primitive class MyValue20 {\n+        MyObject20 obj;\n+\n+        MyValue20() {\n+            this.obj = null;\n+        }\n+    }\n+\n+    @Test\n+    public MyValue20 test20() {\n+        return new MyValue20();\n+    }\n+\n+    @DontCompile\n+    public void test20_verifier(boolean warmup) {\n+        MyValue20 vt = test20();\n+        Asserts.assertEQ(vt.obj, null);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestUnloadedInlineTypeField.java","additions":886,"deletions":0,"binary":false,"changes":886,"status":"added"},{"patch":"@@ -0,0 +1,362 @@\n+\/*\n+ * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\n+package compiler.valhalla.inlinetypes;\n+\n+import java.lang.invoke.*;\n+import java.lang.reflect.Method;\n+import java.util.Arrays;\n+\n+import jdk.test.lib.Asserts;\n+\n+\/*\n+ * @test\n+ * @key randomness\n+ * @summary Verify that C1 performs escape analysis before optimizing withfield bytecode to putfield.\n+ * @library \/testlibrary \/test\/lib \/compiler\/whitebox \/\n+ * @requires os.simpleArch == \"x64\"\n+ * @compile -XDallowWithFieldOperator TestWithfieldC1.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox jdk.test.lib.Platform\n+ * @run main\/othervm\/timeout=300 -Xbootclasspath\/a:. -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                               -XX:+UnlockExperimentalVMOptions -XX:+WhiteBoxAPI\n+ *                               compiler.valhalla.inlinetypes.InlineTypeTest\n+ *                               compiler.valhalla.inlinetypes.TestWithfieldC1\n+ *\/\n+public class TestWithfieldC1 extends InlineTypeTest {\n+    public static final int C1 = COMP_LEVEL_SIMPLE;\n+    public static final int C2 = COMP_LEVEL_FULL_OPTIMIZATION;\n+\n+    public static void main(String[] args) throws Throwable {\n+        TestWithfieldC1 test = new TestWithfieldC1();\n+        test.run(args, FooValue.class);\n+    }\n+\n+    @Override\n+    public int getNumScenarios() {\n+        return 5;\n+    }\n+\n+    @Override\n+    public String[] getVMParameters(int scenario) {\n+        switch (scenario) {\n+        case 0: return new String[] { \/\/ C1 only\n+                \"-XX:TieredStopAtLevel=1\",\n+                \"-XX:+TieredCompilation\",\n+            };\n+        case 1: return new String[] { \/\/ C2 only. (Make sure the tests are correctly written)\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:-TieredCompilation\",\n+            };\n+        case 2: return new String[] { \/\/ interpreter only\n+                \"-Xint\",\n+            };\n+        case 3: return new String[] {\n+                \/\/ Xcomp Only C1.\n+                \"-XX:TieredStopAtLevel=1\",\n+                \"-XX:+TieredCompilation\",\n+                \"-Xcomp\",\n+            };\n+        case 4: return new String[] {\n+                \/\/ Xcomp Only C2.\n+                \"-XX:TieredStopAtLevel=4\",\n+                \"-XX:-TieredCompilation\",\n+                \"-Xcomp\",\n+            };\n+        }\n+        return null;\n+    }\n+\n+    static FooValue.ref foo_static;\n+    static FooValue.ref foo_static_arr[] = new FooValue.ref[1];\n+    FooValue.ref foo_instance;\n+\n+    @DontInline\n+    static void set_foo_static_if_null(FooValue v) {\n+        if (foo_static == null) {\n+            foo_static = v;\n+        }\n+    }\n+\n+    static primitive class FooValue {\n+        public int x = 0, y = 0;\n+\n+        @ForceInline\n+        static FooValue test1() {\n+            FooValue v = FooValue.default;\n+\n+            v = __WithField(v.x, 1);\n+            v = __WithField(v.y, 1);\n+            foo_static = v;\n+\n+            v = __WithField(v.x, 2);\n+            v = __WithField(v.y, 2);\n+            return v;\n+        }\n+\n+        @ForceInline\n+        static FooValue test3() {\n+            FooValue v = FooValue.default;\n+\n+            v = __WithField(v.x, 1);\n+            v = __WithField(v.y, 1);\n+            set_foo_static_if_null(v);\n+\n+            v = __WithField(v.x, 2);\n+            v = __WithField(v.y, 2);\n+            return v;\n+        }\n+\n+        @ForceInline\n+        static FooValue test4() {\n+            FooValue v = FooValue.default;\n+            for (int i=1; i<=2; i++) {\n+                v = __WithField(v.x, i);\n+                v = __WithField(v.y, i);\n+                set_foo_static_if_null(v);\n+            }\n+\n+            return v;\n+        }\n+\n+        @ForceInline\n+        static FooValue test5() {\n+            FooValue v1 = FooValue.default;\n+            FooValue v2 = FooValue.default;\n+            v2 = v1;\n+\n+            v1 = __WithField(v1.x, 1);\n+            v1 = __WithField(v1.y, 1);\n+            set_foo_static_if_null(v1);\n+\n+            v2 = __WithField(v2.x, 2);\n+            v2 = __WithField(v2.y, 2);\n+\n+            return v2;\n+        }\n+\n+        @ForceInline\n+        static FooValue test6() {\n+            FooValue v = FooValue.default;\n+\n+            v = __WithField(v.x, 1);\n+            v = __WithField(v.y, 1);\n+            foo_static_arr[0] = v;\n+\n+            v = __WithField(v.x, 2);\n+            v = __WithField(v.y, 2);\n+            return v;\n+        }\n+\n+\n+        @ForceInline\n+        static FooValue test7() {\n+            FooValue v1 = FooValue.default;\n+            FooValue v2 = FooValue.default;\n+            v2 = v1;\n+\n+            v1 = __WithField(v1.x, 1);\n+            v1 = __WithField(v1.y, 1);\n+\n+            v2 = __WithField(v2.x, 2);\n+            v2 = __WithField(v2.y, 2);\n+\n+            return v1;\n+        }\n+\n+        @ForceInline\n+        static FooValue test8() {\n+            FooValue v1 = FooValue.default;\n+\n+            v1 = __WithField(v1.x, 1);\n+            v1 = __WithField(v1.y, 1);\n+\n+            v1.non_static_method();\n+\n+            v1 = __WithField(v1.x, 2);\n+            v1 = __WithField(v1.y, 2);\n+\n+            return v1;\n+        }\n+\n+\n+        @DontInline\n+        private void non_static_method() {\n+            set_foo_static_if_null(this);\n+        }\n+    }\n+\n+    static void validate_foo_static_and(FooValue v) {\n+        Asserts.assertEQ(foo_static.x, 1);\n+        Asserts.assertEQ(foo_static.y, 1);\n+        Asserts.assertEQ(v.x, 2);\n+        Asserts.assertEQ(v.y, 2);\n+    }\n+\n+    \/\/ escape with putstatic\n+    @Test(compLevel=C1)\n+    public FooValue test1() {\n+        return FooValue.test1();\n+    }\n+\n+    @DontCompile\n+    public void test1_verifier(boolean warmup) {\n+        FooValue v = test1();\n+        validate_foo_static_and(v);\n+    }\n+\n+    \/\/ escape with putfield\n+    @Test(compLevel=C1)\n+    public FooValue test2() {\n+        FooValue v = FooValue.default;\n+\n+        v = __WithField(v.x, 1);\n+        v = __WithField(v.y, 1);\n+        foo_instance = v;\n+\n+        v = __WithField(v.x, 2);\n+        v = __WithField(v.y, 2);\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test2_verifier(boolean warmup) {\n+        foo_instance = null;\n+        FooValue v = test2();\n+        Asserts.assertEQ(foo_instance.x, 1);\n+        Asserts.assertEQ(foo_instance.y, 1);\n+        Asserts.assertEQ(v.x, 2);\n+        Asserts.assertEQ(v.y, 2);\n+    }\n+\n+    \/\/ escape with function call\n+    @Test(compLevel=C1)\n+    public FooValue test3() {\n+        return FooValue.test3();\n+    }\n+\n+    @DontCompile\n+    public void test3_verifier(boolean warmup) {\n+        foo_static = null;\n+        FooValue v = test3();\n+        validate_foo_static_and(v);\n+    }\n+\n+    \/\/ escape and then branch backwards\n+    @Test(compLevel=C1)\n+    public FooValue test4() {\n+        return FooValue.test4();\n+    }\n+\n+    @DontCompile\n+    public void test4_verifier(boolean warmup) {\n+        foo_static = null;\n+        FooValue v = test4();\n+        validate_foo_static_and(v);\n+    }\n+\n+    \/\/ escape using a different local variable\n+    @Test(compLevel=C1)\n+    public FooValue test5() {\n+        return FooValue.test5();\n+    }\n+\n+    @DontCompile\n+    public void test5_verifier(boolean warmup) {\n+        foo_static = null;\n+        FooValue v = test5();\n+        validate_foo_static_and(v);\n+    }\n+\n+    \/\/ escape using aastore\n+    @Test(compLevel=C1)\n+    public FooValue test6() {\n+        return FooValue.test6();\n+    }\n+\n+    @DontCompile\n+    public void test6_verifier(boolean warmup) {\n+        foo_static_arr[0] = null;\n+        FooValue v = test6();\n+        Asserts.assertEQ(foo_static_arr[0].x, 1);\n+        Asserts.assertEQ(foo_static_arr[0].y, 1);\n+        Asserts.assertEQ(v.x, 2);\n+        Asserts.assertEQ(v.y, 2);\n+    }\n+\n+    \/\/ Copying a value into different local slots -- disable withfield optimization\n+    @Test(compLevel=C1)\n+    public FooValue test7() {\n+        return FooValue.test7();\n+    }\n+\n+    @DontCompile\n+    public void test7_verifier(boolean warmup) {\n+        FooValue v = test7();\n+        Asserts.assertEQ(v.x, 1);\n+        Asserts.assertEQ(v.y, 1);\n+    }\n+\n+    \/\/ escape by invoking non-static method\n+    @Test(compLevel=C1)\n+    public FooValue test8() {\n+        return FooValue.test8();\n+    }\n+\n+    @DontCompile\n+    public void test8_verifier(boolean warmup) {\n+        foo_static = null;\n+        FooValue v = test8();\n+        validate_foo_static_and(v);\n+    }\n+\n+    \/\/ duplicate reference with local variables\n+    @Test(compLevel=C1)\n+    public FooValue test9() {\n+        FooValue v = FooValue.default;\n+\n+        v = __WithField(v.x, 1);\n+        v = __WithField(v.y, 1);\n+\n+        FooValue v2 = v;\n+\n+        v = __WithField(v.x, 2);\n+        v = __WithField(v.y, 2);\n+\n+        v2 = __WithField(v2.x, 3);\n+        v2 = __WithField(v2.y, 3);\n+\n+        foo_instance = v2;\n+        return v;\n+    }\n+\n+    @DontCompile\n+    public void test9_verifier(boolean warmup) {\n+        foo_instance = null;\n+        FooValue v = test9();\n+        Asserts.assertEQ(foo_instance.x, 3);\n+        Asserts.assertEQ(foo_instance.y, 3);\n+        Asserts.assertEQ(v.x, 2);\n+        Asserts.assertEQ(v.y, 2);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/TestWithfieldC1.java","additions":362,"deletions":0,"binary":false,"changes":362,"status":"added"},{"patch":"@@ -71,2 +71,2 @@\n-                                             TestCommon.list(mainClass),\n-                                             unlockArg, logArg, nmtArg);\n+                TestCommon.list(mainClass),\n+                unlockArg, logArg, nmtArg);\n@@ -76,1 +76,1 @@\n-            .assertNormalExit(output -> {\n+                .assertNormalExit(output -> {\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/ArchiveRelocationTest.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,74 @@\n+\/*\n+ * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\/*\n+ * @test\n+ * @summary Hello World test for using inline classes with CDS\n+ * @requires vm.cds\n+ * @library \/test\/lib \/test\/hotspot\/jtreg\/runtime\/cds\/appcds\/test-classes\n+ * @build HelloInlineClassApp\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller -jar hello_inline.jar HelloInlineClassApp HelloInlineClassApp$Point HelloInlineClassApp$Point$ref HelloInlineClassApp$Rectangle HelloInlineClassApp$Rectangle$ref\n+ * @run driver HelloInlineClassTest\n+ *\/\n+\n+import jdk.test.lib.helpers.ClassFileInstaller;\n+import jdk.test.lib.process.OutputAnalyzer;\n+\n+public class HelloInlineClassTest {\n+    public static void main(String[] args) throws Exception {\n+        String appJar = ClassFileInstaller.getJarPath(\"hello_inline.jar\");\n+        String mainClass = \"HelloInlineClassApp\";\n+        OutputAnalyzer output =\n+            TestCommon.dump(appJar, TestCommon.list(mainClass,\n+                                                    \"HelloInlineClassApp$Point\",\n+                                                    \"HelloInlineClassApp$Rectangle\"));\n+        output.shouldHaveExitValue(0);\n+\n+        TestCommon.run(\"-Xint\", \"-cp\", appJar,  mainClass)\n+            .assertNormalExit();\n+\n+        TestCommon.run(\"-cp\", appJar,  mainClass)\n+            .assertNormalExit();\n+\n+        String compFlag = \"-XX:CompileCommand=compileonly,HelloInlineClassApp*::*\";\n+\n+        TestCommon.run(\"-Xcomp\", compFlag,\n+                       \"-cp\", appJar,  mainClass)\n+            .assertNormalExit();\n+\n+        TestCommon.run(\"-Xcomp\", compFlag,\n+                       \"-XX:TieredStopAtLevel=1\",\n+                       \"-XX:+TieredCompilation\",\n+                       \"-XX:-Inline\",\n+                       \"-cp\", appJar,  mainClass)\n+            .assertNormalExit();\n+\n+        TestCommon.run(\"-Xcomp\", compFlag,\n+                       \"-XX:TieredStopAtLevel=4\",\n+                       \"-XX:-TieredCompilation\",\n+                       \"-XX:-Inline\",\n+                       \"-cp\", appJar,  mainClass)\n+            .assertNormalExit();\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/HelloInlineClassTest.java","additions":74,"deletions":0,"binary":false,"changes":74,"status":"added"},{"patch":"@@ -0,0 +1,60 @@\n+\/*\n+ * Copyright (c) 2015, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\/*\n+ * @test\n+ * @summary Use Lookup.defineClass() to load a class with rewritten bytecode. Make sure\n+ *          the archived class with the same name is not loaded.\n+ * @requires vm.cds\n+ * @library \/test\/lib\n+ * @compile test-classes\/RewriteBytecodesInline.java test-classes\/Util.java test-classes\/Point.java test-classes\/WithInlinedField.java\n+ * @build sun.hotspot.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ * @run driver RewriteBytecodesInlineTest\n+ *\/\n+\n+import java.io.File;\n+import jdk.test.lib.process.OutputAnalyzer;\n+\n+public class RewriteBytecodesInlineTest {\n+  public static void main(String[] args) throws Exception {\n+    String wbJar = JarBuilder.build(true, \"WhiteBox\", \"sun\/hotspot\/WhiteBox\");\n+    String use_whitebox_jar = \"-Xbootclasspath\/a:\" + wbJar;\n+\n+    String appJar = JarBuilder.build(\"dynamic_define\", \"RewriteBytecodesInline\", \"Util\", \"Point\", \"Point$ref\", \"WithInlinedField\");\n+    String superClsFile = (new File(System.getProperty(\"test.classes\", \".\"), \"Point.class\")).getPath();\n+\n+    TestCommon.dump(appJar, TestCommon.list(\"RewriteBytecodesInline\", \"Point\", \"Point$ref\", \"WithInlinedField\"),\n+                    \/\/ command-line arguments ...\n+                    use_whitebox_jar);\n+\n+    OutputAnalyzer output = TestCommon.exec(appJar,\n+                    \/\/ command-line arguments ...\n+                    use_whitebox_jar,\n+                    \"-XX:+UnlockDiagnosticVMOptions\",\n+                    \"-XX:+WhiteBoxAPI\",\n+                    \"RewriteBytecodesInline\", superClsFile);\n+    TestCommon.checkExec(output);\n+  }\n+}\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/RewriteBytecodesInlineTest.java","additions":60,"deletions":0,"binary":false,"changes":60,"status":"added"},{"patch":"@@ -33,1 +33,1 @@\n- * @build Hello\n+ * @build HelloRelocation\n@@ -35,1 +35,1 @@\n- * @run driver jdk.test.lib.helpers.ClassFileInstaller -jar hello.jar Hello\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller -jar hello.jar HelloRelocation HelloInlineClassApp HelloInlineClassApp$Point HelloInlineClassApp$Point$ref HelloInlineClassApp$Rectangle HelloInlineClassApp$Rectangle$ref\n@@ -81,1 +81,1 @@\n-        String mainClass = \"Hello\";\n+        String mainClass = \"HelloRelocation\";\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/dynamicArchive\/DynamicArchiveRelocationTest.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,78 @@\n+\/*\n+ * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\/*\n+ * @test\n+ * @summary Hello World test for dynamic archive\n+ * @requires vm.cds\n+ * @library \/test\/lib \/test\/hotspot\/jtreg\/runtime\/cds\/appcds \/test\/hotspot\/jtreg\/runtime\/cds\/appcds\/test-classes\n+ * @build HelloInlineClassApp\n+ * @build sun.hotspot.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller -jar hello_inline.jar HelloInlineClassApp HelloInlineClassApp$Point HelloInlineClassApp$Point$ref HelloInlineClassApp$Rectangle HelloInlineClassApp$Rectangle$ref\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:. HelloDynamicInlineClass\n+ *\/\n+\n+import jdk.test.lib.helpers.ClassFileInstaller;\n+\n+public class HelloDynamicInlineClass extends DynamicArchiveTestBase {\n+    public static void main(String[] args) throws Exception {\n+        runTest(HelloDynamicInlineClass::testDefaultBase);\n+        runTest(HelloDynamicInlineClass::testCustomBase);\n+    }\n+\n+    \/\/ (1) Test with default base archive + top archive\n+    static void testDefaultBase() throws Exception {\n+        String topArchiveName = getNewArchiveName(\"top\");\n+        doTest(null, topArchiveName);\n+    }\n+\n+    \/\/ (2) Test with custom base archive + top archive\n+    static void testCustomBase() throws Exception {\n+        String topArchiveName = getNewArchiveName(\"top2\");\n+        String baseArchiveName = getNewArchiveName(\"base\");\n+        TestCommon.dumpBaseArchive(baseArchiveName);\n+        doTest(baseArchiveName, topArchiveName);\n+    }\n+\n+    private static void doTest(String baseArchiveName, String topArchiveName) throws Exception {\n+        String appJar = ClassFileInstaller.getJarPath(\"hello_inline.jar\");\n+        String mainClass = \"HelloInlineClassApp\";\n+        dump2(baseArchiveName, topArchiveName,\n+             \"-Xlog:cds\",\n+             \"-Xlog:cds+dynamic=debug\",\n+             \"-cp\", appJar, mainClass)\n+            .assertNormalExit(output -> {\n+                    output.shouldContain(\"Written dynamic archive 0x\");\n+                });\n+        run2(baseArchiveName, topArchiveName,\n+            \"-Xlog:class+load\",\n+            \"-Xlog:cds+dynamic=debug,cds=debug\",\n+            \"-cp\", appJar, mainClass)\n+            .assertNormalExit(output -> {\n+                    output.shouldContain(\"HelloInlineClassApp$Point source: shared objects file\")\n+                          .shouldHaveExitValue(0);\n+              });\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/dynamicArchive\/HelloDynamicInlineClass.java","additions":78,"deletions":0,"binary":false,"changes":78,"status":"added"},{"patch":"@@ -60,1 +60,1 @@\n-        for (int i = 0; i < 3; i++) {\n+        for (int i = 0; i < 2; i++) {\n@@ -63,1 +63,0 @@\n-            \/\/ i = 2 -- dump with agent = enable BiasedLocking\n@@ -67,1 +66,0 @@\n-            String biasedLock = (i != 2) ? \"-showversion\" : \"-XX:+UseBiasedLocking\";\n@@ -72,1 +70,1 @@\n-                                    agentArg, agentArg2, biasedLock);\n+                                    agentArg, agentArg2);\n@@ -79,1 +77,1 @@\n-                \"-XX:+UnlockDiagnosticVMOptions\", agentArg2, biasedLock,\n+                \"-XX:+UnlockDiagnosticVMOptions\", agentArg2,\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/javaldr\/LockDuringDump.java","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -0,0 +1,753 @@\n+\/*\n+ * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package runtime.valhalla.inlinetypes;\n+\n+import java.lang.invoke.*;\n+import java.lang.ref.*;\n+import java.util.concurrent.*;\n+\n+import static jdk.test.lib.Asserts.*;\n+import jdk.test.lib.Utils;\n+import sun.hotspot.WhiteBox;\n+import test.java.lang.invoke.lib.InstructionHelper;\n+\n+\/**\n+ * @test InlineOops_int_Serial\n+ * @requires vm.gc.Serial\n+ * @summary Test embedding oops into Inline types\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @compile -XDallowWithFieldOperator Person.java\n+ * @compile -XDallowWithFieldOperator InlineOops.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ *                   sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -Xint -XX:+UseSerialGC -Xmx128m -XX:InlineFieldMaxFlatSize=128\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   runtime.valhalla.inlinetypes.InlineOops\n+ *\/\n+\n+\/**\n+ * @test InlineOops_int_G1\n+ * @requires vm.gc.G1\n+ * @summary Test embedding oops into Inline types\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @compile -XDallowWithFieldOperator Person.java\n+ * @compile -XDallowWithFieldOperator InlineOops.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ *                   sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -Xint  -XX:+UseG1GC -Xmx128m -XX:InlineFieldMaxFlatSize=128\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   runtime.valhalla.inlinetypes.InlineOops 20\n+ *\/\n+\n+\/**\n+ * @test InlineOops_int_Parallel\n+ * @requires vm.gc.Parallel\n+ * @summary Test embedding oops into Inline types\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @compile -XDallowWithFieldOperator Person.java\n+ * @compile -XDallowWithFieldOperator InlineOops.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ *                   sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -Xint -XX:+UseParallelGC -Xmx128m -XX:InlineFieldMaxFlatSize=128\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   runtime.valhalla.inlinetypes.InlineOops\n+ *\/\n+\n+\/**\n+ * @test InlineOops_int_Z\n+ * @requires vm.gc.Z\n+ * @summary Test embedding oops into Inline types\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @compile -XDallowWithFieldOperator Person.java\n+ * @compile -XDallowWithFieldOperator InlineOops.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ *                   sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -Xint -XX:+UnlockExperimentalVMOptions -XX:+UseZGC -Xmx128m\n+ *                   -XX:+UnlockDiagnosticVMOptions -XX:+ZVerifyViews -XX:InlineFieldMaxFlatSize=128\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   runtime.valhalla.inlinetypes.InlineOops\n+ *\/\n+\n+\/**\n+ * @test InlineOops_comp_serial\n+ * @requires vm.gc.Serial\n+ * @summary Test embedding oops into Inline types\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @compile -XDallowWithFieldOperator Person.java\n+ * @compile -XDallowWithFieldOperator InlineOops.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ *                   sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -Xcomp -XX:+UseSerialGC -Xmx128m -XX:InlineFieldMaxFlatSize=128\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   runtime.valhalla.inlinetypes.InlineOops\n+ *\/\n+\n+\/**\n+ * @test InlineOops_comp_G1\n+ * @requires vm.gc.G1\n+ * @summary Test embedding oops into Inline types\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @compile -XDallowWithFieldOperator Person.java\n+ * @compile -XDallowWithFieldOperator InlineOops.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ *                   sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -Xcomp -XX:+UseG1GC -Xmx128m -XX:InlineFieldMaxFlatSize=128\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   runtime.valhalla.inlinetypes.InlineOops 20\n+ *\/\n+\n+\/**\n+ * @test InlineOops_comp_Parallel\n+ * @requires vm.gc.Parallel\n+ * @summary Test embedding oops into Inline types\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @compile -XDallowWithFieldOperator Person.java\n+ * @compile -XDallowWithFieldOperator InlineOops.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ *                   sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -Xcomp -XX:+UseParallelGC -Xmx128m -XX:InlineFieldMaxFlatSize=128\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   runtime.valhalla.inlinetypes.InlineOops\n+ *\/\n+\n+\/**\n+ * @test InlineOops_comp_Z\n+ * @requires vm.gc.Z\n+ * @summary Test embedding oops into Inline types\n+ * @library \/test\/lib \/test\/jdk\/lib\/testlibrary\/bytecode \/test\/jdk\/java\/lang\/invoke\/common\n+ * @build jdk.experimental.bytecode.BasicClassBuilder test.java.lang.invoke.lib.InstructionHelper\n+ * @compile -XDallowWithFieldOperator Person.java\n+ * @compile -XDallowWithFieldOperator InlineOops.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ *                   sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -Xcomp -XX:+UnlockExperimentalVMOptions -XX:+UseZGC -Xmx128m\n+ *                   -XX:+UnlockDiagnosticVMOptions -XX:+ZVerifyViews -XX:InlineFieldMaxFlatSize=128\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                   runtime.valhalla.inlinetypes.InlineOops\n+ *\/\n+public class InlineOops {\n+\n+    \/\/ Extra debug: -XX:+VerifyOops -XX:+VerifyStack -XX:+VerifyLastFrame -XX:+VerifyBeforeGC -XX:+VerifyAfterGC -XX:+VerifyDuringGC -XX:VerifySubSet=threads,heap\n+    \/\/ Even more debugging: -XX:+TraceNewOopMapGeneration -Xlog:gc*=info\n+\n+    static final int NOF_PEOPLE = 10000; \/\/ Exercise arrays of this size\n+\n+    static int MIN_ACTIVE_GC_COUNT = 10; \/\/ Run active workload for this number of GC passes\n+\n+    static int MED_ACTIVE_GC_COUNT = 4;  \/\/ Medium life span in terms of GC passes\n+\n+    static final String TEST_STRING1 = \"Test String 1\";\n+    static final String TEST_STRING2 = \"Test String 2\";\n+\n+    static boolean USE_COMPILER = WhiteBox.getWhiteBox().getBooleanVMFlag(\"UseCompiler\");\n+\n+    static MethodHandles.Lookup LOOKUP = MethodHandles.lookup();\n+\n+    public static void main(String[] args) {\n+        if (args.length > 0) {\n+            MIN_ACTIVE_GC_COUNT = Integer.parseInt(args[0]);\n+        }\n+        testClassLoad();\n+        testValues();\n+\n+        if (!USE_COMPILER) {\n+            testOopMaps();\n+        }\n+\n+        \/\/ Check we survive GC...\n+        testOverGc();   \/\/ Exercise root scan \/ oopMap\n+        testActiveGc(); \/\/ Brute force\n+    }\n+\n+    \/**\n+     * Test ClassFileParser can load inline types with reference fields\n+     *\/\n+    public static void testClassLoad() {\n+        String s = Person.class.toString();\n+        new Bar();\n+        new BarWithValue();\n+        s = BarValue.class.toString();\n+        s = ObjectWithObjectValue.class.toString();\n+        s = ObjectWithObjectValues.class.toString();\n+    }\n+\n+\n+    static class Couple {\n+        public Person onePerson;\n+        public Person otherPerson;\n+    }\n+\n+    static final primitive class Composition {\n+        public final Person onePerson;\n+        public final Person otherPerson;\n+\n+        private Composition() {\n+            onePerson   = Person.create(0, null, null);\n+            otherPerson = Person.create(0, null, null);\n+        }\n+\n+        public static Composition create(Person onePerson, Person otherPerson) {\n+            Composition comp = Composition.default;\n+            comp = __WithField(comp.onePerson, onePerson);\n+            comp = __WithField(comp.otherPerson, otherPerson);\n+            return comp;\n+        }\n+    }\n+\n+    \/**\n+     * Check inline type operations with \"Valhalla Inline Types\" (VVT)\n+     *\/\n+    public static void testValues() {\n+        \/\/ Exercise creation, getfield, vreturn with null refs\n+        validateDefaultPerson(createDefaultPerson());\n+\n+        \/\/ anewarray, aaload, aastore\n+        int index = 7;\n+        Person[] array =  new Person[NOF_PEOPLE];\n+        validateDefaultPerson(array[index]);\n+\n+        \/\/ Now with refs...\n+        validateIndexedPerson(createIndexedPerson(index), index);\n+        array[index] = createIndexedPerson(index);\n+        validateIndexedPerson(array[index], index);\n+\n+        \/\/ Check the neighbours\n+        validateDefaultPerson(array[index - 1]);\n+        validateDefaultPerson(array[index + 1]);\n+\n+        \/\/ getfield\/putfield\n+        Couple couple = new Couple();\n+        validateDefaultPerson(couple.onePerson);\n+        validateDefaultPerson(couple.otherPerson);\n+\n+        couple.onePerson = createIndexedPerson(index);\n+        validateIndexedPerson(couple.onePerson, index);\n+\n+        Composition composition = Composition.create(couple.onePerson, couple.onePerson);\n+        validateIndexedPerson(composition.onePerson, index);\n+        validateIndexedPerson(composition.otherPerson, index);\n+    }\n+\n+    \/**\n+     * Check oop map generation for klass layout and frame...\n+     *\/\n+    public static void testOopMaps() {\n+        Object[] objects = WhiteBox.getWhiteBox().getObjectsViaKlassOopMaps(new Couple());\n+        assertTrue(objects.length == 4, \"Expected 4 oops\");\n+        for (int i = 0; i < objects.length; i++) {\n+            assertTrue(objects[i] == null, \"not-null\");\n+        }\n+\n+        String fn1 = \"Sam\";\n+        String ln1 = \"Smith\";\n+        String fn2 = \"Jane\";\n+        String ln2 = \"Jones\";\n+        Couple couple = new Couple();\n+        couple.onePerson = Person.create(0, fn1, ln1);\n+        couple.otherPerson = Person.create(1, fn2, ln2);\n+        objects = WhiteBox.getWhiteBox().getObjectsViaKlassOopMaps(couple);\n+        assertTrue(objects.length == 4, \"Expected 4 oops\");\n+        assertTrue(objects[0] == fn1, \"Bad oop fn1\");\n+        assertTrue(objects[1] == ln1, \"Bad oop ln1\");\n+        assertTrue(objects[2] == fn2, \"Bad oop fn2\");\n+        assertTrue(objects[3] == ln2, \"Bad oop ln2\");\n+\n+        objects = WhiteBox.getWhiteBox().getObjectsViaOopIterator(couple);\n+        assertTrue(objects.length == 4, \"Expected 4 oops\");\n+        assertTrue(objects[0] == fn1, \"Bad oop fn1\");\n+        assertTrue(objects[1] == ln1, \"Bad oop ln1\");\n+        assertTrue(objects[2] == fn2, \"Bad oop fn2\");\n+        assertTrue(objects[3] == ln2, \"Bad oop ln2\");\n+\n+        \/\/ Array..\n+        objects = WhiteBox.getWhiteBox().getObjectsViaOopIterator(createPeople());\n+        assertTrue(objects.length == NOF_PEOPLE * 2, \"Unexpected length: \" + objects.length);\n+        int o = 0;\n+        for (int i = 0; i < NOF_PEOPLE; i++) {\n+            assertTrue(objects[o++].equals(firstName(i)), \"Bad firstName\");\n+            assertTrue(objects[o++].equals(lastName(i)), \"Bad lastName\");\n+        }\n+\n+        \/\/ Sanity check, FixMe need more test cases\n+        objects = testFrameOops(couple);\n+        assertTrue(objects.length == 5, \"Number of frame oops incorrect = \" + objects.length);\n+        assertTrue(objects[0] == couple, \"Bad oop 0\");\n+        assertTrue(objects[1] == fn1, \"Bad oop 1\");\n+        assertTrue(objects[2] == ln1, \"Bad oop 2\");\n+        assertTrue(objects[3] == TEST_STRING1, \"Bad oop 3\");\n+        assertTrue(objects[4] == TEST_STRING2, \"Bad oop 4\");\n+\n+        testFrameOopsVBytecodes();\n+    }\n+\n+    static final String GET_OOP_MAP_NAME = \"getOopMap\";\n+    static final String GET_OOP_MAP_DESC = \"()[Ljava\/lang\/Object;\";\n+\n+    public static Object[] getOopMap() {\n+        Object[] oopMap = WhiteBox.getWhiteBox().getObjectsViaFrameOopIterator(2);\n+        \/* Remove this frame (class mirror for this method), and above class mirror *\/\n+        Object[] trimmedOopMap = new Object[oopMap.length - 2];\n+        System.arraycopy(oopMap, 2, trimmedOopMap, 0, trimmedOopMap.length);\n+        return trimmedOopMap;\n+    }\n+\n+    \/\/ Expecting Couple couple, Person couple.onePerson, and Person (created here)\n+    public static Object[] testFrameOops(Couple couple) {\n+        int someId = 89898;\n+        Person person = couple.onePerson;\n+        assertTrue(person.getId() == 0, \"Bad Person\");\n+        Person anotherPerson = Person.create(someId, TEST_STRING1, TEST_STRING2);\n+        assertTrue(anotherPerson.getId() == someId, \"Bad Person\");\n+        return getOopMap();\n+    }\n+\n+    \/\/ Debug...\n+    static void dumpOopMap(Object[] oopMap) {\n+        System.out.println(\"Oop Map len: \" + oopMap.length);\n+        for (int i = 0; i < oopMap.length; i++) {\n+            System.out.println(\"[\" + i + \"] = \" + oopMap[i]);\n+        }\n+    }\n+\n+    \/**\n+     * Just some check sanity checks with defaultvalue, withfield, astore and aload\n+     *\n+     * Changes to javac slot usage may well break this test\n+     *\/\n+    public static void testFrameOopsVBytecodes() {\n+        int nofOopMaps = 4;\n+        Object[][] oopMaps = new Object[nofOopMaps][];\n+        String[] inputArgs = new String[] { \"aName\", \"aDescription\", \"someNotes\" };\n+\n+        FooValue.testFrameOopsDefault(oopMaps);\n+\n+        \/\/ Test-D0 Slots=R Stack=Q(RRR)RV\n+        assertTrue(oopMaps[0].length == 5 &&\n+                oopMaps[0][1] == null &&\n+                oopMaps[0][2] == null &&\n+                oopMaps[0][3] == null, \"Test-D0 incorrect\");\n+\n+        \/\/ Test-D1 Slots=R Stack=RV\n+        assertTrue(oopMaps[1].length == 2, \"Test-D1 incorrect\");\n+\n+        \/\/ Test-D2 Slots=RQ(RRR) Stack=RV\n+        assertTrue(oopMaps[2].length == 5 &&\n+                oopMaps[2][1] == null &&\n+                oopMaps[2][2] == null &&\n+                oopMaps[2][3] == null, \"Test-D2 incorrect\");\n+\n+        \/\/ Test-D3 Slots=R Stack=Q(RRR)RV\n+        assertTrue(oopMaps[3].length == 6 &&\n+                oopMaps[3][1] == null &&\n+                oopMaps[3][2] == null &&\n+                oopMaps[3][3] == null &&\n+                oopMaps[3][4] == null, \"Test-D3 incorrect\");\n+\n+        \/\/ With ref fields...\n+        String name = \"TestName\";\n+        String desc = \"TestDesc\";\n+        String note = \"TestNotes\";\n+        FooValue.testFrameOopsRefs(name, desc, note, oopMaps);\n+\n+        \/\/ Test-R0 Slots=RR Stack=Q(RRR)RV\n+        assertTrue(oopMaps[0].length == 6 &&\n+                oopMaps[0][2] == name &&\n+                oopMaps[0][3] == desc &&\n+                oopMaps[0][4] == note, \"Test-R0 incorrect\");\n+\n+        \/**\n+         * TODO: vwithfield from method handle cooked from anonymous class within the inline class\n+         *       even with \"MethodHandles.privateLookupIn()\" will fail final putfield rules\n+         *\/\n+    }\n+\n+    \/**\n+     * Check forcing GC for combination of VT on stack\/LVT etc works\n+     *\/\n+    public static void testOverGc() {\n+        try {\n+            Class<?> vtClass = Person.class;\n+\n+            System.out.println(\"vtClass=\"+vtClass);\n+\n+            doGc();\n+\n+            \/\/ VT on stack and lvt, null refs, see if GC flies\n+            MethodHandle moveValueThroughStackAndLvt = InstructionHelper.loadCode(\n+                    LOOKUP,\n+                    \"gcOverPerson\",\n+                    MethodType.methodType(vtClass, vtClass),\n+                    CODE->{\n+                        CODE\n+                        .aload(0)\n+                        .invokestatic(InlineOops.class, \"doGc\", \"()V\", false) \/\/ Stack\n+                        .astore(0)\n+                        .invokestatic(InlineOops.class, \"doGc\", \"()V\", false) \/\/ LVT\n+                        .aload(0)\n+                        .astore(1024) \/\/ LVT wide index\n+                        .aload(1024)\n+                        .iconst_1()  \/\/ push a litte further down\n+                        .invokestatic(InlineOops.class, \"doGc\", \"()V\", false) \/\/ Stack,LVT\n+                        .pop()\n+                        .areturn();\n+                    });\n+            Person person = (Person) moveValueThroughStackAndLvt.invokeExact(createDefaultPerson());\n+            validateDefaultPerson(person);\n+            doGc();\n+\n+            int index = 4711;\n+            person = (Person) moveValueThroughStackAndLvt.invokeExact(createIndexedPerson(index));\n+            validateIndexedPerson(person, index);\n+            doGc();\n+            person = createDefaultPerson();\n+            doGc();\n+        }\n+        catch (Throwable t) { fail(\"testOverGc\", t); }\n+    }\n+\n+    static void submitNewWork(ForkJoinPool fjPool, int size) {\n+        for (int i = 0; i < size; i++) {\n+            for (int j = 0; j < 100; j++) {\n+                fjPool.execute(InlineOops::testValues);\n+            }\n+        }\n+    }\n+\n+    static void sleepNoThrow(long ms) {\n+        try {\n+            Thread.sleep(ms);\n+        }\n+        catch (Throwable t) {}\n+    }\n+\n+    \/**\n+     * Run some workloads with different object\/value life times...\n+     *\/\n+    public static void testActiveGc() {\n+        try {\n+            int nofThreads = 7;\n+            int workSize = nofThreads * 10;\n+\n+            Object longLivedObjects = createLongLived();\n+            Object longLivedPeople = createPeople();\n+\n+            Object medLivedObjects = createLongLived();\n+            Object medLivedPeople = createPeople();\n+\n+            doGc();\n+\n+            ForkJoinPool fjPool = new ForkJoinPool(nofThreads, ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true);\n+\n+            \/\/ submit work until we see some GC\n+            Reference ref = createRef();\n+            submitNewWork(fjPool, workSize);\n+            while (ref.get() != null) {\n+                if (fjPool.hasQueuedSubmissions()) {\n+                    sleepNoThrow(1L);\n+                }\n+                else {\n+                    workSize *= 2; \/\/ Grow the submission size\n+                    submitNewWork(fjPool, workSize);\n+                }\n+            }\n+\n+            \/\/ Keep working and actively GC, until MIN_ACTIVE_GC_COUNT\n+            int nofActiveGc = 1;\n+            ref = createRef();\n+            while (nofActiveGc < MIN_ACTIVE_GC_COUNT) {\n+                if (ref.get() == null) {\n+                    nofActiveGc++;\n+                    ref = createRef();\n+                    if (nofActiveGc % MED_ACTIVE_GC_COUNT == 0) {\n+                        validateLongLived(medLivedObjects);\n+                        validatePeople(medLivedPeople);\n+\n+                        medLivedObjects = createLongLived();\n+                        medLivedPeople = createPeople();\n+                    }\n+                }\n+                else if (fjPool.hasQueuedSubmissions()) {\n+                    sleepNoThrow((long) Utils.getRandomInstance().nextInt(1000));\n+                    doGc();\n+                }\n+                else {\n+                    submitNewWork(fjPool, workSize);\n+                }\n+            }\n+            fjPool.shutdown();\n+\n+            validateLongLived(medLivedObjects);\n+            validatePeople(medLivedPeople);\n+            medLivedObjects = null;\n+            medLivedPeople = null;\n+\n+            validateLongLived(longLivedObjects);\n+            validatePeople(longLivedPeople);\n+\n+            longLivedObjects = null;\n+            longLivedPeople = null;\n+\n+            doGc();\n+        }\n+        catch (Throwable t) { fail(\"testActiveGc\", t); }\n+    }\n+\n+    static final ReferenceQueue<Object> REFQ = new ReferenceQueue<>();\n+\n+    public static void doGc() {\n+        \/\/ Create Reference, wait until it clears...\n+        Reference ref = createRef();\n+        while (ref.get() != null) {\n+            System.gc();\n+        }\n+    }\n+\n+    static Reference createRef() {\n+        return new WeakReference<Object>(new Object(), REFQ);\n+    }\n+\n+    static void validatePerson(Person person, int id, String fn, String ln, boolean equals) {\n+        assertTrue(person.id == id);\n+        if (equals) {\n+            assertTrue(fn.equals(person.getFirstName()), \"Invalid field firstName\");\n+            assertTrue(ln.equals(person.getLastName()), \"Invalid  field lastName\");\n+        }\n+        else {\n+            assertTrue(person.getFirstName() == fn, \"Invalid field firstName\");\n+            assertTrue(person.getLastName() == ln, \"Invalid  field lastName\");\n+        }\n+    }\n+\n+    static Person createIndexedPerson(int i) {\n+        return Person.create(i, firstName(i), lastName(i));\n+    }\n+\n+    static void validateIndexedPerson(Person person, int i) {\n+        validatePerson(person, i, firstName(i), lastName(i), true);\n+    }\n+\n+    static Person createDefaultPerson() {\n+        return Person.create(0, null, null);\n+    }\n+\n+    static void validateDefaultPerson(Person person) {\n+        validatePerson(person, 0, null, null, false);\n+    }\n+\n+    static String firstName(int i) {\n+        return \"FirstName-\" + i;\n+    }\n+\n+    static String lastName(int i) {\n+        return \"LastName-\" + i;\n+    }\n+\n+    static Object createLongLived()  throws Throwable {\n+        Object[] population = new Object[1];\n+        population[0] = createPeople();\n+        return population;\n+    }\n+\n+    static void validateLongLived(Object pop) throws Throwable {\n+        Object[] population = (Object[]) pop;\n+        validatePeople(population[0]);\n+    }\n+\n+    static Object createPeople() {\n+        int arrayLength = NOF_PEOPLE;\n+        Person[] people = new Person[arrayLength];\n+        for (int i = 0; i < arrayLength; i++) {\n+            people[i] = createIndexedPerson(i);\n+        }\n+        return people;\n+    }\n+\n+    static void validatePeople(Object array) {\n+        Person[] people = (Person[]) array;\n+        int arrayLength = people.length;\n+        assertTrue(arrayLength == NOF_PEOPLE);\n+        for (int i = 0; i < arrayLength; i++) {\n+            validateIndexedPerson(people[i], i);\n+        }\n+    }\n+\n+    \/\/ Various field layouts...sanity testing, see MVTCombo testing for full-set\n+\n+    static final primitive class ObjectValue {\n+        final Object object;\n+\n+        private ObjectValue(Object obj) {\n+            object = obj;\n+        }\n+    }\n+\n+    static class ObjectWithObjectValue {\n+        ObjectValue value1;\n+        Object      ref1;\n+    }\n+\n+    static class ObjectWithObjectValues {\n+        ObjectValue value1;\n+        ObjectValue value2;\n+        Object      ref1;\n+    }\n+\n+    static class Foo {\n+        int id;\n+        String name;\n+        String description;\n+        long timestamp;\n+        String notes;\n+    }\n+\n+    static class Bar extends Foo {\n+        long extendedId;\n+        String moreNotes;\n+        int count;\n+        String otherStuff;\n+    }\n+\n+    public static final primitive class FooValue {\n+        public final int id;\n+        public final String name;\n+        public final String description;\n+        public final long timestamp;\n+        public final String notes;\n+\n+        private FooValue() {\n+            id          = 0;\n+            name        = null;\n+            description = null;\n+            timestamp   = 0L;\n+            notes       = null;\n+        }\n+\n+        public static FooValue create(int id, String name, String description, long timestamp, String notes) {\n+            FooValue f = FooValue.default;\n+            f = __WithField(f.id, id);\n+            f = __WithField(f.name, name);\n+            f = __WithField(f.description, description);\n+            f = __WithField(f.timestamp, timestamp);\n+            f = __WithField(f.notes, notes);\n+            return f;\n+        }\n+\n+        public static void testFrameOopsDefault(Object[][] oopMaps) {\n+            MethodType mt = MethodType.methodType(Void.TYPE, oopMaps.getClass());\n+            int oopMapsSlot   = 0;\n+            int vtSlot        = 1;\n+\n+            \/\/ Slots 1=oopMaps\n+            \/\/ OopMap Q=RRR (.name .description .someNotes)\n+            try {\n+                InstructionHelper.loadCode(\n+                        LOOKUP, \"exerciseVBytecodeExprStackWithDefault\", mt,\n+                        CODE->{\n+                            CODE\n+                            .defaultvalue(FooValue.class)\n+                            .aload(oopMapsSlot)\n+                            .iconst_0()  \/\/ Test-D0 Slots=R Stack=Q(RRR)RV\n+                            .invokestatic(InlineOops.class, GET_OOP_MAP_NAME, GET_OOP_MAP_DESC, false)\n+                            .aastore()\n+                            .pop()\n+                            .aload(oopMapsSlot)\n+                            .iconst_1()  \/\/ Test-D1 Slots=R Stack=RV\n+                            .invokestatic(InlineOops.class, GET_OOP_MAP_NAME, GET_OOP_MAP_DESC, false)\n+                            .aastore()\n+                            .defaultvalue(FooValue.class)\n+                            .astore(vtSlot)\n+                            .aload(oopMapsSlot)\n+                            .iconst_2()  \/\/ Test-D2 Slots=RQ(RRR) Stack=RV\n+                            .invokestatic(InlineOops.class, GET_OOP_MAP_NAME, GET_OOP_MAP_DESC, false)\n+                            .aastore()\n+                            .aload(vtSlot)\n+                            .aconst_null()\n+                            .astore(vtSlot) \/\/ Storing null over the Q slot won't remove the ref, but should be single null ref\n+                            .aload(oopMapsSlot)\n+                            .iconst_3()  \/\/ Test-D3 Slots=R Stack=Q(RRR)RV\n+                            .invokestatic(InlineOops.class, GET_OOP_MAP_NAME, GET_OOP_MAP_DESC, false)\n+                            .aastore()\n+                            .pop()\n+                            .return_();\n+                        }).invoke(oopMaps);\n+            } catch (Throwable t) { fail(\"exerciseVBytecodeExprStackWithDefault\", t); }\n+        }\n+\n+        public static void testFrameOopsRefs(String name, String description, String notes, Object[][] oopMaps) {\n+            FooValue f = create(4711, name, description, 9876543231L, notes);\n+            FooValue[] fa = new FooValue[] { f };\n+            MethodType mt = MethodType.methodType(Void.TYPE, fa.getClass(), oopMaps.getClass());\n+            int fooArraySlot  = 0;\n+            int oopMapsSlot   = 1;\n+            try {\n+                InstructionHelper.loadCode(LOOKUP, \"exerciseVBytecodeExprStackWithRefs\", mt,\n+                        CODE->{\n+                            CODE\n+                            .aload(fooArraySlot)\n+                            .iconst_0()\n+                            .aaload()\n+                            .aload(oopMapsSlot)\n+                            .iconst_0()  \/\/ Test-R0 Slots=RR Stack=Q(RRR)RV\n+                            .invokestatic(InlineOops.class, GET_OOP_MAP_NAME, GET_OOP_MAP_DESC, false)\n+                            .aastore()\n+                            .pop()\n+                            .return_();\n+                        }).invoke(fa, oopMaps);\n+            } catch (Throwable t) { fail(\"exerciseVBytecodeExprStackWithRefs\", t); }\n+        }\n+    }\n+\n+    static class BarWithValue {\n+        FooValue foo;\n+        long extendedId;\n+        String moreNotes;\n+        int count;\n+        String otherStuff;\n+    }\n+\n+    static final primitive class BarValue {\n+        final FooValue foo;\n+        final long extendedId;\n+        final String moreNotes;\n+        final int count;\n+        final String otherStuff;\n+\n+        private BarValue(FooValue f, long extId, String mNotes, int c, String other) {\n+            foo = f;\n+            extendedId = extId;\n+            moreNotes = mNotes;\n+            count = c;\n+            otherStuff = other;\n+        }\n+    }\n+\n+}\n+\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/InlineOops.java","additions":753,"deletions":0,"binary":false,"changes":753,"status":"added"},{"patch":"@@ -0,0 +1,319 @@\n+\/*\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+import java.lang.management.MemoryPoolMXBean;\n+\n+import sun.hotspot.WhiteBox;\n+import jdk.test.lib.Asserts;\n+\n+\/**\n+ * @test InlineTypeDensity\n+ * @summary Heap density test for InlineTypes\n+ * @library \/test\/lib\n+ * @compile -XDallowWithFieldOperator InlineTypeDensity.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ * @run main\/othervm -Xint -XX:FlatArrayElementMaxSize=-1 -XX:+UseCompressedOops\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions\n+ *                    -XX:+WhiteBoxAPI InlineTypeDensity\n+ * @run main\/othervm -Xint -XX:FlatArrayElementMaxSize=-1 -XX:-UseCompressedOops\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions\n+ *                    -XX:+WhiteBoxAPI InlineTypeDensity\n+ * @run main\/othervm -Xcomp -XX:FlatArrayElementMaxSize=-1\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions\n+ *                   -XX:+WhiteBoxAPI InlineTypeDensity\n+ * @run main\/othervm -Xbatch -XX:+UnlockDiagnosticVMOptions -XX:FlatArrayElementMaxSize=-1\n+ *                   -Xbootclasspath\/a:. -XX:ForceNonTearable=*\n+ *                   -XX:+WhiteBoxAPI InlineTypeDensity\n+ *\/\n+\n+public class InlineTypeDensity {\n+\n+    private static final WhiteBox WHITE_BOX = WhiteBox.getWhiteBox();\n+    private static final boolean VM_FLAG_FORCENONTEARABLE = WHITE_BOX.getStringVMFlag(\"ForceNonTearable\").equals(\"*\");\n+\n+    public InlineTypeDensity() {\n+        if (WHITE_BOX.getIntxVMFlag(\"FlatArrayElementMaxSize\") != -1) {\n+            throw new IllegalStateException(\"FlatArrayElementMaxSize should be -1\");\n+        }\n+    }\n+\n+    interface LocalDate {\n+        public int getYear();\n+        public short getMonth();\n+        public short getDay();\n+    }\n+\n+    interface LocalTime {\n+        public byte getHour();\n+        public byte getMinute();\n+        public byte getSecond();\n+        public int getNano();\n+    }\n+\n+    interface LocalDateTime extends LocalDate, LocalTime {}\n+\n+    static final primitive class LocalDateValue implements LocalDate {\n+        final int   year;\n+        final short month;\n+        final short day;\n+\n+        LocalDateValue() {\n+            year  = 0;\n+            month = 0;\n+            day   = 0;\n+        }\n+\n+        public int   getYear()  { return year; }\n+        public short getMonth() { return month; }\n+        public short getDay()   { return day; }\n+\n+        public static LocalDateValue create(int year, short month, short day) {\n+            LocalDateValue localDate = LocalDateValue.default;\n+            localDate = __WithField(localDate.year, year);\n+            localDate = __WithField(localDate.month, month);\n+            localDate = __WithField(localDate.day, day);\n+            return localDate;\n+        }\n+    }\n+\n+    static final primitive class LocalTimeValue implements LocalTime {\n+        final byte hour;\n+        final byte minute;\n+        final byte second;\n+        final int nano;\n+\n+        LocalTimeValue() {\n+            hour   = 0;\n+            minute = 0;\n+            second = 0;\n+            nano   = 0;\n+        }\n+\n+        public byte getHour()   { return hour; }\n+        public byte getMinute() { return minute; }\n+        public byte getSecond() { return second; }\n+        public int getNano()    { return nano; }\n+\n+        public static LocalTimeValue create(byte hour, byte minute, byte second, int nano) {\n+            LocalTimeValue localTime = LocalTimeValue.default;\n+            localTime = __WithField(localTime.hour, hour);\n+            localTime = __WithField(localTime.minute, minute);\n+            localTime = __WithField(localTime.second, second);\n+            localTime = __WithField(localTime.nano, nano);\n+            return localTime;\n+        }\n+    }\n+\n+    static final primitive class LocalDateTimeValue implements LocalDateTime {\n+        final LocalDateValue date;\n+        final LocalTimeValue time;\n+\n+        LocalDateTimeValue() {\n+            \/\/ Well this is a little weird...\n+            date = LocalDateValue.create(0, (short)0, (short)0);\n+            time = LocalTimeValue.create((byte)0, (byte)0, (byte)0, 0);\n+        }\n+\n+        public int   getYear()  { return date.year; }\n+        public short getMonth() { return date.month; }\n+        public short getDay()   { return date.day; }\n+\n+        public byte getHour()   { return time.hour; }\n+        public byte getMinute() { return time.minute; }\n+        public byte getSecond() { return time.second; }\n+        public int getNano()    { return time.nano; }\n+\n+        public static LocalDateTimeValue create(LocalDateValue date, LocalTimeValue time) {\n+            LocalDateTimeValue localDateTime = LocalDateTimeValue.default;\n+            localDateTime = __WithField(localDateTime.date, date);\n+            localDateTime = __WithField(localDateTime.time, time);\n+            return localDateTime;\n+        }\n+    }\n+\n+    static final class LocalDateClass implements LocalDate {\n+        final int   year;\n+        final short month;\n+        final short day;\n+\n+        LocalDateClass(int year, short month, short day) {\n+            this.year  = year;\n+            this.month = month;\n+            this.day   = day;\n+        }\n+\n+        public int   getYear()  { return year; }\n+        public short getMonth() { return month; }\n+        public short getDay()   { return day; }\n+    }\n+\n+    static final class LocalTimeClass implements LocalTime {\n+        final byte hour;\n+        final byte minute;\n+        final byte second;\n+        final int nano;\n+\n+        LocalTimeClass(byte hour, byte minute, byte second, int nano) {\n+            this.hour   = hour;\n+            this.minute = minute;\n+            this.second = second;\n+            this.nano   = nano;\n+        }\n+\n+        public byte getHour()   { return hour; }\n+        public byte getMinute() { return minute; }\n+        public byte getSecond() { return second; }\n+        public int getNano()    { return nano; }\n+    }\n+\n+    static final class LocalDateTimeClass implements LocalDateTime {\n+        final LocalDateClass date;\n+        final LocalTimeClass time;\n+\n+        LocalDateTimeClass(LocalDateClass date, LocalTimeClass time) {\n+            this.date = date;\n+            this.time = time;\n+        }\n+\n+        public LocalDateClass getDate() { return date; }\n+        public LocalTimeClass getTime() { return time; }\n+\n+        public int   getYear()  { return date.year; }\n+        public short getMonth() { return date.month; }\n+        public short getDay()   { return date.day; }\n+\n+        public byte getHour()   { return time.hour; }\n+        public byte getMinute() { return time.minute; }\n+        public byte getSecond() { return time.second; }\n+        public int getNano()    { return time.nano; }\n+    }\n+\n+    public void ensureArraySizeWin() {\n+        int arrayLength = 1000;\n+        System.out.println(\"ensureArraySizeWin for length \" + arrayLength);\n+        LocalDateTimeClass[] objectArray = new LocalDateTimeClass[arrayLength];\n+        for (int i = 0; i < arrayLength; i++) {\n+            objectArray[i] = new LocalDateTimeClass(new LocalDateClass(0, (short)0, (short)0),\n+                    new LocalTimeClass((byte)0, (byte)0, (byte)0, 0));\n+        }\n+\n+        long objectArraySize = WHITE_BOX.getObjectSize(objectArray);\n+        System.out.println(\"Empty object array size: \" + objectArraySize);\n+        objectArraySize += (arrayLength *\n+                (WHITE_BOX.getObjectSize(objectArray[0]) +\n+                        WHITE_BOX.getObjectSize(objectArray[0].getDate()) +\n+                        WHITE_BOX.getObjectSize(objectArray[0].getTime())));\n+\n+        LocalDateTimeValue[] flatArray = new LocalDateTimeValue[arrayLength];\n+        \/\/ CMH: add \"isFlatValueArray\" to WhiteBox API, to ensure we are correctly account size\n+\n+        long flatArraySize = WHITE_BOX.getObjectSize(flatArray);\n+        System.out.println(\"Object array and elements: \" + objectArraySize + \" versus Flat Array: \" + flatArraySize);\n+        Asserts.assertLessThan(flatArraySize, objectArraySize, \"Flat array accounts for more heap than object array + elements !\");\n+    }\n+\n+    static primitive class MyByte  { byte  v = 0; }\n+    static primitive class MyShort { short v = 0; }\n+    static primitive class MyInt   { int   v = 0; }\n+    static primitive class MyLong  { long  v = 0; }\n+\n+    void assertArraySameSize(Object a, Object b, int nofElements) {\n+        long aSize = WHITE_BOX.getObjectSize(a);\n+        long bSize = WHITE_BOX.getObjectSize(b);\n+        Asserts.assertEquals(aSize, bSize,\n+            a + \"(\" + aSize + \" bytes) not equivalent size \" +\n+            b + \"(\" + bSize + \" bytes)\" +\n+            (nofElements >= 0 ? \" (array of \" + nofElements + \" elements)\" : \"\"));\n+    }\n+\n+    void testByteArraySizesSame(int[] testSizes) {\n+        for (int testSize : testSizes) {\n+            byte[] ba = new byte[testSize];\n+            MyByte[] mba = new MyByte[testSize];\n+            assertArraySameSize(ba, mba, testSize);\n+        }\n+    }\n+\n+    void testShortArraySizesSame(int[] testSizes) {\n+        for (int testSize : testSizes) {\n+            short[] sa = new short[testSize];\n+            MyShort[] msa = new MyShort[testSize];\n+            assertArraySameSize(sa, msa, testSize);\n+        }\n+    }\n+\n+    void testIntArraySizesSame(int[] testSizes) {\n+        for (int testSize : testSizes) {\n+            int[] ia = new int[testSize];\n+            MyInt[] mia = new MyInt[testSize];\n+            assertArraySameSize(ia, mia, testSize);\n+        }\n+    }\n+\n+    void testLongArraySizesSame(int[] testSizes) {\n+        for (int testSize : testSizes) {\n+            long[] la = new long[testSize];\n+            MyLong[] mla = new MyLong[testSize];\n+            assertArraySameSize(la, mla, testSize);\n+        }\n+    }\n+\n+    public void testPrimitiveArraySizesSame() {\n+        int[] testSizes = new int[] { 0, 1, 2, 3, 4, 7, 10, 257 };\n+        testByteArraySizesSame(testSizes);\n+        testShortArraySizesSame(testSizes);\n+        testIntArraySizesSame(testSizes);\n+        testLongArraySizesSame(testSizes);\n+    }\n+\n+    static primitive class bbValue { byte b = 0; byte b2 = 0;}\n+    static primitive class bsValue { byte b = 0; short s = 0;}\n+    static primitive class siValue { short s = 0; int i = 0;}\n+    static primitive class ssiValue { short s = 0; short s2 = 0; int i = 0;}\n+    static primitive class blValue { byte b = 0; long l = 0; }\n+\n+    \/\/ Expect aligned array addressing to nearest pow2\n+    void testAlignedSize() {\n+        int testSize = 10;\n+        assertArraySameSize(new short[testSize], new bbValue[testSize], testSize);\n+        assertArraySameSize(new long[testSize], new siValue[testSize], testSize);\n+        assertArraySameSize(new long[testSize], new ssiValue[testSize], testSize);\n+        assertArraySameSize(new long[testSize*2], new blValue[testSize], testSize);\n+        assertArraySameSize(new int[testSize], new bsValue[testSize], testSize);\n+    }\n+\n+    public void test() {\n+        ensureArraySizeWin();\n+        testPrimitiveArraySizesSame();\n+        if (!VM_FLAG_FORCENONTEARABLE) {\n+          testAlignedSize();\n+        }\n+    }\n+\n+    public static void main(String[] args) {\n+        new InlineTypeDensity().test();\n+    }\n+\n+}\n+\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/InlineTypeDensity.java","additions":319,"deletions":0,"binary":false,"changes":319,"status":"added"},{"patch":"@@ -0,0 +1,280 @@\n+\/*\n+ * Copyright (c) 2019, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package runtime.valhalla.inlinetypes;\n+\n+import java.lang.reflect.Array;\n+import java.lang.reflect.Field;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Supplier;\n+import java.util.Optional;\n+\n+import jdk.internal.misc.Unsafe;\n+import sun.hotspot.WhiteBox;\n+import static jdk.test.lib.Asserts.*;\n+\n+\/*\n+ * @test ValueTearing\n+ * @summary Test tearing of inline fields and array elements\n+ * @modules java.base\/jdk.internal.misc\n+ * @library \/test\/lib\n+ * @compile ValueTearing.java\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller sun.hotspot.WhiteBox\n+ * @run main\/othervm -Xint  -XX:+UnlockDiagnosticVMOptions -XX:ForceNonTearable=\n+ *                   -DSTEP_COUNT=10000 -XX:InlineFieldMaxFlatSize=128 -XX:FlatArrayElementMaxSize=-1\n+ *                   -Xbootclasspath\/a:. -XX:+WhiteBoxAPI\n+ *                                   runtime.valhalla.inlinetypes.ValueTearing\n+ * @run main\/othervm -Xint  -XX:+UnlockDiagnosticVMOptions -XX:ForceNonTearable=*\n+ *                   -DSTEP_COUNT=10000 -XX:InlineFieldMaxFlatSize=128 -XX:FlatArrayElementMaxSize=-1\n+ *                   -Xbootclasspath\/a:. -XX:+WhiteBoxAPI\n+ *                                   runtime.valhalla.inlinetypes.ValueTearing\n+ * @run main\/othervm -Xbatch -DSTEP_COUNT=10000000 -XX:InlineFieldMaxFlatSize=128 -XX:FlatArrayElementMaxSize=-1\n+ *                   -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *                                   runtime.valhalla.inlinetypes.ValueTearing\n+ * @run main\/othervm -Xbatch -XX:+UnlockDiagnosticVMOptions -XX:ForceNonTearable=\n+ *                   -DTEAR_MODE=fieldonly -XX:InlineFieldMaxFlatSize=128 -XX:FlatArrayElementMaxSize=-1\n+ *                   -Xbootclasspath\/a:. -XX:+WhiteBoxAPI\n+ *                                   runtime.valhalla.inlinetypes.ValueTearing\n+ * @run main\/othervm -Xbatch -XX:+UnlockDiagnosticVMOptions -XX:ForceNonTearable=\n+ *                   -DTEAR_MODE=arrayonly -XX:InlineFieldMaxFlatSize=128 -XX:FlatArrayElementMaxSize=-1\n+ *                   -Xbootclasspath\/a:. -XX:+WhiteBoxAPI\n+ *                                   runtime.valhalla.inlinetypes.ValueTearing\n+ * @run main\/othervm -Xbatch -XX:+UnlockDiagnosticVMOptions -XX:ForceNonTearable=*\n+ *                   -DTEAR_MODE=both -XX:InlineFieldMaxFlatSize=128 -XX:FlatArrayElementMaxSize=-1\n+ *                   -Xbootclasspath\/a:. -XX:+WhiteBoxAPI\n+ *                                   runtime.valhalla.inlinetypes.ValueTearing\n+ *\/\n+public class ValueTearing {\n+    private static final Unsafe UNSAFE = Unsafe.getUnsafe();\n+    private static final WhiteBox WHITE_BOX = WhiteBox.getWhiteBox();\n+    private static final boolean USE_COMPILER = WHITE_BOX.getBooleanVMFlag(\"UseCompiler\");\n+    private static final boolean ALWAYS_ATOMIC = WHITE_BOX.getStringVMFlag(\"ForceNonTearable\").contains(\"*\");\n+    private static final String TEAR_MODE = System.getProperty(\"TEAR_MODE\", \"both\");\n+    private static final boolean TEAR_FIELD = !TEAR_MODE.equals(\"arrayonly\");\n+    private static final boolean TEAR_ARRAY = !TEAR_MODE.equals(\"fieldonly\");\n+    private static final int STEP_COUNT = Integer.getInteger(\"STEP_COUNT\", 100_000);\n+    private static final boolean TFIELD_FLAT, TARRAY_FLAT;\n+    private static final boolean NTFIELD_FLAT, NTARRAY_FLAT;\n+    static {\n+        try {\n+            Field TPB_field = TPointBox.class.getDeclaredField(\"field\");\n+            Field TPB_array = TPointBox.class.getDeclaredField(\"array\");\n+            Field NTPB_field = NTPointBox.class.getDeclaredField(\"field\");\n+            Field NTPB_array = NTPointBox.class.getDeclaredField(\"array\");\n+            TFIELD_FLAT = UNSAFE.isFlattened(TPB_field);\n+            TARRAY_FLAT = UNSAFE.isFlattenedArray(TPB_array.getType());\n+            NTFIELD_FLAT = UNSAFE.isFlattened(NTPB_field);\n+            NTARRAY_FLAT = UNSAFE.isFlattenedArray(NTPB_array.getType());\n+        } catch (ReflectiveOperationException ex) {\n+            throw new AssertionError(ex);\n+        }\n+    }\n+    private static final String SETTINGS =\n+        String.format(\"USE_COMPILER=%s ALWAYS_ATOMIC=%s TEAR_MODE=%s STEP_COUNT=%s FLAT TF\/TA=%s\/%s NTF\/NTA=%s\/%s\",\n+                      USE_COMPILER, ALWAYS_ATOMIC, TEAR_MODE, STEP_COUNT,\n+                      TFIELD_FLAT, TARRAY_FLAT, NTFIELD_FLAT, NTARRAY_FLAT);\n+    private static final String NOTE_TORN_POINT = \"Note: torn point\";\n+\n+    public static void main(String[] args) throws Exception {\n+        System.out.println(SETTINGS);\n+        ValueTearing valueTearing = new ValueTearing();\n+        valueTearing.run();\n+        \/\/ Extra representation check:\n+        assert(!NTFIELD_FLAT) : \"NT field must be indirect not flat\";\n+        assert(!NTARRAY_FLAT) : \"NT array must be indirect not flat\";\n+        if (ALWAYS_ATOMIC) {\n+            assert(!TFIELD_FLAT) : \"field must be indirect not flat\";\n+            assert(!TARRAY_FLAT) : \"array must be indirect not flat\";\n+        }\n+    }\n+\n+    \/\/ A normally tearable inline value.\n+    static primitive class TPoint {\n+        TPoint(long x, long y) { this.x = x; this.y = y; }\n+        final long x, y;\n+        public String toString() { return String.format(\"(%d,%d)\", x, y); }\n+    }\n+\n+    static class TooTearable extends AssertionError {\n+        final Object badPoint;\n+        TooTearable(String msg, Object badPoint) {\n+            super(msg);\n+            this.badPoint = badPoint;\n+        }\n+    }\n+\n+    interface PointBox {\n+        void step();    \/\/ mutate inline value state\n+        void check();   \/\/ check sanity of inline value state\n+    }\n+\n+    class TPointBox implements PointBox {\n+        TPoint field;\n+        TPoint[] array = new TPoint[1];\n+        \/\/ Step the points forward by incrementing their components\n+        \/\/ \"simultaneously\".  A racing thread will catch flaws in the\n+        \/\/ simultaneity.\n+        TPoint step(TPoint p) {\n+            return new TPoint(p.x + 1, p.y + 1);\n+        }\n+        public @Override\n+        void step() {\n+            if (TEAR_FIELD) {\n+                field = step(field);\n+            }\n+            if (TEAR_ARRAY) {\n+                array[0] = step(array[0]);\n+            }\n+            check();\n+        }\n+        \/\/ Invariant:  The components of each point are \"always\" equal.\n+        \/\/ As long as simultaneity is preserved, this is true.\n+        public @Override\n+        void check() {\n+            if (TEAR_FIELD) {\n+                check(field, \"field\");\n+            }\n+            if (TEAR_ARRAY) {\n+                check(array[0], \"array element\");\n+            }\n+        }\n+        void check(TPoint p, String where) {\n+            if (p.x == p.y)  return;\n+            String msg = String.format(\"%s %s in %s; settings = %s\",\n+                                       NOTE_TORN_POINT,\n+                                       p, where, SETTINGS);\n+            throw new TooTearable(msg, p);\n+        }\n+        public String toString() {\n+            return String.format(\"TPB[%s, {%s}]\", field, array[0]);\n+        }\n+    }\n+\n+    \/\/ Add an indirection, as an extra test.\n+    interface NT extends NonTearable { }\n+\n+    \/\/ A hardened, non-tearable version of TPoint.\n+    static primitive class NTPoint implements NT {\n+        NTPoint(long x, long y) { this.x = x; this.y = y; }\n+        final long x, y;\n+        public String toString() { return String.format(\"(%d,%d)\", x, y); }\n+    }\n+\n+    class NTPointBox implements PointBox {\n+        NTPoint field;\n+        NTPoint[] array = new NTPoint[1];\n+        \/\/ Step the points forward by incrementing their components\n+        \/\/ \"simultaneously\".  A racing thread will catch flaws in the\n+        \/\/ simultaneity.\n+        NTPoint step(NTPoint p) {\n+            return new NTPoint(p.x + 1, p.y + 1);\n+        }\n+        public @Override\n+        void step() {\n+            field = step(field);\n+            array[0] = step(array[0]);\n+            check();\n+        }\n+        \/\/ Invariant:  The components of each point are \"always\" equal.\n+        public @Override\n+        void check() {\n+            check(field, \"field\");\n+            check(array[0], \"array element\");\n+        }\n+        void check(NTPoint p, String where) {\n+            if (p.x == p.y)  return;\n+            String msg = String.format(\"%s *NonTearable* %s in %s; settings = %s\",\n+                                       NOTE_TORN_POINT,\n+                                       p, where, SETTINGS);\n+            throw new TooTearable(msg, p);\n+        }\n+        public String toString() {\n+            return String.format(\"NTPB[%s, {%s}]\", field, array[0]);\n+        }\n+    }\n+\n+    class AsyncObserver extends Thread {\n+        volatile boolean done;\n+        long observationCount;\n+        final PointBox pointBox;\n+        volatile Object badPointObserved;\n+        AsyncObserver(PointBox pointBox) {\n+            this.pointBox = pointBox;\n+        }\n+        public void run() {\n+            try {\n+                while (!done) {\n+                    observationCount++;\n+                    pointBox.check();\n+                }\n+            } catch (TooTearable ex) {\n+                done = true;\n+                badPointObserved = ex.badPoint;\n+                System.out.println(ex);\n+                if (ALWAYS_ATOMIC || ex.badPoint instanceof NonTearable) {\n+                    throw ex;\n+                }\n+            }\n+        }\n+    }\n+\n+    public void run() throws Exception {\n+        System.out.println(\"Test for tearing of NTPoint, which must not happen...\");\n+        run(new NTPointBox(), false);\n+        System.out.println(\"Test for tearing of TPoint, which \"+\n+                           (ALWAYS_ATOMIC ? \"must not\" : \"is allowed to\")+\n+                           \" happen...\");\n+        run(new TPointBox(), ALWAYS_ATOMIC ? false : true);\n+    }\n+    public void run(PointBox pointBox, boolean canTear) throws Exception {\n+        var observer = new AsyncObserver(pointBox);\n+        observer.start();\n+        for (int i = 0; i < STEP_COUNT; i++) {\n+            pointBox.step();\n+            if (observer.done)  break;\n+        }\n+        observer.done = true;\n+        observer.join();\n+        var obCount = observer.observationCount;\n+        var badPoint = observer.badPointObserved;\n+        System.out.println(String.format(\"finished after %d observations at %s; %s\",\n+                                         obCount, pointBox,\n+                                         (badPoint == null\n+                                          ? \"no tearing observed\"\n+                                          : \"bad point = \" + badPoint)));\n+        if (canTear && badPoint == null) {\n+            var complain = String.format(\"%s NOT observed after %d observations\",\n+                                         NOTE_TORN_POINT, obCount);\n+            System.out.println(\"?????? \"+complain);\n+            if (STEP_COUNT >= 3_000_000) {\n+                \/\/ If it's a small count, OK, but if it's big the test is broken.\n+                throw new AssertionError(complain + \", but it should have been\");\n+            }\n+        }\n+        if (!canTear && badPoint != null) {\n+            throw new AssertionError(\"should not reach here; other thread must throw\");\n+        }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/runtime\/valhalla\/inlinetypes\/ValueTearing.java","additions":280,"deletions":0,"binary":false,"changes":280,"status":"added"},{"patch":"@@ -104,33 +104,0 @@\n- * @run main\/othervm\/native\n- *                  -agentlib:IterateHeapWithEscapeAnalysisEnabled\n- *                  -XX:+UnlockDiagnosticVMOptions\n- *                  -Xms256m -Xmx256m\n- *                  -XX:CompileCommand=dontinline,*::dontinline_*\n- *                  -XX:+PrintCompilation\n- *                  -XX:+PrintInlining\n- *                  -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n- *                  -Xbatch\n- *                  -XX:+DoEscapeAnalysis -XX:+EliminateAllocations -XX:+EliminateLocks -XX:+EliminateNestedLocks -XX:+UseBiasedLocking\n- *                  IterateHeapWithEscapeAnalysisEnabled\n- * @run main\/othervm\/native\n- *                  -agentlib:IterateHeapWithEscapeAnalysisEnabled\n- *                  -XX:+UnlockDiagnosticVMOptions\n- *                  -Xms256m -Xmx256m\n- *                  -XX:CompileCommand=dontinline,*::dontinline_*\n- *                  -XX:+PrintCompilation\n- *                  -XX:+PrintInlining\n- *                  -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n- *                  -Xbatch\n- *                  -XX:+DoEscapeAnalysis -XX:-EliminateAllocations -XX:+EliminateLocks -XX:+EliminateNestedLocks -XX:+UseBiasedLocking\n- *                  IterateHeapWithEscapeAnalysisEnabled\n- * @run main\/othervm\/native\n- *                  -agentlib:IterateHeapWithEscapeAnalysisEnabled\n- *                  -XX:+UnlockDiagnosticVMOptions\n- *                  -Xms256m -Xmx256m\n- *                  -XX:CompileCommand=dontinline,*::dontinline_*\n- *                  -XX:+PrintCompilation\n- *                  -XX:+PrintInlining\n- *                  -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n- *                  -Xbatch\n- *                  -XX:-DoEscapeAnalysis -XX:-EliminateAllocations -XX:+EliminateLocks -XX:+EliminateNestedLocks -XX:+UseBiasedLocking\n- *                  IterateHeapWithEscapeAnalysisEnabled\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/Heap\/IterateHeapWithEscapeAnalysisEnabled.java","additions":0,"deletions":33,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -42,32 +42,0 @@\n- *                 -XX:+WhiteBoxAPI\n- *                 -Xbatch\n- *                 -XX:+DoEscapeAnalysis -XX:+EliminateAllocations -XX:+EliminateLocks -XX:+EliminateNestedLocks -XX:+UseBiasedLocking\n- * @run driver EATests\n- *                 -XX:+UnlockDiagnosticVMOptions\n- *                 -Xms256m -Xmx256m\n- *                 -Xbootclasspath\/a:.\n- *                 -XX:CompileCommand=dontinline,*::dontinline_*\n- *                 -XX:+WhiteBoxAPI\n- *                 -Xbatch\n- *                 -XX:+DoEscapeAnalysis -XX:+EliminateAllocations -XX:-EliminateLocks -XX:+EliminateNestedLocks -XX:+UseBiasedLocking -XX:-UseOptoBiasInlining\n- * @run driver EATests\n- *                 -XX:+UnlockDiagnosticVMOptions\n- *                 -Xms256m -Xmx256m\n- *                 -Xbootclasspath\/a:.\n- *                 -XX:CompileCommand=dontinline,*::dontinline_*\n- *                 -XX:+WhiteBoxAPI\n- *                 -Xbatch\n- *                 -XX:+DoEscapeAnalysis -XX:-EliminateAllocations -XX:+EliminateLocks -XX:+EliminateNestedLocks -XX:+UseBiasedLocking\n- * @run driver EATests\n- *                 -XX:+UnlockDiagnosticVMOptions\n- *                 -Xms256m -Xmx256m\n- *                 -Xbootclasspath\/a:.\n- *                 -XX:CompileCommand=dontinline,*::dontinline_*\n- *                 -XX:+WhiteBoxAPI\n- *                 -Xbatch\n- *                 -XX:-DoEscapeAnalysis -XX:-EliminateAllocations -XX:+EliminateLocks -XX:+EliminateNestedLocks -XX:+UseBiasedLocking\n- * @run driver EATests\n- *                 -XX:+UnlockDiagnosticVMOptions\n- *                 -Xms256m -Xmx256m\n- *                 -Xbootclasspath\/a:.\n- *                 -XX:CompileCommand=dontinline,*::dontinline_*\n","filename":"test\/jdk\/com\/sun\/jdi\/EATests.java","additions":0,"deletions":32,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -318,0 +318,1 @@\n+        vmOptFinalFlag(map, \"TieredCompilation\");\n@@ -366,0 +367,3 @@\n+        if (WB.getBooleanVMFlag(\"EnableValhalla\").booleanValue()) {\n+            return \"false\";\n+        }\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -151,0 +151,14 @@\n+  private native Object[] getObjectsViaKlassOopMaps0(Object thing);\n+  public Object[] getObjectsViaKlassOopMaps(Object thing) {\n+    Objects.requireNonNull(thing);\n+    return getObjectsViaKlassOopMaps0(thing);\n+  }\n+\n+  private native Object[] getObjectsViaOopIterator0(Object thing);\n+  public Object[] getObjectsViaOopIterator(Object thing) {\n+    Objects.requireNonNull(thing);\n+    return getObjectsViaOopIterator0(thing);\n+  }\n+\n+  public native Object[] getObjectsViaFrameOopIterator(int depth);\n+\n","filename":"test\/lib\/sun\/hotspot\/WhiteBox.java","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"}]}