{"files":[{"patch":"@@ -3641,1 +3641,1 @@\n-      call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &cbuf);\n+      call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type));\n@@ -3650,1 +3650,1 @@\n-      call = __ trampoline_call(Address(addr, rspec), &cbuf);\n+      call = __ trampoline_call(Address(addr, rspec));\n@@ -3658,1 +3658,1 @@\n-        cbuf.shared_stub_to_interp_for(_method, cbuf.insts()->mark_off());\n+        cbuf.shared_stub_to_interp_for(_method, call - cbuf.insts_begin());\n@@ -3661,1 +3661,1 @@\n-        address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);\n+        address stub = CompiledStaticCall::emit_to_interp_stub(cbuf, call);\n@@ -3669,1 +3669,0 @@\n-    _masm.clear_inst_mark();\n@@ -3749,1 +3748,0 @@\n-      _masm.clear_inst_mark();\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -399,1 +399,1 @@\n-  __ far_call(RuntimeAddress(Runtime1::entry_for(_stub)), NULL, rscratch2);\n+  __ far_call(RuntimeAddress(Runtime1::entry_for(_stub)), rscratch2);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_CodeStubs_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -416,1 +416,1 @@\n-  assert(_cb->frame_size() >= 0, \"must have non-zero frame size\");\n+  assert(_cb->frame_size() > 0, \"must have non-zero frame size\");\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -102,1 +102,2 @@\n-                                                 Register tmp,\n+                                                 Register tmp1,\n+                                                 Register tmp2,\n@@ -114,2 +115,2 @@\n-  assert_different_registers(obj, pre_val, tmp, rscratch1);\n-  assert(pre_val != noreg &&  tmp != noreg, \"expecting a register\");\n+  assert_different_registers(obj, pre_val, tmp1, tmp2);\n+  assert(pre_val != noreg && tmp1 != noreg && tmp2 != noreg, \"expecting a register\");\n@@ -123,1 +124,1 @@\n-    __ ldrw(tmp, in_progress);\n+    __ ldrw(tmp1, in_progress);\n@@ -126,1 +127,1 @@\n-    __ ldrb(tmp, in_progress);\n+    __ ldrb(tmp1, in_progress);\n@@ -128,1 +129,1 @@\n-  __ cbzw(tmp, done);\n+  __ cbzw(tmp1, done);\n@@ -142,2 +143,2 @@\n-  __ ldr(tmp, index);                      \/\/ tmp := *index_adr\n-  __ cbz(tmp, runtime);                    \/\/ tmp == 0?\n+  __ ldr(tmp1, index);                      \/\/ tmp := *index_adr\n+  __ cbz(tmp1, runtime);                    \/\/ tmp == 0?\n@@ -146,4 +147,4 @@\n-  __ sub(tmp, tmp, wordSize);              \/\/ tmp := tmp - wordSize\n-  __ str(tmp, index);                      \/\/ *index_adr := tmp\n-  __ ldr(rscratch1, buffer);\n-  __ add(tmp, tmp, rscratch1);             \/\/ tmp := tmp + *buffer_adr\n+  __ sub(tmp1, tmp1, wordSize);             \/\/ tmp := tmp - wordSize\n+  __ str(tmp1, index);                      \/\/ *index_adr := tmp\n+  __ ldr(tmp2, buffer);\n+  __ add(tmp1, tmp1, tmp2);                 \/\/ tmp := tmp + *buffer_adr\n@@ -152,1 +153,1 @@\n-  __ str(pre_val, Address(tmp, 0));\n+  __ str(pre_val, Address(tmp1, 0));\n@@ -213,1 +214,1 @@\n-                                                  Register tmp,\n+                                                  Register tmp1,\n@@ -216,2 +217,3 @@\n-  assert_different_registers(store_addr, new_val, thread, tmp, rscratch1);\n-  assert(store_addr != noreg && new_val != noreg && tmp != noreg\n+  assert_different_registers(store_addr, new_val, thread, tmp1, tmp2,\n+                             rscratch1);\n+  assert(store_addr != noreg && new_val != noreg && tmp1 != noreg\n@@ -232,3 +234,3 @@\n-  __ eor(tmp, store_addr, new_val);\n-  __ lsr(tmp, tmp, HeapRegion::LogOfHRGrainBytes);\n-  __ cbz(tmp, done);\n+  __ eor(tmp1, store_addr, new_val);\n+  __ lsr(tmp1, tmp1, HeapRegion::LogOfHRGrainBytes);\n+  __ cbz(tmp1, done);\n@@ -242,1 +244,1 @@\n-  assert_different_registers(store_addr, thread, tmp, tmp2, rscratch1);\n+  assert_different_registers(store_addr, thread, tmp1, tmp2, rscratch1);\n@@ -244,1 +246,1 @@\n-  const Register card_addr = tmp;\n+  const Register card_addr = tmp1;\n@@ -303,1 +305,1 @@\n-                                    Register dst, Address src, Register tmp1, Register tmp_thread) {\n+                                    Register dst, Address src, Register tmp1, Register tmp2) {\n@@ -308,1 +310,1 @@\n-  ModRefBarrierSetAssembler::load_at(masm, decorators, type, dst, src, tmp1, tmp_thread);\n+  ModRefBarrierSetAssembler::load_at(masm, decorators, type, dst, src, tmp1, tmp2);\n@@ -318,1 +320,2 @@\n-                         tmp1 \/* tmp *\/,\n+                         tmp1 \/* tmp1 *\/,\n+                         tmp2 \/* tmp2 *\/,\n@@ -351,1 +354,2 @@\n-                         tmp1  \/* tmp *\/,\n+                         tmp1  \/* tmp1 *\/,\n+                         rscratch2  \/* tmp2 *\/,\n@@ -369,1 +373,0 @@\n-\n@@ -375,1 +378,1 @@\n-                            tmp1 \/* tmp *\/,\n+                            tmp1 \/* tmp1 *\/,\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1BarrierSetAssembler_aarch64.cpp","additions":30,"deletions":27,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -43,1 +43,1 @@\n-                                  Register dst, Address src, Register tmp1, Register tmp_thread) {\n+                                  Register dst, Address src, Register tmp1, Register tmp2) {\n@@ -318,1 +318,1 @@\n-  __ stp(r10, r11, Address(__ pre(sp, -2 * wordSize)));\n+  __ push(RegSet::of(r10), sp);\n@@ -321,2 +321,1 @@\n-  \/\/ Uses rscratch1 & rscratch2, so we must pass new temporaries.\n-  __ resolve_weak_handle(r10, r11);\n+  __ resolve_weak_handle(r10, rscratch1, rscratch2);\n@@ -324,1 +323,1 @@\n-  __ ldp(r10, r11, Address(__ post(sp, 2 * wordSize)));\n+  __ pop(RegSet::of(r10), sp);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-                       Register dst, Address src, Register tmp1, Register tmp_thread);\n+                       Register dst, Address src, Register tmp1, Register tmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -345,1 +345,1 @@\n-  resolve_oop_handle(result, tmp);\n+  resolve_oop_handle(result, tmp, rscratch2);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -690,1 +690,1 @@\n-void MacroAssembler::far_call(Address entry, CodeBuffer *cbuf, Register tmp) {\n+void MacroAssembler::far_call(Address entry, Register tmp) {\n@@ -703,1 +703,0 @@\n-    if (cbuf) cbuf->set_insts_mark();\n@@ -706,1 +705,0 @@\n-    if (cbuf) cbuf->set_insts_mark();\n@@ -711,1 +709,1 @@\n-int MacroAssembler::far_jump(Address entry, CodeBuffer *cbuf, Register tmp) {\n+int MacroAssembler::far_jump(Address entry, Register tmp) {\n@@ -725,1 +723,0 @@\n-    if (cbuf) cbuf->set_insts_mark();\n@@ -728,1 +725,0 @@\n-    if (cbuf) cbuf->set_insts_mark();\n@@ -888,1 +884,1 @@\n-address MacroAssembler::trampoline_call(Address entry, CodeBuffer* cbuf) {\n+address MacroAssembler::trampoline_call(Address entry) {\n@@ -914,1 +910,1 @@\n-  if (cbuf) cbuf->set_insts_mark();\n+  address call_pc = pc();\n@@ -918,2 +914,1 @@\n-  \/\/ just need to return a non-null address\n-  return pc();\n+  return call_pc;\n@@ -1139,1 +1134,1 @@\n-  resolve_oop_handle(obj, inline_klass);\n+  resolve_oop_handle(obj, inline_klass, temp_reg);\n@@ -2645,1 +2640,1 @@\n-void MacroAssembler::resolve_jobject(Register value, Register thread, Register tmp) {\n+void MacroAssembler::resolve_jobject(Register value, Register tmp1, Register tmp2) {\n@@ -2654,1 +2649,1 @@\n-                 Address(value, -JNIHandles::weak_tag_value), tmp, thread);\n+                 Address(value, -JNIHandles::weak_tag_value), tmp1, tmp2);\n@@ -2660,1 +2655,1 @@\n-  access_load_at(T_OBJECT, IN_NATIVE, value, Address(value, 0), tmp, thread);\n+  access_load_at(T_OBJECT, IN_NATIVE, value, Address(value, 0), tmp1, tmp2);\n@@ -4230,1 +4225,1 @@\n-void MacroAssembler::resolve_oop_handle(Register result, Register tmp) {\n+void MacroAssembler::resolve_oop_handle(Register result, Register tmp1, Register tmp2) {\n@@ -4232,1 +4227,1 @@\n-  access_load_at(T_OBJECT, IN_NATIVE, result, Address(result, 0), tmp, noreg);\n+  access_load_at(T_OBJECT, IN_NATIVE, result, Address(result, 0), tmp1, tmp2);\n@@ -4236,2 +4231,2 @@\n-void MacroAssembler::resolve_weak_handle(Register rresult, Register rtmp) {\n-  assert_different_registers(rresult, rtmp);\n+void MacroAssembler::resolve_weak_handle(Register result, Register tmp1, Register tmp2) {\n+  assert_different_registers(result, tmp1, tmp2);\n@@ -4241,1 +4236,1 @@\n-  cbz(rresult, resolved);\n+  cbz(result, resolved);\n@@ -4244,1 +4239,0 @@\n-  \/\/ Only IN_HEAP loads require a thread_tmp register\n@@ -4247,1 +4241,1 @@\n-                 rresult, Address(rresult), rtmp, \/*tmp_thread*\/noreg);\n+                 result, Address(result), tmp1, tmp2);\n@@ -4251,1 +4245,1 @@\n-void MacroAssembler::load_mirror(Register dst, Register method, Register tmp) {\n+void MacroAssembler::load_mirror(Register dst, Register method, Register tmp1, Register tmp2) {\n@@ -4257,1 +4251,1 @@\n-  resolve_oop_handle(dst, tmp);\n+  resolve_oop_handle(dst, tmp1, tmp2);\n@@ -4584,1 +4578,1 @@\n-                                    Register tmp1, Register thread_tmp) {\n+                                    Register tmp1, Register tmp2) {\n@@ -4589,1 +4583,1 @@\n-    bs->BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);\n+    bs->BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, tmp2);\n@@ -4591,1 +4585,1 @@\n-    bs->load_at(this, decorators, type, dst, src, tmp1, thread_tmp);\n+    bs->load_at(this, decorators, type, dst, src, tmp1, tmp2);\n@@ -4649,2 +4643,2 @@\n-                                   Register thread_tmp, DecoratorSet decorators) {\n-  access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);\n+                                   Register tmp2, DecoratorSet decorators) {\n+  access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2);\n@@ -4654,2 +4648,2 @@\n-                                            Register thread_tmp, DecoratorSet decorators) {\n-  access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);\n+                                            Register tmp2, DecoratorSet decorators) {\n+  access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, tmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":24,"deletions":30,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -869,1 +869,1 @@\n-  void resolve_jobject(Register value, Register thread, Register tmp);\n+  void resolve_jobject(Register value, Register tmp1, Register tmp2);\n@@ -884,3 +884,3 @@\n-  void resolve_weak_handle(Register result, Register tmp);\n-  void resolve_oop_handle(Register result, Register tmp = r5);\n-  void load_mirror(Register dst, Register method, Register tmp = r5);\n+  void resolve_weak_handle(Register result, Register tmp1, Register tmp2);\n+  void resolve_oop_handle(Register result, Register tmp1, Register tmp2);\n+  void load_mirror(Register dst, Register method, Register tmp1, Register tmp2);\n@@ -889,1 +889,1 @@\n-                      Register tmp1, Register tmp_thread);\n+                      Register tmp1, Register tmp2);\n@@ -904,1 +904,1 @@\n-                     Register thread_tmp = noreg, DecoratorSet decorators = 0);\n+                     Register tmp2 = noreg, DecoratorSet decorators = 0);\n@@ -907,1 +907,1 @@\n-                              Register thread_tmp = noreg, DecoratorSet decorators = 0);\n+                              Register tmp2 = noreg, DecoratorSet decorators = 0);\n@@ -1242,2 +1242,2 @@\n-  \/\/ Return: NULL if CodeCache is full.\n-  address trampoline_call(Address entry, CodeBuffer* cbuf = NULL);\n+  \/\/ Return: the call PC or NULL if CodeCache is full.\n+  address trampoline_call(Address entry);\n@@ -1265,2 +1265,2 @@\n-  void far_call(Address entry, CodeBuffer *cbuf = NULL, Register tmp = rscratch1);\n-  int far_jump(Address entry, CodeBuffer *cbuf = NULL, Register tmp = rscratch1);\n+  void far_call(Address entry, Register tmp = rscratch1);\n+  int far_jump(Address entry, Register tmp = rscratch1);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -1343,2 +1344,1 @@\n-    address mark = __ pc();\n-    __ trampoline_call(resolve);\n+    const address tr_call = __ trampoline_call(resolve);\n@@ -1352,1 +1352,1 @@\n-    CompiledStaticCall::emit_to_interp_stub(*cbuf, mark);\n+    CompiledStaticCall::emit_to_interp_stub(*cbuf, tr_call);\n@@ -1368,2 +1368,1 @@\n-  address mark = __ pc();\n-  __ trampoline_call(resolve);\n+  const address tr_call = __ trampoline_call(resolve);\n@@ -1411,1 +1410,1 @@\n-  CompiledStaticCall::emit_to_interp_stub(*cbuf, mark);\n+  CompiledStaticCall::emit_to_interp_stub(*cbuf, tr_call);\n@@ -1418,1 +1417,0 @@\n-                                   int& exception_offset,\n@@ -1422,1 +1420,0 @@\n-                                   int& interpreted_entry_offset,\n@@ -1555,5 +1552,4 @@\n-    int vep_offset = 0;\n-    int exception_offset = 0;\n-    int frame_complete = 0;\n-    int stack_slots = 0;\n-    OopMapSet* oop_maps =  new OopMapSet();\n+    int exception_offset = -1;\n+    OopMapSet* oop_maps = new OopMapSet();\n+    int frame_complete = -1;\n+    int stack_slots = -1;\n@@ -1561,0 +1557,1 @@\n+    int vep_offset = -1;\n@@ -1577,1 +1574,0 @@\n-                             exception_offset,\n@@ -1581,1 +1577,0 @@\n-                             interpreted_entry_offset,\n@@ -1586,0 +1581,14 @@\n+\n+#ifdef ASSERT\n+    if (method->is_continuation_enter_intrinsic()) {\n+      assert(interpreted_entry_offset != -1, \"Must be set\");\n+      assert(exception_offset != -1,         \"Must be set\");\n+    } else {\n+      assert(interpreted_entry_offset == -1, \"Must be unset\");\n+      assert(exception_offset == -1,         \"Must be unset\");\n+    }\n+    assert(frame_complete != -1,    \"Must be set\");\n+    assert(stack_slots != -1,       \"Must be set\");\n+    assert(vep_offset != -1,        \"Must be set\");\n+#endif\n+\n@@ -2083,1 +2092,3 @@\n-  __ dmb(Assembler::ISH);\n+  if (!UseSystemMemoryBarrier) {\n+    __ dmb(Assembler::ISH);\n+  }\n@@ -2181,1 +2192,1 @@\n-    __ resolve_jobject(r0, rthread, rscratch2);\n+    __ resolve_jobject(r0, r1, r2);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":28,"deletions":17,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -6807,1 +6807,1 @@\n-  static void jfr_epilogue(MacroAssembler* _masm, Register thread) {\n+  static void jfr_epilogue(MacroAssembler* _masm) {\n@@ -6813,1 +6813,1 @@\n-    bs->load_at(_masm, decorators, T_OBJECT, r0, Address(r0, 0), c_rarg0, thread);\n+    bs->load_at(_masm, decorators, T_OBJECT, r0, Address(r0, 0), rscratch1, rscratch2);\n@@ -6842,1 +6842,1 @@\n-    jfr_epilogue(_masm, rthread);\n+    jfr_epilogue(_masm);\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -758,1 +759,1 @@\n-    __ load_mirror(r0, rmethod);\n+    __ load_mirror(r0, rmethod, r5, rscratch2);\n@@ -834,1 +835,1 @@\n-  __ load_mirror(r10, rmethod);\n+  __ load_mirror(r10, rmethod, r5, rscratch2);\n@@ -904,1 +905,1 @@\n-  bs->load_at(_masm, IN_HEAP | ON_WEAK_OOP_REF, T_OBJECT, local_0, field_address, \/*tmp1*\/ rscratch2, \/*tmp2*\/ rscratch1);\n+  bs->load_at(_masm, IN_HEAP | ON_WEAK_OOP_REF, T_OBJECT, local_0, field_address, \/*tmp1*\/ rscratch1, \/*tmp2*\/ rscratch2);\n@@ -1276,1 +1277,1 @@\n-    __ load_mirror(t, rmethod);\n+    __ load_mirror(t, rmethod, r10, rscratch2);\n@@ -1353,1 +1354,3 @@\n-  __ dmb(Assembler::ISH);\n+  if (!UseSystemMemoryBarrier) {\n+    __ dmb(Assembler::ISH);\n+  }\n@@ -1412,1 +1415,1 @@\n-    __ resolve_jobject(r0, rthread, t);\n+    __ resolve_jobject(r0, t, rscratch2);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":9,"deletions":6,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -149,1 +149,1 @@\n-  __ store_heap_oop(dst, val, r10, r1, r3, decorators);\n+  __ store_heap_oop(dst, val, r10, r11, r3, decorators);\n@@ -156,1 +156,1 @@\n-  __ load_heap_oop(dst, src, r10, r1, decorators);\n+  __ load_heap_oop(dst, src, r10, r11, decorators);\n@@ -416,1 +416,1 @@\n-    __ resolve_oop_handle(tmp);\n+    __ resolve_oop_handle(tmp, r5, rscratch2);\n@@ -2446,1 +2446,1 @@\n-    __ resolve_oop_handle(obj);\n+    __ resolve_oop_handle(obj, r5, rscratch2);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -399,1 +399,1 @@\n-  assert(_cb->frame_size() >= 0, \"must have non-zero frame size\");\n+  assert(_cb->frame_size() > 0, \"must have non-zero frame size\");\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1016,14 +1016,0 @@\n-  void gfmul(XMMRegister tmp0, XMMRegister t);\n-  void schoolbookAAD(int i, Register subkeyH, XMMRegister data, XMMRegister tmp0,\n-                     XMMRegister tmp1, XMMRegister tmp2, XMMRegister tmp3);\n-  void generateHtbl_one_block(Register htbl);\n-  void generateHtbl_eight_blocks(Register htbl);\n- public:\n-  void sha256_AVX2(XMMRegister msg, XMMRegister state0, XMMRegister state1, XMMRegister msgtmp0,\n-                   XMMRegister msgtmp1, XMMRegister msgtmp2, XMMRegister msgtmp3, XMMRegister msgtmp4,\n-                   Register buf, Register state, Register ofs, Register limit, Register rsp,\n-                   bool multi_block, XMMRegister shuf_mask);\n-  void avx_ghash(Register state, Register htbl, Register data, Register blocks);\n-#endif\n-#ifdef _LP64\n- private:\n@@ -1040,0 +1026,4 @@\n+  void sha256_AVX2(XMMRegister msg, XMMRegister state0, XMMRegister state1, XMMRegister msgtmp0,\n+                   XMMRegister msgtmp1, XMMRegister msgtmp2, XMMRegister msgtmp3, XMMRegister msgtmp4,\n+                   Register buf, Register state, Register ofs, Register limit, Register rsp,\n+                   bool multi_block, XMMRegister shuf_mask);\n@@ -1044,21 +1034,1 @@\n-private:\n-  void roundEnc(XMMRegister key, int rnum);\n-  void lastroundEnc(XMMRegister key, int rnum);\n-  void roundDec(XMMRegister key, int rnum);\n-  void lastroundDec(XMMRegister key, int rnum);\n-  void ev_load_key(XMMRegister xmmdst, Register key, int offset, XMMRegister xmm_shuf_mask);\n-  void gfmul_avx512(XMMRegister ghash, XMMRegister hkey);\n-  void generateHtbl_48_block_zmm(Register htbl, Register avx512_subkeyHtbl);\n-  void ghash16_encrypt16_parallel(Register key, Register subkeyHtbl, XMMRegister ctr_blockx,\n-                                  XMMRegister aad_hashx, Register in, Register out, Register data, Register pos, bool reduction,\n-                                  XMMRegister addmask, bool no_ghash_input, Register rounds, Register ghash_pos,\n-                                  bool final_reduction, int index, XMMRegister counter_inc_mask);\n-public:\n-  void aesecb_encrypt(Register source_addr, Register dest_addr, Register key, Register len);\n-  void aesecb_decrypt(Register source_addr, Register dest_addr, Register key, Register len);\n-  void aesctr_encrypt(Register src_addr, Register dest_addr, Register key, Register counter,\n-                      Register len_reg, Register used, Register used_addr, Register saved_encCounter_start);\n-  void aesgcm_encrypt(Register in, Register len, Register ct, Register out, Register key,\n-                      Register state, Register subkeyHtbl, Register avx512_subkeyHtbl, Register counter);\n-\n-#endif\n+#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":5,"deletions":35,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -52,0 +52,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -1725,1 +1726,0 @@\n-                                   int& exception_offset,\n@@ -1729,1 +1729,0 @@\n-                                   int& interpreted_entry_offset,\n@@ -1863,4 +1862,1 @@\n-    int vep_offset = 0;\n-    int exception_offset = 0;\n-    int frame_complete = 0;\n-    int stack_slots = 0;\n+    int exception_offset = -1;\n@@ -1868,0 +1864,2 @@\n+    int frame_complete = -1;\n+    int stack_slots = -1;\n@@ -1869,0 +1867,1 @@\n+    int vep_offset = -1;\n@@ -1881,1 +1880,0 @@\n-                             exception_offset,\n@@ -1885,1 +1883,0 @@\n-                             interpreted_entry_offset,\n@@ -1890,0 +1887,14 @@\n+\n+#ifdef ASSERT\n+    if (method->is_continuation_enter_intrinsic()) {\n+      assert(interpreted_entry_offset != -1, \"Must be set\");\n+      assert(exception_offset != -1,         \"Must be set\");\n+    } else {\n+      assert(interpreted_entry_offset == -1, \"Must be unset\");\n+      assert(exception_offset == -1,         \"Must be unset\");\n+    }\n+    assert(frame_complete != -1,    \"Must be set\");\n+    assert(stack_slots != -1,       \"Must be set\");\n+    assert(vep_offset != -1,        \"Must be set\");\n+#endif\n+\n@@ -2403,1 +2414,2 @@\n-  __ membar(Assembler::Membar_mask_bits(\n+  if (!UseSystemMemoryBarrier) {\n+    __ membar(Assembler::Membar_mask_bits(\n@@ -2406,0 +2418,1 @@\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":22,"deletions":9,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -1280,677 +1280,0 @@\n-\/\/ AES intrinsic stubs\n-\n-address StubGenerator::generate_key_shuffle_mask() {\n-  __ align(16);\n-  StubCodeMark mark(this, \"StubRoutines\", \"key_shuffle_mask\");\n-  address start = __ pc();\n-\n-  __ emit_data64( 0x0405060700010203, relocInfo::none );\n-  __ emit_data64( 0x0c0d0e0f08090a0b, relocInfo::none );\n-\n-  return start;\n-}\n-\n-address StubGenerator::generate_counter_shuffle_mask() {\n-  __ align(16);\n-  StubCodeMark mark(this, \"StubRoutines\", \"counter_shuffle_mask\");\n-  address start = __ pc();\n-\n-  __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);\n-  __ emit_data64(0x0001020304050607, relocInfo::none);\n-\n-  return start;\n-}\n-\n-\/\/ Utility routine for loading a 128-bit key word in little endian format\n-\/\/ can optionally specify that the shuffle mask is already in an xmmregister\n-void StubGenerator::load_key(XMMRegister xmmdst, Register key, int offset, XMMRegister xmm_shuf_mask) {\n-  __ movdqu(xmmdst, Address(key, offset));\n-  if (xmm_shuf_mask != xnoreg) {\n-    __ pshufb(xmmdst, xmm_shuf_mask);\n-  } else {\n-    __ pshufb(xmmdst, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()));\n-  }\n-}\n-\n-\/\/ Utility routine for increase 128bit counter (iv in CTR mode)\n-void StubGenerator::inc_counter(Register reg, XMMRegister xmmdst, int inc_delta, Label& next_block) {\n-  __ pextrq(reg, xmmdst, 0x0);\n-  __ addq(reg, inc_delta);\n-  __ pinsrq(xmmdst, reg, 0x0);\n-  __ jcc(Assembler::carryClear, next_block); \/\/ jump if no carry\n-  __ pextrq(reg, xmmdst, 0x01); \/\/ Carry\n-  __ addq(reg, 0x01);\n-  __ pinsrq(xmmdst, reg, 0x01); \/\/Carry end\n-  __ BIND(next_block);          \/\/ next instruction\n-}\n-\n-\/\/ Arguments:\n-\/\/\n-\/\/ Inputs:\n-\/\/   c_rarg0   - source byte array address\n-\/\/   c_rarg1   - destination byte array address\n-\/\/   c_rarg2   - K (key) in little endian int array\n-\/\/\n-address StubGenerator::generate_aescrypt_encryptBlock() {\n-  assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"aescrypt_encryptBlock\");\n-  Label L_doLast;\n-  address start = __ pc();\n-\n-  const Register from        = c_rarg0;  \/\/ source array address\n-  const Register to          = c_rarg1;  \/\/ destination array address\n-  const Register key         = c_rarg2;  \/\/ key array address\n-  const Register keylen      = rax;\n-\n-  const XMMRegister xmm_result = xmm0;\n-  const XMMRegister xmm_key_shuf_mask = xmm1;\n-  \/\/ On win64 xmm6-xmm15 must be preserved so don't use them.\n-  const XMMRegister xmm_temp1  = xmm2;\n-  const XMMRegister xmm_temp2  = xmm3;\n-  const XMMRegister xmm_temp3  = xmm4;\n-  const XMMRegister xmm_temp4  = xmm5;\n-\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-  \/\/ keylen could be only {11, 13, 15} * 4 = {44, 52, 60}\n-  __ movl(keylen, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-\n-  __ movdqu(xmm_key_shuf_mask, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()));\n-  __ movdqu(xmm_result, Address(from, 0));  \/\/ get 16 bytes of input\n-\n-  \/\/ For encryption, the java expanded key ordering is just what we need\n-  \/\/ we don't know if the key is aligned, hence not using load-execute form\n-\n-  load_key(xmm_temp1, key, 0x00, xmm_key_shuf_mask);\n-  __ pxor(xmm_result, xmm_temp1);\n-\n-  load_key(xmm_temp1, key, 0x10, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0x20, xmm_key_shuf_mask);\n-  load_key(xmm_temp3, key, 0x30, xmm_key_shuf_mask);\n-  load_key(xmm_temp4, key, 0x40, xmm_key_shuf_mask);\n-\n-  __ aesenc(xmm_result, xmm_temp1);\n-  __ aesenc(xmm_result, xmm_temp2);\n-  __ aesenc(xmm_result, xmm_temp3);\n-  __ aesenc(xmm_result, xmm_temp4);\n-\n-  load_key(xmm_temp1, key, 0x50, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0x60, xmm_key_shuf_mask);\n-  load_key(xmm_temp3, key, 0x70, xmm_key_shuf_mask);\n-  load_key(xmm_temp4, key, 0x80, xmm_key_shuf_mask);\n-\n-  __ aesenc(xmm_result, xmm_temp1);\n-  __ aesenc(xmm_result, xmm_temp2);\n-  __ aesenc(xmm_result, xmm_temp3);\n-  __ aesenc(xmm_result, xmm_temp4);\n-\n-  load_key(xmm_temp1, key, 0x90, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0xa0, xmm_key_shuf_mask);\n-\n-  __ cmpl(keylen, 44);\n-  __ jccb(Assembler::equal, L_doLast);\n-\n-  __ aesenc(xmm_result, xmm_temp1);\n-  __ aesenc(xmm_result, xmm_temp2);\n-\n-  load_key(xmm_temp1, key, 0xb0, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0xc0, xmm_key_shuf_mask);\n-\n-  __ cmpl(keylen, 52);\n-  __ jccb(Assembler::equal, L_doLast);\n-\n-  __ aesenc(xmm_result, xmm_temp1);\n-  __ aesenc(xmm_result, xmm_temp2);\n-\n-  load_key(xmm_temp1, key, 0xd0, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0xe0, xmm_key_shuf_mask);\n-\n-  __ BIND(L_doLast);\n-  __ aesenc(xmm_result, xmm_temp1);\n-  __ aesenclast(xmm_result, xmm_temp2);\n-  __ movdqu(Address(to, 0), xmm_result);        \/\/ store the result\n-  __ xorptr(rax, rax); \/\/ return 0\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n-\n-\/\/ Arguments:\n-\/\/\n-\/\/ Inputs:\n-\/\/   c_rarg0   - source byte array address\n-\/\/   c_rarg1   - destination byte array address\n-\/\/   c_rarg2   - K (key) in little endian int array\n-\/\/\n-address StubGenerator::generate_aescrypt_decryptBlock() {\n-  assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"aescrypt_decryptBlock\");\n-  Label L_doLast;\n-  address start = __ pc();\n-\n-  const Register from        = c_rarg0;  \/\/ source array address\n-  const Register to          = c_rarg1;  \/\/ destination array address\n-  const Register key         = c_rarg2;  \/\/ key array address\n-  const Register keylen      = rax;\n-\n-  const XMMRegister xmm_result = xmm0;\n-  const XMMRegister xmm_key_shuf_mask = xmm1;\n-  \/\/ On win64 xmm6-xmm15 must be preserved so don't use them.\n-  const XMMRegister xmm_temp1  = xmm2;\n-  const XMMRegister xmm_temp2  = xmm3;\n-  const XMMRegister xmm_temp3  = xmm4;\n-  const XMMRegister xmm_temp4  = xmm5;\n-\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-  \/\/ keylen could be only {11, 13, 15} * 4 = {44, 52, 60}\n-  __ movl(keylen, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-\n-  __ movdqu(xmm_key_shuf_mask, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()));\n-  __ movdqu(xmm_result, Address(from, 0));\n-\n-  \/\/ for decryption java expanded key ordering is rotated one position from what we want\n-  \/\/ so we start from 0x10 here and hit 0x00 last\n-  \/\/ we don't know if the key is aligned, hence not using load-execute form\n-  load_key(xmm_temp1, key, 0x10, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0x20, xmm_key_shuf_mask);\n-  load_key(xmm_temp3, key, 0x30, xmm_key_shuf_mask);\n-  load_key(xmm_temp4, key, 0x40, xmm_key_shuf_mask);\n-\n-  __ pxor  (xmm_result, xmm_temp1);\n-  __ aesdec(xmm_result, xmm_temp2);\n-  __ aesdec(xmm_result, xmm_temp3);\n-  __ aesdec(xmm_result, xmm_temp4);\n-\n-  load_key(xmm_temp1, key, 0x50, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0x60, xmm_key_shuf_mask);\n-  load_key(xmm_temp3, key, 0x70, xmm_key_shuf_mask);\n-  load_key(xmm_temp4, key, 0x80, xmm_key_shuf_mask);\n-\n-  __ aesdec(xmm_result, xmm_temp1);\n-  __ aesdec(xmm_result, xmm_temp2);\n-  __ aesdec(xmm_result, xmm_temp3);\n-  __ aesdec(xmm_result, xmm_temp4);\n-\n-  load_key(xmm_temp1, key, 0x90, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0xa0, xmm_key_shuf_mask);\n-  load_key(xmm_temp3, key, 0x00, xmm_key_shuf_mask);\n-\n-  __ cmpl(keylen, 44);\n-  __ jccb(Assembler::equal, L_doLast);\n-\n-  __ aesdec(xmm_result, xmm_temp1);\n-  __ aesdec(xmm_result, xmm_temp2);\n-\n-  load_key(xmm_temp1, key, 0xb0, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0xc0, xmm_key_shuf_mask);\n-\n-  __ cmpl(keylen, 52);\n-  __ jccb(Assembler::equal, L_doLast);\n-\n-  __ aesdec(xmm_result, xmm_temp1);\n-  __ aesdec(xmm_result, xmm_temp2);\n-\n-  load_key(xmm_temp1, key, 0xd0, xmm_key_shuf_mask);\n-  load_key(xmm_temp2, key, 0xe0, xmm_key_shuf_mask);\n-\n-  __ BIND(L_doLast);\n-  __ aesdec(xmm_result, xmm_temp1);\n-  __ aesdec(xmm_result, xmm_temp2);\n-\n-  \/\/ for decryption the aesdeclast operation is always on key+0x00\n-  __ aesdeclast(xmm_result, xmm_temp3);\n-  __ movdqu(Address(to, 0), xmm_result);  \/\/ store the result\n-  __ xorptr(rax, rax); \/\/ return 0\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n-\n-\/\/ Arguments:\n-\/\/\n-\/\/ Inputs:\n-\/\/   c_rarg0   - source byte array address\n-\/\/   c_rarg1   - destination byte array address\n-\/\/   c_rarg2   - K (key) in little endian int array\n-\/\/   c_rarg3   - r vector byte array address\n-\/\/   c_rarg4   - input length\n-\/\/\n-\/\/ Output:\n-\/\/   rax       - input length\n-\/\/\n-address StubGenerator::generate_cipherBlockChaining_encryptAESCrypt() {\n-  assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"cipherBlockChaining_encryptAESCrypt\");\n-  address start = __ pc();\n-\n-  Label L_exit, L_key_192_256, L_key_256, L_loopTop_128, L_loopTop_192, L_loopTop_256;\n-  const Register from        = c_rarg0;  \/\/ source array address\n-  const Register to          = c_rarg1;  \/\/ destination array address\n-  const Register key         = c_rarg2;  \/\/ key array address\n-  const Register rvec        = c_rarg3;  \/\/ r byte array initialized from initvector array address\n-                                         \/\/ and left with the results of the last encryption block\n-#ifndef _WIN64\n-  const Register len_reg     = c_rarg4;  \/\/ src len (must be multiple of blocksize 16)\n-#else\n-  const Address  len_mem(rbp, 6 * wordSize);  \/\/ length is on stack on Win64\n-  const Register len_reg     = r11;      \/\/ pick the volatile windows register\n-#endif\n-  const Register pos         = rax;\n-\n-  \/\/ xmm register assignments for the loops below\n-  const XMMRegister xmm_result = xmm0;\n-  const XMMRegister xmm_temp   = xmm1;\n-  \/\/ keys 0-10 preloaded into xmm2-xmm12\n-  const int XMM_REG_NUM_KEY_FIRST = 2;\n-  const int XMM_REG_NUM_KEY_LAST  = 15;\n-  const XMMRegister xmm_key0   = as_XMMRegister(XMM_REG_NUM_KEY_FIRST);\n-  const XMMRegister xmm_key10  = as_XMMRegister(XMM_REG_NUM_KEY_FIRST+10);\n-  const XMMRegister xmm_key11  = as_XMMRegister(XMM_REG_NUM_KEY_FIRST+11);\n-  const XMMRegister xmm_key12  = as_XMMRegister(XMM_REG_NUM_KEY_FIRST+12);\n-  const XMMRegister xmm_key13  = as_XMMRegister(XMM_REG_NUM_KEY_FIRST+13);\n-\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-#ifdef _WIN64\n-  \/\/ on win64, fill len_reg from stack position\n-  __ movl(len_reg, len_mem);\n-#else\n-  __ push(len_reg); \/\/ Save\n-#endif\n-\n-  const XMMRegister xmm_key_shuf_mask = xmm_temp;  \/\/ used temporarily to swap key bytes up front\n-  __ movdqu(xmm_key_shuf_mask, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()));\n-  \/\/ load up xmm regs xmm2 thru xmm12 with key 0x00 - 0xa0\n-  for (int rnum = XMM_REG_NUM_KEY_FIRST, offset = 0x00; rnum <= XMM_REG_NUM_KEY_FIRST+10; rnum++) {\n-    load_key(as_XMMRegister(rnum), key, offset, xmm_key_shuf_mask);\n-    offset += 0x10;\n-  }\n-  __ movdqu(xmm_result, Address(rvec, 0x00));   \/\/ initialize xmm_result with r vec\n-\n-  \/\/ now split to different paths depending on the keylen (len in ints of AESCrypt.KLE array (52=192, or 60=256))\n-  __ movl(rax, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-  __ cmpl(rax, 44);\n-  __ jcc(Assembler::notEqual, L_key_192_256);\n-\n-  \/\/ 128 bit code follows here\n-  __ movptr(pos, 0);\n-  __ align(OptoLoopAlignment);\n-\n-  __ BIND(L_loopTop_128);\n-  __ movdqu(xmm_temp, Address(from, pos, Address::times_1, 0));   \/\/ get next 16 bytes of input\n-  __ pxor  (xmm_result, xmm_temp);               \/\/ xor with the current r vector\n-  __ pxor  (xmm_result, xmm_key0);               \/\/ do the aes rounds\n-  for (int rnum = XMM_REG_NUM_KEY_FIRST + 1; rnum <= XMM_REG_NUM_KEY_FIRST + 9; rnum++) {\n-    __ aesenc(xmm_result, as_XMMRegister(rnum));\n-  }\n-  __ aesenclast(xmm_result, xmm_key10);\n-  __ movdqu(Address(to, pos, Address::times_1, 0), xmm_result);     \/\/ store into the next 16 bytes of output\n-  \/\/ no need to store r to memory until we exit\n-  __ addptr(pos, AESBlockSize);\n-  __ subptr(len_reg, AESBlockSize);\n-  __ jcc(Assembler::notEqual, L_loopTop_128);\n-\n-  __ BIND(L_exit);\n-  __ movdqu(Address(rvec, 0), xmm_result);     \/\/ final value of r stored in rvec of CipherBlockChaining object\n-\n-#ifdef _WIN64\n-  __ movl(rax, len_mem);\n-#else\n-  __ pop(rax); \/\/ return length\n-#endif\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  __ BIND(L_key_192_256);\n-  \/\/ here rax = len in ints of AESCrypt.KLE array (52=192, or 60=256)\n-  load_key(xmm_key11, key, 0xb0, xmm_key_shuf_mask);\n-  load_key(xmm_key12, key, 0xc0, xmm_key_shuf_mask);\n-  __ cmpl(rax, 52);\n-  __ jcc(Assembler::notEqual, L_key_256);\n-\n-  \/\/ 192-bit code follows here (could be changed to use more xmm registers)\n-  __ movptr(pos, 0);\n-  __ align(OptoLoopAlignment);\n-\n-  __ BIND(L_loopTop_192);\n-  __ movdqu(xmm_temp, Address(from, pos, Address::times_1, 0));   \/\/ get next 16 bytes of input\n-  __ pxor  (xmm_result, xmm_temp);               \/\/ xor with the current r vector\n-  __ pxor  (xmm_result, xmm_key0);               \/\/ do the aes rounds\n-  for (int rnum = XMM_REG_NUM_KEY_FIRST + 1; rnum  <= XMM_REG_NUM_KEY_FIRST + 11; rnum++) {\n-    __ aesenc(xmm_result, as_XMMRegister(rnum));\n-  }\n-  __ aesenclast(xmm_result, xmm_key12);\n-  __ movdqu(Address(to, pos, Address::times_1, 0), xmm_result);     \/\/ store into the next 16 bytes of output\n-  \/\/ no need to store r to memory until we exit\n-  __ addptr(pos, AESBlockSize);\n-  __ subptr(len_reg, AESBlockSize);\n-  __ jcc(Assembler::notEqual, L_loopTop_192);\n-  __ jmp(L_exit);\n-\n-  __ BIND(L_key_256);\n-  \/\/ 256-bit code follows here (could be changed to use more xmm registers)\n-  load_key(xmm_key13, key, 0xd0, xmm_key_shuf_mask);\n-  __ movptr(pos, 0);\n-  __ align(OptoLoopAlignment);\n-\n-  __ BIND(L_loopTop_256);\n-  __ movdqu(xmm_temp, Address(from, pos, Address::times_1, 0));   \/\/ get next 16 bytes of input\n-  __ pxor  (xmm_result, xmm_temp);               \/\/ xor with the current r vector\n-  __ pxor  (xmm_result, xmm_key0);               \/\/ do the aes rounds\n-  for (int rnum = XMM_REG_NUM_KEY_FIRST + 1; rnum  <= XMM_REG_NUM_KEY_FIRST + 13; rnum++) {\n-    __ aesenc(xmm_result, as_XMMRegister(rnum));\n-  }\n-  load_key(xmm_temp, key, 0xe0);\n-  __ aesenclast(xmm_result, xmm_temp);\n-  __ movdqu(Address(to, pos, Address::times_1, 0), xmm_result);     \/\/ store into the next 16 bytes of output\n-  \/\/ no need to store r to memory until we exit\n-  __ addptr(pos, AESBlockSize);\n-  __ subptr(len_reg, AESBlockSize);\n-  __ jcc(Assembler::notEqual, L_loopTop_256);\n-  __ jmp(L_exit);\n-\n-  return start;\n-}\n-\n-\/\/ This is a version of CBC\/AES Decrypt which does 4 blocks in a loop at a time\n-\/\/ to hide instruction latency\n-\/\/\n-\/\/ Arguments:\n-\/\/\n-\/\/ Inputs:\n-\/\/   c_rarg0   - source byte array address\n-\/\/   c_rarg1   - destination byte array address\n-\/\/   c_rarg2   - K (key) in little endian int array\n-\/\/   c_rarg3   - r vector byte array address\n-\/\/   c_rarg4   - input length\n-\/\/\n-\/\/ Output:\n-\/\/   rax       - input length\n-\/\/\n-address StubGenerator::generate_cipherBlockChaining_decryptAESCrypt_Parallel() {\n-  assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"cipherBlockChaining_decryptAESCrypt\");\n-  address start = __ pc();\n-\n-  const Register from        = c_rarg0;  \/\/ source array address\n-  const Register to          = c_rarg1;  \/\/ destination array address\n-  const Register key         = c_rarg2;  \/\/ key array address\n-  const Register rvec        = c_rarg3;  \/\/ r byte array initialized from initvector array address\n-                                         \/\/ and left with the results of the last encryption block\n-#ifndef _WIN64\n-  const Register len_reg     = c_rarg4;  \/\/ src len (must be multiple of blocksize 16)\n-#else\n-  const Address  len_mem(rbp, 6 * wordSize);  \/\/ length is on stack on Win64\n-  const Register len_reg     = r11;      \/\/ pick the volatile windows register\n-#endif\n-  const Register pos         = rax;\n-\n-  const int PARALLEL_FACTOR = 4;\n-  const int ROUNDS[3] = { 10, 12, 14 }; \/\/ aes rounds for key128, key192, key256\n-\n-  Label L_exit;\n-  Label L_singleBlock_loopTopHead[3]; \/\/ 128, 192, 256\n-  Label L_singleBlock_loopTopHead2[3]; \/\/ 128, 192, 256\n-  Label L_singleBlock_loopTop[3]; \/\/ 128, 192, 256\n-  Label L_multiBlock_loopTopHead[3]; \/\/ 128, 192, 256\n-  Label L_multiBlock_loopTop[3]; \/\/ 128, 192, 256\n-\n-  \/\/ keys 0-10 preloaded into xmm5-xmm15\n-  const int XMM_REG_NUM_KEY_FIRST = 5;\n-  const int XMM_REG_NUM_KEY_LAST  = 15;\n-  const XMMRegister xmm_key_first = as_XMMRegister(XMM_REG_NUM_KEY_FIRST);\n-  const XMMRegister xmm_key_last  = as_XMMRegister(XMM_REG_NUM_KEY_LAST);\n-\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-#ifdef _WIN64\n-  \/\/ on win64, fill len_reg from stack position\n-  __ movl(len_reg, len_mem);\n-#else\n-  __ push(len_reg); \/\/ Save\n-#endif\n-  __ push(rbx);\n-  \/\/ the java expanded key ordering is rotated one position from what we want\n-  \/\/ so we start from 0x10 here and hit 0x00 last\n-  const XMMRegister xmm_key_shuf_mask = xmm1;  \/\/ used temporarily to swap key bytes up front\n-  __ movdqu(xmm_key_shuf_mask, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()));\n-  \/\/ load up xmm regs 5 thru 15 with key 0x10 - 0xa0 - 0x00\n-  for (int rnum = XMM_REG_NUM_KEY_FIRST, offset = 0x10; rnum < XMM_REG_NUM_KEY_LAST; rnum++) {\n-    load_key(as_XMMRegister(rnum), key, offset, xmm_key_shuf_mask);\n-    offset += 0x10;\n-  }\n-  load_key(xmm_key_last, key, 0x00, xmm_key_shuf_mask);\n-\n-  const XMMRegister xmm_prev_block_cipher = xmm1;  \/\/ holds cipher of previous block\n-\n-  \/\/ registers holding the four results in the parallelized loop\n-  const XMMRegister xmm_result0 = xmm0;\n-  const XMMRegister xmm_result1 = xmm2;\n-  const XMMRegister xmm_result2 = xmm3;\n-  const XMMRegister xmm_result3 = xmm4;\n-\n-  __ movdqu(xmm_prev_block_cipher, Address(rvec, 0x00));   \/\/ initialize with initial rvec\n-\n-  __ xorptr(pos, pos);\n-\n-  \/\/ now split to different paths depending on the keylen (len in ints of AESCrypt.KLE array (52=192, or 60=256))\n-  __ movl(rbx, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-  __ cmpl(rbx, 52);\n-  __ jcc(Assembler::equal, L_multiBlock_loopTopHead[1]);\n-  __ cmpl(rbx, 60);\n-  __ jcc(Assembler::equal, L_multiBlock_loopTopHead[2]);\n-\n-#define DoFour(opc, src_reg)           \\\n-__ opc(xmm_result0, src_reg);         \\\n-__ opc(xmm_result1, src_reg);         \\\n-__ opc(xmm_result2, src_reg);         \\\n-__ opc(xmm_result3, src_reg);         \\\n-\n-  for (int k = 0; k < 3; ++k) {\n-    __ BIND(L_multiBlock_loopTopHead[k]);\n-    if (k != 0) {\n-      __ cmpptr(len_reg, PARALLEL_FACTOR * AESBlockSize); \/\/ see if at least 4 blocks left\n-      __ jcc(Assembler::less, L_singleBlock_loopTopHead2[k]);\n-    }\n-    if (k == 1) {\n-      __ subptr(rsp, 6 * wordSize);\n-      __ movdqu(Address(rsp, 0), xmm15); \/\/save last_key from xmm15\n-      load_key(xmm15, key, 0xb0); \/\/ 0xb0; 192-bit key goes up to 0xc0\n-      __ movdqu(Address(rsp, 2 * wordSize), xmm15);\n-      load_key(xmm1, key, 0xc0);  \/\/ 0xc0;\n-      __ movdqu(Address(rsp, 4 * wordSize), xmm1);\n-    } else if (k == 2) {\n-      __ subptr(rsp, 10 * wordSize);\n-      __ movdqu(Address(rsp, 0), xmm15); \/\/save last_key from xmm15\n-      load_key(xmm15, key, 0xd0); \/\/ 0xd0; 256-bit key goes up to 0xe0\n-      __ movdqu(Address(rsp, 6 * wordSize), xmm15);\n-      load_key(xmm1, key, 0xe0);  \/\/ 0xe0;\n-      __ movdqu(Address(rsp, 8 * wordSize), xmm1);\n-      load_key(xmm15, key, 0xb0); \/\/ 0xb0;\n-      __ movdqu(Address(rsp, 2 * wordSize), xmm15);\n-      load_key(xmm1, key, 0xc0);  \/\/ 0xc0;\n-      __ movdqu(Address(rsp, 4 * wordSize), xmm1);\n-    }\n-    __ align(OptoLoopAlignment);\n-    __ BIND(L_multiBlock_loopTop[k]);\n-    __ cmpptr(len_reg, PARALLEL_FACTOR * AESBlockSize); \/\/ see if at least 4 blocks left\n-    __ jcc(Assembler::less, L_singleBlock_loopTopHead[k]);\n-\n-    if  (k != 0) {\n-      __ movdqu(xmm15, Address(rsp, 2 * wordSize));\n-      __ movdqu(xmm1, Address(rsp, 4 * wordSize));\n-    }\n-\n-    __ movdqu(xmm_result0, Address(from, pos, Address::times_1, 0 * AESBlockSize)); \/\/ get next 4 blocks into xmmresult registers\n-    __ movdqu(xmm_result1, Address(from, pos, Address::times_1, 1 * AESBlockSize));\n-    __ movdqu(xmm_result2, Address(from, pos, Address::times_1, 2 * AESBlockSize));\n-    __ movdqu(xmm_result3, Address(from, pos, Address::times_1, 3 * AESBlockSize));\n-\n-    DoFour(pxor, xmm_key_first);\n-    if (k == 0) {\n-      for (int rnum = 1; rnum < ROUNDS[k]; rnum++) {\n-        DoFour(aesdec, as_XMMRegister(rnum + XMM_REG_NUM_KEY_FIRST));\n-      }\n-      DoFour(aesdeclast, xmm_key_last);\n-    } else if (k == 1) {\n-      for (int rnum = 1; rnum <= ROUNDS[k]-2; rnum++) {\n-        DoFour(aesdec, as_XMMRegister(rnum + XMM_REG_NUM_KEY_FIRST));\n-      }\n-      __ movdqu(xmm_key_last, Address(rsp, 0)); \/\/ xmm15 needs to be loaded again.\n-      DoFour(aesdec, xmm1);  \/\/ key : 0xc0\n-      __ movdqu(xmm_prev_block_cipher, Address(rvec, 0x00));  \/\/ xmm1 needs to be loaded again\n-      DoFour(aesdeclast, xmm_key_last);\n-    } else if (k == 2) {\n-      for (int rnum = 1; rnum <= ROUNDS[k] - 4; rnum++) {\n-        DoFour(aesdec, as_XMMRegister(rnum + XMM_REG_NUM_KEY_FIRST));\n-      }\n-      DoFour(aesdec, xmm1);  \/\/ key : 0xc0\n-      __ movdqu(xmm15, Address(rsp, 6 * wordSize));\n-      __ movdqu(xmm1, Address(rsp, 8 * wordSize));\n-      DoFour(aesdec, xmm15);  \/\/ key : 0xd0\n-      __ movdqu(xmm_key_last, Address(rsp, 0)); \/\/ xmm15 needs to be loaded again.\n-      DoFour(aesdec, xmm1);  \/\/ key : 0xe0\n-      __ movdqu(xmm_prev_block_cipher, Address(rvec, 0x00));  \/\/ xmm1 needs to be loaded again\n-      DoFour(aesdeclast, xmm_key_last);\n-    }\n-\n-    \/\/ for each result, xor with the r vector of previous cipher block\n-    __ pxor(xmm_result0, xmm_prev_block_cipher);\n-    __ movdqu(xmm_prev_block_cipher, Address(from, pos, Address::times_1, 0 * AESBlockSize));\n-    __ pxor(xmm_result1, xmm_prev_block_cipher);\n-    __ movdqu(xmm_prev_block_cipher, Address(from, pos, Address::times_1, 1 * AESBlockSize));\n-    __ pxor(xmm_result2, xmm_prev_block_cipher);\n-    __ movdqu(xmm_prev_block_cipher, Address(from, pos, Address::times_1, 2 * AESBlockSize));\n-    __ pxor(xmm_result3, xmm_prev_block_cipher);\n-    __ movdqu(xmm_prev_block_cipher, Address(from, pos, Address::times_1, 3 * AESBlockSize));   \/\/ this will carry over to next set of blocks\n-    if (k != 0) {\n-      __ movdqu(Address(rvec, 0x00), xmm_prev_block_cipher);\n-    }\n-\n-    __ movdqu(Address(to, pos, Address::times_1, 0 * AESBlockSize), xmm_result0);     \/\/ store 4 results into the next 64 bytes of output\n-    __ movdqu(Address(to, pos, Address::times_1, 1 * AESBlockSize), xmm_result1);\n-    __ movdqu(Address(to, pos, Address::times_1, 2 * AESBlockSize), xmm_result2);\n-    __ movdqu(Address(to, pos, Address::times_1, 3 * AESBlockSize), xmm_result3);\n-\n-    __ addptr(pos, PARALLEL_FACTOR * AESBlockSize);\n-    __ subptr(len_reg, PARALLEL_FACTOR * AESBlockSize);\n-    __ jmp(L_multiBlock_loopTop[k]);\n-\n-    \/\/ registers used in the non-parallelized loops\n-    \/\/ xmm register assignments for the loops below\n-    const XMMRegister xmm_result = xmm0;\n-    const XMMRegister xmm_prev_block_cipher_save = xmm2;\n-    const XMMRegister xmm_key11 = xmm3;\n-    const XMMRegister xmm_key12 = xmm4;\n-    const XMMRegister key_tmp = xmm4;\n-\n-    __ BIND(L_singleBlock_loopTopHead[k]);\n-    if (k == 1) {\n-      __ addptr(rsp, 6 * wordSize);\n-    } else if (k == 2) {\n-      __ addptr(rsp, 10 * wordSize);\n-    }\n-    __ cmpptr(len_reg, 0); \/\/ any blocks left??\n-    __ jcc(Assembler::equal, L_exit);\n-    __ BIND(L_singleBlock_loopTopHead2[k]);\n-    if (k == 1) {\n-      load_key(xmm_key11, key, 0xb0); \/\/ 0xb0; 192-bit key goes up to 0xc0\n-      load_key(xmm_key12, key, 0xc0); \/\/ 0xc0; 192-bit key goes up to 0xc0\n-    }\n-    if (k == 2) {\n-      load_key(xmm_key11, key, 0xb0); \/\/ 0xb0; 256-bit key goes up to 0xe0\n-    }\n-    __ align(OptoLoopAlignment);\n-    __ BIND(L_singleBlock_loopTop[k]);\n-    __ movdqu(xmm_result, Address(from, pos, Address::times_1, 0)); \/\/ get next 16 bytes of cipher input\n-    __ movdqa(xmm_prev_block_cipher_save, xmm_result); \/\/ save for next r vector\n-    __ pxor(xmm_result, xmm_key_first); \/\/ do the aes dec rounds\n-    for (int rnum = 1; rnum <= 9 ; rnum++) {\n-        __ aesdec(xmm_result, as_XMMRegister(rnum + XMM_REG_NUM_KEY_FIRST));\n-    }\n-    if (k == 1) {\n-      __ aesdec(xmm_result, xmm_key11);\n-      __ aesdec(xmm_result, xmm_key12);\n-    }\n-    if (k == 2) {\n-      __ aesdec(xmm_result, xmm_key11);\n-      load_key(key_tmp, key, 0xc0);\n-      __ aesdec(xmm_result, key_tmp);\n-      load_key(key_tmp, key, 0xd0);\n-      __ aesdec(xmm_result, key_tmp);\n-      load_key(key_tmp, key, 0xe0);\n-      __ aesdec(xmm_result, key_tmp);\n-    }\n-\n-    __ aesdeclast(xmm_result, xmm_key_last); \/\/ xmm15 always came from key+0\n-    __ pxor(xmm_result, xmm_prev_block_cipher); \/\/ xor with the current r vector\n-    __ movdqu(Address(to, pos, Address::times_1, 0), xmm_result); \/\/ store into the next 16 bytes of output\n-    \/\/ no need to store r to memory until we exit\n-    __ movdqa(xmm_prev_block_cipher, xmm_prev_block_cipher_save); \/\/ set up next r vector with cipher input from this block\n-    __ addptr(pos, AESBlockSize);\n-    __ subptr(len_reg, AESBlockSize);\n-    __ jcc(Assembler::notEqual, L_singleBlock_loopTop[k]);\n-    if (k != 2) {\n-      __ jmp(L_exit);\n-    }\n-  } \/\/for 128\/192\/256\n-\n-  __ BIND(L_exit);\n-  __ movdqu(Address(rvec, 0), xmm_prev_block_cipher);     \/\/ final value of r stored in rvec of CipherBlockChaining object\n-  __ pop(rbx);\n-#ifdef _WIN64\n-  __ movl(rax, len_mem);\n-#else\n-  __ pop(rax); \/\/ return length\n-#endif\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n-address StubGenerator::generate_electronicCodeBook_encryptAESCrypt() {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"electronicCodeBook_encryptAESCrypt\");\n-  address start = __ pc();\n-\n-  const Register from = c_rarg0;  \/\/ source array address\n-  const Register to = c_rarg1;  \/\/ destination array address\n-  const Register key = c_rarg2;  \/\/ key array address\n-  const Register len = c_rarg3;  \/\/ src len (must be multiple of blocksize 16)\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ aesecb_encrypt(from, to, key, len);\n-  __ vzeroupper();\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n- }\n-\n-address StubGenerator::generate_electronicCodeBook_decryptAESCrypt() {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"electronicCodeBook_decryptAESCrypt\");\n-  address start = __ pc();\n-\n-  const Register from = c_rarg0;  \/\/ source array address\n-  const Register to = c_rarg1;  \/\/ destination array address\n-  const Register key = c_rarg2;  \/\/ key array address\n-  const Register len = c_rarg3;  \/\/ src len (must be multiple of blocksize 16)\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ aesecb_decrypt(from, to, key, len);\n-  __ vzeroupper();\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n@@ -2179,1045 +1502,0 @@\n-address StubGenerator::ghash_polynomial512_addr() {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"_ghash_poly512_addr\");\n-  address start = __ pc();\n-\n-  __ emit_data64(0x00000001C2000000, relocInfo::none); \/\/ POLY for reduction\n-  __ emit_data64(0xC200000000000000, relocInfo::none);\n-  __ emit_data64(0x00000001C2000000, relocInfo::none);\n-  __ emit_data64(0xC200000000000000, relocInfo::none);\n-  __ emit_data64(0x00000001C2000000, relocInfo::none);\n-  __ emit_data64(0xC200000000000000, relocInfo::none);\n-  __ emit_data64(0x00000001C2000000, relocInfo::none);\n-  __ emit_data64(0xC200000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000001, relocInfo::none); \/\/ POLY\n-  __ emit_data64(0xC200000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000001, relocInfo::none); \/\/ TWOONE\n-  __ emit_data64(0x0000000100000000, relocInfo::none);\n-\n-  return start;\n-}\n-\n-\/\/ Vector AES Galois Counter Mode implementation.\n-\/\/\n-\/\/ Inputs:           Windows    |   Linux\n-\/\/   in         = rcx (c_rarg0) | rsi (c_rarg0)\n-\/\/   len        = rdx (c_rarg1) | rdi (c_rarg1)\n-\/\/   ct         = r8  (c_rarg2) | rdx (c_rarg2)\n-\/\/   out        = r9  (c_rarg3) | rcx (c_rarg3)\n-\/\/   key        = r10           | r8  (c_rarg4)\n-\/\/   state      = r13           | r9  (c_rarg5)\n-\/\/   subkeyHtbl = r14           | r11\n-\/\/   counter    = rsi           | r12\n-\/\/\n-\/\/ Output:\n-\/\/   rax - number of processed bytes\n-address StubGenerator::generate_galoisCounterMode_AESCrypt() {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"galoisCounterMode_AESCrypt\");\n-  address start = __ pc();\n-\n-  const Register in = c_rarg0;\n-  const Register len = c_rarg1;\n-  const Register ct = c_rarg2;\n-  const Register out = c_rarg3;\n-  \/\/ and updated with the incremented counter in the end\n-#ifndef _WIN64\n-  const Register key = c_rarg4;\n-  const Register state = c_rarg5;\n-  const Address subkeyH_mem(rbp, 2 * wordSize);\n-  const Register subkeyHtbl = r11;\n-  const Register avx512_subkeyHtbl = r13;\n-  const Address counter_mem(rbp, 3 * wordSize);\n-  const Register counter = r12;\n-#else\n-  const Address key_mem(rbp, 6 * wordSize);\n-  const Register key = r10;\n-  const Address state_mem(rbp, 7 * wordSize);\n-  const Register state = r13;\n-  const Address subkeyH_mem(rbp, 8 * wordSize);\n-  const Register subkeyHtbl = r14;\n-  const Register avx512_subkeyHtbl = r12;\n-  const Address counter_mem(rbp, 9 * wordSize);\n-  const Register counter = rsi;\n-#endif\n-  __ enter();\n- \/\/ Save state before entering routine\n-  __ push(r12);\n-  __ push(r13);\n-  __ push(r14);\n-  __ push(r15);\n-  __ push(rbx);\n-#ifdef _WIN64\n-  \/\/ on win64, fill len_reg from stack position\n-  __ push(rsi);\n-  __ movptr(key, key_mem);\n-  __ movptr(state, state_mem);\n-#endif\n-  __ movptr(subkeyHtbl, subkeyH_mem);\n-  __ movptr(counter, counter_mem);\n-\/\/ Save rbp and rsp\n-  __ push(rbp);\n-  __ movq(rbp, rsp);\n-\/\/ Align stack\n-  __ andq(rsp, -64);\n-  __ subptr(rsp, 96 * longSize); \/\/ Create space on the stack for htbl entries\n-  __ movptr(avx512_subkeyHtbl, rsp);\n-\n-  __ aesgcm_encrypt(in, len, ct, out, key, state, subkeyHtbl, avx512_subkeyHtbl, counter);\n-  __ vzeroupper();\n-\n-  __ movq(rsp, rbp);\n-  __ pop(rbp);\n-\n-  \/\/ Restore state before leaving routine\n-#ifdef _WIN64\n-  __ pop(rsi);\n-#endif\n-  __ pop(rbx);\n-  __ pop(r15);\n-  __ pop(r14);\n-  __ pop(r13);\n-  __ pop(r12);\n-\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n-\/\/ This mask is used for incrementing counter value(linc0, linc4, etc.)\n-address StubGenerator::counter_mask_addr() {\n-  __ align64();\n-  StubCodeMark mark(this, \"StubRoutines\", \"counter_mask_addr\");\n-  address start = __ pc();\n-\n-  __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);\/\/lbswapmask\n-  __ emit_data64(0x0001020304050607, relocInfo::none);\n-  __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);\n-  __ emit_data64(0x0001020304050607, relocInfo::none);\n-  __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);\n-  __ emit_data64(0x0001020304050607, relocInfo::none);\n-  __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none);\n-  __ emit_data64(0x0001020304050607, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\/\/linc0 = counter_mask_addr+64\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000001, relocInfo::none);\/\/counter_mask_addr() + 80\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000002, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000003, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000004, relocInfo::none);\/\/linc4 = counter_mask_addr() + 128\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000004, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000004, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000004, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000008, relocInfo::none);\/\/linc8 = counter_mask_addr() + 192\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000008, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000008, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000008, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000020, relocInfo::none);\/\/linc32 = counter_mask_addr() + 256\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000020, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000020, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000020, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000010, relocInfo::none);\/\/linc16 = counter_mask_addr() + 320\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000010, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000010, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-  __ emit_data64(0x0000000000000010, relocInfo::none);\n-  __ emit_data64(0x0000000000000000, relocInfo::none);\n-\n-  return start;\n-}\n-\n- \/\/ Vector AES Counter implementation\n-address StubGenerator::generate_counterMode_VectorAESCrypt()  {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"counterMode_AESCrypt\");\n-  address start = __ pc();\n-\n-  const Register from = c_rarg0; \/\/ source array address\n-  const Register to = c_rarg1; \/\/ destination array address\n-  const Register key = c_rarg2; \/\/ key array address r8\n-  const Register counter = c_rarg3; \/\/ counter byte array initialized from counter array address\n-  \/\/ and updated with the incremented counter in the end\n-#ifndef _WIN64\n-  const Register len_reg = c_rarg4;\n-  const Register saved_encCounter_start = c_rarg5;\n-  const Register used_addr = r10;\n-  const Address  used_mem(rbp, 2 * wordSize);\n-  const Register used = r11;\n-#else\n-  const Address len_mem(rbp, 6 * wordSize); \/\/ length is on stack on Win64\n-  const Address saved_encCounter_mem(rbp, 7 * wordSize); \/\/ saved encrypted counter is on stack on Win64\n-  const Address used_mem(rbp, 8 * wordSize); \/\/ used length is on stack on Win64\n-  const Register len_reg = r10; \/\/ pick the first volatile windows register\n-  const Register saved_encCounter_start = r11;\n-  const Register used_addr = r13;\n-  const Register used = r14;\n-#endif\n-  __ enter();\n- \/\/ Save state before entering routine\n-  __ push(r12);\n-  __ push(r13);\n-  __ push(r14);\n-  __ push(r15);\n-#ifdef _WIN64\n-  \/\/ on win64, fill len_reg from stack position\n-  __ movl(len_reg, len_mem);\n-  __ movptr(saved_encCounter_start, saved_encCounter_mem);\n-  __ movptr(used_addr, used_mem);\n-  __ movl(used, Address(used_addr, 0));\n-#else\n-  __ push(len_reg); \/\/ Save\n-  __ movptr(used_addr, used_mem);\n-  __ movl(used, Address(used_addr, 0));\n-#endif\n-  __ push(rbx);\n-  __ aesctr_encrypt(from, to, key, counter, len_reg, used, used_addr, saved_encCounter_start);\n-  __ vzeroupper();\n-  \/\/ Restore state before leaving routine\n-  __ pop(rbx);\n-#ifdef _WIN64\n-  __ movl(rax, len_mem); \/\/ return length\n-#else\n-  __ pop(rax); \/\/ return length\n-#endif\n-  __ pop(r15);\n-  __ pop(r14);\n-  __ pop(r13);\n-  __ pop(r12);\n-\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n-\/\/ This is a version of CTR\/AES crypt which does 6 blocks in a loop at a time\n-\/\/ to hide instruction latency\n-\/\/\n-\/\/ Arguments:\n-\/\/\n-\/\/ Inputs:\n-\/\/   c_rarg0   - source byte array address\n-\/\/   c_rarg1   - destination byte array address\n-\/\/   c_rarg2   - K (key) in little endian int array\n-\/\/   c_rarg3   - counter vector byte array address\n-\/\/   Linux\n-\/\/     c_rarg4   -          input length\n-\/\/     c_rarg5   -          saved encryptedCounter start\n-\/\/     rbp + 6 * wordSize - saved used length\n-\/\/   Windows\n-\/\/     rbp + 6 * wordSize - input length\n-\/\/     rbp + 7 * wordSize - saved encryptedCounter start\n-\/\/     rbp + 8 * wordSize - saved used length\n-\/\/\n-\/\/ Output:\n-\/\/   rax       - input length\n-\/\/\n-address StubGenerator::generate_counterMode_AESCrypt_Parallel() {\n-  assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"counterMode_AESCrypt\");\n-  address start = __ pc();\n-\n-  const Register from = c_rarg0; \/\/ source array address\n-  const Register to = c_rarg1; \/\/ destination array address\n-  const Register key = c_rarg2; \/\/ key array address\n-  const Register counter = c_rarg3; \/\/ counter byte array initialized from counter array address\n-                                    \/\/ and updated with the incremented counter in the end\n-#ifndef _WIN64\n-  const Register len_reg = c_rarg4;\n-  const Register saved_encCounter_start = c_rarg5;\n-  const Register used_addr = r10;\n-  const Address  used_mem(rbp, 2 * wordSize);\n-  const Register used = r11;\n-#else\n-  const Address len_mem(rbp, 6 * wordSize); \/\/ length is on stack on Win64\n-  const Address saved_encCounter_mem(rbp, 7 * wordSize); \/\/ length is on stack on Win64\n-  const Address used_mem(rbp, 8 * wordSize); \/\/ length is on stack on Win64\n-  const Register len_reg = r10; \/\/ pick the first volatile windows register\n-  const Register saved_encCounter_start = r11;\n-  const Register used_addr = r13;\n-  const Register used = r14;\n-#endif\n-  const Register pos = rax;\n-\n-  const int PARALLEL_FACTOR = 6;\n-  const XMMRegister xmm_counter_shuf_mask = xmm0;\n-  const XMMRegister xmm_key_shuf_mask = xmm1; \/\/ used temporarily to swap key bytes up front\n-  const XMMRegister xmm_curr_counter = xmm2;\n-\n-  const XMMRegister xmm_key_tmp0 = xmm3;\n-  const XMMRegister xmm_key_tmp1 = xmm4;\n-\n-  \/\/ registers holding the four results in the parallelized loop\n-  const XMMRegister xmm_result0 = xmm5;\n-  const XMMRegister xmm_result1 = xmm6;\n-  const XMMRegister xmm_result2 = xmm7;\n-  const XMMRegister xmm_result3 = xmm8;\n-  const XMMRegister xmm_result4 = xmm9;\n-  const XMMRegister xmm_result5 = xmm10;\n-\n-  const XMMRegister xmm_from0 = xmm11;\n-  const XMMRegister xmm_from1 = xmm12;\n-  const XMMRegister xmm_from2 = xmm13;\n-  const XMMRegister xmm_from3 = xmm14; \/\/the last one is xmm14. we have to preserve it on WIN64.\n-  const XMMRegister xmm_from4 = xmm3; \/\/reuse xmm3~4. Because xmm_key_tmp0~1 are useless when loading input text\n-  const XMMRegister xmm_from5 = xmm4;\n-\n-  \/\/for key_128, key_192, key_256\n-  const int rounds[3] = {10, 12, 14};\n-  Label L_exit_preLoop, L_preLoop_start;\n-  Label L_multiBlock_loopTop[3];\n-  Label L_singleBlockLoopTop[3];\n-  Label L__incCounter[3][6]; \/\/for 6 blocks\n-  Label L__incCounter_single[3]; \/\/for single block, key128, key192, key256\n-  Label L_processTail_insr[3], L_processTail_4_insr[3], L_processTail_2_insr[3], L_processTail_1_insr[3], L_processTail_exit_insr[3];\n-  Label L_processTail_4_extr[3], L_processTail_2_extr[3], L_processTail_1_extr[3], L_processTail_exit_extr[3];\n-\n-  Label L_exit;\n-\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-#ifdef _WIN64\n-  \/\/ allocate spill slots for r13, r14\n-  enum {\n-      saved_r13_offset,\n-      saved_r14_offset\n-  };\n-  __ subptr(rsp, 2 * wordSize);\n-  __ movptr(Address(rsp, saved_r13_offset * wordSize), r13);\n-  __ movptr(Address(rsp, saved_r14_offset * wordSize), r14);\n-\n-  \/\/ on win64, fill len_reg from stack position\n-  __ movl(len_reg, len_mem);\n-  __ movptr(saved_encCounter_start, saved_encCounter_mem);\n-  __ movptr(used_addr, used_mem);\n-  __ movl(used, Address(used_addr, 0));\n-#else\n-  __ push(len_reg); \/\/ Save\n-  __ movptr(used_addr, used_mem);\n-  __ movl(used, Address(used_addr, 0));\n-#endif\n-\n-  __ push(rbx); \/\/ Save RBX\n-  __ movdqu(xmm_curr_counter, Address(counter, 0x00)); \/\/ initialize counter with initial counter\n-  __ movdqu(xmm_counter_shuf_mask, ExternalAddress(StubRoutines::x86::counter_shuffle_mask_addr()), pos); \/\/ pos as scratch\n-  __ pshufb(xmm_curr_counter, xmm_counter_shuf_mask); \/\/counter is shuffled\n-  __ movptr(pos, 0);\n-\n-  \/\/ Use the partially used encrpyted counter from last invocation\n-  __ BIND(L_preLoop_start);\n-  __ cmpptr(used, 16);\n-  __ jcc(Assembler::aboveEqual, L_exit_preLoop);\n-    __ cmpptr(len_reg, 0);\n-    __ jcc(Assembler::lessEqual, L_exit_preLoop);\n-    __ movb(rbx, Address(saved_encCounter_start, used));\n-    __ xorb(rbx, Address(from, pos));\n-    __ movb(Address(to, pos), rbx);\n-    __ addptr(pos, 1);\n-    __ addptr(used, 1);\n-    __ subptr(len_reg, 1);\n-\n-  __ jmp(L_preLoop_start);\n-\n-  __ BIND(L_exit_preLoop);\n-  __ movl(Address(used_addr, 0), used);\n-\n-  \/\/ key length could be only {11, 13, 15} * 4 = {44, 52, 60}\n-  __ movdqu(xmm_key_shuf_mask, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()), rbx); \/\/ rbx as scratch\n-  __ movl(rbx, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-  __ cmpl(rbx, 52);\n-  __ jcc(Assembler::equal, L_multiBlock_loopTop[1]);\n-  __ cmpl(rbx, 60);\n-  __ jcc(Assembler::equal, L_multiBlock_loopTop[2]);\n-\n-#define CTR_DoSix(opc, src_reg)                \\\n-  __ opc(xmm_result0, src_reg);              \\\n-  __ opc(xmm_result1, src_reg);              \\\n-  __ opc(xmm_result2, src_reg);              \\\n-  __ opc(xmm_result3, src_reg);              \\\n-  __ opc(xmm_result4, src_reg);              \\\n-  __ opc(xmm_result5, src_reg);\n-\n-  \/\/ k == 0 :  generate code for key_128\n-  \/\/ k == 1 :  generate code for key_192\n-  \/\/ k == 2 :  generate code for key_256\n-  for (int k = 0; k < 3; ++k) {\n-    \/\/multi blocks starts here\n-    __ align(OptoLoopAlignment);\n-    __ BIND(L_multiBlock_loopTop[k]);\n-    __ cmpptr(len_reg, PARALLEL_FACTOR * AESBlockSize); \/\/ see if at least PARALLEL_FACTOR blocks left\n-    __ jcc(Assembler::less, L_singleBlockLoopTop[k]);\n-    load_key(xmm_key_tmp0, key, 0x00, xmm_key_shuf_mask);\n-\n-    \/\/load, then increase counters\n-    CTR_DoSix(movdqa, xmm_curr_counter);\n-    inc_counter(rbx, xmm_result1, 0x01, L__incCounter[k][0]);\n-    inc_counter(rbx, xmm_result2, 0x02, L__incCounter[k][1]);\n-    inc_counter(rbx, xmm_result3, 0x03, L__incCounter[k][2]);\n-    inc_counter(rbx, xmm_result4, 0x04, L__incCounter[k][3]);\n-    inc_counter(rbx, xmm_result5,  0x05, L__incCounter[k][4]);\n-    inc_counter(rbx, xmm_curr_counter, 0x06, L__incCounter[k][5]);\n-    CTR_DoSix(pshufb, xmm_counter_shuf_mask); \/\/ after increased, shuffled counters back for PXOR\n-    CTR_DoSix(pxor, xmm_key_tmp0);   \/\/PXOR with Round 0 key\n-\n-    \/\/load two ROUND_KEYs at a time\n-    for (int i = 1; i < rounds[k]; ) {\n-      load_key(xmm_key_tmp1, key, (0x10 * i), xmm_key_shuf_mask);\n-      load_key(xmm_key_tmp0, key, (0x10 * (i+1)), xmm_key_shuf_mask);\n-      CTR_DoSix(aesenc, xmm_key_tmp1);\n-      i++;\n-      if (i != rounds[k]) {\n-        CTR_DoSix(aesenc, xmm_key_tmp0);\n-      } else {\n-        CTR_DoSix(aesenclast, xmm_key_tmp0);\n-      }\n-      i++;\n-    }\n-\n-    \/\/ get next PARALLEL_FACTOR blocks into xmm_result registers\n-    __ movdqu(xmm_from0, Address(from, pos, Address::times_1, 0 * AESBlockSize));\n-    __ movdqu(xmm_from1, Address(from, pos, Address::times_1, 1 * AESBlockSize));\n-    __ movdqu(xmm_from2, Address(from, pos, Address::times_1, 2 * AESBlockSize));\n-    __ movdqu(xmm_from3, Address(from, pos, Address::times_1, 3 * AESBlockSize));\n-    __ movdqu(xmm_from4, Address(from, pos, Address::times_1, 4 * AESBlockSize));\n-    __ movdqu(xmm_from5, Address(from, pos, Address::times_1, 5 * AESBlockSize));\n-\n-    __ pxor(xmm_result0, xmm_from0);\n-    __ pxor(xmm_result1, xmm_from1);\n-    __ pxor(xmm_result2, xmm_from2);\n-    __ pxor(xmm_result3, xmm_from3);\n-    __ pxor(xmm_result4, xmm_from4);\n-    __ pxor(xmm_result5, xmm_from5);\n-\n-    \/\/ store 6 results into the next 64 bytes of output\n-    __ movdqu(Address(to, pos, Address::times_1, 0 * AESBlockSize), xmm_result0);\n-    __ movdqu(Address(to, pos, Address::times_1, 1 * AESBlockSize), xmm_result1);\n-    __ movdqu(Address(to, pos, Address::times_1, 2 * AESBlockSize), xmm_result2);\n-    __ movdqu(Address(to, pos, Address::times_1, 3 * AESBlockSize), xmm_result3);\n-    __ movdqu(Address(to, pos, Address::times_1, 4 * AESBlockSize), xmm_result4);\n-    __ movdqu(Address(to, pos, Address::times_1, 5 * AESBlockSize), xmm_result5);\n-\n-    __ addptr(pos, PARALLEL_FACTOR * AESBlockSize); \/\/ increase the length of crypt text\n-    __ subptr(len_reg, PARALLEL_FACTOR * AESBlockSize); \/\/ decrease the remaining length\n-    __ jmp(L_multiBlock_loopTop[k]);\n-\n-    \/\/ singleBlock starts here\n-    __ align(OptoLoopAlignment);\n-    __ BIND(L_singleBlockLoopTop[k]);\n-    __ cmpptr(len_reg, 0);\n-    __ jcc(Assembler::lessEqual, L_exit);\n-    load_key(xmm_key_tmp0, key, 0x00, xmm_key_shuf_mask);\n-    __ movdqa(xmm_result0, xmm_curr_counter);\n-    inc_counter(rbx, xmm_curr_counter, 0x01, L__incCounter_single[k]);\n-    __ pshufb(xmm_result0, xmm_counter_shuf_mask);\n-    __ pxor(xmm_result0, xmm_key_tmp0);\n-    for (int i = 1; i < rounds[k]; i++) {\n-      load_key(xmm_key_tmp0, key, (0x10 * i), xmm_key_shuf_mask);\n-      __ aesenc(xmm_result0, xmm_key_tmp0);\n-    }\n-    load_key(xmm_key_tmp0, key, (rounds[k] * 0x10), xmm_key_shuf_mask);\n-    __ aesenclast(xmm_result0, xmm_key_tmp0);\n-    __ cmpptr(len_reg, AESBlockSize);\n-    __ jcc(Assembler::less, L_processTail_insr[k]);\n-      __ movdqu(xmm_from0, Address(from, pos, Address::times_1, 0 * AESBlockSize));\n-      __ pxor(xmm_result0, xmm_from0);\n-      __ movdqu(Address(to, pos, Address::times_1, 0 * AESBlockSize), xmm_result0);\n-      __ addptr(pos, AESBlockSize);\n-      __ subptr(len_reg, AESBlockSize);\n-      __ jmp(L_singleBlockLoopTop[k]);\n-    __ BIND(L_processTail_insr[k]);                               \/\/ Process the tail part of the input array\n-      __ addptr(pos, len_reg);                                    \/\/ 1. Insert bytes from src array into xmm_from0 register\n-      __ testptr(len_reg, 8);\n-      __ jcc(Assembler::zero, L_processTail_4_insr[k]);\n-        __ subptr(pos,8);\n-        __ pinsrq(xmm_from0, Address(from, pos), 0);\n-      __ BIND(L_processTail_4_insr[k]);\n-      __ testptr(len_reg, 4);\n-      __ jcc(Assembler::zero, L_processTail_2_insr[k]);\n-        __ subptr(pos,4);\n-        __ pslldq(xmm_from0, 4);\n-        __ pinsrd(xmm_from0, Address(from, pos), 0);\n-      __ BIND(L_processTail_2_insr[k]);\n-      __ testptr(len_reg, 2);\n-      __ jcc(Assembler::zero, L_processTail_1_insr[k]);\n-        __ subptr(pos, 2);\n-        __ pslldq(xmm_from0, 2);\n-        __ pinsrw(xmm_from0, Address(from, pos), 0);\n-      __ BIND(L_processTail_1_insr[k]);\n-      __ testptr(len_reg, 1);\n-      __ jcc(Assembler::zero, L_processTail_exit_insr[k]);\n-        __ subptr(pos, 1);\n-        __ pslldq(xmm_from0, 1);\n-        __ pinsrb(xmm_from0, Address(from, pos), 0);\n-      __ BIND(L_processTail_exit_insr[k]);\n-\n-      __ movdqu(Address(saved_encCounter_start, 0), xmm_result0);  \/\/ 2. Perform pxor of the encrypted counter and plaintext Bytes.\n-      __ pxor(xmm_result0, xmm_from0);                             \/\/    Also the encrypted counter is saved for next invocation.\n-\n-      __ testptr(len_reg, 8);\n-      __ jcc(Assembler::zero, L_processTail_4_extr[k]);            \/\/ 3. Extract bytes from xmm_result0 into the dest. array\n-        __ pextrq(Address(to, pos), xmm_result0, 0);\n-        __ psrldq(xmm_result0, 8);\n-        __ addptr(pos, 8);\n-      __ BIND(L_processTail_4_extr[k]);\n-      __ testptr(len_reg, 4);\n-      __ jcc(Assembler::zero, L_processTail_2_extr[k]);\n-        __ pextrd(Address(to, pos), xmm_result0, 0);\n-        __ psrldq(xmm_result0, 4);\n-        __ addptr(pos, 4);\n-      __ BIND(L_processTail_2_extr[k]);\n-      __ testptr(len_reg, 2);\n-      __ jcc(Assembler::zero, L_processTail_1_extr[k]);\n-        __ pextrw(Address(to, pos), xmm_result0, 0);\n-        __ psrldq(xmm_result0, 2);\n-        __ addptr(pos, 2);\n-      __ BIND(L_processTail_1_extr[k]);\n-      __ testptr(len_reg, 1);\n-      __ jcc(Assembler::zero, L_processTail_exit_extr[k]);\n-        __ pextrb(Address(to, pos), xmm_result0, 0);\n-\n-      __ BIND(L_processTail_exit_extr[k]);\n-      __ movl(Address(used_addr, 0), len_reg);\n-      __ jmp(L_exit);\n-  }\n-\n-  __ BIND(L_exit);\n-  __ pshufb(xmm_curr_counter, xmm_counter_shuf_mask); \/\/counter is shuffled back.\n-  __ movdqu(Address(counter, 0), xmm_curr_counter); \/\/save counter back\n-  __ pop(rbx); \/\/ pop the saved RBX.\n-#ifdef _WIN64\n-  __ movl(rax, len_mem);\n-  __ movptr(r13, Address(rsp, saved_r13_offset * wordSize));\n-  __ movptr(r14, Address(rsp, saved_r14_offset * wordSize));\n-  __ addptr(rsp, 2 * wordSize);\n-#else\n-  __ pop(rax); \/\/ return 'len'\n-#endif\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n-void StubGenerator::roundDec(XMMRegister xmm_reg) {\n-  __ vaesdec(xmm1, xmm1, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdec(xmm2, xmm2, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdec(xmm3, xmm3, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdec(xmm4, xmm4, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdec(xmm5, xmm5, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdec(xmm6, xmm6, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdec(xmm7, xmm7, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdec(xmm8, xmm8, xmm_reg, Assembler::AVX_512bit);\n-}\n-\n-void StubGenerator::roundDeclast(XMMRegister xmm_reg) {\n-  __ vaesdeclast(xmm1, xmm1, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdeclast(xmm2, xmm2, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdeclast(xmm3, xmm3, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdeclast(xmm4, xmm4, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdeclast(xmm5, xmm5, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdeclast(xmm6, xmm6, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdeclast(xmm7, xmm7, xmm_reg, Assembler::AVX_512bit);\n-  __ vaesdeclast(xmm8, xmm8, xmm_reg, Assembler::AVX_512bit);\n-}\n-\n-void StubGenerator::ev_load_key(XMMRegister xmmdst, Register key, int offset, XMMRegister xmm_shuf_mask) {\n-  __ movdqu(xmmdst, Address(key, offset));\n-  if (xmm_shuf_mask != xnoreg) {\n-    __ pshufb(xmmdst, xmm_shuf_mask);\n-  } else {\n-    __ pshufb(xmmdst, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()));\n-  }\n-  __ evshufi64x2(xmmdst, xmmdst, xmmdst, 0x0, Assembler::AVX_512bit);\n-}\n-\n-address StubGenerator::generate_cipherBlockChaining_decryptVectorAESCrypt() {\n-  assert(VM_Version::supports_avx512_vaes(), \"need AES instructions and misaligned SSE support\");\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"cipherBlockChaining_decryptAESCrypt\");\n-  address start = __ pc();\n-\n-  const Register from = c_rarg0;  \/\/ source array address\n-  const Register to = c_rarg1;  \/\/ destination array address\n-  const Register key = c_rarg2;  \/\/ key array address\n-  const Register rvec = c_rarg3;  \/\/ r byte array initialized from initvector array address\n-  \/\/ and left with the results of the last encryption block\n-#ifndef _WIN64\n-  const Register len_reg = c_rarg4;  \/\/ src len (must be multiple of blocksize 16)\n-#else\n-  const Address  len_mem(rbp, 6 * wordSize);  \/\/ length is on stack on Win64\n-  const Register len_reg = r11;      \/\/ pick the volatile windows register\n-#endif\n-\n-  Label Loop, Loop1, L_128, L_256, L_192, KEY_192, KEY_256, Loop2, Lcbc_dec_rem_loop,\n-        Lcbc_dec_rem_last, Lcbc_dec_ret, Lcbc_dec_rem, Lcbc_exit;\n-\n-  __ enter();\n-\n-#ifdef _WIN64\n-\/\/ on win64, fill len_reg from stack position\n-  __ movl(len_reg, len_mem);\n-#else\n-  __ push(len_reg); \/\/ Save\n-#endif\n-  __ push(rbx);\n-  __ vzeroupper();\n-\n-  \/\/ Temporary variable declaration for swapping key bytes\n-  const XMMRegister xmm_key_shuf_mask = xmm1;\n-  __ movdqu(xmm_key_shuf_mask, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()));\n-\n-  \/\/ Calculate number of rounds from key size: 44 for 10-rounds, 52 for 12-rounds, 60 for 14-rounds\n-  const Register rounds = rbx;\n-  __ movl(rounds, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-\n-  const XMMRegister IV = xmm0;\n-  \/\/ Load IV and broadcast value to 512-bits\n-  __ evbroadcasti64x2(IV, Address(rvec, 0), Assembler::AVX_512bit);\n-\n-  \/\/ Temporary variables for storing round keys\n-  const XMMRegister RK0 = xmm30;\n-  const XMMRegister RK1 = xmm9;\n-  const XMMRegister RK2 = xmm18;\n-  const XMMRegister RK3 = xmm19;\n-  const XMMRegister RK4 = xmm20;\n-  const XMMRegister RK5 = xmm21;\n-  const XMMRegister RK6 = xmm22;\n-  const XMMRegister RK7 = xmm23;\n-  const XMMRegister RK8 = xmm24;\n-  const XMMRegister RK9 = xmm25;\n-  const XMMRegister RK10 = xmm26;\n-\n-  \/\/ Load and shuffle key\n-  \/\/ the java expanded key ordering is rotated one position from what we want\n-  \/\/ so we start from 1*16 here and hit 0*16 last\n-  ev_load_key(RK1, key, 1 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK2, key, 2 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK3, key, 3 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK4, key, 4 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK5, key, 5 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK6, key, 6 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK7, key, 7 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK8, key, 8 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK9, key, 9 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK10, key, 10 * 16, xmm_key_shuf_mask);\n-  ev_load_key(RK0, key, 0*16, xmm_key_shuf_mask);\n-\n-  \/\/ Variables for storing source cipher text\n-  const XMMRegister S0 = xmm10;\n-  const XMMRegister S1 = xmm11;\n-  const XMMRegister S2 = xmm12;\n-  const XMMRegister S3 = xmm13;\n-  const XMMRegister S4 = xmm14;\n-  const XMMRegister S5 = xmm15;\n-  const XMMRegister S6 = xmm16;\n-  const XMMRegister S7 = xmm17;\n-\n-  \/\/ Variables for storing decrypted text\n-  const XMMRegister B0 = xmm1;\n-  const XMMRegister B1 = xmm2;\n-  const XMMRegister B2 = xmm3;\n-  const XMMRegister B3 = xmm4;\n-  const XMMRegister B4 = xmm5;\n-  const XMMRegister B5 = xmm6;\n-  const XMMRegister B6 = xmm7;\n-  const XMMRegister B7 = xmm8;\n-\n-  __ cmpl(rounds, 44);\n-  __ jcc(Assembler::greater, KEY_192);\n-  __ jmp(Loop);\n-\n-  __ BIND(KEY_192);\n-  const XMMRegister RK11 = xmm27;\n-  const XMMRegister RK12 = xmm28;\n-  ev_load_key(RK11, key, 11*16, xmm_key_shuf_mask);\n-  ev_load_key(RK12, key, 12*16, xmm_key_shuf_mask);\n-\n-  __ cmpl(rounds, 52);\n-  __ jcc(Assembler::greater, KEY_256);\n-  __ jmp(Loop);\n-\n-  __ BIND(KEY_256);\n-  const XMMRegister RK13 = xmm29;\n-  const XMMRegister RK14 = xmm31;\n-  ev_load_key(RK13, key, 13*16, xmm_key_shuf_mask);\n-  ev_load_key(RK14, key, 14*16, xmm_key_shuf_mask);\n-\n-  __ BIND(Loop);\n-  __ cmpl(len_reg, 512);\n-  __ jcc(Assembler::below, Lcbc_dec_rem);\n-  __ BIND(Loop1);\n-  __ subl(len_reg, 512);\n-  __ evmovdquq(S0, Address(from, 0 * 64), Assembler::AVX_512bit);\n-  __ evmovdquq(S1, Address(from, 1 * 64), Assembler::AVX_512bit);\n-  __ evmovdquq(S2, Address(from, 2 * 64), Assembler::AVX_512bit);\n-  __ evmovdquq(S3, Address(from, 3 * 64), Assembler::AVX_512bit);\n-  __ evmovdquq(S4, Address(from, 4 * 64), Assembler::AVX_512bit);\n-  __ evmovdquq(S5, Address(from, 5 * 64), Assembler::AVX_512bit);\n-  __ evmovdquq(S6, Address(from, 6 * 64), Assembler::AVX_512bit);\n-  __ evmovdquq(S7, Address(from, 7 * 64), Assembler::AVX_512bit);\n-  __ leaq(from, Address(from, 8 * 64));\n-\n-  __ evpxorq(B0, S0, RK1, Assembler::AVX_512bit);\n-  __ evpxorq(B1, S1, RK1, Assembler::AVX_512bit);\n-  __ evpxorq(B2, S2, RK1, Assembler::AVX_512bit);\n-  __ evpxorq(B3, S3, RK1, Assembler::AVX_512bit);\n-  __ evpxorq(B4, S4, RK1, Assembler::AVX_512bit);\n-  __ evpxorq(B5, S5, RK1, Assembler::AVX_512bit);\n-  __ evpxorq(B6, S6, RK1, Assembler::AVX_512bit);\n-  __ evpxorq(B7, S7, RK1, Assembler::AVX_512bit);\n-\n-  __ evalignq(IV, S0, IV, 0x06);\n-  __ evalignq(S0, S1, S0, 0x06);\n-  __ evalignq(S1, S2, S1, 0x06);\n-  __ evalignq(S2, S3, S2, 0x06);\n-  __ evalignq(S3, S4, S3, 0x06);\n-  __ evalignq(S4, S5, S4, 0x06);\n-  __ evalignq(S5, S6, S5, 0x06);\n-  __ evalignq(S6, S7, S6, 0x06);\n-\n-  roundDec(RK2);\n-  roundDec(RK3);\n-  roundDec(RK4);\n-  roundDec(RK5);\n-  roundDec(RK6);\n-  roundDec(RK7);\n-  roundDec(RK8);\n-  roundDec(RK9);\n-  roundDec(RK10);\n-\n-  __ cmpl(rounds, 44);\n-  __ jcc(Assembler::belowEqual, L_128);\n-  roundDec(RK11);\n-  roundDec(RK12);\n-\n-  __ cmpl(rounds, 52);\n-  __ jcc(Assembler::belowEqual, L_192);\n-  roundDec(RK13);\n-  roundDec(RK14);\n-\n-  __ BIND(L_256);\n-  roundDeclast(RK0);\n-  __ jmp(Loop2);\n-\n-  __ BIND(L_128);\n-  roundDeclast(RK0);\n-  __ jmp(Loop2);\n-\n-  __ BIND(L_192);\n-  roundDeclast(RK0);\n-\n-  __ BIND(Loop2);\n-  __ evpxorq(B0, B0, IV, Assembler::AVX_512bit);\n-  __ evpxorq(B1, B1, S0, Assembler::AVX_512bit);\n-  __ evpxorq(B2, B2, S1, Assembler::AVX_512bit);\n-  __ evpxorq(B3, B3, S2, Assembler::AVX_512bit);\n-  __ evpxorq(B4, B4, S3, Assembler::AVX_512bit);\n-  __ evpxorq(B5, B5, S4, Assembler::AVX_512bit);\n-  __ evpxorq(B6, B6, S5, Assembler::AVX_512bit);\n-  __ evpxorq(B7, B7, S6, Assembler::AVX_512bit);\n-  __ evmovdquq(IV, S7, Assembler::AVX_512bit);\n-\n-  __ evmovdquq(Address(to, 0 * 64), B0, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(to, 1 * 64), B1, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(to, 2 * 64), B2, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(to, 3 * 64), B3, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(to, 4 * 64), B4, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(to, 5 * 64), B5, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(to, 6 * 64), B6, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(to, 7 * 64), B7, Assembler::AVX_512bit);\n-  __ leaq(to, Address(to, 8 * 64));\n-  __ jmp(Loop);\n-\n-  __ BIND(Lcbc_dec_rem);\n-  __ evshufi64x2(IV, IV, IV, 0x03, Assembler::AVX_512bit);\n-\n-  __ BIND(Lcbc_dec_rem_loop);\n-  __ subl(len_reg, 16);\n-  __ jcc(Assembler::carrySet, Lcbc_dec_ret);\n-\n-  __ movdqu(S0, Address(from, 0));\n-  __ evpxorq(B0, S0, RK1, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK2, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK3, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK4, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK5, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK6, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK7, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK8, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK9, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK10, Assembler::AVX_512bit);\n-  __ cmpl(rounds, 44);\n-  __ jcc(Assembler::belowEqual, Lcbc_dec_rem_last);\n-\n-  __ vaesdec(B0, B0, RK11, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK12, Assembler::AVX_512bit);\n-  __ cmpl(rounds, 52);\n-  __ jcc(Assembler::belowEqual, Lcbc_dec_rem_last);\n-\n-  __ vaesdec(B0, B0, RK13, Assembler::AVX_512bit);\n-  __ vaesdec(B0, B0, RK14, Assembler::AVX_512bit);\n-\n-  __ BIND(Lcbc_dec_rem_last);\n-  __ vaesdeclast(B0, B0, RK0, Assembler::AVX_512bit);\n-\n-  __ evpxorq(B0, B0, IV, Assembler::AVX_512bit);\n-  __ evmovdquq(IV, S0, Assembler::AVX_512bit);\n-  __ movdqu(Address(to, 0), B0);\n-  __ leaq(from, Address(from, 16));\n-  __ leaq(to, Address(to, 16));\n-  __ jmp(Lcbc_dec_rem_loop);\n-\n-  __ BIND(Lcbc_dec_ret);\n-  __ movdqu(Address(rvec, 0), IV);\n-\n-  \/\/ Zero out the round keys\n-  __ evpxorq(RK0, RK0, RK0, Assembler::AVX_512bit);\n-  __ evpxorq(RK1, RK1, RK1, Assembler::AVX_512bit);\n-  __ evpxorq(RK2, RK2, RK2, Assembler::AVX_512bit);\n-  __ evpxorq(RK3, RK3, RK3, Assembler::AVX_512bit);\n-  __ evpxorq(RK4, RK4, RK4, Assembler::AVX_512bit);\n-  __ evpxorq(RK5, RK5, RK5, Assembler::AVX_512bit);\n-  __ evpxorq(RK6, RK6, RK6, Assembler::AVX_512bit);\n-  __ evpxorq(RK7, RK7, RK7, Assembler::AVX_512bit);\n-  __ evpxorq(RK8, RK8, RK8, Assembler::AVX_512bit);\n-  __ evpxorq(RK9, RK9, RK9, Assembler::AVX_512bit);\n-  __ evpxorq(RK10, RK10, RK10, Assembler::AVX_512bit);\n-  __ cmpl(rounds, 44);\n-  __ jcc(Assembler::belowEqual, Lcbc_exit);\n-  __ evpxorq(RK11, RK11, RK11, Assembler::AVX_512bit);\n-  __ evpxorq(RK12, RK12, RK12, Assembler::AVX_512bit);\n-  __ cmpl(rounds, 52);\n-  __ jcc(Assembler::belowEqual, Lcbc_exit);\n-  __ evpxorq(RK13, RK13, RK13, Assembler::AVX_512bit);\n-  __ evpxorq(RK14, RK14, RK14, Assembler::AVX_512bit);\n-\n-  __ BIND(Lcbc_exit);\n-  __ vzeroupper();\n-  __ pop(rbx);\n-#ifdef _WIN64\n-  __ movl(rax, len_mem);\n-#else\n-  __ pop(rax); \/\/ return length\n-#endif\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n-\/\/ Polynomial x^128+x^127+x^126+x^121+1\n-address StubGenerator::ghash_polynomial_addr() {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"_ghash_poly_addr\");\n-  address start = __ pc();\n-\n-  __ emit_data64(0x0000000000000001, relocInfo::none);\n-  __ emit_data64(0xc200000000000000, relocInfo::none);\n-\n-  return start;\n-}\n-\n-address StubGenerator::ghash_shufflemask_addr() {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"_ghash_shuffmask_addr\");\n-  address start = __ pc();\n-\n-  __ emit_data64(0x0f0f0f0f0f0f0f0f, relocInfo::none);\n-  __ emit_data64(0x0f0f0f0f0f0f0f0f, relocInfo::none);\n-\n-  return start;\n-}\n-\n-\/\/ Ghash single and multi block operations using AVX instructions\n-address StubGenerator::generate_avx_ghash_processBlocks() {\n-  __ align(CodeEntryAlignment);\n-\n-  StubCodeMark mark(this, \"StubRoutines\", \"ghash_processBlocks\");\n-  address start = __ pc();\n-\n-  \/\/ arguments\n-  const Register state = c_rarg0;\n-  const Register htbl = c_rarg1;\n-  const Register data = c_rarg2;\n-  const Register blocks = c_rarg3;\n-  __ enter();\n- \/\/ Save state before entering routine\n-  __ avx_ghash(state, htbl, data, blocks);\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n-\/\/ byte swap x86 long\n-address StubGenerator::generate_ghash_long_swap_mask() {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"ghash_long_swap_mask\");\n-  address start = __ pc();\n-\n-  __ emit_data64(0x0f0e0d0c0b0a0908, relocInfo::none );\n-  __ emit_data64(0x0706050403020100, relocInfo::none );\n-\n-return start;\n-}\n-\n-\/\/ byte swap x86 byte array\n-address StubGenerator::generate_ghash_byte_swap_mask() {\n-  __ align(CodeEntryAlignment);\n-  StubCodeMark mark(this, \"StubRoutines\", \"ghash_byte_swap_mask\");\n-  address start = __ pc();\n-\n-  __ emit_data64(0x08090a0b0c0d0e0f, relocInfo::none );\n-  __ emit_data64(0x0001020304050607, relocInfo::none );\n-\n-return start;\n-}\n-\n-\/* Single and multi-block ghash operations *\/\n-address StubGenerator::generate_ghash_processBlocks() {\n-  __ align(CodeEntryAlignment);\n-  Label L_ghash_loop, L_exit;\n-  StubCodeMark mark(this, \"StubRoutines\", \"ghash_processBlocks\");\n-  address start = __ pc();\n-\n-  const Register state        = c_rarg0;\n-  const Register subkeyH      = c_rarg1;\n-  const Register data         = c_rarg2;\n-  const Register blocks       = c_rarg3;\n-\n-  const XMMRegister xmm_temp0 = xmm0;\n-  const XMMRegister xmm_temp1 = xmm1;\n-  const XMMRegister xmm_temp2 = xmm2;\n-  const XMMRegister xmm_temp3 = xmm3;\n-  const XMMRegister xmm_temp4 = xmm4;\n-  const XMMRegister xmm_temp5 = xmm5;\n-  const XMMRegister xmm_temp6 = xmm6;\n-  const XMMRegister xmm_temp7 = xmm7;\n-  const XMMRegister xmm_temp8 = xmm8;\n-  const XMMRegister xmm_temp9 = xmm9;\n-  const XMMRegister xmm_temp10 = xmm10;\n-\n-  __ enter();\n-\n-  __ movdqu(xmm_temp10, ExternalAddress(StubRoutines::x86::ghash_long_swap_mask_addr()));\n-\n-  __ movdqu(xmm_temp0, Address(state, 0));\n-  __ pshufb(xmm_temp0, xmm_temp10);\n-\n-\n-  __ BIND(L_ghash_loop);\n-  __ movdqu(xmm_temp2, Address(data, 0));\n-  __ pshufb(xmm_temp2, ExternalAddress(StubRoutines::x86::ghash_byte_swap_mask_addr()));\n-\n-  __ movdqu(xmm_temp1, Address(subkeyH, 0));\n-  __ pshufb(xmm_temp1, xmm_temp10);\n-\n-  __ pxor(xmm_temp0, xmm_temp2);\n-\n-  \/\/\n-  \/\/ Multiply with the hash key\n-  \/\/\n-  __ movdqu(xmm_temp3, xmm_temp0);\n-  __ pclmulqdq(xmm_temp3, xmm_temp1, 0);      \/\/ xmm3 holds a0*b0\n-  __ movdqu(xmm_temp4, xmm_temp0);\n-  __ pclmulqdq(xmm_temp4, xmm_temp1, 16);     \/\/ xmm4 holds a0*b1\n-\n-  __ movdqu(xmm_temp5, xmm_temp0);\n-  __ pclmulqdq(xmm_temp5, xmm_temp1, 1);      \/\/ xmm5 holds a1*b0\n-  __ movdqu(xmm_temp6, xmm_temp0);\n-  __ pclmulqdq(xmm_temp6, xmm_temp1, 17);     \/\/ xmm6 holds a1*b1\n-\n-  __ pxor(xmm_temp4, xmm_temp5);      \/\/ xmm4 holds a0*b1 + a1*b0\n-\n-  __ movdqu(xmm_temp5, xmm_temp4);    \/\/ move the contents of xmm4 to xmm5\n-  __ psrldq(xmm_temp4, 8);    \/\/ shift by xmm4 64 bits to the right\n-  __ pslldq(xmm_temp5, 8);    \/\/ shift by xmm5 64 bits to the left\n-  __ pxor(xmm_temp3, xmm_temp5);\n-  __ pxor(xmm_temp6, xmm_temp4);      \/\/ Register pair <xmm6:xmm3> holds the result\n-                                      \/\/ of the carry-less multiplication of\n-                                      \/\/ xmm0 by xmm1.\n-\n-  \/\/ We shift the result of the multiplication by one bit position\n-  \/\/ to the left to cope for the fact that the bits are reversed.\n-  __ movdqu(xmm_temp7, xmm_temp3);\n-  __ movdqu(xmm_temp8, xmm_temp6);\n-  __ pslld(xmm_temp3, 1);\n-  __ pslld(xmm_temp6, 1);\n-  __ psrld(xmm_temp7, 31);\n-  __ psrld(xmm_temp8, 31);\n-  __ movdqu(xmm_temp9, xmm_temp7);\n-  __ pslldq(xmm_temp8, 4);\n-  __ pslldq(xmm_temp7, 4);\n-  __ psrldq(xmm_temp9, 12);\n-  __ por(xmm_temp3, xmm_temp7);\n-  __ por(xmm_temp6, xmm_temp8);\n-  __ por(xmm_temp6, xmm_temp9);\n-\n-  \/\/\n-  \/\/ First phase of the reduction\n-  \/\/\n-  \/\/ Move xmm3 into xmm7, xmm8, xmm9 in order to perform the shifts\n-  \/\/ independently.\n-  __ movdqu(xmm_temp7, xmm_temp3);\n-  __ movdqu(xmm_temp8, xmm_temp3);\n-  __ movdqu(xmm_temp9, xmm_temp3);\n-  __ pslld(xmm_temp7, 31);    \/\/ packed right shift shifting << 31\n-  __ pslld(xmm_temp8, 30);    \/\/ packed right shift shifting << 30\n-  __ pslld(xmm_temp9, 25);    \/\/ packed right shift shifting << 25\n-  __ pxor(xmm_temp7, xmm_temp8);      \/\/ xor the shifted versions\n-  __ pxor(xmm_temp7, xmm_temp9);\n-  __ movdqu(xmm_temp8, xmm_temp7);\n-  __ pslldq(xmm_temp7, 12);\n-  __ psrldq(xmm_temp8, 4);\n-  __ pxor(xmm_temp3, xmm_temp7);      \/\/ first phase of the reduction complete\n-\n-  \/\/\n-  \/\/ Second phase of the reduction\n-  \/\/\n-  \/\/ Make 3 copies of xmm3 in xmm2, xmm4, xmm5 for doing these\n-  \/\/ shift operations.\n-  __ movdqu(xmm_temp2, xmm_temp3);\n-  __ movdqu(xmm_temp4, xmm_temp3);\n-  __ movdqu(xmm_temp5, xmm_temp3);\n-  __ psrld(xmm_temp2, 1);     \/\/ packed left shifting >> 1\n-  __ psrld(xmm_temp4, 2);     \/\/ packed left shifting >> 2\n-  __ psrld(xmm_temp5, 7);     \/\/ packed left shifting >> 7\n-  __ pxor(xmm_temp2, xmm_temp4);      \/\/ xor the shifted versions\n-  __ pxor(xmm_temp2, xmm_temp5);\n-  __ pxor(xmm_temp2, xmm_temp8);\n-  __ pxor(xmm_temp3, xmm_temp2);\n-  __ pxor(xmm_temp6, xmm_temp3);      \/\/ the result is in xmm6\n-\n-  __ decrement(blocks);\n-  __ jcc(Assembler::zero, L_exit);\n-  __ movdqu(xmm_temp0, xmm_temp6);\n-  __ addptr(data, 16);\n-  __ jmp(L_ghash_loop);\n-\n-  __ BIND(L_exit);\n-  __ pshufb(xmm_temp6, xmm_temp10);          \/\/ Byte swap 16-byte result\n-  __ movdqu(Address(state, 0), xmm_temp6);   \/\/ store the result\n-  __ leave();\n-  __ ret(0);\n-\n-  return start;\n-}\n-\n@@ -5652,18 +3930,1 @@\n-  \/\/ don't bother generating these AES intrinsic stubs unless global flag is set\n-  if (UseAESIntrinsics) {\n-    StubRoutines::x86::_key_shuffle_mask_addr = generate_key_shuffle_mask();  \/\/ needed by the others\n-    StubRoutines::_aescrypt_encryptBlock = generate_aescrypt_encryptBlock();\n-    StubRoutines::_aescrypt_decryptBlock = generate_aescrypt_decryptBlock();\n-    StubRoutines::_cipherBlockChaining_encryptAESCrypt = generate_cipherBlockChaining_encryptAESCrypt();\n-    if (VM_Version::supports_avx512_vaes() &&  VM_Version::supports_avx512vl() && VM_Version::supports_avx512dq() ) {\n-      StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptVectorAESCrypt();\n-      StubRoutines::_electronicCodeBook_encryptAESCrypt = generate_electronicCodeBook_encryptAESCrypt();\n-      StubRoutines::_electronicCodeBook_decryptAESCrypt = generate_electronicCodeBook_decryptAESCrypt();\n-      StubRoutines::x86::_counter_mask_addr = counter_mask_addr();\n-      StubRoutines::x86::_ghash_poly512_addr = ghash_polynomial512_addr();\n-      StubRoutines::x86::_ghash_long_swap_mask_addr = generate_ghash_long_swap_mask();\n-      StubRoutines::_galoisCounterMode_AESCrypt = generate_galoisCounterMode_AESCrypt();\n-    } else {\n-      StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptAESCrypt_Parallel();\n-    }\n-  }\n+  generate_aes_stubs();\n@@ -5671,11 +3932,1 @@\n-  if (UseAESCTRIntrinsics) {\n-    if (VM_Version::supports_avx512_vaes() && VM_Version::supports_avx512bw() && VM_Version::supports_avx512vl()) {\n-      if (StubRoutines::x86::_counter_mask_addr == NULL) {\n-        StubRoutines::x86::_counter_mask_addr = counter_mask_addr();\n-      }\n-      StubRoutines::_counterMode_AESCrypt = generate_counterMode_VectorAESCrypt();\n-    } else {\n-      StubRoutines::x86::_counter_shuffle_mask_addr = generate_counter_shuffle_mask();\n-      StubRoutines::_counterMode_AESCrypt = generate_counterMode_AESCrypt_Parallel();\n-    }\n-  }\n+  generate_ghash_stubs();\n@@ -5713,16 +3964,0 @@\n-  \/\/ Generate GHASH intrinsics code\n-  if (UseGHASHIntrinsics) {\n-    if (StubRoutines::x86::_ghash_long_swap_mask_addr == NULL) {\n-      StubRoutines::x86::_ghash_long_swap_mask_addr = generate_ghash_long_swap_mask();\n-    }\n-  StubRoutines::x86::_ghash_byte_swap_mask_addr = generate_ghash_byte_swap_mask();\n-    if (VM_Version::supports_avx()) {\n-      StubRoutines::x86::_ghash_shuffmask_addr = ghash_shufflemask_addr();\n-      StubRoutines::x86::_ghash_poly_addr = ghash_polynomial_addr();\n-      StubRoutines::_ghash_processBlocks = generate_avx_ghash_processBlocks();\n-    } else {\n-      StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks();\n-    }\n-  }\n-\n-\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":2,"deletions":1767,"binary":false,"changes":1769,"status":"modified"},{"patch":"@@ -274,4 +274,1 @@\n-  \/\/ AES intrinsic stubs\n-  enum {\n-    AESBlockSize = 16\n-  };\n+  \/\/ MD5 stubs\n@@ -280,1 +277,3 @@\n-  address generate_key_shuffle_mask();\n+  \/\/ ofs and limit are use for multi-block byte array.\n+  \/\/ int com.sun.security.provider.MD5.implCompress(byte[] b, int ofs)\n+  address generate_md5_implCompress(bool multi_block, const char *name);\n@@ -282,4 +281,1 @@\n-  address generate_counter_shuffle_mask();\n-  \/\/ Utility routine for loading a 128-bit key word in little endian format\n-  \/\/ can optionally specify that the shuffle mask is already in an xmmregister\n-  void load_key(XMMRegister xmmdst, Register key, int offset, XMMRegister xmm_shuf_mask = xnoreg);\n+  \/\/ SHA stubs\n@@ -288,2 +284,18 @@\n-  \/\/ Utility routine for increase 128bit counter (iv in CTR mode)\n-  void inc_counter(Register reg, XMMRegister xmmdst, int inc_delta, Label& next_block);\n+  \/\/ ofs and limit are use for multi-block byte array.\n+  \/\/ int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)\n+  address generate_sha1_implCompress(bool multi_block, const char *name);\n+\n+  \/\/ ofs and limit are use for multi-block byte array.\n+  \/\/ int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)\n+  address generate_sha256_implCompress(bool multi_block, const char *name);\n+  address generate_sha512_implCompress(bool multi_block, const char *name);\n+\n+  \/\/ Mask for byte-swapping a couple of qwords in an XMM register using (v)pshufb.\n+  address generate_pshuffle_byte_flip_mask_sha512();\n+\n+  address generate_upper_word_mask();\n+  address generate_shuffle_byte_flip_mask();\n+  address generate_pshuffle_byte_flip_mask();\n+\n+\n+  \/\/ AES intrinsic stubs\n@@ -303,18 +315,1 @@\n-  address generate_electronicCodeBook_decryptAESCrypt();\n-\n-  \/\/ ofs and limit are use for multi-block byte array.\n-  \/\/ int com.sun.security.provider.MD5.implCompress(byte[] b, int ofs)\n-  address generate_md5_implCompress(bool multi_block, const char *name);\n-\n-  address generate_upper_word_mask();\n-\n-  address generate_shuffle_byte_flip_mask();\n-\n-  \/\/ ofs and limit are use for multi-block byte array.\n-  \/\/ int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)\n-  address generate_sha1_implCompress(bool multi_block, const char *name);\n-\n-  address generate_pshuffle_byte_flip_mask();\n-\n-  \/\/ Mask for byte-swapping a couple of qwords in an XMM register using (v)pshufb.\n-  address generate_pshuffle_byte_flip_mask_sha512();\n+  void aesecb_encrypt(Register source_addr, Register dest_addr, Register key, Register len);\n@@ -322,4 +317,1 @@\n-  \/\/ ofs and limit are use for multi-block byte array.\n-  \/\/ int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)\n-  address generate_sha256_implCompress(bool multi_block, const char *name);\n-  address generate_sha512_implCompress(bool multi_block, const char *name);\n+  address generate_electronicCodeBook_decryptAESCrypt();\n@@ -327,1 +319,1 @@\n-  address ghash_polynomial512_addr();\n+  void aesecb_decrypt(Register source_addr, Register dest_addr, Register key, Register len);\n@@ -331,0 +323,2 @@\n+  void aesgcm_encrypt(Register in, Register len, Register ct, Register out, Register key,\n+                      Register state, Register subkeyHtbl, Register avx512_subkeyHtbl, Register counter);\n@@ -332,2 +326,0 @@\n-  \/\/ This mask is used for incrementing counter value(linc0, linc4, etc.)\n-  address counter_mask_addr();\n@@ -337,0 +329,2 @@\n+  void aesctr_encrypt(Register src_addr, Register dest_addr, Register key, Register counter,\n+                      Register len_reg, Register used, Register used_addr, Register saved_encCounter_start);\n@@ -342,1 +336,3 @@\n-  void roundDec(XMMRegister xmm_reg);\n+  address generate_cipherBlockChaining_decryptVectorAESCrypt();\n+\n+  address generate_key_shuffle_mask();\n@@ -344,0 +340,1 @@\n+  void roundDec(XMMRegister xmm_reg);\n@@ -345,0 +342,13 @@\n+  void roundEnc(XMMRegister key, int rnum);\n+  void lastroundEnc(XMMRegister key, int rnum);\n+  void roundDec(XMMRegister key, int rnum);\n+  void lastroundDec(XMMRegister key, int rnum);\n+  void gfmul_avx512(XMMRegister ghash, XMMRegister hkey);\n+  void generateHtbl_48_block_zmm(Register htbl, Register avx512_subkeyHtbl, Register rscratch);\n+  void ghash16_encrypt16_parallel(Register key, Register subkeyHtbl, XMMRegister ctr_blockx,\n+                                  XMMRegister aad_hashx, Register in, Register out, Register data, Register pos, bool reduction,\n+                                  XMMRegister addmask, bool no_ghash_input, Register rounds, Register ghash_pos,\n+                                  bool final_reduction, int index, XMMRegister counter_inc_mask);\n+  \/\/ Load key and shuffle operation\n+  void ev_load_key(XMMRegister xmmdst, Register key, int offset, XMMRegister xmm_shuf_mask);\n+  void ev_load_key(XMMRegister xmmdst, Register key, int offset, Register rscratch);\n@@ -346,1 +356,4 @@\n-  void ev_load_key(XMMRegister xmmdst, Register key, int offset, XMMRegister xmm_shuf_mask = xnoreg);\n+  \/\/ Utility routine for loading a 128-bit key word in little endian format\n+  \/\/ can optionally specify that the shuffle mask is already in an xmmregister\n+  void load_key(XMMRegister xmmdst, Register key, int offset, XMMRegister xmm_shuf_mask);\n+  void load_key(XMMRegister xmmdst, Register key, int offset, Register rscratch);\n@@ -348,1 +361,2 @@\n-  address generate_cipherBlockChaining_decryptVectorAESCrypt();\n+  \/\/ Utility routine for increase 128bit counter (iv in CTR mode)\n+  void inc_counter(Register reg, XMMRegister xmmdst, int inc_delta, Label& next_block);\n@@ -350,2 +364,1 @@\n-  \/\/ Polynomial x^128+x^127+x^126+x^121+1\n-  address ghash_polynomial_addr();\n+  void generate_aes_stubs();\n@@ -353,3 +366,1 @@\n-  address ghash_shufflemask_addr();\n-  \/\/ Ghash single and multi block operations using AVX instructions\n-  address generate_avx_ghash_processBlocks();\n+  \/\/ GHASH stubs\n@@ -358,2 +369,1 @@\n-  \/\/ byte swap x86 long\n-  address generate_ghash_long_swap_mask();\n+  void generate_ghash_stubs();\n@@ -361,2 +371,12 @@\n-  \/\/ byte swap x86 byte array\n-  address generate_ghash_byte_swap_mask();\n+  void schoolbookAAD(int i, Register subkeyH, XMMRegister data, XMMRegister tmp0,\n+                     XMMRegister tmp1, XMMRegister tmp2, XMMRegister tmp3);\n+  void gfmul(XMMRegister tmp0, XMMRegister t);\n+  void generateHtbl_one_block(Register htbl, Register rscratch);\n+  void generateHtbl_eight_blocks(Register htbl);\n+  void avx_ghash(Register state, Register htbl, Register data, Register blocks);\n+\n+  \/\/ Used by GHASH and AES stubs.\n+  address ghash_polynomial_addr();\n+  address ghash_shufflemask_addr();\n+  address ghash_long_swap_mask_addr(); \/\/ byte swap x86 long\n+  address ghash_byte_swap_mask_addr(); \/\/ byte swap x86 byte array\n@@ -367,0 +387,6 @@\n+  \/\/ Ghash single and multi block operations using AVX instructions\n+  address generate_avx_ghash_processBlocks();\n+\n+\n+  \/\/ BASE64 stubs\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":74,"deletions":48,"binary":false,"changes":122,"status":"modified"},{"patch":"@@ -36,0 +36,3 @@\n+#if INCLUDE_JVMCI\n+#include \"jvmci\/jvmci_globals.hpp\"\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_arraycopy.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -1091,4 +1092,5 @@\n-  __ membar(Assembler::Membar_mask_bits(\n-              Assembler::LoadLoad | Assembler::LoadStore |\n-              Assembler::StoreLoad | Assembler::StoreStore));\n-\n+  if (!UseSystemMemoryBarrier) {\n+    __ membar(Assembler::Membar_mask_bits(\n+                Assembler::LoadLoad | Assembler::LoadStore |\n+                Assembler::StoreLoad | Assembler::StoreStore));\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2590,2 +2590,1 @@\n-  bool will_link;\n-  ciKlass* klass = stream()->get_klass(will_link);\n+  ciKlass* klass = stream()->get_klass();\n@@ -2617,2 +2616,1 @@\n-  bool will_link;\n-  ciKlass* klass = stream()->get_klass(will_link);\n+  ciKlass* klass = stream()->get_klass();\n@@ -2644,2 +2642,1 @@\n-  bool will_link;\n-  ciKlass* klass = stream()->get_klass(will_link);\n+  ciKlass* klass = stream()->get_klass();\n@@ -2666,2 +2663,1 @@\n-  bool will_link;\n-  ciKlass* klass = stream()->get_klass(will_link);\n+  ciKlass* klass = stream()->get_klass();\n@@ -2721,2 +2717,1 @@\n-  bool will_link;\n-  ciKlass* klass = stream()->get_klass(will_link);\n+  ciKlass* klass = stream()->get_klass();\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":5,"deletions":10,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -1424,0 +1424,31 @@\n+static bool is_patching_needed(JavaThread* current, Runtime1::StubID stub_id) {\n+  if (stub_id == Runtime1::load_klass_patching_id ||\n+      stub_id == Runtime1::load_mirror_patching_id) {\n+    \/\/ last java frame on stack\n+    vframeStream vfst(current, true);\n+    assert(!vfst.at_end(), \"Java frame must exist\");\n+\n+    methodHandle caller_method(current, vfst.method());\n+    int bci = vfst.bci();\n+    Bytecodes::Code code = caller_method()->java_code_at(bci);\n+\n+    switch (code) {\n+      case Bytecodes::_new:\n+      case Bytecodes::_anewarray:\n+      case Bytecodes::_multianewarray:\n+      case Bytecodes::_instanceof:\n+      case Bytecodes::_checkcast: {\n+        Bytecode bc(caller_method(), caller_method->bcp_from(bci));\n+        constantTag tag = caller_method->constants()->tag_at(bc.get_index_u2(code));\n+        if (tag.is_unresolved_klass_in_error()) {\n+          return false; \/\/ throws resolution error\n+        }\n+        break;\n+      }\n+\n+      default: break;\n+    }\n+  }\n+  return true;\n+}\n+\n@@ -1448,4 +1479,6 @@\n-  \/\/ Make sure the nmethod is invalidated, i.e. made not entrant.\n-  nmethod* nm = CodeCache::find_nmethod(caller_frame.pc());\n-  if (nm != NULL) {\n-    nm->make_not_entrant();\n+  if (is_patching_needed(current, stub_id)) {\n+    \/\/ Make sure the nmethod is invalidated, i.e. made not entrant.\n+    nmethod* nm = CodeCache::find_nmethod(caller_frame.pc());\n+    if (nm != NULL) {\n+      nm->make_not_entrant();\n+    }\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":37,"deletions":4,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -112,1 +112,1 @@\n-  address _dumped_obj;\n+  address _buffered_obj;\n@@ -115,2 +115,2 @@\n-  RelocateEmbeddedPointers(ArchiveBuilder* builder, address dumped_obj, BitMap::idx_t start_idx) :\n-    _builder(builder), _dumped_obj(dumped_obj), _start_idx(start_idx) {}\n+  RelocateEmbeddedPointers(ArchiveBuilder* builder, address buffered_obj, BitMap::idx_t start_idx) :\n+    _builder(builder), _buffered_obj(buffered_obj), _start_idx(start_idx) {}\n@@ -120,1 +120,1 @@\n-    address* ptr_loc = (address*)(_dumped_obj + field_offset);\n+    address* ptr_loc = (address*)(_buffered_obj + field_offset);\n@@ -123,1 +123,1 @@\n-    address new_p = _builder->get_dumped_addr(old_p);\n+    address new_p = _builder->get_buffered_addr(old_p);\n@@ -139,1 +139,1 @@\n-  RelocateEmbeddedPointers relocator(builder, src_info->dumped_addr(), start);\n+  RelocateEmbeddedPointers relocator(builder, src_info->buffered_addr(), start);\n@@ -161,1 +161,1 @@\n-  _dumped_to_src_obj_table(INITIAL_TABLE_SIZE, MAX_TABLE_SIZE),\n+  _buffered_to_src_table(INITIAL_TABLE_SIZE, MAX_TABLE_SIZE),\n@@ -630,1 +630,1 @@\n-    _dumped_to_src_obj_table.put_if_absent((address)dest, src, &created);\n+    _buffered_to_src_table.put_if_absent((address)dest, src, &created);\n@@ -632,2 +632,2 @@\n-    if (_dumped_to_src_obj_table.maybe_grow()) {\n-      log_info(cds, hashtables)(\"Expanded _dumped_to_src_obj_table table to %d\", _dumped_to_src_obj_table.table_size());\n+    if (_buffered_to_src_table.maybe_grow()) {\n+      log_info(cds, hashtables)(\"Expanded _buffered_to_src_table table to %d\", _buffered_to_src_table.table_size());\n@@ -644,1 +644,1 @@\n-  src_info->set_dumped_addr((address)dest);\n+  src_info->set_buffered_addr((address)dest);\n@@ -649,2 +649,2 @@\n-address ArchiveBuilder::get_dumped_addr(address src_obj) const {\n-  SourceObjInfo* p = _src_obj_table.get(src_obj);\n+address ArchiveBuilder::get_buffered_addr(address src_addr) const {\n+  SourceObjInfo* p = _src_obj_table.get(src_addr);\n@@ -653,1 +653,1 @@\n-  return p->dumped_addr();\n+  return p->buffered_addr();\n@@ -656,5 +656,5 @@\n-address ArchiveBuilder::get_src_obj(address dumped_addr) const {\n-  assert(is_in_buffer_space(dumped_addr), \"must be\");\n-  address* src_obj = _dumped_to_src_obj_table.get(dumped_addr);\n-  assert(src_obj != NULL && *src_obj != NULL, \"must be\");\n-  return *src_obj;\n+address ArchiveBuilder::get_source_addr(address buffered_addr) const {\n+  assert(is_in_buffer_space(buffered_addr), \"must be\");\n+  address* src_p = _buffered_to_src_table.get(buffered_addr);\n+  assert(src_p != NULL && *src_p != NULL, \"must be\");\n+  return *src_p;\n@@ -674,1 +674,1 @@\n-    address dst_obj = get_dumped_addr(src_obj);\n+    address dst_obj = get_buffered_addr(src_obj);\n@@ -708,1 +708,1 @@\n-      ref->update(_builder->get_dumped_addr(ref->obj()));\n+      ref->update(_builder->get_buffered_addr(ref->obj()));\n@@ -843,3 +843,3 @@\n-\/\/ Update a Java object to point its Klass* to the new location after\n-\/\/ shared archive has been compacted.\n-void ArchiveBuilder::relocate_klass_ptr(oop o) {\n+\/\/ Update a Java object to point its Klass* to the address whene\n+\/\/ the class would be mapped at runtime.\n+void ArchiveBuilder::relocate_klass_ptr_of_oop(oop o) {\n@@ -847,1 +847,1 @@\n-  Klass* k = get_relocated_klass(o->klass());\n+  Klass* k = get_buffered_klass(o->klass());\n@@ -995,2 +995,2 @@\n-      address src = src_info->orig_obj();\n-      address dest = src_info->dumped_addr();\n+      address src = src_info->source_addr();\n+      address dest = src_info->buffered_addr();\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":27,"deletions":27,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -64,0 +64,28 @@\n+\/\/\n+\/\/ \"source\" vs \"buffered\" vs \"requested\"\n+\/\/\n+\/\/ The ArchiveBuilder deals with three types of addresses.\n+\/\/\n+\/\/ \"source\":    These are the addresses of objects created in step [1] above. They are the actual\n+\/\/              InstanceKlass*, Method*, etc, of the Java classes that are loaded for executing\n+\/\/              Java bytecodes in the JVM process that's dumping the CDS archive.\n+\/\/\n+\/\/              It may be necessary to contiue Java execution after ArchiveBuilder is finished.\n+\/\/              Therefore, we don't modify any of the \"source\" objects.\n+\/\/\n+\/\/ \"buffered\":  The \"source\" objects that are deemed archivable are copied into a temporary buffer.\n+\/\/              Objects in the buffer are modified in steps [2, 3, 4] (e.g., unshareable info is\n+\/\/              removed, pointers are relocated, etc) to prepare them to be loaded at runtime.\n+\/\/\n+\/\/ \"requested\": These are the addreses where the \"buffered\" objects should be loaded at runtime.\n+\/\/              When the \"buffered\" objects are written into the archive file, their addresses\n+\/\/              are adjusted in step [5] such that the lowest of these objects would be mapped\n+\/\/              at SharedBaseAddress.\n+\/\/\n+\/\/ Translation between \"source\" and \"buffered\" addresses is done with two hashtables:\n+\/\/     _src_obj_table          : \"source\"   -> \"buffered\"\n+\/\/     _buffered_to_src_table  : \"buffered\" -> \"source\"\n+\/\/\n+\/\/ Translation between \"buffered\" and \"requested\" addresses is done with a simple shift:\n+\/\/    buffered_address + _buffer_to_requested_delta == requested_address\n+\/\/\n@@ -120,1 +148,1 @@\n-    MetaspaceClosure::Ref* _ref;\n+    MetaspaceClosure::Ref* _ref; \/\/ The object that's copied into the buffer\n@@ -127,2 +155,1 @@\n-    address _dumped_addr;    \/\/ Address this->obj(), as used by the dumped archive.\n-    address _orig_obj;       \/\/ The value of the original object (_ref->obj()) when this\n+    address _source_addr;    \/\/ The value of the source object (_ref->obj()) when this\n@@ -131,1 +158,1 @@\n-\n+    address _buffered_addr;  \/\/ The copy of _ref->obj() insider the buffer.\n@@ -136,1 +163,1 @@\n-      _orig_obj(ref->obj()) {\n+      _source_addr(ref->obj()) {\n@@ -138,1 +165,1 @@\n-        _dumped_addr = ref->obj();\n+        _buffered_addr = ref->obj();\n@@ -140,1 +167,1 @@\n-        _dumped_addr = NULL;\n+        _buffered_addr = NULL;\n@@ -146,1 +173,1 @@\n-    void set_dumped_addr(address dumped_addr)  {\n+    void set_buffered_addr(address addr)  {\n@@ -148,3 +175,3 @@\n-      assert(_dumped_addr == NULL, \"cannot be copied twice\");\n-      assert(dumped_addr != NULL, \"must be a valid copy\");\n-      _dumped_addr = dumped_addr;\n+      assert(_buffered_addr == NULL, \"cannot be copied twice\");\n+      assert(addr != NULL, \"must be a valid copy\");\n+      _buffered_addr = addr;\n@@ -158,2 +185,2 @@\n-    address orig_obj()    const    { return _orig_obj; }\n-    address dumped_addr() const    { return _dumped_addr; }\n+    address source_addr() const    { return _source_addr; }\n+    address buffered_addr() const  { return _buffered_addr; }\n@@ -208,1 +235,1 @@\n-  ResizeableResourceHashtable<address, address, ResourceObj::C_HEAP, mtClassShared> _dumped_to_src_obj_table;\n+  ResizeableResourceHashtable<address, address, ResourceObj::C_HEAP, mtClassShared> _buffered_to_src_table;\n@@ -394,10 +421,4 @@\n-  \/\/ + When creating a CDS archive, we first load Java classes and create metadata\n-  \/\/   objects as usual. These are call \"source\" objects.\n-  \/\/ + We then copy the source objects into the output buffer at \"dumped addresses\".\n-  \/\/\n-  \/\/ The following functions translate between these two (non-overlapping) spaces.\n-  \/\/ (The API should be renamed to be less confusing!)\n-  address get_dumped_addr(address src_obj) const;\n-  address get_src_obj(address dumped_addr) const;\n-  template <typename T> T get_src_obj(T dumped_addr) const {\n-    return (T)get_src_obj((address)dumped_addr);\n+  address get_buffered_addr(address src_addr) const;\n+  address get_source_addr(address buffered_addr) const;\n+  template <typename T> T get_source_addr(T buffered_addr) const {\n+    return (T)get_source_addr((address)buffered_addr);\n@@ -432,1 +453,1 @@\n-  void relocate_klass_ptr(oop o);\n+  void relocate_klass_ptr_of_oop(oop o);\n@@ -434,2 +455,2 @@\n-  static Klass* get_relocated_klass(Klass* orig_klass) {\n-    Klass* klass = (Klass*)current()->get_dumped_addr((address)orig_klass);\n+  static Klass* get_buffered_klass(Klass* src_klass) {\n+    Klass* klass = (Klass*)current()->get_buffered_addr((address)src_klass);\n@@ -440,2 +461,2 @@\n-  static Symbol* get_relocated_symbol(Symbol* orig_symbol) {\n-    return (Symbol*)current()->get_dumped_addr((address)orig_symbol);\n+  static Symbol* get_buffered_symbol(Symbol* src_symbol) {\n+    return (Symbol*)current()->get_buffered_addr((address)src_symbol);\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.hpp","additions":50,"deletions":29,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -68,0 +68,15 @@\n+struct ArchivableStaticFieldInfo {\n+  const char* klass_name;\n+  const char* field_name;\n+  InstanceKlass* klass;\n+  int offset;\n+  BasicType type;\n+\n+  ArchivableStaticFieldInfo(const char* k, const char* f)\n+  : klass_name(k), field_name(f), klass(NULL), offset(0), type(T_ILLEGAL) {}\n+\n+  bool valid() {\n+    return klass_name != NULL;\n+  }\n+};\n+\n@@ -71,0 +86,9 @@\n+#ifndef PRODUCT\n+#define ARCHIVE_TEST_FIELD_NAME \"archivedObjects\"\n+static Array<char>* _archived_ArchiveHeapTestClass = NULL;\n+static const char* _test_class_name = NULL;\n+static const Klass* _test_class = NULL;\n+static const ArchivedKlassSubGraphInfoRecord* _test_class_record = NULL;\n+#endif\n+\n+\n@@ -86,0 +110,1 @@\n+  {NULL, NULL},\n@@ -94,0 +119,4 @@\n+#ifndef PRODUCT\n+  {NULL, NULL}, \/\/ Extra slot for -XX:ArchiveHeapTestClass\n+#endif\n+  {NULL, NULL},\n@@ -101,0 +130,1 @@\n+  {NULL, NULL},\n@@ -103,7 +133,0 @@\n-const static int num_closed_archive_subgraph_entry_fields =\n-  sizeof(closed_archive_subgraph_entry_fields) \/ sizeof(ArchivableStaticFieldInfo);\n-const static int num_open_archive_subgraph_entry_fields =\n-  sizeof(open_archive_subgraph_entry_fields) \/ sizeof(ArchivableStaticFieldInfo);\n-const static int num_fmg_open_archive_subgraph_entry_fields =\n-  sizeof(fmg_open_archive_subgraph_entry_fields) \/ sizeof(ArchivableStaticFieldInfo);\n-\n@@ -121,2 +144,2 @@\n-static bool is_subgraph_root_class_of(ArchivableStaticFieldInfo fields[], int num, InstanceKlass* ik) {\n-  for (int i = 0; i < num; i++) {\n+static bool is_subgraph_root_class_of(ArchivableStaticFieldInfo fields[], InstanceKlass* ik) {\n+  for (int i = 0; fields[i].valid(); i++) {\n@@ -131,6 +154,3 @@\n-  return is_subgraph_root_class_of(closed_archive_subgraph_entry_fields,\n-                                   num_closed_archive_subgraph_entry_fields, ik) ||\n-         is_subgraph_root_class_of(open_archive_subgraph_entry_fields,\n-                                   num_open_archive_subgraph_entry_fields, ik) ||\n-         is_subgraph_root_class_of(fmg_open_archive_subgraph_entry_fields,\n-                                   num_fmg_open_archive_subgraph_entry_fields, ik);\n+  return is_subgraph_root_class_of(closed_archive_subgraph_entry_fields, ik) ||\n+         is_subgraph_root_class_of(open_archive_subgraph_entry_fields, ik) ||\n+         is_subgraph_root_class_of(fmg_open_archive_subgraph_entry_fields, ik);\n@@ -325,1 +345,1 @@\n-    Klass* k = ArchiveBuilder::get_relocated_klass(klasses->at(i));\n+    Klass* k = ArchiveBuilder::get_buffered_klass(klasses->at(i));\n@@ -362,1 +382,1 @@\n-  Klass* relocated_k = ArchiveBuilder::get_relocated_klass(k);\n+  Klass* buffered_k = ArchiveBuilder::get_buffered_klass(k);\n@@ -370,1 +390,1 @@\n-    relocated_k->set_has_archived_enum_objs();\n+    buffered_k->set_has_archived_enum_objs();\n@@ -482,1 +502,0 @@\n-                           num_closed_archive_subgraph_entry_fields,\n@@ -500,1 +519,0 @@\n-                           num_open_archive_subgraph_entry_fields,\n@@ -505,1 +523,0 @@\n-                             num_fmg_open_archive_subgraph_entry_fields,\n@@ -555,2 +572,2 @@\n-\/\/ there is no existing one for k. The subgraph_info records the relocated\n-\/\/ Klass* of the original k.\n+\/\/ there is no existing one for k. The subgraph_info records the \"buffered\"\n+\/\/ address of the class.\n@@ -560,1 +577,1 @@\n-  Klass* relocated_k = ArchiveBuilder::get_relocated_klass(k);\n+  Klass* buffered_k = ArchiveBuilder::get_buffered_klass(k);\n@@ -562,1 +579,1 @@\n-    _dump_time_subgraph_info_table->put_if_absent(k, KlassSubGraphInfo(relocated_k, is_full_module_graph),\n+    _dump_time_subgraph_info_table->put_if_absent(k, KlassSubGraphInfo(buffered_k, is_full_module_graph),\n@@ -591,1 +608,1 @@\n-  Klass* relocated_k = ArchiveBuilder::get_relocated_klass(orig_k);\n+  Klass* buffered_k = ArchiveBuilder::get_buffered_klass(orig_k);\n@@ -598,1 +615,1 @@\n-  assert(ArchiveBuilder::current()->is_in_buffer_space(relocated_k), \"must be a shared class\");\n+  assert(ArchiveBuilder::current()->is_in_buffer_space(buffered_k), \"must be a shared class\");\n@@ -600,1 +617,1 @@\n-  if (_k == relocated_k) {\n+  if (_k == buffered_k) {\n@@ -606,2 +623,2 @@\n-  if (relocated_k->is_instance_klass()) {\n-    assert(InstanceKlass::cast(relocated_k)->is_shared_boot_class(),\n+  if (buffered_k->is_instance_klass()) {\n+    assert(InstanceKlass::cast(buffered_k)->is_shared_boot_class(),\n@@ -617,2 +634,3 @@\n-  } else if (relocated_k->is_objArray_klass()) {\n-    Klass* abk = ObjArrayKlass::cast(relocated_k)->bottom_klass();\n+    check_allowed_klass(InstanceKlass::cast(orig_k));\n+  } else if (buffered_k->is_objArray_klass()) {\n+    Klass* abk = ObjArrayKlass::cast(buffered_k)->bottom_klass();\n@@ -622,0 +640,1 @@\n+      check_allowed_klass(InstanceKlass::cast(ObjArrayKlass::cast(orig_k)->bottom_klass()));\n@@ -623,1 +642,1 @@\n-    if (relocated_k == Universe::objectArrayKlassObj()) {\n+    if (buffered_k == Universe::objectArrayKlassObj()) {\n@@ -629,1 +648,1 @@\n-    assert(relocated_k->is_typeArray_klass(), \"must be\");\n+    assert(buffered_k->is_typeArray_klass(), \"must be\");\n@@ -635,1 +654,1 @@\n-    if (!_subgraph_object_klasses->contains(relocated_k)) {\n+    if (!_subgraph_object_klasses->contains(buffered_k)) {\n@@ -641,1 +660,1 @@\n-  _subgraph_object_klasses->append_if_missing(relocated_k);\n+  _subgraph_object_klasses->append_if_missing(buffered_k);\n@@ -645,0 +664,22 @@\n+void KlassSubGraphInfo::check_allowed_klass(InstanceKlass* ik) {\n+  if (ik->module()->name() == vmSymbols::java_base()) {\n+    assert(ik->package() != NULL, \"classes in java.base cannot be in unnamed package\");\n+    return;\n+  }\n+\n+#ifndef PRODUCT\n+  if (!ik->module()->is_named() && ik->package() == NULL) {\n+    \/\/ This class is loaded by ArchiveHeapTestClass\n+    return;\n+  }\n+  const char* extra_msg = \", or in an unnamed package of an unnamed module\";\n+#else\n+  const char* extra_msg = \"\";\n+#endif\n+\n+  ResourceMark rm;\n+  log_error(cds, heap)(\"Class %s not allowed in archive heap. Must be in java.base%s\",\n+                       ik->external_name(), extra_msg);\n+  os::_exit(1);\n+}\n+\n@@ -731,2 +772,2 @@\n-      Klass* relocated_k = ArchiveBuilder::get_relocated_klass(klass);\n-      unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary((address)relocated_k);\n+      Klass* buffered_k = ArchiveBuilder::get_buffered_klass(klass);\n+      unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary((address)buffered_k);\n@@ -758,0 +799,9 @@\n+\n+#ifndef PRODUCT\n+  if (ArchiveHeapTestClass != NULL) {\n+    size_t len = strlen(ArchiveHeapTestClass) + 1;\n+    Array<char>* array = ArchiveBuilder::new_ro_array<char>((int)len);\n+    strncpy(array->adr_at(0), ArchiveHeapTestClass, len);\n+    _archived_ArchiveHeapTestClass = array;\n+  }\n+#endif\n@@ -777,0 +827,8 @@\n+#ifndef PRODUCT\n+  soc->do_ptr((void**)&_archived_ArchiveHeapTestClass);\n+  if (soc->reading() && _archived_ArchiveHeapTestClass != NULL) {\n+    _test_class_name = _archived_ArchiveHeapTestClass->adr_at(0);\n+    setup_test_class(_test_class_name);\n+  }\n+#endif\n+\n@@ -814,0 +872,1 @@\n+  assert(UseSharedSpaces, \"runtime only!\");\n@@ -817,9 +876,3 @@\n-  resolve_classes_for_subgraphs(closed_archive_subgraph_entry_fields,\n-                                num_closed_archive_subgraph_entry_fields,\n-                                THREAD);\n-  resolve_classes_for_subgraphs(open_archive_subgraph_entry_fields,\n-                                num_open_archive_subgraph_entry_fields,\n-                                THREAD);\n-  resolve_classes_for_subgraphs(fmg_open_archive_subgraph_entry_fields,\n-                                num_fmg_open_archive_subgraph_entry_fields,\n-                                THREAD);\n+  resolve_classes_for_subgraphs(closed_archive_subgraph_entry_fields,   THREAD);\n+  resolve_classes_for_subgraphs(open_archive_subgraph_entry_fields,     THREAD);\n+  resolve_classes_for_subgraphs(fmg_open_archive_subgraph_entry_fields, THREAD);\n@@ -829,2 +882,2 @@\n-                                               int num, JavaThread* THREAD) {\n-  for (int i = 0; i < num; i++) {\n+                                               JavaThread* THREAD) {\n+  for (int i = 0; fields[i].valid(); i++) {\n@@ -883,0 +936,7 @@\n+#ifndef PRODUCT\n+  if (_test_class_name != NULL && k->name()->equals(_test_class_name) && record != NULL) {\n+    _test_class = k;\n+    _test_class_record = record;\n+  }\n+#endif\n+\n@@ -904,0 +964,5 @@\n+    if (log_is_enabled(Info, cds, heap)) {\n+      ResourceMark rm;\n+      log_info(cds, heap)(\"%s subgraph %s \", do_init ? \"init\" : \"resolve\", k->external_name());\n+    }\n+\n@@ -1405,4 +1470,5 @@\n-      assert(!_found, \"fields cannot be overloaded\");\n-      assert(is_reference_type(fd->field_type()), \"can archive only fields that are references\");\n-      _found = true;\n-      _offset = fd->offset();\n+      assert(!_found, \"fields can never be overloaded\");\n+      if (is_reference_type(fd->field_type())) {\n+        _found = true;\n+        _offset = fd->offset();\n+      }\n@@ -1416,2 +1482,2 @@\n-                                            int num, TRAPS) {\n-  for (int i = 0; i < num; i++) {\n+                                            TRAPS) {\n+  for (int i = 0; fields[i].valid(); i++) {\n@@ -1421,0 +1487,25 @@\n+    ResourceMark rm; \/\/ for stringStream::as_string() etc.\n+\n+#ifndef PRODUCT\n+    bool is_test_class = (ArchiveHeapTestClass != NULL) && (strcmp(info->klass_name, ArchiveHeapTestClass) == 0);\n+#else\n+    bool is_test_class = false;\n+#endif\n+\n+    if (is_test_class) {\n+      log_warning(cds)(\"Loading ArchiveHeapTestClass %s ...\", ArchiveHeapTestClass);\n+    }\n+\n+    Klass* k = SystemDictionary::resolve_or_fail(klass_name, true, THREAD);\n+    if (HAS_PENDING_EXCEPTION) {\n+      CLEAR_PENDING_EXCEPTION;\n+      stringStream st;\n+      st.print(\"Fail to initialize archive heap: %s cannot be loaded by the boot loader\", info->klass_name);\n+      THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), st.as_string());\n+    }\n+\n+    if (!k->is_instance_klass()) {\n+      stringStream st;\n+      st.print(\"Fail to initialize archive heap: %s is not an instance class\", info->klass_name);\n+      THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), st.as_string());\n+    }\n@@ -1422,1 +1513,0 @@\n-    Klass* k = SystemDictionary::resolve_or_fail(klass_name, true, CHECK);\n@@ -1426,0 +1516,30 @@\n+\n+    if (is_test_class) {\n+      if (ik->module()->is_named()) {\n+        \/\/ We don't want ArchiveHeapTestClass to be abused to easily load\/initialize arbitrary\n+        \/\/ core-lib classes. You need to at least append to the bootclasspath.\n+        stringStream st;\n+        st.print(\"ArchiveHeapTestClass %s is not in unnamed module\", ArchiveHeapTestClass);\n+        THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), st.as_string());\n+      }\n+\n+      if (ik->package() != NULL) {\n+        \/\/ This restriction makes HeapShared::is_a_test_class_in_unnamed_module() easy.\n+        stringStream st;\n+        st.print(\"ArchiveHeapTestClass %s is not in unnamed package\", ArchiveHeapTestClass);\n+        THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), st.as_string());\n+      }\n+    } else {\n+      if (ik->module()->name() != vmSymbols::java_base()) {\n+        \/\/ We don't want to deal with cases when a module is unavailable at runtime.\n+        \/\/ FUTURE -- load from archived heap only when module graph has not changed\n+        \/\/           between dump and runtime.\n+        stringStream st;\n+        st.print(\"%s is not in java.base module\", info->klass_name);\n+        THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), st.as_string());\n+      }\n+    }\n+\n+    if (is_test_class) {\n+      log_warning(cds)(\"Initializing ArchiveHeapTestClass %s ...\", ArchiveHeapTestClass);\n+    }\n@@ -1430,1 +1550,5 @@\n-    assert(finder.found(), \"field must exist\");\n+    if (!finder.found()) {\n+      stringStream st;\n+      st.print(\"Unable to find the static T_OBJECT field %s::%s\", info->klass_name, info->field_name);\n+      THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), st.as_string());\n+    }\n@@ -1440,6 +1564,2 @@\n-  init_subgraph_entry_fields(closed_archive_subgraph_entry_fields,\n-                             num_closed_archive_subgraph_entry_fields,\n-                             CHECK);\n-  init_subgraph_entry_fields(open_archive_subgraph_entry_fields,\n-                             num_open_archive_subgraph_entry_fields,\n-                             CHECK);\n+  init_subgraph_entry_fields(closed_archive_subgraph_entry_fields, CHECK);\n+  init_subgraph_entry_fields(open_archive_subgraph_entry_fields, CHECK);\n@@ -1447,3 +1567,59 @@\n-    init_subgraph_entry_fields(fmg_open_archive_subgraph_entry_fields,\n-                               num_fmg_open_archive_subgraph_entry_fields,\n-                               CHECK);\n+    init_subgraph_entry_fields(fmg_open_archive_subgraph_entry_fields, CHECK);\n+  }\n+}\n+\n+#ifndef PRODUCT\n+void HeapShared::setup_test_class(const char* test_class_name) {\n+  ArchivableStaticFieldInfo* p = open_archive_subgraph_entry_fields;\n+  int num_slots = sizeof(open_archive_subgraph_entry_fields) \/ sizeof(ArchivableStaticFieldInfo);\n+  assert(p[num_slots - 2].klass_name == NULL, \"must have empty slot that's patched below\");\n+  assert(p[num_slots - 1].klass_name == NULL, \"must have empty slot that marks the end of the list\");\n+\n+  if (test_class_name != NULL) {\n+    p[num_slots - 2].klass_name = test_class_name;\n+    p[num_slots - 2].field_name = ARCHIVE_TEST_FIELD_NAME;\n+  }\n+}\n+\n+\/\/ See if ik is one of the test classes that are pulled in by -XX:ArchiveHeapTestClass\n+\/\/ during runtime. This may be called before the module system is initialized so\n+\/\/ we cannot rely on InstanceKlass::module(), etc.\n+bool HeapShared::is_a_test_class_in_unnamed_module(Klass* ik) {\n+  if (_test_class != NULL) {\n+    if (ik == _test_class) {\n+      return true;\n+    }\n+    Array<Klass*>* klasses = _test_class_record->subgraph_object_klasses();\n+    if (klasses == NULL) {\n+      return false;\n+    }\n+\n+    for (int i = 0; i < klasses->length(); i++) {\n+      Klass* k = klasses->at(i);\n+      if (k == ik) {\n+        Symbol* name;\n+        if (k->is_instance_klass()) {\n+          name = InstanceKlass::cast(k)->name();\n+        } else if (k->is_objArray_klass()) {\n+          Klass* bk = ObjArrayKlass::cast(k)->bottom_klass();\n+          if (!bk->is_instance_klass()) {\n+            return false;\n+          }\n+          name = bk->name();\n+        } else {\n+          return false;\n+        }\n+\n+        \/\/ See KlassSubGraphInfo::check_allowed_klass() - only two types of\n+        \/\/ classes are allowed:\n+        \/\/   (A) java.base classes (which must not be in the unnamed module)\n+        \/\/   (B) test classes which must be in the unnamed package of the unnamed module.\n+        \/\/ So if we see a '\/' character in the class name, it must be in (A);\n+        \/\/ otherwise it must be in (B).\n+        if (name->index_of_at(0, \"\/\", 1)  >= 0) {\n+          return false; \/\/ (A)\n+        }\n+\n+        return true; \/\/ (B)\n+      }\n+    }\n@@ -1451,0 +1627,2 @@\n+\n+  return false;\n@@ -1452,0 +1630,1 @@\n+#endif\n@@ -1455,0 +1634,1 @@\n+    setup_test_class(ArchiveHeapTestClass);\n@@ -1461,1 +1641,1 @@\n-                                          int num, bool is_closed_archive,\n+                                          bool is_closed_archive,\n@@ -1476,1 +1656,1 @@\n-  for (i = 0; i < num; ) {\n+  for (int i = 0; fields[i].valid(); ) {\n@@ -1485,1 +1665,1 @@\n-    for (; i < num; i++) {\n+    for (; fields[i].valid(); i++) {\n@@ -1506,1 +1686,1 @@\n-  for (int i = 0; i < num; i++) {\n+  for (int i = 0; fields[i].valid(); i++) {\n@@ -1611,1 +1791,1 @@\n-      builder->relocate_klass_ptr(o);\n+      builder->relocate_klass_ptr_of_oop(o);\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":251,"deletions":71,"binary":false,"changes":322,"status":"modified"},{"patch":"@@ -1681,0 +1681,6 @@\n+#ifdef COMPILER2\n+    if (ReplayReduce && compiler_data() != NULL) {\n+      \/\/ Dump C2 \"reduced\" inlining data.\n+      ((Compile*)compiler_data())->dump_inline_data_reduced(out);\n+    }\n+#endif\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -637,0 +637,1 @@\n+    reset();\n@@ -735,7 +736,1 @@\n-    const char* comp_level_label = \"comp_level\";\n-    int comp_level = parse_int(comp_level_label);\n-    \/\/ old version w\/o comp_level\n-    if (had_error() && (error_message() == comp_level_label)) {\n-      \/\/ use highest available tier\n-      comp_level = CompilationPolicy::highest_compile_level();\n-    }\n+    int comp_level = parse_int(\"comp_level\");\n@@ -812,1 +807,0 @@\n-    reset();\n","filename":"src\/hotspot\/share\/ci\/ciReplay.cpp","additions":2,"deletions":8,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -26,1 +26,0 @@\n-#include \"ci\/ciCallSite.hpp\"\n@@ -29,0 +28,2 @@\n+#include \"ci\/ciKlass.hpp\"\n+#include \"ci\/ciObjArrayKlass.hpp\"\n@@ -195,0 +196,19 @@\n+\/\/ ciBytecodeStream::get_klass\n+\/\/\n+\/\/ If this bytecode is a new, newarray, multianewarray, instanceof,\n+\/\/ or checkcast, get the referenced klass. Retuns an unloaded ciKlass\n+\/\/ if the referenced klass is not accessible.\n+ciKlass* ciBytecodeStream::get_klass() {\n+  bool will_link;\n+  ciKlass* klass = get_klass(will_link);\n+  if (!will_link && klass->is_loaded()) { \/\/ klass not accessible\n+    if (klass->is_array_klass()) {\n+      assert(!klass->is_type_array_klass(), \"\");\n+      klass = ciEnv::unloaded_ciobjarrayklass();\n+    } else {\n+      klass = ciEnv::unloaded_ciinstance_klass();\n+    }\n+  }\n+  return klass;\n+}\n+\n","filename":"src\/hotspot\/share\/ci\/ciStreams.cpp","additions":21,"deletions":1,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -222,0 +222,1 @@\n+  ciKlass* get_klass();\n","filename":"src\/hotspot\/share\/ci\/ciStreams.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1163,1 +1163,1 @@\n-  Klass* copy = ArchiveBuilder::get_relocated_klass(k);\n+  Klass* copy = ArchiveBuilder::get_buffered_klass(k);\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1102,2 +1102,7 @@\n-    assert(scp_entry != NULL && scp_entry->is_modules_image(),\n-           \"Loading non-bootstrap classes before the module system is initialized\");\n+    assert(scp_entry != NULL, \"must be\");\n+    \/\/ At this point, no modules have been defined yet. KlassSubGraphInfo::check_allowed_klass()\n+    \/\/ has restricted the classes can be loaded at this step to be only:\n+    \/\/ [1] scp_entry->is_modules_image(): classes in java.base, or,\n+    \/\/ [2] HeapShared::is_a_test_class_in_unnamed_module(ik): classes in bootstrap\/unnamed module\n+    assert(scp_entry->is_modules_image() || HeapShared::is_a_test_class_in_unnamed_module(ik),\n+           \"only these classes can be loaded before the module system is initialized\");\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1746,1 +1746,1 @@\n-    GCTraceCPUTime tcpu;\n+    GCTraceCPUTime tcpu(&_gc_tracer);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -80,1 +80,1 @@\n-    if (can_use_native_byte_order(bc, is_wide))\n+    if (can_use_native_byte_order(bc, is_wide)) {\n@@ -82,1 +82,3 @@\n-    else  return Bytes::get_Java_u2(p);\n+    } else {\n+      return Bytes::get_Java_u2(p);\n+    }\n","filename":"src\/hotspot\/share\/interpreter\/bytecode.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -449,1 +449,1 @@\n-    st->print(INTPTR_FORMAT, p2i(klass->class_loader_data()));\n+    st->print(PTR_FORMAT, p2i(klass->class_loader_data()));\n","filename":"src\/hotspot\/share\/memory\/heapInspection.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2324,1 +2324,1 @@\n-    st->print_cr(\" - holder: \" INTPTR_FORMAT, p2i(pool_holder()));\n+    st->print_cr(\" - holder: \" PTR_FORMAT, p2i(pool_holder()));\n@@ -2326,4 +2326,4 @@\n-  st->print_cr(\" - cache: \" INTPTR_FORMAT, p2i(cache()));\n-  st->print_cr(\" - resolved_references: \" INTPTR_FORMAT, p2i(resolved_references_or_null()));\n-  st->print_cr(\" - reference_map: \" INTPTR_FORMAT, p2i(reference_map()));\n-  st->print_cr(\" - resolved_klasses: \" INTPTR_FORMAT, p2i(resolved_klasses()));\n+  st->print_cr(\" - cache: \" PTR_FORMAT, p2i(cache()));\n+  st->print_cr(\" - resolved_references: \" PTR_FORMAT, p2i(resolved_references_or_null()));\n+  st->print_cr(\" - reference_map: \" PTR_FORMAT, p2i(reference_map()));\n+  st->print_cr(\" - resolved_klasses: \" PTR_FORMAT, p2i(resolved_klasses()));\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1548,1 +1548,1 @@\n-    tty->print_cr(\" (\" INTPTR_FORMAT \") as finalizable\", p2i(i));\n+    tty->print_cr(\" (\" PTR_FORMAT \") as finalizable\", p2i(i));\n@@ -1669,1 +1669,1 @@\n-    ls.print_cr(\"%s (\" INTPTR_FORMAT \")\", h_method() == NULL ? \"(no method)\" : \"\", p2i(this));\n+    ls.print_cr(\"%s (\" PTR_FORMAT \")\", h_method() == NULL ? \"(no method)\" : \"\", p2i(this));\n@@ -2241,1 +2241,1 @@\n-  _st->print(INTPTR_FORMAT \"  \", p2i(k));\n+  _st->print(PTR_FORMAT \"  \", p2i(k));\n@@ -2895,1 +2895,1 @@\n-    log_info(class, unload)(\"unloading class %s \" INTPTR_FORMAT, ik->external_name(), p2i(ik));\n+    log_info(class, unload)(\"unloading class %s \" PTR_FORMAT, ik->external_name(), p2i(ik));\n@@ -3752,1 +3752,1 @@\n-  st->print(BULLET\"vtable length      %d  (start addr: \" INTPTR_FORMAT \")\", vtable_length(), p2i(start_of_vtable())); st->cr();\n+  st->print(BULLET\"vtable length      %d  (start addr: \" PTR_FORMAT \")\", vtable_length(), p2i(start_of_vtable())); st->cr();\n@@ -3754,1 +3754,1 @@\n-  st->print(BULLET\"itable length      %d (start addr: \" INTPTR_FORMAT \")\", itable_length(), p2i(start_of_itable())); st->cr();\n+  st->print(BULLET\"itable length      %d (start addr: \" PTR_FORMAT \")\", itable_length(), p2i(start_of_itable())); st->cr();\n@@ -3961,1 +3961,1 @@\n-    debug_stream.print(\" klass: \" INTPTR_FORMAT \" super: \" INTPTR_FORMAT,\n+    debug_stream.print(\" klass: \" PTR_FORMAT \" super: \" PTR_FORMAT,\n@@ -3969,1 +3969,1 @@\n-        debug_stream.print(\" \" INTPTR_FORMAT,\n+        debug_stream.print(\" \" PTR_FORMAT,\n@@ -4252,1 +4252,1 @@\n-        (\"previous version \" INTPTR_FORMAT \" is dead.\", p2i(pv_node));\n+        (\"previous version \" PTR_FORMAT \" is dead.\", p2i(pv_node));\n@@ -4266,1 +4266,1 @@\n-      log_trace(redefine, class, iklass, purge)(\"previous version \" INTPTR_FORMAT \" is alive\", p2i(pv_node));\n+      log_trace(redefine, class, iklass, purge)(\"previous version \" PTR_FORMAT \" is alive\", p2i(pv_node));\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -345,1 +345,1 @@\n-         \"bcp doesn't belong to this method. bcp: \" INTPTR_FORMAT, p2i(bcp));\n+         \"bcp doesn't belong to this method. bcp: \" PTR_FORMAT, p2i(bcp));\n@@ -2449,1 +2449,1 @@\n-  st->print_cr(\" - this oop:          \" INTPTR_FORMAT, p2i(this));\n+  st->print_cr(\" - this oop:          \" PTR_FORMAT, p2i(this));\n@@ -2451,1 +2451,1 @@\n-  st->print   (\" - constants:         \" INTPTR_FORMAT \" \", p2i(constants()));\n+  st->print   (\" - constants:         \" PTR_FORMAT \" \", p2i(constants()));\n@@ -2469,1 +2469,1 @@\n-  st->print_cr(\" - i2i entry:         \" INTPTR_FORMAT, p2i(interpreter_entry()));\n+  st->print_cr(\" - i2i entry:         \" PTR_FORMAT, p2i(interpreter_entry()));\n@@ -2473,1 +2473,1 @@\n-    st->print_cr(INTPTR_FORMAT, p2i(a));\n+    st->print_cr(PTR_FORMAT, p2i(a));\n@@ -2476,3 +2476,3 @@\n-  st->print_cr(\" - compiled entry           \" INTPTR_FORMAT, p2i(from_compiled_entry()));\n-  st->print_cr(\" - compiled inline entry    \" INTPTR_FORMAT, p2i(from_compiled_inline_entry()));\n-  st->print_cr(\" - compiled inline ro entry \" INTPTR_FORMAT, p2i(from_compiled_inline_ro_entry()));\n+  st->print_cr(\" - compiled entry           \" PTR_FORMAT, p2i(from_compiled_entry()));\n+  st->print_cr(\" - compiled inline entry    \" PTR_FORMAT, p2i(from_compiled_inline_entry()));\n+  st->print_cr(\" - compiled inline ro entry \" PTR_FORMAT, p2i(from_compiled_inline_ro_entry()));\n@@ -2481,2 +2481,2 @@\n-    st->print_cr(\" - code start:        \" INTPTR_FORMAT, p2i(code_base()));\n-    st->print_cr(\" - code end (excl):   \" INTPTR_FORMAT, p2i(code_base() + code_size()));\n+    st->print_cr(\" - code start:        \" PTR_FORMAT, p2i(code_base()));\n+    st->print_cr(\" - code end (excl):   \" PTR_FORMAT, p2i(code_base() + code_size()));\n@@ -2485,1 +2485,1 @@\n-    st->print_cr(\" - method data:       \" INTPTR_FORMAT, p2i(method_data()));\n+    st->print_cr(\" - method data:       \" PTR_FORMAT, p2i(method_data()));\n@@ -2490,1 +2490,1 @@\n-    st->print_cr(\" - checked ex start:  \" INTPTR_FORMAT, p2i(table));\n+    st->print_cr(\" - checked ex start:  \" PTR_FORMAT, p2i(table));\n@@ -2499,1 +2499,1 @@\n-    st->print_cr(\" - linenumber start:  \" INTPTR_FORMAT, p2i(table));\n+    st->print_cr(\" - linenumber start:  \" PTR_FORMAT, p2i(table));\n@@ -2510,1 +2510,1 @@\n-    st->print_cr(\" - localvar start:    \" INTPTR_FORMAT, p2i(table));\n+    st->print_cr(\" - localvar start:    \" PTR_FORMAT, p2i(table));\n@@ -2527,2 +2527,2 @@\n-    st->print_cr(\" - native function:   \" INTPTR_FORMAT, p2i(native_function()));\n-    st->print_cr(\" - signature handler: \" INTPTR_FORMAT, p2i(signature_handler()));\n+    st->print_cr(\" - native function:   \" PTR_FORMAT, p2i(native_function()));\n+    st->print_cr(\" - signature handler: \" PTR_FORMAT, p2i(signature_handler()));\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":16,"deletions":16,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-  st->print(\"{\" INTPTR_FORMAT \"}\", p2i(this));\n+  st->print(\"{\" PTR_FORMAT \"}\", p2i(this));\n@@ -136,1 +136,1 @@\n-  guarantee(oopDesc::is_oop_or_null(obj), \"invalid oop: \" INTPTR_FORMAT, p2i((oopDesc*) obj));\n+  guarantee(oopDesc::is_oop_or_null(obj), \"invalid oop: \" PTR_FORMAT, p2i(obj));\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -195,3 +195,4 @@\n-\/\/ Finds if the given string is a substring of this symbol's utf8 bytes.\n-\/\/ Return -1 on failure.  Otherwise return the first index where str occurs.\n-int Symbol::index_of_at(int i, const char* str, int len) const {\n+\/\/ Test if we have the give substring at or after the i-th char of this\n+\/\/ symbol's utf8 bytes.\n+\/\/ Return -1 on failure.  Otherwise return the first index where substr occurs.\n+int Symbol::index_of_at(int i, const char* substr, int substr_len) const {\n@@ -199,2 +200,2 @@\n-  if (len <= 0)  return 0;\n-  char first_char = str[0];\n+  if (substr_len <= 0)  return 0;\n+  char first_char = substr[0];\n@@ -202,1 +203,1 @@\n-  address limit = bytes + utf8_length() - len;  \/\/ inclusive limit\n+  address limit = bytes + utf8_length() - substr_len;  \/\/ inclusive limit\n@@ -211,3 +212,3 @@\n-    if (len <= 2\n-        ? (char) scan[len-1] == str[len-1]\n-        : memcmp(scan+1, str+1, len-1) == 0) {\n+    if (substr_len <= 2\n+        ? (char) scan[substr_len-1] == substr[substr_len-1]\n+        : memcmp(scan+1, substr+1, substr_len-1) == 0) {\n","filename":"src\/hotspot\/share\/oops\/symbol.cpp","additions":11,"deletions":10,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -255,2 +255,2 @@\n-  \/\/ Tests if the symbol starts with the given prefix.\n-  int index_of_at(int i, const char* str, int len) const;\n+  \/\/ Test if the symbol has the give substring at or after the i-th char.\n+  int index_of_at(int i, const char* substr, int substr_len) const;\n","filename":"src\/hotspot\/share\/oops\/symbol.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -716,2 +716,2 @@\n-void InlineTree::dump_replay_data(outputStream* out) {\n-  out->print(\" %d %d %d \", inline_level(), caller_bci(), _late_inline);\n+void InlineTree::dump_replay_data(outputStream* out, int depth_adjust) {\n+  out->print(\" %d %d %d \", inline_level() + depth_adjust, caller_bci(), _late_inline);\n@@ -720,1 +720,1 @@\n-    _subtrees.at(i)->dump_replay_data(out);\n+    _subtrees.at(i)->dump_replay_data(out, depth_adjust);\n","filename":"src\/hotspot\/share\/opto\/bytecodeInfo.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -5097,0 +5097,29 @@\n+void Compile::dump_inline_data_reduced(outputStream* out) {\n+  assert(ReplayReduce, \"\");\n+\n+  InlineTree* inl_tree = ilt();\n+  if (inl_tree == NULL) {\n+    return;\n+  }\n+  \/\/ Enable iterative replay file reduction\n+  \/\/ Output \"compile\" lines for depth 1 subtrees,\n+  \/\/ simulating that those trees were compiled\n+  \/\/ instead of inlined.\n+  for (int i = 0; i < inl_tree->subtrees().length(); ++i) {\n+    InlineTree* sub = inl_tree->subtrees().at(i);\n+    if (sub->inline_level() != 1) {\n+      continue;\n+    }\n+\n+    ciMethod* method = sub->method();\n+    int entry_bci = -1;\n+    int comp_level = env()->task()->comp_level();\n+    out->print(\"compile \");\n+    method->dump_name_as_ascii(out);\n+    out->print(\" %d %d\", entry_bci, comp_level);\n+    out->print(\" inline %d\", sub->count());\n+    sub->dump_replay_data(out, -1);\n+    out->cr();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":29,"deletions":0,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -515,0 +515,1 @@\n+  void dump_inline_data_reduced(outputStream* out);\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -938,0 +938,2 @@\n+  static void count_opaque_loop_nodes(Node* n, uint& init, uint& stride);\n+  static bool subgraph_has_opaque(Node* n);\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -95,1 +95,0 @@\n-  int         inline_level()      const { return stack_depth(); }\n@@ -127,0 +126,1 @@\n+  int         inline_level()      const { return stack_depth(); }\n@@ -144,1 +144,1 @@\n-  void dump_replay_data(outputStream* out);\n+  void dump_replay_data(outputStream* out, int depth_adjust = 0);\n","filename":"src\/hotspot\/share\/opto\/parse.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2575,0 +2575,1 @@\n+    tty->print(\" %s\", Bytecodes::name(bc()));\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -204,1 +204,1 @@\n-  if (n->Opcode() == Op_OpaqueLoopStride || n->Opcode() == Op_OpaqueLoopInit) {\n+  if (subgraph_has_opaque(n)) {\n","filename":"src\/hotspot\/share\/opto\/split_if.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -166,0 +166,11 @@\n+  Node* mem = map->memory();\n+  if (!mem->is_MergeMem()) {\n+    \/\/ Since we are not in parsing, the SafePointNode does not guarantee that the memory\n+    \/\/ input is necessarily a MergeMemNode. But we need to ensure that there is that\n+    \/\/ MergeMemNode, since the GraphKit assumes the memory input of the map to be a\n+    \/\/ MergeMemNode, so that it can directly access the memory slices.\n+    PhaseGVN& gvn = *C->initial_gvn();\n+    Node* mergemem = MergeMemNode::make(mem);\n+    gvn.set_type_bottom(mergemem);\n+    map->set_memory(mergemem);\n+  }\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1185,0 +1185,2 @@\n+\n+  JvmtiVTMSTransitionDisabler disabler;\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -224,1 +224,1 @@\n-void frame::set_pc(address   newpc ) {\n+void frame::set_pc(address newpc) {\n@@ -238,15 +238,0 @@\n-void frame::set_pc_preserve_deopt(address newpc) {\n-  set_pc_preserve_deopt(newpc, CodeCache::find_blob(newpc));\n-}\n-\n-void frame::set_pc_preserve_deopt(address newpc, CodeBlob* cb) {\n-#ifdef ASSERT\n-  if (_cb != NULL && _cb->is_nmethod()) {\n-    assert(!((nmethod*)_cb)->is_deopt_pc(_pc), \"invariant violation\");\n-  }\n-#endif \/\/ ASSERT\n-\n-  _pc = newpc;\n-  _cb = cb;\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":1,"deletions":16,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -123,2 +123,0 @@\n-  void set_pc_preserve_deopt(address newpc);\n-  void set_pc_preserve_deopt(address newpc, CodeBlob* cb);\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1315,0 +1315,3 @@\n+  product(bool, UseSystemMemoryBarrier, false, EXPERIMENTAL,                \\\n+          \"Try to enable system memory barrier\")                            \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -165,4 +165,4 @@\n-  Thread* current = Thread::current_or_null_safe();\n-  assert(current != nullptr, \"cannot be called by a detached thread\");\n-  guarantee(current != this || JavaThread::cast(current)->is_oop_safe(),\n-            \"current cannot touch oops after its GC barrier is detached.\");\n+  \/\/ Ideally we would verify the current thread is oop_safe when this is called, but as we can\n+  \/\/ be called from a signal handler we would have to use Thread::current_or_null_safe(). That\n+  \/\/ has overhead and also interacts poorly with GetLastError on Windows due to the use of TLS.\n+  \/\/ Instead callers must verify oop safe access.\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -53,0 +53,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -73,0 +74,1 @@\n+#include \"utilities\/systemMemoryBarrier.hpp\"\n@@ -343,2 +345,5 @@\n-\n-  OrderAccess::fence(); \/\/ storestore|storeload, global state -> local state\n+  if (UseSystemMemoryBarrier) {\n+    SystemMemoryBarrier::emit(); \/\/ storestore|storeload, global state -> local state\n+  } else {\n+    OrderAccess::fence(); \/\/ storestore|storeload, global state -> local state\n+  }\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1005,0 +1005,3 @@\n+    Thread* current = Thread::current();\n+    guarantee(current != thread || JavaThread::cast(thread)->is_oop_safe(),\n+              \"current cannot touch oops after its GC barrier is detached.\");\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -134,0 +134,5 @@\n+#ifdef _LP64\n+#define SIZE_FORMAT_X_0          \"0x%016\"     PRIxPTR\n+#else\n+#define SIZE_FORMAT_X_0          \"0x%08\"      PRIxPTR\n+#endif\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -341,1 +341,1 @@\n-    tty->print(\"Growable Array \" INTPTR_FORMAT, p2i(this));\n+    tty->print(\"Growable Array \" PTR_FORMAT, p2i(this));\n","filename":"src\/hotspot\/share\/utilities\/growableArray.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+import java.util.Objects;\n@@ -342,1 +343,1 @@\n-    STRICT(Modifier.STRICT, true, Location.SET_METHOD,\n+    STRICT(Modifier.STRICT, true, Location.EMPTY_SET,\n@@ -488,0 +489,1 @@\n+        Objects.requireNonNull(cffv);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/AccessFlag.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -334,1 +334,1 @@\n-            final Type[] nonGenericParamTypes = getParameterTypes();\n+            final Type[] nonGenericParamTypes = getSharedParameterTypes();\n@@ -361,1 +361,1 @@\n-                    genericParamTypes : nonGenericParamTypes;\n+                    genericParamTypes : getParameterTypes();\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Executable.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1260,1 +1260,1 @@\n-                        Method m = proxyIntf.getMethod(method.getName(), method.getParameterTypes());\n+                        Method m = proxyIntf.getMethod(method.getName(), method.getSharedParameterTypes());\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Proxy.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -535,1 +535,1 @@\n-        Class<?>[] exceptionTypes = m.getExceptionTypes();\n+        Class<?>[] exceptionTypes = m.getSharedExceptionTypes();\n@@ -557,1 +557,1 @@\n-        sigmethods.add(new ProxyMethod(m, sig, m.getParameterTypes(), returnType,\n+        sigmethods.add(new ProxyMethod(m, sig, m.getSharedParameterTypes(), returnType,\n@@ -748,2 +748,2 @@\n-                    method.getParameterTypes(), method.getReturnType(),\n-                    method.getExceptionTypes(), method.getDeclaringClass(), methodFieldName);\n+                    method.getSharedParameterTypes(), method.getReturnType(),\n+                    method.getSharedExceptionTypes(), method.getDeclaringClass(), methodFieldName);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/ProxyGenerator.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -188,1 +188,2 @@\n-        jdk.jlink;\n+        jdk.jlink,\n+        jdk.jshell;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -210,1 +210,0 @@\n-        DIAMOND(MIN, Fragments.FeatureDiamond, DiagKind.NORMAL), \/\/ Used in Analyzer\n@@ -214,5 +213,0 @@\n-        POLY(JDK8),\n-        LAMBDA(JDK8, Fragments.FeatureLambda, DiagKind.PLURAL),\n-        DEFAULT_METHODS(JDK8, Fragments.FeatureDefaultMethods, DiagKind.PLURAL),\n-        STRICT_METHOD_CLASH_CHECK(JDK8),\n-        GRAPH_INFERENCE(JDK8), \/\/ Used in Analyzer\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Source.java","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2927,5 +2927,1 @@\n-        return isSubSignature(t, s, true);\n-    }\n-\n-    public boolean isSubSignature(Type t, Type s, boolean strict) {\n-        return hasSameArgs(t, s, strict) || hasSameArgs(t, erasure(s), strict);\n+        return hasSameArgs(t, s, true) || hasSameArgs(t, erasure(s), true);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Types.java","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -170,2 +170,0 @@\n-        allowPoly = Feature.POLY.allowedInSource(source);\n-        allowLambda = Feature.LAMBDA.allowedInSource(source);\n@@ -191,8 +189,0 @@\n-    \/** Switch: support target-typing inference\n-     *\/\n-    boolean allowPoly;\n-\n-    \/** Switch: support lambda expressions ?\n-     *\/\n-    boolean allowLambda;\n-\n@@ -256,1 +246,1 @@\n-        } else if (allowPoly && inferenceContext.free(found)) {\n+        } else if (inferenceContext.free(found)) {\n@@ -779,1 +769,1 @@\n-            Type argtype = chk.checkNonVoid(arg, attribTree(arg, env, allowPoly ? methodAttrInfo : unknownExprInfo));\n+            Type argtype = chk.checkNonVoid(arg, attribTree(arg, env, methodAttrInfo));\n@@ -1192,8 +1182,9 @@\n-            } else if ((tree.sym.flags() & (ABSTRACT|DEFAULT|PRIVATE)) == ABSTRACT) {\n-                if ((owner.flags() & INTERFACE) != 0) {\n-                    log.error(tree.body.pos(), Errors.IntfMethCantHaveBody);\n-                } else {\n-                    log.error(tree.pos(), Errors.AbstractMethCantHaveBody);\n-                }\n-            } else if ((tree.mods.flags & NATIVE) != 0) {\n-                log.error(tree.pos(), Errors.NativeMethCantHaveBody);\n+                if ((tree.sym.flags() & (ABSTRACT|DEFAULT|PRIVATE)) == ABSTRACT) {\n+                    if ((owner.flags() & INTERFACE) != 0) {\n+                        log.error(tree.body.pos(), Errors.IntfMethCantHaveBody);\n+                    } else {\n+                        log.error(tree.pos(), Errors.AbstractMethCantHaveBody);\n+                    }\n+                } else if ((tree.mods.flags & NATIVE) != 0) {\n+                    log.error(tree.pos(), Errors.NativeMethCantHaveBody);\n+                }\n@@ -2002,2 +1993,1 @@\n-        tree.polyKind = (!allowPoly ||\n-                pt().hasTag(NONE) && pt() != Type.recoveryType && pt() != Infer.anyPoly ||\n+        tree.polyKind = (pt().hasTag(NONE) && pt() != Type.recoveryType && pt() != Infer.anyPoly ||\n@@ -2461,4 +2451,2 @@\n-        Type owntype = attribExpr(tree.expr, env, allowPoly ? Type.noType : syms.throwableType);\n-        if (allowPoly) {\n-            chk.checkType(tree, owntype, syms.throwableType);\n-        }\n+        Type owntype = attribExpr(tree.expr, env, Type.noType);\n+        chk.checkType(tree, owntype, syms.throwableType);\n@@ -4096,1 +4084,1 @@\n-        boolean isPoly = allowPoly && (expr.hasTag(LAMBDA) || expr.hasTag(REFERENCE));\n+        boolean isPoly = (expr.hasTag(LAMBDA) || expr.hasTag(REFERENCE));\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":15,"deletions":27,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -2859,1 +2859,1 @@\n-                if (!types.isSubSignature(sym.type, types.memberType(site, m2), Feature.STRICT_METHOD_CLASH_CHECK.allowedInSource(source)) &&\n+                if (!types.isSubSignature(sym.type, types.memberType(site, m2)) &&\n@@ -2904,1 +2904,1 @@\n-            if (!types.isSubSignature(sym.type, types.memberType(site, s), Feature.STRICT_METHOD_CLASH_CHECK.allowedInSource(source))) {\n+            if (!types.isSubSignature(sym.type, types.memberType(site, s))) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -501,0 +501,1 @@\n+        c.isPermittedExplicit = tree.permitting.nonEmpty();\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Enter.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -79,3 +79,0 @@\n-    \/** Switch: is complex graph inference supported? *\/\n-    private final boolean allowGraphInference;\n-\n@@ -92,2 +89,0 @@\n-        Source source = Source.instance(context);\n-        allowGraphInference = Feature.GRAPH_INFERENCE.allowedInSource(source);\n@@ -593,1 +588,1 @@\n-        tree.cases = translate(tree.cases);\n+        tree.cases = translate(tree.cases, tree.type);\n@@ -681,2 +676,1 @@\n-        boolean useInstantiatedPtArgs =\n-                allowGraphInference && !types.isSignaturePolymorphic((MethodSymbol)meth.baseSymbol());\n+        boolean useInstantiatedPtArgs = !types.isSignaturePolymorphic((MethodSymbol)meth.baseSymbol());\n@@ -716,1 +710,1 @@\n-        List<Type> argtypes = erasedConstructorType != null && allowGraphInference ?\n+        List<Type> argtypes = erasedConstructorType != null ?\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TransTypes.java","additions":3,"deletions":9,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -733,8 +733,0 @@\n-            \/\/ Determine permits.\n-            ListBuffer<Symbol> permittedSubtypeSymbols = new ListBuffer<>();\n-            List<JCExpression> permittedTrees = tree.permitting;\n-            for (JCExpression permitted : permittedTrees) {\n-                Type pt = attr.attribBase(permitted, baseEnv, false, false, false);\n-                permittedSubtypeSymbols.append(pt.tsym);\n-            }\n-\n@@ -749,8 +741,0 @@\n-            \/* it could be that there are already some symbols in the permitted list, for the case\n-             * where there are subtypes in the same compilation unit but the permits list is empty\n-             * so don't overwrite the permitted list if it is not empty\n-             *\/\n-            if (!permittedSubtypeSymbols.isEmpty()) {\n-                sym.permitted = permittedSubtypeSymbols.toList();\n-            }\n-            sym.isPermittedExplicit = !permittedSubtypeSymbols.isEmpty();\n@@ -767,1 +751,1 @@\n-            super(CompletionCause.HIERARCHY_PHASE, new PermitsPhase());\n+            super(CompletionCause.HIERARCHY_PHASE, new HeaderPhase());\n@@ -841,27 +825,0 @@\n-    private final class PermitsPhase extends AbstractHeaderPhase {\n-\n-        public PermitsPhase() {\n-            super(CompletionCause.HIERARCHY_PHASE, new HeaderPhase());\n-        }\n-\n-        @Override\n-        protected void runPhase(Env<AttrContext> env) {\n-            JCClassDecl tree = env.enclClass;\n-            if (!tree.sym.isAnonymous() || tree.sym.isEnum()) {\n-                for (Type supertype : types.directSupertypes(tree.sym.type)) {\n-                    if (supertype.tsym.kind == TYP) {\n-                        ClassSymbol supClass = (ClassSymbol) supertype.tsym;\n-                        Env<AttrContext> supClassEnv = enter.getEnv(supClass);\n-                        if (supClass.isSealed() &&\n-                            !supClass.isPermittedExplicit &&\n-                            supClassEnv != null &&\n-                            supClassEnv.toplevel == env.toplevel) {\n-                            supClass.permitted = supClass.permitted.append(tree.sym);\n-                        }\n-                    }\n-                }\n-            }\n-        }\n-\n-    }\n-\n@@ -891,0 +848,2 @@\n+            fillPermits(tree, baseEnv);\n+\n@@ -919,0 +878,30 @@\n+\n+        private void fillPermits(JCClassDecl tree, Env<AttrContext> baseEnv) {\n+            ClassSymbol sym = tree.sym;\n+\n+            \/\/fill in implicit permits in supertypes:\n+            if (!sym.isAnonymous() || sym.isEnum()) {\n+                for (Type supertype : types.directSupertypes(sym.type)) {\n+                    if (supertype.tsym.kind == TYP) {\n+                        ClassSymbol supClass = (ClassSymbol) supertype.tsym;\n+                        Env<AttrContext> supClassEnv = enter.getEnv(supClass);\n+                        if (supClass.isSealed() &&\n+                            !supClass.isPermittedExplicit &&\n+                            supClassEnv != null &&\n+                            supClassEnv.toplevel == baseEnv.toplevel) {\n+                            supClass.permitted = supClass.permitted.append(sym);\n+                        }\n+                    }\n+                }\n+            }\n+            \/\/ attribute (explicit) permits of the current class:\n+            if (sym.isPermittedExplicit) {\n+                ListBuffer<Symbol> permittedSubtypeSymbols = new ListBuffer<>();\n+                List<JCExpression> permittedTrees = tree.permitting;\n+                for (JCExpression permitted : permittedTrees) {\n+                    Type pt = attr.attribBase(permitted, baseEnv, false, false, false);\n+                    permittedSubtypeSymbols.append(pt.tsym);\n+                }\n+                sym.permitted = permittedSubtypeSymbols.toList();\n+            }\n+        }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":33,"deletions":44,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -2050,1 +2050,0 @@\n-        checkSourceLevel(Feature.LAMBDA);\n@@ -2186,1 +2185,0 @@\n-                checkSourceLevel(Feature.DIAMOND);\n@@ -3370,1 +3368,1 @@\n-            case DEFAULT     : checkSourceLevel(Feature.DEFAULT_METHODS); flag = Flags.DEFAULT; break;\n+            case DEFAULT     : flag = Flags.DEFAULT; break;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/parser\/JavacParser.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3023,1 +3023,0 @@\n-\n@@ -3033,9 +3032,0 @@\n-compiler.misc.feature.diamond=\\\n-    diamond operator\n-\n-compiler.misc.feature.lambda=\\\n-    lambda expressions\n-\n-compiler.misc.feature.default.methods=\\\n-    default methods\n-\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -86,1 +86,1 @@\n-gc\/metaspace\/TestMetaspacePerfCounters.java#Epsilon-64 8293503 macosx-all,windows-x64\n+gc\/metaspace\/TestMetaspacePerfCounters.java#Epsilon-64 8293503 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n- * @bug 8266670 8281463\n+ * @bug 8266670 8281463 8293626\n@@ -46,0 +46,1 @@\n+        testLocationsNullHandling();\n@@ -155,0 +156,11 @@\n+\n+    private static void testLocationsNullHandling() {\n+        for (var flag : AccessFlag.values() ) {\n+            try {\n+                flag.locations(null);\n+                throw new RuntimeException(\"Did not get NPE on \" + flag + \".location(null)\");\n+            } catch (NullPointerException npe ) {\n+                ; \/\/ Expected\n+            }\n+        }\n+    }\n","filename":"test\/jdk\/java\/lang\/reflect\/AccessFlag\/BasicAccessFlagTest.java","additions":13,"deletions":1,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -69,1 +69,0 @@\n-compiler.misc.feature.default.methods                   # just preserved for testing (for now)\n","filename":"test\/langtools\/tools\/javac\/diags\/examples.not-yet.txt","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}