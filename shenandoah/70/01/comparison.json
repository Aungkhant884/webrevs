{"files":[{"patch":"@@ -229,1 +229,1 @@\n-  \/\/ Check if are need to learn a bit about the application\n+  \/\/ Check if we need to learn a bit about the application\n@@ -255,0 +255,3 @@\n+  log_debug(gc)(\"%s: average GC time: %.2f ms, allocation rate: %.0f %s\/s\",\n+    _generation->name(), avg_cycle_time * 1000, byte_size_in_proper_unit(avg_alloc_rate), proper_unit_for_byte_size(avg_alloc_rate));\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -263,0 +263,3 @@\n+  log_debug(gc)(\"%s: average GC time: %.2f ms, allocation rate: %.0f %s\/s\",\n+                _generation->name(), avg_cycle_time * 1000, byte_size_in_proper_unit(avg_alloc_rate), proper_unit_for_byte_size(avg_alloc_rate));\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveOldHeuristics.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -245,0 +245,1 @@\n+        _heap->generation_for(req.affiliation())->increase_allocated(waste);\n@@ -387,1 +388,3 @@\n-    _heap->notify_mutator_alloc_words(ShenandoahHeapRegion::region_size_words() - remainder, true);\n+    size_t waste = ShenandoahHeapRegion::region_size_words() - remainder;\n+    _heap->notify_mutator_alloc_words(waste, true);\n+    _heap->generation_for(req.affiliation())->increase_allocated(waste * HeapWordSize);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -120,1 +120,9 @@\n-  return ShenandoahHeap::heap()->bytes_allocated_since_gc_start();\n+  return Atomic::load(&_bytes_allocated_since_gc_start);;\n+}\n+\n+void ShenandoahGeneration::reset_bytes_allocated_since_gc_start() {\n+  Atomic::store(&_bytes_allocated_since_gc_start, (size_t)0);\n+}\n+\n+void ShenandoahGeneration::increase_allocated(size_t bytes) {\n+  Atomic::add(&_bytes_allocated_since_gc_start, bytes, memory_order_relaxed);\n@@ -276,1 +284,1 @@\n-  _affiliated_region_count(0), _used(0),\n+  _affiliated_region_count(0), _used(0), _bytes_allocated_since_gc_start(0),\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -53,0 +53,1 @@\n+  volatile size_t _bytes_allocated_since_gc_start;\n@@ -78,0 +79,4 @@\n+  size_t bytes_allocated_since_gc_start();\n+  void reset_bytes_allocated_since_gc_start();\n+  void increase_allocated(size_t bytes);\n+\n@@ -82,2 +87,0 @@\n-  virtual size_t bytes_allocated_since_gc_start();\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -506,1 +506,0 @@\n-  _bytes_allocated_since_gc_start(0),\n@@ -694,4 +693,0 @@\n-void ShenandoahHeap::increase_allocated(size_t bytes) {\n-  Atomic::add(&_bytes_allocated_since_gc_start, bytes, memory_order_relaxed);\n-}\n-\n@@ -703,1 +698,1 @@\n-  increase_allocated(bytes);\n+\n@@ -810,0 +805,16 @@\n+void ShenandoahHeap::handle_old_evacuation(HeapWord* obj, size_t words, bool promotion) {\n+  \/\/ Only register the copy of the object that won the evacuation race.\n+  card_scan()->register_object_wo_lock(obj);\n+\n+  \/\/ Mark the entire range of the evacuated object as dirty.  At next remembered set scan,\n+  \/\/ we will clear dirty bits that do not hold interesting pointers.  It's more efficient to\n+  \/\/ do this in batch, in a background GC thread than to try to carefully dirty only cards\n+  \/\/ that hold interesting pointers right now.\n+  card_scan()->mark_range_as_dirty(obj, words);\n+\n+  if (promotion) {\n+    \/\/ This evacuation was a promotion, track this as allocation against old gen\n+    old_generation()->increase_allocated(words * HeapWordSize);\n+  }\n+}\n+\n@@ -1022,0 +1033,1 @@\n+    ShenandoahGeneration* alloc_generation = generation_for(req.affiliation());\n@@ -1024,0 +1036,1 @@\n+    size_t actual_bytes = actual * HeapWordSize;\n@@ -1031,0 +1044,1 @@\n+      alloc_generation->increase_allocated(actual_bytes);\n@@ -1039,1 +1053,1 @@\n-      increase_used(actual*HeapWordSize);\n+      increase_used(actual_bytes);\n@@ -1048,22 +1062,1 @@\n-  HeapWord* result = _free_set->allocate(req, in_new_region);\n-  if (result != NULL && req.affiliation() == ShenandoahRegionAffiliation::OLD_GENERATION) {\n-    \/\/ Register the newly allocated object while we're holding the global lock since there's no synchronization\n-    \/\/ built in to the implementation of register_object().  There are potential races when multiple independent\n-    \/\/ threads are allocating objects, some of which might span the same card region.  For example, consider\n-    \/\/ a card table's memory region within which three objects are being allocated by three different threads:\n-    \/\/\n-    \/\/ objects being \"concurrently\" allocated:\n-    \/\/    [-----a------][-----b-----][--------------c------------------]\n-    \/\/            [---- card table memory range --------------]\n-    \/\/\n-    \/\/ Before any objects are allocated, this card's memory range holds no objects.  Note that:\n-    \/\/   allocation of object a wants to set the has-object, first-start, and last-start attributes of the preceding card region.\n-    \/\/   allocation of object b wants to set the has-object, first-start, and last-start attributes of this card region.\n-    \/\/   allocation of object c also wants to set the has-object, first-start, and last-start attributes of this card region.\n-    \/\/\n-    \/\/ The thread allocating b and the thread allocating c can \"race\" in various ways, resulting in confusion, such as last-start\n-    \/\/ representing object b while first-start represents object c.  This is why we need to require all register_object()\n-    \/\/ invocations to be \"mutually exclusive\" with respect to each card's memory range.\n-    ShenandoahHeap::heap()->card_scan()->register_object(result);\n-  }\n-  return result;\n+  return _free_set->allocate(req, in_new_region);\n@@ -2019,4 +2012,0 @@\n-size_t ShenandoahHeap::bytes_allocated_since_gc_start() {\n-  return Atomic::load(&_bytes_allocated_since_gc_start);\n-}\n-\n@@ -2024,1 +2013,6 @@\n-  Atomic::store(&_bytes_allocated_since_gc_start, (size_t)0);\n+  if (mode()->is_generational()) {\n+    young_generation()->reset_bytes_allocated_since_gc_start();\n+    old_generation()->reset_bytes_allocated_since_gc_start();\n+  }\n+\n+  global_generation()->reset_bytes_allocated_since_gc_start();\n@@ -2743,0 +2737,13 @@\n+\n+ShenandoahGeneration* ShenandoahHeap::generation_for(ShenandoahRegionAffiliation affiliation) const {\n+  if (!mode()->is_generational()) {\n+    return global_generation();\n+  } else if (affiliation == YOUNG_GENERATION) {\n+    return young_generation();\n+  } else if (affiliation == OLD_GENERATION) {\n+    return old_generation();\n+  }\n+\n+  ShouldNotReachHere();\n+  return nullptr;\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":41,"deletions":34,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -226,1 +226,0 @@\n-  volatile size_t _bytes_allocated_since_gc_start;\n@@ -240,1 +239,0 @@\n-  void increase_allocated(size_t bytes);\n@@ -242,1 +240,0 @@\n-  size_t bytes_allocated_since_gc_start();\n@@ -464,0 +461,1 @@\n+  ShenandoahGeneration*      generation_for(ShenandoahRegionAffiliation affiliation) const;\n@@ -678,0 +676,1 @@\n+  void handle_old_evacuation(HeapWord* obj, size_t words, bool promotion);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -314,4 +314,0 @@\n-\n-  if (mode()->is_generational() && obj != NULL) {\n-    ShenandoahHeap::heap()->card_scan()->register_object_wo_lock(obj);\n-  }\n@@ -396,1 +392,1 @@\n-      \/\/ Indicate that a promotion attempt failed.\n+      \/\/ TODO: Inform old generation heuristic of promotion failure\n@@ -411,12 +407,0 @@\n-  if (target_gen == YOUNG_GENERATION) {\n-    \/\/ Increment the age in young copies, absorbing region age.\n-    \/\/ (Only retired regions will have more than zero age to pass along.)\n-\n-    ShenandoahHeap::increase_object_age(copy_val, from_region->age() + 1);\n-\n-    \/\/ Note that p may have been forwarded by another thread,\n-    \/\/ anywhere between here and the check above for forwarding.\n-    \/\/ In that case try_update_forwardee() below will not be successful\n-    \/\/ and the increment we just performed will simply be forgotten,\n-    \/\/ but it will have succeeded in said other thread.\n-  }\n@@ -427,0 +411,1 @@\n+    \/\/ Successfully evacuated. Our copy is now the public one!\n@@ -428,10 +413,5 @@\n-      if (alloc_from_lab) {\n-        card_scan()->register_object_wo_lock(copy);\n-      }\n-      \/\/ else, allocate_memory_under_lock() has already registered the object\n-\n-      \/\/ Mark the entire range of the evacuated object as dirty.  At next remembered set scan,\n-      \/\/ we will clear dirty bits that do not hold interesting pointers.  It's more efficient to\n-      \/\/ do this in batch, in a background GC thread than to try to carefully dirty only cards\n-      \/\/ that hold interesting pointers right now.\n-      card_scan()->mark_range_as_dirty(copy, size);\n+      handle_old_evacuation(copy, size, from_region->is_young());\n+    } else if (target_gen == YOUNG_GENERATION) {\n+      ShenandoahHeap::increase_object_age(copy_val, from_region->age() + 1);\n+    } else {\n+      ShouldNotReachHere();\n@@ -439,1 +419,1 @@\n-    \/\/ Successfully evacuated. Our copy is now the public one!\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":8,"deletions":28,"binary":false,"changes":36,"status":"modified"}]}