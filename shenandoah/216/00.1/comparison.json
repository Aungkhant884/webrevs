{"files":[{"patch":"@@ -33,0 +33,1 @@\n+#include \"gc\/shenandoah\/shenandoahGeneration.hpp\"\n@@ -42,0 +43,1 @@\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.inline.hpp\"\n@@ -47,0 +49,1 @@\n+template <GenerationMode GENERATION>\n@@ -59,1 +62,2 @@\n-    ShenandoahConcurrentWorkerSession worker_session(worker_id);\n+    ShenandoahParallelWorkerSession worker_session(worker_id);\n+    ShenandoahWorkerTimingsTracker timer(ShenandoahPhaseTimings::conc_mark, ShenandoahPhaseTimings::ParallelMark, worker_id, true);\n@@ -61,2 +65,1 @@\n-    ShenandoahObjToScanQueue* q = _cm->get_queue(worker_id);\n-    ShenandoahReferenceProcessor* rp = heap->ref_processor();\n+    ShenandoahReferenceProcessor* rp = heap->active_generation()->ref_processor();\n@@ -65,1 +68,1 @@\n-    _cm->mark_loop(worker_id, _terminator, rp,\n+    _cm->mark_loop(GENERATION, worker_id, _terminator, rp,\n@@ -95,0 +98,1 @@\n+template<GenerationMode GENERATION>\n@@ -110,1 +114,1 @@\n-    ShenandoahReferenceProcessor* rp = heap->ref_processor();\n+    ShenandoahReferenceProcessor* rp = heap->active_generation()->ref_processor();\n@@ -116,0 +120,1 @@\n+      ShenandoahObjToScanQueue* old = _cm->get_old_queue(worker_id);\n@@ -117,1 +122,1 @@\n-      ShenandoahSATBBufferClosure cl(q);\n+      ShenandoahSATBBufferClosure<GENERATION> cl(q, old);\n@@ -122,1 +127,1 @@\n-      ShenandoahMarkRefsClosure             mark_cl(q, rp);\n+      ShenandoahMarkRefsClosure<GENERATION> mark_cl(q, rp, old);\n@@ -127,1 +132,1 @@\n-    _cm->mark_loop(worker_id, _terminator, rp,\n+    _cm->mark_loop(GENERATION, worker_id, _terminator, rp,\n@@ -135,2 +140,2 @@\n-ShenandoahConcurrentMark::ShenandoahConcurrentMark() :\n-  ShenandoahMark() {}\n+ShenandoahConcurrentMark::ShenandoahConcurrentMark(ShenandoahGeneration* generation) :\n+  ShenandoahMark(generation) {}\n@@ -139,0 +144,1 @@\n+template<GenerationMode GENERATION>\n@@ -144,0 +150,1 @@\n+  ShenandoahObjToScanQueueSet* const  _old_queue_set;\n@@ -148,0 +155,1 @@\n+                                    ShenandoahObjToScanQueueSet* old,\n@@ -154,4 +162,6 @@\n-ShenandoahMarkConcurrentRootsTask::ShenandoahMarkConcurrentRootsTask(ShenandoahObjToScanQueueSet* qs,\n-                                                                     ShenandoahReferenceProcessor* rp,\n-                                                                     ShenandoahPhaseTimings::Phase phase,\n-                                                                     uint nworkers) :\n+template<GenerationMode GENERATION>\n+ShenandoahMarkConcurrentRootsTask<GENERATION>::ShenandoahMarkConcurrentRootsTask(ShenandoahObjToScanQueueSet* qs,\n+                                                                                 ShenandoahObjToScanQueueSet* old,\n+                                                                                 ShenandoahReferenceProcessor* rp,\n+                                                                                 ShenandoahPhaseTimings::Phase phase,\n+                                                                                 uint nworkers) :\n@@ -161,0 +171,1 @@\n+  _old_queue_set(old),\n@@ -165,1 +176,2 @@\n-void ShenandoahMarkConcurrentRootsTask::work(uint worker_id) {\n+template<GenerationMode GENERATION>\n+void ShenandoahMarkConcurrentRootsTask<GENERATION>::work(uint worker_id) {\n@@ -168,1 +180,2 @@\n-  ShenandoahMarkRefsClosure cl(q, _rp);\n+  ShenandoahObjToScanQueue* old = _old_queue_set == NULL ? NULL : _old_queue_set->queue(worker_id);\n+  ShenandoahMarkRefsClosure<GENERATION> cl(q, _rp, old);\n@@ -176,7 +189,19 @@\n-  TASKQUEUE_STATS_ONLY(task_queues()->reset_taskqueue_stats());\n-\n-  ShenandoahReferenceProcessor* rp = heap->ref_processor();\n-  task_queues()->reserve(workers->active_workers());\n-  ShenandoahMarkConcurrentRootsTask task(task_queues(), rp, ShenandoahPhaseTimings::conc_mark_roots, workers->active_workers());\n-\n-  workers->run_task(&task);\n+  ShenandoahReferenceProcessor* rp = _generation->ref_processor();\n+  _generation->reserve_task_queues(workers->active_workers());\n+  switch (_generation->generation_mode()) {\n+    case YOUNG: {\n+      ShenandoahMarkConcurrentRootsTask<YOUNG> task(task_queues(), old_task_queues(), rp, ShenandoahPhaseTimings::conc_mark_roots, workers->active_workers());\n+      workers->run_task(&task);\n+      break;\n+    }\n+    case GLOBAL: {\n+      assert(old_task_queues() == NULL, \"Global mark should not have old gen mark queues.\");\n+      ShenandoahMarkConcurrentRootsTask<GLOBAL> task(task_queues(), old_task_queues(), rp, ShenandoahPhaseTimings::conc_mark_roots, workers->active_workers());\n+      workers->run_task(&task);\n+      break;\n+    }\n+    default:\n+      \/\/ Intentionally haven't added OLD here. We use a YOUNG generation\n+      \/\/ cycle to bootstrap concurrent old marking.\n+      ShouldNotReachHere();\n+  }\n@@ -208,3 +233,22 @@\n-    TaskTerminator terminator(nworkers, task_queues());\n-    ShenandoahConcurrentMarkingTask task(this, &terminator);\n-    workers->run_task(&task);\n+    switch (_generation->generation_mode()) {\n+      case YOUNG: {\n+        TaskTerminator terminator(nworkers, task_queues());\n+        ShenandoahConcurrentMarkingTask<YOUNG> task(this, &terminator);\n+        workers->run_task(&task);\n+        break;\n+      }\n+      case OLD: {\n+        TaskTerminator terminator(nworkers, task_queues());\n+        ShenandoahConcurrentMarkingTask<OLD> task(this, &terminator);\n+        workers->run_task(&task);\n+        break;\n+      }\n+      case GLOBAL: {\n+        TaskTerminator terminator(nworkers, task_queues());\n+        ShenandoahConcurrentMarkingTask<GLOBAL> task(this, &terminator);\n+        workers->run_task(&task);\n+        break;\n+      }\n+      default:\n+        ShouldNotReachHere();\n+    }\n@@ -237,3 +281,2 @@\n-  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-  heap->set_concurrent_mark_in_progress(false);\n-  heap->mark_complete_marking_context();\n+  _generation->set_concurrent_mark_in_progress(false);\n+  _generation->set_mark_complete();\n@@ -259,4 +302,19 @@\n-  ShenandoahFinalMarkingTask task(this, &terminator, ShenandoahStringDedup::is_enabled());\n-  heap->workers()->run_task(&task);\n-  assert(task_queues()->is_empty(), \"Should be empty\");\n-}\n+  switch (_generation->generation_mode()) {\n+    case YOUNG:{\n+      ShenandoahFinalMarkingTask<YOUNG> task(this, &terminator, ShenandoahStringDedup::is_enabled());\n+      heap->workers()->run_task(&task);\n+      break;\n+    }\n+    case OLD:{\n+      ShenandoahFinalMarkingTask<OLD> task(this, &terminator, ShenandoahStringDedup::is_enabled());\n+      heap->workers()->run_task(&task);\n+      break;\n+    }\n+    case GLOBAL:{\n+      ShenandoahFinalMarkingTask<GLOBAL> task(this, &terminator, ShenandoahStringDedup::is_enabled());\n+      heap->workers()->run_task(&task);\n+      break;\n+    }\n+    default:\n+      ShouldNotReachHere();\n+  }\n@@ -266,4 +324,1 @@\n-void ShenandoahConcurrentMark::cancel() {\n-  clear();\n-  ShenandoahReferenceProcessor* rp = ShenandoahHeap::heap()->ref_processor();\n-  rp->abandon_partial_discovery();\n+  assert(task_queues()->is_empty(), \"Should be empty\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentMark.cpp","additions":92,"deletions":37,"binary":false,"changes":129,"status":"modified"},{"patch":"@@ -0,0 +1,442 @@\n+\/*\n+ * Copyright (c) 2021, Amazon.com, Inc. or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/shared\/strongRootsScope.hpp\"\n+#include \"gc\/shenandoah\/shenandoahCollectorPolicy.hpp\"\n+#include \"gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.hpp\"\n+#include \"gc\/shenandoah\/heuristics\/shenandoahAggressiveHeuristics.hpp\"\n+#include \"gc\/shenandoah\/heuristics\/shenandoahCompactHeuristics.hpp\"\n+#include \"gc\/shenandoah\/heuristics\/shenandoahOldHeuristics.hpp\"\n+#include \"gc\/shenandoah\/heuristics\/shenandoahStaticHeuristics.hpp\"\n+#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n+#include \"gc\/shenandoah\/shenandoahFreeSet.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeapRegion.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMarkClosures.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMonitoringSupport.hpp\"\n+#include \"gc\/shenandoah\/shenandoahOldGeneration.hpp\"\n+#include \"gc\/shenandoah\/shenandoahOopClosures.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahReferenceProcessor.hpp\"\n+#include \"gc\/shenandoah\/shenandoahStringDedup.hpp\"\n+#include \"gc\/shenandoah\/shenandoahUtils.hpp\"\n+#include \"gc\/shenandoah\/shenandoahWorkerPolicy.hpp\"\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n+#include \"prims\/jvmtiTagMap.hpp\"\n+#include \"runtime\/threads.hpp\"\n+#include \"utilities\/events.hpp\"\n+\n+class ShenandoahFlushAllSATB : public ThreadClosure {\n+ private:\n+  SATBMarkQueueSet& _satb_qset;\n+\n+ public:\n+  explicit ShenandoahFlushAllSATB(SATBMarkQueueSet& satb_qset) :\n+    _satb_qset(satb_qset) {}\n+\n+  void do_thread(Thread* thread) {\n+    \/\/ Transfer any partial buffer to the qset for completed buffer processing.\n+    _satb_qset.flush_queue(ShenandoahThreadLocalData::satb_mark_queue(thread));\n+  }\n+};\n+\n+class ShenandoahProcessOldSATB : public SATBBufferClosure {\n+ private:\n+  ShenandoahObjToScanQueue* _queue;\n+  ShenandoahHeap* _heap;\n+  ShenandoahMarkingContext* const _mark_context;\n+\n+ public:\n+  size_t _trashed_oops;\n+\n+  explicit ShenandoahProcessOldSATB(ShenandoahObjToScanQueue* q) :\n+    _queue(q),\n+    _heap(ShenandoahHeap::heap()),\n+    _mark_context(_heap->marking_context()),\n+    _trashed_oops(0) {}\n+\n+  void do_buffer(void **buffer, size_t size) {\n+    assert(size == 0 || !_heap->has_forwarded_objects() || _heap->is_concurrent_old_mark_in_progress(), \"Forwarded objects are not expected here\");\n+    for (size_t i = 0; i < size; ++i) {\n+      oop *p = (oop *) &buffer[i];\n+      ShenandoahHeapRegion* region = _heap->heap_region_containing(*p);\n+      if (region->is_old() && region->is_active()) {\n+          ShenandoahMark::mark_through_ref<oop, OLD>(p, _queue, NULL, _mark_context, false);\n+      } else {\n+        ++_trashed_oops;\n+      }\n+    }\n+  }\n+};\n+\n+class ShenandoahPurgeSATBTask : public WorkerTask {\n+private:\n+  ShenandoahObjToScanQueueSet* _mark_queues;\n+\n+public:\n+  volatile size_t _trashed_oops;\n+\n+  explicit ShenandoahPurgeSATBTask(ShenandoahObjToScanQueueSet* queues) :\n+    WorkerTask(\"Purge SATB\"),\n+    _mark_queues(queues),\n+    _trashed_oops(0) {\n+    Threads::change_thread_claim_token();\n+  }\n+\n+  ~ShenandoahPurgeSATBTask() {\n+    if (_trashed_oops > 0) {\n+      log_info(gc)(\"Purged \" SIZE_FORMAT \" oops from old generation SATB buffers.\", _trashed_oops);\n+    }\n+  }\n+\n+  void work(uint worker_id) {\n+    ShenandoahParallelWorkerSession worker_session(worker_id);\n+    ShenandoahSATBMarkQueueSet &satb_queues = ShenandoahBarrierSet::satb_mark_queue_set();\n+    ShenandoahFlushAllSATB flusher(satb_queues);\n+    Threads::possibly_parallel_threads_do(true \/* is_par *\/, &flusher);\n+\n+    ShenandoahObjToScanQueue* mark_queue = _mark_queues->queue(worker_id);\n+    ShenandoahProcessOldSATB processor(mark_queue);\n+    while (satb_queues.apply_closure_to_completed_buffer(&processor)) {}\n+\n+    Atomic::add(&_trashed_oops, processor._trashed_oops);\n+  }\n+};\n+\n+class ShenandoahConcurrentCoalesceAndFillTask : public WorkerTask {\n+ private:\n+  uint _nworkers;\n+  ShenandoahHeapRegion** _coalesce_and_fill_region_array;\n+  uint _coalesce_and_fill_region_count;\n+  volatile bool _is_preempted;\n+\n+ public:\n+  ShenandoahConcurrentCoalesceAndFillTask(uint nworkers, ShenandoahHeapRegion** coalesce_and_fill_region_array,\n+                                          uint region_count) :\n+    WorkerTask(\"Shenandoah Concurrent Coalesce and Fill\"),\n+    _nworkers(nworkers),\n+    _coalesce_and_fill_region_array(coalesce_and_fill_region_array),\n+    _coalesce_and_fill_region_count(region_count),\n+    _is_preempted(false) {\n+  }\n+\n+  void work(uint worker_id) {\n+    for (uint region_idx = worker_id; region_idx < _coalesce_and_fill_region_count; region_idx += _nworkers) {\n+      ShenandoahHeapRegion* r = _coalesce_and_fill_region_array[region_idx];\n+      if (r->is_humongous()) {\n+        \/\/ there's only one object in this region and it's not garbage, so no need to coalesce or fill\n+        continue;\n+      }\n+\n+      if (!r->oop_fill_and_coalesce()) {\n+        \/\/ Coalesce and fill has been preempted\n+        Atomic::store(&_is_preempted, true);\n+        return;\n+      }\n+    }\n+  }\n+\n+  \/\/ Value returned from is_completed() is only valid after all worker thread have terminated.\n+  bool is_completed() {\n+    return !Atomic::load(&_is_preempted);\n+  }\n+};\n+\n+ShenandoahOldGeneration::ShenandoahOldGeneration(uint max_queues, size_t max_capacity, size_t soft_max_capacity)\n+  : ShenandoahGeneration(OLD, max_queues, max_capacity, soft_max_capacity),\n+    _coalesce_and_fill_region_array(NEW_C_HEAP_ARRAY(ShenandoahHeapRegion*, ShenandoahHeap::heap()->num_regions(), mtGC)),\n+    _state(IDLE)\n+{\n+  \/\/ Always clear references for old generation\n+  ref_processor()->set_soft_reference_policy(true);\n+}\n+\n+const char* ShenandoahOldGeneration::name() const {\n+  return \"OLD\";\n+}\n+\n+bool ShenandoahOldGeneration::contains(ShenandoahHeapRegion* region) const {\n+  return region->affiliation() != YOUNG_GENERATION;\n+}\n+\n+void ShenandoahOldGeneration::parallel_heap_region_iterate(ShenandoahHeapRegionClosure* cl) {\n+  ShenandoahGenerationRegionClosure<OLD> old_regions(cl);\n+  ShenandoahHeap::heap()->parallel_heap_region_iterate(&old_regions);\n+}\n+\n+void ShenandoahOldGeneration::heap_region_iterate(ShenandoahHeapRegionClosure* cl) {\n+  ShenandoahGenerationRegionClosure<OLD> old_regions(cl);\n+  ShenandoahHeap::heap()->heap_region_iterate(&old_regions);\n+}\n+\n+void ShenandoahOldGeneration::set_concurrent_mark_in_progress(bool in_progress) {\n+  ShenandoahHeap::heap()->set_concurrent_old_mark_in_progress(in_progress);\n+}\n+\n+bool ShenandoahOldGeneration::is_concurrent_mark_in_progress() {\n+  return ShenandoahHeap::heap()->is_concurrent_old_mark_in_progress();\n+}\n+\n+void ShenandoahOldGeneration::cancel_marking() {\n+  if (is_concurrent_mark_in_progress()) {\n+    log_info(gc)(\"Abandon satb buffers.\");\n+    ShenandoahBarrierSet::satb_mark_queue_set().abandon_partial_marking();\n+  }\n+\n+  ShenandoahGeneration::cancel_marking();\n+}\n+\n+void ShenandoahOldGeneration::prepare_gc() {\n+\n+  \/\/ Make the old generation regions parseable, so they can be safely\n+  \/\/ scanned when looking for objects in memory indicated by dirty cards.\n+  if (entry_coalesce_and_fill()) {\n+    \/\/ Now that we have made the old generation parseable, it is safe to reset the mark bitmap.\n+    static const char* msg = \"Concurrent reset (OLD)\";\n+    ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_reset_old);\n+    ShenandoahWorkerScope scope(ShenandoahHeap::heap()->workers(),\n+                                ShenandoahWorkerPolicy::calc_workers_for_conc_reset(),\n+                                msg);\n+    ShenandoahGeneration::prepare_gc();\n+  }\n+  \/\/ Else, coalesce-and-fill has been preempted and we'll finish that effort in the future.  Do not invoke\n+  \/\/ ShenandoahGeneration::prepare_gc() until coalesce-and-fill is done because it resets the mark bitmap\n+  \/\/ and invokes set_mark_incomplete().  Coalesce-and-fill depends on the mark bitmap.\n+}\n+\n+bool ShenandoahOldGeneration::entry_coalesce_and_fill() {\n+  char msg[1024];\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+\n+  ShenandoahConcurrentPhase gc_phase(\"Coalescing and filling (OLD)\", ShenandoahPhaseTimings::coalesce_and_fill);\n+\n+  \/\/ TODO: I don't think we're using these concurrent collection counters correctly.\n+  TraceCollectorStats tcs(heap->monitoring_support()->concurrent_collection_counters());\n+  EventMark em(\"%s\", msg);\n+  ShenandoahWorkerScope scope(heap->workers(),\n+                              ShenandoahWorkerPolicy::calc_workers_for_conc_marking(),\n+                              \"concurrent coalesce and fill\");\n+\n+  return coalesce_and_fill();\n+}\n+\n+bool ShenandoahOldGeneration::coalesce_and_fill() {\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+  heap->set_prepare_for_old_mark_in_progress(true);\n+  transition_to(FILLING);\n+\n+  ShenandoahOldHeuristics* old_heuristics = heap->old_heuristics();\n+  WorkerThreads* workers = heap->workers();\n+  uint nworkers = workers->active_workers();\n+\n+  log_debug(gc)(\"Starting (or resuming) coalesce-and-fill of old heap regions\");\n+  uint coalesce_and_fill_regions_count = old_heuristics->get_coalesce_and_fill_candidates(_coalesce_and_fill_region_array);\n+  assert(coalesce_and_fill_regions_count <= heap->num_regions(), \"Sanity\");\n+  ShenandoahConcurrentCoalesceAndFillTask task(nworkers, _coalesce_and_fill_region_array, coalesce_and_fill_regions_count);\n+\n+  workers->run_task(&task);\n+  if (task.is_completed()) {\n+    \/\/ Remember that we're done with coalesce-and-fill.\n+    heap->set_prepare_for_old_mark_in_progress(false);\n+    transition_to(BOOTSTRAPPING);\n+    return true;\n+  } else {\n+    log_debug(gc)(\"Suspending coalesce-and-fill of old heap regions\");\n+    \/\/ Otherwise, we got preempted before the work was done.\n+    return false;\n+  }\n+}\n+\n+void ShenandoahOldGeneration::transfer_pointers_from_satb() {\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  shenandoah_assert_safepoint();\n+  assert(heap->is_concurrent_old_mark_in_progress(), \"Only necessary during old marking.\");\n+  log_info(gc)(\"Transfer satb buffers.\");\n+  uint nworkers = heap->workers()->active_workers();\n+  StrongRootsScope scope(nworkers);\n+\n+  ShenandoahPurgeSATBTask purge_satb_task(task_queues());\n+  heap->workers()->run_task(&purge_satb_task);\n+}\n+\n+bool ShenandoahOldGeneration::contains(oop obj) const {\n+  return ShenandoahHeap::heap()->is_in_old(obj);\n+}\n+\n+void ShenandoahOldGeneration::prepare_regions_and_collection_set(bool concurrent) {\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  assert(!heap->is_full_gc_in_progress(), \"Only for concurrent and degenerated GC\");\n+\n+  {\n+    ShenandoahGCPhase phase(concurrent ? ShenandoahPhaseTimings::final_update_region_states : ShenandoahPhaseTimings::degen_gc_final_update_region_states);\n+    ShenandoahFinalMarkUpdateRegionStateClosure cl(complete_marking_context());\n+\n+    parallel_heap_region_iterate(&cl);\n+    heap->assert_pinned_region_status();\n+  }\n+\n+  {\n+    \/\/ This doesn't actually choose a collection set, but prepares a list of\n+    \/\/ regions as 'candidates' for inclusion in a mixed collection.\n+    ShenandoahGCPhase phase(concurrent ? ShenandoahPhaseTimings::choose_cset : ShenandoahPhaseTimings::degen_gc_choose_cset);\n+    ShenandoahHeapLocker locker(heap->lock());\n+    heuristics()->choose_collection_set(nullptr, nullptr);\n+  }\n+\n+  {\n+    \/\/ Though we did not choose a collection set above, we still may have\n+    \/\/ freed up immediate garbage regions so proceed with rebuilding the free set.\n+    ShenandoahGCPhase phase(concurrent ? ShenandoahPhaseTimings::final_rebuild_freeset : ShenandoahPhaseTimings::degen_gc_final_rebuild_freeset);\n+    ShenandoahHeapLocker locker(heap->lock());\n+    heap->free_set()->rebuild();\n+  }\n+}\n+\n+const char* ShenandoahOldGeneration::state_name(State state) {\n+  switch (state) {\n+    case IDLE:          return \"Idle\";\n+    case FILLING:       return \"Coalescing\";\n+    case BOOTSTRAPPING: return \"Bootstrapping\";\n+    case MARKING:       return \"Marking\";\n+    case WAITING:       return \"Waiting\";\n+    default:\n+      ShouldNotReachHere();\n+      return \"Unknown\";\n+  }\n+}\n+\n+void ShenandoahOldGeneration::transition_to(State new_state) {\n+  if (_state != new_state) {\n+    log_info(gc)(\"Old generation transition from %s to %s\", state_name(_state), state_name(new_state));\n+    assert(validate_transition(new_state), \"Invalid state transition.\");\n+    _state = new_state;\n+  }\n+}\n+\n+#ifdef ASSERT\n+\/\/ This diagram depicts the expected state transitions for marking the old generation\n+\/\/ and preparing for old collections. When a young generation cycle executes, the\n+\/\/ remembered set scan must visit objects in old regions. Visiting an object which\n+\/\/ has become dead on previous old cycles will result in crashes. To avoid visiting\n+\/\/ such objects, the remembered set scan will use the old generation mark bitmap when\n+\/\/ possible. It is _not_ possible to use the old generation bitmap when old marking\n+\/\/ is active (bitmap is not complete). For this reason, the old regions are made\n+\/\/ parseable _before_ the old generation bitmap is reset. The diagram does not depict\n+\/\/ global and full collections, both of which cancel any old generation activity.\n+\/\/\n+\/\/                              +-----------------+\n+\/\/               +------------> |      IDLE       |\n+\/\/               |   +--------> |                 |\n+\/\/               |   |          +-----------------+\n+\/\/               |   |            |\n+\/\/               |   |            | Begin Old Mark\n+\/\/               |   |            v\n+\/\/               |   |          +-----------------+     +--------------------+\n+\/\/               |   |          |     FILLING     | <-> |      YOUNG GC      |\n+\/\/               |   |          |                 |     | (RSet Uses Bitmap) |\n+\/\/               |   |          +-----------------+     +--------------------+\n+\/\/               |   |            |\n+\/\/               |   |            | Reset Bitmap\n+\/\/               |   |            v\n+\/\/               |   |          +-----------------+\n+\/\/               |   |          |    BOOTSTRAP    |\n+\/\/               |   |          |                 |\n+\/\/               |   |          +-----------------+\n+\/\/               |   |            |\n+\/\/               |   |            | Continue Marking\n+\/\/               |   |            v\n+\/\/               |   |          +-----------------+     +----------------------+\n+\/\/               |   |          |    MARKING      | <-> |       YOUNG GC       |\n+\/\/               |   +----------|                 |     | (RSet Parses Region) |\n+\/\/               |              +-----------------+     +----------------------+\n+\/\/               |                |\n+\/\/               |                | Has Candidates\n+\/\/               |                v\n+\/\/               |              +-----------------+\n+\/\/               |              |     WAITING     |\n+\/\/               +------------- |                 |\n+\/\/                              +-----------------+\n+\/\/\n+bool ShenandoahOldGeneration::validate_transition(State new_state) {\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  switch (new_state) {\n+    case IDLE:\n+      assert(!heap->is_concurrent_old_mark_in_progress(), \"Cannot become idle during old mark.\");\n+      assert(_old_heuristics->unprocessed_old_collection_candidates() == 0, \"Cannot become idle with collection candidates\");\n+      assert(!heap->is_prepare_for_old_mark_in_progress(), \"Cannot become idle while making old generation parseable.\");\n+      assert(heap->young_generation()->old_gen_task_queues() == nullptr, \"Cannot become idle when setup for bootstrapping.\");\n+      return true;\n+    case FILLING:\n+      assert(_state == IDLE, \"Cannot begin filling without first being idle.\");\n+      assert(heap->is_prepare_for_old_mark_in_progress(), \"Should be preparing for old mark now.\");\n+      return true;\n+    case BOOTSTRAPPING:\n+      assert(_state == FILLING, \"Cannot reset bitmap without making old regions parseable.\");\n+      \/\/ assert(heap->young_generation()->old_gen_task_queues() != nullptr, \"Cannot bootstrap without old mark queues.\");\n+      assert(!heap->is_prepare_for_old_mark_in_progress(), \"Cannot still be making old regions parseable.\");\n+      return true;\n+    case MARKING:\n+      assert(_state == BOOTSTRAPPING, \"Must have finished bootstrapping before marking.\");\n+      assert(heap->young_generation()->old_gen_task_queues() != nullptr, \"Young generation needs old mark queues.\");\n+      assert(heap->is_concurrent_old_mark_in_progress(), \"Should be marking old now.\");\n+      return true;\n+    case WAITING:\n+      assert(_state == MARKING, \"Cannot have old collection candidates without first marking.\");\n+      assert(_old_heuristics->unprocessed_old_collection_candidates() > 0, \"Must have collection candidates here.\");\n+      return true;\n+    default:\n+      ShouldNotReachHere();\n+      return false;\n+  }\n+}\n+#endif\n+\n+ShenandoahHeuristics* ShenandoahOldGeneration::initialize_heuristics(ShenandoahMode* gc_mode) {\n+  assert(ShenandoahOldGCHeuristics != NULL, \"ShenandoahOldGCHeuristics should not equal NULL\");\n+  ShenandoahHeuristics* trigger;\n+  if (strcmp(ShenandoahOldGCHeuristics, \"static\") == 0) {\n+    trigger = new ShenandoahStaticHeuristics(this);\n+  } else if (strcmp(ShenandoahOldGCHeuristics, \"adaptive\") == 0) {\n+    trigger = new ShenandoahAdaptiveHeuristics(this);\n+  } else if (strcmp(ShenandoahOldGCHeuristics, \"compact\") == 0) {\n+    trigger = new ShenandoahCompactHeuristics(this);\n+  } else {\n+    vm_exit_during_initialization(\"Unknown -XX:ShenandoahOldGCHeuristics option (must be one of: static, adaptive, compact)\");\n+    ShouldNotReachHere();\n+    return NULL;\n+  }\n+  trigger->set_guaranteed_gc_interval(ShenandoahGuaranteedOldGCInterval);\n+  _old_heuristics = new ShenandoahOldHeuristics(this, trigger);\n+  _heuristics = _old_heuristics;\n+  return _heuristics;\n+}\n+\n+void ShenandoahOldGeneration::record_success_concurrent(bool abbreviated) {\n+  heuristics()->record_success_concurrent(abbreviated);\n+  ShenandoahHeap::heap()->shenandoah_policy()->record_success_old();\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.cpp","additions":442,"deletions":0,"binary":false,"changes":442,"status":"added"}]}