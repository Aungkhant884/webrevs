{"files":[{"patch":"@@ -115,1 +115,1 @@\n-      if (!region->has_live() && !heap->mode()->is_generational()) {\n+      if (!region->has_live()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahHeuristics.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -35,3 +35,1 @@\n-    _hidden_next_old_collection_candidate(0),\n-    _old_coalesce_and_fill_candidates(0),\n-    _first_coalesce_and_fill_candidate(0)\n+    _hidden_next_old_collection_candidate(0)\n@@ -210,2 +208,0 @@\n-      _first_coalesce_and_fill_candidate = (uint)i;\n-      _old_coalesce_and_fill_candidates = (uint)(cand_idx - i);\n@@ -215,3 +211,2 @@\n-      log_info(gc)(\"Old-gen mark evac (%llu RR), %llu CF)\",\n-                   (unsigned long long) (_hidden_old_collection_candidates),\n-                   (unsigned long long) _old_coalesce_and_fill_candidates);\n+      log_info(gc)(\"Old-gen mark evac (%llu RR)\",\n+                   (unsigned long long) (_hidden_old_collection_candidates));\n@@ -225,2 +220,0 @@\n-  _first_coalesce_and_fill_candidate = 0;\n-  _old_coalesce_and_fill_candidates = 0;\n@@ -230,3 +223,2 @@\n-  log_info(gc)(\"Old-gen mark evac (%llu RR), %llu CF)\",\n-               (unsigned long long) (_hidden_old_collection_candidates),\n-               (unsigned long long) _old_coalesce_and_fill_candidates);\n+  log_info(gc)(\"Old-gen mark evac (%llu RR)\",\n+               (unsigned long long) (_hidden_old_collection_candidates));\n@@ -241,1 +233,2 @@\n-  _hidden_old_collection_candidates = 0;}\n+  _hidden_old_collection_candidates = 0;\n+}\n@@ -260,14 +253,0 @@\n-uint ShenandoahOldHeuristics::old_coalesce_and_fill_candidates() {\n-  assert(_generation->generation_mode() == OLD, \"This service only available for old-gc heuristics\");\n-  return _old_coalesce_and_fill_candidates;\n-}\n-\n-void ShenandoahOldHeuristics::get_coalesce_and_fill_candidates(ShenandoahHeapRegion** buffer) {\n-  assert(_generation->generation_mode() == OLD, \"This service only available for old-gc heuristics\");\n-  uint count = _old_coalesce_and_fill_candidates;\n-  int index = _first_coalesce_and_fill_candidate;\n-  while (count-- > 0) {\n-    *buffer++ = _region_data[index++]._region;\n-  }\n-}\n-\n@@ -291,2 +270,0 @@\n-  _old_coalesce_and_fill_candidates = 0;\n-  _first_coalesce_and_fill_candidate = 0;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahOldHeuristics.cpp","additions":7,"deletions":30,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -56,10 +56,0 @@\n-  \/\/ if (_generation->generation_mode() == OLD)\n-  \/\/  _old_coalesce_and_fill_candidates represents the number of regions\n-  \/\/  that were chosen for the garbage contained therein to be coalesced\n-  \/\/  and filled and _first_coalesce_and_fill_candidate represents the\n-  \/\/  the index of the first such region within the _region_data array.\n-  \/\/ if (_generation->generation_mode() != OLD) these two variables are\n-  \/\/  not used.\n-  uint _old_coalesce_and_fill_candidates;\n-  uint _first_coalesce_and_fill_candidate;\n-\n@@ -91,10 +81,0 @@\n-  \/\/ How many old-collection regions were identified at the end of the most recent old-gen mark to require their\n-  \/\/ unmarked objects to be coalesced and filled?\n-  uint old_coalesce_and_fill_candidates();\n-\n-  \/\/ Fill in buffer with all of the old-collection regions that were identified at the end of the most recent old-gen\n-  \/\/ mark to require their unmarked objects to be coalesced and filled.  The buffer array must have at least\n-  \/\/ old_coalesce_and_fill_candidates() entries, or memory may be corrupted when this function overwrites the\n-  \/\/ end of the array.\n-  void get_coalesce_and_fill_candidates(ShenandoahHeapRegion** buffer);\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahOldHeuristics.hpp","additions":0,"deletions":20,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -33,7 +33,0 @@\n-  \/\/ When we fill in dead objects during update refs, we use oop::size,\n-  \/\/ which depends on the klass being loaded. However, if these dead objects\n-  \/\/ were the last referrers to the klass, it will be unloaded and we'll\n-  \/\/ crash. Class unloading is disabled until we're able to sort this out.\n-  FLAG_SET_ERGO(ClassUnloading, false);\n-  FLAG_SET_ERGO(ClassUnloadingWithConcurrentMark, false);\n-  FLAG_SET_ERGO(ShenandoahUnloadClassesFrequency, 0);\n@@ -59,1 +52,0 @@\n-  SHENANDOAH_CHECK_FLAG_UNSET(ClassUnloading);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/mode\/shenandoahGenerationalMode.cpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -0,0 +1,190 @@\n+\/*\n+ * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n+#include \"gc\/shenandoah\/shenandoahBitmapRegion.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeapRegion.hpp\"\n+#include \"memory\/virtualspace.hpp\"\n+#include \"runtime\/globals.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"services\/memTracker.hpp\"\n+#include \"utilities\/powerOfTwo.hpp\"\n+\n+class ShenandoahPretouchBitmapTask : public AbstractGangTask {\n+ private:\n+  ShenandoahRegionIterator _regions;\n+  char* _bitmap_base;\n+  const size_t _bitmap_size;\n+  const size_t _page_size;\n+ public:\n+  ShenandoahPretouchBitmapTask(char* bitmap_base, size_t bitmap_size, size_t page_size) :\n+    AbstractGangTask(\"Shenandoah Pretouch Bitmap\"),\n+    _bitmap_base(bitmap_base),\n+    _bitmap_size(bitmap_size),\n+    _page_size(page_size) {}\n+\n+  virtual void work(uint worker_id) {\n+    ShenandoahHeapRegion* r = _regions.next();\n+    while (r != NULL) {\n+      size_t start = r->index()       * ShenandoahHeapRegion::region_size_bytes() \/ MarkBitMap::heap_map_factor();\n+      size_t end   = (r->index() + 1) * ShenandoahHeapRegion::region_size_bytes() \/ MarkBitMap::heap_map_factor();\n+      assert (end <= _bitmap_size, \"end is sane: \" SIZE_FORMAT \" < \" SIZE_FORMAT, end, _bitmap_size);\n+\n+      if (r->is_committed()) {\n+        os::pretouch_memory(_bitmap_base + start, _bitmap_base + end, _page_size);\n+      }\n+\n+      r = _regions.next();\n+    }\n+  }\n+};\n+\n+void ShenandoahBitmapRegion::initialize(size_t bitmap_size,\n+                                        size_t bitmap_bytes_per_region,\n+                                        size_t num_committed_regions) {\n+  _bitmap_size = bitmap_size;\n+  size_t bitmap_page_size = UseLargePages ? (size_t)os::large_page_size() : (size_t)os::vm_page_size();\n+\n+  guarantee(bitmap_bytes_per_region != 0,\n+            \"Bitmap bytes per region should not be zero\");\n+  guarantee(is_power_of_2(bitmap_bytes_per_region),\n+            \"Bitmap bytes per region should be power of two: \" SIZE_FORMAT, bitmap_bytes_per_region);\n+\n+  if (bitmap_page_size > bitmap_bytes_per_region) {\n+    _bitmap_regions_per_slice = bitmap_page_size \/ bitmap_bytes_per_region;\n+    _bitmap_bytes_per_slice = bitmap_page_size;\n+  } else {\n+    _bitmap_regions_per_slice = 1;\n+    _bitmap_bytes_per_slice = bitmap_bytes_per_region;\n+  }\n+\n+  guarantee(_bitmap_regions_per_slice >= 1,\n+            \"Should have at least one region per slice: \" SIZE_FORMAT,\n+            _bitmap_regions_per_slice);\n+\n+  guarantee(((_bitmap_bytes_per_slice) % bitmap_page_size) == 0,\n+            \"Bitmap slices should be page-granular: bps = Bitmap slices should be page-granular: bps = \" SIZE_FORMAT \", page size = \" SIZE_FORMAT,\n+              _bitmap_bytes_per_slice, bitmap_page_size);\n+\n+  ReservedSpace bitmap(_bitmap_size, bitmap_page_size);\n+  MemTracker::record_virtual_memory_type(bitmap.base(), mtGC);\n+  _bitmap_region = MemRegion((HeapWord*) bitmap.base(), bitmap.size() \/ HeapWordSize);\n+  _bitmap_region_special = bitmap.special();\n+\n+  if (!_bitmap_region_special) {\n+    size_t bitmap_init_commit = _bitmap_bytes_per_slice *\n+                                align_up(num_committed_regions, _bitmap_regions_per_slice) \/ _bitmap_regions_per_slice;\n+    bitmap_init_commit = MIN2(_bitmap_size, bitmap_init_commit);\n+    os::commit_memory_or_exit((char *) _bitmap_region.start(), bitmap_init_commit, bitmap_page_size, false,\n+                              \"Cannot commit bitmap memory\");\n+  }\n+}\n+\n+bool ShenandoahBitmapRegion::commit_bitmap_slice(ShenandoahHeapRegion *r) {\n+  shenandoah_assert_heaplocked();\n+\n+  \/\/ Bitmaps in special regions do not need commits\n+  if (_bitmap_region_special) {\n+    return true;\n+  }\n+\n+  if (is_bitmap_slice_committed(r, true)) {\n+    \/\/ Some other region from the group is already committed, meaning the bitmap\n+    \/\/ slice is already committed, we exit right away.\n+    return true;\n+  }\n+\n+  \/\/ Commit the bitmap slice:\n+  size_t slice = r->index() \/ _bitmap_regions_per_slice;\n+  size_t off = _bitmap_bytes_per_slice * slice;\n+  size_t len = _bitmap_bytes_per_slice;\n+  char* start = (char*) _bitmap_region.start() + off;\n+\n+  if (!os::commit_memory(start, len, false)) {\n+    return false;\n+  }\n+\n+  if (AlwaysPreTouch) {\n+    os::pretouch_memory(start, start + len, _pretouch_bitmap_page_size);\n+  }\n+\n+  return true;\n+}\n+\n+bool ShenandoahBitmapRegion::uncommit_bitmap_slice(ShenandoahHeapRegion *r) {\n+  shenandoah_assert_heaplocked();\n+\n+  \/\/ Bitmaps in special regions do not need uncommits\n+  if (_bitmap_region_special) {\n+    return true;\n+  }\n+\n+  if (is_bitmap_slice_committed(r, true)) {\n+    \/\/ Some other region from the group is still committed, meaning the bitmap\n+    \/\/ slice is should stay committed, exit right away.\n+    return true;\n+  }\n+\n+  \/\/ Uncommit the bitmap slice:\n+  size_t slice = r->index() \/ _bitmap_regions_per_slice;\n+  size_t off = _bitmap_bytes_per_slice * slice;\n+  size_t len = _bitmap_bytes_per_slice;\n+  if (!os::uncommit_memory((char*)_bitmap_region.start() + off, len)) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+bool ShenandoahBitmapRegion::is_bitmap_slice_committed(ShenandoahHeapRegion* r, bool skip_self) {\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  size_t slice = r->index() \/ _bitmap_regions_per_slice;\n+\n+  size_t regions_from = _bitmap_regions_per_slice * slice;\n+  size_t regions_to   = MIN2(heap->num_regions(), _bitmap_regions_per_slice * (slice + 1));\n+  for (size_t g = regions_from; g < regions_to; g++) {\n+    assert (g \/ _bitmap_regions_per_slice == slice, \"same slice\");\n+    if (skip_self && g == r->index()) continue;\n+    if (heap->get_region(g)->is_committed()) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+void ShenandoahBitmapRegion::pretouch(size_t pretouch_bitmap_page_size) {\n+  _pretouch_bitmap_page_size = pretouch_bitmap_page_size;\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  ShenandoahPretouchBitmapTask bcl((char*)_bitmap_region.start(), _bitmap_size, _pretouch_bitmap_page_size);\n+  heap->workers()->run_task(&bcl);\n+}\n+\n+ShenandoahBitmapRegion::ShenandoahBitmapRegion() :\n+  _bitmap_region_special(false),\n+  _bitmap_size(0),\n+  _bitmap_regions_per_slice(0),\n+  _bitmap_bytes_per_slice(0), _pretouch_bitmap_page_size(0) {}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBitmapRegion.cpp","additions":190,"deletions":0,"binary":false,"changes":190,"status":"added"},{"patch":"@@ -0,0 +1,66 @@\n+\/*\n+ * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHBITMAPREGION_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHBITMAPREGION_HPP\n+\n+#include \"memory\/memRegion.hpp\"\n+\n+class ShenandoahHeapRegion;\n+\n+\/*\n+ * The purpose of this class to encapsulate operations on the memory backing\n+ * instances of Shenandoah's mark bitmap. The encapsulation allows Shenandoah\n+ * to use a secondary mark bitmap to support remembered set scans during\n+ * concurrent marking of the old generation.\n+ *\/\n+class ShenandoahBitmapRegion {\n+ public:\n+\n+  ShenandoahBitmapRegion();\n+\n+  void initialize(size_t bitmap_size,\n+                  size_t bitmap_bytes_per_region,\n+                  size_t num_committed_regions);\n+\n+  bool commit_bitmap_slice(ShenandoahHeapRegion *r);\n+  bool uncommit_bitmap_slice(ShenandoahHeapRegion *r);\n+  bool is_bitmap_slice_committed(ShenandoahHeapRegion *r, bool skip_self = false);\n+\n+  void pretouch(size_t pretouch_bitmap_page_size);\n+\n+  MemRegion bitmap_region() { return _bitmap_region; }\n+\n+ private:\n+  MemRegion _bitmap_region;\n+  bool _bitmap_region_special;\n+\n+  size_t _bitmap_size;\n+  size_t _bitmap_regions_per_slice;\n+  size_t _bitmap_bytes_per_slice;\n+  size_t _pretouch_bitmap_page_size;\n+};\n+\n+\n+#endif \/\/SHENANDOAHBITMAPREGION_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBitmapRegion.hpp","additions":66,"deletions":0,"binary":false,"changes":66,"status":"added"},{"patch":"@@ -493,0 +493,1 @@\n+  rp->set_alive_closure(_generation->is_alive_closure());\n@@ -639,0 +640,2 @@\n+  ShenandoahGeneration* const _generation;\n+  bool is_marked(oop obj);\n@@ -641,1 +644,1 @@\n-  ShenandoahEvacUpdateCleanupOopStorageRootsClosure();\n+  ShenandoahEvacUpdateCleanupOopStorageRootsClosure(ShenandoahGeneration* generation);\n@@ -646,1 +649,1 @@\n-ShenandoahEvacUpdateCleanupOopStorageRootsClosure::ShenandoahEvacUpdateCleanupOopStorageRootsClosure() :\n+ShenandoahEvacUpdateCleanupOopStorageRootsClosure::ShenandoahEvacUpdateCleanupOopStorageRootsClosure(ShenandoahGeneration* generation) :\n@@ -650,1 +653,2 @@\n-  _thread(Thread::current()) {\n+  _thread(Thread::current()),\n+  _generation(generation) {\n@@ -656,1 +660,1 @@\n-    if (!_mark_context->is_marked(obj)) {\n+    if (!is_marked(obj)) {\n@@ -672,0 +676,10 @@\n+bool ShenandoahEvacUpdateCleanupOopStorageRootsClosure::is_marked(oop obj) {\n+  \/\/ Old weak handles will be cleaned up in mixed evacuations.\n+  assert(_generation->generation_mode() != OLD, \"Should not be here for old marking cycle.\");\n+  if (_heap->is_concurrent_old_mark_in_progress() && _heap->is_old(obj)) {\n+    return _heap->previous_marking_context()->is_marked(obj);\n+  }\n+\n+  return _heap->marking_context()->is_marked(obj);\n+}\n+\n@@ -703,0 +717,2 @@\n+  ShenandoahGeneration*                      _generation;\n+\n@@ -704,1 +720,1 @@\n-  ShenandoahConcurrentWeakRootsEvacUpdateTask(ShenandoahPhaseTimings::Phase phase) :\n+  ShenandoahConcurrentWeakRootsEvacUpdateTask(ShenandoahPhaseTimings::Phase phase, ShenandoahGeneration* generation) :\n@@ -710,1 +726,2 @@\n-    _phase(phase) {\n+    _phase(phase),\n+    _generation(generation) {\n@@ -736,1 +753,1 @@\n-      ShenandoahEvacUpdateCleanupOopStorageRootsClosure cl;\n+      ShenandoahEvacUpdateCleanupOopStorageRootsClosure cl(_generation);\n@@ -776,1 +793,1 @@\n-    ShenandoahConcurrentWeakRootsEvacUpdateTask task(ShenandoahPhaseTimings::conc_weak_roots_work);\n+    ShenandoahConcurrentWeakRootsEvacUpdateTask task(ShenandoahPhaseTimings::conc_weak_roots_work, _generation);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.cpp","additions":25,"deletions":8,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -412,1 +412,1 @@\n-  const ShenandoahHeap* heap, const GenerationMode generation, GCCause::Cause cause) {\n+  ShenandoahHeap* heap, const GenerationMode generation, GCCause::Cause cause) {\n@@ -443,1 +443,1 @@\n-void ShenandoahControlThread::service_concurrent_old_cycle(const ShenandoahHeap* heap, GCCause::Cause &cause) {\n+void ShenandoahControlThread::service_concurrent_old_cycle(ShenandoahHeap* heap, GCCause::Cause &cause) {\n@@ -459,0 +459,8 @@\n+  \/\/ The remembered set scan uses the markbits for old regions when resolving\n+  \/\/ objects within dirty cards. When this old cycle begins it will reset all\n+  \/\/ the bitmaps. A young collect cycle which interrupts the old marking is at\n+  \/\/ risk from using an incomplete old mark bitmap, so we squirrel away the\n+  \/\/ last known state of the old generation so the rset scan can operate safely\n+  \/\/ during the concurrent marking of old.\n+  heap->swap_marking_contexts();\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.cpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -0,0 +1,1 @@\n+\n@@ -165,1 +166,1 @@\n-  void service_concurrent_normal_cycle(const ShenandoahHeap* heap,\n+  void service_concurrent_normal_cycle(ShenandoahHeap* heap,\n@@ -169,2 +170,1 @@\n-  void service_concurrent_old_cycle(const ShenandoahHeap* heap,\n-                                    GCCause::Cause &cause);\n+  void service_concurrent_old_cycle(ShenandoahHeap* heap, GCCause::Cause &cause);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -173,0 +173,3 @@\n+    if (req.affiliation() == OLD_GENERATION) {\n+      _heap->previous_marking_context()->clear_bitmap(r);\n+    }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -33,0 +33,12 @@\n+#include \"gc\/shenandoah\/shenandoahReferenceProcessor.hpp\"\n+\n+class ShenandoahGlobalIsAliveClosure: public ShenandoahIsMarkedClosure {\n+ public:\n+  virtual bool is_marked(oop obj) override {\n+    return ShenandoahHeap::heap()->marking_context()->is_marked(obj);\n+  }\n+\n+  virtual bool is_marked_strong(oop obj) override {\n+    return ShenandoahHeap::heap()->marking_context()->is_marked_strong(obj);\n+  }\n+};\n@@ -111,0 +123,4 @@\n+  virtual ShenandoahIsMarkedClosure* is_alive_closure() {\n+    return &_is_alive_closure;\n+  }\n+\n@@ -132,0 +148,2 @@\n+\n+  ShenandoahGlobalIsAliveClosure _is_alive_closure;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-  ShenandoahGlobalGeneration(uint max_queues)\n+  explicit ShenandoahGlobalGeneration(uint max_queues)\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGlobalGeneration.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -118,29 +118,0 @@\n-class ShenandoahPretouchBitmapTask : public AbstractGangTask {\n-private:\n-  ShenandoahRegionIterator _regions;\n-  char* _bitmap_base;\n-  const size_t _bitmap_size;\n-  const size_t _page_size;\n-public:\n-  ShenandoahPretouchBitmapTask(char* bitmap_base, size_t bitmap_size, size_t page_size) :\n-    AbstractGangTask(\"Shenandoah Pretouch Bitmap\"),\n-    _bitmap_base(bitmap_base),\n-    _bitmap_size(bitmap_size),\n-    _page_size(page_size) {}\n-\n-  virtual void work(uint worker_id) {\n-    ShenandoahHeapRegion* r = _regions.next();\n-    while (r != NULL) {\n-      size_t start = r->index()       * ShenandoahHeapRegion::region_size_bytes() \/ MarkBitMap::heap_map_factor();\n-      size_t end   = (r->index() + 1) * ShenandoahHeapRegion::region_size_bytes() \/ MarkBitMap::heap_map_factor();\n-      assert (end <= _bitmap_size, \"end is sane: \" SIZE_FORMAT \" < \" SIZE_FORMAT, end, _bitmap_size);\n-\n-      if (r->is_committed()) {\n-        os::pretouch_memory(_bitmap_base + start, _bitmap_base + end, _page_size);\n-      }\n-\n-      r = _regions.next();\n-    }\n-  }\n-};\n-\n@@ -250,2 +221,2 @@\n-  _bitmap_size = ShenandoahMarkBitMap::compute_size(heap_rs.size());\n-  _bitmap_size = align_up(_bitmap_size, bitmap_page_size);\n+  size_t mark_bitmap_size = ShenandoahMarkBitMap::compute_size(heap_rs.size());\n+  mark_bitmap_size = align_up(mark_bitmap_size, bitmap_page_size);\n@@ -255,20 +226,2 @@\n-  guarantee(bitmap_bytes_per_region != 0,\n-            \"Bitmap bytes per region should not be zero\");\n-  guarantee(is_power_of_2(bitmap_bytes_per_region),\n-            \"Bitmap bytes per region should be power of two: \" SIZE_FORMAT, bitmap_bytes_per_region);\n-\n-  if (bitmap_page_size > bitmap_bytes_per_region) {\n-    _bitmap_regions_per_slice = bitmap_page_size \/ bitmap_bytes_per_region;\n-    _bitmap_bytes_per_slice = bitmap_page_size;\n-  } else {\n-    _bitmap_regions_per_slice = 1;\n-    _bitmap_bytes_per_slice = bitmap_bytes_per_region;\n-  }\n-\n-  guarantee(_bitmap_regions_per_slice >= 1,\n-            \"Should have at least one region per slice: \" SIZE_FORMAT,\n-            _bitmap_regions_per_slice);\n-\n-  guarantee(((_bitmap_bytes_per_slice) % bitmap_page_size) == 0,\n-            \"Bitmap slices should be page-granular: bps = \" SIZE_FORMAT \", page size = \" SIZE_FORMAT,\n-            _bitmap_bytes_per_slice, bitmap_page_size);\n+  _bitmap_region_1.initialize(mark_bitmap_size, bitmap_bytes_per_region, num_committed_regions);\n+  _bitmap_region_2.initialize(mark_bitmap_size, bitmap_bytes_per_region, num_committed_regions);\n@@ -276,14 +229,2 @@\n-  ReservedSpace bitmap(_bitmap_size, bitmap_page_size);\n-  MemTracker::record_virtual_memory_type(bitmap.base(), mtGC);\n-  _bitmap_region = MemRegion((HeapWord*) bitmap.base(), bitmap.size() \/ HeapWordSize);\n-  _bitmap_region_special = bitmap.special();\n-\n-  size_t bitmap_init_commit = _bitmap_bytes_per_slice *\n-                              align_up(num_committed_regions, _bitmap_regions_per_slice) \/ _bitmap_regions_per_slice;\n-  bitmap_init_commit = MIN2(_bitmap_size, bitmap_init_commit);\n-  if (!_bitmap_region_special) {\n-    os::commit_memory_or_exit((char *) _bitmap_region.start(), bitmap_init_commit, bitmap_page_size, false,\n-                              \"Cannot commit bitmap memory\");\n-  }\n-\n-  _marking_context = new ShenandoahMarkingContext(_heap_region, _bitmap_region, _num_regions);\n+  _active_marking_context = new ShenandoahMarkingContext(_heap_region, &_bitmap_region_1, _num_regions);\n+  _previous_marking_context = new ShenandoahMarkingContext(_heap_region, &_bitmap_region_2, _num_regions);\n@@ -292,1 +233,1 @@\n-    ReservedSpace verify_bitmap(_bitmap_size, bitmap_page_size);\n+    ReservedSpace verify_bitmap(mark_bitmap_size, bitmap_page_size);\n@@ -304,1 +245,1 @@\n-  ReservedSpace aux_bitmap(_bitmap_size, bitmap_page_size);\n+  ReservedSpace aux_bitmap(mark_bitmap_size, bitmap_page_size);\n@@ -365,1 +306,2 @@\n-      _marking_context->initialize_top_at_mark_start(r);\n+      _active_marking_context->initialize_top_at_mark_start(r);\n+      _previous_marking_context->initialize_top_at_mark_start(r);\n@@ -371,1 +313,2 @@\n-    _marking_context->mark_complete();\n+    _active_marking_context->mark_complete();\n+    _previous_marking_context->mark_complete();\n@@ -383,1 +326,1 @@\n-    _pretouch_bitmap_page_size = bitmap_page_size;\n+    size_t pretouch_bitmap_page_size = bitmap_page_size;\n@@ -391,1 +334,1 @@\n-      _pretouch_bitmap_page_size = (size_t)os::vm_page_size();\n+      pretouch_bitmap_page_size = (size_t)os::vm_page_size();\n@@ -398,2 +341,2 @@\n-    ShenandoahPretouchBitmapTask bcl(bitmap.base(), _bitmap_size, _pretouch_bitmap_page_size);\n-    _workers->run_task(&bcl);\n+    _bitmap_region_1.pretouch(pretouch_bitmap_page_size);\n+    _bitmap_region_2.pretouch(pretouch_bitmap_page_size);\n@@ -527,5 +470,2 @@\n-  _marking_context(NULL),\n-  _bitmap_size(0),\n-  _bitmap_regions_per_slice(0),\n-  _bitmap_bytes_per_slice(0),\n-  _bitmap_region_special(false),\n+  _active_marking_context(NULL),\n+  _previous_marking_context(NULL),\n@@ -1114,2 +1054,1 @@\n-      \/\/ Generational mode doesn't support immediate collection\n-      assert(_sh->mode()->is_generational() || r->has_live(), \"Region \" SIZE_FORMAT \" should have been reclaimed early\", r->index());\n+      assert(r->has_live(), \"Region \" SIZE_FORMAT \" should have been reclaimed early\", r->index());\n@@ -2061,1 +2000,1 @@\n-  set_concurrent_weak_root_in_progress(true);\n+  set_concurrent_weak_root_in_progress(active_generation()->generation_mode() != OLD);\n@@ -2133,1 +2072,1 @@\n-    ShenandoahMarkingContext* const ctx = _heap->marking_context();\n+\n@@ -2147,1 +2086,1 @@\n-            r->oop_iterate(&cl, \/*fill_dead_objects*\/ true, \/* reregister_coalesced_objects *\/ true);\n+            r->oop_iterate(&cl);\n@@ -2153,0 +2092,1 @@\n+              \/\/ TODO: 'Simple' card scanning is deprecated.\n@@ -2170,0 +2110,1 @@\n+    assert(r->is_old(), \"This is only for old regions.\");\n@@ -2173,3 +2114,1 @@\n-      \/\/ We don't have liveness information about this region.\n-      \/\/ Therefore we process all objects, rather than just marked ones.\n-      \/\/ Otherwise subsequent traversals will encounter stale pointers.\n+      ShenandoahMarkingContext* const ctx = _heap->stable_marking_context();\n@@ -2179,0 +2118,1 @@\n+      size_t size(0);\n@@ -2181,2 +2121,5 @@\n-        objs.do_object(obj);\n-        p += obj->size();\n+        bool is_marked = ctx->is_marked_with_size(obj, update_watermark, &size);\n+        if (is_marked) {\n+          objs.do_object(obj);\n+        }\n+        p += size;\n@@ -2275,12 +2218,2 @@\n-  size_t slice = r->index() \/ _bitmap_regions_per_slice;\n-\n-  size_t regions_from = _bitmap_regions_per_slice * slice;\n-  size_t regions_to   = MIN2(num_regions(), _bitmap_regions_per_slice * (slice + 1));\n-  for (size_t g = regions_from; g < regions_to; g++) {\n-    assert (g \/ _bitmap_regions_per_slice == slice, \"same slice\");\n-    if (skip_self && g == r->index()) continue;\n-    if (get_region(g)->is_committed()) {\n-      return true;\n-    }\n-  }\n-  return false;\n+  return _bitmap_region_1.is_bitmap_slice_committed(r, skip_self)\n+      || _bitmap_region_2.is_bitmap_slice_committed(r, skip_self);\n@@ -2290,28 +2223,3 @@\n-  shenandoah_assert_heaplocked();\n-\n-  \/\/ Bitmaps in special regions do not need commits\n-  if (_bitmap_region_special) {\n-    return true;\n-  }\n-\n-  if (is_bitmap_slice_committed(r, true)) {\n-    \/\/ Some other region from the group is already committed, meaning the bitmap\n-    \/\/ slice is already committed, we exit right away.\n-    return true;\n-  }\n-\n-  \/\/ Commit the bitmap slice:\n-  size_t slice = r->index() \/ _bitmap_regions_per_slice;\n-  size_t off = _bitmap_bytes_per_slice * slice;\n-  size_t len = _bitmap_bytes_per_slice;\n-  char* start = (char*) _bitmap_region.start() + off;\n-\n-  if (!os::commit_memory(start, len, false)) {\n-    return false;\n-  }\n-\n-  if (AlwaysPreTouch) {\n-    os::pretouch_memory(start, start + len, _pretouch_bitmap_page_size);\n-  }\n-\n-  return true;\n+  bool committed = _bitmap_region_1.commit_bitmap_slice(r);\n+  committed |= _bitmap_region_2.commit_bitmap_slice(r);\n+  return committed;\n@@ -2321,21 +2229,3 @@\n-  shenandoah_assert_heaplocked();\n-\n-  \/\/ Bitmaps in special regions do not need uncommits\n-  if (_bitmap_region_special) {\n-    return true;\n-  }\n-\n-  if (is_bitmap_slice_committed(r, true)) {\n-    \/\/ Some other region from the group is still committed, meaning the bitmap\n-    \/\/ slice is should stay committed, exit right away.\n-    return true;\n-  }\n-\n-  \/\/ Uncommit the bitmap slice:\n-  size_t slice = r->index() \/ _bitmap_regions_per_slice;\n-  size_t off = _bitmap_bytes_per_slice * slice;\n-  size_t len = _bitmap_bytes_per_slice;\n-  if (!os::uncommit_memory((char*)_bitmap_region.start() + off, len)) {\n-    return false;\n-  }\n-  return true;\n+  bool uncommitted = _bitmap_region_1.uncommit_bitmap_slice(r);\n+  uncommitted |= _bitmap_region_2.uncommit_bitmap_slice(r);\n+  return uncommitted;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":39,"deletions":149,"binary":false,"changes":188,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"gc\/shenandoah\/shenandoahBitmapRegion.hpp\"\n@@ -606,2 +607,5 @@\n-  ShenandoahMarkingContext* _marking_context;\n-  MemRegion  _bitmap_region;\n+  ShenandoahMarkingContext* _active_marking_context;\n+  ShenandoahMarkingContext* _previous_marking_context;\n+  ShenandoahBitmapRegion _bitmap_region_1;\n+  ShenandoahBitmapRegion _bitmap_region_2;\n+\n@@ -612,4 +616,0 @@\n-  size_t _bitmap_size;\n-  size_t _bitmap_regions_per_slice;\n-  size_t _bitmap_bytes_per_slice;\n-\n@@ -617,1 +617,0 @@\n-  size_t _pretouch_bitmap_page_size;\n@@ -619,1 +618,0 @@\n-  bool _bitmap_region_special;\n@@ -627,0 +625,3 @@\n+  inline ShenandoahMarkingContext* previous_marking_context() const;\n+  inline ShenandoahMarkingContext* stable_marking_context() const;\n+  inline void swap_marking_contexts();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":9,"deletions":8,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -343,0 +343,9 @@\n+\n+      bool upgraded(false);\n+      marking_context()->mark_strong(result, upgraded);\n+\n+      \/\/ Marking the previous context (i.e.., last old mark map) is necessary to maintain\n+      \/\/ the information used when scanning the remembered set during concurrent old mark.\n+      if (is_concurrent_old_mark_in_progress()) {\n+        previous_marking_context()->mark_strong(result, upgraded);\n+      }\n@@ -403,1 +412,1 @@\n-  return !_marking_context->is_marked_strong(obj);\n+  return !_active_marking_context->is_marked_strong(obj);\n@@ -615,2 +624,2 @@\n-  assert (_marking_context->is_complete(),\" sanity\");\n-  return _marking_context;\n+  assert (_active_marking_context->is_complete(), \" sanity\");\n+  return _active_marking_context;\n@@ -620,1 +629,15 @@\n-  return _marking_context;\n+  return _active_marking_context;\n+}\n+\n+inline ShenandoahMarkingContext* ShenandoahHeap::previous_marking_context() const {\n+  return _previous_marking_context;\n+}\n+\n+inline ShenandoahMarkingContext* ShenandoahHeap::stable_marking_context() const {\n+  return is_concurrent_old_mark_in_progress() ? _previous_marking_context : _active_marking_context;\n+}\n+\n+inline void ShenandoahHeap::swap_marking_contexts() {\n+  ShenandoahMarkingContext* tmp = _active_marking_context;\n+  _active_marking_context = _previous_marking_context;\n+  _previous_marking_context = tmp;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -264,1 +264,5 @@\n-  reset_age();\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  if (heap->mode()->is_generational()) {\n+    reset_age();\n+  }\n+\n@@ -424,35 +428,2 @@\n-\/\/ oop_iterate without closure\n-void ShenandoahHeapRegion::oop_fill_and_coalesce() {\n-  HeapWord* obj_addr = bottom();\n-  HeapWord* t = top();\n-\n-  assert(!is_humongous(), \"No need to fill or coalesce humongous regions\");\n-  if (!is_active()) return;\n-\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n-  ShenandoahMarkingContext* marking_context = heap->marking_context();\n-\n-  \/\/ Expect this to be invoked only from within threads perfoming old-gen GC, and expect\n-  \/\/ old-gen marking to be completed before these threads invoke this service.\n-  assert(heap->active_generation()->is_mark_complete(), \"sanity\");\n-\n-  while (obj_addr < t) {\n-    oop obj = oop(obj_addr);\n-    if (marking_context->is_marked(obj)) {\n-      assert(obj->klass() != NULL, \"klass should not be NULL\");\n-      obj_addr += obj->size();\n-    } else {\n-      \/\/ Object is not marked.  Coalesce and fill dead object with dead neighbors.\n-      HeapWord* next_marked_obj = marking_context->get_next_marked_addr(obj_addr, t);\n-      assert(next_marked_obj <= t, \"next marked object cannot exceed top\");\n-      size_t fill_size = next_marked_obj - obj_addr;\n-      ShenandoahHeap::fill_with_object(obj_addr, fill_size);\n-      heap->card_scan()->coalesce_objects(obj_addr, fill_size);\n-      obj_addr = next_marked_obj;\n-    }\n-  }\n-}\n-\n-\n-void ShenandoahHeapRegion::oop_iterate(OopIterateClosure* blk, bool fill_dead_objects, bool reregister_coalesced_objects) {\n-  if (!is_active()) return;\n+void ShenandoahHeapRegion::oop_iterate(OopIterateClosure* cl) {\n+  assert(is_active(), \"Region must be active for oop iterate\");\n@@ -460,6 +431,2 @@\n-    \/\/ TODO: This doesn't look right.  This registers objects if !reregister, and it isn't filling if fill_dead_objects.\n-    \/\/ Furthermore, register and fill should be done after iterating.\n-    if (fill_dead_objects && !reregister_coalesced_objects) {\n-      ShenandoahHeap::heap()->card_scan()->register_object(bottom());\n-    }\n-    oop_iterate_humongous(blk);\n+    ShenandoahHeap::heap()->card_scan()->register_object(bottom());\n+    oop_iterate_humongous(cl);\n@@ -467,1 +434,1 @@\n-    oop_iterate_objects(blk, fill_dead_objects, reregister_coalesced_objects);\n+    oop_iterate_objects(cl);\n@@ -471,1 +438,1 @@\n-void ShenandoahHeapRegion::oop_iterate_objects(OopIterateClosure* blk, bool fill_dead_objects, bool reregister_coalesced_objects) {\n+void ShenandoahHeapRegion::oop_iterate_objects(OopIterateClosure* blk) {\n@@ -473,0 +440,3 @@\n+  assert(is_old(), \"Only need this for old regions.\");\n+  assert(ShenandoahHeap::heap()->active_generation()->is_mark_complete(), \"sanity\");\n+\n@@ -474,1 +444,1 @@\n-  HeapWord* t = top();\n+  HeapWord* t = _update_watermark;\n@@ -476,33 +446,9 @@\n-  if (!fill_dead_objects) {\n-    while (obj_addr < t) {\n-      oop obj = oop(obj_addr);\n-      assert(obj->klass() != NULL, \"klass should not be NULL\");\n-      obj_addr += obj->oop_iterate_size(blk);\n-    }\n-  } else {\n-    ShenandoahHeap* heap = ShenandoahHeap::heap();\n-    ShenandoahMarkingContext* marking_context = heap->marking_context();\n-    assert(heap->active_generation()->is_mark_complete(), \"sanity\");\n-    HeapWord* tams = marking_context->top_at_mark_start(this);\n-\n-    while (obj_addr < t) {\n-      oop obj = oop(obj_addr);\n-      if (marking_context->is_marked(obj)) {\n-        assert(obj->klass() != NULL, \"klass should not be NULL\");\n-        if (!reregister_coalesced_objects) {\n-          heap->card_scan()->register_object(obj_addr);\n-        }\n-        obj_addr += obj->oop_iterate_size(blk);\n-      } else {\n-        \/\/ Object is not marked.  Coalesce and fill dead object with dead neighbors.\n-        HeapWord* next_marked_obj = marking_context->get_next_marked_addr(obj_addr, tams);\n-        assert(next_marked_obj <= tams, \"next marked object cannot exceed top at mark start\");\n-        size_t fill_size = next_marked_obj - obj_addr;\n-        ShenandoahHeap::fill_with_object(obj_addr, fill_size);\n-        if (reregister_coalesced_objects) {\n-          heap->card_scan()->coalesce_objects(obj_addr, fill_size);\n-        } else {              \/\/ establish new crossing map information\n-          heap->card_scan()->register_object(obj_addr);\n-        }\n-        obj_addr = next_marked_obj;\n-      }\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  ShenandoahMarkingContext* marking_context = heap->stable_marking_context();\n+\n+  size_t size(0);\n+  while (obj_addr < t) {\n+    oop obj = cast_to_oop(obj_addr);\n+    if (marking_context->is_marked_with_size(obj, t, &size)) {\n+      heap->card_scan()->register_object(cast_from_oop<HeapWord*>(obj));\n+      obj->oop_iterate(blk);\n@@ -510,0 +456,1 @@\n+    obj_addr += size;\n@@ -552,0 +499,4 @@\n+  if (heap->mode()->is_generational()) {\n+    heap->previous_marking_context()->reset_top_at_mark_start(this);\n+  }\n+\n@@ -830,1 +781,1 @@\n-class UpdateCardValuesClosure : public BasicOopIterateClosure {\n+class UpdateCardValuesClosure : public BasicOopIterateClosure, public ObjectClosure {\n@@ -838,0 +789,2 @@\n+  ShenandoahMarkingContext* _ctx;\n+\n@@ -839,0 +792,10 @@\n+  UpdateCardValuesClosure(ShenandoahMarkingContext* ctx) : _ctx(ctx) {}\n+\n+  virtual void do_object(oop obj) {\n+    bool upgraded(false);\n+    ShenandoahHeap::heap()->card_scan()->register_object(cast_from_oop<HeapWord*>(obj));\n+    if (_ctx != NULL) {\n+      _ctx->mark_strong(obj, upgraded);\n+    }\n+  }\n+\n@@ -860,1 +823,0 @@\n-  ShenandoahMarkingContext* marking_context = heap->marking_context();\n@@ -864,1 +826,0 @@\n-  UpdateCardValuesClosure update_card_values;\n@@ -870,1 +831,1 @@\n-    assert(marking_context->is_marked(obj), \"promoted humongous object should be alive\");\n+    assert(ShenandoahHeap::heap()->marking_context()->is_marked(obj), \"promoted humongous object should be alive\");\n@@ -872,0 +833,4 @@\n+    if (heap->is_concurrent_old_mark_in_progress()) {\n+      bool ignore(false);\n+      heap->previous_marking_context()->mark_strong(obj, ignore);\n+    }\n@@ -882,0 +847,1 @@\n+      \/\/ TODO: More precise card marking for humongous objects.\n@@ -902,1 +868,18 @@\n-    oop_iterate_objects(&update_card_values, \/*fill_dead_objects*\/ true, \/* reregister_coalesced_objects *\/ false);\n+\n+    if (!heap->is_concurrent_old_mark_in_progress()) {\n+      \/\/ This is only necessary to register objects with card table. If we replace the\n+      \/\/ object registration with the bitmap, we won't need to do this.\n+      UpdateCardValuesClosure update_card_values(NULL);\n+      heap->marked_object_iterate(this, &update_card_values);\n+    } else {\n+      \/\/ When concurrent old mark is in progress, the remembered set scan will use the last stable\n+      \/\/ bitmap for old regions. We just made this region old and concurrent marking is in progress\n+      \/\/ so update the last stable bitmap for the region.\n+      \/\/ TODO: Find a way to copy the bitmap regions for this region more efficiently.\n+      UpdateCardValuesClosure update_card_values(heap->previous_marking_context());\n+      HeapWord* tams = heap->marking_context()->top_at_mark_start(this);\n+      heap->previous_marking_context()->set_top_at_mark_start(this, tams);\n+      heap->previous_marking_context()->clear_bitmap(this);\n+      heap->marked_object_iterate(this, &update_card_values);\n+      heap->previous_marking_context()->set_top_bitmap(this, tams);\n+    }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.cpp","additions":66,"deletions":83,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -370,4 +370,1 @@\n-  \/\/ coalesce contiguous spans of garbage objects by filling header and reregistering start locations with remembered set.\n-  void oop_fill_and_coalesce();\n-\n-  void oop_iterate(OopIterateClosure* cl, bool fill_dead_objects = false, bool reregister_coalesced_objects = false);\n+  void oop_iterate(OopIterateClosure* cl);\n@@ -424,2 +421,1 @@\n-  void oop_iterate_objects(OopIterateClosure* cl, bool fill_dead_objects, bool reregister_coalesced_objects);\n-  void oop_iterate_objects(bool fill_dead_objects, bool reregister_coalesced_objects);\n+  void oop_iterate_objects(OopIterateClosure* cl);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.hpp","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -159,1 +159,1 @@\n-    log_develop_trace(gc)(\"%s, phase=%u, old_mark=%s, status=%zu\",\n+    log_develop_trace(gc)(\"%s, phase=%u, old_mark=%s, status=\" JLONG_FORMAT,\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegionCounters.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -30,2 +30,2 @@\n-ShenandoahMarkingContext::ShenandoahMarkingContext(MemRegion heap_region, MemRegion bitmap_region, size_t num_regions) :\n-  _mark_bit_map(heap_region, bitmap_region),\n+ShenandoahMarkingContext::ShenandoahMarkingContext(MemRegion heap_region, ShenandoahBitmapRegion* bitmap_region, size_t num_regions) :\n+  _mark_bit_map(heap_region, bitmap_region->bitmap_region()),\n@@ -35,1 +35,2 @@\n-                      ((uintx) heap_region.start() >> ShenandoahHeapRegion::region_size_bytes_shift())) {\n+                      ((uintx) heap_region.start() >> ShenandoahHeapRegion::region_size_bytes_shift())),\n+  _bitmap_region(bitmap_region) {\n@@ -43,1 +44,1 @@\n-    if (heap->is_bitmap_slice_committed(r) && !is_bitmap_clear_range(r->bottom(), r->end())) {\n+    if (_bitmap_region->is_bitmap_slice_committed(r) && !is_bitmap_clear_range(r->bottom(), r->end())) {\n@@ -62,0 +63,4 @@\n+  if (!ShenandoahHeap::heap()->is_bitmap_slice_committed(r)) {\n+    return;\n+  }\n+\n@@ -63,1 +68,1 @@\n-  HeapWord* top_bitmap = _top_bitmaps[r->index()];\n+  HeapWord* top_bitmap = r->end(); \/\/_top_bitmaps[r->index()];\n@@ -72,0 +77,12 @@\n+bool ShenandoahMarkingContext::is_marked_with_size(oop obj, HeapWord* end, size_t* size) const {\n+  bool marked = is_marked(obj);\n+  if (marked) {\n+    *size = obj->size();\n+  } else {\n+    HeapWord* addr = cast_from_oop<HeapWord*>(obj);\n+    HeapWord* next = _mark_bit_map.get_next_marked_addr(addr, end);\n+    *size = pointer_delta(next, addr);\n+  }\n+  return marked;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkingContext.cpp","additions":22,"deletions":5,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+class ShenandoahBitmapRegion;\n@@ -49,0 +50,1 @@\n+  ShenandoahBitmapRegion* _bitmap_region;\n@@ -51,1 +53,1 @@\n-  ShenandoahMarkingContext(MemRegion heap_region, MemRegion bitmap_region, size_t num_regions);\n+  ShenandoahMarkingContext(MemRegion heap_region, ShenandoahBitmapRegion* bitmap_region, size_t num_regions);\n@@ -76,0 +78,1 @@\n+  inline void set_top_at_mark_start(ShenandoahHeapRegion* r, HeapWord* tams);\n@@ -78,2 +81,3 @@\n-  inline void reset_top_bitmap(ShenandoahHeapRegion *r);\n-  void clear_bitmap(ShenandoahHeapRegion *r);\n+  inline void set_top_bitmap(ShenandoahHeapRegion* r, HeapWord* top);\n+  inline void reset_top_bitmap(ShenandoahHeapRegion* r);\n+  void clear_bitmap(ShenandoahHeapRegion* r);\n@@ -87,0 +91,2 @@\n+\n+  bool is_marked_with_size(oop obj, HeapWord* end, size_t* size) const;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkingContext.hpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -95,0 +95,4 @@\n+inline void ShenandoahMarkingContext::set_top_at_mark_start(ShenandoahHeapRegion* r, HeapWord* tams) {\n+  _top_at_mark_starts_base[r->index()] = tams;\n+}\n+\n@@ -99,0 +103,4 @@\n+inline void ShenandoahMarkingContext::set_top_bitmap(ShenandoahHeapRegion* r, HeapWord* top) {\n+  _top_bitmaps[r->index()] = top;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkingContext.inline.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -37,32 +37,0 @@\n-class ShenandoahConcurrentCoalesceAndFillTask : public AbstractGangTask {\n-private:\n-  \/\/ remember nworkers, coalesce_and_fill_region_array,coalesce_and_fill_regions_count\n-\n-  uint _nworkers;\n-  ShenandoahHeapRegion** _coalesce_and_fill_region_array;\n-  uint _coalesce_and_fill_region_count;\n-\n-public:\n-  ShenandoahConcurrentCoalesceAndFillTask(uint nworkers,\n-                                          ShenandoahHeapRegion** coalesce_and_fill_region_array, uint region_count) :\n-    AbstractGangTask(\"Shenandoah Concurrent Coalesce and Fill\"),\n-    _nworkers(nworkers),\n-    _coalesce_and_fill_region_array(coalesce_and_fill_region_array),\n-    _coalesce_and_fill_region_count(region_count) {\n-  }\n-\n-  void work(uint worker_id) {\n-    ShenandoahHeap* heap = ShenandoahHeap::heap();\n-\n-    for (uint region_idx = worker_id; region_idx < _coalesce_and_fill_region_count; region_idx += _nworkers) {\n-      ShenandoahHeapRegion* r = _coalesce_and_fill_region_array[region_idx];\n-      if (!r->is_humongous())\n-        r->oop_fill_and_coalesce();\n-      else {\n-        \/\/ there's only one object in this region and it's not garbage, so no need to coalesce or fill\n-      }\n-    }\n-  }\n-};\n-\n-\n@@ -71,1 +39,0 @@\n-  _coalesce_and_fill_region_array = NEW_C_HEAP_ARRAY(ShenandoahHeapRegion*, ShenandoahHeap::heap()->num_regions(), mtGC);\n@@ -77,1 +44,0 @@\n-  entry_coalesce_and_fill();\n@@ -99,15 +65,0 @@\n-  \/\/ Concurrent stack processing\n-  if (heap->is_evacuation_in_progress()) {\n-    entry_thread_roots();\n-  }\n-\n-  \/\/ Process weak roots that might still point to regions that would be broken by cleanup\n-  if (heap->is_concurrent_weak_root_in_progress()) {\n-    entry_weak_refs();\n-    entry_weak_roots();\n-  }\n-\n-  \/\/ Final mark might have reclaimed some immediate garbage, kick cleanup to reclaim\n-  \/\/ the space. This would be the last action if there is nothing to evacuate.\n-  entry_cleanup_early();\n-\n@@ -119,6 +70,0 @@\n-  \/\/ Perform concurrent class unloading\n-  if (heap->unload_classes() &&\n-      heap->is_concurrent_weak_root_in_progress()) {\n-    entry_class_unloading();\n-  }\n-\n@@ -135,44 +80,0 @@\n-\n-void ShenandoahOldGC::entry_coalesce_and_fill_message(char *buf, size_t len) const {\n-  \/\/ ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-  jio_snprintf(buf, len, \"Coalescing and filling (%s)\", _generation->name());\n-}\n-\n-void ShenandoahOldGC::op_coalesce_and_fill() {\n-  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-\n-  WorkGang* workers = heap->workers();\n-  uint nworkers = workers->active_workers();\n-\n-  assert(_generation->generation_mode() == OLD, \"Only old-GC does coalesce and fill\");\n-\n-  ShenandoahOldHeuristics* old_heuristics = heap->old_heuristics();\n-  uint coalesce_and_fill_regions_count = old_heuristics->old_coalesce_and_fill_candidates();\n-  assert(coalesce_and_fill_regions_count <= heap->num_regions(), \"Sanity\");\n-  old_heuristics->get_coalesce_and_fill_candidates(_coalesce_and_fill_region_array);\n-  ShenandoahConcurrentCoalesceAndFillTask task(nworkers, _coalesce_and_fill_region_array, coalesce_and_fill_regions_count);\n-\n-\n-  \/\/ TODO:  We need to implement preemption of coalesce and fill.  If young-gen wants to run while we're working on this,\n-  \/\/ we should preempt this code and then resume it after young-gen has finished.  This requires that we \"remember\" the state\n-  \/\/ of each worker thread so it can be resumed where it left off.  Note that some worker threads may have processed more regions\n-  \/\/ than others at the time of preemption.\n-\n-  workers->run_task(&task);\n-}\n-\n-void ShenandoahOldGC::entry_coalesce_and_fill() {\n-  char msg[1024];\n-  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-\n-  entry_coalesce_and_fill_message(msg, sizeof(msg));\n-  ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::coalesce_and_fill);\n-\n-  TraceCollectorStats tcs(heap->monitoring_support()->concurrent_collection_counters());\n-  EventMark em(\"%s\", msg);\n-  ShenandoahWorkerScope scope(heap->workers(),\n-                              ShenandoahWorkerPolicy::calc_workers_for_conc_marking(),\n-                              \"concurrent coalesce and fill\");\n-\n-  op_coalesce_and_fill();\n-}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGC.cpp","additions":0,"deletions":99,"binary":false,"changes":99,"status":"modified"},{"patch":"@@ -38,2 +38,0 @@\n-  ShenandoahHeapRegion** _coalesce_and_fill_region_array;\n-\n@@ -41,1 +39,0 @@\n-  void entry_coalesce_and_fill();\n@@ -43,2 +40,0 @@\n-  void op_coalesce_and_fill();\n-  void entry_coalesce_and_fill_message(char *buf, size_t len) const;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGC.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -70,2 +70,0 @@\n-  f(coalesce_and_fill,                              \"Coalesce and Fill Old Dead\")      \\\n-  SHENANDOAH_PAR_PHASE_DO(coalesce_and_fill_,       \"    CFOD: \", f)                   \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPhaseTimings.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -72,2 +72,2 @@\n-static oop lrb(oop obj) {\n-  if (obj != NULL && ShenandoahHeap::heap()->marking_context()->is_marked(obj)) {\n+oop ShenandoahReferenceProcessor::lrb(oop obj) const {\n+  if (obj != NULL && _is_alive_closure->is_marked(obj)) {\n@@ -101,1 +101,1 @@\n-static oop reference_discovered(oop reference) {\n+oop ShenandoahReferenceProcessor::reference_discovered(oop reference) const {\n@@ -142,1 +142,1 @@\n-static oop reference_next(oop reference) {\n+oop ShenandoahReferenceProcessor::reference_next(oop reference) const {\n@@ -163,2 +163,9 @@\n-void ShenandoahRefProcThreadLocal::reset() {\n-  _discovered_list = NULL;\n+void ShenandoahRefProcThreadLocal::reset(bool reset_discovered) {\n+  \/\/ Old marking will discover old references. We expect them to be processed during\n+  \/\/ young collects so we do not want to lose our reference to them when the young\n+  \/\/ cycle starts. When processing is complete it will null out the head of the (now\n+  \/\/ empty) discovered list.\n+  log_trace(gc,ref)(\"Reset ref proc thread locals, discovered: \" PTR_FORMAT, p2i(_discovered_list));\n+  if (reset_discovered) {\n+    _discovered_list = NULL;\n+  }\n@@ -206,1 +213,1 @@\n-    _ref_proc_thread_locals[i].reset();\n+    _ref_proc_thread_locals[i].reset(true \/* reset_discovered *\/);\n@@ -213,1 +220,1 @@\n-    _ref_proc_thread_locals[i].reset();\n+    _ref_proc_thread_locals[i].reset(false \/* reset_discovered *\/);\n@@ -221,0 +228,4 @@\n+void ShenandoahReferenceProcessor::set_alive_closure(ShenandoahIsMarkedClosure* is_marked_closure) {\n+  _is_alive_closure = is_marked_closure;\n+}\n+\n@@ -249,1 +260,2 @@\n-  return ShenandoahHeap::heap()->marking_context()->is_marked_strong(referent);\n+  \/\/ return ShenandoahHeap::heap()->marking_context()->is_marked_strong(referent);\n+  return _is_alive_closure->is_marked_strong(referent);\n@@ -302,1 +314,1 @@\n-    return ShenandoahHeap::heap()->complete_marking_context()->is_marked(referent);\n+    return _is_alive_closure->is_marked(referent);\n@@ -304,1 +316,1 @@\n-    return ShenandoahHeap::heap()->complete_marking_context()->is_marked_strong(referent);\n+    return _is_alive_closure->is_marked_strong(referent);\n@@ -316,1 +328,1 @@\n-    assert(ShenandoahHeap::heap()->marking_context()->is_marked(reference_referent<T>(reference)), \"only make inactive final refs with alive referents\");\n+    assert(_is_alive_closure->is_marked(reference_referent<T>(reference)), \"only make inactive final refs with alive referents\");\n@@ -390,1 +402,1 @@\n-         ShenandoahHeap::heap()->marking_context()->is_marked(reference_referent<T>(reference)), \"only drop references with alive referents\");\n+         _is_alive_closure->is_marked(reference_referent<T>(reference)), \"only drop references with alive referents\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahReferenceProcessor.cpp","additions":25,"deletions":13,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -77,0 +77,5 @@\n+class ShenandoahIsMarkedClosure {\n+public:\n+  virtual bool is_marked(oop obj) = 0;\n+  virtual bool is_marked_strong(oop obj) = 0;\n+};\n@@ -92,1 +97,1 @@\n-  void reset();\n+  void reset(bool reset_discovered = false);\n@@ -142,0 +147,1 @@\n+  ShenandoahIsMarkedClosure* _is_alive_closure;\n@@ -174,0 +180,5 @@\n+  template<typename T>\n+  oop reference_next(oop reference) const;\n+  template <typename T>\n+  oop reference_discovered(oop reference) const;\n+  oop lrb(oop obj) const;\n@@ -179,0 +190,1 @@\n+  void set_alive_closure(ShenandoahIsMarkedClosure* is_marked_closure);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahReferenceProcessor.hpp","additions":13,"deletions":1,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -74,0 +74,1 @@\n+  rp->set_alive_closure(_generation->is_alive_closure());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahSTWMark.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -87,0 +87,6 @@\n+bool ShenandoahDirectCardMarkRememberedSet::is_live(HeapWord* p, HeapWord* endp, size_t* size) {\n+  \/\/ TODO: We don't need to choose the marking context every time we call this method.\n+  ShenandoahMarkingContext* ctx = _heap->stable_marking_context();\n+  return ctx->is_marked_with_size(oop(p), endp, size);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -273,0 +273,2 @@\n+  bool is_live(HeapWord *p, HeapWord *endp, size_t* size);\n+\n@@ -758,17 +760,0 @@\n-  \/\/ Suppose we want to combine several dead objects into a single coalesced object.  How does this\n-  \/\/ impact our representation of crossing map information?\n-  \/\/  1. If the newly coalesced region is contained entirely within a single region, that region's last\n-  \/\/     start entry either remains the same or it is changed to the start of the coalesced region.\n-  \/\/  2. For the region that holds the start of the coalesced object, it will not impact the first start\n-  \/\/     but it may impact the last start.\n-  \/\/  3. For following regions spanned entirely by the newly coalesced object, it will change has_object\n-  \/\/     to false (and make first-start and last-start \"undefined\").\n-  \/\/  4. For a following region that is spanned patially by the newly coalesced object, it may change\n-  \/\/     first-start value, but it will not change the last-start value.\n-  \/\/\n-  \/\/ The range of addresses represented by the arguments to coalesce_objects() must represent a range\n-  \/\/ of memory that was previously occupied exactly by one or more previously registered objects.  For\n-  \/\/ convenience, it is legal to invoke coalesce_objects() with arguments that span a single previously\n-  \/\/ registered object.\n-  void coalesce_objects(HeapWord* address, size_t length_in_words);\n-\n@@ -894,1 +879,0 @@\n-  void coalesce_objects(HeapWord *addr, size_t length_in_words);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.hpp","additions":2,"deletions":18,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -106,0 +106,6 @@\n+\n+  \/\/ If (p + num_heap_words) is not aligned on card boundary, we also need to dirty last card.\n+  if (((unsigned long long) (p + num_heap_words)) & (CardTable::card_size - 1)) {\n+    end_bp++;\n+  }\n+\n@@ -120,0 +126,6 @@\n+\n+  \/\/ If (p + num_heap_words) is not aligned on card boundary, we also need to dirty last card.\n+  if (((unsigned long long) (p + num_heap_words)) & (CardTable::card_size - 1)) {\n+    end_bp++;\n+  }\n+\n@@ -154,50 +166,0 @@\n-template<typename RememberedSet>\n-inline void\n-ShenandoahCardCluster<RememberedSet>::coalesce_objects(HeapWord* address, size_t length_in_words) {\n-#ifdef FAST_REMEMBERED_SET_SCANNING\n-  size_t card_at_start = _rs->card_index_for_addr(address);\n-  HeapWord *card_start_address = _rs->addr_for_card_index(card_at_start);\n-  size_t card_at_end = card_at_start + ((address + length_in_words) - card_start_address) \/ CardTable::card_size_in_words;\n-\n-  if (card_at_start == card_at_end) {\n-    \/\/ No changes to object_starts array.  Either:\n-    \/\/  get_first_start(card_at_start) returns this coalesced object,\n-    \/\/    or it returns an object that precedes the coalesced object.\n-    \/\/  get_last_start(card_at_start) returns the object that immediately follows the coalesced object,\n-    \/\/    or it returns an object that comes after the object immediately following the coalesced object.\n-  } else {\n-    uint8_t coalesced_offset = static_cast<uint8_t>(address - card_start_address);\n-    if (get_last_start(card_at_start) > coalesced_offset) {\n-      \/\/ Existing last start is being coalesced, create new last start\n-      set_last_start(card_at_start, coalesced_offset);\n-    }\n-    \/\/ otherwise, get_last_start(card_at_start) must equal coalesced_offset\n-\n-    \/\/ All the cards between first and last get cleared.\n-    for (size_t i = card_at_start + 1; i < card_at_end; i++) {\n-      clear_has_object_bit(i);\n-    }\n-\n-    uint8_t follow_offset = static_cast<uint8_t>((address + length_in_words) - _rs->addr_for_card_index(card_at_end));\n-    if (has_object(card_at_end) && (get_first_start(card_at_end) < follow_offset)) {\n-      \/\/ It may be that after coalescing within this last card's memory range, the last card\n-      \/\/ no longer holds an object.\n-      if (get_last_start(card_at_end) >= follow_offset) {\n-        set_first_start(card_at_end, follow_offset);\n-      } else {\n-        \/\/ last_start is being coalesced so this card no longer has any objects.\n-        clear_has_object_bit(card_at_end);\n-      }\n-    }\n-    \/\/ else\n-    \/\/  card_at_end did not have an object, so it still does not have an object, or\n-    \/\/  card_at_end had an object that starts after the coalesced object, so no changes required for card_at_end\n-\n-  }\n-#else  \/\/ FAST_REMEMBERED_SET_SCANNING\n-  \/\/ Do nothing for now as we have a brute-force implementation\n-  \/\/ of findSpanningObject().\n-#endif \/\/ FAST_REMEMBERED_SET_SCANNING\n-}\n-\n-\n@@ -407,6 +369,0 @@\n-template<typename RememberedSet>\n-inline void\n-ShenandoahScanRemembered<RememberedSet>::coalesce_objects(HeapWord *addr, size_t length_in_words) {\n-  _scc->coalesce_objects(addr, length_in_words);\n-}\n-\n@@ -463,1 +419,4 @@\n-\n+            size_t size(0);\n+            bool is_live = _rs->is_live(p, endp, &size);\n+            size_t to_end = pointer_delta(endp, p + size);\n+            p += size;\n@@ -468,12 +427,16 @@\n-            if (obj->is_objArray()) {\n-              objArrayOop array = objArrayOop(obj);\n-              int len = array->length();\n-              array->oop_iterate_range(cl, 0, len);\n-            } else if (obj->is_instance()) {\n-              obj->oop_iterate(cl);\n-            } else {\n-              \/\/ Case 3: Primitive array. Do nothing, no oops there. We use the same\n-              \/\/ performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:\n-              \/\/ We skip iterating over the klass pointer since we know that\n-              \/\/ Universe::TypeArrayKlass never moves.\n-              assert (obj->is_typeArray(), \"should be type array\");\n+            \/\/ TODO: The mark loop will do this for us if we can trick it into working on the young\n+            \/\/ pointers of these old objects.\n+            if (is_live) {\n+              if (obj->is_objArray()) {\n+                objArrayOop array = objArrayOop(obj);\n+                int len = array->length();\n+                array->oop_iterate_range(cl, 0, len);\n+              } else if (obj->is_instance()) {\n+                obj->oop_iterate(cl);\n+              } else {\n+                \/\/ Case 3: Primitive array. Do nothing, no oops there. We use the same\n+                \/\/ performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:\n+                \/\/ We skip iterating over the klass pointer since we know that\n+                \/\/ Universe::TypeArrayKlass never moves.\n+                assert (obj->is_typeArray(), \"should be type array\");\n+              }\n@@ -481,1 +444,0 @@\n-            p += obj->size();\n@@ -499,1 +461,3 @@\n-        HeapWord *nextp = p + obj->size();\n+        size_t size(0);\n+        bool is_live = _rs->is_live(p, p + CardTable::card_size_in_words, &size);\n+        HeapWord *nextp = p + size;\n@@ -510,1 +474,1 @@\n-          for (span_card = card_index+1; span_card <= last_card; span_card++)\n+          for (span_card = card_index+1; span_card <= last_card; span_card++) {\n@@ -515,0 +479,1 @@\n+          }\n@@ -517,13 +482,15 @@\n-        if (reaches_next_cluster || spans_dirty_within_this_cluster) {\n-          if (obj->is_objArray()) {\n-            objArrayOop array = objArrayOop(obj);\n-            int len = array->length();\n-            array->oop_iterate_range(cl, 0, len);\n-          } else if (obj->is_instance()) {\n-            obj->oop_iterate(cl);\n-          } else {\n-            \/\/ Case 3: Primitive array. Do nothing, no oops there. We use the same\n-            \/\/ performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:\n-            \/\/ We skip iterating over the klass pointer since we know that\n-            \/\/ Universe::TypeArrayKlass never moves.\n-            assert (obj->is_typeArray(), \"should be type array\");\n+        if (is_live) {\n+          if (reaches_next_cluster || spans_dirty_within_this_cluster) {\n+            if (obj->is_objArray()) {\n+              objArrayOop array = objArrayOop(obj);\n+              int len = array->length();\n+              array->oop_iterate_range(cl, 0, len);\n+            } else if (obj->is_instance()) {\n+              obj->oop_iterate(cl);\n+            } else {\n+              \/\/ Case 3: Primitive array. Do nothing, no oops there. We use the same\n+              \/\/ performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:\n+              \/\/ We skip iterating over the klass pointer since we know that\n+              \/\/ Universe::TypeArrayKlass never moves.\n+              assert (obj->is_typeArray(), \"should be type array\");\n+            }\n@@ -545,0 +512,1 @@\n+  assert(region->is_old() && region->is_active(), \"sanity\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.inline.hpp","additions":53,"deletions":85,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -29,0 +29,17 @@\n+#include \"gc\/shenandoah\/shenandoahReferenceProcessor.hpp\"\n+\n+class ShenandoahYoungIsAliveClosure : public ShenandoahIsMarkedClosure {\n+  bool is_marked(oop obj) override {\n+    return context(obj)->is_marked(obj);\n+  }\n+\n+  bool is_marked_strong(oop obj) override {\n+    return context(obj)->is_marked_strong(obj);\n+  }\n+\n+ private:\n+  static ShenandoahMarkingContext* context(oop obj) {\n+    ShenandoahHeap* heap = ShenandoahHeap::heap();\n+    return heap->is_concurrent_old_mark_in_progress() && heap->is_old(obj) ? heap->previous_marking_context() : heap->marking_context();\n+  }\n+};\n@@ -59,0 +76,4 @@\n+  virtual ShenandoahIsMarkedClosure* is_alive_closure() {\n+    return &_is_alive_closure;\n+  }\n+\n@@ -61,0 +82,3 @@\n+\n+ private:\n+  ShenandoahYoungIsAliveClosure _is_alive_closure;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahYoungGeneration.hpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"}]}