{"files":[{"patch":"@@ -63,0 +63,2 @@\n+const size_t ShenandoahAdaptiveHeuristics::SAMPLE_SIZE = 3;\n+\n@@ -68,3 +70,10 @@\n-  _available(Moving_Average_Samples, ShenandoahAdaptiveDecayFactor) { }\n-\n-ShenandoahAdaptiveHeuristics::~ShenandoahAdaptiveHeuristics() {}\n+  _available(Moving_Average_Samples, ShenandoahAdaptiveDecayFactor),\n+  _first_sample_index(0),\n+  _num_samples(0),\n+  _rate_samples(NEW_C_HEAP_ARRAY(double, SAMPLE_SIZE, mtGC)),\n+  _rate_timestamps(NEW_C_HEAP_ARRAY(double, SAMPLE_SIZE, mtGC)) { }\n+\n+ShenandoahAdaptiveHeuristics::~ShenandoahAdaptiveHeuristics() {\n+  FREE_C_HEAP_ARRAY(double, _rate_samples);\n+  FREE_C_HEAP_ARRAY(double, _rate_timestamps);\n+}\n@@ -184,0 +193,4 @@\n+#define KELVIN_SEE_STATS\n+#ifdef KELVIN_SEE_STATS\n+    log_info(gc)(\"kelvin adjusts last trigger with arg: %.5f\", z_score \/ -100);\n+#endif\n@@ -208,0 +221,28 @@\n+#undef KELVIN_TRACE\n+#ifdef KELVIN_TRACE\n+\n+static double _history_timestamp;\n+static double _history_interval;\n+\n+void ShenandoahAdaptiveHeuristics::timestamp_for_sample(double timestamp, double next_interval) {\n+  _history_timestamp = timestamp;\n+  _history_interval = next_interval;\n+}\n+\n+#define HISTORY_SIZE 512\n+\n+static size_t _history_oldest = 0;\n+static size_t _history_count = 0;\n+static double _historic_avg_cycle_time[HISTORY_SIZE];\n+static double _historic_avg_alloc_rate[HISTORY_SIZE];\n+static double _historic_spike_alloc_rate[HISTORY_SIZE];\n+static double _historic_spike_threshold[HISTORY_SIZE];\n+static double _historic_timestamp[HISTORY_SIZE];\n+static double _historic_interval[HISTORY_SIZE];\n+static unsigned long _historic_headroom[HISTORY_SIZE];\n+static unsigned long _historic_allocated[HISTORY_SIZE];\n+static unsigned long _historic_available[HISTORY_SIZE];\n+static ShenandoahAllocationRate _historic_rates[HISTORY_SIZE];\n+\/\/ _last_sample_time, _last_sample_value, _interval_sec\n+#endif\n+\n@@ -298,0 +339,4 @@\n+#ifdef KELVIN_TRACE\n+    _history_count = 0;\n+    _history_oldest = 0;\n+#endif\n@@ -308,0 +353,14 @@\n+#ifdef KELVIN_TRACE\n+    log_info(gc)(\"Prehistory for instantaneous trigger at time %0.3f\", _history_timestamp);\n+    log_info(gc)(\"%10s:%9s%16s%18s%18s%16s%12s%12s%12s\", \"time_stamp\", \"interval\", \"avg_cycle_time\", \"avg_alloc_rate\", \"spike_alloc_rate\", \"spike_threshold\", \"headroom\", \"allocated\", \"available\");\n+    for (uint i = 0; i < _history_count; i++) {\n+      uint index = _history_oldest + i;\n+      if (index >= HISTORY_SIZE) index = 0;\n+      log_info(gc)(\"%10.3f:%9.3f%16.3f%18.3f%18.3f%16.3f%12lu%12lu%12lu\", _historic_timestamp[index], _historic_interval[index],\n+                   _historic_avg_cycle_time[index], _historic_avg_alloc_rate[index], _historic_spike_alloc_rate[index],\n+                   _historic_spike_threshold[index], _historic_headroom[index], _historic_allocated[index], _historic_available[index]);\n+    }\n+    log_info(gc)(\"%10.3f:%9.3f%16.3f%18.3f%18.3f%16.3f%12lu%12lu%12lu\",\n+                 _history_timestamp, _history_interval, avg_cycle_time * 1000, avg_alloc_rate, rate,\n+                 _spike_threshold_sd, (unsigned long) allocation_headroom, (unsigned long) allocated, (unsigned long) available);\n+#endif\n@@ -312,1 +371,117 @@\n-  return ShenandoahHeuristics::should_start_gc();\n+  \/\/ Allocation rates may accelerate quickly during certain execution phase changes or due to unexpected growth in client demand\n+  \/\/ for a service.  While unbounded quadratic growth of consumption does not fully model this scenario, it is a much better\n+  \/\/ approximation than constant allocation rate within the domain of interest.\n+  \/\/\n+  \/\/ The SPIKE trigger above is not robust against rapidly changing allocation rates.  We have observed situations\n+  \/\/ such as the following:\n+  \/\/\n+  \/\/    Sample Time (s)      Allocation Rate (MB\/s)       Headroom (GB)\n+  \/\/       101.807                       0.0                  26.93\n+  \/\/       101.907                     477.6                  26.85\n+  \/\/       102.007                   3,206.0                  26.35\n+  \/\/       102.108                  23,797.8                  24.19   <--- accelerated spike triggers here\n+  \/\/       102.208                  24,164.5                  21.83\n+  \/\/       102.309                  23,965.0                  19.47\n+  \/\/       102.409                  24,624.35                 17.05   <--- without accelerated spike detection, we trigger here\n+  \/\/\n+  \/\/ The late trigger results in degenerated GC\n+  \/\/\n+  \/\/ The domain of interest is the sampling interval (in this case 100 ms) plus the average gc cycle time (in this case 750 ms).\n+  \/\/ The question we can ask at time 102.108 is:\n+  \/\/\n+  \/\/    Assume allocation rate is accelerating at a constant rate.  If we postpone the spike trigger until the subsequent\n+  \/\/    sample point, will there be enough memory to satisfy allocations that occur during the anticipated concurrent GC\n+  \/\/    cycle?  If not, we should trigger right now.\n+  \/\/\n+  \/\/ Outline of this heuristic triggering technique:\n+  \/\/\n+  \/\/  1. We remember the three most recent samples of spike allocation rate r0, r1, r2 samples at t0, t1, and t2\n+  \/\/  2. if r1 < r0 or r2 < r1, approximate Acceleration = 0.0, Rate = Max(r0, r1, r2)\n+  \/\/  3. Otherwise, use least squares method to compute best-fit line through rate vs time\n+  \/\/  4. The slope of this line represents Acceleration. The y-intercept of this line represents \"initial rate\"\n+  \/\/  5. Calculate modeled CurrentRate by substituting (t2 - t0) for t in the computed best-fit lint\n+  \/\/  6. Use Consumption = CurrentRate * GCTime + 1\/2 * Acceleration * GCTime * GCTime\n+  \/\/     (See High School physics discussions on constant acceleration: D = v0 * t + 1\/2 * a * t^2)\n+  \/\/  7. if Consumption exceeds headroom, trigger now\n+\n+  \/\/ Though larger sample size would improve quality of predictor, it would delay our trigger response as well.  A\n+  \/\/ SAMPLE_SIZE of 2 might work, but that would be more vulnerable to noise.\n+\n+  if (rate > 0.0) {\n+    \/\/ We just collected a new spike allocation rate sample\n+\n+    uint new_sample_index = (_first_sample_index + _num_samples) % SAMPLE_SIZE;\n+\n+    _rate_samples[new_sample_index] = rate;\n+    _rate_timestamps[new_sample_index] = _allocation_rate.last_sample_time();\n+    if (_num_samples == SAMPLE_SIZE) {\n+      _first_sample_index++;\n+      if (_first_sample_index == SAMPLE_SIZE) {\n+        _first_sample_index = 0;\n+      }\n+    } else {\n+      _num_samples++;\n+    }\n+\n+    if (is_spiking) {\n+      double acceleration;\n+      double current_alloc_rate;\n+      size_t consumption = accelerated_consumption(acceleration, current_alloc_rate, avg_cycle_time);\n+      if (consumption > allocation_headroom) {\n+        size_t size_t_acceleration = (size_t) acceleration;\n+        size_t size_t_alloc_rate = (size_t) current_alloc_rate;\n+        log_info(gc)(\"Trigger (%s): Accelerated consumption (\" SIZE_FORMAT \"%s) exceeds free headroom (\" SIZE_FORMAT \"%s) at \"\n+                     \"current rate (\" SIZE_FORMAT \"%s\/s) with acceleration (\" SIZE_FORMAT \"%s\/s\/s) for average GC time (%.2f ms)\",\n+                     _space_info->name(),\n+                     byte_size_in_proper_unit(consumption), proper_unit_for_byte_size(consumption),\n+                     byte_size_in_proper_unit(allocation_headroom), proper_unit_for_byte_size(allocation_headroom),\n+                     byte_size_in_proper_unit(size_t_alloc_rate), proper_unit_for_byte_size(size_t_alloc_rate),\n+                     byte_size_in_proper_unit(size_t_acceleration), proper_unit_for_byte_size(size_t_acceleration),\n+                     avg_cycle_time * 1000);\n+        _num_samples = 0;\n+        _first_sample_index = 0;\n+\n+        \/\/ Count this as an OTHER trigger: we do NOT want to adjust spike threshold or margin of error since\n+        \/\/  acceleration of allocation rate is intended to be relatively rare.\n+        _last_trigger = OTHER;\n+        return true;\n+      }\n+    }\n+  }\n+\n+#ifdef KELVIN_TRACE\n+  if (ShenandoahHeuristics::should_start_gc()) {\n+    _history_count = 0;\n+    _history_oldest = 0;\n+    return true;\n+  } else {\n+    size_t _history_index = (_history_oldest + _history_count) % HISTORY_SIZE;\n+    _historic_avg_cycle_time[_history_index] = avg_cycle_time * 1000;\n+    _historic_avg_alloc_rate[_history_index] = avg_alloc_rate;\n+    _historic_spike_alloc_rate[_history_index] = rate;\n+    _historic_spike_threshold[_history_index] = _spike_threshold_sd;\n+    _historic_timestamp[_history_index] = _history_timestamp;\n+    _historic_interval[_history_index] = _history_interval;\n+    _historic_headroom[_history_index] = (unsigned long) allocation_headroom;\n+    _historic_allocated[_history_index] = (unsigned long) allocated;\n+    _historic_available[_history_index] = (unsigned long) available;\n+    if (_history_count < HISTORY_SIZE) {\n+      \/\/ no wrap around, so no need to adjust _history_oldest\n+      _history_count++;\n+    } else {\n+      \/\/ We're already full.  Don't increment _history_count.  Do increment _history_oldest.\n+      _history_oldest++;\n+      if (_history_oldest >= HISTORY_SIZE) {\n+        _history_oldest = 0;\n+      }\n+    }\n+    return false;\n+  }\n+#endif\n+  if (ShenandoahHeuristics::should_start_gc()) {\n+    _num_samples = 0;\n+    _first_sample_index = 0;\n+    return true;\n+  } else {\n+    return false;\n+  }\n@@ -331,0 +506,68 @@\n+size_t ShenandoahAdaptiveHeuristics::accelerated_consumption(double& acceleration, double& current_rate, double avg_cycle_time) {\n+  double *x_array = (double *) alloca(SAMPLE_SIZE * sizeof(double));\n+  double *y_array = (double *) alloca(SAMPLE_SIZE * sizeof(double));\n+  double x_sum = 0.0;\n+  double y_sum = 0.0;\n+\n+#undef KELVIN_TRACE_CONSUMPTION\n+#ifdef KELVIN_TRACE_CONSUMPTION\n+  log_info(gc)(\"accelerated_consumption(), num_samples: %u\", _num_samples);\n+  for (uint i = 0; i < _num_samples; i++) {\n+    uint index = (_first_sample_index + i) % SAMPLE_SIZE;\n+    log_info(gc)(\"sample[%d]: %.3f @ time %.3f\", i, _rate_samples[index], _rate_timestamps[index]);\n+  }\n+#endif\n+\n+  for (uint i = 0; i < _num_samples; i++) {\n+    uint index = (_first_sample_index + i) % SAMPLE_SIZE;\n+    x_array[i] = _rate_timestamps[index];\n+    x_sum += x_array[i];\n+    y_array[i] = _rate_samples[index];\n+    y_sum += y_array[i];\n+  }\n+  bool spikes_increasing = true;\n+  for (uint i = 1; i < _num_samples; i++) {\n+    if (y_array[i] <= y_array[i-1]) {\n+      spikes_increasing = false;\n+      break;\n+    }\n+  }\n+  if (!spikes_increasing || (_num_samples < SAMPLE_SIZE)) {\n+    acceleration = 0.0;\n+    current_rate = y_sum \/ _num_samples;\n+  } else {\n+    double *xy_array = (double *) alloca(SAMPLE_SIZE * sizeof(double));\n+    double *x2_array = (double *) alloca(SAMPLE_SIZE * sizeof(double));\n+    double xy_sum = 0.0;\n+    double x2_sum = 0.0;\n+    for (uint i = 0; i < SAMPLE_SIZE; i++) {\n+      xy_array[i] = x_array[i] * y_array[i];\n+      xy_sum += xy_array[i];\n+      x2_array[i] = x_array[i] * x_array[i];\n+      x2_sum += x2_array[i];\n+    }\n+    \/\/ Find the best-fit least-squares linear representation of rate vs time\n+    double m;                 \/* slope *\/\n+    double b;                 \/* y-intercept *\/\n+    m = (SAMPLE_SIZE * xy_sum - x_sum * y_sum) \/ (SAMPLE_SIZE * x2_sum - x_sum * x_sum);\n+    b = (y_sum - m * x_sum) \/ SAMPLE_SIZE;\n+    acceleration = m;\n+    current_rate = m * x_array[SAMPLE_SIZE - 1] + b;\n+#ifdef KELVIN_TRACE_CONSUMPTION\n+    log_info(gc)(\"Best-fit line has m %.3f, b: %.3f\", m, b);\n+    for (uint i = 0; i < SAMPLE_SIZE; i++) {\n+      log_info(gc)(\"sample[%d] timestamp: %12.3f, predicted rate: %12.3f\", i, x_array[i], m * x_array[i] + b);\n+    }\n+#endif\n+  }\n+\n+  double time_delta = _allocation_rate.interval() + avg_cycle_time;\n+  size_t bytes_to_be_consumed = (size_t) (current_rate * time_delta + 0.5 * acceleration * time_delta * time_delta);\n+#ifdef KELVIN_TRACE_CONSUMPTION\n+  log_info(gc)(\"accelerated_consumption() acceleration: %0.3f, current_rate: %0.3f, time_delta: %0.3f returning \" SIZE_FORMAT \"%s\",\n+               acceleration, current_rate, time_delta,\n+               byte_size_in_proper_unit(bytes_to_be_consumed), proper_unit_for_byte_size(bytes_to_be_consumed));\n+#endif\n+  return bytes_to_be_consumed;\n+}\n+\n@@ -392,2 +635,4 @@\n-    \/\/ There is a small chance that that rate has already been sampled, but it\n-    \/\/ seems not to matter in practice.\n+    \/\/ There is a small chance that that rate has already been sampled, but it seems not to matter in practice.\n+    \/\/ z_score reports how close this measure is to the average.  A value between -1 and 1 means we are within 1\n+    \/\/ standard deviation.  A value between -3 and +3 meands we are within 3 standard deviations.  In our use\n+    \/\/ case, we only care if the spike is above the mean.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.cpp","additions":251,"deletions":6,"binary":false,"changes":257,"status":"modified"},{"patch":"@@ -46,0 +46,6 @@\n+  double interval() const {\n+    return _interval_sec;\n+  }\n+  double last_sample_time() const {\n+    return _last_sample_time;\n+  }\n@@ -84,1 +90,4 @@\n-\n+#undef KELVIN_TRACE\n+#ifdef KELVIN_TRACE\n+  void timestamp_for_sample(double timestamp, double interval);\n+#endif\n@@ -102,0 +111,2 @@\n+  const static size_t SAMPLE_SIZE;\n+\n@@ -104,0 +115,1 @@\n+\n@@ -116,0 +128,2 @@\n+  size_t accelerated_consumption(double& acceleration, double& current_rate, double avg_cycle_time);\n+\n@@ -145,0 +159,6 @@\n+  \/\/ Keep track of SAMPLE_SIZE most recent spike allocation rate measurements\n+  uint _first_sample_index;\n+  uint _num_samples;\n+  double* const _rate_samples;\n+  double* const _rate_timestamps;\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.hpp","additions":21,"deletions":1,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -85,0 +85,7 @@\n+#undef KELVIN_TRACE\n+#ifdef KELVIN_TRACE\n+  if (which_set == Mutator) {\n+    log_info(gc, free)(\"Mutator CON$UME$: \" SIZE_FORMAT \", remaining available: \" SIZE_FORMAT,\n+                       bytes, _capacity_of[Mutator] - _used_by[Mutator]);\n+  }\n+#endif\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -26,0 +26,2 @@\n+#undef KELVIN_TRACE\n+\n@@ -33,0 +35,3 @@\n+#ifdef KELVIN_TRACE\n+#include \"gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.hpp\"\n+#endif\n@@ -67,0 +72,5 @@\n+#ifdef KELVIN_TRACE\n+static double _most_recent_timestamp;\n+static double _next_sleep_interval;\n+#endif\n+\n@@ -70,0 +80,4 @@\n+#ifdef KELVIN_TRACE\n+  ShenandoahAdaptiveHeuristics* adaptive_heuristics =\n+         (ShenandoahAdaptiveHeuristics*)ShenandoahHeap::heap()->young_heuristics();\n+#endif\n@@ -79,0 +93,3 @@\n+#ifdef KELVIN_TRACE\n+        adaptive_heuristics->timestamp_for_sample(_most_recent_timestamp, _next_sleep_interval);\n+#endif\n@@ -86,0 +103,3 @@\n+#ifdef KELVIN_TRACE\n+      adaptive_heuristics->timestamp_for_sample(_most_recent_timestamp, _next_sleep_interval);\n+#endif\n@@ -131,1 +151,3 @@\n-\n+#ifdef KELVIN_TRACE\n+  _most_recent_timestamp = current;\n+#endif\n@@ -138,0 +160,3 @@\n+#ifdef KELVIN_TRACE\n+  _next_sleep_interval = _sleep;\n+#endif\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRegulatorThread.cpp","additions":26,"deletions":1,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -179,1 +179,1 @@\n-  product(uintx, ShenandoahLearningSteps, 10, EXPERIMENTAL,                 \\\n+  product(uintx, ShenandoahLearningSteps, 5, EXPERIMENTAL,                  \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoah_globals.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}