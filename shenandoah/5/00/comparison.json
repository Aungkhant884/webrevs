{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2018, 2020 Red Hat, Inc. All rights reserved.\n@@ -92,1 +92,8 @@\n-  return BarrierSetC1::atomic_cmpxchg_at_resolved(access, cmp_value, new_value);\n+\n+  LIR_Opr result =  BarrierSetC1::atomic_cmpxchg_at_resolved(access, cmp_value, new_value);\n+\n+  if (access.is_oop()) {\n+    post_barrier(access, access.resolved_addr(), new_value.result());\n+  }\n+\n+  return result;\n@@ -122,0 +129,1 @@\n+    post_barrier(access, access.resolved_addr(), result);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shenandoah\/c1\/shenandoahBarrierSetC1_x86.cpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"gc\/shenandoah\/mode\/shenandoahMode.hpp\"\n@@ -568,0 +569,49 @@\n+void ShenandoahBarrierSetAssembler::store_check(MacroAssembler* masm, Register obj, Address dst) {\n+  if (!ShenandoahHeap::heap()->mode()->is_generational()) {\n+    return;\n+  }\n+\n+  \/\/ Does a store check for the oop in register obj. The content of\n+  \/\/ register obj is destroyed afterwards.\n+  BarrierSet* bs = BarrierSet::barrier_set();\n+\n+  ShenandoahBarrierSet* ctbs = barrier_set_cast<ShenandoahBarrierSet>(bs);\n+  CardTable* ct = ctbs->card_table();\n+\n+  __ shrptr(obj, CardTable::card_shift);\n+\n+  Address card_addr;\n+\n+  \/\/ The calculation for byte_map_base is as follows:\n+  \/\/ byte_map_base = _byte_map - (uintptr_t(low_bound) >> card_shift);\n+  \/\/ So this essentially converts an address to a displacement and it will\n+  \/\/ never need to be relocated. On 64bit however the value may be too\n+  \/\/ large for a 32bit displacement.\n+  intptr_t byte_map_base = (intptr_t)ct->byte_map_base();\n+  if (__ is_simm32(byte_map_base)) {\n+    card_addr = Address(noreg, obj, Address::times_1, byte_map_base);\n+  } else {\n+    \/\/ By doing it as an ExternalAddress 'byte_map_base' could be converted to a rip-relative\n+    \/\/ displacement and done in a single instruction given favorable mapping and a\n+    \/\/ smarter version of as_Address. However, 'ExternalAddress' generates a relocation\n+    \/\/ entry and that entry is not properly handled by the relocation code.\n+    AddressLiteral cardtable((address)byte_map_base, relocInfo::none);\n+    Address index(noreg, obj, Address::times_1);\n+    card_addr = __ as_Address(ArrayAddress(cardtable, index));\n+  }\n+\n+  int dirty = CardTable::dirty_card_val();\n+  if (UseCondCardMark) {\n+    Label L_already_dirty;\n+    if (ct->scanned_concurrently()) {\n+      __ membar(Assembler::StoreLoad);\n+    }\n+    __ cmpb(card_addr, dirty);\n+    __ jcc(Assembler::equal, L_already_dirty);\n+    __ movb(card_addr, dirty);\n+    __ bind(L_already_dirty);\n+  } else {\n+    __ movb(card_addr, dirty);\n+  }\n+}\n+\n@@ -569,1 +619,1 @@\n-              Address dst, Register val, Register tmp1, Register tmp2) {\n+                                             Address dst, Register val, Register tmp1, Register tmp2) {\n@@ -611,0 +661,1 @@\n+      store_check(masm, tmp1, dst);\n@@ -802,0 +853,56 @@\n+#ifdef PRODUCT\n+#define BLOCK_COMMENT(str) \/* nothing *\/\n+#else\n+#define BLOCK_COMMENT(str) __ block_comment(str)\n+#endif\n+\n+#define BIND(label) bind(label); BLOCK_COMMENT(#label \":\")\n+\n+#define TIMES_OOP (UseCompressedOops ? Address::times_4 : Address::times_8)\n+\n+void ShenandoahBarrierSetAssembler::gen_write_ref_array_post_barrier(MacroAssembler* masm, DecoratorSet decorators, Register addr, Register count, Register tmp) {\n+  if (!ShenandoahHeap::heap()->mode()->is_generational()) {\n+    return;\n+  }\n+\n+  BarrierSet *bs = BarrierSet::barrier_set();\n+  ShenandoahBarrierSet* ctbs = barrier_set_cast<ShenandoahBarrierSet>(bs);\n+  CardTable* ct = ctbs->card_table();\n+  intptr_t disp = (intptr_t) ct->byte_map_base();\n+\n+  Label L_loop, L_done;\n+  const Register end = count;\n+  assert_different_registers(addr, end);\n+\n+  __ testl(count, count);\n+  __ jcc(Assembler::zero, L_done); \/\/ zero count - nothing to do\n+\n+\n+#ifdef _LP64\n+  __ leaq(end, Address(addr, count, TIMES_OOP, 0));  \/\/ end == addr+count*oop_size\n+  __ subptr(end, BytesPerHeapOop); \/\/ end - 1 to make inclusive\n+  __ shrptr(addr, CardTable::card_shift);\n+  __ shrptr(end, CardTable::card_shift);\n+  __ subptr(end, addr); \/\/ end --> cards count\n+\n+  __ mov64(tmp, disp);\n+  __ addptr(addr, tmp);\n+__ BIND(L_loop);\n+  __ movb(Address(addr, count, Address::times_1), 0);\n+  __ decrement(count);\n+  __ jcc(Assembler::greaterEqual, L_loop);\n+#else\n+  __ lea(end,  Address(addr, count, Address::times_ptr, -wordSize));\n+  __ shrptr(addr, CardTable::card_shift);\n+  __ shrptr(end,   CardTable::card_shift);\n+  __ subptr(end, addr); \/\/ end --> count\n+__ BIND(L_loop);\n+  Address cardtable(addr, count, Address::times_1, disp);\n+  __ movb(cardtable, 0);\n+  __ decrement(count);\n+  __ jcc(Assembler::greaterEqual, L_loop);\n+#endif\n+\n+__ BIND(L_done);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shenandoah\/shenandoahBarrierSetAssembler_x86.cpp","additions":108,"deletions":1,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2018, 2020, Red Hat, Inc. All rights reserved.\n@@ -59,0 +59,2 @@\n+  void store_check(MacroAssembler* masm, Register obj, Address dst);\n+\n@@ -65,0 +67,2 @@\n+  void gen_write_ref_array_post_barrier(MacroAssembler* masm, DecoratorSet decorators, Register addr, Register count, Register tmp);\n+\n@@ -91,1 +95,0 @@\n-\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shenandoah\/shenandoahBarrierSetAssembler_x86.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/shenandoah\/mode\/shenandoahMode.hpp\"\n@@ -189,0 +190,10 @@\n+\n+  if (access.is_oop()) {\n+    DecoratorSet decorators = access.decorators();\n+    bool is_array = (decorators & IS_ARRAY) != 0;\n+    bool on_anonymous = (decorators & ON_UNKNOWN_OOP_REF) != 0;\n+\n+    bool precise = is_array || on_anonymous;\n+    LIR_Opr post_addr = precise ? access.resolved_addr() : access.base().opr();\n+    post_barrier(access, post_addr, value);\n+  }\n@@ -283,0 +294,67 @@\n+\n+void ShenandoahBarrierSetC1::post_barrier(LIRAccess& access, LIR_OprDesc* addr, LIR_OprDesc* new_val) {\n+  if (!ShenandoahHeap::heap()->mode()->is_generational()) {\n+    return;\n+  }\n+\n+  DecoratorSet decorators = access.decorators();\n+  LIRGenerator* gen = access.gen();\n+  bool in_heap = (decorators & IN_HEAP) != 0;\n+  if (!in_heap) {\n+    return;\n+  }\n+\n+  BarrierSet* bs = BarrierSet::barrier_set();\n+  ShenandoahBarrierSet* ctbs = barrier_set_cast<ShenandoahBarrierSet>(bs);\n+  CardTable* ct = ctbs->card_table();\n+  LIR_Const* card_table_base = new LIR_Const(ct->byte_map_base());\n+  if (addr->is_address()) {\n+    LIR_Address* address = addr->as_address_ptr();\n+    \/\/ ptr cannot be an object because we use this barrier for array card marks\n+    \/\/ and addr can point in the middle of an array.\n+    LIR_Opr ptr = gen->new_pointer_register();\n+    if (!address->index()->is_valid() && address->disp() == 0) {\n+      __ move(address->base(), ptr);\n+    } else {\n+      assert(address->disp() != max_jint, \"lea doesn't support patched addresses!\");\n+      __ leal(addr, ptr);\n+    }\n+    addr = ptr;\n+  }\n+  assert(addr->is_register(), \"must be a register at this point\");\n+\n+  LIR_Opr tmp = gen->new_pointer_register();\n+  if (TwoOperandLIRForm) {\n+    __ move(addr, tmp);\n+    __ unsigned_shift_right(tmp, CardTable::card_shift, tmp);\n+  } else {\n+    __ unsigned_shift_right(addr, CardTable::card_shift, tmp);\n+  }\n+\n+  LIR_Address* card_addr;\n+  if (gen->can_inline_as_constant(card_table_base)) {\n+    card_addr = new LIR_Address(tmp, card_table_base->as_jint(), T_BYTE);\n+  } else {\n+    card_addr = new LIR_Address(tmp, gen->load_constant(card_table_base), T_BYTE);\n+  }\n+\n+  LIR_Opr dirty = LIR_OprFact::intConst(CardTable::dirty_card_val());\n+  if (UseCondCardMark) {\n+    LIR_Opr cur_value = gen->new_register(T_INT);\n+    if (ct->scanned_concurrently()) {\n+      __ membar_storeload();\n+    }\n+    __ move(card_addr, cur_value);\n+\n+    LabelObj* L_already_dirty = new LabelObj();\n+    __ cmp(lir_cond_equal, cur_value, dirty);\n+    __ branch(lir_cond_equal, L_already_dirty->label());\n+    __ move(dirty, card_addr);\n+    __ branch_destination(L_already_dirty->label());\n+  } else {\n+    if (ct->scanned_concurrently()) {\n+      __ membar_storestore();\n+    }\n+    __ move(dirty, card_addr);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c1\/shenandoahBarrierSetC1.cpp","additions":78,"deletions":0,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -232,0 +232,2 @@\n+  void post_barrier(LIRAccess& access, LIR_OprDesc* addr, LIR_OprDesc* new_val);\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c1\/shenandoahBarrierSetC1.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2018, 2020, Red Hat, Inc. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include \"gc\/shenandoah\/mode\/shenandoahMode.hpp\"\n@@ -455,0 +456,101 @@\n+Node* ShenandoahBarrierSetC2::byte_map_base_node(GraphKit* kit) const {\n+  BarrierSet* bs = BarrierSet::barrier_set();\n+  ShenandoahBarrierSet* ctbs = barrier_set_cast<ShenandoahBarrierSet>(bs);\n+  CardTable::CardValue* card_table_base = ctbs->card_table()->byte_map_base();\n+  if (card_table_base != NULL) {\n+    return kit->makecon(TypeRawPtr::make((address)card_table_base));\n+  } else {\n+    return kit->null();\n+  }\n+}\n+\n+void ShenandoahBarrierSetC2::post_barrier(GraphKit* kit,\n+                                          Node* ctl,\n+                                          Node* oop_store,\n+                                          Node* obj,\n+                                          Node* adr,\n+                                          uint  adr_idx,\n+                                          Node* val,\n+                                          BasicType bt,\n+                                          bool use_precise) const {\n+  if (!ShenandoahHeap::heap()->mode()->is_generational()) {\n+    return;\n+  }\n+\n+  ShenandoahBarrierSet* ctbs = barrier_set_cast<ShenandoahBarrierSet>(BarrierSet::barrier_set());\n+  CardTable* ct = ctbs->card_table();\n+  \/\/ No store check needed if we're storing a NULL or an old object\n+  \/\/ (latter case is probably a string constant). The concurrent\n+  \/\/ mark sweep garbage collector, however, needs to have all nonNull\n+  \/\/ oop updates flagged via card-marks.\n+  if (val != NULL && val->is_Con()) {\n+    \/\/ must be either an oop or NULL\n+    const Type* t = val->bottom_type();\n+    if (t == TypePtr::NULL_PTR || t == Type::TOP)\n+      \/\/ stores of null never (?) need barriers\n+      return;\n+  }\n+\n+  if (ReduceInitialCardMarks && obj == kit->just_allocated_object(kit->control())) {\n+    \/\/ We can skip marks on a freshly-allocated object in Eden.\n+    \/\/ Keep this code in sync with new_deferred_store_barrier() in runtime.cpp.\n+    \/\/ That routine informs GC to take appropriate compensating steps,\n+    \/\/ upon a slow-path allocation, so as to make this card-mark\n+    \/\/ elision safe.\n+    return;\n+  }\n+\n+  if (!use_precise) {\n+    \/\/ All card marks for a (non-array) instance are in one place:\n+    adr = obj;\n+  }\n+  \/\/ (Else it's an array (or unknown), and we want more precise card marks.)\n+  assert(adr != NULL, \"\");\n+\n+  IdealKit ideal(kit, true);\n+\n+  \/\/ Convert the pointer to an int prior to doing math on it\n+  Node* cast = __ CastPX(__ ctrl(), adr);\n+\n+  \/\/ Divide by card size\n+  Node* card_offset = __ URShiftX( cast, __ ConI(CardTable::card_shift) );\n+\n+  \/\/ Combine card table base and card offset\n+  Node* card_adr = __ AddP(__ top(), byte_map_base_node(kit), card_offset );\n+\n+  \/\/ Get the alias_index for raw card-mark memory\n+  int adr_type = Compile::AliasIdxRaw;\n+  Node*   zero = __ ConI(0); \/\/ Dirty card value\n+\n+  if (UseCondCardMark) {\n+    if (ct->scanned_concurrently()) {\n+      kit->insert_mem_bar(Op_MemBarVolatile, oop_store);\n+      __ sync_kit(kit);\n+    }\n+    \/\/ The classic GC reference write barrier is typically implemented\n+    \/\/ as a store into the global card mark table.  Unfortunately\n+    \/\/ unconditional stores can result in false sharing and excessive\n+    \/\/ coherence traffic as well as false transactional aborts.\n+    \/\/ UseCondCardMark enables MP \"polite\" conditional card mark\n+    \/\/ stores.  In theory we could relax the load from ctrl() to\n+    \/\/ no_ctrl, but that doesn't buy much latitude.\n+    Node* card_val = __ load( __ ctrl(), card_adr, TypeInt::BYTE, T_BYTE, adr_type);\n+    __ if_then(card_val, BoolTest::ne, zero);\n+  }\n+\n+  \/\/ Smash zero into card\n+  if(!ct->scanned_concurrently()) {\n+    __ store(__ ctrl(), card_adr, zero, T_BYTE, adr_type, MemNode::unordered);\n+  } else {\n+    \/\/ Specialized path for CM store barrier\n+    __ storeCM(__ ctrl(), card_adr, zero, oop_store, adr_idx, T_BYTE, adr_type);\n+  }\n+\n+  if (UseCondCardMark) {\n+    __ end_if();\n+  }\n+\n+  \/\/ Final sync IdealKit and GraphKit.\n+  kit->final_sync(ideal);\n+}\n+\n@@ -521,0 +623,6 @@\n+\n+    Node* result = BarrierSetC2::store_at_resolved(access, val);\n+    bool is_array = (decorators & IS_ARRAY) != 0;\n+    bool use_precise = is_array || anonymous;\n+    post_barrier(kit, kit->control(), access.raw_access(), access.base(), adr, adr_idx, val.node(), access.type(), use_precise);\n+    return result;\n@@ -531,0 +639,1 @@\n+    return BarrierSetC2::store_at_resolved(access, val);\n@@ -532,1 +641,0 @@\n-  return BarrierSetC2::store_at_resolved(access, val);\n@@ -605,1 +713,1 @@\n-                                                   Node* new_val, const Type* value_type) const {\n+                                                             Node* new_val, const Type* value_type) const {\n@@ -647,0 +755,1 @@\n+    post_barrier(kit, kit->control(), access.raw_access(), access.base(), access.addr().node(), access.alias_idx(), new_val, T_OBJECT, true);\n@@ -702,0 +811,2 @@\n+    post_barrier(kit, kit->control(), access.raw_access(), access.base(),\n+                 access.addr().node(), access.alias_idx(), new_val, T_OBJECT, true);\n@@ -718,0 +829,2 @@\n+    post_barrier(kit, kit->control(), access.raw_access(), access.base(),\n+                 access.addr().node(), access.alias_idx(), val, T_OBJECT, true);\n@@ -800,1 +913,1 @@\n-        }\n+    }\n@@ -911,3 +1024,20 @@\n-void ShenandoahBarrierSetC2::eliminate_gc_barrier(PhaseMacroExpand* macro, Node* n) const {\n-  if (is_shenandoah_wb_pre_call(n)) {\n-    shenandoah_eliminate_wb_pre(n, &macro->igvn());\n+void ShenandoahBarrierSetC2::eliminate_gc_barrier(PhaseMacroExpand* macro, Node* node) const {\n+  if (is_shenandoah_wb_pre_call(node)) {\n+    shenandoah_eliminate_wb_pre(node, &macro->igvn());\n+  }\n+  if (node->Opcode() == Op_CastP2X && ShenandoahHeap::heap()->mode()->is_generational()) {\n+    assert(node->Opcode() == Op_CastP2X, \"ConvP2XNode required\");\n+     Node *shift = node->unique_out();\n+     Node *addp = shift->unique_out();\n+     for (DUIterator_Last jmin, j = addp->last_outs(jmin); j >= jmin; --j) {\n+       Node *mem = addp->last_out(j);\n+       if (UseCondCardMark && mem->is_Load()) {\n+         assert(mem->Opcode() == Op_LoadB, \"unexpected code shape\");\n+         \/\/ The load is checking if the card has been written so\n+         \/\/ replace it with zero to fold the test.\n+         macro->replace_node(mem, macro->intcon(0));\n+         continue;\n+       }\n+       assert(mem->is_Store(), \"store required\");\n+       macro->replace_node(mem, mem->in(MemNode::Memory));\n+     }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahBarrierSetC2.cpp","additions":137,"deletions":7,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2018, 2020, Red Hat, Inc. All rights reserved.\n@@ -76,0 +76,12 @@\n+  Node* byte_map_base_node(GraphKit* kit) const;\n+\n+  void post_barrier(GraphKit* kit,\n+                    Node* ctl,\n+                    Node* store,\n+                    Node* obj,\n+                    Node* adr,\n+                    uint adr_idx,\n+                    Node* val,\n+                    BasicType bt,\n+                    bool use_precise) const;\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahBarrierSetC2.hpp","additions":13,"deletions":1,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -55,1 +55,1 @@\n-ShenandoahBarrierSet::ShenandoahBarrierSet(ShenandoahHeap* heap) :\n+ShenandoahBarrierSet::ShenandoahBarrierSet(ShenandoahHeap* heap, MemRegion heap_region) :\n@@ -65,0 +65,4 @@\n+  if (heap->mode()->is_generational()) {\n+    _card_table = new ShenandoahCardTable(heap_region);\n+    _card_table->initialize();\n+  }\n@@ -188,0 +192,20 @@\n+void ShenandoahBarrierSet::write_ref_array(HeapWord* start, size_t count) {\n+  if (!_heap->mode()->is_generational()) {\n+    return;\n+  }\n+\n+  HeapWord* end = (HeapWord*)((char*) start + (count * heapOopSize));\n+  \/\/ In the case of compressed oops, start and end may potentially be misaligned;\n+  \/\/ so we need to conservatively align the first downward (this is not\n+  \/\/ strictly necessary for current uses, but a case of good hygiene and,\n+  \/\/ if you will, aesthetics) and the second upward (this is essential for\n+  \/\/ current uses) to a HeapWord boundary, so we mark all cards overlapping\n+  \/\/ this write.\n+  HeapWord* aligned_start = align_down(start, HeapWordSize);\n+  HeapWord* aligned_end   = align_up  (end,   HeapWordSize);\n+  \/\/ If compressed oops were not being used, these should already be aligned\n+  assert(UseCompressedOops || (aligned_start == start && aligned_end == end),\n+         \"Expected heap word alignment of start and end\");\n+  card_table()->dirty_MemRegion(MemRegion(aligned_start, aligned_end));\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSet.cpp","additions":25,"deletions":1,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shenandoah\/shenandoahCardTable.hpp\"\n@@ -37,1 +38,0 @@\n-\n@@ -39,0 +39,1 @@\n+  ShenandoahCardTable* _card_table;\n@@ -43,1 +44,1 @@\n-  ShenandoahBarrierSet(ShenandoahHeap* heap);\n+  ShenandoahBarrierSet(ShenandoahHeap* heap, MemRegion heap_region);\n@@ -51,0 +52,2 @@\n+  inline CardTable* card_table()  { return _card_table; }\n+\n@@ -99,0 +102,5 @@\n+  template <DecoratorSet decorators, typename T>\n+  void write_ref_field_post(T* field, oop newVal);\n+\n+  void write_ref_array(HeapWord* start, size_t count);\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSet.hpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shared\/cardTable.hpp\"\n@@ -38,0 +39,1 @@\n+#include \"gc\/shenandoah\/mode\/shenandoahMode.hpp\"\n@@ -163,0 +165,13 @@\n+template <DecoratorSet decorators, typename T>\n+inline void ShenandoahBarrierSet::write_ref_field_post(T* field, oop newVal) {\n+  if (ShenandoahHeap::heap()->mode()->is_generational()) {\n+    volatile CardTable::CardValue* byte = card_table()->byte_for(field);\n+    if (card_table()->scanned_concurrently()) {\n+      \/\/ Perform a releasing store if the card table is scanned concurrently\n+      Atomic::release_store(byte, CardTable::dirty_card_val());\n+    } else {\n+      *byte = CardTable::dirty_card_val();\n+    }\n+  }\n+}\n+\n@@ -219,0 +234,1 @@\n+  ShenandoahBarrierSet::barrier_set()->write_ref_field_post<decorators>(addr, value);\n@@ -252,1 +268,3 @@\n-  return oop_atomic_cmpxchg_not_in_heap(addr, compare_value, new_value);\n+  oop result = oop_atomic_cmpxchg_not_in_heap(addr, compare_value, new_value);\n+  ShenandoahBarrierSet::barrier_set()->write_ref_field_post<decorators>(addr, new_value);\n+  return result;\n@@ -280,1 +298,3 @@\n-  return oop_atomic_xchg_not_in_heap(addr, new_value);\n+  oop result = oop_atomic_xchg_not_in_heap(addr, new_value);\n+  ShenandoahBarrierSet::barrier_set()->write_ref_field_post<decorators>(addr, new_value);\n+  return result;\n@@ -302,0 +322,3 @@\n+  T* src = arrayOopDesc::obj_offset_to_raw(src_obj, src_offset_in_bytes, src_raw);\n+  T* dst = arrayOopDesc::obj_offset_to_raw(dst_obj, dst_offset_in_bytes, dst_raw);\n+\n@@ -303,4 +326,4 @@\n-  bs->arraycopy_barrier(arrayOopDesc::obj_offset_to_raw(src_obj, src_offset_in_bytes, src_raw),\n-                        arrayOopDesc::obj_offset_to_raw(dst_obj, dst_offset_in_bytes, dst_raw),\n-                        length);\n-  return Raw::oop_arraycopy_in_heap(src_obj, src_offset_in_bytes, src_raw, dst_obj, dst_offset_in_bytes, dst_raw, length);\n+  bs->arraycopy_barrier(src, dst, length);\n+  bool result = Raw::oop_arraycopy_in_heap(src_obj, src_offset_in_bytes, src_raw, dst_obj, dst_offset_in_bytes, dst_raw, length);\n+  bs->write_ref_array((HeapWord*) dst, length);\n+  return result;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSet.inline.hpp","additions":29,"deletions":6,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -0,0 +1,31 @@\n+\/*\n+ * Copyright (c) 2020, Amazon.com, Inc. and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/shenandoah\/shenandoahCardTable.hpp\"\n+\n+void ShenandoahCardTable::initialize() {\n+  CardTable::initialize();\n+  resize_covered_region(_whole_heap);\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCardTable.cpp","additions":31,"deletions":0,"binary":false,"changes":31,"status":"added"},{"patch":"@@ -0,0 +1,47 @@\n+\/*\n+ * Copyright (c) 2020, Amazon.com, Inc. and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_VM_GC_SHENANDOAH_SHENANDOAHCARDTABLE_HPP\n+#define SHARE_VM_GC_SHENANDOAH_SHENANDOAHCARDTABLE_HPP\n+\n+#include \"gc\/g1\/g1RegionToSpaceMapper.hpp\"\n+#include \"gc\/shared\/cardTable.hpp\"\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+class ShenandoahCardTable: public CardTable {\n+  friend class VMStructs;\n+\n+public:\n+  ShenandoahCardTable(MemRegion whole_heap): CardTable(whole_heap, \/* conc_scan *\/ false) { }\n+\n+  virtual void initialize();\n+\n+  inline bool is_in_young(oop obj) const {\n+    ShouldNotReachHere();\n+    return false;\n+  }\n+};\n+\n+#endif \/\/ SHARE_VM_GC_SHENANDOAH_SHENANDOAHCARDTABLE_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCardTable.hpp","additions":47,"deletions":0,"binary":false,"changes":47,"status":"added"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"gc\/shenandoah\/shenandoahCardTable.hpp\"\n@@ -206,0 +207,22 @@\n+  \/\/\n+  \/\/ After reserving the Java heap, create the card table, barriers, and workers, in dependency order\n+  \/\/\n+  BarrierSet::set_barrier_set(new ShenandoahBarrierSet(this, _heap_region));\n+\n+  _workers = new ShenandoahWorkGang(\"Shenandoah GC Threads\", _max_workers,\n+                            \/* are_GC_task_threads *\/ true,\n+                            \/* are_ConcurrentGC_threads *\/ true);\n+  if (_workers == NULL) {\n+    vm_exit_during_initialization(\"Failed necessary allocation.\");\n+  } else {\n+    _workers->initialize_workers();\n+  }\n+\n+  if (ParallelGCThreads > 1) {\n+    _safepoint_workers = new ShenandoahWorkGang(\"Safepoint Cleanup Thread\",\n+                                                ParallelGCThreads,\n+                      \/* are_GC_task_threads *\/ false,\n+                 \/* are_ConcurrentGC_threads *\/ false);\n+    _safepoint_workers->initialize_workers();\n+  }\n+\n@@ -458,1 +481,1 @@\n-  _max_workers(MAX2(ConcGCThreads, ParallelGCThreads)),\n+  _max_workers(MAX3(ConcGCThreads, ParallelGCThreads, 1U)),\n@@ -491,19 +514,0 @@\n-  BarrierSet::set_barrier_set(new ShenandoahBarrierSet(this));\n-\n-  _max_workers = MAX2(_max_workers, 1U);\n-  _workers = new ShenandoahWorkGang(\"Shenandoah GC Threads\", _max_workers,\n-                            \/* are_GC_task_threads *\/ true,\n-                            \/* are_ConcurrentGC_threads *\/ true);\n-  if (_workers == NULL) {\n-    vm_exit_during_initialization(\"Failed necessary allocation.\");\n-  } else {\n-    _workers->initialize_workers();\n-  }\n-\n-  if (ParallelGCThreads > 1) {\n-    _safepoint_workers = new ShenandoahWorkGang(\"Safepoint Cleanup Thread\",\n-                                                ParallelGCThreads,\n-                      \/* are_GC_task_threads *\/ false,\n-                 \/* are_ConcurrentGC_threads *\/ false);\n-    _safepoint_workers->initialize_workers();\n-  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":24,"deletions":20,"binary":false,"changes":44,"status":"modified"}]}