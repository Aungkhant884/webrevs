{"files":[{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -30,0 +31,1 @@\n+#include \"gc\/shenandoah\/shenandoahGeneration.hpp\"\n@@ -32,0 +34,1 @@\n+#include \"gc\/shenandoah\/shenandoahOldGeneration.hpp\"\n@@ -36,0 +39,1 @@\n+#include \"gc\/shenandoah\/shenandoahYoungGeneration.hpp\"\n@@ -71,0 +75,1 @@\n+  ShenandoahGeneration* _generation;\n@@ -82,1 +87,2 @@\n-    _loc(nullptr) {\n+    _loc(nullptr),\n+    _generation(nullptr) {\n@@ -84,0 +90,1 @@\n+        options._verify_marked == ShenandoahVerifier::_verify_marked_complete_satb_empty ||\n@@ -87,0 +94,5 @@\n+\n+    if (_heap->mode()->is_generational()) {\n+      _generation = _heap->active_generation();\n+      assert(_generation != nullptr, \"Expected active generation in this mode\");\n+    }\n@@ -110,1 +122,3 @@\n-      if (_map->par_mark(obj)) {\n+      \/\/ TODO: We should consider specializing this closure by generation ==\/!= null,\n+      \/\/ to avoid in_generation check on fast path here for non-generational mode.\n+      if (in_generation(obj) && _map->par_mark(obj)) {\n@@ -117,0 +131,9 @@\n+  bool in_generation(oop obj) {\n+    if (_generation == nullptr) {\n+      return true;\n+    }\n+\n+    ShenandoahHeapRegion* region = _heap->heap_region_containing(obj);\n+    return _generation->contains(region);\n+  }\n+\n@@ -167,1 +190,2 @@\n-          check(ShenandoahAsserts::_safe_oop, obj, obj_reg->has_live(),\n+          check(ShenandoahAsserts::_safe_oop, obj, obj_reg->has_live() ||\n+                (obj_reg->is_old() && ShenandoahHeap::heap()->is_gc_generation_young()),\n@@ -216,1 +240,8 @@\n-\n+    \/\/ We allow for marked or old here for two reasons:\n+    \/\/  1. If this is a young collect, old objects wouldn't be marked. We've\n+    \/\/     recently change the verifier traversal to only follow young objects\n+    \/\/     during a young collect so this _shouldn't_ be necessary.\n+    \/\/  2. At present, we do not clear dead objects from the remembered set.\n+    \/\/     Everything in the remembered set is old (ipso facto), so allowing for\n+    \/\/     'marked_or_old' covers the case of stale objects in rset.\n+    \/\/ TODO: Just use 'is_marked' here.\n@@ -222,1 +253,1 @@\n-        check(ShenandoahAsserts::_safe_all, obj, _heap->marking_context()->is_marked(obj),\n+        check(ShenandoahAsserts::_safe_all, obj, _heap->marking_context()->is_marked_or_old(obj),\n@@ -226,1 +257,1 @@\n-        check(ShenandoahAsserts::_safe_all, obj, _heap->complete_marking_context()->is_marked(obj),\n+        check(ShenandoahAsserts::_safe_all, obj, _heap->complete_marking_context()->is_marked_or_old(obj),\n@@ -230,1 +261,2 @@\n-        check(ShenandoahAsserts::_safe_all, obj, _heap->complete_marking_context()->is_marked(obj),\n+      case ShenandoahVerifier::_verify_marked_complete_satb_empty:\n+        check(ShenandoahAsserts::_safe_all, obj, _heap->complete_marking_context()->is_marked_or_old(obj),\n@@ -316,0 +348,2 @@\n+\/\/ This closure computes the amounts of used, committed, and garbage memory and the number of regions contained within\n+\/\/ a subset (e.g. the young generation or old generation) of the total heap.\n@@ -318,1 +352,1 @@\n-  size_t _used, _committed, _garbage;\n+  size_t _used, _committed, _garbage, _regions, _humongous_waste;\n@@ -320,1 +354,1 @@\n-  ShenandoahCalculateRegionStatsClosure() : _used(0), _committed(0), _garbage(0) {};\n+  ShenandoahCalculateRegionStatsClosure() : _used(0), _committed(0), _garbage(0), _regions(0), _humongous_waste(0) {};\n@@ -326,0 +360,6 @@\n+    if (r->is_humongous()) {\n+      _humongous_waste += r->free();\n+    }\n+    _regions++;\n+    log_debug(gc)(\"ShenandoahCalculateRegionStatsClosure: adding \" SIZE_FORMAT \" for %s Region \" SIZE_FORMAT \", yielding: \" SIZE_FORMAT,\n+            r->used(), (r->is_humongous() ? \"humongous\" : \"regular\"), r->index(), _used);\n@@ -331,0 +371,71 @@\n+  size_t regions() { return _regions; }\n+  size_t waste() { return _humongous_waste; }\n+\n+  \/\/ span is the total memory affiliated with these stats (some of which is in use and other is available)\n+  size_t span() { return _regions * ShenandoahHeapRegion::region_size_bytes(); }\n+};\n+\n+class ShenandoahGenerationStatsClosure : public ShenandoahHeapRegionClosure {\n+ public:\n+  ShenandoahCalculateRegionStatsClosure old;\n+  ShenandoahCalculateRegionStatsClosure young;\n+  ShenandoahCalculateRegionStatsClosure global;\n+\n+  void heap_region_do(ShenandoahHeapRegion* r) override {\n+    switch (r->affiliation()) {\n+      case FREE:\n+        return;\n+      case YOUNG_GENERATION:\n+        young.heap_region_do(r);\n+        global.heap_region_do(r);\n+        break;\n+      case OLD_GENERATION:\n+        old.heap_region_do(r);\n+        global.heap_region_do(r);\n+        break;\n+      default:\n+        ShouldNotReachHere();\n+    }\n+  }\n+\n+  static void log_usage(ShenandoahGeneration* generation, ShenandoahCalculateRegionStatsClosure& stats) {\n+    log_debug(gc)(\"Safepoint verification: %s verified usage: \" SIZE_FORMAT \"%s, recorded usage: \" SIZE_FORMAT \"%s\",\n+                  generation->name(),\n+                  byte_size_in_proper_unit(generation->used()), proper_unit_for_byte_size(generation->used()),\n+                  byte_size_in_proper_unit(stats.used()),       proper_unit_for_byte_size(stats.used()));\n+  }\n+\n+  static void validate_usage(const bool adjust_for_padding,\n+                             const char* label, ShenandoahGeneration* generation, ShenandoahCalculateRegionStatsClosure& stats) {\n+    ShenandoahHeap* heap = ShenandoahHeap::heap();\n+    size_t generation_used = generation->used();\n+    size_t generation_used_regions = generation->used_regions();\n+    if (adjust_for_padding && (generation->is_young() || generation->is_global())) {\n+      size_t pad = ShenandoahHeap::heap()->get_pad_for_promote_in_place();\n+      generation_used += pad;\n+    }\n+\n+    guarantee(stats.used() == generation_used,\n+              \"%s: generation (%s) used size must be consistent: generation-used: \" SIZE_FORMAT \"%s, regions-used: \" SIZE_FORMAT \"%s\",\n+              label, generation->name(),\n+              byte_size_in_proper_unit(generation_used), proper_unit_for_byte_size(generation_used),\n+              byte_size_in_proper_unit(stats.used()),    proper_unit_for_byte_size(stats.used()));\n+\n+    guarantee(stats.regions() == generation_used_regions,\n+              \"%s: generation (%s) used regions (\" SIZE_FORMAT \") must equal regions that are in use (\" SIZE_FORMAT \")\",\n+              label, generation->name(), generation->used_regions(), stats.regions());\n+\n+    size_t generation_capacity = generation->max_capacity();\n+    size_t humongous_regions_promoted = 0;\n+    guarantee(stats.span() <= generation_capacity,\n+              \"%s: generation (%s) size spanned by regions (\" SIZE_FORMAT \") must not exceed current capacity (\" SIZE_FORMAT \"%s)\",\n+              label, generation->name(), stats.regions(),\n+              byte_size_in_proper_unit(generation_capacity), proper_unit_for_byte_size(generation_capacity));\n+\n+    size_t humongous_waste = generation->get_humongous_waste();\n+    guarantee(stats.waste() == humongous_waste,\n+              \"%s: generation (%s) humongous waste must be consistent: generation: \" SIZE_FORMAT \"%s, regions: \" SIZE_FORMAT \"%s\",\n+              label, generation->name(),\n+              byte_size_in_proper_unit(humongous_waste), proper_unit_for_byte_size(humongous_waste),\n+              byte_size_in_proper_unit(stats.waste()),   proper_unit_for_byte_size(stats.waste()));\n+  }\n@@ -414,2 +525,5 @@\n-    verify(r, r->get_shared_allocs() + r->get_tlab_allocs() + r->get_gclab_allocs() == r->used(),\n-           \"Accurate accounting: shared + TLAB + GCLAB = used\");\n+    verify(r, r->get_plab_allocs() <= r->capacity(),\n+           \"PLAB alloc count should not be larger than capacity\");\n+\n+    verify(r, r->get_shared_allocs() + r->get_tlab_allocs() + r->get_gclab_allocs() + r->get_plab_allocs() == r->used(),\n+           \"Accurate accounting: shared + TLAB + GCLAB + PLAB = used\");\n@@ -488,0 +602,10 @@\n+class ShenandoahVerifyNoIncompleteSatbBuffers : public ThreadClosure {\n+public:\n+  virtual void do_thread(Thread* thread) {\n+    SATBMarkQueue& queue = ShenandoahThreadLocalData::satb_mark_queue(thread);\n+    if (!queue.is_empty()) {\n+      fatal(\"All SATB buffers should have been flushed during mark\");\n+    }\n+  }\n+};\n+\n@@ -497,0 +621,1 @@\n+  ShenandoahGeneration* _generation;\n@@ -510,1 +635,11 @@\n-          _processed(0) {};\n+          _processed(0),\n+          _generation(nullptr) {\n+    if (_options._verify_marked == ShenandoahVerifier::_verify_marked_complete_satb_empty) {\n+      Threads::change_thread_claim_token();\n+    }\n+\n+    if (_heap->mode()->is_generational()) {\n+      _generation = _heap->active_generation();\n+      assert(_generation != nullptr, \"Expected active generation in this mode.\");\n+    }\n+  };\n@@ -517,0 +652,5 @@\n+    if (_options._verify_marked == ShenandoahVerifier::_verify_marked_complete_satb_empty) {\n+      ShenandoahVerifyNoIncompleteSatbBuffers verify_satb;\n+      Threads::possibly_parallel_threads_do(true, &verify_satb);\n+    }\n+\n@@ -526,0 +666,4 @@\n+        if (!in_generation(r)) {\n+          continue;\n+        }\n+\n@@ -537,0 +681,4 @@\n+  bool in_generation(ShenandoahHeapRegion* r) {\n+    return _generation == nullptr || _generation->contains(r);\n+  }\n+\n@@ -609,1 +757,1 @@\n-    if (actual != _expected) {\n+    if (!verify_gc_state(actual, _expected)) {\n@@ -613,0 +761,7 @@\n+\n+  static bool verify_gc_state(char actual, char expected) {\n+    \/\/ Old generation marking is allowed in all states.\n+    \/\/ TODO: This actually accepts more than just OLD_MARKING.\n+    \/\/ TODO: Also, only accept OLD_MARKING in generational mode.\n+    return (actual == expected) || (actual & ShenandoahHeap::OLD_MARKING);\n+  }\n@@ -615,1 +770,2 @@\n-void ShenandoahVerifier::verify_at_safepoint(const char *label,\n+void ShenandoahVerifier::verify_at_safepoint(const char* label,\n+                                             VerifyRememberedSet remembered,\n@@ -619,0 +775,1 @@\n+                                             VerifySize sizeness,\n@@ -642,1 +799,1 @@\n-        expected = ShenandoahHeap::HAS_FORWARDED | ShenandoahHeap::EVACUATION;\n+        expected = ShenandoahHeap::EVACUATION;\n@@ -648,0 +805,4 @@\n+      case _verify_gcstate_updating:\n+        enabled = true;\n+        expected = ShenandoahHeap::HAS_FORWARDED | ShenandoahHeap::UPDATEREFS;\n+        break;\n@@ -667,1 +828,2 @@\n-      if (actual != expected) {\n+      \/\/ Old generation marking is allowed in all states.\n+      if (!VerifyThreadGCState::verify_gc_state(actual, expected)) {\n@@ -685,7 +847,14 @@\n-    size_t heap_used = _heap->used();\n-    guarantee(cl.used() == heap_used,\n-              \"%s: heap used size must be consistent: heap-used = \" SIZE_FORMAT \"%s, regions-used = \" SIZE_FORMAT \"%s\",\n-              label,\n-              byte_size_in_proper_unit(heap_used), proper_unit_for_byte_size(heap_used),\n-              byte_size_in_proper_unit(cl.used()), proper_unit_for_byte_size(cl.used()));\n-\n+    size_t heap_used;\n+    if (_heap->mode()->is_generational() && (sizeness == _verify_size_adjusted_for_padding)) {\n+      \/\/ Prior to evacuation, regular regions that are to be evacuated in place are padded to prevent further allocations\n+      heap_used = _heap->used() + _heap->get_pad_for_promote_in_place();\n+    } else if (sizeness != _verify_size_disable) {\n+      heap_used = _heap->used();\n+    }\n+    if (sizeness != _verify_size_disable) {\n+      guarantee(cl.used() == heap_used,\n+                \"%s: heap used size must be consistent: heap-used = \" SIZE_FORMAT \"%s, regions-used = \" SIZE_FORMAT \"%s\",\n+                label,\n+                byte_size_in_proper_unit(heap_used), proper_unit_for_byte_size(heap_used),\n+                byte_size_in_proper_unit(cl.used()), proper_unit_for_byte_size(cl.used()));\n+    }\n@@ -700,0 +869,54 @@\n+  log_debug(gc)(\"Safepoint verification finished heap usage verification\");\n+\n+  ShenandoahGeneration* generation;\n+  if (_heap->mode()->is_generational()) {\n+    generation = _heap->active_generation();\n+    guarantee(generation != nullptr, \"Need to know which generation to verify.\");\n+  } else {\n+    generation = nullptr;\n+  }\n+\n+  if (generation != nullptr) {\n+    ShenandoahHeapLocker lock(_heap->lock());\n+\n+    switch (remembered) {\n+      case _verify_remembered_disable:\n+        break;\n+      case _verify_remembered_before_marking:\n+        log_debug(gc)(\"Safepoint verification of remembered set at mark\");\n+        verify_rem_set_before_mark();\n+        break;\n+      case _verify_remembered_before_updating_references:\n+        log_debug(gc)(\"Safepoint verification of remembered set at update ref\");\n+        verify_rem_set_before_update_ref();\n+        break;\n+      case _verify_remembered_after_full_gc:\n+        log_debug(gc)(\"Safepoint verification of remembered set after full gc\");\n+        verify_rem_set_after_full_gc();\n+        break;\n+      default:\n+        fatal(\"Unhandled remembered set verification mode\");\n+    }\n+\n+    ShenandoahGenerationStatsClosure cl;\n+    _heap->heap_region_iterate(&cl);\n+\n+    if (LogTarget(Debug, gc)::is_enabled()) {\n+      ShenandoahGenerationStatsClosure::log_usage(_heap->old_generation(),    cl.old);\n+      ShenandoahGenerationStatsClosure::log_usage(_heap->young_generation(),  cl.young);\n+      ShenandoahGenerationStatsClosure::log_usage(_heap->global_generation(), cl.global);\n+    }\n+    if (sizeness == _verify_size_adjusted_for_padding) {\n+      ShenandoahGenerationStatsClosure::validate_usage(false, label, _heap->old_generation(), cl.old);\n+      ShenandoahGenerationStatsClosure::validate_usage(true, label, _heap->young_generation(), cl.young);\n+      ShenandoahGenerationStatsClosure::validate_usage(true, label, _heap->global_generation(), cl.global);\n+    } else if (sizeness == _verify_size_exact) {\n+      ShenandoahGenerationStatsClosure::validate_usage(false, label, _heap->old_generation(), cl.old);\n+      ShenandoahGenerationStatsClosure::validate_usage(false, label, _heap->young_generation(), cl.young);\n+      ShenandoahGenerationStatsClosure::validate_usage(false, label, _heap->global_generation(), cl.global);\n+    }\n+    \/\/ else: sizeness must equal _verify_size_disable\n+  }\n+\n+  log_debug(gc)(\"Safepoint verification finished remembered set verification\");\n+\n@@ -703,1 +926,5 @@\n-    _heap->heap_region_iterate(&cl);\n+    if (generation != nullptr) {\n+      generation->heap_region_iterate(&cl);\n+    } else {\n+      _heap->heap_region_iterate(&cl);\n+    }\n@@ -706,0 +933,2 @@\n+  log_debug(gc)(\"Safepoint verification finished heap region closure verification\");\n+\n@@ -730,0 +959,2 @@\n+  log_debug(gc)(\"Safepoint verification finished getting initial reachable set\");\n+\n@@ -738,1 +969,4 @@\n-  if (ShenandoahVerifyLevel >= 4 && (marked == _verify_marked_complete || marked == _verify_marked_complete_except_references)) {\n+  if (ShenandoahVerifyLevel >= 4 &&\n+        (marked == _verify_marked_complete ||\n+         marked == _verify_marked_complete_except_references ||\n+         marked == _verify_marked_complete_satb_empty)) {\n@@ -747,0 +981,2 @@\n+  log_debug(gc)(\"Safepoint verification finished walking marked objects\");\n+\n@@ -753,0 +989,3 @@\n+      if (generation != nullptr && !generation->contains(r)) {\n+        continue;\n+      }\n@@ -776,0 +1015,3 @@\n+  log_debug(gc)(\"Safepoint verification finished accumulation of liveness data\");\n+\n+\n@@ -785,0 +1027,1 @@\n+          _verify_remembered_disable,  \/\/ do not verify remembered set\n@@ -790,0 +1033,1 @@\n+          _verify_size_exact,          \/\/ expect generation and heap sizes to match exactly\n@@ -797,0 +1041,2 @@\n+          _verify_remembered_before_marking,\n+                                       \/\/ verify read-only remembered set from bottom() to top()\n@@ -802,0 +1048,1 @@\n+          _verify_size_exact,          \/\/ expect generation and heap sizes to match exactly\n@@ -809,0 +1056,1 @@\n+          _verify_remembered_disable,  \/\/ do not verify remembered set\n@@ -810,1 +1058,2 @@\n-          _verify_marked_complete_except_references, \/\/ bitmaps as precise as we can get, except dangling j.l.r.Refs\n+          _verify_marked_complete_satb_empty,\n+                                       \/\/ bitmaps as precise as we can get, except dangling j.l.r.Refs\n@@ -814,0 +1063,1 @@\n+          _verify_size_exact,          \/\/ expect generation and heap sizes to match exactly\n@@ -821,0 +1071,1 @@\n+          _verify_remembered_disable,                \/\/ do not verify remembered set\n@@ -826,0 +1077,2 @@\n+          _verify_size_adjusted_for_padding,         \/\/ expect generation and heap sizes to match after adjustments\n+                                                     \/\/  for promote in place padding\n@@ -833,0 +1086,1 @@\n+          _verify_remembered_disable, \/\/ do not verify remembered set\n@@ -838,0 +1092,1 @@\n+          _verify_size_disable,       \/\/ we don't know how much of promote-in-place work has been completed\n@@ -845,0 +1100,1 @@\n+          _verify_remembered_disable,  \/\/ do not verify remembered set\n@@ -850,0 +1106,1 @@\n+          _verify_size_exact,          \/\/ expect generation and heap sizes to match exactly\n@@ -857,0 +1114,1 @@\n+          _verify_remembered_before_updating_references,  \/\/ verify read-write remembered set\n@@ -862,1 +1120,2 @@\n-          _verify_gcstate_forwarded    \/\/ evacuation should have produced some forwarded objects\n+          _verify_size_exact,          \/\/ expect generation and heap sizes to match exactly\n+          _verify_gcstate_updating     \/\/ evacuation should have produced some forwarded objects\n@@ -866,0 +1125,1 @@\n+\/\/ We have not yet cleanup (reclaimed) the collection set\n@@ -869,0 +1129,1 @@\n+          _verify_remembered_disable,  \/\/ do not verify remembered set\n@@ -874,0 +1135,1 @@\n+          _verify_size_exact,          \/\/ expect generation and heap sizes to match exactly\n@@ -881,0 +1143,1 @@\n+          _verify_remembered_disable,  \/\/ do not verify remembered set\n@@ -886,0 +1149,1 @@\n+          _verify_size_exact,          \/\/ expect generation and heap sizes to match exactly\n@@ -893,0 +1157,1 @@\n+          _verify_remembered_disable,  \/\/ do not verify remembered set\n@@ -898,0 +1163,1 @@\n+          _verify_size_disable,        \/\/ if we degenerate during evacuation, usage not valid: padding and deferred accounting\n@@ -905,0 +1171,1 @@\n+          _verify_remembered_after_full_gc,  \/\/ verify read-write remembered set\n@@ -910,0 +1177,1 @@\n+          _verify_size_exact,           \/\/ expect generation and heap sizes to match exactly\n@@ -914,1 +1182,2 @@\n-class ShenandoahVerifyNoForwared : public OopClosure {\n+\/\/ TODO: Why this closure does not visit metadata?\n+class ShenandoahVerifyNoForwared : public BasicOopIterateClosure {\n@@ -934,1 +1203,2 @@\n-class ShenandoahVerifyInToSpaceClosure : public OopClosure {\n+\/\/ TODO: Why this closure does not visit metadata?\n+class ShenandoahVerifyInToSpaceClosure : public BasicOopIterateClosure {\n@@ -943,1 +1213,1 @@\n-      if (!heap->marking_context()->is_marked(obj)) {\n+      if (!heap->marking_context()->is_marked_or_old(obj)) {\n@@ -975,0 +1245,212 @@\n+\n+class ShenandoahVerifyRemSetClosure : public BasicOopIterateClosure {\n+protected:\n+  bool               const _init_mark;\n+  ShenandoahHeap*    const _heap;\n+  RememberedScanner* const _scanner;\n+\n+public:\n+  \/\/ Argument distinguishes between initial mark or start of update refs verification.\n+  ShenandoahVerifyRemSetClosure(bool init_mark) :\n+            _init_mark(init_mark),\n+            _heap(ShenandoahHeap::heap()),\n+            _scanner(_heap->card_scan()) {}\n+\n+  template<class T>\n+  inline void work(T* p) {\n+    T o = RawAccess<>::oop_load(p);\n+    if (!CompressedOops::is_null(o)) {\n+      oop obj = CompressedOops::decode_not_null(o);\n+      if (_heap->is_in_young(obj)) {\n+        size_t card_index = _scanner->card_index_for_addr((HeapWord*) p);\n+        if (_init_mark && !_scanner->is_card_dirty(card_index)) {\n+          ShenandoahAsserts::print_failure(ShenandoahAsserts::_safe_all, obj, p, nullptr,\n+                                           \"Verify init-mark remembered set violation\", \"clean card should be dirty\", __FILE__, __LINE__);\n+        } else if (!_init_mark && !_scanner->is_write_card_dirty(card_index)) {\n+          ShenandoahAsserts::print_failure(ShenandoahAsserts::_safe_all, obj, p, nullptr,\n+                                           \"Verify init-update-refs remembered set violation\", \"clean card should be dirty\", __FILE__, __LINE__);\n+        }\n+      }\n+    }\n+  }\n+\n+  virtual void do_oop(narrowOop* p) { work(p); }\n+  virtual void do_oop(oop* p)       { work(p); }\n+};\n+\n+void ShenandoahVerifier::help_verify_region_rem_set(ShenandoahHeapRegion* r, ShenandoahMarkingContext* ctx, HeapWord* from,\n+                                                    HeapWord* top, HeapWord* registration_watermark, const char* message) {\n+  RememberedScanner* scanner = _heap->card_scan();\n+  ShenandoahVerifyRemSetClosure check_interesting_pointers(false);\n+\n+  HeapWord* obj_addr = from;\n+  if (r->is_humongous_start()) {\n+    oop obj = cast_to_oop(obj_addr);\n+    if ((ctx == nullptr) || ctx->is_marked(obj)) {\n+      size_t card_index = scanner->card_index_for_addr(obj_addr);\n+      \/\/ For humongous objects, the typical object is an array, so the following checks may be overkill\n+      \/\/ For regular objects (not object arrays), if the card holding the start of the object is dirty,\n+      \/\/ we do not need to verify that cards spanning interesting pointers within this object are dirty.\n+      if (!scanner->is_write_card_dirty(card_index) || obj->is_objArray()) {\n+        obj->oop_iterate(&check_interesting_pointers);\n+      }\n+      \/\/ else, object's start is marked dirty and obj is not an objArray, so any interesting pointers are covered\n+    }\n+    \/\/ else, this humongous object is not live so no need to verify its internal pointers\n+\n+    if ((obj_addr < registration_watermark) && !scanner->verify_registration(obj_addr, ctx)) {\n+      ShenandoahAsserts::print_failure(ShenandoahAsserts::_safe_all, obj, obj_addr, nullptr, message,\n+                                       \"object not properly registered\", __FILE__, __LINE__);\n+    }\n+  } else if (!r->is_humongous()) {\n+    while (obj_addr < top) {\n+      oop obj = cast_to_oop(obj_addr);\n+      \/\/ ctx->is_marked() returns true if mark bit set or if obj above TAMS.\n+      if ((ctx == nullptr) || ctx->is_marked(obj)) {\n+        size_t card_index = scanner->card_index_for_addr(obj_addr);\n+        \/\/ For regular objects (not object arrays), if the card holding the start of the object is dirty,\n+        \/\/ we do not need to verify that cards spanning interesting pointers within this object are dirty.\n+        if (!scanner->is_write_card_dirty(card_index) || obj->is_objArray()) {\n+          obj->oop_iterate(&check_interesting_pointers);\n+        }\n+        \/\/ else, object's start is marked dirty and obj is not an objArray, so any interesting pointers are covered\n+\n+        if ((obj_addr < registration_watermark) && !scanner->verify_registration(obj_addr, ctx)) {\n+          ShenandoahAsserts::print_failure(ShenandoahAsserts::_safe_all, obj, obj_addr, nullptr, message,\n+                                           \"object not properly registered\", __FILE__, __LINE__);\n+        }\n+        obj_addr += obj->size();\n+      } else {\n+        \/\/ This object is not live so we don't verify dirty cards contained therein\n+        HeapWord* tams = ctx->top_at_mark_start(r);\n+        obj_addr = ctx->get_next_marked_addr(obj_addr, tams);\n+      }\n+    }\n+  }\n+}\n+\n+\/\/ Assure that the remember set has a dirty card everywhere there is an interesting pointer.\n+\/\/ This examines the read_card_table between bottom() and top() since all PLABS are retired\n+\/\/ before the safepoint for init_mark.  Actually, we retire them before update-references and don't\n+\/\/ restore them until the start of evacuation.\n+void ShenandoahVerifier::verify_rem_set_before_mark() {\n+  shenandoah_assert_safepoint();\n+  assert(_heap->mode()->is_generational(), \"Only verify remembered set for generational operational modes\");\n+\n+  ShenandoahRegionIterator iterator;\n+  RememberedScanner* scanner = _heap->card_scan();\n+  ShenandoahVerifyRemSetClosure check_interesting_pointers(true);\n+  ShenandoahMarkingContext* ctx;\n+\n+  log_debug(gc)(\"Verifying remembered set at %s mark\", _heap->doing_mixed_evacuations()? \"mixed\": \"young\");\n+\n+  if (_heap->is_old_bitmap_stable() || _heap->active_generation()->is_global()) {\n+    ctx = _heap->complete_marking_context();\n+  } else {\n+    ctx = nullptr;\n+  }\n+\n+  while (iterator.has_next()) {\n+    ShenandoahHeapRegion* r = iterator.next();\n+    if (r == nullptr) {\n+      \/\/ TODO: Can this really happen?\n+      break;\n+    }\n+\n+    HeapWord* tams = (ctx != nullptr) ? ctx->top_at_mark_start(r) : nullptr;\n+\n+    \/\/ TODO: Is this replaceable with call to help_verify_region_rem_set?\n+\n+    if (r->is_old() && r->is_active()) {\n+      HeapWord* obj_addr = r->bottom();\n+      if (r->is_humongous_start()) {\n+        oop obj = cast_to_oop(obj_addr);\n+        if ((ctx == nullptr) || ctx->is_marked(obj)) {\n+          \/\/ For humongous objects, the typical object is an array, so the following checks may be overkill\n+          \/\/ For regular objects (not object arrays), if the card holding the start of the object is dirty,\n+          \/\/ we do not need to verify that cards spanning interesting pointers within this object are dirty.\n+          if (!scanner->is_card_dirty(obj_addr) || obj->is_objArray()) {\n+            obj->oop_iterate(&check_interesting_pointers);\n+          }\n+          \/\/ else, object's start is marked dirty and obj is not an objArray, so any interesting pointers are covered\n+        }\n+        \/\/ else, this humongous object is not marked so no need to verify its internal pointers\n+        if (!scanner->verify_registration(obj_addr, ctx)) {\n+          ShenandoahAsserts::print_failure(ShenandoahAsserts::_safe_all, obj, nullptr, nullptr,\n+                                           \"Verify init-mark remembered set violation\", \"object not properly registered\", __FILE__, __LINE__);\n+        }\n+      } else if (!r->is_humongous()) {\n+        HeapWord* top = r->top();\n+        while (obj_addr < top) {\n+          oop obj = cast_to_oop(obj_addr);\n+          \/\/ ctx->is_marked() returns true if mark bit set (TAMS not relevant during init mark)\n+          if ((ctx == nullptr) || ctx->is_marked(obj)) {\n+            \/\/ For regular objects (not object arrays), if the card holding the start of the object is dirty,\n+            \/\/ we do not need to verify that cards spanning interesting pointers within this object are dirty.\n+            if (!scanner->is_card_dirty(obj_addr) || obj->is_objArray()) {\n+              obj->oop_iterate(&check_interesting_pointers);\n+            }\n+            \/\/ else, object's start is marked dirty and obj is not an objArray, so any interesting pointers are covered\n+            if (!scanner->verify_registration(obj_addr, ctx)) {\n+              ShenandoahAsserts::print_failure(ShenandoahAsserts::_safe_all, obj, nullptr, nullptr,\n+                                               \"Verify init-mark remembered set violation\", \"object not properly registered\", __FILE__, __LINE__);\n+            }\n+            obj_addr += obj->size();\n+          } else {\n+            \/\/ This object is not live so we don't verify dirty cards contained therein\n+            assert(tams != nullptr, \"If object is not live, ctx and tams should be non-null\");\n+            obj_addr = ctx->get_next_marked_addr(obj_addr, tams);\n+          }\n+        }\n+      } \/\/ else, we ignore humongous continuation region\n+    } \/\/ else, this is not an OLD region so we ignore it\n+  } \/\/ all regions have been processed\n+}\n+\n+void ShenandoahVerifier::verify_rem_set_after_full_gc() {\n+  shenandoah_assert_safepoint();\n+  assert(_heap->mode()->is_generational(), \"Only verify remembered set for generational operational modes\");\n+\n+  ShenandoahRegionIterator iterator;\n+\n+  while (iterator.has_next()) {\n+    ShenandoahHeapRegion* r = iterator.next();\n+    if (r == nullptr) {\n+      \/\/ TODO: Can this really happen?\n+      break;\n+    }\n+    if (r->is_old() && !r->is_cset()) {\n+      help_verify_region_rem_set(r, nullptr, r->bottom(), r->top(), r->top(), \"Remembered set violation at end of Full GC\");\n+    }\n+  }\n+}\n+\n+\/\/ Assure that the remember set has a dirty card everywhere there is an interesting pointer.  Even though\n+\/\/ the update-references scan of remembered set only examines cards up to update_watermark, the remembered\n+\/\/ set should be valid through top.  This examines the write_card_table between bottom() and top() because\n+\/\/ all PLABS are retired immediately before the start of update refs.\n+void ShenandoahVerifier::verify_rem_set_before_update_ref() {\n+  shenandoah_assert_safepoint();\n+  assert(_heap->mode()->is_generational(), \"Only verify remembered set for generational operational modes\");\n+\n+  ShenandoahRegionIterator iterator;\n+  ShenandoahMarkingContext* ctx;\n+\n+  if (_heap->is_old_bitmap_stable() || _heap->active_generation()->is_global()) {\n+    ctx = _heap->complete_marking_context();\n+  } else {\n+    ctx = nullptr;\n+  }\n+\n+  while (iterator.has_next()) {\n+    ShenandoahHeapRegion* r = iterator.next();\n+    if (r == nullptr) {\n+      \/\/ TODO: Can this really happen?\n+      break;\n+    }\n+    if (r->is_old() && !r->is_cset()) {\n+      help_verify_region_rem_set(r, ctx, r->bottom(), r->top(), r->get_update_watermark(),\n+                                 \"Remembered set violation at init-update-references\");\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVerifier.cpp","additions":512,"deletions":30,"binary":false,"changes":542,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -45,0 +46,16 @@\n+\/*\n+ * @test id=generational\n+ * @summary Test Shenandoah string deduplication implementation\n+ * @key randomness\n+ * @requires vm.gc.Shenandoah\n+ * @library \/test\/lib\n+ * @modules java.base\/java.lang:open\n+ *          java.management\n+ *\n+ * @run main\/othervm -Xmx1g -Xlog:gc+stats -Xlog:gc -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -XX:+UseStringDeduplication\n+ *      -XX:+UseShenandoahGC -XX:ShenandoahGCMode=generational\n+ *      -XX:+ShenandoahDegeneratedGC\n+ *      -DtargetStrings=3000000\n+ *      TestStringDedupStress\n+ *\/\n+\n","filename":"test\/hotspot\/jtreg\/gc\/shenandoah\/TestStringDedupStress.java","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -44,0 +45,19 @@\n+\/* @test id=generational-verify\n+ * @summary Test JNI Global Refs with Shenandoah\n+ * @requires vm.gc.Shenandoah\n+ *\n+ * @run main\/othervm\/native -Xmx1g -Xlog:gc -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions\n+ *      -XX:+UseShenandoahGC -XX:ShenandoahGCMode=generational\n+ *      -XX:+ShenandoahVerify\n+ *      TestJNIGlobalRefs\n+ *\/\n+\n+\/* @test id=generational\n+ * @summary Test JNI Global Refs with Shenandoah\n+ * @requires vm.gc.Shenandoah\n+ *\n+ * @run main\/othervm\/native -Xmx1g -Xlog:gc -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions\n+ *      -XX:+UseShenandoahGC -XX:ShenandoahGCMode=generational\n+ *      TestJNIGlobalRefs\n+ *\/\n+\n","filename":"test\/hotspot\/jtreg\/gc\/shenandoah\/jni\/TestJNIGlobalRefs.java","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -107,0 +108,12 @@\n+\/*\n+ * @test id=generational\n+ * @summary Check that MX notifications are reported for all cycles\n+ * @library \/test\/lib \/\n+ * @requires vm.gc.Shenandoah\n+ *\n+ * @run main\/othervm -Xmx128m -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions\n+ *      -XX:+UseShenandoahGC -XX:ShenandoahGCMode=generational\n+ *      -Dprecise=false -Dmem.pool=Young\n+ *      TestChurnNotifications\n+ *\/\n+\n@@ -131,0 +144,2 @@\n+    private static final String POOL_NAME = \"Young\".equals(System.getProperty(\"mem.pool\")) ? \"Shenandoah Young Gen\" : \"Shenandoah\";\n+\n@@ -144,2 +159,2 @@\n-                    MemoryUsage before = mapBefore.get(\"Shenandoah\");\n-                    MemoryUsage after = mapAfter.get(\"Shenandoah\");\n+                    MemoryUsage before = mapBefore.get(POOL_NAME);\n+                    MemoryUsage after = mapAfter.get(POOL_NAME);\n","filename":"test\/hotspot\/jtreg\/gc\/shenandoah\/mxbeans\/TestChurnNotifications.java","additions":17,"deletions":2,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -101,0 +102,11 @@\n+\/*\n+ * @test id=generational\n+ * @summary Check that MX notifications are reported for all cycles\n+ * @library \/test\/lib \/\n+ * @requires vm.gc.Shenandoah\n+ *\n+ * @run main\/othervm -Xmx128m -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions\n+ *      -XX:+UseShenandoahGC -XX:ShenandoahGCMode=generational\n+ *      TestPauseNotifications\n+ *\/\n+\n","filename":"test\/hotspot\/jtreg\/gc\/shenandoah\/mxbeans\/TestPauseNotifications.java","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"}]}