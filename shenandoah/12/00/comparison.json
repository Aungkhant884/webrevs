{"files":[{"patch":"@@ -0,0 +1,103 @@\n+\/\/\n+\/\/ The anticipated benefits of an alternative SATB-based implementation of the remembered set are several fold:\n+\/\/\n+\/\/  1. The representation of remembered set is more concise (1 bit per card) and there is no remembered set maintenance\n+\/\/     required for ShenandoahHeapRegions that correspond to young-gen memory.  Besides requiring less memory overall,\n+\/\/     additional benefits of the more concise remembered set representation are improved cache hit rates and more efficient\n+\/\/     scanning and maintenance of remembered set information by GC threads.\n+\/\/  2. While the mutator overhead is similar between the modified SATB barrier mechanism and direct card marking, the\n+\/\/     SATB mechanism offers the potential of improved accuracy within the remembered set.  This is because direct card\n+\/\/     marking unconditionally marks every old-gen page that is overwritten with a pointer value, even when the new pointer\n+\/\/     value might refer to old-gen memory.  With the modified SATB mechanism, background GC threads process the addresses\n+\/\/     logged within the SATB buffer and mark cards as dirty only if the pointer found at an overwritten old-gen address\n+\/\/     refers to young-gen memory.  There are (at least) two options here:\n+\/\/\n+\/\/      a) Just blindly dirty each card that is overwritten with a pointer value, regardless of the written value, as with\n+\/\/         the implementation of traditional direct card marking.  When this card's memory region is eventually scanned, the\n+\/\/         the implementation of remembered set scanning will clear the page if it no longer holds references to young-gen\n+\/\/         memory.\n+\/\/      b) When the thread-local SATB becomes full, the thread examines the content of each overwritten address and only\n+\/\/         forwards the address to be marked as dirty if the address holds a young-gen reference.  Presumably, the value\n+\/\/         just recently written by this same thread will be available in the L1 cache and fetching this single reference\n+\/\/         \"now\" is more efficient than reading the entire card's memory at remembered set scanning time only to discover\n+\/\/         then that the card represents no references to young-gen memory.\n+\/\/\n+\/\/     Experiments with each approach may help decide between approaches.\n+\/\/\n+\/\/  3. Potentially, the incremental overhead of adding remembered set logging to the existing SATB barrier is lower than\n+\/\/     the incremental overhead of adding an independent and distinct new write barrier for card marking.  This is especially\n+\/\/     true during times that the SATB barrier is already enabled (which might represent 30-50% of execution for GC-intensive\n+\/\/     workloads).  It may even be true during times that the SATB is disabled.  This is because even when the SATB is disabled,\n+\/\/     register allocation is constrained by the reality that SATB will be enabled some of the time, so registers allocated for\n+\/\/     SATB-buffer maintenance will sit idle during times when the SATB barrier is disabled.  In tight loops that write pointer\n+\/\/     values, for example, the SATB implementation might dedicate registers to holding thread-local information associated with\n+\/\/     maintenance of the SATB buffer such as the address of the SATB buffer and the next available buffer slot within this buffer.\n+\/\/     In the traditional card-marking remembered set implementation, an additional register might be dedicated to holding a\n+\/\/     reference to the base of the card table.\n+\/\/\n+\/\/ Note that a ShenandoahBufferWithSATBRememberedSet maintains the remembered set only for memory regions that correspond to\n+\/\/ old-generation memory.  Anticipate that the implementation will use double indirection.\n+\/\/\n+\/\/ To Do:\n+\/\/\n+\/\/  1. Figure out which region an old-gen address belongs to\n+\/\/  2. Find the cluster and card numbers that corresponds to that region\n+\/\/\n+\/\/ Old-gen memory is not necessarily contiguous.  It may be comprised of multiple heap regions.\n+\/\/\n+\/\/ The memory overhead for crossing map and card-table entries is given by the following analysis:\n+\/\/   For each 512-byte card-entry span, we have the following overhead:\n+\/\/    2 bytes for the object_starts map\n+\/\/    1 bit for the card-table entry\n+\/\/  =====\n+\/\/    2 bytes (rounded down) out of 512 bytes is 0.39% bookkeeping overhead\n+\n+\n+\/\/ ShenandoahBufferWithSATBRememberedSet is not implemented correctly in its current form.\n+\/\/\n+\/\/ This class is a placeholder to support a possible future implementation of remembered set that uses a generalization of the\n+\/\/ existing SATB pre-write barrier to maintain remembered set information rather than using unconditional direct card marking in\n+\/\/ a post-write barrier.\n+class ShenandoahBufferWithSATBRememberedSet: public CHeapObj<mtGC> {\n+\n+  \/\/ The current implementation is simply copied from the implementation of class ShenandoahDirectCardMarkRememberedSet\n+\n+  \/\/ Use symbolic constants defined in cardTable.hpp\n+  \/\/  CardTable::card_shift = 9;\n+  \/\/  CardTable::card_size = 512;\n+  \/\/  CardTable::card_size_in_words = 64;\n+\n+  \/\/  CardTable::clean_card_val()\n+  \/\/  CardTable::dirty_card_val()\n+\n+  ShenandoahHeap *_heap;\n+  uint32_t _card_shift;\n+  size_t _card_count;\n+  uint32_t _cluster_count;\n+  HeapWord *_whole_heap_base;\n+  HeapWord *_whole_heap_end;\n+\n+public:\n+  ShenandoahBufferWithSATBRememberedSet(size_t card_count);\n+  ~ShenandoahBufferWithSATBRememberedSet();\n+\n+  uint32_t card_index_for_addr(HeapWord *p);\n+  HeapWord *addr_for_card_index(uint32_t card_index);\n+  bool is_card_dirty(uint32_t card_index);\n+  void mark_card_as_dirty(uint32_t card_index);\n+  void mark_card_as_clean(uint32_t card_index);\n+  void mark_overreach_card_as_dirty(uint32_t card_index);\n+  bool is_card_dirty(HeapWord *p);\n+  void mark_card_as_dirty(HeapWord *p);\n+  void mark_card_as_clean(HeapWord *p);\n+  void mark_overreach_card_as_dirty(void *p);\n+  uint32_t cluster_count();\n+\n+  \/\/ Called by multiple GC threads at start of concurrent mark and\/ evacuation phases.  Each parallel GC thread typically\n+  \/\/ initializes a different subranges of all overreach entries.\n+  void initialize_overreach(uint32_t first_cluster, uint32_t count);\n+\n+  \/\/ Called by GC thread at end of concurrent mark or evacuation phase.\/ Each parallel GC thread typically merges different\n+  \/\/ subranges of all overreach entries.\n+  void merge_overreach(uint32_t first_cluster, uint32_t count);\n+};\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBufferWithSATBRememberedSet.hpp","additions":103,"deletions":0,"binary":false,"changes":103,"status":"added"},{"patch":"@@ -0,0 +1,52 @@\n+\n+\/\/ ShenandoahBufferWithSATBRemberedSet is not currently implemented\n+\n+inline uint32_t\n+ShenandoahBufferWithSATBRememberedSet::card_index_for_addr(HeapWord *p) {\n+  return 0;\n+}\n+\n+inline HeapWord *\n+ShenandoahBufferWithSATBRememberedSet::addr_for_card_index(uint32_t card_index) {\n+  return NULL;\n+}\n+\n+inline bool\n+ShenandoahBufferWithSATBRememberedSet::is_card_dirty(uint32_t card_index) {\n+  return false;\n+}\n+\n+inline void\n+ShenandoahBufferWithSATBRememberedSet::mark_card_as_dirty(uint32_t card_index) {\n+}\n+\n+inline void\n+ShenandoahBufferWithSATBRememberedSet::mark_card_as_clean(uint32_t card_index) {\n+}\n+\n+inline void\n+ShenandoahBufferWithSATBRememberedSet::mark_overreach_card_as_dirty(uint32_t card_index) {\n+}\n+\n+inline bool\n+ShenandoahBufferWithSATBRememberedSet::is_card_dirty(HeapWord *p) {\n+  return false;\n+}\n+\n+\n+inline void\n+ShenandoahBufferWithSATBRememberedSet::mark_card_as_dirty(HeapWord *p) {\n+}\n+\n+inline void\n+ShenandoahBufferWithSATBRememberedSet::mark_card_as_clean(HeapWord *p) {\n+}\n+\n+inline void\n+ShenandoahBufferWithSATBRememberedSet::mark_overreach_card_as_dirty(void *p) {\n+}\n+\n+inline uint32_t\n+ShenandoahBufferWithSATBRememberedSet::cluster_count() {\n+  return 0;\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBufferWithSATBRememberedSet.inline.hpp","additions":52,"deletions":0,"binary":false,"changes":52,"status":"added"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.inline.hpp\"\n@@ -89,0 +90,1 @@\n+  uint const _workers;\n@@ -90,1 +92,2 @@\n-  ShenandoahInitMarkRootsTask(ShenandoahConcurrentMark* scm, ShenandoahRootScanner* rp) :\n+\n+  ShenandoahInitMarkRootsTask(ShenandoahConcurrentMark* scm, ShenandoahRootScanner* rp, uint worker_count) :\n@@ -93,1 +96,2 @@\n-    _rp(rp) {\n+    _rp(rp),\n+    _workers(worker_count) {\n@@ -109,0 +113,26 @@\n+\n+        \/\/ Do the remembered set scanning before the root scanning as the current implementation of remembered set scanning\n+        \/\/ does not do workload balancing.  If certain worker threads end up with disproportionate amounts of remembered set\n+        \/\/ scanning effort, the subsequent root scanning effort will balance workload to even effort between threads.\n+        uint32_t r;\n+        RememberedScanner *rs = heap->card_scan();\n+        ShenandoahReferenceProcessor* rp = heap->ref_processor();\n+        unsigned int total_regions = heap->num_regions();\n+\n+        for (r = worker_id % _workers; r < total_regions; r += _workers) {\n+          ShenandoahHeapRegion *region = heap->get_region(r);\n+          if (region->affiliation() == OLD_GENERATION) {\n+            uint32_t start_cluster_no = rs->cluster_for_addr(region->bottom());\n+\n+            \/\/ region->end() represents the end of memory spanned by this region, but not all of this\n+            \/\/   memory is eligible to be scanned because some of this memory has not yet been allocated.\n+            \/\/\n+            \/\/ region->top() represents the end of allocated memory within this region.  Any addresses\n+            \/\/   beyond region->top() should not be scanned as that memory does not hold valid objects.\n+            HeapWord *end_of_range = region->top();\n+            uint32_t stop_cluster_no  = rs->cluster_for_addr(end_of_range);\n+            rs->process_clusters<ShenandoahInitMarkRootsClosure<YOUNG, UPDATE_REFS>>(worker_id, rp, _scm, start_cluster_no,\n+                                                                                     stop_cluster_no + 1 - start_cluster_no,\n+                                                                                     end_of_range, &mark_cl);\n+          }\n+        }\n@@ -323,1 +353,1 @@\n-    ShenandoahInitMarkRootsTask<RESOLVE> mark_roots(this, &root_proc);\n+    ShenandoahInitMarkRootsTask<RESOLVE> mark_roots(this, &root_proc, nworkers);\n@@ -328,1 +358,1 @@\n-    ShenandoahInitMarkRootsTask<NONE> mark_roots(this, &root_proc);\n+    ShenandoahInitMarkRootsTask<NONE> mark_roots(this, &root_proc, nworkers);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentMark.cpp","additions":34,"deletions":4,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.hpp\"\n@@ -75,0 +76,2 @@\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.inline.hpp\"\n+\n@@ -214,0 +217,6 @@\n+  if (mode()->is_generational()) {\n+    ShenandoahDirectCardMarkRememberedSet *rs;\n+    size_t card_count = ShenandoahBarrierSet::barrier_set()->card_table()->cards_required(heap_rs.size() \/ HeapWordSize) - 1;\n+    rs = new ShenandoahDirectCardMarkRememberedSet(ShenandoahBarrierSet::barrier_set()->card_table(), card_count);\n+    _card_scan = new ShenandoahScanRemembered<ShenandoahDirectCardMarkRememberedSet>(rs);\n+  }\n@@ -514,1 +523,2 @@\n-  _collection_set(NULL)\n+  _collection_set(NULL),\n+  _card_scan(NULL)\n@@ -1149,0 +1159,1 @@\n+\n@@ -2683,1 +2694,1 @@\n-      do_work();\n+      do_work(worker_id);\n@@ -2686,1 +2697,1 @@\n-      do_work();\n+      do_work(worker_id);\n@@ -2691,1 +2702,1 @@\n-  void do_work() {\n+  void do_work(uint worker_id) {\n@@ -2694,0 +2705,1 @@\n+\n@@ -2697,1 +2709,47 @@\n-      if (r->is_active() && !r->is_cset()) {\n+\n+      \/\/ Eventually, scanning of old-gen memory regions for the purpose of updating references can happen\n+      \/\/ concurrently.  This can be done during concurrent evacuation of roots for example.\n+      if (r->is_active() && (r->affiliation() == ShenandoahRegionAffiliation::OLD_GENERATION) && !r->is_cset()) {\n+\n+        \/\/ Note that we use this code even if we are doing an old-gen collection and we have a bitmap to\n+        \/\/ represent marked objects within the heap region.\n+        \/\/\n+        \/\/ It is necessary to process all objects rather than just the marked objects during update-refs of\n+        \/\/ an old-gen region as part of an old-gen collection.  Otherwise, a subseqent update-refs scan of\n+        \/\/ the same region will see stale pointers and crash.\n+        \/\/\n+        \/\/ Kelvin believes (but has not confirmed) the following:\n+        \/\/   r->top() represents the upper end of memory that has been allocated within this region.\n+        \/\/       As new objects are allocated, the value of r->top() increases to accomodate each new\n+        \/\/       object.\n+        \/\/   r->get_update_watermark() represents the value that was held in r->top() at the start of\n+        \/\/       evacuation.  During evacuation, new objects may be allocated within this heap region\n+        \/\/       and this will cause r->top() to increase.  But any objects allocated during the evacuation\n+        \/\/       phase do not need to be scanned by update-refs because the to-space invariant is in force\n+        \/\/       during evacuation and this will assure that any objects residing between\n+        \/\/       r->get_update_watermark() and r->top() hold no pointers to from-space.\n+\n+        HeapWord *p = r->bottom();\n+        ShenandoahObjectToOopBoundedClosure<T> objs(&cl, p, update_watermark);\n+\n+        \/\/ TODO: This code assumes every object ever allocated within this old-gen region is still live.  If we\n+        \/\/ allow a sweep phase to turn garbage objects into free memory regions, we need to modify this code to\n+        \/\/ skip over and\/or synchronize access to these free memory regions.  There might be races, for example,\n+        \/\/ if we are trying to scan one of these free memory regions while a different thread is trying to\n+        \/\/ allocate from within a free region.\n+        \/\/\n+        \/\/ Reality is that this code is likely to be replaced with JVM-292 code before we ever get around to\n+        \/\/ sweeping up garbage objects within old-gen memory.\n+\n+        \/\/ Anything beyond update_watermark is not yet allocated or initialized\n+        while (p < update_watermark) {\n+          oop obj = oop(p);\n+\n+          \/\/ The invocation of do_object() is \"borrowed\" from the implementation of\n+          \/\/ ShenandoahHeap::marked_object_iterate(), which is called by _heap->marked_object_oop_iterate().\n+          objs.do_object(obj);\n+          p += obj->size();\n+\n+        }\n+      }\n+      else if (r->is_active() && !r->is_cset()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":63,"deletions":5,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.hpp\"\n@@ -39,0 +40,1 @@\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.hpp\"\n@@ -47,0 +49,1 @@\n+class ShenandoahDirectCardMarkRememberedSet;\n@@ -68,0 +71,1 @@\n+\n@@ -698,0 +702,9 @@\n+\/\/ ---------- Generational support\n+\/\/\n+private:\n+  RememberedScanner* _card_scan;\n+\n+public:\n+  inline RememberedScanner* card_scan() { return _card_scan; }\n+\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -315,1 +315,7 @@\n-    \/\/ Increment age in young copies\n+    \/\/ Hey!  This code showed up in a merge conflict.  It has \"nothing\" to do with the patch that\n+    \/\/ was merged, so kdnilsen is leaving it in place as is.  However, it looks to me like the object's\n+    \/\/ age should be incremented before the copy is committed to avoid the need for synchronization here.\n+    \/\/\n+    \/\/ kdnilsen believes the following code is replaced\/relocated in a subsequent commit.\n+\n+    \/\/ Increment age in young copies.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shared\/referencePolicy.hpp\"\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahReferenceProcessor.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,146 @@\n+\/*\n+ * Copyright (c) Amazon.com, Inc. or its affiliates.  All rights reserved.\n+ *\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\n+#include \"gc\/shenandoah\/shenandoahHeapRegion.hpp\"\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeapRegion.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeapRegion.inline.hpp\"\n+\n+ShenandoahDirectCardMarkRememberedSet::ShenandoahDirectCardMarkRememberedSet(CardTable *card_table, size_t total_card_count) {\n+  _heap = ShenandoahHeap::heap();\n+  _card_table = card_table;\n+  _total_card_count = total_card_count;\n+  _cluster_count = (total_card_count \/ ShenandoahCardCluster<ShenandoahDirectCardMarkRememberedSet>::CardsPerCluster);\n+  _card_shift = CardTable::card_shift;\n+\n+  _byte_map = _card_table->byte_for_index(0);\n+\n+  _whole_heap_base = _card_table->addr_for(_byte_map);\n+  _whole_heap_end = _whole_heap_base + total_card_count * CardTable::card_size;\n+\n+  _byte_map_base = _byte_map - (uintptr_t(_whole_heap_base) >> _card_shift);\n+\n+  _overreach_map = (uint8_t *) malloc(total_card_count);\n+  _overreach_map_base = (_overreach_map -\n+                         (uintptr_t(_whole_heap_base) >> _card_shift));\n+\n+  assert(total_card_count % ShenandoahCardCluster<ShenandoahDirectCardMarkRememberedSet>::CardsPerCluster == 0, \"Invalid card count.\");\n+  assert(total_card_count > 0, \"Card count cannot be zero.\");\n+  \/\/ assert(_overreach_cards != NULL);\n+}\n+\n+ShenandoahDirectCardMarkRememberedSet::~ShenandoahDirectCardMarkRememberedSet() {\n+  free(_overreach_map);\n+}\n+\n+void ShenandoahDirectCardMarkRememberedSet::initialize_overreach(uint32_t first_cluster, uint32_t count) {\n+\n+  \/\/ We can make this run faster in the future by explicitly\n+  \/\/ unrolling the loop and doing wide writes if the compiler\n+  \/\/ doesn't do this for us.\n+  uint32_t first_card_index = first_cluster * ShenandoahCardCluster<ShenandoahDirectCardMarkRememberedSet>::CardsPerCluster;\n+  uint8_t *omp = &_overreach_map[first_card_index];\n+  uint8_t *endp = omp + count * ShenandoahCardCluster<ShenandoahDirectCardMarkRememberedSet>::CardsPerCluster;\n+  while (omp < endp)\n+    *omp++ = CardTable::clean_card_val();\n+}\n+\n+void ShenandoahDirectCardMarkRememberedSet::merge_overreach(uint32_t first_cluster, uint32_t count) {\n+\n+  \/\/ We can make this run faster in the future by explicitly unrolling the loop and doing wide writes if the compiler\n+  \/\/ doesn't do this for us.\n+  uint32_t first_card_index = first_cluster * ShenandoahCardCluster<ShenandoahDirectCardMarkRememberedSet>::CardsPerCluster;\n+  uint8_t *bmp = &_byte_map[first_card_index];\n+  uint8_t *endp = bmp + count * ShenandoahCardCluster<ShenandoahDirectCardMarkRememberedSet>::CardsPerCluster;\n+  uint8_t *omp = &_overreach_map[first_card_index];\n+\n+  \/\/ dirty_card is 0, clean card is 0xff; if either *bmp or *omp is dirty, we need to mark it as dirty\n+  while (bmp < endp)\n+    *bmp++ &= *omp++;\n+}\n+\n+\n+\/\/ Implementation is not correct.  ShenandoahBufferWithSATBRememberedSet is a placeholder for future planned improvements.\n+ShenandoahBufferWithSATBRememberedSet::ShenandoahBufferWithSATBRememberedSet(size_t card_count)\n+{\n+  _heap = ShenandoahHeap::heap();\n+\n+  _card_count = card_count;\n+  _cluster_count = _card_count \/\n+      ShenandoahCardCluster<ShenandoahBufferWithSATBRememberedSet>::CardsPerCluster;\n+  _card_shift = CardTable::card_shift;\n+\n+  _whole_heap_base = _heap->base();\n+  _whole_heap_end = _whole_heap_base + _card_count *\n+      ShenandoahCardCluster<ShenandoahBufferWithSATBRememberedSet>::CardsPerCluster;\n+}\n+\n+\/\/ Implementation is not correct.  ShenandoahBufferWithSATBRememberedSet is a placeholder for future planned improvements.\n+ShenandoahBufferWithSATBRememberedSet::~ShenandoahBufferWithSATBRememberedSet()\n+{\n+}\n+\n+\/\/ Implementation is not correct.  ShenandoahBufferWithSATBRememberedSet is a placeholder for future planned improvements.\n+void ShenandoahBufferWithSATBRememberedSet::initialize_overreach(\n+    uint32_t first_cluster, uint32_t count) {\n+}\n+\n+\/\/ Implementation is not correct.  ShenandoahBufferWithSATBRememberedSet is a placeholder for future planned improvements.\n+void ShenandoahBufferWithSATBRememberedSet::merge_overreach(\n+    uint32_t first_cluster, uint32_t count) {\n+}\n+\n+#ifdef IMPLEMENT_THIS_OPTIMIZATION_LATER\n+\n+template <class RememberedSet>\n+bool ShenandoahCardCluster<RememberedSet>::has_object(uint32_t card_index) {\n+  return (object_starts[card_index] & ObjectStartsInCardRegion)? true: false;\n+}\n+\n+template <class RememberedSet>\n+uint32_t ShenandoahCardCluster<RememberedSet>::get_first_start(uint32_t card_index)\n+{\n+  assert(object_starts[card_index] & ObjectStartsInCardRegion);\n+  return (((object_starts[card_index] & FirstStartBits) >> FirstStartShift) *\n+          CardWordOffsetMultiplier);\n+}\n+\n+template <class RememberedSet>\n+uint32_t ShenandoahCardCluster<RememberedSet>::get_last_start(uint32_t card_index) {\n+  assert(object_starts[card_index] & ObjectStartsInCardRegion);\n+  return (((object_starts[card_index] & LastStartBits) >> LastStartShift) *\n+          CardWordOffsetMultiplier);\n+}\n+\n+template <class RememberedSet>\n+uint8_t ShenandoahCardCluster<RememberedSet>::get_crossing_object_start(uint32_t card_index) {\n+  assert((object_starts[card_index] & ObjectStartsInCardRegion) == 0);\n+  return object_starts[card_index] * CardWordOffsetMultiplier;\n+}\n+\n+#endif\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.cpp","additions":146,"deletions":0,"binary":false,"changes":146,"status":"added"},{"patch":"@@ -0,0 +1,945 @@\n+\/*\n+ * Copyright (c) Amazon.com, Inc. or its affiliates.  All rights reserved.\n+ *\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\/\/ Terminology used within this source file:\n+\/\/\n+\/\/ Card Entry:   This is the information that identifies whether a\n+\/\/               particular card-table entry is Clean or Dirty.  A clean\n+\/\/               card entry denotes that the associated memory does not\n+\/\/               hold references to young-gen memory.\n+\/\/\n+\/\/ Card Region, aka\n+\/\/ Card Memory:  This is the region of memory that is assocated with a\n+\/\/               particular card entry.\n+\/\/\n+\/\/ Card Cluster: A card cluster represents 64 card entries.  A card\n+\/\/               cluster is the minimal amount of work performed at a\n+\/\/               time by a parallel thread.  Note that the work required\n+\/\/               to scan a card cluster is somewhat variable in that the\n+\/\/               required effort depends on how many cards are dirty, how\n+\/\/               many references are held within the objects that span a\n+\/\/               DIRTY card's memory, and on the size of the object\n+\/\/               that spans the end of a DIRTY card's memory (because\n+\/\/               that object will be scanned in its entirety). For these\n+\/\/               reasons, it is advisable for the multiple worker threads\n+\/\/               to be flexible in the number of clusters to be\n+\/\/               processed by each thread.\n+\n+\n+\n+\/\/ A cluster represents a \"natural\" quantum of work to be performed by\n+\/\/ a parallel GC thread's background remembered set scanning efforts.\n+\/\/ The notion of cluster is similar to the notion of stripe in the\n+\/\/ implementation of parallel GC card scanning.  However, a cluster is\n+\/\/ typically smaller than a stripe, enabling finer grain division of\n+\/\/ labor between multiple threads.\n+\/\/\n+\/\/ For illustration, consider the following possible JVM configurations:\n+\/\/\n+\/\/   Scenario 1:\n+\/\/     RegionSize is 128 MB\n+\/\/     Span of a card entry is 512 B\n+\/\/     Each card table entry consumes 1 B\n+\/\/     Assume one long word of card table entries represents a cluster.\n+\/\/       This long word holds 8 card table entries, spanning a\n+\/\/       total of 4KB\n+\/\/     The number of clusters per region is 128 MB \/ 4 KB = 32K\n+\/\/\n+\/\/   Scenario 2:\n+\/\/     RegionSize is 128 MB\n+\/\/     Span of each card entry is 128 B\n+\/\/     Each card table entry consumes 1 bit\n+\/\/     Assume one int word of card tables represents a cluster.\n+\/\/       This int word holds 32 card table entries, spanning a\n+\/\/       total of 4KB\n+\/\/     The number of clusters per region is 128 MB \/ 4 KB = 32K\n+\/\/\n+\/\/   Scenario 3:\n+\/\/     RegionSize is 128 MB\n+\/\/     Span of each card entry is 512 B\n+\/\/     Each card table entry consumes 1 bit\n+\/\/     Assume one long word of card tables represents a cluster.\n+\/\/       This long word holds 64 card table entries, spanning a\n+\/\/       total of 32 KB\n+\/\/     The number of clusters per region is 128 MB \/ 32 KB = 4K\n+\/\/\n+\n+\/\/ The typical parallel remembered set scanning effort consists of the\n+\/\/ following steps, all of which are performed during a JVM safetpoint:\n+\/\/\n+\/\/ At the start of a new concurrent mark or concurrent evacuation\n+\/\/ pass, the gang of Shenandoah worker threads collaborate in\n+\/\/ performing the following actions:\n+\/\/\n+\/\/  Let old_regions = number of ShenandoahHeapRegion comprising\n+\/\/    old-gen memory\n+\/\/  Let region_size = ShenandoahHeapRegion::region_size_bytes()\n+\/\/    represent the number of bytes in each region\n+\/\/  Let clusters_per_region = region_size \/ 512\n+\/\/  Let rs represent the relevant RememberedSet implementation\n+\/\/    (an instance of ShenandoahBufferWithSATBRememberedSet or\n+\/\/     ShenandoahDirectCardMarkRememberedSet)\n+\/\/\n+\/\/  for each ShenandoahHeapRegion old_region in the whole heap\n+\/\/    determine the cluster number of the first cluster belonging\n+\/\/      to that region\n+\/\/    for each cluster contained within that region\n+\/\/      Assure that exactly one worker thread initializes each\n+\/\/      cluster of overreach memory by invoking:\n+\/\/\n+\/\/        rs->initialize_overreach(cluster_no, cluster_count)\n+\/\/\n+\/\/      in separate threads.  (Divide up the clusters so that\n+\/\/      different threads are responsible for initializing different\n+\/\/      clusters.  Initialization cost is essentially identical for\n+\/\/      each cluster.)\n+\/\/\n+\/\/  Next, we repeat the process for invocations of examineCluster:\n+\/\/  for each ShenandoahHeapRegion old_region in the whole heap\n+\/\/    determine the cluster number of the first cluster belonging\n+\/\/      to that region\n+\/\/    for each cluster contained within that region\n+\/\/      Assure that exactly one worker thread processes each\n+\/\/      cluster, each thread making a series of invocations of the\n+\/\/      following:\n+\/\/\n+\/\/        rs->process_clusters(worker_id, ReferenceProcessor *,\n+\/\/                            ShenandoahConcurrentMark *, cluster_no, cluster_count,\n+\/\/                            HeapWord *end_of_range, OopClosure *oops);\n+\/\/        \/\/ Use the same approach for invocations of replaceClusters()\n+\/\/\n+\/\/      Divide up the clusters so that different threads are\n+\/\/      responsible for processing different clusters.  Processing\n+\/\/      cost may vary greatly between clusters for the following\n+\/\/      reasons:\n+\/\/        a) some clusters contain mostly dirty cards and other\n+\/\/           clusters contain mostly clean cards\n+\/\/        b) some clusters contain mostly primitive data and other\n+\/\/           clusters contain mostly reference data\n+\/\/        c) some clusters are spanned by very large objects that\n+\/\/           begin in some other cluster.  When a large object\n+\/\/           beginning in a preceding cluster spans large portions of\n+\/\/           this cluster, the processing of this cluster gets a\n+\/\/           \"free ride\" because the thread responsible for processing\n+\/\/           the cluster that holds the object's header does the\n+\/\/           processing.\n+\/\/        d) in the case that the end of this cluster is spanned by a\n+\/\/           very large object, the processing of this cluster will\n+\/\/           be responsible for examining the entire object,\n+\/\/           potentially requiring this thread to process large amounts\n+\/\/           of memory pertaining to other clusters.\n+\/\/\n+\/\/      Though an initial division of labor between marking threads\n+\/\/      may assign equal numbers of clusters to be scanned by each\n+\/\/      thread, it should be expected that some threads will finish\n+\/\/      their assigned work before others.  Therefore, some amount\n+\/\/      of the full remembered set scanning effort should be held\n+\/\/      back and assigned incrementally to the threads that end up with\n+\/\/      excess capacity.  Consider the following strategy for dividing\n+\/\/      labor:\n+\/\/\n+\/\/        1. Assume there are 8 marking threads and 1024 remembered\n+\/\/           set clusters to be scanned.\n+\/\/        2. Assign each thread to scan 64 clusters.  This leaves\n+\/\/           512 (1024 - (8*64)) clusters to still be scanned.\n+\/\/        3. As the 8 server threads complete previous cluster\n+\/\/           scanning assignments, issue each of the next 8 scanning\n+\/\/           assignments as units of 32 additional cluster each.\n+\/\/           In the case that there is high variance in effort\n+\/\/           associated with previous cluster scanning assignments,\n+\/\/           multiples of these next assignments may be serviced by\n+\/\/           the server threads that were previously assigned lighter\n+\/\/           workloads.\n+\/\/        4. Make subsequent scanning assignments as follows:\n+\/\/             a) 8 assignments of size 16 clusters\n+\/\/             b) 8 assignments of size 8 clusters\n+\/\/             c) 16 assignments of size 4 clusters\n+\/\/\n+\/\/    When there is no more remembered set processing work to be\n+\/\/    assigned to a newly idled worker threads, that thread can move\n+\/\/    on to work on other tasks associated with root scanning until such\n+\/\/    time as all clusters have been examined.\n+\/\/\n+\/\/  Once all clusters have been processed, the gang of GC worker\n+\/\/  threads collaborate to merge the overreach data.\n+\/\/\n+\/\/  for each ShenandoahHeapRegion old_region in the whole heap\n+\/\/    determine the cluster number of the first cluster belonging\n+\/\/      to that region\n+\/\/    for each cluster contained within that region\n+\/\/      Assure that exactly one worker thread initializes each\n+\/\/      cluster of overreach memory by invoking:\n+\/\/\n+\/\/        rs->merge_overreach(cluster_no, cluster_count)\n+\/\/\n+\/\/      in separate threads.  (Divide up the clusters so that\n+\/\/      different threads are responsible for merging different\n+\/\/      clusters.  Merging cost is essentially identical for\n+\/\/      each cluster.)\n+\/\/\n+\/\/\n+\/\/ To initiate concurrent scanning, insert the above code sequences\n+\/\/ into strong_roots_do and roots_do methods of ShenandoahRootScanner\n+\/\/ (source file shenandoahRootProcessor.cpp) following the\n+\/\/ construction of tc_cl and rm and before the call to\n+\/\/ _serial_roots.oops_do().\n+\/\/\n+\/\/ To initiate concurrent evacuation, insert the above code sequences\n+\/\/ into ShenandoahRootEvacuator::roots_do() before the invocation of\n+\/\/ _serial_roots.oops_do(oops, worker_id).\n+\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHSCANREMEMBERED_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHSCANREMEMBERED_HPP\n+\n+#include <stdint.h>\n+#include \"memory\/iterator.hpp\"\n+#include \"gc\/shenandoah\/shenandoahCardTable.hpp\"\n+#include \"gc\/shenandoah\/shenandoahReferenceProcessor.hpp\"\n+\n+class ReferenceProcessor;\n+class ShenandoahConcurrentMark;\n+class ShenandoahHeap;\n+class CardTable;\n+\n+#include \"gc\/shenandoah\/shenandoahBufferWithSATBRememberedSet.hpp\"\n+\n+class ShenandoahDirectCardMarkRememberedSet: public CHeapObj<mtGC> {\n+\n+private:\n+\n+  \/\/ Use symbolic constants defined in cardTable.hpp\n+  \/\/  CardTable::card_shift = 9;\n+  \/\/  CardTable::card_size = 512;\n+  \/\/  CardTable::card_size_in_words = 64;\n+\n+  \/\/  CardTable::clean_card_val()\n+  \/\/  CardTable::dirty_card_val()\n+\n+  ShenandoahHeap *_heap;\n+  CardTable *_card_table;\n+  uint32_t _card_shift;\n+  size_t _total_card_count;\n+  uint32_t _cluster_count;\n+  HeapWord *_whole_heap_base;   \/\/ Points to first HeapWord of data contained within heap memory\n+  HeapWord *_whole_heap_end;\n+  uint8_t *_byte_map;           \/\/ Points to first entry within the card table\n+  uint8_t *_byte_map_base;      \/\/ Points to byte_map minus the bias computed from address of heap memory\n+  uint8_t *_overreach_map;      \/\/ Points to first entry within the overreach card table\n+  uint8_t *_overreach_map_base; \/\/ Points to overreach_map minus the bias computed from address of heap memory\n+\n+public:\n+  \/\/ count is the number of cards represented by the card table.\n+  ShenandoahDirectCardMarkRememberedSet(CardTable *card_table, size_t total_card_count);\n+  ~ShenandoahDirectCardMarkRememberedSet();\n+\n+  \/\/ Card index is zero-based relative to _byte_map.\n+  uint32_t card_index_for_addr(HeapWord *p);\n+  HeapWord *addr_for_card_index(uint32_t card_index);\n+  bool is_card_dirty(uint32_t card_index);\n+  void mark_card_as_dirty(uint32_t card_index);\n+  void mark_card_as_clean(uint32_t card_index);\n+  void mark_overreach_card_as_dirty(uint32_t card_index);\n+  bool is_card_dirty(HeapWord *p);\n+  void mark_card_as_dirty(HeapWord *p);\n+  void mark_card_as_clean(HeapWord *p);\n+  void mark_overreach_card_as_dirty(void *p);\n+  uint32_t cluster_count();\n+\n+  \/\/ Called by multiple GC threads at start of concurrent mark and evacuation phases.  Each parallel GC thread typically\n+  \/\/ initializes a different subranges of all overreach entries.\n+  void initialize_overreach(uint32_t first_cluster, uint32_t count);\n+\n+  \/\/ Called by GC thread at end of concurrent mark or evacuation phase.  Each parallel GC thread typically merges different\n+  \/\/ subranges of all overreach entries.\n+  void merge_overreach(uint32_t first_cluster, uint32_t count);\n+};\n+\n+\/\/ A ShenandoahCardCluster represents the minimal unit of work\n+\/\/ performed by independent parallel GC threads during scanning of\n+\/\/ remembered sets.\n+\/\/\n+\/\/ The GC threads that perform card-table remembered set scanning may\n+\/\/ overwrite card-table entries to mark them as clean in the case that\n+\/\/ the associated memory no longer holds references to young-gen\n+\/\/ memory.  Rather than access the card-table entries directly, all GC\n+\/\/ thread access to card-table information is made by way of the\n+\/\/ ShenandoahCardCluster data abstraction.  This abstraction\n+\/\/ effectively manages access to multiple possible underlying\n+\/\/ remembered set implementations, including a traditional card-table\n+\/\/ approach and a SATB-based approach.\n+\/\/\n+\/\/ The API services represent a compromise between efficiency and\n+\/\/ convenience.\n+\/\/\n+\/\/ In the initial implementation, we assume that scanning of card\n+\/\/ table entries occurs only while the JVM is at a safe point.  Thus,\n+\/\/ there is no synchronization required between GC threads that are\n+\/\/ scanning card-table entries and marking certain entries that were\n+\/\/ previously dirty as clean, and mutator threads which would possibly\n+\/\/ be marking certain card-table entries as dirty.\n+\/\/\n+\/\/ There is however a need to implement concurrency control and memory\n+\/\/ coherency between multiple GC threads that scan the remembered set\n+\/\/ in parallel.  The desire is to divide the complete scanning effort\n+\/\/ into multiple clusters of work that can be independently processed\n+\/\/ by individual threads without need for synchronizing efforts\n+\/\/ between the work performed by each task.  The term \"cluster\" of\n+\/\/ work is similar to the term \"stripe\" as used in the implementation\n+\/\/ of Parallel GC.\n+\/\/\n+\/\/ Complexity arises when an object to be scanned crosses the boundary\n+\/\/ between adjacent cluster regions.  Here is the protocol that is\n+\/\/ followed:\n+\/\/\n+\/\/  1. We implement a supplemental data structure known as the overreach\n+\/\/     card table.  The thread that is responsible for scanning each\n+\/\/     cluster of card-table entries is granted exclusive access to\n+\/\/     modify the associated card-table entries.  In the case that a\n+\/\/     thread scans a very large object that reaches into one or more\n+\/\/     following clusters, that thread has exclusive access to the\n+\/\/     overreach card table for all of the entries belonging to the\n+\/\/     following clusters that are spanned by this large object.\n+\/\/     After all clusters have been scanned, the scanning threads\n+\/\/     briefly synchronize to merge the contents of the overreach\n+\/\/     entries with the traditional card table entries using logical-\n+\/\/     and operations.\n+\/\/  2. Every object is scanned in its \"entirety\" by the thread that is\n+\/\/     responsible for the cluster that holds its starting address.\n+\/\/     Entirety is in quotes because there are various situations in\n+\/\/     which some portions of the object will not be scanned by this\n+\/\/     thread:\n+\/\/     a) If an object spans multiple card regions, all of which are\n+\/\/        contained within the same cluster, the scanning thread\n+\/\/        consults the existing card-table entries and does not scan\n+\/\/        portions of the object that are not currently dirty.\n+\/\/     b) For any cluster that is spanned in its entirety by a very\n+\/\/        large object, the GC thread that scans this object assumes\n+\/\/        full responsibility for maintenance of the associated\n+\/\/        card-table entries.\n+\/\/     c) If a cluster is partially spanned by an object originating\n+\/\/        in a preceding cluster, the portion of the object that\n+\/\/        partially spans the following cluster is scanned in its\n+\/\/        entirety (because the thread that is responsible for\n+\/\/        scanning the object cannot rely upon the card-table entries\n+\/\/        associated with the following cluster).  Whenever references\n+\/\/        to young-gen memory are found within the scanned data, the\n+\/\/        associated overreach card table entries are marked as dirty\n+\/\/        by the scanning thread.\n+\/\/  3. If a cluster is spanned in its entirety by an object that\n+\/\/     originates within a preceding cluster's memory, the thread\n+\/\/     assigned to examine this cluster does absolutely nothing.  The\n+\/\/     thread assigned to scan the cluster that holds the object's\n+\/\/     starting address takes full responsibility for scanning the\n+\/\/     entire object and updating the associated card-table entries.\n+\/\/  4. If a cluster is spanned partially by an object that originates\n+\/\/     within a preceding cluster's memory, the thread assigned to\n+\/\/     examine this cluster marks the card-table entry as clean for\n+\/\/     each card table that is fully spanned by this overreaching\n+\/\/     object.  If a card-table entry's memory is partially spanned\n+\/\/     by the overreaching object, the thread sets the card-table\n+\/\/     entry to clean if it was previously dirty and if the portion\n+\/\/     of the card-table entry's memory that is not spanned by the\n+\/\/     overreaching object does not hold pointers to young-gen\n+\/\/     memory.\n+\/\/  5. While examining a particular card belonging to a particular\n+\/\/     cluster, if an object reaches beyond the end of its card\n+\/\/     memory, the thread \"scans\" all portions of the object that\n+\/\/     correspond to DIRTY card entries within the current cluster and\n+\/\/     all portions of the object that reach into following clustesr.\n+\/\/     After this object is scanned, continue scanning with the memory\n+\/\/     that follows this object if this memory pertains to the same\n+\/\/     cluster.  Otherwise, consider this cluster's memory to have\n+\/\/     been fully examined.\n+\/\/\n+\/\/ Discussion:\n+\/\/  Though this design results from careful consideration of multiple\n+\/\/  design objectives, it is subject to various criticisms.  Some\n+\/\/  discussion of the design choices is provided here:\n+\/\/\n+\/\/  1. Note that remembered sets are a heuristic technique to avoid\n+\/\/     the need to scan all of old-gen memory with each young-gen\n+\/\/     collection.  If we sometimes scan a bit more memory than is\n+\/\/     absolutely necessary, that should be considered a reasonable\n+\/\/     compromise.  This compromise is already present in the sizing\n+\/\/     of card table memory areas.  Note that a single dirty pointer\n+\/\/     within a 512-byte card region forces the \"unnecessary\" scanning\n+\/\/     of 63 = ((512 - 8 = 504) \/ 8) pointers.\n+\/\/  2. One undesirable aspect of this design is that we sometimes have\n+\/\/     to scan large amounts of memory belonging to very large\n+\/\/     objects, even for parts of the very large object that do not\n+\/\/     correspond to dirty card table entries.  Note that this design\n+\/\/     limits the amount of non-dirty scanning that might have to\n+\/\/     be performed for these very large objects.  In particular, only\n+\/\/     the last part of the very large object that extends into but\n+\/\/     does not completely span a particular cluster is unnecessarily\n+\/\/     scanned.  Thus, for each very large object, the maximum\n+\/\/     over-scan is the size of memory spanned by a single cluster.\n+\/\/  3. The representation of pointer location descriptive information\n+\/\/     within Klass representations is not designed for efficient\n+\/\/     \"random access\".  An alternative approach to this design would\n+\/\/     be to scan very large objects multiple times, once for each\n+\/\/     cluster that is spanned by the object's range.  This reduces\n+\/\/     unnecessary overscan, but it introduces different sorts of\n+\/\/     overhead effort:\n+\/\/       i) For each spanned cluster, we have to look up the start of\n+\/\/          the crossing object.\n+\/\/      ii) Each time we scan the very large object, we have to\n+\/\/          sequentially walk through its pointer location\n+\/\/          descriptors, skipping over all of the pointers that\n+\/\/          precede the start of the range of addresses that we\n+\/\/          consider relevant.\n+\n+\n+\/\/ Because old-gen heap memory is not necessarily contiguous, and\n+\/\/ because cards are not necessarily maintained for young-gen memory,\n+\/\/ consecutive card numbers do not necessarily correspond to consecutive\n+\/\/ address ranges.  For the traditional direct-card-marking\n+\/\/ implementation of this interface, consecutive card numbers are\n+\/\/ likely to correspond to contiguous regions of memory, but this\n+\/\/ should not be assumed.  Instead, rely only upon the following:\n+\/\/\n+\/\/  1. All card numbers for cards pertaining to the same\n+\/\/     ShenandoahHeapRegion are consecutively numbered.\n+\/\/  2. In the case that neighboring ShenandoahHeapRegions both\n+\/\/     represent old-gen memory, the card regions that span the\n+\/\/     boundary between these neighboring heap regions will be\n+\/\/     consecutively numbered.\n+\/\/  3. (A corollary) In the case that an old-gen object spans the\n+\/\/     boundary between two heap regions, the card regions that\n+\/\/     correspond to the span of this object will be consecutively\n+\/\/     numbered.\n+\n+\n+\/\/ ShenandoahCardCluster abstracts access to the remembered set\n+\/\/ and also keeps track of crossing map information to allow efficient\n+\/\/ resolution of object start addresses.\n+\/\/\n+\/\/ ShenandoahCardCluster supports all of the services of\n+\/\/ RememberedSet, plus it supports register_object() and lookup_object().\n+\/\/\n+\/\/ There are two situations under which we need to know the location\n+\/\/ at which the object spanning the start of a particular card-table\n+\/\/ memory region begins:\n+\/\/\n+\/\/ 1. When we begin to scan dirty card memory that is not the\n+\/\/    first card region within a cluster, and the object that\n+\/\/    crosses into this card memory was not previously scanned,\n+\/\/    we need to find where that object starts so we can scan it.\n+\/\/    (Asides: if the objects starts within a previous cluster, it\n+\/\/     has already been scanned.  If the object starts within this\n+\/\/     cluster and it spans at least one card region that is dirty\n+\/\/     and precedes this card region within the cluster, then it has\n+\/\/     already been scanned.)\n+\/\/ 2. When we are otherwise done scanning a complete cluster, if the\n+\/\/    last object within the cluster reaches into the following\n+\/\/    cluster, we need to scan this object.  Thus, we need to find\n+\/\/    its starting location.\n+\/\/\n+\/\/ The RememberedSet template parameter is intended to represent either\n+\/\/     ShenandoahDirectCardMarkRememberedSet, or\n+\/\/     ShenandoahBufferWithSATBRememberedSet.\n+template<typename RememberedSet>\n+class ShenandoahCardCluster: public CHeapObj<mtGC> {\n+\n+private:\n+  RememberedSet *_rs;\n+\n+public:\n+  static const uint32_t CardsPerCluster = 64;\n+\n+  ShenandoahCardCluster(RememberedSet *rs) {\n+    _rs = rs;\n+  }\n+\n+  ~ShenandoahCardCluster() {\n+  }\n+\n+  \/\/ There is one entry within the object_starts array for each\n+  \/\/ card entry.  The interpretation of the data contained within each\n+  \/\/ object_starts entry is described below:\n+  \/\/\n+  \/\/ Bits 0x003f: Value ranges from 0-63, which is multiplied by 8\n+  \/\/              to obtain the offset at which the first object\n+  \/\/              beginning within this card region begins.\n+  \/\/ Bits 0x0fc0: Value ranges from 0-63, which is multiplied by 8 to\n+  \/\/              obtain the offset at which the last object beginning\n+  \/\/              within this card region begins.\n+  \/\/ Bits 0x8000: This bit is on if an object starts within this card\n+  \/\/              region.\n+  \/\/\n+  \/\/ In the most recent implementation of ShenandoahScanRemembered::process_clusters(),\n+  \/\/ there is no need for the get_crossing_object_start() method function, so there is no\n+  \/\/ need to maintain the following information.  The comment is left in place for now in\n+  \/\/ case we find it necessary to add support for this service at a later time.\n+  \/\/\n+  \/\/ Bits 0x7fff: If no object starts within this card region, the\n+  \/\/              remaining bits of the object_starts array represent\n+  \/\/              the absolute word offset within the enclosing\n+  \/\/              cluster's memory of the starting address for the\n+  \/\/              object that spans the start of this card region's\n+  \/\/              memory.  If the spanning object begins in memory\n+  \/\/              that precedes this card region's cluster, the value\n+  \/\/              stored in these bits is the special value 0x7fff.\n+  \/\/              (Note that the maximum value required to represent a\n+  \/\/              spanning object from within the current cluster is\n+  \/\/              ((63 * 64) - 8), which equals 0x0fbf.\n+  \/\/\n+  \/\/ In the absence of the need to support get_crossing_object_start(),\n+  \/\/ here is discussion of performance:\n+  \/\/\n+  \/\/  Suppose multiple garbage objects are coalesced during GC sweep\n+  \/\/  into a single larger \"free segment\".  As each two objects are\n+  \/\/  coalesced together, the start information pertaining to the second\n+  \/\/  object must be removed from the objects_starts array.  If the\n+  \/\/  second object had been been the first object within card memory,\n+  \/\/  the new first object is the object that follows that object if\n+  \/\/  that starts within the same card memory, or NoObject if the\n+  \/\/  following object starts within the following cluster.  If the\n+  \/\/  second object had been the last object in the card memory,\n+  \/\/  replace this entry with the newly coalesced object if it starts\n+  \/\/  within the same card memory, or with NoObject if it starts in a\n+  \/\/  preceding card's memory.\n+  \/\/\n+  \/\/  Suppose a large free segment is divided into a smaller free\n+  \/\/  segment and a new object.  The second part of the newly divided\n+  \/\/  memory must be registered as a new object, overwriting at most\n+  \/\/  one first_start and one last_start entry.  Note that one of the\n+  \/\/  newly divided two objects might be a new GCLAB.\n+  \/\/\n+  \/\/  Suppose postprocessing of a GCLAB finds that the original GCLAB\n+  \/\/  has been divided into N objects.  Each of the N newly allocated\n+  \/\/  objects will be registered, overwriting at most one first_start\n+  \/\/  and one last_start entries.\n+  \/\/\n+  \/\/  No object registration operations are linear in the length of\n+  \/\/  the registered objects.\n+  \/\/\n+  \/\/ Consider further the following observations regarding object\n+  \/\/ registration costs:\n+  \/\/\n+  \/\/   1. The cost is paid once for each old-gen object (Except when\n+  \/\/      an object is demoted and repromoted, in which case we would\n+  \/\/      pay the cost again).\n+  \/\/   2. The cost can be deferred so that there is no urgency during\n+  \/\/      mutator copy-on-first-access promotion.  Background GC\n+  \/\/      threads will update the object_starts array by post-\n+  \/\/      processing the contents of retired GCLAB buffers.\n+  \/\/   3. The bet is that these costs are paid relatively rarely\n+  \/\/      because:\n+  \/\/      a) Most objects die young and objects that die in young-gen\n+  \/\/         memory never need to be registered with the object_starts\n+  \/\/         array.\n+  \/\/      b) Most objects that are promoted into old-gen memory live\n+  \/\/         there without further relocation for a relatively long\n+  \/\/         time, so we get a lot of benefit from each investment\n+  \/\/         in registering an object.\n+\n+private:\n+  const uint32_t CardByteOffsetMultiplier = 8;\n+  const uint32_t CardWordOffsetMultiplier = 1;\n+\n+#ifdef IMPLEMENT_THIS_OPTIMIZATION_LATER\n+\n+  \/\/ This bit is set iff at least one object starts within a\n+  \/\/ particular card region.\n+  const uint_16 ObjectStartsInCardRegion = 0x8000;\n+  const uint_16 FirstStartBits = 0x003f;\n+  const uint_16 LastStartBits = 0x0fc0;\n+  const uint_16 FirstStartShift = 0;\n+  const uint_16 LastStartShift = 6;\n+  const uint_16 CrossingObjectOverflow = 0x7fff;\n+\n+  uint_16 *object_starts;\n+\n+public:\n+  inline void set_first_start(uint32_t card_index, uint8_t value) {\n+    object_starts[card_index] &= ~FirstStartBits;\n+    object_starts[card_index] |= (FirstStartBits & (value << FirstStartShift));\n+  }\n+\n+  inline void set_last_start(uint32_t card_index, uint8_t value) {\n+    object_starts[card_index] &= ~LastStartBits;\n+    object_starts[card_index] |= (LastStartBits & (value << LastStartShift));\n+  }\n+\n+  inline void set_has_object_bit(uint32_t card_index) {\n+    object_starts[card_index] |= ObjectStartsInCardRegion;\n+  }\n+\n+  \/\/ This has side effect of clearing ObjectStartsInCardRegion bit.\n+  inline void set_crossing_object_start(uint32_t card_index, uint_16 crossing_offset) {\n+    object_starts[card_index] = crossing_offset;\n+  }\n+#endif  \/\/ IMPLEMENT_THIS_OPTIMIZATION_LATER\n+\n+public:\n+\n+  \/\/ The starting locations of objects contained within old-gen memory\n+  \/\/ are registered as part of the remembered set implementation.  This\n+  \/\/ information is required when scanning dirty card regions that are\n+  \/\/ spanned by objects beginning within preceding card regions.  It\n+  \/\/ is necessary to find the first and last objects that begin within\n+  \/\/ this card region.  Starting addresses of objects are required to\n+  \/\/ find the object headers, and object headers provide information\n+  \/\/ about which fields within the object hold addresses.\n+  \/\/\n+  \/\/ The old-gen memory allocator invokes register_object() for any\n+  \/\/ object that is allocated within old-gen memory.  This identifies\n+  \/\/ the starting addresses of objects that span boundaries between\n+  \/\/ card regions.\n+  \/\/\n+  \/\/ It is not necessary to invoke register_object at the very instant\n+  \/\/ an object is allocated.  It is only necessary to invoke it\n+  \/\/ prior to the next start of a garbage collection concurrent mark\n+  \/\/ or concurrent evacuation phase.  An \"ideal\" time to register\n+  \/\/ objects is during post-processing of a GCLAB after the GCLAB is\n+  \/\/ retired due to depletion of its memory.\n+  \/\/\n+  \/\/ register_object() does not perform synchronization.  In the case\n+  \/\/ that multiple threads are registering objects whose starting\n+  \/\/ addresses are within the same cluster, races between these\n+  \/\/ threads may result in corruption of the object-start data\n+  \/\/ structures.  Parallel GC threads should avoid registering objects\n+  \/\/ residing within the same cluster by adhering to the following\n+  \/\/ coordination protocols:\n+  \/\/\n+  \/\/  1. Align thread-local GCLAB buffers with some TBD multiple of\n+  \/\/     card clusters.  The card cluster size is 32 KB.  If the\n+  \/\/     desired GCLAB size is 128 KB, align the buffer on a multiple\n+  \/\/     of 4 card clusters.\n+  \/\/  2. Post-process the contents of GCLAB buffers to register the\n+  \/\/     objects allocated therein.  Allow one GC thread at a\n+  \/\/     time to do the post-processing of each GCLAB.\n+  \/\/  3. Since only one GC thread at a time is registering objects\n+  \/\/     belonging to a particular allocation buffer, no locking\n+  \/\/     is performed when registering these objects.\n+  \/\/  4. Any remnant of unallocated memory within an expended GC\n+  \/\/     allocation buffer is not returned to the old-gen allocation\n+  \/\/     pool until after the GC allocation buffer has been post\n+  \/\/     processed.  Before any remnant memory is returned to the\n+  \/\/     old-gen allocation pool, the GC thread that scanned this GC\n+  \/\/     allocation buffer performs a write-commit memory barrier.\n+  \/\/  5. Background GC threads that perform tenuring of young-gen\n+  \/\/     objects without a GCLAB use a CAS lock before registering\n+  \/\/     each tenured object.  The CAS lock assures both mutual\n+  \/\/     exclusion and memory coherency\/visibility.  Note that an\n+  \/\/     object tenured by a background GC thread will not overlap\n+  \/\/     with any of the clusters that are receiving tenured objects\n+  \/\/     by way of GCLAB buffers.  Multiple independent GC threads may\n+  \/\/     attempt to tenure objects into a shared cluster.  This is why\n+  \/\/     sychronization may be necessary.  Consider the following\n+  \/\/     scenarios:\n+  \/\/\n+  \/\/     a) If two objects are tenured into the same card region, each\n+  \/\/        registration may attempt to modify the first-start or\n+  \/\/        last-start information associated with that card region.\n+  \/\/        Furthermore, because the representations of first-start\n+  \/\/        and last-start information within the object_starts array\n+  \/\/        entry uses different bits of a shared uint_16 to represent\n+  \/\/        each, it is necessary to lock the entire card entry\n+  \/\/        before modifying either the first-start or last-start\n+  \/\/        information within the entry.\n+  \/\/     b) Suppose GC thread X promotes a tenured object into\n+  \/\/        card region A and this tenured object spans into\n+  \/\/        neighboring card region B.  Suppose GC thread Y (not equal\n+  \/\/        to X) promotes a tenured object into cluster B.  GC thread X\n+  \/\/        will update the object_starts information for card A.  No\n+  \/\/        synchronization is required.\n+  \/\/     c) In summary, when background GC threads register objects\n+  \/\/        newly tenured into old-gen memory, they must acquire a\n+  \/\/        mutual exclusion lock on the card that holds the starting\n+  \/\/        address of the newly tenured object.  This can be achieved\n+  \/\/        by using a CAS instruction to assure that the previous\n+  \/\/        values of first-offset and last-offset have not been\n+  \/\/        changed since the same thread inquired as to their most\n+  \/\/        current values.\n+  \/\/\n+  \/\/     One way to minimize the need for synchronization between\n+  \/\/     background tenuring GC threads is for each tenuring GC thread\n+  \/\/     to promote young-gen objects into distinct dedicated cluster\n+  \/\/     ranges.\n+  \/\/  6. The object_starts information is only required during the\n+  \/\/     starting of concurrent marking and concurrent evacuation\n+  \/\/     phases of GC.  Before we start either of these GC phases, the\n+  \/\/     JVM enters a safe point and all GC threads perform\n+  \/\/     commit-write barriers to assure that access to the\n+  \/\/     object_starts information is coherent.\n+\n+  static void register_object(void *address, uint32_t length_in_bytes) {\n+\n+#ifdef IMPLEMENT_THIS_OPTIMIZATION_LATER\n+    uint32_t card_at_start = cardAtAddress(address);\n+    \/\/ The end of this object is contained within this card\n+    uint32_t card_at_end = cardAtAddress(address + length_in_bytes);\n+\n+    uint32_t cluster_at_start = clusterAtCard(card_at_start);\n+    uint32_t cluster_at_end = clusterAtCard(card_at_end);\n+\n+    void *card_start_address = addressAtCard(card_at_start);\n+    void *cluster_start_address = addressAtCluster(cluster_at_start);\n+\n+    uint8_t offset_in_card =\n+      (address - card_start_address) \/ CardOffsetMultiplier;\n+\n+    if (!getHashObjectBit(card_at_start)) {\n+      set_has_object_bit(card_at_start);\n+      set_first_start(card_at_start, offset_in_card);\n+      set_last_start(card_at_start, offset_in_card);\n+    } else {\n+      if (offset_in_card < get_first_start(card_at_start))\n+        set_first_start(card_at_start, offset_in_card);\n+      if (offset_in_card > get_last_start(card_at_start))\n+        set_last_start(card_at_last, offset_in_card);\n+    }\n+\n+#ifdef SUPPORT_FOR_GET_CROSSING_OBJECT_START_NO_LONGER_REQUIRED\n+\n+    \/\/ What is the last card within the current cluster?\n+    uint32_t next_cluster = cluster_at_start + 1;\n+    uint32_t card_at_next_cluster = cardAtCluster(next_cluster);\n+    uint32_t last_card_of_this_cluster = card_at_next_cluster - 1;\n+    uint32_t last_card_in_cluster = ((card_at_end < last_card_of_this_cluster) ? card_at_end: last_card_of_this_cluster);\n+\n+    uint_16 crossing_map_within_cluster = address - cluster_at_start;\n+\n+    for (uint32_t card_to_update = card_at_start + 1; card_to_update < last_card_in_cluster; card_to_update++)\n+      set_crossing_object_start(card_to_update, crossing_map_within_cluster);\n+\n+    \/\/ If the last card region of this cluster is completely spanned\n+    \/\/ by this new object,  set its crossing object start as well.\n+    if (cluster_at_end > cluster_at_start) {\n+      set_crossing_object_start(card_to_update++, crossing_map_within_cluster);\n+\n+      \/\/ Now, we have to update all spanned cards that reside within the\n+      \/\/ following clusters.\n+      while (card_to_update < card_at_end)\n+        set_crossing_object_start(card_to_update++, CrossingObjectOverflow);\n+\n+      \/\/ Cases:\n+      \/\/\n+      \/\/ 1. The region for card_at_end is not spanned at all because the\n+      \/\/    end of the new object aligns with the start of the last\n+      \/\/    card region.  In this case, we do nothing with the\n+      \/\/    card_at_end entry of the object_starts array.\n+      \/\/\n+      \/\/ 2. The region for card_at_end is spanned partially.  In this\n+      \/\/    case, we do nothing with the card_at_end entry of the\n+      \/\/    object_starts array.\n+      \/\/\n+      \/\/ 3. Do not need to consider the case that the region for\n+      \/\/    card_at_end is spanned entirely.  If the last region\n+      \/\/    spanned by a newly registered object is spanned in its\n+      \/\/    entirety, then card_at_end will identify the card region\n+      \/\/    that follows the object rather than the last region spanned\n+      \/\/    by the object.\n+\n+      \/\/ Bottom line: no further work to be done in any of these cases.\n+    }\n+    \/\/ Otherwise, the last card region of this cluster is not\n+    \/\/ completely spanned by this new object.  Leave the object_starts\n+    \/\/ array entry alone.  Two cases:\n+    \/\/\n+    \/\/  a) This newly registered object represents a consolidation of\n+    \/\/     multiple smaller objects, not including the object that\n+    \/\/     follows the consolidation.\n+    \/\/  b) This newly registered object is created by splitting a\n+    \/\/     previously existing object.  In this case, the other\n+    \/\/     objects resulting from the split will be registered\n+    \/\/     separately before it is necessary to lookup any information\n+    \/\/     within the object_starts array.\n+    \/\/\n+\n+#endif  \/\/ SUPPORT_FOR_GET_CROSSING_OBJECT_START_NO_LONGER_REQUIRED\n+\n+#else   \/\/ IMPLEMENT_THIS_OPTIMIZATION_LATER\n+\n+    \/\/ Do nothing for now as we have a brute-force implementation\n+    \/\/ of findSpanningObject().\n+\n+#endif  \/\/ IMPLEMENT_THIS_OPTIMIZATION_LATER\n+  }\n+\n+  \/\/ What card number corresponds to old-gen heap addresss p.  (If p\n+  \/\/ does not refer to old-gen memory, the returned value is undefined.)\n+  uint32_t cardNoForAddr(HeapWord *p);\n+\n+  \/\/ The typical use case is going to look something like this:\n+  \/\/   for each heapregion that comprises olg-gen memory\n+  \/\/     for each card number that corresponds to this heap region\n+  \/\/       scan the objects contained therein if the card is dirty\n+  \/\/ To avoid excessive lookups in a sparse array, the API queries\n+  \/\/ the card number pertaining to a particular address and then uses the\n+  \/\/ card noumber for subsequent information lookups and stores.\n+\n+  \/\/ Returns true iff an object is known to start within the card memory\n+  \/\/ associated with addr p.\n+  \/\/ Returns true iff an object is known to start within the card memory\n+  \/\/ associated with addr p.\n+  bool has_object(uint32_t card_index);\n+\n+  \/\/ If has_object(card_index), this returns the word offset within this card\n+  \/\/ memory at which the first object begins.\n+  uint32_t get_first_start(uint32_t card_index);\n+\n+  \/\/ If has_object(card_index), this returns the word offset within this card\n+  \/\/ memory at which the last object begins.\n+  uint32_t get_last_start(uint32_t card_index);\n+\n+  \/\/ If !has_object(card_index), this returns the offset within the\n+  \/\/ enclosing cluster at which the object spanning the start of this\n+  \/\/ card memory begins, or returns 0x7fff if the spanning object\n+  \/\/ starts before the enclosing cluster.\n+  uint32_t get_crossing_object_start(uint32_t card_index);\n+\n+  \/\/ Card index is zero-based relative to first spanned card region.\n+  uint32_t card_index_for_addr(HeapWord *p);\n+  HeapWord *addr_for_card_index(uint32_t card_index);\n+  bool is_card_dirty(uint32_t card_index);\n+  void mark_card_as_dirty(uint32_t card_index);\n+  void mark_card_as_clean(uint32_t card_index);\n+  void mark_overreach_card_as_dirty(uint32_t card_index);\n+  bool is_card_dirty(HeapWord *p);\n+  void mark_card_as_dirty(HeapWord *p);\n+  void mark_card_as_clean(HeapWord *p);\n+  void mark_overreach_card_as_dirty(void *p);\n+  uint32_t cluster_count();\n+  void initialize_overreach(uint32_t first_cluster, uint32_t count);\n+  void merge_overreach(uint32_t first_cluster, uint32_t count);\n+};\n+\n+\/\/ ShenandoahScanRemembered is a concrete class representing the\n+\/\/ ability to scan the old-gen remembered set for references to\n+\/\/ objects residing in young-gen memory.\n+\/\/\n+\/\/ In an initial implementation, remembered set scanning happens\n+\/\/ during a HotSpot safepoint.  This greatly simplifies the\n+\/\/ implementation and improves efficiency of remembered set scanning,\n+\/\/ but this design choice increases pause times experienced at the\n+\/\/ start of concurrent marking and concurrent evacuation.  Pause times\n+\/\/ will be especially long if old-gen memory holds many pointers to\n+\/\/ young-gen memory.\n+\/\/\n+\/\/ Scanning normally begins with an invocation of numRegions and ends\n+\/\/ after all clusters of all regions have been scanned.\n+\/\/\n+\/\/ Throughout the scanning effort, the number of regions does not\n+\/\/ change.\n+\/\/\n+\/\/ Even though the regions that comprise old-gen memory are not\n+\/\/ necessarily contiguous, the abstraction represented by this class\n+\/\/ identifies each of the old-gen regions with an integer value\n+\/\/ in the range from 0 to (numRegions() - 1) inclusive.\n+\/\/\n+\n+template<typename RememberedSet>\n+class ShenandoahScanRemembered: public CHeapObj<mtGC> {\n+\n+private:\n+\n+  ShenandoahCardCluster<RememberedSet> *_scc;\n+\n+public:\n+  \/\/ How to instantiate this object?\n+  \/\/   ShenandoahDirectCardMarkRememberedSet *rs =\n+  \/\/       new ShenandoahDirectCardMarkRememberedSet();\n+  \/\/   scr = new\n+  \/\/     ShenandoahScanRememberd<ShenandoahDirectCardMarkRememberedSet>(rs);\n+  \/\/\n+  \/\/ or, when fully implemented:\n+  \/\/\n+  \/\/   ShenandoahBufferWithSATBRememberedSet *rs =\n+  \/\/       new ShenandoahBufferWithSATBRememberedSet();\n+  \/\/   scr = new\n+  \/\/     ShenandoahScanRememberd<ShenandoahBufferWithSATBRememberedSet>(rs);\n+\n+\n+  ShenandoahScanRemembered(RememberedSet *rs);\n+  ~ShenandoahScanRemembered();\n+\n+  \/\/ process_clusters() scans a portion of the remembered set during a JVM\n+  \/\/ safepoint as part of the root scanning activities that serve to\n+  \/\/ initiate concurrent scanning and concurrent evacuation.  Multiple\n+  \/\/ threads may scan different portions of the remembered set by\n+  \/\/ making parallel invocations of process_clusters() with each\n+  \/\/ invocation scanning different clusters of the remembered set.\n+  \/\/\n+  \/\/ An invocation of process_clusters() examines all of the\n+  \/\/ intergenerational references spanned by count clusters starting\n+  \/\/ with first_cluster.  The oops argument is assumed to represent a\n+  \/\/ thread-local OopClosure into which addresses of intergenerational\n+  \/\/ pointer values will be accumulated for the purposes of root scanning.\n+  \/\/\n+  \/\/ A side effect of executing process_clusters() is to update the card\n+  \/\/ table entries, marking dirty cards as clean if they no longer\n+  \/\/ hold references to young-gen memory.  (THIS IS NOT YET IMPLEMENTED.)\n+  \/\/\n+  \/\/ The implementation of process_clusters() is designed to efficiently\n+  \/\/ minimize work in the large majority of cases for which the\n+  \/\/ associated cluster has very few dirty card-table entries.\n+  \/\/\n+  \/\/ At initialization of concurrent marking, invoke process_clusters with\n+  \/\/ ClosureType equal to ShenandoahInitMarkRootsClosure.\n+  \/\/\n+  \/\/ At initialization of concurrent evacuation, invoke process_clusters with\n+  \/\/ ClosureType equal to ShenandoahEvacuateUpdateRootsClosure.\n+\n+  \/\/ This is big enough it probably shouldn't be in-lined.  On the other hand, there are only a few places this\n+  \/\/ code is called from, so it might as well be in-lined.  The \"real\" reason I'm inlining at the moment is because\n+  \/\/ the template expansions were making it difficult for the link\/loader to resolve references to the template-\n+  \/\/ parameterized implementations of this service.\n+  template <typename ClosureType>\n+  void process_clusters(uint worker_id, ShenandoahReferenceProcessor* rp, ShenandoahConcurrentMark* cm, uint32_t first_cluster, uint32_t count,\n+                        HeapWord *end_of_range, ClosureType *oops);\n+\n+  uint32_t cluster_for_addr(HeapWord *addr);\n+\n+  \/\/ To Do:\n+  \/\/  Create subclasses of ShenandoahInitMarkRootsClosure and\n+  \/\/  ShenandoahEvacuateUpdateRootsClosure and any other closures\n+  \/\/  that need to participate in remembered set scanning.  Within the\n+  \/\/  subclasses, add a (probably templated) instance variable that\n+  \/\/  refers to the associated ShenandoahCardCluster object.  Use this\n+  \/\/  ShenandoahCardCluster instance to \"enhance\" the do_oops\n+  \/\/  processing so that we can:\n+  \/\/\n+  \/\/   1. Avoid processing references that correspond to clean card\n+  \/\/      regions, and\n+  \/\/   2. Set card status to CLEAN when the associated card region no\n+  \/\/      longer holds inter-generatioanal references.\n+  \/\/\n+  \/\/  To enable efficient implementation of these behaviors, we\n+  \/\/  probably also want to add a few fields into the\n+  \/\/  ShenandoahCardCluster object that allow us to precompute and\n+  \/\/  remember the addresses at which card status is going to change\n+  \/\/  from dirty to clean and clean to dirty.  The do_oops\n+  \/\/  implementations will want to update this value each time they\n+  \/\/  cross one of these boundaries.\n+\n+};\n+\n+typedef ShenandoahScanRemembered<ShenandoahDirectCardMarkRememberedSet> RememberedScanner;\n+\n+#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHSCANREMEMBERED_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.hpp","additions":945,"deletions":0,"binary":false,"changes":945,"status":"added"},{"patch":"@@ -0,0 +1,401 @@\n+\/*\n+ * Copyright (c) Amazon.com, Inc. or its affiliates.  All rights reserved.\n+ *\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHSCANREMEMBEREDINLINE_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHSCANREMEMBEREDINLINE_HPP\n+\n+#include \"memory\/iterator.hpp\"\n+#include \"oops\/oop.hpp\"\n+#include \"oops\/objArrayOop.hpp\"\n+#include \"gc\/shenandoah\/shenandoahCardTable.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeapRegion.hpp\"\n+#include \"gc\/shenandoah\/shenandoahScanRemembered.hpp\"\n+\n+#include \"gc\/shenandoah\/shenandoahBufferWithSATBRememberedSet.inline.hpp\"\n+\n+inline uint32_t\n+ShenandoahDirectCardMarkRememberedSet::card_index_for_addr(HeapWord *p) {\n+  return (uint32_t) _card_table->index_for(p);\n+}\n+\n+inline HeapWord *\n+ShenandoahDirectCardMarkRememberedSet::addr_for_card_index(uint32_t card_index) {\n+  return _whole_heap_base + CardTable::card_size_in_words * card_index;\n+}\n+\n+inline bool\n+ShenandoahDirectCardMarkRememberedSet::is_card_dirty(uint32_t card_index) {\n+  uint8_t *bp = &_byte_map[card_index];\n+  return (bp[0] == CardTable::dirty_card_val());\n+}\n+\n+inline void\n+ShenandoahDirectCardMarkRememberedSet::mark_card_as_dirty(uint32_t card_index) {\n+  uint8_t *bp = &_byte_map[card_index];\n+  bp[0] = CardTable::dirty_card_val();\n+}\n+\n+inline void\n+ShenandoahDirectCardMarkRememberedSet::mark_card_as_clean(uint32_t card_index) {\n+  uint8_t *bp = &_byte_map[card_index];\n+  bp[0] = CardTable::clean_card_val();\n+}\n+\n+inline void\n+ShenandoahDirectCardMarkRememberedSet::mark_overreach_card_as_dirty(\n+    uint32_t card_index) {\n+  uint8_t *bp = &_overreach_map[card_index];\n+  bp[0] = CardTable::dirty_card_val();\n+}\n+\n+inline bool\n+ShenandoahDirectCardMarkRememberedSet::is_card_dirty(HeapWord *p) {\n+  uint8_t *bp = &_byte_map_base[uintptr_t(p) >> _card_shift];\n+  return (bp[0] == CardTable::dirty_card_val());\n+}\n+\n+inline void\n+ShenandoahDirectCardMarkRememberedSet::mark_card_as_dirty(HeapWord *p) {\n+  uint8_t *bp = &_byte_map_base[uintptr_t(p) >> _card_shift];\n+  bp[0] = CardTable::dirty_card_val();\n+}\n+\n+inline void\n+ShenandoahDirectCardMarkRememberedSet::mark_card_as_clean(HeapWord *p) {\n+  uint8_t *bp = &_byte_map_base[uintptr_t(p) >> _card_shift];\n+  bp[0] = CardTable::clean_card_val();\n+}\n+\n+inline void\n+ShenandoahDirectCardMarkRememberedSet::mark_overreach_card_as_dirty(void *p) {\n+  uint8_t *bp = &_overreach_map_base[uintptr_t(p) >> _card_shift];\n+  bp[0] = CardTable::dirty_card_val();\n+}\n+\n+inline uint32_t\n+ShenandoahDirectCardMarkRememberedSet::cluster_count() {\n+  return _cluster_count;\n+}\n+\n+\n+template<typename RememberedSet>\n+inline uint32_t\n+ShenandoahCardCluster<RememberedSet>::card_index_for_addr(HeapWord *p) {\n+  return _rs->card_index_for_addr(p);\n+}\n+\n+template<typename RememberedSet>\n+inline bool\n+ShenandoahCardCluster<RememberedSet>::has_object(uint32_t card_index) {\n+\n+  HeapWord *addr = _rs->addr_for_card_index(card_index);\n+\n+  ShenandoahHeap *heap = ShenandoahHeap::heap();\n+  ShenandoahHeapRegion *region = heap->heap_region_containing(addr);\n+\n+  \/\/ Apparently, region->block_start(addr) is not robust to inquiries beyond top() and it crashes.\n+  if (region->top() <= addr)\n+    return false;\n+\n+  HeapWord *obj = region->block_start(addr);\n+\n+  \/\/ addr is the first address of the card region.\n+  \/\/ obj is the object that spans addr (or starts at addr).\n+  assert(obj != NULL, \"Object cannot be null\");\n+  if (obj >= addr)\n+    return true;\n+  else {\n+    HeapWord *end_addr = addr + CardTable::card_size_in_words;\n+\n+    \/\/ end_addr needs to be adjusted downward if top address of the enclosing region is less than end_addr.  this is intended\n+    \/\/ to be slow and reliable alternative to the planned production quality replacement, so go ahead and spend some extra\n+    \/\/ cycles here in order to make this code reliable.\n+    if (region->top() < end_addr) {\n+      end_addr = region->top();\n+    }\n+\n+    obj += oop(obj)->size();\n+    if (obj < end_addr)\n+      return true;\n+    else\n+      return false;\n+  }\n+}\n+\n+template<typename RememberedSet>\n+inline uint32_t\n+ShenandoahCardCluster<RememberedSet>::get_first_start(uint32_t card_index) {\n+  HeapWord *addr = _rs->addr_for_card_index(card_index);\n+  ShenandoahHeap *heap = ShenandoahHeap::heap();\n+  ShenandoahHeapRegion *region = heap->heap_region_containing(addr);\n+\n+  HeapWord *obj = region->block_start(addr);\n+\n+  assert(obj != NULL, \"Object cannot be null.\");\n+  if (obj >= addr)\n+    return obj - addr;\n+  else {\n+    HeapWord *end_addr = addr + CardTable::card_size_in_words;\n+    obj += oop(obj)->size();\n+\n+    \/\/ If obj > end_addr, offset will reach beyond end of this card\n+    \/\/ region.  But clients should not invoke this service unless\n+    \/\/ they first confirm that this card has an object.\n+    assert(obj < end_addr, \"Object out of range\");\n+    return obj - addr;\n+  }\n+}\n+\n+template<typename RememberedSet>\n+inline uint32_t\n+ShenandoahCardCluster<RememberedSet>::get_last_start(uint32_t card_index) {\n+  HeapWord *addr = _rs->addr_for_card_index(card_index);\n+  HeapWord *end_addr = addr + CardTable::card_size_in_words;\n+  ShenandoahHeap *heap = ShenandoahHeap::heap();\n+  ShenandoahHeapRegion *region = heap->heap_region_containing(addr);\n+  HeapWord *obj = region->block_start(addr);\n+  assert(obj != NULL, \"Object cannot be null.\");\n+\n+  if (region->top() <= end_addr) {\n+    end_addr = region->top();\n+  }\n+\n+  HeapWord *end_obj = obj + oop(obj)->size();\n+  while (end_obj < end_addr) {\n+    obj = end_obj;\n+    end_obj = obj + oop(obj)->size();\n+  }\n+  assert(obj >= addr, \"Object out of range.\");\n+  return obj - addr;\n+}\n+\n+template<typename RememberedSet>\n+inline uint32_t\n+ShenandoahCardCluster<RememberedSet>::get_crossing_object_start(uint32_t card_index) {\n+  HeapWord *addr = _rs->addr_for_card_index(card_index);\n+  uint32_t cluster_no = card_index \/ ShenandoahCardCluster<RememberedSet>::CardsPerCluster;\n+  HeapWord *cluster_addr = _rs->addr_for_card_index(cluster_no * CardsPerCluster);\n+\n+  ShenandoahHeap *heap = ShenandoahHeap::heap();\n+  ShenandoahHeapRegion *region = heap->heap_region_containing(addr);\n+  HeapWord *obj = region->block_start(addr);\n+\n+  if (obj > cluster_addr)\n+    return obj - cluster_addr;\n+  else\n+    return 0x7fff;\n+}\n+\n+template<typename RememberedSet>\n+inline HeapWord *\n+ShenandoahCardCluster<RememberedSet>::addr_for_card_index(uint32_t card_index) {\n+  return _rs->addr_for_card_index(card_index);\n+}\n+\n+template<typename RememberedSet>\n+inline bool\n+ShenandoahCardCluster<RememberedSet>::is_card_dirty(uint32_t card_index) {\n+  return _rs->is_card_dirty(card_index);\n+}\n+\n+template<typename RememberedSet>\n+inline void\n+ShenandoahCardCluster<RememberedSet>::mark_card_as_dirty(uint32_t card_index) {\n+  return _rs->mark_card_as_dirty(card_index);\n+}\n+\n+template<typename RememberedSet>\n+inline void\n+ShenandoahCardCluster<RememberedSet>::mark_card_as_clean(uint32_t card_index) {\n+  return _rs->mark_card_as_clean(card_index);\n+}\n+\n+template<typename RememberedSet>\n+inline void\n+ShenandoahCardCluster<RememberedSet>::mark_overreach_card_as_dirty(uint32_t card_index) {\n+  return _rs->mark_overreach_card_as_dirty(card_index);\n+}\n+\n+template<typename RememberedSet>\n+inline bool\n+ShenandoahCardCluster<RememberedSet>::is_card_dirty(HeapWord *p) {\n+  return _rs->is_card_dirty(p);\n+}\n+\n+template<typename RememberedSet>\n+inline void\n+ShenandoahCardCluster<RememberedSet>::mark_card_as_dirty(HeapWord *p) {\n+  return _rs->mark_card_as_dirty(p);\n+}\n+\n+template<typename RememberedSet>\n+inline void\n+ShenandoahCardCluster<RememberedSet>::mark_card_as_clean(HeapWord *p) {\n+  return _rs->mark_card_as_clean(p);\n+}\n+\n+template<typename RememberedSet>\n+inline void\n+ShenandoahCardCluster<RememberedSet>::mark_overreach_card_as_dirty(void *p) {\n+  return _rs->mark_overreach_card_as_dirty(p);\n+}\n+\n+template<typename RememberedSet>\n+inline uint32_t\n+ShenandoahCardCluster<RememberedSet>::cluster_count() {\n+  return _rs->cluster_count();\n+}\n+\n+template<typename RememberedSet>\n+inline void\n+ShenandoahCardCluster<RememberedSet>::initialize_overreach(uint32_t first_cluster, uint32_t count) {\n+  return _rs->initialize_overreach(first_cluster, count);\n+}\n+\n+template<typename RememberedSet>\n+inline void\n+ShenandoahCardCluster<RememberedSet>::merge_overreach(uint32_t first_cluster, uint32_t count) {\n+  return _rs->merge_overreach(first_cluster, count);\n+}\n+\n+template<typename RememberedSet>\n+ShenandoahScanRemembered<RememberedSet>::ShenandoahScanRemembered(RememberedSet *rs) {\n+  _scc = new ShenandoahCardCluster<RememberedSet>(rs);\n+}\n+\n+template<typename RememberedSet>\n+ShenandoahScanRemembered<RememberedSet>::~ShenandoahScanRemembered() {\n+  delete _scc;\n+}\n+\n+template<typename RememberedSet>\n+template <typename ClosureType>\n+inline void\n+ShenandoahScanRemembered<RememberedSet>::process_clusters(uint worker_id, ShenandoahReferenceProcessor* rp, ShenandoahConcurrentMark* cm,\n+                                                          uint32_t first_cluster, uint32_t count, HeapWord *end_of_range,\n+                                                          ClosureType *oops) {\n+\n+  \/\/ Unlike traditional Shenandoah marking, the old-gen resident objects that are examined as part of the remembered set are not\n+  \/\/ themselves marked.  Each such object will be scanned only once.  Any young-gen objects referenced from the remembered set will\n+  \/\/ be marked and then subsequently scanned.\n+\n+  while (count-- > 0) {\n+    uint32_t card_index = first_cluster * ShenandoahCardCluster<RememberedSet>::CardsPerCluster;\n+    uint32_t end_card_index = card_index + ShenandoahCardCluster<RememberedSet>::CardsPerCluster;\n+\n+    first_cluster++;\n+    int next_card_index = 0;\n+    while (card_index < end_card_index) {\n+      int is_dirty = _scc->is_card_dirty(card_index);\n+      int has_object = _scc->has_object(card_index);\n+\n+      if (is_dirty) {\n+        if (has_object) {\n+          \/\/ Scan all objects that start within this card region.\n+          uint32_t start_offset = _scc->get_first_start(card_index);\n+          HeapWord *p = _scc->addr_for_card_index(card_index);\n+          HeapWord *endp = p + CardTable::card_size_in_words;\n+          if (endp > end_of_range) {\n+            endp = end_of_range;\n+            next_card_index = end_card_index;\n+          } else {\n+            \/\/ endp either points to start of next card region, or to the next object that needs to be scanned, which may\n+            \/\/ reside in some successor card region.\n+            next_card_index = _scc->card_index_for_addr(endp);\n+          }\n+\n+          p += start_offset;\n+          while (p < endp) {\n+            oop obj = oop(p);\n+            \/\/ Future TODO:\n+            \/\/ For improved efficiency, we might want to give special handling of obj->is_objArray().  In\n+            \/\/ particular, in that case, we might want to divide the effort for scanning of a very long object array\n+            \/\/ between multiple threads.\n+            if (obj->is_objArray()) {\n+              ShenandoahObjToScanQueue* q = cm->get_queue(worker_id);\n+              ShenandoahMarkRefsClosure<YOUNG> cl(q, rp);\n+              objArrayOop array = objArrayOop(obj);\n+              int len = array->length();\n+              array->oop_iterate_range(&cl, 0, len);\n+            } else {\n+              oops->do_oop(&obj);\n+            }\n+            p += obj->size();\n+          }\n+          card_index = next_card_index;\n+        } else {\n+          \/\/ otherwise, this card will have been scanned during scan of a previous cluster.\n+          card_index++;\n+        }\n+      } else if (_scc->has_object(card_index)) {\n+        \/\/ Scan the last object that starts within this card memory if it spans at least one dirty card within this cluster\n+        \/\/ or if it reaches into the next cluster.\n+        uint32_t start_offset = _scc->get_last_start(card_index);\n+        HeapWord *p = _scc->addr_for_card_index(card_index) + start_offset;\n+        oop obj = oop(p);\n+        HeapWord *nextp = p + obj->size();\n+        uint32_t last_card = _scc->card_index_for_addr(nextp);\n+\n+        bool reaches_next_cluster = (last_card > end_card_index);\n+        bool spans_dirty_within_this_cluster = false;\n+\n+        if (!reaches_next_cluster) {\n+          uint32_t span_card;\n+          for (span_card = card_index+1; span_card < end_card_index; span_card++)\n+            if (_scc->is_card_dirty(span_card)) {\n+              spans_dirty_within_this_cluster = true;\n+              break;\n+            }\n+        }\n+        if (reaches_next_cluster || spans_dirty_within_this_cluster) {\n+          if (obj->is_objArray()) {\n+            ShenandoahObjToScanQueue* q = cm->get_queue(worker_id); \/\/ kelvin to confirm: get_queue wants worker_id\n+            ShenandoahMarkRefsClosure<YOUNG> cl(q, rp);\n+            objArrayOop array = objArrayOop(obj);\n+            int len = array->length();\n+            array->oop_iterate_range(&cl, 0, len);\n+          } else {\n+            oops->do_oop(&obj);\n+          }\n+        }\n+        \/\/ Increment card_index to account for the spanning object, even if we didn't scan it.\n+        card_index = (last_card > card_index)? last_card: card_index + 1;\n+      } else {\n+        card_index++;\n+      }\n+    }\n+  }\n+}\n+\n+template<typename RememberedSet>\n+inline uint32_t\n+ShenandoahScanRemembered<RememberedSet>::cluster_for_addr(HeapWordImpl **addr) {\n+  uint32_t card_index = _scc->card_index_for_addr(addr);\n+  uint32_t result = card_index \/ ShenandoahCardCluster<RememberedSet>::CardsPerCluster;\n+  return result;\n+}\n+\n+#endif   \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHSCANREMEMBEREDINLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.inline.hpp","additions":401,"deletions":0,"binary":false,"changes":401,"status":"added"}]}