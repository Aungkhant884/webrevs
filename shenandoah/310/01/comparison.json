{"files":[{"patch":"@@ -1018,0 +1018,34 @@\n+  assert(get_top_before_promote() == tams, \"Cannot promote regions in place if top has advanced beyond TAMS\");\n+\n+  \/\/ Rebuild the remembered set information and mark the entire range as DIRTY.  We do NOT scan the content of this\n+  \/\/ range to determine which cards need to be DIRTY.  That would force us to scan the region twice, once now, and\n+  \/\/ once during the subsequent remembered set scan.  Instead, we blindly (conservatively) mark everything as DIRTY\n+  \/\/ now and then sort out the CLEAN pages during the next remembered set scan.\n+  \/\/\n+  \/\/ Rebuilding the remembered set consists of clearing all object registrations (reset_object_range()) here,\n+  \/\/ then registering every live object and every coalesced range of free objects in the loop that follows.\n+  heap->card_scan()->reset_object_range(bottom(), end());\n+  heap->card_scan()->mark_range_as_dirty(bottom(), get_top_before_promote() - bottom());\n+\n+  \/\/ TODO: use an existing coalesce-and-fill function rather than replicating the code here.\n+  HeapWord* obj_addr = bottom();\n+  while (obj_addr < tams) {\n+    oop obj = cast_to_oop(obj_addr);\n+    if (marking_context->is_marked(obj)) {\n+      assert(obj->klass() != NULL, \"klass should not be NULL\");\n+      \/\/ This thread is responsible for registering all objects in this region.  No need for lock.\n+      heap->card_scan()->register_object_without_lock(obj_addr);\n+      obj_addr += obj->size();\n+    } else {\n+      HeapWord* next_marked_obj = marking_context->get_next_marked_addr(obj_addr, tams);\n+      assert(next_marked_obj <= tams, \"next marked object cannot exceed tams\");\n+      size_t fill_size = next_marked_obj - obj_addr;\n+      assert(fill_size >= ShenandoahHeap::min_fill_size(), \"previously allocated objects known to be larger than min_size\");\n+      ShenandoahHeap::fill_with_object(obj_addr, fill_size);\n+      heap->card_scan()->register_object_without_lock(obj_addr);\n+      obj_addr = next_marked_obj;\n+    }\n+  }\n+  \/\/ We do not need to scan above TAMS because restored top equals tams\n+  assert(obj_addr == tams, \"Expect loop to terminate when obj_addr equals tams\");\n+\n@@ -1054,30 +1088,0 @@\n-\n-  assert(top() == tams, \"Cannot promote regions in place if top has advanced beyond TAMS\");\n-\n-  \/\/ Since this region may have served previously as OLD, it may hold obsolete object range info.\n-  heap->card_scan()->reset_object_range(bottom(), end());\n-  heap->card_scan()->mark_range_as_dirty(bottom(), top() - bottom());\n-\n-  \/\/ TODO: use an existing coalesce-and-fill function rather than\n-  \/\/ replicating the code here.\n-  HeapWord* obj_addr = bottom();\n-  while (obj_addr < tams) {\n-    oop obj = cast_to_oop(obj_addr);\n-    if (marking_context->is_marked(obj)) {\n-      assert(obj->klass() != NULL, \"klass should not be NULL\");\n-      \/\/ This thread is responsible for registering all objects in this region.  No need for lock.\n-      heap->card_scan()->register_object_without_lock(obj_addr);\n-      obj_addr += obj->size();\n-    } else {\n-      HeapWord* next_marked_obj = marking_context->get_next_marked_addr(obj_addr, tams);\n-      assert(next_marked_obj <= tams, \"next marked object cannot exceed tams\");\n-      size_t fill_size = next_marked_obj - obj_addr;\n-      assert(fill_size >= ShenandoahHeap::min_fill_size(), \"previously allocated objects known to be larger than min_size\");\n-      ShenandoahHeap::fill_with_object(obj_addr, fill_size);\n-      heap->card_scan()->register_object_without_lock(obj_addr);\n-      obj_addr = next_marked_obj;\n-    }\n-  }\n-\n-  \/\/ We do not need to scan above TAMS because top equals tams\n-  assert(obj_addr == tams, \"Expect loop to terminate when obj_addr equals tams\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.cpp","additions":34,"deletions":30,"binary":false,"changes":64,"status":"modified"}]}