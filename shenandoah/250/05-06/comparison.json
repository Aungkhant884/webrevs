{"files":[{"patch":"@@ -33,1 +33,1 @@\n-  virtual ShenandoahHeuristics* initialize_heuristics(ShenandoahGeneration* generation) const override;\n+  virtual ShenandoahHeuristics* initialize_heuristics(ShenandoahGeneration* generation) const;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/mode\/shenandoahGenerationalMode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -58,1 +58,1 @@\n-inline bool ShenandoahFreeSet::peek_is_mutator_free(size_t idx) const {\n+inline bool ShenandoahFreeSet::probe_mutator_set(size_t idx) const {\n@@ -62,1 +62,2 @@\n-inline bool ShenandoahFreeSet::is_mutator_free(size_t idx) const {\n+inline bool ShenandoahFreeSet::in_mutator_set(size_t idx) const {\n+  bool is_mutator_free = _mutator_free_bitmap.at(idx);\n@@ -65,3 +66,2 @@\n-  assert(!_mutator_free_bitmap.at(idx) || (alloc_capacity(ShenandoahHeap::heap()->get_region(idx)) > 0),\n-         \"mutator_free implies available memory in region \" SIZE_FORMAT, idx);\n-  return _mutator_free_bitmap.at(idx);\n+  assert(!is_mutator_free || has_alloc_capacity(idx), \"Mutator free set should contain useful regions\");\n+  return is_mutator_free;\n@@ -70,1 +70,1 @@\n-inline bool ShenandoahFreeSet::peek_is_collector_free(size_t idx) const {\n+inline bool ShenandoahFreeSet::probe_collector_set(size_t idx) const {\n@@ -74,1 +74,2 @@\n-inline bool ShenandoahFreeSet::is_collector_free(size_t idx) const {\n+inline bool ShenandoahFreeSet::in_collector_set(size_t idx) const {\n+  bool is_collector_free = _collector_free_bitmap.at(idx);\n@@ -77,3 +78,2 @@\n-  assert(!_collector_free_bitmap.at(idx) || (alloc_capacity(ShenandoahHeap::heap()->get_region(idx)) > 0),\n-         \"collector_free implies available memory in region \" SIZE_FORMAT, idx);\n-  return _collector_free_bitmap.at(idx);\n+  assert(!is_collector_free || has_alloc_capacity(idx), \"Collector free set should contain useful regions\");\n+  return is_collector_free;\n@@ -82,1 +82,1 @@\n-inline bool ShenandoahFreeSet::peek_is_old_collector_free(size_t idx) const {\n+inline bool ShenandoahFreeSet::probe_old_collector_set(size_t idx) const {\n@@ -86,1 +86,2 @@\n-inline bool ShenandoahFreeSet::is_old_collector_free(size_t idx) const {\n+inline bool ShenandoahFreeSet::in_old_collector_set(size_t idx) const {\n+  bool is_old_collector_free = _old_collector_free_bitmap.at(idx);\n@@ -89,3 +90,2 @@\n-  assert(!_old_collector_free_bitmap.at(idx) || (alloc_capacity(ShenandoahHeap::heap()->get_region(idx)) > 0),\n-         \"old_collector_free implies available memory in region \" SIZE_FORMAT, idx);\n-  return _old_collector_free_bitmap.at(idx);\n+  assert(!is_old_collector_free || has_alloc_capacity(idx), \"Old collector free set should contain useful regions\");\n+  return is_old_collector_free;\n@@ -94,4 +94,3 @@\n-inline void ShenandoahFreeSet::set_mutator_free(size_t idx) {\n-  assert(alloc_capacity(ShenandoahHeap::heap()->get_region(idx)) > 0, \"mutator_free implies available memory in region \"\n-         SIZE_FORMAT, idx);\n-  assert(!is_old_collector_free(idx) && !is_collector_free(idx), \"Freeset membership is mutually exclusive\");\n+inline void ShenandoahFreeSet::add_to_mutator_set(size_t idx) {\n+  assert(has_alloc_capacity(idx), \"Mutator free set should contain useful regions\");\n+  assert(!in_old_collector_set(idx) && !in_collector_set(idx), \"Freeset membership is mutually exclusive\");\n@@ -101,1 +100,1 @@\n-inline void ShenandoahFreeSet::clear_mutator_free(size_t idx) {\n+inline void ShenandoahFreeSet::remove_from_mutator_set(size_t idx) {\n@@ -105,4 +104,3 @@\n-inline void ShenandoahFreeSet::set_collector_free(size_t idx) {\n-  assert(alloc_capacity(ShenandoahHeap::heap()->get_region(idx)) > 0, \"mutator_free implies available memory in region \"\n-         SIZE_FORMAT, idx);\n-  assert(!is_mutator_free(idx) && !is_old_collector_free(idx), \"Freeset membership is mutually exclusive\");\n+inline void ShenandoahFreeSet::add_to_collector_set(size_t idx) {\n+  assert(has_alloc_capacity(idx), \"Collector free set should contain useful regions\");\n+  assert(!in_mutator_set(idx) && !in_old_collector_set(idx), \"Freeset membership is mutually exclusive\");\n@@ -112,1 +110,1 @@\n-inline void ShenandoahFreeSet::clear_collector_free(size_t idx) {\n+inline void ShenandoahFreeSet::remove_from_collector_set(size_t idx) {\n@@ -116,4 +114,3 @@\n-inline void ShenandoahFreeSet::set_old_collector_free(size_t idx) {\n-  assert(alloc_capacity(ShenandoahHeap::heap()->get_region(idx)) > 0, \"old_collector_free implies available memory in region \"\n-         SIZE_FORMAT, idx);\n-  assert(!is_mutator_free(idx) && !is_collector_free(idx), \"Freeset membership is mutually exclusive\");\n+inline void ShenandoahFreeSet::add_to_old_collector_set(size_t idx) {\n+  assert(has_alloc_capacity(idx), \"Old collector free set should contain useful regions\");\n+  assert(!in_mutator_set(idx) && !in_collector_set(idx), \"Freeset membership is mutually exclusive\");\n@@ -123,1 +120,1 @@\n-inline void ShenandoahFreeSet::clear_old_collector_free(size_t idx) {\n+inline void ShenandoahFreeSet::remove_from_old_collector_set(size_t idx) {\n@@ -130,0 +127,1 @@\n+  shenandoah_assert_heaplocked();\n@@ -133,1 +131,1 @@\n-    \/\/ This mode picks up stragglers following a full GC\n+    \/\/ This mode picks up stragglers left by a full GC\n@@ -135,1 +133,1 @@\n-      if (is_old_collector_free(c)) {\n+      if (in_old_collector_set(c)) {\n@@ -137,3 +135,1 @@\n-        assert(r->is_trash() || (r->affiliation() == ShenandoahAffiliation::FREE)\n-               || (r->affiliation() == ShenandoahAffiliation::OLD_GENERATION),\n-               \"is_old_collector_free region has bad affiliation\");\n+        assert(r->is_trash() || !r->is_affiliated() || r->is_old(), \"old_collector_set region has bad affiliation\");\n@@ -149,1 +145,1 @@\n-    \/\/ This mode picks up stragglers from a previous concurrent GC\n+    \/\/ This mode picks up stragglers left by a previous concurrent GC\n@@ -153,1 +149,1 @@\n-      if (is_old_collector_free(idx)) {\n+      if (in_old_collector_set(idx)) {\n@@ -155,3 +151,1 @@\n-        assert(r->is_trash() || (r->affiliation() == ShenandoahAffiliation::FREE)\n-               || (r->affiliation() == ShenandoahAffiliation::OLD_GENERATION),\n-               \"is_old_collector_free region has bad affiliation\");\n+        assert(r->is_trash() || !r->is_affiliated() || r->is_old(), \"old_collector_set region has bad affiliation\");\n@@ -171,0 +165,1 @@\n+  shenandoah_assert_heaplocked();\n@@ -174,1 +169,1 @@\n-    if (is_collector_free(idx)) {\n+    if (in_collector_set(idx)) {\n@@ -189,0 +184,2 @@\n+  shenandoah_assert_heaplocked();\n+\n@@ -235,1 +232,1 @@\n-        if (is_mutator_free(idx) && (allow_new_region || r->is_affiliated())) {\n+        if (in_mutator_set(idx) && (allow_new_region || r->is_affiliated())) {\n@@ -259,1 +256,1 @@\n-          if (is_collector_free(idx)) {\n+          if (in_collector_set(idx)) {\n@@ -279,1 +276,1 @@\n-          if (req.affiliation() == ShenandoahAffiliation::OLD_GENERATION) {\n+          if (req.is_old()) {\n@@ -312,1 +309,1 @@\n-          if (is_mutator_free(idx)) {\n+          if (in_mutator_set(idx)) {\n@@ -315,1 +312,1 @@\n-              if (req.affiliation() == ShenandoahAffiliation::OLD_GENERATION) {\n+              if (req.is_old()) {\n@@ -342,2 +339,1 @@\n-  assert (!has_no_alloc_capacity(r), \"Performance: should avoid full regions on this path: \" SIZE_FORMAT, r->index());\n-\n+  assert (has_alloc_capacity(r), \"Performance: should avoid full regions on this path: \" SIZE_FORMAT, r->index());\n@@ -538,3 +534,3 @@\n-      assert(peek_is_mutator_free(idx), \"Must be mutator free: \" SIZE_FORMAT, idx);\n-      clear_mutator_free(idx);\n-      assert(!is_collector_free(idx) && !is_old_collector_free(idx), \"Region cannot be in multiple free sets\");\n+      assert(probe_mutator_set(idx), \"Must be mutator free: \" SIZE_FORMAT, idx);\n+      remove_from_mutator_set(idx);\n+      assert(!in_collector_set(idx) && !in_old_collector_set(idx), \"Region cannot be in multiple free sets\");\n@@ -553,1 +549,2 @@\n-        waste = 0;              \/\/ if we don't make fill object, then the waste is not permanent\n+        \/\/ We'll retire the region until the freeset is rebuilt. Since retiement is not permanent, we do not account for waste.\n+        waste = 0;\n@@ -555,1 +552,1 @@\n-      if (peek_is_old_collector_free(idx)) {\n+      if (probe_old_collector_set(idx)) {\n@@ -561,2 +558,2 @@\n-        clear_old_collector_free(idx);\n-        assert(!is_collector_free(idx) && !is_mutator_free(idx), \"Region cannot be in multiple free sets\");\n+        remove_from_old_collector_set(idx);\n+        assert(!in_collector_set(idx) && !in_mutator_set(idx), \"Region cannot be in multiple free sets\");\n@@ -564,1 +561,2 @@\n-      } else if (peek_is_collector_free(idx)) {\n+      } else {\n+        assert(probe_collector_set(idx), \"Region that is not mutator free must be collector free or old collector free\");\n@@ -569,2 +567,2 @@\n-        clear_collector_free(idx);\n-        assert(!is_mutator_free(idx) && !is_old_collector_free(idx), \"Region cannot be in multiple free sets\");\n+        remove_from_collector_set(idx);\n+        assert(!in_mutator_set(idx) && !in_old_collector_set(idx), \"Region cannot be in multiple free sets\");\n@@ -583,1 +581,1 @@\n-    while (_mutator_leftmost < _max && !is_mutator_free(_mutator_leftmost)) {\n+    while (_mutator_leftmost < _max && !in_mutator_set(_mutator_leftmost)) {\n@@ -586,1 +584,1 @@\n-    while (_mutator_rightmost > 0 && !is_mutator_free(_mutator_rightmost)) {\n+    while (_mutator_rightmost > 0 && !in_mutator_set(_mutator_rightmost)) {\n@@ -599,1 +597,1 @@\n-    while (_old_collector_leftmost < _max && !is_old_collector_free(_old_collector_leftmost)) {\n+    while (_old_collector_leftmost < _max && !in_old_collector_set(_old_collector_leftmost)) {\n@@ -602,1 +600,1 @@\n-    while (_old_collector_rightmost > 0 && !is_old_collector_free(_old_collector_rightmost)) {\n+    while (_old_collector_rightmost > 0 && !in_old_collector_set(_old_collector_rightmost)) {\n@@ -615,1 +613,1 @@\n-    while (_collector_leftmost < _max && !is_collector_free(_collector_leftmost)) {\n+    while (_collector_leftmost < _max && !in_collector_set(_collector_leftmost)) {\n@@ -618,1 +616,1 @@\n-    while (_collector_rightmost > 0 && !is_collector_free(_collector_rightmost)) {\n+    while (_collector_rightmost > 0 && !in_collector_set(_collector_rightmost)) {\n@@ -650,1 +648,1 @@\n-      if (is_old_collector_free(index)) {\n+      if (in_old_collector_set(index)) {\n@@ -656,1 +654,1 @@\n-      if (is_old_collector_free(index)) {\n+      if (in_old_collector_set(index)) {\n@@ -661,0 +659,7 @@\n+    \/\/ We desire to first consume the sparsely distributed old-collector regions in order that the remaining old-collector\n+    \/\/ regions are densely packed.  Densely packing old-collector regions reduces the effort to search for a region that\n+    \/\/ has sufficient memory to satisfy a new allocation request.  Old-collector regions become sparsely distributed following\n+    \/\/ a Full GC, which tends to slide old-gen regions to the front of the heap rather than allowing them to remain\n+    \/\/ at the end of the heap where we intend for them to congregate.  In the future, we may modify Full GC so that it\n+    \/\/ slides old objects to the end of the heap and young objects to the start of the heap. If this is done, we can\n+    \/\/ always search right to left.\n@@ -665,2 +670,1 @@\n-bool ShenandoahFreeSet::expand_collector_bounds_maybe(size_t idx) {\n-  bool result = false;\n+void ShenandoahFreeSet::expand_collector_bounds_maybe(size_t idx) {\n@@ -669,1 +673,0 @@\n-    result = true;\n@@ -673,1 +676,0 @@\n-    result = true;\n@@ -675,1 +677,0 @@\n-  return result;\n@@ -678,2 +679,1 @@\n-bool ShenandoahFreeSet::expand_old_collector_bounds_maybe(size_t idx) {\n-  bool result = false;\n+void ShenandoahFreeSet::expand_old_collector_bounds_maybe(size_t idx) {\n@@ -682,1 +682,0 @@\n-    result = true;\n@@ -686,1 +685,0 @@\n-    result = true;\n@@ -688,1 +686,0 @@\n-  return result;\n@@ -693,1 +690,1 @@\n-  while (_mutator_leftmost < _max && !is_mutator_free(_mutator_leftmost)) {\n+  while (_mutator_leftmost < _max && !in_mutator_set(_mutator_leftmost)) {\n@@ -696,1 +693,1 @@\n-  while (_mutator_rightmost > 0 && !is_mutator_free(_mutator_rightmost)) {\n+  while (_mutator_rightmost > 0 && !in_mutator_set(_mutator_rightmost)) {\n@@ -700,1 +697,1 @@\n-  while (_collector_leftmost < _max && !is_collector_free(_collector_leftmost)) {\n+  while (_collector_leftmost < _max && !in_collector_set(_collector_leftmost)) {\n@@ -703,1 +700,1 @@\n-  while (_collector_rightmost > 0 && !is_collector_free(_collector_rightmost)) {\n+  while (_collector_rightmost > 0 && !in_collector_set(_collector_rightmost)) {\n@@ -707,1 +704,1 @@\n-  while (_old_collector_leftmost < _max && !is_old_collector_free(_old_collector_leftmost)) {\n+  while (_old_collector_leftmost < _max && !in_old_collector_set(_old_collector_leftmost)) {\n@@ -710,1 +707,1 @@\n-  while (_old_collector_rightmost > 0 && !is_old_collector_free(_old_collector_rightmost)) {\n+  while (_old_collector_rightmost > 0 && !in_old_collector_set(_old_collector_rightmost)) {\n@@ -750,1 +747,1 @@\n-    if (!is_mutator_free(end) || !can_allocate_from(_heap->get_region(end))) {\n+    if (!in_mutator_set(end) || !can_allocate_from(_heap->get_region(end))) {\n@@ -803,1 +800,1 @@\n-    clear_mutator_free(r->index());\n+    remove_from_mutator_set(r->index());\n@@ -844,0 +841,9 @@\n+bool ShenandoahFreeSet::has_alloc_capacity(ShenandoahHeapRegion *r) const {\n+  return alloc_capacity(r) > 0;\n+}\n+\n+bool ShenandoahFreeSet::has_alloc_capacity(size_t idx) const {\n+  ShenandoahHeapRegion* r = _heap->get_region(idx);\n+  return alloc_capacity(r) > 0;\n+}\n+\n@@ -875,3 +881,3 @@\n-  clear_mutator_free(idx);\n-  set_old_collector_free(idx);\n-  bool result = expand_old_collector_bounds_maybe(idx);\n+  remove_from_mutator_set(idx);\n+  add_to_old_collector_set(idx);\n+  expand_old_collector_bounds_maybe(idx);\n@@ -879,1 +885,3 @@\n-  _capacity -= alloc_capacity(r);\n+  size_t region_capacity = alloc_capacity(r);\n+  _capacity -= region_capacity;\n+  _old_capacity += region_capacity;\n@@ -894,3 +902,3 @@\n-  clear_mutator_free(idx);\n-  set_collector_free(idx);\n-  bool result = expand_collector_bounds_maybe(idx);\n+  remove_from_mutator_set(idx);\n+  add_to_collector_set(idx);\n+  expand_collector_bounds_maybe(idx);\n@@ -927,3 +935,6 @@\n-void ShenandoahFreeSet::rebuild() {\n-  shenandoah_assert_heaplocked();\n-  clear();\n+\/\/ This function places all is_old() regions that have allocation capacity into the old_collector set.  It places\n+\/\/ all other regions (not is_old()) that have allocation capacity into the mutator_set.  Subsequently, we will\n+\/\/ move some of the mutator regions into the collector set or old_collector set with the intent of packing\n+\/\/ old_collector memory into the highest (rightmost) addresses of the heap and the collector memory into the\n+\/\/ next highest addresses of the heap, with mutator memory consuming the lowest addresses of the heap.\n+void ShenandoahFreeSet::find_regions_with_alloc_capacity() {\n@@ -931,1 +942,0 @@\n-  log_debug(gc, free)(\"Rebuilding FreeSet\");\n@@ -934,7 +944,0 @@\n-\n-    \/\/ We move all young available regions into mutator_free set and then we take back the regions we need for our\n-    \/\/ reserve.  This allows us to \"compact\" the collector_free (survivor) regions at the high end of the heap.\n-    clear_mutator_free(idx);\n-    clear_collector_free(idx);\n-    clear_old_collector_free(idx);\n-\n@@ -949,3 +952,7 @@\n-        assert(!is_old_collector_free(idx), \"We are about to add it, it shouldn't be there already\");\n-        set_old_collector_free(idx);\n-        log_debug(gc)(\"  Setting Region \" SIZE_FORMAT \" _old_collector_free_bitmap bit to true\", idx);\n+        assert(!in_old_collector_set(idx), \"We are about to add it, it shouldn't be there already\");\n+        add_to_old_collector_set(idx);\n+        log_debug(gc, free)(\n+          \"  Adding Region \" SIZE_FORMAT  \" (Free: \" SIZE_FORMAT \"%s, Used: \" SIZE_FORMAT \"%s) to old collector set\",\n+          idx, byte_size_in_proper_unit(region->free()), proper_unit_for_byte_size(region->free()),\n+          byte_size_in_proper_unit(region->used()), proper_unit_for_byte_size(region->used()));\n+\n@@ -954,4 +961,2 @@\n-\n-        assert(_used <= _capacity, \"must not use more than we have\");\n-        assert(!is_mutator_free(idx), \"We are about to add it, it shouldn't be there already\");\n-        set_mutator_free(idx);\n+        assert(!in_mutator_set(idx), \"We are about to add it, it shouldn't be there already\");\n+        add_to_mutator_set(idx);\n@@ -959,1 +964,1 @@\n-          \"  Adding Region \" SIZE_FORMAT \" (Free: \" SIZE_FORMAT \"%s, Used: \" SIZE_FORMAT \"%s) to mutator free set\",\n+          \"  Adding Region \" SIZE_FORMAT \" (Free: \" SIZE_FORMAT \"%s, Used: \" SIZE_FORMAT \"%s) to mutator set\",\n@@ -965,0 +970,1 @@\n+}\n@@ -966,1 +972,13 @@\n-  \/\/ Evac reserve: reserve trailing space for evacuations\n+void ShenandoahFreeSet::rebuild() {\n+  shenandoah_assert_heaplocked();\n+  \/\/ This resets all state information, removing all regions from all sets.\n+  clear();\n+\n+  log_debug(gc, free)(\"Rebuilding FreeSet\");\n+\n+  \/\/ This places regions that have alloc_capacity into the old_collector set if they identify as is_old() or the\n+  \/\/ mutator set otherwise.\n+  find_regions_with_alloc_capacity();\n+\n+  \/\/ Evac reserve: reserve trailing space for evacuations, with regions reserved for old evacuations placed to the right\n+  \/\/ of regions reserved of young evacuations.\n@@ -972,2 +990,1 @@\n-\n-    \/\/ Note that all allocations performed from old-gen are performed by GC, generally using PLABs for both\n+    \/\/ All allocations taken from the old collector set are performed by GC, generally using PLABs for both\n@@ -975,3 +992,2 @@\n-    \/\/ which is reserved for promotion is enforced using thread-local variables that prescribe intentons within\n-    \/\/ each PLAB.  We do not reserve any of old-gen memory in order to facilitate the loaning of old-gen memory\n-    \/\/ to young-gen purposes.\n+    \/\/ which is reserved for promotion is enforced using thread-local variables that prescribe intentons for\n+    \/\/ each PLAB's available memory.\n@@ -979,1 +995,1 @@\n-      \/\/ We are rebuilding at the end of final mark, having established evacuation budgets for this GC pass.\n+      \/\/ We are rebuilding at the end of final mark, having already established evacuation budgets for this GC pass.\n@@ -995,0 +1011,5 @@\n+\/\/ Having placed all regions that have allocation capacity into the mutator set if they identify as is_young()\n+\/\/ or into the old collector set if they identify as is_old(), move some of these regions from the mutator set\n+\/\/ into the collector set or old collector set in order to assure that the memory available for allocations within\n+\/\/ the collector set is at least to_reserve, and the memory available for allocations within the old collector set\n+\/\/ is at least to_reserve_old.\n@@ -1002,3 +1023,3 @@\n-      if ((_old_capacity < to_reserve_old) && (r->is_trash() || (r->affiliation() == ShenandoahAffiliation::FREE))) {\n-        clear_mutator_free(idx);\n-        set_old_collector_free(idx);\n+      if ((_old_capacity < to_reserve_old) && (r->is_trash() || !r->is_affiliated())) {\n+        remove_from_mutator_set(idx);\n+        add_to_old_collector_set(idx);\n@@ -1014,2 +1035,2 @@\n-        clear_mutator_free(idx);\n-        set_collector_free(idx);\n+        remove_from_mutator_set(idx);\n+        add_to_collector_set(idx);\n@@ -1044,1 +1065,1 @@\n-    log_info(gc, ergo)(\"FreeSet map legend (see source for unexpected codes: *, $, !, #):\\n\"\n+    log_info(gc, free)(\"FreeSet map legend (see source for unexpected codes: *, $, !, #):\\n\"\n@@ -1047,1 +1068,1 @@\n-    log_info(gc, ergo)(\" mutator free range [\" SIZE_FORMAT \"..\" SIZE_FORMAT \"], \"\n+    log_info(gc, free)(\" mutator free range [\" SIZE_FORMAT \"..\" SIZE_FORMAT \"], \"\n@@ -1057,1 +1078,1 @@\n-        log_info(gc, ergo)(\" %6u: %s\", i-64, buffer);\n+        log_info(gc, free)(\" %6u: %s\", i-64, buffer);\n@@ -1059,1 +1080,1 @@\n-      if (is_mutator_free(i) && is_collector_free(i) && is_old_collector_free(i)) {\n+      if (in_mutator_set(i) && in_collector_set(i) && in_old_collector_set(i)) {\n@@ -1061,1 +1082,1 @@\n-      } else if (is_mutator_free(i) && is_collector_free(i)) {\n+      } else if (in_mutator_set(i) && in_collector_set(i)) {\n@@ -1064,1 +1085,1 @@\n-      } else if (is_mutator_free(i) && is_old_collector_free(i)) {\n+      } else if (in_mutator_set(i) && in_old_collector_set(i)) {\n@@ -1067,1 +1088,1 @@\n-      } else if (is_collector_free(i) && is_old_collector_free(i)) {\n+      } else if (in_collector_set(i) && in_old_collector_set(i)) {\n@@ -1069,1 +1090,1 @@\n-      } else if (is_mutator_free(i)) {\n+      } else if (in_mutator_set(i)) {\n@@ -1072,1 +1093,1 @@\n-      } else if (is_collector_free(i)) {\n+      } else if (in_collector_set(i)) {\n@@ -1075,1 +1096,1 @@\n-      } else if (is_old_collector_free(i)) {\n+      } else if (in_old_collector_set(i)) {\n@@ -1077,2 +1098,1 @@\n-      }\n-      else if (r->is_humongous()) {\n+      } else if (r->is_humongous()) {\n@@ -1103,1 +1123,1 @@\n-    log_info(gc, ergo)(\" %6u: %s\", (uint) (_heap->num_regions() - remnant), buffer);\n+    log_info(gc, free)(\" %6u: %s\", (uint) (_heap->num_regions() - remnant), buffer);\n@@ -1106,1 +1126,1 @@\n-    log_info(gc, ergo)(\"Retired young: \" SIZE_FORMAT \"%s (including humongous: \" SIZE_FORMAT \"%s), old: \" SIZE_FORMAT\n+    log_info(gc, free)(\"Retired young: \" SIZE_FORMAT \"%s (including humongous: \" SIZE_FORMAT \"%s), old: \" SIZE_FORMAT\n@@ -1131,1 +1151,1 @@\n-        if (is_mutator_free(idx)) {\n+        if (in_mutator_set(idx)) {\n@@ -1194,1 +1214,1 @@\n-        if (is_collector_free(idx)) {\n+        if (in_collector_set(idx)) {\n@@ -1214,1 +1234,1 @@\n-        if (is_old_collector_free(idx)) {\n+        if (in_old_collector_set(idx)) {\n@@ -1261,1 +1281,1 @@\n-    if (index < _max && is_mutator_free(index)) {\n+    if (index < _max && in_mutator_set(index)) {\n@@ -1276,1 +1296,1 @@\n-    if (is_mutator_free(index)) {\n+    if (in_mutator_set(index)) {\n@@ -1282,1 +1302,1 @@\n-    if (is_collector_free(index)) {\n+    if (in_collector_set(index)) {\n@@ -1315,1 +1335,1 @@\n-    if (is_mutator_free(index)) {\n+    if (in_mutator_set(index)) {\n@@ -1353,1 +1373,1 @@\n-    if (is_mutator_free(index)) {\n+    if (in_mutator_set(index)) {\n@@ -1385,2 +1405,2 @@\n-  assert (_mutator_leftmost == _max || is_mutator_free(_mutator_leftmost),  \"leftmost region should be free: \" SIZE_FORMAT,  _mutator_leftmost);\n-  assert (_mutator_rightmost == 0   || is_mutator_free(_mutator_rightmost), \"rightmost region should be free: \" SIZE_FORMAT, _mutator_rightmost);\n+  assert (_mutator_leftmost == _max || in_mutator_set(_mutator_leftmost),  \"leftmost region should be free: \" SIZE_FORMAT,  _mutator_leftmost);\n+  assert (_mutator_rightmost == 0   || in_mutator_set(_mutator_rightmost), \"rightmost region should be free: \" SIZE_FORMAT, _mutator_rightmost);\n@@ -1396,2 +1416,2 @@\n-  assert (_collector_leftmost == _max || is_collector_free(_collector_leftmost),  \"leftmost region should be free: \" SIZE_FORMAT,  _collector_leftmost);\n-  assert (_collector_rightmost == 0   || is_collector_free(_collector_rightmost), \"rightmost region should be free: \" SIZE_FORMAT, _collector_rightmost);\n+  assert (_collector_leftmost == _max || in_collector_set(_collector_leftmost),  \"leftmost region should be free: \" SIZE_FORMAT,  _collector_leftmost);\n+  assert (_collector_rightmost == 0   || in_collector_set(_collector_rightmost), \"rightmost region should be free: \" SIZE_FORMAT, _collector_rightmost);\n@@ -1407,2 +1427,2 @@\n-  assert (_old_collector_leftmost == _max || is_old_collector_free(_old_collector_leftmost),  \"leftmost region should be free: \" SIZE_FORMAT,  _old_collector_leftmost);\n-  assert (_old_collector_rightmost == 0   || is_old_collector_free(_old_collector_rightmost), \"rightmost region should be free: \" SIZE_FORMAT, _old_collector_rightmost);\n+  assert (_old_collector_leftmost == _max || in_old_collector_set(_old_collector_leftmost),  \"leftmost region should be free: \" SIZE_FORMAT,  _old_collector_leftmost);\n+  assert (_old_collector_rightmost == 0   || in_old_collector_set(_old_collector_rightmost), \"rightmost region should be free: \" SIZE_FORMAT, _old_collector_rightmost);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":170,"deletions":150,"binary":false,"changes":320,"status":"modified"},{"patch":"@@ -36,0 +36,7 @@\n+\n+  \/\/ The _collector_free regions hold survivor objects within young-generation and within traditional single-generation\n+  \/\/ collections.  In general, the _collector_free regions are at the high end of memory and mutator-free regions are at\n+  \/\/ the low-end of memory.  In generational mode, the young survivor regions are typically recycled after the region reaches\n+  \/\/ tenure age.  In the case that a young survivor region reaches tenure age and has sufficiently low amount of garbage,\n+  \/\/ the region will be promoted in place.  This means the region will simply be relabled as an old-generation region and\n+  \/\/ will not be evacuated until an old-generation collection chooses to do so.\n@@ -37,0 +44,1 @@\n+\n@@ -39,2 +47,1 @@\n-  \/\/ even less frequently than the young survivor regions.  In generational mode, the young survivor regions are typically\n-  \/\/ recycled after tenure age GC passes.\n+  \/\/ even less frequently than the young survivor regions.\n@@ -44,2 +51,3 @@\n-  \/\/ Left-most and right-most region indexes. There are no free regions outside\n-  \/\/ of [left-most; right-most] index intervals\n+  \/\/ Left-most and right-most region indexes. There are no free regions outside of [left-most; right-most] index intervals.\n+  \/\/ The sets are not necessarily contiguous.  It is common for collector_is_free regions to reside within the mutator_is_free\n+  \/\/ range, and for _old_collector_is_free regions to reside within the collector_is_free range.\n@@ -50,0 +58,2 @@\n+  \/\/ _capacity represents the amount of memory that can be allocated within the mutator set at the time of the\n+  \/\/ most recent rebuild, as adjusted for the flipping of regions from mutator set to collector set or old collector set.\n@@ -51,2 +61,0 @@\n-  size_t _old_capacity;\n-  size_t _used;\n@@ -54,4 +62,4 @@\n-  \/\/ When is_old_collector_free regions sparsely populate the lower address ranges of the heap, we search from left to\n-  \/\/ right in order to consume (and remove from the is_old_collector_free range) these sparsely distributed regions.\n-  \/\/ This allows us to more quickly condense the range of addresses that represent old_collector_free regions.\n-  bool _old_collector_search_left_to_right = true;\n+  \/\/ _used represents the amount of memory allocated within the mutator set since the time of the most recent rebuild.\n+  \/\/ _used feeds into certain ShenandoanPacing decisions.  There is no need to track of the memory consumed from\n+  \/\/ within the collector and old_collector sets.\n+  size_t _used;\n@@ -59,0 +67,3 @@\n+  \/\/ _old_capacity represents the amount of memory that can be allocated within the old collector set at the time\n+  \/\/ of the most recent rebuild, as adjusted for the flipping of regions from mutator set to old collector set.\n+  size_t _old_capacity;\n@@ -60,1 +71,3 @@\n-  void assert_bounds() const NOT_DEBUG_RETURN;\n+  \/\/ There is no need to compute young collector capacity.  And there is not need to consult _old_capacity once we\n+  \/\/ have successfully reserved the evacuation (old_collector and collector sets) requested at rebuild time.\n+  \/\/ TODO: A cleaner abstraction might encapsulate capacity (and used) information within a refactored set abstraction.\n@@ -62,3 +75,0 @@\n-  inline bool is_mutator_free(size_t idx) const;\n-  inline bool is_collector_free(size_t idx) const;\n-  inline bool is_old_collector_free(size_t idx) const;\n@@ -66,4 +76,4 @@\n-  \/\/ Routines that do not assert non-empty free, for use in assertions and during state transitions\n-  inline bool peek_is_mutator_free(size_t idx) const;\n-  inline bool peek_is_collector_free(size_t idx) const;\n-  inline bool peek_is_old_collector_free(size_t idx) const;\n+  \/\/ When old_collector_set regions sparsely populate the lower address ranges of the heap, we search from left to\n+  \/\/ right in order to consume (and remove from the old_collector set range) these sparsely distributed regions.\n+  \/\/ This allows us to more quickly condense the range of addresses that represent old_collector_free regions.\n+  bool _old_collector_search_left_to_right = true;\n@@ -71,3 +81,13 @@\n-  inline void set_mutator_free(size_t idx);\n-  inline void set_collector_free(size_t idx);\n-  inline void set_old_collector_free(size_t idx);\n+  \/\/ Assure leftmost and rightmost bounds are valid for the mutator_is_free, collector_is_free, and old_collector_is_free sets.\n+  \/\/ valid bounds honor all of the following (where max is the number of heap regions):\n+  \/\/   if the set is empty, leftmost equals max and rightmost equals 0\n+  \/\/   Otherwise (the set is not empty):\n+  \/\/     0 <= leftmost < max and 0 <= rightmost < max\n+  \/\/     the region at leftmost is in the set\n+  \/\/     the region at rightmost is in the set\n+  \/\/     rightmost >= leftmost\n+  \/\/     for every idx that is in the set {\n+  \/\/       idx >= leftmost &&\n+  \/\/       idx <= rightmost\n+  \/\/     }\n+  void assert_bounds() const NOT_DEBUG_RETURN;\n@@ -75,3 +95,28 @@\n-  inline void clear_mutator_free(size_t idx);\n-  inline void clear_collector_free(size_t idx);\n-  inline void clear_old_collector_free(size_t idx);\n+  \/\/ Every region is in exactly one of four sets: mutator_free, collector_free, old_collector_free, not_free.\n+  \/\/ Insofar as the free-set abstraction is concerned, we are only interested in regions that are free so we provide no\n+  \/\/ mechanism to directly inquire as to whether a region is not_free.  not_free membership is implied by not member of\n+  \/\/ mutator_free, collector_free and old_collector_free sets.\n+  \/\/\n+  \/\/ in_xx_set() implies that the region has allocation capacity (i.e. is not yet fully allocated).  Assertions enforce\n+  \/\/ that in_xx_set(idx) implies has_alloc_capacity(idx).\n+  \/\/\n+  \/\/ TODO: a future implementation may replace the three bitmaps with a single array of enums to simplify the representation\n+  \/\/ of membership within these four mutually exclusive sets.\n+  inline bool in_mutator_set(size_t idx) const;\n+  inline bool in_collector_set(size_t idx) const;\n+  inline bool in_old_collector_set(size_t idx) const;\n+\n+  \/\/ The following three probe routines mimic the behavior is in_mutator_set(), in_collector_set() and in_old_collector_set()\n+  \/\/ but do not assert that the regions have allocation capacity.  These probe routines are used in assertions enforced\n+  \/\/ during certain state transitions.\n+  inline bool probe_mutator_set(size_t idx) const;\n+  inline bool probe_collector_set(size_t idx) const;\n+  inline bool probe_old_collector_set(size_t idx) const;\n+\n+  inline void add_to_mutator_set(size_t idx);\n+  inline void add_to_collector_set(size_t idx);\n+  inline void add_to_old_collector_set(size_t idx);\n+\n+  inline void remove_from_mutator_set(size_t idx);\n+  inline void remove_from_collector_set(size_t idx);\n+  inline void remove_from_old_collector_set(size_t idx);\n@@ -80,0 +125,3 @@\n+\n+  \/\/ Satisfy young-generation or single-generation collector allocation request req by finding memory that matches\n+  \/\/ affiliation, which either equals req.affiliation or FREE.  We know req.is_young().\n@@ -81,0 +129,3 @@\n+\n+  \/\/ Satisfy allocation request req by finding memory that matches affiliation, which either equals req.affiliation\n+  \/\/ or FREE. We know req.is_old().\n@@ -95,0 +146,1 @@\n+  \/\/ Compute left-most and right-most indexes for the mutator_is_free, collector_is_free, and old_collector_is_free sets.\n@@ -96,0 +148,3 @@\n+\n+  \/\/ Adjust left-most and right-most indexes for the mutator_is_free, collector_is_free, and old_collector_is_free sets\n+  \/\/  following minor changes to at least one set membership.\n@@ -97,0 +152,2 @@\n+\n+  \/\/ Adjust left-most and right-most indexes for the mutator_is_free set after removing region idx from this set.\n@@ -98,0 +155,2 @@\n+\n+  \/\/ Adjust left-most and right-most indexes for the collector_is_free set after removing region idx from this set.\n@@ -99,0 +158,2 @@\n+\n+  \/\/ Adjust left-most and right-most indexes for the old_collector_is_free set after removing region idx from this set.\n@@ -100,3 +161,9 @@\n-  bool touches_bounds(size_t num) const;\n-  bool expand_collector_bounds_maybe(size_t idx);\n-  bool expand_old_collector_bounds_maybe(size_t idx);\n+\n+  \/\/ Return true iff region idx was the left-most or right-most index for one of the three free sets.\n+  bool touches_bounds(size_t idx) const;\n+\n+  \/\/ Adjust left-most and right-most indexes for the collector_is_free set after adding region idx to this set.\n+  void expand_collector_bounds_maybe(size_t idx);\n+\n+  \/\/ Adjust left-most and right-most indexes for the old_collector_is_free set after adding region idx to this set.\n+  void expand_old_collector_bounds_maybe(size_t idx);\n@@ -111,0 +178,2 @@\n+  bool has_alloc_capacity(size_t idx) const;\n+  bool has_alloc_capacity(ShenandoahHeapRegion *r) const;\n@@ -116,1 +185,1 @@\n-  \/\/ Number of regions dedicated to GC allocations (for evacuation) that are currently free\n+  \/\/ Number of regions dedicated to GC allocations (for evacuation) that are at least partially free\n@@ -119,1 +188,1 @@\n-  \/\/ Number of regions dedicated to Old GC allocations (for evacuation or promotion) that are currently free\n+  \/\/ Number of regions dedicated to Old GC allocations (for evacuation or promotion) that are at least partially free\n@@ -122,1 +191,1 @@\n-  \/\/ Number of regions dedicated to mutator allocations that are currently free\n+  \/\/ Number of regions dedicated to mutator allocations that are at least partially free\n@@ -147,0 +216,1 @@\n+  void find_regions_with_alloc_capacity();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.hpp","additions":100,"deletions":30,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -554,0 +554,2 @@\n+  _upgraded_to_full(false),\n+  _has_evacuation_reserve_quantities(false),\n@@ -2243,1 +2245,1 @@\n-  set_gc_state_mask(VALID_EVACUATION_RESERVE_QUANTITIES, is_valid);\n+  _has_evacuation_reserve_quantities = is_valid;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -321,3 +321,0 @@\n-\n-    \/\/ The evacuation reserves for old-gen and young-gen are available\n-    VALID_EVACUATION_RESERVE_QUANTITIES_BITPOS = 6\n@@ -334,1 +331,0 @@\n-    VALID_EVACUATION_RESERVE_QUANTITIES = 1 << VALID_EVACUATION_RESERVE_QUANTITIES_BITPOS\n@@ -397,2 +393,0 @@\n-\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -670,1 +670,1 @@\n-  return _gc_state.is_set(VALID_EVACUATION_RESERVE_QUANTITIES);\n+  return _has_evacuation_reserve_quantities;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}