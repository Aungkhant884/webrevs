{"files":[{"patch":"@@ -34,1 +34,7 @@\n-ShenandoahDirectCardMarkRememberedSet::ShenandoahDirectCardMarkRememberedSet(ShenandoahCardTable* card_table, size_t total_card_count) {\n+ShenandoahDirectCardMarkRememberedSet::ShenandoahDirectCardMarkRememberedSet(ShenandoahCardTable* card_table, size_t total_card_count) :\n+  LogCardValsPerIntPtr(log2i_exact(sizeof(intptr_t)) - log2i_exact(sizeof(CardValue))),\n+  LogCardSizeInWords(log2i_exact(CardTable::card_size_in_words())) {\n+\n+  \/\/ Paranoid assert for LogCardsPerIntPtr calculation above\n+  assert(sizeof(intptr_t) > sizeof(CardValue), \"LogsCardValsPerIntPtr would underflow\");\n+\n@@ -50,0 +56,48 @@\n+\/\/ Merge any dirty values from write table into the read table, while leaving\n+\/\/ the write table unchanged.\n+void ShenandoahDirectCardMarkRememberedSet::merge_write_table(HeapWord* start, size_t word_count) {\n+  size_t start_index = card_index_for_addr(start);\n+#ifdef ASSERT\n+  \/\/ avoid querying card_index_for_addr() for an address past end of heap\n+  size_t end_index = card_index_for_addr(start + word_count - 1) + 1;\n+#endif\n+  assert(start_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+  assert(end_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+\n+  \/\/ We'll access in groups of intptr_t worth of card entries\n+  intptr_t* const read_table  = (intptr_t*) &(_card_table->read_byte_map())[start_index];\n+  intptr_t* const write_table = (intptr_t*) &(_card_table->write_byte_map())[start_index];\n+\n+  \/\/ Avoid division, use shift instead\n+  assert(word_count % ((size_t)1 << (LogCardSizeInWords + LogCardValsPerIntPtr)) == 0, \"Expected a multiple of CardSizeInWords*CardValsPerIntPtr\");\n+  size_t const num = word_count >> (LogCardSizeInWords + LogCardValsPerIntPtr);\n+\n+  for (size_t i = 0; i < num; i++) {\n+    read_table[i] &= write_table[i];\n+  }\n+}\n+\n+\/\/ Destructively copy the write table to the read table, and clean the write table.\n+void ShenandoahDirectCardMarkRememberedSet::reset_remset(HeapWord* start, size_t word_count) {\n+  size_t start_index = card_index_for_addr(start);\n+#ifdef ASSERT\n+  \/\/ avoid querying card_index_for_addr() for an address past end of heap\n+  size_t end_index = card_index_for_addr(start + word_count - 1) + 1;\n+#endif\n+  assert(start_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+  assert(end_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+\n+  \/\/ We'll access in groups of intptr_t worth of card entries\n+  intptr_t* const read_table  = (intptr_t*) &(_card_table->read_byte_map())[start_index];\n+  intptr_t* const write_table = (intptr_t*) &(_card_table->write_byte_map())[start_index];\n+\n+  \/\/ Avoid division, use shift instead\n+  assert(word_count % ((size_t)1 << (LogCardSizeInWords + LogCardValsPerIntPtr)) == 0, \"Expected a multiple of CardSizeInWords*CardValsPerIntPtr\");\n+  size_t const num = word_count >> (LogCardSizeInWords + LogCardValsPerIntPtr);\n+\n+  for (size_t i = 0; i < num; i++) {\n+    read_table[i]  = write_table[i];\n+    write_table[i] = CardTable::clean_card_row_val();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.cpp","additions":55,"deletions":1,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -207,0 +207,3 @@\n+  const size_t LogCardValsPerIntPtr;    \/\/ the number of card values (entries) in an intptr_t\n+  const size_t LogCardSizeInWords;      \/\/ the size of a card in heap word units\n+\n@@ -242,0 +245,2 @@\n+  \/\/ Instead of swap_remset, the current implementation of concurrent remembered set scanning does reset_remset\n+  \/\/ in parallel threads, each invocation processing one entire HeapRegion at a time.\n@@ -244,12 +249,3 @@\n-  void merge_write_table(HeapWord* start, size_t word_count) {\n-    size_t card_index = card_index_for_addr(start);\n-    size_t num_cards = word_count \/ CardTable::card_size_in_words();\n-    size_t iterations = num_cards \/ (sizeof (intptr_t) \/ sizeof (CardValue));\n-    intptr_t* read_table_ptr = (intptr_t*) &(_card_table->read_byte_map())[card_index];\n-    intptr_t* write_table_ptr = (intptr_t*) &(_card_table->write_byte_map())[card_index];\n-    for (size_t i = 0; i < iterations; i++) {\n-      intptr_t card_value = *write_table_ptr;\n-      *read_table_ptr++ &= card_value;\n-      write_table_ptr++;\n-    }\n-  }\n+  \/\/ Merge any dirty values from write table into the read table, while leaving\n+  \/\/ the write table unchanged.\n+  void merge_write_table(HeapWord* start, size_t word_count);\n@@ -257,14 +253,2 @@\n-  \/\/ Instead of swap_remset, the current implementation of concurrent remembered set scanning does reset_remset\n-  \/\/ in parallel threads, each invocation processing one entire HeapRegion at a time.  Processing of a region\n-  \/\/ consists of copying the write table to the read table and cleaning the write table.\n-  void reset_remset(HeapWord* start, size_t word_count) {\n-    size_t card_index = card_index_for_addr(start);\n-    size_t num_cards = word_count \/ CardTable::card_size_in_words();\n-    size_t iterations = num_cards \/ (sizeof (intptr_t) \/ sizeof (CardValue));\n-    intptr_t* read_table_ptr = (intptr_t*) &(_card_table->read_byte_map())[card_index];\n-    intptr_t* write_table_ptr = (intptr_t*) &(_card_table->write_byte_map())[card_index];\n-    for (size_t i = 0; i < iterations; i++) {\n-      *read_table_ptr++ = *write_table_ptr;\n-      *write_table_ptr++ = CardTable::clean_card_row_val();\n-    }\n-  }\n+  \/\/ Destructively copy the write table to the read table, and clean the write table.\n+  void reset_remset(HeapWord* start, size_t word_count);\n@@ -274,1 +258,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.hpp","additions":10,"deletions":27,"binary":false,"changes":37,"status":"modified"}]}