{"files":[{"patch":"@@ -85,0 +85,2 @@\n+\/\/ Copy the write-version of the card-table into the read-version, clearing the\n+\/\/ write-copy.\n@@ -93,3 +95,2 @@\n-    if (r->is_old()) {\n-      _scanner->merge_write_table(r->bottom(), ShenandoahHeapRegion::region_size_words());\n-    }\n+    assert(r->is_old(), \"Don't waste time doing this for non-old regions\");\n+    _scanner->merge_write_table(r->bottom(), ShenandoahHeapRegion::region_size_words());\n@@ -113,3 +114,2 @@\n-    if (region->is_old()) {\n-      _scanner->reset_remset(region->bottom(), ShenandoahHeapRegion::region_size_words());\n-    }\n+    assert(region->is_old(), \"Don't waste time doing this for non-old regions\");\n+    _scanner->reset_remset(region->bottom(), ShenandoahHeapRegion::region_size_words());\n@@ -204,4 +204,3 @@\n-\/\/ If a concurrent cycle fails _after_ the card table has been swapped we need to update the read card\n-\/\/ table with any writes that have occurred during the transition to the degenerated cycle. Without this,\n-\/\/ newly created objects which are only referenced by old objects could be lost when the remembered set\n-\/\/ is scanned during the degenerated mark.\n+\/\/ Copy the write-version of the card-table into the read-version, clearing the\n+\/\/ write-version. The work is done at a safepoint and in parallel by the GC\n+\/\/ worker threads.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":9,"deletions":10,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -3377,2 +3377,2 @@\n-  \/\/ Visit young and free regions\n-  if (!region->is_old()) {\n+  \/\/ Visit young regions\n+  if (region->is_young()) {\n@@ -3385,2 +3385,2 @@\n-  \/\/ Visit old and free regions\n-  if (!region->is_young()) {\n+  \/\/ Visit old regions\n+  if (region->is_old()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -34,1 +34,7 @@\n-ShenandoahDirectCardMarkRememberedSet::ShenandoahDirectCardMarkRememberedSet(ShenandoahCardTable* card_table, size_t total_card_count) {\n+ShenandoahDirectCardMarkRememberedSet::ShenandoahDirectCardMarkRememberedSet(ShenandoahCardTable* card_table, size_t total_card_count) :\n+  LogCardValsPerIntPtr(log2i_exact(sizeof(intptr_t)) - log2i_exact(sizeof(CardValue))),\n+  LogCardSizeInWords(log2i_exact(CardTable::card_size_in_words())) {\n+\n+  \/\/ Paranoid assert for LogCardsPerIntPtr calculation above\n+  assert(sizeof(intptr_t) > sizeof(CardValue), \"LogsCardValsPerIntPtr would underflow\");\n+\n@@ -50,0 +56,48 @@\n+\/\/ Merge any dirty values from write table into the read table, while leaving\n+\/\/ the write table unchanged.\n+void ShenandoahDirectCardMarkRememberedSet::merge_write_table(HeapWord* start, size_t word_count) {\n+  size_t start_index = card_index_for_addr(start);\n+#ifdef ASSERT\n+  \/\/ avoid querying card_index_for_addr() for an address past end of heap\n+  size_t end_index = card_index_for_addr(start + word_count - 1) + 1;\n+#endif\n+  assert(start_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+  assert(end_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+\n+  \/\/ We'll access in groups of intptr_t worth of card entries\n+  intptr_t* const read_table  = (intptr_t*) &(_card_table->read_byte_map())[start_index];\n+  intptr_t* const write_table = (intptr_t*) &(_card_table->write_byte_map())[start_index];\n+\n+  \/\/ Avoid division, use shift instead\n+  assert(word_count % ((size_t)1 << (LogCardSizeInWords + LogCardValsPerIntPtr)) == 0, \"Expected a multiple of CardSizeInWords*CardValsPerIntPtr\");\n+  size_t const num = word_count >> (LogCardSizeInWords + LogCardValsPerIntPtr);\n+\n+  for (size_t i = 0; i < num; i++) {\n+    read_table[i] &= write_table[i];\n+  }\n+}\n+\n+\/\/ Destructively copy the write table to the read table, and clean the write table.\n+void ShenandoahDirectCardMarkRememberedSet::reset_remset(HeapWord* start, size_t word_count) {\n+  size_t start_index = card_index_for_addr(start);\n+#ifdef ASSERT\n+  \/\/ avoid querying card_index_for_addr() for an address past end of heap\n+  size_t end_index = card_index_for_addr(start + word_count - 1) + 1;\n+#endif\n+  assert(start_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+  assert(end_index % ((size_t)1 << LogCardValsPerIntPtr) == 0, \"Expected a multiple of CardValsPerIntPtr\");\n+\n+  \/\/ We'll access in groups of intptr_t worth of card entries\n+  intptr_t* const read_table  = (intptr_t*) &(_card_table->read_byte_map())[start_index];\n+  intptr_t* const write_table = (intptr_t*) &(_card_table->write_byte_map())[start_index];\n+\n+  \/\/ Avoid division, use shift instead\n+  assert(word_count % ((size_t)1 << (LogCardSizeInWords + LogCardValsPerIntPtr)) == 0, \"Expected a multiple of CardSizeInWords*CardValsPerIntPtr\");\n+  size_t const num = word_count >> (LogCardSizeInWords + LogCardValsPerIntPtr);\n+\n+  for (size_t i = 0; i < num; i++) {\n+    read_table[i]  = write_table[i];\n+    write_table[i] = CardTable::clean_card_row_val();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.cpp","additions":55,"deletions":1,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -207,0 +207,3 @@\n+  const size_t LogCardValsPerIntPtr;    \/\/ the number of card values (entries) in an intptr_t\n+  const size_t LogCardSizeInWords;      \/\/ the size of a card in heap word units\n+\n@@ -242,0 +245,2 @@\n+  \/\/ Instead of swap_remset, the current implementation of concurrent remembered set scanning does reset_remset\n+  \/\/ in parallel threads, each invocation processing one entire HeapRegion at a time.\n@@ -244,12 +249,3 @@\n-  void merge_write_table(HeapWord* start, size_t word_count) {\n-    size_t card_index = card_index_for_addr(start);\n-    size_t num_cards = word_count \/ CardTable::card_size_in_words();\n-    size_t iterations = num_cards \/ (sizeof (intptr_t) \/ sizeof (CardValue));\n-    intptr_t* read_table_ptr = (intptr_t*) &(_card_table->read_byte_map())[card_index];\n-    intptr_t* write_table_ptr = (intptr_t*) &(_card_table->write_byte_map())[card_index];\n-    for (size_t i = 0; i < iterations; i++) {\n-      intptr_t card_value = *write_table_ptr;\n-      *read_table_ptr++ &= card_value;\n-      write_table_ptr++;\n-    }\n-  }\n+  \/\/ Merge any dirty values from write table into the read table, while leaving\n+  \/\/ the write table unchanged.\n+  void merge_write_table(HeapWord* start, size_t word_count);\n@@ -257,14 +253,2 @@\n-  \/\/ Instead of swap_remset, the current implementation of concurrent remembered set scanning does reset_remset\n-  \/\/ in parallel threads, each invocation processing one entire HeapRegion at a time.  Processing of a region\n-  \/\/ consists of copying the write table to the read table and cleaning the write table.\n-  void reset_remset(HeapWord* start, size_t word_count) {\n-    size_t card_index = card_index_for_addr(start);\n-    size_t num_cards = word_count \/ CardTable::card_size_in_words();\n-    size_t iterations = num_cards \/ (sizeof (intptr_t) \/ sizeof (CardValue));\n-    intptr_t* read_table_ptr = (intptr_t*) &(_card_table->read_byte_map())[card_index];\n-    intptr_t* write_table_ptr = (intptr_t*) &(_card_table->write_byte_map())[card_index];\n-    for (size_t i = 0; i < iterations; i++) {\n-      *read_table_ptr++ = *write_table_ptr;\n-      *write_table_ptr++ = CardTable::clean_card_row_val();\n-    }\n-  }\n+  \/\/ Destructively copy the write table to the read table, and clean the write table.\n+  void reset_remset(HeapWord* start, size_t word_count);\n@@ -274,1 +258,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.hpp","additions":10,"deletions":27,"binary":false,"changes":37,"status":"modified"}]}