{"files":[{"patch":"@@ -25,0 +25,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -26,0 +27,2 @@\n+#include \"memory\/universe.hpp\"\n+#include \"memory\/metaspace\/virtualSpaceList.hpp\"\n@@ -30,0 +33,2 @@\n+#include \"runtime\/osThread.hpp\"\n+#include \"runtime\/threads.hpp\"\n@@ -34,0 +39,12 @@\n+#include <linux\/futex.h>\n+#include <linux\/rseq.h>\n+#include <pthread.h>\n+#include <stdint.h>\n+#include <string.h>\n+#include <sys\/mman.h>\n+#include <sys\/prctl.h>\n+#include <sys\/ptrace.h>\n+#include <sys\/syscall.h>\n+#include <sys\/wait.h>\n+#include <unistd.h>\n+\n@@ -343,0 +360,21 @@\n+static bool check_can_write() {\n+  char path[PATH_MAX];\n+  snprintf(path, PATH_MAX, \"%s%s.test\", CRaCCheckpointTo, os::file_separator());\n+  int fd = os::open(path, O_WRONLY | O_CREAT | O_TRUNC, S_IRUSR | S_IWUSR);\n+  if (fd < 0) {\n+    tty->print_cr(\"Cannot create %s: %s\\n\", path, os::strerror(errno));\n+    return false;\n+  }\n+  bool success = write(fd, \"test\", 4) > 0;\n+  if (!success) {\n+    tty->print_cr(\"Cannot write to %s: %s\\n\", path, os::strerror(errno));\n+  }\n+  if (::close(fd)) {\n+    tty->print_cr(\"Cannot close %s: %s\", path, os::strerror(errno));\n+  }\n+  if (::unlink(path)) {\n+    tty->print_cr(\"Cannot remove %s: %s\", path, os::strerror(errno));\n+  }\n+  return success;\n+}\n+\n@@ -344,0 +382,16 @@\n+  if (CRPersistMemory) {\n+    \/\/ Check early if the checkpoint directory is writable; from this point\n+    \/\/ we won't be able to go back\n+    if (!check_can_write()) {\n+      return false;\n+    }\n+    Universe::heap()->persist_for_checkpoint();\n+    metaspace::VirtualSpaceList *vsc = metaspace::VirtualSpaceList::vslist_class();\n+    if (vsc != nullptr) {\n+      vsc->persist_for_checkpoint();\n+    }\n+    metaspace::VirtualSpaceList *vsn = metaspace::VirtualSpaceList::vslist_nonclass();\n+    if (vsn != nullptr) {\n+      vsn->persist_for_checkpoint();\n+    }\n+  }\n@@ -348,0 +402,13 @@\n+  if (CRPersistMemory) {\n+    Universe::heap()->on_restore();\n+#ifdef ASSERT\n+    metaspace::VirtualSpaceList *vsc = metaspace::VirtualSpaceList::vslist_class();\n+    if (vsc != nullptr) {\n+      vsc->assert_checkpoint();\n+    }\n+    metaspace::VirtualSpaceList *vsn = metaspace::VirtualSpaceList::vslist_nonclass();\n+    if (vsn != nullptr) {\n+      vsn->assert_checkpoint();\n+    }\n+#endif \/\/ ASSERT\n+  }\n@@ -460,0 +527,218 @@\n+\n+bool crac::MemoryPersister::unmap(void *addr, size_t length) {\n+  if (::munmap(addr, length) != 0) {\n+    perror(\"::munmap\");\n+    return false;\n+  }\n+  return true;\n+}\n+\n+bool crac::MemoryPersister::map(void *addr, size_t length, int fd, size_t offset, bool executable) {\n+  if (::mmap(addr, length, PROT_READ | PROT_WRITE | (executable ? PROT_EXEC : 0),\n+      MAP_PRIVATE | MAP_FIXED | (fd < 0 ? MAP_ANONYMOUS : 0), fd, offset) != addr) {\n+    fprintf(stderr, \"::mmap %p %lu RW: %m\\n\", addr, length);\n+    return false;\n+  }\n+  return true;\n+}\n+\n+bool crac::MemoryPersister::map_gap(void *addr, size_t length) {\n+  if (::mmap(addr, length, PROT_NONE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0) != addr) {\n+    perror(\"::mmap NONE\");\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static volatile int persist_waiters = 0;\n+static volatile int persist_futex = 0;\n+\n+#if __GLIBC__ >= 2 && __GLIBC_MINOR__ >= 35\n+#define HAS_RSEQ\n+#endif\n+\n+#ifdef HAS_RSEQ\n+static struct __ptrace_rseq_configuration *rseq_configs = nullptr;\n+#endif\n+\n+static void block_in_other_futex(int signal, siginfo_t *info, void *ctx) {\n+#ifdef HAS_RSEQ\n+  struct __ptrace_rseq_configuration *rseqc = &rseq_configs[info->si_value.sival_int];\n+  if (rseqc->rseq_abi_pointer) {\n+    \/\/ Unregister rseq to prevent CRIU reading the configuration\n+    if (syscall(SYS_rseq, rseqc->rseq_abi_pointer, rseqc->rseq_abi_size, RSEQ_FLAG_UNREGISTER, rseqc->signature)) {\n+      perror(\"Unregister rseq\");\n+    }\n+  }\n+#endif \/\/ HAS_RSEQ\n+\n+  Atomic::add(&persist_waiters, 1);\n+  \/\/ From now on the code must not use stack variables!\n+#if defined(__x86_64__)\n+  asm volatile (\n+\t\t\t\".begin: syscall\\n\\t\"\n+      \"mov (%%rsi), %%ecx\\n\\t\"\n+      \"test %%ecx, %%ecx\\n\\t\"\n+      \"jnz .begin\\n\\t\"\n+\t\t\t: \/\/ ignore return value\n+\t\t\t: \"a\"(SYS_futex), \"D\"(FUTEX_WAIT_PRIVATE), \"S\"(&persist_futex), \"d\"(1)\n+\t\t\t: \"memory\", \"cc\", \"rcx\", \"r11\");\n+#elif defined(__aarch64__)\n+  register int sysnum asm (\"x8\") = SYS_futex;\n+  register int op asm (\"x0\") = FUTEX_WAIT_PRIVATE;\n+  register volatile int *futex asm (\"x1\") = &persist_futex;\n+  register int value asm (\"x2\") = 1;\n+  asm volatile (\n+\t\t\t\".begin: svc #0\\n\\t\"\n+      \"ldr w3, [x1]\\n\\t\"\n+      \"cbnz w3, .begin\\n\\t\"\n+\t\t\t: \/\/ ignore return value\n+\t\t\t: \"r\"(sysnum), \"r\"(op), \"r\"(futex), \"r\"(value)\n+\t\t\t: \"memory\", \"cc\", \"x3\");\n+#else\n+# error Unimplemented\n+  \/\/ This is the logic any platform should perform:\n+  \/\/ while (persist_futex) {\n+  \/\/    syscall(SYS_futex, &persist_futex, FUTEX_WAIT_PRIVATE, 1, nullptr, nullptr, 0);\n+  \/\/ }\n+#endif \/\/ x86_64 or aarch64\n+\n+  int dec = Atomic::sub(&persist_waiters, 1);\n+#ifdef HAS_RSEQ\n+  if (rseqc->rseq_abi_pointer) {\n+    \/\/ Register the rseq back after restore\n+    if (syscall(SYS_rseq, rseqc->rseq_abi_pointer, rseqc->rseq_abi_size, 0, rseqc->signature) != 0) {\n+      perror(\"Register rseq again\");\n+    }\n+  }\n+  if (dec == 0) {\n+    FREE_C_HEAP_ARRAY(struct __ptrace_rseq_configuration, rseq_configs);\n+    rseq_configs = nullptr;\n+  }\n+#endif \/\/ HAS_RSEQ\n+}\n+\n+#ifdef HAS_RSEQ\n+class GetRseqClosure: public ThreadClosure {\n+private:\n+  int _idx;\n+public:\n+  GetRseqClosure(): _idx(0) {}\n+\n+  void do_thread(Thread* thread) {\n+    pid_t tid = thread->osthread()->thread_id();\n+    if (ptrace(PTRACE_SEIZE, tid, 0, 0)) {\n+      perror(\"Cannot seize\");\n+    }\n+    if (ptrace(PTRACE_INTERRUPT, tid, 0, 0)) {\n+      perror(\"Cannot interrupt\");\n+    }\n+    int status;\n+    if (waitpid(tid, &status, 0) < 0) {\n+      perror(\"Cannot wait for tracee\");\n+    }\n+    struct __ptrace_rseq_configuration rseqc;\n+    if (ptrace(PTRACE_GET_RSEQ_CONFIGURATION, tid, sizeof(rseqc), &rseqc) != sizeof(rseqc)) {\n+      perror(\"Cannot get rseq\");\n+    }\n+    for (size_t i = 0; i < sizeof(rseqc); i += sizeof(long)) {\n+      if (ptrace(PTRACE_POKEDATA, tid, (char *)(rseq_configs + _idx) + i, *(long *)((char *)&rseqc + i))) {\n+        perror(\"Cannot write rseq to tracee process\");\n+      }\n+    }\n+    if (ptrace(PTRACE_DETACH, tid, 0, 0)) {\n+      perror(\"Cannot detach\");\n+    }\n+    _idx++;\n+  }\n+};\n+#endif \/\/ HAS_RSEQ\n+\n+class SignalClosure: public ThreadClosure {\n+private:\n+  int _idx;\n+public:\n+  SignalClosure(): _idx(0) {}\n+\n+  void do_thread(Thread* thread) {\n+    sigval_t val;\n+    val.sival_int = _idx++;\n+    pthread_sigqueue(thread->osthread()->pthread_id(), SIGUSR1, val);\n+\n+    JavaThread *jt = JavaThread::cast(thread);\n+    jt->wakeup_sleep();\n+    jt->parker()->unpark();\n+    jt->_ParkEvent->unpark();\n+  }\n+};\n+\n+\n+\/\/ JavaThreads that are going to be unmapped are parked as we're on safepoint\n+\/\/ but the parking syscall likely uses memory that is going to be unmapped.\n+\/\/ This is fine for the duration of the syscall, but if CREngine restarts\n+\/\/ these syscalls these would fail with EFAULT and crash in GLIBC.\n+\/\/ Therefore we register a signal handler that will park on global futex,\n+\/\/ send signal to each individual thread and wake up the threads to move\n+\/\/ to this signal handler.\n+void crac::before_threads_persisted() {\n+  persist_futex = 1;\n+\n+  CountThreadsClosure counter;\n+  Threads::java_threads_do(&counter);\n+\n+#ifdef HAS_RSEQ\n+  rseq_configs = NEW_C_HEAP_ARRAY(\n+    struct __ptrace_rseq_configuration, counter.count(), mtInternal);\n+  guarantee(rseq_configs, \"Cannot allocate %lu rseq structs\", counter.count());\n+#endif \/\/ HAS_RSEQ\n+\n+  sigset_t blocking_set;\n+  sigemptyset(&blocking_set);\n+  sigaddset(&blocking_set, SIGUSR1);\n+  sigprocmask(SIG_BLOCK, &blocking_set, nullptr);\n+  pid_t child = fork();\n+  if (child == 0) {\n+    siginfo_t info;\n+    sigwaitinfo(&blocking_set, &info);\n+#ifdef HAS_RSEQ\n+    GetRseqClosure get_rseq;\n+    Threads::java_threads_do(&get_rseq);\n+#endif \/\/ HAS_RSEQ\n+    os::exit(0);\n+  } else {\n+    sigprocmask(SIG_UNBLOCK, &blocking_set, nullptr);\n+    \/\/ Allow child to trace us if \/proc\/sys\/kernel\/yama\/ptrace_scope = 1\n+    prctl(PR_SET_PTRACER, child, 0, 0);\n+    kill(child, SIGUSR1);\n+    int status;\n+    if (waitpid(child, &status, 0) < 0) {\n+      perror(\"Waiting for tracer child\");\n+    }\n+  }\n+\n+  struct sigaction action, old;\n+  action.sa_sigaction = block_in_other_futex;\n+  action.sa_flags = SA_SIGINFO;\n+  action.sa_restorer = nullptr;\n+  if (sigaction(SIGUSR1, &action, &old)) {\n+    fatal(\"Cannot install SIGUSR1 handler: %s\", os::strerror(errno));\n+  }\n+\n+  SignalClosure closure;\n+  Threads::java_threads_do(&closure);\n+\n+  while ((size_t) persist_waiters < counter.count()) {\n+    sched_yield();\n+  }\n+\n+  if (sigaction(SIGUSR1, &old, nullptr)) {\n+    fatal(\"Cannot restore SIGUSR1 handler: %s\", os::strerror(errno));\n+  }\n+}\n+\n+void crac::after_threads_restored() {\n+  persist_futex = 0;\n+  if (syscall(SYS_futex, &persist_futex, FUTEX_WAKE_PRIVATE, INT_MAX, nullptr, nullptr, 0) < 0) {\n+    fatal(\"Cannot wake up threads after restore: %s\", os::strerror(errno));\n+  }\n+}\n","filename":"src\/hotspot\/os\/linux\/crac_linux.cpp","additions":285,"deletions":0,"binary":false,"changes":285,"status":"modified"},{"patch":"@@ -63,1 +63,14 @@\n-#endif\n\\ No newline at end of file\n+\n+bool crac::MemoryPersister::unmap(void *addr, size_t length) {\n+}\n+\n+bool crac::MemoryPersister::map(void *addr, size_t length, int fd, size_t offset, bool executable) {\n+}\n+\n+void crac::before_threads_persisted() {\n+}\n+\n+void crac::after_threads_restored() {\n+}\n+\n+#endif\n","filename":"src\/hotspot\/os\/posix\/crac_posix.cpp","additions":14,"deletions":1,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -68,0 +68,1 @@\n+#include <spawn.h>\n@@ -1968,3 +1969,6 @@\n-  pid_t pid = fork();\n-  if (pid == -1) {\n-    perror(\"cannot fork for crengine\");\n+  \/\/ We do not use fork & exec since glibc goes over all threads on fork(),\n+  \/\/ and when some threads have stack unmapped (in-JVM memory persistence)\n+  \/\/ this would crash the process.\n+  pid_t pid;\n+  if (posix_spawn(&pid, path, nullptr, nullptr, (char * const *) argv, env) != 0) {\n+    perror(\"Cannot spawn crengine\");\n@@ -1973,5 +1977,0 @@\n-  if (pid == 0) {\n-    execve(path, (char* const*)argv, env);\n-    perror(\"execve\");\n-    exit(1);\n-  }\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":7,"deletions":8,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -56,0 +56,12 @@\n+\n+bool crac::MemoryPersister::unmap(void *addr, size_t length) {\n+}\n+\n+bool crac::MemoryPersister::map(void *addr, size_t length, int fd, size_t offset, bool executable) {\n+}\n+\n+void crac::before_threads_persisted() {\n+}\n+\n+void crac::after_threads_restored() {\n+}\n","filename":"src\/hotspot\/os\/windows\/crac_windows.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -1880,0 +1881,20 @@\n+\n+void CodeCache::persist_for_checkpoint() {\n+  FOR_ALL_HEAPS(it) {\n+    CodeHeap *heap = *it;\n+    if (heap != nullptr) {\n+      heap->persist_for_checkpoint();\n+    }\n+  }\n+}\n+\n+#ifdef ASSERT\n+void CodeCache::assert_checkpoint() {\n+  FOR_ALL_HEAPS(it) {\n+    CodeHeap *heap = *it;\n+    if (heap != nullptr) {\n+      heap->assert_checkpoint();\n+    }\n+  }\n+}\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/code\/codeCache.cpp","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -343,0 +343,3 @@\n+\n+  static void persist_for_checkpoint();\n+  DEBUG_ONLY(static void assert_checkpoint();)\n","filename":"src\/hotspot\/share\/code\/codeCache.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"gc\/g1\/g1FromCardCache.hpp\"\n@@ -1320,0 +1321,15 @@\n+\n+  void persist_for_checkpoint() {\n+    _hrm.persist_for_checkpoint();\n+    G1FromCardCache::persist_for_checkpoint();\n+    _cm->persist_for_checkpoint();\n+    _task_queues->dealloc_queues();\n+  }\n+  void on_restore() {\n+  #ifdef ASSERT\n+    _hrm.assert_checkpoint();\n+    G1FromCardCache::assert_checkpoint();\n+  #endif \/\/ ASSERT\n+    _cm->on_restore();\n+    _task_queues->realloc_queues();\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -70,0 +70,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -3056,0 +3057,16 @@\n+\n+void G1CMMarkStack::persist_for_checkpoint() {\n+  size_t used = MIN2(_hwm, _chunk_capacity) * sizeof(TaskQueueEntryChunk);\n+  size_t committed = _chunk_capacity * sizeof(TaskQueueEntryChunk);\n+  if (!crac::MemoryPersister::store(_base, used, committed, false)) {\n+    fatal(\"Cannot persist GC CM Mark stack\");\n+  }\n+}\n+\n+#ifdef ASSERT\n+void G1CMMarkStack::assert_checkpoint() {\n+  size_t used = MIN2(_hwm, _chunk_capacity) * sizeof(TaskQueueEntryChunk);\n+  size_t committed = _chunk_capacity * sizeof(TaskQueueEntryChunk);\n+  crac::MemoryPersister::assert_mem(_base, used, committed);\n+}\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -211,0 +211,3 @@\n+  void persist_for_checkpoint();\n+  DEBUG_ONLY(void assert_checkpoint());\n+\n@@ -620,0 +623,10 @@\n+  void persist_for_checkpoint() {\n+    _global_mark_stack.persist_for_checkpoint();\n+    _task_queues->dealloc_queues();\n+  }\n+\n+  void on_restore() {\n+    DEBUG_ONLY(_global_mark_stack.assert_checkpoint();)\n+    _task_queues->realloc_queues();\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -93,0 +94,20 @@\n+\n+void G1FromCardCache::persist_for_checkpoint() {\n+  if (_cache == nullptr || _static_mem_size == 0) {\n+    return;\n+  }\n+  size_t size = align_up(_static_mem_size, os::vm_allocation_granularity());\n+  if (!crac::MemoryPersister::store(_cache, size, size, false)) {\n+    fatal(\"Failed to persist G1FromCardCache\");\n+  }\n+}\n+\n+#ifdef ASSERT\n+void G1FromCardCache::assert_checkpoint() {\n+  if (_cache == nullptr || _static_mem_size == 0) {\n+    return;\n+  }\n+  size_t size = align_up(_static_mem_size, os::vm_allocation_granularity());\n+  crac::MemoryPersister::assert_mem(_cache, size, size);\n+}\n+#endif \/\/ASSERT\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FromCardCache.cpp","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -98,0 +98,3 @@\n+\n+  static void persist_for_checkpoint();\n+  DEBUG_ONLY(static void assert_checkpoint();)\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FromCardCache.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -253,0 +254,42 @@\n+\n+void G1PageBasedVirtualSpace::persist_for_checkpoint() {\n+  bool flip = _committed.at(0);\n+  size_t index = 0;\n+  while (index < _committed.size()) {\n+    size_t next;\n+    if (flip) {\n+      next = _committed.find_first_clear_bit(index);\n+      size_t length = (next - index) * _page_size;\n+      if (!crac::MemoryPersister::store((char *) _low_boundary + index * _page_size, length, length, false)) {\n+        fatal(\"Failed to persist committed virtual space node range\");\n+      }\n+    } else {\n+      next = _committed.find_first_set_bit(index);\n+      if (!crac::MemoryPersister::store_gap((char *) _low_boundary + index * _page_size, (next - index) * _page_size)) {\n+        fatal(\"Failed to persist uncommitted virtual space node range\");\n+      }\n+    }\n+    flip = !flip;\n+    index = next;\n+  }\n+}\n+\n+#ifdef ASSERT\n+void G1PageBasedVirtualSpace::assert_checkpoint() {\n+  bool flip = _committed.at(0);\n+  size_t index = 0;\n+  while (index < _committed.size()) {\n+    size_t next;\n+    if (flip) {\n+      next = _committed.find_first_clear_bit(index);\n+      size_t length = (next - index) * _page_size;\n+      crac::MemoryPersister::assert_mem((char *) _low_boundary + index * _page_size, length, length);\n+    } else {\n+      next = _committed.find_first_set_bit(index);\n+      crac::MemoryPersister::assert_gap((char *) _low_boundary + index * _page_size, (next - index) * _page_size);\n+    }\n+    flip = !flip;\n+    index = next;\n+  }\n+}\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/gc\/g1\/g1PageBasedVirtualSpace.cpp","additions":43,"deletions":0,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -147,0 +147,3 @@\n+\n+  void persist_for_checkpoint();\n+  DEBUG_ONLY(void assert_checkpoint());\n","filename":"src\/hotspot\/share\/gc\/g1\/g1PageBasedVirtualSpace.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -89,0 +89,10 @@\n+\n+  void persist_for_checkpoint() {\n+    _storage.persist_for_checkpoint();\n+  }\n+\n+#ifdef ASSERT\n+  void assert_checkpoint() {\n+    _storage.assert_checkpoint();\n+  }\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RegionToSpaceMapper.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -831,0 +832,45 @@\n+\n+\n+void HeapRegionManager::persist_for_checkpoint() {\n+  size_t page_size = os::vm_page_size();\n+  for (size_t i = 0; i < _regions.length(); ++i) {\n+    HeapRegion *region = _regions.get_by_index(i);\n+    if (region == nullptr) {\n+      continue;\n+    }\n+    u_int64_t top_aligned = align_up((u_int64_t) region->top(), page_size);\n+    \/\/ both active and inactive are mapped RW\n+    if (_committed_map.active(i) || _committed_map.inactive(i)) {\n+      if (!crac::MemoryPersister::store(region->bottom(), region->used(), region->capacity(), false)) {\n+        fatal(\"Cannot persist heap region %p - %p\", region->bottom(), region->end());\n+      }\n+    } else {\n+      if (!crac::MemoryPersister::store_gap(region->bottom(), region->capacity())) {\n+        fatal(\"Cannot persist heap region %p - %p\", region->bottom(), region->end());\n+      }\n+    }\n+  }\n+  _bot_mapper->persist_for_checkpoint();\n+  _cardtable_mapper->persist_for_checkpoint();\n+  _bitmap_mapper->persist_for_checkpoint();\n+}\n+\n+#ifdef ASSERT\n+void HeapRegionManager::assert_checkpoint() {\n+  for (size_t i = 0; i < _regions.length(); ++i) {\n+    HeapRegion *region = _regions.get_by_index(i);\n+    if (region == nullptr) {\n+      continue;\n+    }\n+    if (_committed_map.active(i) || _committed_map.inactive(i)) {\n+      crac::MemoryPersister::assert_mem(region->bottom(), region->used(), region->capacity());\n+    } else {\n+      crac::MemoryPersister::assert_gap(region->bottom(), region->capacity());\n+    }\n+  }\n+\n+  _bot_mapper->assert_checkpoint();\n+  _cardtable_mapper->assert_checkpoint();\n+  _bitmap_mapper->assert_checkpoint();\n+}\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionManager.cpp","additions":46,"deletions":0,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -295,0 +295,3 @@\n+\n+  void persist_for_checkpoint();\n+  DEBUG_ONLY(void assert_checkpoint();)\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionManager.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -543,0 +543,6 @@\n+\n+  \/\/ CRaC related\n+  virtual void persist_for_checkpoint() {\n+    \/\/ by default ignore the request\n+  }\n+  virtual void on_restore() {}\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -418,0 +418,3 @@\n+\n+  void release_memory();\n+  void realloc_memory();\n@@ -508,0 +511,11 @@\n+  void dealloc_queues() {\n+    for (uint i = 0; i < _n; ++i) {\n+      _queues[i]->release_memory();\n+    }\n+  }\n+  void realloc_queues() {\n+    for (uint i = 0; i < _n; ++i) {\n+      _queues[i]->realloc_memory();\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/taskqueue.hpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -111,0 +111,13 @@\n+template<class E, MEMFLAGS F, unsigned int N>\n+void GenericTaskQueue<E, F, N>::release_memory() {\n+  guarantee(size() == 0, \"Task queue not empty\");\n+  ArrayAllocator<E>::free(_elems, N);\n+  _elems = nullptr;\n+}\n+\n+template<class E, MEMFLAGS F, unsigned int N>\n+void GenericTaskQueue<E, F, N>::realloc_memory() {\n+  guarantee(_elems == nullptr, \"Task queue not released\");\n+  _elems = ArrayAllocator<E>::allocate(N, F);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/taskqueue.inline.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -231,0 +231,12 @@\n+\n+  void persist_for_checkpoint() {\n+    _memory.persist_on_checkpoint();\n+    _segmap.persist_on_checkpoint();\n+  }\n+\n+#ifdef ASSERT\n+  void assert_checkpoint() {\n+    _memory.assert_checkpoint();\n+    _segmap.assert_checkpoint();\n+  }\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/memory\/heap.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -213,0 +214,22 @@\n+void VirtualSpaceList::persist_for_checkpoint() {\n+  size_t granule_size = Settings::commit_granule_bytes();\n+\n+  VirtualSpaceNode* vsn = _first_node;\n+  while (vsn != nullptr) {\n+    vsn->persist_for_checkpoint();\n+    vsn = vsn->next();\n+  }\n+}\n+\n+#ifdef ASSERT\n+void VirtualSpaceList::assert_checkpoint() {\n+  size_t granule_size = Settings::commit_granule_bytes();\n+\n+  VirtualSpaceNode* vsn = _first_node;\n+  while (vsn != nullptr) {\n+    vsn->assert_checkpoint();\n+    vsn = vsn->next();\n+  }\n+}\n+#endif \/\/ ASSERT\n+\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceList.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -142,0 +142,2 @@\n+  void persist_for_checkpoint();\n+  DEBUG_ONLY(void assert_checkpoint();)\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceList.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"utilities\/bitMap.inline.hpp\"\n@@ -451,0 +452,44 @@\n+void VirtualSpaceNode::persist_for_checkpoint() {\n+  size_t granule_size = Settings::commit_granule_bytes();\n+  bool flip = _commit_mask.at(0);\n+  size_t index = 0;\n+  while (index < _commit_mask.size()) {\n+    size_t next;\n+    if (flip) {\n+      next = _commit_mask.find_first_clear_bit(index);\n+      size_t length = (next - index) * granule_size;\n+      if (!crac::MemoryPersister::store((char *) _base + index * granule_size, length, length, false)) {\n+        fatal(\"Failed to persist committed virtual space node range\");\n+      }\n+    } else {\n+      next = _commit_mask.find_first_set_bit(index);\n+      if (!crac::MemoryPersister::store_gap((char *) _base + index * granule_size, (next - index) * granule_size)) {\n+        fatal(\"Failed to persist uncommitted virtual space node range\");\n+      }\n+    }\n+    flip = !flip;\n+    index = next;\n+  }\n+}\n+\n+#ifdef ASSERT\n+void VirtualSpaceNode::assert_checkpoint() {\n+  size_t granule_size = Settings::commit_granule_bytes();\n+  bool flip = _commit_mask.at(0);\n+  size_t index = 0;\n+  while (index < _commit_mask.size()) {\n+    size_t next;\n+    if (flip) {\n+      next = _commit_mask.find_first_clear_bit(index);\n+      size_t length = (next - index) * granule_size;\n+      crac::MemoryPersister::assert_mem((char *) _base + index * granule_size, length, length);\n+    } else {\n+      next = _commit_mask.find_first_set_bit(index);\n+      crac::MemoryPersister::assert_gap((char *) _base + index * granule_size, (next - index) * granule_size);\n+    }\n+    flip = !flip;\n+    index = next;\n+  }\n+}\n+#endif \/\/ ASSERT\n+\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceNode.cpp","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -258,0 +259,3 @@\n+  void persist_for_checkpoint();\n+  DEBUG_ONLY(void assert_checkpoint();)\n+\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceNode.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/crac.hpp\"\n@@ -1073,0 +1074,18 @@\n+\n+void VirtualSpace::persist_on_checkpoint() {\n+  size_t used = committed_size();\n+  if (!crac::MemoryPersister::store_gap(_low_boundary, _low - _low_boundary) ||\n+      !crac::MemoryPersister::store(_low, used, used, true) ||\n+      !crac::MemoryPersister::store_gap(_high, _high_boundary - _high)) {\n+    fatal(\"Cannot persist virtual space at %p - %p\", _low_boundary, _high_boundary);\n+  }\n+}\n+\n+#ifdef ASSERT\n+void VirtualSpace::assert_checkpoint() {\n+  size_t used = _high - _low;\n+  crac::MemoryPersister::assert_gap(_low_boundary, _low - _low_boundary);\n+  crac::MemoryPersister::assert_mem(_low, used, used);\n+  crac::MemoryPersister::assert_gap(_high, _high_boundary - _high);\n+}\n+#endif \/\/ASSERT\n","filename":"src\/hotspot\/share\/memory\/virtualspace.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -189,1 +189,0 @@\n-\n@@ -245,0 +244,3 @@\n+\n+  void persist_on_checkpoint();\n+  DEBUG_ONLY(void assert_checkpoint();)\n","filename":"src\/hotspot\/share\/memory\/virtualspace.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"code\/codeCache.hpp\"\n@@ -44,0 +45,2 @@\n+#include <malloc.h>\n+\n@@ -286,0 +289,51 @@\n+class PersistThreadStackClosure: public ThreadClosure {\n+public:\n+  void do_thread(Thread* t) {\n+    JavaThread *thread = JavaThread::cast(t);\n+    size_t reserved = thread->stack_overflow_state()->stack_reserved_zone_base() - thread->stack_end();\n+    if (!crac::MemoryPersister::store_gap(thread->stack_end(), reserved)) {\n+      fatal(\"Cannot record reserved zone for stack\");\n+    }\n+    \/\/ On aarch64 the stack size might be not aligned to page boundaries on the upper end\n+    size_t length = align_up(thread->stack_size() - reserved, os::vm_page_size());\n+    if (!crac::MemoryPersister::store(thread->stack_end() + reserved, length, length, false)) {\n+      fatal(\"Cannot persist thread stack\");\n+    }\n+  }\n+};\n+\n+#ifdef ASSERT\n+class AssertThreadStackClosure: public ThreadClosure {\n+public:\n+  void do_thread(Thread* t) {\n+    JavaThread *thread = JavaThread::cast(t);\n+    size_t reserved = thread->stack_overflow_state()->stack_reserved_zone_base() - thread->stack_end();\n+    crac::MemoryPersister::assert_gap(thread->stack_end(), reserved);\n+    size_t length = align_up(thread->stack_size() - reserved, os::vm_page_size());\n+    crac::MemoryPersister::assert_mem(thread->stack_end() + reserved, length, length);\n+  }\n+};\n+#endif \/\/ ASSERT\n+\n+static void persist_thread_stacks() {\n+\/\/ Not platform-specific, but skip this on non-Linux\n+#ifdef LINUX\n+  crac::before_threads_persisted();\n+  CountThreadsClosure counter;\n+  Threads::java_threads_do(&counter);\n+  PersistThreadStackClosure closure;\n+  Threads::java_threads_do(&closure);\n+#endif\n+}\n+\n+static void restore_thread_stacks() {\n+\/\/ Not platform-specific, but skip this on non-Linux\n+#ifdef LINUX\n+# ifdef ASSERT\n+  AssertThreadStackClosure closure;\n+  Threads::java_threads_do(&closure);\n+# endif \/\/ ASSERT\n+  crac::after_threads_restored();\n+#endif\n+}\n+\n@@ -335,0 +389,8 @@\n+  \/\/ We don't invoke this inside memory_checkpoint() for symmetry;\n+  \/\/ CodeCache must be restored earlier (see below)\n+  if (CRPersistMemory) {\n+    CodeCache::persist_for_checkpoint();\n+  }\n+\n+  malloc_trim(0);\n+\n@@ -341,0 +403,6 @@\n+    if (CRPersistMemory) {\n+      \/\/ Since VM_Crac instance is allocated on stack of other thread\n+      \/\/ we must not use it from now on\n+      persist_thread_stacks();\n+      crac::MemoryPersister::finalize();\n+    }\n@@ -342,0 +410,7 @@\n+    if (CRPersistMemory) {\n+      crac::MemoryPersister::load_on_restore();\n+      restore_thread_stacks();\n+#ifdef ASSERT\n+      CodeCache::assert_checkpoint();\n+#endif \/\/ ASSERT\n+    }\n@@ -605,0 +680,202 @@\n+\n+GrowableArray<struct crac::MemoryPersister::record> crac::MemoryPersister::_index(256, mtInternal);\n+int crac::MemoryPersister::_fd = -1;\n+DEBUG_ONLY(bool crac::MemoryPersister::_loading = false;)\n+size_t crac::MemoryPersister::_offset_curr = 0;\n+\n+void crac::MemoryPersister::ensure_open(bool loading) {\n+  \/\/ We don't need any synchronization as only the VM thread persists memory\n+  assert(Thread::current()->is_VM_thread(), \"All writes should be performed by VM thread\");\n+  assert(_loading == loading, loading ? \"Cannot load during persist\" : \"Cannot persist when loading\");\n+  if (_fd >= 0) {\n+    return;\n+  }\n+  char path[PATH_MAX];\n+  snprintf(path, PATH_MAX, \"%s%smemory.img\", CRaCCheckpointTo, os::file_separator());\n+  _fd = os::open(path, loading ? O_RDONLY : (O_WRONLY | O_CREAT | O_TRUNC), S_IRUSR | S_IWUSR);\n+  if (_fd < 0) {\n+    fatal(\"Cannot open persisted memory file: %s\", os::strerror(errno));\n+  }\n+  _offset_curr = 0;\n+}\n+\n+static bool is_all_zeroes(void *addr, size_t page_size) {\n+  unsigned long long *ptr = (unsigned long long *) addr;\n+  unsigned long long *end = (unsigned long long *)((char *) addr + page_size);\n+  while (ptr < end && *ptr == 0) ++ptr;\n+  return ptr == end;\n+}\n+\n+#define BAD_OFFSET 0xFFFFFFFFBAD0FF5Eull\n+\n+bool crac::MemoryPersister::store(void *addr, size_t length, size_t mapped_length, bool executable) {\n+  if (mapped_length == 0) {\n+    return true;\n+  }\n+\n+  size_t page_size = os::vm_page_size();\n+  assert(((u_int64_t) addr & (page_size - 1)) == 0, \"Unaligned address %p\", addr);\n+  assert(length <= mapped_length, \"Useful length %lx longer than mapped %lx\", length, mapped_length);\n+  assert((mapped_length & (page_size - 1)) == 0, \"Unaligned length %lx at %p (page size %lx)\", mapped_length, addr, page_size);\n+\n+  MemoryPersister::ensure_open(false);\n+\n+  char *curr = (char *) addr;\n+  char *end = curr + length;\n+  char *start = curr;\n+  bool do_zeroes = is_all_zeroes(addr, page_size);\n+  while (curr < end) {\n+    if (do_zeroes) {\n+      do {\n+        curr += page_size;\n+      } while (curr < end && is_all_zeroes(curr, page_size));\n+      os::seek_to_file_offset(_fd, _offset_curr + (curr - (char *) addr));\n+      \/\/ We don't have to punch holes using fallocate, OS creates holes automatically\n+      \/\/ when we are seeking over gaps.\n+      \/\/ TODO: in the future it might be useful to record holes explicitly, too,\n+      \/\/ to support transfer or encryption.\n+      \/\/ On the other hand, recording zero-only sections into index individually will\n+      \/\/ complicate the assertions as there would be > 2 records per one store()\n+      do_zeroes = false;\n+      start = curr;\n+    } else {\n+      do {\n+        curr += page_size;\n+      } while (curr < end && !is_all_zeroes(curr, page_size));\n+      size_t to_write = (curr > end ? end : curr) - start;\n+      if (!os::write(_fd, start, to_write)) {\n+        tty->print_cr(\"Cannot store persisted memory\");\n+        return false;\n+      }\n+      if (curr > end) {\n+        os::seek_to_file_offset(_fd, _offset_curr + (curr - (char *) addr));\n+      }\n+      do_zeroes = true;\n+    }\n+  }\n+\n+  int execFlag = (executable ? Flags::EXECUTABLE : 0);\n+  if (length > 0) {\n+    _index.append({\n+      .addr = (u_int64_t) addr,\n+      .length = (u_int64_t) length,\n+      .offset = (u_int64_t) _offset_curr,\n+      .flags = Flags::DATA | Flags::ACCESSIBLE | execFlag\n+    });\n+  }\n+  size_t aligned_length = align_up(length, page_size);\n+  if (aligned_length < mapped_length) {\n+    _index.append({\n+      .addr = (u_int64_t) addr + aligned_length,\n+      .length = (u_int64_t) mapped_length - aligned_length,\n+      .offset = BAD_OFFSET,\n+      .flags = Flags::ACCESSIBLE | execFlag\n+    });\n+  }\n+  _offset_curr += aligned_length;\n+  return unmap(addr, mapped_length);\n+}\n+\n+bool crac::MemoryPersister::store_gap(void *addr, size_t length) {\n+  assert(((u_int64_t) addr & (os::vm_page_size() - 1)) == 0, \"Unaligned address\");\n+  assert((length & (os::vm_page_size() - 1)) == 0, \"Unaligned length\");\n+  if (length == 0) {\n+    return true;\n+  }\n+  _index.append({\n+    .addr = (u_int64_t) addr,\n+    .length = (u_int64_t) length,\n+    .offset = BAD_OFFSET,\n+    .flags = 0\n+  });\n+  return unmap(addr, length);\n+}\n+\n+void crac::MemoryPersister::load_on_restore() {\n+  ensure_open(true);\n+  for (int i = 0; i < _index.length(); ++i) {\n+    const struct record &r = _index.at(i);\n+    size_t aligned_length = align_up(r.length, os::vm_page_size());\n+    int fd = _fd;\n+    size_t offset = r.offset;\n+    if ((r.flags & Flags::DATA) == 0) {\n+      fd = -1;\n+      offset = 0;\n+    }\n+    bool executable = r.flags & Flags::EXECUTABLE;\n+    if (r.flags && Flags::ACCESSIBLE) {\n+      if (!map((void *) r.addr, aligned_length, fd, offset, executable)) {\n+        fatal(\"Cannot remap memory at %p-%p\", (void *) r.addr, (void *)(r.addr + aligned_length));\n+      }\n+    } else {\n+      if (!map_gap((void *) r.addr, aligned_length)) {\n+        fatal(\"Cannot remap non-accessible memory at %p-%p\", (void *) r.addr, (void *)(r.addr + aligned_length));\n+      }\n+    }\n+  }\n+}\n+\n+#ifdef ASSERT\n+void crac::MemoryPersister::assert_mem(void *addr, size_t used, size_t total) {\n+  assert(((u_int64_t) addr & (os::vm_page_size() - 1)) == 0, \"Unaligned address %p\", addr);\n+  assert((total & (os::vm_page_size() - 1)) == 0, \"Unaligned length %lx\", total);\n+\n+  if (used > 0) {\n+    SearchInIndex comparator;\n+    bool found;\n+    size_t at = (size_t) _index.find_sorted<struct record>(&comparator, { .addr = (u_int64_t) addr }, found);\n+    assert(found, \"Cannot find region with address %p (%d records)\", addr, _index.length());\n+    record &r = _index.at(at);\n+    assert(r.length == used, \"Persisted memory region length does not match at %p: %lu vs. %lu\", addr, used, r.length);\n+    assert(r.flags & (Flags::DATA | Flags::ACCESSIBLE), \"Bad flags for %p: 0x%x\", addr, r.flags);\n+    assert(r.offset != BAD_OFFSET, \"Invalid offset at %p\", addr);\n+  }\n+  size_t aligned = align_up(used, os::vm_page_size());\n+  size_t unused = total - aligned;\n+  void *gap_addr = (char *) addr + aligned;\n+  if (unused > 0) {\n+    SearchInIndex comparator;\n+    bool found;\n+    size_t at = (size_t) _index.find_sorted<struct record>(&comparator, { .addr = (u_int64_t) gap_addr }, found);\n+    assert(found, \"Cannot find region with address %p (%d records)\", addr, _index.length());\n+    record &r = _index.at(at);\n+    assert(r.length == unused, \"Persisted gap length does not match at %p: %lu vs. %lu\", gap_addr, unused, r.length);\n+    assert((r.flags & (Flags::DATA | Flags::ACCESSIBLE)) == Flags::ACCESSIBLE, \"Bad flags for gap %p: 0x%x\", gap_addr, r.flags);\n+    assert(r.offset == BAD_OFFSET, \"Invalid offset at %p: %lx\", gap_addr, r.offset);\n+  }\n+}\n+\n+void crac::MemoryPersister::assert_gap(void *addr, size_t length) {\n+  assert(((u_int64_t) addr & (os::vm_page_size() - 1)) == 0, \"Unaligned address %p\", addr);\n+  assert((length & (os::vm_page_size() - 1)) == 0, \"Unaligned length %lx\", length);\n+\n+  if (length > 0) {\n+    SearchInIndex comparator;\n+    bool found;\n+    size_t at = (size_t) _index.find_sorted<struct record>(&comparator, { .addr = (u_int64_t) addr }, found);\n+    assert(found, \"Cannot find region with address %p (%d records)\", addr, _index.length());\n+    record &r = _index.at(at);\n+    assert(r.length == length, \"Persisted memory region length does not match at %p: %lu vs. %lu\", addr, length, r.length);\n+    assert((r.flags & (Flags::DATA | Flags::ACCESSIBLE)) == 0, \"Bad flags for %p: 0x%x\", addr, r.flags);\n+    assert(r.offset == BAD_OFFSET, \"Invalid offset at %p: %lx\", addr, r.offset);\n+  }\n+}\n+#endif \/\/ ASSERT\n+\n+void crac::MemoryPersister::finalize() {\n+  if (_fd >= 0) {\n+    ::close(_fd);\n+    _fd = -1;\n+  }\n+#ifdef ASSERT\n+  _index.sort([](struct record *a, struct record *b) {\n+    \/\/ simple cast to int doesn't work, let compiler figure it out with cmovs\n+    if (a->addr < b->addr) return -1;\n+    if (a->addr > b->addr) return 1;\n+    return 0;\n+  });\n+  _loading = true;\n+#endif \/\/ ASSERT\n+  \/\/ Note: here we could persist _index and dallocate it as well but since it's\n+  \/\/ usually tens or hundreds of 32 byte records, we won't save much.\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/runtime\/crac.cpp","additions":277,"deletions":0,"binary":false,"changes":277,"status":"modified"},{"patch":"@@ -51,0 +51,51 @@\n+  class MemoryPersister: AllStatic {\n+  protected:\n+    enum Flags {\n+      DATA       = 1 << 0,\n+      EXECUTABLE = 1 << 1,\n+      ACCESSIBLE = 1 << 2,\n+    };\n+\n+    struct record {\n+      u_int64_t addr;\n+      u_int64_t length;\n+      u_int64_t offset;\n+      int flags;\n+    };\n+\n+    class SearchInIndex: public CompareClosure<struct record> {\n+    public:\n+      int do_compare(const struct record &a, const struct record &b) {\n+        if (a.addr < b.addr) return -1;\n+        if (a.addr > b.addr) return 1;\n+        return 0;\n+      }\n+    };\n+\n+    static void ensure_open(bool loading);\n+    static void allocate_index(size_t slots);\n+\n+    static GrowableArray<struct crac::MemoryPersister::record> _index;\n+    static int _fd;\n+    static bool _loading;\n+    static size_t _offset_curr;\n+\n+  public:\n+    static bool store(void *addr, size_t length, size_t mapped_length, bool executable);\n+    static bool store_gap(void *addr, size_t length);\n+\n+    static void finalize();\n+    static void load_on_restore();\n+#ifdef ASSERT\n+    static void assert_mem(void *addr, size_t used, size_t total);\n+    static void assert_gap(void *addr, size_t length);\n+#endif \/\/ ASSERT\n+  private:\n+    static bool unmap(void *addr, size_t length);\n+    static bool map(void *addr, size_t length, int fd, size_t offset, bool executable);\n+    static bool map_gap(void *addr, size_t length);\n+  };\n+\n+  static void before_threads_persisted();\n+  static void after_threads_restored();\n+\n@@ -60,0 +111,15 @@\n+class CountThreadsClosure: public ThreadClosure {\n+private:\n+  size_t _count;\n+public:\n+  CountThreadsClosure(): _count(0) {}\n+\n+  void do_thread(Thread* t) {\n+    ++_count;\n+  }\n+\n+  size_t count() {\n+    return _count;\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/crac.hpp","additions":66,"deletions":0,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -2023,0 +2023,3 @@\n+  product(bool, CRPersistMemory, true, DIAGNOSTIC, \"Persist\/load memory \"   \\\n+      \"from within the VM rather than relying on the C\/R engine.\")          \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include <stdbool.h>\n@@ -646,0 +647,7 @@\n+\/\/ Instead of waiting on the implicit futex that is located in the address\n+\/\/ space of the main Java thread stack we'll wait on a global condition here.\n+static pthread_mutex_t main_thread_mutex = PTHREAD_MUTEX_INITIALIZER;\n+static pthread_cond_t main_thread_cond = PTHREAD_COND_INITIALIZER;\n+static bool main_thread_done = false;\n+static int main_thread_result = 0;\n+\n@@ -650,1 +658,7 @@\n-    return (void*)(intptr_t)JavaMain(args);\n+    pthread_mutex_lock(&main_thread_mutex);\n+    main_thread_result = JavaMain(args);\n+    void *retval = (void*)(intptr_t) main_thread_result;\n+    main_thread_done = true;\n+    pthread_cond_signal(&main_thread_cond);\n+    pthread_mutex_unlock(&main_thread_mutex);\n+    return retval;\n@@ -676,1 +690,2 @@\n-    pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);\n+    \/\/ See main_thread_mutex\n+    pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);\n@@ -701,3 +716,9 @@\n-        void* tmp;\n-        pthread_join(tid, &tmp);\n-        rslt = (int)(intptr_t)tmp;\n+        for (;;) {\n+            pthread_mutex_lock(&main_thread_mutex);\n+            pthread_cond_wait(&main_thread_cond, &main_thread_mutex);\n+            if (main_thread_done) {\n+                break;\n+            }\n+            pthread_mutex_unlock(&main_thread_mutex);\n+        }\n+        rslt = main_thread_result;\n","filename":"src\/java.base\/unix\/native\/libjli\/java_md.c","additions":26,"deletions":5,"binary":false,"changes":31,"status":"modified"}]}