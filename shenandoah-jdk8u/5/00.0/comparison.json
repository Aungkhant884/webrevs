{"files":[{"patch":"@@ -228,0 +228,13 @@\n+\/\/ Ensure a valid Address (base + offset) to a stack-slot. If stack access is\n+\/\/ not encodable as a base + (immediate) offset, generate an explicit address\n+\/\/ calculation to hold the address in a temporary register.\n+Address LIR_Assembler::stack_slot_address(int index, uint size, Register tmp, int adjust) {\n+  precond(size == 4 || size == 8);\n+  Address addr = frame_map()->address_for_slot(index, adjust);\n+  precond(addr.getMode() == Address::base_plus_offset);\n+  precond(addr.base() == sp);\n+  precond(addr.offset() > 0);\n+  uint mask = size - 1;\n+  assert((addr.offset() & mask) == 0, \"scaled offsets only\");\n+  return __ legitimize_address(addr, size, tmp);\n+}\n@@ -793,0 +806,5 @@\n+  precond(src->is_register() && dest->is_stack());\n+\n+  uint const c_sz32 = sizeof(uint32_t);\n+  uint const c_sz64 = sizeof(uint64_t);\n+\n@@ -794,0 +812,1 @@\n+    int index = dest->single_stack_ix();\n@@ -795,1 +814,1 @@\n-      __ str(src->as_register(), frame_map()->address_for_slot(dest->single_stack_ix()));\n+      __ str(src->as_register(), stack_slot_address(index, c_sz64, rscratch1));\n@@ -798,1 +817,1 @@\n-      __ str(src->as_register(), frame_map()->address_for_slot(dest->single_stack_ix()));\n+      __ str(src->as_register(), stack_slot_address(index, c_sz64, rscratch1));\n@@ -800,1 +819,1 @@\n-      __ strw(src->as_register(), frame_map()->address_for_slot(dest->single_stack_ix()));\n+      __ strw(src->as_register(), stack_slot_address(index, c_sz32, rscratch1));\n@@ -804,1 +823,2 @@\n-    Address dest_addr_LO = frame_map()->address_for_slot(dest->double_stack_ix(), lo_word_offset_in_bytes);\n+    int index = dest->double_stack_ix();\n+    Address dest_addr_LO = stack_slot_address(index, c_sz64, rscratch1, lo_word_offset_in_bytes);\n@@ -808,2 +828,2 @@\n-    Address dest_addr = frame_map()->address_for_slot(dest->single_stack_ix());\n-    __ strs(src->as_float_reg(), dest_addr);\n+    int index = dest->single_stack_ix();\n+    __ strs(src->as_float_reg(), stack_slot_address(index, c_sz32, rscratch1));\n@@ -812,2 +832,2 @@\n-    Address dest_addr = frame_map()->address_for_slot(dest->double_stack_ix());\n-    __ strd(src->as_double_reg(), dest_addr);\n+    int index = dest->double_stack_ix();\n+    __ strd(src->as_double_reg(), stack_slot_address(index, c_sz64, rscratch1));\n@@ -818,1 +838,0 @@\n-\n@@ -903,2 +922,4 @@\n-  assert(src->is_stack(), \"should not call otherwise\");\n-  assert(dest->is_register(), \"should not call otherwise\");\n+  precond(src->is_stack() && dest->is_register());\n+\n+  uint const c_sz32 = sizeof(uint32_t);\n+  uint const c_sz64 = sizeof(uint64_t);\n@@ -907,0 +928,1 @@\n+    int index = src->single_stack_ix();\n@@ -908,1 +930,1 @@\n-      __ ldr(dest->as_register(), frame_map()->address_for_slot(src->single_stack_ix()));\n+      __ ldr(dest->as_register(), stack_slot_address(index, c_sz64, rscratch1));\n@@ -911,1 +933,1 @@\n-      __ ldr(dest->as_register(), frame_map()->address_for_slot(src->single_stack_ix()));\n+      __ ldr(dest->as_register(), stack_slot_address(index, c_sz64, rscratch1));\n@@ -913,1 +935,1 @@\n-      __ ldrw(dest->as_register(), frame_map()->address_for_slot(src->single_stack_ix()));\n+      __ ldrw(dest->as_register(), stack_slot_address(index, c_sz32, rscratch1));\n@@ -917,1 +939,2 @@\n-    Address src_addr_LO = frame_map()->address_for_slot(src->double_stack_ix(), lo_word_offset_in_bytes);\n+    int index = src->double_stack_ix();\n+    Address src_addr_LO = stack_slot_address(index, c_sz64, rscratch1, lo_word_offset_in_bytes);\n@@ -921,2 +944,2 @@\n-    Address src_addr = frame_map()->address_for_slot(src->single_stack_ix());\n-    __ ldrs(dest->as_float_reg(), src_addr);\n+    int index = src->single_stack_ix();\n+    __ ldrs(dest->as_float_reg(), stack_slot_address(index, c_sz32, rscratch1));\n@@ -925,2 +948,2 @@\n-    Address src_addr = frame_map()->address_for_slot(src->double_stack_ix());\n-    __ ldrd(dest->as_double_reg(), src_addr);\n+    int index = src->double_stack_ix();\n+    __ ldrd(dest->as_double_reg(), stack_slot_address(index, c_sz64, rscratch1));\n","filename":"hotspot\/src\/cpu\/aarch64\/vm\/c1_LIRAssembler_aarch64.cpp","additions":42,"deletions":19,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"asm\/assembler.hpp\"\n+#include \"asm\/assembler.inline.hpp\"\n@@ -140,0 +140,14 @@\n+  \/* Sometimes we get misaligned loads and stores, usually from Unsafe\n+     accesses, and these can exceed the offset range. *\/\n+  Address legitimize_address(const Address &a, int size, Register scratch) {\n+    if (a.getMode() == Address::base_plus_offset) {\n+      if (! Address::offset_ok_for_immed(a.offset(), exact_log2(size))) {\n+        block_comment(\"legitimize_address {\");\n+        lea(scratch, a);\n+        block_comment(\"} legitimize_address\");\n+        return Address(scratch);\n+      }\n+    }\n+    return a;\n+  }\n+\n","filename":"hotspot\/src\/cpu\/aarch64\/vm\/macroAssembler_aarch64.hpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1203,0 +1203,1 @@\n+  assert(depth <= SHRT_MAX, \"sanity\");\n","filename":"hotspot\/src\/share\/vm\/opto\/loopnode.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -353,1 +353,1 @@\n-  uint8 _nest;                  \/\/ Nesting depth\n+  uint16_t _nest;               \/\/ Nesting depth\n","filename":"hotspot\/src\/share\/vm\/opto\/loopnode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}