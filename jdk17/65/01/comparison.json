{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,0 +29,4 @@\n+#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/mutex.hpp\"\n+#include \"runtime\/mutexLocker.hpp\"\n+#include \"utilities\/debug.hpp\"\n@@ -71,0 +75,21 @@\n+\n+static volatile size_t last_used_in_bytes = 0;\n+\n+void SpaceCounters::update_used() {\n+  size_t new_used = _object_space->used_in_bytes();\n+  Atomic::store(&last_used_in_bytes, new_used);\n+  _used->set_value(new_used);\n+}\n+\n+jlong MutableSpaceUsedHelper::take_sample() {\n+  \/\/ Sampling may occur during GC, possibly while GC is updating the space.\n+  \/\/ The space can be in an inconsistent state during such an update.  We\n+  \/\/ don't want to block sampling for the duration of a GC.  Instead, skip\n+  \/\/ sampling in that case, using the last recorded value.\n+  assert(!Heap_lock->owned_by_self(), \"precondition\");\n+  if (Heap_lock->try_lock()) {\n+    Atomic::store(&last_used_in_bytes, _m->used_in_bytes());\n+    Heap_lock->unlock();\n+  }\n+  return Atomic::load(&last_used_in_bytes);\n+}\n","filename":"src\/hotspot\/share\/gc\/parallel\/spaceCounters.cpp","additions":26,"deletions":1,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -61,3 +61,1 @@\n-  inline void update_used() {\n-    _used->set_value(_object_space->used_in_bytes());\n-  }\n+  void update_used();\n@@ -80,3 +78,1 @@\n-    inline jlong take_sample() {\n-      return _m->used_in_bytes();\n-    }\n+    jlong take_sample() override;\n","filename":"src\/hotspot\/share\/gc\/parallel\/spaceCounters.hpp","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -75,0 +75,2 @@\n+static volatile size_t last_used_in_bytes = 0;\n+\n@@ -76,1 +78,3 @@\n-  _used->set_value(_space->used());\n+  size_t new_used = _space->used();\n+  Atomic::store(&last_used_in_bytes, new_used);\n+  _used->set_value(new_used);\n@@ -85,1 +89,10 @@\n-  return _space->used();\n+  \/\/ Sampling may occur during GC, possibly while GC is updating the space.\n+  \/\/ The space can be in an inconsistent state during such an update.  We\n+  \/\/ don't want to block sampling for the duration of a GC.  Instead, skip\n+  \/\/ sampling in that case, using the last recorded value.\n+  assert(!Heap_lock->owned_by_self(), \"precondition\");\n+  if (Heap_lock->try_lock()) {\n+    Atomic::store(&last_used_in_bytes, _space->used());\n+    Heap_lock->unlock();\n+  }\n+  return Atomic::load(&last_used_in_bytes);\n","filename":"src\/hotspot\/share\/gc\/serial\/cSpaceCounters.cpp","additions":15,"deletions":2,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -57,3 +57,3 @@\n-  virtual void update_capacity();\n-  virtual void update_used();\n-  virtual void update_all();\n+  void update_capacity();\n+  void update_used();\n+  void update_all();\n@@ -71,1 +71,1 @@\n-    jlong take_sample();\n+    jlong take_sample() override;\n","filename":"src\/hotspot\/share\/gc\/serial\/cSpaceCounters.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"}]}