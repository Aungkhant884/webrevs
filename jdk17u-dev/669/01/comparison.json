{"files":[{"patch":"@@ -479,0 +479,2 @@\n+        assert(offset_ok_for_immed(_offset, size),\n+               \"must be, was: \" INT64_FORMAT \", %d\", _offset, size);\n@@ -480,9 +482,8 @@\n-        if (_offset < 0 || _offset & mask)\n-          {\n-            i->f(0b00, 25, 24);\n-            i->f(0, 21), i->f(0b00, 11, 10);\n-            i->sf(_offset, 20, 12);\n-          } else {\n-            i->f(0b01, 25, 24);\n-            i->f(_offset >> size, 21, 10);\n-          }\n+        if (_offset < 0 || _offset & mask) {\n+          i->f(0b00, 25, 24);\n+          i->f(0, 21), i->f(0b00, 11, 10);\n+          i->sf(_offset, 20, 12);\n+        } else {\n+          i->f(0b01, 25, 24);\n+          i->f(_offset >> size, 21, 10);\n+        }\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":10,"deletions":9,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -33,1 +33,6 @@\n-\n+\/\/ Check if an offset is within the encoding range for LDR\/STR instructions\n+\/\/ with an immediate offset, either using unscaled signed 9-bits or, scaled\n+\/\/ unsigned 12-bits. We favour the scaled unsigned encoding for all aligned\n+\/\/ offsets (only using the signed 9-bit encoding for negative and unaligned\n+\/\/ offsets). As a precondition, 0 <= shift <= 4 is the log2(size), for the\n+\/\/ supported data widths, {1, 2, 4, 8, 16} bytes.\n@@ -35,0 +40,1 @@\n+  precond(shift < 5);\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.inline.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -190,8 +190,7 @@\n-  } else  {\n-    intptr_t addr_offset = intptr_t(addr->disp());\n-    if (Address::offset_ok_for_immed(addr_offset, addr->scale()))\n-      return Address(base, addr_offset, Address::lsl(addr->scale()));\n-    else {\n-      __ mov(tmp, addr_offset);\n-      return Address(base, tmp, Address::lsl(addr->scale()));\n-    }\n+  } else {\n+    assert(addr->scale() == 0,\n+           \"expected for immediate operand, was: %d\", addr->scale());\n+    ptrdiff_t offset = ptrdiff_t(addr->disp());\n+    \/\/ NOTE: Does not handle any 16 byte vector access.\n+    const uint type_size = type2aelembytes(addr->type(), true);\n+    return __ legitimize_address(Address(base, offset), type_size, tmp);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":7,"deletions":8,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -151,1 +151,1 @@\n-      large_disp += index->as_jint() << shift;\n+      large_disp += ((intx)index->as_jint()) << shift;\n@@ -197,1 +197,1 @@\n-    assert(Address::offset_ok_for_immed(large_disp, 0), \"must be\");\n+    assert(Address::offset_ok_for_immed(large_disp, shift), \"failed for large_disp: \" INTPTR_FORMAT \" and shift %d\", large_disp, shift);\n@@ -207,18 +207,1 @@\n-\n-  LIR_Address* addr;\n-  if (index_opr->is_constant()) {\n-    addr = new LIR_Address(array_opr,\n-                           offset_in_bytes + (intx)(index_opr->as_jint()) * elem_size, type);\n-  } else {\n-    if (offset_in_bytes) {\n-      LIR_Opr tmp = new_pointer_register();\n-      __ add(array_opr, LIR_OprFact::intConst(offset_in_bytes), tmp);\n-      array_opr = tmp;\n-      offset_in_bytes = 0;\n-    }\n-    addr =  new LIR_Address(array_opr,\n-                            index_opr,\n-                            LIR_Address::scale(type),\n-                            offset_in_bytes, type);\n-  }\n-  return addr;\n+  return generate_address(array_opr, index_opr, shift, offset_in_bytes, type);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":3,"deletions":20,"binary":false,"changes":23,"status":"modified"}]}