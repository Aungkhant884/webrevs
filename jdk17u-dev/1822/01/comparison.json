{"files":[{"patch":"@@ -672,5 +672,1 @@\n-  const NMT_TrackingLevel level = MemTracker::tracking_level();\n-  const size_t nmt_overhead =\n-      MemTracker::malloc_header_size(level) + MemTracker::malloc_footer_size(level);\n-\n-  const size_t outer_size = size + nmt_overhead;\n+  const size_t outer_size = size + MemTracker::overhead_per_malloc();\n@@ -683,1 +679,1 @@\n-  void* const outer_ptr = (u_char*)::malloc(outer_size);\n+  void* const outer_ptr = ::malloc(outer_size);\n@@ -688,1 +684,1 @@\n-  void* inner_ptr = MemTracker::record_malloc((address)outer_ptr, size, memflags, stack, level);\n+  void* const inner_ptr = MemTracker::record_malloc((address)outer_ptr, size, memflags, stack);\n@@ -727,5 +723,1 @@\n-  const NMT_TrackingLevel level = MemTracker::tracking_level();\n-  const size_t nmt_overhead =\n-      MemTracker::malloc_header_size(level) + MemTracker::malloc_footer_size(level);\n-\n-  const size_t new_outer_size = size + nmt_overhead;\n+  const size_t new_outer_size = size + MemTracker::overhead_per_malloc();\n@@ -734,1 +726,1 @@\n-  void* const old_outer_ptr = MemTracker::record_free(memblock, level);\n+  void* const old_outer_ptr = MemTracker::record_free(memblock);\n@@ -737,0 +729,3 @@\n+  if (new_outer_ptr == NULL) {\n+    return NULL;\n+  }\n@@ -738,2 +733,1 @@\n-  \/\/ If NMT is enabled, this checks for heap overwrites, then de-accounts the old block.\n-  void* const new_inner_ptr = MemTracker::record_malloc(new_outer_ptr, size, memflags, stack, level);\n+  void* const new_inner_ptr = MemTracker::record_malloc(new_outer_ptr, size, memflags, stack);\n@@ -760,2 +754,0 @@\n-  const NMT_TrackingLevel level = MemTracker::tracking_level();\n-\n@@ -763,1 +755,2 @@\n-  void* const old_outer_ptr = MemTracker::record_free(memblock, level);\n+  void* const old_outer_ptr = MemTracker::record_free(memblock);\n+\n","filename":"src\/hotspot\/share\/runtime\/os.cpp","additions":11,"deletions":18,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -109,2 +109,1 @@\n-MallocSite* MallocSiteTable::lookup_or_add(const NativeCallStack& key, size_t* bucket_idx,\n-  size_t* pos_idx, MEMFLAGS flags) {\n+MallocSite* MallocSiteTable::lookup_or_add(const NativeCallStack& key, uint32_t* marker, MEMFLAGS flags) {\n@@ -114,2 +113,1 @@\n-  *bucket_idx = (size_t)index;\n-  *pos_idx = 0;\n+  *marker = 0;\n@@ -125,0 +123,1 @@\n+      *marker = build_marker(index, 0);\n@@ -131,0 +130,1 @@\n+  unsigned pos_idx = 0;\n@@ -132,1 +132,1 @@\n-  while (head != NULL && (*pos_idx) <= MAX_BUCKET_LENGTH) {\n+  while (head != NULL && pos_idx < MAX_BUCKET_LENGTH) {\n@@ -136,0 +136,1 @@\n+        *marker = build_marker(index, pos_idx);\n@@ -140,1 +141,1 @@\n-    if (head->next() == NULL && (*pos_idx) < MAX_BUCKET_LENGTH) {\n+    if (head->next() == NULL && pos_idx < (MAX_BUCKET_LENGTH - 1)) {\n@@ -145,1 +146,2 @@\n-        (*pos_idx) ++;\n+        pos_idx ++;\n+        *marker = build_marker(index, pos_idx);\n@@ -152,1 +154,1 @@\n-    (*pos_idx) ++;\n+    pos_idx ++;\n@@ -158,1 +160,2 @@\n-MallocSite* MallocSiteTable::malloc_site(size_t bucket_idx, size_t pos_idx) {\n+MallocSite* MallocSiteTable::malloc_site(uint32_t marker) {\n+  uint16_t bucket_idx = bucket_idx_from_marker(marker);\n@@ -160,0 +163,1 @@\n+  const uint16_t pos_idx = pos_idx_from_marker(marker);\n","filename":"src\/hotspot\/share\/services\/mallocSiteTable.cpp","additions":13,"deletions":9,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -52,0 +52,2 @@\n+  \/\/ Peak memory ever allocated from this code path\n+  size_t peak_size()  const { return _c.peak_size(); }\n@@ -54,0 +56,2 @@\n+\n+  const MemoryCounter* counter() const { return &_c; }\n@@ -117,2 +121,5 @@\n-  \/\/ The table must not be wider than the maximum value the bucket_idx field\n-  \/\/ in the malloc header can hold.\n+  \/\/ Table cannot be wider than a 16bit bucket idx can hold\n+#define MAX_MALLOCSITE_TABLE_SIZE (USHRT_MAX - 1)\n+  \/\/ Each bucket chain cannot be longer than what a 16 bit pos idx can hold (hopefully way shorter)\n+#define MAX_BUCKET_LENGTH         (USHRT_MAX - 1)\n+\n@@ -121,0 +128,7 @@\n+  static uint32_t build_marker(unsigned bucket_idx, unsigned pos_idx) {\n+    assert(bucket_idx <= MAX_MALLOCSITE_TABLE_SIZE && pos_idx < MAX_BUCKET_LENGTH, \"overflow\");\n+    return (uint32_t)bucket_idx << 16 | pos_idx;\n+  }\n+  static uint16_t bucket_idx_from_marker(uint32_t marker) { return marker >> 16; }\n+  static uint16_t pos_idx_from_marker(uint32_t marker) { return marker & 0xFFFF; }\n+\n@@ -122,0 +136,1 @@\n+\n@@ -129,3 +144,2 @@\n-  static inline bool access_stack(NativeCallStack& stack, size_t bucket_idx,\n-    size_t pos_idx) {\n-    MallocSite* site = malloc_site(bucket_idx, pos_idx);\n+  static inline bool access_stack(NativeCallStack& stack, uint32_t marker) {\n+    MallocSite* site = malloc_site(marker);\n@@ -140,3 +154,2 @@\n-  \/\/ Return true if the allocation is recorded successfully, bucket_idx\n-  \/\/ and pos_idx are also updated to indicate the entry where the allocation\n-  \/\/ information was recorded.\n+  \/\/ Return true if the allocation is recorded successfully and updates marker\n+  \/\/ to indicate the entry where the allocation information was recorded.\n@@ -147,2 +160,2 @@\n-    size_t* bucket_idx, size_t* pos_idx, MEMFLAGS flags) {\n-    MallocSite* site = lookup_or_add(stack, bucket_idx, pos_idx, flags);\n+      uint32_t* marker, MEMFLAGS flags) {\n+    MallocSite* site = lookup_or_add(stack, marker, flags);\n@@ -153,1 +166,1 @@\n-  \/\/ Record memory deallocation. bucket_idx and pos_idx indicate where the allocation\n+  \/\/ Record memory deallocation. marker indicates where the allocation\n@@ -155,2 +168,2 @@\n-  static inline bool deallocation_at(size_t size, size_t bucket_idx, size_t pos_idx) {\n-    MallocSite* site = malloc_site(bucket_idx, pos_idx);\n+  static inline bool deallocation_at(size_t size, uint32_t marker) {\n+    MallocSite* site = malloc_site(marker);\n@@ -176,2 +189,2 @@\n-  static MallocSite* lookup_or_add(const NativeCallStack& key, size_t* bucket_idx, size_t* pos_idx, MEMFLAGS flags);\n-  static MallocSite* malloc_site(size_t bucket_idx, size_t pos_idx);\n+  static MallocSite* lookup_or_add(const NativeCallStack& key, uint32_t* marker, MEMFLAGS flags);\n+  static MallocSite* malloc_site(uint32_t marker);\n","filename":"src\/hotspot\/share\/services\/mallocSiteTable.hpp","additions":28,"deletions":15,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"runtime\/atomic.hpp\"\n@@ -29,1 +30,0 @@\n-#include \"services\/mallocTracker.inline.hpp\"\n@@ -37,11 +37,1 @@\n-void MemoryCounter::update_peak_count(size_t count) {\n-  size_t peak_cnt = peak_count();\n-  while (peak_cnt < count) {\n-    size_t old_cnt = Atomic::cmpxchg(&_peak_count, peak_cnt, count, memory_order_relaxed);\n-    if (old_cnt != peak_cnt) {\n-      peak_cnt = old_cnt;\n-    }\n-  }\n-}\n-\n-void MemoryCounter::update_peak_size(size_t sz) {\n+void MemoryCounter::update_peak(size_t size, size_t cnt) {\n@@ -49,3 +39,7 @@\n-  while (peak_sz < sz) {\n-    size_t old_sz = Atomic::cmpxchg(&_peak_size, peak_sz, sz, memory_order_relaxed);\n-    if (old_sz != peak_sz) {\n+  while (peak_sz < size) {\n+    size_t old_sz = Atomic::cmpxchg(&_peak_size, peak_sz, size, memory_order_relaxed);\n+    if (old_sz == peak_sz) {\n+      \/\/ I won\n+      _peak_count = cnt;\n+      break;\n+    } else {\n@@ -56,28 +50,1 @@\n-\n-size_t MemoryCounter::peak_count() const {\n-  return Atomic::load(&_peak_count);\n-}\n-\n-size_t MemoryCounter::peak_size() const {\n-  return Atomic::load(&_peak_size);\n-}\n-#endif\n-\n-\/\/ Total malloc invocation count\n-size_t MallocMemorySnapshot::total_count() const {\n-  size_t amount = 0;\n-  for (int index = 0; index < mt_number_of_types; index ++) {\n-    amount += _malloc[index].malloc_count();\n-  }\n-  return amount;\n-}\n-\n-\/\/ Total malloc'd memory amount\n-size_t MallocMemorySnapshot::total() const {\n-  size_t amount = 0;\n-  for (int index = 0; index < mt_number_of_types; index ++) {\n-    amount += _malloc[index].malloc_size();\n-  }\n-  amount += _tracking_header.size() + total_arena();\n-  return amount;\n-}\n+#endif \/\/ ASSERT\n@@ -100,0 +67,1 @@\n+  _all_mallocs.deallocate(arena_size);\n@@ -115,14 +83,0 @@\n-void MallocHeader::release() {\n-  assert(MemTracker::enabled(), \"Sanity\");\n-\n-  check_block_integrity();\n-\n-  MallocMemorySummary::record_free(size(), flags());\n-  MallocMemorySummary::record_free_malloc_header(sizeof(MallocHeader));\n-  if (MemTracker::tracking_level() == NMT_detail) {\n-    MallocSiteTable::deallocation_at(size(), _bucket_idx, _pos_idx);\n-  }\n-\n-  mark_block_as_dead();\n-}\n-\n@@ -222,5 +176,0 @@\n-bool MallocHeader::record_malloc_site(const NativeCallStack& stack, size_t size,\n-  size_t* bucket_idx, size_t* pos_idx, MEMFLAGS flags) const {\n-  return MallocSiteTable::allocation_at(stack, size, bucket_idx, pos_idx, flags);\n-}\n-\n@@ -228,1 +177,1 @@\n-  return MallocSiteTable::access_stack(stack, _bucket_idx, _pos_idx);\n+  return MallocSiteTable::access_stack(stack, _mst_marker);\n@@ -244,4 +193,4 @@\n-  const NativeCallStack& stack, NMT_TrackingLevel level) {\n-  assert(level != NMT_off, \"precondition\");\n-  void*         memblock;      \/\/ the address for user data\n-  MallocHeader* header = NULL;\n+  const NativeCallStack& stack)\n+{\n+  assert(MemTracker::enabled(), \"precondition\");\n+  assert(malloc_base != NULL, \"precondition\");\n@@ -249,2 +198,4 @@\n-  if (malloc_base == NULL) {\n-    return NULL;\n+  MallocMemorySummary::record_malloc(size, flags);\n+  uint32_t mst_marker = 0;\n+  if (MemTracker::tracking_level() == NMT_detail) {\n+    MallocSiteTable::allocation_at(stack, size, &mst_marker, flags);\n@@ -254,3 +205,2 @@\n-\n-  header = ::new (malloc_base)MallocHeader(size, flags, stack, level);\n-  memblock = (void*)((char*)malloc_base + sizeof(MallocHeader));\n+  MallocHeader* const header = ::new (malloc_base)MallocHeader(size, flags, stack, mst_marker);\n+  void* const memblock = (void*)((char*)malloc_base + sizeof(MallocHeader));\n@@ -263,4 +213,6 @@\n-  if (level > NMT_off) {\n-    \/\/ Read back\n-    assert(get_size(memblock) == size,   \"Wrong size\");\n-    assert(get_flags(memblock) == flags, \"Wrong flags\");\n+  \/\/ Read back\n+  {\n+    MallocHeader* const header2 = malloc_header(memblock);\n+    assert(header2->size() == size, \"Wrong size\");\n+    assert(header2->flags() == flags, \"Wrong flags\");\n+    header2->check_block_integrity();\n@@ -274,3 +226,13 @@\n-  assert(MemTracker::tracking_level() != NMT_off && memblock != NULL, \"precondition\");\n-  MallocHeader* header = malloc_header(memblock);\n-  header->release();\n+  assert(MemTracker::enabled(), \"Sanity\");\n+  assert(memblock != NULL, \"precondition\");\n+\n+  MallocHeader* const header = malloc_header(memblock);\n+  header->check_block_integrity();\n+\n+  MallocMemorySummary::record_free(header->size(), header->flags());\n+  if (MemTracker::tracking_level() == NMT_detail) {\n+    MallocSiteTable::deallocation_at(header->size(), header->mst_marker());\n+  }\n+\n+  header->mark_block_as_dead();\n+\n","filename":"src\/hotspot\/share\/services\/mallocTracker.cpp","additions":41,"deletions":79,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -46,2 +46,7 @@\n-  DEBUG_ONLY(volatile size_t   _peak_count;)\n-  DEBUG_ONLY(volatile size_t   _peak_size; )\n+#ifdef ASSERT\n+  \/\/ Peak size and count. Note: Peak count is the count at the point\n+  \/\/ peak size was reached, not the absolute highest peak count.\n+  volatile size_t _peak_count;\n+  volatile size_t _peak_size;\n+  void update_peak(size_t size, size_t cnt);\n+#endif \/\/ ASSERT\n@@ -59,1 +64,1 @@\n-      DEBUG_ONLY(update_peak_size(sum);)\n+      DEBUG_ONLY(update_peak(sum, cnt);)\n@@ -61,1 +66,0 @@\n-    DEBUG_ONLY(update_peak_count(cnt);)\n@@ -77,1 +81,1 @@\n-      DEBUG_ONLY(update_peak_size(sum);)\n+      DEBUG_ONLY(update_peak(sum, _count);)\n@@ -84,6 +88,7 @@\n-#ifdef ASSERT\n-  void update_peak_count(size_t cnt);\n-  void update_peak_size(size_t sz);\n-  size_t peak_count() const;\n-  size_t peak_size()  const;\n-#endif \/\/ ASSERT\n+  inline size_t peak_count() const {\n+    return DEBUG_ONLY(Atomic::load(&_peak_count)) NOT_DEBUG(0);\n+  }\n+\n+  inline size_t peak_size() const {\n+    return DEBUG_ONLY(Atomic::load(&_peak_size)) NOT_DEBUG(0);\n+  }\n@@ -126,0 +131,1 @@\n+  inline size_t malloc_peak_size()  const { return _malloc.peak_size(); }\n@@ -128,0 +134,1 @@\n+  inline size_t arena_peak_size()  const { return _arena.peak_size(); }\n@@ -130,2 +137,2 @@\n-  DEBUG_ONLY(inline const MemoryCounter& malloc_counter() const { return _malloc; })\n-  DEBUG_ONLY(inline const MemoryCounter& arena_counter()  const { return _arena;  })\n+  const MemoryCounter* malloc_counter() const { return &_malloc; }\n+  const MemoryCounter* arena_counter()  const { return &_arena;  }\n@@ -143,1 +150,1 @@\n-  MemoryCounter     _tracking_header;\n+  MemoryCounter     _all_mallocs;\n@@ -152,3 +159,1 @@\n-  inline MemoryCounter* malloc_overhead() {\n-    return &_tracking_header;\n-  }\n+  inline size_t malloc_overhead() const;\n@@ -157,1 +162,4 @@\n-  size_t total_count() const;\n+  size_t total_count() const {\n+    return _all_mallocs.count();\n+  }\n+\n@@ -159,1 +167,4 @@\n-  size_t total() const;\n+  size_t total() const {\n+    return _all_mallocs.size() + malloc_overhead() + total_arena();\n+  }\n+\n@@ -173,1 +184,1 @@\n-    s->_tracking_header = _tracking_header;\n+    s->_all_mallocs = _all_mallocs;\n@@ -197,0 +208,1 @@\n+     as_snapshot()->_all_mallocs.allocate(size);\n@@ -201,0 +213,1 @@\n+     as_snapshot()->_all_mallocs.deallocate(size);\n@@ -220,9 +233,0 @@\n-   \/\/ Record memory used by malloc tracking header\n-   static inline void record_new_malloc_header(size_t sz) {\n-     as_snapshot()->malloc_overhead()->allocate(sz);\n-   }\n-\n-   static inline void record_free_malloc_header(size_t sz) {\n-     as_snapshot()->malloc_overhead()->deallocate(sz);\n-   }\n-\n@@ -231,1 +235,1 @@\n-     return as_snapshot()->malloc_overhead()->size();\n+     return as_snapshot()->malloc_overhead();\n@@ -270,1 +274,1 @@\n- *  ...  |   bucket idx    |     pos idx     | flags  | unused |     canary      |  ... User payload ....\n+ *  ...  |   malloc site table marker        | flags  | unused |     canary      |  ... User payload ....\n@@ -282,1 +286,1 @@\n- *  ...  |   bucket idx    |     pos idx     | flags  | unused |     canary      |  ... User payload ....\n+ *  ...  |   malloc site table marker        | flags  | unused |     canary      |  ... User payload ....\n@@ -297,5 +301,4 @@\n-  size_t _size;\n-  uint16_t _bucket_idx;\n-  uint16_t _pos_idx;\n-  uint8_t _flags;\n-  uint8_t _unused;\n+  const size_t _size;\n+  const uint32_t _mst_marker;\n+  const uint8_t _flags;\n+  const uint8_t _unused;\n@@ -304,3 +307,0 @@\n-#define MAX_MALLOCSITE_TABLE_SIZE (USHRT_MAX - 1)\n-#define MAX_BUCKET_LENGTH         (USHRT_MAX - 1)\n-\n@@ -317,4 +317,0 @@\n-  \/\/ Check block integrity. If block is broken, print out a report\n-  \/\/ to tty (optionally with hex dump surrounding the broken block),\n-  \/\/ then trigger a fatal error.\n-  void check_block_integrity() const;\n@@ -322,1 +318,0 @@\n-  void mark_block_as_dead();\n@@ -332,1 +327,4 @@\n-  MallocHeader(size_t size, MEMFLAGS flags, const NativeCallStack& stack, NMT_TrackingLevel level) {\n+  MallocHeader(size_t size, MEMFLAGS flags, const NativeCallStack& stack, uint32_t mst_marker)\n+    : _size(size), _mst_marker(mst_marker), _flags(NMTUtil::flag_to_index(flags)),\n+      _unused(0), _canary(_header_canary_life_mark)\n+  {\n@@ -334,16 +332,0 @@\n-\n-    _flags = NMTUtil::flag_to_index(flags);\n-    set_size(size);\n-    if (level == NMT_detail) {\n-      size_t bucket_idx;\n-      size_t pos_idx;\n-      if (record_malloc_site(stack, size, &bucket_idx, &pos_idx, flags)) {\n-        assert(bucket_idx <= MAX_MALLOCSITE_TABLE_SIZE, \"Overflow bucket index\");\n-        assert(pos_idx <= MAX_BUCKET_LENGTH, \"Overflow bucket position index\");\n-        _bucket_idx = (uint16_t)bucket_idx;\n-        _pos_idx = (uint16_t)pos_idx;\n-      }\n-    }\n-\n-    _unused = 0;\n-    _canary = _header_canary_life_mark;\n@@ -354,3 +336,0 @@\n-\n-    MallocMemorySummary::record_malloc(size, flags);\n-    MallocMemorySummary::record_new_malloc_header(sizeof(MallocHeader));\n@@ -361,0 +340,1 @@\n+  inline uint32_t mst_marker() const { return _mst_marker; }\n@@ -363,2 +343,1 @@\n-  \/\/ Cleanup tracking information and mark block as dead before the memory is released.\n-  void release();\n+  void mark_block_as_dead();\n@@ -366,6 +345,4 @@\n- private:\n-  inline void set_size(size_t size) {\n-    _size = size;\n-  }\n-  bool record_malloc_site(const NativeCallStack& stack, size_t size,\n-    size_t* bucket_idx, size_t* pos_idx, MEMFLAGS flags) const;\n+  \/\/ Check block integrity. If block is broken, print out a report\n+  \/\/ to tty (optionally with hex dump surrounding the broken block),\n+  \/\/ then trigger a fatal error.\n+  void check_block_integrity() const;\n@@ -374,0 +351,4 @@\n+size_t MallocMemorySnapshot::malloc_overhead() const {\n+  return _all_mallocs.count() * sizeof(MallocHeader);\n+}\n+\n@@ -384,9 +365,3 @@\n-  \/\/ malloc tracking header size for specific tracking level\n-  static inline size_t malloc_header_size(NMT_TrackingLevel level) {\n-    return (level == NMT_off) ? 0 : sizeof(MallocHeader);\n-  }\n-\n-  \/\/ malloc tracking footer size for specific tracking level\n-  static inline size_t malloc_footer_size(NMT_TrackingLevel level) {\n-    return (level == NMT_off) ? 0 : sizeof(uint16_t);\n-  }\n+  \/\/ The overhead that is incurred by switching on NMT (we need, per malloc allocation,\n+  \/\/ space for header and 16-bit footer)\n+  static const size_t overhead_per_malloc = sizeof(MallocHeader) + sizeof(uint16_t);\n@@ -404,1 +379,1 @@\n-    const NativeCallStack& stack, NMT_TrackingLevel level);\n+    const NativeCallStack& stack);\n@@ -409,19 +384,0 @@\n-  \/\/ Offset memory address to header address\n-  static inline void* get_base(void* memblock);\n-  static inline void* get_base(void* memblock, NMT_TrackingLevel level) {\n-    if (memblock == NULL || level == NMT_off) return memblock;\n-    return (char*)memblock - malloc_header_size(level);\n-  }\n-\n-  \/\/ Get memory size\n-  static inline size_t get_size(void* memblock) {\n-    MallocHeader* header = malloc_header(memblock);\n-    return header->size();\n-  }\n-\n-  \/\/ Get memory type\n-  static inline MEMFLAGS get_flags(void* memblock) {\n-    MallocHeader* header = malloc_header(memblock);\n-    return header->flags();\n-  }\n-\n@@ -442,2 +398,5 @@\n-    MallocHeader* header = (MallocHeader*)((char*)memblock - sizeof(MallocHeader));\n-    return header;\n+    return (MallocHeader*)((char*)memblock - sizeof(MallocHeader));\n+  }\n+  static inline const MallocHeader* malloc_header(const void *memblock) {\n+    assert(memblock != NULL, \"NULL pointer\");\n+    return (const MallocHeader*)((const char*)memblock - sizeof(MallocHeader));\n","filename":"src\/hotspot\/share\/services\/mallocTracker.hpp","additions":63,"deletions":104,"binary":false,"changes":167,"status":"modified"},{"patch":"@@ -1,36 +0,0 @@\n-\/*\n- * Copyright (c) 2014, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_SERVICES_MALLOCTRACKER_INLINE_HPP\n-#define SHARE_SERVICES_MALLOCTRACKER_INLINE_HPP\n-\n-#include \"services\/mallocTracker.hpp\"\n-\n-#include \"services\/memTracker.hpp\"\n-\n-inline void* MallocTracker::get_base(void* memblock){\n-  return get_base(memblock, MemTracker::tracking_level());\n-}\n-\n-#endif \/\/ SHARE_SERVICES_MALLOCTRACKER_INLINE_HPP\n","filename":"src\/hotspot\/share\/services\/mallocTracker.inline.hpp","additions":0,"deletions":36,"binary":false,"changes":36,"status":"deleted"},{"patch":"@@ -145,1 +145,1 @@\n-    return bl->_malloc_memory_snapshot.malloc_overhead()->size();\n+    return bl->_malloc_memory_snapshot.malloc_overhead();\n","filename":"src\/hotspot\/share\/services\/memBaseline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-void MemReporterBase::print_malloc(size_t amount, size_t count, MEMFLAGS flag) const {\n+void MemReporterBase::print_malloc(const MemoryCounter* c, MEMFLAGS flag) const {\n@@ -53,0 +53,3 @@\n+  const size_t amount = c->size();\n+  const size_t count = c->count();\n+\n@@ -61,0 +64,1 @@\n+  \/\/ blends out mtChunk count number\n@@ -66,0 +70,9 @@\n+\n+  size_t pk_amount = c->peak_size();\n+  if (pk_amount == amount) {\n+    out->print_raw(\" (at peak)\");\n+  } else if (pk_amount > amount) {\n+    size_t pk_count = c->peak_count();\n+    out->print(\" (peak=\" SIZE_FORMAT \"%s #\" SIZE_FORMAT \")\",\n+        amount_in_current_scale(pk_amount), scale, pk_count);\n+  }\n@@ -74,1 +87,1 @@\n-void MemReporterBase::print_malloc_line(size_t amount, size_t count) const {\n+void MemReporterBase::print_malloc_line(const MemoryCounter* c) const {\n@@ -76,1 +89,1 @@\n-  print_malloc(amount, count);\n+  print_malloc(c);\n@@ -86,1 +99,1 @@\n-void MemReporterBase::print_arena_line(size_t amount, size_t count) const {\n+void MemReporterBase::print_arena_line(const MemoryCounter* c) const {\n@@ -88,1 +101,6 @@\n-  output()->print_cr(\"%27s (arena=\" SIZE_FORMAT \"%s #\" SIZE_FORMAT \")\", \" \",\n+  outputStream* out = output();\n+\n+  const size_t amount = c->size();\n+  const size_t count = c->count();\n+\n+  out->print(\"%27s (arena=\" SIZE_FORMAT \"%s #\" SIZE_FORMAT \")\", \"\",\n@@ -90,0 +108,11 @@\n+\n+  size_t pk_amount = c->peak_size();\n+  if (pk_amount == amount) {\n+    out->print_raw(\" (at peak)\");\n+  } else if (pk_amount > amount) {\n+    size_t pk_count = c->peak_count();\n+    out->print(\" (peak=\" SIZE_FORMAT \"%s #\" SIZE_FORMAT \")\",\n+        amount_in_current_scale(pk_amount), scale, pk_count);\n+  }\n+\n+  out->cr();\n@@ -160,2 +189,2 @@\n-    reserved_amount  += _malloc_snapshot->malloc_overhead()->size();\n-    committed_amount += _malloc_snapshot->malloc_overhead()->size();\n+    reserved_amount  += _malloc_snapshot->malloc_overhead();\n+    committed_amount += _malloc_snapshot->malloc_overhead();\n@@ -198,4 +227,3 @@\n-    if (amount_in_current_scale(malloc_memory->malloc_size()) > 0) {\n-      \/\/ We don't know how many arena chunks are in used, so don't report the count\n-      size_t count = (flag == mtChunk) ? 0 : malloc_memory->malloc_count();\n-      print_malloc_line(malloc_memory->malloc_size(), count);\n+    if (amount_in_current_scale(malloc_memory->malloc_size()) > 0\n+        DEBUG_ONLY(|| amount_in_current_scale(malloc_memory->malloc_peak_size()) > 0)) {\n+      print_malloc_line(malloc_memory->malloc_counter());\n@@ -208,2 +236,3 @@\n-    if (amount_in_current_scale(malloc_memory->arena_size()) > 0) {\n-      print_arena_line(malloc_memory->arena_size(), malloc_memory->arena_count());\n+    if (amount_in_current_scale(malloc_memory->arena_size()) > 0\n+        DEBUG_ONLY(|| amount_in_current_scale(malloc_memory->arena_peak_size()) > 0)) {\n+      print_arena_line(malloc_memory->arena_counter());\n@@ -213,1 +242,1 @@\n-      amount_in_current_scale(_malloc_snapshot->malloc_overhead()->size()) > 0) {\n+      amount_in_current_scale(_malloc_snapshot->malloc_overhead()) > 0) {\n@@ -215,1 +244,1 @@\n-        amount_in_current_scale(_malloc_snapshot->malloc_overhead()->size()), scale);\n+        amount_in_current_scale(_malloc_snapshot->malloc_overhead()), scale);\n@@ -274,6 +303,3 @@\n-    \/\/ Don't report free sites; does not count toward omitted count.\n-    if (malloc_site->size() == 0) {\n-      continue;\n-    }\n-    \/\/ Don't report if site has allocated less than one unit of whatever our scale is\n-    if (scale() > 1 && amount_in_current_scale(malloc_site->size()) == 0) {\n+    \/\/ Don't report if site has never allocated less than one unit of whatever our scale is\n+    if (scale() > 1 && amount_in_current_scale(malloc_site->size()) == 0\n+                       DEBUG_ONLY(&& amount_in_current_scale(malloc_site->peak_size()) == 0)) {\n@@ -289,1 +315,1 @@\n-    print_malloc(malloc_site->size(), malloc_site->count(),flag);\n+    print_malloc(malloc_site->counter(), flag);\n","filename":"src\/hotspot\/share\/services\/memReporter.cpp","additions":48,"deletions":22,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -85,1 +85,1 @@\n-  void print_malloc(size_t amount, size_t count, MEMFLAGS flag = mtNone) const;\n+  void print_malloc(const MemoryCounter* c, MEMFLAGS flag = mtNone) const;\n@@ -88,1 +88,1 @@\n-  void print_malloc_line(size_t amount, size_t count) const;\n+  void print_malloc_line(const MemoryCounter* c) const;\n@@ -90,1 +90,1 @@\n-  void print_arena_line(size_t amount, size_t count) const;\n+  void print_arena_line(const MemoryCounter* c) const;\n","filename":"src\/hotspot\/share\/services\/memReporter.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-#include \"services\/mallocTracker.inline.hpp\"\n+#include \"services\/mallocTracker.hpp\"\n@@ -93,4 +93,0 @@\n-void* MemTracker::malloc_base(void* memblock) {\n-  return MallocTracker::get_base(memblock);\n-}\n-\n","filename":"src\/hotspot\/share\/services\/memTracker.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"utilities\/debug.hpp\"\n@@ -53,0 +54,1 @@\n+  static size_t overhead_per_malloc() { return 0; }\n@@ -58,1 +60,1 @@\n-    const NativeCallStack& stack, NMT_TrackingLevel level) { return mem_base; }\n+    const NativeCallStack& stack) { return mem_base; }\n@@ -63,1 +65,1 @@\n-  static inline void* record_free(void* memblock, NMT_TrackingLevel level) { return memblock; }\n+  static inline void* record_free(void* memblock) { return memblock; }\n@@ -144,0 +146,5 @@\n+  \/\/ Per-malloc overhead incurred by NMT, depending on the current NMT level\n+  static size_t overhead_per_malloc() {\n+    return enabled() ? MallocTracker::overhead_per_malloc : 0;\n+  }\n+\n@@ -145,3 +152,4 @@\n-    const NativeCallStack& stack, NMT_TrackingLevel level) {\n-    if (level != NMT_off) {\n-      return MallocTracker::record_malloc(mem_base, size, flag, stack, level);\n+    const NativeCallStack& stack) {\n+    assert(mem_base != NULL, \"caller should handle NULL\");\n+    if (enabled()) {\n+      return MallocTracker::record_malloc(mem_base, size, flag, stack);\n@@ -152,14 +160,0 @@\n-  static inline size_t malloc_header_size(NMT_TrackingLevel level) {\n-    return MallocTracker::malloc_header_size(level);\n-  }\n-\n-  \/\/ malloc tracking footer size for specific tracking level\n-  static inline size_t malloc_footer_size(NMT_TrackingLevel level) {\n-    return MallocTracker::malloc_footer_size(level);\n-  }\n-\n-  \/\/ To malloc base address, which is the starting address\n-  \/\/ of malloc tracking header if tracking is enabled.\n-  \/\/ Otherwise, it returns the same address.\n-  static void* malloc_base(void* memblock);\n-\n@@ -167,1 +161,1 @@\n-  static inline void* record_free(void* memblock, NMT_TrackingLevel level) {\n+  static inline void* record_free(void* memblock) {\n@@ -169,1 +163,2 @@\n-    if (level == NMT_off || memblock == NULL) {\n+    assert(memblock != NULL, \"caller should handle NULL\");\n+    if (!enabled()) {\n@@ -175,1 +170,0 @@\n-\n","filename":"src\/hotspot\/share\/services\/memTracker.hpp","additions":16,"deletions":22,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -90,1 +90,1 @@\n-    assert(flag_is_valid(flag), \"Invalid flag\");\n+    assert(flag_is_valid(flag), \"Invalid flag (%u)\", (unsigned)flag);\n@@ -101,1 +101,1 @@\n-    assert(flag_index_is_valid(index), \"Invalid flag\");\n+    assert(flag_index_is_valid(index), \"Invalid flag index (%d)\", index);\n","filename":"src\/hotspot\/share\/services\/nmtCommon.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -479,0 +479,4 @@\n+  if (p == NULL) {\n+    tty->print_cr(\"NULL\");\n+    return;\n+  }\n","filename":"src\/hotspot\/share\/utilities\/debug.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"}]}