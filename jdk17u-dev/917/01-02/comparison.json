{"files":[{"patch":"@@ -3872,46 +3872,0 @@\n-void C2_MacroAssembler::rearrange_bytes(XMMRegister dst, XMMRegister shuffle, XMMRegister src, XMMRegister xtmp1,\n-                                        XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, KRegister ktmp,\n-                                        int vlen_enc) {\n-  assert(VM_Version::supports_avx512bw(), \"\");\n-  \/\/ Byte shuffles are inlane operations and indices are determined using\n-  \/\/ lower 4 bit of each shuffle lane, thus all shuffle indices are\n-  \/\/ normalized to index range 0-15. This makes sure that all the multiples\n-  \/\/ of an index value are placed at same relative position in 128 bit\n-  \/\/ lane i.e. elements corresponding to shuffle indices 16, 32 and 64\n-  \/\/ will be 16th element in their respective 128 bit lanes.\n-  movl(rtmp, 16);\n-  evpbroadcastb(xtmp1, rtmp, vlen_enc);\n-\n-  \/\/ Compute a mask for shuffle vector by comparing indices with expression INDEX < 16,\n-  \/\/ Broadcast first 128 bit lane across entire vector, shuffle the vector lanes using\n-  \/\/ original shuffle indices and move the shuffled lanes corresponding to true\n-  \/\/ mask to destination vector.\n-  evpcmpb(ktmp, k0, shuffle, xtmp1, Assembler::lt, true, vlen_enc);\n-  evshufi64x2(xtmp2, src, src, 0x0, vlen_enc);\n-  evpshufb(dst, ktmp, xtmp2, shuffle, false, vlen_enc);\n-\n-  \/\/ Perform above steps with lane comparison expression as INDEX >= 16 && INDEX < 32\n-  \/\/ and broadcasting second 128 bit lane.\n-  evpcmpb(ktmp, k0, shuffle,  xtmp1, Assembler::nlt, true, vlen_enc);\n-  vpsllq(xtmp2, xtmp1, 0x1, vlen_enc);\n-  evpcmpb(ktmp, ktmp, shuffle, xtmp2, Assembler::lt, true, vlen_enc);\n-  evshufi64x2(xtmp3, src, src, 0x55, vlen_enc);\n-  evpshufb(dst, ktmp, xtmp3, shuffle, true, vlen_enc);\n-\n-  \/\/ Perform above steps with lane comparison expression as INDEX >= 32 && INDEX < 48\n-  \/\/ and broadcasting third 128 bit lane.\n-  evpcmpb(ktmp, k0, shuffle,  xtmp2, Assembler::nlt, true, vlen_enc);\n-  vpaddb(xtmp1, xtmp1, xtmp2, vlen_enc);\n-  evpcmpb(ktmp, ktmp, shuffle,  xtmp1, Assembler::lt, true, vlen_enc);\n-  evshufi64x2(xtmp3, src, src, 0xAA, vlen_enc);\n-  evpshufb(dst, ktmp, xtmp3, shuffle, true, vlen_enc);\n-\n-  \/\/ Perform above steps with lane comparison expression as INDEX >= 48 && INDEX < 64\n-  \/\/ and broadcasting third 128 bit lane.\n-  evpcmpb(ktmp, k0, shuffle,  xtmp1, Assembler::nlt, true, vlen_enc);\n-  vpsllq(xtmp2, xtmp2, 0x1, vlen_enc);\n-  evpcmpb(ktmp, ktmp, shuffle,  xtmp2, Assembler::lt, true, vlen_enc);\n-  evshufi64x2(xtmp3, src, src, 0xFF, vlen_enc);\n-  evpshufb(dst, ktmp, xtmp3, shuffle, true, vlen_enc);\n-}\n-\n@@ -3971,0 +3925,46 @@\n+\n+void C2_MacroAssembler::rearrange_bytes(XMMRegister dst, XMMRegister shuffle, XMMRegister src, XMMRegister xtmp1,\n+                                        XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, KRegister ktmp,\n+                                        int vlen_enc) {\n+  assert(VM_Version::supports_avx512bw(), \"\");\n+  \/\/ Byte shuffles are inlane operations and indices are determined using\n+  \/\/ lower 4 bit of each shuffle lane, thus all shuffle indices are\n+  \/\/ normalized to index range 0-15. This makes sure that all the multiples\n+  \/\/ of an index value are placed at same relative position in 128 bit\n+  \/\/ lane i.e. elements corresponding to shuffle indices 16, 32 and 64\n+  \/\/ will be 16th element in their respective 128 bit lanes.\n+  movl(rtmp, 16);\n+  evpbroadcastb(xtmp1, rtmp, vlen_enc);\n+\n+  \/\/ Compute a mask for shuffle vector by comparing indices with expression INDEX < 16,\n+  \/\/ Broadcast first 128 bit lane across entire vector, shuffle the vector lanes using\n+  \/\/ original shuffle indices and move the shuffled lanes corresponding to true\n+  \/\/ mask to destination vector.\n+  evpcmpb(ktmp, k0, shuffle, xtmp1, Assembler::lt, true, vlen_enc);\n+  evshufi64x2(xtmp2, src, src, 0x0, vlen_enc);\n+  evpshufb(dst, ktmp, xtmp2, shuffle, false, vlen_enc);\n+\n+  \/\/ Perform above steps with lane comparison expression as INDEX >= 16 && INDEX < 32\n+  \/\/ and broadcasting second 128 bit lane.\n+  evpcmpb(ktmp, k0, shuffle,  xtmp1, Assembler::nlt, true, vlen_enc);\n+  vpsllq(xtmp2, xtmp1, 0x1, vlen_enc);\n+  evpcmpb(ktmp, ktmp, shuffle, xtmp2, Assembler::lt, true, vlen_enc);\n+  evshufi64x2(xtmp3, src, src, 0x55, vlen_enc);\n+  evpshufb(dst, ktmp, xtmp3, shuffle, true, vlen_enc);\n+\n+  \/\/ Perform above steps with lane comparison expression as INDEX >= 32 && INDEX < 48\n+  \/\/ and broadcasting third 128 bit lane.\n+  evpcmpb(ktmp, k0, shuffle,  xtmp2, Assembler::nlt, true, vlen_enc);\n+  vpaddb(xtmp1, xtmp1, xtmp2, vlen_enc);\n+  evpcmpb(ktmp, ktmp, shuffle,  xtmp1, Assembler::lt, true, vlen_enc);\n+  evshufi64x2(xtmp3, src, src, 0xAA, vlen_enc);\n+  evpshufb(dst, ktmp, xtmp3, shuffle, true, vlen_enc);\n+\n+  \/\/ Perform above steps with lane comparison expression as INDEX >= 48 && INDEX < 64\n+  \/\/ and broadcasting third 128 bit lane.\n+  evpcmpb(ktmp, k0, shuffle,  xtmp1, Assembler::nlt, true, vlen_enc);\n+  vpsllq(xtmp2, xtmp2, 0x1, vlen_enc);\n+  evpcmpb(ktmp, ktmp, shuffle,  xtmp2, Assembler::lt, true, vlen_enc);\n+  evshufi64x2(xtmp3, src, src, 0xFF, vlen_enc);\n+  evpshufb(dst, ktmp, xtmp3, shuffle, true, vlen_enc);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":46,"deletions":46,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -279,0 +279,1 @@\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}