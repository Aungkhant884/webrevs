{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -44,1 +44,1 @@\n-     * The MIME types of all supported media.\n+     * The MIME types of all supported media on Windows and Linux.\n@@ -58,0 +58,8 @@\n+    \/**\n+     * The MIME types of all supported media on macOS.\n+     *\/\n+    private static final String[] CONTENT_TYPES_MACOS = {\n+        \"audio\/x-aiff\",\n+        \"audio\/x-wav\"\n+    };\n+\n@@ -102,1 +110,5 @@\n-        return Arrays.copyOf(CONTENT_TYPES, CONTENT_TYPES.length);\n+        if (HostUtils.isMacOSX()) {\n+            return Arrays.copyOf(CONTENT_TYPES_MACOS, CONTENT_TYPES_MACOS.length);\n+        } else {\n+            return Arrays.copyOf(CONTENT_TYPES, CONTENT_TYPES.length);\n+        }\n","filename":"modules\/javafx.media\/src\/main\/java\/com\/sun\/media\/jfxmediaimpl\/platform\/gstreamer\/GSTPlatform.java","additions":15,"deletions":3,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2016, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -49,1 +49,2 @@\n-        osxCreatePlayer(mediaLocator.getStringLocation());\n+        osxCreatePlayer(mediaLocator, mediaLocator.getContentType(),\n+                mediaLocator.getContentLength());\n@@ -172,1 +173,3 @@\n-    private native void osxCreatePlayer(String sourceURI) throws MediaException;\n+    private native void osxCreatePlayer(Locator locator,\n+                                        String contentType,\n+                                        long sizeHint) throws MediaException;\n@@ -194,0 +197,1 @@\n+    private native boolean osxNeedsLocator() throws MediaException;\n","filename":"modules\/javafx.media\/src\/main\/java\/com\/sun\/media\/jfxmediaimpl\/platform\/osx\/OSXMediaPlayer.java","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -48,1 +48,0 @@\n-        \"audio\/x-aiff\",\n@@ -64,1 +63,3 @@\n-        \"https\"\n+        \"https\",\n+        \"jrt\",\n+        \"resource\"\n","filename":"modules\/javafx.media\/src\/main\/java\/com\/sun\/media\/jfxmediaimpl\/platform\/osx\/OSXPlatform.java","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1,1430 +0,0 @@\n-\/*\n- * Copyright (c) 2010, 2018, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#ifdef HAVE_CONFIG_H\n-#include <config.h>\n-#endif\n-\n-#include <stdio.h>\n-#include <fcntl.h>\n-#include <unistd.h>\n-#include <sys\/types.h>\n-#include <sys\/stat.h>\n-\n-#include \"audioconverter.h\"\n-\n-GST_DEBUG_CATEGORY_STATIC (audioconverter_debug);\n-#define GST_CAT_DEFAULT audioconverter_debug\n-\n-\/*\n- * The input capabilities.\n- *\/\n-#define AUDIOCONVERTER_SINK_CAPS \\\n-\"audio\/mpeg, \" \\\n-\"mpegversion = (int) 1, \" \\\n-\"layer = (int) [ 1, 3 ], \" \\\n-\"rate = (int) { 8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000 }, \" \\\n-\"channels = (int) [ 1, 2 ]; \" \\\n-\"audio\/mpeg, \" \\\n-\"mpegversion = (int) {2, 4}\"\n-\n-static GstStaticPadTemplate sink_factory =\n-GST_STATIC_PAD_TEMPLATE (\"sink\",\n-                         GST_PAD_SINK,\n-                         GST_PAD_ALWAYS,\n-                         GST_STATIC_CAPS (AUDIOCONVERTER_SINK_CAPS));\n-\n-\/*\n- * The output capabilities.\n- *\/\n-#define AUDIOCONVERTER_SRC_CAPS \\\n-\"audio\/x-raw, \" \\\n-\"format = (string) F32LE, \" \\\n-\"layout = (string) interleaved, \" \\\n-\"rate = (int) { 8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000 }, \" \\\n-\"channels = (int) [ 1, 2 ]\"\n-\n-static GstStaticPadTemplate src_factory =\n-GST_STATIC_PAD_TEMPLATE (\"src\",\n-                         GST_PAD_SRC,\n-                         GST_PAD_ALWAYS,\n-                         GST_STATIC_CAPS (AUDIOCONVERTER_SRC_CAPS));\n-\n-\/***********************************************************************************\n- * Substitution for\n- * G_DEFINE_TYPE (AudioConverter, audioconverter, GstElement, GST_TYPE_ELEMENT);\n- ***********************************************************************************\/\n-#define audioconverter_parent_class parent_class\n-static void audioconverter_init          (AudioConverter      *self);\n-static void audioconverter_class_init    (AudioConverterClass *klass);\n-static gpointer audioconverter_parent_class = NULL;\n-static void     audioconverter_class_intern_init (gpointer klass)\n-{\n-    audioconverter_parent_class = g_type_class_peek_parent (klass);\n-    audioconverter_class_init ((AudioConverterClass*) klass);\n-}\n-\n-GType audioconverter_get_type (void)\n-{\n-    static volatile gsize gonce_data = 0;\n-\/\/ INLINE - g_once_init_enter()\n-    if (g_once_init_enter (&gonce_data))\n-    {\n-        GType _type;\n-        _type = g_type_register_static_simple (GST_TYPE_ELEMENT,\n-               g_intern_static_string (\"AudioConverter\"),\n-               sizeof (AudioConverterClass),\n-               (GClassInitFunc) audioconverter_class_intern_init,\n-               sizeof(AudioConverter),\n-               (GInstanceInitFunc) audioconverter_init,\n-               (GTypeFlags) 0);\n-        g_once_init_leave (&gonce_data, (gsize) _type);\n-    }\n-    return (GType) gonce_data;\n-}\n-\n-\/*\n- * Forward declarations.\n- *\/\n-static GstStateChangeReturn audioconverter_change_state (GstElement* element,\n-                                                         GstStateChange transition);\n-static gboolean audioconverter_sink_event (GstPad * pad, GstObject *parent, GstEvent * event);\n-static GstFlowReturn audioconverter_chain (GstPad * pad, GstObject *parent, GstBuffer * buf);\n-static gboolean audioconverter_src_event (GstPad * pad, GstObject *parent, GstEvent * event);\n-static gboolean audioconverter_src_query (GstPad * pad, GstObject *parent, GstQuery* query);\n-static void audioconverter_state_init(AudioConverter *decode);\n-\n-static void initAudioFormatPCM(Float64 sampleRate, AudioStreamBasicDescription* outputFormat);\n-static void propertyListener(void *clientData,\n-                             AudioFileStreamID audioFileStream,\n-                             AudioFileStreamPropertyID propertyID,\n-                             UInt32 *flags);\n-static void packetListener(void *clientData,\n-                           UInt32 numberBytes,\n-                           UInt32 numberPackets,\n-                           const void *inputData,\n-                           AudioStreamPacketDescription  *packetDescriptions);\n-static OSStatus retrieveInputData(AudioConverterRef audioConverter,\n-                                  UInt32* numberDataPackets,\n-                                  AudioBufferList* bufferList,\n-                                  AudioStreamPacketDescription** dataPacketDescription,\n-                                  void* userData);\n-\n-\/* --- GObject vmethod implementations --- *\/\n-\n-\/*\n- * Initialize mpadec's class.\n- *\/\n-static void\n-audioconverter_class_init (AudioConverterClass * klass)\n-{\n-    GstElementClass *element_class = GST_ELEMENT_CLASS (klass);\n-\n-    gst_element_class_set_metadata(element_class,\n-        \"AudioConverter\",\n-        \"Codec\/Decoder\/Audio\",\n-        \"Decode raw MPEG audio stream to mono or stereo-interleaved PCM\",\n-        \"Oracle Corporation\");\n-\n-    gst_element_class_add_pad_template (element_class,\n-                                        gst_static_pad_template_get (&src_factory));\n-    gst_element_class_add_pad_template (element_class,\n-                                        gst_static_pad_template_get (&sink_factory));\n-\n-    element_class->change_state = audioconverter_change_state;\n-}\n-\n-\/*\n- * Initialize the new element.\n- * Instantiate pads and add them to element.\n- * Set pad calback functions.\n- * Initialize instance structure.\n- *\/\n-static void\n-audioconverter_init (AudioConverter * decode)\n-{\n-    \/\/ Input.\n-    decode->sinkpad = gst_pad_new_from_static_template (&sink_factory, \"sink\");\n-    if (FALSE == gst_element_add_pad (GST_ELEMENT (decode), decode->sinkpad))\n-        g_warning (\"audioconverter element failed to add sink pad!\\n\");\n-    gst_pad_set_chain_function (decode->sinkpad, GST_DEBUG_FUNCPTR(audioconverter_chain));\n-    gst_pad_set_event_function(decode->sinkpad, audioconverter_sink_event);\n-\n-    \/\/ Output.\n-    decode->srcpad = gst_pad_new_from_static_template (&src_factory, \"src\");\n-    if (TRUE != gst_element_add_pad (GST_ELEMENT (decode), decode->srcpad))\n-        g_warning (\"audioconverter element failed to add source pad!\\n\");\n-    gst_pad_set_event_function(decode->srcpad, audioconverter_src_event);\n-    gst_pad_set_query_function(decode->srcpad, audioconverter_src_query);\n-    gst_pad_use_fixed_caps (decode->srcpad);\n-}\n-\n-\/* --- GstElement vmethod implementations --- *\/\n-\n-\/**\n- * Initialize the AudioConverter structure. This should happen\n- * only once, before decoding begins.\n- *\/\n-static void\n-audioconverter_state_init(AudioConverter *decode)\n-{\n-    decode->packetDesc = NULL;\n-    decode->inputData = NULL;\n-\n-    decode->enable_parser = TRUE;\n-\n-    decode->sink_caps = NULL;\n-    decode->segment_event = NULL;\n-\n-    decode->audioStreamID = NULL;\n-\n-    decode->cookieSize = 0;\n-    decode->cookieData = NULL;\n-\n-    decode->audioConverter = NULL;\n-    decode->outPacketDescription = NULL;\n-\n-    decode->isAudioConverterReady = FALSE;\n-    decode->isFormatInitialized = FALSE;\n-    decode->hasAudioPacketTableInfo = FALSE;\n-\n-    decode->audioDataPacketCount = 0;\n-    decode->previousDesc = NULL;\n-\n-    \/\/ Flags\n-    decode->is_initialized = FALSE;\n-    decode->has_pad_caps = FALSE;\n-\n-    \/\/ Counters\n-    decode->total_samples = 0;\n-\n-    \/\/ Values\n-    decode->data_format = AUDIOCONVERTER_DATA_FORMAT_NONE;\n-    decode->initial_offset = (guint64)-1;\n-    decode->stream_length = AUDIOCONVERTER_STREAM_LENGTH_UNKNOWN;\n-    decode->duration = AUDIOCONVERTER_DURATION_UNKNOWN;\n-}\n-\n-\/**\n- * Reset the state of the AudioConverter structure. This should happen before\n- * decoding a new segment.\n- *\/\n-static void\n-audioconverter_state_reset(AudioConverter *decode)\n-{\n-    \/\/ Buffer cache\n-    if (NULL == decode->packetDesc) {\n-        decode->packetDesc = g_queue_new();\n-    } else if(!g_queue_is_empty(decode->packetDesc)) {\n-        guint queueLength = g_queue_get_length(decode->packetDesc);\n-        int i;\n-        for(i = 0; i < queueLength; i++) {\n-            gpointer p = g_queue_pop_head(decode->packetDesc);\n-            g_free(p);\n-        }\n-    }\n-\n-    \/\/ Input data\n-    if (NULL == decode->inputData) {\n-        decode->inputData = g_array_sized_new(FALSE, FALSE, sizeof(guint8),\n-                                              AUDIOCONVERTER_INITIAL_BUFFER_SIZE);\n-    } else {\n-        decode->inputData = g_array_set_size(decode->inputData, 0);\n-    }\n-    decode->inputOffset = 0;\n-\n-    \/\/ Decoder\n-    if (NULL != decode->audioConverter) {\n-        AudioConverterReset(decode->audioConverter);\n-    }\n-\n-    \/\/ Flags\n-    decode->is_synced = FALSE;\n-    decode->is_discont = TRUE;\n-\n-    \/\/ Counters\n-    decode->total_packets = 0;\n-\n-    if(NULL != decode->previousDesc) {\n-        g_free(decode->previousDesc);\n-        decode->previousDesc = NULL;\n-    }\n-}\n-\n-\/*\n- * Perform processing needed for state transitions.\n- *\/\n-static GstStateChangeReturn\n-audioconverter_change_state (GstElement* element, GstStateChange transition)\n-{\n-    AudioConverter *decode = AUDIOCONVERTER(element);\n-    GstStateChangeReturn ret;\n-\n-    switch(transition)\n-    {\n-        case GST_STATE_CHANGE_NULL_TO_READY:\n-            audioconverter_state_init(decode);\n-            break;\n-        case GST_STATE_CHANGE_READY_TO_PAUSED:\n-            \/\/ Clear the AudioConverter state.\n-            audioconverter_state_reset(decode);\n-            break;\n-        case GST_STATE_CHANGE_PAUSED_TO_PLAYING:\n-            break;\n-        default:\n-            break;\n-    }\n-\n-    \/\/ Change state.\n-    ret = GST_ELEMENT_CLASS(parent_class)->change_state(element, transition);\n-    if(GST_STATE_CHANGE_FAILURE == ret)\n-    {\n-        return ret;\n-    }\n-\n-    switch(transition)\n-    {\n-        case GST_STATE_CHANGE_PLAYING_TO_PAUSED:\n-            break;\n-        case GST_STATE_CHANGE_PAUSED_TO_READY:\n-            \/\/ Free all allocated memory.\n-            if(!g_queue_is_empty(decode->packetDesc)) {\n-                guint queueLength = g_queue_get_length(decode->packetDesc);\n-                int i;\n-                for(i = 0; i < queueLength; i++) {\n-                    gpointer p = g_queue_pop_head(decode->packetDesc);\n-                    g_free(p);\n-                }\n-            }\n-\n-            g_queue_free(decode->packetDesc);\n-            decode->packetDesc = NULL;\n-\n-            g_array_free(decode->inputData, TRUE);\n-            decode->inputData = NULL;\n-\n-            if(NULL != decode->audioStreamID) {\n-                AudioFileStreamClose(decode->audioStreamID);\n-                decode->audioStreamID = NULL;\n-            }\n-\n-            if(NULL != decode->audioConverter) {\n-                AudioConverterDispose(decode->audioConverter);\n-                decode->audioConverter = NULL;\n-            }\n-\n-            if(NULL != decode->cookieData) {\n-                g_free(decode->cookieData);\n-                decode->cookieData = NULL;\n-            }\n-\n-            if(NULL != decode->outPacketDescription) {\n-                g_free(decode->outPacketDescription);\n-                decode->outPacketDescription = NULL;\n-            }\n-\n-            if(NULL != decode->previousDesc) {\n-                g_free(decode->previousDesc);\n-                decode->previousDesc = NULL;\n-            }\n-\n-            if (decode->sink_caps != NULL) {\n-                gst_caps_unref(decode->sink_caps);\n-                decode->sink_caps = NULL;\n-            }\n-\n-            if (decode->segment_event != NULL) {\n-                \/\/ INLINE - gst_event_unref()\n-                gst_event_unref (decode->segment_event);\n-                decode->segment_event = NULL;\n-            }\n-            break;\n-        case GST_STATE_CHANGE_READY_TO_NULL:\n-            break;\n-        default:\n-            break;\n-    }\n-\n-    return ret;\n-}\n-\n-\/*\n- * Process events received from upstream. The explicitly handled events are\n- * FLUSH_START, FLUSH_STOP, and NEWSEGMENT; all others are forwarded.\n- *\/\n-static gboolean\n-audioconverter_sink_event (GstPad * pad, GstObject *parent, GstEvent * event)\n-{\n-    gboolean ret = FALSE;\n-    AudioConverter *decode = AUDIOCONVERTER(parent);\n-\n-#if ENABLE_PRINT_SPEW\n-    g_print(\"sink event: %s\\n\", GST_EVENT_TYPE_NAME(event));\n-#endif\n-    switch (GST_EVENT_TYPE (event))\n-    {\n-        case GST_EVENT_FLUSH_START:\n-        {\n-            \/\/ Start flushing buffers.\n-\n-            \/\/ Set flag so chain function refuses new buffers.\n-            decode->is_flushing = TRUE;\n-\n-            \/\/ Push the event downstream.\n-            ret = gst_pad_push_event (decode->srcpad, event);\n-            break;\n-        }\n-\n-        case GST_EVENT_FLUSH_STOP:\n-        {\n-            \/\/ Stop flushing buffers.\n-            audioconverter_state_reset(decode);\n-\n-            \/\/ Unset flag so chain function accepts buffers.\n-            decode->is_flushing = FALSE;\n-\n-            \/\/ Push the event downstream.\n-            ret = gst_pad_push_event (decode->srcpad, event);\n-            break;\n-        }\n-\n-        case GST_EVENT_EOS:\n-        {\n-            if (decode->is_priming)\n-            {\n-                gst_element_message_full(GST_ELEMENT(decode), GST_MESSAGE_ERROR, GST_STREAM_ERROR, GST_STREAM_ERROR_DECODE, g_strdup(\"MP3 file must contain 3 MP3 frames.\"), NULL, (\"audioconverter.c\"), (\"audioconverter_sink_event\"), 0);\n-            }\n-\n-            \/\/ Push the event downstream.\n-            ret = gst_pad_push_event (decode->srcpad, event);\n-            break;\n-        }\n-\n-        case GST_EVENT_CAPS:\n-        {\n-            GstCaps *caps;\n-\n-            gst_event_parse_caps (event, &caps);\n-            if (decode->sink_caps != NULL)\n-                gst_caps_unref(decode->sink_caps);\n-\n-            decode->sink_caps = gst_caps_copy(caps);\n-\n-            \/\/ INLINE - gst_event_unref()\n-            gst_event_unref (event);\n-            ret = TRUE;\n-            break;\n-        }\n-\n-        case GST_EVENT_SEGMENT:\n-        {\n-            if (!decode->has_pad_caps)\n-            {\n-                if (decode->segment_event != NULL)\n-                {\n-                    \/\/ INLINE - gst_event_unref()\n-                    gst_event_unref (decode->segment_event);\n-                }\n-                decode->segment_event = gst_event_copy(event);\n-                \/\/ INLINE - gst_event_unref()\n-                gst_event_unref (event);\n-                ret = TRUE;\n-            }\n-            else\n-            {\n-                ret = gst_pad_push_event (decode->srcpad, event);\n-            }\n-            break;\n-        }\n-\n-        default:\n-            \/\/ Push the event downstream.\n-            ret = gst_pad_push_event (decode->srcpad, event);\n-            break;\n-    }\n-\n-    return ret;\n-}\n-\n-\/*\n- * Process events received from downstream. The only handled event is SEEK and\n- * that only to convert the event from TIME to BYTE format.\n- *\/\n-static gboolean\n-audioconverter_src_event (GstPad * pad, GstObject *parent, GstEvent * event)\n-{\n-    gboolean result = FALSE;\n-    AudioConverter *decode = AUDIOCONVERTER(parent);\n-\n-    if (GST_EVENT_TYPE(event) == GST_EVENT_SEEK)\n-    {\n-        gdouble rate;           \/\/ segment rate\n-        GstFormat format;       \/\/ format of the seek values\n-        GstSeekFlags flags;     \/\/ the seek flags\n-        GstSeekType start_type; \/\/ the seek type of the start position\n-        GstSeekType stop_type;  \/\/ the seek type of the stop position\n-        gint64 start;           \/\/ the seek start position in the given format\n-        gint64 stop;            \/\/ the seek stop position in the given format\n-\n-        \/\/ Get seek description from the event.\n-        gst_event_parse_seek (event, &rate, &format, &flags, &start_type, &start, &stop_type, &stop);\n-        if (format == GST_FORMAT_TIME)\n-        {\n-            gint64 start_byte = 0;\n-            if (gst_pad_peer_query_convert(decode->sinkpad, GST_FORMAT_TIME, start, GST_FORMAT_BYTES, &start_byte))\n-            {\n-                result = gst_pad_push_event(decode->sinkpad,\n-                                            gst_event_new_seek(rate, GST_FORMAT_BYTES,\n-                                                               (GstSeekFlags)(GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_ACCURATE),\n-                                                               GST_SEEK_TYPE_SET, start_byte,\n-                                                               GST_SEEK_TYPE_NONE, 0));\n-                if (result)\n-                {\n-                    \/\/ INLINE - gst_event_unref()\n-                    gst_event_unref (event);\n-                }\n-            }\n-\n-            if (!result)\n-            {\n-                if (decode->frame_duration != 0)\n-                {\n-                    SInt64 absolutePacketOffset = start \/ decode->frame_duration;\n-                    SInt64 absoluteByteOffset;\n-                    UInt32 flags = 0;\n-                    if(noErr == AudioFileStreamSeek(decode->audioStreamID, absolutePacketOffset,\n-                                                    &absoluteByteOffset, &flags)) {\n-                        start_byte = (gint64)absoluteByteOffset;\n-                        result = gst_pad_push_event(decode->sinkpad,\n-                                                    gst_event_new_seek(rate, GST_FORMAT_BYTES,\n-                                                                       (GstSeekFlags)(GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_ACCURATE),\n-                                                                       GST_SEEK_TYPE_SET, start_byte,\n-                                                                       GST_SEEK_TYPE_NONE, 0));\n-                        if (result)\n-                        {\n-                            \/\/ INLINE - gst_event_unref()\n-                            gst_event_unref (event);\n-                        }\n-                    }\n-                }\n-                else\n-                    gst_element_message_full(GST_ELEMENT(decode), GST_MESSAGE_ERROR, GST_STREAM_ERROR, GST_STREAM_ERROR_DECODE,\n-                                             g_strdup(\"Zero frame duration\"), NULL, (\"audioconverter.c\"), (\"audioconverter_src_event\"), 0);\n-            }\n-        }\n-    }\n-\n-    \/\/ Push the event upstream only if it was not processed.\n-    if (!result)\n-        result = gst_pad_push_event(decode->sinkpad, event);\n-\n-    return result;\n-}\n-\n-static gboolean\n-audioconverter_src_query (GstPad * pad, GstObject *parent, GstQuery * query)\n-{\n-    \/\/ Set flag indicating that the query has not been handled.\n-    gboolean result = FALSE;\n-    AudioConverter *decode = AUDIOCONVERTER(parent);\n-    GstFormat format;\n-    gint64 value;\n-\n-    switch (GST_QUERY_TYPE (query))\n-    {\n-        case GST_QUERY_DURATION:\n-        {\n-#if ENABLE_PRINT_SPEW\n-            g_print(\"Duration query\\n\");\n-#endif\n-\n-            \/\/ Do not handle query if the stream offset is unknown.\n-            if ((guint64)-1 == decode->initial_offset) {\n-                return FALSE;\n-            }\n-\n-            \/\/ Get the format required by the query.\n-            gst_query_parse_duration(query, &format, NULL);\n-\n-            \/\/ Handled time-valued query.\n-            if (format == GST_FORMAT_TIME) {\n-                if(AUDIOCONVERTER_DURATION_UNKNOWN != decode->duration) {\n-#if ENABLE_PRINT_SPEW\n-                    g_print(\"STORED DURATION\\n\");\n-#endif\n-                    gst_query_set_duration(query, GST_FORMAT_TIME, decode->duration);\n-                    result = TRUE;\n-                } else if (gst_pad_peer_query_duration(decode->sinkpad, GST_FORMAT_TIME, &value) &&\n-                           format == GST_FORMAT_TIME) {\n-                    \/\/ Get the duration from the sinkpad.\n-                    gst_query_set_duration(query, GST_FORMAT_TIME, value);\n-                    decode->duration = value;\n-                    result = TRUE;\n-#if ENABLE_PRINT_SPEW\n-                    g_print(\"SINK PAD TIME DURATION\\n\");\n-#endif\n-                } else {\n-                    gint64 data_length;\n-                    if (gst_pad_peer_query_duration(decode->sinkpad, GST_FORMAT_BYTES, &data_length)) {\n-                        data_length -= decode->initial_offset;\n-\n-                        if (gst_pad_peer_query_convert(decode->sinkpad, GST_FORMAT_BYTES, data_length, GST_FORMAT_TIME, &value)) {\n-#if ENABLE_PRINT_SPEW\n-                            g_print(\"SINK PAD BYTE DURATION\\n\");\n-#endif\n-                            gst_query_set_duration(query, GST_FORMAT_TIME, value);\n-                            decode->duration = value;\n-                            result = TRUE;\n-                        }\n-                    }\n-                }\n-            }\n-            break;\n-        }\n-\n-        case GST_QUERY_POSITION:\n-        {\n-            \/\/ Get the format required by the query.\n-            gst_query_parse_position(query, &format, NULL);\n-\n-            \/\/ Handle time-valued query if the decoder is initialized.\n-            if(format == GST_FORMAT_TIME && decode->is_initialized)\n-            {\n-                \/\/ Use the sampling rate to convert sample offset to time.\n-                value = gst_util_uint64_scale_int(decode->total_samples,\n-                                                  GST_SECOND,\n-                                                  decode->sampling_rate);\n-\n-                \/\/ Set the position on the query object.\n-                gst_query_set_position(query, format, value);\n-\n-                \/\/ Set flag indicating that the query has been handled.\n-                result = TRUE;\n-            }\n-        }\n-\n-        default:\n-            break;\n-    }\n-\n-    \/\/ Use default query if flag indicates query not handled.\n-    if(result == FALSE)\n-    {\n-        result = gst_pad_query_default(pad, parent, query);\n-    }\n-\n-    return result;\n-}\n-\n-\/*\n- * Processes a buffer of MPEG audio data pushed to the sink pad.\n- *\/\n-static GstFlowReturn\n-audioconverter_chain (GstPad * pad, GstObject *parent, GstBuffer * buf)\n-{\n-    AudioConverter *decode = AUDIOCONVERTER(parent);\n-    GstFlowReturn ret      = GST_FLOW_OK;\n-    GstMapInfo info;\n-    gboolean unmap_buf = FALSE;\n-    guint8 *buf_data       = NULL;\n-    guint buf_size         = 0;\n-    GstClockTime buf_time  = GST_BUFFER_TIMESTAMP(buf);\n-    GstEvent *caps_event = NULL;\n-\n-    \/\/ If between FLUSH_START and FLUSH_STOP, reject new buffers.\n-    if (decode->is_flushing)\n-    {\n-        ret = GST_FLOW_FLUSHING;\n-        goto _exit;\n-    }\n-\n-    \/\/ Reset state on discont buffer if not after FLUSH_STOP.\n-    if (GST_BUFFER_IS_DISCONT(buf) && TRUE == decode->is_synced) {\n-        audioconverter_state_reset(decode);\n-    }\n-\n-    \/\/ Get memory pointers from buffer\n-    if (gst_buffer_map(buf, &info, GST_MAP_READ)) {\n-        buf_data = info.data;\n-        buf_size = info.size;\n-        unmap_buf = TRUE;\n-    } else {\n-        ret = GST_FLOW_ERROR;\n-        goto _exit;\n-    }\n-\n-    if (decode->enable_parser && NULL == decode->audioStreamID) {\n-        AudioFileTypeID audioStreamTypeHint = kAudioFileM4AType;\n-\n-        \/\/ Try to set a better parser hint from the sink pad caps.\n-        GstCaps* sink_peer_caps = decode->sink_caps;\n-        if(NULL != sink_peer_caps) {\n-            if(gst_caps_get_size(sink_peer_caps) > 0) {\n-                GstStructure* caps_struct = gst_caps_get_structure(sink_peer_caps, 0);\n-                if(NULL != caps_struct) {\n-                    const gchar* struct_name = gst_structure_get_name(caps_struct);\n-                    if(NULL != struct_name) {\n-                        if(0 == strcmp(struct_name, \"audio\/mpeg\")) {\n-                            gint mpegversion;\n-                            if(!gst_structure_get_int(caps_struct, \"mpegversion\", &mpegversion)) {\n-                                mpegversion = 1;\n-                            }\n-\n-                            if(4 == mpegversion &&\n-                               NULL != gst_structure_get_value (caps_struct, \"codec_data\")) {\n-                                decode->enable_parser = FALSE;\n-                                decode->data_format = AUDIOCONVERTER_DATA_FORMAT_AAC;\n-\n-                                const GValue* codec_data_value = gst_structure_get_value (caps_struct, \"codec_data\");\n-                                GstBuffer* codec_data_buf = gst_value_get_buffer (codec_data_value);\n-                                GstMapInfo info;\n-                                GstMapInfo info2;\n-                                guint8* codec_data = NULL;\n-                                guint codec_data_size = 0;\n-\n-                                if (gst_buffer_map(codec_data_buf, &info, GST_MAP_READ)) {\n-                                    codec_data = info.data;\n-                                    codec_data_size = info.size;\n-                                } else {\n-                                    ret = GST_FLOW_ERROR;\n-                                    goto _exit;\n-                                }\n-\n-                                \/\/\n-                                \/\/ Get the number of channels from the Audio Specific Config\n-                                \/\/ which is what is passed in \"codec_data\"\n-                                \/\/\n-                                \/\/ Ref: http:\/\/wiki.multimedia.cx\/index.php?title=MPEG-4_Audio\n-                                \/\/\n-                                guint8 channel_config = 0;\n-                                if (codec_data_size >= 2) {\n-                                    guint8 freq_index = (codec_data[0]&0x07) << 1 | (codec_data[1]&0x80) >> 7;\n-                                    if (15 == freq_index) {\n-                                        if(codec_data_size >= 5) {\n-                                            channel_config = (codec_data[4]&0x78) >> 3;\n-                                        }\n-                                    } else {\n-                                        channel_config = (codec_data[1]&0x78) >> 3;\n-                                    }\n-                                }\n-\n-                                gst_buffer_unmap(codec_data_buf, &info);\n-\n-                                const GValue* esds_value = gst_structure_get_value (caps_struct, \"esds_data\");\n-                                if(esds_value) {\n-                                    gint rate;\n-                                    if(!gst_structure_get_int(caps_struct, \"rate\", &rate)) {\n-                                        rate = 44100;\n-                                    }\n-\n-                                    gint channels;\n-                                    if(!gst_structure_get_int(caps_struct, \"channels\", &channels)) {\n-                                        channels = 2;\n-                                    }\n-\n-                                    GstBuffer* esds_buf = gst_value_get_buffer (esds_value);\n-                                    guint8* esds_data = NULL;\n-                                    guint esds_size = 0;\n-\n-                                    if (gst_buffer_map(esds_buf, &info2, GST_MAP_READ)) {\n-                                      esds_data = info2.data;\n-                                      esds_size = info2.size;\n-                                    } else {\n-                                        ret = GST_FLOW_ERROR;\n-                                        goto _exit;\n-                                    }\n-\n-                                    decode->sampling_rate = rate;\n-                                    if (channel_config > 0 && channel_config < 7) {\n-                                        decode->num_channels = channel_config;\n-                                    } else if (7 == channel_config) {\n-                                        decode->num_channels = 8;\n-                                    } else {\n-                                        decode->num_channels = channels;\n-                                    }\n-                                    decode->samples_per_frame = 1024; \/\/ XXX Note: AAC-LC has 960 spf\n-\n-                                    decode->audioInputFormat.mSampleRate = decode->sampling_rate;\n-                                    decode->audioInputFormat.mFormatID = kAudioFormatMPEG4AAC;\n-                                    decode->audioInputFormat.mFramesPerPacket = decode->samples_per_frame;\n-                                    decode->audioInputFormat.mChannelsPerFrame = decode->num_channels;\n-\n-                                    initAudioFormatPCM(decode->audioInputFormat.mSampleRate,\n-                                                       &decode->audioOutputFormat);\n-\n-                                    decode->cookieSize = esds_size - AUDIOCONVERTER_AAC_ESDS_HEADER_SIZE;\n-                                    decode->cookieData = g_malloc0(decode->cookieSize);\n-                                    if(NULL != decode->cookieData) {\n-                                        memcpy(decode->cookieData,\n-                                               esds_data + AUDIOCONVERTER_AAC_ESDS_HEADER_SIZE,\n-                                               decode->cookieSize);\n-                                    }\n-\n-                                    decode->isFormatInitialized = TRUE;\n-                                    decode->isAudioConverterReady = TRUE;\n-\n-                                    gst_buffer_unmap(esds_buf, &info2);\n-                                } else {\n-                                    ret = GST_FLOW_ERROR;\n-                                    goto _exit;\n-                                }\n-                            } else {\n-                                gint layer;\n-                                if(gst_structure_get_int(caps_struct, \"layer\", &layer)) {\n-                                    switch(layer) {\n-                                        case 1:\n-                                            audioStreamTypeHint = kAudioFileMP1Type;\n-                                            break;\n-                                        case 2:\n-                                            audioStreamTypeHint = kAudioFileMP2Type;\n-                                            break;\n-                                        case 3:\n-                                        default:\n-                                            audioStreamTypeHint = kAudioFileMP3Type;\n-                                            break;\n-                                    }\n-                                } else {\n-                                    audioStreamTypeHint = kAudioFileM4AType;\n-                                }\n-                            }\n-                        }\n-                    }\n-                }\n-            }\n-        }\n-\n-        if(decode->enable_parser) {\n-            if(noErr != AudioFileStreamOpen((void*)decode,\n-                                            propertyListener,\n-                                            packetListener,\n-                                            audioStreamTypeHint,\n-                                            &decode->audioStreamID)) {\n-#if ENABLE_PRINT_SPEW\n-                g_print(\"AudioFileStreamOpen failed\\n\");\n-#endif\n-                ret = GST_FLOW_ERROR;\n-                goto _exit;\n-            }\n-        }\n-    }\n-\n-    if(decode->enable_parser) {\n-        guint32 parserFlags;\n-        if(!decode->isAudioConverterReady) {\n-            parserFlags = 0;\n-        } else {\n-            \/\/parserFlags = decode->is_synced ? 0 : kAudioFileStreamParseFlag_Discontinuity;\n-            if(decode->is_synced) {\n-                parserFlags = 0;\n-            } else {\n-                parserFlags = kAudioFileStreamParseFlag_Discontinuity;\n-                AudioConverterReset(decode->audioConverter);\n-            }\n-        }\n-\n-        OSStatus result = AudioFileStreamParseBytes(decode->audioStreamID, buf_size, buf_data, parserFlags);\n-\n-        if(noErr != result) {\n-#if ENABLE_PRINT_SPEW\n-            g_print(\"AudioFileStreamParseBytes %d\\n\", result);\n-#endif\n-            ret = GST_FLOW_ERROR;\n-            goto _exit;\n-        }\n-    } else {\n-        if(!decode->is_synced && NULL != decode->audioConverter) {\n-            AudioConverterReset(decode->audioConverter);\n-        }\n-\n-        AudioStreamPacketDescription packetDescriptions;\n-        packetDescriptions.mDataByteSize = buf_size;\n-        packetDescriptions.mStartOffset = 0;\n-        packetDescriptions.mVariableFramesInPacket = 0;\n-\n-        packetListener((void*)decode, buf_size, 1, (const void*)buf_data,\n-                       &packetDescriptions);\n-    }\n-\n-    \/\/ Return without pushing a buffer if format not derived from stream parser.\n-    if(!decode->isFormatInitialized) {\n-        return GST_FLOW_OK;\n-    }\n-\n-    \/\/ Return without pushing a buffer if format is MPEG audio but no packets are enqueued.\n-    if(AUDIOCONVERTER_DATA_FORMAT_MPA == decode->data_format && 0 == decode->total_packets) {\n-        goto _exit; \/\/ GST_FLOW_OK\n-    }\n-\n-    if(decode->is_synced == FALSE) {\n-        \/\/ Set flags.\n-        gboolean is_first_frame = !decode->is_initialized;\n-        decode->is_initialized = TRUE;\n-        decode->is_synced = TRUE;\n-        decode->is_priming = TRUE;\n-\n-        \/\/ Save frame description.\n-        decode->sampling_rate = (guint)decode->audioInputFormat.mSampleRate;\n-        decode->samples_per_frame = decode->audioInputFormat.mFramesPerPacket;\n-        decode->frame_duration = (guint)(GST_SECOND*\n-                                         (double)decode->samples_per_frame\/\n-                                         (double)decode->sampling_rate);\n-\n-        if(is_first_frame) {\n-            \/\/ Allocate memory for output packet descriptions.\n-            decode->outPacketDescription = g_malloc(decode->samples_per_frame*sizeof(AudioStreamPacketDescription));\n-            if(NULL == decode->outPacketDescription) {\n-                ret = GST_FLOW_ERROR;\n-                goto _exit;\n-            }\n-\n-            \/\/ Save first frame offset.\n-            decode->initial_offset = GST_BUFFER_OFFSET_IS_VALID(buf) ? GST_BUFFER_OFFSET(buf) : 0;\n-\n-            \/\/ Query for the stream length if it was not set from a header.\n-            if (AUDIOCONVERTER_STREAM_LENGTH_UNKNOWN == decode->stream_length)\n-            {\n-                gint64 sink_length;\n-\n-                if (gst_pad_peer_query_duration(decode->sinkpad, GST_FORMAT_BYTES, &sink_length))\n-                {\n-                    decode->stream_length = sink_length;\n-                }\n-            }\n-        }\n-\n-        \/\/ Check frame duration for zero to avoid division by zero.\n-        if (decode->frame_duration == 0)\n-        {\n-            gst_element_message_full(GST_ELEMENT(decode), GST_MESSAGE_ERROR, GST_STREAM_ERROR, GST_STREAM_ERROR_DECODE,\n-                                     g_strdup(\"Zero frame duration\"), NULL, (\"audioconverter.c\"), (\"audioconverter_chain\"), 0);\n-            ret = GST_FLOW_ERROR;\n-            goto _exit;\n-        }\n-\n-        \/\/ Derive sample count using the timestamp.\n-        guint64 frame_index = buf_time\/decode->frame_duration;\n-        decode->total_samples = frame_index * decode->samples_per_frame;\n-\n-        \/\/ Set the sink and source pad caps if not already done.\n-        if (TRUE != decode->has_pad_caps)\n-        {\n-            GstCaps* caps = NULL;\n-\n-            if(AUDIOCONVERTER_DATA_FORMAT_MPA == decode->data_format) {\n-                \/\/ Determine the layer.\n-                gint layer;\n-                switch(decode->audioInputFormat.mFormatID) {\n-                    case kAudioFormatMPEGLayer1:\n-                        layer = 1;\n-                        break;\n-                    case kAudioFormatMPEGLayer2:\n-                        layer = 2;\n-                        break;\n-                    case kAudioFormatMPEGLayer3:\n-                        layer = 3;\n-                        break;\n-                    default:\n-                        layer = 3;\n-                        break;\n-                }\n-\n-                \/\/ Sink caps: MPEG audio.\n-                caps = gst_caps_new_simple (\"audio\/mpeg\",\n-                                            \"version\", G_TYPE_INT, 1,\n-                                            \"layer\", G_TYPE_INT, layer,\n-                                            \"rate\", G_TYPE_INT, (gint)decode->sampling_rate,\n-                                            \"channels\", G_TYPE_INT, (gint)decode->num_channels,\n-                                            NULL);\n-            } else if(AUDIOCONVERTER_DATA_FORMAT_AAC == decode->data_format) {\n-                caps = gst_caps_new_simple (\"audio\/mpeg\",\n-                                            \"mpegversion\", G_TYPE_INT, 2,\n-                                             NULL);\n-            } else {\n-                ret = GST_FLOW_ERROR;\n-                goto _exit;\n-            }\n-\n-            caps_event = gst_event_new_caps (caps);\n-            if (caps_event)\n-            {\n-                if(!gst_pad_send_event(decode->sinkpad, caps_event))\n-                {\n-#if ENABLE_PRINT_SPEW\n-                    g_print(\"WARNING: COULD NOT SET sinkpad CAPS\\n\");\n-#endif\n-                }\n-#if ENABLE_PRINT_SPEW\n-                g_print(\"sink_caps %s\\n\", gst_caps_to_string(caps));\n-#endif\n-            }\n-\n-            gst_caps_unref (caps);\n-            caps = NULL;\n-\n-            \/\/ Source caps: PCM audio.\n-\n-            \/\/ Create the source caps.\n-            caps = gst_caps_new_simple (\"audio\/x-raw\",\n-                                        \"rate\", G_TYPE_INT, (gint)decode->sampling_rate,\n-                                        \"channels\", G_TYPE_INT,\n-                                        decode->audioOutputFormat.mChannelsPerFrame, \/\/ may not equal num_channels\n-                                        \"format\", G_TYPE_STRING, \"F32LE\",\n-                                        \"layout\", G_TYPE_STRING, \"interleaved\",\n-                                        NULL);\n-\n-            \/\/ Set the source caps.\n-            caps_event = gst_event_new_caps (caps);\n-            if (caps_event)\n-            {\n-                if(!gst_pad_push_event(decode->srcpad, caps_event))\n-                {\n-#if ENABLE_PRINT_SPEW\n-                    g_print(\"WARNING: COULD NOT SET srcpad CAPS\\n\");\n-#endif\n-                }\n-#if ENABLE_PRINT_SPEW\n-                g_print(\"src_caps %s\\n\", gst_caps_to_string(caps));\n-#endif\n-            }\n-\n-            gst_caps_unref (caps);\n-            caps = NULL;\n-\n-            if (decode->segment_event)\n-            {\n-                gst_pad_push_event (decode->srcpad, decode->segment_event);\n-                decode->segment_event = NULL;\n-            }\n-\n-            \/\/ Set the source caps flag.\n-            decode->has_pad_caps = TRUE;\n-        }\n-    }\n-\n-    if(!decode->isAudioConverterReady) {\n-        \/\/ Return without pushing a buffer if converter is not ready.\n-        goto _exit; \/\/ GST_FLOW_OK\n-    } else if(NULL == decode->audioConverter) {\n-        \/\/ Initialize the converter.\n-        if(noErr != AudioConverterNew(&decode->audioInputFormat,\n-                                      &decode->audioOutputFormat,\n-                                      &decode->audioConverter)) {\n-#if ENABLE_PRINT_SPEW\n-            g_print(\"Failed to initialize AudioConverter\\n\");\n-#endif\n-            \/\/ Return an error if converter cannot be initialized.\n-            ret = GST_FLOW_ERROR;\n-            goto _exit;\n-        } else if(NULL != decode->cookieData && noErr != AudioConverterSetProperty(decode->audioConverter,\n-                                                                            kAudioConverterDecompressionMagicCookie,\n-                                                                            decode->cookieSize, decode->cookieData)) {\n-#if ENABLE_PRINT_SPEW\n-            g_print(\"Failed to set AudioConverter magic cookie data\\n\");\n-#endif\n-            \/\/ Return an error if converter cannot be initialized.\n-            ret = GST_FLOW_ERROR;\n-            goto _exit;\n-        } else if(AUDIOCONVERTER_DATA_FORMAT_AAC == decode->data_format) {\n-            AudioConverterPrimeInfo primeInfo;\n-            primeInfo.leadingFrames = 0;\n-            primeInfo.trailingFrames = 0;\n-            AudioConverterSetProperty(decode->audioConverter, kAudioConverterPrimeInfo,\n-                                      sizeof(primeInfo),\n-                                      &primeInfo);\n-        }\n-    }\n-\n-    \/\/ Decoder priming (MPEG audio only).\n-    if(decode->is_priming &&\n-       \/\/AUDIOCONVERTER_DATA_FORMAT_MPA == decode->data_format &&\n-       decode->total_packets >= AUDIOCONVERTER_MPEG_MIN_PACKETS) {\n-        \/\/ Turn off priming if enough packets are enqueued.\n-        decode->is_priming = FALSE;\n-    }\n-\n-    if(decode->is_priming) {\n-        \/\/ Return without pushing a buffer if there are not enough packets enqueued.\n-        if(g_queue_get_length(decode->packetDesc) < AUDIOCONVERTER_MPEG_MIN_PACKETS) {\n-            goto _exit; \/\/ GST_FLOW_OK;\n-        } else {\n-            decode->is_priming = FALSE;\n-        }\n-    }\n-\n-    \/\/ Drain the packet queue.\n-    while(!g_queue_is_empty(decode->packetDesc)) {\n-        UInt32 outputDataPacketSize = decode->samples_per_frame;\n-\n-        guint outbuf_size = outputDataPacketSize*decode->audioOutputFormat.mBytesPerPacket;\n-        GstMapInfo info2;\n-        GstBuffer *outbuf = gst_buffer_new_allocate(NULL, outbuf_size, NULL);\n-\n-        \/\/ Bail out on error.\n-        if(outbuf == NULL || !gst_buffer_map(outbuf, &info2, GST_MAP_WRITE))\n-        {\n-            if (ret != GST_FLOW_FLUSHING)\n-            {\n-                gst_element_message_full(GST_ELEMENT(decode), GST_MESSAGE_ERROR, GST_CORE_ERROR, GST_CORE_ERROR_SEEK, g_strdup(\"Decoded audio buffer allocation failed\"), NULL, (\"audioconverter.c\"), (\"audioconverter_chain\"), 0);\n-            }\n-\n-            goto _exit;\n-        }\n-\n-        AudioBufferList outputData;\n-        outputData.mNumberBuffers = 1;\n-        outputData.mBuffers[0].mNumberChannels = decode->audioOutputFormat.mChannelsPerFrame;\n-        outputData.mBuffers[0].mDataByteSize = (UInt32)outputDataPacketSize*decode->audioOutputFormat.mBytesPerFrame;\n-        outputData.mBuffers[0].mData = info2.data;\n-        OSStatus err = AudioConverterFillComplexBuffer(decode->audioConverter,\n-                                                       retrieveInputData,\n-                                                       (void*)decode,\n-                                                       &outputDataPacketSize,\n-                                                       &outputData,\n-                                                       decode->outPacketDescription);\n-        gst_buffer_unmap(outbuf, &info2);\n-        if(noErr != err) {\n-#if ENABLE_PRINT_SPEW\n-            g_print(\"AudioConverterFillComplexBuffer err: %u\\n\", err);\n-#endif\n-            \/\/ INLINE - gst_buffer_unref()\n-            gst_buffer_unref(outbuf);\n-            ret = GST_FLOW_ERROR;\n-            goto _exit;\n-        }\n-\n-        if(0 == outputDataPacketSize) {\n-            \/\/ INLINE - gst_buffer_unref()\n-            gst_buffer_unref(outbuf);\n-            break;\n-        }\n-\n-        \/\/ Calculate the timestamp from the sample count and rate.\n-        guint64 timestamp = gst_util_uint64_scale_int(decode->total_samples,\n-                                                      GST_SECOND,\n-                                                      decode->sampling_rate);\n-\n-        \/\/ Set output buffer properties.\n-        GST_BUFFER_TIMESTAMP(outbuf) = timestamp;\n-        GST_BUFFER_DURATION(outbuf) = decode->frame_duration;\n-        gst_buffer_set_size(outbuf, outputDataPacketSize*decode->audioOutputFormat.mBytesPerPacket);\n-        GST_BUFFER_OFFSET(outbuf) = decode->total_samples;\n-        GST_BUFFER_OFFSET_END(outbuf) = (decode->total_samples += outputDataPacketSize);\n-        if(decode->is_discont)\n-        {\n-            GST_BUFFER_FLAG_SET (outbuf, GST_BUFFER_FLAG_DISCONT);\n-            decode->is_discont = FALSE;\n-        }\n-\n-        ret = gst_pad_push (decode->srcpad, outbuf);\n-        if(GST_FLOW_OK != ret) {\n-            goto _exit;\n-        }\n-    }\n-\n-    \/\/ Remove processed bytes from the buffer cache.\n-    if(decode->inputOffset != 0)\n-    {\n-        decode->inputData = g_array_remove_range(decode->inputData, 0,\n-                                                 decode->inputOffset <= decode->inputData->len ?\n-                                                 decode->inputOffset : decode->inputData->len);\n-        decode->inputOffset = 0;\n-    }\n-\n-_exit:\n-    if (unmap_buf) {\n-        gst_buffer_unmap(buf, &info);\n-    }\n-    \/\/ Unref the input buffer.\n-    \/\/ INLINE - gst_buffer_unref()\n-    gst_buffer_unref(buf);\n-    return ret;\n-}\n-\n-#if ENABLE_PRINT_SPEW\n-static void printStreamDesc (AudioStreamBasicDescription* d) {\n-    g_print (\"%lf %d %d %d %d %d %d %d %d\\n\",\n-            d->mSampleRate,\n-            d->mFormatID,\n-            d->mFormatFlags,\n-            d->mBytesPerPacket,\n-            d->mFramesPerPacket,\n-            d->mBytesPerFrame,\n-            d->mChannelsPerFrame,\n-            d->mBitsPerChannel,\n-            d->mReserved);\n-}\n-#endif\n-\n-\/\/ AudioStream and AudioConverter functions\n-static void initAudioFormatPCM(Float64 sampleRate,\n-                               AudioStreamBasicDescription* outputFormat) {\n-    outputFormat->mSampleRate = sampleRate;\n-    outputFormat->mFormatID = kAudioFormatLinearPCM;\n-    outputFormat->mFormatFlags = kAudioFormatFlagIsFloat | kAudioFormatFlagIsPacked;\n-    outputFormat->mBytesPerPacket = 8;\n-    outputFormat->mFramesPerPacket = 1;\n-    outputFormat->mBytesPerFrame = 8;\n-    outputFormat->mChannelsPerFrame = 2;\n-    outputFormat->mBitsPerChannel = 32;\n-    outputFormat->mReserved = 0;\n-}\n-\n-static void propertyListener(void *clientData,\n-                             AudioFileStreamID audioFileStream,\n-                             AudioFileStreamPropertyID propertyID,\n-                             UInt32 *flags) {\n-    AudioConverter* decode = (AudioConverter*)clientData;\n-    UInt32 propertyDataSize;\n-    UInt32 isReady;\n-    Boolean isCookieWritable;\n-\n-    switch(propertyID) {\n-        case kAudioFileStreamProperty_ReadyToProducePackets:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_ReadyToProducePackets\\n\");\n-#endif\n-            propertyDataSize = sizeof(isReady);\n-            AudioFileStreamGetProperty(audioFileStream, propertyID,\n-                                       &propertyDataSize, &isReady);\n-            if(1 == isReady && TRUE == decode->isFormatInitialized) {\n-                decode->isAudioConverterReady = TRUE;\n-                if(decode->hasAudioPacketTableInfo) {\n-                    UInt64 numFrames = decode->packetTableInfo.mNumberValidFrames;\n-                    Float64 sampleRate = decode->audioInputFormat.mSampleRate;\n-                    decode->duration = (gint64)(numFrames\/sampleRate*GST_SECOND + 0.5);\n-#if ENABLE_PRINT_SPEW\n-                    g_print(\"duration: %ld\\n\", decode->duration);\n-#endif\n-                }\n-            }\n-            break;\n-        case kAudioFileStreamProperty_FileFormat:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_FileFormat\\n\");\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_DataFormat:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_DataFormat\\n\");\n-#endif\n-            propertyDataSize = sizeof(decode->audioInputFormat);\n-            AudioFileStreamGetProperty(audioFileStream, propertyID,\n-                                       &propertyDataSize, &decode->audioInputFormat);\n-#if ENABLE_PRINT_SPEW\n-            printStreamDesc(&decode->audioInputFormat);\n-#endif\n-            switch(decode->audioInputFormat.mFormatID) {\n-                case kAudioFormatMPEGLayer1:\n-                case kAudioFormatMPEGLayer2:\n-                case kAudioFormatMPEGLayer3:\n-                    decode->data_format = AUDIOCONVERTER_DATA_FORMAT_MPA;\n-                    break;\n-                case kAudioFormatMPEG4AAC:\n-                    decode->data_format = AUDIOCONVERTER_DATA_FORMAT_AAC;\n-                    break;\n-            }\n-            decode->sampling_rate = decode->audioInputFormat.mSampleRate;\n-            decode->samples_per_frame = decode->audioInputFormat.mFramesPerPacket;\n-            decode->num_channels = decode->audioInputFormat.mChannelsPerFrame;\n-            initAudioFormatPCM(decode->audioInputFormat.mSampleRate, &decode->audioOutputFormat);\n-            decode->isFormatInitialized = TRUE;\n-            break;\n-        case kAudioFileStreamProperty_FormatList:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_FormatList\\n\");\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_MagicCookieData:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_MagicCookieData\\n\");\n-#endif\n-            if(AudioFileStreamGetPropertyInfo(audioFileStream, kAudioFileStreamProperty_MagicCookieData,\n-                                              &decode->cookieSize, &isCookieWritable)) {\n-                decode->cookieSize = 0;\n-            }\n-\n-            if(decode->cookieSize > 0) {\n-                decode->cookieData = g_malloc0(decode->cookieSize);\n-                if(NULL != decode->cookieData) {\n-                    if(AudioFileStreamGetProperty(audioFileStream, kAudioFileStreamProperty_MagicCookieData,\n-                                                  &decode->cookieSize, decode->cookieData)) {\n-                        decode->cookieData = NULL;\n-                    }\n-                }\n-            }\n-            break;\n-        case kAudioFileStreamProperty_AudioDataByteCount:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_AudioDataByteCount\\n\");\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_AudioDataPacketCount:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_AudioDataPacketCount\\n\");\n-#endif\n-            propertyDataSize = 8;\n-            AudioFileStreamGetProperty(audioFileStream, propertyID,\n-                                       &propertyDataSize, &decode->audioDataPacketCount);\n-#if ENABLE_PRINT_SPEW\n-            g_print (\">>> audioDataPacketCount: %llu\\n\", decode->audioDataPacketCount);\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_MaximumPacketSize:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_MaximumPacketSize\\n\");\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_DataOffset:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_DataOffset\\n\");\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_ChannelLayout:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_ChannelLayout\\n\");\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_PacketTableInfo:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_PacketTableInfo\\n\");\n-#endif\n-            propertyDataSize = sizeof(AudioFilePacketTableInfo);\n-            if(noErr == AudioFileStreamGetProperty(audioFileStream, propertyID,\n-                                                   &propertyDataSize, &decode->packetTableInfo)) {\n-                decode->hasAudioPacketTableInfo = TRUE;\n-            }\n-#if ENABLE_PRINT_SPEW\n-            g_print(\"valid frames %d priming frames %d remainder frames %d\\n\",\n-                    (int)decode->packetTableInfo.mNumberValidFrames,\n-                    decode->packetTableInfo.mPrimingFrames,\n-                    decode->packetTableInfo.mRemainderFrames);\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_PacketSizeUpperBound:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_PacketSizeUpperBound\\n\");\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_AverageBytesPerPacket:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_AverageBytesPerPacket\\n\");\n-#endif\n-            break;\n-        case kAudioFileStreamProperty_BitRate:\n-#if ENABLE_PRINT_SPEW\n-            g_print (\"kAudioFileStreamProperty_BitRate\\n\");\n-#endif\n-            break;\n-        default:\n-#if ENABLE_PRINT_SPEW\n-            g_print(\"propertyID: %d\\n\", propertyID);\n-#endif\n-            break;\n-    }\n-}\n-\n-static void packetListener(void *clientData,\n-                           UInt32 numberBytes,\n-                           UInt32 numberPackets,\n-                           const void *inputData,\n-                           AudioStreamPacketDescription  *packetDescriptions) {\n-    AudioConverter* decode = (AudioConverter*)clientData;\n-\n-    int i;\n-    for(i = 0; i < numberPackets; i++) {\n-        decode->total_packets++;\n-        decode->inputData = g_array_append_vals(decode->inputData,\n-                                                inputData + packetDescriptions[i].mStartOffset,\n-                                                packetDescriptions[i].mDataByteSize);\n-        AudioStreamPacketDescription* packetDesc = g_malloc(sizeof(AudioStreamPacketDescription));\n-        *packetDesc = packetDescriptions[i];\n-        g_queue_push_tail(decode->packetDesc, packetDesc);\n-    }\n-}\n-\n-OSStatus retrieveInputData(AudioConverterRef                audioConverter,\n-                           UInt32*                          numberDataPackets,\n-                           AudioBufferList*                 bufferList,\n-                           AudioStreamPacketDescription**   dataPacketDescription,\n-                           void*                            userData) {\n-    AudioConverter* decode = (AudioConverter*)userData;\n-\n-    if(!g_queue_is_empty(decode->packetDesc)) {\n-        guint numPackets;\n-        if(*numberDataPackets <= g_queue_get_length(decode->packetDesc)) {\n-            numPackets = *numberDataPackets;\n-        } else {\n-            numPackets = g_queue_get_length(decode->packetDesc);\n-        }\n-\n-        if (NULL != dataPacketDescription) {\n-            *dataPacketDescription = g_malloc(numPackets*sizeof(AudioStreamPacketDescription));\n-            if(NULL == dataPacketDescription) {\n-                return kAudioConverterErr_UnspecifiedError;\n-            }\n-            if(NULL != decode->previousDesc) {\n-                g_free(decode->previousDesc);\n-            }\n-            decode->previousDesc = *dataPacketDescription;\n-        }\n-\n-        int i;\n-        for(i = 0; i < numPackets; i++) {\n-            bufferList->mBuffers[i].mData = decode->inputData->data + decode->inputOffset;\n-            AudioStreamPacketDescription* packetDesc = g_queue_pop_head(decode->packetDesc);\n-            decode->inputOffset += packetDesc->mDataByteSize;\n-            bufferList->mBuffers[i].mDataByteSize = packetDesc->mDataByteSize;\n-            bufferList->mBuffers[i].mNumberChannels = decode->audioOutputFormat.mChannelsPerFrame;\n-\n-            if (NULL != dataPacketDescription) {\n-                dataPacketDescription[i]->mStartOffset = 0;\n-                dataPacketDescription[i]->mVariableFramesInPacket = packetDesc->mVariableFramesInPacket;\n-                dataPacketDescription[i]->mDataByteSize = packetDesc->mDataByteSize;\n-            }\n-            g_free(packetDesc);\n-        }\n-        *numberDataPackets = numPackets;\n-    } else {\n-        *numberDataPackets = 0;\n-    }\n-\n-    return 0;\n-}\n-\n-\/\/ --------------------------------------------------------------------------\n-gboolean audioconverter_plugin_init (GstPlugin * audioconverter)\n-{\n-    \/* debug category for fltering log messages\n-     *\n-     * exchange the string 'Template audioconverter' with your description\n-     *\/\n-    GST_DEBUG_CATEGORY_INIT (audioconverter_debug, \"audioconverter\",\n-                             0, \"Template audioconverter\");\n-\n-    gboolean reg_result = gst_element_register (audioconverter, \"audioconverter\",\n-                                                512, TYPE_AUDIOCONVERTER);\n-\n-    return reg_result;\n-}\n","filename":"modules\/javafx.media\/src\/main\/native\/gstreamer\/plugins\/audioconverter\/audioconverter.c","additions":0,"deletions":1430,"binary":false,"changes":1430,"status":"deleted"},{"patch":"@@ -1,139 +0,0 @@\n-\/*\n- * Copyright (c) 2010, 2015, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#ifndef __AUDIOCONVERTER_H__\n-#define __AUDIOCONVERTER_H__\n-\n-#include <gst\/gst.h>\n-\n-#if !defined(__COREAUDIO_USE_FLAT_INCLUDES__)\n-#include <AudioToolbox\/AudioToolbox.h>\n-#include <CoreFoundation\/CoreFoundation.h>\n-#else\n-#include \"AudioToolbox.h\"\n-#include \"CoreFoundation.h\"\n-#endif\n-\n-G_BEGIN_DECLS\n-\n-#define TYPE_AUDIOCONVERTER \\\n-(audioconverter_get_type())\n-#define AUDIOCONVERTER(obj) \\\n-(G_TYPE_CHECK_INSTANCE_CAST((obj),TYPE_AUDIOCONVERTER,AudioConverter))\n-#define AUDIOCONVERTER_CLASS(klass) \\\n-(G_TYPE_CHECK_CLASS_CAST((klass),TYPE_AUDIOCONVERTER,AudioConverterClass))\n-#define IS_AUDIOCONVERTER(obj) \\\n-(G_TYPE_CHECK_INSTANCE_TYPE((obj),TYPE_AUDIOCONVERTER))\n-#define IS_AUDIOCONVERTER_CLASS(klass) \\\n-(G_TYPE_CHECK_CLASS_TYPE((klass),TYPE_AUDIOCONVERTER))\n-\n-\/\/ Set to non-zero to enable a slew of print messages, zero to suppress.\n-#define ENABLE_PRINT_SPEW 0\n-\n-#define AUDIOCONVERTER_DURATION_UNKNOWN      -1\n-#define AUDIOCONVERTER_STREAM_LENGTH_UNKNOWN -1\n-\n-#define AUDIOCONVERTER_DATA_FORMAT_NONE 0\n-#define AUDIOCONVERTER_DATA_FORMAT_MPA  1\n-#define AUDIOCONVERTER_DATA_FORMAT_AAC  2\n-\n-#define AUDIOCONVERTER_INITIAL_BUFFER_SIZE 8192\n-#define AUDIOCONVERTER_MPEG_MIN_PACKETS    3\n-\n-#define AUDIOCONVERTER_AAC_ESDS_HEADER_SIZE 12\n-\n-typedef struct _AudioConverter      AudioConverter;\n-typedef struct _AudioConverterClass AudioConverterClass;\n-\n-struct _AudioConverter {\n-    GstElement element;\n-\n-    GstPad *sinkpad;         \/\/ input compressed audio port\n-    GstPad *srcpad;          \/\/ output compressed audio port\n-\n-    GQueue *packetDesc;      \/\/ queue of compressed audio packets\n-    GArray *inputData;       \/\/ buffer of encoded audio samples\n-    guint inputOffset;       \/\/ offset into input buffer\n-\n-    gboolean is_initialized; \/\/ whether the struct has been set from a frame\n-    gboolean is_synced;      \/\/ whether the first audio frame has been found\n-    gboolean is_discont;     \/\/ whether the next frame is a discontinuity\n-\n-    guint   data_format;     \/\/ the audio data format\n-    guint64 total_packets;   \/\/ number of compressed packets received; reset after seek\n-    guint64 total_samples;   \/\/ sample offset from zero at current time\n-\n-    guint sampling_rate;     \/\/ samples \/ second\n-    guint samples_per_frame; \/\/ samples \/ frame\n-    guint num_channels;      \/\/ channel count\n-\n-    guint64  initial_offset; \/\/ offset of first frame in stream (bytes)\n-    gint64   stream_length;  \/\/ length of MPEG audio stream (bytes)\n-    gint64   duration;       \/\/ duration of the MP3 stream (nsec.)\n-\n-    guint frame_duration;    \/\/ duration of a frame (nsec.)\n-\n-    gboolean is_priming;     \/\/ whether the decoder is being primed\n-    gboolean has_pad_caps;   \/\/ whether the pad caps have been set\n-    gboolean is_flushing;    \/\/ element is between flush start and stop\n-\n-    gboolean enable_parser;  \/\/ whether stream parsing is enabled\n-\n-    GstCaps *sink_caps;\n-    GstEvent *segment_event;\n-\n-    AudioFileStreamID audioStreamID;\n-\n-    Boolean isFormatInitialized;\n-    AudioStreamBasicDescription audioInputFormat;\n-    AudioStreamBasicDescription audioOutputFormat;\n-\n-    UInt64 audioDataPacketCount;\n-    Boolean hasAudioPacketTableInfo;\n-    AudioFilePacketTableInfo packetTableInfo;\n-\n-    UInt32 cookieSize;\n-    void* cookieData;\n-    Boolean isAudioConverterReady;\n-    AudioConverterRef audioConverter;\n-\n-    AudioStreamPacketDescription* outPacketDescription;\n-\n-    void* previousDesc; \/\/ pointer to AudioStreamPacketDescription memory allocated during\n-                        \/\/ most recent to call to retrieveInputData\n-};\n-\n-struct _AudioConverterClass\n-{\n-    GstElementClass parent_class;\n-};\n-\n-GType audioconverter_get_type (void);\n-\n-gboolean audioconverter_plugin_init (GstPlugin * audioconverter);\n-\n-G_END_DECLS\n-\n-#endif \/\/ __AUDIOCONVERTER_H__\n","filename":"modules\/javafx.media\/src\/main\/native\/gstreamer\/plugins\/audioconverter\/audioconverter.h","additions":0,"deletions":139,"binary":false,"changes":139,"status":"deleted"},{"patch":"@@ -1,882 +0,0 @@\n-\/*\n- * Copyright (c) 2010, 2021, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#ifdef HAVE_CONFIG_H\n-#include <config.h>\n-#endif\n-\n-#include <string.h>\n-#include <gst\/gst.h>\n-\n-#include \"avcdecoder.h\"\n-\n-\/\/ Note: define as non-zero to enable warnings.\n-#define ENABLE_WARNINGS 1\n-\n-\/***************************************************************\/\n-\n-GST_DEBUG_CATEGORY_STATIC (avcdecoder_debug);\n-#define GST_CAT_DEFAULT avcdecoder_debug\n-\n-\/*\n- * The input capabilities.\n- *\/\n-static GstStaticPadTemplate sink_factory =\n-GST_STATIC_PAD_TEMPLATE (\"sink\",\n-                         GST_PAD_SINK,\n-                         GST_PAD_ALWAYS,\n-                         GST_STATIC_CAPS (\n-                         \"video\/x-h264; \"\n-                         \"video\/x-h265\") \/\/ Fake caps, so we can connect and post error\n-                         );\n-\n-\/*\n- * The output capabilities.\n- *\/\n-\/\/ Note: For 'yuvs' the format should be \"format = (fourcc) YUY2\"\n-static GstStaticPadTemplate src_factory =\n-GST_STATIC_PAD_TEMPLATE (\"src\",\n-                         GST_PAD_SRC,\n-                         GST_PAD_ALWAYS,\n-                         GST_STATIC_CAPS (\"video\/x-raw-ycbcr422, format = (string) UYVY\")\n-                         );\n-\n-\/***********************************************************************************\n- * Substitution for\n- * G_DEFINE_TYPE (AvcDecoder, avcdecoder, GstElement, GST_TYPE_ELEMENT);\n- ***********************************************************************************\/\n-#define avcdecoder_parent_class parent_class\n-static void avcdecoder_init          (AvcDecoder      *self);\n-static void avcdecoder_class_init    (AvcDecoderClass *klass);\n-static gpointer avcdecoder_parent_class = NULL;\n-static void     avcdecoder_class_intern_init (gpointer klass)\n-{\n-    avcdecoder_parent_class = g_type_class_peek_parent (klass);\n-    avcdecoder_class_init ((AvcDecoderClass*) klass);\n-}\n-\n-GType avcdecoder_get_type (void)\n-{\n-    static volatile gsize gonce_data = 0;\n-\/\/ INLINE - g_once_init_enter()\n-    if (g_once_init_enter (&gonce_data))\n-    {\n-        GType _type;\n-        _type = g_type_register_static_simple (GST_TYPE_ELEMENT,\n-               g_intern_static_string (\"AvcDecoder\"),\n-               sizeof (AvcDecoderClass),\n-               (GClassInitFunc) avcdecoder_class_intern_init,\n-               sizeof(AvcDecoder),\n-               (GInstanceInitFunc) avcdecoder_init,\n-               (GTypeFlags) 0);\n-        g_once_init_leave (&gonce_data, (gsize) _type);\n-    }\n-    return (GType) gonce_data;\n-}\n-\n-\/*\n- * Forward declarations.\n- *\/\n-static GstStateChangeReturn avcdecoder_change_state (GstElement* element, GstStateChange transition);\n-static gboolean avcdecoder_sink_event (GstPad * pad, GstObject *parent, GstEvent * event);\n-static GstFlowReturn avcdecoder_chain (GstPad * pad, GstObject *parent, GstBuffer * buf);\n-static void avcdecoder_dispose(GObject* object);\n-static void avcdecoder_state_destroy(AvcDecoder *decode);\n-\n-\/* --- GObject vmethod implementations --- *\/\n-\n-\/*\n- * Initialize avcdecoder's class.\n- *\/\n-static void\n-avcdecoder_class_init (AvcDecoderClass * klass)\n-{\n-    GstElementClass *gstelement_class = (GstElementClass *) klass;\n-    GObjectClass *gobject_class = (GObjectClass*)klass;\n-\n-    gst_element_class_set_metadata(gstelement_class,\n-                                         \"AVCDecoder\",\n-                                         \"Codec\/Decoder\/Video\",\n-                                         \"Decode raw MPEG-4 H.264 video stream\",\n-                                         \"Oracle Corporation\");\n-\n-    gst_element_class_add_pad_template (gstelement_class,\n-                                        gst_static_pad_template_get (&src_factory));\n-    gst_element_class_add_pad_template (gstelement_class,\n-                                        gst_static_pad_template_get (&sink_factory));\n-\n-    gstelement_class->change_state = avcdecoder_change_state;\n-\n-    gobject_class->dispose = avcdecoder_dispose;\n-}\n-\n-\/*\n- * Initialize the new element.\n- * Instantiate pads and add them to element.\n- * Set pad callback functions.\n- * Initialize instance structure.\n- *\/\n-static void\n-avcdecoder_init (AvcDecoder * decode)\n-{\n-    \/\/ Input.\n-    if (NULL == (decode->sinkpad = gst_pad_new_from_static_template (&sink_factory, \"sink\")))\n-    {\n-#if ENABLE_WARNINGS\n-        g_warning (\"avcdecoder element failed to create sink pad!\\n\");\n-#endif\n-        return;\n-    }\n-\n-    if (FALSE == gst_element_add_pad (GST_ELEMENT (decode), decode->sinkpad))\n-    {\n-#if ENABLE_WARNINGS\n-        g_warning (\"avcdecoder element failed to add sink pad!\\n\");\n-#endif\n-    }\n-\n-    gst_pad_set_chain_function (decode->sinkpad, GST_DEBUG_FUNCPTR(avcdecoder_chain));\n-    gst_pad_set_event_function(decode->sinkpad, avcdecoder_sink_event);\n-\n-    \/\/ Output.\n-    if (NULL == (decode->srcpad = gst_pad_new_from_static_template (&src_factory, \"src\")))\n-    {\n-#if ENABLE_WARNINGS\n-        g_warning (\"avcdecoder element failed to create sink pad!\\n\");\n-#endif\n-        return;\n-    }\n-\n-    if (TRUE != gst_element_add_pad (GST_ELEMENT (decode), decode->srcpad))\n-    {\n-#if ENABLE_WARNINGS\n-        g_warning (\"avcdecoder element failed to add source pad!\\n\");\n-#endif\n-    }\n-\n-    gst_pad_use_fixed_caps (decode->srcpad);\n-\n-    g_mutex_init(&decode->mutex);\n-}\n-\n-static void\n-avcdecoder_dispose(GObject* object)\n-{\n-    AvcDecoder* decode = AVCDECODER(object);\n-\n-    avcdecoder_state_destroy (decode);\n-\n-    g_mutex_clear(&decode->mutex);\n-\n-    G_OBJECT_CLASS(parent_class)->dispose(object);\n-}\n-\n-\/* --- GstElement vmethod implementations --- *\/\n-\n-\/*\n- * GCompareDataFunc used to sort GstBuffers into order of ascending timestamp.\n- *\/\n-static gint\n-avcdecoder_buffer_compare (gconstpointer a, gconstpointer b, gpointer user_data)\n-{\n-    gint ret = 0;\n-\n-    if (NULL != a && NULL != b)\n-    {\n-        const GstBuffer* bufa = (const GstBuffer*)a;\n-        const GstBuffer* bufb = (const GstBuffer*)b;\n-\n-        if (GST_BUFFER_TIMESTAMP_IS_VALID(bufa) && GST_BUFFER_TIMESTAMP_IS_VALID(bufb))\n-        {\n-            GstClockTime ta = GST_BUFFER_TIMESTAMP(bufa);\n-            GstClockTime tb = GST_BUFFER_TIMESTAMP(bufb);\n-            if (ta < tb)\n-            {\n-                ret = -1;\n-            }\n-            else if (ta > tb)\n-            {\n-                ret = 1;\n-            }\n-            \/\/ else ret = 0 by default.\n-        }\n-    }\n-\n-    return ret;\n-}\n-\n-\/*\n- * Callback which receives decoded video frames from the VDADecoder. The\n- * decoded frames are not guaranteed to be in timestamp-order and it is\n- * unknown how many frames there are between I-frames. Frames are pushed\n- * in the order received to a GAsyncQueue. This data type is used as there\n- * is no apparent way without causing a deadlock to lock a sorted queue or\n- * sequence by both this callback and the function which sorts the frames\n- * in timestamp-order.\n- *\/\n-static void\n-avcdecoder_decoder_output_callback (void* userData,\n-                                    CFDictionaryRef frameInfo,\n-                                    OSStatus status,\n-                                    uint32_t infoFlags,\n-                                    CVImageBufferRef imageBuffer)\n-{\n-    AvcDecoder *decode = AVCDECODER (userData);\n-\n-    if(decode->is_flushing)\n-    {\n-        return;\n-    }\n-\n-    \/\/ Check whether there is a problem.\n-\n-    gboolean isGap = FALSE;\n-\n-    if (kVDADecoderNoErr != status)\n-    {\n-#if ENABLE_WARNINGS\n-        g_warning(\"output callback received status %d\\n\", (int)status);\n-#endif\n-        isGap = TRUE;\n-    } else if (1UL << 1 == (infoFlags & (1UL << 1))) \/\/ XXX hard-coding\n-    {\n-#if ENABLE_WARNINGS\n-        g_warning(\"output callback called on dropped frame\\n\");\n-#endif\n-        isGap = TRUE;\n-    } else if (NULL == imageBuffer)\n-    {\n-#if ENABLE_WARNINGS\n-        g_warning (\"output callback received NULL image buffer!\\n\");\n-#endif\n-        isGap = TRUE;\n-    } else if ('2vuy' != CVPixelBufferGetPixelFormatType(imageBuffer))\n-    {\n-#if ENABLE_WARNINGS\n-        g_warning(\"output callback image buffer format not '2vuy'\\n\");\n-#endif\n-        isGap = TRUE;\n-    }\n-\n-    \/\/ Retrieve the timestamp and delta flag.\n-\n-    int64_t timestamp = 0;\n-    int32_t deltaFlag = 0; \/\/ deltaFlag == 0 indicates an intra-frame, non-zero an inter-frame.\n-    if (NULL != frameInfo)\n-    {\n-        CFNumberRef timestampRef = CFDictionaryGetValue(frameInfo, CFSTR(\"timestamp\"));\n-        if (timestampRef)\n-        {\n-            CFNumberGetValue(timestampRef, kCFNumberSInt64Type, &timestamp);\n-        }\n-        CFNumberRef deltaFlagRef = CFDictionaryGetValue(frameInfo, CFSTR(\"deltaFlag\"));\n-        if (deltaFlagRef)\n-        {\n-            CFNumberGetValue(deltaFlagRef, kCFNumberSInt32Type, &deltaFlag);\n-        }\n-    }\n-\n-    if (timestamp < decode->segment_start)\n-    {\n-        return;\n-    }\n-\n-    GstBuffer* buf = NULL;\n-\n-    if (isGap)\n-    {\n-        \/\/ Push a flagged, empty buffer it there is a problem.\n-\n-        buf = gst_buffer_new();\n-        GST_BUFFER_TIMESTAMP(buf) = timestamp;\n-        GST_BUFFER_FLAG_SET(buf, GST_BUFFER_FLAG_GAP);\n-    }\n-    else\n-    {\n-        \/\/ Push a valid buffer.\n-\n-        CVBufferRetain(imageBuffer); \/\/ return value equals parameter\n-\n-        GstPad* srcpad = decode->srcpad;\n-\n-        size_t width = CVPixelBufferGetWidth(imageBuffer);\n-        size_t height = CVPixelBufferGetHeight(imageBuffer);\n-        size_t bytes_per_row = CVPixelBufferGetBytesPerRow(imageBuffer);\n-        if(!decode->is_stride_set)\n-        {\n-            GstCaps *pad_caps = gst_pad_get_current_caps(srcpad);\n-            if (pad_caps != NULL)\n-            {\n-                GstCaps *caps = gst_caps_copy(pad_caps);\n-                if (caps != NULL)\n-                {\n-                    gst_caps_set_simple(caps, \"line_stride\", G_TYPE_INT, (int)bytes_per_row, NULL);\n-                    GstEvent *caps_event = gst_event_new_caps(caps);\n-                    if (caps_event != NULL)\n-                        gst_pad_push_event(decode->srcpad, caps_event);\n-                    decode->is_stride_set = TRUE;\n-                    gst_caps_unref(caps);\n-                }\n-                gst_caps_unref(pad_caps);\n-            }\n-        }\n-        if (kCVReturnSuccess == CVPixelBufferLockBaseAddress (imageBuffer, 0))\n-        {\n-            void* image_data = CVPixelBufferGetBaseAddress(imageBuffer);\n-            buf = gst_buffer_new_allocate(NULL, bytes_per_row*height, NULL);\n-            if (buf != NULL)\n-            {\n-                GstMapInfo info;\n-                if (gst_buffer_map(buf, &info, GST_MAP_WRITE))\n-                {\n-                    memcpy (info.data, image_data, info.size);\n-                    gst_buffer_unmap(buf, &info);\n-                    GST_BUFFER_TIMESTAMP(buf) = timestamp;\n-                }\n-            }\n-\n-            CVPixelBufferUnlockBaseAddress (imageBuffer, 0); \/\/ ignore return value\n-        }\n-\n-        CVBufferRelease(imageBuffer);\n-\n-        if (!buf)\n-        {\n-            buf = gst_buffer_new();\n-            GST_BUFFER_TIMESTAMP(buf) = timestamp;\n-            GST_BUFFER_FLAG_SET(buf, GST_BUFFER_FLAG_GAP);\n-        }\n-    }\n-\n-    \/\/ the callback might be called from several threads\n-    \/\/ need to synchronize ordered_frames queue access\n-    g_mutex_lock(&decode->mutex);\n-\n-    g_queue_insert_sorted(decode->ordered_frames, buf, avcdecoder_buffer_compare, NULL);\n-\n-    GstBuffer* frame;\n-    GstFlowReturn ret = GST_FLOW_OK;\n-    while(ret == GST_FLOW_OK && !decode->is_flushing && NULL != (frame = g_queue_peek_head(decode->ordered_frames)))\n-    {\n-        GstClockTime ts = GST_BUFFER_TIMESTAMP(frame);\n-        if(GST_CLOCK_TIME_NONE == decode->previous_timestamp ||         \/\/ first frame\n-           ts <= decode->previous_timestamp + decode->timestamp_ceil || \/\/ frame is at next timestamp\n-           (0 == deltaFlag && ts < timestamp))                          \/\/ have newer I-frame\n-        {\n-            decode->previous_timestamp = ts;\n-            g_queue_pop_head(decode->ordered_frames);\n-\n-            if(GST_BUFFER_FLAG_IS_SET(frame, GST_BUFFER_FLAG_GAP))\n-            {\n-                \/\/ INLINE - gst_buffer_unref()\n-                gst_buffer_unref (frame);\n-            }\n-            else\n-            {\n-                if(decode->is_newsegment)\n-                {\n-                    GST_BUFFER_FLAG_SET(frame, GST_BUFFER_FLAG_DISCONT);\n-                    decode->is_newsegment = FALSE;\n-                }\n-\n-                \/\/ it's better not to call gst_pad_push under mutex to avoid deadlocks\n-                g_mutex_unlock(&decode->mutex);\n-                ret = gst_pad_push(decode->srcpad, frame);\n-                g_mutex_lock(&decode->mutex);\n-            }\n-        }\n-        else\n-        {\n-            break;\n-        }\n-    }\n-\n-    g_mutex_unlock(&decode->mutex);\n-}\n-\n-\/*\n- * GFunc used to unref GstBuffers in a queue.\n- *\/\n-static void\n-avcdecoder_element_destroy(gpointer data, gpointer user_data)\n-{\n-    if (NULL != data)\n-    {\n-        GstBuffer* buf = (GstBuffer*)data;\n-\n-        \/\/ INLINE - gst_buffer_unref()\n-        gst_buffer_unref (buf);\n-    }\n-}\n-\n-\/**\n- * Initialize the AvcDecoder structure. This should happen\n- * only once, before decoding begins.\n- *\/\n-static void\n-avcdecoder_state_init(AvcDecoder *decode)\n-{\n-    decode->outputCallback = (VDADecoderOutputCallback*)avcdecoder_decoder_output_callback;\n-    decode->decoder = NULL;\n-    decode->is_initialized = FALSE;\n-    decode->is_newsegment = FALSE;\n-    decode->is_stride_set = FALSE;\n-    decode->frame_duration = GST_CLOCK_TIME_NONE;\n-    decode->ordered_frames = g_queue_new();\n-    decode->segment_start = 0;\n-}\n-\n-\/**\n- * Reset the state of the AvcDecoder structure.\n- *\/\n-static void\n-avcdecoder_state_reset(AvcDecoder *decode)\n-{\n-    \/\/ Flush the decoder.\n-    if (NULL != decode->decoder)\n-    {\n-        OSStatus result = VDADecoderFlush (decode->decoder, 0);\n-#if ENABLE_WARNINGS\n-        if (kVDADecoderNoErr != result)\n-        {\n-            g_warning (\"Could not flush decoder: result code %d\\n\", (int)result);\n-        }\n-#endif\n-    }\n-\n-    g_mutex_lock(&decode->mutex);\n-\n-    \/\/ Unref all sorted buffers and clear the associated queue.\n-    if (NULL != decode->ordered_frames)\n-    {\n-        g_queue_foreach(decode->ordered_frames, avcdecoder_element_destroy, NULL);\n-        g_queue_clear(decode->ordered_frames);\n-    }\n-\n-    decode->is_newsegment = FALSE;\n-    decode->segment_start = 0;\n-\n-    g_mutex_unlock(&decode->mutex);\n-}\n-\n-\/**\n- * Reset and then destroy the state of the AvcDecoder structure.\n- *\/\n-static void\n-avcdecoder_state_destroy(AvcDecoder *decode)\n-{\n-    \/\/ Reset the state.\n-    avcdecoder_state_reset(decode);\n-\n-    \/\/ Release the VDADecoder.\n-    if (NULL != decode->decoder)\n-    {\n-        OSStatus result = VDADecoderDestroy (decode->decoder);\n-#if ENABLE_WARNINGS\n-        if (kVDADecoderNoErr != result)\n-        {\n-            g_warning (\"Could not destroy decoder: result code %d\\n\", (int)result);\n-        }\n-#endif\n-        decode->decoder = NULL;\n-    }\n-\n-    \/\/ Free the sorted queue.\n-    if (NULL != decode->ordered_frames)\n-    {\n-        g_queue_free(decode->ordered_frames);\n-        decode->ordered_frames = NULL;\n-    }\n-}\n-\n-\/*\n- * Perform processing needed for state transitions.\n- *\/\n-static GstStateChangeReturn\n-avcdecoder_change_state (GstElement* element, GstStateChange transition)\n-{\n-    AvcDecoder *decode = AVCDECODER(element);\n-\n-    switch(transition)\n-    {\n-        case GST_STATE_CHANGE_NULL_TO_READY:\n-            \/\/ Initialize the AvcDecoder structure.\n-            avcdecoder_state_init (decode);\n-            break;\n-        default:\n-            break;\n-    }\n-\n-    \/\/ Change state.\n-    return GST_ELEMENT_CLASS(parent_class)->change_state(element, transition);\n-}\n-\n-static GstFlowReturn\n-avcdecoder_init_decoder (AvcDecoder *decode, GstCaps* videoSpecificCaps)\n-{\n-    GstFlowReturn ret = GST_FLOW_OK;\n-    OSStatus status = kVDADecoderNoErr;\n-    GstStructure *s = NULL;\n-    const gchar *mimetype = NULL;\n-\n-    \/\/ Post error to halt playback if we asked to decode HEVC, so we can\n-    \/\/ fallback to OSXPlatform. With soft error we will play audio only for MP4\n-    \/\/ with HEVC and AAC.\n-    s = gst_caps_get_structure(videoSpecificCaps, 0);\n-    if (s != NULL)\n-    {\n-        mimetype = gst_structure_get_name(s);\n-        if (mimetype != NULL)\n-        {\n-            if (strstr(mimetype, \"video\/x-h265\") != NULL)\n-            {\n-                gst_element_message_full(GST_ELEMENT(decode), GST_MESSAGE_ERROR,\n-                        GST_STREAM_ERROR, GST_STREAM_ERROR_DECODE,\n-                        g_strdup(\"GSTPlatform does not support HEVC on macOS, use OSXPlatform instead.\"),\n-                        NULL, (\"avcdecoder.c\"), (\"avcdecoder_init_decoder\"), 0);\n-\n-                return GST_FLOW_ERROR;\n-            }\n-        }\n-    }\n-\n-    \/\/ Initialize the element structure.\n-    if (FALSE == decode->is_initialized)\n-    {\n-        \/\/ Obtain configuration data from the \"codec_data\" structure in the sink caps.\n-        if (NULL == videoSpecificCaps || gst_caps_get_size(videoSpecificCaps) < 1)\n-        {\n-            return GST_FLOW_ERROR;\n-        }\n-\n-        GstStructure* videoSpecificStructure = gst_caps_get_structure (videoSpecificCaps, 0);\n-\n-        const GValue *videoSpecificValue = gst_structure_get_value(videoSpecificStructure, \"codec_data\");\n-        if (NULL == videoSpecificValue)\n-        {\n-            return GST_FLOW_ERROR;\n-        }\n-\n-        gint encoded_width;\n-        if (!gst_structure_get_int (videoSpecificStructure, \"width\", &encoded_width))\n-            encoded_width = 0;\n-\n-        gint encoded_height;\n-        if (!gst_structure_get_int (videoSpecificStructure, \"height\", &encoded_height))\n-            encoded_height = 0;\n-\n-        gint framerate_num;\n-        gint framerate_den;\n-        if (!gst_structure_get_fraction (videoSpecificStructure, \"framerate\", &framerate_num, &framerate_den))\n-        {\n-            framerate_num = 25;\n-            framerate_den = 1;\n-        }\n-\n-        \/\/ Calculate frame duration and timestamp bound.\n-        decode->frame_duration = gst_util_uint64_scale_int_ceil(GST_SECOND, framerate_den, framerate_num);\n-        decode->timestamp_ceil = (GstClockTime)(1.5*decode->frame_duration + 0.5);\n-\n-        SInt32 avcWidth = (SInt32)encoded_width;\n-        SInt32 avcHeight = (SInt32)encoded_height;\n-\n-        \/\/ Set up parameters required to create the VDADecoder.\n-        CFNumberRef width = CFNumberCreate(kCFAllocatorDefault, kCFNumberSInt32Type, &avcWidth);\n-        CFNumberRef height = CFNumberCreate(kCFAllocatorDefault, kCFNumberSInt32Type, &avcHeight);\n-        SInt32 sourceFormat = 'avc1';\n-        CFNumberRef avcFormat = CFNumberCreate(kCFAllocatorDefault, kCFNumberSInt32Type, &sourceFormat);\n-\n-        GstBuffer*  videoSpecificBuffer = gst_value_get_buffer (videoSpecificValue);\n-        GstMapInfo info;\n-        CFDataRef avcCData = NULL;\n-        if (gst_buffer_map(videoSpecificBuffer, &info, GST_MAP_READ))\n-        {\n-            guint8* videoSpecificData = info.data;\n-            guint videoSpecificDataLength = info.size;\n-            avcCData = CFDataCreate(kCFAllocatorDefault, videoSpecificData, videoSpecificDataLength);\n-            gst_buffer_unmap(videoSpecificBuffer, &info);\n-        }\n-\n-        CFMutableDictionaryRef decoderConfiguration = (CFDictionaryCreateMutable(kCFAllocatorDefault, 4, &kCFTypeDictionaryKeyCallBacks, &kCFTypeDictionaryValueCallBacks));\n-\n-        CFDictionarySetValue(decoderConfiguration, kVDADecoderConfiguration_Height, height);\n-        CFDictionarySetValue(decoderConfiguration, kVDADecoderConfiguration_Width, width);\n-        CFDictionarySetValue(decoderConfiguration, kVDADecoderConfiguration_SourceFormat, avcFormat);\n-        if (avcCData != NULL)\n-            CFDictionarySetValue(decoderConfiguration, kVDADecoderConfiguration_avcCData, avcCData);\n-\n-        \/\/ Note: For 'yuvs' the formatType should be kYUVSPixelFormat.\n-        SInt32 formatType = k2vuyPixelFormat;\n-        CFNumberRef imgFormat = CFNumberCreate(kCFAllocatorDefault, kCFNumberSInt32Type, &formatType);\n-        CFMutableDictionaryRef destinationImageBufferAttributes = CFDictionaryCreateMutable(kCFAllocatorDefault, 2, &kCFTypeDictionaryKeyCallBacks, &kCFTypeDictionaryValueCallBacks);\n-\n-        \/\/ empty IOSurface properties dictionary\n-        CFDictionaryRef emptyDictionary = CFDictionaryCreate(kCFAllocatorDefault,\n-                                                             NULL,\n-                                                             NULL,\n-                                                             0,\n-                                                             &kCFTypeDictionaryKeyCallBacks,\n-                                                             &kCFTypeDictionaryValueCallBacks);\n-\n-        CFDictionarySetValue(destinationImageBufferAttributes,\n-                             kCVPixelBufferPixelFormatTypeKey, imgFormat);\n-        CFDictionarySetValue(destinationImageBufferAttributes,\n-                             kCVPixelBufferIOSurfacePropertiesKey,\n-                             emptyDictionary); \/\/ XXX probably should delete this.\n-\n-        \/\/ Create the VDADecoder.\n-        status = VDADecoderCreate(decoderConfiguration,\n-                                  destinationImageBufferAttributes,\n-                                  (VDADecoderOutputCallback *)decode->outputCallback,\n-                                  (void *)decode,\n-                                  &decode->decoder);\n-\n-        if (decoderConfiguration)\n-            CFRelease(decoderConfiguration);\n-        if (destinationImageBufferAttributes)\n-            CFRelease(destinationImageBufferAttributes);\n-        if (emptyDictionary)\n-            CFRelease(emptyDictionary);\n-        if (avcCData)\n-            CFRelease(avcCData);\n-\n-        if (kVDADecoderNoErr == status)\n-        {\n-            \/\/ Set the srcpad caps.\n-\n-            \/\/ Note: For 'yuvs' the format should be GST_MAKE_FOURCC ('Y', 'U', 'Y', '2')\n-            GstCaps* caps = gst_caps_new_simple (\n-                                                 \"video\/x-raw-ycbcr422\",\n-                                                 \"format\", G_TYPE_STRING, \"UYVY\",\n-                                                 \"framerate\", GST_TYPE_FRACTION, framerate_num, framerate_den,\n-                                                 \"width\", G_TYPE_INT, encoded_width,\n-                                                 \"height\", G_TYPE_INT, encoded_height,\n-                                                 NULL);\n-            GstEvent *caps_event = gst_event_new_caps(caps);\n-            if (caps_event)\n-                gst_pad_push_event (decode->srcpad, caps_event);\n-            gst_caps_unref (caps);\n-\n-            decode->is_initialized = TRUE;\n-        }\n-        else\n-        {\n-#if ENABLE_WARNINGS\n-            const char* message;\n-            switch (status)\n-            {\n-                case kVDADecoderHardwareNotSupportedErr:\n-                    message = \"hardware does not support accelerated video decode services\";\n-                    break;\n-                case kVDADecoderFormatNotSupportedErr:\n-                    message = \"hardware decoder does not support requested output format\";\n-                    break;\n-                case kVDADecoderConfigurationError:\n-                    message = \"unsupported hardware decoder configuration parameters\";\n-                    break;\n-                case kVDADecoderDecoderFailedErr:\n-                    message = \"hardware decoder resources in use by another process or cannot decode the source into the requested format\";\n-                    break;\n-                default:\n-                    message = \"unknown error\";\n-                    break;\n-            }\n-            g_warning (\"Could not create decoder: result code %d, %s\", (int)status, message);\n-#endif\n-\n-            \/\/ Post an error message to the pipeline bus.\n-            GError* error = g_error_new (g_quark_from_string(\"AVCDecoder\"), 666, \"%s\", message);\n-            GstMessage* msg = gst_message_new_error (GST_OBJECT (decode), error, message);\n-            gst_element_post_message(GST_ELEMENT(decode), msg);\n-\n-            ret = GST_FLOW_ERROR;\n-        }\n-    }\n-\n-    return ret;\n-}\n-\n-\/*\n- * FLUSH_START, NEWSEGMENT, and FLUSH_STOP are recognized and forwarded;\n- * all others are simply forwarded.\n- *\/\n-static gboolean\n-avcdecoder_sink_event (GstPad * pad, GstObject *parent, GstEvent * event)\n-{\n-    gboolean ret = FALSE;\n-    AvcDecoder *decode = AVCDECODER (parent);\n-    GstSegment segment;\n-\n-    switch (GST_EVENT_TYPE (event))\n-    {\n-        case GST_EVENT_FLUSH_START:\n-        {\n-            \/\/ Start flushing buffers.\n-\n-            \/\/ Set flag so chain function refuses buffers.\n-            decode->is_flushing = TRUE;\n-\n-            break;\n-        }\n-\n-        case GST_EVENT_FLUSH_STOP:\n-        {\n-            \/\/ Stop flushing buffers.\n-            avcdecoder_state_reset(decode);\n-\n-            \/\/ Unset flag so chain function accepts buffers.\n-            decode->is_flushing = FALSE;\n-\n-            break;\n-        }\n-\n-        case GST_EVENT_SEGMENT:\n-        {\n-            \/\/ Set a flag indicating a new segment has begun.\n-            decode->is_newsegment = TRUE;\n-            decode->previous_timestamp = GST_CLOCK_TIME_NONE;\n-            gst_event_copy_segment(event, &segment);\n-            if(GST_FORMAT_TIME == segment.format)\n-            {\n-                decode->segment_start = segment.start;\n-            }\n-            break;\n-        }\n-\n-        case GST_EVENT_CAPS:\n-        {\n-            GstCaps *caps;\n-\n-            gst_event_parse_caps (event, &caps);\n-            avcdecoder_init_decoder(decode, caps);\n-\n-            \/\/ INLINE - gst_event_unref()\n-            gst_event_unref (event);\n-            ret = TRUE;\n-            break;\n-        }\n-\n-        default:\n-            break;\n-    }\n-\n-    \/\/ Push the event downstream.\n-    if (!ret)\n-        ret = gst_pad_push_event (decode->srcpad, event);\n-\n-    return ret;\n-}\n-\n-\/*\n- * Processes a buffer of AVC-encoded video data pushed to the sink pad.\n- *\/\n-static GstFlowReturn\n-avcdecoder_chain (GstPad * pad, GstObject *parent, GstBuffer * buf)\n-{\n-    GstFlowReturn ret = GST_FLOW_OK;\n-    AvcDecoder *decode = AVCDECODER (parent);\n-    OSStatus status = kVDADecoderNoErr;\n-\/\/    g_print(\"chain - time %f discont %d flags %d\\n\",\n-\/\/            (float)GST_BUFFER_TIMESTAMP(buf)\/(float)GST_SECOND,\n-\/\/            (int)GST_BUFFER_IS_DISCONT(buf), (int)GST_BUFFER_FLAGS(buf));\n-\n-    \/\/ If between FLUSH_START and FLUSH_STOP, reject new buffers.\n-    if (decode->is_flushing)\n-    {\n-        \/\/ Unref the input buffer.\n-        \/\/ INLINE - gst_buffer_unref()\n-        gst_buffer_unref(buf);\n-\n-        return GST_FLOW_FLUSHING;\n-    }\n-\n-    if (GST_FLOW_OK == ret)\n-    {\n-        \/\/ Set the timestamp of the encoded frame.\n-        int64_t timestamp = GST_BUFFER_TIMESTAMP (buf);\n-        CFStringRef timestamp_key = CFSTR(\"timestamp\");\n-        CFNumberRef timestamp_value = CFNumberCreate(kCFAllocatorDefault, kCFNumberSInt64Type, &timestamp);\n-        int32_t deltaFlag = (int32_t)(GST_BUFFER_FLAG_IS_SET(buf, GST_BUFFER_FLAG_DELTA_UNIT) ?\n-                                      GST_BUFFER_FLAG_DELTA_UNIT : 0);\n-        CFStringRef delta_key = CFSTR(\"deltaFlag\");\n-        CFNumberRef delta_value = CFNumberCreate(kCFAllocatorDefault, kCFNumberSInt32Type, &deltaFlag);\n-        CFStringRef keys[2];\n-        CFNumberRef values[2];\n-        keys[0] = timestamp_key;\n-        keys[1] = delta_key;\n-        values[0] = timestamp_value;\n-        values[1] = delta_value;\n-        CFDictionaryRef frame_info = CFDictionaryCreate(kCFAllocatorDefault,\n-                                                        (const void **)&keys,\n-                                                        (const void **)&values,\n-                                                        2,\n-                                                        &kCFTypeDictionaryKeyCallBacks,\n-                                                        &kCFTypeDictionaryValueCallBacks);\n-\n-        GstMapInfo info;\n-        CFTypeRef buffer = NULL;\n-        if (gst_buffer_map(buf, &info, GST_MAP_READ))\n-        {\n-            buffer = CFDataCreate(kCFAllocatorDefault, info.data, info.size);\n-            gst_buffer_unmap(buf, &info);\n-\n-            \/\/ Send the encoded frame to the VDADecoder.\n-            status = VDADecoderDecode (decode->decoder, 0, buffer, frame_info);\n-            CFRelease(buffer);\n-            CFRelease(frame_info);\n-\n-            if (kVDADecoderNoErr != status)\n-            {\n-#if ENABLE_WARNINGS\n-                g_warning (\"Could not decode data: result code %d\\n\", (int)status);\n-#endif\n-\n-                \/\/ Set an error return code only if this was not a \"simple\" decoding error.\n-                if (kVDADecoderDecoderFailedErr != status)\n-                {\n-                    ret = GST_FLOW_ERROR;\n-                }\n-            }\n-        }\n-    }\n-\n-    \/\/ INLINE - gst_buffer_unref()\n-    gst_buffer_unref (buf);\n-\n-    return ret;\n-}\n-\n-\/\/ --------------------------------------------------------------------------\n-gboolean avcdecoder_plugin_init (GstPlugin * avcdecoder)\n-{\n-    \/* debug category for fltering log messages\n-     *\n-     * exchange the string 'Template avcdecoder' with your description\n-     *\/\n-    GST_DEBUG_CATEGORY_INIT (avcdecoder_debug, \"avcdecoder\",\n-                             0, \"Template avcdecoder\"); \/\/ FIXME\n-\n-    return gst_element_register (avcdecoder, \"avcdecoder\", 512, TYPE_AVCDECODER);\n-}\n","filename":"modules\/javafx.media\/src\/main\/native\/gstreamer\/plugins\/avcdecoder\/avcdecoder.c","additions":0,"deletions":882,"binary":false,"changes":882,"status":"deleted"},{"patch":"@@ -1,85 +0,0 @@\n-\/*\n- * Copyright (c) 2010, 2015, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#ifndef __AVCDECODER_H__\n-#define __AVCDECODER_H__\n-\n-#include <gst\/gst.h>\n-#include <CoreFoundation\/CoreFoundation.h>\n-#include <VideoDecodeAcceleration\/VDADecoder.h>\n-\n-G_BEGIN_DECLS\n-\n-#define TYPE_AVCDECODER \\\n-(avcdecoder_get_type())\n-#define AVCDECODER(obj) \\\n-(G_TYPE_CHECK_INSTANCE_CAST((obj),TYPE_AVCDECODER,AvcDecoder))\n-#define AVCDECODER_CLASS(klass) \\\n-(G_TYPE_CHECK_CLASS_CAST((klass),TYPE_AVCDECODER,AvcDecoderClass))\n-#define IS_AVCDECODER(obj) \\\n-(G_TYPE_CHECK_INSTANCE_TYPE((obj),TYPE_AVCDECODER))\n-#define IS_AVCDECODER_CLASS(klass) \\\n-(G_TYPE_CHECK_CLASS_TYPE((klass),TYPE_AVCDECODER))\n-\n-typedef struct _AvcDecoder      AvcDecoder;\n-typedef struct _AvcDecoderClass AvcDecoderClass;\n-\n-struct _AvcDecoder\n-{\n-    GstElement element;\n-\n-    GstPad *sinkpad;        \/\/ input port for MPEG-4 audio\n-    GstPad *srcpad;         \/\/ output port for PCM samples\n-\n-    VDADecoder decoder;     \/\/ the Video Decode Acceleration framework decoder reference\n-    VDADecoderOutputCallback* outputCallback; \/\/ the callback which receives decoded frames\n-\n-    gboolean is_initialized; \/\/ whether this structure is initialized\n-    gboolean is_newsegment; \/\/ whether a new segment has been received\n-    volatile gboolean is_flushing; \/\/ element is between flush start and stop\n-    gboolean is_stride_set; \/\/ whether the output buffer stride has been set\n-\n-    gint64 segment_start; \/\/ the start time of the segment\n-\n-    GstClockTime frame_duration; \/\/ the duration of a single video frame (nsec)\n-\n-    GQueue* ordered_frames;      \/\/ decoded frames sorted into order of increasign time stamp\n-    GMutex mutex;    \/\/ synchronize frames queue access\n-\n-    GstClockTime previous_timestamp; \/\/ the timestamp of the most recent preceding frame\n-    GstClockTime timestamp_ceil;     \/\/ increment above previous timestamp in which frame should fall\n-};\n-\n-struct _AvcDecoderClass\n-{\n-    GstElementClass parent_class;\n-};\n-\n-GType avcdecoder_get_type (void);\n-gboolean avcdecoder_plugin_init (GstPlugin * avcdecoder);\n-\n-G_END_DECLS\n-\n-#endif \/* __AVCDECODER_H__ *\/\n","filename":"modules\/javafx.media\/src\/main\/native\/gstreamer\/plugins\/avcdecoder\/avcdecoder.h","additions":0,"deletions":85,"binary":false,"changes":85,"status":"deleted"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,5 +33,0 @@\n-#ifdef OSX\n-#include <audioconverter.h>\n-#include <avcdecoder.h>\n-#endif\n-\n@@ -55,3 +50,0 @@\n-#elif defined(OSX)\n-           audioconverter_plugin_init(plugin) &&\n-           avcdecoder_plugin_init(plugin) &&\n","filename":"modules\/javafx.media\/src\/main\/native\/gstreamer\/plugins\/fxplugins.c","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#define BUFFER_SIZE 4096\n+\n@@ -846,1 +846,1 @@\n-                gst_buffer_set_size(buf, read); \/\/ Set ammount of valid data in buffer if read less then requested\n+                gst_buffer_set_size(buf, read); \/\/ Set amount of valid data in buffer if read less then requested\n","filename":"modules\/javafx.media\/src\/main\/native\/gstreamer\/plugins\/javasource\/javasource.c","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -15,2 +15,1 @@\n-DIRLIST = audioconverter       \\\n-          progressbuffer       \\\n+DIRLIST = progressbuffer       \\\n@@ -18,2 +17,1 @@\n-          javasource           \\\n-          avcdecoder\n+          javasource\n@@ -57,6 +55,1 @@\n-           -lglib-lite \\\n-           -framework ApplicationServices \\\n-           -framework QuartzCore \\\n-           -framework VideoDecodeAcceleration \\\n-           -framework AudioToolbox \\\n-           -framework CoreFoundation\n+           -lglib-lite\n@@ -65,1 +58,0 @@\n-            audioconverter\/audioconverter.c    \\\n@@ -70,2 +62,1 @@\n-            javasource\/marshal.c               \\\n-            avcdecoder\/avcdecoder.c\n+            javasource\/marshal.c\n","filename":"modules\/javafx.media\/src\/main\/native\/gstreamer\/projects\/mac\/fxplugins\/Makefile","additions":4,"deletions":13,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2013, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -54,2 +54,26 @@\n-CLocator::~CLocator()\n-{}\n+jstring CLocator::LocatorGetStringLocation(JNIEnv *env, jobject locator)\n+{\n+    static jmethodID mid_toString = 0;\n+    jstring result = NULL;\n+    CJavaEnvironment javaEnv(env);\n+\n+    if (mid_toString == 0)\n+    {\n+        jclass klass = env->GetObjectClass(locator);\n+\n+        mid_toString = env->GetMethodID(klass, \"getStringLocation\", \"()Ljava\/lang\/String;\");\n+        env->DeleteLocalRef(klass);\n+        if (javaEnv.clearException())\n+        {\n+            return NULL;\n+        }\n+    }\n+\n+    result = (jstring)env->CallObjectMethod(locator, mid_toString);\n+    if (javaEnv.clearException())\n+    {\n+        return NULL;\n+    }\n+\n+    return result;\n+}\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/Locator\/Locator.cpp","additions":27,"deletions":3,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2013, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,2 @@\n+#include <jni\/JniUtils.h>\n+\n@@ -46,1 +48,0 @@\n-    virtual ~CLocator();\n@@ -50,0 +51,2 @@\n+    static jstring LocatorGetStringLocation(JNIEnv *env, jobject locator);\n+\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/Locator\/Locator.h","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -56,1 +56,1 @@\n-    \/* CopyBlock copies the datra from whatever internal buffer to the destination.*\/\n+    \/* CopyBlock copies the data from whatever internal buffer to the destination.*\/\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/Locator\/LocatorStream.h","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2013, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -37,1 +37,2 @@\n-:   m_PlayerState(Unknown),\n+:   m_pEventDispatcher(NULL),\n+    m_PlayerState(Unknown),\n@@ -39,1 +40,0 @@\n-    m_pEventDispatcher(NULL),\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/PipelineManagement\/Pipeline.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2016, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include <Locator\/Locator.h>\n@@ -51,23 +52,0 @@\n-    static jstring LocatorToString(JNIEnv *env, jobject locator)\n-    {\n-        static jmethodID mid_toString = 0;\n-        jstring result = NULL;\n-        CJavaEnvironment javaEnv(env);\n-\n-        if (mid_toString == 0)\n-        {\n-            jclass klass = env->GetObjectClass(locator);\n-\n-            mid_toString = env->GetMethodID(klass, \"getStringLocation\", \"()Ljava\/lang\/String;\");\n-            env->DeleteLocalRef(klass);\n-            if (javaEnv.clearException())\n-                return NULL;\n-        }\n-\n-        result = (jstring)env->CallObjectMethod(locator, mid_toString);\n-        if (javaEnv.clearException())\n-            return NULL;\n-\n-        return result;\n-    }\n-\n@@ -79,1 +57,1 @@\n-        jstring         jLocation = LocatorToString(env, jLocator);\n+        jstring         jLocation = CLocator::LocatorGetStringLocation(env, jLocator);\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/platform\/gstreamer\/GstMedia.cpp","additions":3,"deletions":25,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2016, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,3 @@\n+#import <jni\/JavaInputStreamCallbacks.h>\n+#import <Locator\/Locator.h>\n+#import <Locator\/LocatorStream.h>\n@@ -101,1 +104,1 @@\n-- (id) initWithURL:(NSURL *)source javaPlayer:(jobject)jp andEnv:(JNIEnv*)env eventHandler:(CJavaPlayerEventDispatcher*)hdlr\n+- (id) initWithURL:(NSURL *)source javaPlayer:(jobject)jp andEnv:(JNIEnv*)env eventHandler:(CJavaPlayerEventDispatcher*)hdlr locatorStream:(CLocatorStream*)ls\n@@ -127,1 +130,1 @@\n-        player = [[gMediaPlayerClass alloc] initWithURL:movieURL eventHandler:eventHandler];\n+        player = [[gMediaPlayerClass alloc] initWithURL:movieURL eventHandler:eventHandler locatorStream:ls];\n@@ -132,1 +135,1 @@\n-- (id) initWithURL:(NSURL *)source eventHandler:(CJavaPlayerEventDispatcher*)hdlr\n+- (id) initWithURL:(NSURL *)source eventHandler:(CJavaPlayerEventDispatcher*)hdlr locatorStream:(CLocatorStream*)ls\n@@ -291,1 +294,2 @@\n-    (JNIEnv *env, jobject playerObject, jstring sourceURI)\n+    (JNIEnv *env, jobject playerObject, jobject jLocator, jstring jContentType,\n+    jlong jSizeHint)\n@@ -293,0 +297,5 @@\n+    CLocatorStream *locatorStream = NULL;\n+    jstring jSourceURI = CLocator::LocatorGetStringLocation(env, jLocator);\n+    char *pjSourceURI = NULL;\n+    char *pjContent = NULL;\n+\n@@ -298,1 +307,1 @@\n-    NSString *sourceURIString = NSStringFromJavaString(env, sourceURI);\n+    NSString *sourceURIString = NSStringFromJavaString(env, jSourceURI);\n@@ -314,1 +323,47 @@\n-    OSXMediaPlayer *player = [[OSXMediaPlayer alloc] initWithURL:mediaURL javaPlayer:playerObject andEnv:env eventHandler:eventHandler];\n+    \/\/ Check if we need to use Locator to read data. For FILE\/HTTP\/HTTPS\n+    \/\/ AVFoundation will read data directly. For JAR\/JRT we will use Locator to\n+    \/\/ read data.\n+    NSString *scheme = [mediaURL scheme];\n+    if ([scheme caseInsensitiveCompare:@\"jar\"] == NSOrderedSame ||\n+        [scheme caseInsensitiveCompare:@\"jrt\"] == NSOrderedSame) {\n+        CJavaInputStreamCallbacks *callbacks = new (nothrow) CJavaInputStreamCallbacks();\n+        if (callbacks == NULL) {\n+            [mediaURL release];\n+            LOGGER_WARNMSG(\"OSXMediaPlayer: Unable to create CJavaInputStreamCallbacks\\n\");\n+            ThrowJavaException(env, \"com\/sun\/media\/jfxmedia\/MediaException\",\n+                               \"OSXMediaPlayer: Unable to create CJavaInputStreamCallbacks\");\n+            return;\n+        }\n+\n+        if (!callbacks->Init(env, jLocator)) {\n+            [mediaURL release];\n+            delete callbacks;\n+            LOGGER_WARNMSG(\"OSXMediaPlayer: callbacks->Init() failed\\n\");\n+            ThrowJavaException(env, \"com\/sun\/media\/jfxmedia\/MediaException\",\n+                               \"OSXMediaPlayer: callbacks->Init() failed\");\n+            return;\n+        }\n+\n+        pjContent = (char*)env->GetStringUTFChars(jContentType, NULL);\n+        pjSourceURI = (char*)env->GetStringUTFChars(jSourceURI, NULL);\n+        if (pjContent == NULL || pjSourceURI == NULL) {\n+            [mediaURL release];\n+            delete callbacks;\n+            if (pjContent != NULL) {\n+                env->ReleaseStringUTFChars(jContentType, pjContent);\n+            }\n+            if (pjSourceURI != NULL) {\n+                env->ReleaseStringUTFChars(jSourceURI, pjSourceURI);\n+            }\n+            LOGGER_WARNMSG(\"OSXMediaPlayer: memory allocation failed\\n\");\n+            ThrowJavaException(env, \"com\/sun\/media\/jfxmedia\/MediaException\",\n+                                    \"OSXMediaPlayer: memory allocation failed\");\n+            return;\n+        }\n+\n+        locatorStream = new(nothrow) CLocatorStream(callbacks, pjContent, pjSourceURI, jSizeHint);\n+        env->ReleaseStringUTFChars(jContentType, pjContent);\n+        env->ReleaseStringUTFChars(jSourceURI, pjSourceURI);\n+    }\n+\n+    OSXMediaPlayer *player = [[OSXMediaPlayer alloc] initWithURL:mediaURL javaPlayer:playerObject andEnv:env eventHandler:eventHandler locatorStream:locatorStream];\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/platform\/osx\/OSXMediaPlayer.mm","additions":62,"deletions":7,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2014, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+#import <Locator\/LocatorStream.h>\n@@ -60,1 +61,1 @@\n-- (id) initWithURL:(NSURL *)source eventHandler:(CJavaPlayerEventDispatcher*)hdlr;\n+- (id) initWithURL:(NSURL *)source eventHandler:(CJavaPlayerEventDispatcher*)hdlr locatorStream:(CLocatorStream*)ls;\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/platform\/osx\/OSXPlayerProtocol.h","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -48,6 +48,0 @@\n-static OSStatus AVFTapRenderCallback(void *inRefCon,\n-                                     AudioUnitRenderActionFlags *ioActionFlags,\n-                                     const AudioTimeStamp *inTimeStamp,\n-                                     UInt32 inBusNumber,\n-                                     UInt32 inNumberFrames,\n-                                     AudioBufferList *ioData);\n@@ -172,28 +166,0 @@\n-static OSStatus SetupAudioUnit(AudioUnit unit,\n-                               const AudioStreamBasicDescription *processingFormat,\n-                               UInt32 maxFrames) {\n-    OSStatus status = noErr;\n-    if (noErr == status) {\n-        status = AudioUnitSetProperty(unit,\n-                                      kAudioUnitProperty_StreamFormat,\n-                                      kAudioUnitScope_Input, 0,\n-                                      processingFormat, sizeof(AudioStreamBasicDescription));\n-    }\n-    if (noErr == status) {\n-        status = AudioUnitSetProperty(unit,\n-                                      kAudioUnitProperty_StreamFormat,\n-                                      kAudioUnitScope_Output, 0,\n-                                      processingFormat, sizeof(AudioStreamBasicDescription));\n-    }\n-    if (noErr == status) {\n-        status = AudioUnitSetProperty(unit,\n-                                      kAudioUnitProperty_MaximumFramesPerSlice,\n-                                      kAudioUnitScope_Global, 0,\n-                                      &maxFrames, sizeof(UInt32));\n-    }\n-    if (noErr == status) {\n-        status = AudioUnitInitialize(unit);\n-    }\n-    return status;\n-}\n-\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/platform\/osx\/avf\/AVFAudioProcessor.mm","additions":0,"deletions":34,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,0 +29,1 @@\n+#import <AVFoundation\/AVAssetResourceLoader.h>\n@@ -38,1 +39,3 @@\n-@interface AVFMediaPlayer : NSObject<OSXPlayerProtocol,AVPlayerItemOutputPullDelegate>\n+@interface AVFMediaPlayer : NSObject<OSXPlayerProtocol,\n+                                     AVPlayerItemOutputPullDelegate,\n+                                     AVAssetResourceLoaderDelegate>\n@@ -44,0 +47,1 @@\n+    dispatch_queue_t playerLoaderQueue;\n@@ -46,0 +50,1 @@\n+    CLocatorStream *locatorStream;\n@@ -85,1 +90,1 @@\n-- (id) initWithURL:(NSURL *)source eventHandler:(CJavaPlayerEventDispatcher*)hdlr;\n+- (id) initWithURL:(NSURL *)source eventHandler:(CJavaPlayerEventDispatcher*)hdlr locatorStream:(CLocatorStream*)ls;\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/platform\/osx\/avf\/AVFMediaPlayer.h","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -88,0 +88,3 @@\n+\/\/ Max number of bytes we will provide per request\n+#define MAX_READ_SIZE (1024 * 1024)\n+\n@@ -106,1 +109,1 @@\n-- (id) initWithURL:(NSURL *)source eventHandler:(CJavaPlayerEventDispatcher*)hdlr {\n+- (id) initWithURL:(NSURL *)source eventHandler:(CJavaPlayerEventDispatcher*)hdlr locatorStream:(CLocatorStream*)ls {\n@@ -126,0 +129,19 @@\n+\n+        \/\/ Setup AVAssetResourceLoaderDelegate if locatorStream provided and use\n+        \/\/ it to load data.\n+        if (ls != NULL) {\n+            AVAsset *avAsset = _player.currentItem.asset;\n+            if ([avAsset isKindOfClass:AVURLAsset.class]) {\n+                AVURLAsset *avUrlAsset = (AVURLAsset *)avAsset;\n+\n+                playerLoaderQueue = dispatch_queue_create(NULL, NULL);\n+\n+                AVAssetResourceLoader *resourceLoader = avUrlAsset.resourceLoader;\n+                [resourceLoader setDelegate:self queue:playerLoaderQueue];\n+            } else {\n+                return nil;\n+            }\n+\n+            self->locatorStream = ls;\n+        }\n+\n@@ -300,0 +322,16 @@\n+- (void) logNSError:(NSString*)tag error:(NSError*)error\n+{\n+    if (error != nil) {\n+        LOGGER_DEBUGMSG(([\n+            [NSString stringWithFormat:@\"[%@] error code: %d\",\n+            tag, (int)error.code] UTF8String]));\n+        LOGGER_DEBUGMSG(([\n+            [NSString stringWithFormat:@\"[%@] error description: %@\",\n+            tag, error.localizedDescription] UTF8String]));\n+    } else {\n+        LOGGER_DEBUGMSG(([\n+             [NSString stringWithFormat:@\"Error nil for [%@]\",\n+             tag] UTF8String]));\n+    }\n+}\n+\n@@ -315,0 +353,9 @@\n+            } else if (status == AVPlayerStatusFailed) {\n+                LOGGER_DEBUGMSG(([[NSString stringWithFormat:@\"Setting player to HALTED state\"] UTF8String]));\n+                if (_player != nil) {\n+                    [self logNSError:@\"AVPlayer\" error:_player.error];\n+                    if (_player.currentItem != nil) {\n+                         [self logNSError:@\"AVPlayerItem\" error:_player.currentItem.error];\n+                    }\n+                }\n+                [self setPlayerState:kPlayerState_HALTED];\n@@ -450,0 +497,6 @@\n+\n+            if (locatorStream != NULL) {\n+                locatorStream->GetCallbacks()->CloseConnection();\n+                locatorStream = NULL;\n+            }\n+\n@@ -672,0 +725,97 @@\n+- (NSString*) getContentTypeFromURL:(NSString*) URL {\n+    if (URL == nil) {\n+        return nil;\n+    }\n+\n+    NSString *lowercaseURL = [URL lowercaseString];\n+    if ([lowercaseURL hasSuffix:@\"mp4\"]) {\n+        return AVFileTypeMPEG4;\n+    } else if ([lowercaseURL hasSuffix:@\"m4a\"]) {\n+        return AVFileTypeMPEG4;\n+    } else if ([lowercaseURL hasSuffix:@\"m4v\"]) {\n+        return AVFileTypeMPEG4;\n+    } else if ([lowercaseURL hasSuffix:@\"mp3\"]) {\n+        return AVFileTypeMPEGLayer3;\n+    }\n+\n+    return nil;\n+}\n+\n+\/\/ AVAssetResourceLoaderDelegate\n+- (BOOL)resourceLoader:(AVAssetResourceLoader *)resourceLoader\n+        shouldWaitForLoadingOfRequestedResource:\n+        (AVAssetResourceLoadingRequest *)loadingRequest {\n+    AVAssetResourceLoadingContentInformationRequest* contentRequest = loadingRequest.contentInformationRequest;\n+    AVAssetResourceLoadingDataRequest* dataRequest = loadingRequest.dataRequest;\n+    NSURLResponse *response = loadingRequest.response;\n+\n+    if (locatorStream == NULL) {\n+        return NO;\n+    }\n+\n+    if (contentRequest != nil) {\n+        contentRequest.contentType = [self getContentTypeFromURL:loadingRequest.request.URL.absoluteString];\n+        contentRequest.contentLength = locatorStream->GetSizeHint();\n+        contentRequest.byteRangeAccessSupported = YES;\n+    }\n+\n+    if (dataRequest != nil) {\n+        long position = locatorStream->GetCallbacks()->Seek(dataRequest.requestedOffset);\n+        if (position != dataRequest.requestedOffset) {\n+            return NO;\n+        }\n+\n+        \/\/ If requestsAllDataToEndOfResource is YES, than requestedLength is\n+        \/\/ invalid and we need to provide all data to the end of file.\n+        long requestedLength = 0;\n+        if (dataRequest.requestsAllDataToEndOfResource) {\n+           int64_t sizeHint = locatorStream->GetSizeHint();\n+           requestedLength = sizeHint - dataRequest.requestedOffset;\n+        } else {\n+           requestedLength = dataRequest.requestedLength;\n+        }\n+\n+        \/\/ Do not provide more then MAX_READ_SIZE at one call, otherwise\n+        \/\/ AVFoundation might fail if we provide too much data.\n+        \/\/ We will be requested again if not all data provided.\n+        if (requestedLength > MAX_READ_SIZE) {\n+           requestedLength = MAX_READ_SIZE;\n+        }\n+\n+        NSMutableData* readData = nil;\n+        while (requestedLength > 0) {\n+            unsigned int blockSize = locatorStream->GetCallbacks()->ReadNextBlock();\n+            if (blockSize <= 0) {\n+                break;\n+            }\n+\n+            unsigned int readSize =\n+                    (blockSize > (unsigned int)dataRequest.requestedLength) ?\n+                    (unsigned int)dataRequest.requestedLength : blockSize;\n+            readData = [NSMutableData dataWithLength:readSize];\n+\n+            locatorStream->GetCallbacks()->CopyBlock((void*)[readData bytes], readSize);\n+            [loadingRequest.dataRequest respondWithData:readData];\n+\n+            requestedLength -= readSize;\n+        }\n+\n+        [loadingRequest finishLoading];\n+\n+        return YES;\n+    }\n+\n+    return NO;\n+}\n+\n+- (BOOL)resourceLoader:(AVAssetResourceLoader *)resourceLoader\n+        shouldWaitForRenewalOfRequestedResource:\n+        (AVAssetResourceRenewalRequest *)renewalRequest {\n+     return NO;\n+}\n+\n+- (void)resourceLoader:(AVAssetResourceLoader *)resourceLoader\n+        didCancelLoadingRequest:\n+        (AVAssetResourceLoadingRequest *)loadingRequest {\n+}\n+\n","filename":"modules\/javafx.media\/src\/main\/native\/jfxmedia\/platform\/osx\/avf\/AVFMediaPlayer.mm","additions":152,"deletions":2,"binary":false,"changes":154,"status":"modified"},{"patch":"@@ -34,8 +34,0 @@\n-\t\t652BEF1A19A69B84007217BB \/* AUBase.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEE5C19A69B84007217BB \/* AUBase.cpp *\/; };\n-\t\t652BEF1C19A69B84007217BB \/* AUInputElement.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEE6019A69B84007217BB \/* AUInputElement.cpp *\/; };\n-\t\t652BEF1D19A69B84007217BB \/* AUOutputElement.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEE6219A69B84007217BB \/* AUOutputElement.cpp *\/; };\n-\t\t652BEF1E19A69B84007217BB \/* AUPlugInDispatch.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEE6419A69B84007217BB \/* AUPlugInDispatch.cpp *\/; };\n-\t\t652BEF1F19A69B84007217BB \/* AUScopeElement.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEE6719A69B84007217BB \/* AUScopeElement.cpp *\/; };\n-\t\t652BEF2019A69B84007217BB \/* ComponentBase.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEE6919A69B84007217BB \/* ComponentBase.cpp *\/; };\n-\t\t652BEF2A19A69B84007217BB \/* AUEffectBase.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEE8419A69B84007217BB \/* AUEffectBase.cpp *\/; };\n-\t\t652BEF5D19A69B84007217BB \/* CASpectralProcessor.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEEFE19A69B84007217BB \/* CASpectralProcessor.cpp *\/; };\n@@ -44,1 +36,0 @@\n-\t\t652BEF7719AF87FE007217BB \/* AVFKernelProcessor.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEF7519AF87FE007217BB \/* AVFKernelProcessor.cpp *\/; };\n@@ -93,4 +84,0 @@\n-\t\t65D754D219B7888C00EE3C99 \/* AUBuffer.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEE9319A69B84007217BB \/* AUBuffer.cpp *\/; };\n-\t\t65D754D819B78C1D00EE3C99 \/* CAAudioChannelLayout.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 652BEEA319A69B84007217BB \/* CAAudioChannelLayout.cpp *\/; };\n-\t\t65D754E719B7BFFB00EE3C99 \/* CAStreamBasicDescription.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 65D754E519B7BFFB00EE3C99 \/* CAStreamBasicDescription.cpp *\/; };\n-\t\t65D754E819B7BFFB00EE3C99 \/* CAVectorUnit.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = 65D754E619B7BFFB00EE3C99 \/* CAVectorUnit.cpp *\/; };\n@@ -98,1 +85,0 @@\n-\t\tB319E1DD1DC29AD100A4E6E8 \/* CAHostTimeBase.cpp in Sources *\/ = {isa = PBXBuildFile; fileRef = B319E1DC1DC29AD100A4E6E8 \/* CAHostTimeBase.cpp *\/; };\n@@ -134,24 +120,0 @@\n-\t\t652BEE5C19A69B84007217BB \/* AUBase.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = AUBase.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEE5D19A69B84007217BB \/* AUBase.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUBase.h; sourceTree = \"<group>\"; };\n-\t\t652BEE6019A69B84007217BB \/* AUInputElement.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = AUInputElement.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEE6119A69B84007217BB \/* AUInputElement.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUInputElement.h; sourceTree = \"<group>\"; };\n-\t\t652BEE6219A69B84007217BB \/* AUOutputElement.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = AUOutputElement.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEE6319A69B84007217BB \/* AUOutputElement.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUOutputElement.h; sourceTree = \"<group>\"; };\n-\t\t652BEE6419A69B84007217BB \/* AUPlugInDispatch.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = AUPlugInDispatch.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEE6519A69B84007217BB \/* AUPlugInDispatch.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUPlugInDispatch.h; sourceTree = \"<group>\"; };\n-\t\t652BEE6719A69B84007217BB \/* AUScopeElement.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = AUScopeElement.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEE6819A69B84007217BB \/* AUScopeElement.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUScopeElement.h; sourceTree = \"<group>\"; };\n-\t\t652BEE6919A69B84007217BB \/* ComponentBase.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = ComponentBase.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEE6A19A69B84007217BB \/* ComponentBase.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = ComponentBase.h; sourceTree = \"<group>\"; };\n-\t\t652BEE8419A69B84007217BB \/* AUEffectBase.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = AUEffectBase.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEE8519A69B84007217BB \/* AUEffectBase.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUEffectBase.h; sourceTree = \"<group>\"; };\n-\t\t652BEE9319A69B84007217BB \/* AUBuffer.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = AUBuffer.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEE9419A69B84007217BB \/* AUBuffer.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUBuffer.h; sourceTree = \"<group>\"; };\n-\t\t652BEE9F19A69B84007217BB \/* CAAtomic.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAAtomic.h; sourceTree = \"<group>\"; };\n-\t\t652BEEA319A69B84007217BB \/* CAAudioChannelLayout.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = CAAudioChannelLayout.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEEA419A69B84007217BB \/* CAAudioChannelLayout.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAAudioChannelLayout.h; sourceTree = \"<group>\"; };\n-\t\t652BEEB719A69B84007217BB \/* CAAutoDisposer.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAAutoDisposer.h; sourceTree = \"<group>\"; };\n-\t\t652BEEB819A69B84007217BB \/* CABitOperations.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CABitOperations.h; sourceTree = \"<group>\"; };\n-\t\t652BEEF719A69B84007217BB \/* CAReferenceCounted.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAReferenceCounted.h; sourceTree = \"<group>\"; };\n-\t\t652BEEFE19A69B84007217BB \/* CASpectralProcessor.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = CASpectralProcessor.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEEFF19A69B84007217BB \/* CASpectralProcessor.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CASpectralProcessor.h; sourceTree = \"<group>\"; };\n@@ -161,2 +123,0 @@\n-\t\t652BEF7519AF87FE007217BB \/* AVFKernelProcessor.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = AVFKernelProcessor.cpp; sourceTree = \"<group>\"; };\n-\t\t652BEF7619AF87FE007217BB \/* AVFKernelProcessor.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AVFKernelProcessor.h; sourceTree = \"<group>\"; };\n@@ -164,3 +124,0 @@\n-\t\t6548E54819C1050900CDAC55 \/* CAAtomicStack.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAAtomicStack.h; sourceTree = \"<group>\"; };\n-\t\t6548E54919C106E200CDAC55 \/* CAVectorUnitTypes.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAVectorUnitTypes.h; sourceTree = \"<group>\"; };\n-\t\t6548E54A19C1070200CDAC55 \/* CADebugPrintf.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CADebugPrintf.h; sourceTree = \"<group>\"; };\n@@ -262,13 +219,0 @@\n-\t\t65D754D319B789C500EE3C99 \/* AUSilentTimeout.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUSilentTimeout.h; sourceTree = \"<group>\"; };\n-\t\t65D754D419B789E100EE3C99 \/* AUBaseHelper.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AUBaseHelper.h; sourceTree = \"<group>\"; };\n-\t\t65D754DC19B7BBC000EE3C99 \/* CADebugMacros.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CADebugMacros.h; sourceTree = \"<group>\"; };\n-\t\t65D754DD19B7BEA600EE3C99 \/* CAException.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAException.h; sourceTree = \"<group>\"; };\n-\t\t65D754DE19B7BF1700EE3C99 \/* CAStreamBasicDescription.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAStreamBasicDescription.h; sourceTree = \"<group>\"; };\n-\t\t65D754DF19B7BF5700EE3C99 \/* CAXException.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAXException.h; sourceTree = \"<group>\"; };\n-\t\t65D754E019B7BF7100EE3C99 \/* CAMath.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAMath.h; sourceTree = \"<group>\"; };\n-\t\t65D754E119B7BFA600EE3C99 \/* CAThreadSafeList.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAThreadSafeList.h; sourceTree = \"<group>\"; };\n-\t\t65D754E219B7BFB500EE3C99 \/* CAVectorUnit.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAVectorUnit.h; sourceTree = \"<group>\"; };\n-\t\t65D754E319B7BFC700EE3C99 \/* CAMutex.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAMutex.h; sourceTree = \"<group>\"; };\n-\t\t65D754E419B7BFD800EE3C99 \/* CAHostTimeBase.h *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = CAHostTimeBase.h; sourceTree = \"<group>\"; };\n-\t\t65D754E519B7BFFB00EE3C99 \/* CAStreamBasicDescription.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = CAStreamBasicDescription.cpp; sourceTree = \"<group>\"; };\n-\t\t65D754E619B7BFFB00EE3C99 \/* CAVectorUnit.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = CAVectorUnit.cpp; sourceTree = \"<group>\"; };\n@@ -281,1 +225,0 @@\n-\t\tB319E1DC1DC29AD100A4E6E8 \/* CAHostTimeBase.cpp *\/ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = CAHostTimeBase.cpp; sourceTree = \"<group>\"; };\n@@ -328,2 +271,0 @@\n-\t\t\t\t652BEF7619AF87FE007217BB \/* AVFKernelProcessor.h *\/,\n-\t\t\t\t652BEF7519AF87FE007217BB \/* AVFKernelProcessor.cpp *\/,\n@@ -334,97 +275,0 @@\n-\t\t652BEE3D19A69B84007217BB \/* CoreAudio *\/ = {\n-\t\t\tisa = PBXGroup;\n-\t\t\tchildren = (\n-\t\t\t\t652BEE5919A69B84007217BB \/* AudioUnits *\/,\n-\t\t\t\t652BEE9A19A69B84007217BB \/* PublicUtility *\/,\n-\t\t\t);\n-\t\t\tname = CoreAudio;\n-\t\t\tpath = CoreAudioUtilityClasses\/CoreAudio;\n-\t\t\tsourceTree = \"<group>\";\n-\t\t};\n-\t\t652BEE5919A69B84007217BB \/* AudioUnits *\/ = {\n-\t\t\tisa = PBXGroup;\n-\t\t\tchildren = (\n-\t\t\t\t652BEE5A19A69B84007217BB \/* AUPublic *\/,\n-\t\t\t);\n-\t\t\tpath = AudioUnits;\n-\t\t\tsourceTree = \"<group>\";\n-\t\t};\n-\t\t652BEE5A19A69B84007217BB \/* AUPublic *\/ = {\n-\t\t\tisa = PBXGroup;\n-\t\t\tchildren = (\n-\t\t\t\t652BEE5B19A69B84007217BB \/* AUBase *\/,\n-\t\t\t\t652BEE8319A69B84007217BB \/* OtherBases *\/,\n-\t\t\t\t652BEE9019A69B84007217BB \/* Utility *\/,\n-\t\t\t);\n-\t\t\tpath = AUPublic;\n-\t\t\tsourceTree = \"<group>\";\n-\t\t};\n-\t\t652BEE5B19A69B84007217BB \/* AUBase *\/ = {\n-\t\t\tisa = PBXGroup;\n-\t\t\tchildren = (\n-\t\t\t\t652BEE5C19A69B84007217BB \/* AUBase.cpp *\/,\n-\t\t\t\t652BEE5D19A69B84007217BB \/* AUBase.h *\/,\n-\t\t\t\t652BEE6019A69B84007217BB \/* AUInputElement.cpp *\/,\n-\t\t\t\t652BEE6119A69B84007217BB \/* AUInputElement.h *\/,\n-\t\t\t\t652BEE6219A69B84007217BB \/* AUOutputElement.cpp *\/,\n-\t\t\t\t652BEE6319A69B84007217BB \/* AUOutputElement.h *\/,\n-\t\t\t\t652BEE6419A69B84007217BB \/* AUPlugInDispatch.cpp *\/,\n-\t\t\t\t652BEE6519A69B84007217BB \/* AUPlugInDispatch.h *\/,\n-\t\t\t\t652BEE6719A69B84007217BB \/* AUScopeElement.cpp *\/,\n-\t\t\t\t652BEE6819A69B84007217BB \/* AUScopeElement.h *\/,\n-\t\t\t\t652BEE6919A69B84007217BB \/* ComponentBase.cpp *\/,\n-\t\t\t\t652BEE6A19A69B84007217BB \/* ComponentBase.h *\/,\n-\t\t\t);\n-\t\t\tpath = AUBase;\n-\t\t\tsourceTree = \"<group>\";\n-\t\t};\n-\t\t652BEE8319A69B84007217BB \/* OtherBases *\/ = {\n-\t\t\tisa = PBXGroup;\n-\t\t\tchildren = (\n-\t\t\t\t652BEE8419A69B84007217BB \/* AUEffectBase.cpp *\/,\n-\t\t\t\t652BEE8519A69B84007217BB \/* AUEffectBase.h *\/,\n-\t\t\t);\n-\t\t\tpath = OtherBases;\n-\t\t\tsourceTree = \"<group>\";\n-\t\t};\n-\t\t652BEE9019A69B84007217BB \/* Utility *\/ = {\n-\t\t\tisa = PBXGroup;\n-\t\t\tchildren = (\n-\t\t\t\t65D754D419B789E100EE3C99 \/* AUBaseHelper.h *\/,\n-\t\t\t\t65D754D319B789C500EE3C99 \/* AUSilentTimeout.h *\/,\n-\t\t\t\t652BEE9319A69B84007217BB \/* AUBuffer.cpp *\/,\n-\t\t\t\t652BEE9419A69B84007217BB \/* AUBuffer.h *\/,\n-\t\t\t);\n-\t\t\tpath = Utility;\n-\t\t\tsourceTree = \"<group>\";\n-\t\t};\n-\t\t652BEE9A19A69B84007217BB \/* PublicUtility *\/ = {\n-\t\t\tisa = PBXGroup;\n-\t\t\tchildren = (\n-\t\t\t\t652BEE9F19A69B84007217BB \/* CAAtomic.h *\/,\n-\t\t\t\t6548E54819C1050900CDAC55 \/* CAAtomicStack.h *\/,\n-\t\t\t\t652BEEA319A69B84007217BB \/* CAAudioChannelLayout.cpp *\/,\n-\t\t\t\t652BEEA419A69B84007217BB \/* CAAudioChannelLayout.h *\/,\n-\t\t\t\t652BEEB719A69B84007217BB \/* CAAutoDisposer.h *\/,\n-\t\t\t\t652BEEB819A69B84007217BB \/* CABitOperations.h *\/,\n-\t\t\t\t65D754DC19B7BBC000EE3C99 \/* CADebugMacros.h *\/,\n-\t\t\t\t6548E54A19C1070200CDAC55 \/* CADebugPrintf.h *\/,\n-\t\t\t\t65D754DD19B7BEA600EE3C99 \/* CAException.h *\/,\n-\t\t\t\tB319E1DC1DC29AD100A4E6E8 \/* CAHostTimeBase.cpp *\/,\n-\t\t\t\t65D754E419B7BFD800EE3C99 \/* CAHostTimeBase.h *\/,\n-\t\t\t\t65D754E019B7BF7100EE3C99 \/* CAMath.h *\/,\n-\t\t\t\t65D754E319B7BFC700EE3C99 \/* CAMutex.h *\/,\n-\t\t\t\t652BEEF719A69B84007217BB \/* CAReferenceCounted.h *\/,\n-\t\t\t\t652BEEFE19A69B84007217BB \/* CASpectralProcessor.cpp *\/,\n-\t\t\t\t652BEEFF19A69B84007217BB \/* CASpectralProcessor.h *\/,\n-\t\t\t\t65D754E519B7BFFB00EE3C99 \/* CAStreamBasicDescription.cpp *\/,\n-\t\t\t\t65D754DE19B7BF1700EE3C99 \/* CAStreamBasicDescription.h *\/,\n-\t\t\t\t65D754E119B7BFA600EE3C99 \/* CAThreadSafeList.h *\/,\n-\t\t\t\t65D754E619B7BFFB00EE3C99 \/* CAVectorUnit.cpp *\/,\n-\t\t\t\t65D754E219B7BFB500EE3C99 \/* CAVectorUnit.h *\/,\n-\t\t\t\t6548E54919C106E200CDAC55 \/* CAVectorUnitTypes.h *\/,\n-\t\t\t\t65D754DF19B7BF5700EE3C99 \/* CAXException.h *\/,\n-\t\t\t);\n-\t\t\tpath = PublicUtility;\n-\t\t\tsourceTree = \"<group>\";\n-\t\t};\n@@ -569,1 +413,0 @@\n-\t\t\t\t652BEE3D19A69B84007217BB \/* CoreAudio *\/,\n@@ -715,0 +558,1 @@\n+\t\t\t\tEnglish,\n@@ -767,1 +611,0 @@\n-\t\t\t\t652BEF1C19A69B84007217BB \/* AUInputElement.cpp in Sources *\/,\n@@ -769,5 +612,0 @@\n-\t\t\t\t65D754D219B7888C00EE3C99 \/* AUBuffer.cpp in Sources *\/,\n-\t\t\t\tB319E1DD1DC29AD100A4E6E8 \/* CAHostTimeBase.cpp in Sources *\/,\n-\t\t\t\t652BEF1D19A69B84007217BB \/* AUOutputElement.cpp in Sources *\/,\n-\t\t\t\t652BEF7719AF87FE007217BB \/* AVFKernelProcessor.cpp in Sources *\/,\n-\t\t\t\t652BEF1A19A69B84007217BB \/* AUBase.cpp in Sources *\/,\n@@ -775,3 +613,0 @@\n-\t\t\t\t652BEF1F19A69B84007217BB \/* AUScopeElement.cpp in Sources *\/,\n-\t\t\t\t652BEF1E19A69B84007217BB \/* AUPlugInDispatch.cpp in Sources *\/,\n-\t\t\t\t652BEF2019A69B84007217BB \/* ComponentBase.cpp in Sources *\/,\n@@ -779,3 +614,0 @@\n-\t\t\t\t65D754E719B7BFFB00EE3C99 \/* CAStreamBasicDescription.cpp in Sources *\/,\n-\t\t\t\t65D754E819B7BFFB00EE3C99 \/* CAVectorUnit.cpp in Sources *\/,\n-\t\t\t\t652BEF5D19A69B84007217BB \/* CASpectralProcessor.cpp in Sources *\/,\n@@ -783,2 +615,0 @@\n-\t\t\t\t65D754D819B78C1D00EE3C99 \/* CAAudioChannelLayout.cpp in Sources *\/,\n-\t\t\t\t652BEF2A19A69B84007217BB \/* AUEffectBase.cpp in Sources *\/,\n@@ -951,1 +781,1 @@\n-\t\t\t\tGLIB_LITE_DIR = \"..\/gstreamer\/3rd_party\/glib\";\n+\t\t\t\tGLIB_LITE_DIR = ..\/gstreamer\/3rd_party\/glib;\n@@ -1003,1 +833,1 @@\n-\t\t\t\tGLIB_LITE_DIR = \"..\/gstreamer\/3rd_party\/glib\";\n+\t\t\t\tGLIB_LITE_DIR = ..\/gstreamer\/3rd_party\/glib;\n","filename":"modules\/javafx.media\/src\/main\/native\/xcode_project\/JFXMedia.xcodeproj\/project.pbxproj","additions":3,"deletions":173,"binary":false,"changes":176,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-    <target depends=\"test,jar\" description=\"Build and test whole project.\" name=\"default\"\/>\n+    <target depends=\"jar\" description=\"Build and test whole project.\" name=\"default\"\/>\n@@ -872,1 +872,1 @@\n-                <java classname=\"@{classname}\" dir=\"${work.dir}\" failonerror=\"${java.failonerror}\" fork=\"true\" jvm=\"${platform.java}\" module=\"@{modulename}\">\n+                <java classname=\"@{classname}\" dir=\"${work.dir}\" failonerror=\"${java.failonerror}\" fork=\"true\" jvm=\"\" module=\"@{modulename}\">\n@@ -877,1 +877,1 @@\n-                        <pathelement path=\"@{modulepath}\"\/>\n+                        <pathelement path=\"..\/..\/..\/..\/build\/sdk\/lib:@{modulepath}\"\/>\n","filename":"tests\/manual\/media\/FXMediaPlayer\/nbproject\/build-impl.xml","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -165,0 +165,1 @@\n+        System.out.println(\"FXMediaPlayer source: \" + source);\n","filename":"tests\/manual\/media\/FXMediaPlayer\/src\/fxmediaplayer\/FXMediaPlayer.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+import fxmediaplayer.media.FXMedia;\n@@ -153,1 +154,6 @@\n-        loadPlayListProperties();\n+        List<String> embededSources = FXMedia.getEmbededMediaFiles();\n+        if (embededSources.size() > 0) {\n+            sources.addAll(embededSources);\n+        } else {\n+            loadPlayListProperties();\n+        }\n","filename":"tests\/manual\/media\/FXMediaPlayer\/src\/fxmediaplayer\/control\/MediaPlayerPlayListTab.java","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -0,0 +1,141 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package fxmediaplayer.media;\n+\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.nio.file.Path;\n+import java.nio.file.FileSystem;\n+import java.nio.file.FileSystems;\n+import java.util.List;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.io.IOException;\n+import java.util.stream.Stream;\n+import java.nio.file.Files;\n+import java.util.function.Predicate;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.nio.file.NoSuchFileException;\n+\n+\/**\n+ * Helper class to generate playlist from embeded media files located under\n+ * src\/fxmediaplayer\/media. This is useful to test \"file\", \"jar\" and \"jrt\" protocol.\n+ * Copy supported media files under src\/fxmediaplayer\/media,\n+ * compile \"FXMediaPlayer\", run it and go to \"Play List\" tab and you should see\n+ * your embeded media files.\n+ *\n+ * FILE protocol:\n+ * cd rt\/tests\/manual\/media\/FXMediaPlayer\n+ * and run\n+ *\n+ * JAR protocol:\n+ * cd rt\/tests\/manual\/media\/FXMediaPlayer\n+ * ant\n+ * java @..\/..\/..\/..\/build\/run.args -jar dist\/FXMediaPlayer.jar\n+ *\n+ * JRT protocol:\n+ * cd rt\/tests\/manual\/media\/FXMediaPlayer\n+ * ant\n+ * [macOS\/Linux] jlink --output dist\/FXMediaPlayer -p ..\/..\/..\/..\/build\/jmods:dist --add-modules javafx.controls,javafx.media,FXMediaPlayer --launcher FXMediaPlayer=FXMediaPlayer\/fxmediaplayer.FXMediaPlayer\n+ * [macOS\/Linux] .\/dist\/FXMediaPlayer\/bin\/FXMediaPlayer\n+ * [Windows] jlink --output dist\/FXMediaPlayer -p ..\/..\/..\/..\/build\/jmods;dist --add-modules javafx.controls,javafx.media,FXMediaPlayer --launcher FXMediaPlayer=FXMediaPlayer\/fxmediaplayer.FXMediaPlayer\n+ * [Windows] dist\\FXMediaPlayer\\bin\\FXMediaPlayer.bat\n+ *\/\n+public class FXMedia {\n+\n+    private static List<String> SUPPORTED_EXT = new ArrayList<>();\n+    private static boolean isJRT = true;\n+\n+    static {\n+        SUPPORTED_EXT.add(\"mp3\");\n+        SUPPORTED_EXT.add(\"wav\");\n+        SUPPORTED_EXT.add(\"aif\");\n+        SUPPORTED_EXT.add(\"mp4\");\n+        SUPPORTED_EXT.add(\"m4a\");\n+        SUPPORTED_EXT.add(\"m4v\");\n+    }\n+\n+    public static List<String> getEmbededMediaFiles() {\n+        List<String> sources = new ArrayList<>();\n+\n+        try {\n+            Path path = null;\n+            URI uri = null;\n+            Stream<Path> walk = null;\n+            try {\n+                FileSystem fileSystem = FileSystems.getFileSystem(URI.create(\"jrt:\/\"));\n+                path = fileSystem.getPath(\"modules\", \"FXMediaPlayer\",\n+                        \"fxmediaplayer\", \"media\");\n+                walk = Files.walk(path, 1);\n+            } catch (NoSuchFileException ex) {\n+                isJRT = false;\n+                uri = FXMedia.class.getResource(\"\/fxmediaplayer\/media\").toURI();\n+\n+                if (uri.getScheme().equals(\"jar\")) {\n+                    FileSystem fileSystem = FileSystems.newFileSystem(uri,\n+                            Collections.<String, Object>emptyMap());\n+                    path = fileSystem.getPath(\"fxmediaplayer\", \"media\");\n+                } else {\n+                    path = Path.of(uri);\n+                }\n+                walk = Files.walk(path, 1);\n+            }\n+\n+            Predicate<Path> predicate = new Predicate<Path>() {\n+                @Override\n+                public boolean test(Path p) {\n+                    final AtomicBoolean isSupported = new AtomicBoolean(false);\n+                    SUPPORTED_EXT.stream().forEach(ext -> {\n+                        if (p.getFileName().toString().endsWith(ext)) {\n+                            isSupported.set(true);\n+                        }\n+                    });\n+\n+                    return isSupported.get();\n+                }\n+            };\n+\n+            final URI uri2 = uri;\n+            walk.filter(predicate).forEach(p -> {\n+                if (isJRT()) {\n+                    sources.add(\"jrt:\/\/\/FXMediaPlayer\/fxmediaplayer\/media\" +\n+                        \"\/\" + p.getFileName());\n+                } else {\n+                    sources.add(uri2.toString() + \"\/\" + p.getFileName());\n+                }\n+            });\n+        } catch (URISyntaxException | IOException ex) {\n+            System.err.println(\"Exception: \" + ex);\n+        }\n+\n+        return sources;\n+    }\n+\n+    private static boolean isJRT() {\n+        return isJRT;\n+    }\n+\n+}\n","filename":"tests\/manual\/media\/FXMediaPlayer\/src\/fxmediaplayer\/media\/FXMedia.java","additions":141,"deletions":0,"binary":false,"changes":141,"status":"added"},{"patch":"@@ -0,0 +1,32 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+module FXMediaPlayer {\n+    requires javafx.base;\n+    requires javafx.controls;\n+    requires javafx.media;\n+\n+    exports fxmediaplayer to javafx.graphics;\n+}\n","filename":"tests\/manual\/media\/FXMediaPlayer\/src\/module-info.java","additions":32,"deletions":0,"binary":false,"changes":32,"status":"added"}]}