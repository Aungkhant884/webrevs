{"files":[{"patch":"@@ -3773,7 +3773,29 @@\n-      Label slow;\n-      __ fast_lock(oop, disp_hdr, box, tmp, rscratch1, slow);\n-\n-      \/\/ Indicate success at cont.\n-      __ cmp(oop, oop);\n-      __ b(cont);\n-      __ bind(slow);\n+      \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n+      __ orr(tmp, disp_hdr, markWord::unlocked_value);\n+\n+      \/\/ Initialize the box. (Must happen before we update the object mark!)\n+      __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ Compare object markWord with an unlocked value (tmp) and if\n+      \/\/ equal exchange the stack address of our box with object markWord.\n+      \/\/ On failure disp_hdr contains the possibly locked markWord.\n+      __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n+                 \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n+      __ br(Assembler::EQ, cont);\n+\n+      assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+\n+      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n+      \/\/ object, will have now locked it will continue at label cont\n+\n+      \/\/ Check if the owner is self by comparing the value in the\n+      \/\/ markWord of object (disp_hdr) with the stack pointer.\n+      __ mov(rscratch1, sp);\n+      __ sub(disp_hdr, disp_hdr, rscratch1);\n+      __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n+      \/\/ If condition is true we are cont and hence we can store 0 as the\n+      \/\/ displaced header in the box, which indicates that it is a recursive lock.\n+      __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n+      __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    } else {\n+      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n@@ -3781,1 +3803,0 @@\n-    __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n@@ -3795,0 +3816,7 @@\n+    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n+    \/\/ lock. The fast-path monitor unlock code checks for\n+    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n+    \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n+    __ mov(tmp, (address)markWord::unused_mark().value());\n+    __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n@@ -3826,0 +3854,9 @@\n+    if (!UseHeavyMonitors) {\n+      \/\/ Find the lock address and load the displaced header from the stack.\n+      __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ If the displaced header is 0, we have a recursive unlock.\n+      __ cmp(disp_hdr, zr);\n+      __ br(Assembler::EQ, cont);\n+    }\n+\n@@ -3828,2 +3865,1 @@\n-\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+    __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);\n@@ -3832,2 +3868,3 @@\n-      Label slow;\n-      __ tbnz(tmp, exact_log2(markWord::monitor_value), object_has_monitor);\n+      \/\/ Check if it is still a light weight lock, this is is true if we\n+      \/\/ see the stack address of the basicLock in the markWord of the\n+      \/\/ object.\n@@ -3835,7 +3872,4 @@\n-      __ fast_unlock(oop, tmp, box, disp_hdr, slow);\n-\n-      \/\/ Indicate success at cont.\n-      __ cmp(oop, oop);\n-      __ b(cont);\n-\n-      __ bind(slow);\n+      __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n+                 \/*release*\/ true, \/*weak*\/ false, tmp);\n+    } else {\n+      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n@@ -3843,1 +3877,0 @@\n-    __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n@@ -3846,0 +3879,2 @@\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+\n@@ -3850,13 +3885,1 @@\n-\n-    \/\/ If the owner is anonymous, we need to fix it -- in the slow-path.\n-    {\n-      Label L;\n-      __ ldr(disp_hdr, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));\n-      __ cmp(disp_hdr, (unsigned char)(intptr_t) ANONYMOUS_OWNER);\n-      __ br(Assembler::NE, L);\n-      __ tst(oop, oop); \/\/ Indicate failure at cont -- dive into slow-path.\n-      __ b(cont);\n-      __ bind(L);\n-    }\n-\n-   __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));\n+    __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));\n@@ -16111,2 +16134,2 @@\n-  match(Set cr (FastLock object));\n-  effect(TEMP tmp, TEMP tmp2, TEMP box);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP tmp2);\n@@ -16126,2 +16149,2 @@\n-  match(Set cr (FastUnlock object));\n-  effect(TEMP box, TEMP tmp, TEMP tmp2);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp, TEMP tmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":60,"deletions":37,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -213,2 +213,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg, lock_reg)\n@@ -223,1 +223,2 @@\n-  ce->store_parameter(_obj_reg->as_register(),  0);\n+  ce->store_parameter(_obj_reg->as_register(),  1);\n+  ce->store_parameter(_lock_reg->as_register(), 0);\n@@ -239,1 +240,5 @@\n-  ce->store_parameter(_obj_reg->as_register(), 0);\n+  if (_compute_lock) {\n+    \/\/ lock_reg was destroyed by fast unlocking attempt => recompute it\n+    ce->monitor_address(_monitor_ix, _lock_reg);\n+  }\n+  ce->store_parameter(_lock_reg->as_register(), 0);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_CodeStubs_aarch64.cpp","additions":9,"deletions":4,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -269,1 +269,4 @@\n-      BytesPerWord * (number_of_locks - 1);\n+      (2 * BytesPerWord) * (number_of_locks - 1);\n+    \/\/ SharedRuntime::OSR_migration_begin() packs BasicObjectLocks in\n+    \/\/ the OSR buffer using 2 word entries: first the lock and then\n+    \/\/ the oop.\n@@ -271,1 +274,1 @@\n-      int slot_offset = monitor_offset - (i * BytesPerWord);\n+      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n@@ -276,1 +279,1 @@\n-        __ ldr(rscratch1, Address(OSR_buf, slot_offset));\n+        __ ldr(rscratch1, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n@@ -282,2 +285,3 @@\n-      __ ldr(r19, Address(OSR_buf, slot_offset));\n-      __ str(r19, frame_map()->address_for_monitor_object(i));\n+      __ ldp(r19, r20, Address(OSR_buf, slot_offset));\n+      __ str(r19, frame_map()->address_for_monitor_lock(i));\n+      __ str(r20, frame_map()->address_for_monitor_object(i));\n@@ -429,2 +433,1 @@\n-    __ ldr(r4, Address(r0, BasicObjectLock::obj_offset_in_bytes()));\n-    stub = new MonitorExitStub(FrameMap::r4_opr);\n+    stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);\n@@ -2543,0 +2546,1 @@\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -2550,0 +2554,1 @@\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -2664,1 +2669,1 @@\n-  __ lea(dst->as_register(), frame_map()->address_for_monitor_object(monitor_no));\n+  __ lea(dst->as_register(), frame_map()->address_for_monitor_lock(monitor_no));\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":13,"deletions":8,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -316,1 +316,1 @@\n-  LIR_Opr lock = new_register(T_ADDRESS);\n+  LIR_Opr lock = new_register(T_INT);\n@@ -325,2 +325,2 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n-                x->monitor_no(), info_for_exception, info);\n+  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n+                        x->monitor_no(), info_for_exception, info);\n@@ -336,1 +336,1 @@\n-  LIR_Opr lock = new_register(T_ADDRESS);\n+  LIR_Opr lock = new_register(T_INT);\n@@ -339,1 +339,1 @@\n-  monitor_exit(obj_temp, lock, syncTempOpr(), new_register(T_INT), x->monitor_no());\n+  monitor_exit(obj_temp, lock, syncTempOpr(), LIR_OprFact::illegalOpr, x->monitor_no());\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -72,0 +72,3 @@\n+  \/\/ save object being locked into the BasicObjectLock\n+  str(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n+\n@@ -81,2 +84,35 @@\n-  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-  fast_lock(obj, hdr, disp_hdr, rscratch1, rscratch2, slow_case);\n+  \/\/ Load object header\n+  ldr(hdr, Address(obj, hdr_offset));\n+  \/\/ and mark it as unlocked\n+  orr(hdr, hdr, markWord::unlocked_value);\n+  \/\/ save unlocked object header into the displaced header location on the stack\n+  str(hdr, Address(disp_hdr, 0));\n+  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n+  \/\/ displaced header address in the object header - if it is not the same, get the\n+  \/\/ object header instead\n+  lea(rscratch2, Address(obj, hdr_offset));\n+  cmpxchgptr(hdr, disp_hdr, rscratch2, rscratch1, done, \/*fallthough*\/NULL);\n+  \/\/ if the object header was the same, we're done\n+  \/\/ if the object header was not the same, it is now in the hdr register\n+  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n+  \/\/\n+  \/\/ 1) (hdr & aligned_mask) == 0\n+  \/\/ 2) sp <= hdr\n+  \/\/ 3) hdr <= sp + page_size\n+  \/\/\n+  \/\/ these 3 tests can be done by evaluating the following expression:\n+  \/\/\n+  \/\/ (hdr - sp) & (aligned_mask - page_size)\n+  \/\/\n+  \/\/ assuming both the stack pointer and page_size have their least\n+  \/\/ significant 2 bits cleared and page_size is a power of 2\n+  mov(rscratch1, sp);\n+  sub(hdr, hdr, rscratch1);\n+  ands(hdr, hdr, aligned_mask - os::vm_page_size());\n+  \/\/ for recursive locking, the result is zero => save it in the displaced header\n+  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n+  str(hdr, Address(disp_hdr, 0));\n+  \/\/ otherwise we don't care about the result and handle locking via runtime call\n+  cbnz(hdr, slow_case);\n+  \/\/ done\n+  bind(done);\n@@ -91,1 +127,2 @@\n-  assert_different_registers(hdr, obj, disp_hdr);\n+  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n+  Label done;\n@@ -93,0 +130,7 @@\n+  \/\/ load displaced header\n+  ldr(hdr, Address(disp_hdr, 0));\n+  \/\/ if the loaded hdr is NULL we had recursive locking\n+  \/\/ if we had recursive locking, we are done\n+  cbz(hdr, done);\n+  \/\/ load object\n+  ldr(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n@@ -94,3 +138,13 @@\n-\n-  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-  fast_unlock(obj, hdr, rscratch1, rscratch2, slow_case);\n+  \/\/ test if object header is pointing to the displaced header, and if so, restore\n+  \/\/ the displaced header in the object - if the object header is not pointing to\n+  \/\/ the displaced header, get the object header instead\n+  \/\/ if the object header was not pointing to the displaced header,\n+  \/\/ we do unlocking via runtime call\n+  if (hdr_offset) {\n+    lea(rscratch1, Address(obj, hdr_offset));\n+    cmpxchgptr(disp_hdr, hdr, rscratch1, rscratch2, done, &slow_case);\n+  } else {\n+    cmpxchgptr(disp_hdr, hdr, obj, rscratch2, done, &slow_case);\n+  }\n+  \/\/ done\n+  bind(done);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":60,"deletions":6,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -876,1 +876,2 @@\n-        f.load_argument(0, r0); \/\/ r0,: object\n+        f.load_argument(1, r0); \/\/ r0,: object\n+        f.load_argument(0, r1); \/\/ r1,: lock address\n@@ -878,1 +879,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), r0);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), r0, r1);\n@@ -896,1 +897,1 @@\n-        f.load_argument(0, r0); \/\/ r0: object\n+        f.load_argument(0, r0); \/\/ r0,: lock address\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -733,7 +733,0 @@\n-\n-  const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-\n-  \/\/ Load object pointer into obj_reg %c_rarg3\n-  ldr(obj_reg, Address(lock_reg, obj_offset));\n-\n@@ -743,1 +736,1 @@\n-            obj_reg);\n+            lock_reg);\n@@ -749,0 +742,6 @@\n+    const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n+\n+    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n+    const int mark_offset = lock_offset +\n+                            BasicLock::displaced_header_offset_in_bytes();\n@@ -752,0 +751,3 @@\n+    \/\/ Load object pointer into obj_reg %c_rarg3\n+    ldr(obj_reg, Address(lock_reg, obj_offset));\n+\n@@ -759,3 +761,49 @@\n-    ldr(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    fast_lock(obj_reg, tmp, rscratch1, swap_reg, rscratch2, slow_case);\n-    b(count);\n+    \/\/ Load (object->mark() | 1) into swap_reg\n+    ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    orr(swap_reg, rscratch1, 1);\n+\n+    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+    str(swap_reg, Address(lock_reg, mark_offset));\n+\n+    assert(lock_offset == 0,\n+           \"displached header must be first word in BasicObjectLock\");\n+\n+    Label fail;\n+    cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n+\n+    \/\/ Fast check for recursive lock.\n+    \/\/\n+    \/\/ Can apply the optimization only if this is a stack lock\n+    \/\/ allocated in this thread. For efficiency, we can focus on\n+    \/\/ recently allocated stack locks (instead of reading the stack\n+    \/\/ base and checking whether 'mark' points inside the current\n+    \/\/ thread stack):\n+    \/\/  1) (mark & 7) == 0, and\n+    \/\/  2) sp <= mark < mark + os::pagesize()\n+    \/\/\n+    \/\/ Warning: sp + os::pagesize can overflow the stack base. We must\n+    \/\/ neither apply the optimization for an inflated lock allocated\n+    \/\/ just above the thread stack (this is why condition 1 matters)\n+    \/\/ nor apply the optimization if the stack lock is inside the stack\n+    \/\/ of another thread. The latter is avoided even in case of overflow\n+    \/\/ because we have guard pages at the end of all stacks. Hence, if\n+    \/\/ we go over the stack base and hit the stack of another thread,\n+    \/\/ this should not be in a writeable area that could contain a\n+    \/\/ stack lock allocated by that thread. As a consequence, a stack\n+    \/\/ lock less than page size away from sp is guaranteed to be\n+    \/\/ owned by the current thread.\n+    \/\/\n+    \/\/ These 3 tests can be done by evaluating the following\n+    \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n+    \/\/ assuming both stack pointer and pagesize have their\n+    \/\/ least significant 3 bits clear.\n+    \/\/ NOTE: the mark is in swap_reg %r0 as the result of cmpxchg\n+    \/\/ NOTE2: aarch64 does not like to subtract sp from rn so take a\n+    \/\/ copy\n+    mov(rscratch1, sp);\n+    sub(swap_reg, swap_reg, rscratch1);\n+    ands(swap_reg, swap_reg, (uint64_t)(7 - os::vm_page_size()));\n+\n+    \/\/ Save the test result, for recursive case, the result is zero\n+    str(swap_reg, Address(lock_reg, mark_offset));\n+    br(Assembler::EQ, count);\n@@ -768,1 +816,1 @@\n-            obj_reg);\n+            lock_reg);\n@@ -794,8 +842,0 @@\n-  const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n-\n-  \/\/ Load oop into obj_reg(%c_rarg3)\n-  ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-  \/\/ Free entry\n-  str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n@@ -803,1 +843,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -805,1 +845,1 @@\n-    Label count, done, slow_case;\n+    Label count, done;\n@@ -809,0 +849,1 @@\n+    const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n@@ -812,5 +853,9 @@\n-    \/\/ Check for non-symmetric locking. This is allowed by the spec and the interpreter\n-    \/\/ must handle it.\n-    ldr(header_reg, Address(rthread, Thread::lock_stack_current_offset()));\n-    cmpoop(header_reg, obj_reg);\n-    br(Assembler::NE, slow_case);\n+    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+    \/\/ structure Store the BasicLock address into %r0\n+    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+\n+    \/\/ Load oop into obj_reg(%c_rarg3)\n+    ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+    \/\/ Free entry\n+    str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n@@ -818,3 +863,9 @@\n-    ldr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    fast_unlock(obj_reg, header_reg, swap_reg, rscratch1, slow_case);\n-    b(count);\n+    \/\/ Load the old header from BasicLock structure\n+    ldr(header_reg, Address(swap_reg,\n+                            BasicLock::displaced_header_offset_in_bytes()));\n+\n+    \/\/ Test for recursion\n+    cbz(header_reg, count);\n+\n+    \/\/ Atomic swap back the old header\n+    cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n@@ -823,2 +874,2 @@\n-    bind(slow_case);\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n+    str(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes())); \/\/ restore obj\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":83,"deletions":32,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -5954,46 +5954,0 @@\n-\n-\/\/ Attempt to fast-lock an object. Fall-through on success, branch to slow label\n-\/\/ on failure.\n-\/\/ Registers:\n-\/\/  - obj: the object to be locked\n-\/\/  - hdr: the header, already loaded from obj, will be destroyed\n-\/\/  - t1, t2, t3: temporary registers, will be destroyed\n-void MacroAssembler::fast_lock(Register obj, Register hdr, Register t1, Register t2, Register t3, Label& slow) {\n-  \/\/ Check if we would have space on lock-stack for the object.\n-  ldr(t1, Address(rthread, Thread::lock_stack_current_offset()));\n-  ldr(t2, Address(rthread, Thread::lock_stack_limit_offset()));\n-  cmp(t1, t2);\n-  br(Assembler::GE, slow);\n-\n-  \/\/ Load (object->mark() | 1) into hdr\n-  orr(hdr, hdr, markWord::unlocked_value);\n-  \/\/ Clear lock-bits, into t2\n-  eor(t2, hdr, markWord::unlocked_value);\n-  \/\/ Try to swing header from unlocked to locked\n-  cmpxchg(\/*addr*\/ obj, \/*expected*\/ hdr, \/*new*\/ t2, Assembler::xword,\n-          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t3);\n-  br(Assembler::NE, slow);\n-\n-  \/\/ After successful lock, push object on lock-stack\n-  str(obj, Address(t1, 0));\n-  add(t1, t1, oopSize);\n-  str(t1, Address(rthread, Thread::lock_stack_current_offset()));\n-}\n-\n-void MacroAssembler::fast_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow) {\n-  \/\/ Load the expected old header (lock-bits cleared to indicate 'locked') into hdr\n-  andr(hdr, hdr, ~markWord::lock_mask_in_place);\n-\n-  \/\/ Load the new header (unlocked) into t1\n-  orr(t1, hdr, markWord::unlocked_value);\n-\n-  \/\/ Try to swing header from locked to unlocked\n-  cmpxchg(obj, hdr, t1, Assembler::xword,\n-          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t2);\n-  br(Assembler::NE, slow);\n-\n-  \/\/ After successful unlock, pop object from lock-stack\n-  ldr(t1, Address(rthread, Thread::lock_stack_current_offset()));\n-  sub(t1, t1, oopSize);\n-  str(t1, Address(rthread, Thread::lock_stack_current_offset()));\n-}\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":0,"deletions":46,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -1570,3 +1570,0 @@\n-public:\n-  void fast_lock(Register obj, Register hdr, Register t1, Register t2, Register t3, Label& slow);\n-  void fast_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1315,0 +1315,1 @@\n+                                              in_ByteSize(-1),\n@@ -1348,0 +1349,1 @@\n+                                       in_ByteSize(-1),\n@@ -1407,0 +1409,1 @@\n+  int lock_slot_offset = 0;\n@@ -1419,0 +1422,1 @@\n+    lock_slot_offset = stack_slots;\n@@ -1433,0 +1437,2 @@\n+  \/\/      | lock box (if sync)  |\n+  \/\/      |---------------------| <- lock_slot_offset\n@@ -1689,0 +1695,1 @@\n+    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n@@ -1693,0 +1700,4 @@\n+    \/\/ Get address of the box\n+\n+    __ lea(lock_reg, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+\n@@ -1697,2 +1708,28 @@\n-      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_lock(obj_reg, old_hdr, swap_reg, tmp, rscratch1, slow_path_lock);\n+      \/\/ Load (object->mark() | 1) into swap_reg %r0\n+      __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ orr(swap_reg, rscratch1, 1);\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n+\n+      \/\/ src -> dest iff dest == r0 else r0 <- dest\n+      __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n+\n+      \/\/ Hmm should this move to the slow path code area???\n+\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) sp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n+\n+      __ sub(swap_reg, sp, swap_reg);\n+      __ neg(swap_reg, swap_reg);\n+      __ ands(swap_reg, swap_reg, 3 - os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n+      __ br(Assembler::NE, slow_path_lock);\n@@ -1807,1 +1844,11 @@\n-    Label done;\n+    Label done, not_recursive;\n+\n+    if (!UseHeavyMonitors) {\n+      \/\/ Simple recursive lock?\n+      __ ldr(rscratch1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      __ cbnz(rscratch1, not_recursive);\n+      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+      __ b(done);\n+    }\n+\n+    __ bind(not_recursive);\n@@ -1815,2 +1862,9 @@\n-      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_unlock(obj_reg, old_hdr, swap_reg, rscratch1, slow_path_unlock);\n+      \/\/ get address of the stack lock\n+      __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      \/\/  get old displaced header\n+      __ ldr(old_hdr, Address(r0, 0));\n+\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      Label count;\n+      __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, count, &slow_path_unlock);\n+      __ bind(count);\n@@ -1886,1 +1940,2 @@\n-    __ mov(c_rarg1, rthread);\n+    __ mov(c_rarg1, lock_reg);\n+    __ mov(c_rarg2, rthread);\n@@ -1889,1 +1944,1 @@\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_locking_C), 2);\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_locking_C), 3);\n@@ -1914,1 +1969,2 @@\n-    __ mov(c_rarg1, rthread);\n+    __ mov(c_rarg2, rthread);\n+    __ lea(c_rarg1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n@@ -2018,0 +2074,1 @@\n+                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":65,"deletions":8,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -198,2 +198,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg, lock_reg)\n@@ -208,0 +208,1 @@\n+  const Register lock_reg = _lock_reg->as_pointer_register();\n@@ -210,1 +211,6 @@\n-  __ str(obj_reg, Address(SP));\n+  if (obj_reg < lock_reg) {\n+    __ stmia(SP, RegisterSet(obj_reg) | RegisterSet(lock_reg));\n+  } else {\n+    __ str(obj_reg, Address(SP));\n+    __ str(lock_reg, Address(SP, BytesPerWord));\n+  }\n@@ -224,1 +230,4 @@\n-  const Register obj_reg = _obj_reg->as_pointer_register();\n+  if (_compute_lock) {\n+    ce->monitor_address(_monitor_ix, _lock_reg);\n+  }\n+  const Register lock_reg = _lock_reg->as_pointer_register();\n@@ -227,1 +236,1 @@\n-  __ str(obj_reg, Address(SP));\n+  __ str(lock_reg, Address(SP));\n","filename":"src\/hotspot\/cpu\/arm\/c1_CodeStubs_arm.cpp","additions":14,"deletions":5,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -152,1 +152,1 @@\n-  int monitor_offset = (method()->max_locals() + (number_of_locks - 1)) * BytesPerWord;\n+  int monitor_offset = (method()->max_locals() + 2 * (number_of_locks - 1)) * BytesPerWord;\n@@ -154,3 +154,5 @@\n-    int slot_offset = monitor_offset - (i * BytesPerWord);\n-    __ ldr(R1, Address(OSR_buf, slot_offset));\n-    __ str(R1, frame_map()->address_for_monitor_object(i));\n+    int slot_offset = monitor_offset - (i * 2 * BytesPerWord);\n+    __ ldr(R1, Address(OSR_buf, slot_offset + 0*BytesPerWord));\n+    __ ldr(R2, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n+    __ str(R1, frame_map()->address_for_monitor_lock(i));\n+    __ str(R2, frame_map()->address_for_monitor_object(i));\n@@ -244,3 +246,2 @@\n-    __ ldr(R1, Address(R0, BasicObjectLock::obj_offset_in_bytes()));\n-    stub = new MonitorExitStub(FrameMap::R1_opr);\n-    __ b(*stub->entry());\n+    stub = new MonitorExitStub(FrameMap::R0_opr, true, 0);\n+    __ unlock_object(R2, R1, R0, *stub->entry());\n@@ -2433,2 +2434,17 @@\n-  \/\/ TODO: Implement fast-locking.\n-  __ b(*op->stub()->entry());\n+  if (UseHeavyMonitors) {\n+    if (op->info() != NULL) {\n+      add_debug_info_for_null_check_here(op->info());\n+      __ null_check(obj);\n+    }\n+    __ b(*op->stub()->entry());\n+  } else if (op->code() == lir_lock) {\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n+    int null_check_offset = __ lock_object(hdr, obj, lock, *op->stub()->entry());\n+    if (op->info() != NULL) {\n+      add_debug_info_for_null_check(null_check_offset, op->info());\n+    }\n+  } else if (op->code() == lir_unlock) {\n+    __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n+  } else {\n+    ShouldNotReachHere();\n+  }\n@@ -2561,1 +2577,1 @@\n-  Address mon_addr = frame_map()->address_for_monitor_object(monitor_no);\n+  Address mon_addr = frame_map()->address_for_monitor_lock(monitor_no);\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":26,"deletions":10,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -413,0 +413,1 @@\n+  LIR_Opr hdr  = new_pointer_register();\n@@ -420,1 +421,1 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n+  monitor_enter(obj.result(), lock, hdr, LIR_OprFact::illegalOpr,\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRGenerator_arm.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -184,0 +184,88 @@\n+int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n+  Label done, fast_lock, fast_lock_done;\n+  int null_check_offset = 0;\n+\n+  const Register tmp2 = Rtemp; \/\/ Rtemp should be free at c1 LIR level\n+  assert_different_registers(hdr, obj, disp_hdr, tmp2);\n+\n+  assert(BasicObjectLock::lock_offset_in_bytes() == 0, \"adjust this code\");\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+  const int mark_offset = BasicLock::displaced_header_offset_in_bytes();\n+\n+  str(obj, Address(disp_hdr, obj_offset));\n+\n+  null_check_offset = offset();\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(tmp2, obj);\n+    ldr_u32(tmp2, Address(tmp2, Klass::access_flags_offset()));\n+    tst(tmp2, JVM_ACC_IS_VALUE_BASED_CLASS);\n+    b(slow_case, ne);\n+  }\n+\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"Required by atomic instructions\");\n+\n+  \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n+  \/\/ That would be acceptable as ether CAS or slow case path is taken in that case.\n+\n+  \/\/ Must be the first instruction here, because implicit null check relies on it\n+  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+  tst(hdr, markWord::unlocked_value);\n+  b(fast_lock, ne);\n+\n+  \/\/ Check for recursive locking\n+  \/\/ See comments in InterpreterMacroAssembler::lock_object for\n+  \/\/ explanations on the fast recursive locking check.\n+  \/\/ -1- test low 2 bits\n+  movs(tmp2, AsmOperand(hdr, lsl, 30));\n+  \/\/ -2- test (hdr - SP) if the low two bits are 0\n+  sub(tmp2, hdr, SP, eq);\n+  movs(tmp2, AsmOperand(tmp2, lsr, exact_log2(os::vm_page_size())), eq);\n+  \/\/ If still 'eq' then recursive locking OK\n+  \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8267042)\n+  str(tmp2, Address(disp_hdr, mark_offset));\n+  b(fast_lock_done, eq);\n+  \/\/ else need slow case\n+  b(slow_case);\n+\n+\n+  bind(fast_lock);\n+  \/\/ Save previous object header in BasicLock structure and update the header\n+  str(hdr, Address(disp_hdr, mark_offset));\n+\n+  cas_for_lock_acquire(hdr, disp_hdr, obj, tmp2, slow_case);\n+\n+  bind(fast_lock_done);\n+  bind(done);\n+\n+  return null_check_offset;\n+}\n+\n+void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n+  assert_different_registers(hdr, obj, disp_hdr, Rtemp);\n+  Register tmp2 = Rtemp;\n+\n+  assert(BasicObjectLock::lock_offset_in_bytes() == 0, \"adjust this code\");\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+  const int mark_offset = BasicLock::displaced_header_offset_in_bytes();\n+\n+  Label done;\n+\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"Required by atomic instructions\");\n+\n+  \/\/ Load displaced header and object from the lock\n+  ldr(hdr, Address(disp_hdr, mark_offset));\n+  \/\/ If hdr is NULL, we've got recursive locking and there's nothing more to do\n+  cbz(hdr, done);\n+\n+  \/\/ load object\n+  ldr(obj, Address(disp_hdr, obj_offset));\n+\n+  \/\/ Restore the object header\n+  cas_for_lock_release(disp_hdr, hdr, obj, tmp2, slow_case);\n+\n+  bind(done);\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.cpp","additions":88,"deletions":0,"binary":false,"changes":88,"status":"modified"},{"patch":"@@ -62,0 +62,4 @@\n+  int lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case);\n+\n+  void unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case);\n+\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -629,0 +629,1 @@\n+        const Register lock = R2;\n@@ -631,1 +632,2 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), obj);\n+        __ ldr(lock, Address(SP, arg2_offset));\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), obj, lock);\n@@ -644,1 +646,1 @@\n-        const Register obj = R1;\n+        const Register lock = R1;\n@@ -646,2 +648,2 @@\n-        __ ldr(obj, Address(SP, arg1_offset));\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorexit), obj);\n+        __ ldr(lock, Address(SP, arg1_offset));\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorexit), lock);\n","filename":"src\/hotspot\/cpu\/arm\/c1_Runtime1_arm.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -100,2 +100,24 @@\n-  \/\/ TODO: Implement fast-locking.\n-  tst(Roop, Roop); \/\/ Indicate failure -> take slow path\n+  ldr(Rmark, Address(Roop, oopDesc::mark_offset_in_bytes()));\n+  tst(Rmark, markWord::unlocked_value);\n+  b(fast_lock, ne);\n+\n+  \/\/ Check for recursive lock\n+  \/\/ See comments in InterpreterMacroAssembler::lock_object for\n+  \/\/ explanations on the fast recursive locking check.\n+  \/\/ -1- test low 2 bits\n+  movs(Rscratch, AsmOperand(Rmark, lsl, 30));\n+  \/\/ -2- test (hdr - SP) if the low two bits are 0\n+  sub(Rscratch, Rmark, SP, eq);\n+  movs(Rscratch, AsmOperand(Rscratch, lsr, exact_log2(os::vm_page_size())), eq);\n+  \/\/ If still 'eq' then recursive locking OK\n+  \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8153107)\n+  str(Rscratch, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n+  b(done);\n+\n+  bind(fast_lock);\n+  str(Rmark, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n+\n+  bool allow_fallthrough_on_failure = true;\n+  bool one_shot = true;\n+  cas_for_lock_acquire(Rmark, Rbox, Roop, Rscratch, done, allow_fallthrough_on_failure, one_shot);\n+\n@@ -121,2 +143,10 @@\n-  \/\/ TODO: Implement fast-unlocking.\n-  tst(Roop, Roop); \/\/ Indicate failure -> take slow path\n+  ldr(Rmark, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n+  \/\/ If hdr is NULL, we've got recursive locking and there's nothing more to do\n+  cmp(Rmark, 0);\n+  b(done, eq);\n+\n+  \/\/ Restore the object header\n+  bool allow_fallthrough_on_failure = true;\n+  bool one_shot = true;\n+  cas_for_lock_release(Rmark, Rbox, Roop, Rscratch, done, allow_fallthrough_on_failure, one_shot);\n+\n","filename":"src\/hotspot\/cpu\/arm\/c2_MacroAssembler_arm.cpp","additions":34,"deletions":4,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -866,3 +866,0 @@\n-  const Register Robj = R2;\n-  assert_different_registers(Robj, Rlock);\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n@@ -870,2 +867,17 @@\n-  \/\/ Load object pointer\n-  ldr(Robj, Address(Rlock, obj_offset));\n+  if (UseHeavyMonitors) {\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), Rlock);\n+  } else {\n+    Label done;\n+\n+    const Register Robj = R2;\n+    const Register Rmark = R3;\n+    assert_different_registers(Robj, Rmark, Rlock, R0, Rtemp);\n+\n+    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n+    const int mark_offset = lock_offset + BasicLock::displaced_header_offset_in_bytes();\n+\n+    Label already_locked, slow_case;\n+\n+    \/\/ Load object pointer\n+    ldr(Robj, Address(Rlock, obj_offset));\n@@ -873,3 +885,77 @@\n-  \/\/ TODO: Implement fast-locking.\n-  mov(R0, Robj);\n-  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), R0);\n+    if (DiagnoseSyncOnValueBasedClasses != 0) {\n+      load_klass(R0, Robj);\n+      ldr_u32(R0, Address(R0, Klass::access_flags_offset()));\n+      tst(R0, JVM_ACC_IS_VALUE_BASED_CLASS);\n+      b(slow_case, ne);\n+    }\n+\n+    \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n+    \/\/ That would be acceptable as ether CAS or slow case path is taken in that case.\n+    \/\/ Exception to that is if the object is locked by the calling thread, then the recursive test will pass (guaranteed as\n+    \/\/ loads are satisfied from a store queue if performed on the same processor).\n+\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"must be\");\n+    ldr(Rmark, Address(Robj, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ Test if object is already locked\n+    tst(Rmark, markWord::unlocked_value);\n+    b(already_locked, eq);\n+\n+    \/\/ Save old object->mark() into BasicLock's displaced header\n+    str(Rmark, Address(Rlock, mark_offset));\n+\n+    cas_for_lock_acquire(Rmark, Rlock, Robj, Rtemp, slow_case);\n+\n+    b(done);\n+\n+    \/\/ If we got here that means the object is locked by ether calling thread or another thread.\n+    bind(already_locked);\n+    \/\/ Handling of locked objects: recursive locks and slow case.\n+\n+    \/\/ Fast check for recursive lock.\n+    \/\/\n+    \/\/ Can apply the optimization only if this is a stack lock\n+    \/\/ allocated in this thread. For efficiency, we can focus on\n+    \/\/ recently allocated stack locks (instead of reading the stack\n+    \/\/ base and checking whether 'mark' points inside the current\n+    \/\/ thread stack):\n+    \/\/  1) (mark & 3) == 0\n+    \/\/  2) SP <= mark < SP + os::pagesize()\n+    \/\/\n+    \/\/ Warning: SP + os::pagesize can overflow the stack base. We must\n+    \/\/ neither apply the optimization for an inflated lock allocated\n+    \/\/ just above the thread stack (this is why condition 1 matters)\n+    \/\/ nor apply the optimization if the stack lock is inside the stack\n+    \/\/ of another thread. The latter is avoided even in case of overflow\n+    \/\/ because we have guard pages at the end of all stacks. Hence, if\n+    \/\/ we go over the stack base and hit the stack of another thread,\n+    \/\/ this should not be in a writeable area that could contain a\n+    \/\/ stack lock allocated by that thread. As a consequence, a stack\n+    \/\/ lock less than page size away from SP is guaranteed to be\n+    \/\/ owned by the current thread.\n+    \/\/\n+    \/\/ Note: assuming SP is aligned, we can check the low bits of\n+    \/\/ (mark-SP) instead of the low bits of mark. In that case,\n+    \/\/ assuming page size is a power of 2, we can merge the two\n+    \/\/ conditions into a single test:\n+    \/\/ => ((mark - SP) & (3 - os::pagesize())) == 0\n+\n+    \/\/ (3 - os::pagesize()) cannot be encoded as an ARM immediate operand.\n+    \/\/ Check independently the low bits and the distance to SP.\n+    \/\/ -1- test low 2 bits\n+    movs(R0, AsmOperand(Rmark, lsl, 30));\n+    \/\/ -2- test (mark - SP) if the low two bits are 0\n+    sub(R0, Rmark, SP, eq);\n+    movs(R0, AsmOperand(R0, lsr, exact_log2(os::vm_page_size())), eq);\n+    \/\/ If still 'eq' then recursive locking OK: store 0 into lock record\n+    str(R0, Address(Rlock, mark_offset), eq);\n+\n+    b(done, eq);\n+\n+    bind(slow_case);\n+\n+    \/\/ Call the runtime routine for slow case\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), Rlock);\n+\n+    bind(done);\n+  }\n@@ -886,3 +972,0 @@\n-  const Register Robj = R2;\n-  assert_different_registers(Robj, Rlock);\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n@@ -890,2 +973,8 @@\n-  \/\/ Load oop into Robj\n-  ldr(Robj, Address(Rlock, obj_offset));\n+  if (UseHeavyMonitors) {\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), Rlock);\n+  } else {\n+    Label done, slow_case;\n+\n+    const Register Robj = R2;\n+    const Register Rmark = R3;\n+    assert_different_registers(Robj, Rmark, Rlock, Rtemp);\n@@ -893,3 +982,32 @@\n-  \/\/ TODO: Implement fast-locking.\n-  mov(R0, Robj);\n-  call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), R0);\n+    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n+    const int mark_offset = lock_offset + BasicLock::displaced_header_offset_in_bytes();\n+\n+    const Register Rzero = zero_register(Rtemp);\n+\n+    \/\/ Load oop into Robj\n+    ldr(Robj, Address(Rlock, obj_offset));\n+\n+    \/\/ Free entry\n+    str(Rzero, Address(Rlock, obj_offset));\n+\n+    \/\/ Load the old header from BasicLock structure\n+    ldr(Rmark, Address(Rlock, mark_offset));\n+\n+    \/\/ Test for recursion (zero mark in BasicLock)\n+    cbz(Rmark, done);\n+\n+    bool allow_fallthrough_on_failure = true;\n+\n+    cas_for_lock_release(Rlock, Rmark, Robj, Rtemp, slow_case, allow_fallthrough_on_failure);\n+\n+    b(done, eq);\n+\n+    bind(slow_case);\n+\n+    \/\/ Call the runtime routine for slow case.\n+    str(Robj, Address(Rlock, obj_offset)); \/\/ restore obj\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), Rlock);\n+\n+    bind(done);\n+  }\n","filename":"src\/hotspot\/cpu\/arm\/interp_masm_arm.cpp","additions":134,"deletions":16,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -772,0 +772,1 @@\n+                                       in_ByteSize(-1),\n@@ -805,0 +806,8 @@\n+  \/\/ Plus a lock if needed\n+  int lock_slot_offset = 0;\n+  if (method->is_synchronized()) {\n+    lock_slot_offset = stack_slots;\n+    assert(sizeof(BasicLock) == wordSize, \"adjust this code\");\n+    stack_slots += VMRegImpl::slots_per_word;\n+  }\n+\n@@ -811,0 +820,2 @@\n+  int lock_slot_fp_offset = stack_size - 2 * wordSize -\n+    lock_slot_offset * VMRegImpl::stack_slot_size;\n@@ -1141,1 +1152,22 @@\n-    \/\/ TODO: Implement fast-locking.\n+    const Register mark = tmp;\n+    \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n+    \/\/ That would be acceptable as either CAS or slow case path is taken in that case\n+\n+    __ ldr(mark, Address(sync_obj, oopDesc::mark_offset_in_bytes()));\n+    __ sub(disp_hdr, FP, lock_slot_fp_offset);\n+    __ tst(mark, markWord::unlocked_value);\n+    __ b(fast_lock, ne);\n+\n+    \/\/ Check for recursive lock\n+    \/\/ See comments in InterpreterMacroAssembler::lock_object for\n+    \/\/ explanations on the fast recursive locking check.\n+    \/\/ Check independently the low bits and the distance to SP\n+    \/\/ -1- test low 2 bits\n+    __ movs(Rtemp, AsmOperand(mark, lsl, 30));\n+    \/\/ -2- test (hdr - SP) if the low two bits are 0\n+    __ sub(Rtemp, mark, SP, eq);\n+    __ movs(Rtemp, AsmOperand(Rtemp, lsr, exact_log2(os::vm_page_size())), eq);\n+    \/\/ If still 'eq' then recursive locking OK\n+    \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8267042)\n+    __ str(Rtemp, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n+    __ b(lock_done, eq);\n@@ -1143,0 +1175,6 @@\n+\n+    __ bind(fast_lock);\n+    __ str(mark, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n+\n+    __ cas_for_lock_acquire(mark, disp_hdr, sync_obj, Rtemp, slow_lock);\n+\n@@ -1194,2 +1232,7 @@\n-    \/\/ TODO: Implement fast-unlocking.\n-    __ b(slow_unlock);\n+\n+    \/\/ See C1_MacroAssembler::unlock_object() for more comments\n+    __ ldr(R2, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n+    __ cbz(R2, unlock_done);\n+\n+    __ cas_for_lock_release(disp_hdr, R2, sync_obj, Rtemp, slow_unlock);\n+\n@@ -1251,1 +1294,2 @@\n-    __ mov(R1, Rthread);\n+    __ mov(R1, disp_hdr);\n+    __ mov(R2, Rthread);\n@@ -1270,1 +1314,2 @@\n-    __ mov(R1, Rthread);\n+    __ mov(R1, disp_hdr);\n+    __ mov(R2, Rthread);\n@@ -1287,0 +1332,1 @@\n+                                     in_ByteSize(lock_slot_offset * VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":51,"deletions":5,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -287,2 +287,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n-  : MonitorAccessStub(obj_reg) {\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n+  : MonitorAccessStub(obj_reg, lock_reg) {\n@@ -298,0 +298,1 @@\n+  assert(_lock_reg->as_register() == R5_ARG3, \"\");\n@@ -307,0 +308,3 @@\n+  if (_compute_lock) {\n+    ce->monitor_address(_monitor_ix, _lock_reg);\n+  }\n@@ -310,1 +314,1 @@\n-  __ mr_if_needed(\/*scratch_opr()->as_register()*\/ R4_ARG2, _obj_reg->as_register());\n+  assert(_lock_reg->as_register() == R4_ARG2, \"\");\n","filename":"src\/hotspot\/cpu\/ppc\/c1_CodeStubs_ppc.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -140,1 +140,4 @@\n-      BytesPerWord * (number_of_locks - 1);\n+      (2 * BytesPerWord) * (number_of_locks - 1);\n+    \/\/ SharedRuntime::OSR_migration_begin() packs BasicObjectLocks in\n+    \/\/ the OSR buffer using 2 word entries: first the lock and then\n+    \/\/ the oop.\n@@ -142,1 +145,1 @@\n-      int slot_offset = monitor_offset - (i * BytesPerWord);\n+      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n@@ -155,2 +158,3 @@\n-      Address mo = frame_map()->address_for_monitor_object(i);\n-      assert(mo.index() == noreg, \"sanity\");\n+      Address ml = frame_map()->address_for_monitor_lock(i),\n+              mo = frame_map()->address_for_monitor_object(i);\n+      assert(ml.index() == noreg && mo.index() == noreg, \"sanity\");\n@@ -158,0 +162,2 @@\n+      __ std(R0, ml.disp(), ml.base());\n+      __ ld(R0, slot_offset + 1*BytesPerWord, OSR_buf);\n@@ -211,3 +217,2 @@\n-    __ ld(R4, BasicObjectLock::obj_offset_in_bytes(), R4);\n-    stub = new MonitorExitStub(FrameMap::R4_opr);\n-    __ b(*stub->entry());\n+    stub = new MonitorExitStub(FrameMap::R4_opr, true, 0);\n+    __ unlock_object(R5, R6, R4, *stub->entry());\n@@ -2661,1 +2666,1 @@\n-  Address mon_addr = frame_map()->address_for_monitor_object(monitor_no);\n+  Address mon_addr = frame_map()->address_for_monitor_lock(monitor_no);\n@@ -2678,9 +2683,23 @@\n-    \/\/ always do slow locking\n-    \/\/ note: The slow locking code could be inlined here, however if we use\n-    \/\/       slow locking, speed doesn't matter anyway and this solution is\n-    \/\/       simpler and requires less duplicated code - additionally, the\n-    \/\/       slow locking code is the same in either case which simplifies\n-    \/\/       debugging.\n-    if (op->info() != NULL) {\n-      add_debug_info_for_null_check_here(op->info());\n-      __ null_check(obj);\n+    if (!UseHeavyMonitors) {\n+      assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n+      \/\/ Add debug info for NullPointerException only if one is possible.\n+      if (op->info() != NULL) {\n+        if (!os::zero_page_read_protected() || !ImplicitNullChecks) {\n+          explicit_null_check(obj, op->info());\n+        } else {\n+          add_debug_info_for_null_check_here(op->info());\n+        }\n+      }\n+      __ lock_object(hdr, obj, lock, op->scratch_opr()->as_register(), *op->stub()->entry());\n+    } else {\n+      \/\/ always do slow locking\n+      \/\/ note: The slow locking code could be inlined here, however if we use\n+      \/\/       slow locking, speed doesn't matter anyway and this solution is\n+      \/\/       simpler and requires less duplicated code - additionally, the\n+      \/\/       slow locking code is the same in either case which simplifies\n+      \/\/       debugging.\n+      if (op->info() != NULL) {\n+        add_debug_info_for_null_check_here(op->info());\n+        __ null_check(obj);\n+      }\n+      __ b(*op->stub()->entry());\n@@ -2688,1 +2707,0 @@\n-    __ b(*op->stub()->entry());\n@@ -2691,7 +2709,12 @@\n-    \/\/ always do slow unlocking\n-    \/\/ note: The slow unlocking code could be inlined here, however if we use\n-    \/\/       slow unlocking, speed doesn't matter anyway and this solution is\n-    \/\/       simpler and requires less duplicated code - additionally, the\n-    \/\/       slow unlocking code is the same in either case which simplifies\n-    \/\/       debugging.\n-    __ b(*op->stub()->entry());\n+    if (!UseHeavyMonitors) {\n+      assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n+      __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n+    } else {\n+      \/\/ always do slow unlocking\n+      \/\/ note: The slow unlocking code could be inlined here, however if we use\n+      \/\/       slow unlocking, speed doesn't matter anyway and this solution is\n+      \/\/       simpler and requires less duplicated code - additionally, the\n+      \/\/       slow unlocking code is the same in either case which simplifies\n+      \/\/       debugging.\n+      __ b(*op->stub()->entry());\n+    }\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":48,"deletions":25,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -349,1 +349,1 @@\n-  monitor_enter(obj.result(), lock, hdr, scratch, new_register(T_INT), x->monitor_no(), info_for_exception, info);\n+  monitor_enter(obj.result(), lock, hdr, scratch, x->monitor_no(), info_for_exception, info);\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRGenerator_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -95,0 +95,97 @@\n+\n+void C1_MacroAssembler::lock_object(Register Rmark, Register Roop, Register Rbox, Register Rscratch, Label& slow_case) {\n+  assert_different_registers(Rmark, Roop, Rbox, Rscratch);\n+\n+  Label done, cas_failed, slow_int;\n+\n+  \/\/ The following move must be the first instruction of emitted since debug\n+  \/\/ information may be generated for it.\n+  \/\/ Load object header.\n+  ld(Rmark, oopDesc::mark_offset_in_bytes(), Roop);\n+\n+  verify_oop(Roop, FILE_AND_LINE);\n+\n+  \/\/ Save object being locked into the BasicObjectLock...\n+  std(Roop, BasicObjectLock::obj_offset_in_bytes(), Rbox);\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(Rscratch, Roop);\n+    lwz(Rscratch, in_bytes(Klass::access_flags_offset()), Rscratch);\n+    testbitdi(CCR0, R0, Rscratch, exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n+    bne(CCR0, slow_int);\n+  }\n+\n+  \/\/ ... and mark it unlocked.\n+  ori(Rmark, Rmark, markWord::unlocked_value);\n+\n+  \/\/ Save unlocked object header into the displaced header location on the stack.\n+  std(Rmark, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n+\n+  \/\/ Compare object markWord with Rmark and if equal exchange Rscratch with object markWord.\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"cas must take a zero displacement\");\n+  cmpxchgd(\/*flag=*\/CCR0,\n+           \/*current_value=*\/Rscratch,\n+           \/*compare_value=*\/Rmark,\n+           \/*exchange_value=*\/Rbox,\n+           \/*where=*\/Roop\/*+0==mark_offset_in_bytes*\/,\n+           MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n+           MacroAssembler::cmpxchgx_hint_acquire_lock(),\n+           noreg,\n+           &cas_failed,\n+           \/*check without membar and ldarx first*\/true);\n+  \/\/ If compare\/exchange succeeded we found an unlocked object and we now have locked it\n+  \/\/ hence we are done.\n+  b(done);\n+\n+  bind(slow_int);\n+  b(slow_case); \/\/ far\n+\n+  bind(cas_failed);\n+  \/\/ We did not find an unlocked object so see if this is a recursive case.\n+  sub(Rscratch, Rscratch, R1_SP);\n+  load_const_optimized(R0, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n+  and_(R0\/*==0?*\/, Rscratch, R0);\n+  std(R0\/*==0, perhaps*\/, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n+  bne(CCR0, slow_int);\n+\n+  bind(done);\n+}\n+\n+\n+void C1_MacroAssembler::unlock_object(Register Rmark, Register Roop, Register Rbox, Label& slow_case) {\n+  assert_different_registers(Rmark, Roop, Rbox);\n+\n+  Label slow_int, done;\n+\n+  Address mark_addr(Roop, oopDesc::mark_offset_in_bytes());\n+  assert(mark_addr.disp() == 0, \"cas must take a zero displacement\");\n+\n+  \/\/ Test first it it is a fast recursive unlock.\n+  ld(Rmark, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n+  cmpdi(CCR0, Rmark, 0);\n+  beq(CCR0, done);\n+\n+  \/\/ Load object.\n+  ld(Roop, BasicObjectLock::obj_offset_in_bytes(), Rbox);\n+  verify_oop(Roop, FILE_AND_LINE);\n+\n+  \/\/ Check if it is still a light weight lock, this is is true if we see\n+  \/\/ the stack address of the basicLock in the markWord of the object.\n+  cmpxchgd(\/*flag=*\/CCR0,\n+           \/*current_value=*\/R0,\n+           \/*compare_value=*\/Rbox,\n+           \/*exchange_value=*\/Rmark,\n+           \/*where=*\/Roop,\n+           MacroAssembler::MemBarRel,\n+           MacroAssembler::cmpxchgx_hint_release_lock(),\n+           noreg,\n+           &slow_int);\n+  b(done);\n+  bind(slow_int);\n+  b(slow_case); \/\/ far\n+\n+  \/\/ Done\n+  bind(done);\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/ppc\/c1_MacroAssembler_ppc.cpp","additions":97,"deletions":0,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -45,0 +45,4 @@\n+  \/\/ locking\/unlocking\n+  void lock_object  (Register Rmark, Register Roop, Register Rbox, Register Rscratch, Label& slow_case);\n+  void unlock_object(Register Rmark, Register Roop, Register Rbox,                    Label& slow_case);\n+\n","filename":"src\/hotspot\/cpu\/ppc\/c1_MacroAssembler_ppc.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -612,1 +612,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), R4_ARG2);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), R4_ARG2, R5_ARG3);\n","filename":"src\/hotspot\/cpu\/ppc\/c1_Runtime1_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -908,1 +908,103 @@\n-  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n+  if (UseHeavyMonitors) {\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n+  } else {\n+    \/\/ template code:\n+    \/\/\n+    \/\/ markWord displaced_header = obj->mark().set_unlocked();\n+    \/\/ monitor->lock()->set_displaced_header(displaced_header);\n+    \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n+    \/\/   \/\/ We stored the monitor address into the object's mark word.\n+    \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n+    \/\/   \/\/ Simple recursive case.\n+    \/\/   monitor->lock()->set_displaced_header(NULL);\n+    \/\/ } else {\n+    \/\/   \/\/ Slow path.\n+    \/\/   InterpreterRuntime::monitorenter(THREAD, monitor);\n+    \/\/ }\n+\n+    const Register displaced_header = R7_ARG5;\n+    const Register object_mark_addr = R8_ARG6;\n+    const Register current_header   = R9_ARG7;\n+    const Register tmp              = R10_ARG8;\n+\n+    Label done;\n+    Label cas_failed, slow_case;\n+\n+    assert_different_registers(displaced_header, object_mark_addr, current_header, tmp);\n+\n+    \/\/ markWord displaced_header = obj->mark().set_unlocked();\n+\n+    \/\/ Load markWord from object into displaced_header.\n+    ld(displaced_header, oopDesc::mark_offset_in_bytes(), object);\n+\n+    if (DiagnoseSyncOnValueBasedClasses != 0) {\n+      load_klass(tmp, object);\n+      lwz(tmp, in_bytes(Klass::access_flags_offset()), tmp);\n+      testbitdi(CCR0, R0, tmp, exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n+      bne(CCR0, slow_case);\n+    }\n+\n+    \/\/ Set displaced_header to be (markWord of object | UNLOCK_VALUE).\n+    ori(displaced_header, displaced_header, markWord::unlocked_value);\n+\n+    \/\/ monitor->lock()->set_displaced_header(displaced_header);\n+\n+    \/\/ Initialize the box (Must happen before we update the object mark!).\n+    std(displaced_header, BasicObjectLock::lock_offset_in_bytes() +\n+        BasicLock::displaced_header_offset_in_bytes(), monitor);\n+\n+    \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n+\n+    \/\/ Store stack address of the BasicObjectLock (this is monitor) into object.\n+    addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());\n+\n+    \/\/ Must fence, otherwise, preceding store(s) may float below cmpxchg.\n+    \/\/ CmpxchgX sets CCR0 to cmpX(current, displaced).\n+    cmpxchgd(\/*flag=*\/CCR0,\n+             \/*current_value=*\/current_header,\n+             \/*compare_value=*\/displaced_header, \/*exchange_value=*\/monitor,\n+             \/*where=*\/object_mark_addr,\n+             MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n+             MacroAssembler::cmpxchgx_hint_acquire_lock(),\n+             noreg,\n+             &cas_failed,\n+             \/*check without membar and ldarx first*\/true);\n+\n+    \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n+    \/\/ object and we have now locked it.\n+    b(done);\n+    bind(cas_failed);\n+\n+    \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n+    \/\/   \/\/ Simple recursive case.\n+    \/\/   monitor->lock()->set_displaced_header(NULL);\n+\n+    \/\/ We did not see an unlocked object so try the fast recursive case.\n+\n+    \/\/ Check if owner is self by comparing the value in the markWord of object\n+    \/\/ (current_header) with the stack pointer.\n+    sub(current_header, current_header, R1_SP);\n+\n+    assert(os::vm_page_size() > 0xfff, \"page size too small - change the constant\");\n+    load_const_optimized(tmp, ~(os::vm_page_size()-1) | markWord::lock_mask_in_place);\n+\n+    and_(R0\/*==0?*\/, current_header, tmp);\n+    \/\/ If condition is true we are done and hence we can store 0 in the displaced\n+    \/\/ header indicating it is a recursive lock.\n+    bne(CCR0, slow_case);\n+    std(R0\/*==0!*\/, BasicObjectLock::lock_offset_in_bytes() +\n+        BasicLock::displaced_header_offset_in_bytes(), monitor);\n+    b(done);\n+\n+    \/\/ } else {\n+    \/\/   \/\/ Slow path.\n+    \/\/   InterpreterRuntime::monitorenter(THREAD, monitor);\n+\n+    \/\/ None of the above fast optimizations worked so we have to get into the\n+    \/\/ slow case of monitor enter.\n+    bind(slow_case);\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n+    \/\/ }\n+    align(32, 12);\n+    bind(done);\n+  }\n@@ -919,1 +1021,79 @@\n-  call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);\n+  if (UseHeavyMonitors) {\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);\n+  } else {\n+\n+    \/\/ template code:\n+    \/\/\n+    \/\/ if ((displaced_header = monitor->displaced_header()) == NULL) {\n+    \/\/   \/\/ Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.\n+    \/\/   monitor->set_obj(NULL);\n+    \/\/ } else if (Atomic::cmpxchg(obj->mark_addr(), monitor, displaced_header) == monitor) {\n+    \/\/   \/\/ We swapped the unlocked mark in displaced_header into the object's mark word.\n+    \/\/   monitor->set_obj(NULL);\n+    \/\/ } else {\n+    \/\/   \/\/ Slow path.\n+    \/\/   InterpreterRuntime::monitorexit(monitor);\n+    \/\/ }\n+\n+    const Register object           = R7_ARG5;\n+    const Register displaced_header = R8_ARG6;\n+    const Register object_mark_addr = R9_ARG7;\n+    const Register current_header   = R10_ARG8;\n+\n+    Label free_slot;\n+    Label slow_case;\n+\n+    assert_different_registers(object, displaced_header, object_mark_addr, current_header);\n+\n+    \/\/ Test first if we are in the fast recursive case.\n+    ld(displaced_header, BasicObjectLock::lock_offset_in_bytes() +\n+           BasicLock::displaced_header_offset_in_bytes(), monitor);\n+\n+    \/\/ If the displaced header is zero, we have a recursive unlock.\n+    cmpdi(CCR0, displaced_header, 0);\n+    beq(CCR0, free_slot); \/\/ recursive unlock\n+\n+    \/\/ } else if (Atomic::cmpxchg(obj->mark_addr(), monitor, displaced_header) == monitor) {\n+    \/\/   \/\/ We swapped the unlocked mark in displaced_header into the object's mark word.\n+    \/\/   monitor->set_obj(NULL);\n+\n+    \/\/ If we still have a lightweight lock, unlock the object and be done.\n+\n+    \/\/ The object address from the monitor is in object.\n+    ld(object, BasicObjectLock::obj_offset_in_bytes(), monitor);\n+    addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());\n+\n+    \/\/ We have the displaced header in displaced_header. If the lock is still\n+    \/\/ lightweight, it will contain the monitor address and we'll store the\n+    \/\/ displaced header back into the object's mark word.\n+    \/\/ CmpxchgX sets CCR0 to cmpX(current, monitor).\n+    cmpxchgd(\/*flag=*\/CCR0,\n+             \/*current_value=*\/current_header,\n+             \/*compare_value=*\/monitor, \/*exchange_value=*\/displaced_header,\n+             \/*where=*\/object_mark_addr,\n+             MacroAssembler::MemBarRel,\n+             MacroAssembler::cmpxchgx_hint_release_lock(),\n+             noreg,\n+             &slow_case);\n+    b(free_slot);\n+\n+    \/\/ } else {\n+    \/\/   \/\/ Slow path.\n+    \/\/   InterpreterRuntime::monitorexit(monitor);\n+\n+    \/\/ The lock has been converted into a heavy lock and hence\n+    \/\/ we need to get into the slow case.\n+    bind(slow_case);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);\n+    \/\/ }\n+\n+    Label done;\n+    b(done); \/\/ Monitor register may be overwritten! Runtime has already freed the slot.\n+\n+    \/\/ Exchange worked, do monitor->set_obj(NULL);\n+    align(32, 12);\n+    bind(free_slot);\n+    li(R0, 0);\n+    std(R0, BasicObjectLock::obj_offset_in_bytes(), monitor);\n+    bind(done);\n+  }\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":182,"deletions":2,"binary":false,"changes":184,"status":"modified"},{"patch":"@@ -2544,0 +2544,1 @@\n+  std(boxReg, BasicLock::displaced_header_offset_in_bytes(), boxReg);\n@@ -2651,2 +2652,26 @@\n-  \/\/ Set NE to indicate 'failure' -> take slow-path.\n-  crandc(flag, Assembler::equal, flag, Assembler::equal);\n+  if (!UseHeavyMonitors) {\n+    \/\/ Set displaced_header to be (markWord of object | UNLOCK_VALUE).\n+    ori(displaced_header, displaced_header, markWord::unlocked_value);\n+\n+    \/\/ Load Compare Value application register.\n+\n+    \/\/ Initialize the box. (Must happen before we update the object mark!)\n+    std(displaced_header, BasicLock::displaced_header_offset_in_bytes(), box);\n+\n+    \/\/ Must fence, otherwise, preceding store(s) may float below cmpxchg.\n+    \/\/ Compare object markWord with mark and if equal exchange scratch1 with object markWord.\n+    cmpxchgd(\/*flag=*\/flag,\n+             \/*current_value=*\/current_header,\n+             \/*compare_value=*\/displaced_header,\n+             \/*exchange_value=*\/box,\n+             \/*where=*\/oop,\n+             MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n+             MacroAssembler::cmpxchgx_hint_acquire_lock(),\n+             noreg,\n+             &cas_failed,\n+             \/*check without membar and ldarx first*\/true);\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+  } else {\n+    \/\/ Set NE to indicate 'failure' -> take slow-path.\n+    crandc(flag, Assembler::equal, flag, Assembler::equal);\n+  }\n@@ -2670,0 +2695,1 @@\n+  std(R0\/*==0, perhaps*\/, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -2696,0 +2722,2 @@\n+  \/\/ Store a non-null value into the box.\n+  std(box, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -2737,0 +2765,9 @@\n+  if (!UseHeavyMonitors) {\n+    \/\/ Find the lock address and load the displaced header from the stack.\n+    ld(displaced_header, BasicLock::displaced_header_offset_in_bytes(), box);\n+\n+    \/\/ If the displaced header is 0, we have a recursive unlock.\n+    cmpdi(flag, displaced_header, 0);\n+    beq(flag, cont);\n+  }\n+\n@@ -2744,2 +2781,18 @@\n-  \/\/ Set NE to indicate 'failure' -> take slow-path.\n-  crandc(flag, Assembler::equal, flag, Assembler::equal);\n+  if (!UseHeavyMonitors) {\n+    \/\/ Check if it is still a light weight lock, this is is true if we see\n+    \/\/ the stack address of the basicLock in the markWord of the object.\n+    \/\/ Cmpxchg sets flag to cmpd(current_header, box).\n+    cmpxchgd(\/*flag=*\/flag,\n+             \/*current_value=*\/current_header,\n+             \/*compare_value=*\/box,\n+             \/*exchange_value=*\/displaced_header,\n+             \/*where=*\/oop,\n+             MacroAssembler::MemBarRel,\n+             MacroAssembler::cmpxchgx_hint_release_lock(),\n+             noreg,\n+             &cont);\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+  } else {\n+    \/\/ Set NE to indicate 'failure' -> take slow-path.\n+    crandc(flag, Assembler::equal, flag, Assembler::equal);\n+  }\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.cpp","additions":57,"deletions":4,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -1661,0 +1661,1 @@\n+                                       in_ByteSize(-1),\n@@ -1757,0 +1758,8 @@\n+  int lock_slot_offset = 0;\n+  int lock_offset      = -1;\n+  if (method->is_synchronized()) {                                                \/\/ 5)\n+    lock_slot_offset   = stack_slots;\n+    lock_offset        = lock_slot_offset * VMRegImpl::stack_slot_size;\n+    stack_slots       += VMRegImpl::slots_per_word;\n+  }\n+\n@@ -2008,0 +2017,3 @@\n+    \/\/ Get the lock box slot's address.\n+    __ addi(r_box, R1_SP, lock_offset);\n+\n@@ -2219,0 +2231,1 @@\n+    __ addi(r_box, R1_SP, lock_offset);\n@@ -2332,0 +2345,1 @@\n+                                            in_ByteSize(lock_offset),\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -203,2 +203,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg) {\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg, lock_reg) {\n@@ -211,1 +211,2 @@\n-  ce->store_parameter(_obj_reg->as_register(),  0);\n+  ce->store_parameter(_obj_reg->as_register(),  1);\n+  ce->store_parameter(_lock_reg->as_register(), 0);\n@@ -226,1 +227,5 @@\n-  ce->store_parameter(_obj_reg->as_register(), 0);\n+  if (_compute_lock) {\n+    \/\/ lock_reg was destroyed by fast unlocking attempt => recompute it\n+    ce->monitor_address(_monitor_ix, _lock_reg);\n+  }\n+  ce->store_parameter(_lock_reg->as_register(), 0);\n","filename":"src\/hotspot\/cpu\/riscv\/c1_CodeStubs_riscv.cpp","additions":9,"deletions":4,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -242,1 +242,1 @@\n-      BytesPerWord * (number_of_locks - 1);\n+      (2 * BytesPerWord) * (number_of_locks - 1);\n@@ -247,1 +247,1 @@\n-      int slot_offset = monitor_offset - (i * BytesPerWord);\n+      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n@@ -252,1 +252,1 @@\n-        __ ld(t0, Address(OSR_buf, slot_offset));\n+        __ ld(t0, Address(OSR_buf, slot_offset + 1 * BytesPerWord));\n@@ -258,1 +258,3 @@\n-      __ ld(x9, Address(OSR_buf, slot_offset));\n+      __ ld(x9, Address(OSR_buf, slot_offset + 0));\n+      __ sd(x9, frame_map()->address_for_monitor_lock(i));\n+      __ ld(x9, Address(OSR_buf, slot_offset + 1 * BytesPerWord));\n@@ -360,2 +362,1 @@\n-    __ ld(x14, Address(x10, BasicObjectLock::obj_offset_in_bytes()));\n-    stub = new MonitorExitStub(FrameMap::r14_opr);\n+    stub = new MonitorExitStub(FrameMap::r10_opr, true, 0);\n@@ -1504,0 +1505,1 @@\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -1510,0 +1512,1 @@\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -1606,1 +1609,1 @@\n-  __ la(dst->as_register(), frame_map()->address_for_monitor_object(monitor_no));\n+  __ la(dst->as_register(), frame_map()->address_for_monitor_lock(monitor_no));\n","filename":"src\/hotspot\/cpu\/riscv\/c1_LIRAssembler_riscv.cpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -279,1 +279,1 @@\n-  LIR_Opr lock = new_register(T_ADDRESS);\n+  LIR_Opr lock = new_register(T_INT);\n@@ -288,1 +288,1 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n+  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n@@ -298,1 +298,1 @@\n-  LIR_Opr lock = new_register(T_ADDRESS);\n+  LIR_Opr lock = new_register(T_INT);\n@@ -301,1 +301,1 @@\n-  monitor_exit(obj_temp, lock, syncTempOpr(), new_register(T_INT), x->monitor_no());\n+  monitor_exit(obj_temp, lock, syncTempOpr(), LIR_OprFact::illegalOpr, x->monitor_no());\n","filename":"src\/hotspot\/cpu\/riscv\/c1_LIRGenerator_riscv.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -62,0 +62,3 @@\n+  \/\/ save object being locked into the BasicObjectLock\n+  sd(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n+\n@@ -71,3 +74,34 @@\n-  ld(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-  fast_lock(obj, hdr, disp_hdr, t0, t1, slow_case);\n-\n+  \/\/ Load object header\n+  ld(hdr, Address(obj, hdr_offset));\n+  \/\/ and mark it as unlocked\n+  ori(hdr, hdr, markWord::unlocked_value);\n+  \/\/ save unlocked object header into the displaced header location on the stack\n+  sd(hdr, Address(disp_hdr, 0));\n+  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n+  \/\/ displaced header address in the object header - if it is not the same, get the\n+  \/\/ object header instead\n+  la(t1, Address(obj, hdr_offset));\n+  cmpxchgptr(hdr, disp_hdr, t1, t0, done, \/*fallthough*\/NULL);\n+  \/\/ if the object header was the same, we're done\n+  \/\/ if the object header was not the same, it is now in the hdr register\n+  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n+  \/\/\n+  \/\/ 1) (hdr & aligned_mask) == 0\n+  \/\/ 2) sp <= hdr\n+  \/\/ 3) hdr <= sp + page_size\n+  \/\/\n+  \/\/ these 3 tests can be done by evaluating the following expression:\n+  \/\/\n+  \/\/ (hdr -sp) & (aligned_mask - page_size)\n+  \/\/\n+  \/\/ assuming both the stack pointer and page_size have their least\n+  \/\/ significant 2 bits cleared and page_size is a power of 2\n+  sub(hdr, hdr, sp);\n+  mv(t0, aligned_mask - os::vm_page_size());\n+  andr(hdr, hdr, t0);\n+  \/\/ for recursive locking, the result is zero => save it in the displaced header\n+  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n+  sd(hdr, Address(disp_hdr, 0));\n+  \/\/ otherwise we don't care about the result and handle locking via runtime call\n+  bnez(hdr, slow_case, \/* is_far *\/ true);\n+  bind(done);\n@@ -80,1 +114,2 @@\n-  assert_different_registers(hdr, obj, disp_hdr);\n+  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n+  Label done;\n@@ -82,0 +117,7 @@\n+  \/\/ load displaced header\n+  ld(hdr, Address(disp_hdr, 0));\n+  \/\/ if the loaded hdr is NULL we had recursive locking\n+  \/\/ if we had recursive locking, we are done\n+  beqz(hdr, done);\n+  \/\/ load object\n+  ld(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n@@ -83,3 +125,12 @@\n-\n-  ld(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-  fast_unlock(obj, hdr, t0, t1, slow_case);\n+  \/\/ test if object header is pointing to the displaced header, and if so, restore\n+  \/\/ the displaced header in the object - if the object header is not pointing to\n+  \/\/ the displaced header, get the object header instead\n+  \/\/ if the object header was not pointing to the displaced header,\n+  \/\/ we do unlocking via runtime call\n+  if (hdr_offset) {\n+    la(t0, Address(obj, hdr_offset));\n+    cmpxchgptr(disp_hdr, hdr, t0, t1, done, &slow_case);\n+  } else {\n+    cmpxchgptr(disp_hdr, hdr, obj, t1, done, &slow_case);\n+  }\n+  bind(done);\n","filename":"src\/hotspot\/cpu\/riscv\/c1_MacroAssembler_riscv.cpp","additions":58,"deletions":7,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -886,1 +886,2 @@\n-        f.load_argument(0, x10); \/\/ x10: object\n+        f.load_argument(1, x10); \/\/ x10: object\n+        f.load_argument(0, x11); \/\/ x11: lock address\n@@ -888,1 +889,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), x10);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), x10, x11);\n@@ -907,1 +908,1 @@\n-        f.load_argument(0, x10); \/\/ x10: object\n+        f.load_argument(0, x10); \/\/ x10: lock address\n","filename":"src\/hotspot\/cpu\/riscv\/c1_Runtime1_riscv.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -781,7 +781,0 @@\n-\n-  const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-\n-  \/\/ Load object pointer into obj_reg c_rarg3\n-  ld(obj_reg, Address(lock_reg, obj_offset));\n-\n@@ -791,1 +784,1 @@\n-            obj_reg);\n+            lock_reg);\n@@ -797,0 +790,6 @@\n+    const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n+\n+    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n+    const int mark_offset = lock_offset +\n+                            BasicLock::displaced_header_offset_in_bytes();\n@@ -800,0 +799,3 @@\n+    \/\/ Load object pointer into obj_reg c_rarg3\n+    ld(obj_reg, Address(lock_reg, obj_offset));\n+\n@@ -807,3 +809,28 @@\n-    ld(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    fast_lock(obj_reg, tmp, t0, swap_reg, t1, slow_case);\n-    j(done);\n+    \/\/ Load (object->mark() | 1) into swap_reg\n+    ld(t0, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    ori(swap_reg, t0, 1);\n+\n+    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+    sd(swap_reg, Address(lock_reg, mark_offset));\n+\n+    assert(lock_offset == 0,\n+           \"displached header must be first word in BasicObjectLock\");\n+\n+    cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, t0, done, \/*fallthrough*\/NULL);\n+\n+    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+    \/\/  1) (mark & 7) == 0, and\n+    \/\/  2) sp <= mark < mark + os::pagesize()\n+    \/\/\n+    \/\/ These 3 tests can be done by evaluating the following\n+    \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n+    \/\/ assuming both stack pointer and pagesize have their\n+    \/\/ least significant 3 bits clear.\n+    \/\/ NOTE: the oopMark is in swap_reg x10 as the result of cmpxchg\n+    sub(swap_reg, swap_reg, sp);\n+    mv(t0, (int64_t)(7 - os::vm_page_size()));\n+    andr(swap_reg, swap_reg, t0);\n+\n+    \/\/ Save the test result, for recursive case, the result is zero\n+    sd(swap_reg, Address(lock_reg, mark_offset));\n+    beqz(swap_reg, done);\n@@ -816,1 +843,1 @@\n-            obj_reg);\n+            lock_reg);\n@@ -838,8 +865,0 @@\n-  const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n-\n-  \/\/ Load oop into obj_reg(c_rarg3)\n-  ld(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-  \/\/ Free entry\n-  sd(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n@@ -847,1 +866,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -849,1 +868,1 @@\n-    Label done, slow_case;\n+    Label done;\n@@ -853,0 +872,1 @@\n+    const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n@@ -856,4 +876,6 @@\n-    \/\/ Check for non-symmetric locking. This is allowed by the spec and the interpreter\n-    \/\/ must handle it.\n-    ld(header_reg, Address(xthread, Thread::lock_stack_current_offset()));\n-    bne(header_reg, obj_reg, slow_case);\n+    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+    \/\/ structure Store the BasicLock address into x10\n+    la(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+\n+    \/\/ Load oop into obj_reg(c_rarg3)\n+    ld(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n@@ -861,3 +883,12 @@\n-    ld(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    fast_unlock(obj_reg, header_reg, swap_reg, t0, slow_case);\n-    j(done);\n+    \/\/ Free entry\n+    sd(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+    \/\/ Load the old header from BasicLock structure\n+    ld(header_reg, Address(swap_reg,\n+                           BasicLock::displaced_header_offset_in_bytes()));\n+\n+    \/\/ Test for recursion\n+    beqz(header_reg, done);\n+\n+    \/\/ Atomic swap back the old header\n+    cmpxchg_obj_header(swap_reg, header_reg, obj_reg, t0, done, \/*fallthrough*\/NULL);\n@@ -866,2 +897,2 @@\n-    bind(slow_case);\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n+    sd(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes())); \/\/ restore obj\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -870,0 +901,1 @@\n+\n","filename":"src\/hotspot\/cpu\/riscv\/interp_masm_riscv.cpp","additions":63,"deletions":31,"binary":false,"changes":94,"status":"modified"},{"patch":"@@ -2178,0 +2178,6 @@\n+void MacroAssembler::cmpxchg_obj_header(Register oldv, Register newv, Register obj, Register tmp,\n+                                        Label &succeed, Label *fail) {\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"assumption\");\n+  cmpxchgptr(oldv, newv, obj, tmp, succeed, fail);\n+}\n+\n@@ -4147,46 +4153,0 @@\n-\n-\/\/ Attempt to fast-lock an object. Fall-through on success, branch to slow label\n-\/\/ on failure.\n-\/\/ Registers:\n-\/\/  - obj: the object to be locked\n-\/\/  - hdr: the header, already loaded from obj, will be destroyed\n-\/\/  - tmp1, tmp2, tmp3: temporary registers, will be destroyed\n-void MacroAssembler::fast_lock(Register obj, Register hdr, Register tmp1, Register tmp2, Register tmp3, Label& slow) {\n-  \/\/ Check if we would have space on lock-stack for the object.\n-  ld(tmp1, Address(xthread, Thread::lock_stack_current_offset()));\n-  ld(tmp2, Address(xthread, Thread::lock_stack_limit_offset()));\n-  bge(tmp1, tmp2, slow, true);\n-\n-  \/\/ Load (object->mark() | 1) into hdr\n-  ori(hdr, hdr, markWord::unlocked_value);\n-  \/\/ Clear lock-bits, into tmp2\n-  xori(tmp2, hdr, markWord::unlocked_value);\n-  \/\/ Try to swing header from unlocked to locked\n-  Label success;\n-  cmpxchgptr(hdr, tmp2, obj, tmp3, success, &slow);\n-  bind(success);\n-\n-  \/\/ After successful lock, push object on lock-stack\n-  sd(obj, Address(tmp1, 0));\n-  add(tmp1, tmp1, oopSize);\n-  sd(tmp1, Address(xthread, Thread::lock_stack_current_offset()));\n-}\n-\n-void MacroAssembler::fast_unlock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow) {\n-  \/\/ Load the expected old header (lock-bits cleared to indicate 'locked') into hdr\n-  mv(tmp1, ~markWord::lock_mask_in_place);\n-  andr(hdr, hdr, tmp1);\n-\n-  \/\/ Load the new header (unlocked) into tmp1\n-  ori(tmp1, hdr, markWord::unlocked_value);\n-\n-  \/\/ Try to swing header from locked to unlocked\n-  Label success;\n-  cmpxchgptr(hdr, tmp1, obj, tmp2, success, &slow);\n-  bind(success);\n-\n-  \/\/ After successful unlock, pop object from lock-stack\n-  ld(tmp1, Address(xthread, Thread::lock_stack_current_offset()));\n-  sub(tmp1, tmp1, oopSize);\n-  sd(tmp1, Address(xthread, Thread::lock_stack_current_offset()));\n-}\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.cpp","additions":6,"deletions":46,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -559,0 +559,1 @@\n+  void cmpxchg_obj_header(Register oldv, Register newv, Register obj, Register tmp, Label &succeed, Label *fail);\n@@ -930,4 +931,0 @@\n-\n-public:\n-  void fast_lock(Register obj, Register hdr, Register tmp1, Register tmp2, Register tmp3, Label& slow);\n-  void fast_unlock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow);\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2381,2 +2381,2 @@\n-      Label slow;\n-      __ fast_lock(oop, disp_hdr, box, tmp, t0, slow);\n+      \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n+      __ ori(tmp, disp_hdr, markWord::unlocked_value);\n@@ -2384,1 +2384,8 @@\n-      \/\/ Indicate success at cont.\n+      \/\/ Initialize the box. (Must happen before we update the object mark!)\n+      __ sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ Compare object markWord with an unlocked value (tmp) and if\n+      \/\/ equal exchange the stack address of our box with object markWord.\n+      \/\/ On failure disp_hdr contains the possibly locked markWord.\n+      __ cmpxchg(\/*memory address*\/oop, \/*expected value*\/tmp, \/*new value*\/box, Assembler::int64, Assembler::aq,\n+                 Assembler::rl, \/*result*\/disp_hdr);\n@@ -2386,2 +2393,20 @@\n-      __ j(cont);\n-      __ bind(slow);\n+      __ beq(disp_hdr, tmp, cont); \/\/ prepare zero flag and goto cont if we won the cas\n+\n+      assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+\n+      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n+      \/\/ object, will have now locked it will continue at label cont\n+      \/\/ We did not see an unlocked object so try the fast recursive case.\n+\n+      \/\/ Check if the owner is self by comparing the value in the\n+      \/\/ markWord of object (disp_hdr) with the stack pointer.\n+      __ sub(disp_hdr, disp_hdr, sp);\n+      __ mv(tmp, (intptr_t) (~(os::vm_page_size()-1) | (uintptr_t)markWord::lock_mask_in_place));\n+      \/\/ If (mark & lock_mask) == 0 and mark - sp < page_size, we are stack-locking and goto cont,\n+      \/\/ hence we can store 0 as the displaced header in the box, which indicates that it is a\n+      \/\/ recursive lock.\n+      __ andr(tmp\/*==0?*\/, disp_hdr, tmp);\n+      __ sd(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+      __ mv(flag, tmp); \/\/ we can use the value of tmp as the result here\n+    } else {\n+      __ mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow-path\n@@ -2390,1 +2415,0 @@\n-    __ mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow-path\n@@ -2403,0 +2427,7 @@\n+    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n+    \/\/ lock. The fast-path monitor unlock code checks for\n+    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n+    \/\/ relevant bit set, and also matches ObjectSynchronizer::slow_enter.\n+    __ mv(tmp, (address)markWord::unused_mark().value());\n+    __ sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n@@ -2429,0 +2460,9 @@\n+    if (!UseHeavyMonitors) {\n+      \/\/ Find the lock address and load the displaced header from the stack.\n+      __ ld(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ If the displaced header is 0, we have a recursive unlock.\n+      __ mv(flag, disp_hdr);\n+      __ beqz(disp_hdr, cont);\n+    }\n+\n@@ -2431,2 +2471,2 @@\n-\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+    __ andi(t0, disp_hdr, markWord::monitor_value);\n+    __ bnez(t0, object_has_monitor);\n@@ -2435,5 +2475,3 @@\n-      Label slow;\n-      __ andi(t0, tmp, markWord::monitor_value);\n-      __ bnez(t0, object_has_monitor);\n-\n-      __ fast_unlock(oop, tmp, box, disp_hdr, slow);\n+      \/\/ Check if it is still a light weight lock, this is true if we\n+      \/\/ see the stack address of the basicLock in the markWord of the\n+      \/\/ object.\n@@ -2441,4 +2479,5 @@\n-      \/\/ Indicate success at cont.\n-      __ mv(flag, zr);\n-      __ j(cont);\n-      __ bind(slow);\n+      __ cmpxchg(\/*memory address*\/oop, \/*expected value*\/box, \/*new value*\/disp_hdr, Assembler::int64, Assembler::relaxed,\n+                 Assembler::rl, \/*result*\/tmp);\n+      __ xorr(flag, box, tmp); \/\/ box == tmp if cas succeeds\n+    } else {\n+      __ mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow path\n@@ -2446,2 +2485,0 @@\n-\n-    __ mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow path\n@@ -2450,0 +2487,2 @@\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+\n@@ -2454,12 +2493,0 @@\n-\n-    \/\/ If the owner is anonymous, we need to fix it -- in the slow-path.\n-    {\n-      Label L;\n-      __ ld(disp_hdr, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));\n-      __ mv(t0, (unsigned char)(intptr_t)ANONYMOUS_OWNER);\n-      __ bne(disp_hdr, t0, L);\n-      __ mv(flag, 1); \/\/ Indicate failure at cont -- dive into slow-path.\n-      __ j(cont);\n-      __ bind(L);\n-    }\n-\n@@ -10370,2 +10397,2 @@\n-  match(Set cr (FastLock object));\n-  effect(TEMP box, TEMP tmp1, TEMP tmp2);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp1, TEMP tmp2);\n@@ -10384,2 +10411,2 @@\n-  match(Set cr (FastUnlock object));\n-  effect(TEMP box, TEMP tmp1, TEMP tmp2);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp1, TEMP tmp2);\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":62,"deletions":35,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -957,0 +957,1 @@\n+                                       in_ByteSize(-1),\n@@ -1012,0 +1013,1 @@\n+  int lock_slot_offset = 0;\n@@ -1024,0 +1026,1 @@\n+    lock_slot_offset = stack_slots;\n@@ -1040,0 +1043,2 @@\n+  \/\/      | lock box (if sync)  |\n+  \/\/      |---------------------| <- lock_slot_offset\n@@ -1295,0 +1300,2 @@\n+    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n+\n@@ -1298,0 +1305,4 @@\n+    \/\/ Get address of the box\n+\n+    __ la(lock_reg, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+\n@@ -1302,2 +1313,28 @@\n-      __ ld(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_lock(obj_reg, old_hdr, swap_reg, tmp, t0, slow_path_lock);\n+      \/\/ Load (object->mark() | 1) into swap_reg % x10\n+      __ ld(t0, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ ori(swap_reg, t0, 1);\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ sd(swap_reg, Address(lock_reg, mark_word_offset));\n+\n+      \/\/ src -> dest if dest == x10 else x10 <- dest\n+      {\n+        Label here;\n+        __ cmpxchg_obj_header(x10, lock_reg, obj_reg, t0, lock_done, \/*fallthrough*\/NULL);\n+      }\n+\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) sp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg % 10 as the result of cmpxchg\n+\n+      __ sub(swap_reg, swap_reg, sp);\n+      __ andi(swap_reg, swap_reg, 3 - os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ sd(swap_reg, Address(lock_reg, mark_word_offset));\n+      __ bnez(swap_reg, slow_path_lock);\n@@ -1395,0 +1432,7 @@\n+    if (!UseHeavyMonitors) {\n+      \/\/ Simple recursive lock?\n+      __ ld(t0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      __ beqz(t0, done);\n+    }\n+\n+\n@@ -1401,2 +1445,9 @@\n-      __ ld(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_unlock(obj_reg, old_hdr, swap_reg, t0, slow_path_unlock);\n+      \/\/ get address of the stack lock\n+      __ la(x10, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      \/\/  get old displaced header\n+      __ ld(old_hdr, Address(x10, 0));\n+\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      Label succeed;\n+      __ cmpxchg_obj_header(x10, old_hdr, obj_reg, t0, succeed, &slow_path_unlock);\n+      __ bind(succeed);\n@@ -1471,1 +1522,2 @@\n-    __ mv(c_rarg1, xthread);\n+    __ mv(c_rarg1, lock_reg);\n+    __ mv(c_rarg2, xthread);\n@@ -1474,1 +1526,1 @@\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_locking_C), 2);\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_locking_C), 3);\n@@ -1496,1 +1548,2 @@\n-    __ mv(c_rarg1, xthread);\n+    __ mv(c_rarg2, xthread);\n+    __ la(c_rarg1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n@@ -1600,0 +1653,1 @@\n+                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/riscv\/sharedRuntime_riscv.cpp","additions":61,"deletions":7,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -230,2 +230,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n-  : MonitorAccessStub(obj_reg) {\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n+  : MonitorAccessStub(obj_reg, lock_reg) {\n@@ -244,0 +244,1 @@\n+  __ lgr_if_needed(Z_R13, _lock_reg->as_register()); \/\/ See LIRGenerator::syncTempOpr().\n@@ -254,1 +255,6 @@\n-  __ lgr_if_needed(Z_R1_scratch, _obj_reg->as_register());\n+  if (_compute_lock) {\n+    \/\/ Lock_reg was destroyed by fast unlocking attempt => recompute it.\n+    ce->monitor_address(_monitor_ix, FrameMap::as_opr(Z_R1_scratch));\n+  } else {\n+    __ lgr_if_needed(Z_R1_scratch, _lock_reg->as_register());\n+  }\n","filename":"src\/hotspot\/cpu\/s390\/c1_CodeStubs_s390.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -139,1 +139,4 @@\n-      BytesPerWord * (number_of_locks - 1);\n+      (2 * BytesPerWord) * (number_of_locks - 1);\n+    \/\/ SharedRuntime::OSR_migration_begin() packs BasicObjectLocks in\n+    \/\/ the OSR buffer using 2 word entries: first the lock and then\n+    \/\/ the oop.\n@@ -141,1 +144,1 @@\n-      int slot_offset = monitor_offset - (i * BytesPerWord);\n+      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n@@ -145,1 +148,3 @@\n-      __ z_lg(Z_R1_scratch, slot_offset, OSR_buf);\n+      __ z_lg(Z_R1_scratch, slot_offset + 0, OSR_buf);\n+      __ z_stg(Z_R1_scratch, frame_map()->address_for_monitor_lock(i));\n+      __ z_lg(Z_R1_scratch, slot_offset + 1*BytesPerWord, OSR_buf);\n@@ -216,3 +221,2 @@\n-    __ z_lg(Z_R1_scratch, Address(Z_R1_scratch, BasicObjectLock::obj_offset_in_bytes()));\n-    stub = new MonitorExitStub(lock);\n-    __ branch_optimized(Assembler::bcondAlways, *stub->entry());\n+    stub = new MonitorExitStub(lock, true, 0);\n+    __ unlock_object(Rtmp1, Rtmp2, lock->as_register(), *stub->entry());\n@@ -2711,1 +2715,1 @@\n-  Address addr = frame_map()->address_for_monitor_object(monitor_no);\n+  Address addr = frame_map()->address_for_monitor_lock(monitor_no);\n@@ -2719,3 +2723,19 @@\n-  if (op->info() != NULL) {\n-    add_debug_info_for_null_check_here(op->info());\n-    __ null_check(obj);\n+  if (UseHeavyMonitors) {\n+    if (op->info() != NULL) {\n+      add_debug_info_for_null_check_here(op->info());\n+      __ null_check(obj);\n+    }\n+    __ branch_optimized(Assembler::bcondAlways, *op->stub()->entry());\n+  } else if (op->code() == lir_lock) {\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n+    \/\/ Add debug info for NullPointerException only if one is possible.\n+    if (op->info() != NULL) {\n+      add_debug_info_for_null_check_here(op->info());\n+    }\n+    __ lock_object(hdr, obj, lock, *op->stub()->entry());\n+    \/\/ done\n+  } else if (op->code() == lir_unlock) {\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n+    __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n+  } else {\n+    ShouldNotReachHere();\n@@ -2723,1 +2743,0 @@\n-  __ branch_optimized(Assembler::bcondAlways, *op->stub()->entry());\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRAssembler_s390.cpp","additions":30,"deletions":11,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -277,1 +277,1 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n+  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRGenerator_s390.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -81,0 +81,79 @@\n+void C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n+  const int hdr_offset = oopDesc::mark_offset_in_bytes();\n+  assert_different_registers(hdr, obj, disp_hdr);\n+  NearLabel done;\n+\n+  verify_oop(obj, FILE_AND_LINE);\n+\n+  \/\/ Load object header.\n+  z_lg(hdr, Address(obj, hdr_offset));\n+\n+  \/\/ Save object being locked into the BasicObjectLock...\n+  z_stg(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(Z_R1_scratch, obj);\n+    testbit(Address(Z_R1_scratch, Klass::access_flags_offset()), exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n+    z_btrue(slow_case);\n+  }\n+\n+  \/\/ and mark it as unlocked.\n+  z_oill(hdr, markWord::unlocked_value);\n+  \/\/ Save unlocked object header into the displaced header location on the stack.\n+  z_stg(hdr, Address(disp_hdr, (intptr_t)0));\n+  \/\/ Test if object header is still the same (i.e. unlocked), and if so, store the\n+  \/\/ displaced header address in the object header. If it is not the same, get the\n+  \/\/ object header instead.\n+  z_csg(hdr, disp_hdr, hdr_offset, obj);\n+  \/\/ If the object header was the same, we're done.\n+  branch_optimized(Assembler::bcondEqual, done);\n+  \/\/ If the object header was not the same, it is now in the hdr register.\n+  \/\/ => Test if it is a stack pointer into the same stack (recursive locking), i.e.:\n+  \/\/\n+  \/\/ 1) (hdr & markWord::lock_mask_in_place) == 0\n+  \/\/ 2) rsp <= hdr\n+  \/\/ 3) hdr <= rsp + page_size\n+  \/\/\n+  \/\/ These 3 tests can be done by evaluating the following expression:\n+  \/\/\n+  \/\/ (hdr - Z_SP) & (~(page_size-1) | markWord::lock_mask_in_place)\n+  \/\/\n+  \/\/ assuming both the stack pointer and page_size have their least\n+  \/\/ significant 2 bits cleared and page_size is a power of 2\n+  z_sgr(hdr, Z_SP);\n+\n+  load_const_optimized(Z_R0_scratch, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n+  z_ngr(hdr, Z_R0_scratch); \/\/ AND sets CC (result eq\/ne 0).\n+  \/\/ For recursive locking, the result is zero. => Save it in the displaced header\n+  \/\/ location (NULL in the displaced hdr location indicates recursive locking).\n+  z_stg(hdr, Address(disp_hdr, (intptr_t)0));\n+  \/\/ Otherwise we don't care about the result and handle locking via runtime call.\n+  branch_optimized(Assembler::bcondNotZero, slow_case);\n+  \/\/ done\n+  bind(done);\n+}\n+\n+void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n+  const int aligned_mask = BytesPerWord -1;\n+  const int hdr_offset = oopDesc::mark_offset_in_bytes();\n+  assert_different_registers(hdr, obj, disp_hdr);\n+  NearLabel done;\n+\n+  \/\/ Load displaced header.\n+  z_ltg(hdr, Address(disp_hdr, (intptr_t)0));\n+  \/\/ If the loaded hdr is NULL we had recursive locking, and we are done.\n+  z_bre(done);\n+  \/\/ Load object.\n+  z_lg(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n+  verify_oop(obj, FILE_AND_LINE);\n+  \/\/ Test if object header is pointing to the displaced header, and if so, restore\n+  \/\/ the displaced header in the object. If the object header is not pointing to\n+  \/\/ the displaced header, get the object header instead.\n+  z_csg(disp_hdr, hdr, hdr_offset, obj);\n+  \/\/ If the object header was not pointing to the displaced header,\n+  \/\/ we do unlocking via runtime call.\n+  branch_optimized(Assembler::bcondNotEqual, slow_case);\n+  \/\/ done\n+  bind(done);\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/c1_MacroAssembler_s390.cpp","additions":79,"deletions":0,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -43,0 +43,13 @@\n+  \/\/ locking\n+  \/\/ hdr     : Used to hold locked markWord to be CASed into obj, contents destroyed.\n+  \/\/ obj     : Must point to the object to lock, contents preserved.\n+  \/\/ disp_hdr: Must point to the displaced header location, contents preserved.\n+  \/\/ Returns code offset at which to add null check debug information.\n+  void lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case);\n+\n+  \/\/ unlocking\n+  \/\/ hdr     : Used to hold original markWord to be CASed back into obj, contents destroyed.\n+  \/\/ obj     : Must point to the object to lock, contents preserved.\n+  \/\/ disp_hdr: Must point to the displaced header location, contents destroyed.\n+  void unlock_object(Register hdr, Register obj, Register lock, Label& slow_case);\n+\n","filename":"src\/hotspot\/cpu\/s390\/c1_MacroAssembler_s390.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -588,1 +588,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), Z_R1_scratch);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), Z_R1_scratch, Z_R13);\n","filename":"src\/hotspot\/cpu\/s390\/c1_Runtime1_s390.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -970,0 +970,89 @@\n+\n+  if (UseHeavyMonitors) {\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n+    return;\n+  }\n+\n+  \/\/ template code:\n+  \/\/\n+  \/\/ markWord displaced_header = obj->mark().set_unlocked();\n+  \/\/ monitor->lock()->set_displaced_header(displaced_header);\n+  \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n+  \/\/   \/\/ We stored the monitor address into the object's mark word.\n+  \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n+  \/\/   \/\/ Simple recursive case.\n+  \/\/   monitor->lock()->set_displaced_header(NULL);\n+  \/\/ } else {\n+  \/\/   \/\/ Slow path.\n+  \/\/   InterpreterRuntime::monitorenter(THREAD, monitor);\n+  \/\/ }\n+\n+  const Register displaced_header = Z_ARG5;\n+  const Register object_mark_addr = Z_ARG4;\n+  const Register current_header   = Z_ARG5;\n+\n+  NearLabel done;\n+  NearLabel slow_case;\n+\n+  \/\/ markWord displaced_header = obj->mark().set_unlocked();\n+\n+  \/\/ Load markWord from object into displaced_header.\n+  z_lg(displaced_header, oopDesc::mark_offset_in_bytes(), object);\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(Z_R1_scratch, object);\n+    testbit(Address(Z_R1_scratch, Klass::access_flags_offset()), exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n+    z_btrue(slow_case);\n+  }\n+\n+  \/\/ Set displaced_header to be (markWord of object | UNLOCK_VALUE).\n+  z_oill(displaced_header, markWord::unlocked_value);\n+\n+  \/\/ monitor->lock()->set_displaced_header(displaced_header);\n+\n+  \/\/ Initialize the box (Must happen before we update the object mark!).\n+  z_stg(displaced_header, BasicObjectLock::lock_offset_in_bytes() +\n+                          BasicLock::displaced_header_offset_in_bytes(), monitor);\n+\n+  \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n+\n+  \/\/ Store stack address of the BasicObjectLock (this is monitor) into object.\n+  add2reg(object_mark_addr, oopDesc::mark_offset_in_bytes(), object);\n+\n+  z_csg(displaced_header, monitor, 0, object_mark_addr);\n+  assert(current_header==displaced_header, \"must be same register\"); \/\/ Identified two registers from z\/Architecture.\n+\n+  z_bre(done);\n+\n+  \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n+  \/\/   \/\/ Simple recursive case.\n+  \/\/   monitor->lock()->set_displaced_header(NULL);\n+\n+  \/\/ We did not see an unlocked object so try the fast recursive case.\n+\n+  \/\/ Check if owner is self by comparing the value in the markWord of object\n+  \/\/ (current_header) with the stack pointer.\n+  z_sgr(current_header, Z_SP);\n+\n+  assert(os::vm_page_size() > 0xfff, \"page size too small - change the constant\");\n+\n+  \/\/ The prior sequence \"LGR, NGR, LTGR\" can be done better\n+  \/\/ (Z_R1 is temp and not used after here).\n+  load_const_optimized(Z_R0, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n+  z_ngr(Z_R0, current_header); \/\/ AND sets CC (result eq\/ne 0)\n+\n+  \/\/ If condition is true we are done and hence we can store 0 in the displaced\n+  \/\/ header indicating it is a recursive lock and be done.\n+  z_brne(slow_case);\n+  z_release();  \/\/ Membar unnecessary on zarch AND because the above csg does a sync before and after.\n+  z_stg(Z_R0\/*==0!*\/, BasicObjectLock::lock_offset_in_bytes() +\n+                      BasicLock::displaced_header_offset_in_bytes(), monitor);\n+  z_bru(done);\n+\n+  \/\/ } else {\n+  \/\/   \/\/ Slow path.\n+  \/\/   InterpreterRuntime::monitorenter(THREAD, monitor);\n+\n+  \/\/ None of the above fast optimizations worked so we have to get into the\n+  \/\/ slow case of monitor enter.\n+  bind(slow_case);\n@@ -971,0 +1060,4 @@\n+\n+  \/\/ }\n+\n+  bind(done);\n@@ -981,0 +1074,70 @@\n+\n+  if (UseHeavyMonitors) {\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);\n+    return;\n+  }\n+\n+\/\/ else {\n+  \/\/ template code:\n+  \/\/\n+  \/\/ if ((displaced_header = monitor->displaced_header()) == NULL) {\n+  \/\/   \/\/ Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.\n+  \/\/   monitor->set_obj(NULL);\n+  \/\/ } else if (Atomic::cmpxchg(obj->mark_addr(), monitor, displaced_header) == monitor) {\n+  \/\/   \/\/ We swapped the unlocked mark in displaced_header into the object's mark word.\n+  \/\/   monitor->set_obj(NULL);\n+  \/\/ } else {\n+  \/\/   \/\/ Slow path.\n+  \/\/   InterpreterRuntime::monitorexit(monitor);\n+  \/\/ }\n+\n+  const Register displaced_header = Z_ARG4;\n+  const Register current_header   = Z_R1;\n+  Address obj_entry(monitor, BasicObjectLock::obj_offset_in_bytes());\n+  Label done;\n+\n+  if (object == noreg) {\n+    \/\/ In the template interpreter, we must assure that the object\n+    \/\/ entry in the monitor is cleared on all paths. Thus we move\n+    \/\/ loading up to here, and clear the entry afterwards.\n+    object = Z_ARG3; \/\/ Use Z_ARG3 if caller didn't pass object.\n+    z_lg(object, obj_entry);\n+  }\n+\n+  assert_different_registers(monitor, object, displaced_header, current_header);\n+\n+  \/\/ if ((displaced_header = monitor->displaced_header()) == NULL) {\n+  \/\/   \/\/ Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.\n+  \/\/   monitor->set_obj(NULL);\n+\n+  clear_mem(obj_entry, sizeof(oop));\n+\n+  \/\/ Test first if we are in the fast recursive case.\n+  MacroAssembler::load_and_test_long(displaced_header,\n+                                     Address(monitor, BasicObjectLock::lock_offset_in_bytes() +\n+                                                      BasicLock::displaced_header_offset_in_bytes()));\n+  z_bre(done); \/\/ displaced_header == 0 -> goto done\n+\n+  \/\/ } else if (Atomic::cmpxchg(obj->mark_addr(), monitor, displaced_header) == monitor) {\n+  \/\/   \/\/ We swapped the unlocked mark in displaced_header into the object's mark word.\n+  \/\/   monitor->set_obj(NULL);\n+\n+  \/\/ If we still have a lightweight lock, unlock the object and be done.\n+\n+  \/\/ The markword is expected to be at offset 0.\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"unlock_object: review code below\");\n+\n+  \/\/ We have the displaced header in displaced_header. If the lock is still\n+  \/\/ lightweight, it will contain the monitor address and we'll store the\n+  \/\/ displaced header back into the object's mark word.\n+  z_lgr(current_header, monitor);\n+  z_csg(current_header, displaced_header, 0, object);\n+  z_bre(done);\n+\n+  \/\/ } else {\n+  \/\/   \/\/ Slow path.\n+  \/\/   InterpreterRuntime::monitorexit(monitor);\n+\n+  \/\/ The lock has been converted into a heavy lock and hence\n+  \/\/ we need to get into the slow case.\n+  z_stg(object, obj_entry);   \/\/ Restore object entry, has been cleared above.\n@@ -982,0 +1145,4 @@\n+\n+  \/\/ }\n+\n+  bind(done);\n","filename":"src\/hotspot\/cpu\/s390\/interp_masm_s390.cpp","additions":167,"deletions":0,"binary":false,"changes":167,"status":"modified"},{"patch":"@@ -3162,0 +3162,3 @@\n+  \/\/ Initialize the box (must happen before we update the object mark).\n+  z_stg(displacedHeader, BasicLock::displaced_header_offset_in_bytes(), box);\n+\n@@ -3179,0 +3182,1 @@\n+  z_stg(currentHeader\/*==0 or not 0*\/, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -3192,0 +3196,2 @@\n+  \/\/ Store a non-null value into the box.\n+  z_stg(box, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -3218,0 +3224,5 @@\n+  \/\/ Find the lock address and load the displaced header from the stack.\n+  \/\/ if the displaced header is zero, we have a recursive unlock.\n+  load_and_test_long(displacedHeader, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+  z_bre(done);\n+\n","filename":"src\/hotspot\/cpu\/s390\/macroAssembler_s390.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1325,0 +1325,1 @@\n+                                       in_ByteSize(-1),\n@@ -1431,0 +1432,2 @@\n+  \/\/     5| lock box (if sync)  |\n+  \/\/      |---------------------| <- lock_slot_offset\n@@ -1473,0 +1476,8 @@\n+  int lock_slot_offset = 0;\n+  int lock_offset      = -1;\n+  if (method->is_synchronized()) {                                        \/\/ 5)\n+    lock_slot_offset   = stack_slots;\n+    lock_offset        = lock_slot_offset * VMRegImpl::stack_slot_size;\n+    stack_slots       += VMRegImpl::slots_per_word;\n+  }\n+\n@@ -1701,0 +1712,4 @@\n+    lock_offset = (lock_slot_offset * VMRegImpl::stack_slot_size);\n+    \/\/ Get the lock box slot's address.\n+    __ add2reg(r_box, lock_offset, Z_SP);\n+\n@@ -1720,0 +1735,1 @@\n+    __ add2reg(Z_ARG2, lock_offset, oldSP);\n@@ -1894,0 +1910,3 @@\n+    \/\/ ... and address of lock object box.\n+    __ add2reg(r_box, lock_offset, Z_SP);\n+\n@@ -1917,1 +1936,2 @@\n-    __ z_lgr(Z_ARG2, Z_thread);\n+    __ add2reg(Z_ARG2, lock_offset, Z_SP);\n+    __ z_lgr(Z_ARG3, Z_thread);\n@@ -2024,0 +2044,1 @@\n+                                            in_ByteSize(lock_offset),\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":22,"deletions":1,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -260,2 +260,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg, lock_reg)\n@@ -270,1 +270,2 @@\n-  ce->store_parameter(_obj_reg->as_register(),  0);\n+  ce->store_parameter(_obj_reg->as_register(),  1);\n+  ce->store_parameter(_lock_reg->as_register(), 0);\n@@ -286,1 +287,5 @@\n-  ce->store_parameter(_obj_reg->as_register(), 0);\n+  if (_compute_lock) {\n+    \/\/ lock_reg was destroyed by fast unlocking attempt => recompute it\n+    ce->monitor_address(_monitor_ix, _lock_reg);\n+  }\n+  ce->store_parameter(_lock_reg->as_register(), 0);\n","filename":"src\/hotspot\/cpu\/x86\/c1_CodeStubs_x86.cpp","additions":9,"deletions":4,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -313,0 +313,3 @@\n+    \/\/ SharedRuntime::OSR_migration_begin() packs BasicObjectLocks in\n+    \/\/ the OSR buffer using 2 word entries: first the lock and then\n+    \/\/ the oop.\n@@ -314,1 +317,1 @@\n-      int slot_offset = monitor_offset - (i * BytesPerWord);\n+      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n@@ -319,1 +322,1 @@\n-        __ cmpptr(Address(OSR_buf, slot_offset), (int32_t)NULL_WORD);\n+        __ cmpptr(Address(OSR_buf, slot_offset + 1*BytesPerWord), NULL_WORD);\n@@ -325,1 +328,3 @@\n-      __ movptr(rbx, Address(OSR_buf, slot_offset));\n+      __ movptr(rbx, Address(OSR_buf, slot_offset + 0));\n+      __ movptr(frame_map()->address_for_monitor_lock(i), rbx);\n+      __ movptr(rbx, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n@@ -450,3 +455,2 @@\n-    monitor_address(0, FrameMap::rdi_opr);\n-    __ movptr(rsi, Address(rdi, BasicObjectLock::obj_offset_in_bytes()));\n-    stub = new MonitorExitStub(FrameMap::rsi_oop_opr);\n+    monitor_address(0, FrameMap::rax_opr);\n+    stub = new MonitorExitStub(FrameMap::rax_opr, true, 0);\n@@ -456,1 +460,1 @@\n-      __ unlock_object(rax, rsi, rdi, *stub->entry());\n+      __ unlock_object(rdi, rsi, rax, *stub->entry());\n@@ -3503,1 +3507,0 @@\n-  Register tmp = op->scratch_opr()->as_register();\n@@ -3511,0 +3514,1 @@\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -3512,1 +3516,1 @@\n-    int null_check_offset = __ lock_object(hdr, obj, lock, tmp, *op->stub()->entry());\n+    int null_check_offset = __ lock_object(hdr, obj, lock, *op->stub()->entry());\n@@ -3518,1 +3522,2 @@\n-    __ unlock_object(hdr, obj, tmp, *op->stub()->entry());\n+    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n+    __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n@@ -3787,1 +3792,1 @@\n-  __ lea(dst->as_register(), frame_map()->address_for_monitor_object(monitor_no));\n+  __ lea(dst->as_register(), frame_map()->address_for_monitor_lock(monitor_no));\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":16,"deletions":11,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -313,3 +313,1 @@\n-  LIR_Opr lock = new_register(T_ADDRESS);\n-  LIR_Opr tmp1 = new_register(T_INT);\n-  LIR_Opr tmp2 = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_INT);\n@@ -324,1 +322,1 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), tmp1, tmp2,\n+  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n@@ -335,3 +333,2 @@\n-  LIR_Opr lock = new_register(T_ADDRESS);\n-  LIR_Opr obj_temp = new_register(T_ADDRESS);\n-  LIR_Opr tmp = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_INT);\n+  LIR_Opr obj_temp = new_register(T_INT);\n@@ -339,1 +336,1 @@\n-  monitor_exit(obj_temp, lock, syncTempOpr(), tmp, x->monitor_no());\n+  monitor_exit(obj_temp, lock, syncTempOpr(), LIR_OprFact::illegalOpr, x->monitor_no());\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":5,"deletions":8,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register tmp, Label& slow_case) {\n+int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n@@ -45,1 +45,2 @@\n-  assert_different_registers(hdr, obj, disp_hdr, tmp);\n+  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n+  Label done;\n@@ -50,0 +51,3 @@\n+  \/\/ save object being locked into the BasicObjectLock\n+  movptr(Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()), obj);\n+\n@@ -59,8 +63,1 @@\n-#ifdef _LP64\n-  const Register thread = r15_thread;\n-  const Register tmp2 = disp_hdr;\n-#else\n-  const Register thread = disp_hdr;\n-  get_thread(thread);\n-  const Register tmp2 = noreg;\n-#endif\n+  \/\/ Load object header\n@@ -68,1 +65,34 @@\n-  fast_lock_impl(obj, hdr, thread, tmp, tmp2, slow_case);\n+  \/\/ and mark it as unlocked\n+  orptr(hdr, markWord::unlocked_value);\n+  \/\/ save unlocked object header into the displaced header location on the stack\n+  movptr(Address(disp_hdr, 0), hdr);\n+  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n+  \/\/ displaced header address in the object header - if it is not the same, get the\n+  \/\/ object header instead\n+  MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n+  cmpxchgptr(disp_hdr, Address(obj, hdr_offset));\n+  \/\/ if the object header was the same, we're done\n+  jcc(Assembler::equal, done);\n+  \/\/ if the object header was not the same, it is now in the hdr register\n+  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n+  \/\/\n+  \/\/ 1) (hdr & aligned_mask) == 0\n+  \/\/ 2) rsp <= hdr\n+  \/\/ 3) hdr <= rsp + page_size\n+  \/\/\n+  \/\/ these 3 tests can be done by evaluating the following expression:\n+  \/\/\n+  \/\/ (hdr - rsp) & (aligned_mask - page_size)\n+  \/\/\n+  \/\/ assuming both the stack pointer and page_size have their least\n+  \/\/ significant 2 bits cleared and page_size is a power of 2\n+  subptr(hdr, rsp);\n+  andptr(hdr, aligned_mask - os::vm_page_size());\n+  \/\/ for recursive locking, the result is zero => save it in the displaced header\n+  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n+  movptr(Address(disp_hdr, 0), hdr);\n+  \/\/ otherwise we don't care about the result and handle locking via runtime call\n+  jcc(Assembler::notZero, slow_case);\n+  \/\/ done\n+  bind(done);\n+\n@@ -70,0 +100,1 @@\n+\n@@ -73,2 +104,2 @@\n-\n-void C1_MacroAssembler::unlock_object(Register disp_hdr, Register obj, Register hdr, Label& slow_case) {\n+void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n+  const int aligned_mask = BytesPerWord -1;\n@@ -78,0 +109,10 @@\n+  Label done;\n+\n+  \/\/ load displaced header\n+  movptr(hdr, Address(disp_hdr, 0));\n+  \/\/ if the loaded hdr is NULL we had recursive locking\n+  testptr(hdr, hdr);\n+  \/\/ if we had recursive locking, we are done\n+  jcc(Assembler::zero, done);\n+  \/\/ load object\n+  movptr(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n@@ -80,0 +121,10 @@\n+  \/\/ test if object header is pointing to the displaced header, and if so, restore\n+  \/\/ the displaced header in the object - if the object header is not pointing to\n+  \/\/ the displaced header, get the object header instead\n+  MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n+  cmpxchgptr(hdr, Address(obj, hdr_offset));\n+  \/\/ if the object header was not pointing to the displaced header,\n+  \/\/ we do unlocking via runtime call\n+  jcc(Assembler::notEqual, slow_case);\n+  \/\/ done\n+  bind(done);\n@@ -81,3 +132,0 @@\n-  movptr(disp_hdr, Address(obj, hdr_offset));\n-  andptr(disp_hdr, ~(int32_t)markWord::lock_mask_in_place);\n-  fast_unlock_impl(obj, disp_hdr, hdr, slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":64,"deletions":16,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-  int lock_object  (Register swap, Register obj, Register disp_hdr, Register tmp, Label& slow_case);\n+  int lock_object  (Register swap, Register obj, Register disp_hdr, Label& slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1306,1 +1306,1 @@\n-        OopMap* map = save_live_registers(sasm, 2, save_fpu_registers);\n+        OopMap* map = save_live_registers(sasm, 3, save_fpu_registers);\n@@ -1310,1 +1310,2 @@\n-        f.load_argument(0, rax); \/\/ rax,: object\n+        f.load_argument(1, rax); \/\/ rax,: object\n+        f.load_argument(0, rbx); \/\/ rbx,: lock address\n@@ -1312,1 +1313,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), rax);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), rax, rbx);\n@@ -1330,1 +1331,1 @@\n-        f.load_argument(0, rax); \/\/ rax: obj\n+        f.load_argument(0, rax); \/\/ rax,: lock address\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -414,0 +414,1 @@\n+  movptr(Address(boxReg, 0), checked_cast<int32_t>(markWord::unused_mark().value()));\n@@ -559,1 +560,1 @@\n-                                 Register scrReg, Register cx1Reg, Register cx2Reg, Register thread,\n+                                 Register scrReg, Register cx1Reg, Register cx2Reg,\n@@ -571,1 +572,1 @@\n-    assert_different_registers(objReg, boxReg, tmpReg, scrReg, cx1Reg);\n+    assert_different_registers(objReg, boxReg, tmpReg, scrReg);\n@@ -589,1 +590,1 @@\n-  Label IsInflated, DONE_LABEL, slow_path, NO_COUNT, COUNT;\n+  Label IsInflated, DONE_LABEL, NO_COUNT, COUNT;\n@@ -612,3 +613,17 @@\n-    fast_lock_impl(objReg, tmpReg, thread, scrReg, cx1Reg, slow_path);\n-    xorptr(rax, rax); \/\/ Set ZF = 1 (success)\n-    jmp(COUNT);\n+    \/\/ Attempt stack-locking ...\n+    orptr (tmpReg, markWord::unlocked_value);\n+    movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n+    lock();\n+    cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n+    jcc(Assembler::equal, COUNT);           \/\/ Success\n+\n+    \/\/ Recursive locking.\n+    \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n+    \/\/ Locked by current thread if difference with current SP is less than one page.\n+    subptr(tmpReg, rsp);\n+    \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n+    andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - os::vm_page_size())) );\n+    movptr(Address(boxReg, 0), tmpReg);\n+  } else {\n+    \/\/ Clear ZF so that we take the slow path at the DONE label. objReg is known to be not 0.\n+    testptr(objReg, objReg);\n@@ -616,3 +631,0 @@\n-  bind(slow_path);\n-  \/\/ Clear ZF so that we take the slow path at the DONE label. objReg is known to be not 0.\n-  testptr(objReg, objReg);\n@@ -658,2 +670,3 @@\n-  cmpxchgptr(thread, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-  \/\/ If we weren't able to swing _owner from NULL to the thread\n+  cmpxchgptr(scrReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  movptr(Address(scrReg, 0), 3);          \/\/ box->_displaced_header = 3\n+  \/\/ If we weren't able to swing _owner from NULL to the BasicLock\n@@ -662,0 +675,3 @@\n+  \/\/ update _owner from BasicLock to thread\n+  get_thread (scrReg);                    \/\/ beware: clobbers ICCs\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), scrReg);\n@@ -676,1 +692,4 @@\n-  cmpxchgptr(thread, Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  cmpxchgptr(r15_thread, Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  \/\/ Unconditionally set box->_displaced_header = markWord::unused_mark().\n+  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n+  movptr(Address(boxReg, 0), checked_cast<int32_t>(markWord::unused_mark().value()));\n@@ -680,1 +699,1 @@\n-  cmpptr(thread, rax);                     \/\/ Check if we are already the owner (recursive lock)\n+  cmpptr(r15_thread, rax);                \/\/ Check if we are already the owner (recursive lock)\n@@ -770,1 +789,0 @@\n-  movptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Examine the object's markword\n@@ -772,10 +790,7 @@\n-    testptr(boxReg, markWord::monitor_value);\n-    jcc(Assembler::zero, Stacked);\n-\n-    \/\/ If the owner is ANONYMOUS, we need to fix it - in the slow-path.\n-    Label L;\n-    cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t) (intptr_t) ANONYMOUS_OWNER);\n-    jccb(Assembler::notEqual, L);\n-    testptr(objReg, objReg); \/\/ Clear ZF to indicate failure at DONE_LABEL.\n-    jmp(DONE_LABEL);\n-    bind(L);\n+    cmpptr(Address(boxReg, 0), NULL_WORD);                            \/\/ Examine the displaced header\n+    jcc   (Assembler::zero, COUNT);                                   \/\/ 0 indicates recursive stack-lock\n+  }\n+  movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes()));   \/\/ Examine the object's markword\n+  if (!UseHeavyMonitors) {\n+    testptr(tmpReg, markWord::monitor_value);                         \/\/ Inflated?\n+    jccb   (Assembler::zero, Stacked);\n@@ -789,2 +804,2 @@\n-    movptr(tmpReg, Address(boxReg, owner_offset));\n-    testptr(tmpReg, tmpReg);\n+    movptr(boxReg, Address(tmpReg, owner_offset));\n+    testptr(boxReg, boxReg);\n@@ -793,1 +808,1 @@\n-    jmp(DONE_LABEL);\n+    jmpb(DONE_LABEL);\n@@ -817,0 +832,2 @@\n+  get_thread (boxReg);\n+\n@@ -821,5 +838,2 @@\n-  xorptr(tmpReg, tmpReg);\n-  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n-  jccb  (Assembler::notZero, DONE_LABEL);\n-  movptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n-  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+  xorptr(boxReg, boxReg);\n+  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n@@ -827,1 +841,4 @@\n-  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n+  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+  jccb  (Assembler::notZero, CheckSucc);\n+  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n@@ -829,0 +846,18 @@\n+\n+  bind (Stacked);\n+  \/\/ It's not inflated and it's not recursively stack-locked.\n+  \/\/ It must be stack-locked.\n+  \/\/ Try to reset the header to displaced header.\n+  \/\/ The \"box\" value on the stack is stable, so we can reload\n+  \/\/ and be assured we observe the same value as above.\n+  movptr(tmpReg, Address(boxReg, 0));\n+  lock();\n+  cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+  \/\/ Intention fall-thru into DONE_LABEL\n+\n+  \/\/ DONE_LABEL is a hot target - we'd really like to place it at the\n+  \/\/ start of cache line by padding with NOPs.\n+  \/\/ See the AMD and Intel software optimization manuals for the\n+  \/\/ most efficient \"long\" NOP encodings.\n+  \/\/ Unfortunately none of our alignment mechanisms suffice.\n+  bind (CheckSucc);\n@@ -833,1 +868,1 @@\n-  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n+  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n@@ -837,1 +872,1 @@\n-  decq(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  decq(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n@@ -841,2 +876,2 @@\n-  movptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n@@ -845,1 +880,1 @@\n-  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n+  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n@@ -855,1 +890,1 @@\n-  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n+  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), NULL_WORD);\n@@ -858,0 +893,1 @@\n+  xorptr(boxReg, boxReg);\n@@ -859,1 +895,1 @@\n-  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n+  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n@@ -870,1 +906,1 @@\n-  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n+  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), NULL_WORD);\n@@ -873,3 +909,0 @@\n-  mov(tmpReg, boxReg);\n-  xorptr(boxReg, boxReg);\n-\n@@ -906,1 +939,0 @@\n-#endif\n@@ -908,4 +940,4 @@\n-    bind(Stacked);\n-    \/\/ Mark-word must be 00 now, try to swing it back to 01 (unlocked)\n-    fast_unlock_impl(objReg, boxReg, tmpReg, DONE_LABEL);\n-    xorptr(rax, rax); \/\/ Set ZF = 1 (success)\n+    bind  (Stacked);\n+    movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n+    lock();\n+    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n@@ -913,0 +945,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":82,"deletions":49,"binary":false,"changes":131,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-                 Register scr, Register cx1, Register cx2, Register thread,\n+                 Register scr, Register cx1, Register cx2,\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1199,4 +1199,0 @@\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-  const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx); \/\/ Will contain the oop\n-  \/\/ Load object pointer into obj_reg\n-  movptr(obj_reg, Address(lock_reg, obj_offset));\n@@ -1206,1 +1202,1 @@\n-            obj_reg);\n+            lock_reg);\n@@ -1208,1 +1204,1 @@\n-    Label done, slow_case;\n+    Label count_locking, done, slow_case;\n@@ -1212,0 +1208,1 @@\n+    const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx); \/\/ Will contain the oop\n@@ -1214,0 +1211,8 @@\n+    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n+    const int mark_offset = lock_offset +\n+                            BasicLock::displaced_header_offset_in_bytes();\n+\n+    \/\/ Load object pointer into obj_reg\n+    movptr(obj_reg, Address(lock_reg, obj_offset));\n+\n@@ -1221,11 +1226,53 @@\n-#ifdef _LP64\n-    const Register thread = r15_thread;\n-    const Register tmp2 = rscratch1;\n-#else\n-    const Register thread = lock_reg;\n-    get_thread(thread);\n-    const Register tmp2 = noreg;\n-#endif\n-    \/\/ Load object header, prepare for CAS from unlocked to locked.\n-    movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    fast_lock_impl(obj_reg, swap_reg, thread, tmp_reg, tmp2, slow_case);\n+    \/\/ Load immediate 1 into swap_reg %rax\n+    movl(swap_reg, 1);\n+\n+    \/\/ Load (object->mark() | 1) into swap_reg %rax\n+    orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+    movptr(Address(lock_reg, mark_offset), swap_reg);\n+\n+    assert(lock_offset == 0,\n+           \"displaced header must be first word in BasicObjectLock\");\n+\n+    lock();\n+    cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    jcc(Assembler::zero, count_locking);\n+\n+    const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n+\n+    \/\/ Fast check for recursive lock.\n+    \/\/\n+    \/\/ Can apply the optimization only if this is a stack lock\n+    \/\/ allocated in this thread. For efficiency, we can focus on\n+    \/\/ recently allocated stack locks (instead of reading the stack\n+    \/\/ base and checking whether 'mark' points inside the current\n+    \/\/ thread stack):\n+    \/\/  1) (mark & zero_bits) == 0, and\n+    \/\/  2) rsp <= mark < mark + os::pagesize()\n+    \/\/\n+    \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n+    \/\/ neither apply the optimization for an inflated lock allocated\n+    \/\/ just above the thread stack (this is why condition 1 matters)\n+    \/\/ nor apply the optimization if the stack lock is inside the stack\n+    \/\/ of another thread. The latter is avoided even in case of overflow\n+    \/\/ because we have guard pages at the end of all stacks. Hence, if\n+    \/\/ we go over the stack base and hit the stack of another thread,\n+    \/\/ this should not be in a writeable area that could contain a\n+    \/\/ stack lock allocated by that thread. As a consequence, a stack\n+    \/\/ lock less than page size away from rsp is guaranteed to be\n+    \/\/ owned by the current thread.\n+    \/\/\n+    \/\/ These 3 tests can be done by evaluating the following\n+    \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n+    \/\/ assuming both stack pointer and pagesize have their\n+    \/\/ least significant bits clear.\n+    \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n+    subptr(swap_reg, rsp);\n+    andptr(swap_reg, zero_bits - os::vm_page_size());\n+\n+    \/\/ Save the test result, for recursive case, the result is zero\n+    movptr(Address(lock_reg, mark_offset), swap_reg);\n+    jcc(Assembler::notZero, slow_case);\n+\n+    bind(count_locking);\n@@ -1240,1 +1287,1 @@\n-            obj_reg);\n+            lock_reg);\n@@ -1263,7 +1310,0 @@\n-  const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx);  \/\/ Will contain the oop\n-  \/\/ Load oop into obj_reg(%c_rarg3)\n-  movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-  \/\/ Free entry\n-  movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL_WORD);\n-\n@@ -1271,1 +1311,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -1273,1 +1313,1 @@\n-    Label done, slow_case;\n+    Label count_locking, done, slow_case;\n@@ -1277,0 +1317,1 @@\n+    const Register obj_reg    = LP64_ONLY(c_rarg3) NOT_LP64(rcx);  \/\/ Will contain the oop\n@@ -1280,8 +1321,13 @@\n-#ifdef _LP64\n-    const Register thread = r15_thread;\n-#else\n-    const Register thread = header_reg;\n-    get_thread(thread);\n-#endif\n-    cmpptr(obj_reg, Address(thread, Thread::lock_stack_current_offset()));\n-    jcc(Assembler::notEqual, slow_case);\n+    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+    \/\/ structure Store the BasicLock address into %rax\n+    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+\n+    \/\/ Load oop into obj_reg(%c_rarg3)\n+    movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+    \/\/ Free entry\n+    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), NULL_WORD);\n+\n+    \/\/ Load the old header from BasicLock structure\n+    movptr(header_reg, Address(swap_reg,\n+                               BasicLock::displaced_header_offset_in_bytes()));\n@@ -1289,4 +1335,14 @@\n-    \/\/ Try to swing header from locked to unlock.\n-    movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n-    fast_unlock_impl(obj_reg, swap_reg, header_reg, slow_case);\n+    \/\/ Test for recursion\n+    testptr(header_reg, header_reg);\n+\n+    \/\/ zero for recursive case\n+    jcc(Assembler::zero, count_locking);\n+\n+    \/\/ Atomic swap back the old header\n+    lock();\n+    cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ zero for simple unlock of a stack-lock case\n+    jcc(Assembler::notZero, slow_case);\n+\n+    bind(count_locking);\n@@ -1298,2 +1354,2 @@\n-    bind(slow_case);\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n+    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), obj_reg); \/\/ restore obj\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":97,"deletions":41,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -9756,50 +9756,0 @@\n-\n-void MacroAssembler::fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp1, Register tmp2, Label& slow) {\n-  assert(hdr == rax, \"header must be in rax for cmpxchg\");\n-  assert_different_registers(obj, hdr, thread, tmp1, tmp2);\n-\n-  \/\/ First we need to check if the lock-stack has room for pushing the object reference.\n-  movptr(tmp1, Address(thread, Thread::lock_stack_current_offset()));\n-  cmpptr(tmp1, Address(thread, Thread::lock_stack_limit_offset()));\n-  jcc(Assembler::greaterEqual, slow);\n-\n-  Register locked_hdr = tmp2->is_valid() ? tmp2 : tmp1;\n-  \/\/ Now we attempt to take the fast-lock.\n-  \/\/ Clear lowest two header bits (locked state).\n-  andptr(hdr, ~(int32_t )markWord::lock_mask_in_place);\n-  movptr(locked_hdr, hdr);\n-  \/\/ Set lowest bit (unlocked state).\n-  orptr(hdr, markWord::unlocked_value);\n-  lock();\n-  cmpxchgptr(locked_hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-  jcc(Assembler::notEqual, slow);\n-\n-  \/\/ Success: push object to lock-stack.\n-  if (!tmp2->is_valid()) {\n-    \/\/ If we did not have a valid tmp2, we used tmp1 instead, and we must re-load the current offset.\n-    movptr(tmp1, Address(thread, Thread::lock_stack_current_offset()));\n-  }\n-  movptr(Address(tmp1, 0), obj);\n-  increment(tmp1, oopSize);\n-  movptr(Address(thread, Thread::lock_stack_current_offset()), tmp1);\n-}\n-\n-void MacroAssembler::fast_unlock_impl(Register obj, Register hdr, Register tmp, Label& slow) {\n-  assert(hdr == rax, \"header must be in rax for cmpxchg\");\n-  assert_different_registers(obj, hdr, tmp);\n-\n-  \/\/ Mark-word must be 00 now, try to swing it back to 01 (unlocked)\n-  movptr(tmp, hdr); \/\/ The expected old value\n-  orptr(tmp, markWord::unlocked_value);\n-  lock();\n-  cmpxchgptr(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n-  jcc(Assembler::notZero, slow);\n-  \/\/ Pop the lock object from the lock-stack.\n-#ifdef _LP64\n-  const Register thread = r15_thread;\n-#else\n-  const Register thread = rax;\n-  get_thread(rax);\n-#endif\n-  subptr(Address(thread, Thread::lock_stack_current_offset()), oopSize);\n-}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":0,"deletions":50,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -877,1 +877,0 @@\n-  void xorptr(Register dst, int32_t src) { LP64_ONLY(xorq(dst, src)) NOT_LP64(xorl(dst, src)); }\n@@ -2015,3 +2014,0 @@\n-  void fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp1, Register tmp2, Label& slow);\n-  void fast_unlock_impl(Register obj, Register hdr, Register tmp, Label& slow);\n-\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1330,0 +1330,1 @@\n+                                       in_ByteSize(-1),\n@@ -1384,0 +1385,1 @@\n+  int lock_slot_offset = 0;\n@@ -1396,0 +1398,1 @@\n+    lock_slot_offset = stack_slots;\n@@ -1410,0 +1413,2 @@\n+  \/\/      | lock box (if sync)  |\n+  \/\/      |---------------------| <- lock_slot_offset  (-lock_slot_rbp_offset)\n@@ -1515,0 +1520,4 @@\n+  \/\/ Compute the rbp, offset for any slots used after the jni call\n+\n+  int lock_slot_rbp_offset = (lock_slot_offset*VMRegImpl::stack_slot_size) - fp_adjustment;\n+\n@@ -1649,1 +1658,1 @@\n-  const Register tmp      = rdx;\n+  const Register lock_reg = rdx;  \/\/ Address of compiler lock object (BasicLock)\n@@ -1656,0 +1665,4 @@\n+    Label count_mon;\n+\n+    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n+\n@@ -1659,0 +1672,4 @@\n+    \/\/ Get address of the box\n+\n+    __ lea(lock_reg, Address(rbp, lock_slot_rbp_offset));\n+\n@@ -1663,3 +1680,30 @@\n-      \/\/ Load object header\n-      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_lock_impl(obj_reg, swap_reg, thread, tmp, noreg, slow_path_lock);\n+      \/\/ Load immediate 1 into swap_reg %rax,\n+      __ movptr(swap_reg, 1);\n+\n+      \/\/ Load (object->mark() | 1) into swap_reg %rax,\n+      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+\n+      \/\/ src -> dest iff dest == rax, else rax, <- dest\n+      \/\/ *obj_reg = lock_reg iff *obj_reg == rax, else rax, = *(obj_reg)\n+      __ lock();\n+      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::equal, count_mon);\n+\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) rsp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg %rax, as the result of cmpxchg\n+\n+      __ subptr(swap_reg, rsp);\n+      __ andptr(swap_reg, 3 - os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+      __ jcc(Assembler::notEqual, slow_path_lock);\n@@ -1669,0 +1713,1 @@\n+    __ bind(count_mon);\n@@ -1788,0 +1833,10 @@\n+    if (!UseHeavyMonitors) {\n+      Label not_recur;\n+      \/\/ Simple recursive lock?\n+      __ cmpptr(Address(rbp, lock_slot_rbp_offset), NULL_WORD);\n+      __ jcc(Assembler::notEqual, not_recur);\n+      __ dec_held_monitor_count();\n+      __ jmpb(fast_done);\n+      __ bind(not_recur);\n+    }\n+\n@@ -1794,3 +1849,12 @@\n-      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n-      __ fast_unlock_impl(obj_reg, swap_reg, tmp, slow_path_unlock);\n+      \/\/  get old displaced header\n+      __ movptr(rbx, Address(rbp, lock_slot_rbp_offset));\n+\n+      \/\/ get address of the stack lock\n+      __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n+\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      \/\/ src -> dest iff dest == rax, else rax, <- dest\n+      \/\/ *obj_reg = rbx, iff *obj_reg == rax, else rax, = *(obj_reg)\n+      __ lock();\n+      __ cmpxchgptr(rbx, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::notEqual, slow_path_unlock);\n@@ -1883,0 +1947,1 @@\n+    __ push(lock_reg);\n@@ -1885,1 +1950,1 @@\n-    __ addptr(rsp, 2*wordSize);\n+    __ addptr(rsp, 3*wordSize);\n@@ -1917,0 +1982,2 @@\n+    __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n+    __ push(rax);\n@@ -1920,1 +1987,1 @@\n-    __ addptr(rsp, 2*wordSize);\n+    __ addptr(rsp, 3*wordSize);\n@@ -1975,0 +2042,1 @@\n+                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":77,"deletions":9,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -1633,0 +1633,1 @@\n+                                              in_ByteSize(-1),\n@@ -1661,0 +1662,1 @@\n+                                       in_ByteSize(-1),\n@@ -1716,0 +1718,1 @@\n+  int lock_slot_offset = 0;\n@@ -1728,0 +1731,1 @@\n+    lock_slot_offset = stack_slots;\n@@ -1742,0 +1746,2 @@\n+  \/\/      | lock box (if sync)  |\n+  \/\/      |---------------------| <- lock_slot_offset\n@@ -2018,1 +2024,2 @@\n-  const Register tmp      = r13;\n+  const Register lock_reg = r13;  \/\/ Address of compiler lock object (BasicLock)\n+  const Register old_hdr  = r13;  \/\/ value of old header at unlock time\n@@ -2024,0 +2031,4 @@\n+    Label count_mon;\n+\n+    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n+\n@@ -2027,0 +2038,4 @@\n+    \/\/ Get address of the box\n+\n+    __ lea(lock_reg, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+\n@@ -2031,3 +2046,32 @@\n-      \/\/ Load object header\n-      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_lock_impl(obj_reg, swap_reg, r15_thread, tmp, rscratch1, slow_path_lock);\n+\n+      \/\/ Load immediate 1 into swap_reg %rax\n+      __ movl(swap_reg, 1);\n+\n+      \/\/ Load (object->mark() | 1) into swap_reg %rax\n+      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+\n+      \/\/ src -> dest iff dest == rax else rax <- dest\n+      __ lock();\n+      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::equal, count_mon);\n+\n+      \/\/ Hmm should this move to the slow path code area???\n+\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 3) == 0, and\n+      \/\/  2) rsp <= mark < mark + os::pagesize()\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 2 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n+\n+      __ subptr(swap_reg, rsp);\n+      __ andptr(swap_reg, 3 - os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+      __ jcc(Assembler::notEqual, slow_path_lock);\n@@ -2037,0 +2081,1 @@\n+    __ bind(count_mon);\n@@ -2146,0 +2191,10 @@\n+    if (!UseHeavyMonitors) {\n+      Label not_recur;\n+      \/\/ Simple recursive lock?\n+      __ cmpptr(Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size), NULL_WORD);\n+      __ jcc(Assembler::notEqual, not_recur);\n+      __ dec_held_monitor_count();\n+      __ jmpb(fast_done);\n+      __ bind(not_recur);\n+    }\n+\n@@ -2152,3 +2207,9 @@\n-      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n-      __ fast_unlock_impl(obj_reg, swap_reg, tmp, slow_path_unlock);\n+      \/\/ get address of the stack lock\n+      __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+      \/\/  get old displaced header\n+      __ movptr(old_hdr, Address(rax, 0));\n+\n+      \/\/ Atomic swap old header if oop still contains the stack lock\n+      __ lock();\n+      __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ jcc(Assembler::notEqual, slow_path_unlock);\n@@ -2229,1 +2290,2 @@\n-    __ mov(c_rarg1, r15_thread);\n+    __ mov(c_rarg1, lock_reg);\n+    __ mov(c_rarg2, r15_thread);\n@@ -2232,1 +2294,1 @@\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_locking_C), 2);\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_locking_C), 3);\n@@ -2257,0 +2319,2 @@\n+    __ lea(c_rarg1, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+\n@@ -2258,1 +2322,1 @@\n-    __ mov(c_rarg1, r15_thread);\n+    __ mov(c_rarg2, r15_thread);\n@@ -2319,0 +2383,1 @@\n+                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":75,"deletions":10,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -13803,1 +13803,1 @@\n-instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2, eRegP thread) %{\n+instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2) %{\n@@ -13805,2 +13805,2 @@\n-  match(Set cr (FastLock object));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, TEMP box, TEMP thread);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n@@ -13810,1 +13810,0 @@\n-    __ get_thread($thread$$Register);\n@@ -13812,1 +13811,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register, $thread$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n@@ -13820,1 +13819,1 @@\n-instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr, rRegI cx1, eRegP thread) %{\n+instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr) %{\n@@ -13822,2 +13821,2 @@\n-  match(Set cr (FastLock object));\n-  effect(TEMP tmp, TEMP scr, TEMP box, TEMP cx1, TEMP thread);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP scr, USE_KILL box);\n@@ -13827,1 +13826,0 @@\n-    __ get_thread($thread$$Register);\n@@ -13829,1 +13827,1 @@\n-                 $scr$$Register, $cx1$$Register, noreg, $thread$$Register, NULL, NULL, NULL, false, false);\n+                 $scr$$Register, noreg, noreg, NULL, NULL, NULL, false, false);\n@@ -13835,2 +13833,2 @@\n-  match(Set cr (FastUnlock object));\n-  effect(TEMP tmp, TEMP box);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp, USE_KILL box);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":10,"deletions":12,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -13294,2 +13294,2 @@\n-  match(Set cr (FastLock object));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, TEMP box);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n@@ -13300,1 +13300,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register, r15_thread,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n@@ -13308,1 +13308,1 @@\n-instruct cmpFastLock(rFlagsReg cr, rRegP object, rax_RegI tmp, rRegP scr, rRegP cx1) %{\n+instruct cmpFastLock(rFlagsReg cr, rRegP object, rbx_RegP box, rax_RegI tmp, rRegP scr, rRegP cx1) %{\n@@ -13310,2 +13310,2 @@\n-  match(Set cr (FastLock object));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, USE_KILL box);\n@@ -13313,1 +13313,1 @@\n-  format %{ \"fastlock $object\\t! kills $tmp,$scr\" %}\n+  format %{ \"fastlock $object,$box\\t! kills $box,$tmp,$scr\" %}\n@@ -13315,2 +13315,2 @@\n-    __ fast_lock($object$$Register, noreg, $tmp$$Register,\n-                 $scr$$Register, $cx1$$Register, noreg, r15_thread, NULL, NULL, NULL, false, false);\n+    __ fast_lock($object$$Register, $box$$Register, $tmp$$Register,\n+                 $scr$$Register, $cx1$$Register, noreg, NULL, NULL, NULL, false, false);\n@@ -13322,2 +13322,2 @@\n-  match(Set cr (FastUnlock object));\n-  effect(TEMP tmp, TEMP box);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp, USE_KILL box);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -397,0 +397,2 @@\n+    else if (offset ==  BasicObjectLock::lock_offset_in_bytes())\n+      snprintf(fieldbuf, buflen, \"monitor[%d]->_lock\", index);\n","filename":"src\/hotspot\/cpu\/zero\/frame_zero.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -334,4 +334,18 @@\n-\n-    CALL_VM_NOCHECK(InterpreterRuntime::monitorenter(thread, lockee));\n-    if (HAS_PENDING_EXCEPTION)\n-      goto unwind_and_return;\n+    markWord disp = lockee->mark().set_unlocked();\n+    monitor->lock()->set_displaced_header(disp);\n+    bool call_vm = UseHeavyMonitors;\n+    bool inc_monitor_count = true;\n+    if (call_vm || lockee->cas_set_mark(markWord::from_pointer(monitor), disp) != disp) {\n+      \/\/ Is it simple recursive case?\n+      if (!call_vm && thread->is_lock_owned((address) disp.clear_lock_bits().to_pointer())) {\n+        monitor->lock()->set_displaced_header(markWord::from_pointer(NULL));\n+      } else {\n+        inc_monitor_count = false;\n+        CALL_VM_NOCHECK(InterpreterRuntime::monitorenter(thread, monitor));\n+        if (HAS_PENDING_EXCEPTION)\n+          goto unwind_and_return;\n+      }\n+    }\n+    if (inc_monitor_count) {\n+      THREAD->inc_held_monitor_count();\n+    }\n@@ -468,0 +482,2 @@\n+    BasicLock *lock = monitor->lock();\n+    markWord header = lock->displaced_header();\n@@ -470,1 +486,13 @@\n-    InterpreterRuntime::monitorexit(rcvr);\n+\n+    bool dec_monitor_count = true;\n+    if (header.to_pointer() != NULL) {\n+      markWord old_header = markWord::encode(lock);\n+      if (rcvr->cas_set_mark(header, old_header) != old_header) {\n+        monitor->set_obj(rcvr);\n+        dec_monitor_count = false;\n+        InterpreterRuntime::monitorexit(monitor);\n+      }\n+    }\n+    if (dec_monitor_count) {\n+      THREAD->dec_held_monitor_count();\n+    }\n","filename":"src\/hotspot\/cpu\/zero\/zeroInterpreter_zero.cpp","additions":33,"deletions":5,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -319,0 +319,1 @@\n+  LIR_Opr _lock_reg;\n@@ -321,1 +322,1 @@\n-  MonitorAccessStub(LIR_Opr obj_reg) {\n+  MonitorAccessStub(LIR_Opr obj_reg, LIR_Opr lock_reg) {\n@@ -323,0 +324,1 @@\n+    _lock_reg  = lock_reg;\n@@ -336,1 +338,1 @@\n-  MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info);\n+  MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info);\n@@ -342,1 +344,1 @@\n-    visitor->do_temp(_obj_reg);\n+    visitor->do_input(_lock_reg);\n@@ -352,0 +354,4 @@\n+ private:\n+  bool _compute_lock;\n+  int  _monitor_ix;\n+\n@@ -353,2 +359,3 @@\n-  MonitorExitStub(LIR_Opr obj_reg)\n-    : MonitorAccessStub(obj_reg) { }\n+  MonitorExitStub(LIR_Opr lock_reg, bool compute_lock, int monitor_ix)\n+    : MonitorAccessStub(LIR_OprFact::illegalOpr, lock_reg),\n+      _compute_lock(compute_lock), _monitor_ix(monitor_ix) { }\n@@ -357,2 +364,6 @@\n-    visitor->do_input(_obj_reg);\n-    visitor->do_temp(_obj_reg);\n+    assert(_obj_reg->is_illegal(), \"unused\");\n+    if (_compute_lock) {\n+      visitor->do_temp(_lock_reg);\n+    } else {\n+      visitor->do_input(_lock_reg);\n+    }\n","filename":"src\/hotspot\/share\/c1\/c1_CodeStubs.hpp","additions":18,"deletions":7,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -286,0 +286,5 @@\n+ByteSize FrameMap::sp_offset_for_monitor_lock(int index) const {\n+  check_monitor_index(index);\n+  return sp_offset_for_monitor_base(index) + in_ByteSize(BasicObjectLock::lock_offset_in_bytes());;\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+  ByteSize sp_offset_for_monitor_lock(int monitor_index) const;\n@@ -208,0 +209,3 @@\n+  Address address_for_monitor_lock(int monitor_index) const {\n+    return make_new_address(sp_offset_for_monitor_lock(monitor_index));\n+  }\n@@ -219,0 +223,3 @@\n+  bool location_for_monitor_lock  (int monitor_index, Location* loc) const {\n+    return location_for_sp_offset(sp_offset_for_monitor_lock(monitor_index), Location::normal, loc);\n+  }\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -798,1 +798,1 @@\n-      assert(opLock->_obj->is_valid(),  \"used\");  do_input(opLock->_obj); do_temp(opLock->_obj);\n+      assert(opLock->_obj->is_valid(),  \"used\");  do_temp(opLock->_obj);\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -609,1 +609,1 @@\n-void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr tmp1, LIR_Opr tmp2, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n+void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n@@ -612,1 +612,1 @@\n-  CodeStub* slow_path = new MonitorEnterStub(object, info);\n+  CodeStub* slow_path = new MonitorEnterStub(object, lock, info);\n@@ -614,1 +614,0 @@\n-  __ move(object, new LIR_Address(lock, BasicObjectLock::obj_offset_in_bytes(), T_ADDRESS));\n@@ -616,1 +615,1 @@\n-  __ lock_object(hdr, object, tmp1, tmp2, slow_path, info_for_exception);\n+  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception);\n@@ -623,1 +622,3 @@\n-  CodeStub* slow_path = new MonitorExitStub(object);\n+  LIR_Opr hdr = lock;\n+  lock = new_hdr;\n+  CodeStub* slow_path = new MonitorExitStub(lock, !UseHeavyMonitors, monitor_no);\n@@ -625,2 +626,1 @@\n-  __ move(new LIR_Address(lock, BasicObjectLock::obj_offset_in_bytes(),T_ADDRESS), object);\n-  __ unlock_object(new_hdr, object, lock, scratch, slow_path);\n+  __ unlock_object(hdr, object, lock, scratch, slow_path);\n@@ -2677,1 +2677,3 @@\n-      LIR_Opr lock = new_register(T_ADDRESS);\n+      LIR_Opr lock = syncLockOpr();\n+      __ load_stack_address_monitor(0, lock);\n+\n@@ -2679,1 +2681,4 @@\n-      monitor_enter(obj, lock, syncTempOpr(), new_register(T_INT), new_register(T_INT), 0, NULL, info);\n+      CodeStub* slow_path = new MonitorEnterStub(obj, lock, info);\n+\n+      \/\/ receiver is guaranteed non-NULL so don't need CodeEmitInfo\n+      __ lock_object(syncTempOpr(), obj, lock, new_register(T_OBJECT), slow_path, NULL);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":14,"deletions":9,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -365,1 +365,1 @@\n-  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr tmp1, LIR_Opr tmp2, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info);\n+  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2535,0 +2535,3 @@\n+  if (!frame_map()->location_for_monitor_lock(monitor_index, &loc)) {\n+    bailout(\"too large frame\");\n+  }\n","filename":"src\/hotspot\/share\/c1\/c1_LinearScan.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -752,1 +752,1 @@\n-JRT_BLOCK_ENTRY(void, Runtime1::monitorenter(JavaThread* current, oopDesc* obj))\n+JRT_BLOCK_ENTRY(void, Runtime1::monitorenter(JavaThread* current, oopDesc* obj, BasicObjectLock* lock))\n@@ -758,1 +758,5 @@\n-  SharedRuntime::monitor_enter_helper(obj, current);\n+  if (UseHeavyMonitors) {\n+    lock->set_obj(obj);\n+  }\n+  assert(obj == lock->obj(), \"must match\");\n+  SharedRuntime::monitor_enter_helper(obj, lock->lock(), current);\n@@ -762,1 +766,1 @@\n-JRT_LEAF(void, Runtime1::monitorexit(JavaThread* current, oopDesc* obj))\n+JRT_LEAF(void, Runtime1::monitorexit(JavaThread* current, BasicObjectLock* lock))\n@@ -769,2 +773,3 @@\n-  assert(oopDesc::is_oop(oop(obj)), \"must be NULL or an object: \" PTR_FORMAT, p2i(obj));\n-  SharedRuntime::monitor_exit_helper(obj, current);\n+  oop obj = lock->obj();\n+  assert(oopDesc::is_oop(obj), \"must be NULL or an object\");\n+  SharedRuntime::monitor_exit_helper(obj, lock->lock(), current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":10,"deletions":5,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -156,2 +156,2 @@\n-  static void monitorenter(JavaThread* current, oopDesc* obj);\n-  static void monitorexit (JavaThread* current, oopDesc* obj);\n+  static void monitorenter(JavaThread* current, oopDesc* obj, BasicObjectLock* lock);\n+  static void monitorexit (JavaThread* current, BasicObjectLock* lock);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -461,0 +461,1 @@\n+  ByteSize basic_lock_sp_offset,\n@@ -481,0 +482,1 @@\n+            basic_lock_sp_offset,\n@@ -603,0 +605,1 @@\n+  ByteSize basic_lock_sp_offset,\n@@ -607,0 +610,1 @@\n+  _native_basic_lock_sp_offset(basic_lock_sp_offset),\n@@ -741,0 +745,1 @@\n+  _native_basic_lock_sp_offset(in_ByteSize(-1)),\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -239,1 +239,1 @@\n-  \/\/ locate the owner for the lock. They are\n+  \/\/ locate the owner and stack slot for the BasicLock. They are\n@@ -247,0 +247,1 @@\n+  ByteSize _native_basic_lock_sp_offset;\n@@ -271,0 +272,1 @@\n+          ByteSize basic_lock_sp_offset,       \/* synchronized natives only *\/\n@@ -350,0 +352,1 @@\n+      _native_basic_lock_sp_offset(in_ByteSize(-1)),\n@@ -360,0 +363,1 @@\n+                                     ByteSize basic_lock_sp_offset,\n@@ -686,0 +690,3 @@\n+  ByteSize native_basic_lock_sp_offset() {\n+    return _native_basic_lock_sp_offset;\n+  }\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -707,1 +707,1 @@\n-      \/\/ shenandoah_assert_correct(p, obj);\n+      shenandoah_assert_correct(p, obj);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -81,1 +81,2 @@\n-  markWord old_mark = obj->mark_acquire();\n+  markWord old_mark = ObjectSynchronizer::read_stable_mark(obj);\n+  assert(!old_mark.is_being_inflated(), \"must not see INFLATING marker here\");\n@@ -87,0 +88,4 @@\n+  \/\/ Ensure that the copy has the correct mark-word, in case it happened to copy with\n+  \/\/ INFLATING marker.\n+  update->set_mark(old_mark);\n+\n@@ -88,6 +93,12 @@\n-  markWord prev_mark = obj->cas_set_mark(new_mark, old_mark, memory_order_conservative);\n-  if (prev_mark == old_mark) {\n-    return update;\n-  } else {\n-    assert(prev_mark.is_marked(), \"must be forwarded\");\n-    return cast_to_oop(prev_mark.clear_lock_bits().to_pointer());\n+  while (true) {\n+    markWord prev_mark = obj->cas_set_mark(new_mark, old_mark, memory_order_conservative);\n+    if (prev_mark == old_mark) {\n+      return update;\n+    } else if (prev_mark == markWord::INFLATING()) {\n+      \/\/ This happens when we encounter a stack-locked object in from-space.\n+      \/\/ Busy-wait for completion.\n+      SpinPause();\n+    } else {\n+      assert(prev_mark.is_marked(), \"must be forwarded\");\n+      return cast_to_oop(prev_mark.clear_lock_bits().to_pointer());\n+    }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahForwarding.inline.hpp","additions":18,"deletions":7,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -41,1 +41,4 @@\n-  markWord mark = obj->mark_acquire();\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  for (;;) {\n+    assert(heap->is_in(obj), \"object not in heap: \" PTR_FORMAT, p2i(obj));\n+    markWord mark = obj->mark_acquire();\n@@ -43,6 +46,9 @@\n-  if (mark.is_neutral() || mark.is_fast_locked()) {\n-    return mark;\n-  } else if (mark.is_marked()) {\n-    \/\/ If object is already forwarded, then resolve it, and try again.\n-    if (ShenandoahHeap::heap()->is_full_gc_move_in_progress()) {\n-      \/\/ In these cases, we want to return the header as-is: the Klass* would not be overloaded.\n+    \/\/ The mark can be in one of the following states:\n+    \/\/ *  Inflated     - just return mark from inflated monitor\n+    \/\/ *  Stack-locked - coerce it to inflating, and then return displaced mark\n+    \/\/ *  INFLATING    - busy wait for conversion to complete\n+    \/\/ *  Neutral      - return mark\n+    \/\/ *  Marked       - object is forwarded, try again on forwardee\n+\n+    \/\/ Most common case first.\n+    if (mark.is_neutral()) {\n@@ -51,7 +57,65 @@\n-    return stable_mark(cast_to_oop(mark.decode_pointer()));\n-  } else {\n-    assert(mark.has_monitor(), \"must be inflated here\");\n-    ObjectMonitor* monitor = mark.monitor();\n-    markWord dmw = monitor->header();\n-    assert(dmw.is_neutral(), \"invariant\");\n-    return dmw;\n+\n+    \/\/ If object is already forwarded, then resolve it, and try again.\n+    if (mark.is_marked()) {\n+      if (heap->is_full_gc_move_in_progress()) {\n+        \/\/ In these cases, we want to return the header as-is: the Klass* would not be overloaded.\n+        return mark;\n+      }\n+      obj = cast_to_oop(mark.decode_pointer());\n+      continue;\n+    }\n+\n+    \/\/ CASE: inflated\n+    if (mark.has_monitor()) {\n+      \/\/ It is safe to access the object monitor because all Java and GC worker threads\n+      \/\/ participate in the monitor deflation protocol (i.e, they react to handshakes and STS requests).\n+      ObjectMonitor* inf = mark.monitor();\n+      markWord dmw = inf->header();\n+      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(), mark.value());\n+      return dmw;\n+    }\n+\n+    \/\/ CASE: inflating\n+    if (mark.is_being_inflated()) {\n+      \/\/ Interference, try again.\n+      continue;\n+    }\n+\n+    \/\/ CASE: stack-locked\n+    if (mark.has_locker()) {\n+      if (Thread::current()->is_lock_owned((address)mark.locker())) {\n+        \/\/ This thread owns the lock. We can safely access it.\n+        markWord dmw = mark.displaced_mark_helper();\n+        assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(), mark.value());\n+        return dmw;\n+      }\n+\n+      \/\/ Else we try to install INFLATING into the header. This will (temporarily) prevent other\n+      \/\/ threads from stack-locking or evacuating the object.\n+      markWord cmp = obj->cas_set_mark(markWord::INFLATING(), mark);\n+      if (cmp != mark) {\n+        continue;       \/\/ Interference -- just retry\n+      }\n+\n+      \/\/ We've successfully installed INFLATING (0) into the mark-word.\n+      \/\/ This is the only case where 0 will appear in a mark-word.\n+      \/\/ Only the singular thread that successfully swings the mark-word\n+      \/\/ to 0 can fetch the stack-lock and safely read the displaced header.\n+\n+      \/\/ fetch the displaced mark from the owner's stack.\n+      \/\/ The owner can't die or unwind past the lock while our INFLATING\n+      \/\/ object is in the mark.  Furthermore the owner can't complete\n+      \/\/ an unlock on the object, either. No other thread can do evacuation, either.\n+      markWord dmw = mark.displaced_mark_helper();\n+      \/\/ Catch if the object's header is not neutral (not locked and\n+      \/\/ not marked is what we care about here).\n+      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n+\n+      \/\/ Must preserve store ordering. The monitor state must\n+      \/\/ be stable at the time of publishing the monitor address.\n+      guarantee(obj->mark() == markWord::INFLATING(), \"invariant\");\n+      \/\/ Release semantics so that above set_object() is seen first.\n+      obj->release_set_mark(mark);\n+\n+      return dmw;\n+    }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahObjectUtils.inline.hpp","additions":78,"deletions":14,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -49,4 +49,4 @@\n-    markWord mark = obj->mark();\n-    \/\/ Fetch displaced header from monitor\n-    if (mark.has_displaced_mark_helper()) {\n-      mark = mark.displaced_mark_helper();\n+    const markWord mark = obj->mark();\n+    \/\/ Having\/had displaced header, too risk to deal with them, skip\n+    if (mark == markWord::INFLATING() || mark.has_displaced_mark_helper()) {\n+      return false;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahStringDedup.inline.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -730,2 +730,5 @@\n-JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* current, oopDesc* obj))\n-  Handle h_obj(current, obj);\n+JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* current, BasicObjectLock* elem))\n+#ifdef ASSERT\n+  current->last_frame().interpreter_frame_verify_monitor(elem);\n+#endif\n+  Handle h_obj(current, elem->obj());\n@@ -734,2 +737,2 @@\n-  ObjectSynchronizer::enter(h_obj, current);\n-  assert(Universe::heap()->is_in_or_null(h_obj()),\n+  ObjectSynchronizer::enter(h_obj, elem->lock(), current);\n+  assert(Universe::heap()->is_in_or_null(elem->obj()),\n@@ -737,0 +740,3 @@\n+#ifdef ASSERT\n+  current->last_frame().interpreter_frame_verify_monitor(elem);\n+#endif\n@@ -740,2 +746,2 @@\n-JRT_LEAF(void, InterpreterRuntime::monitorexit(oopDesc* o))\n-  oop obj = oop(o);\n+JRT_LEAF(void, InterpreterRuntime::monitorexit(BasicObjectLock* elem))\n+  oop obj = elem->obj();\n@@ -751,1 +757,4 @@\n-  ObjectSynchronizer::exit(obj, JavaThread::current());\n+  ObjectSynchronizer::exit(obj, elem->lock(), JavaThread::current());\n+  \/\/ Free entry. If it is not cleared, the exception handling code will try to unlock the monitor\n+  \/\/ again at method exit or in the case of an exception.\n+  elem->set_obj(NULL);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":16,"deletions":7,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -108,2 +108,2 @@\n-  static void    monitorenter(JavaThread* current, oopDesc* obj);\n-  static void    monitorexit (oopDesc* obj);\n+  static void    monitorenter(JavaThread* current, BasicObjectLock* elem);\n+  static void    monitorexit (BasicObjectLock* elem);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -627,1 +627,16 @@\n-        CALL_VM(InterpreterRuntime::monitorenter(THREAD, rcvr), handle_exception);\n+        markWord displaced = rcvr->mark().set_unlocked();\n+        mon->lock()->set_displaced_header(displaced);\n+        bool call_vm = UseHeavyMonitors;\n+        bool inc_monitor_count = true;\n+        if (call_vm || rcvr->cas_set_mark(markWord::from_pointer(mon), displaced) != displaced) {\n+          \/\/ Is it simple recursive case?\n+          if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n+            mon->lock()->set_displaced_header(markWord::from_pointer(NULL));\n+          } else {\n+            inc_monitor_count = false;\n+            CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);\n+          }\n+        }\n+        if (inc_monitor_count) {\n+          THREAD->inc_held_monitor_count();\n+        }\n@@ -711,1 +726,16 @@\n-      CALL_VM(InterpreterRuntime::monitorenter(THREAD, lockee), handle_exception);\n+      markWord displaced = lockee->mark().set_unlocked();\n+      entry->lock()->set_displaced_header(displaced);\n+      bool call_vm = UseHeavyMonitors;\n+      bool inc_monitor_count = true;\n+      if (call_vm || lockee->cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {\n+        \/\/ Is it simple recursive case?\n+        if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n+          entry->lock()->set_displaced_header(markWord::from_pointer(NULL));\n+        } else {\n+          inc_monitor_count = false;\n+          CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);\n+        }\n+      }\n+      if (inc_monitor_count) {\n+        THREAD->inc_held_monitor_count();\n+      }\n@@ -1626,1 +1656,16 @@\n-          CALL_VM(InterpreterRuntime::monitorenter(THREAD, lockee), handle_exception);\n+          markWord displaced = lockee->mark().set_unlocked();\n+          entry->lock()->set_displaced_header(displaced);\n+          bool call_vm = UseHeavyMonitors;\n+          bool inc_monitor_count = true;\n+          if (call_vm || lockee->cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {\n+            \/\/ Is it simple recursive case?\n+            if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n+              entry->lock()->set_displaced_header(markWord::from_pointer(NULL));\n+            } else {\n+              inc_monitor_count = false;\n+              CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);\n+            }\n+          }\n+          if (inc_monitor_count) {\n+            THREAD->inc_held_monitor_count();\n+          }\n@@ -1643,0 +1688,2 @@\n+            BasicLock* lock = most_recent->lock();\n+            markWord header = lock->displaced_header();\n@@ -1644,1 +1691,16 @@\n-            InterpreterRuntime::monitorexit(lockee);\n+\n+            \/\/ If it isn't recursive we either must swap old header or call the runtime\n+            bool dec_monitor_count = true;\n+            bool call_vm = UseHeavyMonitors;\n+            if (header.to_pointer() != NULL || call_vm) {\n+              markWord old_header = markWord::encode(lock);\n+              if (call_vm || lockee->cas_set_mark(header, old_header) != old_header) {\n+                \/\/ restore object for the slow case\n+                most_recent->set_obj(lockee);\n+                dec_monitor_count = false;\n+                InterpreterRuntime::monitorexit(most_recent);\n+              }\n+            }\n+            if (dec_monitor_count) {\n+              THREAD->dec_held_monitor_count();\n+            }\n@@ -3076,0 +3138,2 @@\n+          BasicLock* lock = end->lock();\n+          markWord header = lock->displaced_header();\n@@ -3077,1 +3141,15 @@\n-          InterpreterRuntime::monitorexit(lockee);\n+\n+          \/\/ If it isn't recursive we either must swap old header or call the runtime\n+          bool dec_monitor_count = true;\n+          if (header.to_pointer() != NULL) {\n+            markWord old_header = markWord::encode(lock);\n+            if (lockee->cas_set_mark(header, old_header) != old_header) {\n+              \/\/ restore object for the slow case\n+              end->set_obj(lockee);\n+              dec_monitor_count = false;\n+              InterpreterRuntime::monitorexit(end);\n+            }\n+          }\n+          if (dec_monitor_count) {\n+            THREAD->dec_held_monitor_count();\n+          }\n@@ -3124,2 +3202,2 @@\n-          } else {\n-            InterpreterRuntime::monitorexit(rcvr);\n+          } else if (UseHeavyMonitors) {\n+            InterpreterRuntime::monitorexit(base);\n@@ -3130,0 +3208,23 @@\n+          } else {\n+            BasicLock* lock = base->lock();\n+            markWord header = lock->displaced_header();\n+            base->set_obj(NULL);\n+\n+            \/\/ If it isn't recursive we either must swap old header or call the runtime\n+            bool dec_monitor_count = true;\n+            if (header.to_pointer() != NULL) {\n+              markWord old_header = markWord::encode(lock);\n+              if (rcvr->cas_set_mark(header, old_header) != old_header) {\n+                \/\/ restore object for the slow case\n+                base->set_obj(rcvr);\n+                dec_monitor_count = false;\n+                InterpreterRuntime::monitorexit(base);\n+                if (THREAD->has_pending_exception()) {\n+                  if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD->pending_exception());\n+                  THREAD->clear_pending_exception();\n+                }\n+              }\n+            }\n+            if (dec_monitor_count) {\n+              THREAD->dec_held_monitor_count();\n+            }\n","filename":"src\/hotspot\/share\/interpreter\/zero\/bytecodeInterpreter.cpp","additions":108,"deletions":7,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -81,0 +81,1 @@\n+    static int sizeof_BasicLock;\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+int CompilerToVM::Data::sizeof_BasicLock = sizeof(BasicLock);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVMInit.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -408,2 +408,2 @@\n-JRT_BLOCK_ENTRY(void, JVMCIRuntime::monitorenter(JavaThread* current, oopDesc* obj))\n-  SharedRuntime::monitor_enter_helper(obj, current);\n+JRT_BLOCK_ENTRY(void, JVMCIRuntime::monitorenter(JavaThread* current, oopDesc* obj, BasicLock* lock))\n+  SharedRuntime::monitor_enter_helper(obj, lock, current);\n@@ -412,1 +412,1 @@\n-JRT_LEAF(void, JVMCIRuntime::monitorexit(JavaThread* current, oopDesc* obj))\n+JRT_LEAF(void, JVMCIRuntime::monitorexit(JavaThread* current, oopDesc* obj, BasicLock* lock))\n@@ -415,1 +415,1 @@\n-  SharedRuntime::monitor_exit_helper(obj, current);\n+  SharedRuntime::monitor_exit_helper(obj, lock, current);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciRuntime.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -498,2 +498,2 @@\n-  static void monitorenter(JavaThread* current, oopDesc* obj);\n-  static void monitorexit (JavaThread* current, oopDesc* obj);\n+  static void monitorenter(JavaThread* current, oopDesc* obj, BasicLock* lock);\n+  static void monitorexit (JavaThread* current, oopDesc* obj, BasicLock* lock);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciRuntime.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -90,0 +90,1 @@\n+  static_field(CompilerToVM::Data,             sizeof_BasicLock,                       int)                                          \\\n@@ -114,0 +115,2 @@\n+  volatile_nonstatic_field(BasicLock,          _displaced_header,                      markWord)                                     \\\n+                                                                                                                                     \\\n@@ -367,0 +370,1 @@\n+  declare_toplevel_type(BasicLock)                                        \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -39,0 +39,4 @@\n+  if (has_locker()) {  \/\/ has a stack lock\n+    BasicLock* locker = this->locker();\n+    return locker->displaced_header();\n+  }\n@@ -52,0 +56,5 @@\n+  if (has_locker()) {  \/\/ has a stack lock\n+    BasicLock* locker = this->locker();\n+    locker->set_displaced_header(m);\n+    return;\n+  }\n","filename":"src\/hotspot\/share\/oops\/markWord.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-\/\/    [header          | 00]  locked             object is fast-locked\n+\/\/    [ptr             | 00]  locked             ptr points to real header on stack\n@@ -56,0 +56,7 @@\n+\/\/    [0 ............ 0| 00]  inflating          inflation in progress\n+\/\/\n+\/\/    We assume that stack\/thread pointers have the lowest two bits cleared.\n+\/\/\n+\/\/  - INFLATING() is a distinguished markword value of all zeros that is\n+\/\/    used when inflating an existing stack-lock into an ObjectMonitor.\n+\/\/    See below for is_being_inflated() and INFLATING().\n@@ -57,0 +64,1 @@\n+class BasicLock;\n@@ -153,0 +161,12 @@\n+  \/\/ Special temporary state of the markWord while being inflated.\n+  \/\/ Code that looks at mark outside a lock need to take this into account.\n+  bool is_being_inflated() const { return (value() == 0); }\n+\n+  \/\/ Distinguished markword value - used when inflating over\n+  \/\/ an existing stack-lock.  0 indicates the markword is \"BUSY\".\n+  \/\/ Lockword mutators that use a LD...CAS idiom should always\n+  \/\/ check for and avoid overwriting a 0 value installed by some\n+  \/\/ other thread.  (They should spin or block instead.  The 0 value\n+  \/\/ is transient and *should* be short-lived).\n+  static markWord INFLATING() { return zero(); }    \/\/ inflate-in-progress\n+\n@@ -164,4 +184,1 @@\n-  markWord set_fast_locked() const {\n-    return markWord(value() & ~lock_mask_in_place);\n-  }\n-  bool is_fast_locked() const {\n+  bool has_locker() const {\n@@ -170,0 +187,4 @@\n+  BasicLock* locker() const {\n+    assert(has_locker(), \"check\");\n+    return (BasicLock*) value();\n+  }\n@@ -179,1 +200,1 @@\n-    return has_monitor();\n+    return ((value() & unlocked_value) == 0);\n@@ -188,1 +209,10 @@\n-  \/\/ create the markWord to be stored into object header, it encodes monitor info\n+  \/\/ it is only used to be stored into BasicLock as the\n+  \/\/ indicator that the lock is using heavyweight monitor\n+  static markWord unused_mark() {\n+    return markWord(marked_value);\n+  }\n+  \/\/ the following two functions create the markWord to be\n+  \/\/ stored into object header, it encodes monitor info\n+  static markWord encode(BasicLock* lock) {\n+    return from_pointer(lock);\n+  }\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":37,"deletions":7,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -112,1 +112,15 @@\n-  return Universe::heap()->is_oop(obj);\n+  if (!Universe::heap()->is_oop(obj)) {\n+    return false;\n+  }\n+\n+  \/\/ Header verification: the mark is typically non-zero. If we're\n+  \/\/ at a safepoint, it must not be zero.\n+  \/\/ Outside of a safepoint, the header could be changing (for example,\n+  \/\/ another thread could be inflating a lock on this object).\n+  if (ignore_mark_word) {\n+    return true;\n+  }\n+  if (obj->mark().value() != 0) {\n+    return true;\n+  }\n+  return !SafepointSynchronize::is_at_safepoint();\n@@ -169,1 +183,1 @@\n-  assert(header.is_neutral() | header.is_fast_locked(), \"expect neutral or fast-locked header here\");\n+  assert(header.is_neutral(), \"expect neutral header here\");\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":16,"deletions":2,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -92,1 +92,0 @@\n-  virtual uint match_edge(uint idx) const { return idx < 2; \/* Don't match box *\/ }\n@@ -123,1 +122,0 @@\n-  virtual uint match_edge(uint idx) const { return idx < 2; \/* Don't match box *\/ }\n","filename":"src\/hotspot\/share\/opto\/locknode.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2169,1 +2169,1 @@\n-                                  obj, NULL, NULL);\n+                                  obj, box, NULL);\n@@ -2229,1 +2229,1 @@\n-                                  \"complete_monitor_unlocking_C\", slow_path, obj, thread, NULL);\n+                                  \"complete_monitor_unlocking_C\", slow_path, obj, box, thread);\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -225,1 +225,1 @@\n-  Node *monitors_addr = basic_plus_adr(osr_buf, osr_buf, (max_locals+mcnt-1)*wordSize);\n+  Node *monitors_addr = basic_plus_adr(osr_buf, osr_buf, (max_locals+mcnt*2-1)*wordSize);\n@@ -234,1 +234,6 @@\n-    Node *lock_object = fetch_interpreter_state(index, T_OBJECT, monitors_addr, osr_buf);\n+    Node *lock_object = fetch_interpreter_state(index*2, T_OBJECT, monitors_addr, osr_buf);\n+    \/\/ Try and copy the displaced header to the BoxNode\n+    Node *displaced_hdr = fetch_interpreter_state((index*2) + 1, T_ADDRESS, monitors_addr, osr_buf);\n+\n+\n+    store_to_memory(control(), box, displaced_hdr, T_ADDRESS, Compile::AliasIdxRaw, MemNode::unordered);\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -567,1 +567,1 @@\n-  const Type **fields = TypeTuple::fields(1);\n+  const Type **fields = TypeTuple::fields(2);\n@@ -569,1 +569,2 @@\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+1,fields);\n+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;   \/\/ Address of stack location for lock\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2,fields);\n@@ -583,1 +584,1 @@\n-  const Type **fields = TypeTuple::fields(2);\n+  const Type **fields = TypeTuple::fields(3);\n@@ -585,2 +586,3 @@\n-  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;    \/\/ Thread pointer (Self)\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;    \/\/ Address of stack location for lock - BasicLock\n+  fields[TypeFunc::Parms+2] = TypeRawPtr::BOTTOM;    \/\/ Thread pointer (Self)\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":7,"deletions":5,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1386,1 +1386,1 @@\n-  ObjectMonitor* mon = NULL;\n+  ObjectMonitor *mon = NULL;\n@@ -1393,11 +1393,43 @@\n-  owning_thread = Threads::owning_thread_from_object(tlh.list(), hobj(), &mon);\n-  if (owning_thread != NULL) {\n-    Handle th(current_thread, get_vthread_or_thread_oop(owning_thread));\n-    ret.owner = (jthread)jni_reference(calling_thread, th);\n-    \/\/ The recursions field of a monitor does not reflect recursions\n-    \/\/ as lightweight locks before inflating the monitor are not included.\n-    \/\/ We have to count the number of recursive monitor entries the hard way.\n-    \/\/ We pass a handle to survive any GCs along the way.\n-    ret.entry_count = count_locked_objects(owning_thread, hobj);\n-  }\n-  \/\/ implied else: entry_count == 0\n+  {\n+    address owner = NULL;\n+    {\n+      markWord mark = hobj()->mark();\n+\n+      if (!mark.has_monitor()) {\n+        \/\/ this object has a lightweight monitor\n+\n+        if (mark.has_locker()) {\n+          owner = (address)mark.locker(); \/\/ save the address of the Lock word\n+        }\n+        \/\/ implied else: no owner\n+      } else {\n+        \/\/ this object has a heavyweight monitor\n+        mon = mark.monitor();\n+\n+        \/\/ The owner field of a heavyweight monitor may be NULL for no\n+        \/\/ owner, a JavaThread * or it may still be the address of the\n+        \/\/ Lock word in a JavaThread's stack. A monitor can be inflated\n+        \/\/ by a non-owning JavaThread, but only the owning JavaThread\n+        \/\/ can change the owner field from the Lock word to the\n+        \/\/ JavaThread * and it may not have done that yet.\n+        owner = (address)mon->owner();\n+      }\n+    }\n+\n+    if (owner != NULL) {\n+      \/\/ This monitor is owned so we have to find the owning JavaThread.\n+      owning_thread = Threads::owning_thread_from_monitor_owner(tlh.list(), owner);\n+      assert(owning_thread != NULL, \"owning JavaThread must not be NULL\");\n+      Handle th(current_thread, get_vthread_or_thread_oop(owning_thread));\n+      ret.owner = (jthread)jni_reference(calling_thread, th);\n+    }\n+\n+    if (owning_thread != NULL) {  \/\/ monitor is owned\n+      \/\/ The recursions field of a monitor does not reflect recursions\n+      \/\/ as lightweight locks before inflating the monitor are not included.\n+      \/\/ We have to count the number of recursive monitor entries the hard way.\n+      \/\/ We pass a handle to survive any GCs along the way.\n+      ret.entry_count = count_locked_objects(owning_thread, hobj);\n+    }\n+    \/\/ implied else: entry_count == 0\n+  }\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnvBase.cpp","additions":44,"deletions":12,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -0,0 +1,84 @@\n+\/*\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"runtime\/basicLock.hpp\"\n+#include \"runtime\/synchronizer.hpp\"\n+\n+void BasicLock::print_on(outputStream* st, oop owner) const {\n+  st->print(\"monitor\");\n+  markWord mark_word = displaced_header();\n+  if (mark_word.value() != 0) {\n+    \/\/ Print monitor info if there's an owning oop and it refers to this BasicLock.\n+    bool print_monitor_info = (owner != NULL) && (owner->mark() == markWord::from_pointer((void*)this));\n+    mark_word.print_on(st, print_monitor_info);\n+  }\n+}\n+\n+void BasicLock::move_to(oop obj, BasicLock* dest) {\n+  \/\/ Check to see if we need to inflate the lock. This is only needed\n+  \/\/ if an object is locked using \"this\" lightweight monitor. In that\n+  \/\/ case, the displaced_header() is unlocked\/is_neutral, because the\n+  \/\/ displaced_header() contains the header for the originally unlocked\n+  \/\/ object. However the lock could have already been inflated. But it\n+  \/\/ does not matter, this inflation will just a no-op. For other cases,\n+  \/\/ the displaced header will be either 0x0 or 0x3, which are location\n+  \/\/ independent, therefore the BasicLock is free to move.\n+  \/\/\n+  \/\/ During OSR we may need to relocate a BasicLock (which contains a\n+  \/\/ displaced word) from a location in an interpreter frame to a\n+  \/\/ new location in a compiled frame.  \"this\" refers to the source\n+  \/\/ BasicLock in the interpreter frame.  \"dest\" refers to the destination\n+  \/\/ BasicLock in the new compiled frame.  We *always* inflate in move_to()\n+  \/\/ when the object is locked using \"this\" lightweight monitor.\n+  \/\/\n+  \/\/ The always-Inflate policy works properly, but it depends on the\n+  \/\/ inflated fast-path operations in fast_lock and fast_unlock to avoid\n+  \/\/ performance problems. See x86\/macroAssembler_x86.cpp: fast_lock()\n+  \/\/ and fast_unlock() for examples.\n+  \/\/\n+  \/\/ Note that there is a way to safely swing the object's markword from\n+  \/\/ one stack location to another.  This avoids inflation.  Obviously,\n+  \/\/ we need to ensure that both locations refer to the current thread's stack.\n+  \/\/ There are some subtle concurrency issues, however, and since the benefit is\n+  \/\/ is small (given the support for inflated fast-path locking in the fast_lock, etc)\n+  \/\/ we'll leave that optimization for another time.\n+\n+  if (displaced_header().is_neutral()) {\n+    \/\/ The object is locked and the resulting ObjectMonitor* will also be\n+    \/\/ locked so it can't be async deflated until ownership is dropped.\n+    ObjectSynchronizer::inflate_helper(obj);\n+    \/\/ WARNING: We cannot put a check here, because the inflation\n+    \/\/ will not update the displaced header. Once BasicLock is inflated,\n+    \/\/ no one should ever look at its content.\n+  } else {\n+    \/\/ Typically the displaced header will be 0 (recursive stack lock) or\n+    \/\/ unused_mark.  Naively we'd like to assert that the displaced mark\n+    \/\/ value is either 0, neutral, or 3.  But with the advent of the\n+    \/\/ store-before-CAS avoidance in fast_lock\/compiler_lock_object\n+    \/\/ we can find any flavor mark in the displaced mark.\n+  }\n+  dest->set_displaced_header(displaced_header());\n+}\n","filename":"src\/hotspot\/share\/runtime\/basicLock.cpp","additions":84,"deletions":0,"binary":false,"changes":84,"status":"added"},{"patch":"@@ -32,1 +32,23 @@\n-\/\/ A BasicObjectLock represents a locked object.\n+class BasicLock {\n+  friend class VMStructs;\n+  friend class JVMCIVMStructs;\n+ private:\n+  volatile markWord _displaced_header;\n+ public:\n+  markWord displaced_header() const {\n+    return Atomic::load(&_displaced_header);\n+  }\n+\n+  void set_displaced_header(markWord header) {\n+    Atomic::store(&_displaced_header, header);\n+  }\n+\n+  void print_on(outputStream* st, oop owner) const;\n+\n+  \/\/ move a basic lock (used during deoptimization\n+  void move_to(oop obj, BasicLock* dest);\n+\n+  static int displaced_header_offset_in_bytes()       { return offset_of(BasicLock, _displaced_header); }\n+};\n+\n+\/\/ A BasicObjectLock associates a specific Java object with a BasicLock.\n@@ -37,1 +59,3 @@\n-\/\/ after the end of the BasicObjectLock.\n+\/\/ after the end of the BasicObjectLock.  Also, in order to guarantee\n+\/\/ alignment of the embedded BasicLock objects on such machines, we\n+\/\/ put the embedded BasicLock at the beginning of the struct.\n@@ -42,0 +66,1 @@\n+  BasicLock _lock;                                    \/\/ the lock, must be double word aligned\n@@ -43,5 +68,0 @@\n-#if defined(AARCH64) || defined(RISCV64)\n-  \/\/ Stack needs to be 16-byte-aligned. Inserting a dummy field here is\n-  \/\/ the simplest way to achieve that.\n-  intptr_t _dummy;\n-#endif\n@@ -53,0 +73,1 @@\n+  BasicLock* lock()                                   { return &_lock; }\n@@ -62,0 +83,1 @@\n+  static int lock_offset_in_bytes()                   { return offset_of(BasicObjectLock, _lock); }\n","filename":"src\/hotspot\/share\/runtime\/basicLock.hpp","additions":29,"deletions":7,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -1513,7 +1513,17 @@\n-        if (exec_mode == Unpack_none && mark.has_monitor()) {\n-          \/\/ defer relocking if the deoptee thread is currently waiting for obj\n-          ObjectMonitor* waiting_monitor = deoptee_thread->current_waiting_monitor();\n-          if (waiting_monitor != NULL && waiting_monitor->object() == obj()) {\n-            assert(fr.is_deoptimized_frame(), \"frame must be scheduled for deoptimization\");\n-            JvmtiDeferredUpdates::inc_relock_count_after_wait(deoptee_thread);\n-            continue;\n+        if (exec_mode == Unpack_none) {\n+          if (mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n+            \/\/ With exec_mode == Unpack_none obj may be thread local and locked in\n+            \/\/ a callee frame. Make the lock in the callee a recursive lock and restore the displaced header.\n+            markWord dmw = mark.displaced_mark_helper();\n+            mark.locker()->set_displaced_header(markWord::encode((BasicLock*) NULL));\n+            obj->set_mark(dmw);\n+          }\n+          if (mark.has_monitor()) {\n+            \/\/ defer relocking if the deoptee thread is currently waiting for obj\n+            ObjectMonitor* waiting_monitor = deoptee_thread->current_waiting_monitor();\n+            if (waiting_monitor != NULL && waiting_monitor->object() == obj()) {\n+              assert(fr.is_deoptimized_frame(), \"frame must be scheduled for deoptimization\");\n+              mon_info->lock()->set_displaced_header(markWord::unused_mark());\n+              JvmtiDeferredUpdates::inc_relock_count_after_wait(deoptee_thread);\n+              continue;\n+            }\n@@ -1522,1 +1532,2 @@\n-        ObjectSynchronizer::enter(obj, deoptee_thread);\n+        BasicLock* lock = mon_info->lock();\n+        ObjectSynchronizer::enter(obj, lock, deoptee_thread);\n@@ -1597,1 +1608,1 @@\n-          ObjectSynchronizer::exit(src->obj(), thread);\n+          ObjectSynchronizer::exit(src->obj(), src->lock(), thread);\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":20,"deletions":9,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -576,0 +576,3 @@\n+    st->print(\" - lock   [\");\n+    current->lock()->print_on(st, current->obj());\n+    st->print_cr(\"]\");\n@@ -1084,0 +1087,9 @@\n+BasicLock* frame::get_native_monitor() {\n+  nmethod* nm = (nmethod*)_cb;\n+  assert(_cb != NULL && _cb->is_nmethod() && nm->method()->is_native(),\n+         \"Should not call this unless it's a native nmethod\");\n+  int byte_offset = in_bytes(nm->native_basic_lock_sp_offset());\n+  assert(byte_offset >= 0, \"should not see invalid offset\");\n+  return (BasicLock*) &sp()[byte_offset \/ wordSize];\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -340,1 +340,1 @@\n-  \/\/ Return the monitor owner for compiled synchronized\n+  \/\/ Return the monitor owner and BasicLock for compiled synchronized\n@@ -343,0 +343,1 @@\n+  BasicLock* get_native_monitor();\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -731,1 +731,1 @@\n-  product(intx, hashCode, 6, EXPERIMENTAL,                                  \\\n+  product(intx, hashCode, 5, EXPERIMENTAL,                                  \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -976,0 +976,34 @@\n+bool JavaThread::is_lock_owned(address adr) const {\n+  if (Thread::is_lock_owned(adr)) return true;\n+\n+  for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk->next()) {\n+    if (chunk->contains(adr)) return true;\n+  }\n+\n+  return false;\n+}\n+\n+bool JavaThread::is_lock_owned_current(address adr) const {\n+  address stack_end = _stack_base - _stack_size;\n+  const ContinuationEntry* ce = vthread_continuation();\n+  address stack_base = ce != nullptr ? (address)ce->entry_sp() : _stack_base;\n+  if (stack_base > adr && adr >= stack_end) {\n+    return true;\n+  }\n+\n+  for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk->next()) {\n+    if (chunk->contains(adr)) {\n+      return true;\n+    }\n+  }\n+\n+  return false;\n+}\n+\n+bool JavaThread::is_lock_owned_carrier(address adr) const {\n+  assert(is_vthread_mounted(), \"\");\n+  address stack_end = _stack_base - _stack_size;\n+  address stack_base = (address)vthread_continuation()->entry_sp();\n+  return stack_base > adr && adr >= stack_end;\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":34,"deletions":0,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -665,0 +665,5 @@\n+  \/\/ Fast-locking support\n+  bool is_lock_owned(address adr) const;\n+  bool is_lock_owned_current(address adr) const; \/\/ virtual if mounted, otherwise whole thread\n+  bool is_lock_owned_carrier(address adr) const;\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1,71 +0,0 @@\n-\/*\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"memory\/allocation.hpp\"\n-#include \"runtime\/lockStack.hpp\"\n-#include \"runtime\/safepoint.hpp\"\n-#include \"runtime\/thread.hpp\"\n-#include \"utilities\/copy.hpp\"\n-#include \"utilities\/ostream.hpp\"\n-\n-LockStack::LockStack() :\n-        _base(UseHeavyMonitors ? NULL : NEW_C_HEAP_ARRAY(oop, INITIAL_CAPACITY, mtSynchronizer)),\n-        _limit(_base + INITIAL_CAPACITY),\n-        _current(_base) {\n-}\n-\n-LockStack::~LockStack() {\n-  if (!UseHeavyMonitors) {\n-    FREE_C_HEAP_ARRAY(oop, _base);\n-  }\n-}\n-\n-#ifndef PRODUCT\n-void LockStack::validate(const char* msg) const {\n-  assert(!UseHeavyMonitors, \"never use lock-stack when fast-locking is disabled\");\n-  for (oop* loc1 = _base; loc1 < _current - 1; loc1++) {\n-    for (oop* loc2 = loc1 + 1; loc2 < _current; loc2++) {\n-      assert(*loc1 != *loc2, \"entries must be unique: %s\", msg);\n-    }\n-  }\n-}\n-#endif\n-\n-void LockStack::grow() {\n-  \/\/ Grow stack.\n-  assert(_limit > _base, \"invariant\");\n-  size_t capacity = _limit - _base;\n-  size_t index = _current - _base;\n-  size_t new_capacity = capacity * 2;\n-  oop* new_stack = NEW_C_HEAP_ARRAY(oop, new_capacity, mtSynchronizer);\n-  for (size_t i = 0; i < index; i++) {\n-    *(new_stack + i) = *(_base + i);\n-  }\n-  FREE_C_HEAP_ARRAY(oop, _base);\n-  _base = new_stack;\n-  _limit = _base + new_capacity;\n-  _current = _base + index;\n-  assert(_current < _limit, \"must fit after growing\");\n-}\n","filename":"src\/hotspot\/share\/runtime\/lockStack.cpp","additions":0,"deletions":71,"binary":false,"changes":71,"status":"deleted"},{"patch":"@@ -1,64 +0,0 @@\n-\/*\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_RUNTIME_LOCKSTACK_HPP\n-#define SHARE_RUNTIME_LOCKSTACK_HPP\n-\n-#include \"oops\/oopsHierarchy.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/sizes.hpp\"\n-\n-class Thread;\n-class OopClosure;\n-\n-class LockStack {\n-  friend class VMStructs;\n-private:\n-  static const size_t INITIAL_CAPACITY = 4;\n-  oop* _base;\n-  oop* _limit;\n-  oop* _current;\n-\n-  void grow();\n-  void validate(const char* msg) const PRODUCT_RETURN;\n-public:\n-  static ByteSize current_offset()    { return byte_offset_of(LockStack, _current); }\n-  static ByteSize base_offset()       { return byte_offset_of(LockStack, _base); }\n-  static ByteSize limit_offset()      { return byte_offset_of(LockStack, _limit); }\n-\n-  LockStack();\n-  ~LockStack();\n-\n-  inline void push(oop o);\n-  inline oop pop();\n-  inline void remove(oop o);\n-\n-  inline bool contains(oop o) const;\n-\n-  \/\/ GC support\n-  inline void oops_do(OopClosure* cl);\n-\n-};\n-\n-#endif \/\/ SHARE_RUNTIME_LOCKSTACK_HPP\n","filename":"src\/hotspot\/share\/runtime\/lockStack.hpp","additions":0,"deletions":64,"binary":false,"changes":64,"status":"deleted"},{"patch":"@@ -1,92 +0,0 @@\n-\/*\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n-#define SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n-\n-#include \"memory\/iterator.hpp\"\n-#include \"runtime\/lockStack.hpp\"\n-\n-inline void LockStack::push(oop o) {\n-  validate(\"pre-push\");\n-  assert(!contains(o), \"entries must be unique\");\n-  if (_current >= _limit) {\n-    grow();\n-  }\n-  *_current = o;\n-  _current++;\n-  validate(\"post-push\");\n-}\n-\n-inline oop LockStack::pop() {\n-  validate(\"pre-pop\");\n-  oop* new_loc = _current - 1;\n-  assert(new_loc < _current, \"underflow, probably unbalanced push\/pop\");\n-  _current = new_loc;\n-  oop o = *_current;\n-  assert(!contains(o), \"entries must be unique\");\n-  validate(\"post-pop\");\n-  return o;\n-}\n-\n-inline void LockStack::remove(oop o) {\n-  validate(\"pre-remove\");\n-  assert(contains(o), \"entry must be present\");\n-  for (oop* loc = _base; loc < _current; loc++) {\n-    if (*loc == o) {\n-      oop* last = _current - 1;\n-      for (; loc < last; loc++) {\n-        *loc = *(loc + 1);\n-      }\n-      _current--;\n-      break;\n-    }\n-  }\n-  assert(!contains(o), \"entries must be unique: \" PTR_FORMAT, p2i(o));\n-  validate(\"post-remove\");\n-}\n-\n-inline bool LockStack::contains(oop o) const {\n-  validate(\"pre-contains\");\n-  bool found = false;\n-  size_t i = 0;\n-  size_t found_i = 0;\n-  for (oop* loc = _current - 1; loc >= _base; loc--) {\n-    if (*loc == o) {\n-      return true;\n-    }\n-  }\n-  validate(\"post-contains\");\n-  return false;\n-}\n-\n-inline void LockStack::oops_do(OopClosure* cl) {\n-  validate(\"pre-oops-do\");\n-  for (oop* loc = _base; loc < _current; loc++) {\n-    cl->do_oop(loc);\n-  }\n-  validate(\"post-oops-do\");\n-}\n-\n-#endif \/\/ SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n","filename":"src\/hotspot\/share\/runtime\/lockStack.inline.hpp","additions":0,"deletions":92,"binary":false,"changes":92,"status":"deleted"},{"patch":"@@ -337,1 +337,6 @@\n-  assert(cur == ANONYMOUS_OWNER || !current->is_lock_owned((address)cur), \"precondition\");\n+  if (current->is_lock_owned((address)cur)) {\n+    assert(_recursions == 0, \"internal state error\");\n+    _recursions = 1;\n+    set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n+    return true;\n+  }\n@@ -1149,10 +1154,14 @@\n-    assert(!current->is_lock_owned((address)cur), \"no stack-locking\");\n-    \/\/ Apparent unbalanced locking ...\n-    \/\/ Naively we'd like to throw IllegalMonitorStateException.\n-    \/\/ As a practical matter we can neither allocate nor throw an\n-    \/\/ exception as ::exit() can be called from leaf routines.\n-    \/\/ see x86_32.ad Fast_Unlock() and the I1 and I2 properties.\n-    \/\/ Upon deeper reflection, however, in a properly run JVM the only\n-    \/\/ way we should encounter this situation is in the presence of\n-    \/\/ unbalanced JNI locking. TODO: CheckJNICalls.\n-    \/\/ See also: CR4414101\n+    if (current->is_lock_owned((address)cur)) {\n+      assert(_recursions == 0, \"invariant\");\n+      set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n+      _recursions = 0;\n+    } else {\n+      \/\/ Apparent unbalanced locking ...\n+      \/\/ Naively we'd like to throw IllegalMonitorStateException.\n+      \/\/ As a practical matter we can neither allocate nor throw an\n+      \/\/ exception as ::exit() can be called from leaf routines.\n+      \/\/ see x86_32.ad Fast_Unlock() and the I1 and I2 properties.\n+      \/\/ Upon deeper reflection, however, in a properly run JVM the only\n+      \/\/ way we should encounter this situation is in the presence of\n+      \/\/ unbalanced JNI locking. TODO: CheckJNICalls.\n+      \/\/ See also: CR4414101\n@@ -1160,6 +1169,6 @@\n-    LogStreamHandle(Error, monitorinflation) lsh;\n-    lsh.print_cr(\"ERROR: ObjectMonitor::exit(): thread=\" INTPTR_FORMAT\n-                  \" is exiting an ObjectMonitor it does not own.\", p2i(current));\n-    lsh.print_cr(\"The imbalance is possibly caused by JNI locking.\");\n-    print_debug_style_on(&lsh);\n-    assert(false, \"Non-balanced monitor enter\/exit! \" PTR_FORMAT, p2i(object()));\n+      LogStreamHandle(Error, monitorinflation) lsh;\n+      lsh.print_cr(\"ERROR: ObjectMonitor::exit(): thread=\" INTPTR_FORMAT\n+                    \" is exiting an ObjectMonitor it does not own.\", p2i(current));\n+      lsh.print_cr(\"The imbalance is possibly caused by JNI locking.\");\n+      print_debug_style_on(&lsh);\n+      assert(false, \"Non-balanced monitor enter\/exit!\");\n@@ -1167,1 +1176,2 @@\n-    return;\n+      return;\n+    }\n@@ -1364,1 +1374,5 @@\n-    assert(!current->is_lock_owned((address)cur), \"no stack-locking\");\n+    if (current->is_lock_owned((address)cur)) {\n+      assert(_recursions == 0, \"internal state error\");\n+      set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n+      _recursions = 0;\n+    }\n@@ -1409,1 +1423,0 @@\n-  assert(cur != ANONYMOUS_OWNER, \"no anon owner here\");\n@@ -1413,0 +1426,5 @@\n+  if (current->is_lock_owned((address)cur)) {\n+    set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n+    _recursions = 0;\n+    return true;\n+  }\n@@ -2014,0 +2032,6 @@\n+\/\/ Beware too, that _owner is sometimes a BasicLock address and sometimes\n+\/\/ a thread pointer.\n+\/\/ Alternately, we might tag the type (thread pointer vs basiclock pointer)\n+\/\/ with the LSB of _owner.  Another option would be to probabilistically probe\n+\/\/ the putative _owner->TypeTag value.\n+\/\/\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":44,"deletions":20,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-\/\/ JavaMonitor. The lightweight fast-lock version has been\n+\/\/ JavaMonitor. The lightweight BasicLock\/stack lock version has been\n@@ -149,2 +149,1 @@\n-  #define ANONYMOUS_OWNER reinterpret_cast<void*>(1)\n-  void* volatile _owner;            \/\/ pointer to owning thread\n+  void* volatile _owner;            \/\/ pointer to owning thread OR BasicLock\n@@ -260,0 +259,2 @@\n+  \/\/ Simply set _owner field to current; current value must match basic_lock_p.\n+  void      set_owner_from_BasicLock(void* basic_lock_p, JavaThread* current);\n@@ -278,12 +279,0 @@\n-  void set_owner_anonymous() {\n-    set_owner_from(NULL, ANONYMOUS_OWNER);\n-  }\n-\n-  bool is_owner_anonymous() const {\n-    return _owner == ANONYMOUS_OWNER;\n-  }\n-\n-  void set_owner_from_anonymous(Thread* owner) {\n-    set_owner_from(ANONYMOUS_OWNER, owner);\n-  }\n-\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":4,"deletions":15,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -119,0 +119,16 @@\n+\/\/ Simply set _owner field to self; current value must match basic_lock_p.\n+inline void ObjectMonitor::set_owner_from_BasicLock(void* basic_lock_p, JavaThread* current) {\n+#ifdef ASSERT\n+  void* prev = Atomic::load(&_owner);\n+  assert(prev == basic_lock_p, \"unexpected prev owner=\" INTPTR_FORMAT\n+         \", expected=\" INTPTR_FORMAT, p2i(prev), p2i(basic_lock_p));\n+#endif\n+  \/\/ Non-null owner field to non-null owner field is safe without\n+  \/\/ cmpxchg() as long as all readers can tolerate either flavor.\n+  Atomic::store(&_owner, current);\n+  log_trace(monitorinflation, owner)(\"set_owner_from_BasicLock(): mid=\"\n+                                     INTPTR_FORMAT \", basic_lock_p=\"\n+                                     INTPTR_FORMAT \", new_value=\" INTPTR_FORMAT,\n+                                     p2i(this), p2i(basic_lock_p), p2i(current));\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.inline.hpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2191,1 +2191,1 @@\n-void SharedRuntime::monitor_enter_helper(oopDesc* obj, JavaThread* current) {\n+void SharedRuntime::monitor_enter_helper(oopDesc* obj, BasicLock* lock, JavaThread* current) {\n@@ -2195,1 +2195,1 @@\n-    if (ObjectSynchronizer::quick_enter(obj, current)) {\n+    if (ObjectSynchronizer::quick_enter(obj, current, lock)) {\n@@ -2205,1 +2205,1 @@\n-  ObjectSynchronizer::enter(h_obj, current);\n+  ObjectSynchronizer::enter(h_obj, lock, current);\n@@ -2211,2 +2211,2 @@\n-JRT_BLOCK_ENTRY(void, SharedRuntime::complete_monitor_locking_C(oopDesc* obj, JavaThread* current))\n-  SharedRuntime::monitor_enter_helper(obj, current);\n+JRT_BLOCK_ENTRY(void, SharedRuntime::complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* current))\n+  SharedRuntime::monitor_enter_helper(obj, lock, current);\n@@ -2215,1 +2215,1 @@\n-void SharedRuntime::monitor_exit_helper(oopDesc* obj, JavaThread* current) {\n+void SharedRuntime::monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current) {\n@@ -2227,1 +2227,1 @@\n-  ObjectSynchronizer::exit(obj, current);\n+  ObjectSynchronizer::exit(obj, lock, current);\n@@ -2231,2 +2231,2 @@\n-JRT_LEAF(void, SharedRuntime::complete_monitor_unlocking_C(oopDesc* obj, JavaThread* current))\n-  SharedRuntime::monitor_exit_helper(obj, current);\n+JRT_LEAF(void, SharedRuntime::complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* current))\n+  SharedRuntime::monitor_exit_helper(obj, lock, current);\n@@ -3229,0 +3229,11 @@\n+      BasicLock *lock = kptr2->lock();\n+      \/\/ Inflate so the object's header no longer refers to the BasicLock.\n+      if (lock->displaced_header().is_unlocked()) {\n+        \/\/ The object is locked and the resulting ObjectMonitor* will also be\n+        \/\/ locked so it can't be async deflated until ownership is dropped.\n+        \/\/ See the big comment in basicLock.cpp: BasicLock::move_to().\n+        ObjectSynchronizer::inflate_helper(kptr2->obj());\n+      }\n+      \/\/ Now the displaced header is free to move because the\n+      \/\/ object's header no longer refers to it.\n+      buf[i++] = (intptr_t)lock->displaced_header().value();\n@@ -3232,1 +3243,1 @@\n-  assert(i - max_locals == active_monitor_count, \"found the expected number of monitors\");\n+  assert(i - max_locals == active_monitor_count*2, \"found the expected number of monitors\");\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":21,"deletions":10,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -346,1 +346,1 @@\n-  static void monitor_enter_helper(oopDesc* obj, JavaThread* thread);\n+  static void monitor_enter_helper(oopDesc* obj, BasicLock* lock, JavaThread* thread);\n@@ -348,1 +348,1 @@\n-  static void monitor_exit_helper(oopDesc* obj, JavaThread* current);\n+  static void monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current);\n@@ -494,2 +494,2 @@\n-  static void complete_monitor_locking_C(oopDesc* obj, JavaThread* current);\n-  static void complete_monitor_unlocking_C(oopDesc* obj, JavaThread* current);\n+  static void complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* current);\n+  static void complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* current);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -250,0 +250,15 @@\n+BasicLock* StackValue::resolve_monitor_lock(const frame* fr, Location location) {\n+  assert(location.is_stack(), \"for now we only look at the stack\");\n+  int word_offset = location.stack_offset() \/ wordSize;\n+  \/\/ (stack picture)\n+  \/\/ high: [     ]  word_offset + 1\n+  \/\/ low   [     ]  word_offset\n+  \/\/\n+  \/\/ sp->  [     ]  0\n+  \/\/ the word_offset is the distance from the stack pointer to the lowest address\n+  \/\/ The frame's original stack pointer, before any extension by its callee\n+  \/\/ (due to Compiler1 linkage on SPARC), must be used.\n+  return (BasicLock*) (fr->unextended_sp() + word_offset);\n+}\n+\n+\n","filename":"src\/hotspot\/share\/runtime\/stackValue.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+class BasicLock;\n@@ -110,0 +111,2 @@\n+  static BasicLock*  resolve_monitor_lock(const frame* fr, Location location);\n+\n","filename":"src\/hotspot\/share\/runtime\/stackValue.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -43,1 +43,0 @@\n-#include \"runtime\/lockStack.inline.hpp\"\n@@ -316,1 +315,1 @@\n-  if (mark.is_fast_locked() && current->lock_stack().contains(oop(obj))) {\n+  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n@@ -357,1 +356,2 @@\n-bool ObjectSynchronizer::quick_enter(oop obj, JavaThread* current) {\n+bool ObjectSynchronizer::quick_enter(oop obj, JavaThread* current,\n+                                     BasicLock * lock) {\n@@ -389,0 +389,11 @@\n+    \/\/ This Java Monitor is inflated so obj's header will never be\n+    \/\/ displaced to this thread's BasicLock. Make the displaced header\n+    \/\/ non-NULL so this BasicLock is not seen as recursive nor as\n+    \/\/ being locked. We do this unconditionally so that this thread's\n+    \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n+    \/\/ performance reasons, stack walkers generally first check for\n+    \/\/ stack-locking in the object's header, the second check is for\n+    \/\/ recursive stack-locking in the displaced header in the BasicLock,\n+    \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n+    lock->set_displaced_header(markWord::unused_mark());\n+\n@@ -468,1 +479,1 @@\n-void ObjectSynchronizer::enter(Handle obj, JavaThread* current) {\n+void ObjectSynchronizer::enter(Handle obj, BasicLock* lock, JavaThread* current) {\n@@ -476,19 +487,7 @@\n-    LockStack& lock_stack = current->lock_stack();\n-\n-    markWord header = obj()->mark_acquire();\n-    while (true) {\n-      if (header.is_neutral()) {\n-        assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n-        \/\/ Try to swing into 'fast-locked' state without inflating.\n-        markWord locked_header = header.set_fast_locked();\n-        markWord witness = obj()->cas_set_mark(locked_header, header);\n-        if (witness == header) {\n-          \/\/ Successfully fast-locked, push object to lock-stack and return.\n-          lock_stack.push(obj());\n-          return;\n-        }\n-        \/\/ Otherwise retry.\n-        header = witness;\n-      } else {\n-        \/\/ Fall-through to inflate-enter.\n-        break;\n+    markWord mark = obj->mark();\n+    if (mark.is_neutral()) {\n+      \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n+      \/\/ be visible <= the ST performed by the CAS.\n+      lock->set_displaced_header(mark);\n+      if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+        return;\n@@ -496,0 +495,7 @@\n+      \/\/ Fall through to inflate() ...\n+    } else if (mark.has_locker() &&\n+               current->is_lock_owned((address)mark.locker())) {\n+      assert(lock != mark.locker(), \"must not re-lock the same lock\");\n+      assert(lock != (BasicLock*)obj->mark().value(), \"don't relock with same BasicLock\");\n+      lock->set_displaced_header(markWord::from_pointer(NULL));\n+      return;\n@@ -497,0 +503,6 @@\n+\n+    \/\/ The object header will never be displaced to this lock,\n+    \/\/ so it does not matter what the value is, except that it\n+    \/\/ must be non-zero to avoid looking like a re-entrant lock,\n+    \/\/ and must not look locked either.\n+    lock->set_displaced_header(markWord::unused_mark());\n@@ -498,1 +510,1 @@\n-    guarantee(!obj->mark().is_fast_locked(), \"must not be stack-locked\");\n+    guarantee(!obj->mark().has_locker(), \"must not be stack-locked\");\n@@ -512,1 +524,1 @@\n-void ObjectSynchronizer::exit(oop object, JavaThread* current) {\n+void ObjectSynchronizer::exit(oop object, BasicLock* lock, JavaThread* current) {\n@@ -514,12 +526,32 @@\n-  markWord header = object->mark_acquire();\n-  if (!useHeavyMonitors() && header.is_fast_locked()) {\n-    markWord unlocked_header = header.set_unlocked();\n-    markWord witness = object->cas_set_mark(unlocked_header, header);\n-    if (witness != header) {\n-      \/\/ Another thread beat us, it can only have installed an anonymously locked monitor at this point.\n-      \/\/ Fetch that monitor, set owner correctly to this thread, and exit it (allowing waiting threads to enter).\n-      assert(witness.has_monitor(), \"must have monitor\");\n-      ObjectMonitor* monitor = witness.monitor();\n-      assert(monitor->is_owner_anonymous(), \"must be anonymous owner\");\n-      monitor->set_owner_from_anonymous(current);\n-      monitor->exit(current);\n+\n+  if (!useHeavyMonitors()) {\n+    markWord mark = object->mark();\n+\n+    markWord dhw = lock->displaced_header();\n+    if (dhw.value() == 0) {\n+      \/\/ If the displaced header is NULL, then this exit matches up with\n+      \/\/ a recursive enter. No real work to do here except for diagnostics.\n+#ifndef PRODUCT\n+      if (mark != markWord::INFLATING()) {\n+        \/\/ Only do diagnostics if we are not racing an inflation. Simply\n+        \/\/ exiting a recursive enter of a Java Monitor that is being\n+        \/\/ inflated is safe; see the has_monitor() comment below.\n+        assert(!mark.is_neutral(), \"invariant\");\n+        assert(!mark.has_locker() ||\n+        current->is_lock_owned((address)mark.locker()), \"invariant\");\n+        if (mark.has_monitor()) {\n+          \/\/ The BasicLock's displaced_header is marked as a recursive\n+          \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n+          \/\/ This is a special case where the Java Monitor was inflated\n+          \/\/ after this thread entered the stack-lock recursively. When a\n+          \/\/ Java Monitor is inflated, we cannot safely walk the Java\n+          \/\/ Monitor owner's stack and update the BasicLocks because a\n+          \/\/ Java Monitor can be asynchronously inflated by a thread that\n+          \/\/ does not own the Java Monitor.\n+          ObjectMonitor* m = mark.monitor();\n+          assert(m->object()->mark() == mark, \"invariant\");\n+          assert(m->is_entered(current), \"invariant\");\n+        }\n+      }\n+#endif\n+      return;\n@@ -527,4 +559,0 @@\n-    LockStack& lock_stack = current->lock_stack();\n-    lock_stack.remove(object);\n-    return;\n-  }\n@@ -532,9 +560,10 @@\n-  assert(header.has_monitor(), \"must have monitor\");\n-  log_trace(monitorinflation)(\"monitor unlocking object: \" PTR_FORMAT, p2i(object));\n-  ObjectMonitor* monitor = header.monitor();\n-  if (!useHeavyMonitors() && monitor->is_owner_anonymous()) {\n-    \/\/ It must be us. Pop lock object from lock stack.\n-    LockStack& lock_stack = current->lock_stack();\n-    oop popped = lock_stack.pop();\n-    assert(popped == object, \"must be owned by this thread\");\n-    monitor->set_owner_from_anonymous(current);\n+    if (mark == markWord::from_pointer(lock)) {\n+      \/\/ If the object is stack-locked by the current thread, try to\n+      \/\/ swing the displaced header from the BasicLock back to the mark.\n+      assert(dhw.is_neutral(), \"invariant\");\n+      if (object->cas_set_mark(dhw, mark) == mark) {\n+        return;\n+      }\n+    }\n+  } else if (VerifyHeavyMonitors) {\n+    guarantee(!object->mark().has_locker(), \"must not be stack-locked\");\n@@ -542,0 +571,5 @@\n+\n+  \/\/ We have to take the slow-path of possible inflation and then exit.\n+  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n+  \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n+  ObjectMonitor* monitor = inflate(current, object, inflate_cause_vm_internal);\n@@ -629,1 +663,1 @@\n-    ObjectSynchronizer::enter(_obj, _thread);\n+    ObjectSynchronizer::enter(_obj, &_lock, _thread);\n@@ -635,1 +669,1 @@\n-    ObjectSynchronizer::exit(_obj(), _thread);\n+    ObjectSynchronizer::exit(_obj(), &_lock, _thread);\n@@ -678,1 +712,1 @@\n-  if (mark.is_fast_locked() && current->lock_stack().contains(obj())) {\n+  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n@@ -693,1 +727,1 @@\n-  if (mark.is_fast_locked() && current->lock_stack().contains(obj())) {\n+  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n@@ -719,0 +753,65 @@\n+markWord ObjectSynchronizer::read_stable_mark(oop obj) {\n+  markWord mark = obj->mark_acquire();\n+  if (!mark.is_being_inflated()) {\n+    return mark;       \/\/ normal fast-path return\n+  }\n+\n+  int its = 0;\n+  for (;;) {\n+    markWord mark = obj->mark_acquire();\n+    if (!mark.is_being_inflated()) {\n+      return mark;    \/\/ normal fast-path return\n+    }\n+\n+    \/\/ The object is being inflated by some other thread.\n+    \/\/ The caller of read_stable_mark() must wait for inflation to complete.\n+    \/\/ Avoid live-lock.\n+\n+    ++its;\n+    if (its > 10000 || !os::is_MP()) {\n+      if (its & 1) {\n+        os::naked_yield();\n+      } else {\n+        \/\/ Note that the following code attenuates the livelock problem but is not\n+        \/\/ a complete remedy.  A more complete solution would require that the inflating\n+        \/\/ thread hold the associated inflation lock.  The following code simply restricts\n+        \/\/ the number of spinners to at most one.  We'll have N-2 threads blocked\n+        \/\/ on the inflationlock, 1 thread holding the inflation lock and using\n+        \/\/ a yield\/park strategy, and 1 thread in the midst of inflation.\n+        \/\/ A more refined approach would be to change the encoding of INFLATING\n+        \/\/ to allow encapsulation of a native thread pointer.  Threads waiting for\n+        \/\/ inflation to complete would use CAS to push themselves onto a singly linked\n+        \/\/ list rooted at the markword.  Once enqueued, they'd loop, checking a per-thread flag\n+        \/\/ and calling park().  When inflation was complete the thread that accomplished inflation\n+        \/\/ would detach the list and set the markword to inflated with a single CAS and\n+        \/\/ then for each thread on the list, set the flag and unpark() the thread.\n+\n+        \/\/ Index into the lock array based on the current object address.\n+        static_assert(is_power_of_2(NINFLATIONLOCKS), \"must be\");\n+        int ix = (cast_from_oop<intptr_t>(obj) >> 5) & (NINFLATIONLOCKS-1);\n+        int YieldThenBlock = 0;\n+        assert(ix >= 0 && ix < NINFLATIONLOCKS, \"invariant\");\n+        gInflationLocks[ix]->lock();\n+        while (obj->mark_acquire() == markWord::INFLATING()) {\n+          \/\/ Beware: naked_yield() is advisory and has almost no effect on some platforms\n+          \/\/ so we periodically call current->_ParkEvent->park(1).\n+          \/\/ We use a mixed spin\/yield\/block mechanism.\n+          if ((YieldThenBlock++) >= 16) {\n+            Thread::current()->_ParkEvent->park(1);\n+          } else {\n+            os::naked_yield();\n+          }\n+        }\n+        gInflationLocks[ix]->unlock();\n+      }\n+    } else {\n+      SpinPause();       \/\/ SMP-polite spinning\n+    }\n+  }\n+}\n+\n+\/\/ Safely load a mark word from an object, even with racing stack-locking or monitor inflation.\n+\/\/ The protocol is a partial inflation-protocol: it installs INFLATING into the object's mark\n+\/\/ word in order to prevent an stack-locks or inflations from interferring (or detect such\n+\/\/ interference and retry), but then, instead of creating and installing a monitor, simply\n+\/\/ read and return the real mark word.\n@@ -720,6 +819,58 @@\n-  const markWord mark = object->mark_acquire();\n-  if (mark.has_monitor()) {\n-    ObjectMonitor* inf = mark.monitor();\n-    markWord dmw = inf->header();\n-    assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-    return dmw;\n+  for (;;) {\n+    const markWord mark = read_stable_mark(object);\n+    assert(!mark.is_being_inflated(), \"read_stable_mark must prevent inflating mark\");\n+\n+    \/\/ The mark can be in one of the following states:\n+    \/\/ *  Inflated     - just return mark from inflated monitor\n+    \/\/ *  Stack-locked - coerce it to inflating, and then return displaced mark\n+    \/\/ *  Neutral      - return mark\n+    \/\/ *  Marked       - return mark\n+\n+    \/\/ CASE: inflated\n+    if (mark.has_monitor()) {\n+      ObjectMonitor* inf = mark.monitor();\n+      markWord dmw = inf->header();\n+      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n+      return dmw;\n+    }\n+\n+    \/\/ CASE: stack-locked\n+    \/\/ Could be stack-locked either by this thread or by some other thread.\n+    if (mark.has_locker()) {\n+      BasicLock* lock = mark.locker();\n+      if (Thread::current()->is_lock_owned((address)lock)) {\n+        \/\/ If locked by this thread, it is safe to access the displaced header.\n+        markWord dmw = lock->displaced_header();\n+        assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n+        return dmw;\n+      }\n+\n+      \/\/ Otherwise, attempt to temporarily install INFLATING into the mark-word,\n+      \/\/ to prevent inflation or unlocking by competing thread.\n+      markWord cmp = object->cas_set_mark(markWord::INFLATING(), mark);\n+      if (cmp != mark) {\n+        continue;       \/\/ Interference -- just retry\n+      }\n+\n+      \/\/ fetch the displaced mark from the owner's stack.\n+      \/\/ The owner can't die or unwind past the lock while our INFLATING\n+      \/\/ object is in the mark.  Furthermore the owner can't complete\n+      \/\/ an unlock on the object, either.\n+      markWord dmw = mark.displaced_mark_helper();\n+      \/\/ Catch if the object's header is not neutral (not locked and\n+      \/\/ not marked is what we care about here).\n+      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n+\n+      \/\/ Must preserve store ordering. The monitor state must\n+      \/\/ be stable at the time of publishing the monitor address.\n+      assert(object->mark() == markWord::INFLATING(), \"invariant\");\n+      \/\/ Release semantics so that above set_object() is seen first.\n+      object->release_set_mark(mark);\n+\n+      return dmw;\n+    }\n+\n+    \/\/ CASE: neutral or marked (for GC)\n+    \/\/ Catch if the object's header is not neutral or marked (it must not be locked).\n+    assert(mark.is_neutral() || mark.is_marked(), \"invariant: header=\" INTPTR_FORMAT, mark.value());\n+    return mark;\n@@ -727,1 +878,0 @@\n-  return mark;\n@@ -793,1 +943,1 @@\n-    markWord mark = obj->mark_acquire();\n+    markWord mark = read_stable_mark(obj);\n@@ -796,1 +946,1 @@\n-      guarantee(!mark.is_fast_locked(), \"must not be fast-locked\");\n+      guarantee(!mark.has_locker(), \"must not be stack locked\");\n@@ -841,5 +991,6 @@\n-    } else if (current->lock_stack().contains(obj)) {\n-      \/\/ This is a fast lock owned by the calling thread so use the\n-      \/\/ markWord from the object.\n-      assert(mark.is_fast_locked(), \"invariant: header=\" INTPTR_FORMAT, temp.value());\n-      hash = mark.hash();\n+    } else if (current->is_lock_owned((address)mark.locker())) {\n+      \/\/ This is a stack lock owned by the calling thread so fetch the\n+      \/\/ displaced markWord from the BasicLock on the stack.\n+      temp = mark.displaced_mark_helper();\n+      assert(temp.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, temp.value());\n+      hash = temp.hash();\n@@ -849,0 +1000,8 @@\n+      \/\/ WARNING:\n+      \/\/ The displaced header in the BasicLock on a thread's stack\n+      \/\/ is strictly immutable. It CANNOT be changed in ANY cases.\n+      \/\/ So we have to inflate the stack lock into an ObjectMonitor\n+      \/\/ even if the current thread owns the lock. The BasicLock on\n+      \/\/ a thread's stack can be asynchronously read by other threads\n+      \/\/ during an inflate() call so any change to that stack memory\n+      \/\/ may not propagate to other threads correctly.\n@@ -902,1 +1061,1 @@\n-  markWord mark = obj->mark_acquire();\n+  markWord mark = read_stable_mark(obj);\n@@ -904,2 +1063,3 @@\n-  if (mark.is_fast_locked()) {\n-    return current->lock_stack().contains(h_obj());\n+  \/\/ Uncontended case, header points to stack\n+  if (mark.has_locker()) {\n+    return current->is_lock_owned((address)mark.locker());\n@@ -912,5 +1072,1 @@\n-    if (monitor->is_owner_anonymous()) {\n-      return current->lock_stack().contains(h_obj());\n-    } else {\n-      return monitor->is_entered(current) != 0;\n-    }\n+    return monitor->is_entered(current) != 0;\n@@ -926,2 +1082,29 @@\n-  ObjectMonitor* monitor_dummy;\n-  return Threads::owning_thread_from_object(t_list, obj, &monitor_dummy);\n+  address owner = NULL;\n+\n+  markWord mark = read_stable_mark(obj);\n+\n+  \/\/ Uncontended case, header points to stack\n+  if (mark.has_locker()) {\n+    owner = (address) mark.locker();\n+  }\n+\n+  \/\/ Contended case, header points to ObjectMonitor (tagged pointer)\n+  else if (mark.has_monitor()) {\n+    \/\/ The first stage of async deflation does not affect any field\n+    \/\/ used by this comparison so the ObjectMonitor* is usable here.\n+    ObjectMonitor* monitor = mark.monitor();\n+    assert(monitor != NULL, \"monitor should be non-null\");\n+    owner = (address) monitor->owner();\n+  }\n+\n+  if (owner != NULL) {\n+    \/\/ owning_thread_from_monitor_owner() may also return NULL here\n+    return Threads::owning_thread_from_monitor_owner(t_list, owner);\n+  }\n+\n+  \/\/ Unlocked case, header in place\n+  \/\/ Cannot have assertion since this object may have been\n+  \/\/ locked by another thread when reaching here.\n+  \/\/ assert(mark.is_neutral(), \"sanity check\");\n+\n+  return NULL;\n@@ -1115,2 +1298,3 @@\n-    \/\/ *  Inflated     - just return, maybe fix anon owner\n-    \/\/ *  Fast-locked  - coerce it to inflated\n+    \/\/ *  Inflated     - just return\n+    \/\/ *  Stack-locked - coerce it to inflated\n+    \/\/ *  INFLATING    - busy wait for conversion to complete\n@@ -1124,6 +1308,0 @@\n-      if (inf->is_owner_anonymous()) {\n-        if (current->lock_stack().contains(object)) {\n-          inf->set_owner_from_anonymous(current);\n-          current->lock_stack().remove(object);\n-        }\n-      }\n@@ -1133,2 +1311,21 @@\n-    \/\/ CASE: fast-locked\n-    \/\/ Could be fast-locked either by this thread or by some other thread.\n+    \/\/ CASE: inflation in progress - inflating over a stack-lock.\n+    \/\/ Some other thread is converting from stack-locked to inflated.\n+    \/\/ Only that thread can complete inflation -- other threads must wait.\n+    \/\/ The INFLATING value is transient.\n+    \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n+    \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n+    if (mark == markWord::INFLATING()) {\n+      read_stable_mark(object);\n+      continue;\n+    }\n+\n+    \/\/ CASE: stack-locked\n+    \/\/ Could be stack-locked either by this thread or by some other thread.\n+    \/\/\n+    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_ attempting\n+    \/\/ to install INFLATING into the mark word.  We originally installed INFLATING,\n+    \/\/ allocated the ObjectMonitor, and then finally STed the address of the\n+    \/\/ ObjectMonitor into the mark.  This was correct, but artificially lengthened\n+    \/\/ the interval in which INFLATING appeared in the mark, thus increasing\n+    \/\/ the odds of inflation contention.\n+\n@@ -1137,11 +1334,10 @@\n-    if (mark.is_fast_locked()) {\n-      ObjectMonitor* monitor = new ObjectMonitor(object);\n-      monitor->set_header(mark.set_unlocked());\n-      LockStack& lock_stack = current->lock_stack();\n-      bool own = lock_stack.contains(object);\n-      if (own) {\n-        \/\/ Owned by us.\n-        monitor->set_owner_from(NULL, current);\n-      } else {\n-        \/\/ Owned by somebody else.\n-        monitor->set_owner_anonymous();\n+    if (mark.has_locker()) {\n+      ObjectMonitor* m = new ObjectMonitor(object);\n+      \/\/ Optimistically prepare the ObjectMonitor - anticipate successful CAS\n+      \/\/ We do this before the CAS in order to minimize the length of time\n+      \/\/ in which INFLATING appears in the mark.\n+\n+      markWord cmp = object->cas_set_mark(markWord::INFLATING(), mark);\n+      if (cmp != mark) {\n+        delete m;\n+        continue;       \/\/ Interference -- just retry\n@@ -1149,24 +1345,65 @@\n-      markWord monitor_mark = markWord::encode(monitor);\n-      markWord witness = object->cas_set_mark(monitor_mark, mark);\n-      if (witness == mark) {\n-        \/\/ Success! Return inflated monitor.\n-        if (own) {\n-          lock_stack.remove(object);\n-        }\n-        \/\/ Once the ObjectMonitor is configured and object is associated\n-        \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n-        _in_use_list.add(monitor);\n-\n-        \/\/ Hopefully the performance counters are allocated on distinct\n-        \/\/ cache lines to avoid false sharing on MP systems ...\n-        OM_PERFDATA_OP(Inflations, inc());\n-        if (log_is_enabled(Trace, monitorinflation)) {\n-          ResourceMark rm(current);\n-          lsh.print_cr(\"inflate(locked): object=\" INTPTR_FORMAT \", mark=\"\n-                       INTPTR_FORMAT \", type='%s'\", p2i(object),\n-                       object->mark().value(), object->klass()->external_name());\n-        }\n-        if (event.should_commit()) {\n-          post_monitor_inflate_event(&event, object, cause);\n-        }\n-        return monitor;\n+\n+      \/\/ We've successfully installed INFLATING (0) into the mark-word.\n+      \/\/ This is the only case where 0 will appear in a mark-word.\n+      \/\/ Only the singular thread that successfully swings the mark-word\n+      \/\/ to 0 can perform (or more precisely, complete) inflation.\n+      \/\/\n+      \/\/ Why do we CAS a 0 into the mark-word instead of just CASing the\n+      \/\/ mark-word from the stack-locked value directly to the new inflated state?\n+      \/\/ Consider what happens when a thread unlocks a stack-locked object.\n+      \/\/ It attempts to use CAS to swing the displaced header value from the\n+      \/\/ on-stack BasicLock back into the object header.  Recall also that the\n+      \/\/ header value (hash code, etc) can reside in (a) the object header, or\n+      \/\/ (b) a displaced header associated with the stack-lock, or (c) a displaced\n+      \/\/ header in an ObjectMonitor.  The inflate() routine must copy the header\n+      \/\/ value from the BasicLock on the owner's stack to the ObjectMonitor, all\n+      \/\/ the while preserving the hashCode stability invariants.  If the owner\n+      \/\/ decides to release the lock while the value is 0, the unlock will fail\n+      \/\/ and control will eventually pass from slow_exit() to inflate.  The owner\n+      \/\/ will then spin, waiting for the 0 value to disappear.   Put another way,\n+      \/\/ the 0 causes the owner to stall if the owner happens to try to\n+      \/\/ drop the lock (restoring the header from the BasicLock to the object)\n+      \/\/ while inflation is in-progress.  This protocol avoids races that might\n+      \/\/ would otherwise permit hashCode values to change or \"flicker\" for an object.\n+      \/\/ Critically, while object->mark is 0 mark.displaced_mark_helper() is stable.\n+      \/\/ 0 serves as a \"BUSY\" inflate-in-progress indicator.\n+\n+\n+      \/\/ fetch the displaced mark from the owner's stack.\n+      \/\/ The owner can't die or unwind past the lock while our INFLATING\n+      \/\/ object is in the mark.  Furthermore the owner can't complete\n+      \/\/ an unlock on the object, either.\n+      markWord dmw = mark.displaced_mark_helper();\n+      \/\/ Catch if the object's header is not neutral (not locked and\n+      \/\/ not marked is what we care about here).\n+      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n+\n+      \/\/ Setup monitor fields to proper values -- prepare the monitor\n+      m->set_header(dmw);\n+\n+      \/\/ Optimization: if the mark.locker stack address is associated\n+      \/\/ with this thread we could simply set m->_owner = current.\n+      \/\/ Note that a thread can inflate an object\n+      \/\/ that it has stack-locked -- as might happen in wait() -- directly\n+      \/\/ with CAS.  That is, we can avoid the xchg-NULL .... ST idiom.\n+      m->set_owner_from(NULL, mark.locker());\n+      \/\/ TODO-FIXME: assert BasicLock->dhw != 0.\n+\n+      \/\/ Must preserve store ordering. The monitor state must\n+      \/\/ be stable at the time of publishing the monitor address.\n+      guarantee(object->mark() == markWord::INFLATING(), \"invariant\");\n+      \/\/ Release semantics so that above set_object() is seen first.\n+      object->release_set_mark(markWord::encode(m));\n+\n+      \/\/ Once ObjectMonitor is configured and the object is associated\n+      \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n+      _in_use_list.add(m);\n+\n+      \/\/ Hopefully the performance counters are allocated on distinct cache lines\n+      \/\/ to avoid false sharing on MP systems ...\n+      OM_PERFDATA_OP(Inflations, inc());\n+      if (log_is_enabled(Trace, monitorinflation)) {\n+        ResourceMark rm(current);\n+        lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n+                     INTPTR_FORMAT \", type='%s'\", p2i(object),\n+                     object->mark().value(), object->klass()->external_name());\n@@ -1174,3 +1411,4 @@\n-      \/\/ Otherwise, discard the monitor and retry.\n-      delete monitor;\n-      continue;\n+      if (event.should_commit()) {\n+        post_monitor_inflate_event(&event, object, cause);\n+      }\n+      return m;\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":364,"deletions":126,"binary":false,"changes":490,"status":"modified"},{"patch":"@@ -146,2 +146,2 @@\n-  static void enter(Handle obj, JavaThread* current);\n-  static void exit(oop obj, JavaThread* current);\n+  static void enter(Handle obj, BasicLock* lock, JavaThread* current);\n+  static void exit(oop obj, BasicLock* lock, JavaThread* current);\n@@ -160,1 +160,1 @@\n-  static bool quick_enter(oop obj, JavaThread* current);\n+  static bool quick_enter(oop obj, JavaThread* current, BasicLock* Lock);\n@@ -184,0 +184,3 @@\n+  \/\/ Read mark-word and spin-wait as long as INFLATING is observed.\n+  static markWord read_stable_mark(oop obj);\n+\n@@ -264,0 +267,1 @@\n+  BasicLock   _lock;\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-#include \"runtime\/lockStack.inline.hpp\"\n@@ -76,2 +75,1 @@\n-Thread::Thread():\n-  _lock_stack() {\n+Thread::Thread() {\n@@ -419,3 +417,0 @@\n-  if (!UseHeavyMonitors) {\n-    lock_stack().oops_do(f);\n-  }\n@@ -549,2 +544,1 @@\n-  assert(adr != ANONYMOUS_OWNER, \"must convert to lock object\");\n-  return !UseHeavyMonitors && lock_stack().contains(cast_to_oop(adr));\n+  return is_in_full_stack(adr);\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":2,"deletions":8,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-#include \"runtime\/lockStack.hpp\"\n@@ -611,1 +610,2 @@\n-  ParkEvent * volatile _ParkEvent;            \/\/ for Object monitors and JVMTI raw monitors\n+  ParkEvent * volatile _ParkEvent;            \/\/ for Object monitors, JVMTI raw monitors,\n+                                              \/\/ and ObjectSynchronizer::read_stable_mark\n@@ -623,10 +623,0 @@\n-private:\n-  LockStack _lock_stack;\n-\n-public:\n-  LockStack& lock_stack() { return _lock_stack; }\n-  const LockStack& lock_stack() const { return _lock_stack; }\n-\n-  static ByteSize lock_stack_current_offset()    { return byte_offset_of(Thread, _lock_stack) + LockStack::current_offset(); }\n-  static ByteSize lock_stack_limit_offset()    { return byte_offset_of(Thread, _lock_stack) + LockStack::limit_offset(); }\n-\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":2,"deletions":12,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -71,1 +71,0 @@\n-#include \"runtime\/lockStack.inline.hpp\"\n@@ -75,1 +74,1 @@\n-#include \"runtime\/objectMonitor.inline.hpp\"\n+#include \"runtime\/objectMonitor.hpp\"\n@@ -1379,8 +1378,0 @@\n-JavaThread* Threads::owning_thread_impl(ThreadsList * t_list, oop obj) {\n-  for (JavaThread* q : *t_list) {\n-    if (q->lock_stack().contains(obj)) {\n-      return q;\n-    }\n-  }\n-  return NULL;\n-}\n@@ -1388,9 +1379,8 @@\n-JavaThread* Threads::owning_thread_from_object(ThreadsList * t_list, oop obj, ObjectMonitor** monitor_out) {\n-  markWord header = obj->mark();\n-  if (header.is_fast_locked()) {\n-    return owning_thread_impl(t_list, obj);\n-  } else if (header.has_monitor()) {\n-    *monitor_out = header.monitor();\n-    return owning_thread_from_monitor(t_list, *monitor_out);\n-  } else {\n-    return NULL;\n+JavaThread *Threads::owning_thread_from_monitor_owner(ThreadsList * t_list,\n+                                                      address owner) {\n+  \/\/ NULL owner means not locked so we can skip the search\n+  if (owner == NULL) return NULL;\n+\n+  for (JavaThread* p : *t_list) {\n+    \/\/ first, see if owner is the address of a Java thread\n+    if (owner == (address)p) return p;\n@@ -1398,1 +1388,0 @@\n-}\n@@ -1400,11 +1389,15 @@\n-JavaThread *Threads::owning_thread_from_monitor(ThreadsList * t_list,\n-                                                ObjectMonitor* monitor) {\n-  if (monitor->is_owner_anonymous()) {\n-    return owning_thread_impl(t_list, monitor->object());\n-  } else {\n-    \/\/ TODO: owner could return Thread* or even JavaThread* already.\n-    Thread* owner = reinterpret_cast<Thread*>(monitor->owner());\n-    \/\/ NULL owner means not locked.\n-    if (owner == NULL) return NULL;\n-    assert(owner->is_Java_thread(), \"only JavaThreads own monitors\");\n-    return reinterpret_cast<JavaThread*>(owner);\n+  \/\/ Cannot assert on lack of success here since this function may be\n+  \/\/ used by code that is trying to report useful problem information\n+  \/\/ like deadlock detection.\n+  if (UseHeavyMonitors) return NULL;\n+\n+  \/\/ If we didn't find a matching Java thread and we didn't force use of\n+  \/\/ heavyweight monitors, then the owner is the stack address of the\n+  \/\/ Lock Word in the owning Java thread's stack.\n+  \/\/\n+  JavaThread* the_owner = NULL;\n+  for (JavaThread* q : *t_list) {\n+    if (q->is_lock_owned(owner)) {\n+      the_owner = q;\n+      break;\n+    }\n@@ -1412,0 +1405,3 @@\n+\n+  \/\/ cannot assert on lack of success here; see above comment\n+  return the_owner;\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":27,"deletions":31,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -136,5 +136,2 @@\n-private:\n-  static JavaThread* owning_thread_impl(ThreadsList * t_list, oop obj);\n-public:\n-  static JavaThread* owning_thread_from_object(ThreadsList * t_list, oop obj, ObjectMonitor** monitor_out);\n-  static JavaThread* owning_thread_from_monitor(ThreadsList * t_list, ObjectMonitor* owner);\n+  static JavaThread *owning_thread_from_monitor_owner(ThreadsList * t_list,\n+                                                      address owner);\n","filename":"src\/hotspot\/share\/runtime\/threads.hpp","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -47,1 +47,0 @@\n-#include \"runtime\/lockStack.inline.hpp\"\n@@ -276,11 +275,7 @@\n-          if (mark.has_monitor()) {\n-            if (mark.monitor()->is_owner_anonymous()) {\n-              if (!thread()->lock_stack().contains(monitor->owner())) {\n-                lock_state = \"waiting to lock\";\n-              }\n-            } else if (\/\/ we have marked ourself as pending on this monitor\n-                    mark.monitor() == thread()->current_pending_monitor() ||\n-                    \/\/ we are not the owner of this monitor\n-                    !mark.monitor()->is_entered(thread())) {\n-              lock_state = \"waiting to lock\";\n-            }\n+          if (mark.has_monitor() &&\n+              ( \/\/ we have marked ourself as pending on this monitor\n+                mark.monitor() == thread()->current_pending_monitor() ||\n+                \/\/ we are not the owner of this monitor\n+                !mark.monitor()->is_entered(thread())\n+              )) {\n+            lock_state = \"waiting to lock\";\n@@ -321,1 +316,1 @@\n-      result->push(new MonitorInfo(current->obj(), false, false));\n+      result->push(new MonitorInfo(current->obj(), current->lock(), false, false));\n@@ -514,1 +509,1 @@\n-MonitorInfo::MonitorInfo(oop owner, bool eliminated, bool owner_is_scalar_replaced) {\n+MonitorInfo::MonitorInfo(oop owner, BasicLock* lock, bool eliminated, bool owner_is_scalar_replaced) {\n@@ -524,0 +519,1 @@\n+  _lock = lock;\n@@ -750,0 +746,3 @@\n+    tty->print(\"\\t  \");\n+    monitor->lock()->print_on(tty, monitor->owner());\n+    tty->cr();\n","filename":"src\/hotspot\/share\/runtime\/vframe.cpp","additions":13,"deletions":14,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -53,0 +53,2 @@\n+\/\/ - BasicLock\n+\n@@ -256,0 +258,1 @@\n+  BasicLock* _lock;\n@@ -261,1 +264,1 @@\n-  MonitorInfo(oop owner, bool eliminated, bool owner_is_scalar_replaced);\n+  MonitorInfo(oop owner, BasicLock* lock, bool eliminated, bool owner_is_scalar_replaced);\n@@ -271,0 +274,1 @@\n+  BasicLock* lock()  const { return _lock;  }\n","filename":"src\/hotspot\/share\/runtime\/vframe.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -90,1 +90,1 @@\n-      \/\/ Migrate the BasicObjectLocks from the stack to the monitor chunk\n+      \/\/ Migrate the BasicLocks from the stack to the monitor chunk\n@@ -100,0 +100,1 @@\n+          monitor->lock()->move_to(monitor->owner(), dest->lock());\n@@ -310,0 +311,1 @@\n+    src->lock()->move_to(src->obj(), top->lock());\n","filename":"src\/hotspot\/share\/runtime\/vframeArray.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -237,0 +237,4 @@\n+BasicLock* compiledVFrame::resolve_monitor_lock(Location location) const {\n+  return StackValue::resolve_monitor_lock(&_fr, location);\n+}\n+\n@@ -253,1 +257,1 @@\n-        fr.get_native_receiver(), false, false);\n+        fr.get_native_receiver(), fr.get_native_monitor(), false, false);\n@@ -273,1 +277,2 @@\n-      result->push(new MonitorInfo(k(), mv->eliminated(), true));\n+      result->push(new MonitorInfo(k(), resolve_monitor_lock(mv->basic_lock()),\n+                                   mv->eliminated(), true));\n@@ -275,1 +280,2 @@\n-      result->push(new MonitorInfo(owner_sv->get_obj()(), mv->eliminated(), false));\n+      result->push(new MonitorInfo(owner_sv->get_obj()(), resolve_monitor_lock(mv->basic_lock()),\n+                                   mv->eliminated(), false));\n@@ -509,1 +515,2 @@\n-      MonitorInfo* new_info = new MonitorInfo((oopDesc*)val->value().l, info->eliminated(), false);\n+      MonitorInfo* new_info = new MonitorInfo((oopDesc*)val->value().l, info->lock(),\n+                                              info->eliminated(), false);\n","filename":"src\/hotspot\/share\/runtime\/vframe_hp.cpp","additions":11,"deletions":4,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -96,0 +96,1 @@\n+  BasicLock* resolve_monitor_lock(Location location) const;\n","filename":"src\/hotspot\/share\/runtime\/vframe_hp.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -707,3 +707,0 @@\n-  nonstatic_field(Thread,                      _lock_stack,                                   LockStack)                             \\\n-  nonstatic_field(LockStack,                   _current,                                      oop*)                                  \\\n-  nonstatic_field(LockStack,                   _base,                                         oop*)                                  \\\n@@ -857,0 +854,1 @@\n+  volatile_nonstatic_field(BasicLock,          _displaced_header,                             markWord)                              \\\n@@ -860,0 +858,1 @@\n+  nonstatic_field(BasicObjectLock,             _lock,                                         BasicLock)                             \\\n@@ -1322,1 +1321,0 @@\n-  declare_toplevel_type(LockStack)                                        \\\n@@ -1441,0 +1439,1 @@\n+  declare_toplevel_type(BasicLock)                                        \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -458,2 +458,4 @@\n-        if (waitingToLockMonitor->is_owner_anonymous() || waitingToLockMonitor->owner() != NULL) {\n-          currentThread = Threads::owning_thread_from_monitor(t_list, waitingToLockMonitor);\n+        address currentOwner = (address)waitingToLockMonitor->owner();\n+        if (currentOwner != NULL) {\n+          currentThread = Threads::owning_thread_from_monitor_owner(t_list,\n+                                                                    currentOwner);\n@@ -1053,1 +1055,2 @@\n-      currentThread = Threads::owning_thread_from_monitor(t_list, waitingToLockMonitor);\n+      currentThread = Threads::owning_thread_from_monitor_owner(t_list,\n+                                                                (address)waitingToLockMonitor->owner());\n","filename":"src\/hotspot\/share\/services\/threadService.cpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -151,0 +151,6 @@\n+  public BasicLock locker() {\n+    if (Assert.ASSERTS_ENABLED) {\n+      Assert.that(hasLocker(), \"check\");\n+    }\n+    return new BasicLock(valueAsAddress());\n+  }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Mark.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,58 @@\n+\/*\n+ * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+package sun.jvm.hotspot.runtime;\n+\n+import java.util.*;\n+\n+import sun.jvm.hotspot.debugger.*;\n+import sun.jvm.hotspot.oops.*;\n+import sun.jvm.hotspot.types.*;\n+import sun.jvm.hotspot.utilities.Observable;\n+import sun.jvm.hotspot.utilities.Observer;\n+\n+public class BasicLock extends VMObject {\n+  static {\n+    VM.registerVMInitializedObserver(new Observer() {\n+        public void update(Observable o, Object data) {\n+          initialize(VM.getVM().getTypeDataBase());\n+        }\n+      });\n+  }\n+\n+  private static synchronized void initialize(TypeDataBase db) throws WrongTypeException {\n+    Type type  = db.lookupType(\"BasicLock\");\n+    displacedHeaderField = type.getCIntegerField(\"_displaced_header\");\n+  }\n+\n+  private static CIntegerField displacedHeaderField;\n+\n+  public BasicLock(Address addr) {\n+    super(addr);\n+  }\n+\n+  public Mark displacedHeader() {\n+    return new Mark(addr.addOffsetTo(displacedHeaderField.getOffset()));\n+  }\n+}\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/BasicLock.java","additions":58,"deletions":0,"binary":false,"changes":58,"status":"added"},{"patch":"@@ -45,0 +45,1 @@\n+    lockField  = type.getField(\"_lock\");\n@@ -49,0 +50,1 @@\n+  private static sun.jvm.hotspot.types.Field    lockField;\n@@ -57,0 +59,1 @@\n+  public BasicLock lock() { return new BasicLock(addr.addOffsetTo(lockField.getOffset())); }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/BasicObjectLock.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -148,1 +148,1 @@\n-        result.add(new MonitorInfo(k, mv.eliminated(), true));\n+        result.add(new MonitorInfo(k, resolveMonitorLock(mv.basicLock()), mv.eliminated(), true));\n@@ -150,1 +150,1 @@\n-        result.add(new MonitorInfo(ownerSV.getObject(), mv.eliminated(), false));\n+        result.add(new MonitorInfo(ownerSV.getObject(), resolveMonitorLock(mv.basicLock()), mv.eliminated(), false));\n@@ -313,0 +313,16 @@\n+\n+  private BasicLock resolveMonitorLock(Location location) {\n+    if (Assert.ASSERTS_ENABLED) {\n+      Assert.that(location.isStack(), \"for now we only look at the stack\");\n+    }\n+    int byteOffset = location.getStackOffset();\n+    \/\/ (stack picture)\n+    \/\/ high: [     ]  byte_offset + wordSize\n+    \/\/ low   [     ]  byte_offset\n+    \/\/\n+    \/\/ sp->  [     ]  0\n+    \/\/ the byte_offset is the distance from the stack pointer to the lowest address\n+    \/\/ The frame's original stack pointer, before any extension by its callee\n+    \/\/ (due to Compiler1 linkage on SPARC), must be used.\n+    return new BasicLock(getFrame().getUnextendedSP().addOffsetTo(byteOffset));\n+  }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/CompiledVFrame.java","additions":18,"deletions":2,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -116,1 +116,1 @@\n-      result.add(new MonitorInfo(current.obj(), false, false));\n+      result.add(new MonitorInfo(current.obj(), current.lock(), false, false));\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/InterpretedVFrame.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -397,0 +397,9 @@\n+  public boolean isLockOwned(Address a) {\n+    Address stackBase = getStackBase();\n+    Address stackLimit = stackBase.addOffsetTo(-getStackSize());\n+\n+    return stackBase.greaterThan(a) && stackLimit.lessThanOrEqual(a);\n+\n+    \/\/ FIXME: should traverse MonitorArray\/MonitorChunks as in VM\n+  }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaThread.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -85,1 +85,0 @@\n-          mark.monitor().isOwnedAnonymous() ||\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaVFrame.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+  private BasicLock lock;\n@@ -36,1 +37,1 @@\n-  public MonitorInfo(OopHandle owner, boolean eliminated, boolean ownerIsScalarReplaced) {\n+  public MonitorInfo(OopHandle owner, BasicLock lock, boolean eliminated, boolean ownerIsScalarReplaced) {\n@@ -59,0 +60,1 @@\n+  public BasicLock lock()  { return lock; }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/MonitorInfo.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -75,2 +75,2 @@\n-    if (o.asLongValue() == 1) throw new InternalError(\"Check anonymous owner before calling isEntered()\");\n-    if (current.threadObjectAddress().equals(o)) {\n+    if (current.threadObjectAddress().equals(o) ||\n+        current.isLockOwned(o)) {\n@@ -82,10 +82,1 @@\n-  public boolean isOwnedAnonymous() {\n-    return addr.getAddressAt(ownerFieldOffset).asLongValue() == 1;\n-  }\n-\n-  public Address owner() {\n-    Address owner = addr.getAddressAt(ownerFieldOffset);\n-    if (owner.asLongValue() == 1) throw new InternalError(\"Check anonymous owner before calling isEntered()\");\n-    return owner;\n-  }\n-\n+  public Address owner() { return addr.getAddressAt(ownerFieldOffset); }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/ObjectMonitor.java","additions":3,"deletions":12,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -36,3 +36,0 @@\n-  private static long lockStackCurrentOffset;\n-  private static long lockStackBaseOffset;\n-\n@@ -46,2 +43,0 @@\n-  private static long oopPtrSize;\n-\n@@ -59,1 +54,0 @@\n-    Type typeLockStack = db.lookupType(\"LockStack\");\n@@ -67,4 +61,0 @@\n-\n-    lockStackCurrentOffset = typeThread.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_current\").getOffset();\n-    lockStackBaseOffset = typeThread.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_base\").getOffset();\n-    oopPtrSize = VM.getVM().getAddressSize();\n@@ -121,10 +111,2 @@\n-  public boolean isLockOwned(OopHandle obj) {\n-    Address current = addr.getAddressAt(lockStackCurrentOffset);\n-    Address base = addr.getAddressAt(lockStackBaseOffset);\n-    while (base.lessThan(current)) {\n-        Address oop = base.getAddressAt(0);\n-        if (oop.equals(obj)) {\n-            return true;\n-        }\n-        base = base.addOffsetTo(oopPtrSize);\n-    }\n+  public boolean isLockOwned(Address lock) {\n+    if (isInStack(lock)) return true;\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Thread.java","additions":2,"deletions":20,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -212,12 +212,1 @@\n-    public JavaThread owningThreadFromMonitor(ObjectMonitor monitor) {\n-        if (monitor.isOwnedAnonymous()) {\n-            OopHandle object = monitor.object();\n-            for (int i = 0; i < getNumberOfThreads(); i++) {\n-                JavaThread thread = getJavaThreadAt(i);\n-                if (thread.isLockOwned(object)) {\n-                    return thread;\n-                }\n-            }\n-            throw new InternalError(\"We should have found a thread that owns the anonymous lock\");\n-        }\n-        Address o = monitor.owner();\n+    public JavaThread owningThreadFromMonitor(Address o) {\n@@ -231,0 +220,6 @@\n+\n+        for (int i = 0; i < getNumberOfThreads(); i++) {\n+            JavaThread thread = getJavaThreadAt(i);\n+            if (thread.isLockOwned(o))\n+                return thread;\n+        }\n@@ -234,0 +229,4 @@\n+    public JavaThread owningThreadFromMonitor(ObjectMonitor monitor) {\n+        return owningThreadFromMonitor(monitor.owner());\n+    }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Threads.java","additions":11,"deletions":12,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -78,0 +78,6 @@\n+        if (!thread.getAddress().equals(owner)) {\n+          if (!thread.isLockOwned(owner)) {\n+            tty.println(\"    WARNING! _owner doesn't fall in \" + thread +\n+                        \"'s stack space\");\n+          }\n+        }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/ui\/MonitorCacheDumpPanel.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1,62 +0,0 @@\n-\/*\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-\/*\n- * @test\n- * @summary Check that monitorenter A; monitorenter B; monitorexit A; monitorexit B; works\n- * @compile TestUnstructuredLocking.jasm\n- * @run main\/othervm -Xint TestUnstructuredLocking\n- *\/\n-\n-super public class TestUnstructuredLocking version 64:0 {\n-\n-\/\/    Method \"<init>\":\"()V\" stack 1 locals 1 {\n-\/\/        aload_0;\n-\/\/        invokespecial    Method java\/lang\/Object.\"<init>\":\"()V\";\n-\/\/        return;\n-\/\/    }\n-\n-    public static Method main:\"([Ljava\/lang\/String;)V\" stack 2 locals 4 {\n-        new class java\/lang\/Object;\n-        dup;\n-        invokespecial Method java\/lang\/Object.\"<init>\":\"()V\";\n-        astore_1;\n-        new class java\/lang\/Object;\n-        dup;\n-        invokespecial Method java\/lang\/Object.\"<init>\":\"()V\";\n-        astore_2;\n-        aload_1;\n-        monitorenter;\n-        aload_2;\n-        monitorenter;\n-        aload_1;\n-        monitorexit;\n-        aload_2;\n-        invokevirtual Method java\/lang\/Object.notify:\"()V\";\n-        aload_2;\n-        monitorexit;\n-        return;\n-    }\n-\n-}\n","filename":"test\/hotspot\/jtreg\/runtime\/locking\/TestUnstructuredLocking.jasm","additions":0,"deletions":62,"binary":false,"changes":62,"status":"deleted"},{"patch":"@@ -41,1 +41,1 @@\n-        output.shouldContain(\"inflate(locked):\");\n+        output.shouldContain(\"inflate(has_locker):\");\n","filename":"test\/hotspot\/jtreg\/runtime\/logging\/MonitorInflationTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}