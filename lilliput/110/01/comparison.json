{"files":[{"patch":"@@ -7340,1 +7340,1 @@\n-instruct loadNKlassLilliput(iRegNNoSp dst, memory4 mem, rFlagsReg cr)\n+instruct loadNKlassCompactHeaders(iRegNNoSp dst, memory4 mem, rFlagsReg cr)\n@@ -7351,11 +7351,1 @@\n-    Register dst = $dst$$Register;\n-    Register obj = $mem$$base$$Register;\n-    C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n-    Compile::current()->output()->add_stub(stub);\n-    __ ldr(dst, Address(obj, oopDesc::mark_offset_in_bytes()));\n-    \/\/ NOTE: We can't use tbnz here, because the target is sometimes too far away\n-    \/\/ and cannot be encoded.\n-    __ tst(dst, markWord::monitor_value);\n-    __ br(Assembler::NE, stub->entry());\n-    __ bind(stub->continuation());\n-    __ lsr(dst, dst, markWord::klass_shift);\n+    __ load_nklass_compact($dst$$Register, $mem$$base$$Register);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":2,"deletions":12,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2292,2 +2292,0 @@\n-  Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());\n-  Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -2354,9 +2352,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ load_nklass(tmp, src);\n-        __ load_nklass(rscratch1, dst);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(tmp, Address(src, oopDesc::klass_offset_in_bytes()));\n-        __ ldr(rscratch1, Address(dst, oopDesc::klass_offset_in_bytes()));\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(src, dst, tmp, rscratch1);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -220,6 +220,0 @@\n-  \/\/ Zero first 4 bytes, if start offset is not word aligned.\n-  if (!is_aligned(hdr_size_in_bytes, BytesPerWord)) {\n-    strw(zr, Address(obj, hdr_size_in_bytes));\n-    hdr_size_in_bytes += BytesPerInt;\n-  }\n-\n@@ -306,0 +300,11 @@\n+  \/\/ Clear leading 4 bytes, if necessary.\n+  \/\/ TODO: This could perhaps go into initialize_body() and also clear the leading 4 bytes\n+  \/\/ for non-array objects, thereby replacing the klass-gap clearing code in initialize_header().\n+  int base_offset = base_offset_in_bytes;\n+  if (!is_aligned(base_offset, BytesPerWord)) {\n+    assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n+    strw(zr, Address(obj, base_offset));\n+    base_offset += BytesPerInt;\n+  }\n+  assert(is_aligned(base_offset, BytesPerWord), \"must be word-aligned\");\n+\n@@ -307,1 +312,1 @@\n-  initialize_body(obj, arr_size, base_offset_in_bytes, t1, t2);\n+  initialize_body(obj, arr_size, base_offset, t1, t2);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":12,"deletions":7,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -291,0 +291,1 @@\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2061,0 +2061,12 @@\n+\n+void C2_MacroAssembler::load_nklass_compact(Register dst, Register obj) {\n+  C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n+  Compile::current()->output()->add_stub(stub);\n+  ldr(dst, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  \/\/ NOTE: We can't use tbnz here, because the target is sometimes too far away\n+  \/\/ and cannot be encoded.\n+  tst(dst, markWord::monitor_value);\n+  br(Assembler::NE, stub->entry());\n+  bind(stub->continuation());\n+  lsr(dst, dst, markWord::klass_shift);\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -175,0 +175,2 @@\n+  void load_nklass_compact(Register dst, Register obj);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -4317,6 +4317,1 @@\n-  assert(UseCompressedClassPointers, \"expects UseCompressedClassPointers\");\n-\n-  if (!UseCompactObjectHeaders) {\n-    ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n-    return;\n-  }\n+  assert(UseCompactObjectHeaders, \"expects UseCompactObjectHeaders\");\n@@ -4339,6 +4334,5 @@\n-  if (UseCompressedClassPointers) {\n-    if (UseCompactObjectHeaders) {\n-      load_nklass(dst, src);\n-    } else {\n-      ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n-    }\n+  if (UseCompactObjectHeaders) {\n+    load_nklass(dst, src);\n+    decode_klass_not_null(dst);\n+  } else if (UseCompressedClassPointers) {\n+    ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n@@ -4405,0 +4399,16 @@\n+void MacroAssembler::cmp_klass(Register src, Register dst, Register tmp1, Register tmp2) {\n+  if (UseCompactObjectHeaders) {\n+    load_nklass(tmp1, src);\n+    load_nklass(tmp2, dst);\n+    cmpw(tmp1, tmp2);\n+  } else if (UseCompressedClassPointers) {\n+    ldrw(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    ldrw(tmp2, Address(dst, oopDesc::klass_offset_in_bytes()));\n+    cmpw(tmp1, tmp2);\n+  } else {\n+    ldr(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    ldr(tmp2, Address(dst, oopDesc::klass_offset_in_bytes()));\n+    cmp(tmp1, tmp2);\n+  }\n+}\n+\n@@ -4408,0 +4418,1 @@\n+  assert(!UseCompactObjectHeaders, \"not with compact headers\");\n@@ -4417,0 +4428,1 @@\n+  assert(!UseCompactObjectHeaders, \"not with compact headers\");\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":24,"deletions":12,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -857,0 +857,1 @@\n+  void cmp_klass(Register src, Register dst, Register tmp1, Register tmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3610,1 +3610,6 @@\n-    __ sub(r3, r3, oopDesc::base_offset_in_bytes());\n+    if (UseCompactObjectHeaders) {\n+      assert(is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong), \"oop base offset must be 8-byte-aligned\");\n+      __ sub(r3, r3, oopDesc::base_offset_in_bytes());\n+    } else {\n+      __ sub(r3, r3, sizeof(oopDesc));\n+    }\n@@ -3615,5 +3620,5 @@\n-      __ add(r2, r0, oopDesc::base_offset_in_bytes());\n-      if (!is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong)) {\n-        __ strw(zr, Address(__ post(r2, BytesPerInt)));\n-        __ sub(r3, r3, BytesPerInt);\n-        __ cbz(r3, initialize_header);\n+      if (UseCompactObjectHeaders) {\n+        assert(is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong), \"oop base offset must be 8-byte-aligned\");\n+        __ add(r2, r0, oopDesc::base_offset_in_bytes());\n+      } else {\n+        __ add(r2, r0, sizeof(oopDesc));\n@@ -3636,0 +3641,1 @@\n+      __ store_klass_gap(r0, zr);  \/\/ zero klass gap for compressed oops\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":12,"deletions":6,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -3198,2 +3198,0 @@\n-  Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());\n-  Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -3324,0 +3322,1 @@\n+        Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -3540,2 +3539,1 @@\n-  } else\n-  if (UseCompressedClassPointers) {\n+  } else if (UseCompressedClassPointers) {\n@@ -3546,0 +3544,1 @@\n+  {\n@@ -3547,0 +3546,1 @@\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -167,0 +167,1 @@\n+#ifdef _LP64\n@@ -170,1 +171,1 @@\n-  } else {\n+  } else if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n@@ -172,6 +173,4 @@\n-#ifdef _LP64\n-    if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n-      movptr(t1, klass);\n-      encode_klass_not_null(t1, rscratch1);\n-      movl(Address(obj, oopDesc::klass_offset_in_bytes()), t1);\n-    } else\n+    movptr(t1, klass);\n+    encode_klass_not_null(t1, rscratch1);\n+    movl(Address(obj, oopDesc::klass_offset_in_bytes()), t1);\n+  } else\n@@ -179,3 +178,3 @@\n-    {\n-      movptr(Address(obj, oopDesc::klass_offset_in_bytes()), klass);\n-    }\n+  {\n+    movptr(Address(obj, oopDesc::mark_offset_in_bytes()), checked_cast<int32_t>(markWord::prototype().value()));\n+    movptr(Address(obj, oopDesc::klass_offset_in_bytes()), klass);\n@@ -221,1 +220,3 @@\n-\n+  if (UseCompactObjectHeaders) {\n+    assert(hdr_size_in_bytes == 8, \"check object headers size\");\n+  }\n@@ -229,1 +230,0 @@\n-    int hdr_size_aligned = align_up(hdr_size_in_bytes, BytesPerWord); \/\/ klass gap is already cleared by init_header().\n@@ -232,1 +232,1 @@\n-      initialize_body(obj, index, hdr_size_aligned, t1_zero);\n+      initialize_body(obj, index, hdr_size_in_bytes, t1_zero);\n@@ -237,1 +237,1 @@\n-      for (int i = hdr_size_aligned; i < con_size_in_bytes; i += BytesPerWord)\n+      for (int i = hdr_size_in_bytes; i < con_size_in_bytes; i += BytesPerWord)\n@@ -239,1 +239,1 @@\n-    } else if (con_size_in_bytes > hdr_size_aligned) {\n+    } else if (con_size_in_bytes > hdr_size_in_bytes) {\n@@ -244,1 +244,1 @@\n-      movptr(index, (con_size_in_bytes - hdr_size_aligned) >> 3);\n+      movptr(index, (con_size_in_bytes - hdr_size_in_bytes) >> 3);\n@@ -246,1 +246,1 @@\n-      if (((con_size_in_bytes - hdr_size_aligned) & 4) != 0)\n+      if (((con_size_in_bytes - hdr_size_in_bytes) & 4) != 0)\n@@ -251,1 +251,1 @@\n-        movptr(Address(obj, index, Address::times_8, hdr_size_aligned - (1*BytesPerWord)),\n+        movptr(Address(obj, index, Address::times_8, hdr_size_in_bytes - (1*BytesPerWord)),\n@@ -253,1 +253,1 @@\n-        NOT_LP64(movptr(Address(obj, index, Address::times_8, hdr_size_aligned - (2*BytesPerWord)),\n+        NOT_LP64(movptr(Address(obj, index, Address::times_8, hdr_size_in_bytes - (2*BytesPerWord)),\n@@ -290,0 +290,13 @@\n+  \/\/ Clear leading 4 bytes, if necessary.\n+  \/\/ TODO: This could perhaps go into initialize_body() and also clear the leading 4 bytes\n+  \/\/ for non-array objects, thereby replacing the klass-gap clearing code in initialize_header().\n+  int base_offset = base_offset_in_bytes;\n+#ifdef _LP64\n+  if (!is_aligned(base_offset, BytesPerWord)) {\n+    assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n+    movl(Address(obj, base_offset), 0);\n+    base_offset += BytesPerInt;\n+  }\n+#endif\n+  assert(is_aligned(base_offset, BytesPerWord), \"must be word aligned\");\n+\n@@ -292,1 +305,1 @@\n-  initialize_body(obj, arr_size, base_offset_in_bytes, len_zero);\n+  initialize_body(obj, arr_size, base_offset, len_zero);\n@@ -307,2 +320,1 @@\n-  \/\/ check against inline cache\n-  assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), \"must add explicit null check\");\n+  \/\/ check against inline cache. This is checked in Universe::genesis().\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":34,"deletions":22,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -666,1 +666,1 @@\n-  cmpxchgptr(thread, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  cmpxchgptr(scrReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n@@ -668,0 +668,7 @@\n+  \/\/ If we weren't able to swing _owner from null to the BasicLock\n+  \/\/ then take the slow path.\n+  jccb  (Assembler::notZero, NO_COUNT);\n+  \/\/ update _owner from BasicLock to thread\n+  get_thread (scrReg);                    \/\/ beware: clobbers ICCs\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), scrReg);\n+  xorptr(boxReg, boxReg);                 \/\/ set icc.ZFlag = 1 to indicate success\n@@ -6175,0 +6182,12 @@\n+\n+#ifdef _LP64\n+void C2_MacroAssembler::load_nklass_compact_c2(Register dst, Register obj) {\n+  C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n+  Compile::current()->output()->add_stub(stub);\n+  movq(dst, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  testb(dst, markWord::monitor_value);\n+  jcc(Assembler::notZero, stub->entry());\n+  bind(stub->continuation());\n+  shrq(dst, markWord::klass_shift);\n+}\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":20,"deletions":1,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -495,0 +495,2 @@\n+  void load_nklass_compact_c2(Register dst, Register obj);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -4159,1 +4159,1 @@\n-  assert((offset_in_bytes & (BytesPerInt - 1)) == 0, \"offset must be a multiple of BytesPerInt\");\n+  assert((offset_in_bytes & (BytesPerWord - 1)) == 0, \"offset must be a multiple of BytesPerWord\");\n@@ -4165,13 +4165,0 @@\n-  \/\/ Emit single 32bit store to clear leading bytes, if necessary.\n-  xorptr(temp, temp);    \/\/ use _zero reg to clear memory (shorter code)\n-#ifdef _LP64\n-  if (!is_aligned(offset_in_bytes, BytesPerWord)) {\n-    movl(Address(address, offset_in_bytes), temp);\n-    offset_in_bytes += BytesPerInt;\n-    decrement(length_in_bytes, BytesPerInt);\n-  }\n-  assert((offset_in_bytes & (BytesPerWord - 1)) == 0, \"offset must be a multiple of BytesPerWord\");\n-  testptr(length_in_bytes, length_in_bytes);\n-  jcc(Assembler::zero, done);\n-#endif\n-\n@@ -4190,0 +4177,1 @@\n+  xorptr(temp, temp);    \/\/ use _zero reg to clear memory (shorter code)\n@@ -5241,7 +5229,2 @@\n-void MacroAssembler::load_nklass(Register dst, Register src) {\n-  assert(UseCompressedClassPointers, \"expect compressed class pointers\");\n-\n-  if (!UseCompactObjectHeaders) {\n-    movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n-    return;\n-  }\n+void MacroAssembler::load_nklass_compact(Register dst, Register src) {\n+  assert(UseCompactObjectHeaders, \"expect compact object headers\");\n@@ -5266,2 +5249,5 @@\n-  if (UseCompressedClassPointers) {\n-    load_nklass(dst, src);\n+  if (UseCompactObjectHeaders) {\n+    load_nklass_compact(dst, src);\n+    decode_klass_not_null(dst, tmp);\n+  } else if (UseCompressedClassPointers) {\n+    movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));\n@@ -5271,0 +5257,1 @@\n+  {\n@@ -5272,0 +5259,1 @@\n+  }\n@@ -5284,1 +5272,1 @@\n-   movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);\n+    movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);\n@@ -5290,4 +5278,1 @@\n-    \/\/ NOTE: We need to deal with possible ObjectMonitor in object header.\n-    \/\/ Eventually we might be able to do simple movl & cmpl like in\n-    \/\/ the CCP path below.\n-    load_nklass(tmp, obj);\n+    load_nklass_compact(tmp, obj);\n@@ -5307,3 +5292,0 @@\n-    \/\/ NOTE: We need to deal with possible ObjectMonitor in object header.\n-    \/\/ Eventually we might be able to do simple movl & cmpl like in\n-    \/\/ the CCP path below.\n@@ -5312,2 +5294,2 @@\n-    load_nklass(tmp1, src);\n-    load_nklass(tmp2, dst);\n+    load_nklass_compact(tmp1, src);\n+    load_nklass_compact(tmp2, dst);\n@@ -5373,0 +5355,1 @@\n+  assert(!UseCompactObjectHeaders, \"Don't use with compact headers\");\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":16,"deletions":33,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -367,1 +367,1 @@\n-  void load_nklass(Register dst, Register src);\n+  void load_nklass_compact(Register dst, Register src);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -4059,2 +4059,6 @@\n-    int header_size = align_up(oopDesc::base_offset_in_bytes(), BytesPerLong);\n-    __ decrement(rdx, header_size);\n+    if (UseCompactObjectHeaders) {\n+      assert(is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong), \"oop base offset must be 8-byte-aligned\");\n+      __ decrement(rdx, oopDesc::base_offset_in_bytes());\n+    } else {\n+      __ decrement(rdx, sizeof(oopDesc));\n+    }\n@@ -4082,2 +4086,9 @@\n-    __ movptr(Address(rax, rdx, Address::times_8, header_size - 1*oopSize), rcx);\n-    NOT_LP64(__ movptr(Address(rax, rdx, Address::times_8, header_size - 2*oopSize), rcx));\n+    if (UseCompactObjectHeaders) {\n+      assert(is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong), \"oop base offset must be 8-byte-aligned\");\n+      int header_size = oopDesc::base_offset_in_bytes();\n+      __ movptr(Address(rax, rdx, Address::times_8, header_size - 1*oopSize), rcx);\n+      NOT_LP64(__ movptr(Address(rax, rdx, Address::times_8, header_size - 2*oopSize), rcx));\n+    } else {\n+      __ movptr(Address(rax, rdx, Address::times_8, sizeof(oopDesc) - 1*oopSize), rcx);\n+      NOT_LP64(__ movptr(Address(rax, rdx, Address::times_8, sizeof(oopDesc) - 2*oopSize), rcx));\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -5328,1 +5328,1 @@\n-instruct loadNKlassLilliput(rRegN dst, indOffset8 mem, rFlagsReg cr)\n+instruct loadNKlassCompactHeaders(rRegN dst, indOffset8 mem, rFlagsReg cr)\n@@ -5338,9 +5338,1 @@\n-    Register dst = $dst$$Register;\n-    Register obj = $mem$$base$$Register;\n-    C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n-    Compile::current()->output()->add_stub(stub);\n-    __ movq(dst, Address(obj, oopDesc::mark_offset_in_bytes()));\n-    __ testb(dst, markWord::monitor_value);\n-    __ jcc(Assembler::notZero, stub->entry());\n-    __ bind(stub->continuation());\n-    __ shrq(dst, markWord::klass_shift);\n+    __ load_nklass_compact_c2($dst$$Register, $mem$$base$$Register);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":2,"deletions":10,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -175,1 +175,0 @@\n-\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1911,1 +1911,2 @@\n-    , _stub(stub) {}\n+    , _stub(stub)\n+    {}\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -727,0 +727,13 @@\n+#ifdef _LP64\n+    if (UseCompactObjectHeaders) {\n+      Klass* requested_k = to_requested(k);\n+#if INCLUDE_CDS_JAVA_HEAP\n+      address narrow_klass_base = _requested_static_archive_bottom; \/\/ runtime encoding base == runtime mapping start\n+      const int narrow_klass_shift = ArchiveHeapWriter::precomputed_narrow_klass_shift;\n+      narrowKlass nk = CompressedKlassPointers::encode_not_null(requested_k, narrow_klass_base, narrow_klass_shift);\n+#else\n+      narrowKlass nk = CompressedKlassPointers::encode_not_null(requested_k);\n+#endif\n+      k->set_prototype_header(markWord::prototype().set_narrow_klass(nk));\n+    }\n+#endif \/\/_LP64\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -461,1 +461,3 @@\n-  fake_oop->set_narrow_klass(nk);\n+  if (!UseCompactObjectHeaders) {\n+    fake_oop->set_narrow_klass(nk);\n+  }\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -59,1 +59,0 @@\n-#include \"runtime\/safepoint.hpp\"\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -105,2 +105,2 @@\n-  static const int first_vtableStub_size = 256;\n-  static const int first_itableStub_size = 512;\n+  static const int first_vtableStub_size = 64;\n+  static const int first_itableStub_size = 256;\n","filename":"src\/hotspot\/share\/code\/vtableStubs.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -79,1 +79,0 @@\n-#include \"gc\/shared\/gcForwarding.hpp\"\n@@ -91,0 +90,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -1521,1 +1521,1 @@\n-  GCForwarding::initialize(heap_rs.region(), HeapRegion::GrainWords);\n+  SlidingForwarding::initialize(heap_rs.region(), HeapRegion::GrainWords);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -42,1 +42,0 @@\n-#include \"gc\/shared\/gcForwarding.hpp\"\n@@ -46,0 +45,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -214,1 +214,2 @@\n-  GCForwarding::begin();\n+  SlidingForwarding::begin();\n+\n@@ -227,1 +228,1 @@\n-  GCForwarding::end();\n+  SlidingForwarding::end();\n@@ -401,1 +402,2 @@\n-void G1FullCollector::phase2c_prepare_serial_compaction() {\n+template <bool ALT_FWD>\n+void G1FullCollector::phase2c_prepare_serial_compaction_impl() {\n@@ -426,1 +428,1 @@\n-  G1SerialRePrepareClosure re_prepare(serial_cp, dense_prefix_top);\n+  G1SerialRePrepareClosure<ALT_FWD> re_prepare(serial_cp, dense_prefix_top);\n@@ -439,1 +441,10 @@\n-void G1FullCollector::phase2d_prepare_humongous_compaction() {\n+void G1FullCollector::phase2c_prepare_serial_compaction() {\n+  if (UseAltGCForwarding) {\n+    phase2c_prepare_serial_compaction_impl<true>();\n+  } else {\n+    phase2c_prepare_serial_compaction_impl<false>();\n+  }\n+}\n+\n+template <bool ALT_FWD>\n+void G1FullCollector::phase2d_prepare_humongous_compaction_impl() {\n@@ -457,1 +468,1 @@\n-      uint num_regions = humongous_cp->forward_humongous(hr);\n+      uint num_regions = humongous_cp->forward_humongous<ALT_FWD>(hr);\n@@ -468,0 +479,8 @@\n+void G1FullCollector::phase2d_prepare_humongous_compaction() {\n+  if (UseAltGCForwarding) {\n+    phase2d_prepare_humongous_compaction_impl<true>();\n+  } else {\n+    phase2d_prepare_humongous_compaction_impl<false>();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":26,"deletions":7,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -161,0 +161,2 @@\n+  template <bool ALT_FWD>\n+  void phase2c_prepare_serial_compaction_impl();\n@@ -162,0 +164,2 @@\n+  template <bool ALT_FWD>\n+  void phase2d_prepare_humongous_compaction_impl();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+template <bool ALT_FWD>\n@@ -44,1 +45,1 @@\n-  G1AdjustClosure* _adjust_closure;\n+  G1AdjustClosure<ALT_FWD>* _adjust_closure;\n@@ -46,1 +47,1 @@\n-  G1AdjustLiveClosure(G1AdjustClosure* cl) :\n+  G1AdjustLiveClosure(G1AdjustClosure<ALT_FWD>* cl) :\n@@ -65,1 +66,11 @@\n-    G1AdjustClosure cl(_collector);\n+    if (UseAltGCForwarding) {\n+      return do_heap_region_impl<true>(r);\n+    } else {\n+      return do_heap_region_impl<false>(r);\n+    }\n+  }\n+\n+private:\n+  template <bool ALT_FWD>\n+  bool do_heap_region_impl(HeapRegion* r) {\n+    G1AdjustClosure<ALT_FWD> cl(_collector);\n@@ -73,1 +84,1 @@\n-      G1AdjustLiveClosure adjust(&cl);\n+      G1AdjustLiveClosure<ALT_FWD> adjust(&cl);\n@@ -84,2 +95,1 @@\n-    _hrclaimer(collector->workers()),\n-    _adjust(collector) {\n+    _hrclaimer(collector->workers()) {\n@@ -89,1 +99,2 @@\n-void G1FullGCAdjustTask::work(uint worker_id) {\n+template <bool ALT_FWD>\n+void G1FullGCAdjustTask::work_impl(uint worker_id) {\n@@ -97,0 +108,1 @@\n+  G1AdjustClosure<ALT_FWD> adjust(collector());\n@@ -100,1 +112,1 @@\n-    _weak_proc_task.work(worker_id, &always_alive, &_adjust);\n+    _weak_proc_task.work(worker_id, &always_alive, &adjust);\n@@ -103,3 +115,3 @@\n-  CLDToOopClosure adjust_cld(&_adjust, ClassLoaderData::_claim_stw_fullgc_adjust);\n-  CodeBlobToOopClosure adjust_code(&_adjust, CodeBlobToOopClosure::FixRelocations);\n-  _root_processor.process_all_roots(&_adjust, &adjust_cld, &adjust_code);\n+  CLDToOopClosure adjust_cld(&adjust, ClassLoaderData::_claim_stw_fullgc_adjust);\n+  CodeBlobToOopClosure adjust_code(&adjust, CodeBlobToOopClosure::FixRelocations);\n+  _root_processor.process_all_roots(&adjust, &adjust_cld, &adjust_code);\n@@ -112,0 +124,8 @@\n+\n+void G1FullGCAdjustTask::work(uint worker_id) {\n+  if (UseAltGCForwarding) {\n+    work_impl<true>(worker_id);\n+  } else {\n+    work_impl<false>(worker_id);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCAdjustTask.cpp","additions":31,"deletions":11,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-  G1AdjustClosure          _adjust;\n@@ -43,0 +42,2 @@\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCAdjustTask.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"gc\/shared\/gcForwarding.inline.hpp\"\n@@ -34,0 +33,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -38,1 +38,2 @@\n-void G1FullGCCompactTask::G1CompactRegionClosure::clear_in_bitmap(oop obj) {\n+template <bool ALT_FWD>\n+void G1FullGCCompactTask::G1CompactRegionClosure<ALT_FWD>::clear_in_bitmap(oop obj) {\n@@ -43,1 +44,2 @@\n-size_t G1FullGCCompactTask::G1CompactRegionClosure::apply(oop obj) {\n+template <bool ALT_FWD>\n+size_t G1FullGCCompactTask::G1CompactRegionClosure<ALT_FWD>::apply(oop obj) {\n@@ -45,2 +47,2 @@\n-  if (GCForwarding::is_forwarded(obj)) {\n-    G1FullGCCompactTask::copy_object_to_new_location(obj);\n+  if (SlidingForwarding::is_forwarded(obj)) {\n+    G1FullGCCompactTask::copy_object_to_new_location<ALT_FWD>(obj);\n@@ -55,0 +57,1 @@\n+template <bool ALT_FWD>\n@@ -56,2 +59,2 @@\n-  assert(GCForwarding::is_forwarded(obj), \"Sanity!\");\n-  assert(GCForwarding::forwardee(obj) != obj, \"Object must have a new location\");\n+  assert(SlidingForwarding::is_forwarded(obj), \"Sanity!\");\n+  assert(SlidingForwarding::forwardee<ALT_FWD>(obj) != obj, \"Object must have a new location\");\n@@ -62,1 +65,1 @@\n-  HeapWord* destination = cast_from_oop<HeapWord*>(GCForwarding::forwardee(obj));\n+  HeapWord* destination = cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(obj));\n@@ -81,2 +84,7 @@\n-    G1CompactRegionClosure compact(collector()->mark_bitmap());\n-    hr->apply_to_marked_objects(collector()->mark_bitmap(), &compact);\n+    if (UseAltGCForwarding) {\n+      G1CompactRegionClosure<true> compact(collector()->mark_bitmap());\n+      hr->apply_to_marked_objects(collector()->mark_bitmap(), &compact);\n+    } else {\n+      G1CompactRegionClosure<false> compact(collector()->mark_bitmap());\n+      hr->apply_to_marked_objects(collector()->mark_bitmap(), &compact);\n+    }\n@@ -108,3 +116,2 @@\n-void G1FullGCCompactTask::humongous_compaction() {\n-  GCTraceTime(Debug, gc, phases) tm(\"Phase 4: Humonguous Compaction\", collector()->scope()->timer());\n-\n+template <bool ALT_FWD>\n+void G1FullGCCompactTask::humongous_compaction_impl() {\n@@ -113,1 +120,10 @@\n-    compact_humongous_obj(hr);\n+    compact_humongous_obj<ALT_FWD>(hr);\n+  }\n+}\n+\n+void G1FullGCCompactTask::humongous_compaction() {\n+  GCTraceTime(Debug, gc, phases) tm(\"Phase 4: Humonguous Compaction\", collector()->scope()->timer());\n+  if (UseAltGCForwarding) {\n+    humongous_compaction_impl<true>();\n+  } else {\n+    humongous_compaction_impl<false>();\n@@ -117,0 +133,1 @@\n+template <bool ALT_FWD>\n@@ -124,1 +141,1 @@\n-  HeapWord* destination = cast_from_oop<HeapWord*>(GCForwarding::forwardee(obj));\n+  HeapWord* destination = cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(obj));\n@@ -129,1 +146,1 @@\n-  copy_object_to_new_location(obj);\n+  copy_object_to_new_location<ALT_FWD>(obj);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.cpp","additions":33,"deletions":16,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+  template <bool ALT_FWD>\n@@ -47,0 +48,1 @@\n+  template <bool ALT_FWD>\n@@ -49,0 +51,3 @@\n+  template <bool ALT_FWD>\n+  void humongous_compaction_impl();\n+\n@@ -60,0 +65,1 @@\n+  template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-#include \"gc\/shared\/gcForwarding.inline.hpp\"\n@@ -31,0 +30,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -96,0 +96,1 @@\n+template <bool ALT_FWD>\n@@ -106,2 +107,2 @@\n-    GCForwarding::forward_to(object, cast_to_oop(_compaction_top));\n-    assert(GCForwarding::is_forwarded(object), \"must be forwarded\");\n+    SlidingForwarding::forward_to<ALT_FWD>(object, cast_to_oop(_compaction_top));\n+    assert(SlidingForwarding::is_forwarded(object), \"must be forwarded\");\n@@ -109,1 +110,1 @@\n-    assert(GCForwarding::is_not_forwarded(object), \"must not be forwarded\");\n+    assert(SlidingForwarding::is_not_forwarded(object), \"must not be forwarded\");\n@@ -117,0 +118,3 @@\n+template void G1FullGCCompactionPoint::forward<true>(oop object, size_t size);\n+template void G1FullGCCompactionPoint::forward<false>(oop object, size_t size);\n+\n@@ -149,0 +153,1 @@\n+template <bool ALT_FWD>\n@@ -172,2 +177,2 @@\n-  GCForwarding::forward_to(obj, cast_to_oop(dest_hr->bottom()));\n-  assert(GCForwarding::is_forwarded(obj), \"Object must be forwarded!\");\n+  SlidingForwarding::forward_to<ALT_FWD>(obj, cast_to_oop(dest_hr->bottom()));\n+  assert(SlidingForwarding::is_forwarded(obj), \"Object must be forwarded!\");\n@@ -184,0 +189,3 @@\n+template uint G1FullGCCompactionPoint::forward_humongous<true>(HeapRegion* hr);\n+template uint G1FullGCCompactionPoint::forward_humongous<false>(HeapRegion* hr);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.cpp","additions":14,"deletions":6,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+  template <bool ALT_FWD>\n@@ -58,0 +59,1 @@\n+  template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -76,0 +76,1 @@\n+template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCOopClosures.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,1 +35,1 @@\n-#include \"gc\/shared\/gcForwarding.inline.hpp\"\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -55,1 +55,2 @@\n-template <class T> inline void G1AdjustClosure::adjust_pointer(T* p) {\n+template <bool ALT_FWD>\n+template <class T> inline void G1AdjustClosure<ALT_FWD>::adjust_pointer(T* p) {\n@@ -69,2 +70,2 @@\n-  if (GCForwarding::is_forwarded(obj)) {\n-    oop forwardee = GCForwarding::forwardee(obj);\n+  if (SlidingForwarding::is_forwarded(obj)) {\n+    oop forwardee = SlidingForwarding::forwardee<ALT_FWD>(obj);\n@@ -78,2 +79,4 @@\n-inline void G1AdjustClosure::do_oop(oop* p)       { do_oop_work(p); }\n-inline void G1AdjustClosure::do_oop(narrowOop* p) { do_oop_work(p); }\n+template <bool ALT_FWD>\n+inline void G1AdjustClosure<ALT_FWD>::do_oop(oop* p)       { do_oop_work(p); }\n+template <bool ALT_FWD>\n+inline void G1AdjustClosure<ALT_FWD>::do_oop(narrowOop* p) { do_oop_work(p); }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCOopClosures.inline.hpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -107,1 +107,2 @@\n-G1FullGCPrepareTask::G1PrepareCompactLiveClosure::G1PrepareCompactLiveClosure(G1FullGCCompactionPoint* cp) :\n+template <bool ALT_FWD>\n+G1FullGCPrepareTask::G1PrepareCompactLiveClosure<ALT_FWD>::G1PrepareCompactLiveClosure(G1FullGCCompactionPoint* cp) :\n@@ -110,1 +111,2 @@\n-size_t G1FullGCPrepareTask::G1PrepareCompactLiveClosure::apply(oop object) {\n+template <bool ALT_FWD>\n+size_t G1FullGCPrepareTask::G1PrepareCompactLiveClosure<ALT_FWD>::apply(oop object) {\n@@ -112,1 +114,1 @@\n-  _cp->forward(object, size);\n+  _cp->forward<ALT_FWD>(object, size);\n@@ -118,2 +120,7 @@\n-    G1PrepareCompactLiveClosure prepare_compact(_cp);\n-    hr->apply_to_marked_objects(_bitmap, &prepare_compact);\n+    if (UseAltGCForwarding) {\n+      G1PrepareCompactLiveClosure<true> prepare_compact(_cp);\n+      hr->apply_to_marked_objects(_bitmap, &prepare_compact);\n+    } else {\n+      G1PrepareCompactLiveClosure<false> prepare_compact(_cp);\n+      hr->apply_to_marked_objects(_bitmap, &prepare_compact);\n+    }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.cpp","additions":12,"deletions":5,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -92,0 +92,1 @@\n+  template <bool ALT_FWD>\n@@ -103,0 +104,1 @@\n+template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -104,2 +105,3 @@\n-inline size_t G1SerialRePrepareClosure::apply(oop obj) {\n-  if (GCForwarding::is_forwarded(obj)) {\n+template <bool ALT_FWD>\n+inline size_t G1SerialRePrepareClosure<ALT_FWD>::apply(oop obj) {\n+  if (SlidingForwarding::is_forwarded(obj)) {\n@@ -108,1 +110,1 @@\n-    if (cast_from_oop<HeapWord*>(GCForwarding::forwardee(obj)) < _dense_prefix_top) {\n+    if (cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(obj)) < _dense_prefix_top) {\n@@ -115,1 +117,1 @@\n-  _cp->forward(obj, size);\n+  _cp->forward<ALT_FWD>(obj, size);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.inline.hpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -229,0 +229,1 @@\n+  assert(from_obj->forward_safe_klass()->is_objArray_klass(), \"must be obj array\");\n@@ -258,0 +259,1 @@\n+  assert(from_obj->forward_safe_klass()->is_objArray_klass(), \"precondition\");\n@@ -384,1 +386,1 @@\n-                                                  oop const old, Klass* klass, size_t word_sz, uint age,\n+                                                  Klass* klass, size_t word_sz, uint age,\n@@ -399,1 +401,0 @@\n-                                                   oop old,\n@@ -423,1 +424,1 @@\n-      report_promotion_event(*dest_attr, old, klass, word_sz, age, obj_ptr, node_index);\n+      report_promotion_event(*dest_attr, klass, word_sz, age, obj_ptr, node_index);\n@@ -458,4 +459,0 @@\n-  if (old_mark.is_marked()) {\n-    \/\/ Already forwarded by somebody else, return forwardee.\n-    return old->forwardee(old_mark);\n-  }\n@@ -464,9 +461,7 @@\n-  Klass* klass;\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    klass = old_mark.safe_klass();\n-  } else\n-#endif\n-  {\n-    klass = old->klass();\n-  }\n+  \/\/ NOTE: With compact headers, it is not safe to load the Klass* from o, because\n+  \/\/ that would access the mark-word, and the mark-word might change at any time by\n+  \/\/ concurrent promotion. The promoted mark-word would point to the forwardee, which\n+  \/\/ may not yet have completed copying. Therefore we must load the Klass* from\n+  \/\/ the mark-word that we have already loaded. This is safe, because we have checked\n+  \/\/ that this is not yet forwarded in the caller.\n+  Klass* klass = old->forward_safe_klass(old_mark);\n@@ -485,1 +480,1 @@\n-    obj_ptr = allocate_copy_slow(&dest_attr, old, klass, word_sz, age, node_index);\n+    obj_ptr = allocate_copy_slow(&dest_attr, klass, word_sz, age, node_index);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":12,"deletions":17,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -176,1 +176,0 @@\n-                               oop old,\n@@ -212,1 +211,1 @@\n-                              oop const old, Klass* klass, size_t word_sz, uint age,\n+                              Klass* klass, size_t word_sz, uint age,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -398,1 +398,3 @@\n-    HeapWord* test_addr = cast_from_oop<HeapWord*>(obj);\n+    \/\/ With compact headers, the objects can be one-word sized.\n+    size_t int_off = UseCompactObjectHeaders ? MIN2((size_t)1, obj->size() - 1) : 1;\n+    HeapWord* test_addr = cast_from_oop<HeapWord*>(obj) + int_off;\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -298,0 +298,1 @@\n+  assert(old->forward_safe_klass()->is_objArray_klass(), \"invariant\");\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -108,1 +108,1 @@\n-  inline void promotion_trace_event(oop new_obj, oop old_obj, Klass* klass, size_t obj_size,\n+  inline void promotion_trace_event(oop new_obj, Klass* klass, size_t obj_size,\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-inline void PSPromotionManager::promotion_trace_event(oop new_obj, oop old_obj, Klass* klass,\n+inline void PSPromotionManager::promotion_trace_event(oop new_obj, Klass* klass,\n@@ -166,9 +166,7 @@\n-  Klass* klass;\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    klass = test_mark.safe_klass();\n-  } else\n-#endif\n-  {\n-    klass = o->klass();\n-  }\n+  \/\/ NOTE: With compact headers, it is not safe to load the Klass* from o, because\n+  \/\/ that would access the mark-word, and the mark-word might change at any time by\n+  \/\/ concurrent promotion. The promoted mark-word would point to the forwardee, which\n+  \/\/ may not yet have completed copying. Therefore we must load the Klass* from\n+  \/\/ the mark-word that we have already loaded. This is safe, because we have checked\n+  \/\/ that this is not yet forwarded in the caller.\n+  Klass* klass = o->forward_safe_klass(test_mark);\n@@ -190,1 +188,1 @@\n-          promotion_trace_event(new_obj, o, klass, new_obj_size, age, false, nullptr);\n+          promotion_trace_event(new_obj, klass, new_obj_size, age, false, nullptr);\n@@ -200,1 +198,1 @@\n-            promotion_trace_event(new_obj, o, klass, new_obj_size, age, false, &_young_lab);\n+            promotion_trace_event(new_obj, klass, new_obj_size, age, false, &_young_lab);\n@@ -226,1 +224,1 @@\n-          promotion_trace_event(new_obj, o, klass, new_obj_size, age, true, nullptr);\n+          promotion_trace_event(new_obj, klass, new_obj_size, age, true, nullptr);\n@@ -236,1 +234,1 @@\n-            promotion_trace_event(new_obj, o, klass, new_obj_size, age, true, &_old_lab);\n+            promotion_trace_event(new_obj, klass, new_obj_size, age, true, &_old_lab);\n@@ -259,3 +257,13 @@\n-  if (!new_obj->mark().is_marked()) {\n-    \/\/ Parallel GC claims with a release - so other threads might access this object\n-    \/\/ after claiming and they should see the \"completed\" object.\n+  if (UseCompactObjectHeaders) {\n+    \/\/ The copy above is not atomic. Make sure we have seen the proper mark\n+    \/\/ and re-install it into the copy, so that Klass* is guaranteed to be correct.\n+    markWord mark = o->mark();\n+    if (!mark.is_marked()) {\n+      new_obj->set_mark(mark);\n+      ContinuationGCSupport::transform_stack_chunk(new_obj);\n+    } else {\n+      \/\/ If we copied a mark-word that indicates 'forwarded' state, the object\n+      \/\/ installation would not succeed. We cannot access Klass* anymore either.\n+      \/\/ Skip the transformation.\n+    }\n+  } else {\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.inline.hpp","additions":25,"deletions":17,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -846,10 +846,1 @@\n-    \/\/ Ensure that compaction spaces are in address-order.\n-    if (from()->bottom() < to()->bottom()) {\n-      eden()->set_next_compaction_space(from());\n-      from()->set_next_compaction_space(to());\n-      to()->set_next_compaction_space(nullptr);\n-    } else {\n-      eden()->set_next_compaction_space(to());\n-      to()->set_next_compaction_space(from());\n-      from()->set_next_compaction_space(nullptr);\n-    }\n+    from()->set_next_compaction_space(to());\n@@ -890,15 +881,1 @@\n-#ifdef _LP64\n-        if (UseCompactObjectHeaders) {\n-          oop forwardee = obj->forwardee();\n-          markWord header = forwardee->mark();\n-          if (header.has_displaced_mark_helper()) {\n-            header = header.displaced_mark_helper();\n-          }\n-          assert(UseCompressedClassPointers, \"assume +UseCompressedClassPointers\");\n-          narrowKlass nklass = header.narrow_klass();\n-          obj->set_mark(markWord::prototype().set_narrow_klass(nklass));\n-        } else\n-#endif\n-        {\n-          obj->init_mark();\n-        }\n+        obj->forward_safe_init_mark();\n","filename":"src\/hotspot\/share\/gc\/serial\/defNewGeneration.cpp","additions":2,"deletions":25,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -40,1 +40,0 @@\n-#include \"gc\/shared\/gcForwarding.hpp\"\n@@ -51,0 +50,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -93,1 +93,1 @@\n-  GCForwarding::begin();\n+  SlidingForwarding::begin();\n@@ -107,1 +107,1 @@\n-  GCForwarding::end();\n+  SlidingForwarding::end();\n@@ -170,3 +170,0 @@\n-  _young_marked_objects = 0;\n-  _old_marked_objects = 0;\n-\n@@ -254,9 +251,23 @@\n-  CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n-  gch->process_roots(GenCollectedHeap::SO_AllCodeCache,\n-                     &adjust_pointer_closure,\n-                     &adjust_cld_closure,\n-                     &adjust_cld_closure,\n-                     &code_closure);\n-\n-  gch->gen_process_weak_roots(&adjust_pointer_closure);\n-\n+  if (UseAltGCForwarding) {\n+    AdjustPointerClosure<true> adjust_pointer_closure;\n+    CLDToOopClosure adjust_cld_closure(&adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n+    CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n+    gch->process_roots(GenCollectedHeap::SO_AllCodeCache,\n+                       &adjust_pointer_closure,\n+                       &adjust_cld_closure,\n+                       &adjust_cld_closure,\n+                       &code_closure);\n+\n+    gch->gen_process_weak_roots(&adjust_pointer_closure);\n+  } else {\n+    AdjustPointerClosure<false> adjust_pointer_closure;\n+    CLDToOopClosure adjust_cld_closure(&adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n+    CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n+    gch->process_roots(GenCollectedHeap::SO_AllCodeCache,\n+                       &adjust_pointer_closure,\n+                       &adjust_cld_closure,\n+                       &adjust_cld_closure,\n+                       &code_closure);\n+\n+    gch->gen_process_weak_roots(&adjust_pointer_closure);\n+  }\n","filename":"src\/hotspot\/share\/gc\/serial\/genMarkSweep.cpp","additions":26,"deletions":15,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"gc\/shared\/genCollectedHeap.hpp\"\n@@ -64,1 +63,0 @@\n-CLDToOopClosure    MarkSweep::adjust_cld_closure(&adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n@@ -168,0 +166,2 @@\n+  \/\/ Do the transform while we still have the header intact,\n+  \/\/ which might include important class information.\n@@ -173,13 +173,1 @@\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    markWord real_mark = mark;\n-    if (real_mark.has_displaced_mark_helper()) {\n-      real_mark = real_mark.displaced_mark_helper();\n-    }\n-    Klass* klass = real_mark.klass();\n-    obj->set_mark(klass->prototype_header().set_marked());\n-  } else\n-#endif\n-  {\n-    obj->set_mark(markWord::prototype().set_marked());\n-  }\n+  obj->set_mark(obj->prototype_mark().set_marked());\n@@ -190,6 +178,0 @@\n-\n-  if (GenCollectedHeap::heap()->is_in_young(obj)) {\n-    _young_marked_objects++;\n-  } else {\n-    _old_marked_objects++;\n-  }\n@@ -214,3 +196,2 @@\n-AdjustPointerClosure MarkSweep::adjust_pointer_closure;\n-\n-void MarkSweep::adjust_marks() {\n+template <bool ALT_FWD>\n+void MarkSweep::adjust_marks_impl() {\n@@ -219,1 +200,1 @@\n-    PreservedMarks::adjust_preserved_mark(_preserved_marks + i);\n+    PreservedMarks::adjust_preserved_mark<ALT_FWD>(_preserved_marks + i);\n@@ -226,0 +207,8 @@\n+void MarkSweep::adjust_marks() {\n+  if (UseAltGCForwarding) {\n+    adjust_marks_impl<true>();\n+  } else {\n+    adjust_marks_impl<false>();\n+  }\n+}\n+\n@@ -244,3 +233,0 @@\n-size_t MarkSweep::_young_marked_objects = 0;\n-size_t MarkSweep::_old_marked_objects = 0;\n-\n","filename":"src\/hotspot\/share\/gc\/serial\/markSweep.cpp","additions":14,"deletions":28,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -54,1 +54,0 @@\n-class AdjustPointerClosure;\n@@ -88,1 +87,0 @@\n-  friend class AdjustPointerClosure;\n@@ -119,4 +117,1 @@\n-  static size_t _young_marked_objects;\n-  static size_t _old_marked_objects;\n-\n-public:\n+ public:\n@@ -131,2 +126,0 @@\n-  static AdjustPointerClosure adjust_pointer_closure;\n-  static CLDToOopClosure      adjust_cld_closure;\n@@ -148,0 +141,1 @@\n+  template <bool ALT_FWD>\n@@ -152,1 +146,2 @@\n-  template <class T> static inline void adjust_pointer(T* p);\n+  template <bool ALT_FWD, class T>\n+  static void adjust_pointer(T* p);\n@@ -158,0 +153,3 @@\n+  template <bool ALT_FWD>\n+  static void adjust_marks_impl();\n+\n@@ -185,0 +183,1 @@\n+template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/serial\/markSweep.hpp","additions":8,"deletions":9,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,1 +30,0 @@\n-#include \"gc\/shared\/gcForwarding.inline.hpp\"\n@@ -35,0 +34,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -43,1 +43,2 @@\n-template <class T> inline void MarkSweep::adjust_pointer(T* p) {\n+template <bool ALT_FWD, class T>\n+inline void MarkSweep::adjust_pointer(T* p) {\n@@ -49,2 +50,2 @@\n-    if (GCForwarding::is_forwarded(obj)) {\n-      oop new_obj = GCForwarding::forwardee(obj);\n+    if (SlidingForwarding::is_forwarded(obj)) {\n+      oop new_obj = SlidingForwarding::forwardee<ALT_FWD>(obj);\n@@ -57,0 +58,1 @@\n+template <bool ALT_FWD>\n@@ -58,3 +60,3 @@\n-void AdjustPointerClosure::do_oop_work(T* p)           { MarkSweep::adjust_pointer(p); }\n-inline void AdjustPointerClosure::do_oop(oop* p)       { do_oop_work(p); }\n-inline void AdjustPointerClosure::do_oop(narrowOop* p) { do_oop_work(p); }\n+void AdjustPointerClosure<ALT_FWD>::do_oop_work(T* p)           { MarkSweep::adjust_pointer<ALT_FWD>(p); }\n+template <bool ALT_FWD>\n+inline void AdjustPointerClosure<ALT_FWD>::do_oop(oop* p)       { do_oop_work(p); }\n@@ -62,0 +64,4 @@\n+template <bool ALT_FWD>\n+inline void AdjustPointerClosure<ALT_FWD>::do_oop(narrowOop* p) { do_oop_work(p); }\n+\n+template <bool ALT_FWD>\n@@ -63,1 +69,2 @@\n-  return obj->oop_iterate_size(&MarkSweep::adjust_pointer_closure);\n+  AdjustPointerClosure<ALT_FWD> adjust_pointer_closure;\n+  return obj->oop_iterate_size(&adjust_pointer_closure);\n","filename":"src\/hotspot\/share\/gc\/serial\/markSweep.inline.hpp","additions":16,"deletions":9,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -231,0 +231,2 @@\n+  \/\/ With compact headers, we can't safely access the class, due\n+  \/\/ to possibly forwarded objects.\n@@ -261,4 +263,2 @@\n-  int header_size_in_bytes = arrayOopDesc::base_offset_in_bytes(T_INT);\n-  assert(header_size_in_bytes % sizeof(jint) == 0, \"must be aligned to int\");\n-  int header_size_in_ints = header_size_in_bytes \/ sizeof(jint);\n-  _filler_array_max_size = align_object_size((header_size_in_ints + max_len) \/ elements_per_word);\n+  _filler_array_max_size = align_object_size(filler_array_hdr_size() +\n+                                             max_len \/ elements_per_word);\n@@ -405,0 +405,7 @@\n+\/\/ Returns the header size in words aligned to the requirements of the\n+\/\/ array object type.\n+static int int_array_header_size() {\n+  size_t typesize_in_bytes = arrayOopDesc::header_size_in_bytes();\n+  return (int)align_up(typesize_in_bytes, HeapWordSize)\/HeapWordSize;\n+}\n+\n@@ -414,3 +421,1 @@\n-  int header_size_in_bytes = typeArrayOopDesc::base_offset_in_bytes(T_INT);\n-  assert(header_size_in_bytes % sizeof(jint) == 0, \"header size must align to int\");\n-  size_t max_int_size = header_size_in_bytes \/ HeapWordSize +\n+  size_t max_int_size = int_array_header_size() +\n@@ -422,0 +427,4 @@\n+size_t CollectedHeap::filler_array_hdr_size() {\n+  return align_object_offset(int_array_header_size()); \/\/ align to Long\n+}\n+\n@@ -423,2 +432,1 @@\n-  int aligned_header_size_words = align_up(arrayOopDesc::base_offset_in_bytes(T_INT), HeapWordSize) \/ HeapWordSize;\n-  return align_object_size(aligned_header_size_words); \/\/ align to MinObjAlignment\n+  return align_object_size(filler_array_hdr_size()); \/\/ align to MinObjAlignment\n@@ -428,3 +436,2 @@\n-  int payload_start = align_up(arrayOopDesc::base_offset_in_bytes(T_INT), HeapWordSize) \/ HeapWordSize;\n-  Copy::fill_to_words(start + payload_start,\n-                      words - payload_start, value);\n+  Copy::fill_to_words(start + filler_array_hdr_size(),\n+                      words - filler_array_hdr_size(), value);\n@@ -454,3 +461,2 @@\n-  const size_t payload_size_bytes = words * HeapWordSize - arrayOopDesc::base_offset_in_bytes(T_INT);\n-  assert(payload_size_bytes % sizeof(jint) == 0, \"must be int aligned\");\n-  const size_t len = payload_size_bytes \/ sizeof(jint);\n+  const size_t payload_size = words - filler_array_hdr_size();\n+  const size_t len = payload_size * HeapWordSize \/ sizeof(jint);\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.cpp","additions":21,"deletions":15,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -167,0 +167,1 @@\n+  static inline size_t filler_array_hdr_size();\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1,57 +0,0 @@\n-\/*\n- * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"gc\/shared\/gcForwarding.hpp\"\n-#include \"gc\/shared\/slidingForwarding.hpp\"\n-#include \"runtime\/globals.hpp\"\n-\n-SlidingForwarding* GCForwarding::_sliding_forwarding = nullptr;\n-\n-void GCForwarding::initialize(MemRegion heap, size_t region_size_words) {\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    assert(_sliding_forwarding == nullptr, \"only call this once\");\n-    _sliding_forwarding = new SlidingForwarding(heap, region_size_words);\n-  }\n-#endif\n-}\n-\n-void GCForwarding::begin() {\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    assert(_sliding_forwarding != nullptr, \"expect sliding forwarding initialized\");\n-    _sliding_forwarding->begin();\n-  }\n-#endif\n-}\n-\n-void GCForwarding::end() {\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    assert(_sliding_forwarding != nullptr, \"expect sliding forwarding initialized\");\n-    _sliding_forwarding->end();\n-  }\n-#endif\n-}\n","filename":"src\/hotspot\/share\/gc\/shared\/gcForwarding.cpp","additions":0,"deletions":57,"binary":false,"changes":57,"status":"deleted"},{"patch":"@@ -1,49 +0,0 @@\n-\/*\n- * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_SHARED_GCFORWARDING_HPP\n-#define SHARE_GC_SHARED_GCFORWARDING_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-#include \"memory\/memRegion.hpp\"\n-#include \"oops\/oopsHierarchy.hpp\"\n-\n-class SlidingForwarding;\n-\n-class GCForwarding : public AllStatic {\n-private:\n-  static SlidingForwarding* _sliding_forwarding;\n-\n-public:\n-  static void initialize(MemRegion heap, size_t region_size_words_shift);\n-  static void begin();\n-  static void end();\n-\n-  static inline bool is_forwarded(oop obj);\n-  static inline bool is_not_forwarded(oop obj);\n-  static inline oop forwardee(oop obj);\n-  static inline void forward_to(oop obj, oop fwd);\n-};\n-\n-#endif \/\/ SHARE_GC_SHARED_GCFORWARDING_HPP\n","filename":"src\/hotspot\/share\/gc\/shared\/gcForwarding.hpp","additions":0,"deletions":49,"binary":false,"changes":49,"status":"deleted"},{"patch":"@@ -1,61 +0,0 @@\n-\/*\n- * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_SHARED_GCFORWARDING_INLINE_HPP\n-#define SHARE_GC_SHARED_GCFORWARDING_INLINE_HPP\n-\n-#include \"gc\/shared\/gcForwarding.hpp\"\n-#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-\n-inline bool GCForwarding::is_forwarded(oop obj) {\n-  return obj->is_forwarded();\n-}\n-\n-inline bool GCForwarding::is_not_forwarded(oop obj) {\n-  return !obj->is_forwarded();\n-}\n-\n-inline oop GCForwarding::forwardee(oop obj) {\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    assert(_sliding_forwarding != nullptr, \"expect sliding forwarding initialized\");\n-    return _sliding_forwarding->forwardee(obj);\n-  } else\n-#endif\n-    return obj->forwardee();\n-}\n-\n-inline void GCForwarding::forward_to(oop obj, oop fwd) {\n-#ifdef _LP64\n-  if (UseCompactObjectHeaders) {\n-    assert(_sliding_forwarding != nullptr, \"expect sliding forwarding initialized\");\n-    _sliding_forwarding->forward_to(obj, fwd);\n-    assert(forwardee(obj) == fwd, \"must be forwarded to correct forwardee\");\n-  } else\n-#endif\n-    obj->forward_to(fwd);\n-}\n-\n-#endif \/\/ SHARE_GC_SHARED_GCFORWARDING_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/shared\/gcForwarding.inline.hpp","additions":0,"deletions":61,"binary":false,"changes":61,"status":"deleted"},{"patch":"@@ -695,2 +695,6 @@\n-          constraint(GCCardSizeInBytesConstraintFunc,AtParse)\n-  \/\/ end of GC_FLAGS\n+          constraint(GCCardSizeInBytesConstraintFunc,AtParse)               \\\n+                                                                            \\\n+  product(bool, UseAltGCForwarding, false, EXPERIMENTAL,                    \\\n+          \"Use alternative GC forwarding that preserves object headers\")    \\\n+\n+\/\/ end of GC_FLAGS\n","filename":"src\/hotspot\/share\/gc\/shared\/gc_globals.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -42,1 +42,0 @@\n-#include \"gc\/shared\/gcForwarding.hpp\"\n@@ -58,0 +57,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -135,1 +135,1 @@\n-  GCForwarding::initialize(_reserved, SpaceAlignment);\n+  SlidingForwarding::initialize(_reserved, SpaceAlignment \/ HeapWordSize);\n","filename":"src\/hotspot\/share\/gc\/shared\/genCollectedHeap.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -63,11 +63,0 @@\n-size_t MarkBitMap::count_marked(MemRegion mr) {\n-  MemRegion intersection = mr.intersection(_covered);\n-  assert(!intersection.is_empty(),\n-         \"Given range from \" PTR_FORMAT \" to \" PTR_FORMAT \" is completely outside the heap\",\n-         p2i(mr.start()), p2i(mr.end()));\n-  \/\/ convert address range into offset range\n-  size_t beg = addr_to_offset(intersection.start());\n-  size_t end = addr_to_offset(intersection.end());\n-  return _bm.count_one_bits(beg, end);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/markBitMap.cpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -101,2 +101,0 @@\n-\n-  size_t count_marked(MemRegion mr);\n","filename":"src\/hotspot\/share\/gc\/shared\/markBitMap.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"gc\/shared\/gcForwarding.inline.hpp\"\n@@ -28,0 +27,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -44,4 +44,6 @@\n-void PreservedMarks::adjust_preserved_mark(PreservedMark* elem) {\n-  oop obj = elem->get_oop();\n-  if (GCForwarding::is_forwarded(obj)) {\n-    elem->set_oop(GCForwarding::forwardee(obj));\n+template <bool ALT_FWD>\n+void PreservedMarks::adjust_during_full_gc_impl() {\n+  StackIterator<PreservedMark, mtGC> iter(_stack);\n+  while (!iter.is_empty()) {\n+    PreservedMark* elem = iter.next_addr();\n+    adjust_preserved_mark<ALT_FWD>(elem);\n@@ -52,4 +54,4 @@\n-  StackIterator<PreservedMark, mtGC> iter(_stack);\n-  while (!iter.is_empty()) {\n-    PreservedMark* elem = iter.next_addr();\n-    adjust_preserved_mark(elem);\n+  if (UseAltGCForwarding) {\n+    adjust_during_full_gc_impl<true>();\n+  } else {\n+    adjust_during_full_gc_impl<false>();\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.cpp","additions":12,"deletions":10,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -58,0 +58,3 @@\n+  template <bool ALT_FWD>\n+  void adjust_during_full_gc_impl();\n+\n@@ -68,1 +71,2 @@\n-  static void adjust_preserved_mark(PreservedMark* elem);\n+  template <bool ALT_FWD>\n+  static inline void adjust_preserved_mark(PreservedMark* elem);\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -63,0 +64,8 @@\n+template <bool ALT_FWD>\n+inline void PreservedMarks::adjust_preserved_mark(PreservedMark* elem) {\n+  oop obj = elem->get_oop();\n+  if (obj->is_forwarded()) {\n+    elem->set_oop(SlidingForwarding::forwardee<ALT_FWD>(obj));\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.inline.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -32,2 +32,2 @@\n-#ifdef _LP64\n-\n+\/\/ We cannot use 0, because that may already be a valid base address in zero-based heaps.\n+\/\/ 0x1 is safe because heap base addresses must be aligned by much larger alignment\n@@ -36,15 +36,32 @@\n-SlidingForwarding::SlidingForwarding(MemRegion heap, size_t region_size_words)\n-  : _heap_start(heap.start()),\n-    _num_regions(((heap.end() - heap.start()) \/ region_size_words) + 1),\n-    _region_size_words_shift(log2i_exact(region_size_words)),\n-  _target_base_table(nullptr),\n-  _fallback_table(nullptr) {\n-  assert(_region_size_words_shift <= NUM_COMPRESSED_BITS, \"regions must not be larger than maximum addressing bits allow\");\n-  size_t heap_size_words = heap.end() - heap.start();\n-  if (UseSerialGC && heap_size_words <= (1 << NUM_COMPRESSED_BITS)) {\n-    \/\/ In this case we can treat the whole heap as a single region and\n-    \/\/ make the encoding very simple.\n-    _num_regions = 1;\n-    _region_size_words_shift = log2i_exact(round_up_power_of_2(heap_size_words));\n-  }\n-}\n+HeapWord* SlidingForwarding::_heap_start = nullptr;\n+size_t SlidingForwarding::_region_size_words = 0;\n+size_t SlidingForwarding::_heap_start_region_bias = 0;\n+size_t SlidingForwarding::_num_regions = 0;\n+uint SlidingForwarding::_region_size_bytes_shift = 0;\n+uintptr_t SlidingForwarding::_region_mask = 0;\n+HeapWord** SlidingForwarding::_biased_bases[SlidingForwarding::NUM_TARGET_REGIONS] = { nullptr, nullptr };\n+HeapWord** SlidingForwarding::_bases_table = nullptr;\n+SlidingForwarding::FallbackTable* SlidingForwarding::_fallback_table = nullptr;\n+\n+void SlidingForwarding::initialize(MemRegion heap, size_t region_size_words) {\n+#ifdef _LP64\n+  if (UseAltGCForwarding) {\n+    _heap_start = heap.start();\n+\n+    \/\/ If the heap is small enough to fit directly into the available offset bits,\n+    \/\/ and we are running Serial GC, we can treat the whole heap as a single region\n+    \/\/ if it happens to be aligned to allow biasing.\n+    size_t rounded_heap_size = round_up_power_of_2(heap.byte_size());\n+\n+    if (UseSerialGC && (heap.word_size() <= (1 << NUM_OFFSET_BITS)) &&\n+        is_aligned((uintptr_t)_heap_start, rounded_heap_size)) {\n+      _num_regions = 1;\n+      _region_size_words = heap.word_size();\n+      _region_size_bytes_shift = log2i_exact(rounded_heap_size);\n+    } else {\n+      _num_regions = align_up(pointer_delta(heap.end(), heap.start()), region_size_words) \/ region_size_words;\n+      _region_size_words = region_size_words;\n+      _region_size_bytes_shift = log2i_exact(_region_size_words) + LogHeapWordSize;\n+    }\n+    _heap_start_region_bias = (uintptr_t)_heap_start >> _region_size_bytes_shift;\n+    _region_mask = ~((uintptr_t(1) << _region_size_bytes_shift) - 1);\n@@ -52,6 +69,5 @@\n-SlidingForwarding::~SlidingForwarding() {\n-  if (_target_base_table != nullptr) {\n-    FREE_C_HEAP_ARRAY(HeapWord*, _target_base_table);\n-  }\n-  if (_fallback_table != nullptr) {\n-    delete _fallback_table;\n+    guarantee((_heap_start_region_bias << _region_size_bytes_shift) == (uintptr_t)_heap_start, \"must be aligned: _heap_start_region_bias: \" SIZE_FORMAT \", _region_size_byte_shift: %u, _heap_start: \" PTR_FORMAT, _heap_start_region_bias, _region_size_bytes_shift, p2i(_heap_start));\n+\n+    assert(_region_size_words >= 1, \"regions must be at least a word large\");\n+    assert(_bases_table == nullptr, \"should not be initialized yet\");\n+    assert(_fallback_table == nullptr, \"should not be initialized yet\");\n@@ -59,0 +75,1 @@\n+#endif\n@@ -62,5 +79,13 @@\n-  assert(_target_base_table == nullptr, \"Should be uninitialized\");\n-  _target_base_table = NEW_C_HEAP_ARRAY(HeapWord*, _num_regions * NUM_TARGET_REGIONS, mtGC);\n-  size_t max = _num_regions * NUM_TARGET_REGIONS;\n-  for (size_t i = 0; i < max; i++) {\n-    _target_base_table[i] = UNUSED_BASE;\n+#ifdef _LP64\n+  if (UseAltGCForwarding) {\n+    assert(_bases_table == nullptr, \"should not be initialized yet\");\n+    assert(_fallback_table == nullptr, \"should not be initialized yet\");\n+\n+    size_t max = _num_regions * NUM_TARGET_REGIONS;\n+    _bases_table = NEW_C_HEAP_ARRAY(HeapWord*, max, mtGC);\n+    HeapWord** biased_start = _bases_table - _heap_start_region_bias;\n+    _biased_bases[0] = biased_start;\n+    _biased_bases[1] = biased_start + _num_regions;\n+    for (size_t i = 0; i < max; i++) {\n+      _bases_table[i] = UNUSED_BASE;\n+    }\n@@ -68,0 +93,1 @@\n+#endif\n@@ -71,5 +97,5 @@\n-  assert(_target_base_table != nullptr, \"Should be initialized\");\n-  FREE_C_HEAP_ARRAY(HeapWord*, _target_base_table);\n-  _target_base_table = nullptr;\n-\n-  if (_fallback_table != nullptr) {\n+#ifdef _LP64\n+  if (UseAltGCForwarding) {\n+    assert(_bases_table != nullptr, \"should be initialized\");\n+    FREE_C_HEAP_ARRAY(HeapWord*, _bases_table);\n+    _bases_table = nullptr;\n@@ -79,0 +105,1 @@\n+#endif\n@@ -83,1 +110,1 @@\n-    _fallback_table = new FallbackTable();\n+    _fallback_table = new (mtGC) FallbackTable();\n@@ -85,1 +112,1 @@\n-  _fallback_table->forward_to(from, to);\n+  _fallback_table->put_when_absent(from, to);\n@@ -88,3 +115,5 @@\n-HeapWord* SlidingForwarding::fallback_forwardee(HeapWord* from) const {\n-  if (_fallback_table == nullptr) {\n-    return nullptr;\n+HeapWord* SlidingForwarding::fallback_forwardee(HeapWord* from) {\n+  assert(_fallback_table != nullptr, \"fallback table must be present\");\n+  HeapWord** found = _fallback_table->get(from);\n+  if (found != nullptr) {\n+    return *found;\n@@ -92,54 +121,1 @@\n-    return _fallback_table->forwardee(from);\n-  }\n-}\n-\n-FallbackTable::FallbackTable() {\n-  for (size_t i = 0; i < TABLE_SIZE; i++) {\n-    _table[i]._next = nullptr;\n-    _table[i]._from = nullptr;\n-    _table[i]._to   = nullptr;\n-  }\n-}\n-\n-FallbackTable::~FallbackTable() {\n-  for (size_t i = 0; i < TABLE_SIZE; i++) {\n-    FallbackTableEntry* entry = _table[i]._next;\n-    while (entry != nullptr) {\n-      FallbackTableEntry* next = entry->_next;\n-      FREE_C_HEAP_OBJ(entry);\n-      entry = next;\n-    }\n-  }\n-}\n-\n-size_t FallbackTable::home_index(HeapWord* from) {\n-  uint64_t val = reinterpret_cast<uint64_t>(from);\n-  val *= 0xbf58476d1ce4e5b9ull;\n-  val ^= val >> 56;\n-  val *= 0x94d049bb133111ebull;\n-  val = (val * 11400714819323198485llu) >> (64 - log2i_exact(TABLE_SIZE));\n-  assert(val < TABLE_SIZE, \"must fit in table: val: \" UINT64_FORMAT \", table-size: \" UINTX_FORMAT \", table-size-bits: %d\", val, TABLE_SIZE, log2i_exact(TABLE_SIZE));\n-  return static_cast<size_t>(val);\n-}\n-\n-void FallbackTable::forward_to(HeapWord* from, HeapWord* to) {\n-  size_t idx = home_index(from);\n-  if (_table[idx]._from != nullptr) {\n-    FallbackTableEntry* entry = NEW_C_HEAP_OBJ(FallbackTableEntry, mtGC);\n-    entry->_next = _table[idx]._next;\n-    entry->_from = _table[idx]._from;\n-    entry->_to = _table[idx]._to;\n-    _table[idx]._next = entry;\n-  }\n-  _table[idx]._from = from;\n-  _table[idx]._to   = to;\n-}\n-\n-HeapWord* FallbackTable::forwardee(HeapWord* from) const {\n-  size_t idx = home_index(from);\n-  const FallbackTableEntry* entry = &_table[idx];\n-  while (entry != nullptr) {\n-    if (entry->_from == from) {\n-      return entry->_to;\n-    }\n-    entry = entry->_next;\n+    return nullptr;\n@@ -147,1 +123,0 @@\n-  return nullptr;\n@@ -149,2 +124,0 @@\n-\n-#endif \/\/ _LP64\n","filename":"src\/hotspot\/share\/gc\/shared\/slidingForwarding.cpp","additions":68,"deletions":95,"binary":false,"changes":163,"status":"modified"},{"patch":"@@ -29,2 +29,0 @@\n-#ifdef _LP64\n-\n@@ -35,2 +33,2 @@\n-\n-class FallbackTable;\n+#include \"utilities\/fastHash.hpp\"\n+#include \"utilities\/resourceHash.hpp\"\n@@ -40,3 +38,6 @@\n- * that has been specifically designed for sliding compaction GCs.\n- * It avoids overriding the compressed class pointer in the upper bits of the header, which would otherwise\n- * be lost. SlidingForwarding requires only small side tables and guarantees constant-time access and modification.\n+ * that has been specifically designed for sliding compaction GCs and compact object headers. With compact object\n+ * headers, we store the compressed class pointer in the header, which would be overwritten by full forwarding\n+ * pointer, if we allow the legacy forwarding code to act. This would lose the class information for the object,\n+ * which is required later in GC cycle to iterate the reference fields and get the object size for copying.\n+ *\n+ * SlidingForwarding requires only small side tables and guarantees constant-time access and modification.\n@@ -45,5 +46,8 @@\n- * We divide the heap into number of logical regions. Each region spans maximum of 2^NUM_COMPRESSED_BITS words.\n- * We take advantage of the fact that sliding compaction can forward objects from one region to a maximum of\n- * two regions (including itself, but that does not really matter). We need 1 bit to indicate which region is forwarded\n- * into. We also currently require the two lowest header bits to indicate that the object is forwarded. In addition to that,\n- * we use 1 more bit to indicate that we should use a fallback-lookup-table instead of using the sliding encoding.\n+ * We divide the heap into number of logical regions. Each region spans maximum of 2^NUM_OFFSET_BITS words.\n+ *\n+ * The key advantage of sliding compaction for encoding efficiency: it can forward objects from one region to a\n+ * maximum of two regions. This is an intuitive property: when we slide the compact region full of data, it can\n+ * only span two adjacent regions. This property allows us to use the off-side table to record the addresses of\n+ * two target regions. The table holds N*2 entries for N logical regions. For each region, it gives the base\n+ * address of the two target regions, or a special placeholder if not used. A single bit in forwarding would\n+ * indicate to which of the two \"to\" regions the object is forwarded into.\n@@ -51,2 +55,2 @@\n- * For addressing, we need a table with N*2 entries, for N logical regions. For each region, it gives the base\n- * address of the two target regions, or a special placeholder if not used.\n+ * This encoding efficiency allows to store the forwarding information in the object header _together_ with the\n+ * compressed class pointer.\n@@ -54,12 +58,1 @@\n- * Adding a forwarding then works as follows:\n- * Given an original address 'orig', and a 'target' address:\n- * - Look-up first target base of region of orig. If it is already established and the region\n- *   that 'target' is in, then use it in step 3. If not yet used, establish it to be the base of region of target\n-     address. Use that base in step 3.\n- * - Else, if first target base is already used, check second target base. This must either be unused, or the\n- *   base of the region of our target address. If unused, establish it to be the base of the region of our target\n- *   address. Use that base for next step.\n- * - Now we found a base address. Encode the target address with that base into lowest NUM_COMPRESSED_BITS bits, and shift\n- *   that up by 4 bits. Set the 3rd bit if we used the secondary target base, otherwise leave it at 0. Set the\n- *   lowest two bits to indicate that the object has been forwarded. Store that in the lowest 32 bits of the\n- *   original object's header.\n+ * When recording the sliding forwarding, the mark word would look roughly like this:\n@@ -67,5 +60,8 @@\n- * Similarily, looking up the target address, given an original object address works as follows:\n- * - Load lowest 32 from original object header. Extract target region bit and compressed address bits.\n- * - Depending on target region bit, load base address from the target base table by looking up the corresponding entry\n- *   for the region of the original object.\n- * - Decode the target address by using the target base address and the compressed address bits.\n+ *   64                              32                                0\n+ *    [................................OOOOOOOOOOOOOOOOOOOOOOOOOOOOAFTT]\n+ *                                                                    ^----- normal lock bits, would record \"object is forwarded\"\n+ *                                                                  ^------- fallback bit (explained below)\n+ *                                                                 ^-------- alternate region select\n+ *                                     ^------------------------------------ in-region offset\n+ *     ^-------------------------------------------------------------------- protected area, *not touched* by this code, useful for\n+ *                                                                           compressed class pointer with compact object headers\n@@ -73,6 +69,20 @@\n- * One complication is that G1 serial compaction breaks the assumption that we only forward\n- * to two target regions. When that happens, we initialize a fallback-hashtable for storing those extra\n- * forwardings, and set the 4th bit in the header to indicate that the forwardee is not encoded but\n- * should be looked-up in the hashtable. G1 serial compaction is not very common -  it is the last-last-ditch\n- * GC that is used when the JVM is scrambling to squeeze more space out of the heap, and at that\n- * point, ultimate performance is no longer the main concern.\n+ * Adding a forwarding then generally works as follows:\n+ *   1. Compute the \"to\" offset in the \"to\" region, this gives \"offset\".\n+ *   2. Check if the primary \"from\" offset at base table contains \"to\" region base, use it.\n+ *      If not usable, continue to next step. If usable, set \"alternate\" = \"false\" and jump to (4).\n+ *   3. Check if the alternate \"from\" offset at base table contains \"to\" region base, use it.\n+ *      This gives us \"alternate\" = \"true\". This should always complete for sliding forwarding.\n+ *   4. Compute the mark word from \"offset\" and \"alternate\", write it out\n+ *\n+ * Similarly, looking up the target address, given an original object address generally works as follows:\n+ *   1. Load the mark from object, and decode \"offset\" and \"alternate\" from there\n+ *   2. Compute the \"from\" base offset from the object\n+ *   3. Look up \"to\" region base from the base table either at primary or alternate indices, using \"alternate\" flag\n+ *   4. Compute the \"to\" address from \"to\" region base and \"offset\"\n+ *\n+ * This algorithm is broken by G1 last-ditch serial compaction: there, object from a single region can be\n+ * forwarded to multiple, more than two regions. To deal with that, we initialize a fallback-hashtable for\n+ * storing those extra forwardings, and set another bit in the header to indicate that the forwardee is not\n+ * encoded but should be looked-up in the hashtable. G1 serial compaction is not very common - it is the\n+ * last-last-ditch GC that is used when the JVM is scrambling to squeeze more space out of the heap, and at\n+ * that point, ultimate performance is no longer the main concern.\n@@ -80,1 +90,1 @@\n-class SlidingForwarding : public CHeapObj<mtGC> {\n+class SlidingForwarding : public AllStatic {\n@@ -82,1 +92,26 @@\n-  static const uintptr_t MARK_LOWER_HALF_MASK = 0xffffffff;\n+\n+  \/*\n+   * A simple hash-table that acts as fallback for the sliding forwarding.\n+   * This is used in the case of G1 serial compaction, which violates the\n+   * assumption of sliding forwarding that each object of any region is only\n+   * ever forwarded to one of two target regions. At this point, the GC is\n+   * scrambling to free up more Java heap memory, and therefore performance\n+   * is not the major concern.\n+   *\n+   * The implementation is a straightforward open hashtable.\n+   * It is a single-threaded (not thread-safe) implementation, and that\n+   * is sufficient because G1 serial compaction is single-threaded.\n+   *\/\n+  inline static unsigned hash(HeapWord* const& from) {\n+    uint64_t val = reinterpret_cast<uint64_t>(from);\n+    uint64_t hash = FastHash::get_hash64(val, UCONST64(0xAAAAAAAAAAAAAAAA));\n+    return checked_cast<unsigned>(hash >> 32);\n+  }\n+  inline static bool equals(HeapWord* const& lhs, HeapWord* const& rhs) {\n+    return lhs == rhs;\n+  }\n+  typedef ResourceHashtable<HeapWord* \/* key-type *\/, HeapWord* \/* value-type *\/,\n+                            1024 \/* size *\/, AnyObj::C_HEAP \/* alloc-type *\/, mtGC,\n+                            SlidingForwarding::hash, SlidingForwarding::equals> FallbackTable;\n+\n+  static const uintptr_t MARK_LOWER_HALF_MASK = right_n_bits(32);\n@@ -85,2 +120,1 @@\n-  \/\/ The 3rd bit (fallback-bit) indicates that the forwardee should be\n-  \/\/ looked-up in a fallback-table.\n+  \/\/ The next bit indicates that the forwardee should be looked-up in a fallback-table.\n@@ -90,3 +124,0 @@\n-  \/\/ The 4th bit selects the target region.\n-  static const int REGION_SHIFT = FALLBACK_SHIFT + FALLBACK_BITS;\n-  static const int REGION_BITS = 1;\n@@ -94,2 +125,5 @@\n-  \/\/ The compressed address bits start here.\n-  static const int COMPRESSED_BITS_SHIFT = REGION_SHIFT + REGION_BITS;\n+  \/\/ Next bit selects the target region\n+  static const int ALT_REGION_SHIFT = FALLBACK_SHIFT + FALLBACK_BITS;\n+  static const int ALT_REGION_BITS = 1;\n+  \/\/ This will be \"2\" always, but expose it as named constant for clarity\n+  static const size_t NUM_TARGET_REGIONS = 1 << ALT_REGION_BITS;\n@@ -97,2 +131,2 @@\n-  \/\/ How many bits we use for the compressed pointer\n-  static const int NUM_COMPRESSED_BITS = 32 - COMPRESSED_BITS_SHIFT;\n+  \/\/ The offset bits start then\n+  static const int OFFSET_BITS_SHIFT = ALT_REGION_SHIFT + ALT_REGION_BITS;\n@@ -100,1 +134,2 @@\n-  static const size_t NUM_TARGET_REGIONS = 1 << REGION_BITS;\n+  \/\/ How many bits we use for the offset\n+  static const int NUM_OFFSET_BITS = 32 - OFFSET_BITS_SHIFT;\n@@ -102,2 +137,1 @@\n-  \/\/ Indicates an usused base address in the target base table. We cannot use 0, because that may already be\n-  \/\/ a valid base address in zero-based heaps. 0x1 is safe because heap base addresses must be aligned by 2^X.\n+  \/\/ Indicates an unused base address in the target base table.\n@@ -106,6 +140,2 @@\n-  HeapWord*  const _heap_start;\n-  size_t           _num_regions;\n-  size_t           _region_size_words_shift;\n-  HeapWord**       _target_base_table;\n-\n-  FallbackTable* _fallback_table;\n+  static HeapWord*      _heap_start;\n+  static size_t         _region_size_words;\n@@ -113,2 +143,4 @@\n-  inline size_t region_index_containing(HeapWord* addr) const;\n-  inline bool region_contains(HeapWord* region_base, HeapWord* addr) const;\n+  static size_t         _heap_start_region_bias;\n+  static size_t         _num_regions;\n+  static uint           _region_size_bytes_shift;\n+  static uintptr_t      _region_mask;\n@@ -116,2 +148,4 @@\n-  inline uintptr_t encode_forwarding(HeapWord* original, HeapWord* target);\n-  inline HeapWord* decode_forwarding(HeapWord* original, uintptr_t encoded) const;\n+  \/\/ The target base table memory.\n+  static HeapWord**     _bases_table;\n+  \/\/ Entries into the target base tables, biased to the start of the heap.\n+  static HeapWord**     _biased_bases[NUM_TARGET_REGIONS];\n@@ -119,2 +153,1 @@\n-  void fallback_forward_to(HeapWord* from, HeapWord* to);\n-  HeapWord* fallback_forwardee(HeapWord* from) const;\n+  static FallbackTable* _fallback_table;\n@@ -122,3 +155,1 @@\n-public:\n-  SlidingForwarding(MemRegion heap, size_t region_size_words);\n-  ~SlidingForwarding();\n+  static inline size_t biased_region_index_containing(HeapWord* addr);\n@@ -126,2 +157,2 @@\n-  void begin();\n-  void end();\n+  static inline uintptr_t encode_forwarding(HeapWord* from, HeapWord* to);\n+  static inline HeapWord* decode_forwarding(HeapWord* from, uintptr_t encoded);\n@@ -129,3 +160,2 @@\n-  inline void forward_to(oop original, oop target);\n-  inline oop forwardee(oop original) const;\n-};\n+  static void fallback_forward_to(HeapWord* from, HeapWord* to);\n+  static HeapWord* fallback_forwardee(HeapWord* from);\n@@ -133,19 +163,2 @@\n-\/*\n- * A simple hash-table that acts as fallback for the sliding forwarding.\n- * This is used in the case of G1 serial compactio, which violates the\n- * assumption of sliding forwarding that each object of any region is only\n- * ever forwarded to one of two target regions. At this point, the GC is\n- * scrambling to free up more Java heap memory, and therefore performance\n- * is not the major concern.\n- *\n- * The implementation is a straightforward open hashtable.\n- * It is a single-threaded (not thread-safe) implementation, and that\n- * is sufficient because G1 serial compaction is single-threaded.\n- *\/\n-class FallbackTable : public CHeapObj<mtGC>{\n-private:\n-  struct FallbackTableEntry {\n-    FallbackTableEntry* _next;\n-    HeapWord* _from;\n-    HeapWord* _to;\n-  };\n+  static inline void forward_to_impl(oop from, oop to);\n+  static inline oop forwardee_impl(oop from);\n@@ -153,2 +166,2 @@\n-  static const size_t TABLE_SIZE = 128;\n-  FallbackTableEntry _table[TABLE_SIZE];\n+public:\n+  static void initialize(MemRegion heap, size_t region_size_words);\n@@ -156,1 +169,2 @@\n-  static size_t home_index(HeapWord* from);\n+  static void begin();\n+  static void end();\n@@ -158,3 +172,2 @@\n-public:\n-  FallbackTable();\n-  ~FallbackTable();\n+  static inline bool is_forwarded(oop obj);\n+  static inline bool is_not_forwarded(oop obj);\n@@ -162,2 +175,4 @@\n-  void forward_to(HeapWord* from, HeapWord* to);\n-  HeapWord* forwardee(HeapWord* from) const;\n+  template <bool ALT_FWD>\n+  static inline void forward_to(oop from, oop to);\n+  template <bool ALT_FWD>\n+  static inline oop forwardee(oop from);\n@@ -166,1 +181,0 @@\n-#endif \/\/ _LP64\n","filename":"src\/hotspot\/share\/gc\/shared\/slidingForwarding.hpp","additions":113,"deletions":99,"binary":false,"changes":212,"status":"modified"},{"patch":"@@ -28,2 +28,1 @@\n-#ifdef _LP64\n-\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -35,5 +34,6 @@\n-size_t SlidingForwarding::region_index_containing(HeapWord* addr) const {\n-  assert(addr >= _heap_start, \"sanity: addr: \" PTR_FORMAT \" heap base: \" PTR_FORMAT, p2i(addr), p2i(_heap_start));\n-  size_t index = ((size_t) (addr - _heap_start)) >> _region_size_words_shift;\n-  assert(index < _num_regions, \"Region index is in bounds: \" PTR_FORMAT, p2i(addr));\n-  return index;\n+inline bool SlidingForwarding::is_forwarded(oop obj) {\n+  return obj->is_forwarded();\n+}\n+\n+inline bool SlidingForwarding::is_not_forwarded(oop obj) {\n+  return !obj->is_forwarded();\n@@ -42,2 +42,2 @@\n-bool SlidingForwarding::region_contains(HeapWord* region_base, HeapWord* addr) const {\n-  return uintptr_t(addr - region_base) < (1ull << _region_size_words_shift);\n+size_t SlidingForwarding::biased_region_index_containing(HeapWord* addr) {\n+  return (uintptr_t)addr >> _region_size_bytes_shift;\n@@ -46,0 +46,5 @@\n+uintptr_t SlidingForwarding::encode_forwarding(HeapWord* from, HeapWord* to) {\n+  static_assert(NUM_TARGET_REGIONS == 2, \"Only implemented for this amount\");\n+\n+  size_t from_reg_idx = biased_region_index_containing(from);\n+  HeapWord* to_region_base = (HeapWord*)((uintptr_t)to & _region_mask);\n@@ -47,14 +52,22 @@\n-uintptr_t SlidingForwarding::encode_forwarding(HeapWord* original, HeapWord* target) {\n-  size_t orig_idx = region_index_containing(original);\n-  size_t base_table_idx = orig_idx * 2;\n-  size_t target_idx = region_index_containing(target);\n-  HeapWord* encode_base;\n-  uintptr_t region_idx;\n-  for (region_idx = 0; region_idx < NUM_TARGET_REGIONS; region_idx++) {\n-    encode_base = _target_base_table[base_table_idx + region_idx];\n-    if (encode_base == UNUSED_BASE) {\n-      encode_base = _heap_start + target_idx * (1ull << _region_size_words_shift);\n-      _target_base_table[base_table_idx + region_idx] = encode_base;\n-      break;\n-    } else if (region_contains(encode_base, target)) {\n-      break;\n+  HeapWord** base = &_biased_bases[0][from_reg_idx];\n+  uintptr_t alternate = 0;\n+  if (*base == to_region_base) {\n+    \/\/ Primary is good\n+  } else if (*base == UNUSED_BASE) {\n+    \/\/ Primary is free\n+    *base = to_region_base;\n+  } else {\n+    base = &_biased_bases[1][from_reg_idx];\n+    if (*base == to_region_base) {\n+      \/\/ Alternate is good\n+    } else if (*base == UNUSED_BASE) {\n+      \/\/ Alternate is free\n+      *base = to_region_base;\n+    } else {\n+      \/\/ Both primary and alternate are not fitting\n+      \/\/ This happens only in the following rare situations:\n+      \/\/ - In Serial GC, sometimes when compact-top switches spaces, because the\n+      \/\/   region boudaries are virtual and objects can cross regions\n+      \/\/ - In G1 serial compaction, because tails of various compaction chains\n+      \/\/   are distributed across the remainders of already compacted regions.\n+      return (1 << FALLBACK_SHIFT) | markWord::marked_value;\n@@ -62,0 +75,1 @@\n+    alternate = 1;\n@@ -63,11 +77,12 @@\n-  if (region_idx >= NUM_TARGET_REGIONS) {\n-    assert(G1GC_ONLY(UseG1GC) NOT_G1GC(false), \"Only happens with G1 serial compaction\");\n-    return 1 << FALLBACK_SHIFT | markWord::marked_value;\n-  }\n-  assert(region_idx < NUM_TARGET_REGIONS, \"need to have found an encoding base\");\n-  assert(target >= encode_base, \"target must be above encode base, target:\" PTR_FORMAT \", encoded_base: \" PTR_FORMAT \",  target_idx: \" SIZE_FORMAT \", heap start: \" PTR_FORMAT \", region_idx: \" INTPTR_FORMAT,\n-         p2i(target), p2i(encode_base), target_idx, p2i(_heap_start), region_idx);\n-  assert(region_contains(encode_base, target), \"region must contain target: original: \" PTR_FORMAT \", target: \" PTR_FORMAT \", encode_base: \" PTR_FORMAT \", region_idx: \" INTPTR_FORMAT, p2i(original), p2i(target), p2i(encode_base), region_idx);\n-  uintptr_t encoded = (((uintptr_t)(target - encode_base)) << COMPRESSED_BITS_SHIFT) |\n-                      (region_idx << REGION_SHIFT) | markWord::marked_value;\n-  assert(target == decode_forwarding(original, encoded), \"must be reversible\");\n+\n+  size_t offset = pointer_delta(to, to_region_base);\n+  assert(offset < _region_size_words, \"Offset should be within the region. from: \" PTR_FORMAT\n+         \", to: \" PTR_FORMAT \", to_region_base: \" PTR_FORMAT \", offset: \" SIZE_FORMAT,\n+         p2i(from), p2i(to), p2i(to_region_base), offset);\n+\n+  uintptr_t encoded = (offset << OFFSET_BITS_SHIFT) |\n+                      (alternate << ALT_REGION_SHIFT) |\n+                      markWord::marked_value;\n+\n+  assert(to == decode_forwarding(from, encoded), \"must be reversible\");\n+  assert((encoded & ~MARK_LOWER_HALF_MASK) == 0, \"must encode to lowest 32 bits\");\n@@ -77,7 +92,16 @@\n-HeapWord* SlidingForwarding::decode_forwarding(HeapWord* original, uintptr_t encoded) const {\n-  assert((encoded & markWord::marked_value) == markWord::marked_value, \"must be marked as forwarded\");\n-  size_t orig_idx = region_index_containing(original);\n-  size_t region_idx = (encoded >> REGION_SHIFT) & right_n_bits(REGION_BITS);\n-  size_t base_table_idx = orig_idx * 2 + region_idx;\n-  HeapWord* decoded = _target_base_table[base_table_idx] + (encoded >> COMPRESSED_BITS_SHIFT);\n-  assert(decoded >= _heap_start, \"must be above heap start, encoded: \" INTPTR_FORMAT \", region_idx: \" SIZE_FORMAT \", base: \" PTR_FORMAT, encoded, region_idx, p2i(_target_base_table[base_table_idx]));\n+HeapWord* SlidingForwarding::decode_forwarding(HeapWord* from, uintptr_t encoded) {\n+  assert((encoded & markWord::lock_mask_in_place) == markWord::marked_value, \"must be marked as forwarded\");\n+  assert((encoded & FALLBACK_MASK) == 0, \"must not be fallback-forwarded\");\n+  assert((encoded & ~MARK_LOWER_HALF_MASK) == 0, \"must decode from lowest 32 bits\");\n+  size_t alternate = (encoded >> ALT_REGION_SHIFT) & right_n_bits(ALT_REGION_BITS);\n+  assert(alternate < NUM_TARGET_REGIONS, \"Sanity\");\n+  uintptr_t offset = (encoded >> OFFSET_BITS_SHIFT);\n+\n+  size_t from_idx = biased_region_index_containing(from);\n+  HeapWord* base = _biased_bases[alternate][from_idx];\n+  assert(base != UNUSED_BASE, \"must not be unused base\");\n+  HeapWord* decoded = base + offset;\n+  assert(decoded >= _heap_start,\n+         \"Address must be above heap start. encoded: \" INTPTR_FORMAT \", alt_region: \" SIZE_FORMAT \", base: \" PTR_FORMAT,\n+         encoded, alternate, p2i(base));\n+\n@@ -87,5 +111,6 @@\n-void SlidingForwarding::forward_to(oop original, oop target) {\n-  assert(_target_base_table != nullptr, \"call begin() before forwarding\");\n-  markWord header = original->mark();\n-  if (header.has_displaced_mark_helper()) {\n-    header = header.displaced_mark_helper();\n+inline void SlidingForwarding::forward_to_impl(oop from, oop to) {\n+  assert(_bases_table != nullptr, \"call begin() before forwarding\");\n+\n+  markWord from_header = from->mark();\n+  if (from_header.has_displaced_mark_helper()) {\n+    from_header = from_header.displaced_mark_helper();\n@@ -93,5 +118,7 @@\n-  HeapWord* from = cast_from_oop<HeapWord*>(original);\n-  HeapWord* to   = cast_from_oop<HeapWord*>(target);\n-  uintptr_t encoded = encode_forwarding(from, to);\n-  header = markWord((header.value() & ~MARK_LOWER_HALF_MASK) | encoded);\n-  original->set_mark(header);\n+\n+  HeapWord* from_hw = cast_from_oop<HeapWord*>(from);\n+  HeapWord* to_hw   = cast_from_oop<HeapWord*>(to);\n+  uintptr_t encoded = encode_forwarding(from_hw, to_hw);\n+  markWord new_header = markWord((from_header.value() & ~MARK_LOWER_HALF_MASK) | encoded);\n+  from->set_mark(new_header);\n+\n@@ -99,2 +126,15 @@\n-    fallback_forward_to(from, to);\n-    return;\n+    fallback_forward_to(from_hw, to_hw);\n+  }\n+}\n+\n+template <bool ALT_FWD>\n+inline void SlidingForwarding::forward_to(oop obj, oop fwd) {\n+#ifdef _LP64\n+  if (ALT_FWD) {\n+    assert(_bases_table != nullptr, \"expect sliding forwarding initialized\");\n+    forward_to_impl(obj, fwd);\n+    assert(forwardee<ALT_FWD>(obj) == fwd, \"must be forwarded to correct forwardee\");\n+  } else\n+#endif\n+  {\n+    obj->forward_to(fwd);\n@@ -104,3 +144,5 @@\n-oop SlidingForwarding::forwardee(oop original) const {\n-  assert(_target_base_table != nullptr, \"call begin() before forwarding\");\n-  markWord header = original->mark();\n+inline oop SlidingForwarding::forwardee_impl(oop from) {\n+  assert(_bases_table != nullptr, \"call begin() before asking for forwarding\");\n+\n+  markWord header = from->mark();\n+  HeapWord* from_hw = cast_from_oop<HeapWord*>(from);\n@@ -108,2 +150,1 @@\n-    HeapWord* from = cast_from_oop<HeapWord*>(original);\n-    HeapWord* to = fallback_forwardee(from);\n+    HeapWord* to = fallback_forwardee(from_hw);\n@@ -113,2 +154,15 @@\n-  HeapWord* forwardee = decode_forwarding(cast_from_oop<HeapWord*>(original), encoded);\n-  return cast_to_oop(forwardee);\n+  HeapWord* to = decode_forwarding(from_hw, encoded);\n+  return cast_to_oop(to);\n+}\n+\n+template <bool ALT_FWD>\n+inline oop SlidingForwarding::forwardee(oop obj) {\n+#ifdef _LP64\n+  if (ALT_FWD) {\n+    assert(_bases_table != nullptr, \"expect sliding forwarding initialized\");\n+    return forwardee_impl(obj);\n+  } else\n+#endif\n+  {\n+    return obj->forwardee();\n+  }\n@@ -117,1 +171,0 @@\n-#endif \/\/ _LP64\n","filename":"src\/hotspot\/share\/gc\/shared\/slidingForwarding.inline.hpp","additions":114,"deletions":61,"binary":false,"changes":175,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"gc\/shared\/gcForwarding.inline.hpp\"\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -248,1 +248,1 @@\n-\n+template <bool ALT_FWD>\n@@ -273,1 +273,1 @@\n-    GCForwarding::forward_to(q, cast_to_oop(compact_top));\n+    SlidingForwarding::forward_to<ALT_FWD>(q, cast_to_oop(compact_top));\n@@ -279,1 +279,1 @@\n-    assert(GCForwarding::is_not_forwarded(q), \"should not be forwarded\");\n+    assert(SlidingForwarding::is_not_forwarded(q), \"should not be forwarded\");\n@@ -293,1 +293,2 @@\n-void ContiguousSpace::prepare_for_compaction(CompactPoint* cp) {\n+template <bool ALT_FWD>\n+void ContiguousSpace::prepare_for_compaction_impl(CompactPoint* cp) {\n@@ -326,1 +327,1 @@\n-      compact_top = cp->space->forward(cast_to_oop(cur_obj), size, cp, compact_top);\n+      compact_top = cp->space->forward<ALT_FWD>(cast_to_oop(cur_obj), size, cp, compact_top);\n@@ -342,1 +343,1 @@\n-        compact_top = cp->space->forward(obj, obj->size(), cp, compact_top);\n+        compact_top = cp->space->forward<ALT_FWD>(obj, obj->size(), cp, compact_top);\n@@ -373,1 +374,10 @@\n-void ContiguousSpace::adjust_pointers() {\n+void ContiguousSpace::prepare_for_compaction(CompactPoint* cp) {\n+  if (UseAltGCForwarding) {\n+    prepare_for_compaction_impl<true>(cp);\n+  } else {\n+    prepare_for_compaction_impl<false>(cp);\n+  }\n+}\n+\n+template <bool ALT_FWD>\n+void ContiguousSpace::adjust_pointers_impl() {\n@@ -396,1 +406,1 @@\n-      size_t size = MarkSweep::adjust_pointers(cast_to_oop(cur_obj));\n+      size_t size = MarkSweep::adjust_pointers<ALT_FWD>(cast_to_oop(cur_obj));\n@@ -410,1 +420,10 @@\n-void ContiguousSpace::compact() {\n+void ContiguousSpace::adjust_pointers() {\n+  if (UseAltGCForwarding) {\n+    adjust_pointers_impl<true>();\n+  } else {\n+    adjust_pointers_impl<false>();\n+  }\n+}\n+\n+template <bool ALT_FWD>\n+void ContiguousSpace::compact_impl() {\n@@ -439,1 +458,1 @@\n-    if (GCForwarding::is_not_forwarded(cast_to_oop(cur_obj))) {\n+    if (SlidingForwarding::is_not_forwarded(cast_to_oop(cur_obj))) {\n@@ -450,1 +469,1 @@\n-      HeapWord* compaction_top = cast_from_oop<HeapWord*>(GCForwarding::forwardee(cast_to_oop(cur_obj)));\n+      HeapWord* compaction_top = cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(cast_to_oop(cur_obj)));\n@@ -473,0 +492,8 @@\n+void ContiguousSpace::compact() {\n+  if (UseAltGCForwarding) {\n+    compact_impl<true>();\n+  } else {\n+    compact_impl<false>();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/space.cpp","additions":39,"deletions":12,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -314,1 +314,12 @@\n- protected:\n+#if INCLUDE_SERIALGC\n+  template <bool ALT_FWD>\n+  void prepare_for_compaction_impl(CompactPoint* cp);\n+\n+  template <bool ALT_FWD>\n+  void adjust_pointers_impl();\n+\n+  template <bool ALT_FWD>\n+  void compact_impl();\n+#endif\n+\n+protected:\n@@ -401,1 +412,2 @@\n-  virtual HeapWord* forward(oop q, size_t size, CompactPoint* cp,\n+  template <bool ALT_FWD>\n+  HeapWord* forward(oop q, size_t size, CompactPoint* cp,\n","filename":"src\/hotspot\/share\/gc\/shared\/space.hpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"gc\/shenandoah\/shenandoahObjectUtils.inline.hpp\"\n@@ -201,1 +200,1 @@\n-  Klass* obj_klass = ShenandoahObjectUtils::klass(obj);\n+  Klass* obj_klass = obj->forward_safe_klass();\n@@ -233,1 +232,1 @@\n-    if (obj_klass != ShenandoahObjectUtils::klass(fwd)) {\n+    if (obj_klass != fwd->forward_safe_klass()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAsserts.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -33,1 +33,0 @@\n-#include \"runtime\/synchronizer.hpp\"\n@@ -90,1 +89,0 @@\n-    assert(prev_mark.is_marked(), \"must be forwarded\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahForwarding.inline.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/shared\/gcForwarding.inline.hpp\"\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -225,1 +225,2 @@\n-    GCForwarding::begin();\n+    SlidingForwarding::begin();\n+\n@@ -237,1 +238,0 @@\n-    GCForwarding::end();\n@@ -240,0 +240,1 @@\n+    SlidingForwarding::end();\n@@ -301,0 +302,1 @@\n+template <bool ALT_FWD>\n@@ -369,1 +371,1 @@\n-    GCForwarding::forward_to(p, cast_to_oop(_compact_point));\n+    SlidingForwarding::forward_to<ALT_FWD>(p, cast_to_oop(_compact_point));\n@@ -400,0 +402,10 @@\n+    if (UseAltGCForwarding) {\n+      work_impl<true>(worker_id);\n+    } else {\n+      work_impl<false>(worker_id);\n+    }\n+  }\n+\n+private:\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id) {\n@@ -415,1 +427,1 @@\n-    ShenandoahPrepareForCompactionObjectClosure cl(_preserved_marks->get(worker_id), empty_regions, from_region);\n+    ShenandoahPrepareForCompactionObjectClosure<ALT_FWD> cl(_preserved_marks->get(worker_id), empty_regions, from_region);\n@@ -422,1 +434,0 @@\n-        size_t num_marked = _heap->complete_marking_context()->count_marked(MemRegion(from_region->bottom(), from_region->top()));\n@@ -442,1 +453,2 @@\n-void ShenandoahFullGC::calculate_target_humongous_objects() {\n+template <bool ALT_FWD>\n+void ShenandoahFullGC::calculate_target_humongous_objects_impl() {\n@@ -478,1 +490,1 @@\n-        GCForwarding::forward_to(old_obj, cast_to_oop(heap->get_region(start)->bottom()));\n+        SlidingForwarding::forward_to<ALT_FWD>(old_obj, cast_to_oop(heap->get_region(start)->bottom()));\n@@ -490,0 +502,8 @@\n+void ShenandoahFullGC::calculate_target_humongous_objects() {\n+  if (UseAltGCForwarding) {\n+    calculate_target_humongous_objects_impl<true>();\n+  } else {\n+    calculate_target_humongous_objects_impl<false>();\n+  }\n+}\n+\n@@ -727,0 +747,1 @@\n+template <bool ALT_FWD>\n@@ -738,2 +759,2 @@\n-      if (GCForwarding::is_forwarded(obj)) {\n-        oop forw = GCForwarding::forwardee(obj);\n+      if (SlidingForwarding::is_forwarded(obj)) {\n+        oop forw = SlidingForwarding::forwardee<ALT_FWD>(obj);\n@@ -756,0 +777,1 @@\n+template <bool ALT_FWD>\n@@ -759,1 +781,1 @@\n-  ShenandoahAdjustPointersClosure _cl;\n+  ShenandoahAdjustPointersClosure<ALT_FWD> _cl;\n@@ -782,1 +804,3 @@\n-  void work(uint worker_id) {\n+private:\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id) {\n@@ -784,1 +808,1 @@\n-    ShenandoahAdjustPointersObjectClosure obj_cl;\n+    ShenandoahAdjustPointersObjectClosure<ALT_FWD> obj_cl;\n@@ -793,0 +817,9 @@\n+\n+public:\n+  void work(uint worker_id) {\n+    if (UseAltGCForwarding) {\n+      work_impl<true>(worker_id);\n+    } else {\n+      work_impl<false>(worker_id);\n+    }\n+  }\n@@ -799,0 +832,1 @@\n+\n@@ -805,1 +839,3 @@\n-  void work(uint worker_id) {\n+private:\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id) {\n@@ -807,1 +843,1 @@\n-    ShenandoahAdjustPointersClosure cl;\n+    ShenandoahAdjustPointersClosure<ALT_FWD> cl;\n@@ -811,0 +847,9 @@\n+\n+public:\n+  void work(uint worker_id) {\n+    if (UseAltGCForwarding) {\n+      work_impl<true>(worker_id);\n+    } else {\n+      work_impl<false>(worker_id);\n+    }\n+  }\n@@ -837,0 +882,1 @@\n+template <bool ALT_FWD>\n@@ -849,1 +895,1 @@\n-    if (GCForwarding::is_forwarded(p)) {\n+    if (SlidingForwarding::is_forwarded(p)) {\n@@ -851,1 +897,1 @@\n-      HeapWord* compact_to = cast_from_oop<HeapWord*>(GCForwarding::forwardee(p));\n+      HeapWord* compact_to = cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(p));\n@@ -873,1 +919,3 @@\n-  void work(uint worker_id) {\n+private:\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id) {\n@@ -877,1 +925,1 @@\n-    ShenandoahCompactObjectsClosure cl(worker_id);\n+    ShenandoahCompactObjectsClosure<ALT_FWD> cl(worker_id);\n@@ -888,0 +936,9 @@\n+\n+public:\n+  void work(uint worker_id) {\n+    if (UseAltGCForwarding) {\n+      work_impl<true>(worker_id);\n+    } else {\n+      work_impl<false>(worker_id);\n+    }\n+  }\n@@ -940,1 +997,2 @@\n-void ShenandoahFullGC::compact_humongous_objects() {\n+template <bool ALT_FWD>\n+void ShenandoahFullGC::compact_humongous_objects_impl() {\n@@ -953,1 +1011,1 @@\n-      if (GCForwarding::is_not_forwarded(old_obj)) {\n+      if (SlidingForwarding::is_not_forwarded(old_obj)) {\n@@ -962,1 +1020,1 @@\n-      size_t new_start = heap->heap_region_index_containing(GCForwarding::forwardee(old_obj));\n+      size_t new_start = heap->heap_region_index_containing(SlidingForwarding::forwardee<ALT_FWD>(old_obj));\n@@ -1003,0 +1061,8 @@\n+void ShenandoahFullGC::compact_humongous_objects() {\n+  if (UseAltGCForwarding) {\n+    compact_humongous_objects_impl<true>();\n+  } else {\n+    compact_humongous_objects_impl<false>();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.cpp","additions":88,"deletions":22,"binary":false,"changes":110,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+  template <bool ALT_FWD>\n@@ -85,0 +86,2 @@\n+  template <bool ALT_FWD>\n+  void calculate_target_humongous_objects_impl();\n@@ -87,0 +90,2 @@\n+  template <bool ALT_FWD>\n+  void compact_humongous_objects_impl();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"gc\/shared\/gcForwarding.hpp\"\n@@ -37,0 +36,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -443,1 +443,1 @@\n-  GCForwarding::initialize(_heap_region, ShenandoahHeapRegion::region_size_words());\n+  SlidingForwarding::initialize(_heap_region, ShenandoahHeapRegion::region_size_words());\n@@ -996,1 +996,1 @@\n-    if (!ShenandoahForwarding::is_forwarded(p)) {\n+    if (!p->is_forwarded()) {\n@@ -1341,1 +1341,0 @@\n-    shenandoah_assert_not_in_cset_except(NULL, obj, cancelled_gc());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -45,1 +45,0 @@\n-#include \"gc\/shenandoah\/shenandoahObjectUtils.inline.hpp\"\n@@ -288,1 +287,1 @@\n-  size_t size = ShenandoahObjectUtils::size(p);\n+  size_t size = p->forward_safe_size();\n@@ -323,2 +322,0 @@\n-\n-  \/\/ Try to install the new forwarding pointer.\n@@ -326,5 +323,13 @@\n-  if (!copy_val->mark().is_marked()) {\n-    \/\/ If we copied a mark-word that indicates 'forwarded' state, then\n-    \/\/ another thread beat us, and this new copy will never be published.\n-    \/\/ ContinuationGCSupport would get a corrupt Klass* in that case,\n-    \/\/ so don't even attempt it.\n+  if (UseCompactObjectHeaders) {\n+    \/\/ The copy above is not atomic. Make sure we have seen the proper mark\n+    \/\/ and re-install it into the copy, so that Klass* is guaranteed to be correct.\n+    markWord mark = copy_val->mark();\n+    if (!mark.is_marked()) {\n+      copy_val->set_mark(mark);\n+      ContinuationGCSupport::relativize_stack_chunk(copy_val);\n+    } else {\n+      \/\/ If we copied a mark-word that indicates 'forwarded' state, the object\n+      \/\/ installation would not succeed. We cannot access Klass* anymore either.\n+      \/\/ Skip the transformation.\n+    }\n+  } else {\n@@ -333,0 +338,2 @@\n+\n+  \/\/ Try to install the new forwarding pointer.\n@@ -512,1 +519,1 @@\n-    size_t size = ShenandoahObjectUtils::size(obj);\n+    size_t size = obj->forward_safe_size();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":17,"deletions":10,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -123,19 +123,0 @@\n-size_t ShenandoahMarkBitMap::count_marked(MemRegion mr) const {\n-  MemRegion intersection = mr.intersection(_covered);\n-  assert(!intersection.is_empty(),\n-         \"Given range from \" PTR_FORMAT \" to \" PTR_FORMAT \" is completely outside the heap\",\n-          p2i(mr.start()), p2i(mr.end()));\n-  \/\/ convert address range into offset range\n-  HeapWord* beg = intersection.start();\n-  HeapWord* end = intersection.end();\n-  size_t sum = 0;\n-  \/\/ We could probably be smarter here, but the complication is that we use\n-  \/\/ two bits per object for strong vs weak marking.\n-  for (HeapWord* current = beg; current < end; current++) {\n-    if (is_marked(current)) {\n-      sum++;\n-    }\n-  }\n-  return sum;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkBitMap.cpp","additions":0,"deletions":19,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -176,2 +176,0 @@\n-\n-  size_t count_marked(MemRegion mr) const;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkBitMap.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -71,4 +71,0 @@\n-size_t ShenandoahMarkingContext::count_marked(MemRegion mr) const {\n-  return _mark_bit_map.count_marked(mr);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkingContext.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -86,2 +86,0 @@\n-  size_t count_marked(MemRegion mr) const;\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkingContext.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1,43 +0,0 @@\n-\/*\n- * Copyright (c) 2022, Red Hat, Inc. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHOBJECTUTILS_HPP\n-#define SHARE_GC_SHENANDOAH_SHENANDOAHOBJECTUTILS_HPP\n-\n-#include \"memory\/allStatic.hpp\"\n-#include \"oops\/markWord.hpp\"\n-#include \"oops\/oopsHierarchy.hpp\"\n-\n-class Klass;\n-\n-class ShenandoahObjectUtils : public AllStatic {\n-public:\n-#ifdef _LP64\n-  static inline markWord stable_mark(oop obj);\n-#endif\n-  static inline Klass* klass(oop obj);\n-  static inline size_t size(oop obj);\n-};\n-\n-#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHOBJECTUTILS_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahObjectUtils.hpp","additions":0,"deletions":43,"binary":false,"changes":43,"status":"deleted"},{"patch":"@@ -1,148 +0,0 @@\n-\/*\n- * Copyright (c) 2022, Red Hat, Inc. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHOBJECTUTILS_INLINE_HPP\n-#define SHARE_GC_SHENANDOAH_SHENANDOAHOBJECTUTILS_INLINE_HPP\n-\n-#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahObjectUtils.hpp\"\n-#include \"oops\/klass.hpp\"\n-#include \"oops\/markWord.inline.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-#include \"runtime\/objectMonitor.inline.hpp\"\n-#include \"runtime\/thread.hpp\"\n-\n-\/\/ This is a variant of ObjectSynchronizer::stable_mark(), which does the same thing, but also\n-\/\/ handles forwarded objects. This is intended to be used by concurrent evacuation only. No other\n-\/\/ code is supposed to observe from-space objects.\n-#ifdef _LP64\n-markWord ShenandoahObjectUtils::stable_mark(oop obj) {\n-  assert(UseCompactObjectHeaders, \"only used with compact object headers\");\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n-  for (;;) {\n-    assert(heap->is_in(obj), \"object not in heap: \" PTR_FORMAT, p2i(obj));\n-    markWord mark = obj->mark_acquire();\n-\n-    \/\/ The mark can be in one of the following states:\n-    \/\/ *  Inflated     - just return mark from inflated monitor\n-    \/\/ *  Stack-locked - coerce it to inflating, and then return displaced mark\n-    \/\/ *  INFLATING    - busy wait for conversion to complete\n-    \/\/ *  Neutral      - return mark\n-    \/\/ *  Marked       - object is forwarded, try again on forwardee\n-\n-    \/\/ Most common case first.\n-    if (mark.is_neutral() || mark.is_fast_locked()) {\n-      return mark;\n-    }\n-\n-    \/\/ If object is already forwarded, then resolve it, and try again.\n-    if (mark.is_marked()) {\n-      if (heap->is_full_gc_move_in_progress()) {\n-        \/\/ In these cases, we want to return the header as-is: the Klass* would not be overloaded.\n-        return mark;\n-      }\n-      obj = cast_to_oop(mark.decode_pointer());\n-      continue;\n-    }\n-\n-    \/\/ CASE: inflated\n-    if (mark.has_monitor()) {\n-      \/\/ It is safe to access the object monitor because all Java and GC worker threads\n-      \/\/ participate in the monitor deflation protocol (i.e, they react to handshakes and STS requests).\n-      ObjectMonitor* inf = mark.monitor();\n-      markWord dmw = inf->header();\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(), mark.value());\n-      return dmw;\n-    }\n-\n-    \/\/ CASE: inflating\n-    if (mark.is_being_inflated()) {\n-      \/\/ Interference, try again.\n-      continue;\n-    }\n-\n-    \/\/ CASE: stack-locked\n-    if (mark.has_locker()) {\n-      if (Thread::current()->is_lock_owned((address)mark.locker())) {\n-        \/\/ This thread owns the lock. We can safely access it.\n-        markWord dmw = mark.displaced_mark_helper();\n-        assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(), mark.value());\n-        return dmw;\n-      }\n-\n-      \/\/ Else we try to install INFLATING into the header. This will (temporarily) prevent other\n-      \/\/ threads from stack-locking or evacuating the object.\n-      markWord cmp = obj->cas_set_mark(markWord::INFLATING(), mark);\n-      if (cmp != mark) {\n-        continue;       \/\/ Interference -- just retry\n-      }\n-\n-      \/\/ We've successfully installed INFLATING (0) into the mark-word.\n-      \/\/ This is the only case where 0 will appear in a mark-word.\n-      \/\/ Only the singular thread that successfully swings the mark-word\n-      \/\/ to 0 can fetch the stack-lock and safely read the displaced header.\n-\n-      \/\/ fetch the displaced mark from the owner's stack.\n-      \/\/ The owner can't die or unwind past the lock while our INFLATING\n-      \/\/ object is in the mark.  Furthermore the owner can't complete\n-      \/\/ an unlock on the object, either. No other thread can do evacuation, either.\n-      markWord dmw = mark.displaced_mark_helper();\n-      \/\/ Catch if the object's header is not neutral (not locked and\n-      \/\/ not marked is what we care about here).\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-      \/\/ Must preserve store ordering. The monitor state must\n-      \/\/ be stable at the time of publishing the monitor address.\n-      guarantee(obj->mark() == markWord::INFLATING(), \"invariant\");\n-      \/\/ Release semantics so that above set_object() is seen first.\n-      obj->release_set_mark(mark);\n-\n-      return dmw;\n-    }\n-  }\n-}\n-#endif\n-\n-Klass* ShenandoahObjectUtils::klass(oop obj) {\n-  if (!UseCompactObjectHeaders) {\n-    return obj->klass();\n-  }\n-#ifdef _LP64\n-  markWord header = stable_mark(obj);\n-  assert(header.narrow_klass() != 0, \"klass must not be NULL: \" INTPTR_FORMAT, header.value());\n-  return header.klass();\n-#else\n-  return obj->klass();\n-#endif\n-}\n-\n-size_t ShenandoahObjectUtils::size(oop obj) {\n-  if (!UseCompactObjectHeaders) {\n-    return obj->size();\n-  }\n-  Klass* kls = klass(obj);\n-  return obj->size_given_klass(kls);\n-}\n-\n-#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHOBJECTUTILS_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahObjectUtils.inline.hpp","additions":0,"deletions":148,"binary":false,"changes":148,"status":"deleted"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"gc\/shenandoah\/shenandoahObjectUtils.inline.hpp\"\n@@ -102,1 +101,1 @@\n-      if (is_instance_ref_klass(ShenandoahObjectUtils::klass(obj))) {\n+      if (is_instance_ref_klass(obj->forward_safe_klass())) {\n@@ -129,1 +128,1 @@\n-    Klass* obj_klass = ShenandoahObjectUtils::klass(obj);\n+    Klass* obj_klass = obj->forward_safe_klass();\n@@ -144,1 +143,1 @@\n-        check(ShenandoahAsserts::_safe_unknown, obj, (obj_addr + ShenandoahObjectUtils::size(obj)) <= obj_reg->top(),\n+        check(ShenandoahAsserts::_safe_unknown, obj, (obj_addr + obj->forward_safe_size()) <= obj_reg->top(),\n@@ -148,1 +147,1 @@\n-        size_t humongous_end = humongous_start + (ShenandoahObjectUtils::size(obj) >> ShenandoahHeapRegion::region_size_words_shift());\n+        size_t humongous_end = humongous_start + (obj->forward_safe_size() >> ShenandoahHeapRegion::region_size_words_shift());\n@@ -165,1 +164,1 @@\n-          Atomic::add(&_ld[obj_reg->index()], (uint) ShenandoahObjectUtils::size(obj), memory_order_relaxed);\n+          Atomic::add(&_ld[obj_reg->index()], (uint) obj->forward_safe_size(), memory_order_relaxed);\n@@ -206,1 +205,1 @@\n-      check(ShenandoahAsserts::_safe_oop, obj, (fwd_addr + ShenandoahObjectUtils::size(fwd)) <= fwd_reg->top(),\n+      check(ShenandoahAsserts::_safe_oop, obj, (fwd_addr + fwd->forward_safe_size()) <= fwd_reg->top(),\n@@ -309,1 +308,1 @@\n-    Klass* klass = ShenandoahObjectUtils::klass(obj);\n+    Klass* klass = obj->forward_safe_klass();\n@@ -590,1 +589,1 @@\n-    if (!is_instance_ref_klass(ShenandoahObjectUtils::klass(obj))) {\n+    if (!is_instance_ref_klass(obj->forward_safe_klass())) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVerifier.cpp","additions":8,"deletions":9,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -53,1 +53,0 @@\n-int base_offset = arrayOopDesc::base_offset_in_bytes(element_type);\n@@ -55,1 +54,2 @@\n-  \/\/ Clear leading 32 bit, if necessary.\n+  \/\/ Clear leading 32 bits, if necessary.\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(element_type);\n","filename":"src\/hotspot\/share\/gc\/x\/xObjArrayAllocator.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -53,1 +53,0 @@\n-  int base_offset = arrayOopDesc::base_offset_in_bytes(element_type);\n@@ -55,1 +54,2 @@\n-  \/\/ Clear leading 32 bit, if necessary.\n+  \/\/ Clear leading 32 bits, if necessary.\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(element_type);\n@@ -151,1 +151,5 @@\n-  oopDesc::release_set_mark(mem, markWord::prototype());\n+  if (UseCompactObjectHeaders) {\n+    oopDesc::release_set_mark(mem, _klass->prototype_header());\n+  } else {\n+    oopDesc::release_set_mark(mem, markWord::prototype());\n+  }\n","filename":"src\/hotspot\/share\/gc\/z\/zObjArrayAllocator.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -609,1 +609,0 @@\n-    const size_t size = ZUtils::object_size(from_addr);\n@@ -617,0 +616,1 @@\n+        const size_t size = ZUtils::object_size(to_addr);\n@@ -623,0 +623,1 @@\n+    const size_t size = ZUtils::object_size(from_addr);\n","filename":"src\/hotspot\/share\/gc\/z\/zRelocate.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2003,6 +2003,7 @@\n-#ifdef _LP64\n-              oopDesc::release_set_mark(result, ik->prototype_header());\n-#else\n-              oopDesc::set_mark(result, markWord::prototype());\n-              oopDesc::release_set_klass(result, ik);\n-#endif\n+              if (UseCompactObjectHeaders) {\n+                oopDesc::release_set_mark(result, ik->prototype_header());\n+              } else {\n+                oopDesc::set_mark(result, markWord::prototype());\n+                oopDesc::set_klass_gap(result, 0);\n+                oopDesc::release_set_klass(result, ik);\n+              }\n","filename":"src\/hotspot\/share\/interpreter\/zero\/bytecodeInterpreter.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -69,2 +69,1 @@\n-    markWord mark = obj->mark();\n-    _store->push(ObjectSampleMarkWord(obj, mark));\n+    _store->push(ObjectSampleMarkWord(obj, obj->mark()));\n@@ -74,6 +73,1 @@\n-#ifdef _LP64\n-    if (mark.has_displaced_mark_helper()) {\n-      mark = mark.displaced_mark_helper();\n-    }\n-#endif\n-    obj->set_mark(markWord::prototype().set_marked() LP64_ONLY(.set_narrow_klass(mark.narrow_klass())));\n+    obj->set_mark(obj->prototype_mark().set_marked());\n","filename":"src\/hotspot\/share\/jfr\/leakprofiler\/chains\/objectSampleMarker.hpp","additions":2,"deletions":8,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -443,1 +443,5 @@\n-  if (offset == oopDesc::klass_offset_in_bytes()) {\n+\n+  \/\/ With compact object headers, we can test for the explicit offset within\n+  \/\/ the header to figure out if compiler code is accessing the class.\n+  int klass_offset = UseCompactObjectHeaders ? 4 : oopDesc::klass_offset_in_bytes();\n+  if (offset == klass_offset) {\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -296,0 +296,1 @@\n+  volatile_nonstatic_field(oopDesc,            _metadata._klass,                              Klass*)                                \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -323,2 +323,7 @@\n-  assert(oopDesc::klass_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n-         \"Klass offset is expected to be less than the page size\");\n+  if (UseCompactObjectHeaders) {\n+    assert(oopDesc::mark_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n+           \"Mark offset is expected to be less than the page size\");\n+  } else {\n+    assert(oopDesc::klass_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n+           \"Klass offset is expected to be less than the page size\");\n+  }\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -48,15 +49,1 @@\n-  \/\/ Header size computation.\n-  \/\/ The header is considered the oop part of this type plus the length.\n-  \/\/ Returns the aligned header_size_in_bytes.  This is not equivalent to\n-  \/\/ sizeof(arrayOopDesc) which should not appear in the code.\n-  static int header_size_in_bytes() {\n-    size_t hs = length_offset_in_bytes() + sizeof(int);\n-#ifdef ASSERT\n-    \/\/ make sure it isn't called before UseCompressedOops is initialized.\n-    static size_t arrayoopdesc_hs = 0;\n-    if (arrayoopdesc_hs == 0) arrayoopdesc_hs = hs;\n-    assert(arrayoopdesc_hs == hs, \"header size can't change\");\n-#endif \/\/ ASSERT\n-    return (int)hs;\n-  }\n-\n+private:\n@@ -69,2 +56,2 @@\n-  \/\/ Check whether an element of a typeArrayOop with the given type must be\n-  \/\/ aligned 0 mod 8.  The typeArrayOop itself must be aligned at least this\n+  \/\/ Check whether an element of an arrayOop with the given type must be\n+  \/\/ aligned 0 mod 8.  The arrayOop itself must be aligned at least this\n@@ -82,0 +69,14 @@\n+  \/\/ Header size computation.\n+  \/\/ The header is considered the oop part of this type plus the length.\n+  \/\/ This is not equivalent to sizeof(arrayOopDesc) which should not appear in the code.\n+  static int header_size_in_bytes() {\n+    size_t hs = length_offset_in_bytes() + sizeof(int);\n+#ifdef ASSERT\n+    \/\/ make sure it isn't called before UseCompressedOops is initialized.\n+    static size_t arrayoopdesc_hs = 0;\n+    if (arrayoopdesc_hs == 0) arrayoopdesc_hs = hs;\n+    assert(arrayoopdesc_hs == hs, \"header size can't change\");\n+#endif \/\/ ASSERT\n+    return (int)hs;\n+  }\n+\n@@ -86,1 +87,7 @@\n-    return oopDesc::base_offset_in_bytes();\n+    if (UseCompactObjectHeaders) {\n+      return oopDesc::base_offset_in_bytes();\n+    } else if (UseCompressedClassPointers) {\n+      return klass_gap_offset_in_bytes();\n+    } else {\n+      return sizeof(arrayOopDesc);\n+    }\n@@ -91,4 +98,2 @@\n-    size_t typesize_in_bytes = header_size_in_bytes();\n-    return (int)(element_type_should_be_aligned(type)\n-                 ? align_up(typesize_in_bytes, BytesPerLong)\n-                 : typesize_in_bytes);\n+    size_t hs = header_size_in_bytes();\n+    return (int)(element_type_should_be_aligned(type) ? align_up(hs, BytesPerLong) : hs);\n@@ -131,1 +136,1 @@\n-  \/\/ Return the maximum length of an array of BasicType.  The length can passed\n+  \/\/ Return the maximum length of an array of BasicType.  The length can be passed\n@@ -139,2 +144,8 @@\n-    const size_t max_size_bytes = align_down(SIZE_MAX - base_offset_in_bytes(type), MinObjAlignmentInBytes);\n-    const size_t max_elements_per_size_t = max_size_bytes \/ type2aelembytes(type);\n+    size_t hdr_size_in_bytes = base_offset_in_bytes(type);\n+    \/\/ This is rounded-up and may overlap with the first array elements.\n+    size_t hdr_size_in_words = align_up(hdr_size_in_bytes, HeapWordSize) \/ HeapWordSize;\n+\n+    const size_t max_element_words_per_size_t =\n+      align_down((SIZE_MAX\/HeapWordSize - hdr_size_in_words), MinObjAlignment);\n+    const size_t max_elements_per_size_t =\n+      HeapWordSize * max_element_words_per_size_t \/ type2aelembytes(type);\n@@ -146,2 +157,1 @@\n-      int header_size_words = align_up(base_offset_in_bytes(type), HeapWordSize) \/ HeapWordSize;\n-      return align_down(max_jint - header_size_words, MinObjAlignment);\n+      return align_down(max_jint - hdr_size_in_words, MinObjAlignment);\n","filename":"src\/hotspot\/share\/oops\/arrayOop.hpp","additions":37,"deletions":27,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -38,1 +38,7 @@\n-    return oopDesc::base_offset_in_bytes();\n+    if (UseCompactObjectHeaders) {\n+      return oopDesc::base_offset_in_bytes();\n+    } else if (UseCompressedClassPointers) {\n+      return klass_gap_offset_in_bytes();\n+    } else {\n+      return sizeof(instanceOopDesc);\n+    }\n","filename":"src\/hotspot\/share\/oops\/instanceOop.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -126,1 +126,1 @@\n-  void trace_reference_gc(const char *s, oop obj) NOT_DEBUG_RETURN;\n+  static void trace_reference_gc(const char *s, oop obj) NOT_DEBUG_RETURN;\n","filename":"src\/hotspot\/share\/oops\/instanceRefKlass.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -53,1 +53,0 @@\n-#include \"runtime\/globals.hpp\"\n@@ -55,1 +54,0 @@\n-#include \"utilities\/align.hpp\"\n@@ -197,5 +195,1 @@\n-  MetaWord* p = Metaspace::allocate(loader_data, word_size, MetaspaceObj::ClassType, THREAD);\n-  assert(is_aligned(p, KlassAlignmentInBytes),\n-         \"metaspace returned badly aligned memory (\" PTR_FORMAT \"), alignment required: %u\",\n-         p2i(p), (unsigned)KlassAlignmentInBytes);\n-  return p;\n+  return Metaspace::allocate(loader_data, word_size, MetaspaceObj::ClassType, THREAD);\n@@ -791,4 +785,0 @@\n-  if (UseCompressedClassPointers) {\n-    assert(is_aligned(this, KlassAlignmentInBytes), \"misaligned Klass structure\");\n-  }\n-\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -26,1 +26,0 @@\n-#include \"oops\/compressedOops.inline.hpp\"\n","filename":"src\/hotspot\/share\/oops\/markWord.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -29,1 +30,1 @@\n-#include \"oops\/compressedKlass.hpp\" \/\/ for narrowKlass\n+#include \"oops\/compressedKlass.hpp\"\n@@ -286,0 +287,1 @@\n+  inline markWord actual_mark() const;\n@@ -288,2 +290,0 @@\n-  inline Klass* safe_klass() const;\n-  inline markWord set_klass(const Klass* klass) const;\n@@ -291,1 +291,2 @@\n-  inline markWord set_narrow_klass(const narrowKlass klass) const;\n+  inline markWord set_narrow_klass(narrowKlass nklass) const;\n+  inline markWord set_klass(Klass* klass) const;\n@@ -308,0 +309,1 @@\n+#ifdef _LP64\n@@ -309,1 +311,3 @@\n-    return mask_bits(value(), self_forwarded_mask_in_place) != 0;\n+    bool self_fwd = mask_bits(value(), self_forwarded_mask_in_place) != 0;\n+    assert(!self_fwd || UseAltGCForwarding, \"Only set self-fwd bit when using alt GC forwarding\");\n+    return self_fwd;\n@@ -313,0 +317,1 @@\n+    assert(UseAltGCForwarding, \"Only call this with alt GC forwarding\");\n@@ -315,0 +320,1 @@\n+#endif\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":11,"deletions":5,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-#include \"oops\/compressedOops.inline.hpp\"\n@@ -30,1 +29,1 @@\n-#include \"runtime\/safepoint.hpp\"\n+#include \"oops\/compressedOops.inline.hpp\"\n@@ -33,2 +32,7 @@\n-narrowKlass markWord::narrow_klass() const {\n-  return narrowKlass(value() >> klass_shift);\n+markWord markWord::actual_mark() const {\n+  assert(UseCompactObjectHeaders, \"only safe when using compact headers\");\n+  if (has_displaced_mark_helper()) {\n+    return displaced_mark_helper();\n+  } else {\n+    return *this;\n+  }\n@@ -48,1 +52,1 @@\n-markWord markWord::set_narrow_klass(const narrowKlass nklass) const {\n+narrowKlass markWord::narrow_klass() const {\n@@ -50,1 +54,1 @@\n-  return markWord((value() & ~klass_mask_in_place) | ((uintptr_t) nklass << klass_shift));\n+  return narrowKlass(value() >> klass_shift);\n@@ -53,1 +57,1 @@\n-Klass* markWord::safe_klass() const {\n+markWord markWord::set_narrow_klass(narrowKlass nklass) const {\n@@ -55,6 +59,1 @@\n-  assert(SafepointSynchronize::is_at_safepoint(), \"only call at safepoint\");\n-  markWord m = *this;\n-  if (m.has_displaced_mark_helper()) {\n-    m = m.displaced_mark_helper();\n-  }\n-  return CompressedKlassPointers::decode_not_null(m.narrow_klass());\n+  return markWord((value() & ~klass_mask_in_place) | ((uintptr_t) nklass << klass_shift));\n@@ -63,1 +62,1 @@\n-markWord markWord::set_klass(const Klass* klass) const {\n+markWord markWord::set_klass(Klass* klass) const {\n@@ -66,1 +65,0 @@\n-  \/\/ TODO: Don't cast to non-const, change CKP::encode() to accept const Klass* instead.\n@@ -70,1 +68,1 @@\n-#endif\n+#endif \/\/ _LP64\n","filename":"src\/hotspot\/share\/oops\/markWord.inline.hpp","additions":15,"deletions":17,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -159,0 +159,2 @@\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert(UseCompactObjectHeaders || obj->is_objArray(), \"must be object array\");\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -73,0 +73,2 @@\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert (UseCompactObjectHeaders || obj->is_array(), \"obj must be array\");\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.inline.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -54,6 +54,0 @@\n-private:\n-  \/\/ Give size of objArrayOop in bytes minus the header\n-  static size_t array_size_in_bytes(int length) {\n-    return (size_t)length * heapOopSize;\n-  }\n-\n@@ -81,2 +75,2 @@\n-    size_t asz = array_size_in_bytes(length);\n-    size_t size_words = align_up(base_offset_in_bytes() + asz, HeapWordSize) \/ HeapWordSize;\n+    size_t asz = (size_t)length * heapOopSize;\n+    size_t size_words = heap_word_size(base_offset_in_bytes() + asz);\n","filename":"src\/hotspot\/share\/oops\/objArrayOop.hpp","additions":2,"deletions":8,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-#include \"runtime\/interfaceSupport.inline.hpp\"\n@@ -160,2 +159,2 @@\n-  \/\/ Only has a klass gap when compressed class pointers are used, but\n-  \/\/ only if not using compact headers..\n+  \/\/ Only has a klass gap when compressed class pointers are used.\n+  \/\/ Except when using compact headers.\n@@ -169,5 +168,1 @@\n-  if (UseCompactObjectHeaders) {\n-    set_mark(mark().set_narrow_klass(nk));\n-  } else {\n-    _metadata._compressed_klass = nk;\n-  }\n+  _metadata._compressed_klass = nk;\n@@ -178,8 +173,9 @@\n-  \/\/ TODO: Remove method altogether and replace with calls to obj->klass() ?\n-  \/\/ OTOH, we may eventually get rid of locking in header, and then no\n-  \/\/ longer have to deal with that anymore.\n-#ifdef _LP64\n-  return obj->klass();\n-#else\n-  return obj->_metadata._klass;\n-#endif\n+  if (UseCompactObjectHeaders) {\n+    return obj->klass();\n+  } else if (UseCompressedClassPointers) {\n+    narrowKlass narrow_klass = obj->_metadata._compressed_klass;\n+    if (narrow_klass == 0) return nullptr;\n+    return (void*)CompressedKlassPointers::decode_raw(narrow_klass);\n+  } else {\n+    return obj->_metadata._klass;\n+  }\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":12,"deletions":16,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -85,0 +85,3 @@\n+  \/\/ Returns the prototype mark that should be used for this object.\n+  inline markWord prototype_mark() const;\n+\n@@ -104,1 +107,0 @@\n-#ifdef _LP64\n@@ -107,3 +109,3 @@\n-    } else\n-#endif\n-    return sizeof(oopDesc)\/HeapWordSize;\n+    } else {\n+      return sizeof(oopDesc)\/HeapWordSize;\n+    }\n@@ -122,0 +124,14 @@\n+  \/\/ The following set of methods is used to access the mark-word and related\n+  \/\/ properties when the object may be forwarded. Be careful where and when\n+  \/\/ using this method. It assumes that the forwardee is installed in\n+  \/\/ the header as a plain pointer (or self-forwarded). In particular,\n+  \/\/ those methods can not deal with the sliding-forwarding that is used\n+  \/\/ in Serial, G1 and Shenandoah full-GCs.\n+private:\n+  inline Klass*   forward_safe_klass_impl(markWord m) const;\n+public:\n+  inline Klass*   forward_safe_klass() const;\n+  inline Klass*   forward_safe_klass(markWord m) const;\n+  inline size_t   forward_safe_size();\n+  inline void     forward_safe_init_mark();\n+\n@@ -326,6 +342,0 @@\n-  static int klass_gap_offset_in_bytes() {\n-    assert(has_klass_gap(), \"only applicable to compressed klass pointers\");\n-    assert(!UseCompactObjectHeaders, \"don't use klass_offset_in_bytes() with compact headers\");\n-    return klass_offset_in_bytes() + sizeof(narrowKlass);\n-  }\n-\n@@ -339,1 +349,8 @@\n-    return offset_of(oopDesc, _metadata._klass);\n+    {\n+      return (int)offset_of(oopDesc, _metadata._klass);\n+    }\n+  }\n+  static int klass_gap_offset_in_bytes() {\n+    assert(has_klass_gap(), \"only applicable to compressed klass pointers\");\n+    assert(!UseCompactObjectHeaders, \"don't use klass_offset_in_bytes() with compact headers\");\n+    return klass_offset_in_bytes() + sizeof(narrowKlass);\n@@ -353,1 +370,3 @@\n-    return sizeof(oopDesc);\n+    {\n+      return sizeof(oopDesc);\n+    }\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":31,"deletions":12,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-#include \"runtime\/objectMonitor.inline.hpp\"\n@@ -43,1 +42,0 @@\n-#include \"runtime\/synchronizer.hpp\"\n@@ -90,4 +88,12 @@\n-  markWord hdr = mark();\n-  if (hdr.has_monitor()) {\n-    ObjectMonitor* monitor = hdr.monitor();\n-    return monitor->header();\n+  markWord m = mark();\n+  if (m.has_displaced_mark_helper()) {\n+    m = m.displaced_mark_helper();\n+  }\n+  return m;\n+}\n+\n+markWord oopDesc::prototype_mark() const {\n+  if (UseCompactObjectHeaders) {\n+    return klass()->prototype_header();\n+  } else {\n+    return markWord::prototype();\n@@ -95,1 +101,0 @@\n-  return hdr;\n@@ -99,1 +104,0 @@\n-#ifdef _LP64\n@@ -101,6 +105,4 @@\n-    markWord header = resolve_mark();\n-    assert(UseCompressedClassPointers, \"expect compressed klass pointers\");\n-    set_mark(markWord((header.value() & markWord::klass_mask_in_place) | markWord::prototype().value()));\n-  } else\n-#endif\n-  set_mark(markWord::prototype());\n+    set_mark(prototype_mark());\n+  } else {\n+    set_mark(markWord::prototype());\n+  }\n@@ -112,3 +114,2 @@\n-    assert(UseCompressedClassPointers, \"only with compressed class pointers\");\n-    markWord header = resolve_mark();\n-    return header.klass();\n+    markWord m = resolve_mark();\n+    return m.klass();\n@@ -119,1 +120,3 @@\n-  return _metadata._klass;\n+  {\n+    return _metadata._klass;\n+  }\n@@ -125,3 +128,2 @@\n-    assert(UseCompressedClassPointers, \"only with compressed class pointers\");\n-    markWord header = resolve_mark();\n-    return header.klass_or_null();\n+    markWord m = resolve_mark();\n+    return m.klass_or_null();\n@@ -132,1 +134,3 @@\n-  return _metadata._klass;\n+  {\n+    return _metadata._klass;\n+  }\n@@ -138,4 +142,3 @@\n-    assert(UseCompressedClassPointers, \"only with compressed class pointers\");\n-    markWord header = mark_acquire();\n-    if (header.has_monitor()) {\n-      header = header.monitor()->header();\n+    markWord m = mark_acquire();\n+    if (m.has_displaced_mark_helper()) {\n+      m = m.displaced_mark_helper();\n@@ -143,1 +146,1 @@\n-    return header.klass_or_null();\n+    return m.klass_or_null();\n@@ -149,1 +152,3 @@\n-  return Atomic::load_acquire(&_metadata._klass);\n+  {\n+    return Atomic::load_acquire(&_metadata._klass);\n+  }\n@@ -153,1 +158,7 @@\n-  return klass();\n+  if (UseCompactObjectHeaders) {\n+    return klass();\n+  } else if (UseCompressedClassPointers) {\n+    return CompressedKlassPointers::decode_raw(_metadata._compressed_klass);\n+  } else {\n+    return _metadata._klass;\n+  }\n@@ -157,1 +168,1 @@\n-  assert(Universe::is_bootstrapping() || (k != NULL && k->is_klass()), \"incorrect Klass\");\n+  assert(Universe::is_bootstrapping() || (k != nullptr && k->is_klass()), \"incorrect Klass\");\n@@ -167,1 +178,1 @@\n-  assert(Universe::is_bootstrapping() || (k != NULL && k->is_klass()), \"incorrect Klass\");\n+  assert(Universe::is_bootstrapping() || (k != nullptr && k->is_klass()), \"incorrect Klass\");\n@@ -242,0 +253,47 @@\n+#ifdef _LP64\n+Klass* oopDesc::forward_safe_klass_impl(markWord m) const {\n+  assert(UseCompactObjectHeaders, \"Only get here with compact headers\");\n+  if (m.is_marked()) {\n+    oop fwd = forwardee(m);\n+    markWord m2 = fwd->mark();\n+    assert(!m2.is_marked() || m2.self_forwarded(), \"no double forwarding: this: \" PTR_FORMAT \" (\" INTPTR_FORMAT \"), fwd: \" PTR_FORMAT \" (\" INTPTR_FORMAT \")\", p2i(this), m.value(), p2i(fwd), m2.value());\n+    m = m2;\n+  }\n+  return m.actual_mark().klass();\n+}\n+#endif\n+\n+Klass* oopDesc::forward_safe_klass(markWord m) const {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    return forward_safe_klass_impl(m);\n+  } else\n+#endif\n+  {\n+    return klass();\n+  }\n+}\n+\n+Klass* oopDesc::forward_safe_klass() const {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    return forward_safe_klass_impl(mark());\n+  } else\n+#endif\n+  {\n+    return klass();\n+  }\n+}\n+\n+size_t oopDesc::forward_safe_size() {\n+  return size_given_klass(forward_safe_klass());\n+}\n+\n+void oopDesc::forward_safe_init_mark() {\n+  if (UseCompactObjectHeaders) {\n+    set_mark(forward_safe_klass()->prototype_header());\n+  } else {\n+    set_mark(markWord::prototype());\n+  }\n+}\n+\n@@ -310,0 +368,1 @@\n+  assert(p != cast_to_oop(this) || !UseAltGCForwarding, \"Must not be called with self-forwarding\");\n@@ -317,11 +376,12 @@\n-  markWord m = mark();\n-  \/\/ If mark is displaced, we need to preserve the Klass* from real header.\n-  assert(SafepointSynchronize::is_at_safepoint(), \"we can only safely fetch the displaced header at safepoint\");\n-  if (m.has_displaced_mark_helper()) {\n-    m = m.displaced_mark_helper();\n-  }\n-  m = m.set_self_forwarded();\n-  assert(forwardee(m) == cast_to_oop(this), \"encoding must be reversable\");\n-  set_mark(m);\n-#else\n-  forward_to(oop(this));\n+  if (UseAltGCForwarding) {\n+    markWord m = mark();\n+    \/\/ If mark is displaced, we need to preserve the real header during GC.\n+    \/\/ It will be restored to the displaced header after GC.\n+    assert(SafepointSynchronize::is_at_safepoint(), \"we can only safely fetch the displaced header at safepoint\");\n+    if (m.has_displaced_mark_helper()) {\n+      m = m.displaced_mark_helper();\n+    }\n+    m = m.set_self_forwarded();\n+    assert(forwardee(m) == cast_to_oop(this), \"encoding must be reversible\");\n+    set_mark(m);\n+  } else\n@@ -329,0 +389,3 @@\n+  {\n+    forward_to(oop(this));\n+  }\n@@ -332,0 +395,1 @@\n+  assert(p != cast_to_oop(this) || !UseAltGCForwarding, \"Must not be called with self-forwarding\");\n@@ -333,1 +397,1 @@\n-  assert(forwardee(m) == p, \"encoding must be reversable\");\n+  assert(m.decode_pointer() == p, \"encoding must be reversible\");\n@@ -344,17 +408,18 @@\n-  markWord m = compare;\n-  \/\/ If mark is displaced, we need to preserve the Klass* from real header.\n-  assert(SafepointSynchronize::is_at_safepoint(), \"we can only safely fetch the displaced header at safepoint\");\n-  if (m.has_displaced_mark_helper()) {\n-    m = m.displaced_mark_helper();\n-  }\n-  m = m.set_self_forwarded();\n-  assert(forwardee(m) == cast_to_oop(this), \"encoding must be reversable\");\n-  markWord old_mark = cas_set_mark(m, compare, order);\n-  if (old_mark == compare) {\n-    return NULL;\n-  } else {\n-    assert(old_mark.is_marked(), \"must be marked here\");\n-    return forwardee(old_mark);\n-  }\n-#else\n-  return forward_to_atomic(oop(this), compare, order);\n+  if (UseAltGCForwarding) {\n+    markWord m = compare;\n+    \/\/ If mark is displaced, we need to preserve the real header during GC.\n+    \/\/ It will be restored to the displaced header after GC.\n+    assert(SafepointSynchronize::is_at_safepoint(), \"we can only safely fetch the displaced header at safepoint\");\n+    if (m.has_displaced_mark_helper()) {\n+      m = m.displaced_mark_helper();\n+    }\n+    m = m.set_self_forwarded();\n+    assert(forwardee(m) == cast_to_oop(this), \"encoding must be reversible\");\n+    markWord old_mark = cas_set_mark(m, compare, order);\n+    if (old_mark == compare) {\n+      return nullptr;\n+    } else {\n+      assert(old_mark.is_marked(), \"must be marked here\");\n+      return forwardee(old_mark);\n+    }\n+  } else\n@@ -362,7 +427,3 @@\n-}\n-\n-\/\/ Note that the forwardee is not the same thing as the displaced_mark.\n-\/\/ The forwardee is used when copying during scavenge and mark-sweep.\n-\/\/ It does need to clear the low two locking- and GC-related bits.\n-oop oopDesc::forwardee() const {\n-  return forwardee(mark());\n+  {\n+    return forward_to_atomic(cast_to_oop(this), compare, order);\n+  }\n@@ -372,1 +433,1 @@\n-  assert(header.is_marked(), \"must be forwarded\");\n+  assert(header.is_marked(), \"only decode when actually forwarded\");\n@@ -379,1 +440,0 @@\n-    assert(header.is_marked(), \"only decode when actually forwarded\");\n@@ -384,0 +444,7 @@\n+\/\/ Note that the forwardee is not the same thing as the displaced_mark.\n+\/\/ The forwardee is used when copying during scavenge and mark-sweep.\n+\/\/ It does need to clear the low two locking- and GC-related bits.\n+oop oopDesc::forwardee() const {\n+  return forwardee(mark());\n+}\n+\n@@ -438,0 +505,2 @@\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert(UseCompactObjectHeaders || k == klass(), \"wrong klass\");\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":138,"deletions":69,"binary":false,"changes":207,"status":"modified"},{"patch":"@@ -231,0 +231,2 @@\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert(UseCompactObjectHeaders || obj->is_typeArray(),\"must be a type array\");\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,0 +38,2 @@\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert(UseCompactObjectHeaders || obj->is_typeArray(),\"must be a type array\");\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.inline.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -323,3 +323,2 @@\n-    const size_t hs_bytes = arrayOopDesc::base_offset_in_bytes(elem_type);\n-    \/\/ Align to next 8 bytes to avoid trashing arrays's length.\n-    const size_t aligned_hs_bytes = align_up(hs_bytes, BytesPerLong);\n+    size_t hs_bytes = arrayOopDesc::base_offset_in_bytes(elem_type);\n+    assert(is_aligned(hs_bytes, BytesPerInt), \"must be 4 byte aligned\");\n@@ -327,2 +326,3 @@\n-    if (aligned_hs_bytes > hs_bytes) {\n-      Copy::zero_to_bytes(obj + hs_bytes, aligned_hs_bytes - hs_bytes);\n+    if (!is_aligned(hs_bytes, BytesPerLong)) {\n+      *reinterpret_cast<jint*>(reinterpret_cast<char*>(obj) + hs_bytes) = 0;\n+      hs_bytes += BytesPerInt;\n@@ -330,0 +330,1 @@\n+\n@@ -331,1 +332,2 @@\n-    const size_t aligned_hs = aligned_hs_bytes \/ HeapWordSize;\n+    assert(is_aligned(hs_bytes, BytesPerLong), \"must be 8-byte aligned\");\n+    const size_t aligned_hs = hs_bytes \/ BytesPerLong;\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":8,"deletions":6,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -5159,1 +5159,0 @@\n-      BasicType basic_elem_type = elem()->basic_type();\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1402,1 +1402,1 @@\n-        _offset != arrayOopDesc::klass_offset_in_bytes()) {\n+        _offset != oopDesc::klass_offset_in_bytes()) {\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3096,2 +3096,2 @@\n-  if (UseCompactObjectHeaders && UseZGC) {\n-    warning(\"ZGC does not work with compact object headers, disabling UseCompactObjectHeaders\");\n+  if (UseCompactObjectHeaders && UseZGC && !ZGenerational) {\n+    warning(\"Single-generational ZGC does not work with compact object headers, disabling UseCompactObjectHeaders\");\n@@ -3100,1 +3100,0 @@\n-\n@@ -3102,1 +3101,0 @@\n-    \/\/ If user specifies -UseCompressedClassPointers, disable compact headers with a warning.\n@@ -3106,1 +3104,0 @@\n-\n@@ -3110,0 +3107,6 @@\n+  if (UseCompactObjectHeaders && !UseAltGCForwarding) {\n+    FLAG_SET_DEFAULT(UseAltGCForwarding, true);\n+  }\n+  if (UseCompactObjectHeaders && !UseCompressedClassPointers) {\n+    FLAG_SET_DEFAULT(UseCompressedClassPointers, true);\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -134,1 +134,1 @@\n-          \"Use 64-bit object headers instead of 96-bit headers\")            \\\n+          \"Use compact 64-bit object headers in 64-bit VM\")                 \\\n@@ -1062,1 +1062,1 @@\n-  product(bool, UseHeavyMonitors, false, DIAGNOSTIC,                        \\\n+  develop(bool, UseHeavyMonitors, false,                                    \\\n@@ -1986,6 +1986,0 @@\n-  product(bool, HeapObjectStats, false, DIAGNOSTIC,                         \\\n-             \"Enable gathering of heap object statistics\")                  \\\n-                                                                            \\\n-  product(size_t, HeapObjectStatsSamplingInterval, 500, DIAGNOSTIC,         \\\n-             \"Heap object statistics sampling interval (ms)\")               \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":2,"deletions":8,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-#include \"gc\/shared\/suspendibleThreadSet.hpp\"\n@@ -1713,3 +1712,0 @@\n-      \/\/ Also, we sync and desync GC threads around the handshake, so that they can\n-      \/\/ safely read the mark-word and look-through to the object-monitor, without\n-      \/\/ being afraid that the object-monitor is going away.\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -94,1 +94,0 @@\n-  template(HeapObjectStatistics)                  \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1,177 +0,0 @@\n-\/*\n- * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"gc\/shared\/collectedHeap.hpp\"\n-#include \"logging\/logStream.hpp\"\n-#include \"logging\/logTag.hpp\"\n-#include \"memory\/allocation.hpp\"\n-#include \"memory\/iterator.hpp\"\n-#include \"memory\/resourceArea.hpp\"\n-#include \"memory\/universe.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-#include \"runtime\/mutexLocker.hpp\"\n-#include \"runtime\/vmThread.hpp\"\n-#include \"services\/heapObjectStatistics.hpp\"\n-#include \"utilities\/copy.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/ostream.hpp\"\n-\n-HeapObjectStatistics* HeapObjectStatistics::_instance = NULL;\n-\n-class HeapObjectStatsObjectClosure : public ObjectClosure {\n-private:\n-  HeapObjectStatistics* const _stats;\n-public:\n-  HeapObjectStatsObjectClosure() : _stats(HeapObjectStatistics::instance()) {}\n-  void do_object(oop obj) {\n-    _stats->visit_object(obj);\n-  }\n-};\n-\n-class VM_HeapObjectStatistics : public VM_Operation {\n-public:\n-  VMOp_Type type() const { return VMOp_HeapObjectStatistics; }\n-  bool doit_prologue() {\n-    Heap_lock->lock();\n-    return true;\n-  }\n-\n-  void doit_epilogue() {\n-    Heap_lock->unlock();\n-  }\n-\n-  void doit() {\n-    assert(SafepointSynchronize::is_at_safepoint(), \"all threads are stopped\");\n-    assert(Heap_lock->is_locked(), \"should have the Heap_lock\");\n-\n-    CollectedHeap* heap = Universe::heap();\n-    heap->ensure_parsability(false);\n-\n-    HeapObjectStatistics* stats = HeapObjectStatistics::instance();\n-    stats->begin_sample();\n-\n-    HeapObjectStatsObjectClosure cl;\n-    heap->object_iterate(&cl);\n-  }\n-};\n-\n-HeapObjectStatisticsTask::HeapObjectStatisticsTask() : PeriodicTask(HeapObjectStatsSamplingInterval) {}\n-\n-void HeapObjectStatisticsTask::task() {\n-  VM_HeapObjectStatistics vmop;\n-  VMThread::execute(&vmop);\n-}\n-\n-void HeapObjectStatistics::initialize() {\n-  assert(_instance == NULL, \"Don't init twice\");\n-  if (HeapObjectStats) {\n-    _instance = new HeapObjectStatistics();\n-    _instance->start();\n-  }\n-}\n-\n-void HeapObjectStatistics::shutdown() {\n-  if (HeapObjectStats) {\n-    assert(_instance != NULL, \"Must be initialized\");\n-    LogTarget(Info, heap, stats) lt;\n-    if (lt.is_enabled()) {\n-      LogStream ls(lt);\n-      ResourceMark rm;\n-      _instance->print(&ls);\n-    }\n-    _instance->stop();\n-    delete _instance;\n-    _instance = NULL;\n-  }\n-}\n-\n-HeapObjectStatistics* HeapObjectStatistics::instance() {\n-  assert(_instance != NULL, \"Must be initialized\");\n-  return _instance;\n-}\n-\n-void HeapObjectStatistics::increase_counter(uint64_t& counter, uint64_t val) {\n-  uint64_t oldval = counter;\n-  uint64_t newval = counter + val;\n-  if (newval < oldval) {\n-    log_warning(heap, stats)(\"HeapObjectStats counter overflow: resulting statistics will be useless\");\n-  }\n-  counter = newval;\n-}\n-\n-HeapObjectStatistics::HeapObjectStatistics() :\n-  _task(), _num_samples(0), _num_objects(0), _num_ihashed(0), _num_locked(0), _lds(0) { }\n-\n-void HeapObjectStatistics::start() {\n-  _task.enroll();\n-}\n-\n-void HeapObjectStatistics::stop() {\n-  _task.disenroll();\n-}\n-\n-void HeapObjectStatistics::begin_sample() {\n-  _num_samples++;\n-}\n-\n-void HeapObjectStatistics::visit_object(oop obj) {\n-  increase_counter(_num_objects);\n-  markWord mark = obj->mark();\n-  if (!mark.has_no_hash()) {\n-    increase_counter(_num_ihashed);\n-    if (mark.age() > 0) {\n-      increase_counter(_num_ihashed_moved);\n-    }\n-  }\n-  if (mark.is_locked()) {\n-    increase_counter(_num_locked);\n-  }\n-#ifdef ASSERT\n-#ifdef _LP64\n-  if (!mark.has_displaced_mark_helper()) {\n-    assert(mark.narrow_klass() == CompressedKlassPointers::encode(obj->klass_or_null()), \"upper 32 mark bits must be narrow klass: mark: \" INTPTR_FORMAT \", compressed-klass: \" INTPTR_FORMAT, (intptr_t)mark.narrow_klass(), (intptr_t)CompressedKlassPointers::encode(obj->klass_or_null()));\n-  }\n-#endif\n-#endif\n-  increase_counter(_lds, obj->size());\n-}\n-\n-void HeapObjectStatistics::print(outputStream* out) const {\n-  if (!HeapObjectStats) {\n-    return;\n-  }\n-  if (_num_samples == 0 || _num_objects == 0) {\n-    return;\n-  }\n-\n-  out->print_cr(\"Number of samples:  \" UINT64_FORMAT, _num_samples);\n-  out->print_cr(\"Average number of objects: \" UINT64_FORMAT, _num_objects \/ _num_samples);\n-  out->print_cr(\"Average object size: \" UINT64_FORMAT \" bytes, %.1f words\", (_lds * HeapWordSize) \/ _num_objects, (float) _lds \/ _num_objects);\n-  out->print_cr(\"Average number of hashed objects: \" UINT64_FORMAT \" (%.2f%%)\", _num_ihashed \/ _num_samples, (float) (_num_ihashed * 100.0) \/ _num_objects);\n-  out->print_cr(\"Average number of moved hashed objects: \" UINT64_FORMAT \" (%.2f%%)\", _num_ihashed_moved \/ _num_samples, (float) (_num_ihashed_moved * 100.0) \/ _num_objects);\n-  out->print_cr(\"Average number of locked objects: \" UINT64_FORMAT \" (%.2f%%)\", _num_locked \/ _num_samples, (float) (_num_locked * 100) \/ _num_objects);\n-  out->print_cr(\"Average LDS: \" UINT64_FORMAT \" bytes\", _lds * HeapWordSize \/ _num_samples);\n-  out->print_cr(\"Avg LDS with (assumed) 64bit header: \" UINT64_FORMAT \" bytes (%.1f%%)\", (_lds - _num_objects) * HeapWordSize \/ _num_samples, ((float) _lds - _num_objects) * 100.0 \/ _lds);\n-}\n","filename":"src\/hotspot\/share\/services\/heapObjectStatistics.cpp","additions":0,"deletions":177,"binary":false,"changes":177,"status":"deleted"},{"patch":"@@ -1,71 +0,0 @@\n-\/*\n- * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_SERVICES_HEAPOBJECTSTATISTICS_HPP\n-#define SHARE_SERVICES_HEAPOBJECTSTATISTICS_HPP\n-\n-#include \"memory\/allocation.hpp\"\n-#include \"oops\/oopsHierarchy.hpp\"\n-#include \"runtime\/task.hpp\"\n-#include \"runtime\/vmOperation.hpp\"\n-\n-class outputStream;\n-\n-class HeapObjectStatisticsTask : public PeriodicTask {\n-public:\n-  HeapObjectStatisticsTask();\n-  void task();\n-};\n-\n-class HeapObjectStatistics : public CHeapObj<mtGC> {\n-private:\n-  static HeapObjectStatistics* _instance;\n-\n-  HeapObjectStatisticsTask _task;\n-  uint64_t _num_samples;\n-  uint64_t _num_objects;\n-  uint64_t _num_ihashed;\n-  uint64_t _num_ihashed_moved;\n-  uint64_t _num_locked;\n-  uint64_t _lds;\n-\n-  static void increase_counter(uint64_t& counter, uint64_t val = 1);\n-\n-  void print(outputStream* out) const;\n-\n-public:\n-  static void initialize();\n-  static void shutdown();\n-\n-  static HeapObjectStatistics* instance();\n-\n-  HeapObjectStatistics();\n-  void start();\n-  void stop();\n-\n-  void begin_sample();\n-  void visit_object(oop object);\n-};\n-\n-#endif \/\/ SHARE_SERVICES_HEAPOBJECTSTATISTICS_HPP\n","filename":"src\/hotspot\/share\/services\/heapObjectStatistics.hpp","additions":0,"deletions":71,"binary":false,"changes":71,"status":"deleted"},{"patch":"@@ -0,0 +1,97 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_FASTHASH_HPP\n+#define SHARE_UTILITIES_FASTHASH_HPP\n+\n+#include \"memory\/allStatic.hpp\"\n+\n+class FastHash : public AllStatic {\n+private:\n+  static void fullmul64(uint64_t& hi, uint64_t& lo, uint64_t op1, uint64_t op2) {\n+#if defined(__SIZEOF_INT128__)\n+    __uint128_t prod = static_cast<__uint128_t>(op1) * static_cast<__uint128_t>(op2);\n+    hi = static_cast<uint64_t>(prod >> 64);\n+    lo = static_cast<uint64_t>(prod >>  0);\n+#else\n+    \/* First calculate all of the cross products. *\/\n+    uint64_t lo_lo = (op1 & 0xFFFFFFFF) * (op2 & 0xFFFFFFFF);\n+    uint64_t hi_lo = (op1 >> 32)        * (op2 & 0xFFFFFFFF);\n+    uint64_t lo_hi = (op1 & 0xFFFFFFFF) * (op2 >> 32);\n+    uint64_t hi_hi = (op1 >> 32)        * (op2 >> 32);\n+\n+    \/* Now add the products together. These will never overflow. *\/\n+    uint64_t cross = (lo_lo >> 32) + (hi_lo & 0xFFFFFFFF) + lo_hi;\n+    uint64_t upper = (hi_lo >> 32) + (cross >> 32)        + hi_hi;\n+    hi = upper;\n+    lo = (cross << 32) | (lo_lo & 0xFFFFFFFF);\n+#endif\n+  }\n+\n+  static void fullmul32(uint32_t& hi, uint32_t& lo, uint32_t op1, uint32_t op2) {\n+    uint64_t x64 = op1, y64 = op2, xy64 = x64 * y64;\n+    hi = (uint32_t)(xy64 >> 32);\n+    lo = (uint32_t)(xy64 >>  0);\n+  }\n+\n+  static uint64_t ror(uint64_t x, uint64_t distance) {\n+    distance = distance & 0x3F;\n+    return (x >> distance) | (x << (64 - distance));\n+  }\n+\n+public:\n+  static uint64_t get_hash64(uint64_t x, uint64_t y) {\n+    const uint64_t M  = 0x8ADAE89C337954D5;\n+    const uint64_t A  = 0xAAAAAAAAAAAAAAAA; \/\/ REPAA\n+    const uint64_t H0 = (x ^ y), L0 = (x ^ A);\n+\n+    uint64_t U0, V0; fullmul64(U0, V0, L0, M);\n+    const uint64_t Q0 = (H0 * M);\n+    const uint64_t L1 = (Q0 ^ U0);\n+\n+    uint64_t U1, V1; fullmul64(U1, V1, L1, M);\n+    const uint64_t P1 = (V0 ^ M);\n+    const uint64_t Q1 = ror(P1, L1);\n+    const uint64_t L2 = (Q1 ^ U1);\n+    return V1 ^ L2;\n+  }\n+\n+  static uint32_t get_hash32(uint32_t x, uint32_t y) {\n+    const uint32_t M  = 0x337954D5;\n+    const uint32_t A  = 0xAAAAAAAA; \/\/ REPAA\n+    const uint32_t H0 = (x ^ y), L0 = (x ^ A);\n+\n+    uint32_t U0, V0; fullmul32(U0, V0, L0, M);\n+    const uint32_t Q0 = (H0 * M);\n+    const uint32_t L1 = (Q0 ^ U0);\n+\n+    uint32_t U1, V1; fullmul32(U1, V1, L1, M);\n+    const uint32_t P1 = (V0 ^ M);\n+    const uint32_t Q1 = ror(P1, L1);\n+    const uint32_t L2 = (Q1 ^ U1);\n+    return V1 ^ L2;\n+  }\n+};\n+\n+#endif\/\/ SHARE_UTILITIES_FASTHASH_HPP\n","filename":"src\/hotspot\/share\/utilities\/fastHash.hpp","additions":97,"deletions":0,"binary":false,"changes":97,"status":"added"},{"patch":"@@ -78,0 +78,2 @@\n+    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+      headerSize = typeSize;\n@@ -79,6 +81,2 @@\n-      if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-         headerSize = typeSize;\n-      } else {\n-        headerSize = VM.getVM().alignUp(typeSize + VM.getVM().getIntSize(),\n-                                        VM.getVM().getHeapWordSize());\n-      }\n+      headerSize = VM.getVM().alignUp(typeSize + VM.getVM().getIntSize(),\n+                                      VM.getVM().getHeapWordSize());\n@@ -89,8 +87,0 @@\n-   private static long headerSize(BasicType type) {\n-     if (elementTypeShouldBeAligned(type)) {\n-        return alignObjectSize(headerSizeInBytes())\/VM.getVM().getHeapWordSize();\n-     } else {\n-       return headerSizeInBytes()\/VM.getVM().getHeapWordSize();\n-     }\n-   }\n-\n@@ -103,0 +93,2 @@\n+    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+      lengthOffsetInBytes = typeSize - VM.getVM().getIntSize();\n@@ -104,5 +96,1 @@\n-      if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-        lengthOffsetInBytes = typeSize - VM.getVM().getIntSize();\n-      } else {\n-        lengthOffsetInBytes = typeSize;\n-      }\n+      lengthOffsetInBytes = typeSize;\n@@ -131,8 +119,4 @@\n-    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n-      long typeSizeInBytes = headerSizeInBytes();\n-      if (elementTypeShouldBeAligned(type)) {\n-        VM vm = VM.getVM();\n-        return vm.alignUp(typeSizeInBytes, vm.getVM().getHeapWordSize());\n-      } else {\n-        return typeSizeInBytes;\n-      }\n+    long typeSizeInBytes = headerSizeInBytes();\n+    if (elementTypeShouldBeAligned(type)) {\n+      VM vm = VM.getVM();\n+      return vm.alignUp(typeSizeInBytes, vm.getVM().getHeapWordSize());\n@@ -140,1 +124,1 @@\n-      return headerSize(type) * VM.getVM().getHeapWordSize();\n+      return typeSizeInBytes;\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Array.java","additions":12,"deletions":28,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -72,1 +72,0 @@\n-        System.out.println(\"base: \" + baseField.getValue().minus(null));\n@@ -78,3 +77,1 @@\n-\n-      System.out.println(\"shift: \" + (int)shiftField.getValue());\n-      return (int)shiftField.getValue();\n+    return (int)shiftField.getValue();\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/CompressedKlassPointers.java","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -60,2 +60,1 @@\n-    }\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Instance.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -72,2 +72,1 @@\n-    \/\/ TODO: Lilliput. Probably ok.\n-    final int hubOffset = 4; \/\/ getFieldOffset(\"oopDesc::_metadata._klass\", Integer.class, \"Klass*\");\n+    final int hubOffset = getFieldOffset(\"oopDesc::_metadata._klass\", Integer.class, \"Klass*\");\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/hotspot\/HotSpotVMConfig.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -58,3 +59,1 @@\n-#ifdef _LP64\n-  FlagSetting fs(UseCompactObjectHeaders, false);\n-#endif\n+  FlagSetting fs(UseAltGCForwarding, false);\n","filename":"test\/hotspot\/gtest\/gc\/shared\/test_preservedMarks.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -0,0 +1,124 @@\n+\/*\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n+#include \"oops\/markWord.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"utilities\/align.hpp\"\n+#include \"unittest.hpp\"\n+\n+#ifdef _LP64\n+#ifndef PRODUCT\n+\n+static uintptr_t make_mark(uintptr_t target_region, uintptr_t offset) {\n+  return (target_region) << 3 | (offset << 4) | 3 \/* forwarded *\/;\n+}\n+\n+static uintptr_t make_fallback() {\n+  return ((uintptr_t(1) << 2) \/* fallback *\/ | 3 \/* forwarded *\/);\n+}\n+\n+\/\/ Test simple forwarding within the same region.\n+TEST_VM(SlidingForwarding, simple) {\n+  FlagSetting fs(UseAltGCForwarding, true);\n+  HeapWord fakeheap[32] = { nullptr };\n+  HeapWord* heap = align_up(fakeheap, 8 * sizeof(HeapWord));\n+  oop obj1 = cast_to_oop(&heap[2]);\n+  oop obj2 = cast_to_oop(&heap[0]);\n+  SlidingForwarding::initialize(MemRegion(&heap[0], &heap[16]), 8);\n+  obj1->set_mark(markWord::prototype());\n+  SlidingForwarding::begin();\n+\n+  SlidingForwarding::forward_to<true>(obj1, obj2);\n+  ASSERT_EQ(obj1->mark().value(), make_mark(0 \/* target_region *\/, 0 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(obj1), obj2);\n+\n+  SlidingForwarding::end();\n+}\n+\n+\/\/ Test forwardings crossing 2 regions.\n+TEST_VM(SlidingForwarding, tworegions) {\n+  FlagSetting fs(UseAltGCForwarding, true);\n+  HeapWord fakeheap[32] = { nullptr };\n+  HeapWord* heap = align_up(fakeheap, 8 * sizeof(HeapWord));\n+  oop obj1 = cast_to_oop(&heap[14]);\n+  oop obj2 = cast_to_oop(&heap[2]);\n+  oop obj3 = cast_to_oop(&heap[10]);\n+  SlidingForwarding::initialize(MemRegion(&heap[0], &heap[16]), 8);\n+  obj1->set_mark(markWord::prototype());\n+  SlidingForwarding::begin();\n+\n+  SlidingForwarding::forward_to<true>(obj1, obj2);\n+  ASSERT_EQ(obj1->mark().value(), make_mark(0 \/* target_region *\/, 2 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(obj1), obj2);\n+\n+  SlidingForwarding::forward_to<true>(obj1, obj3);\n+  ASSERT_EQ(obj1->mark().value(), make_mark(1 \/* target_region *\/, 2 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(obj1), obj3);\n+\n+  SlidingForwarding::end();\n+}\n+\n+\/\/ Test fallback forwardings crossing 4 regions.\n+TEST_VM(SlidingForwarding, fallback) {\n+  FlagSetting fs(UseAltGCForwarding, true);\n+  HeapWord fakeheap[32] = { nullptr };\n+  HeapWord* heap = align_up(fakeheap, 8 * sizeof(HeapWord));\n+  oop s_obj1 = cast_to_oop(&heap[12]);\n+  oop s_obj2 = cast_to_oop(&heap[13]);\n+  oop s_obj3 = cast_to_oop(&heap[14]);\n+  oop s_obj4 = cast_to_oop(&heap[15]);\n+  oop t_obj1 = cast_to_oop(&heap[2]);\n+  oop t_obj2 = cast_to_oop(&heap[4]);\n+  oop t_obj3 = cast_to_oop(&heap[10]);\n+  oop t_obj4 = cast_to_oop(&heap[12]);\n+  SlidingForwarding::initialize(MemRegion(&heap[0], &heap[16]), 4);\n+  s_obj1->set_mark(markWord::prototype());\n+  s_obj2->set_mark(markWord::prototype());\n+  s_obj3->set_mark(markWord::prototype());\n+  s_obj4->set_mark(markWord::prototype());\n+  SlidingForwarding::begin();\n+\n+  SlidingForwarding::forward_to<true>(s_obj1, t_obj1);\n+  ASSERT_EQ(s_obj1->mark().value(), make_mark(0 \/* target_region *\/, 2 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(s_obj1), t_obj1);\n+\n+  SlidingForwarding::forward_to<true>(s_obj2, t_obj2);\n+  ASSERT_EQ(s_obj2->mark().value(), make_mark(1 \/* target_region *\/, 0 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(s_obj2), t_obj2);\n+\n+  SlidingForwarding::forward_to<true>(s_obj3, t_obj3);\n+  ASSERT_EQ(s_obj3->mark().value(), make_fallback());\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(s_obj3), t_obj3);\n+\n+  SlidingForwarding::forward_to<true>(s_obj4, t_obj4);\n+  ASSERT_EQ(s_obj4->mark().value(), make_fallback());\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(s_obj4), t_obj4);\n+\n+  SlidingForwarding::end();\n+}\n+\n+#endif \/\/ PRODUCT\n+#endif \/\/ _LP64\n","filename":"test\/hotspot\/gtest\/gc\/shared\/test_slidingForwarding.cpp","additions":124,"deletions":0,"binary":false,"changes":124,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2016, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,8 +30,0 @@\n-class arrayOopDescTest {\n- public:\n-\n-  static int header_size_in_bytes() {\n-    return arrayOopDesc::header_size_in_bytes();\n-  }\n-};\n-\n@@ -42,1 +34,1 @@\n-          + arrayOopDescTest::header_size_in_bytes();\n+          + arrayOopDesc::base_offset_in_bytes(type);\n@@ -90,0 +82,55 @@\n+\n+TEST_VM(arrayOopDesc, base_offset) {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BOOLEAN), 12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BYTE),    12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_SHORT),   12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_CHAR),    12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_INT),     12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_FLOAT),   12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_LONG),    16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_DOUBLE),  16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT),  12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),   12);\n+  } else if (UseCompressedClassPointers) {\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BOOLEAN), 16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BYTE),    16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_SHORT),   16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_CHAR),    16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_INT),     16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_FLOAT),   16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_LONG),    16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_DOUBLE),  16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT),  16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),   16);\n+  } else {\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BOOLEAN), 20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BYTE),    20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_SHORT),   20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_CHAR),    20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_INT),     20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_FLOAT),   20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_LONG),    24);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_DOUBLE),  24);\n+    if (UseCompressedOops) {\n+      EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT), 20);\n+      EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),  20);\n+    } else {\n+      EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT), 24);\n+      EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),  24);\n+    }\n+  }\n+#else\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BOOLEAN), 12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BYTE),    12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_SHORT),   12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_CHAR),    12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_INT),     12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_FLOAT),   12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_LONG),    16);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_DOUBLE),  16);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT),  12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),   12);\n+#endif\n+}\n","filename":"test\/hotspot\/gtest\/oops\/test_arrayOop.cpp","additions":57,"deletions":10,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -0,0 +1,57 @@\n+\/*\n+ * Copyright Amazon.com Inc. or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"oops\/objArrayOop.hpp\"\n+#include \"unittest.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+TEST_VM(objArrayOop, osize) {\n+  static const struct {\n+    int objal; bool ccp; bool coops; int result;\n+  } x[] = {\n+\/\/    ObjAligInB, UseCCP, UseCoops, object size in heap words\n+#ifdef _LP64\n+    { 8,          false,  false,    4 },  \/\/ 20 byte header, 8 byte oops\n+    { 8,          false,  true,     3 },  \/\/ 20 byte header, 4 byte oops\n+    { 8,          true,   false,    3 },  \/\/ 16 byte header, 8 byte oops\n+    { 8,          true,   true,     3 },  \/\/ 16 byte header, 4 byte oops\n+    { 16,         false,  false,    4 },  \/\/ 20 byte header, 8 byte oops, 16-byte align\n+    { 16,         false,  true,     4 },  \/\/ 20 byte header, 4 byte oops, 16-byte align\n+    { 16,         true,   false,    4 },  \/\/ 16 byte header, 8 byte oops, 16-byte align\n+    { 16,         true,   true,     4 },  \/\/ 16 byte header, 4 byte oops, 16-byte align\n+    { 256,        false,  false,    32 }, \/\/ 20 byte header, 8 byte oops, 256-byte align\n+    { 256,        false,  true,     32 }, \/\/ 20 byte header, 4 byte oops, 256-byte align\n+    { 256,        true,   false,    32 }, \/\/ 16 byte header, 8 byte oops, 256-byte align\n+    { 256,        true,   true,     32 }, \/\/ 16 byte header, 4 byte oops, 256-byte align\n+#else\n+    { 8,          false,  false,    4 }, \/\/ 12 byte header, 4 byte oops, wordsize 4\n+#endif\n+    { -1,         false,  false,   -1 }\n+  };\n+  for (int i = 0; x[i].result != -1; i++) {\n+    if (x[i].objal == (int)ObjectAlignmentInBytes && x[i].ccp == UseCompressedClassPointers && x[i].coops == UseCompressedOops) {\n+      EXPECT_EQ(objArrayOopDesc::object_size(1), (size_t)x[i].result);\n+    }\n+  }\n+}\n","filename":"test\/hotspot\/gtest\/oops\/test_objArrayOop.cpp","additions":57,"deletions":0,"binary":false,"changes":57,"status":"added"},{"patch":"@@ -39,3 +39,5 @@\n-#ifndef _LP64\n-  o->set_klass(Universe::boolArrayKlassObj());\n-#endif\n+  if (UseCompactObjectHeaders) {\n+    o->set_mark(Universe::boolArrayKlassObj()->prototype_header());\n+  } else {\n+    o->set_klass(Universe::boolArrayKlassObj());\n+  }\n","filename":"test\/hotspot\/gtest\/oops\/test_typeArrayOop.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -174,13 +174,0 @@\n-\n-Lilliput temporary:\n-compiler\/c2\/irTests\/TestVectorizationNotRun.java 8301785 generic-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#x64-area-beyond-encoding-range-use-xor 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#x64-area-partly-within-encoding-range-use-add 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#x64-area-within-encoding-range-use-zero 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#x64-area-far-out-no-low-bits-use-xor 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#x64-area-far-out-with-low-bits-use-add 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#aarch64-xor 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#aarch64-movk-1 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#aarch64-movk-2 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassPointerEncoding.java#aarch64-movk-3 8302094 windows-all,macosx-all\n-runtime\/CompressedOops\/CompressedClassSpaceSize.java 8302094 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":0,"deletions":13,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -387,0 +387,2 @@\n+ -runtime\/Metaspace\/elastic\/TestMetaspaceAllocationMT1.java \\\n+ -runtime\/Metaspace\/elastic\/TestMetaspaceAllocationMT2.java \\\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,7 +34,0 @@\n-\/\/ Note Lilliput:\n-\/\/ Tests test that vectorization is used to fill destination byte array if alignment allows. That works in Stock VM\n-\/\/ since for both byte[] and long[] members start at the same offset. It does not work in Lilliput, nor would it work\n-\/\/ in stock if we fix \"8139457: Array bases are aligned at HeapWord granularity\", since bytes start at offset 12, long\n-\/\/ at offset 16.\n-\/\/ For now I just enforce -CompactObjectHeaders.\n-\n@@ -65,1 +58,1 @@\n-            TestFramework.runWithFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"--add-modules\", \"java.base\", \"--add-exports\", \"java.base\/jdk.internal.misc=ALL-UNNAMED\");\n+            TestFramework.runWithFlags(\"--add-modules\", \"java.base\", \"--add-exports\", \"java.base\/jdk.internal.misc=ALL-UNNAMED\");\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/TestVectorizationMismatchedAccess.java","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -25,5 +25,0 @@\n-\/\/ Note Lilliput:\n-\/\/ Tests rely on array members starting at the same offset, otherwise vectorization does not kick in. Not true\n-\/\/ for Lilliput.\n-\/\/ For now I just enforce -CompactObjectHeaders.\n-\n@@ -86,1 +81,1 @@\n-                                   \"-XX:LoopUnrollLimit=1000\", \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\");\n+                                   \"-XX:LoopUnrollLimit=1000\");\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestIndependentPacksWithCyclicDependency.java","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -36,0 +36,5 @@\n+ *                                 -XX:+UseCompressedOops -XX:-UseCompressedClassPointers\n+ *                                 -XX:CompileCommand=dontinline,compiler.unsafe.OpaqueAccesses::test*\n+ *                                 compiler.unsafe.OpaqueAccesses\n+ * @run main\/bootclasspath\/othervm -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                                 -XX:-TieredCompilation -Xbatch\n@@ -38,0 +43,5 @@\n+ *                                 compiler.unsafe.OpaqueAccesses\n+ * @run main\/bootclasspath\/othervm -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n+ *                                 -XX:-TieredCompilation -Xbatch\n+ *                                 -XX:-UseCompressedOops -XX:-UseCompressedClassPointers\n+ *                                 -XX:CompileCommand=dontinline,compiler.unsafe.OpaqueAccesses::test*\n","filename":"test\/hotspot\/jtreg\/compiler\/unsafe\/OpaqueAccesses.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -0,0 +1,56 @@\n+\/*\n+ * Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package gc.arguments;\n+\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.Platform;\n+\n+\/*\n+ * @test\n+ * @bug 8015107\n+ * @summary Tests that VM prints a warning when -XX:CompressedClassSpaceSize\n+ *          is used together with -XX:-UseCompressedClassPointers\n+ * @library \/test\/lib\n+ * @library \/\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @run driver gc.arguments.TestCompressedClassFlags\n+ *\/\n+public class TestCompressedClassFlags {\n+    public static void main(String[] args) throws Exception {\n+        if (Platform.is64bit()) {\n+            OutputAnalyzer output = runJava(\"-XX:CompressedClassSpaceSize=1g\",\n+                                            \"-XX:-UseCompressedClassPointers\",\n+                                            \"-version\");\n+            output.shouldContain(\"warning\");\n+            output.shouldNotContain(\"error\");\n+            output.shouldHaveExitValue(0);\n+        }\n+    }\n+\n+    private static OutputAnalyzer runJava(String ... args) throws Exception {\n+        ProcessBuilder pb = GCArguments.createJavaProcessBuilder(args);\n+        return new OutputAnalyzer(pb.start());\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/gc\/arguments\/TestCompressedClassFlags.java","additions":56,"deletions":0,"binary":false,"changes":56,"status":"added"},{"patch":"@@ -129,3 +129,1 @@\n-    \/\/ Lilliput: do not assume a max. class space size, since that is subject to change. Instead, use a value slightly smaller\n-    \/\/  than what the parent VM runs with (which is the default size).\n-    String compressedClassSpaceSizeArg = \"-XX:CompressedClassSpaceSize=\" + (getCompressedClassSpaceSize() - 1);\n+    String compressedClassSpaceSizeArg = \"-XX:CompressedClassSpaceSize=\" + 2 * getCompressedClassSpaceSize();\n","filename":"test\/hotspot\/jtreg\/gc\/arguments\/TestUseCompressedOopsErgoTools.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-        dump_args.addAll(Arrays.asList(new String[] { \"-Xshare:dump\", \"-Xlog:cds*\", \"-Xlog:metaspace*\" }));\n+        dump_args.addAll(Arrays.asList(new String[] { \"-Xshare:dump\", \"-Xlog:cds\" }));\n@@ -64,1 +64,0 @@\n-        output.reportDiagnosticSummary();\n@@ -74,1 +73,1 @@\n-            load_args.addAll(Arrays.asList(new String[] { \"-Xshare:on\", \"-Xlog:cds*\", \"-Xlog:metaspace*\", \"-version\" }));\n+            load_args.addAll(Arrays.asList(new String[] { \"-Xshare:on\", \"-version\" }));\n@@ -78,1 +77,0 @@\n-            output.reportDiagnosticSummary();\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestSharedArchiveWithPreTouch.java","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n- * @run main\/timeout=240 gc.g1.plab.TestPLABPromotion\n+ * @run main\/othervm\/timeout=240 -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI gc.g1.plab.TestPLABPromotion\n@@ -51,0 +51,1 @@\n+import jdk.test.whitebox.WhiteBox;\n@@ -57,0 +58,2 @@\n+    private static final boolean COMPACT_HEADERS = Platform.is64bit() && WhiteBox.getWhiteBox().getBooleanVMFlag(\"UseCompactObjectHeaders\");\n+\n@@ -76,1 +79,1 @@\n-    private static final int OBJECT_SIZE_HIGH = Platform.is64bit() ? 3266 : 3258;\n+    private static final int OBJECT_SIZE_HIGH   = COMPACT_HEADERS ? 3266 : 3250;\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/plab\/TestPLABPromotion.java","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -38,1 +38,2 @@\n- * @run driver gc.metaspace.TestSizeTransitions -XX:+UseSerialGC\n+ * @run driver gc.metaspace.TestSizeTransitions false -XX:+UseSerialGC\n+ * @run driver gc.metaspace.TestSizeTransitions true  -XX:+UseSerialGC\n@@ -45,1 +46,2 @@\n- * @run driver gc.metaspace.TestSizeTransitions -XX:+UseParallelGC\n+ * @run driver gc.metaspace.TestSizeTransitions false -XX:+UseParallelGC\n+ * @run driver gc.metaspace.TestSizeTransitions true  -XX:+UseParallelGC\n@@ -52,1 +54,2 @@\n- * @run driver gc.metaspace.TestSizeTransitions -XX:+UseG1GC\n+ * @run driver gc.metaspace.TestSizeTransitions false -XX:+UseG1GC\n+ * @run driver gc.metaspace.TestSizeTransitions true  -XX:+UseG1GC\n@@ -90,2 +93,2 @@\n-    \/\/ args: <gc-arg>\n-    if (args.length != 1) {\n+    \/\/ args: <use-coops> <gc-arg>\n+    if (args.length != 2) {\n@@ -96,1 +99,8 @@\n-    final String gcArg = args[0];\n+    final boolean useCompressedKlassPointers = Boolean.parseBoolean(args[0]);\n+    final String gcArg = args[1];\n+\n+    if (!hasCompressedKlassPointers && useCompressedKlassPointers) {\n+       \/\/ No need to run this configuration.\n+       System.out.println(\"Skipping test.\");\n+       return;\n+    }\n@@ -99,0 +109,3 @@\n+    if (hasCompressedKlassPointers) {\n+      jvmArgs.add(useCompressedKlassPointers ? \"-XX:+UseCompressedClassPointers\" : \"-XX:-UseCompressedClassPointers\");\n+    }\n@@ -114,1 +127,1 @@\n-    if (hasCompressedKlassPointers) {\n+    if (useCompressedKlassPointers) {\n","filename":"test\/hotspot\/jtreg\/gc\/metaspace\/TestSizeTransitions.java","additions":20,"deletions":7,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n- *   -Xmx1100M -XX:G1HeapRegionSize=8m -XX:MaxGCPauseMillis=1000 gc.stress.TestMultiThreadStressRSet 60 16\n+ *   -Xmx1G -XX:G1HeapRegionSize=8m -XX:MaxGCPauseMillis=1000 gc.stress.TestMultiThreadStressRSet 60 16\n","filename":"test\/hotspot\/jtreg\/gc\/stress\/TestMultiThreadStressRSet.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -58,1 +58,0 @@\n- * @requires vm.debug\n@@ -63,37 +62,0 @@\n-\n-\n-\/* @test id=ccs-on-compact-headers-on\n- * @summary Run with +UseCCS and +UseCompactObjectHeaders\n- * @library \/test\/lib\n- * @modules java.base\/jdk.internal.misc\n- *          java.xml\n- * @requires vm.debug\n- * @requires vm.bits == 64\n- * @requires vm.flagless\n- * @run main\/native GTestWrapper --gtest_filter=metaspace* -Xlog:metaspace* -XX:+UnlockExperimentalVMOptions -XX:+UseCompactObjectHeaders -XX:+UseCompressedClassPointers -XX:VerifyMetaspaceInterval=3\n- *\/\n-\n-\/* @test id=ccs-on-compact-headers-off\n- * @summary Run with +UseCCS and -UseCompactObjectHeaders\n- * @library \/test\/lib\n- * @modules java.base\/jdk.internal.misc\n- *          java.xml\n- * @requires vm.debug\n- * @requires vm.bits == 64\n- * @requires vm.flagless\n- * @run main\/native GTestWrapper --gtest_filter=metaspace* -Xlog:metaspace* -XX:+UnlockExperimentalVMOptions -XX:-UseCompactObjectHeaders -XX:+UseCompressedClassPointers -XX:VerifyMetaspaceInterval=3\n- *\/\n-\n-\/* @test id=ccs-off\n- * @summary Run with -UseCCS\n- * @library \/test\/lib\n- * @modules java.base\/jdk.internal.misc\n- *          java.xml\n- * @requires vm.debug\n- * @requires vm.bits == 64\n- * @requires vm.flagless\n- * @run main\/native GTestWrapper --gtest_filter=metaspace* -Xlog:metaspace* -XX:-UseCompressedClassPointers -XX:VerifyMetaspaceInterval=3\n- *\/\n-\n-\n-\n","filename":"test\/hotspot\/jtreg\/gtest\/MetaspaceGtests.java","additions":0,"deletions":38,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -30,0 +30,11 @@\n+\n+\/* @test\n+ * @bug 8264008\n+ * @summary Run metaspace utils related gtests with compressed class pointers off\n+ * @requires vm.bits == 64\n+ * @library \/test\/lib\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.xml\n+ * @requires vm.flagless\n+ * @run main\/native GTestWrapper --gtest_filter=MetaspaceUtils* -XX:-UseCompressedClassPointers\n+ *\/\n","filename":"test\/hotspot\/jtreg\/gtest\/MetaspaceUtilsGtests.java","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+ * @run main\/othervm -XX:+UseCompressedOops -XX:-UseCompressedClassPointers FieldDensityTest\n","filename":"test\/hotspot\/jtreg\/runtime\/FieldLayout\/FieldDensityTest.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -51,1 +51,11 @@\n- * @test id=test-64bit-compact-headers\n+ * @test id=test-64bit-noccs\n+ * @summary Test the VM.metaspace command\n+ * @requires vm.bits == \"64\"\n+ * @library \/test\/lib\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @run main\/othervm -Dwithout-compressed-class-space -XX:MaxMetaspaceSize=201M -Xmx100M -XX:-UseCompressedOops -XX:-UseCompressedClassPointers PrintMetaspaceDcmd\n+ *\/\n+\n+ \/*\n+ * @test id=test-nospecified\n@@ -54,1 +64,0 @@\n- * @requires vm.debug == true\n@@ -58,1 +67,1 @@\n- * @run main\/othervm -Dwith-compressed-class-space -XX:+UnlockExperimentalVMOptions -XX:+UseCompactObjectHeaders -XX:MaxMetaspaceSize=201M -Xmx100M -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:+UnlockDiagnosticVMOptions -XX:+MetaspaceGuardAllocations PrintMetaspaceDcmd\n+ * @run main\/othervm -Dno-specified-flag -Xmx100M -XX:-UseCompressedOops -XX:-UseCompressedClassPointers PrintMetaspaceDcmd\n","filename":"test\/hotspot\/jtreg\/runtime\/Metaspace\/PrintMetaspaceDcmd.java","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-      processArgs.add(\"-XX:MaxMetaspaceSize=2m\");\n+      processArgs.add(\"-XX:MaxMetaspaceSize=3m\");\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/MaxMetaspaceSize.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -70,0 +70,2 @@\n+        testTable.add( new TestVector(\"-XX:+UseCompressedClassPointers\", \"-XX:-UseCompressedClassPointers\",\n+           \"The saved state of UseCompressedOops and UseCompressedClassPointers is different from runtime, CDS will be disabled.\", 1) );\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/CommandLineFlagComboNegative.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+        public boolean useCompressedClassPointers;   \/\/ UseCompressedClassPointers\n@@ -51,1 +52,1 @@\n-        public ConfArg(boolean useCompressedOops, String msg, int code) {\n+        public ConfArg(boolean useCompressedOops, boolean useCompressedClassPointers, String msg, int code) {\n@@ -53,0 +54,1 @@\n+            this.useCompressedClassPointers = useCompressedClassPointers;\n@@ -67,1 +69,1 @@\n-            *          UseCompressedOops   Result\n+            *          UseCompressedOops   UseCompressedClassPointers  Result\n@@ -69,3 +71,5 @@\n-            *    dump: on\n-            *    test: on                  Pass\n-            *          off                 Fail\n+            *    dump: on                  on\n+            *    test: on                  on                          Pass\n+            *          on                  off                         Fail\n+            *          off                 on                          Fail\n+            *          off                 off                         Fail\n@@ -73,3 +77,15 @@\n-            *    dump: off\n-            *    test: off                 Pass\n-            *          on                  Fail\n+            *    dump: on                  off\n+            *    test: on                  off                         Pass\n+            *          on                  on                          Fail\n+            *          off                 on                          Pass\n+            *          off                 off                         Fail\n+            *    3.\n+            *    dump: off                 on\n+            *    test: off                 on                          Pass\n+            *          on                  on                          Fail\n+            *          on                  off                         Fail\n+            *    4.\n+            *    dump: off                 off\n+            *    test: off                 off                         Pass\n+            *          on                  on                          Fail\n+            *          on                  off                         Fail\n@@ -78,1 +94,1 @@\n-            if (dumpArg.useCompressedOops) {\n+            if (dumpArg.useCompressedOops && dumpArg.useCompressedClassPointers) {\n@@ -80,1 +96,1 @@\n-                    .add(new ConfArg(true, HELLO_STRING, PASS));\n+                    .add(new ConfArg(true, true, HELLO_STRING, PASS));\n@@ -82,1 +98,15 @@\n-                    .add(new ConfArg(false, EXEC_ABNORMAL_MSG, FAIL));\n+                    .add(new ConfArg(true, false, EXEC_ABNORMAL_MSG, FAIL));\n+                execArgs\n+                    .add(new ConfArg(false, true, EXEC_ABNORMAL_MSG, FAIL));\n+                execArgs\n+                    .add(new ConfArg(false, false, EXEC_ABNORMAL_MSG, FAIL));\n+\n+            }  else if(dumpArg.useCompressedOops && !dumpArg.useCompressedClassPointers) {\n+                execArgs\n+                    .add(new ConfArg(true, false, HELLO_STRING, PASS));\n+                execArgs\n+                    .add(new ConfArg(true, true, EXEC_ABNORMAL_MSG, FAIL));\n+                execArgs\n+                    .add(new ConfArg(false, true, EXEC_ABNORMAL_MSG, FAIL));\n+                execArgs\n+                    .add(new ConfArg(false, false, EXEC_ABNORMAL_MSG, FAIL));\n@@ -84,1 +114,3 @@\n-            } else if (!dumpArg.useCompressedOops) {\n+            } else if (!dumpArg.useCompressedOops && dumpArg.useCompressedClassPointers) {\n+                execArgs\n+                    .add(new ConfArg(false, true, HELLO_STRING, PASS));\n@@ -86,1 +118,1 @@\n-                    .add(new ConfArg(false, HELLO_STRING, PASS));\n+                    .add(new ConfArg(true, true, EXEC_ABNORMAL_MSG, FAIL));\n@@ -88,1 +120,8 @@\n-                    .add(new ConfArg(true, EXEC_ABNORMAL_MSG, FAIL));\n+                    .add(new ConfArg(true, false, EXEC_ABNORMAL_MSG, FAIL));\n+            } else if (!dumpArg.useCompressedOops && !dumpArg.useCompressedClassPointers) {\n+                execArgs\n+                    .add(new ConfArg(false, false, HELLO_STRING, PASS));\n+                execArgs\n+                    .add(new ConfArg(true, true, EXEC_ABNORMAL_MSG, FAIL));\n+                execArgs\n+                    .add(new ConfArg(true, false, EXEC_ABNORMAL_MSG, FAIL));\n@@ -98,0 +137,5 @@\n+    public static String getCompressedClassPointersArg(boolean on) {\n+        if (on) return \"-XX:+UseCompressedClassPointers\";\n+        else    return \"-XX:-UseCompressedClassPointers\";\n+    }\n+\n@@ -103,1 +147,5 @@\n-            .add(new RunArg(new ConfArg(true, null, PASS)));\n+            .add(new RunArg(new ConfArg(true, true, null, PASS)));\n+        runList\n+            .add(new RunArg(new ConfArg(true, false, null, PASS)));\n+        runList\n+            .add(new RunArg(new ConfArg(false, true, null, PASS)));\n@@ -105,1 +153,1 @@\n-            .add(new RunArg(new ConfArg(false, null, PASS)));\n+            .add(new RunArg(new ConfArg(false, false, null, PASS)));\n@@ -117,0 +165,2 @@\n+                      getCompressedClassPointersArg(t.dumpArg.useCompressedClassPointers),\n+                      \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n@@ -129,0 +179,2 @@\n+                                      getCompressedClassPointersArg(c.useCompressedClassPointers),\n+                                      \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/TestCombinedCompressedFlags.java","additions":68,"deletions":16,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+         String compactHeaders = \"-XX:\" + (zGenerational.equals(\"-XX:+ZGenerational\") ? \"+\" : \"-\") + \"UseCompactObjectHeaders\";\n@@ -66,0 +67,2 @@\n+                                        \"-XX:+UnlockExperimentalVMOptions\",\n+                                        compactHeaders,\n@@ -75,0 +78,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -86,0 +91,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -92,1 +99,15 @@\n-         System.out.println(\"3. Run with -UseCompressedOops +UseCompressedClassPointers\");\n+         System.out.println(\"3. Run with -UseCompressedOops -UseCompressedClassPointers\");\n+         out = TestCommon\n+                   .exec(helloJar,\n+                         \"-XX:+UseSerialGC\",\n+                         \"-XX:-UseCompressedOops\",\n+                         \"-XX:-UseCompressedClassPointers\",\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n+                         \"-Xlog:cds\",\n+                         \"Hello\");\n+         out.shouldContain(UNABLE_TO_USE_ARCHIVE);\n+         out.shouldContain(ERR_MSG);\n+         out.shouldHaveExitValue(1);\n+\n+         System.out.println(\"4. Run with -UseCompressedOops +UseCompressedClassPointers\");\n@@ -98,0 +119,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -103,1 +126,15 @@\n-         System.out.println(\"4. Run with +UseCompressedOops +UseCompressedClassPointers\");\n+         System.out.println(\"5. Run with +UseCompressedOops -UseCompressedClassPointers\");\n+         out = TestCommon\n+                   .exec(helloJar,\n+                         \"-XX:+UseSerialGC\",\n+                         \"-XX:+UseCompressedOops\",\n+                         \"-XX:-UseCompressedClassPointers\",\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n+                         \"-Xlog:cds\",\n+                         \"Hello\");\n+         out.shouldContain(UNABLE_TO_USE_ARCHIVE);\n+         out.shouldContain(ERR_MSG);\n+         out.shouldHaveExitValue(1);\n+\n+         System.out.println(\"6. Run with +UseCompressedOops +UseCompressedClassPointers\");\n@@ -109,0 +146,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -115,1 +154,14 @@\n-         System.out.println(\"5. Run with ZGC\");\n+         System.out.println(\"7. Dump with -UseCompressedOops -UseCompressedClassPointers\");\n+         out = TestCommon\n+                   .dump(helloJar,\n+                         new String[] {\"Hello\"},\n+                         \"-XX:+UseSerialGC\",\n+                         \"-XX:-UseCompressedOops\",\n+                         \"-XX:+UseCompressedClassPointers\",\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n+                         \"-Xlog:cds\");\n+         out.shouldContain(\"Dumping shared data to file:\");\n+         out.shouldHaveExitValue(0);\n+\n+         System.out.println(\"8. Run with ZGC\");\n@@ -120,0 +172,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/TestZGCWithCDS.java","additions":57,"deletions":3,"binary":false,"changes":60,"status":"modified"},{"patch":"@@ -170,1 +170,1 @@\n-                                                \"-XX:+UseZGC\", zGenerational, \"-XX:ZCollectionInterval=0.01\",\n+                                                \"-XX:+UseZGC\", zGenerational, \"-XX:ZCollectionInterval=0.01\", \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/loaderConstraints\/DynamicLoaderConstraintsTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -101,1 +101,1 @@\n-                        Platform.is64bit() ? 549755813632L: 4294967168L);\n+                       Platform.is64bit() ? 549755813632L: 4294967168L);\n","filename":"test\/hotspot\/jtreg\/serviceability\/sa\/ClhsdbLongConstant.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -134,1 +134,2 @@\n-        runCheck(BadFailOnConstraint.create(Loads.class, \"load()\", 1, 1, \"Load\"),\n+        runCheck(new String[] {\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:-UseCompressedClassPointers\"},\n+                 BadFailOnConstraint.create(Loads.class, \"load()\", 1, 1, \"Load\"),\n","filename":"test\/hotspot\/jtreg\/testlibrary_tests\/ir_framework\/tests\/TestIRMatching.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -304,0 +304,1 @@\n+    private static final boolean COMPACT_HEADERS = Platform.is64bit() && WhiteBox.getWhiteBox().getBooleanVMFlag(\"UseCompactObjectHeaders\");\n@@ -374,0 +375,10 @@\n+    private static long expectedSmallObjSize() {\n+        long size;\n+        if (!Platform.is64bit() || COMPACT_HEADERS) {\n+            size = 8;\n+        } else {\n+            size = 16;\n+        }\n+        return roundUp(size, OBJ_ALIGN);\n+    }\n+\n@@ -375,1 +386,1 @@\n-        long expected = roundUp(8, OBJ_ALIGN);\n+        long expected = expectedSmallObjSize();\n@@ -382,1 +393,1 @@\n-        long expected = roundUp(8, OBJ_ALIGN);\n+        long expected = expectedSmallObjSize();\n@@ -392,1 +403,1 @@\n-        long expected = roundUp(8, OBJ_ALIGN);\n+        long expected = expectedSmallObjSize();\n","filename":"test\/jdk\/java\/lang\/instrument\/GetObjectSizeIntrinsicsTest.java","additions":14,"deletions":3,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -73,2 +73,1 @@\n-        \/\/ length will be in klass-gap on 64 bits, extra field on 32 bits.\n-        int objectHeaderSize = bytesPerWord * (runsOn32Bit ? 3 : 2);\n+        int objectHeaderSize = bytesPerWord * 3; \/\/ length will be aligned on 64 bits\n","filename":"test\/jdk\/jdk\/jfr\/event\/gc\/objectcount\/ObjectCountEventVerifier.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -81,3 +81,0 @@\n-\n-\n-jdk\/jshell\/ToolTabSnippetTest.java 1234567 generic-all\n","filename":"test\/langtools\/ProblemList.txt","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"}]}