{"files":[{"patch":"@@ -3944,32 +3944,8 @@\n-      \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n-      __ orr(tmp, disp_hdr, markWord::unlocked_value);\n-\n-      \/\/ Initialize the box. (Must happen before we update the object mark!)\n-      __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-      \/\/ Compare object markWord with an unlocked value (tmp) and if\n-      \/\/ equal exchange the stack address of our box with object markWord.\n-      \/\/ On failure disp_hdr contains the possibly locked markWord.\n-      __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n-                 \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n-      __ br(Assembler::EQ, cont);\n-\n-      assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n-      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-      \/\/ object, will have now locked it will continue at label cont\n-\n-      __ bind(cas_failed);\n-      \/\/ We did not see an unlocked object so try the fast recursive case.\n-\n-      \/\/ Check if the owner is self by comparing the value in the\n-      \/\/ markWord of object (disp_hdr) with the stack pointer.\n-      __ mov(rscratch1, sp);\n-      __ sub(disp_hdr, disp_hdr, rscratch1);\n-      __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-      \/\/ If condition is true we are cont and hence we can store 0 as the\n-      \/\/ displaced header in the box, which indicates that it is a recursive lock.\n-      __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n-      __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-    } else {\n-      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n+      Label slow;\n+      __ fast_lock(oop, disp_hdr, box, tmp, rscratch1, slow);\n+\n+      \/\/ Indicate success at cont.\n+      __ cmp(oop, oop);\n+      __ b(cont);\n+\n+      __ bind(slow);\n@@ -3977,0 +3953,1 @@\n+    __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n@@ -3990,7 +3967,0 @@\n-    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n-    \/\/ lock. The fast-path monitor unlock code checks for\n-    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n-    \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n-    __ mov(tmp, (address)markWord::unused_mark().value());\n-    __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n@@ -4022,9 +3992,0 @@\n-    if (!UseHeavyMonitors) {\n-      \/\/ Find the lock address and load the displaced header from the stack.\n-      __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-      \/\/ If the displaced header is 0, we have a recursive unlock.\n-      __ cmp(disp_hdr, zr);\n-      __ br(Assembler::EQ, cont);\n-    }\n-\n@@ -4033,1 +3994,2 @@\n-    __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);\n+\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n@@ -4036,3 +3998,2 @@\n-      \/\/ Check if it is still a light weight lock, this is is true if we\n-      \/\/ see the stack address of the basicLock in the markWord of the\n-      \/\/ object.\n+      Label slow;\n+      __ tbnz(tmp, exact_log2(markWord::monitor_value), object_has_monitor);\n@@ -4040,4 +4001,7 @@\n-      __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n-                 \/*release*\/ true, \/*weak*\/ false, tmp);\n-    } else {\n-      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n+      __ fast_unlock(oop, tmp, box, disp_hdr, slow);\n+\n+      \/\/ Indicate success at cont.\n+      __ cmp(oop, oop);\n+      __ b(cont);\n+\n+      __ bind(slow);\n@@ -4045,0 +4009,1 @@\n+    __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n@@ -4047,2 +4012,0 @@\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n@@ -4053,0 +4016,12 @@\n+\n+    \/\/ If the owner is anonymous, we need to fix it -- in the slow-path.\n+    {\n+      Label L;\n+      __ ldr(disp_hdr, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));\n+      __ cmp(disp_hdr, (unsigned char)(intptr_t) ANONYMOUS_OWNER);\n+      __ br(Assembler::NE, L);\n+      __ tst(oop, oop); \/\/ Indicate failure at cont -- dive into slow-path.\n+      __ b(cont);\n+      __ bind(L);\n+    }\n+\n@@ -16620,2 +16595,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP tmp2);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP tmp2, TEMP box);\n@@ -16635,2 +16610,2 @@\n-  match(Set cr (FastUnlock object box));\n-  effect(TEMP tmp, TEMP tmp2);\n+  match(Set cr (FastUnlock object));\n+  effect(TEMP box, TEMP tmp, TEMP tmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":37,"deletions":62,"binary":false,"changes":99,"status":"modified"},{"patch":"@@ -213,2 +213,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg, lock_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg)\n@@ -223,2 +223,1 @@\n-  ce->store_parameter(_obj_reg->as_register(),  1);\n-  ce->store_parameter(_lock_reg->as_register(), 0);\n+  ce->store_parameter(_obj_reg->as_register(),  0);\n@@ -240,5 +239,1 @@\n-  if (_compute_lock) {\n-    \/\/ lock_reg was destroyed by fast unlocking attempt => recompute it\n-    ce->monitor_address(_monitor_ix, _lock_reg);\n-  }\n-  ce->store_parameter(_lock_reg->as_register(), 0);\n+  ce->store_parameter(_obj_reg->as_register(), 0);\n@@ -256,26 +251,0 @@\n-void LoadKlassStub::emit_code(LIR_Assembler* ce) {\n-  __ bind(_entry);\n-  Register res = _result->as_register();\n-  ce->store_parameter(_obj->as_register(), 0);\n-  if (res != r0) {\n-    \/\/ Note: we cannot push\/pop r0 around the call, because that\n-    \/\/ would mess with the stack pointer sp, and we need that to\n-    \/\/ remain intact for store_paramater\/load_argument to work correctly.\n-    \/\/ We swap r0 and res instead, which preserves current r0 in res.\n-    \/\/ The preserved value is later saved and restored around the\n-    \/\/ call in Runtime1::load_klass_id.\n-    __ mov(rscratch1, r0);\n-    __ mov(r0, res);\n-    __ mov(res, rscratch1);\n-  }\n-  __ far_call(RuntimeAddress(Runtime1::entry_for(Runtime1::load_klass_id)));\n-  if (res != r0) {\n-    \/\/ Swap back r0 and res. This brings the call return value\n-    \/\/ from r0 into res, and the preserved value in res back into r0.\n-    __ mov(rscratch1, r0);\n-    __ mov(r0, res);\n-    __ mov(res, rscratch1);\n-  }\n-  __ b(_continuation);\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_CodeStubs_aarch64.cpp","additions":4,"deletions":35,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -274,1 +274,1 @@\n-      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n+      int slot_offset = monitor_offset - (i * BytesPerWord);\n@@ -279,1 +279,1 @@\n-        __ ldr(rscratch1, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n+        __ ldr(rscratch1, Address(OSR_buf, slot_offset));\n@@ -285,3 +285,1 @@\n-      __ ldr(r19, Address(OSR_buf, slot_offset + 0));\n-      __ str(r19, frame_map()->address_for_monitor_lock(i));\n-      __ ldr(r19, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n+      __ ldr(r19, Address(OSR_buf, slot_offset));\n@@ -440,1 +438,2 @@\n-    stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);\n+    __ ldr(r4, Address(r0, BasicObjectLock::obj_offset_in_bytes()));\n+    stub = new MonitorExitStub(FrameMap::r4_opr);\n@@ -2554,1 +2553,0 @@\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -2562,1 +2560,0 @@\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -2573,1 +2570,0 @@\n-  Register tmp = rscratch1;\n@@ -2580,14 +2576,1 @@\n-  assert(UseCompressedClassPointers, \"expects UseCompressedClassPointers\");\n-\n-  \/\/ Check if we can take the (common) fast path, if obj is unlocked.\n-  __ ldr(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n-  __ eor(tmp, tmp, markWord::unlocked_value);\n-  __ tst(tmp, markWord::lock_mask_in_place);\n-  __ br(Assembler::NE, *op->stub()->entry());\n-\n-  \/\/ Fast-path: shift and decode Klass*.\n-  __ mov(result, tmp);\n-  __ lsr(result, result, markWord::klass_shift);\n-\n-  __ bind(*op->stub()->continuation());\n-  __ decode_klass_not_null(result);\n+  __ load_klass(result, obj);\n@@ -2677,1 +2660,1 @@\n-  __ lea(dst->as_register(), frame_map()->address_for_monitor_lock(monitor_no));\n+  __ lea(dst->as_register(), frame_map()->address_for_monitor_object(monitor_no));\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":7,"deletions":24,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -315,1 +315,1 @@\n-  LIR_Opr lock = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_ADDRESS);\n@@ -324,2 +324,2 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n-                        x->monitor_no(), info_for_exception, info);\n+  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n+                x->monitor_no(), info_for_exception, info);\n@@ -335,1 +335,1 @@\n-  LIR_Opr lock = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_ADDRESS);\n@@ -338,1 +338,1 @@\n-  monitor_exit(obj_temp, lock, syncTempOpr(), LIR_OprFact::illegalOpr, x->monitor_no());\n+  monitor_exit(obj_temp, lock, syncTempOpr(), new_register(T_INT), x->monitor_no());\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -72,3 +72,0 @@\n-  \/\/ save object being locked into the BasicObjectLock\n-  str(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n-\n@@ -84,35 +81,2 @@\n-  \/\/ Load object header\n-  ldr(hdr, Address(obj, hdr_offset));\n-  \/\/ and mark it as unlocked\n-  orr(hdr, hdr, markWord::unlocked_value);\n-  \/\/ save unlocked object header into the displaced header location on the stack\n-  str(hdr, Address(disp_hdr, 0));\n-  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n-  \/\/ displaced header address in the object header - if it is not the same, get the\n-  \/\/ object header instead\n-  lea(rscratch2, Address(obj, hdr_offset));\n-  cmpxchgptr(hdr, disp_hdr, rscratch2, rscratch1, done, \/*fallthough*\/NULL);\n-  \/\/ if the object header was the same, we're done\n-  \/\/ if the object header was not the same, it is now in the hdr register\n-  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-  \/\/\n-  \/\/ 1) (hdr & aligned_mask) == 0\n-  \/\/ 2) sp <= hdr\n-  \/\/ 3) hdr <= sp + page_size\n-  \/\/\n-  \/\/ these 3 tests can be done by evaluating the following expression:\n-  \/\/\n-  \/\/ (hdr - sp) & (aligned_mask - page_size)\n-  \/\/\n-  \/\/ assuming both the stack pointer and page_size have their least\n-  \/\/ significant 2 bits cleared and page_size is a power of 2\n-  mov(rscratch1, sp);\n-  sub(hdr, hdr, rscratch1);\n-  ands(hdr, hdr, aligned_mask - os::vm_page_size());\n-  \/\/ for recursive locking, the result is zero => save it in the displaced header\n-  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n-  str(hdr, Address(disp_hdr, 0));\n-  \/\/ otherwise we don't care about the result and handle locking via runtime call\n-  cbnz(hdr, slow_case);\n-  \/\/ done\n-  bind(done);\n+  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  fast_lock(obj, hdr, disp_hdr, rscratch1, rscratch2, slow_case);\n@@ -126,2 +90,1 @@\n-  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n-  Label done;\n+  assert_different_registers(hdr, obj, disp_hdr);\n@@ -129,7 +92,0 @@\n-  \/\/ load displaced header\n-  ldr(hdr, Address(disp_hdr, 0));\n-  \/\/ if the loaded hdr is NULL we had recursive locking\n-  \/\/ if we had recursive locking, we are done\n-  cbz(hdr, done);\n-  \/\/ load object\n-  ldr(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n@@ -137,13 +93,3 @@\n-  \/\/ test if object header is pointing to the displaced header, and if so, restore\n-  \/\/ the displaced header in the object - if the object header is not pointing to\n-  \/\/ the displaced header, get the object header instead\n-  \/\/ if the object header was not pointing to the displaced header,\n-  \/\/ we do unlocking via runtime call\n-  if (hdr_offset) {\n-    lea(rscratch1, Address(obj, hdr_offset));\n-    cmpxchgptr(disp_hdr, hdr, rscratch1, rscratch2, done, &slow_case);\n-  } else {\n-    cmpxchgptr(disp_hdr, hdr, obj, rscratch2, done, &slow_case);\n-  }\n-  \/\/ done\n-  bind(done);\n+\n+  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  fast_unlock(obj, hdr, rscratch1, rscratch2, slow_case);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":6,"deletions":60,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -728,10 +728,0 @@\n-    case load_klass_id:\n-      {\n-        StubFrame f(sasm, \"load_klass\", dont_gc_arguments);\n-        save_live_registers_no_oop_map(sasm, true);\n-        f.load_argument(0, r0); \/\/ obj\n-        __ call_VM_leaf(CAST_FROM_FN_PTR(address, oopDesc::load_nklass_runtime), r0);\n-        restore_live_registers_except_r0(sasm, true);\n-      }\n-      break;\n-\n@@ -971,2 +961,1 @@\n-        f.load_argument(1, r0); \/\/ r0,: object\n-        f.load_argument(0, r1); \/\/ r1,: lock address\n+        f.load_argument(0, r0); \/\/ r0,: object\n@@ -974,1 +963,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), r0, r1);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), r0);\n@@ -992,1 +981,1 @@\n-        f.load_argument(0, r0); \/\/ r0,: lock address\n+        f.load_argument(0, r0); \/\/ r0: object\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":3,"deletions":14,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -728,0 +728,7 @@\n+\n+  const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+\n+  \/\/ Load object pointer into obj_reg %c_rarg3\n+  ldr(obj_reg, Address(lock_reg, obj_offset));\n+\n@@ -731,1 +738,1 @@\n-            lock_reg);\n+            obj_reg);\n@@ -737,6 +744,0 @@\n-    const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n-\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n-    const int mark_offset = lock_offset +\n-                            BasicLock::displaced_header_offset_in_bytes();\n@@ -746,3 +747,0 @@\n-    \/\/ Load object pointer into obj_reg %c_rarg3\n-    ldr(obj_reg, Address(lock_reg, obj_offset));\n-\n@@ -756,49 +754,3 @@\n-    \/\/ Load (object->mark() | 1) into swap_reg\n-    ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    orr(swap_reg, rscratch1, 1);\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    str(swap_reg, Address(lock_reg, mark_offset));\n-\n-    assert(lock_offset == 0,\n-           \"displached header must be first word in BasicObjectLock\");\n-\n-    Label fail;\n-    cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, done, \/*fallthrough*\/NULL);\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & 7) == 0, and\n-    \/\/  2) sp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: sp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from sp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 3 bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %r0 as the result of cmpxchg\n-    \/\/ NOTE2: aarch64 does not like to subtract sp from rn so take a\n-    \/\/ copy\n-    mov(rscratch1, sp);\n-    sub(swap_reg, swap_reg, rscratch1);\n-    ands(swap_reg, swap_reg, (uint64_t)(7 - os::vm_page_size()));\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    str(swap_reg, Address(lock_reg, mark_offset));\n-    br(Assembler::EQ, done);\n+    ldr(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    fast_lock(obj_reg, tmp, rscratch1, swap_reg, rscratch2, slow_case);\n+    b(done);\n@@ -811,1 +763,1 @@\n-            lock_reg);\n+            obj_reg);\n@@ -833,0 +785,8 @@\n+  const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n+\n+  \/\/ Load oop into obj_reg(%c_rarg3)\n+  ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+  \/\/ Free entry\n+  str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n@@ -834,1 +794,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n@@ -836,1 +796,1 @@\n-    Label done;\n+    Label done, slow_case;\n@@ -840,1 +800,0 @@\n-    const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n@@ -844,19 +803,3 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %r0\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n-\n-    \/\/ Load oop into obj_reg(%c_rarg3)\n-    ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-    \/\/ Free entry\n-    str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-    \/\/ Load the old header from BasicLock structure\n-    ldr(header_reg, Address(swap_reg,\n-                            BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Test for recursion\n-    cbz(header_reg, done);\n-\n-    \/\/ Atomic swap back the old header\n-    cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, done, \/*fallthrough*\/NULL);\n+    ldr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    fast_unlock(obj_reg, header_reg, swap_reg, rscratch1, slow_case);\n+    b(done);\n@@ -865,2 +808,2 @@\n-    str(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes())); \/\/ restore obj\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+    bind(slow_case);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":27,"deletions":84,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -3721,3 +3721,0 @@\n-  assert_different_registers(src, dst);\n-\n-  Label slow, done;\n@@ -3726,0 +3723,1 @@\n+  Label no_monitor;\n@@ -3727,3 +3725,3 @@\n-  eor(dst, dst, markWord::unlocked_value);\n-  tst(dst, markWord::lock_mask_in_place);\n-  br(Assembler::NE, slow);\n+  tbz(dst, exact_log2(markWord::monitor_value), no_monitor);\n+  ldr(dst, Address(dst, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+  bind(no_monitor);\n@@ -3731,1 +3729,1 @@\n-  \/\/ Fast-path: shift and decode Klass*.\n+  \/\/ Fast-path: shift header to get narrowKlass\n@@ -3733,1 +3731,0 @@\n-  b(done);\n@@ -3735,15 +3732,0 @@\n-  bind(slow);\n-  RegSet saved_regs = RegSet::of(lr);\n-  \/\/ We need r0 as argument and return register for the call. Preserve it, if necessary.\n-  if (dst != r0) {\n-    saved_regs += RegSet::of(r0);\n-  }\n-  push(saved_regs, sp);\n-  mov(r0, src);\n-  assert(StubRoutines::load_nklass() != NULL, \"Must have stub\");\n-  far_call(RuntimeAddress(StubRoutines::load_nklass()));\n-  if (dst != r0) {\n-    mov(dst, r0);\n-  }\n-  pop(saved_regs, sp);\n-  bind(done);\n@@ -5463,0 +5445,46 @@\n+\n+\/\/ Attempt to fast-lock an object. Fall-through on success, branch to slow label\n+\/\/ on failure.\n+\/\/ Registers:\n+\/\/  - obj: the object to be locked\n+\/\/  - hdr: the header, already loaded from obj, will be destroyed\n+\/\/  - t1, t2, t3: temporary registers, will be destroyed\n+void MacroAssembler::fast_lock(Register obj, Register hdr, Register t1, Register t2, Register t3, Label& slow) {\n+  \/\/ Check if we would have space on lock-stack for the object.\n+  ldr(t1, Address(rthread, Thread::lock_stack_current_offset()));\n+  ldr(t2, Address(rthread, Thread::lock_stack_limit_offset()));\n+  cmp(t1, t2);\n+  br(Assembler::GE, slow);\n+\n+  \/\/ Load (object->mark() | 1) into hdr\n+  orr(hdr, hdr, markWord::unlocked_value);\n+  \/\/ Clear lock-bits, into t2\n+  eor(t2, hdr, markWord::unlocked_value);\n+  \/\/ Try to swing header from unlocked to locked\n+  cmpxchg(\/*addr*\/ obj, \/*expected*\/ hdr, \/*new*\/ t2, Assembler::xword,\n+          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t3);\n+  br(Assembler::NE, slow);\n+\n+  \/\/ After successful lock, push object on lock-stack\n+  str(obj, Address(t1, 0));\n+  add(t1, t1, oopSize);\n+  str(t1, Address(rthread, Thread::lock_stack_current_offset()));\n+}\n+\n+void MacroAssembler::fast_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow) {\n+  \/\/ Load the expected old header (lock-bits cleared to indicate 'locked') into hdr\n+  andr(hdr, hdr, ~markWord::lock_mask_in_place);\n+\n+  \/\/ Load the new header (unlocked) into t1\n+  orr(t1, hdr, markWord::unlocked_value);\n+\n+  \/\/ Try to swing header from locked to unlocked\n+  cmpxchg(obj, hdr, t1, Assembler::xword,\n+          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t2);\n+  br(Assembler::NE, slow);\n+\n+  \/\/ After successful unlock, pop object from lock-stack\n+  ldr(t1, Address(rthread, Thread::lock_stack_current_offset()));\n+  sub(t1, t1, oopSize);\n+  str(t1, Address(rthread, Thread::lock_stack_current_offset()));\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":51,"deletions":23,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -1466,0 +1466,3 @@\n+public:\n+  void fast_lock(Register obj, Register hdr, Register t1, Register t2, Register t3, Label& slow);\n+  void fast_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1287,1 +1287,0 @@\n-                                       in_ByteSize(-1),\n@@ -1347,1 +1346,0 @@\n-  int lock_slot_offset = 0;\n@@ -1360,1 +1358,0 @@\n-    lock_slot_offset = stack_slots;\n@@ -1375,2 +1372,0 @@\n-  \/\/      | lock box (if sync)  |\n-  \/\/      |---------------------| <- lock_slot_offset\n@@ -1634,2 +1629,0 @@\n-    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n@@ -1639,4 +1632,0 @@\n-    \/\/ Get address of the box\n-\n-    __ lea(lock_reg, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-\n@@ -1647,30 +1636,2 @@\n-      \/\/ Load (object->mark() | 1) into swap_reg %r0\n-      __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ orr(swap_reg, rscratch1, 1);\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-\n-      \/\/ src -> dest iff dest == r0 else r0 <- dest\n-      { Label here;\n-        __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, lock_done, \/*fallthrough*\/NULL);\n-      }\n-\n-      \/\/ Hmm should this move to the slow path code area???\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) sp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n-\n-      __ sub(swap_reg, sp, swap_reg);\n-      __ neg(swap_reg, swap_reg);\n-      __ ands(swap_reg, swap_reg, 3 - os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-      __ br(Assembler::NE, slow_path_lock);\n+      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock(obj_reg, old_hdr, swap_reg, tmp, rscratch1, slow_path_lock);\n@@ -1783,6 +1744,0 @@\n-    if (!UseHeavyMonitors) {\n-      \/\/ Simple recursive lock?\n-      __ ldr(rscratch1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      __ cbz(rscratch1, done);\n-    }\n-\n@@ -1795,9 +1750,2 @@\n-      \/\/ get address of the stack lock\n-      __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      \/\/  get old displaced header\n-      __ ldr(old_hdr, Address(r0, 0));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      Label succeed;\n-      __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, succeed, &slow_path_unlock);\n-      __ bind(succeed);\n+      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_unlock(obj_reg, old_hdr, swap_reg, rscratch1, slow_path_unlock);\n@@ -1872,2 +1820,1 @@\n-    __ mov(c_rarg1, lock_reg);\n-    __ mov(c_rarg2, rthread);\n+    __ mov(c_rarg1, rthread);\n@@ -1901,2 +1848,1 @@\n-    __ mov(c_rarg2, rthread);\n-    __ lea(c_rarg1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+    __ mov(c_rarg1, rthread);\n@@ -2006,1 +1952,0 @@\n-                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":6,"deletions":61,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -6479,23 +6479,0 @@\n-  \/\/ Pass object argument in r0 (which has to be preserved outside this stub)\n-  \/\/ Pass back result in r0\n-  \/\/ Clobbers rscratch1\n-  address generate_load_nklass() {\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, \"StubRoutines\", \"load_nklass\");\n-\n-    address start = __ pc();\n-\n-    __ set_last_Java_frame(sp, rfp, lr, rscratch1);\n-    __ enter();\n-    __ push(RegSet::of(rscratch1, rscratch2), sp);\n-    __ push_call_clobbered_registers_except(r0);\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, oopDesc::load_nklass_runtime), 1);\n-    __ pop_call_clobbered_registers_except(r0);\n-    __ pop(RegSet::of(rscratch1, rscratch2), sp);\n-    __ leave();\n-    __ reset_last_Java_frame(true);\n-    __ ret(lr);\n-\n-    return start;\n-  }\n-\n@@ -7484,2 +7461,0 @@\n-\n-    StubRoutines::_load_nklass = generate_load_nklass();\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":0,"deletions":25,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -198,2 +198,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg, lock_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg)\n@@ -208,1 +208,0 @@\n-  const Register lock_reg = _lock_reg->as_pointer_register();\n@@ -211,6 +210,1 @@\n-  if (obj_reg < lock_reg) {\n-    __ stmia(SP, RegisterSet(obj_reg) | RegisterSet(lock_reg));\n-  } else {\n-    __ str(obj_reg, Address(SP));\n-    __ str(lock_reg, Address(SP, BytesPerWord));\n-  }\n+  __ str(obj_reg, Address(SP));\n@@ -230,4 +224,1 @@\n-  if (_compute_lock) {\n-    ce->monitor_address(_monitor_ix, _lock_reg);\n-  }\n-  const Register lock_reg = _lock_reg->as_pointer_register();\n+  const Register obj_reg = _obj_reg->as_pointer_register();\n@@ -236,1 +227,1 @@\n-  __ str(lock_reg, Address(SP));\n+  __ str(obj_reg, Address(SP));\n@@ -246,5 +237,0 @@\n-void LoadKlassStub::emit_code(LIR_Assembler* ce) {\n-  \/\/ Currently not needed.\n-  Unimplemented();\n-}\n-\n","filename":"src\/hotspot\/cpu\/arm\/c1_CodeStubs_arm.cpp","additions":5,"deletions":19,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -152,1 +152,1 @@\n-  int monitor_offset = (method()->max_locals() + 2 * (number_of_locks - 1)) * BytesPerWord;\n+  int monitor_offset = (method()->max_locals() + (number_of_locks - 1)) * BytesPerWord;\n@@ -154,5 +154,3 @@\n-    int slot_offset = monitor_offset - (i * 2 * BytesPerWord);\n-    __ ldr(R1, Address(OSR_buf, slot_offset + 0*BytesPerWord));\n-    __ ldr(R2, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n-    __ str(R1, frame_map()->address_for_monitor_lock(i));\n-    __ str(R2, frame_map()->address_for_monitor_object(i));\n+    int slot_offset = monitor_offset - (i * BytesPerWord);\n+    __ ldr(R1, Address(OSR_buf, slot_offset));\n+    __ str(R1, frame_map()->address_for_monitor_object(i));\n@@ -249,2 +247,3 @@\n-    stub = new MonitorExitStub(FrameMap::R0_opr, true, 0);\n-    __ unlock_object(R2, R1, R0, *stub->entry());\n+    __ ldr(R1, Address(R0, BasicObjectLock::obj_offset_in_bytes()));\n+    stub = new MonitorExitStub(FrameMap::R1_opr);\n+    __ b(*stub->entry());\n@@ -2434,13 +2433,2 @@\n-  if (UseHeavyMonitors) {\n-    __ b(*op->stub()->entry());\n-  } else if (op->code() == lir_lock) {\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n-    int null_check_offset = __ lock_object(hdr, obj, lock, *op->stub()->entry());\n-    if (op->info() != NULL) {\n-      add_debug_info_for_null_check(null_check_offset, op->info());\n-    }\n-  } else if (op->code() == lir_unlock) {\n-    __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n-  } else {\n-    ShouldNotReachHere();\n-  }\n+  \/\/ TODO: Implement fast-locking.\n+  __ b(*op->stub()->entry());\n@@ -2573,1 +2561,1 @@\n-  Address mon_addr = frame_map()->address_for_monitor_lock(monitor_no);\n+  Address mon_addr = frame_map()->address_for_monitor_object(monitor_no);\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":10,"deletions":22,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -413,1 +413,0 @@\n-  LIR_Opr hdr  = new_pointer_register();\n@@ -421,1 +420,1 @@\n-  monitor_enter(obj.result(), lock, hdr, LIR_OprFact::illegalOpr,\n+  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRGenerator_arm.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -184,88 +184,0 @@\n-int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n-  Label done, fast_lock, fast_lock_done;\n-  int null_check_offset = 0;\n-\n-  const Register tmp2 = Rtemp; \/\/ Rtemp should be free at c1 LIR level\n-  assert_different_registers(hdr, obj, disp_hdr, tmp2);\n-\n-  assert(BasicObjectLock::lock_offset_in_bytes() == 0, \"adjust this code\");\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-  const int mark_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n-  str(obj, Address(disp_hdr, obj_offset));\n-\n-  null_check_offset = offset();\n-\n-  if (DiagnoseSyncOnValueBasedClasses != 0) {\n-    load_klass(tmp2, obj);\n-    ldr_u32(tmp2, Address(tmp2, Klass::access_flags_offset()));\n-    tst(tmp2, JVM_ACC_IS_VALUE_BASED_CLASS);\n-    b(slow_case, ne);\n-  }\n-\n-  assert(oopDesc::mark_offset_in_bytes() == 0, \"Required by atomic instructions\");\n-\n-  \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n-  \/\/ That would be acceptable as ether CAS or slow case path is taken in that case.\n-\n-  \/\/ Must be the first instruction here, because implicit null check relies on it\n-  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-\n-  tst(hdr, markWord::unlocked_value);\n-  b(fast_lock, ne);\n-\n-  \/\/ Check for recursive locking\n-  \/\/ See comments in InterpreterMacroAssembler::lock_object for\n-  \/\/ explanations on the fast recursive locking check.\n-  \/\/ -1- test low 2 bits\n-  movs(tmp2, AsmOperand(hdr, lsl, 30));\n-  \/\/ -2- test (hdr - SP) if the low two bits are 0\n-  sub(tmp2, hdr, SP, eq);\n-  movs(tmp2, AsmOperand(tmp2, lsr, exact_log2(os::vm_page_size())), eq);\n-  \/\/ If still 'eq' then recursive locking OK\n-  \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8267042)\n-  str(tmp2, Address(disp_hdr, mark_offset));\n-  b(fast_lock_done, eq);\n-  \/\/ else need slow case\n-  b(slow_case);\n-\n-\n-  bind(fast_lock);\n-  \/\/ Save previous object header in BasicLock structure and update the header\n-  str(hdr, Address(disp_hdr, mark_offset));\n-\n-  cas_for_lock_acquire(hdr, disp_hdr, obj, tmp2, slow_case);\n-\n-  bind(fast_lock_done);\n-  bind(done);\n-\n-  return null_check_offset;\n-}\n-\n-void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n-  assert_different_registers(hdr, obj, disp_hdr, Rtemp);\n-  Register tmp2 = Rtemp;\n-\n-  assert(BasicObjectLock::lock_offset_in_bytes() == 0, \"adjust this code\");\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-  const int mark_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n-  Label done;\n-\n-  assert(oopDesc::mark_offset_in_bytes() == 0, \"Required by atomic instructions\");\n-\n-  \/\/ Load displaced header and object from the lock\n-  ldr(hdr, Address(disp_hdr, mark_offset));\n-  \/\/ If hdr is NULL, we've got recursive locking and there's nothing more to do\n-  cbz(hdr, done);\n-\n-  \/\/ load object\n-  ldr(obj, Address(disp_hdr, obj_offset));\n-\n-  \/\/ Restore the object header\n-  cas_for_lock_release(disp_hdr, hdr, obj, tmp2, slow_case);\n-\n-  bind(done);\n-}\n-\n-\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.cpp","additions":0,"deletions":88,"binary":false,"changes":88,"status":"modified"},{"patch":"@@ -62,4 +62,0 @@\n-  int lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case);\n-\n-  void unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case);\n-\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -704,1 +704,0 @@\n-        const Register lock = R2;\n@@ -707,2 +706,1 @@\n-        __ ldr(lock, Address(SP, arg2_offset));\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), obj, lock);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), obj);\n@@ -721,1 +719,1 @@\n-        const Register lock = R1;\n+        const Register obj = R1;\n@@ -723,2 +721,2 @@\n-        __ ldr(lock, Address(SP, arg1_offset));\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorexit), lock);\n+        __ ldr(obj, Address(SP, arg1_offset));\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorexit), obj);\n","filename":"src\/hotspot\/cpu\/arm\/c1_Runtime1_arm.cpp","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -100,23 +100,1 @@\n-  ldr(Rmark, Address(Roop, oopDesc::mark_offset_in_bytes()));\n-  tst(Rmark, markWord::unlocked_value);\n-  b(fast_lock, ne);\n-\n-  \/\/ Check for recursive lock\n-  \/\/ See comments in InterpreterMacroAssembler::lock_object for\n-  \/\/ explanations on the fast recursive locking check.\n-  \/\/ -1- test low 2 bits\n-  movs(Rscratch, AsmOperand(Rmark, lsl, 30));\n-  \/\/ -2- test (hdr - SP) if the low two bits are 0\n-  sub(Rscratch, Rmark, SP, eq);\n-  movs(Rscratch, AsmOperand(Rscratch, lsr, exact_log2(os::vm_page_size())), eq);\n-  \/\/ If still 'eq' then recursive locking OK\n-  \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8153107)\n-  str(Rscratch, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n-  b(done);\n-\n-  bind(fast_lock);\n-  str(Rmark, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n-\n-  bool allow_fallthrough_on_failure = true;\n-  bool one_shot = true;\n-  cas_for_lock_acquire(Rmark, Rbox, Roop, Rscratch, done, allow_fallthrough_on_failure, one_shot);\n+  \/\/ TODO: Implement fast-locking.\n@@ -124,0 +102,1 @@\n+  tst(Roop, Roop); \/\/ Indicate failure -> take slow path\n@@ -143,10 +122,2 @@\n-  ldr(Rmark, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n-  \/\/ If hdr is NULL, we've got recursive locking and there's nothing more to do\n-  cmp(Rmark, 0);\n-  b(done, eq);\n-\n-  \/\/ Restore the object header\n-  bool allow_fallthrough_on_failure = true;\n-  bool one_shot = true;\n-  cas_for_lock_release(Rmark, Rbox, Roop, Rscratch, done, allow_fallthrough_on_failure, one_shot);\n-\n+  \/\/ TODO: Implement fast-unlocking.\n+  tst(Roop, Roop); \/\/ Indicate failure -> take slow path\n","filename":"src\/hotspot\/cpu\/arm\/c2_MacroAssembler_arm.cpp","additions":4,"deletions":33,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -866,0 +866,3 @@\n+  const Register Robj = R2;\n+  assert_different_registers(Robj, Rlock);\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n@@ -867,24 +870,2 @@\n-  if (UseHeavyMonitors) {\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), Rlock);\n-  } else {\n-    Label done;\n-\n-    const Register Robj = R2;\n-    const Register Rmark = R3;\n-    assert_different_registers(Robj, Rmark, Rlock, R0, Rtemp);\n-\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n-    const int mark_offset = lock_offset + BasicLock::displaced_header_offset_in_bytes();\n-\n-    Label already_locked, slow_case;\n-\n-    \/\/ Load object pointer\n-    ldr(Robj, Address(Rlock, obj_offset));\n-\n-    if (DiagnoseSyncOnValueBasedClasses != 0) {\n-      load_klass(R0, Robj);\n-      ldr_u32(R0, Address(R0, Klass::access_flags_offset()));\n-      tst(R0, JVM_ACC_IS_VALUE_BASED_CLASS);\n-      b(slow_case, ne);\n-    }\n+  \/\/ Load object pointer\n+  ldr(Robj, Address(Rlock, obj_offset));\n@@ -892,70 +873,3 @@\n-    \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n-    \/\/ That would be acceptable as ether CAS or slow case path is taken in that case.\n-    \/\/ Exception to that is if the object is locked by the calling thread, then the recursive test will pass (guaranteed as\n-    \/\/ loads are satisfied from a store queue if performed on the same processor).\n-\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"must be\");\n-    ldr(Rmark, Address(Robj, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ Test if object is already locked\n-    tst(Rmark, markWord::unlocked_value);\n-    b(already_locked, eq);\n-\n-    \/\/ Save old object->mark() into BasicLock's displaced header\n-    str(Rmark, Address(Rlock, mark_offset));\n-\n-    cas_for_lock_acquire(Rmark, Rlock, Robj, Rtemp, slow_case);\n-\n-    b(done);\n-\n-    \/\/ If we got here that means the object is locked by ether calling thread or another thread.\n-    bind(already_locked);\n-    \/\/ Handling of locked objects: recursive locks and slow case.\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & 3) == 0\n-    \/\/  2) SP <= mark < SP + os::pagesize()\n-    \/\/\n-    \/\/ Warning: SP + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from SP is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ Note: assuming SP is aligned, we can check the low bits of\n-    \/\/ (mark-SP) instead of the low bits of mark. In that case,\n-    \/\/ assuming page size is a power of 2, we can merge the two\n-    \/\/ conditions into a single test:\n-    \/\/ => ((mark - SP) & (3 - os::pagesize())) == 0\n-\n-    \/\/ (3 - os::pagesize()) cannot be encoded as an ARM immediate operand.\n-    \/\/ Check independently the low bits and the distance to SP.\n-    \/\/ -1- test low 2 bits\n-    movs(R0, AsmOperand(Rmark, lsl, 30));\n-    \/\/ -2- test (mark - SP) if the low two bits are 0\n-    sub(R0, Rmark, SP, eq);\n-    movs(R0, AsmOperand(R0, lsr, exact_log2(os::vm_page_size())), eq);\n-    \/\/ If still 'eq' then recursive locking OK: store 0 into lock record\n-    str(R0, Address(Rlock, mark_offset), eq);\n-\n-    b(done, eq);\n-\n-    bind(slow_case);\n-\n-    \/\/ Call the runtime routine for slow case\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), Rlock);\n-\n-    bind(done);\n-  }\n+  \/\/ TODO: Implement fast-locking.\n+  mov(R0, Robj);\n+  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), R0);\n@@ -972,0 +886,3 @@\n+  const Register Robj = R2;\n+  assert_different_registers(Robj, Rlock);\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n@@ -973,38 +890,2 @@\n-  if (UseHeavyMonitors) {\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), Rlock);\n-  } else {\n-    Label done, slow_case;\n-\n-    const Register Robj = R2;\n-    const Register Rmark = R3;\n-    assert_different_registers(Robj, Rmark, Rlock, Rtemp);\n-\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n-    const int mark_offset = lock_offset + BasicLock::displaced_header_offset_in_bytes();\n-\n-    const Register Rzero = zero_register(Rtemp);\n-\n-    \/\/ Load oop into Robj\n-    ldr(Robj, Address(Rlock, obj_offset));\n-\n-    \/\/ Free entry\n-    str(Rzero, Address(Rlock, obj_offset));\n-\n-    \/\/ Load the old header from BasicLock structure\n-    ldr(Rmark, Address(Rlock, mark_offset));\n-\n-    \/\/ Test for recursion (zero mark in BasicLock)\n-    cbz(Rmark, done);\n-\n-    bool allow_fallthrough_on_failure = true;\n-\n-    cas_for_lock_release(Rlock, Rmark, Robj, Rtemp, slow_case, allow_fallthrough_on_failure);\n-\n-    b(done, eq);\n-\n-    bind(slow_case);\n-\n-    \/\/ Call the runtime routine for slow case.\n-    str(Robj, Address(Rlock, obj_offset)); \/\/ restore obj\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), Rlock);\n+  \/\/ Load oop into Robj\n+  ldr(Robj, Address(Rlock, obj_offset));\n@@ -1012,2 +893,3 @@\n-    bind(done);\n-  }\n+  \/\/ TODO: Implement fast-locking.\n+  mov(R0, Robj);\n+  call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), R0);\n","filename":"src\/hotspot\/cpu\/arm\/interp_masm_arm.cpp","additions":16,"deletions":134,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -772,1 +772,0 @@\n-                                       in_ByteSize(-1),\n@@ -806,8 +805,0 @@\n-  \/\/ Plus a lock if needed\n-  int lock_slot_offset = 0;\n-  if (method->is_synchronized()) {\n-    lock_slot_offset = stack_slots;\n-    assert(sizeof(BasicLock) == wordSize, \"adjust this code\");\n-    stack_slots += VMRegImpl::slots_per_word;\n-  }\n-\n@@ -820,2 +811,0 @@\n-  int lock_slot_fp_offset = stack_size - 2 * wordSize -\n-    lock_slot_offset * VMRegImpl::stack_slot_size;\n@@ -1152,22 +1141,1 @@\n-    const Register mark = tmp;\n-    \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n-    \/\/ That would be acceptable as either CAS or slow case path is taken in that case\n-\n-    __ ldr(mark, Address(sync_obj, oopDesc::mark_offset_in_bytes()));\n-    __ sub(disp_hdr, FP, lock_slot_fp_offset);\n-    __ tst(mark, markWord::unlocked_value);\n-    __ b(fast_lock, ne);\n-\n-    \/\/ Check for recursive lock\n-    \/\/ See comments in InterpreterMacroAssembler::lock_object for\n-    \/\/ explanations on the fast recursive locking check.\n-    \/\/ Check independently the low bits and the distance to SP\n-    \/\/ -1- test low 2 bits\n-    __ movs(Rtemp, AsmOperand(mark, lsl, 30));\n-    \/\/ -2- test (hdr - SP) if the low two bits are 0\n-    __ sub(Rtemp, mark, SP, eq);\n-    __ movs(Rtemp, AsmOperand(Rtemp, lsr, exact_log2(os::vm_page_size())), eq);\n-    \/\/ If still 'eq' then recursive locking OK\n-    \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8267042)\n-    __ str(Rtemp, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n-    __ b(lock_done, eq);\n+    \/\/ TODO: Implement fast-locking.\n@@ -1175,6 +1143,0 @@\n-\n-    __ bind(fast_lock);\n-    __ str(mark, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n-\n-    __ cas_for_lock_acquire(mark, disp_hdr, sync_obj, Rtemp, slow_lock);\n-\n@@ -1232,7 +1194,2 @@\n-\n-    \/\/ See C1_MacroAssembler::unlock_object() for more comments\n-    __ ldr(R2, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n-    __ cbz(R2, unlock_done);\n-\n-    __ cas_for_lock_release(disp_hdr, R2, sync_obj, Rtemp, slow_unlock);\n-\n+    \/\/ TODO: Implement fast-unlocking.\n+    __ b(slow_unlock);\n@@ -1294,1 +1251,0 @@\n-    __ mov(R1, disp_hdr);\n@@ -1314,1 +1270,0 @@\n-    __ mov(R1, disp_hdr);\n@@ -1332,1 +1287,0 @@\n-                                     in_ByteSize(lock_slot_offset * VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":3,"deletions":49,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -260,2 +260,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg, lock_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg)\n@@ -270,2 +270,1 @@\n-  ce->store_parameter(_obj_reg->as_register(),  1);\n-  ce->store_parameter(_lock_reg->as_register(), 0);\n+  ce->store_parameter(_obj_reg->as_register(),  0);\n@@ -287,5 +286,1 @@\n-  if (_compute_lock) {\n-    \/\/ lock_reg was destroyed by fast unlocking attempt => recompute it\n-    ce->monitor_address(_monitor_ix, _lock_reg);\n-  }\n-  ce->store_parameter(_lock_reg->as_register(), 0);\n+  ce->store_parameter(_obj_reg->as_register(), 0);\n@@ -303,21 +298,0 @@\n-void LoadKlassStub::emit_code(LIR_Assembler* ce) {\n-  __ bind(_entry);\n-#ifdef _LP64\n-  Register res = _result->as_register();\n-  ce->store_parameter(_obj->as_register(), 0);\n-  if (res != rax) {\n-    \/\/ This preserves rax and allows it to be used as return-register,\n-    \/\/ without messing with the stack.\n-    __ xchgptr(rax, res);\n-  }\n-  __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::load_klass_id)));\n-  if (res != rax) {\n-    \/\/ Swap back rax, and move result to correct register.\n-    __ xchgptr(rax, res);\n-  }\n-  __ jmp(_continuation);\n-#else\n-  __ should_not_reach_here();\n-#endif\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/c1_CodeStubs_x86.cpp","additions":4,"deletions":30,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -317,1 +317,1 @@\n-      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n+      int slot_offset = monitor_offset - (i * BytesPerWord);\n@@ -322,1 +322,1 @@\n-        __ cmpptr(Address(OSR_buf, slot_offset + 1*BytesPerWord), (int32_t)NULL_WORD);\n+        __ cmpptr(Address(OSR_buf, slot_offset), (int32_t)NULL_WORD);\n@@ -328,3 +328,1 @@\n-      __ movptr(rbx, Address(OSR_buf, slot_offset + 0));\n-      __ movptr(frame_map()->address_for_monitor_lock(i), rbx);\n-      __ movptr(rbx, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n+      __ movptr(rbx, Address(OSR_buf, slot_offset));\n@@ -462,2 +460,3 @@\n-    monitor_address(0, FrameMap::rax_opr);\n-    stub = new MonitorExitStub(FrameMap::rax_opr, true, 0);\n+    monitor_address(0, FrameMap::rdi_opr);\n+    __ movptr(rsi, Address(rdi, BasicObjectLock::obj_offset_in_bytes()));\n+    stub = new MonitorExitStub(FrameMap::rsi_oop_opr);\n@@ -467,1 +466,1 @@\n-      __ unlock_object(rdi, rsi, rax, *stub->entry());\n+      __ unlock_object(rax, rsi, rdi, *stub->entry());\n@@ -3516,0 +3515,1 @@\n+  Register tmp = op->scratch_opr()->as_register();\n@@ -3519,1 +3519,0 @@\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -3521,1 +3520,1 @@\n-    int null_check_offset = __ lock_object(hdr, obj, lock, *op->stub()->entry());\n+    int null_check_offset = __ lock_object(hdr, obj, lock, tmp, *op->stub()->entry());\n@@ -3527,2 +3526,1 @@\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n-    __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n+    __ unlock_object(hdr, obj, tmp, *op->stub()->entry());\n@@ -3542,22 +3540,1 @@\n-#ifdef _LP64\n-  Register tmp = rscratch1;\n-  assert_different_registers(tmp, obj);\n-  assert_different_registers(tmp, result);\n-\n-  \/\/ Check if we can take the (common) fast path, if obj is unlocked.\n-  __ movq(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n-  __ xorq(tmp, markWord::unlocked_value);\n-  __ testb(tmp, markWord::lock_mask_in_place);\n-  __ jcc(Assembler::notZero, *op->stub()->entry());\n-\n-  \/\/ Fast-path: shift and decode Klass*.\n-  __ movq(result, tmp);\n-  __ shrq(result, markWord::klass_shift);\n-\n-  __ bind(*op->stub()->continuation());\n-  __ decode_klass_not_null(result, tmp);\n-#else\n-  __ movptr(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n-  \/\/ Not really needed, but bind the label anyway to make compiler happy.\n-  __ bind(*op->stub()->continuation());\n-#endif\n+  __ load_klass(result, obj, LP64_ONLY(rscratch1) NOT_LP64(noreg));\n@@ -3797,1 +3774,1 @@\n-  __ lea(dst->as_register(), frame_map()->address_for_monitor_lock(monitor_no));\n+  __ lea(dst->as_register(), frame_map()->address_for_monitor_object(monitor_no));\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":12,"deletions":35,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -313,2 +313,3 @@\n-  LIR_Opr lock = new_register(T_INT);\n-\n+  LIR_Opr lock = new_register(T_ADDRESS);\n+  LIR_Opr tmp1 = new_register(T_INT);\n+  LIR_Opr tmp2 = new_register(T_INT);\n@@ -322,1 +323,1 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n+  monitor_enter(obj.result(), lock, syncTempOpr(), tmp1, tmp2,\n@@ -333,2 +334,3 @@\n-  LIR_Opr lock = new_register(T_INT);\n-  LIR_Opr obj_temp = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_ADDRESS);\n+  LIR_Opr obj_temp = new_register(T_ADDRESS);\n+  LIR_Opr tmp = new_register(T_INT);\n@@ -336,1 +338,1 @@\n-  monitor_exit(obj_temp, lock, syncTempOpr(), LIR_OprFact::illegalOpr, x->monitor_no());\n+  monitor_exit(obj_temp, lock, syncTempOpr(), tmp, x->monitor_no());\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":8,"deletions":6,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n+int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register tmp, Label& slow_case) {\n@@ -42,1 +42,0 @@\n-  const int aligned_mask = BytesPerWord -1;\n@@ -45,2 +44,1 @@\n-  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n-  Label done;\n+  assert_different_registers(hdr, obj, disp_hdr, tmp);\n@@ -51,3 +49,0 @@\n-  \/\/ save object being locked into the BasicObjectLock\n-  movptr(Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()), obj);\n-\n@@ -63,1 +58,8 @@\n-  \/\/ Load object header\n+#ifdef _LP64\n+  const Register thread = r15_thread;\n+  const Register tmp2 = disp_hdr;\n+#else\n+  const Register thread = disp_hdr;\n+  get_thread(thread);\n+  const Register tmp2 = noreg;\n+#endif\n@@ -65,33 +67,1 @@\n-  \/\/ and mark it as unlocked\n-  orptr(hdr, markWord::unlocked_value);\n-  \/\/ save unlocked object header into the displaced header location on the stack\n-  movptr(Address(disp_hdr, 0), hdr);\n-  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n-  \/\/ displaced header address in the object header - if it is not the same, get the\n-  \/\/ object header instead\n-  MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n-  cmpxchgptr(disp_hdr, Address(obj, hdr_offset));\n-  \/\/ if the object header was the same, we're done\n-  jcc(Assembler::equal, done);\n-  \/\/ if the object header was not the same, it is now in the hdr register\n-  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-  \/\/\n-  \/\/ 1) (hdr & aligned_mask) == 0\n-  \/\/ 2) rsp <= hdr\n-  \/\/ 3) hdr <= rsp + page_size\n-  \/\/\n-  \/\/ these 3 tests can be done by evaluating the following expression:\n-  \/\/\n-  \/\/ (hdr - rsp) & (aligned_mask - page_size)\n-  \/\/\n-  \/\/ assuming both the stack pointer and page_size have their least\n-  \/\/ significant 2 bits cleared and page_size is a power of 2\n-  subptr(hdr, rsp);\n-  andptr(hdr, aligned_mask - os::vm_page_size());\n-  \/\/ for recursive locking, the result is zero => save it in the displaced header\n-  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n-  movptr(Address(disp_hdr, 0), hdr);\n-  \/\/ otherwise we don't care about the result and handle locking via runtime call\n-  jcc(Assembler::notZero, slow_case);\n-  \/\/ done\n-  bind(done);\n+  fast_lock_impl(obj, hdr, thread, tmp, tmp2, slow_case);\n@@ -102,2 +72,1 @@\n-void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n-  const int aligned_mask = BytesPerWord -1;\n+void C1_MacroAssembler::unlock_object(Register disp_hdr, Register obj, Register hdr, Label& slow_case) {\n@@ -107,10 +76,0 @@\n-  Label done;\n-\n-  \/\/ load displaced header\n-  movptr(hdr, Address(disp_hdr, 0));\n-  \/\/ if the loaded hdr is NULL we had recursive locking\n-  testptr(hdr, hdr);\n-  \/\/ if we had recursive locking, we are done\n-  jcc(Assembler::zero, done);\n-  \/\/ load object\n-  movptr(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n@@ -119,10 +78,4 @@\n-  \/\/ test if object header is pointing to the displaced header, and if so, restore\n-  \/\/ the displaced header in the object - if the object header is not pointing to\n-  \/\/ the displaced header, get the object header instead\n-  MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n-  cmpxchgptr(hdr, Address(obj, hdr_offset));\n-  \/\/ if the object header was not pointing to the displaced header,\n-  \/\/ we do unlocking via runtime call\n-  jcc(Assembler::notEqual, slow_case);\n-  \/\/ done\n-  bind(done);\n+\n+  movptr(disp_hdr, Address(obj, hdr_offset));\n+  andptr(disp_hdr, ~(int32_t)markWord::lock_mask_in_place);\n+  fast_unlock_impl(obj, disp_hdr, hdr, slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":16,"deletions":63,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-  int lock_object  (Register swap, Register obj, Register disp_hdr, Label& slow_case);\n+  int lock_object  (Register swap, Register obj, Register disp_hdr, Register tmp, Label& slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1102,11 +1102,0 @@\n-#ifdef _LP64\n-    case load_klass_id:\n-      {\n-        StubFrame f(sasm, \"load_klass\", dont_gc_arguments);\n-        sasm->save_live_registers_no_oop_map(true);\n-        f.load_argument(0, c_rarg0); \/\/ obj\n-        __ call_VM_leaf(CAST_FROM_FN_PTR(address, oopDesc::load_nklass_runtime), c_rarg0);\n-        sasm->restore_live_registers_except_rax(true);\n-      }\n-      break;\n-#endif\n@@ -1407,1 +1396,1 @@\n-        OopMap* map = save_live_registers(sasm, 3, save_fpu_registers);\n+        OopMap* map = save_live_registers(sasm, 2, save_fpu_registers);\n@@ -1411,2 +1400,1 @@\n-        f.load_argument(1, rax); \/\/ rax,: object\n-        f.load_argument(0, rbx); \/\/ rbx,: lock address\n+        f.load_argument(0, rax); \/\/ rax,: object\n@@ -1414,1 +1402,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), rax, rbx);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), rax);\n@@ -1432,1 +1420,1 @@\n-        f.load_argument(0, rax); \/\/ rax,: lock address\n+        f.load_argument(0, rax); \/\/ rax: obj\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":4,"deletions":16,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -214,56 +214,0 @@\n-\/\/ Use RTM for normal stack locks\n-\/\/ Input: objReg (object to lock)\n-void C2_MacroAssembler::rtm_stack_locking(Register objReg, Register tmpReg, Register scrReg,\n-                                         Register retry_on_abort_count_Reg,\n-                                         RTMLockingCounters* stack_rtm_counters,\n-                                         Metadata* method_data, bool profile_rtm,\n-                                         Label& DONE_LABEL, Label& IsInflated) {\n-  assert(UseRTMForStackLocks, \"why call this otherwise?\");\n-  assert(tmpReg == rax, \"\");\n-  assert(scrReg == rdx, \"\");\n-  Label L_rtm_retry, L_decrement_retry, L_on_abort;\n-\n-  if (RTMRetryCount > 0) {\n-    movl(retry_on_abort_count_Reg, RTMRetryCount); \/\/ Retry on abort\n-    bind(L_rtm_retry);\n-  }\n-  movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes()));\n-  testptr(tmpReg, markWord::monitor_value);  \/\/ inflated vs stack-locked|neutral\n-  jcc(Assembler::notZero, IsInflated);\n-\n-  if (PrintPreciseRTMLockingStatistics || profile_rtm) {\n-    Label L_noincrement;\n-    if (RTMTotalCountIncrRate > 1) {\n-      \/\/ tmpReg, scrReg and flags are killed\n-      branch_on_random_using_rdtsc(tmpReg, scrReg, RTMTotalCountIncrRate, L_noincrement);\n-    }\n-    assert(stack_rtm_counters != NULL, \"should not be NULL when profiling RTM\");\n-    atomic_incptr(ExternalAddress((address)stack_rtm_counters->total_count_addr()), scrReg);\n-    bind(L_noincrement);\n-  }\n-  xbegin(L_on_abort);\n-  movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes()));       \/\/ fetch markword\n-  andptr(tmpReg, markWord::lock_mask_in_place);     \/\/ look at 2 lock bits\n-  cmpptr(tmpReg, markWord::unlocked_value);         \/\/ bits = 01 unlocked\n-  jcc(Assembler::equal, DONE_LABEL);        \/\/ all done if unlocked\n-\n-  Register abort_status_Reg = tmpReg; \/\/ status of abort is stored in RAX\n-  if (UseRTMXendForLockBusy) {\n-    xend();\n-    movptr(abort_status_Reg, 0x2);   \/\/ Set the abort status to 2 (so we can retry)\n-    jmp(L_decrement_retry);\n-  }\n-  else {\n-    xabort(0);\n-  }\n-  bind(L_on_abort);\n-  if (PrintPreciseRTMLockingStatistics || profile_rtm) {\n-    rtm_profiling(abort_status_Reg, scrReg, stack_rtm_counters, method_data, profile_rtm);\n-  }\n-  bind(L_decrement_retry);\n-  if (RTMRetryCount > 0) {\n-    \/\/ retry on lock abort if abort status is 'can retry' (0x2) or 'memory conflict' (0x4)\n-    rtm_retry_lock_on_abort(retry_on_abort_count_Reg, abort_status_Reg, L_rtm_retry);\n-  }\n-}\n-\n@@ -286,2 +230,0 @@\n-  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n-  movptr(Address(boxReg, 0), (int32_t)intptr_t(markWord::unused_mark().value()));\n@@ -433,1 +375,1 @@\n-                                 Register scrReg, Register cx1Reg, Register cx2Reg,\n+                                 Register scrReg, Register cx1Reg, Register cx2Reg, Register thread,\n@@ -445,1 +387,1 @@\n-    assert_different_registers(objReg, boxReg, tmpReg, scrReg);\n+    assert_different_registers(objReg, boxReg, tmpReg, scrReg, cx1Reg);\n@@ -463,1 +405,1 @@\n-  Label IsInflated, DONE_LABEL;\n+  Label IsInflated, DONE_LABEL, slow_path;\n@@ -472,9 +414,0 @@\n-#if INCLUDE_RTM_OPT\n-  if (UseRTMForStackLocks && use_rtm) {\n-    assert(!UseHeavyMonitors, \"+UseHeavyMonitors and +UseRTMForStackLocks are mutually exclusive\");\n-    rtm_stack_locking(objReg, tmpReg, scrReg, cx2Reg,\n-                      stack_rtm_counters, method_data, profile_rtm,\n-                      DONE_LABEL, IsInflated);\n-  }\n-#endif \/\/ INCLUDE_RTM_OPT\n-\n@@ -486,17 +419,4 @@\n-    \/\/ Attempt stack-locking ...\n-    orptr (tmpReg, markWord::unlocked_value);\n-    movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n-    lock();\n-    cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n-    jcc(Assembler::equal, DONE_LABEL);           \/\/ Success\n-\n-    \/\/ Recursive locking.\n-    \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n-    \/\/ Locked by current thread if difference with current SP is less than one page.\n-    subptr(tmpReg, rsp);\n-    \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n-    andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - os::vm_page_size())) );\n-    movptr(Address(boxReg, 0), tmpReg);\n-  } else {\n-    \/\/ Clear ZF so that we take the slow path at the DONE label. objReg is known to be not 0.\n-    testptr(objReg, objReg);\n+    fast_lock_impl(objReg, tmpReg, thread, scrReg, cx1Reg, slow_path);\n+\n+    xorptr(rax, rax); \/\/ Set ZF = 1 (success)\n+    jmp(DONE_LABEL);\n@@ -504,0 +424,3 @@\n+  bind(slow_path);\n+  \/\/ Clear ZF so that we take the slow path at the DONE label. objReg is known to be not 0.\n+  testptr(objReg, objReg);\n@@ -543,9 +466,1 @@\n-  cmpxchgptr(scrReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-  movptr(Address(scrReg, 0), 3);          \/\/ box->_displaced_header = 3\n-  \/\/ If we weren't able to swing _owner from NULL to the BasicLock\n-  \/\/ then take the slow path.\n-  jccb  (Assembler::notZero, DONE_LABEL);\n-  \/\/ update _owner from BasicLock to thread\n-  get_thread (scrReg);                    \/\/ beware: clobbers ICCs\n-  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), scrReg);\n-  xorptr(boxReg, boxReg);                 \/\/ set icc.ZFlag = 1 to indicate success\n+  cmpxchgptr(thread, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n@@ -565,4 +480,1 @@\n-  cmpxchgptr(r15_thread, Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-  \/\/ Unconditionally set box->_displaced_header = markWord::unused_mark().\n-  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n-  movptr(Address(boxReg, 0), (int32_t)intptr_t(markWord::unused_mark().value()));\n+  cmpxchgptr(thread, Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n@@ -572,1 +484,1 @@\n-  cmpptr(r15_thread, rax);                     \/\/ Check if we are already the owner (recursive lock)\n+  cmpptr(thread, rax);                     \/\/ Check if we are already the owner (recursive lock)\n@@ -631,19 +543,1 @@\n-#if INCLUDE_RTM_OPT\n-  if (UseRTMForStackLocks && use_rtm) {\n-    assert(!UseHeavyMonitors, \"+UseHeavyMonitors and +UseRTMForStackLocks are mutually exclusive\");\n-    Label L_regular_unlock;\n-    movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ fetch markword\n-    andptr(tmpReg, markWord::lock_mask_in_place);                     \/\/ look at 2 lock bits\n-    cmpptr(tmpReg, markWord::unlocked_value);                         \/\/ bits = 01 unlocked\n-    jccb(Assembler::notEqual, L_regular_unlock);                      \/\/ if !HLE RegularLock\n-    xend();                                                           \/\/ otherwise end...\n-    jmp(DONE_LABEL);                                                  \/\/ ... and we're done\n-    bind(L_regular_unlock);\n-  }\n-#endif\n-\n-  if (!UseHeavyMonitors) {\n-    cmpptr(Address(boxReg, 0), (int32_t)NULL_WORD);                   \/\/ Examine the displaced header\n-    jcc   (Assembler::zero, DONE_LABEL);                              \/\/ 0 indicates recursive stack-lock\n-  }\n-  movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Examine the object's markword\n+  movptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Examine the object's markword\n@@ -651,2 +545,10 @@\n-    testptr(tmpReg, markWord::monitor_value);                         \/\/ Inflated?\n-    jccb  (Assembler::zero, Stacked);\n+    testptr(boxReg, markWord::monitor_value);\n+    jcc(Assembler::zero, Stacked);\n+\n+    \/\/ If the owner is ANONYMOUS, we need to fix it - in the slow-path.\n+    Label L;\n+    cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t) (intptr_t) ANONYMOUS_OWNER);\n+    jccb(Assembler::notEqual, L);\n+    testptr(objReg, objReg); \/\/ Clear ZF to indicate failure at DONE_LABEL.\n+    jmp(DONE_LABEL);\n+    bind(L);\n@@ -655,1 +557,0 @@\n-  \/\/ It's inflated.\n@@ -660,2 +561,2 @@\n-    movptr(boxReg, Address(tmpReg, owner_offset));\n-    testptr(boxReg, boxReg);\n+    movptr(tmpReg, Address(boxReg, owner_offset));\n+    testptr(tmpReg, tmpReg);\n@@ -688,2 +589,0 @@\n-  get_thread (boxReg);\n-\n@@ -694,2 +593,2 @@\n-  xorptr(boxReg, boxReg);\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  xorptr(tmpReg, tmpReg);\n+  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n@@ -697,4 +596,4 @@\n-  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-  jccb  (Assembler::notZero, CheckSucc);\n-  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n+  movptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+  jccb  (Assembler::notZero, DONE_LABEL);\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n@@ -702,18 +601,0 @@\n-\n-  bind (Stacked);\n-  \/\/ It's not inflated and it's not recursively stack-locked.\n-  \/\/ It must be stack-locked.\n-  \/\/ Try to reset the header to displaced header.\n-  \/\/ The \"box\" value on the stack is stable, so we can reload\n-  \/\/ and be assured we observe the same value as above.\n-  movptr(tmpReg, Address(boxReg, 0));\n-  lock();\n-  cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n-  \/\/ Intention fall-thru into DONE_LABEL\n-\n-  \/\/ DONE_LABEL is a hot target - we'd really like to place it at the\n-  \/\/ start of cache line by padding with NOPs.\n-  \/\/ See the AMD and Intel software optimization manuals for the\n-  \/\/ most efficient \"long\" NOP encodings.\n-  \/\/ Unfortunately none of our alignment mechanisms suffice.\n-  bind (CheckSucc);\n@@ -724,1 +605,1 @@\n-  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n+  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n@@ -728,1 +609,1 @@\n-  decq(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  decq(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n@@ -732,2 +613,3 @@\n-  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+\n+  movptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n@@ -736,1 +618,1 @@\n-  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n@@ -746,1 +628,1 @@\n-  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n+  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n@@ -749,1 +631,0 @@\n-  xorptr(boxReg, boxReg);\n@@ -751,1 +632,1 @@\n-  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n@@ -762,1 +643,1 @@\n-  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n+  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n@@ -765,0 +646,4 @@\n+  mov(tmpReg, boxReg);\n+\n+  xorptr(boxReg, boxReg);\n+\n@@ -795,0 +680,1 @@\n+#endif\n@@ -796,4 +682,4 @@\n-    bind  (Stacked);\n-    movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n-    lock();\n-    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+    bind(Stacked);\n+    \/\/ Mark-word must be 00 now, try to swing it back to 01 (unlocked)\n+    fast_unlock_impl(objReg, boxReg, tmpReg, DONE_LABEL);\n+    xorptr(rax, rax); \/\/ Set ZF = 1 (success)\n@@ -801,1 +687,1 @@\n-#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":51,"deletions":165,"binary":false,"changes":216,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-                 Register scr, Register cx1, Register cx2,\n+                 Register scr, Register cx1, Register cx2, Register thread,\n@@ -53,5 +53,0 @@\n-  void rtm_stack_locking(Register obj, Register tmp, Register scr,\n-                         Register retry_on_abort_count,\n-                         RTMLockingCounters* stack_rtm_counters,\n-                         Metadata* method_data, bool profile_rtm,\n-                         Label& DONE_LABEL, Label& IsInflated);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -151,3 +151,0 @@\n-  product(bool, UseRTMForStackLocks, false, EXPERIMENTAL,                   \\\n-          \"Enable RTM lock eliding for stack locks in compiled code\")       \\\n-                                                                            \\\n","filename":"src\/hotspot\/cpu\/x86\/globals_x86.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1199,0 +1199,4 @@\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+  const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx); \/\/ Will contain the oop\n+  \/\/ Load object pointer into obj_reg\n+  movptr(obj_reg, Address(lock_reg, obj_offset));\n@@ -1202,1 +1206,1 @@\n-            lock_reg);\n+            obj_reg);\n@@ -1208,1 +1212,0 @@\n-    const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx); \/\/ Will contain the oop\n@@ -1211,5 +1214,0 @@\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n-    const int mark_offset = lock_offset +\n-                            BasicLock::displaced_header_offset_in_bytes();\n-\n@@ -1218,3 +1216,0 @@\n-    \/\/ Load object pointer into obj_reg\n-    movptr(obj_reg, Address(lock_reg, obj_offset));\n-\n@@ -1228,51 +1223,12 @@\n-    \/\/ Load immediate 1 into swap_reg %rax\n-    movl(swap_reg, (int32_t)1);\n-\n-    \/\/ Load (object->mark() | 1) into swap_reg %rax\n-    orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-\n-    assert(lock_offset == 0,\n-           \"displaced header must be first word in BasicObjectLock\");\n-\n-    lock();\n-    cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    jcc(Assembler::zero, done);\n-\n-    const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & zero_bits) == 0, and\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from rsp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n-    subptr(swap_reg, rsp);\n-    andptr(swap_reg, zero_bits - os::vm_page_size());\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-    jcc(Assembler::zero, done);\n+#ifdef _LP64\n+    const Register thread = r15_thread;\n+    const Register tmp2 = rscratch1;\n+#else\n+    const Register thread = lock_reg;\n+    get_thread(thread);\n+    const Register tmp2 = noreg;\n+#endif\n+    \/\/ Load object header, prepare for CAS from unlocked to locked.\n+    movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    fast_lock_impl(obj_reg, swap_reg, thread, tmp_reg, tmp2, slow_case);\n+    jmp(done);\n@@ -1285,1 +1241,1 @@\n-            lock_reg);\n+            obj_reg);\n@@ -1308,0 +1264,7 @@\n+  const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx);  \/\/ Will contain the oop\n+  \/\/ Load oop into obj_reg(%c_rarg3)\n+  movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+  \/\/ Free entry\n+  movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL_WORD);\n+\n@@ -1309,1 +1272,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n@@ -1311,1 +1274,1 @@\n-    Label done;\n+    Label done, slow_case;\n@@ -1313,1 +1276,1 @@\n-    const Register swap_reg   = rax;  \/\/ Must use rax for cmpxchg instruction\n+    const Register swap_reg = rax;  \/\/ Must use rax for cmpxchg instruction\n@@ -1315,1 +1278,0 @@\n-    const Register obj_reg    = LP64_ONLY(c_rarg3) NOT_LP64(rcx);  \/\/ Will contain the oop\n@@ -1319,27 +1281,5 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %rax\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n-\n-    \/\/ Load oop into obj_reg(%c_rarg3)\n-    movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-    \/\/ Free entry\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), (int32_t)NULL_WORD);\n-\n-    \/\/ Load the old header from BasicLock structure\n-    movptr(header_reg, Address(swap_reg,\n-                               BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Test for recursion\n-    testptr(header_reg, header_reg);\n-\n-    \/\/ zero for recursive case\n-    jcc(Assembler::zero, done);\n-\n-    \/\/ Atomic swap back the old header\n-    lock();\n-    cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ zero for simple unlock of a stack-lock case\n-    jcc(Assembler::zero, done);\n-\n+    \/\/ Try to swing header from locked to unlock.\n+    movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+    fast_unlock_impl(obj_reg, swap_reg, header_reg, slow_case);\n+    jmp(done);\n@@ -1347,0 +1287,1 @@\n+    bind(slow_case);\n@@ -1348,2 +1289,1 @@\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), obj_reg); \/\/ restore obj\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":35,"deletions":95,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -4748,1 +4748,0 @@\n-  assert_different_registers(src, dst);\n@@ -4751,1 +4750,1 @@\n-  Label slow, done;\n+  Label fast;\n@@ -4756,1 +4755,1 @@\n-  xorq(dst, markWord::unlocked_value);\n+  xorq(dst, markWord::monitor_value);\n@@ -4758,5 +4757,1 @@\n-  jccb(Assembler::notZero, slow);\n-\n-  shrq(dst, markWord::klass_shift);\n-  jmp(done);\n-  bind(slow);\n+  jccb(Assembler::notZero, fast);\n@@ -4764,11 +4759,2 @@\n-  if (dst != rax) {\n-    push(rax);\n-  }\n-  if (src != rax) {\n-    mov(rax, src);\n-  }\n-  call(RuntimeAddress(StubRoutines::load_nklass()));\n-  if (dst != rax) {\n-    mov(dst, rax);\n-    pop(rax);\n-  }\n+  \/\/ Fetch displaced header\n+  movq(dst, Address(dst, ObjectMonitor::header_offset_in_bytes()));\n@@ -4776,1 +4762,2 @@\n-  bind(done);\n+  bind(fast);\n+  shrq(dst, markWord::klass_shift);\n@@ -4781,2 +4768,0 @@\n-  assert_different_registers(src, tmp);\n-  assert_different_registers(dst, tmp);\n@@ -4785,4 +4770,0 @@\n-  Register d = dst;\n-  if (src == dst) {\n-    d = tmp;\n-  }\n@@ -4792,4 +4773,1 @@\n-  load_nklass(d, src);\n-  if (src == dst) {\n-    mov(dst, d);\n-  }\n+  load_nklass(dst, src);\n@@ -9464,1 +9442,0 @@\n-\n@@ -9466,0 +9443,51 @@\n+\n+void MacroAssembler::fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp1, Register tmp2, Label& slow) {\n+  assert(hdr == rax, \"header must be in rax for cmpxchg\");\n+  assert_different_registers(obj, hdr, thread, tmp1, tmp2);\n+\n+  \/\/ First we need to check if the lock-stack has room for pushing the object reference.\n+  movptr(tmp1, Address(thread, Thread::lock_stack_current_offset()));\n+  cmpptr(tmp1, Address(thread, Thread::lock_stack_limit_offset()));\n+  jcc(Assembler::greaterEqual, slow);\n+\n+  Register locked_hdr = tmp2->is_valid() ? tmp2 : tmp1;\n+  \/\/ Now we attempt to take the fast-lock.\n+  \/\/ Clear lowest two header bits (locked state).\n+  andptr(hdr, ~(int32_t )markWord::lock_mask_in_place);\n+  movptr(locked_hdr, hdr);\n+  \/\/ Set lowest bit (unlocked state).\n+  orptr(hdr, markWord::unlocked_value);\n+  lock();\n+  cmpxchgptr(locked_hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  jcc(Assembler::notEqual, slow);\n+\n+  \/\/ Success: push object to lock-stack.\n+  if (!tmp2->is_valid()) {\n+    \/\/ If we did not have a valid tmp2, we used tmp1 instead, and we must re-load the current offset.\n+    movptr(tmp1, Address(thread, Thread::lock_stack_current_offset()));\n+  }\n+  movptr(Address(tmp1, 0), obj);\n+  increment(tmp1, oopSize);\n+  movptr(Address(thread, Thread::lock_stack_current_offset()), tmp1);\n+}\n+\n+void MacroAssembler::fast_unlock_impl(Register obj, Register hdr, Register tmp, Label& slow) {\n+  assert(hdr == rax, \"header must be in rax for cmpxchg\");\n+  assert_different_registers(obj, hdr, tmp);\n+\n+  \/\/ Mark-word must be 00 now, try to swing it back to 01 (unlocked)\n+  movptr(tmp, hdr); \/\/ The expected old value\n+  orptr(tmp, markWord::unlocked_value);\n+  lock();\n+  cmpxchgptr(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  jcc(Assembler::notZero, slow);\n+  \/\/ Pop the lock object from the lock-stack.\n+#ifdef _LP64\n+  const Register thread = r15_thread;\n+#else\n+  const Register thread = rax;\n+  get_thread(rax);\n+#endif\n+  subptr(Address(thread, Thread::lock_stack_current_offset()), oopSize);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":59,"deletions":31,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -866,0 +866,1 @@\n+  void xorptr(Register dst, int32_t src) { LP64_ONLY(xorq(dst, src)) NOT_LP64(xorl(dst, src)); }\n@@ -2063,0 +2064,3 @@\n+\n+  void fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp1, Register tmp2, Label& slow);\n+  void fast_unlock_impl(Register obj, Register hdr, Register tmp, Label& slow);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"runtime\/objectMonitor.hpp\"\n@@ -61,3 +62,8 @@\n-  \/\/ check if locked\n-  __ testptr(result, markWord::unlocked_value);\n-  __ jcc(Assembler::zero, slowCase);\n+  \/\/ Check if monitor - in this case we can pull the hashcode out of the displaced header.\n+  {\n+    Label L;\n+    __ testptr(result, markWord::monitor_value);\n+    __ jcc(Assembler::zero, L);\n+    __ movptr(result, Address(result, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+    __ bind(L);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1360,1 +1360,0 @@\n-                                       in_ByteSize(-1),\n@@ -1415,1 +1414,0 @@\n-  int lock_slot_offset = 0;\n@@ -1428,1 +1426,0 @@\n-    lock_slot_offset = stack_slots;\n@@ -1443,2 +1440,0 @@\n-  \/\/      | lock box (if sync)  |\n-  \/\/      |---------------------| <- lock_slot_offset  (-lock_slot_rbp_offset)\n@@ -1550,4 +1545,0 @@\n-  \/\/ Compute the rbp, offset for any slots used after the jni call\n-\n-  int lock_slot_rbp_offset = (lock_slot_offset*VMRegImpl::stack_slot_size) - fp_adjustment;\n-\n@@ -1688,1 +1679,1 @@\n-  const Register lock_reg = rdx;  \/\/ Address of compiler lock object (BasicLock)\n+  const Register tmp      = rdx;\n@@ -1696,2 +1687,0 @@\n-    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n@@ -1701,4 +1690,0 @@\n-    \/\/ Get address of the box\n-\n-    __ lea(lock_reg, Address(rbp, lock_slot_rbp_offset));\n-\n@@ -1709,30 +1694,3 @@\n-      \/\/ Load immediate 1 into swap_reg %rax,\n-      __ movptr(swap_reg, 1);\n-\n-      \/\/ Load (object->mark() | 1) into swap_reg %rax,\n-      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-\n-      \/\/ src -> dest iff dest == rax, else rax, <- dest\n-      \/\/ *obj_reg = lock_reg iff *obj_reg == rax, else rax, = *(obj_reg)\n-      __ lock();\n-      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::equal, lock_done);\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) rsp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %rax, as the result of cmpxchg\n-\n-      __ subptr(swap_reg, rsp);\n-      __ andptr(swap_reg, 3 - os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-      __ jcc(Assembler::notEqual, slow_path_lock);\n+      \/\/ Load object header\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock_impl(obj_reg, swap_reg, thread, tmp, noreg, slow_path_lock);\n@@ -1860,7 +1818,0 @@\n-    if (!UseHeavyMonitors) {\n-      \/\/ Simple recursive lock?\n-\n-      __ cmpptr(Address(rbp, lock_slot_rbp_offset), (int32_t)NULL_WORD);\n-      __ jcc(Assembler::equal, done);\n-    }\n-\n@@ -1873,12 +1824,3 @@\n-      \/\/  get old displaced header\n-      __ movptr(rbx, Address(rbp, lock_slot_rbp_offset));\n-\n-      \/\/ get address of the stack lock\n-      __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      \/\/ src -> dest iff dest == rax, else rax, <- dest\n-      \/\/ *obj_reg = rbx, iff *obj_reg == rax, else rax, = *(obj_reg)\n-      __ lock();\n-      __ cmpxchgptr(rbx, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::notEqual, slow_path_unlock);\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      __ fast_unlock_impl(obj_reg, swap_reg, tmp, slow_path_unlock);\n@@ -1971,1 +1913,0 @@\n-    __ push(lock_reg);\n@@ -1974,1 +1915,1 @@\n-    __ addptr(rsp, 3*wordSize);\n+    __ addptr(rsp, 2*wordSize);\n@@ -2006,2 +1947,0 @@\n-    __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n-    __ push(rax);\n@@ -2011,1 +1950,1 @@\n-    __ addptr(rsp, 3*wordSize);\n+    __ addptr(rsp, 2*wordSize);\n@@ -2066,1 +2005,0 @@\n-                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":9,"deletions":71,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -1526,1 +1526,0 @@\n-                                       in_ByteSize(-1),\n@@ -1582,1 +1581,0 @@\n-  int lock_slot_offset = 0;\n@@ -1595,1 +1593,0 @@\n-    lock_slot_offset = stack_slots;\n@@ -1610,2 +1607,0 @@\n-  \/\/      | lock box (if sync)  |\n-  \/\/      |---------------------| <- lock_slot_offset\n@@ -1625,1 +1620,0 @@\n-\n@@ -1895,2 +1889,1 @@\n-  const Register lock_reg = r13;  \/\/ Address of compiler lock object (BasicLock)\n-  const Register old_hdr  = r13;  \/\/ value of old header at unlock time\n+  const Register tmp = r13;       \/\/ value of old header at unlock time\n@@ -1903,2 +1896,0 @@\n-    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n@@ -1908,4 +1899,0 @@\n-    \/\/ Get address of the box\n-\n-    __ lea(lock_reg, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-\n@@ -1916,31 +1903,3 @@\n-      \/\/ Load immediate 1 into swap_reg %rax\n-      __ movl(swap_reg, 1);\n-\n-      \/\/ Load (object->mark() | 1) into swap_reg %rax\n-      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-\n-      \/\/ src -> dest iff dest == rax else rax <- dest\n-      __ lock();\n-      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::equal, lock_done);\n-\n-      \/\/ Hmm should this move to the slow path code area???\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) rsp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n-\n-      __ subptr(swap_reg, rsp);\n-      __ andptr(swap_reg, 3 - os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-      __ jcc(Assembler::notEqual, slow_path_lock);\n+      \/\/ Load object header\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock_impl(obj_reg, swap_reg, r15_thread, tmp, rscratch1, slow_path_lock);\n@@ -2057,6 +2016,0 @@\n-    if (!UseHeavyMonitors) {\n-      \/\/ Simple recursive lock?\n-      __ cmpptr(Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size), (int32_t)NULL_WORD);\n-      __ jcc(Assembler::equal, done);\n-    }\n-\n@@ -2068,1 +2021,0 @@\n-\n@@ -2070,9 +2022,3 @@\n-      \/\/ get address of the stack lock\n-      __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      \/\/  get old displaced header\n-      __ movptr(old_hdr, Address(rax, 0));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      __ lock();\n-      __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::notEqual, slow_path_unlock);\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      __ fast_unlock_impl(obj_reg, swap_reg, tmp, slow_path_unlock);\n@@ -2082,1 +2028,0 @@\n-\n@@ -2153,2 +2098,1 @@\n-    __ mov(c_rarg1, lock_reg);\n-    __ mov(c_rarg2, r15_thread);\n+    __ mov(c_rarg1, r15_thread);\n@@ -2182,2 +2126,0 @@\n-    __ lea(c_rarg1, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-\n@@ -2185,1 +2127,1 @@\n-    __ mov(c_rarg2, r15_thread);\n+    __ mov(c_rarg1, r15_thread);\n@@ -2246,1 +2188,0 @@\n-                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":9,"deletions":68,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -7417,40 +7417,0 @@\n-  \/\/ Call stub to call runtime oopDesc::load_nklass_runtime().\n-  \/\/ rax: call argument (object)\n-  \/\/ rax: return object's narrowKlass\n-  \/\/ Preserves all caller-saved registers, except rax\n-#ifdef _LP64\n-  address generate_load_nklass() {\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark(this, \"StubRoutines\", \"load_nklass\");\n-    address start = __ pc();\n-    __ enter(); \/\/ save rbp\n-\n-    __ andptr(rsp, -(StackAlignmentInBytes));    \/\/ Align stack\n-    __ push_FPU_state();\n-\n-    __ push(rdi);\n-    __ push(rsi);\n-    __ push(rdx);\n-    __ push(rcx);\n-    __ push(r8);\n-    __ push(r9);\n-    __ push(r10);\n-    __ push(r11);\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, oopDesc::load_nklass_runtime), rax);\n-    __ pop(r11);\n-    __ pop(r10);\n-    __ pop(r9);\n-    __ pop(r8);\n-    __ pop(rcx);\n-    __ pop(rdx);\n-    __ pop(rsi);\n-    __ pop(rdi);\n-\n-    __ pop_FPU_state();\n-\n-    __ leave();\n-    __ ret(0);\n-    return start;\n-  }\n-#endif \/\/ _LP64\n-\n@@ -7675,4 +7635,0 @@\n-\n-#ifdef _LP64\n-    StubRoutines::_load_nklass = generate_load_nklass();\n-#endif\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":0,"deletions":44,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -1225,6 +1225,0 @@\n-    if (UseRTMForStackLocks) {\n-      if (!FLAG_IS_DEFAULT(UseRTMForStackLocks)) {\n-        warning(\"UseRTMForStackLocks flag should be off when UseRTMLocking flag is off\");\n-      }\n-      FLAG_SET_DEFAULT(UseRTMForStackLocks, false);\n-    }\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -13690,1 +13690,1 @@\n-instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2) %{\n+instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2, eRegP thread) %{\n@@ -13692,2 +13692,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, TEMP box, TEMP thread);\n@@ -13697,0 +13697,1 @@\n+    __ get_thread($thread$$Register);\n@@ -13698,1 +13699,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register, $thread$$Register,\n@@ -13706,1 +13707,1 @@\n-instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr) %{\n+instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr, rRegI cx1, eRegP thread) %{\n@@ -13708,2 +13709,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, USE_KILL box);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP scr, TEMP box, TEMP cx1, TEMP thread);\n@@ -13713,0 +13714,1 @@\n+    __ get_thread($thread$$Register);\n@@ -13714,1 +13716,1 @@\n-                 $scr$$Register, noreg, noreg, NULL, NULL, NULL, false, false);\n+                 $scr$$Register, $cx1$$Register, noreg, $thread$$Register, NULL, NULL, NULL, false, false);\n@@ -13720,2 +13722,2 @@\n-  match(Set cr (FastUnlock object box));\n-  effect(TEMP tmp, USE_KILL box);\n+  match(Set cr (FastUnlock object));\n+  effect(TEMP tmp, TEMP box);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":12,"deletions":10,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -5236,1 +5236,1 @@\n-  effect(TEMP_DEF dst, KILL cr);\n+  effect(KILL cr);\n@@ -12991,2 +12991,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, TEMP box);\n@@ -12997,1 +12997,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register, r15_thread,\n@@ -13005,1 +13005,1 @@\n-instruct cmpFastLock(rFlagsReg cr, rRegP object, rbx_RegP box, rax_RegI tmp, rRegP scr, rRegP cx1) %{\n+instruct cmpFastLock(rFlagsReg cr, rRegP object, rax_RegI tmp, rRegP scr, rRegP cx1) %{\n@@ -13007,2 +13007,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, USE_KILL box);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1);\n@@ -13010,1 +13010,1 @@\n-  format %{ \"fastlock $object,$box\\t! kills $box,$tmp,$scr\" %}\n+  format %{ \"fastlock $object\\t! kills $tmp,$scr\" %}\n@@ -13012,2 +13012,2 @@\n-    __ fast_lock($object$$Register, $box$$Register, $tmp$$Register,\n-                 $scr$$Register, $cx1$$Register, noreg, NULL, NULL, NULL, false, false);\n+    __ fast_lock($object$$Register, noreg, $tmp$$Register,\n+                 $scr$$Register, $cx1$$Register, noreg, r15_thread, NULL, NULL, NULL, false, false);\n@@ -13019,2 +13019,2 @@\n-  match(Set cr (FastUnlock object box));\n-  effect(TEMP tmp, USE_KILL box);\n+  match(Set cr (FastUnlock object));\n+  effect(TEMP tmp, TEMP box);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -419,2 +419,0 @@\n-    else if (offset ==  BasicObjectLock::lock_offset_in_bytes())\n-      snprintf(fieldbuf, buflen, \"monitor[%d]->_lock\", index);\n","filename":"src\/hotspot\/cpu\/zero\/frame_zero.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -334,13 +334,4 @@\n-    markWord disp = lockee->mark().set_unlocked();\n-    monitor->lock()->set_displaced_header(disp);\n-    bool call_vm = UseHeavyMonitors;\n-    if (call_vm || lockee->cas_set_mark(markWord::from_pointer(monitor), disp) != disp) {\n-      \/\/ Is it simple recursive case?\n-      if (!call_vm && thread->is_lock_owned((address) disp.clear_lock_bits().to_pointer())) {\n-        monitor->lock()->set_displaced_header(markWord::from_pointer(NULL));\n-      } else {\n-        CALL_VM_NOCHECK(InterpreterRuntime::monitorenter(thread, monitor));\n-        if (HAS_PENDING_EXCEPTION)\n-          goto unwind_and_return;\n-      }\n-    }\n+\n+    CALL_VM_NOCHECK(InterpreterRuntime::monitorenter(thread, lockee));\n+    if (HAS_PENDING_EXCEPTION)\n+      goto unwind_and_return;\n@@ -477,2 +468,0 @@\n-    BasicLock *lock = monitor->lock();\n-    markWord header = lock->displaced_header();\n@@ -481,8 +470,1 @@\n-\n-    if (header.to_pointer() != NULL) {\n-      markWord old_header = markWord::encode(lock);\n-      if (rcvr->cas_set_mark(header, old_header) != old_header) {\n-        monitor->set_obj(rcvr);\n-        InterpreterRuntime::monitorexit(monitor);\n-      }\n-    }\n+    InterpreterRuntime::monitorexit(rcvr);\n","filename":"src\/hotspot\/cpu\/zero\/zeroInterpreter_zero.cpp","additions":5,"deletions":23,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -318,1 +318,0 @@\n-  LIR_Opr _lock_reg;\n@@ -321,1 +320,1 @@\n-  MonitorAccessStub(LIR_Opr obj_reg, LIR_Opr lock_reg) {\n+  MonitorAccessStub(LIR_Opr obj_reg) {\n@@ -323,1 +322,0 @@\n-    _lock_reg  = lock_reg;\n@@ -337,1 +335,1 @@\n-  MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info);\n+  MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info);\n@@ -343,1 +341,0 @@\n-    visitor->do_input(_lock_reg);\n@@ -353,4 +350,0 @@\n- private:\n-  bool _compute_lock;\n-  int  _monitor_ix;\n-\n@@ -358,3 +351,2 @@\n-  MonitorExitStub(LIR_Opr lock_reg, bool compute_lock, int monitor_ix)\n-    : MonitorAccessStub(LIR_OprFact::illegalOpr, lock_reg),\n-      _compute_lock(compute_lock), _monitor_ix(monitor_ix) { }\n+  MonitorExitStub(LIR_Opr obj_reg)\n+    : MonitorAccessStub(obj_reg) { }\n@@ -363,6 +355,2 @@\n-    assert(_obj_reg->is_illegal(), \"unused\");\n-    if (_compute_lock) {\n-      visitor->do_temp(_lock_reg);\n-    } else {\n-      visitor->do_input(_lock_reg);\n-    }\n+    visitor->do_input(_obj_reg);\n+    visitor->do_temp(_obj_reg);\n@@ -549,19 +537,0 @@\n-class LoadKlassStub: public CodeStub {\n-private:\n-  LIR_Opr          _obj;\n-  LIR_Opr          _result;\n-\n-public:\n-  LoadKlassStub(LIR_Opr obj, LIR_Opr result) :\n-    CodeStub(), _obj(obj), _result(result) {};\n-\n-  virtual void emit_code(LIR_Assembler* e);\n-  virtual void visit(LIR_OpVisitState* visitor) {\n-    visitor->do_input(_obj);\n-    visitor->do_output(_result);\n-  }\n-#ifndef PRODUCT\n-virtual void print_name(outputStream* out) const { out->print(\"LoadKlassStub\"); }\n-#endif \/\/ PRODUCT\n-};\n-\n","filename":"src\/hotspot\/share\/c1\/c1_CodeStubs.hpp","additions":6,"deletions":37,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -286,5 +286,0 @@\n-ByteSize FrameMap::sp_offset_for_monitor_lock(int index) const {\n-  check_monitor_index(index);\n-  return sp_offset_for_monitor_base(index) + in_ByteSize(BasicObjectLock::lock_offset_in_bytes());;\n-}\n-\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -144,1 +144,0 @@\n-  ByteSize sp_offset_for_monitor_lock(int monitor_index) const;\n@@ -209,3 +208,0 @@\n-  Address address_for_monitor_lock(int monitor_index) const {\n-    return make_new_address(sp_offset_for_monitor_lock(monitor_index));\n-  }\n@@ -223,3 +219,0 @@\n-  bool location_for_monitor_lock  (int monitor_index, Location* loc) const {\n-    return location_for_sp_offset(sp_offset_for_monitor_lock(monitor_index), Location::normal, loc);\n-  }\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.hpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -798,1 +798,1 @@\n-      assert(opLock->_obj->is_valid(),  \"used\");  do_temp(opLock->_obj);\n+      assert(opLock->_obj->is_valid(),  \"used\");  do_input(opLock->_obj); do_temp(opLock->_obj);\n@@ -890,1 +890,0 @@\n-      do_stub(opLoadKlass->_stub);\n@@ -1071,1 +1070,0 @@\n-  masm->append_code_stub(stub());\n@@ -2040,1 +2038,0 @@\n-  out->print(\"[lbl:\" INTPTR_FORMAT \"]\", p2i(stub()->entry()));\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1903,1 +1903,0 @@\n-  CodeStub* _stub;\n@@ -1905,1 +1904,1 @@\n-  LIR_OpLoadKlass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info, CodeStub* stub)\n+  LIR_OpLoadKlass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info)\n@@ -1907,2 +1906,1 @@\n-    , _obj(obj)\n-    , _stub(stub) {}\n+    , _obj(obj) {}\n@@ -1911,1 +1909,0 @@\n-  CodeStub* stub()     const { return _stub; }\n@@ -2375,1 +2372,1 @@\n-  void load_klass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info, CodeStub* stub) { append(new LIR_OpLoadKlass(obj, result, info, stub)); }\n+  void load_klass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info) { append(new LIR_OpLoadKlass(obj, result, info)); }\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -608,1 +608,1 @@\n-void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n+void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr tmp1, LIR_Opr tmp2, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n@@ -611,1 +611,1 @@\n-  CodeStub* slow_path = new MonitorEnterStub(object, lock, info);\n+  CodeStub* slow_path = new MonitorEnterStub(object, info);\n@@ -613,0 +613,1 @@\n+  __ move(object, new LIR_Address(lock, BasicObjectLock::obj_offset_in_bytes(), T_ADDRESS));\n@@ -614,1 +615,1 @@\n-  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception);\n+  __ lock_object(hdr, object, tmp1, tmp2, slow_path, info_for_exception);\n@@ -621,3 +622,1 @@\n-  LIR_Opr hdr = lock;\n-  lock = new_hdr;\n-  CodeStub* slow_path = new MonitorExitStub(lock, !UseHeavyMonitors, monitor_no);\n+  CodeStub* slow_path = new MonitorExitStub(object);\n@@ -625,1 +624,2 @@\n-  __ unlock_object(hdr, object, lock, scratch, slow_path);\n+  __ move(new LIR_Address(lock, BasicObjectLock::obj_offset_in_bytes(),T_ADDRESS), object);\n+  __ unlock_object(new_hdr, object, lock, scratch, slow_path);\n@@ -1243,2 +1243,1 @@\n-  CodeStub* slow_path = new LoadKlassStub(obj, klass);\n-  __ load_klass(obj, klass, null_check_info, slow_path);\n+  __ load_klass(obj, klass, null_check_info);\n@@ -2655,3 +2654,1 @@\n-      LIR_Opr lock = syncLockOpr();\n-      __ load_stack_address_monitor(0, lock);\n-\n+      LIR_Opr lock = new_register(T_ADDRESS);\n@@ -2659,4 +2656,1 @@\n-      CodeStub* slow_path = new MonitorEnterStub(obj, lock, info);\n-\n-      \/\/ receiver is guaranteed non-NULL so don't need CodeEmitInfo\n-      __ lock_object(syncTempOpr(), obj, lock, new_register(T_OBJECT), slow_path, NULL);\n+      monitor_enter(obj, lock, syncTempOpr(), new_register(T_INT), new_register(T_INT), 0, NULL, info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":10,"deletions":16,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -362,1 +362,1 @@\n-  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info);\n+  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr tmp1, LIR_Opr tmp2, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2535,3 +2535,0 @@\n-  if (!frame_map()->location_for_monitor_lock(monitor_index, &loc)) {\n-    bailout(\"too large frame\");\n-  }\n","filename":"src\/hotspot\/share\/c1\/c1_LinearScan.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -241,1 +241,0 @@\n-  case load_klass_id:\n@@ -734,1 +733,1 @@\n-JRT_BLOCK_ENTRY(void, Runtime1::monitorenter(JavaThread* current, oopDesc* obj, BasicObjectLock* lock))\n+JRT_BLOCK_ENTRY(void, Runtime1::monitorenter(JavaThread* current, oopDesc* obj))\n@@ -740,5 +739,1 @@\n-  if (UseHeavyMonitors) {\n-    lock->set_obj(obj);\n-  }\n-  assert(obj == lock->obj(), \"must match\");\n-  SharedRuntime::monitor_enter_helper(obj, lock->lock(), current);\n+  SharedRuntime::monitor_enter_helper(obj, current);\n@@ -748,1 +743,1 @@\n-JRT_LEAF(void, Runtime1::monitorexit(JavaThread* current, BasicObjectLock* lock))\n+JRT_LEAF(void, Runtime1::monitorexit(JavaThread* current, oopDesc* obj))\n@@ -755,3 +750,2 @@\n-  oop obj = lock->obj();\n-  assert(oopDesc::is_oop(obj), \"must be NULL or an object\");\n-  SharedRuntime::monitor_exit_helper(obj, lock->lock(), current);\n+  assert(oopDesc::is_oop(oop(obj)), \"must be NULL or an object: \" PTR_FORMAT, p2i(obj));\n+  SharedRuntime::monitor_exit_helper(obj, current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":5,"deletions":11,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -66,1 +66,0 @@\n-  stub(load_klass)                   \\\n@@ -156,2 +155,2 @@\n-  static void monitorenter(JavaThread* current, oopDesc* obj, BasicObjectLock* lock);\n-  static void monitorexit (JavaThread* current, BasicObjectLock* lock);\n+  static void monitorenter(JavaThread* current, oopDesc* obj);\n+  static void monitorexit (JavaThread* current, oopDesc* obj);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -462,1 +462,0 @@\n-  ByteSize basic_lock_sp_offset,\n@@ -479,1 +478,0 @@\n-            basic_lock_sp_offset,\n@@ -604,1 +602,0 @@\n-  ByteSize basic_lock_sp_offset,\n@@ -608,2 +605,1 @@\n-  _native_receiver_sp_offset(basic_lock_owner_sp_offset),\n-  _native_basic_lock_sp_offset(basic_lock_sp_offset)\n+  _native_receiver_sp_offset(basic_lock_owner_sp_offset)\n@@ -740,2 +736,1 @@\n-  _native_receiver_sp_offset(in_ByteSize(-1)),\n-  _native_basic_lock_sp_offset(in_ByteSize(-1))\n+  _native_receiver_sp_offset(in_ByteSize(-1))\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":2,"deletions":7,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -272,1 +272,1 @@\n-  \/\/ locate the owner and stack slot for the BasicLock. They are\n+  \/\/ locate the owner for the lock. It is\n@@ -280,1 +280,0 @@\n-  ByteSize _native_basic_lock_sp_offset;\n@@ -293,1 +292,0 @@\n-          ByteSize basic_lock_sp_offset,       \/* synchronized natives only *\/\n@@ -376,2 +374,1 @@\n-      _native_receiver_sp_offset(in_ByteSize(-1)),\n-      _native_basic_lock_sp_offset(in_ByteSize(-1)) {}\n+      _native_receiver_sp_offset(in_ByteSize(-1)) {}\n@@ -387,1 +384,0 @@\n-                                     ByteSize basic_lock_sp_offset,\n@@ -739,3 +735,0 @@\n-  ByteSize native_basic_lock_sp_offset() {\n-    return _native_basic_lock_sp_offset;\n-  }\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":2,"deletions":9,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -80,2 +80,1 @@\n-  markWord old_mark = ObjectSynchronizer::read_stable_mark(obj);\n-  assert(!old_mark.is_being_inflated(), \"must not see INFLATING marker here\");\n+  markWord old_mark = obj->mark_acquire();\n@@ -87,4 +86,0 @@\n-  \/\/ Ensure that the copy has the correct mark-word, in case it happened to copy with\n-  \/\/ INFLATING marker.\n-  update->set_mark(old_mark);\n-\n@@ -92,12 +87,6 @@\n-  while (true) {\n-    markWord prev_mark = obj->cas_set_mark(new_mark, old_mark, memory_order_conservative);\n-    if (prev_mark == old_mark) {\n-      return update;\n-    } else if (prev_mark == markWord::INFLATING()) {\n-      \/\/ This happens when we encounter a stack-locked object in from-space.\n-      \/\/ Busy-wait for completion.\n-      SpinPause();\n-    } else {\n-      assert(prev_mark.is_marked(), \"must be forwarded\");\n-      return cast_to_oop(prev_mark.clear_lock_bits().to_pointer());\n-    }\n+  markWord prev_mark = obj->cas_set_mark(new_mark, old_mark, memory_order_conservative);\n+  if (prev_mark == old_mark) {\n+    return update;\n+  } else {\n+    assert(prev_mark.is_marked(), \"must be forwarded\");\n+    return cast_to_oop(prev_mark.clear_lock_bits().to_pointer());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahForwarding.inline.hpp","additions":7,"deletions":18,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -36,3 +36,0 @@\n-#ifdef _LP64\n-  static inline markWord stable_mark(oop obj);\n-#endif\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahObjectUtils.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -36,90 +36,0 @@\n-\/\/ This is a variant of ObjectSynchronizer::stable_mark(), which does the same thing, but also\n-\/\/ handles forwarded objects. This is intended to be used by concurrent evacuation only. No other\n-\/\/ code is supposed to observe from-space objects.\n-#ifdef _LP64\n-markWord ShenandoahObjectUtils::stable_mark(oop obj) {\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n-  for (;;) {\n-    assert(heap->is_in(obj), \"object not in heap: \" PTR_FORMAT, p2i(obj));\n-    markWord mark = obj->mark_acquire();\n-\n-    \/\/ The mark can be in one of the following states:\n-    \/\/ *  Inflated     - just return mark from inflated monitor\n-    \/\/ *  Stack-locked - coerce it to inflating, and then return displaced mark\n-    \/\/ *  INFLATING    - busy wait for conversion to complete\n-    \/\/ *  Neutral      - return mark\n-    \/\/ *  Marked       - object is forwarded, try again on forwardee\n-\n-    \/\/ Most common case first.\n-    if (mark.is_neutral()) {\n-      return mark;\n-    }\n-\n-    \/\/ If object is already forwarded, then resolve it, and try again.\n-    if (mark.is_marked()) {\n-      if (heap->is_full_gc_move_in_progress()) {\n-        \/\/ In these cases, we want to return the header as-is: the Klass* would not be overloaded.\n-        return mark;\n-      }\n-      obj = cast_to_oop(mark.decode_pointer());\n-      continue;\n-    }\n-\n-    \/\/ CASE: inflated\n-    if (mark.has_monitor()) {\n-      \/\/ It is safe to access the object monitor because all Java and GC worker threads\n-      \/\/ participate in the monitor deflation protocol (i.e, they react to handshakes and STS requests).\n-      ObjectMonitor* inf = mark.monitor();\n-      markWord dmw = inf->header();\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(), mark.value());\n-      return dmw;\n-    }\n-\n-    \/\/ CASE: inflating\n-    if (mark.is_being_inflated()) {\n-      \/\/ Interference, try again.\n-      continue;\n-    }\n-\n-    \/\/ CASE: stack-locked\n-    if (mark.has_locker()) {\n-      if (Thread::current()->is_lock_owned((address)mark.locker())) {\n-        \/\/ This thread owns the lock. We can safely access it.\n-        markWord dmw = mark.displaced_mark_helper();\n-        assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(), mark.value());\n-        return dmw;\n-      }\n-\n-      \/\/ Else we try to install INFLATING into the header. This will (temporarily) prevent other\n-      \/\/ threads from stack-locking or evacuating the object.\n-      markWord cmp = obj->cas_set_mark(markWord::INFLATING(), mark);\n-      if (cmp != mark) {\n-        continue;       \/\/ Interference -- just retry\n-      }\n-\n-      \/\/ We've successfully installed INFLATING (0) into the mark-word.\n-      \/\/ This is the only case where 0 will appear in a mark-word.\n-      \/\/ Only the singular thread that successfully swings the mark-word\n-      \/\/ to 0 can fetch the stack-lock and safely read the displaced header.\n-\n-      \/\/ fetch the displaced mark from the owner's stack.\n-      \/\/ The owner can't die or unwind past the lock while our INFLATING\n-      \/\/ object is in the mark.  Furthermore the owner can't complete\n-      \/\/ an unlock on the object, either. No other thread can do evacuation, either.\n-      markWord dmw = mark.displaced_mark_helper();\n-      \/\/ Catch if the object's header is not neutral (not locked and\n-      \/\/ not marked is what we care about here).\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-      \/\/ Must preserve store ordering. The monitor state must\n-      \/\/ be stable at the time of publishing the monitor address.\n-      guarantee(obj->mark() == markWord::INFLATING(), \"invariant\");\n-      \/\/ Release semantics so that above set_object() is seen first.\n-      obj->release_set_mark(mark);\n-\n-      return dmw;\n-    }\n-  }\n-}\n-#endif\n-\n@@ -128,1 +38,8 @@\n-  markWord header = stable_mark(obj);\n+  markWord header = obj->mark_acquire();\n+  if (header.is_marked()) {\n+    obj = cast_to_oop(header.decode_pointer());\n+    header = obj->mark_acquire();\n+  }\n+  if (header.has_displaced_mark_helper()) {\n+    header = header.displaced_mark_helper();\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahObjectUtils.inline.hpp","additions":8,"deletions":91,"binary":false,"changes":99,"status":"modified"},{"patch":"@@ -49,4 +49,3 @@\n-    const markWord mark = obj->mark();\n-    \/\/ Having\/had displaced header, too risk to deal with them, skip\n-    if (mark == markWord::INFLATING() || mark.has_displaced_mark_helper()) {\n-      return false;\n+    markWord mark = obj->mark();\n+    if (mark.has_displaced_mark_helper()) {\n+      mark = mark.displaced_mark_helper();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahStringDedup.inline.hpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -109,3 +109,0 @@\n-\n-  \/\/ Cannot currently support stack-locking with Lilliput and ZGC.\n-  FLAG_SET_DEFAULT(UseHeavyMonitors, true);\n","filename":"src\/hotspot\/share\/gc\/z\/zArguments.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -729,5 +729,2 @@\n-JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* current, BasicObjectLock* elem))\n-#ifdef ASSERT\n-  current->last_frame().interpreter_frame_verify_monitor(elem);\n-#endif\n-  Handle h_obj(current, elem->obj());\n+JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* current, oopDesc* obj))\n+  Handle h_obj(current, obj);\n@@ -736,2 +733,2 @@\n-  ObjectSynchronizer::enter(h_obj, elem->lock(), current);\n-  assert(Universe::heap()->is_in_or_null(elem->obj()),\n+  ObjectSynchronizer::enter(h_obj, current);\n+  assert(Universe::heap()->is_in_or_null(h_obj()),\n@@ -739,3 +736,0 @@\n-#ifdef ASSERT\n-  current->last_frame().interpreter_frame_verify_monitor(elem);\n-#endif\n@@ -745,2 +739,2 @@\n-JRT_LEAF(void, InterpreterRuntime::monitorexit(BasicObjectLock* elem))\n-  oop obj = elem->obj();\n+JRT_LEAF(void, InterpreterRuntime::monitorexit(oopDesc* o))\n+  oop obj = oop(o);\n@@ -756,4 +750,1 @@\n-  ObjectSynchronizer::exit(obj, elem->lock(), JavaThread::current());\n-  \/\/ Free entry. If it is not cleared, the exception handling code will try to unlock the monitor\n-  \/\/ again at method exit or in the case of an exception.\n-  elem->set_obj(NULL);\n+  ObjectSynchronizer::exit(obj, JavaThread::current());\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":7,"deletions":16,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -108,2 +108,2 @@\n-  static void    monitorenter(JavaThread* current, BasicObjectLock* elem);\n-  static void    monitorexit (BasicObjectLock* elem);\n+  static void    monitorenter(JavaThread* current, oopDesc* obj);\n+  static void    monitorexit (oopDesc* obj);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -626,11 +626,1 @@\n-        markWord displaced = rcvr->mark().set_unlocked();\n-        mon->lock()->set_displaced_header(displaced);\n-        bool call_vm = UseHeavyMonitors;\n-        if (call_vm || rcvr->cas_set_mark(markWord::from_pointer(mon), displaced) != displaced) {\n-          \/\/ Is it simple recursive case?\n-          if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n-            mon->lock()->set_displaced_header(markWord::from_pointer(NULL));\n-          } else {\n-            CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);\n-          }\n-        }\n+        CALL_VM(InterpreterRuntime::monitorenter(THREAD, rcvr), handle_exception);\n@@ -720,11 +710,1 @@\n-      markWord displaced = lockee->mark().set_unlocked();\n-      entry->lock()->set_displaced_header(displaced);\n-      bool call_vm = UseHeavyMonitors;\n-      if (call_vm || lockee->cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {\n-        \/\/ Is it simple recursive case?\n-        if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n-          entry->lock()->set_displaced_header(markWord::from_pointer(NULL));\n-        } else {\n-          CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);\n-        }\n-      }\n+      CALL_VM(InterpreterRuntime::monitorenter(THREAD, lockee), handle_exception);\n@@ -1628,11 +1608,1 @@\n-          markWord displaced = lockee->mark().set_unlocked();\n-          entry->lock()->set_displaced_header(displaced);\n-          bool call_vm = UseHeavyMonitors;\n-          if (call_vm || lockee->cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {\n-            \/\/ Is it simple recursive case?\n-            if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n-              entry->lock()->set_displaced_header(markWord::from_pointer(NULL));\n-            } else {\n-              CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);\n-            }\n-          }\n+          CALL_VM(InterpreterRuntime::monitorenter(THREAD, lockee), handle_exception);\n@@ -1655,2 +1625,0 @@\n-            BasicLock* lock = most_recent->lock();\n-            markWord header = lock->displaced_header();\n@@ -1658,11 +1626,1 @@\n-\n-            \/\/ If it isn't recursive we either must swap old header or call the runtime\n-            bool call_vm = UseHeavyMonitors;\n-            if (header.to_pointer() != NULL || call_vm) {\n-              markWord old_header = markWord::encode(lock);\n-              if (call_vm || lockee->cas_set_mark(header, old_header) != old_header) {\n-                \/\/ restore object for the slow case\n-                most_recent->set_obj(lockee);\n-                InterpreterRuntime::monitorexit(most_recent);\n-              }\n-            }\n+            InterpreterRuntime::monitorexit(lockee);\n@@ -3081,2 +3039,0 @@\n-          BasicLock* lock = end->lock();\n-          markWord header = lock->displaced_header();\n@@ -3084,10 +3040,1 @@\n-\n-          \/\/ If it isn't recursive we either must swap old header or call the runtime\n-          if (header.to_pointer() != NULL) {\n-            markWord old_header = markWord::encode(lock);\n-            if (lockee->cas_set_mark(header, old_header) != old_header) {\n-              \/\/ restore object for the slow case\n-              end->set_obj(lockee);\n-              InterpreterRuntime::monitorexit(end);\n-            }\n-          }\n+          InterpreterRuntime::monitorexit(lockee);\n@@ -3140,2 +3087,2 @@\n-          } else if (UseHeavyMonitors) {\n-            InterpreterRuntime::monitorexit(base);\n+          } else {\n+            InterpreterRuntime::monitorexit(rcvr);\n@@ -3146,18 +3093,0 @@\n-          } else {\n-            BasicLock* lock = base->lock();\n-            markWord header = lock->displaced_header();\n-            base->set_obj(NULL);\n-\n-            \/\/ If it isn't recursive we either must swap old header or call the runtime\n-            if (header.to_pointer() != NULL) {\n-              markWord old_header = markWord::encode(lock);\n-              if (rcvr->cas_set_mark(header, old_header) != old_header) {\n-                \/\/ restore object for the slow case\n-                base->set_obj(rcvr);\n-                InterpreterRuntime::monitorexit(base);\n-                if (THREAD->has_pending_exception()) {\n-                  if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD->pending_exception());\n-                  THREAD->clear_pending_exception();\n-                }\n-              }\n-            }\n","filename":"src\/hotspot\/share\/interpreter\/zero\/bytecodeInterpreter.cpp","additions":7,"deletions":78,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -81,1 +81,0 @@\n-    static int sizeof_BasicLock;\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -85,1 +85,0 @@\n-int CompilerToVM::Data::sizeof_BasicLock = sizeof(BasicLock);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVMInit.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -394,2 +394,2 @@\n-JRT_BLOCK_ENTRY(void, JVMCIRuntime::monitorenter(JavaThread* current, oopDesc* obj, BasicLock* lock))\n-  SharedRuntime::monitor_enter_helper(obj, lock, current);\n+JRT_BLOCK_ENTRY(void, JVMCIRuntime::monitorenter(JavaThread* current, oopDesc* obj))\n+  SharedRuntime::monitor_enter_helper(obj, current);\n@@ -398,1 +398,1 @@\n-JRT_LEAF(void, JVMCIRuntime::monitorexit(JavaThread* current, oopDesc* obj, BasicLock* lock))\n+JRT_LEAF(void, JVMCIRuntime::monitorexit(JavaThread* current, oopDesc* obj))\n@@ -401,1 +401,1 @@\n-  SharedRuntime::monitor_exit_helper(obj, lock, current);\n+  SharedRuntime::monitor_exit_helper(obj, current);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciRuntime.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -503,2 +503,2 @@\n-  static void monitorenter(JavaThread* current, oopDesc* obj, BasicLock* lock);\n-  static void monitorexit (JavaThread* current, oopDesc* obj, BasicLock* lock);\n+  static void monitorenter(JavaThread* current, oopDesc* obj);\n+  static void monitorexit (JavaThread* current, oopDesc* obj);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciRuntime.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -90,1 +90,0 @@\n-  static_field(CompilerToVM::Data,             sizeof_BasicLock,                       int)                                          \\\n@@ -113,2 +112,0 @@\n-  volatile_nonstatic_field(BasicLock,          _displaced_header,                      markWord)                                     \\\n-                                                                                                                                     \\\n@@ -365,1 +362,0 @@\n-  declare_toplevel_type(BasicLock)                                        \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -39,4 +39,0 @@\n-  if (has_locker()) {  \/\/ has a stack lock\n-    BasicLock* locker = this->locker();\n-    return locker->displaced_header();\n-  }\n@@ -56,5 +52,0 @@\n-  if (has_locker()) {  \/\/ has a stack lock\n-    BasicLock* locker = this->locker();\n-    locker->set_displaced_header(m);\n-    return;\n-  }\n","filename":"src\/hotspot\/share\/oops\/markWord.cpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-\/\/    [ptr             | 00]  locked             ptr points to real header on stack\n+\/\/    [header          | 00]  locked             object is fast-locked\n@@ -56,1 +56,0 @@\n-\/\/    [0 ............ 0| 00]  inflating          inflation in progress\n@@ -59,4 +58,0 @@\n-\/\/\n-\/\/  - INFLATING() is a distinguished markword value of all zeros that is\n-\/\/    used when inflating an existing stack-lock into an ObjectMonitor.\n-\/\/    See below for is_being_inflated() and INFLATING().\n@@ -64,1 +59,0 @@\n-class BasicLock;\n@@ -161,12 +155,0 @@\n-  \/\/ Special temporary state of the markWord while being inflated.\n-  \/\/ Code that looks at mark outside a lock need to take this into account.\n-  bool is_being_inflated() const { return (value() == 0); }\n-\n-  \/\/ Distinguished markword value - used when inflating over\n-  \/\/ an existing stack-lock.  0 indicates the markword is \"BUSY\".\n-  \/\/ Lockword mutators that use a LD...CAS idiom should always\n-  \/\/ check for and avoid overwriting a 0 value installed by some\n-  \/\/ other thread.  (They should spin or block instead.  The 0 value\n-  \/\/ is transient and *should* be short-lived).\n-  static markWord INFLATING() { return zero(); }    \/\/ inflate-in-progress\n-\n@@ -184,2 +166,2 @@\n-  bool has_locker() const {\n-    return ((value() & lock_mask_in_place) == locked_value);\n+  markWord set_fast_locked() const {\n+    return markWord(value() & ~lock_mask_in_place);\n@@ -187,3 +169,2 @@\n-  BasicLock* locker() const {\n-    assert(has_locker(), \"check\");\n-    return (BasicLock*) value();\n+  bool is_fast_locked() const {\n+    return ((value() & lock_mask_in_place) == locked_value);\n@@ -200,1 +181,1 @@\n-    return ((value() & unlocked_value) == 0);\n+    return has_monitor();\n@@ -209,10 +190,1 @@\n-  \/\/ it is only used to be stored into BasicLock as the\n-  \/\/ indicator that the lock is using heavyweight monitor\n-  static markWord unused_mark() {\n-    return markWord(marked_value);\n-  }\n-  \/\/ the following two functions create the markWord to be\n-  \/\/ stored into object header, it encodes monitor info\n-  static markWord encode(BasicLock* lock) {\n-    return from_pointer(lock);\n-  }\n+  \/\/ create the markWord to be stored into object header, it encodes monitor info\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":7,"deletions":35,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -106,15 +106,1 @@\n-  if (!Universe::heap()->is_oop(obj)) {\n-    return false;\n-  }\n-\n-  \/\/ Header verification: the mark is typically non-zero. If we're\n-  \/\/ at a safepoint, it must not be zero.\n-  \/\/ Outside of a safepoint, the header could be changing (for example,\n-  \/\/ another thread could be inflating a lock on this object).\n-  if (ignore_mark_word) {\n-    return true;\n-  }\n-  if (obj->mark().value() != 0) {\n-    return true;\n-  }\n-  return !SafepointSynchronize::is_at_safepoint();\n+  return Universe::heap()->is_oop(obj);\n@@ -167,15 +153,0 @@\n-#ifdef _LP64\n-JRT_LEAF(narrowKlass, oopDesc::load_nklass_runtime(oopDesc* o))\n-  assert(o != NULL, \"null-check\");\n-  oop obj = oop(o);\n-  assert(oopDesc::is_oop(obj), \"need a valid oop here: \" PTR_FORMAT, p2i(o));\n-  markWord header = obj->mark();\n-  if (!header.is_neutral()) {\n-    header = ObjectSynchronizer::stable_mark(obj);\n-  }\n-  assert(header.is_neutral(), \"expect neutral header here\");\n-  narrowKlass nklass = header.narrow_klass();\n-  return nklass;\n-JRT_END\n-#endif\n-\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":1,"deletions":30,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -318,5 +318,0 @@\n-  \/\/ Runtime entry\n-#ifdef _LP64\n-  static narrowKlass load_nklass_runtime(oopDesc* o);\n-#endif\n-\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -88,1 +88,4 @@\n-  markWord header = ObjectSynchronizer::stable_mark(cast_to_oop(this));\n+  markWord header = mark();\n+  if (header.has_displaced_mark_helper()) {\n+    header = header.displaced_mark_helper();\n+  }\n@@ -101,2 +104,2 @@\n-  if (!header.is_neutral()) {\n-    header = ObjectSynchronizer::stable_mark(cast_to_oop(this));\n+  if (header.has_displaced_mark_helper()) {\n+    header = header.displaced_mark_helper();\n@@ -114,2 +117,2 @@\n-  if (!header.is_neutral()) {\n-    header = ObjectSynchronizer::stable_mark(cast_to_oop(this));\n+  if (header.has_displaced_mark_helper()) {\n+    header = header.displaced_mark_helper();\n@@ -127,2 +130,2 @@\n-  if (!header.is_neutral()) {\n-    header = ObjectSynchronizer::stable_mark(cast_to_oop(this));\n+  if (header.has_displaced_mark_helper()) {\n+    header = header.displaced_mark_helper();\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -3909,8 +3909,25 @@\n-  \/\/ Test the header to see if it is unlocked.\n-  Node *lock_mask      = _gvn.MakeConX(markWord::lock_mask_in_place);\n-  Node *lmasked_header = _gvn.transform(new AndXNode(header, lock_mask));\n-  Node *unlocked_val   = _gvn.MakeConX(markWord::unlocked_value);\n-  Node *chk_unlocked   = _gvn.transform(new CmpXNode( lmasked_header, unlocked_val));\n-  Node *test_unlocked  = _gvn.transform(new BoolNode( chk_unlocked, BoolTest::ne));\n-\n-  generate_slow_guard(test_unlocked, slow_region);\n+  \/\/ Test the header to see if it has a monitor. If so, try to pull the hashcode from there.\n+  Node* monitor_val   = _gvn.MakeConX(markWord::monitor_value);\n+  Node* xored_header  = _gvn.transform(new XorXNode(header, monitor_val));\n+  Node* lock_mask      = _gvn.MakeConX(markWord::lock_mask_in_place);\n+  Node* lmasked_header = _gvn.transform(new AndXNode(xored_header, lock_mask));\n+  Node* chk_monitor   = _gvn.transform(new CmpXNode( lmasked_header, _gvn.MakeConX(0)));\n+  Node* test_monitor  = _gvn.transform(new BoolNode( chk_monitor, BoolTest::eq));\n+\n+  RegionNode *r = new RegionNode(3);\n+  Node *phi = new PhiNode(r, TypeX_X);\n+\n+  IfNode* iff = create_and_xform_if(control(), test_monitor, PROB_FAIR, COUNT_UNKNOWN);\n+  Node* if_true = _gvn.transform(new IfTrueNode(iff));\n+  Node* monitor_ptr = _gvn.transform(new CastX2PNode(xored_header));\n+  header_addr = basic_plus_adr(monitor_ptr, ObjectMonitor::header_offset_in_bytes());\n+  Node* displaced_header = make_load(if_true, header_addr, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n+  r->init_req(1, if_true);\n+  phi->init_req(1, displaced_header);\n+  Node* if_false = _gvn.transform(new IfFalseNode(iff));\n+  r->init_req(2, if_false);\n+  phi->init_req(2, xored_header);\n+\n+  set_control(_gvn.transform(r));\n+  record_for_igvn(r);\n+  header = _gvn.transform(phi);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":25,"deletions":8,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -168,5 +168,0 @@\n-    if (UseRTMForStackLocks) {\n-      rlnc = (RTMLockingNamedCounter*)\n-           OptoRuntime::new_named_counter(state, NamedCounter::RTMLockingCounter);\n-      _stack_rtm_counters = rlnc->counters();\n-    }\n","filename":"src\/hotspot\/share\/opto\/locknode.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -92,0 +92,1 @@\n+  virtual uint match_edge(uint idx) const { return idx < 2; \/* Don't match box *\/ }\n@@ -122,0 +123,1 @@\n+  virtual uint match_edge(uint idx) const { return idx < 2; \/* Don't match box *\/ }\n","filename":"src\/hotspot\/share\/opto\/locknode.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2189,1 +2189,1 @@\n-                                  obj, box, NULL);\n+                                  obj, NULL, NULL);\n@@ -2246,1 +2246,1 @@\n-                                  \"complete_monitor_unlocking_C\", slow_path, obj, box, thread);\n+                                  \"complete_monitor_unlocking_C\", slow_path, obj, thread, NULL);\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -226,1 +226,1 @@\n-  Node *monitors_addr = basic_plus_adr(osr_buf, osr_buf, (max_locals+mcnt*2-1)*wordSize);\n+  Node *monitors_addr = basic_plus_adr(osr_buf, osr_buf, (max_locals+mcnt-1)*wordSize);\n@@ -235,6 +235,1 @@\n-    Node *lock_object = fetch_interpreter_state(index*2, T_OBJECT, monitors_addr, osr_buf);\n-    \/\/ Try and copy the displaced header to the BoxNode\n-    Node *displaced_hdr = fetch_interpreter_state((index*2) + 1, T_ADDRESS, monitors_addr, osr_buf);\n-\n-\n-    store_to_memory(control(), box, displaced_hdr, T_ADDRESS, Compile::AliasIdxRaw, MemNode::unordered);\n+    Node *lock_object = fetch_interpreter_state(index, T_OBJECT, monitors_addr, osr_buf);\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":2,"deletions":7,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -563,1 +563,1 @@\n-  const Type **fields = TypeTuple::fields(2);\n+  const Type **fields = TypeTuple::fields(1);\n@@ -565,2 +565,1 @@\n-  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;   \/\/ Address of stack location for lock\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2,fields);\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+1,fields);\n@@ -580,1 +579,1 @@\n-  const Type **fields = TypeTuple::fields(3);\n+  const Type **fields = TypeTuple::fields(2);\n@@ -582,3 +581,2 @@\n-  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;    \/\/ Address of stack location for lock - BasicLock\n-  fields[TypeFunc::Parms+2] = TypeRawPtr::BOTTOM;    \/\/ Thread pointer (Self)\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;    \/\/ Thread pointer (Self)\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1978,0 +1978,1 @@\n+#define XorXNode     XorLNode\n@@ -2024,0 +2025,1 @@\n+#define XorXNode     XorINode\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -975,0 +975,3 @@\n+      if (mark.is_fast_locked()) {\n+        owner = cast_from_oop<address>(hobj());\n+      }\n@@ -976,8 +979,1 @@\n-      if (!mark.has_monitor()) {\n-        \/\/ this object has a lightweight monitor\n-\n-        if (mark.has_locker()) {\n-          owner = (address)mark.locker(); \/\/ save the address of the Lock word\n-        }\n-        \/\/ implied else: no owner\n-      } else {\n+      if (mark.has_monitor()) {\n@@ -988,2 +984,2 @@\n-        \/\/ owner, a JavaThread * or it may still be the address of the\n-        \/\/ Lock word in a JavaThread's stack. A monitor can be inflated\n+        \/\/ owner, a JavaThread* or ANONYMOUS marker, in which case another thread holds\n+        \/\/ the stack-lock. A monitor can be inflated\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnvBase.cpp","additions":6,"deletions":10,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2059,8 +2059,0 @@\n-#endif\n-#if (defined(X86) || defined(PPC64)) && !defined(ZERO)\n-  if (UseHeavyMonitors && UseRTMForStackLocks) {\n-    jio_fprintf(defaultStream::error_stream(),\n-                \"-XX:+UseHeavyMonitors and -XX:+UseRTMForStackLocks are mutually exclusive\");\n-\n-    return false;\n-  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1,84 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-#include \"runtime\/basicLock.hpp\"\n-#include \"runtime\/synchronizer.hpp\"\n-\n-void BasicLock::print_on(outputStream* st, oop owner) const {\n-  st->print(\"monitor\");\n-  markWord mark_word = displaced_header();\n-  if (mark_word.value() != 0) {\n-    \/\/ Print monitor info if there's an owning oop and it refers to this BasicLock.\n-    bool print_monitor_info = (owner != NULL) && (owner->mark() == markWord::from_pointer((void*)this));\n-    mark_word.print_on(st, print_monitor_info);\n-  }\n-}\n-\n-void BasicLock::move_to(oop obj, BasicLock* dest) {\n-  \/\/ Check to see if we need to inflate the lock. This is only needed\n-  \/\/ if an object is locked using \"this\" lightweight monitor. In that\n-  \/\/ case, the displaced_header() is unlocked\/is_neutral, because the\n-  \/\/ displaced_header() contains the header for the originally unlocked\n-  \/\/ object. However the lock could have already been inflated. But it\n-  \/\/ does not matter, this inflation will just a no-op. For other cases,\n-  \/\/ the displaced header will be either 0x0 or 0x3, which are location\n-  \/\/ independent, therefore the BasicLock is free to move.\n-  \/\/\n-  \/\/ During OSR we may need to relocate a BasicLock (which contains a\n-  \/\/ displaced word) from a location in an interpreter frame to a\n-  \/\/ new location in a compiled frame.  \"this\" refers to the source\n-  \/\/ BasicLock in the interpreter frame.  \"dest\" refers to the destination\n-  \/\/ BasicLock in the new compiled frame.  We *always* inflate in move_to()\n-  \/\/ when the object is locked using \"this\" lightweight monitor.\n-  \/\/\n-  \/\/ The always-Inflate policy works properly, but it depends on the\n-  \/\/ inflated fast-path operations in fast_lock and fast_unlock to avoid\n-  \/\/ performance problems. See x86\/macroAssembler_x86.cpp: fast_lock()\n-  \/\/ and fast_unlock() for examples.\n-  \/\/\n-  \/\/ Note that there is a way to safely swing the object's markword from\n-  \/\/ one stack location to another.  This avoids inflation.  Obviously,\n-  \/\/ we need to ensure that both locations refer to the current thread's stack.\n-  \/\/ There are some subtle concurrency issues, however, and since the benefit is\n-  \/\/ is small (given the support for inflated fast-path locking in the fast_lock, etc)\n-  \/\/ we'll leave that optimization for another time.\n-\n-  if (displaced_header().is_neutral()) {\n-    \/\/ The object is locked and the resulting ObjectMonitor* will also be\n-    \/\/ locked so it can't be async deflated until ownership is dropped.\n-    ObjectSynchronizer::inflate_helper(obj);\n-    \/\/ WARNING: We cannot put a check here, because the inflation\n-    \/\/ will not update the displaced header. Once BasicLock is inflated,\n-    \/\/ no one should ever look at its content.\n-  } else {\n-    \/\/ Typically the displaced header will be 0 (recursive stack lock) or\n-    \/\/ unused_mark.  Naively we'd like to assert that the displaced mark\n-    \/\/ value is either 0, neutral, or 3.  But with the advent of the\n-    \/\/ store-before-CAS avoidance in fast_lock\/compiler_lock_object\n-    \/\/ we can find any flavor mark in the displaced mark.\n-  }\n-  dest->set_displaced_header(displaced_header());\n-}\n","filename":"src\/hotspot\/share\/runtime\/basicLock.cpp","additions":0,"deletions":84,"binary":false,"changes":84,"status":"deleted"},{"patch":"@@ -32,23 +32,1 @@\n-class BasicLock {\n-  friend class VMStructs;\n-  friend class JVMCIVMStructs;\n- private:\n-  volatile markWord _displaced_header;\n- public:\n-  markWord displaced_header() const {\n-    return Atomic::load(&_displaced_header);\n-  }\n-\n-  void set_displaced_header(markWord header) {\n-    Atomic::store(&_displaced_header, header);\n-  }\n-\n-  void print_on(outputStream* st, oop owner) const;\n-\n-  \/\/ move a basic lock (used during deoptimization\n-  void move_to(oop obj, BasicLock* dest);\n-\n-  static int displaced_header_offset_in_bytes()       { return offset_of(BasicLock, _displaced_header); }\n-};\n-\n-\/\/ A BasicObjectLock associates a specific Java object with a BasicLock.\n+\/\/ A BasicObjectLock represents a locked object.\n@@ -59,3 +37,1 @@\n-\/\/ after the end of the BasicObjectLock.  Also, in order to guarantee\n-\/\/ alignment of the embedded BasicLock objects on such machines, we\n-\/\/ put the embedded BasicLock at the beginning of the struct.\n+\/\/ after the end of the BasicObjectLock.\n@@ -66,1 +42,0 @@\n-  BasicLock _lock;                                    \/\/ the lock, must be double word aligned\n@@ -68,0 +43,5 @@\n+#ifdef AARCH64\n+  \/\/ Stack needs to be 16-byte-aligned. Inserting a dummy field here is\n+  \/\/ the simplest way to achieve that.\n+  intptr_t _dummy;\n+#endif\n@@ -73,1 +53,0 @@\n-  BasicLock* lock()                                   { return &_lock; }\n@@ -83,1 +62,0 @@\n-  static int lock_offset_in_bytes()                   { return offset_of(BasicObjectLock, _lock); }\n","filename":"src\/hotspot\/share\/runtime\/basicLock.hpp","additions":7,"deletions":29,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -1485,17 +1485,7 @@\n-        if (exec_mode == Unpack_none) {\n-          if (mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n-            \/\/ With exec_mode == Unpack_none obj may be thread local and locked in\n-            \/\/ a callee frame. Make the lock in the callee a recursive lock and restore the displaced header.\n-            markWord dmw = mark.displaced_mark_helper();\n-            mark.locker()->set_displaced_header(markWord::encode((BasicLock*) NULL));\n-            obj->set_mark(dmw);\n-          }\n-          if (mark.has_monitor()) {\n-            \/\/ defer relocking if the deoptee thread is currently waiting for obj\n-            ObjectMonitor* waiting_monitor = deoptee_thread->current_waiting_monitor();\n-            if (waiting_monitor != NULL && waiting_monitor->object() == obj()) {\n-              assert(fr.is_deoptimized_frame(), \"frame must be scheduled for deoptimization\");\n-              mon_info->lock()->set_displaced_header(markWord::unused_mark());\n-              JvmtiDeferredUpdates::inc_relock_count_after_wait(deoptee_thread);\n-              continue;\n-            }\n+        if (exec_mode == Unpack_none && mark.has_monitor()) {\n+          \/\/ defer relocking if the deoptee thread is currently waiting for obj\n+          ObjectMonitor* waiting_monitor = deoptee_thread->current_waiting_monitor();\n+          if (waiting_monitor != NULL && waiting_monitor->object() == obj()) {\n+            assert(fr.is_deoptimized_frame(), \"frame must be scheduled for deoptimization\");\n+            JvmtiDeferredUpdates::inc_relock_count_after_wait(deoptee_thread);\n+            continue;\n@@ -1504,2 +1494,1 @@\n-        BasicLock* lock = mon_info->lock();\n-        ObjectSynchronizer::enter(obj, lock, deoptee_thread);\n+        ObjectSynchronizer::enter(obj, deoptee_thread);\n@@ -1580,1 +1569,1 @@\n-          ObjectSynchronizer::exit(src->obj(), src->lock(), thread);\n+          ObjectSynchronizer::exit(src->obj(), thread);\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":9,"deletions":20,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -507,3 +507,0 @@\n-    st->print(\" - lock   [\");\n-    current->lock()->print_on(st, current->obj());\n-    st->print_cr(\"]\");\n@@ -1003,10 +1000,0 @@\n-\n-BasicLock* frame::get_native_monitor() {\n-  nmethod* nm = (nmethod*)_cb;\n-  assert(_cb != NULL && _cb->is_nmethod() && nm->method()->is_native(),\n-         \"Should not call this unless it's a native nmethod\");\n-  int byte_offset = in_bytes(nm->native_basic_lock_sp_offset());\n-  assert(byte_offset >= 0, \"should not see invalid offset\");\n-  return (BasicLock*) &sp()[byte_offset \/ wordSize];\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":0,"deletions":13,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -272,1 +272,1 @@\n-  \/\/ Return the monitor owner and BasicLock for compiled synchronized\n+  \/\/ Return the monitor owner for compiled synchronized\n@@ -275,1 +275,0 @@\n-  BasicLock* get_native_monitor();\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,71 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"runtime\/lockStack.hpp\"\n+#include \"runtime\/safepoint.hpp\"\n+#include \"runtime\/thread.hpp\"\n+#include \"utilities\/copy.hpp\"\n+#include \"utilities\/ostream.hpp\"\n+\n+LockStack::LockStack() :\n+        _base(UseHeavyMonitors ? NULL : NEW_C_HEAP_ARRAY(oop, INITIAL_CAPACITY, mtSynchronizer)),\n+        _limit(_base + INITIAL_CAPACITY),\n+        _current(_base) {\n+}\n+\n+LockStack::~LockStack() {\n+  if (!UseHeavyMonitors) {\n+    FREE_C_HEAP_ARRAY(oop, _base);\n+  }\n+}\n+\n+#ifndef PRODUCT\n+void LockStack::validate(const char* msg) const {\n+  assert(!UseHeavyMonitors, \"never use lock-stack when fast-locking is disabled\");\n+  for (oop* loc1 = _base; loc1 < _current - 1; loc1++) {\n+    for (oop* loc2 = loc1 + 1; loc2 < _current; loc2++) {\n+      assert(*loc1 != *loc2, \"entries must be unique: %s\", msg);\n+    }\n+  }\n+}\n+#endif\n+\n+void LockStack::grow() {\n+  \/\/ Grow stack.\n+  assert(_limit > _base, \"invariant\");\n+  size_t capacity = _limit - _base;\n+  size_t index = _current - _base;\n+  size_t new_capacity = capacity * 2;\n+  oop* new_stack = NEW_C_HEAP_ARRAY(oop, new_capacity, mtSynchronizer);\n+  for (size_t i = 0; i < index; i++) {\n+    *(new_stack + i) = *(_base + i);\n+  }\n+  FREE_C_HEAP_ARRAY(oop, _base);\n+  _base = new_stack;\n+  _limit = _base + new_capacity;\n+  _current = _base + index;\n+  assert(_current < _limit, \"must fit after growing\");\n+}\n","filename":"src\/hotspot\/share\/runtime\/lockStack.cpp","additions":71,"deletions":0,"binary":false,"changes":71,"status":"added"},{"patch":"@@ -0,0 +1,64 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_RUNTIME_LOCKSTACK_HPP\n+#define SHARE_RUNTIME_LOCKSTACK_HPP\n+\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/sizes.hpp\"\n+\n+class Thread;\n+class OopClosure;\n+\n+class LockStack {\n+  friend class VMStructs;\n+private:\n+  static const size_t INITIAL_CAPACITY = 4;\n+  oop* _base;\n+  oop* _limit;\n+  oop* _current;\n+\n+  void grow();\n+  void validate(const char* msg) const PRODUCT_RETURN;\n+public:\n+  static ByteSize current_offset()    { return byte_offset_of(LockStack, _current); }\n+  static ByteSize base_offset()       { return byte_offset_of(LockStack, _base); }\n+  static ByteSize limit_offset()      { return byte_offset_of(LockStack, _limit); }\n+\n+  LockStack();\n+  ~LockStack();\n+\n+  inline void push(oop o);\n+  inline oop pop();\n+  inline void remove(oop o);\n+\n+  inline bool contains(oop o) const;\n+\n+  \/\/ GC support\n+  inline void oops_do(OopClosure* cl);\n+\n+};\n+\n+#endif \/\/ SHARE_RUNTIME_LOCKSTACK_HPP\n","filename":"src\/hotspot\/share\/runtime\/lockStack.hpp","additions":64,"deletions":0,"binary":false,"changes":64,"status":"added"},{"patch":"@@ -0,0 +1,92 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n+#define SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n+\n+#include \"memory\/iterator.hpp\"\n+#include \"runtime\/lockStack.hpp\"\n+\n+inline void LockStack::push(oop o) {\n+  validate(\"pre-push\");\n+  assert(!contains(o), \"entries must be unique\");\n+  if (_current >= _limit) {\n+    grow();\n+  }\n+  *_current = o;\n+  _current++;\n+  validate(\"post-push\");\n+}\n+\n+inline oop LockStack::pop() {\n+  validate(\"pre-pop\");\n+  oop* new_loc = _current - 1;\n+  assert(new_loc < _current, \"underflow, probably unbalanced push\/pop\");\n+  _current = new_loc;\n+  oop o = *_current;\n+  assert(!contains(o), \"entries must be unique\");\n+  validate(\"post-pop\");\n+  return o;\n+}\n+\n+inline void LockStack::remove(oop o) {\n+  validate(\"pre-remove\");\n+  assert(contains(o), \"entry must be present\");\n+  for (oop* loc = _base; loc < _current; loc++) {\n+    if (*loc == o) {\n+      oop* last = _current - 1;\n+      for (; loc < last; loc++) {\n+        *loc = *(loc + 1);\n+      }\n+      _current--;\n+      break;\n+    }\n+  }\n+  assert(!contains(o), \"entries must be unique: \" PTR_FORMAT, p2i(o));\n+  validate(\"post-remove\");\n+}\n+\n+inline bool LockStack::contains(oop o) const {\n+  validate(\"pre-contains\");\n+  bool found = false;\n+  size_t i = 0;\n+  size_t found_i = 0;\n+  for (oop* loc = _current - 1; loc >= _base; loc--) {\n+    if (*loc == o) {\n+      return true;\n+    }\n+  }\n+  validate(\"post-contains\");\n+  return false;\n+}\n+\n+inline void LockStack::oops_do(OopClosure* cl) {\n+  validate(\"pre-oops-do\");\n+  for (oop* loc = _base; loc < _current; loc++) {\n+    cl->do_oop(loc);\n+  }\n+  validate(\"post-oops-do\");\n+}\n+\n+#endif \/\/ SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n","filename":"src\/hotspot\/share\/runtime\/lockStack.inline.hpp","additions":92,"deletions":0,"binary":false,"changes":92,"status":"added"},{"patch":"@@ -337,6 +337,1 @@\n-  if (current->is_lock_owned((address)cur)) {\n-    assert(_recursions == 0, \"internal state error\");\n-    _recursions = 1;\n-    set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-    return true;\n-  }\n+  assert(cur == ANONYMOUS_OWNER || !current->is_lock_owned((address)cur), \"no stack-locking\");\n@@ -1154,14 +1149,10 @@\n-    if (current->is_lock_owned((address)cur)) {\n-      assert(_recursions == 0, \"invariant\");\n-      set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-      _recursions = 0;\n-    } else {\n-      \/\/ Apparent unbalanced locking ...\n-      \/\/ Naively we'd like to throw IllegalMonitorStateException.\n-      \/\/ As a practical matter we can neither allocate nor throw an\n-      \/\/ exception as ::exit() can be called from leaf routines.\n-      \/\/ see x86_32.ad Fast_Unlock() and the I1 and I2 properties.\n-      \/\/ Upon deeper reflection, however, in a properly run JVM the only\n-      \/\/ way we should encounter this situation is in the presence of\n-      \/\/ unbalanced JNI locking. TODO: CheckJNICalls.\n-      \/\/ See also: CR4414101\n+    assert(!current->is_lock_owned((address)cur), \"no stack-locking\");\n+    \/\/ Apparent unbalanced locking ...\n+    \/\/ Naively we'd like to throw IllegalMonitorStateException.\n+    \/\/ As a practical matter we can neither allocate nor throw an\n+    \/\/ exception as ::exit() can be called from leaf routines.\n+    \/\/ see x86_32.ad Fast_Unlock() and the I1 and I2 properties.\n+    \/\/ Upon deeper reflection, however, in a properly run JVM the only\n+    \/\/ way we should encounter this situation is in the presence of\n+    \/\/ unbalanced JNI locking. TODO: CheckJNICalls.\n+    \/\/ See also: CR4414101\n@@ -1169,6 +1160,6 @@\n-      LogStreamHandle(Error, monitorinflation) lsh;\n-      lsh.print_cr(\"ERROR: ObjectMonitor::exit(): thread=\" INTPTR_FORMAT\n-                    \" is exiting an ObjectMonitor it does not own.\", p2i(current));\n-      lsh.print_cr(\"The imbalance is possibly caused by JNI locking.\");\n-      print_debug_style_on(&lsh);\n-      assert(false, \"Non-balanced monitor enter\/exit!\");\n+    LogStreamHandle(Error, monitorinflation) lsh;\n+    lsh.print_cr(\"ERROR: ObjectMonitor::exit(): thread=\" INTPTR_FORMAT\n+                  \" is exiting an ObjectMonitor it does not own.\", p2i(current));\n+    lsh.print_cr(\"The imbalance is possibly caused by JNI locking.\");\n+    print_debug_style_on(&lsh);\n+    assert(false, \"Non-balanced monitor enter\/exit! \" PTR_FORMAT, p2i(object()));\n@@ -1176,2 +1167,1 @@\n-      return;\n-    }\n+    return;\n@@ -1374,5 +1364,1 @@\n-    if (current->is_lock_owned((address)cur)) {\n-      assert(_recursions == 0, \"internal state error\");\n-      set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-      _recursions = 0;\n-    }\n+    assert(!current->is_lock_owned((address)cur), \"no stack-locking\");\n@@ -1423,0 +1409,1 @@\n+  assert(cur != ANONYMOUS_OWNER, \"no anon owner here\");\n@@ -1426,5 +1413,0 @@\n-  if (current->is_lock_owned((address)cur)) {\n-    set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-    _recursions = 0;\n-    return true;\n-  }\n@@ -2030,6 +2012,0 @@\n-\/\/ Beware too, that _owner is sometimes a BasicLock address and sometimes\n-\/\/ a thread pointer.\n-\/\/ Alternately, we might tag the type (thread pointer vs basiclock pointer)\n-\/\/ with the LSB of _owner.  Another option would be to probabilistically probe\n-\/\/ the putative _owner->TypeTag value.\n-\/\/\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":20,"deletions":44,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -63,1 +63,1 @@\n-\/\/ JavaMonitor. The lightweight BasicLock\/stack lock version has been\n+\/\/ JavaMonitor. The lightweight fast-lock version has been\n@@ -150,1 +150,4 @@\n-  void* volatile _owner;            \/\/ pointer to owning thread OR BasicLock\n+  #define ANONYMOUS_OWNER reinterpret_cast<void*>(1)\n+\n+  \/\/ TODO: Change type to Thread*\n+  void* volatile _owner;            \/\/ pointer to owning thread\n@@ -260,2 +263,0 @@\n-  \/\/ Simply set _owner field to current; current value must match basic_lock_p.\n-  void      set_owner_from_BasicLock(void* basic_lock_p, JavaThread* current);\n@@ -267,0 +268,12 @@\n+  void set_owner_anonymous() {\n+    set_owner_from(NULL, ANONYMOUS_OWNER);\n+  }\n+\n+  bool is_owner_anonymous() const {\n+    return _owner == ANONYMOUS_OWNER;\n+  }\n+\n+  void set_owner_from_anonymous(Thread* owner) {\n+    set_owner_from(ANONYMOUS_OWNER, owner);\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -119,16 +119,0 @@\n-\/\/ Simply set _owner field to self; current value must match basic_lock_p.\n-inline void ObjectMonitor::set_owner_from_BasicLock(void* basic_lock_p, JavaThread* current) {\n-#ifdef ASSERT\n-  void* prev = Atomic::load(&_owner);\n-  assert(prev == basic_lock_p, \"unexpected prev owner=\" INTPTR_FORMAT\n-         \", expected=\" INTPTR_FORMAT, p2i(prev), p2i(basic_lock_p));\n-#endif\n-  \/\/ Non-null owner field to non-null owner field is safe without\n-  \/\/ cmpxchg() as long as all readers can tolerate either flavor.\n-  Atomic::store(&_owner, current);\n-  log_trace(monitorinflation, owner)(\"set_owner_from_BasicLock(): mid=\"\n-                                     INTPTR_FORMAT \", basic_lock_p=\"\n-                                     INTPTR_FORMAT \", new_value=\" INTPTR_FORMAT,\n-                                     p2i(this), p2i(basic_lock_p), p2i(current));\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.inline.hpp","additions":0,"deletions":16,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2113,1 +2113,1 @@\n-void SharedRuntime::monitor_enter_helper(oopDesc* obj, BasicLock* lock, JavaThread* current) {\n+void SharedRuntime::monitor_enter_helper(oopDesc* obj, JavaThread* current) {\n@@ -2117,1 +2117,1 @@\n-    if (ObjectSynchronizer::quick_enter(obj, current, lock)) return;\n+    if (ObjectSynchronizer::quick_enter(obj, current)) return;\n@@ -2125,1 +2125,1 @@\n-  ObjectSynchronizer::enter(h_obj, lock, current);\n+  ObjectSynchronizer::enter(h_obj, current);\n@@ -2131,2 +2131,2 @@\n-JRT_BLOCK_ENTRY(void, SharedRuntime::complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* current))\n-  SharedRuntime::monitor_enter_helper(obj, lock, current);\n+JRT_BLOCK_ENTRY(void, SharedRuntime::complete_monitor_locking_C(oopDesc* obj, JavaThread* current))\n+  SharedRuntime::monitor_enter_helper(obj, current);\n@@ -2135,1 +2135,1 @@\n-void SharedRuntime::monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current) {\n+void SharedRuntime::monitor_exit_helper(oopDesc* obj, JavaThread* current) {\n@@ -2147,1 +2147,1 @@\n-  ObjectSynchronizer::exit(obj, lock, current);\n+  ObjectSynchronizer::exit(obj, current);\n@@ -2151,2 +2151,2 @@\n-JRT_LEAF(void, SharedRuntime::complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* current))\n-  SharedRuntime::monitor_exit_helper(obj, lock, current);\n+JRT_LEAF(void, SharedRuntime::complete_monitor_unlocking_C(oopDesc* obj, JavaThread* current))\n+  SharedRuntime::monitor_exit_helper(obj, current);\n@@ -3222,11 +3222,0 @@\n-      BasicLock *lock = kptr2->lock();\n-      \/\/ Inflate so the object's header no longer refers to the BasicLock.\n-      if (lock->displaced_header().is_unlocked()) {\n-        \/\/ The object is locked and the resulting ObjectMonitor* will also be\n-        \/\/ locked so it can't be async deflated until ownership is dropped.\n-        \/\/ See the big comment in basicLock.cpp: BasicLock::move_to().\n-        ObjectSynchronizer::inflate_helper(kptr2->obj());\n-      }\n-      \/\/ Now the displaced header is free to move because the\n-      \/\/ object's header no longer refers to it.\n-      buf[i++] = (intptr_t)lock->displaced_header().value();\n@@ -3236,1 +3225,1 @@\n-  assert(i - max_locals == active_monitor_count*2, \"found the expected number of monitors\");\n+  assert(i - max_locals == active_monitor_count, \"found the expected number of monitors\");\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":10,"deletions":21,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -341,1 +341,1 @@\n-  static void monitor_enter_helper(oopDesc* obj, BasicLock* lock, JavaThread* thread);\n+  static void monitor_enter_helper(oopDesc* obj, JavaThread* thread);\n@@ -343,1 +343,1 @@\n-  static void monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current);\n+  static void monitor_exit_helper(oopDesc* obj, JavaThread* current);\n@@ -489,2 +489,2 @@\n-  static void complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* current);\n-  static void complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* current);\n+  static void complete_monitor_locking_C(oopDesc* obj, JavaThread* current);\n+  static void complete_monitor_unlocking_C(oopDesc* obj, JavaThread* current);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -201,16 +201,0 @@\n-\n-BasicLock* StackValue::resolve_monitor_lock(const frame* fr, Location location) {\n-  assert(location.is_stack(), \"for now we only look at the stack\");\n-  int word_offset = location.stack_offset() \/ wordSize;\n-  \/\/ (stack picture)\n-  \/\/ high: [     ]  word_offset + 1\n-  \/\/ low   [     ]  word_offset\n-  \/\/\n-  \/\/ sp->  [     ]  0\n-  \/\/ the word_offset is the distance from the stack pointer to the lowest address\n-  \/\/ The frame's original stack pointer, before any extension by its callee\n-  \/\/ (due to Compiler1 linkage on SPARC), must be used.\n-  return (BasicLock*) (fr->unextended_sp() + word_offset);\n-}\n-\n-\n","filename":"src\/hotspot\/share\/runtime\/stackValue.cpp","additions":0,"deletions":16,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-class BasicLock;\n@@ -111,1 +110,0 @@\n-  static BasicLock*  resolve_monitor_lock(const frame* fr, Location location);\n","filename":"src\/hotspot\/share\/runtime\/stackValue.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -307,1 +308,1 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if (mark.is_fast_locked() && current->lock_stack().contains(oop(obj))) {\n@@ -348,2 +349,1 @@\n-bool ObjectSynchronizer::quick_enter(oop obj, JavaThread* current,\n-                                     BasicLock * lock) {\n+bool ObjectSynchronizer::quick_enter(oop obj, JavaThread* current) {\n@@ -380,11 +380,0 @@\n-    \/\/ This Java Monitor is inflated so obj's header will never be\n-    \/\/ displaced to this thread's BasicLock. Make the displaced header\n-    \/\/ non-NULL so this BasicLock is not seen as recursive nor as\n-    \/\/ being locked. We do this unconditionally so that this thread's\n-    \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n-    \/\/ performance reasons, stack walkers generally first check for\n-    \/\/ stack-locking in the object's header, the second check is for\n-    \/\/ recursive stack-locking in the displaced header in the BasicLock,\n-    \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n-    lock->set_displaced_header(markWord::unused_mark());\n-\n@@ -469,1 +458,1 @@\n-void ObjectSynchronizer::enter(Handle obj, BasicLock* lock, JavaThread* current) {\n+void ObjectSynchronizer::enter(Handle obj, JavaThread* current) {\n@@ -475,7 +464,47 @@\n-    markWord mark = obj->mark();\n-    if (mark.is_neutral()) {\n-      \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n-      \/\/ be visible <= the ST performed by the CAS.\n-      lock->set_displaced_header(mark);\n-      if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n-        return;\n+    LockStack& lock_stack = current->lock_stack();\n+\n+    markWord header = obj()->mark_acquire();\n+    while (true) {\n+      if (header.is_neutral()) {\n+        assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+        \/\/ Try to swing into 'fast-locked' state without inflating.\n+        markWord locked_header = header.set_fast_locked();\n+        markWord witness = obj()->cas_set_mark(locked_header, header);\n+        if (witness == header) {\n+          \/\/ Successfully fast-locked, push object to lock-stack and return.\n+          lock_stack.push(obj());\n+          return;\n+        }\n+        \/\/ Otherwise retry.\n+        header = witness;\n+      } else if (header.is_fast_locked()) {\n+        bool own = lock_stack.contains(obj());\n+        ObjectMonitor* monitor = new ObjectMonitor(obj());\n+        \/\/ Pre-lock monitor to anon or current thread.\n+        if (own) {\n+          monitor->set_owner_from(NULL, current);\n+        } else {\n+          monitor->set_owner_anonymous();\n+        }\n+        monitor->set_header(header.set_unlocked());\n+        markWord witness = obj()->cas_set_mark(markWord::encode(monitor), header);\n+        if (witness == header) {\n+          _in_use_list.add(monitor);\n+\n+          \/\/ Successfully inflated. Get in line for monitor enter\n+          if (monitor->enter(current)) {\n+            if (own) {\n+              lock_stack.remove(obj());\n+            }\n+            return;\n+          }\n+          \/\/ Else we have been beaten by concurrent monitor deflation and need to try again.\n+          header = obj()->mark_acquire();\n+          delete monitor;\n+        } else {\n+          \/\/ If we failed the installation of the monitor, we have been beaten by another thread and need to try again.\n+          delete monitor;\n+          header = witness;\n+        }\n+      } else {\n+        break;\n@@ -483,7 +512,0 @@\n-      \/\/ Fall through to inflate() ...\n-    } else if (mark.has_locker() &&\n-               current->is_lock_owned((address)mark.locker())) {\n-      assert(lock != mark.locker(), \"must not re-lock the same lock\");\n-      assert(lock != (BasicLock*)obj->mark().value(), \"don't relock with same BasicLock\");\n-      lock->set_displaced_header(markWord::from_pointer(NULL));\n-      return;\n@@ -491,6 +513,0 @@\n-\n-    \/\/ The object header will never be displaced to this lock,\n-    \/\/ so it does not matter what the value is, except that it\n-    \/\/ must be non-zero to avoid looking like a re-entrant lock,\n-    \/\/ and must not look locked either.\n-    lock->set_displaced_header(markWord::unused_mark());\n@@ -498,1 +514,1 @@\n-    guarantee(!obj->mark().has_locker(), \"must not be stack-locked\");\n+    guarantee(!obj->mark().is_fast_locked(), \"must not be stack-locked\");\n@@ -512,41 +528,13 @@\n-void ObjectSynchronizer::exit(oop object, BasicLock* lock, JavaThread* current) {\n-  if (!useHeavyMonitors()) {\n-    markWord mark = object->mark();\n-\n-    markWord dhw = lock->displaced_header();\n-    if (dhw.value() == 0) {\n-      \/\/ If the displaced header is NULL, then this exit matches up with\n-      \/\/ a recursive enter. No real work to do here except for diagnostics.\n-#ifndef PRODUCT\n-      if (mark != markWord::INFLATING()) {\n-        \/\/ Only do diagnostics if we are not racing an inflation. Simply\n-        \/\/ exiting a recursive enter of a Java Monitor that is being\n-        \/\/ inflated is safe; see the has_monitor() comment below.\n-        assert(!mark.is_neutral(), \"invariant\");\n-        assert(!mark.has_locker() ||\n-        current->is_lock_owned((address)mark.locker()), \"invariant\");\n-        if (mark.has_monitor()) {\n-          \/\/ The BasicLock's displaced_header is marked as a recursive\n-          \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n-          \/\/ This is a special case where the Java Monitor was inflated\n-          \/\/ after this thread entered the stack-lock recursively. When a\n-          \/\/ Java Monitor is inflated, we cannot safely walk the Java\n-          \/\/ Monitor owner's stack and update the BasicLocks because a\n-          \/\/ Java Monitor can be asynchronously inflated by a thread that\n-          \/\/ does not own the Java Monitor.\n-          ObjectMonitor* m = mark.monitor();\n-          assert(m->object()->mark() == mark, \"invariant\");\n-          assert(m->is_entered(current), \"invariant\");\n-        }\n-      }\n-#endif\n-      return;\n-    }\n-\n-    if (mark == markWord::from_pointer(lock)) {\n-      \/\/ If the object is stack-locked by the current thread, try to\n-      \/\/ swing the displaced header from the BasicLock back to the mark.\n-      assert(dhw.is_neutral(), \"invariant\");\n-      if (object->cas_set_mark(dhw, mark) == mark) {\n-        return;\n-      }\n+void ObjectSynchronizer::exit(oop object, JavaThread* current) {\n+  markWord header = object->mark_acquire();\n+  if (!useHeavyMonitors() && header.is_fast_locked()) {\n+    markWord unlocked_header = header.set_unlocked();\n+    markWord witness = object->cas_set_mark(unlocked_header, header);\n+    if (witness != header) {\n+      \/\/ Another thread beat us, it can only have installed an anonymously locked monitor at this point.\n+      \/\/ Fetch that monitor, set owner correctly to this thread, and exit it (allowing waiting threads to enter).\n+      assert(witness.has_monitor(), \"must have monitor\");\n+      ObjectMonitor* monitor = witness.monitor();\n+      assert(monitor->is_owner_anonymous(), \"must be anonymous owner\");\n+      monitor->set_owner_from_anonymous(current);\n+      monitor->exit(current);\n@@ -554,2 +542,5 @@\n-  } else if (VerifyHeavyMonitors) {\n-    guarantee(!object->mark().has_locker(), \"must not be stack-locked\");\n+    LockStack& lock_stack = current->lock_stack();\n+    oop top_lock = lock_stack.pop();\n+    assert(top_lock == object, \"unbalanced monitorenter\/exit: top_lock: \" PTR_FORMAT \", object: \" PTR_FORMAT,\n+           p2i(top_lock), p2i(object));\n+    return;\n@@ -558,4 +549,10 @@\n-  \/\/ We have to take the slow-path of possible inflation and then exit.\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n-  ObjectMonitor* monitor = inflate(current, object, inflate_cause_vm_internal);\n+  assert(header.has_monitor(), \"must have monitor\");\n+  log_trace(monitorinflation)(\"monitor unlocking object: \" PTR_FORMAT, p2i(object));\n+  ObjectMonitor* monitor = header.monitor();\n+  if (!useHeavyMonitors() && monitor->is_owner_anonymous()) {\n+    \/\/ It must be us. Pop lock object from lock stack.\n+    LockStack& lock_stack = current->lock_stack();\n+    oop popped = lock_stack.pop();\n+    assert(popped == object, \"must be owned by this thread\");\n+    monitor->set_owner_from_anonymous(current);\n+  }\n@@ -645,1 +642,1 @@\n-    ObjectSynchronizer::enter(_obj, &_lock, _thread);\n+    ObjectSynchronizer::enter(_obj, _thread);\n@@ -651,1 +648,1 @@\n-    ObjectSynchronizer::exit(_obj(), &_lock, _thread);\n+    ObjectSynchronizer::exit(_obj(), _thread);\n@@ -694,1 +691,1 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if (mark.is_fast_locked() && current->lock_stack().contains(obj())) {\n@@ -709,1 +706,1 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if (mark.is_fast_locked() && current->lock_stack().contains(obj())) {\n@@ -735,127 +732,0 @@\n-markWord ObjectSynchronizer::read_stable_mark(oop obj) {\n-  markWord mark = obj->mark_acquire();\n-  if (!mark.is_being_inflated()) {\n-    return mark;       \/\/ normal fast-path return\n-  }\n-\n-  int its = 0;\n-  for (;;) {\n-    markWord mark = obj->mark_acquire();\n-    if (!mark.is_being_inflated()) {\n-      return mark;    \/\/ normal fast-path return\n-    }\n-\n-    \/\/ The object is being inflated by some other thread.\n-    \/\/ The caller of read_stable_mark() must wait for inflation to complete.\n-    \/\/ Avoid live-lock.\n-\n-    ++its;\n-    if (its > 10000 || !os::is_MP()) {\n-      if (its & 1) {\n-        os::naked_yield();\n-      } else {\n-        \/\/ Note that the following code attenuates the livelock problem but is not\n-        \/\/ a complete remedy.  A more complete solution would require that the inflating\n-        \/\/ thread hold the associated inflation lock.  The following code simply restricts\n-        \/\/ the number of spinners to at most one.  We'll have N-2 threads blocked\n-        \/\/ on the inflationlock, 1 thread holding the inflation lock and using\n-        \/\/ a yield\/park strategy, and 1 thread in the midst of inflation.\n-        \/\/ A more refined approach would be to change the encoding of INFLATING\n-        \/\/ to allow encapsulation of a native thread pointer.  Threads waiting for\n-        \/\/ inflation to complete would use CAS to push themselves onto a singly linked\n-        \/\/ list rooted at the markword.  Once enqueued, they'd loop, checking a per-thread flag\n-        \/\/ and calling park().  When inflation was complete the thread that accomplished inflation\n-        \/\/ would detach the list and set the markword to inflated with a single CAS and\n-        \/\/ then for each thread on the list, set the flag and unpark() the thread.\n-\n-        \/\/ Index into the lock array based on the current object address.\n-        static_assert(is_power_of_2(NINFLATIONLOCKS), \"must be\");\n-        int ix = (cast_from_oop<intptr_t>(obj) >> 5) & (NINFLATIONLOCKS-1);\n-        int YieldThenBlock = 0;\n-        assert(ix >= 0 && ix < NINFLATIONLOCKS, \"invariant\");\n-        gInflationLocks[ix]->lock();\n-        while (obj->mark_acquire() == markWord::INFLATING()) {\n-          \/\/ Beware: naked_yield() is advisory and has almost no effect on some platforms\n-          \/\/ so we periodically call current->_ParkEvent->park(1).\n-          \/\/ We use a mixed spin\/yield\/block mechanism.\n-          if ((YieldThenBlock++) >= 16) {\n-            Thread::current()->_ParkEvent->park(1);\n-          } else {\n-            os::naked_yield();\n-          }\n-        }\n-        gInflationLocks[ix]->unlock();\n-      }\n-    } else {\n-      SpinPause();       \/\/ SMP-polite spinning\n-    }\n-  }\n-}\n-\n-\/\/ Safely load a mark word from an object, even with racing stack-locking or monitor inflation.\n-\/\/ The protocol is a partial inflation-protocol: it installs INFLATING into the object's mark\n-\/\/ word in order to prevent an stack-locks or inflations from interferring (or detect such\n-\/\/ interference and retry), but then, instead of creating and installing a monitor, simply\n-\/\/ read and return the real mark word.\n-markWord ObjectSynchronizer::stable_mark(oop object) {\n-  for (;;) {\n-    const markWord mark = read_stable_mark(object);\n-    assert(!mark.is_being_inflated(), \"read_stable_mark must prevent inflating mark\");\n-\n-    \/\/ The mark can be in one of the following states:\n-    \/\/ *  Inflated     - just return mark from inflated monitor\n-    \/\/ *  Stack-locked - coerce it to inflating, and then return displaced mark\n-    \/\/ *  Neutral      - return mark\n-    \/\/ *  Marked       - return mark\n-\n-    \/\/ CASE: inflated\n-    if (mark.has_monitor()) {\n-      ObjectMonitor* inf = mark.monitor();\n-      markWord dmw = inf->header();\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-      return dmw;\n-    }\n-\n-    \/\/ CASE: stack-locked\n-    \/\/ Could be stack-locked either by this thread or by some other thread.\n-    if (mark.has_locker()) {\n-      BasicLock* lock = mark.locker();\n-      if (Thread::current()->is_lock_owned((address)lock)) {\n-        \/\/ If locked by this thread, it is safe to access the displaced header.\n-        markWord dmw = lock->displaced_header();\n-        assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-        return dmw;\n-      }\n-\n-      \/\/ Otherwise, attempt to temporarily install INFLATING into the mark-word,\n-      \/\/ to prevent inflation or unlocking by competing thread.\n-      markWord cmp = object->cas_set_mark(markWord::INFLATING(), mark);\n-      if (cmp != mark) {\n-        continue;       \/\/ Interference -- just retry\n-      }\n-\n-      \/\/ fetch the displaced mark from the owner's stack.\n-      \/\/ The owner can't die or unwind past the lock while our INFLATING\n-      \/\/ object is in the mark.  Furthermore the owner can't complete\n-      \/\/ an unlock on the object, either.\n-      markWord dmw = mark.displaced_mark_helper();\n-      \/\/ Catch if the object's header is not neutral (not locked and\n-      \/\/ not marked is what we care about here).\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-      \/\/ Must preserve store ordering. The monitor state must\n-      \/\/ be stable at the time of publishing the monitor address.\n-      assert(object->mark() == markWord::INFLATING(), \"invariant\");\n-      \/\/ Release semantics so that above set_object() is seen first.\n-      object->release_set_mark(mark);\n-\n-      return dmw;\n-    }\n-\n-    \/\/ CASE: neutral or marked (for GC)\n-    \/\/ Catch if the object's header is not neutral or marked (it must not be locked).\n-    assert(mark.is_neutral() || mark.is_marked(), \"invariant: header=\" INTPTR_FORMAT, mark.value());\n-    return mark;\n-  }\n-}\n-\n@@ -925,6 +795,2 @@\n-    markWord mark = read_stable_mark(obj);\n-    if (VerifyHeavyMonitors) {\n-      assert(UseHeavyMonitors, \"+VerifyHeavyMonitors requires +UseHeavyMonitors\");\n-      guarantee(!mark.has_locker(), \"must not be stack locked\");\n-    }\n-    if (mark.is_neutral()) {               \/\/ if this is a normal header\n+    markWord mark = obj->mark_acquire();\n+    if (mark.is_neutral() || mark.is_fast_locked()) { \/\/ if this is a normal header\n@@ -973,17 +839,0 @@\n-    } else if (current->is_lock_owned((address)mark.locker())) {\n-      \/\/ This is a stack lock owned by the calling thread so fetch the\n-      \/\/ displaced markWord from the BasicLock on the stack.\n-      temp = mark.displaced_mark_helper();\n-      assert(temp.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, temp.value());\n-      hash = temp.hash();\n-      if (hash != 0) {                  \/\/ if it has a hash, just return it\n-        return hash;\n-      }\n-      \/\/ WARNING:\n-      \/\/ The displaced header in the BasicLock on a thread's stack\n-      \/\/ is strictly immutable. It CANNOT be changed in ANY cases.\n-      \/\/ So we have to inflate the stack lock into an ObjectMonitor\n-      \/\/ even if the current thread owns the lock. The BasicLock on\n-      \/\/ a thread's stack can be asynchronously read by other threads\n-      \/\/ during an inflate() call so any change to that stack memory\n-      \/\/ may not propagate to other threads correctly.\n@@ -1043,1 +892,1 @@\n-  markWord mark = read_stable_mark(obj);\n+  markWord mark = obj->mark_acquire();\n@@ -1045,3 +894,2 @@\n-  \/\/ Uncontended case, header points to stack\n-  if (mark.has_locker()) {\n-    return current->is_lock_owned((address)mark.locker());\n+  if (mark.is_fast_locked()) {\n+    return current->lock_stack().contains(h_obj());\n@@ -1054,1 +902,5 @@\n-    return monitor->is_entered(current) != 0;\n+    if (monitor->is_owner_anonymous()) {\n+      return current->lock_stack().contains(h_obj());\n+    } else {\n+      return monitor->is_entered(current) != 0;\n+    }\n@@ -1066,1 +918,1 @@\n-  markWord mark = read_stable_mark(obj);\n+  markWord mark = obj->mark_acquire();\n@@ -1068,3 +920,2 @@\n-  \/\/ Uncontended case, header points to stack\n-  if (mark.has_locker()) {\n-    owner = (address) mark.locker();\n+  if (mark.is_fast_locked()) {\n+    owner = cast_from_oop<address>(obj);\n@@ -1079,1 +930,5 @@\n-    owner = (address) monitor->owner();\n+    if (monitor->is_owner_anonymous()) {\n+      owner = cast_from_oop<address>(obj);\n+    } else {\n+      owner = (address) monitor->owner();\n+    }\n@@ -1280,3 +1135,2 @@\n-    \/\/ *  Inflated     - just return\n-    \/\/ *  Stack-locked - coerce it to inflated\n-    \/\/ *  INFLATING    - busy wait for conversion to complete\n+    \/\/ *  Inflated     - just return, maybe fix anon owner\n+    \/\/ *  Fast-locked  - coerce it to inflated\n@@ -1290,0 +1144,6 @@\n+      if (inf->is_owner_anonymous()) {\n+        if (current->lock_stack().contains(object)) {\n+          inf->set_owner_from_anonymous(current);\n+          current->lock_stack().remove(object);\n+        }\n+      }\n@@ -1293,21 +1153,2 @@\n-    \/\/ CASE: inflation in progress - inflating over a stack-lock.\n-    \/\/ Some other thread is converting from stack-locked to inflated.\n-    \/\/ Only that thread can complete inflation -- other threads must wait.\n-    \/\/ The INFLATING value is transient.\n-    \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n-    \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n-    if (mark == markWord::INFLATING()) {\n-      read_stable_mark(object);\n-      continue;\n-    }\n-\n-    \/\/ CASE: stack-locked\n-    \/\/ Could be stack-locked either by this thread or by some other thread.\n-    \/\/\n-    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_ attempting\n-    \/\/ to install INFLATING into the mark word.  We originally installed INFLATING,\n-    \/\/ allocated the ObjectMonitor, and then finally STed the address of the\n-    \/\/ ObjectMonitor into the mark.  This was correct, but artificially lengthened\n-    \/\/ the interval in which INFLATING appeared in the mark, thus increasing\n-    \/\/ the odds of inflation contention.\n-\n+    \/\/ CASE: fast-locked\n+    \/\/ Could be fast-locked either by this thread or by some other thread.\n@@ -1316,10 +1157,11 @@\n-    if (mark.has_locker()) {\n-      ObjectMonitor* m = new ObjectMonitor(object);\n-      \/\/ Optimistically prepare the ObjectMonitor - anticipate successful CAS\n-      \/\/ We do this before the CAS in order to minimize the length of time\n-      \/\/ in which INFLATING appears in the mark.\n-\n-      markWord cmp = object->cas_set_mark(markWord::INFLATING(), mark);\n-      if (cmp != mark) {\n-        delete m;\n-        continue;       \/\/ Interference -- just retry\n+    if (mark.is_fast_locked()) {\n+      ObjectMonitor* monitor = new ObjectMonitor(object);\n+      monitor->set_header(mark.set_unlocked());\n+      LockStack& lock_stack = current->lock_stack();\n+      bool own = lock_stack.contains(object);\n+      if (own) {\n+        \/\/ Owned by us.\n+        monitor->set_owner_from(NULL, current);\n+      } else {\n+        \/\/ Owned by somebody else.\n+        monitor->set_owner_anonymous();\n@@ -1327,0 +1169,23 @@\n+      markWord monitor_mark = markWord::encode(monitor);\n+      markWord witness = object->cas_set_mark(monitor_mark, mark);\n+      if (witness == mark) {\n+        \/\/ Success! Return inflated monitor.\n+        if (own) {\n+          lock_stack.remove(object);\n+        }\n+        \/\/ Once the ObjectMonitor is configured and object is associated\n+        \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n+        _in_use_list.add(monitor);\n+\n+        \/\/ Hopefully the performance counters are allocated on distinct\n+        \/\/ cache lines to avoid false sharing on MP systems ...\n+        OM_PERFDATA_OP(Inflations, inc());\n+        if (log_is_enabled(Trace, monitorinflation)) {\n+          ResourceMark rm(current);\n+          lsh.print_cr(\"inflate(locked): object=\" INTPTR_FORMAT \", mark=\"\n+                       INTPTR_FORMAT \", type='%s'\", p2i(object),\n+                       object->mark().value(), object->klass()->external_name());\n+        }\n+        if (event.should_commit()) {\n+          post_monitor_inflate_event(&event, object, cause);\n+        }\n@@ -1328,64 +1193,1 @@\n-      \/\/ We've successfully installed INFLATING (0) into the mark-word.\n-      \/\/ This is the only case where 0 will appear in a mark-word.\n-      \/\/ Only the singular thread that successfully swings the mark-word\n-      \/\/ to 0 can perform (or more precisely, complete) inflation.\n-      \/\/\n-      \/\/ Why do we CAS a 0 into the mark-word instead of just CASing the\n-      \/\/ mark-word from the stack-locked value directly to the new inflated state?\n-      \/\/ Consider what happens when a thread unlocks a stack-locked object.\n-      \/\/ It attempts to use CAS to swing the displaced header value from the\n-      \/\/ on-stack BasicLock back into the object header.  Recall also that the\n-      \/\/ header value (hash code, etc) can reside in (a) the object header, or\n-      \/\/ (b) a displaced header associated with the stack-lock, or (c) a displaced\n-      \/\/ header in an ObjectMonitor.  The inflate() routine must copy the header\n-      \/\/ value from the BasicLock on the owner's stack to the ObjectMonitor, all\n-      \/\/ the while preserving the hashCode stability invariants.  If the owner\n-      \/\/ decides to release the lock while the value is 0, the unlock will fail\n-      \/\/ and control will eventually pass from slow_exit() to inflate.  The owner\n-      \/\/ will then spin, waiting for the 0 value to disappear.   Put another way,\n-      \/\/ the 0 causes the owner to stall if the owner happens to try to\n-      \/\/ drop the lock (restoring the header from the BasicLock to the object)\n-      \/\/ while inflation is in-progress.  This protocol avoids races that might\n-      \/\/ would otherwise permit hashCode values to change or \"flicker\" for an object.\n-      \/\/ Critically, while object->mark is 0 mark.displaced_mark_helper() is stable.\n-      \/\/ 0 serves as a \"BUSY\" inflate-in-progress indicator.\n-\n-\n-      \/\/ fetch the displaced mark from the owner's stack.\n-      \/\/ The owner can't die or unwind past the lock while our INFLATING\n-      \/\/ object is in the mark.  Furthermore the owner can't complete\n-      \/\/ an unlock on the object, either.\n-      markWord dmw = mark.displaced_mark_helper();\n-      \/\/ Catch if the object's header is not neutral (not locked and\n-      \/\/ not marked is what we care about here).\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-      \/\/ Setup monitor fields to proper values -- prepare the monitor\n-      m->set_header(dmw);\n-\n-      \/\/ Optimization: if the mark.locker stack address is associated\n-      \/\/ with this thread we could simply set m->_owner = current.\n-      \/\/ Note that a thread can inflate an object\n-      \/\/ that it has stack-locked -- as might happen in wait() -- directly\n-      \/\/ with CAS.  That is, we can avoid the xchg-NULL .... ST idiom.\n-      m->set_owner_from(NULL, mark.locker());\n-      \/\/ TODO-FIXME: assert BasicLock->dhw != 0.\n-\n-      \/\/ Must preserve store ordering. The monitor state must\n-      \/\/ be stable at the time of publishing the monitor address.\n-      guarantee(object->mark() == markWord::INFLATING(), \"invariant\");\n-      \/\/ Release semantics so that above set_object() is seen first.\n-      object->release_set_mark(markWord::encode(m));\n-\n-      \/\/ Once ObjectMonitor is configured and the object is associated\n-      \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n-      _in_use_list.add(m);\n-\n-      \/\/ Hopefully the performance counters are allocated on distinct cache lines\n-      \/\/ to avoid false sharing on MP systems ...\n-      OM_PERFDATA_OP(Inflations, inc());\n-      if (log_is_enabled(Trace, monitorinflation)) {\n-        ResourceMark rm(current);\n-        lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n-                     INTPTR_FORMAT \", type='%s'\", p2i(object),\n-                     object->mark().value(), object->klass()->external_name());\n+        return monitor;\n@@ -1393,4 +1195,3 @@\n-      if (event.should_commit()) {\n-        post_monitor_inflate_event(&event, object, cause);\n-      }\n-      return m;\n+      \/\/ Otherwise, discard the monitor and retry.\n+      delete monitor;\n+      continue;\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":150,"deletions":349,"binary":false,"changes":499,"status":"modified"},{"patch":"@@ -149,2 +149,2 @@\n-  static void enter(Handle obj, BasicLock* lock, JavaThread* current);\n-  static void exit(oop obj, BasicLock* lock, JavaThread* current);\n+  static void enter(Handle obj, JavaThread* current);\n+  static void exit(oop obj, JavaThread* current);\n@@ -163,1 +163,1 @@\n-  static bool quick_enter(oop obj, JavaThread* current, BasicLock* Lock);\n+  static bool quick_enter(oop obj, JavaThread* current);\n@@ -187,5 +187,0 @@\n-  \/\/ Read mark-word and spin-wait as long as INFLATING is observed.\n-  static markWord read_stable_mark(oop obj);\n-\n-  static markWord stable_mark(oop obj);\n-\n@@ -270,1 +265,0 @@\n-  BasicLock   _lock;\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":3,"deletions":9,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -91,0 +91,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -208,1 +209,2 @@\n-Thread::Thread() {\n+Thread::Thread():\n+  _lock_stack() {\n@@ -550,0 +552,3 @@\n+  if (!UseHeavyMonitors) {\n+    lock_stack().oops_do(f);\n+  }\n@@ -1555,0 +1560,4 @@\n+  assert(adr != ANONYMOUS_OWNER, \"must convert to lock object\");\n+  if (!UseHeavyMonitors && lock_stack().contains(cast_to_oop(adr))) {\n+    return true;\n+  }\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"runtime\/lockStack.hpp\"\n@@ -616,2 +617,1 @@\n-  ParkEvent * volatile _ParkEvent;            \/\/ for Object monitors, JVMTI raw monitors,\n-                                              \/\/ and ObjectSynchronizer::read_stable_mark\n+  ParkEvent * volatile _ParkEvent;            \/\/ for Object monitors and JVMTI raw monitors\n@@ -629,0 +629,10 @@\n+private:\n+  LockStack _lock_stack;\n+\n+public:\n+  LockStack& lock_stack() { return _lock_stack; }\n+  const LockStack& lock_stack() const { return _lock_stack; }\n+\n+  static ByteSize lock_stack_current_offset()    { return byte_offset_of(Thread, _lock_stack) + LockStack::current_offset(); }\n+  static ByteSize lock_stack_limit_offset()    { return byte_offset_of(Thread, _lock_stack) + LockStack::limit_offset(); }\n+\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -260,7 +261,11 @@\n-          if (mark.has_monitor() &&\n-              ( \/\/ we have marked ourself as pending on this monitor\n-                mark.monitor() == thread()->current_pending_monitor() ||\n-                \/\/ we are not the owner of this monitor\n-                !mark.monitor()->is_entered(thread())\n-              )) {\n-            lock_state = \"waiting to lock\";\n+          if (mark.has_monitor()) {\n+            if (mark.monitor()->is_owner_anonymous()) {\n+              if (!thread()->lock_stack().contains(monitor->owner())) {\n+                lock_state = \"waiting to lock\";\n+              }\n+            } else if (\/\/ we have marked ourself as pending on this monitor\n+                    mark.monitor() == thread()->current_pending_monitor() ||\n+                    \/\/ we are not the owner of this monitor\n+                    !mark.monitor()->is_entered(thread())) {\n+              lock_state = \"waiting to lock\";\n+            }\n@@ -298,1 +303,1 @@\n-    result->push(new MonitorInfo(current->obj(), current->lock(), false, false));\n+    result->push(new MonitorInfo(current->obj(), false, false));\n@@ -468,1 +473,1 @@\n-MonitorInfo::MonitorInfo(oop owner, BasicLock* lock, bool eliminated, bool owner_is_scalar_replaced) {\n+MonitorInfo::MonitorInfo(oop owner, bool eliminated, bool owner_is_scalar_replaced) {\n@@ -478,1 +483,0 @@\n-  _lock = lock;\n@@ -678,3 +682,0 @@\n-    tty->print(\"\\t  \");\n-    monitor->lock()->print_on(tty, monitor->owner());\n-    tty->cr();\n","filename":"src\/hotspot\/share\/runtime\/vframe.cpp","additions":14,"deletions":13,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -53,2 +53,0 @@\n-\/\/ - BasicLock\n-\n@@ -250,1 +248,0 @@\n-  BasicLock* _lock;\n@@ -256,1 +253,1 @@\n-  MonitorInfo(oop owner, BasicLock* lock, bool eliminated, bool owner_is_scalar_replaced);\n+  MonitorInfo(oop owner, bool eliminated, bool owner_is_scalar_replaced);\n@@ -266,1 +263,0 @@\n-  BasicLock* lock()  const { return _lock;  }\n","filename":"src\/hotspot\/share\/runtime\/vframe.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -90,1 +90,1 @@\n-      \/\/ Migrate the BasicLocks from the stack to the monitor chunk\n+      \/\/ Migrate the BasicObjectLocks from the stack to the monitor chunk\n@@ -100,1 +100,0 @@\n-          monitor->lock()->move_to(monitor->owner(), dest->lock());\n@@ -311,1 +310,0 @@\n-    src->lock()->move_to(src->obj(), top->lock());\n","filename":"src\/hotspot\/share\/runtime\/vframeArray.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -221,5 +221,0 @@\n-BasicLock* compiledVFrame::resolve_monitor_lock(Location location) const {\n-  return StackValue::resolve_monitor_lock(&_fr, location);\n-}\n-\n-\n@@ -241,1 +236,1 @@\n-        fr.get_native_receiver(), fr.get_native_monitor(), false, false);\n+        fr.get_native_receiver(), false, false);\n@@ -261,2 +256,1 @@\n-      result->push(new MonitorInfo(k(), resolve_monitor_lock(mv->basic_lock()),\n-                                   mv->eliminated(), true));\n+      result->push(new MonitorInfo(k(), mv->eliminated(), true));\n@@ -264,2 +258,1 @@\n-      result->push(new MonitorInfo(owner_sv->get_obj()(), resolve_monitor_lock(mv->basic_lock()),\n-                                   mv->eliminated(), false));\n+      result->push(new MonitorInfo(owner_sv->get_obj()(), mv->eliminated(), false));\n@@ -499,2 +492,1 @@\n-      MonitorInfo* new_info = new MonitorInfo((oopDesc*)val->value().l, info->lock(),\n-                                              info->eliminated(), false);\n+      MonitorInfo* new_info = new MonitorInfo((oopDesc*)val->value().l, info->eliminated(), false);\n","filename":"src\/hotspot\/share\/runtime\/vframe_hp.cpp","additions":4,"deletions":12,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -96,1 +96,0 @@\n-  BasicLock* resolve_monitor_lock(Location location) const;\n","filename":"src\/hotspot\/share\/runtime\/vframe_hp.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -708,0 +708,3 @@\n+  nonstatic_field(Thread,                      _lock_stack,                                   LockStack)                             \\\n+  nonstatic_field(LockStack,                   _current,                                      oop*)                                  \\\n+  nonstatic_field(LockStack,                   _base,                                         oop*)                                  \\\n@@ -852,1 +855,0 @@\n-  volatile_nonstatic_field(BasicLock,          _displaced_header,                             markWord)                              \\\n@@ -856,1 +858,0 @@\n-  nonstatic_field(BasicObjectLock,             _lock,                                         BasicLock)                             \\\n@@ -1319,0 +1320,1 @@\n+  declare_toplevel_type(LockStack)                                        \\\n@@ -1437,1 +1439,0 @@\n-  declare_toplevel_type(BasicLock)                                        \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -433,1 +433,6 @@\n-        address currentOwner = (address)waitingToLockMonitor->owner();\n+        address currentOwner;\n+        if (waitingToLockMonitor->is_owner_anonymous()) {\n+          currentOwner = cast_from_oop<address>(waitingToLockMonitor->object());\n+        } else {\n+          currentOwner = (address)waitingToLockMonitor->owner();\n+        }\n","filename":"src\/hotspot\/share\/services\/threadService.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -64,6 +64,2 @@\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-      headerSize = typeSize;\n-    } else {\n-      headerSize = VM.getVM().alignUp(typeSize + VM.getVM().getIntSize(),\n-                                      VM.getVM().getHeapWordSize());\n-    }\n+    assert(VM.getVM().isCompressedKlassPointersEnabled());\n+    headerSize = typeSize;\n@@ -73,8 +69,0 @@\n-  private static long headerSize(BasicType type) {\n-    if (Universe.elementTypeShouldBeAligned(type)) {\n-       return alignObjectSize(headerSizeInBytes())\/VM.getVM().getHeapWordSize();\n-    } else {\n-      return headerSizeInBytes()\/VM.getVM().getHeapWordSize();\n-    }\n-  }\n-\n@@ -85,5 +73,2 @@\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-      lengthOffsetInBytes = typeSize - VM.getVM().getIntSize();\n-    } else {\n-      lengthOffsetInBytes = typeSize;\n-    }\n+    assert(VM.getVM().isCompressedKlassPointersEnabled());\n+    lengthOffsetInBytes = typeSize;\n@@ -111,1 +96,6 @@\n-    return headerSize(type) * VM.getVM().getHeapWordSize();\n+    long base = lengthOffsetInBytes + VM.getVM().getIntSize();\n+    if (Universe.elementTypeShouldBeAligned(type)) {\n+      VM vm = VM.getVM();\n+      base = vm.alignUp(base, vm.getBytesPerWord());\n+    }\n+    return base;\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Array.java","additions":10,"deletions":20,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -151,6 +151,0 @@\n-  public BasicLock locker() {\n-    if (Assert.ASSERTS_ENABLED) {\n-      Assert.that(hasLocker(), \"check\");\n-    }\n-    return new BasicLock(valueAsAddress());\n-  }\n@@ -189,0 +183,5 @@\n+  public Klass getKlass() {\n+    \/\/Address klassAddr = addr.getAddressAt(markField.getOffset() + 4);\n+    return (Klass)Metadata.instantiateWrapperFor(addr.getCompKlassAddressAt(4));\n+  }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Mark.java","additions":5,"deletions":6,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -51,2 +51,0 @@\n-    klass      = new MetadataField(type.getAddressField(\"_metadata._klass\"), 0);\n-    compressedKlass  = new NarrowKlassField(type.getAddressField(\"_metadata._compressed_klass\"), 0);\n@@ -75,2 +73,0 @@\n-  private static MetadataField  klass;\n-  private static NarrowKlassField compressedKlass;\n@@ -80,5 +76,5 @@\n-  public Klass getKlass() {\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-      return (Klass)compressedKlass.getValue(getHandle());\n-    } else {\n-      return (Klass)klass.getValue(getHandle());\n+\n+  private static Klass getKlass(Mark mark) {\n+    if (mark.hasMonitor()) {\n+      ObjectMonitor mon = mark.monitor();\n+      mark = mon.header();\n@@ -86,0 +82,6 @@\n+    return mark.getKlass();\n+  }\n+\n+  public Klass getKlass() {\n+    assert(VM.getVM().isCompressedKlassPointersEnabled());\n+    return getKlass(getMark());\n@@ -152,5 +154,0 @@\n-      if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-        visitor.doMetadata(compressedKlass, true);\n-      } else {\n-        visitor.doMetadata(klass, true);\n-      }\n@@ -211,5 +208,2 @@\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-      return (Klass)Metadata.instantiateWrapperFor(handle.getCompKlassAddressAt(compressedKlass.getOffset()));\n-    } else {\n-      return (Klass)Metadata.instantiateWrapperFor(handle.getAddressAt(klass.getOffset()));\n-    }\n+    Mark mark = new Mark(handle);\n+    return getKlass(mark);\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Oop.java","additions":13,"deletions":19,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -1,58 +0,0 @@\n-\/*\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-package sun.jvm.hotspot.runtime;\n-\n-import java.util.*;\n-\n-import sun.jvm.hotspot.debugger.*;\n-import sun.jvm.hotspot.oops.*;\n-import sun.jvm.hotspot.types.*;\n-import sun.jvm.hotspot.utilities.Observable;\n-import sun.jvm.hotspot.utilities.Observer;\n-\n-public class BasicLock extends VMObject {\n-  static {\n-    VM.registerVMInitializedObserver(new Observer() {\n-        public void update(Observable o, Object data) {\n-          initialize(VM.getVM().getTypeDataBase());\n-        }\n-      });\n-  }\n-\n-  private static synchronized void initialize(TypeDataBase db) throws WrongTypeException {\n-    Type type  = db.lookupType(\"BasicLock\");\n-    displacedHeaderField = type.getCIntegerField(\"_displaced_header\");\n-  }\n-\n-  private static CIntegerField displacedHeaderField;\n-\n-  public BasicLock(Address addr) {\n-    super(addr);\n-  }\n-\n-  public Mark displacedHeader() {\n-    return new Mark(addr.addOffsetTo(displacedHeaderField.getOffset()));\n-  }\n-}\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/BasicLock.java","additions":0,"deletions":58,"binary":false,"changes":58,"status":"deleted"},{"patch":"@@ -45,1 +45,0 @@\n-    lockField  = type.getField(\"_lock\");\n@@ -50,1 +49,0 @@\n-  private static sun.jvm.hotspot.types.Field    lockField;\n@@ -59,1 +57,0 @@\n-  public BasicLock lock() { return new BasicLock(addr.addOffsetTo(lockField.getOffset())); }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/BasicObjectLock.java","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -148,1 +148,1 @@\n-        result.add(new MonitorInfo(k, resolveMonitorLock(mv.basicLock()), mv.eliminated(), true));\n+        result.add(new MonitorInfo(k, mv.eliminated(), true));\n@@ -150,1 +150,1 @@\n-        result.add(new MonitorInfo(ownerSV.getObject(), resolveMonitorLock(mv.basicLock()), mv.eliminated(), false));\n+        result.add(new MonitorInfo(ownerSV.getObject(), mv.eliminated(), false));\n@@ -313,16 +313,0 @@\n-\n-  private BasicLock resolveMonitorLock(Location location) {\n-    if (Assert.ASSERTS_ENABLED) {\n-      Assert.that(location.isStack(), \"for now we only look at the stack\");\n-    }\n-    int byteOffset = location.getStackOffset();\n-    \/\/ (stack picture)\n-    \/\/ high: [     ]  byte_offset + wordSize\n-    \/\/ low   [     ]  byte_offset\n-    \/\/\n-    \/\/ sp->  [     ]  0\n-    \/\/ the byte_offset is the distance from the stack pointer to the lowest address\n-    \/\/ The frame's original stack pointer, before any extension by its callee\n-    \/\/ (due to Compiler1 linkage on SPARC), must be used.\n-    return new BasicLock(getFrame().getUnextendedSP().addOffsetTo(byteOffset));\n-  }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/CompiledVFrame.java","additions":2,"deletions":18,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -116,1 +116,1 @@\n-      result.add(new MonitorInfo(current.obj(), current.lock(), false, false));\n+      result.add(new MonitorInfo(current.obj(), false, false));\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/InterpretedVFrame.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -397,9 +397,0 @@\n-  public boolean isLockOwned(Address a) {\n-    Address stackBase = getStackBase();\n-    Address stackLimit = stackBase.addOffsetTo(-getStackSize());\n-\n-    return stackBase.greaterThan(a) && stackLimit.lessThanOrEqual(a);\n-\n-    \/\/ FIXME: should traverse MonitorArray\/MonitorChunks as in VM\n-  }\n-\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaThread.java","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -80,0 +80,1 @@\n+          mark.monitor().isOwnedAnonymous() ||\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaVFrame.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-  private BasicLock lock;\n@@ -37,1 +36,1 @@\n-  public MonitorInfo(OopHandle owner, BasicLock lock, boolean eliminated, boolean ownerIsScalarReplaced) {\n+  public MonitorInfo(OopHandle owner, boolean eliminated, boolean ownerIsScalarReplaced) {\n@@ -60,1 +59,0 @@\n-  public BasicLock lock()  { return lock; }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/MonitorInfo.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -75,2 +75,2 @@\n-    if (current.threadObjectAddress().equals(o) ||\n-        current.isLockOwned(o)) {\n+    if (o.asLongValue() == 1) throw new InternalError(\"Check anonymous owner before calling isEntered()\");\n+    if (current.threadObjectAddress().equals(o)) {\n@@ -82,1 +82,9 @@\n-  public Address owner() { return addr.getAddressAt(ownerFieldOffset); }\n+  public boolean isOwnedAnonymous() {\n+    return addr.getAddressAt(ownerFieldOffset).asLongValue() == 1;\n+  }\n+\n+  public Address owner() {\n+    Address owner = addr.getAddressAt(ownerFieldOffset);\n+    if (owner.asLongValue() == 1) throw new InternalError(\"Check anonymous owner before calling isEntered()\");\n+    return owner;\n+  }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/ObjectMonitor.java","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -36,0 +36,3 @@\n+  private static long lockStackCurrentOffset;\n+  private static long lockStackBaseOffset;\n+\n@@ -43,0 +46,1 @@\n+  private static long oopPtrSize;\n@@ -54,0 +58,1 @@\n+    Type typeLockStack = db.lookupType(\"LockStack\");\n@@ -61,0 +66,4 @@\n+\n+    lockStackCurrentOffset = typeThread.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_current\").getOffset();\n+    lockStackBaseOffset = typeThread.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_base\").getOffset();\n+    oopPtrSize = VM.getVM().getAddressSize();\n@@ -111,2 +120,10 @@\n-  public boolean isLockOwned(Address lock) {\n-    if (isInStack(lock)) return true;\n+  public boolean isLockOwned(OopHandle obj) {\n+    Address current = addr.getAddressAt(lockStackCurrentOffset);\n+    Address base = addr.getAddressAt(lockStackBaseOffset);\n+    while (base.lessThan(current)) {\n+        Address oop = base.getAddressAt(0);\n+        if (oop.equals(obj)) {\n+            return true;\n+        }\n+        base = base.addOffsetTo(oopPtrSize);\n+    }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Thread.java","additions":19,"deletions":2,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -212,2 +212,12 @@\n-    \/\/ refer to Threads::owning_thread_from_monitor_owner\n-    public JavaThread owningThreadFromMonitor(Address o) {\n+    public JavaThread owningThreadFromMonitor(ObjectMonitor monitor) {\n+        if (monitor.isOwnedAnonymous()) {\n+            OopHandle object = monitor.object();\n+            for (int i = 0; i < getNumberOfThreads(); i++) {\n+                JavaThread thread = getJavaThreadAt(i);\n+                if (thread.isLockOwned(object)) {\n+                    return thread;\n+                }\n+            }\n+            throw new InternalError(\"We should have found a thread that owns the anonymous lock\");\n+        }\n+        Address o = monitor.owner();\n@@ -221,6 +231,0 @@\n-\n-        for (int i = 0; i < getNumberOfThreads(); i++) {\n-            JavaThread thread = getJavaThreadAt(i);\n-            if (thread.isLockOwned(o))\n-                return thread;\n-        }\n@@ -230,4 +234,0 @@\n-    public JavaThread owningThreadFromMonitor(ObjectMonitor monitor) {\n-        return owningThreadFromMonitor(monitor.owner());\n-    }\n-\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Threads.java","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -78,6 +78,0 @@\n-        if (!thread.getAddress().equals(owner)) {\n-          if (!thread.isLockOwned(owner)) {\n-            tty.println(\"    WARNING! _owner doesn't fall in \" + thread +\n-                        \"'s stack space\");\n-          }\n-        }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/ui\/MonitorCacheDumpPanel.java","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+import sun.jvm.hotspot.oops.Klass;\n@@ -29,0 +30,1 @@\n+import sun.jvm.hotspot.oops.Oop;\n@@ -40,1 +42,0 @@\n-  private static AddressField klassField;\n@@ -52,6 +53,0 @@\n-\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-      klassField = type.getAddressField(\"_metadata._compressed_klass\");\n-    } else {\n-      klassField = type.getAddressField(\"_metadata._klass\");\n-    }\n@@ -69,5 +64,1 @@\n-      if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-        Metadata.instantiateWrapperFor(oop.getCompKlassAddressAt(klassField.getOffset()));\n-      } else {\n-        Metadata.instantiateWrapperFor(klassField.getValue(oop));\n-      }\n+      Klass klass = Oop.getKlassForOopHandle(oop);\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/utilities\/RobustOopDeterminator.java","additions":3,"deletions":12,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -129,34 +129,0 @@\n-# Missing Lilliput support to load Klass*\n-serviceability\/sa\/CDSJMapClstats.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbCDSCore.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbDumpheap.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbFindPC.java#no-xcomp-core\n-serviceability\/sa\/ClhsdbFindPC.java#no-xcomp-process\n-serviceability\/sa\/ClhsdbFindPC.java#xcomp-core\n-serviceability\/sa\/ClhsdbFindPC.java#xcomp-process\n-serviceability\/sa\/ClhsdbInspect.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbJdis.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbJhisto.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbJstack.java#id0 1234567 generic-all\n-serviceability\/sa\/ClhsdbJstack.java#id1 1234567 generic-all\n-serviceability\/sa\/ClhsdbPrintAs.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbPstack.java#core 1234567 generic-all\n-serviceability\/sa\/ClhsdbPstack.java#process 1234567 generic-all\n-serviceability\/sa\/ClhsdbSource.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbThread.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbThreadContext.java 1234567 generic-all\n-serviceability\/sa\/ClhsdbWhere.java 1234567 generic-all\n-serviceability\/sa\/DeadlockDetectionTest.java 1234567 generic-all\n-serviceability\/sa\/JhsdbThreadInfoTest.java 1234567 generic-all\n-serviceability\/sa\/TestClhsdbJstackLock.java 1234567 generic-all\n-serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 1234567 generic-all\n-serviceability\/sa\/TestJhsdbJstackLineNumbers.java 1234567 generic-all\n-serviceability\/sa\/TestJhsdbJstackLock.java 1234567 generic-all\n-serviceability\/sa\/TestJhsdbJstackMixed.java 1234567 generic-all\n-serviceability\/sa\/TestObjectMonitorIterate.java 1234567 generic-all\n-serviceability\/sa\/TestSysProps.java 1234567 generic-all\n-serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 1234567 generic-all\n-serviceability\/sa\/sadebugd\/DebugdConnectTest.java 1234567 generic-all\n-serviceability\/sa\/sadebugd\/DisableRegistryTest.java 1234567 generic-all\n-\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":0,"deletions":34,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-        output.shouldContain(\"inflate(has_locker):\");\n+        output.shouldContain(\"inflate(locked):\");\n","filename":"test\/hotspot\/jtreg\/runtime\/logging\/MonitorInflationTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -68,1 +68,2 @@\n-                \/\/ when the object is locked causes monitor inflation.\n+                \/\/ when the object is locked does not cause monitor inflation\n+                \/\/ (but used to before Lilliput)\n@@ -70,1 +71,1 @@\n-                Asserts.assertEQ(wb.isMonitorInflated(obj), true,\n+                Asserts.assertEQ(wb.isMonitorInflated(obj), false,\n","filename":"test\/hotspot\/jtreg\/runtime\/whitebox\/TestWBDeflateIdleMonitors.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"}]}