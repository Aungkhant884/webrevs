{"files":[{"patch":"@@ -1765,0 +1765,11 @@\n+  if (C->clinit_barrier_on_entry()) {\n+    assert(!C->method()->holder()->is_not_initialized(), \"initialization should have been started\");\n+\n+    Label L_skip_barrier;\n+\n+    __ mov_metadata(rscratch2, C->method()->holder()->constant_encoding());\n+    __ clinit_barrier(rscratch2, rscratch1, &L_skip_barrier);\n+    __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));\n+    __ bind(L_skip_barrier);\n+  }\n+  \n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -320,1 +320,9 @@\n-  ShouldNotReachHere(); \/\/ not implemented\n+  assert(VM_Version::supports_fast_class_init_checks(), \"sanity\");\n+  assert(!method->holder()->is_not_initialized(), \"initialization should have been started\");\n+\n+  Label L_skip_barrier;\n+\n+  __ mov_metadata(rscratch2, method->holder()->constant_encoding());\n+  __ clinit_barrier(rscratch2, rscratch1, &L_skip_barrier \/*L_fast_path*\/);\n+  __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));\n+  __ bind(L_skip_barrier);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -334,5 +334,0 @@\n-  \/\/ If we have to make this method not-entrant we'll overwrite its\n-  \/\/ first instruction with a jump.  For this action to be legal we\n-  \/\/ must ensure that this first instruction is a B, BL, NOP, BKPT,\n-  \/\/ SVC, HVC, or SMC.  Make it a NOP.\n-  nop();\n@@ -352,0 +347,5 @@\n+  \/\/ If we have to make this method not-entrant we'll overwrite its\n+  \/\/ first instruction with a jump.  For this action to be legal we\n+  \/\/ must ensure that this first instruction is a B, BL, NOP, BKPT,\n+  \/\/ SVC, HVC, or SMC.  Make it a NOP.\n+  nop();\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -291,0 +291,12 @@\n+void InterpreterMacroAssembler::load_resolved_method_at_index(int byte_no,\n+                                                              Register method,\n+                                                              Register cache) {\n+  const int method_offset = in_bytes(\n+    ConstantPoolCache::base_offset() +\n+      ((byte_no == TemplateTable::f2_byte)\n+       ? ConstantPoolCacheEntry::f2_offset()\n+       : ConstantPoolCacheEntry::f1_offset()));\n+\n+  ldr(method, Address(cache, method_offset)); \/\/ get f1 Method*\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -127,0 +127,2 @@\n+  void load_resolved_method_at_index(int byte_no, Register method, Register cache);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1304,0 +1304,29 @@\n+void MacroAssembler::clinit_barrier(Register klass, Register scratch, Label* L_fast_path, Label* L_slow_path) {\n+  assert(L_fast_path != NULL || L_slow_path != NULL, \"at least one is required\");\n+  assert_different_registers(klass, rthread, scratch);\n+\n+  Label L_fallthrough, L_tmp;\n+  if (L_fast_path == NULL) {\n+    L_fast_path = &L_fallthrough;\n+  } else if (L_slow_path == NULL) {\n+    L_slow_path = &L_fallthrough;\n+  }\n+  \/\/ Fast path check: class is fully initialized\n+  ldrb(scratch, Address(klass, InstanceKlass::init_state_offset()));\n+  subs(zr, scratch, InstanceKlass::fully_initialized);\n+  br(Assembler::EQ, *L_fast_path);\n+\n+  \/\/ Fast path check: current thread is initializer thread\n+  ldr(scratch, Address(klass, InstanceKlass::init_thread_offset()));\n+  cmp(rthread, scratch);\n+\n+  if (L_slow_path == &L_fallthrough) {\n+    br(Assembler::EQ, *L_fast_path);\n+    bind(*L_slow_path);\n+  } else if (L_fast_path == &L_fallthrough) {\n+    br(Assembler::NE, *L_slow_path);\n+    bind(*L_fast_path);\n+  } else {\n+    Unimplemented();\n+  }\n+}\n@@ -3684,0 +3713,6 @@\n+void MacroAssembler::load_method_holder(Register holder, Register method) {\n+  ldr(holder, Address(method, Method::const_offset()));                      \/\/ ConstMethod*\n+  ldr(holder, Address(holder, ConstMethod::constants_offset()));             \/\/ ConstantPool*\n+  ldr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); \/\/ InstanceKlass*\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":35,"deletions":0,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -794,0 +794,2 @@\n+  void load_method_holder(Register holder, Register method);\n+\n@@ -932,0 +934,5 @@\n+  void clinit_barrier(Register klass,\n+                      Register thread,\n+                      Label* L_fast_path = NULL,\n+                      Label* L_slow_path = NULL);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -711,0 +711,16 @@\n+  \/\/ Class initialization barrier for static methods\n+  if (VM_Version::supports_fast_class_init_checks()) {\n+    Label L_skip_barrier;\n+\n+    { \/\/ Bypass the barrier for non-static methods\n+      __ ldrw(rscratch1, Address(rmethod, Method::access_flags_offset()));\n+      __ andsw(zr, rscratch1, JVM_ACC_STATIC);\n+      __ br(Assembler::EQ, L_skip_barrier); \/\/ non-static\n+    }\n+\n+    __ load_method_holder(rscratch2, rmethod);\n+    __ clinit_barrier(rscratch2, rscratch1, &L_skip_barrier);\n+    __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));\n+    __ bind(L_skip_barrier);\n+  }\n+\n@@ -1474,0 +1490,9 @@\n+  if (VM_Version::supports_fast_class_init_checks() && method->needs_clinit_barrier()) {\n+    Label L_skip_barrier;\n+    __ mov_metadata(rscratch2, method->method_holder()); \/\/ InstanceKlass*\n+    __ clinit_barrier(rscratch2, rscratch1, &L_skip_barrier);\n+    __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));\n+\n+    __ bind(L_skip_barrier);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2320,1 +2320,1 @@\n-  Label resolved;\n+  Label resolved, clinit_barrier_slow;\n@@ -2335,0 +2335,2 @@\n+  \/\/ Class initialization barrier slow path lands here as well.\n+  __ bind(clinit_barrier_slow);\n@@ -2344,0 +2346,7 @@\n+\n+  \/\/ Class initialization barrier for static methods\n+  if (VM_Version::supports_fast_class_init_checks() && bytecode() == Bytecodes::_invokestatic) {\n+    __ load_resolved_method_at_index(byte_no, temp, Rcache);\n+    __ load_method_holder(temp, temp);\n+    __ clinit_barrier(temp, rscratch1, NULL, &clinit_barrier_slow);\n+  }\n@@ -3415,3 +3424,2 @@\n-  __ ldr(r0, Address(rmethod, Method::const_offset()));\n-  __ ldr(r0, Address(r0, ConstMethod::constants_offset()));\n-  __ ldr(r0, Address(r0, ConstantPool::pool_holder_offset_in_bytes()));\n+\n+  __ load_method_holder(r0, rmethod);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -127,0 +127,1 @@\n+  static bool supports_fast_class_init_checks() { return true; }\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}