{"files":[{"patch":"@@ -0,0 +1,138 @@\n+# Copyright (c) 2021, Alibaba Group Holding Limited. All Rights Reserved.\n+# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+#\n+# This code is free software; you can redistribute it and\/or modify it\n+# under the terms of the GNU General Public License version 2 only, as\n+# published by the Free Software Foundation.\n+#\n+# This code is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+# version 2 for more details (a copy is included in the LICENSE file that\n+# accompanied this code).\n+#\n+# You should have received a copy of the GNU General Public License version\n+# 2 along with this work; if not, write to the Free Software Foundation,\n+# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+#\n+# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+# or visit www.oracle.com if you need additional information or have any\n+# questions.\n+\n+\"\"\"\n+1. Find hot files which have many commit messages, output looks like:\n+\n+269   2021-04-14      src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp                                             \n+217   2021-03-30      src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp                                      \n+134   2021-04-12      src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp                                             \n+127   2021-04-06      src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp                                            \n+99    2021-04-14      src\/hotspot\/share\/gc\/shared\/genCollectedHeap.cpp                                        \n+95    2021-04-15      src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp                                     \n+...\n+\n+2. Sort files by last commit date, output looks like:\n+17    2021-04-15      src\/hotspot\/share\/services\/diagnosticCommand.hpp                                        \n+64    2021-04-15      src\/hotspot\/share\/prims\/jvmtiExport.cpp                                                 \n+79    2021-04-15      src\/hotspot\/share\/classfile\/classLoader.cpp                                             \n+16    2021-04-15      src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.cpp                                         \n+17    2021-04-15      src\/hotspot\/share\/gc\/g1\/g1FullGCMarker.inline.hpp                                       \n+19    2021-04-15      src\/hotspot\/share\/jvmci\/compilerRuntime.cpp                                             \n+...\n+\"\"\"\n+import hashlib\n+import json\n+import os\n+import sys\n+import threading\n+\n+g = []\n+\n+\n+def analysis(files):\n+    for file in files:\n+        result = os.popen(f\"git --no-pager log --pretty=format:'%ad' --date=short {file}\").read()\n+        nof_commit = len(result.splitlines())\n+        lst_mod = result.splitlines()[0]\n+        g.append({\"file\": file, \"nof_commit\": nof_commit, \"lst_mod\": lst_mod})\n+\n+\n+def save_array_to_file(arr, file_name):\n+    with open(file_name, 'w') as f:\n+        for item in arr:\n+            f.write(\"%-5s %-15s %-88s\\n\" % (item['nof_commit'], item['lst_mod'], item['file']))\n+\n+\n+def digest(text):\n+    return hashlib.md5(text.encode('utf-8')).hexdigest()\n+\n+\n+def find_interesting(use_cache):\n+    save_prefix = digest(sys.argv[1])\n+\n+    if not use_cache:\n+        with open(save_prefix + \".json\", 'w') as outfile:\n+            json.dump(g, outfile)\n+    hot_files = sorted(g, key=lambda k: k['nof_commit'], reverse=True)\n+    save_array_to_file(hot_files, save_prefix + \"hot_files.log\")\n+\n+    hot_compiler_files = [f for f in hot_files\n+                          if 'opto\/' in f['file'] or\n+                          'c1\/' in f['file'] or\n+                          'code\/' in f['file'] or\n+                          'jvmci\/' in f['file'] or\n+                          'ci\/' in f['file']]\n+    save_array_to_file(hot_compiler_files, save_prefix + \"hot_compiler_files.log\")\n+\n+    hot_gc_files = [f for f in hot_files\n+                    if 'gc\/' in f['file']]\n+    save_array_to_file(hot_gc_files, save_prefix + \"hot_gc_files.log\")\n+\n+    lst_mod = sorted(g, key=lambda k: k['lst_mod'], reverse=True)\n+    save_array_to_file(lst_mod, save_prefix + \"last_modify.log\")\n+\n+\n+def main():\n+    if len(sys.argv) != 2 or len(sys.argv[1]) == 0:\n+        print(f\"Usage: python {__file__} JDK_SOURCE_DIR\")\n+        return \n+\n+    # try loading data from cached file, otherwise start threads to analyze\n+    save_prefix = digest(sys.argv[1])\n+    use_cache = False\n+    if os.path.isfile(save_prefix + \".json\"):\n+        with open(save_prefix + \".json\", 'r') as outfile:\n+            global g\n+            g = json.load(outfile)\n+        print(f\"Using cached {save_prefix}.json file\")\n+        use_cache = True\n+    else:\n+        # change working directory to given path\n+        old_cwd = os.getcwd()\n+        os.chdir(os.path.expanduser(sys.argv[1]))\n+        # split files into each chunk\n+        files = []\n+        for (path, name, filenames) in os.walk(\"src\/hotspot\"):\n+            files += [os.path.join(path, file) for file in filenames]\n+        chunks = [files[i:i + 100] for i in range(0, len(files), 100)]\n+        # do analysis based on each chunk\n+        threads = []\n+        for chunk in chunks:\n+            t = threading.Thread(target=analysis, args=(chunk,))\n+            t.start()\n+            threads.append(t)\n+\n+        print(f\"Analysing... [thread:{len(threads)}]\")\n+        for t in threads:\n+            t.join()\n+\n+        # restore old path and save analyzed data into it\n+        os.chdir(old_cwd)\n+\n+    find_interesting(use_cache)\n+\n+    print(\"Analysis done!\")\n+\n+\n+if __name__ == '__main__':\n+    main()\n+\n","filename":"scripts\/find_hot_and_lstmod.py","additions":138,"deletions":0,"binary":false,"changes":138,"status":"added"}]}