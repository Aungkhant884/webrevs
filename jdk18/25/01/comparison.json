{"files":[{"patch":"@@ -66,1 +66,1 @@\n-    (void)ObjectSynchronizer::deflate_idle_monitors();\n+    (void)ObjectSynchronizer::deflate_idle_monitors(\/* ObjectMonitorsHashtable is not needed here *\/ nullptr);\n","filename":"src\/hotspot\/share\/runtime\/monitorDeflationThread.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -60,0 +60,34 @@\n+class CleanupObjectMonitorsHashtable: StackObj {\n+ public:\n+  bool do_entry(JavaThread*& key, ObjectMonitorsHashtable::PtrList*& list) {\n+    list->clear();  \/\/ clear the LinkListNodes\n+    delete list;    \/\/ then delete the LinkedList\n+    return true;\n+  }\n+};\n+\n+ObjectMonitorsHashtable::~ObjectMonitorsHashtable() {\n+  CleanupObjectMonitorsHashtable cleanup;\n+  _ptrs->unlink(&cleanup);  \/\/ cleanup the LinkedLists\n+  delete _ptrs;             \/\/ then delete the hash table\n+}\n+\n+void ObjectMonitorsHashtable::add_entry(JavaThread* jt, ObjectMonitor* om) {\n+  ObjectMonitorsHashtable::PtrList* list = get_entry(jt);\n+  if (list == nullptr) {\n+    \/\/ Create new list and add it to the hash table:\n+    list = new (ResourceObj::C_HEAP, mtThread) ObjectMonitorsHashtable::PtrList();\n+    add_entry(jt, list);\n+  }\n+  list->add(om);  \/\/ Add the ObjectMonitor to the list.\n+  _om_count++;\n+}\n+\n+bool ObjectMonitorsHashtable::has_entry(JavaThread* jt, ObjectMonitor* om) {\n+  ObjectMonitorsHashtable::PtrList* list = get_entry(jt);\n+  if (list == nullptr || list->find(om) == nullptr) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n@@ -995,0 +1029,5 @@\n+\/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n+\/\/ ObjectMonitors where owner is set to a stack lock address in thread.\n+\/\/\n+\/\/ This version of monitors_iterate() works with the in-use monitor list.\n+\/\/\n@@ -1000,0 +1039,2 @@\n+      \/\/ Not owned by the target thread and intentionally skips when owner\n+      \/\/ is set to a stack lock address in the target thread.\n@@ -1016,0 +1057,25 @@\n+\/\/ This version of monitors_iterate() works with the specified linked list.\n+\/\/\n+void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure,\n+                                          ObjectMonitorsHashtable::PtrList* list,\n+                                          JavaThread* thread) {\n+  typedef LinkedListIterator<ObjectMonitor*> ObjectMonitorIterator;\n+  ObjectMonitorIterator iter(list->head());\n+  while (!iter.is_empty()) {\n+    ObjectMonitor* mid = *iter.next();\n+    \/\/ Owner set to a stack lock address in thread should never be seen here:\n+    assert(mid->owner() == thread, \"must be\");\n+    if (!mid->is_being_async_deflated() && mid->object_peek() != NULL) {\n+      \/\/ Only process with closure if the object is set.\n+\n+      \/\/ monitors_iterate() is only called at a safepoint or when the\n+      \/\/ target thread is suspended or when the target thread is\n+      \/\/ operating on itself. The current closures in use today are\n+      \/\/ only interested in an owned ObjectMonitor and ownership\n+      \/\/ cannot be dropped under the calling contexts so the\n+      \/\/ ObjectMonitor cannot be async deflated.\n+      closure->do_monitor(mid);\n+    }\n+  }\n+}\n+\n@@ -1341,0 +1407,8 @@\n+\/\/\n+\/\/ If table != nullptr, we gather owned ObjectMonitors indexed by the\n+\/\/ owner in the table. Please note that ObjectMonitors where the owner\n+\/\/ is set to a stack lock address are NOT associated with the JavaThread\n+\/\/ that holds that stack lock. All of the current consumers of\n+\/\/ ObjectMonitorsHashtable info only care about JNI locked monitors and\n+\/\/ those do not have the owner set to a stack lock address.\n+\/\/\n@@ -1342,1 +1416,2 @@\n-                                                elapsedTimer* timer_p) {\n+                                                elapsedTimer* timer_p,\n+                                                ObjectMonitorsHashtable* table) {\n@@ -1353,0 +1428,12 @@\n+    } else if (table != nullptr) {\n+      \/\/ The caller is interested in the owned ObjectMonitors. This does\n+      \/\/ not include when owner is set to a stack lock address in thread.\n+      \/\/ This also does not capture unowned ObjectMonitors that cannot be\n+      \/\/ deflated because of a waiter.\n+      JavaThread* jt = (JavaThread*)mid->owner();\n+      \/\/ Since deflate_idle_monitors() and deflate_monitor_list() can be\n+      \/\/ called more than once, we have to make sure the entry has not\n+      \/\/ already been added.\n+      if (jt != nullptr && !table->has_entry(jt, mid)) {\n+        table->add_entry(jt, mid);\n+      }\n@@ -1377,2 +1464,2 @@\n-\/\/ by the VMThread.\n-size_t ObjectSynchronizer::deflate_idle_monitors() {\n+\/\/ and VM_ThreadDump::doit() by the VMThread.\n+size_t ObjectSynchronizer::deflate_idle_monitors(ObjectMonitorsHashtable* table) {\n@@ -1403,1 +1490,1 @@\n-  size_t deflated_count = deflate_monitor_list(current, ls, &timer);\n+  size_t deflated_count = deflate_monitor_list(current, ls, &timer, table);\n@@ -1461,0 +1548,4 @@\n+    if (table != nullptr) {\n+      ls->print_cr(\"ObjectMonitorsHashtable: jt_count=\" SIZE_FORMAT \", om_count=\" SIZE_FORMAT,\n+                   table->jt_count(), table->om_count());\n+    }\n@@ -1563,1 +1654,1 @@\n-    while (ObjectSynchronizer::deflate_idle_monitors() != 0) {\n+    while (ObjectSynchronizer::deflate_idle_monitors(\/* ObjectMonitorsHashtable is not needed here *\/ nullptr) >= (size_t)MonitorDeflationMax) {\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":96,"deletions":5,"binary":false,"changes":101,"status":"modified"},{"patch":"@@ -33,0 +33,2 @@\n+#include \"utilities\/linkedlist.hpp\"\n+#include \"utilities\/resourceHash.hpp\"\n@@ -38,0 +40,55 @@\n+\/\/ Hash table of JavaThread* to a list of ObjectMonitor* owned by the JavaThread*.\n+\/\/\n+class ObjectMonitorsHashtable {\n+ private:\n+  static unsigned int ptr_hash(JavaThread* const& s1) {\n+    \/\/ 2654435761 = 2^32 * Phi (golden ratio)\n+    return (unsigned int)(((uint32_t)(uintptr_t)s1) * 2654435761u);\n+  }\n+\n+ public:\n+  typedef LinkedListImpl<ObjectMonitor*,\n+                         ResourceObj::C_HEAP, mtThread,\n+                         AllocFailStrategy::RETURN_NULL> PtrList;\n+\n+  \/\/ ResourceHashtable SIZE is specified at compile time so we\n+  \/\/ use 1031 which is the first prime after 1024.\n+  typedef ResourceHashtable<JavaThread*, PtrList*, 1031,\n+                            ResourceObj::C_HEAP, mtThread,\n+                            &ObjectMonitorsHashtable::ptr_hash> PtrTable;\n+ private:\n+  PtrTable* _ptrs;\n+  size_t _jt_count;\n+  size_t _om_count;\n+\n+ public:\n+  \/\/ ResourceHashtable is passed to various functions and populated in\n+  \/\/ different places so we allocate it using C_HEAP to make it immune\n+  \/\/ from any ResourceMarks that happen to be in the code paths.\n+  ObjectMonitorsHashtable() : _ptrs(new (ResourceObj::C_HEAP, mtThread) PtrTable()), _jt_count(0), _om_count(0) {}\n+\n+  ~ObjectMonitorsHashtable();\n+\n+  void add_entry(JavaThread* jt, ObjectMonitor* om);\n+\n+  void add_entry(JavaThread* jt, PtrList* list) {\n+    _ptrs->put(jt, list);\n+    _jt_count++;\n+  }\n+\n+  PtrList* get_entry(JavaThread* jt) {\n+    PtrList** listpp = _ptrs->get(jt);\n+    return (listpp == nullptr) ? nullptr : *listpp;\n+  }\n+\n+  bool has_entry(JavaThread* jt) {\n+    PtrList** listpp = _ptrs->get(jt);\n+    return listpp != nullptr && *listpp != nullptr;\n+  }\n+\n+  bool has_entry(JavaThread* jt, ObjectMonitor* om);\n+\n+  size_t jt_count() { return _jt_count; }\n+  size_t om_count() { return _om_count; }\n+};\n+\n@@ -136,0 +193,5 @@\n+\n+  \/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n+  \/\/ ObjectMonitors where owner is set to a stack lock address in thread:\n+  \/\/\n+  \/\/ This version of monitors_iterate() works with the in-use monitor list.\n@@ -137,0 +199,4 @@\n+  \/\/ This version of monitors_iterate() works with the specified linked list.\n+  static void monitors_iterate(MonitorClosure* closure,\n+                               ObjectMonitorsHashtable::PtrList* list,\n+                               JavaThread* thread);\n@@ -141,1 +207,1 @@\n-  \/\/ GC: we current use aggressive monitor deflation policy\n+  \/\/ GC: we currently use aggressive monitor deflation policy\n@@ -143,1 +209,1 @@\n-  static size_t deflate_idle_monitors();\n+  static size_t deflate_idle_monitors(ObjectMonitorsHashtable* table);\n@@ -149,2 +215,2 @@\n-  static size_t deflate_monitor_list(Thread* current, LogStream* ls,\n-                                     elapsedTimer* timer_p);\n+  static size_t deflate_monitor_list(Thread* current, LogStream* ls, elapsedTimer* timer_p,\n+                                     ObjectMonitorsHashtable* table);\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":70,"deletions":4,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -282,0 +282,12 @@\n+  ObjectMonitorsHashtable table;\n+  ObjectMonitorsHashtable* tablep = nullptr;\n+  if (_with_locked_monitors) {\n+    \/\/ The caller wants locked monitor information and that's expensive to gather\n+    \/\/ when there are a lot of inflated monitors. So we deflate idle monitors and\n+    \/\/ gather information about owned monitors at the same time.\n+    tablep = &table;\n+    while (ObjectSynchronizer::deflate_idle_monitors(tablep) >= (size_t)MonitorDeflationMax) {\n+      ; \/* empty *\/\n+    }\n+  }\n+\n@@ -296,1 +308,1 @@\n-      snapshot_thread(jt, tcl);\n+      snapshot_thread(jt, tcl, tablep);\n@@ -331,1 +343,1 @@\n-      snapshot_thread(jt, tcl);\n+      snapshot_thread(jt, tcl, tablep);\n@@ -336,1 +348,2 @@\n-void VM_ThreadDump::snapshot_thread(JavaThread* java_thread, ThreadConcurrentLocks* tcl) {\n+void VM_ThreadDump::snapshot_thread(JavaThread* java_thread, ThreadConcurrentLocks* tcl,\n+                                    ObjectMonitorsHashtable* table) {\n@@ -338,1 +351,1 @@\n-  snapshot->dump_stack_at_safepoint(_max_depth, _with_locked_monitors);\n+  snapshot->dump_stack_at_safepoint(_max_depth, _with_locked_monitors, table);\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -210,1 +210,2 @@\n-  void snapshot_thread(JavaThread* java_thread, ThreadConcurrentLocks* tcl);\n+  void snapshot_thread(JavaThread* java_thread, ThreadConcurrentLocks* tcl,\n+                       ObjectMonitorsHashtable* table);\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2391,1 +2391,1 @@\n-      stack_trace->dump_stack_at_safepoint(-1);\n+      stack_trace->dump_stack_at_safepoint(-1, \/* ObjectMonitorsHashtable is not needed here *\/ nullptr);\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -662,1 +662,1 @@\n-void ThreadStackTrace::dump_stack_at_safepoint(int maxDepth) {\n+void ThreadStackTrace::dump_stack_at_safepoint(int maxDepth, ObjectMonitorsHashtable* table) {\n@@ -686,1 +686,1 @@\n-    \/\/ not found in the stack\n+    \/\/ that are not found in the stack, e.g. JNI locked monitors:\n@@ -688,1 +688,11 @@\n-    ObjectSynchronizer::monitors_iterate(&imc, _thread);\n+    if (table != nullptr) {\n+      \/\/ Get the ObjectMonitors locked by the target thread, if any,\n+      \/\/ and does not include any where owner is set to a stack lock\n+      \/\/ address in the target thread:\n+      ObjectMonitorsHashtable::PtrList* list = table->get_entry(_thread);\n+      if (list != nullptr) {\n+        ObjectSynchronizer::monitors_iterate(&imc, list, _thread);\n+      }\n+    } else {\n+      ObjectSynchronizer::monitors_iterate(&imc, _thread);\n+    }\n@@ -939,1 +949,2 @@\n-void ThreadSnapshot::dump_stack_at_safepoint(int max_depth, bool with_locked_monitors) {\n+void ThreadSnapshot::dump_stack_at_safepoint(int max_depth, bool with_locked_monitors,\n+                                             ObjectMonitorsHashtable* table) {\n@@ -941,1 +952,1 @@\n-  _stack_trace->dump_stack_at_safepoint(max_depth);\n+  _stack_trace->dump_stack_at_safepoint(max_depth, table);\n","filename":"src\/hotspot\/share\/services\/threadService.cpp","additions":16,"deletions":5,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -250,1 +250,2 @@\n-  void        dump_stack_at_safepoint(int max_depth, bool with_locked_monitors);\n+  void        dump_stack_at_safepoint(int max_depth, bool with_locked_monitors,\n+                                      ObjectMonitorsHashtable* table);\n@@ -273,1 +274,1 @@\n-  void            dump_stack_at_safepoint(int max_depth);\n+  void            dump_stack_at_safepoint(int max_depth, ObjectMonitorsHashtable* table);\n","filename":"src\/hotspot\/share\/services\/threadService.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"}]}