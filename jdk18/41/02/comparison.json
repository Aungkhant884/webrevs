{"files":[{"patch":"@@ -10594,1 +10594,1 @@\n-\/\/ ------------------------------ Shift ---------------------------------------\n+\/\/ ------------------------------ ShiftCount ----------------------------------\n@@ -10653,0 +10653,2 @@\n+\/\/ ------------------------------ LogicalShift --------------------------------\n+\n@@ -10769,1 +10771,1 @@\n-\/\/ ------------------------------ LeftShift -----------------------------------\n+\/\/ ------------------------------ LogicalLeftShift ----------------------------\n@@ -10771,1 +10773,1 @@\n-\/\/ Byte vector left shift\n+\/\/ Byte vector logical left shift\n@@ -10793,1 +10795,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -10809,1 +10811,1 @@\n-  predicate(n->as_Vector()->length() == 16);\n+  predicate(n->as_Vector()->length() == 16 && !n->as_ShiftV()->is_var_shift());\n@@ -10824,1 +10826,1 @@\n-\/\/ Shorts\/Chars vector logical left\/right shift\n+\/\/ Shorts\/Chars vector logical left shift\n@@ -10828,1 +10830,0 @@\n-  match(Set dst (URShiftVS src shift));\n@@ -10839,1 +10840,0 @@\n-  match(Set dst (URShiftVS src shift));\n@@ -10848,1 +10848,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -10864,1 +10864,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -10879,1 +10879,1 @@\n-\/\/ Integers vector logical left\/right shift\n+\/\/ Integers vector logical left shift\n@@ -10883,1 +10883,0 @@\n-  match(Set dst (URShiftVI src shift));\n@@ -10894,1 +10893,0 @@\n-  match(Set dst (URShiftVI src shift));\n@@ -10903,1 +10901,3 @@\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n@@ -10919,1 +10919,3 @@\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n@@ -10934,1 +10936,1 @@\n-\/\/ Longs vector logical left\/right shift\n+\/\/ Longs vector logical left shift\n@@ -10938,1 +10940,0 @@\n-  match(Set dst (URShiftVL src shift));\n@@ -10947,1 +10948,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -10968,0 +10969,10 @@\n+\/\/ Right shift with vector shift count on aarch32 SIMD is implemented as left\n+\/\/ shift by negative shift count value.\n+\/\/\n+\/\/ Method is_var_shift() denotes that vector shift count is a variable shift:\n+\/\/ 1) for this case, vector shift count should be negated before conducting\n+\/\/    right shifts. E.g., vsrl4S_reg_var rule.\n+\/\/ 2) for the opposite case, vector shift count is generated via RShiftCntV\n+\/\/    rules and is already negated there. Hence, no negation is needed.\n+\/\/    E.g., vsrl4S_reg rule.\n+\n@@ -10969,0 +10980,60 @@\n+instruct vsrl4S_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh4S_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl4S_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.U16 $dst.D,$src.D,$tmp.D\\t! logical right shift packed4S\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsrl8S_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh8S_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl8S_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U16 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -10970,1 +11041,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -10986,1 +11057,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -11002,0 +11073,68 @@\n+instruct vsrl2I_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh2I_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl2I_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.U32 $dst.D,$src.D,$tmp.D\\t! logical right shift packed2I\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsrl4I_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh4I_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl4I_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U32 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed4I\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -11003,1 +11142,3 @@\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n@@ -11019,1 +11160,3 @@\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n@@ -11035,0 +11178,30 @@\n+instruct vsrl2L_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVL src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh2L_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl2L_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVL src shift));\n+  effect(TEMP tmp, DEF dst, USE src, USE shift);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U64 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed2L\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -11036,1 +11209,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -11170,1 +11343,0 @@\n-\n@@ -11172,1 +11344,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -11181,2 +11353,22 @@\n-instruct vsrl16B_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n+instruct vsra8B_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVB src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S8 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed8B\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra16B_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 16 && !n->as_ShiftV()->is_var_shift());\n@@ -11191,2 +11383,2 @@\n-instruct vsrl8B_immI(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n+instruct vsra16B_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 16 && n->as_ShiftV()->is_var_shift());\n@@ -11194,0 +11386,20 @@\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S8 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed16B\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra8B_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -11197,1 +11409,1 @@\n-    \"VSHR.S8 $dst.D,$src.D,$shift\\t! logical right shift packed8B\"\n+    \"VSHR.S8 $dst.D,$src.D,$shift\\t! arithmetic right shift packed8B\"\n@@ -11207,3 +11419,3 @@\n-instruct vsrl16B_immI(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (RShiftVB src shift));\n+instruct vsra16B_immI(vecX dst, vecX src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 16 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -11213,1 +11425,1 @@\n-    \"VSHR.S8 $dst.Q,$src.Q,$shift\\t! logical right shift packed16B\"\n+    \"VSHR.S8 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed16B\"\n@@ -11225,1 +11437,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -11234,0 +11446,20 @@\n+instruct vsra4S_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVS src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S16 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed4S\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -11235,1 +11467,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -11244,2 +11476,2 @@\n-instruct vsra4S_immI(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n+instruct vsra8S_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n@@ -11247,0 +11479,20 @@\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S16 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra4S_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -11250,1 +11502,1 @@\n-    \"VSHR.S16 $dst.D,$src.D,$shift\\t! logical right shift packed4S\"\n+    \"VSHR.S16 $dst.D,$src.D,$shift\\t! arithmetic right shift packed4S\"\n@@ -11261,2 +11513,2 @@\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (RShiftVS src shift));\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -11266,1 +11518,1 @@\n-    \"VSHR.S16 $dst.Q,$src.Q,$shift\\t! logical right shift packed8S\"\n+    \"VSHR.S16 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed8S\"\n@@ -11278,1 +11530,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -11287,0 +11539,20 @@\n+instruct vsra2I_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVI src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S32 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed2I\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -11288,1 +11560,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -11297,2 +11569,2 @@\n-instruct vsra2I_immI(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n+instruct vsra4I_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n@@ -11300,0 +11572,20 @@\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S32 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed4I\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra2I_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -11303,1 +11595,1 @@\n-    \"VSHR.S32 $dst.D,$src.D,$shift\\t! logical right shift packed2I\"\n+    \"VSHR.S32 $dst.D,$src.D,$shift\\t! arithmetic right shift packed2I\"\n@@ -11314,2 +11606,2 @@\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (RShiftVI src shift));\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -11319,1 +11611,1 @@\n-    \"VSHR.S32 $dst.Q,$src.Q,$shift\\t! logical right shift packed4I\"\n+    \"VSHR.S32 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed4I\"\n@@ -11331,1 +11623,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -11340,2 +11632,2 @@\n-instruct vsra2L_immI(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n+instruct vsra2L_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n@@ -11343,0 +11635,20 @@\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S64 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed2L\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra2L_immI(vecX dst, vecX src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n@@ -11346,1 +11658,1 @@\n-    \"VSHR.S64 $dst.Q,$src.Q,$shift\\t! logical right shift packed2L\"\n+    \"VSHR.S64 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed2L\"\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":366,"deletions":54,"binary":false,"changes":420,"status":"modified"},{"patch":"@@ -534,1 +534,2 @@\n- bool _is_var_shift;\n+ private:\n+  bool _is_var_shift;\n@@ -542,0 +543,4 @@\n+  virtual uint hash() const { return VectorNode::hash() + _is_var_shift; }\n+  virtual bool cmp(const Node& n) const {\n+    return VectorNode::cmp(n) && _is_var_shift == ((ShiftVNode&)n)._is_var_shift;\n+  }\n@@ -543,1 +548,1 @@\n-  virtual  uint  size_of() const { return sizeof(ShiftVNode); }\n+  virtual uint size_of() const { return sizeof(ShiftVNode); }\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"}]}