{"files":[{"patch":"@@ -10594,1 +10594,1 @@\n-\/\/ ------------------------------ Shift ---------------------------------------\n+\/\/ ------------------------------ ShiftCount ----------------------------------\n@@ -10596,3 +10596,1 @@\n-\/\/ Low bits of vector \"shift\" elements are used, so it\n-\/\/ doesn't matter if we treat it as ints or bytes here.\n-instruct vscntD(vecD dst, iRegI cnt) %{\n+instruct vslcntD(vecD dst, iRegI cnt) %{\n@@ -10601,1 +10599,0 @@\n-  match(Set dst (RShiftCntV cnt));\n@@ -10609,1 +10606,1 @@\n-instruct vscntX(vecX dst, iRegI cnt) %{\n+instruct vslcntX(vecX dst, iRegI cnt) %{\n@@ -10612,1 +10609,0 @@\n-  match(Set dst (RShiftCntV cnt));\n@@ -10620,1 +10616,18 @@\n-\/\/ ------------------------------ LeftShift -----------------------------------\n+\/\/ Low bits of vector \"shift\" elements are used, so it\n+\/\/ doesn't matter if we treat it as ints or bytes here.\n+instruct vsrcntD(vecD dst, iRegI cnt) %{\n+  predicate(n->as_Vector()->length_in_bytes() == 8 && VM_Version::has_simd());\n+  match(Set dst (RShiftCntV cnt));\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{ \"VDUP.8 $dst.D,$cnt\\n\\t\"\n+            \"VNEG.S8 $dst.D,$dst.D\\t! neg packed8B\" %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vdupI($dst$$FloatRegister, $cnt$$Register,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n@@ -10622,2 +10635,21 @@\n-\/\/ Byte vector logical left shift\n-instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{\n+instruct vsrcntX(vecX dst, iRegI cnt) %{\n+  predicate(n->as_Vector()->length_in_bytes() == 16 && VM_Version::has_simd());\n+  match(Set dst (RShiftCntV cnt));\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{ \"VDUP.8 $dst.Q,$cnt\\n\\t\"\n+            \"VNEG.S8 $dst.Q,$dst.Q\\t! neg packed16B\" %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vdupI($dst$$FloatRegister, $cnt$$Register,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+\/\/ ------------------------------ LogicalShift --------------------------------\n+\n+\/\/ Byte vector logical left\/right shift based on sign\n+instruct vsh8B_reg(vecD dst, vecD src, vecD shift) %{\n@@ -10625,1 +10657,1 @@\n-  match(Set dst (LShiftVB src shift));\n+  effect(DEF dst, USE src, USE shift);\n@@ -10629,1 +10661,1 @@\n-    \"VSHL.U8 $dst.D,$src.D,$shift.D\\t! logical left shift packed8B\"\n+    \"VSHL.U8 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed8B\"\n@@ -10639,1 +10671,1 @@\n-instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{\n+instruct vsh16B_reg(vecX dst, vecX src, vecX shift) %{\n@@ -10641,1 +10673,1 @@\n-  match(Set dst (LShiftVB src shift));\n+  effect(DEF dst, USE src, USE shift);\n@@ -10645,1 +10677,1 @@\n-    \"VSHL.U8 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed16B\"\n+    \"VSHL.U8 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed16B\"\n@@ -10655,1 +10687,87 @@\n-instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{\n+\/\/ Shorts\/Char vector logical left\/right shift based on sign\n+instruct vsh4S_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 4);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U16 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed4S\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsh8S_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 8);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U16 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+\/\/ Integers vector logical left\/right shift based on sign\n+instruct vsh2I_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 2);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U32 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed2I\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsh4I_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 4);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U32 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed4I\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+\/\/ Longs vector logical left\/right shift based on sign\n+instruct vsh2L_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 2);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U64 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed2L\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+\/\/ ------------------------------ LogicalLeftShift ----------------------------\n+\n+\/\/ Byte vector logical left shift\n+instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{\n@@ -10657,0 +10775,20 @@\n+  match(Set dst (LShiftVB src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsh8B_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 16);\n+  match(Set dst (LShiftVB src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsh16B_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -10672,1 +10810,1 @@\n-  predicate(n->as_Vector()->length() == 16);\n+  predicate(n->as_Vector()->length() == 16 && !n->as_ShiftV()->is_var_shift());\n@@ -10693,7 +10831,2 @@\n-  format %{\n-    \"VSHL.U16 $dst.D,$src.D,$shift.D\\t! logical left shift packed4S\"\n-  %}\n-  ins_encode %{\n-    bool quad = false;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, quad);\n+  expand %{\n+    vsh4S_reg(dst, src, shift);\n@@ -10701,1 +10834,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10709,7 +10841,2 @@\n-  format %{\n-    \"VSHL.U16 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed8S\"\n-  %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, quad);\n+  expand %{\n+    vsh8S_reg(dst, src, shift);\n@@ -10717,1 +10844,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10721,1 +10847,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -10737,1 +10863,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -10758,7 +10884,2 @@\n-  format %{\n-    \"VSHL.U32 $dst.D,$src.D,$shift.D\\t! logical left shift packed2I\"\n-  %}\n-  ins_encode %{\n-    bool quad = false;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, quad);\n+  expand %{\n+    vsh2I_reg(dst, src, shift);\n@@ -10766,1 +10887,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10774,7 +10894,2 @@\n-  format %{\n-    \"VSHL.U32 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed4I\"\n-  %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, quad);\n+  expand %{\n+    vsh4I_reg(dst, src, shift);\n@@ -10782,1 +10897,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10786,1 +10900,3 @@\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n@@ -10802,1 +10918,3 @@\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n@@ -10823,7 +10941,2 @@\n-  format %{\n-    \"VSHL.U64 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed2L\"\n-  %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_64, quad);\n+  expand %{\n+    vsh2L_reg(dst, src, shift);\n@@ -10831,1 +10944,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10835,1 +10947,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -10856,0 +10968,10 @@\n+\/\/ Right shift with vector shift count on aarch32 SIMD is implemented as left\n+\/\/ shift by negative shift count value.\n+\/\/\n+\/\/ Method is_var_shift() denotes that vector shift count is a variable shift:\n+\/\/ 1) for this case, vector shift count should be negated before conducting\n+\/\/    right shifts. E.g., vsrl4S_reg_var rule.\n+\/\/ 2) for the opposite case, vector shift count is generated via RShiftCntV\n+\/\/    rules and is already negated there. Hence, no negation is needed.\n+\/\/    E.g., vsrl4S_reg rule.\n+\n@@ -10857,2 +10979,12 @@\n-instruct vsrl4S_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 4);\n+instruct vsrl4S_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsh4S_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl4S_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n@@ -10877,2 +11009,12 @@\n-instruct vsrl8S_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 8);\n+instruct vsrl8S_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsh8S_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl8S_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n@@ -10898,1 +11040,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -10914,1 +11056,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -10930,2 +11072,16 @@\n-instruct vsrl2I_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+instruct vsrl2I_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsh2I_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl2I_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            n->as_ShiftV()->is_var_shift());\n@@ -10950,2 +11106,16 @@\n-instruct vsrl4I_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+instruct vsrl4I_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsh4I_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl4I_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            n->as_ShiftV()->is_var_shift());\n@@ -10971,1 +11141,3 @@\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n@@ -10987,1 +11159,3 @@\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n@@ -11003,2 +11177,12 @@\n-instruct vsrl2L_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 2);\n+instruct vsrl2L_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVL src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsh2L_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl2L_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n@@ -11024,1 +11208,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -11042,2 +11226,18 @@\n-instruct vsra8B_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 8);\n+instruct vsra8B_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVB src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S8 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed8B\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsra8B_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n@@ -11062,2 +11262,18 @@\n-instruct vsra16B_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 16);\n+instruct vsra16B_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 16 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVB src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S8 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed16B\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsra16B_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 16 && n->as_ShiftV()->is_var_shift());\n@@ -11083,1 +11299,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -11099,1 +11315,1 @@\n-  predicate(n->as_Vector()->length() == 16);\n+  predicate(n->as_Vector()->length() == 16 && !n->as_ShiftV()->is_var_shift());\n@@ -11115,2 +11331,18 @@\n-instruct vsra4S_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 4);\n+instruct vsra4S_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVS src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S16 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed4S\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsra4S_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n@@ -11135,2 +11367,18 @@\n-instruct vsra8S_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 8);\n+instruct vsra8S_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVS src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S16 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsra8S_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n@@ -11156,1 +11404,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -11172,1 +11420,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -11188,2 +11436,18 @@\n-instruct vsra2I_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 2);\n+instruct vsra2I_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVI src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S32 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed2I\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsra2I_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n@@ -11208,2 +11472,18 @@\n-instruct vsra4I_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 4);\n+instruct vsra4I_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVI src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S32 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed4I\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsra4I_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n@@ -11229,1 +11509,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -11245,1 +11525,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -11261,2 +11541,18 @@\n-instruct vsra2L_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 2);\n+instruct vsra2L_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVL src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S64 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed2L\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+%}\n+\n+instruct vsra2L_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n@@ -11282,1 +11578,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":394,"deletions":98,"binary":false,"changes":492,"status":"modified"},{"patch":"@@ -534,1 +534,2 @@\n- bool _is_var_shift;\n+ private:\n+  bool _is_var_shift;\n@@ -542,0 +543,4 @@\n+  virtual uint hash() const { return VectorNode::hash() + _is_var_shift; }\n+  virtual bool cmp(const Node& n) const {\n+    return VectorNode::cmp(n) && _is_var_shift == ((ShiftVNode&)n)._is_var_shift;\n+  }\n@@ -543,1 +548,1 @@\n-  virtual  uint  size_of() const { return sizeof(ShiftVNode); }\n+  virtual uint size_of() const { return sizeof(ShiftVNode); }\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"}]}