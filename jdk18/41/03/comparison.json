{"files":[{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2008, 2021, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2008, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -126,0 +126,2 @@\n+\/\/ Assert that the given node is not a var shift.\n+bool assert_not_var_shift(const Node *n);\n@@ -129,0 +131,7 @@\n+\n+\/\/ Assert that the given node is not a var shift.\n+bool assert_not_var_shift(const Node *n) {\n+  assert(!n->as_ShiftV()->is_var_shift(), \"illegal var shift\");\n+  return true;\n+}\n+\n@@ -10594,1 +10603,1 @@\n-\/\/ ------------------------------ Shift ---------------------------------------\n+\/\/ ------------------------------ ShiftCount ----------------------------------\n@@ -10653,0 +10662,2 @@\n+\/\/ ------------------------------ LogicalShift --------------------------------\n+\n@@ -10769,1 +10780,1 @@\n-\/\/ ------------------------------ LeftShift -----------------------------------\n+\/\/ ------------------------------ LogicalLeftShift ----------------------------\n@@ -10771,1 +10782,1 @@\n-\/\/ Byte vector left shift\n+\/\/ Byte vector logical left shift\n@@ -10793,1 +10804,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && assert_not_var_shift(n));\n@@ -10809,1 +10820,1 @@\n-  predicate(n->as_Vector()->length() == 16);\n+  predicate(n->as_Vector()->length() == 16 && assert_not_var_shift(n));\n@@ -10824,1 +10835,1 @@\n-\/\/ Shorts\/Chars vector logical left\/right shift\n+\/\/ Shorts\/Chars vector logical left shift\n@@ -10828,1 +10839,0 @@\n-  match(Set dst (URShiftVS src shift));\n@@ -10839,1 +10849,0 @@\n-  match(Set dst (URShiftVS src shift));\n@@ -10848,1 +10857,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && assert_not_var_shift(n));\n@@ -10864,1 +10873,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && assert_not_var_shift(n));\n@@ -10879,1 +10888,1 @@\n-\/\/ Integers vector logical left\/right shift\n+\/\/ Integers vector logical left shift\n@@ -10883,1 +10892,0 @@\n-  match(Set dst (URShiftVI src shift));\n@@ -10894,1 +10902,0 @@\n-  match(Set dst (URShiftVI src shift));\n@@ -10903,1 +10910,3 @@\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            assert_not_var_shift(n));\n@@ -10919,1 +10928,3 @@\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            assert_not_var_shift(n));\n@@ -10934,1 +10945,1 @@\n-\/\/ Longs vector logical left\/right shift\n+\/\/ Longs vector logical left shift\n@@ -10938,1 +10949,0 @@\n-  match(Set dst (URShiftVL src shift));\n@@ -10947,1 +10957,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && assert_not_var_shift(n));\n@@ -10968,0 +10978,10 @@\n+\/\/ Right shift with vector shift count on aarch32 SIMD is implemented as left\n+\/\/ shift by negative shift count value.\n+\/\/\n+\/\/ Method is_var_shift() denotes that vector shift count is a variable shift:\n+\/\/ 1) for this case, vector shift count should be negated before conducting\n+\/\/    right shifts. E.g., vsrl4S_reg_var rule.\n+\/\/ 2) for the opposite case, vector shift count is generated via RShiftCntV\n+\/\/    rules and is already negated there. Hence, no negation is needed.\n+\/\/    E.g., vsrl4S_reg rule.\n+\n@@ -10969,0 +10989,60 @@\n+instruct vsrl4S_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh4S_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl4S_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.U16 $dst.D,$src.D,$tmp.D\\t! logical right shift packed4S\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsrl8S_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh8S_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl8S_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVS src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U16 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -10970,1 +11050,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && assert_not_var_shift(n));\n@@ -10986,1 +11066,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && assert_not_var_shift(n));\n@@ -11002,0 +11082,68 @@\n+instruct vsrl2I_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh2I_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl2I_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.U32 $dst.D,$src.D,$tmp.D\\t! logical right shift packed2I\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsrl4I_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh4I_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl4I_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVI src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U32 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed4I\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -11003,1 +11151,3 @@\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 2 &&\n+            VM_Version::has_simd() &&\n+            assert_not_var_shift(n));\n@@ -11019,1 +11169,3 @@\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+  predicate(n->as_Vector()->length() == 4 &&\n+            VM_Version::has_simd() &&\n+            assert_not_var_shift(n));\n@@ -11035,0 +11187,30 @@\n+instruct vsrl2L_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVL src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST);\n+  expand %{\n+    vsh2L_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl2L_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVL src shift));\n+  effect(TEMP tmp, DEF dst, USE src, USE shift);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U64 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed2L\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -11036,1 +11218,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && assert_not_var_shift(n));\n@@ -11170,1 +11352,0 @@\n-\n@@ -11172,1 +11353,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -11181,2 +11362,22 @@\n-instruct vsrl16B_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n+instruct vsra8B_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVB src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S8 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed8B\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra16B_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 16 && !n->as_ShiftV()->is_var_shift());\n@@ -11191,2 +11392,2 @@\n-instruct vsrl8B_immI(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n+instruct vsra16B_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 16 && n->as_ShiftV()->is_var_shift());\n@@ -11194,0 +11395,20 @@\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S8 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed16B\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra8B_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 8 && assert_not_var_shift(n));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -11197,1 +11418,1 @@\n-    \"VSHR.S8 $dst.D,$src.D,$shift\\t! logical right shift packed8B\"\n+    \"VSHR.S8 $dst.D,$src.D,$shift\\t! arithmetic right shift packed8B\"\n@@ -11207,3 +11428,3 @@\n-instruct vsrl16B_immI(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (RShiftVB src shift));\n+instruct vsra16B_immI(vecX dst, vecX src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 16 && assert_not_var_shift(n));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -11213,1 +11434,1 @@\n-    \"VSHR.S8 $dst.Q,$src.Q,$shift\\t! logical right shift packed16B\"\n+    \"VSHR.S8 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed16B\"\n@@ -11225,1 +11446,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -11234,0 +11455,20 @@\n+instruct vsra4S_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVS src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S16 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed4S\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -11235,1 +11476,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(n->as_Vector()->length() == 8 && !n->as_ShiftV()->is_var_shift());\n@@ -11244,2 +11485,2 @@\n-instruct vsra4S_immI(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n+instruct vsra8S_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 8 && n->as_ShiftV()->is_var_shift());\n@@ -11247,0 +11488,20 @@\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S16 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra4S_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 4 && assert_not_var_shift(n));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -11250,1 +11511,1 @@\n-    \"VSHR.S16 $dst.D,$src.D,$shift\\t! logical right shift packed4S\"\n+    \"VSHR.S16 $dst.D,$src.D,$shift\\t! arithmetic right shift packed4S\"\n@@ -11261,2 +11522,2 @@\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (RShiftVS src shift));\n+  predicate(n->as_Vector()->length() == 8 && assert_not_var_shift(n));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -11266,1 +11527,1 @@\n-    \"VSHR.S16 $dst.Q,$src.Q,$shift\\t! logical right shift packed8S\"\n+    \"VSHR.S16 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed8S\"\n@@ -11278,1 +11539,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -11287,0 +11548,20 @@\n+instruct vsra2I_reg_var(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVI src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S32 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed2I\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -11288,1 +11569,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(n->as_Vector()->length() == 4 && !n->as_ShiftV()->is_var_shift());\n@@ -11297,2 +11578,2 @@\n-instruct vsra2I_immI(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n+instruct vsra4I_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && n->as_ShiftV()->is_var_shift());\n@@ -11300,0 +11581,20 @@\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S32 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed4I\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra2I_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 2 && assert_not_var_shift(n));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -11303,1 +11604,1 @@\n-    \"VSHR.S32 $dst.D,$src.D,$shift\\t! logical right shift packed2I\"\n+    \"VSHR.S32 $dst.D,$src.D,$shift\\t! arithmetic right shift packed2I\"\n@@ -11314,2 +11615,2 @@\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (RShiftVI src shift));\n+  predicate(n->as_Vector()->length() == 4 && assert_not_var_shift(n));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -11319,1 +11620,1 @@\n-    \"VSHR.S32 $dst.Q,$src.Q,$shift\\t! logical right shift packed4I\"\n+    \"VSHR.S32 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed4I\"\n@@ -11331,1 +11632,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(n->as_Vector()->length() == 2 && !n->as_ShiftV()->is_var_shift());\n@@ -11340,2 +11641,2 @@\n-instruct vsra2L_immI(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n+instruct vsra2L_reg_var(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && n->as_ShiftV()->is_var_shift());\n@@ -11343,0 +11644,20 @@\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2);\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S64 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed2L\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct vsra2L_immI(vecX dst, vecX src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 2 && assert_not_var_shift(n));\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n@@ -11346,1 +11667,1 @@\n-    \"VSHR.S64 $dst.Q,$src.Q,$shift\\t! logical right shift packed2L\"\n+    \"VSHR.S64 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed2L\"\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":376,"deletions":55,"binary":false,"changes":431,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2007, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2007, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -534,1 +534,2 @@\n- bool _is_var_shift;\n+ private:\n+  bool _is_var_shift;\n@@ -542,0 +543,4 @@\n+  virtual uint hash() const { return VectorNode::hash() + _is_var_shift; }\n+  virtual bool cmp(const Node& n) const {\n+    return VectorNode::cmp(n) && _is_var_shift == ((ShiftVNode&)n)._is_var_shift;\n+  }\n@@ -543,1 +548,1 @@\n-  virtual  uint  size_of() const { return sizeof(ShiftVNode); }\n+  virtual uint size_of() const { return sizeof(ShiftVNode); }\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"}]}