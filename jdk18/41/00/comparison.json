{"files":[{"patch":"@@ -10596,1 +10596,3 @@\n-instruct vslcntD(vecD dst, iRegI cnt) %{\n+\/\/ Low bits of vector \"shift\" elements are used, so it\n+\/\/ doesn't matter if we treat it as ints or bytes here.\n+instruct vscntD(vecD dst, iRegI cnt) %{\n@@ -10599,0 +10601,1 @@\n+  match(Set dst (RShiftCntV cnt));\n@@ -10606,1 +10609,1 @@\n-instruct vslcntX(vecX dst, iRegI cnt) %{\n+instruct vscntX(vecX dst, iRegI cnt) %{\n@@ -10609,0 +10612,1 @@\n+  match(Set dst (RShiftCntV cnt));\n@@ -10616,36 +10620,1 @@\n-\/\/ Low bits of vector \"shift\" elements are used, so it\n-\/\/ doesn't matter if we treat it as ints or bytes here.\n-instruct vsrcntD(vecD dst, iRegI cnt) %{\n-  predicate(n->as_Vector()->length_in_bytes() == 8 && VM_Version::has_simd());\n-  match(Set dst (RShiftCntV cnt));\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-\n-  format %{ \"VDUP.8 $dst.D,$cnt\\n\\t\"\n-            \"VNEG.S8 $dst.D,$dst.D\\t! neg packed8B\" %}\n-  ins_encode %{\n-    bool quad = false;\n-    __ vdupI($dst$$FloatRegister, $cnt$$Register,\n-             MacroAssembler::VELEM_SIZE_8, quad);\n-    __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_8, quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-instruct vsrcntX(vecX dst, iRegI cnt) %{\n-  predicate(n->as_Vector()->length_in_bytes() == 16 && VM_Version::has_simd());\n-  match(Set dst (RShiftCntV cnt));\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{ \"VDUP.8 $dst.Q,$cnt\\n\\t\"\n-            \"VNEG.S8 $dst.Q,$dst.Q\\t! neg packed16B\" %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vdupI($dst$$FloatRegister, $cnt$$Register,\n-             MacroAssembler::VELEM_SIZE_8, quad);\n-    __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_8, quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n+\/\/ ------------------------------ LeftShift -----------------------------------\n@@ -10653,2 +10622,2 @@\n-\/\/ Byte vector logical left\/right shift based on sign\n-instruct vsh8B_reg(vecD dst, vecD src, vecD shift) %{\n+\/\/ Byte vector logical left shift\n+instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{\n@@ -10656,1 +10625,1 @@\n-  effect(DEF dst, USE src, USE shift);\n+  match(Set dst (LShiftVB src shift));\n@@ -10660,1 +10629,1 @@\n-    \"VSHL.U8 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed8B\"\n+    \"VSHL.U8 $dst.D,$src.D,$shift.D\\t! logical left shift packed8B\"\n@@ -10667,1 +10636,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10670,1 +10639,1 @@\n-instruct vsh16B_reg(vecX dst, vecX src, vecX shift) %{\n+instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{\n@@ -10672,1 +10641,1 @@\n-  effect(DEF dst, USE src, USE shift);\n+  match(Set dst (LShiftVB src shift));\n@@ -10676,1 +10645,1 @@\n-    \"VSHL.U8 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed16B\"\n+    \"VSHL.U8 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed16B\"\n@@ -10683,107 +10652,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-\/\/ Shorts\/Char vector logical left\/right shift based on sign\n-instruct vsh4S_reg(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.U16 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed4S\"\n-  %}\n-  ins_encode %{\n-    bool quad = false;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-instruct vsh8S_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.U16 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed8S\"\n-  %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-\/\/ Integers vector logical left\/right shift based on sign\n-instruct vsh2I_reg(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.U32 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed2I\"\n-  %}\n-  ins_encode %{\n-    bool quad = false;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-instruct vsh4I_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.U32 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed4I\"\n-  %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-\/\/ Longs vector logical left\/right shift based on sign\n-instruct vsh2L_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.U64 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed2L\"\n-  %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_64, quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-\/\/ ------------------------------ LeftShift -----------------------------------\n-\n-\/\/ Byte vector left shift\n-instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (LShiftVB src shift));\n-  size(4*1);\n-  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n-  expand %{\n-    vsh8B_reg(dst, src, shift);\n-  %}\n-%}\n-\n-instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (LShiftVB src shift));\n-  size(4*1);\n-  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n-  expand %{\n-    vsh16B_reg(dst, src, shift);\n-  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10805,1 +10668,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10821,1 +10684,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10824,1 +10687,1 @@\n-\/\/ Shorts\/Chars vector logical left\/right shift\n+\/\/ Shorts\/Chars vector logical left shift\n@@ -10828,5 +10691,4 @@\n-  match(Set dst (URShiftVS src shift));\n-  size(4*1);\n-  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n-  expand %{\n-    vsh4S_reg(dst, src, shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U16 $dst.D,$src.D,$shift.D\\t! logical left shift packed4S\"\n@@ -10834,0 +10696,6 @@\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10839,5 +10707,9 @@\n-  match(Set dst (URShiftVS src shift));\n-  size(4*1);\n-  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n-  expand %{\n-    vsh8S_reg(dst, src, shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U16 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n@@ -10845,0 +10717,1 @@\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10860,1 +10733,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10876,1 +10749,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10879,1 +10752,1 @@\n-\/\/ Integers vector logical left\/right shift\n+\/\/ Integers vector logical left shift\n@@ -10883,5 +10756,9 @@\n-  match(Set dst (URShiftVI src shift));\n-  size(4*1);\n-  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n-  expand %{\n-    vsh2I_reg(dst, src, shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U32 $dst.D,$src.D,$shift.D\\t! logical left shift packed2I\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n@@ -10889,0 +10766,1 @@\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10894,5 +10772,9 @@\n-  match(Set dst (URShiftVI src shift));\n-  size(4*1);\n-  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n-  expand %{\n-    vsh4I_reg(dst, src, shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U32 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed4I\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n@@ -10900,0 +10782,1 @@\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10915,1 +10798,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10931,1 +10814,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10934,1 +10817,1 @@\n-\/\/ Longs vector logical left\/right shift\n+\/\/ Longs vector logical left shift\n@@ -10938,5 +10821,4 @@\n-  match(Set dst (URShiftVL src shift));\n-  size(4*1);\n-  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n-  expand %{\n-    vsh2L_reg(dst, src, shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.U64 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed2L\"\n@@ -10944,0 +10826,6 @@\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10959,1 +10847,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10969,1 +10857,1 @@\n-instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{\n+instruct vsrl4S_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n@@ -10971,3 +10859,4 @@\n-  match(Set dst (URShiftVS src (RShiftCntV shift)));\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  match(Set dst (URShiftVS src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n@@ -10975,1 +10864,2 @@\n-    \"VSHR.U16 $dst.D,$src.D,$shift\\t! logical right shift packed4S\"\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.U16 $dst.D,$src.D,$tmp.D\\t! logical right shift packed4S\"\n@@ -10979,2 +10869,4 @@\n-    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,\n-             quad);\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n@@ -10982,1 +10874,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10985,1 +10877,1 @@\n-instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{\n+instruct vsrl8S_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n@@ -10987,3 +10879,4 @@\n-  match(Set dst (URShiftVS src (RShiftCntV shift)));\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  match(Set dst (URShiftVS src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n@@ -10991,1 +10884,2 @@\n-    \"VSHR.U16 $dst.Q,$src.Q,$shift\\t! logical right shift packed8S\"\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U16 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed8S\"\n@@ -10995,2 +10889,4 @@\n-    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,\n-             quad);\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n@@ -10998,1 +10894,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11001,4 +10897,3 @@\n-\/\/ Integers vector logical right shift\n-instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n-  match(Set dst (URShiftVI src (RShiftCntV shift)));\n+instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 4);\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n@@ -11008,1 +10903,1 @@\n-    \"VSHR.U32 $dst.D,$src.D,$shift\\t! logical right shift packed2I\"\n+    \"VSHR.U16 $dst.D,$src.D,$shift\\t! logical right shift packed4S\"\n@@ -11012,18 +10907,2 @@\n-    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,\n-             quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n-  match(Set dst (URShiftVI src (RShiftCntV shift)));\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHR.U32 $dst.Q,$src.Q,$shift\\t! logical right shift packed4I\"\n-  %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,\n-             quad);\n+    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,\n+              quad);\n@@ -11031,1 +10910,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11034,4 +10913,3 @@\n-\/\/ Longs vector logical right shift\n-instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (URShiftVL src (RShiftCntV shift)));\n+instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 8);\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n@@ -11041,1 +10919,1 @@\n-    \"VSHR.U64 $dst.Q,$src.Q,$shift\\t! logical right shift packed2L\"\n+    \"VSHR.U16 $dst.Q,$src.Q,$shift\\t! logical right shift packed8S\"\n@@ -11045,2 +10923,2 @@\n-    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,\n-             quad);\n+    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,\n+              quad);\n@@ -11048,1 +10926,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11051,8 +10929,7 @@\n-\/\/ ------------------- ArithmeticRightShift -----------------------------------\n-\n-\/\/ Bytes vector arithmetic left\/right shift based on sign\n-instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n+\/\/ Integers vector logical right shift\n+instruct vsrl2I_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+  match(Set dst (URShiftVI src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n@@ -11060,1 +10937,2 @@\n-    \"VSHL.S8 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed8B\"\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.U32 $dst.D,$src.D,$tmp.D\\t! logical right shift packed2I\"\n@@ -11064,2 +10942,4 @@\n-    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n@@ -11067,1 +10947,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11070,5 +10950,6 @@\n-instruct vsha16B_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n+instruct vsrl4I_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+  match(Set dst (URShiftVI src shift));\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n@@ -11076,1 +10957,2 @@\n-    \"VSHL.S8 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed16B\"\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U32 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed4I\"\n@@ -11080,2 +10962,4 @@\n-    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n@@ -11083,1 +10967,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11086,4 +10970,3 @@\n-\/\/ Shorts vector arithmetic left\/right shift based on sign\n-instruct vsha4S_reg(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  effect(DEF dst, USE src, USE shift);\n+instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n@@ -11093,1 +10976,1 @@\n-    \"VSHL.S16 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed4S\"\n+    \"VSHR.U32 $dst.D,$src.D,$shift\\t! logical right shift packed2I\"\n@@ -11097,2 +10980,2 @@\n-    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, quad);\n+    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,\n+              quad);\n@@ -11100,1 +10983,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11103,3 +10986,3 @@\n-instruct vsha8S_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  effect(DEF dst, USE src, USE shift);\n+instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n@@ -11109,1 +10992,1 @@\n-    \"VSHL.S16 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed8S\"\n+    \"VSHR.U32 $dst.Q,$src.Q,$shift\\t! logical right shift packed4I\"\n@@ -11113,2 +10996,2 @@\n-    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, quad);\n+    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,\n+              quad);\n@@ -11116,1 +10999,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11119,2 +11002,2 @@\n-\/\/ Integers vector arithmetic left\/right shift based on sign\n-instruct vsha2I_reg(vecD dst, vecD src, vecD shift) %{\n+\/\/ Longs vector logical right shift\n+instruct vsrl2L_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n@@ -11122,19 +11005,4 @@\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.S32 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed2I\"\n-  %}\n-  ins_encode %{\n-    bool quad = false;\n-    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, quad);\n-  %}\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n-%}\n-\n-instruct vsha4I_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  effect(DEF dst, USE src, USE shift);\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  match(Set dst (URShiftVL src shift));\n+  effect(TEMP tmp, DEF dst, USE src, USE shift);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n@@ -11142,1 +11010,2 @@\n-    \"VSHL.S32 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed4I\"\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.U64 $dst.Q,$src.Q,$tmp.Q\\t! logical right shift packed2L\"\n@@ -11146,2 +11015,4 @@\n-    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, quad);\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n@@ -11149,1 +11020,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11152,2 +11023,1 @@\n-\/\/ Longs vector arithmetic left\/right shift based on sign\n-instruct vsha2L_reg(vecX dst, vecX src, vecX shift) %{\n+instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{\n@@ -11155,1 +11025,1 @@\n-  effect(DEF dst, USE src, USE shift);\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n@@ -11159,1 +11029,1 @@\n-    \"VSHL.S64 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed2L\"\n+    \"VSHR.U64 $dst.Q,$src.Q,$shift\\t! logical right shift packed2L\"\n@@ -11163,2 +11033,2 @@\n-    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_64, quad);\n+    __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,\n+              quad);\n@@ -11166,1 +11036,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11169,1 +11039,1 @@\n-\/\/ Byte vector arithmetic right shift\n+\/\/ ------------------- ArithmeticRightShift -----------------------------------\n@@ -11171,1 +11041,2 @@\n-instruct vsra8B_reg(vecD dst, vecD src, vecD shift) %{\n+\/\/ Byte vector arithmetic right shift\n+instruct vsra8B_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n@@ -11174,4 +11045,13 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  expand %{\n-    vsha8B_reg(dst, src, shift);\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S8 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed8B\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n@@ -11179,0 +11059,1 @@\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11181,1 +11062,1 @@\n-instruct vsrl16B_reg(vecX dst, vecX src, vecX shift) %{\n+instruct vsra16B_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n@@ -11184,4 +11065,6 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  expand %{\n-    vsha16B_reg(dst, src, shift);\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S8 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed16B\"\n@@ -11189,0 +11072,8 @@\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11191,1 +11082,1 @@\n-instruct vsrl8B_immI(vecD dst, vecD src, immI shift) %{\n+instruct vsra8B_immI(vecD dst, vecD src, immI shift) %{\n@@ -11193,1 +11084,1 @@\n-  match(Set dst (RShiftVB src shift));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -11197,1 +11088,1 @@\n-    \"VSHR.S8 $dst.D,$src.D,$shift\\t! logical right shift packed8B\"\n+    \"VSHR.S8 $dst.D,$src.D,$shift\\t! arithmetic right shift packed8B\"\n@@ -11202,1 +11093,1 @@\n-             quad);\n+              quad);\n@@ -11204,1 +11095,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11207,1 +11098,1 @@\n-instruct vsrl16B_immI(vecX dst, vecX src, immI shift) %{\n+instruct vsra16B_immI(vecX dst, vecX src, immI shift) %{\n@@ -11209,1 +11100,1 @@\n-  match(Set dst (RShiftVB src shift));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -11213,1 +11104,1 @@\n-    \"VSHR.S8 $dst.Q,$src.Q,$shift\\t! logical right shift packed16B\"\n+    \"VSHR.S8 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed16B\"\n@@ -11218,1 +11109,1 @@\n-             quad);\n+              quad);\n@@ -11220,1 +11111,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11224,1 +11115,1 @@\n-instruct vsra4S_reg(vecD dst, vecD src, vecD shift) %{\n+instruct vsra4S_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n@@ -11227,4 +11118,6 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  expand %{\n-    vsha4S_reg(dst, src, shift);\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S16 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed4S\"\n@@ -11232,0 +11125,8 @@\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11234,1 +11135,1 @@\n-instruct vsra8S_reg(vecX dst, vecX src, vecX shift) %{\n+instruct vsra8S_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n@@ -11237,4 +11138,13 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  expand %{\n-    vsha8S_reg(dst, src, shift);\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S16 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n@@ -11242,0 +11152,1 @@\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11246,1 +11157,1 @@\n-  match(Set dst (RShiftVS src shift));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -11250,1 +11161,1 @@\n-    \"VSHR.S16 $dst.D,$src.D,$shift\\t! logical right shift packed4S\"\n+    \"VSHR.S16 $dst.D,$src.D,$shift\\t! arithmetic right shift packed4S\"\n@@ -11255,1 +11166,1 @@\n-             quad);\n+              quad);\n@@ -11257,1 +11168,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11262,1 +11173,1 @@\n-  match(Set dst (RShiftVS src shift));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -11266,1 +11177,1 @@\n-    \"VSHR.S16 $dst.Q,$src.Q,$shift\\t! logical right shift packed8S\"\n+    \"VSHR.S16 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed8S\"\n@@ -11271,1 +11182,1 @@\n-             quad);\n+              quad);\n@@ -11273,1 +11184,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11277,1 +11188,1 @@\n-instruct vsra2I_reg(vecD dst, vecD src, vecD shift) %{\n+instruct vsra2I_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n@@ -11280,4 +11191,6 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  expand %{\n-    vsha2I_reg(dst, src, shift);\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{\n+    \"VNEG.S8 $tmp.D,$shift.D\\n\\t! neg packed8B\"\n+    \"VSHL.S32 $dst.D,$src.D,$tmp.D\\t! arithmetic right shift packed2I\"\n@@ -11285,0 +11198,8 @@\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11287,1 +11208,1 @@\n-instruct vsra4I_reg(vecX dst, vecX src, vecX shift) %{\n+instruct vsra4I_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n@@ -11290,4 +11211,6 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  expand %{\n-    vsha4I_reg(dst, src, shift);\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S32 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed4I\"\n@@ -11295,0 +11218,8 @@\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11299,1 +11230,1 @@\n-  match(Set dst (RShiftVI src shift));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -11303,1 +11234,1 @@\n-    \"VSHR.S32 $dst.D,$src.D,$shift\\t! logical right shift packed2I\"\n+    \"VSHR.S32 $dst.D,$src.D,$shift\\t! arithmetic right shift packed2I\"\n@@ -11308,1 +11239,1 @@\n-             quad);\n+              quad);\n@@ -11310,1 +11241,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11315,1 +11246,1 @@\n-  match(Set dst (RShiftVI src shift));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -11319,1 +11250,1 @@\n-    \"VSHR.S32 $dst.Q,$src.Q,$shift\\t! logical right shift packed4I\"\n+    \"VSHR.S32 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed4I\"\n@@ -11324,1 +11255,1 @@\n-             quad);\n+              quad);\n@@ -11326,1 +11257,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11330,1 +11261,1 @@\n-instruct vsra2L_reg(vecX dst, vecX src, vecX shift) %{\n+instruct vsra2L_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n@@ -11333,4 +11264,13 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  expand %{\n-    vsha2L_reg(dst, src, shift);\n+  effect(TEMP tmp);\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{\n+    \"VNEG.S8 $tmp.Q,$shift.Q\\n\\t! neg packed16B\"\n+    \"VSHL.S64 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic right shift packed2L\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n@@ -11338,0 +11278,1 @@\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -11342,1 +11283,1 @@\n-  match(Set dst (RShiftVL src shift));\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n@@ -11346,1 +11287,1 @@\n-    \"VSHR.S64 $dst.Q,$src.Q,$shift\\t! logical right shift packed2L\"\n+    \"VSHR.S64 $dst.Q,$src.Q,$shift\\t! arithmetic right shift packed2L\"\n@@ -11351,1 +11292,1 @@\n-             quad);\n+              quad);\n@@ -11353,1 +11294,1 @@\n-  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+  ins_pipe(ialu_reg_reg); \/\/ FIXME\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":311,"deletions":370,"binary":false,"changes":681,"status":"modified"}]}